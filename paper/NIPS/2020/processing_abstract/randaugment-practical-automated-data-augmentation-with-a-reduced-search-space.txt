Recent work on automated data augmentation strategies has led to state-of-the-art results in image classiﬁcation and object detection. An obstacle to a large-scale adoption of these methods is that they require a separate and expensive search phase. A common way to overcome the expense of the search phase was to use a smaller proxy task. However, it was not clear if the optimized hyperparameters found on the proxy task are also optimal for the actual task. In this work, we rethink the process of designing automated data augmentation strategies.We ﬁnd that while previous work required searching for many augmentation parameters (e.g. magnitude and probability) independently for each augmentation operation, it is sufﬁcient to only search for a single parameter that jointly controls all operations. Hence, we propose a search space that is vastly smaller (e.g. from 1032 to 102 potential candidates). The smaller search space signiﬁcantly reduces the computational expense of automated data augmentation and permits the removal of a separate proxy task. Despite the simpliﬁcations, our method achieves state-of-the-art performance on CIFAR-10, SVHN, and ImageNet. On EfﬁcientNet-B7, we achieve 84.7% accuracy, a 1.0% increase over baseline augmentation and a 0.4% improvement over AutoAugment on the ImageNet dataset. On object detection, the same method used for classiﬁcation leads to 1.0-1.3% improvement over the baseline augmentation method on COCO. Code is available online. 2 3 