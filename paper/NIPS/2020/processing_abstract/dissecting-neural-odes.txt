Continuous deep learning architectures have recently re–emerged as Neural Or-dinary Differential Equations (Neural ODEs). This inﬁnite–depth approach theo-retically bridges the gap between deep learning and dynamical systems, offering a novel perspective. However, deciphering the inner working of these models is still an open challenge, as most applications apply them as generic black–box modules. In this work we “open the box”, further developing the continuous–depth formulation with the aim of clarifying the inﬂuence of several design choices on the underlying dynamics. 