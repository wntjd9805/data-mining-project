Current deep neural networks can achieve remarkable performance on a single task. However, when the deep neural network is continually trained on a sequence of tasks, it seems to gradually forget the previous learned knowledge. This phe-nomenon is referred to as catastrophic forgetting and motivates the ﬁeld called lifelong learning. Recently, episodic memory based approaches such as GEM [1] and A-GEM [2] have shown remarkable performance. In this paper, we provide the ﬁrst uniﬁed view of episodic memory based approaches from an optimization’s perspective. This view leads to two improved schemes for episodic memory based lifelong learning, called MEGA-I and MEGA-II. MEGA-I and MEGA-II mod-ulate the balance between old tasks and the new task by integrating the current gradient with the gradient computed on the episodic memory. Notably, we show that GEM and A-GEM are degenerate cases of MEGA-I and MEGA-II which consistently put the same emphasis on the current task, regardless of how the loss changes over time. Our proposed schemes address this issue by using novel loss-balancing updating rules, which drastically improve the performance overGEM and A-GEM. Extensive experimental results show that the proposed schemes signiﬁcantly advance the state-of-the-art on four commonly used lifelong learning benchmarks, reducing the error by up to 18%. Implementation is available at: https://github.com/yunhuiguo/MEGA