We present an efﬁcient and practical (polynomial time) algorithm for online pre-diction in unknown and partially observed linear dynamical systems (LDS) under stochastic noise. When the system parameters are known, the optimal linear predic-tor is the Kalman ﬁlter. However, in unknown systems, the performance of existing predictive models is poor in important classes of LDS that are only marginally stable and exhibit long-term forecast memory. We tackle this problem by bounding the generalized Kolmogorov width of the Kalman ﬁlter coefﬁcient set. This moti-vates the design of an algorithm, which we call spectral LDS improper predictor (SLIP), based on conducting a tight convex relaxation of the Kalman predictive model via spectral methods. We provide a ﬁnite-sample analysis, showing that our algorithm competes with the Kalman ﬁlter in hindsight with only logarithmic regret.Our regret analysis relies on Mendelson’s small-ball method, providing sharp error bounds without concentration, boundedness, or exponential forgetting assumptions.Empirical evaluations demonstrate that SLIP outperforms state-of-the-art methods in LDS prediction. Our theoretical and experimental results shed light on the conditions required for efﬁcient probably approximately correct (PAC) learning of the Kalman ﬁlter from partially observed data. 