Most state-of-the-art deep geometric learning single-view reconstruction ap-proaches rely on encoder-decoder architectures that output either shape parametriza-tions [7, 8, 23] or implicit representations [14, 26, 4]. However, these representa-tions rarely preserve the Euclidean structure of the 3D space objects exist in. In this paper, we show that building a geometry preserving 3-dimensional latent space helps the network concurrently learn global shape regularities and local reasoning in the object coordinate space and, as a result, boosts performance.We demonstrate both on ShapeNet synthetic images, which are often used for benchmarking purposes, and on real-world images that our approach outperforms state-of-the-art ones. Furthermore, the single-view pipeline naturally extends to multi-view reconstruction, which we also show. 