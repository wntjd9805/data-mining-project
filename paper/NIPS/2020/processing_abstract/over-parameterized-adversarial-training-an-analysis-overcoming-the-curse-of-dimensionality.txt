Adversarial training is a popular method to give neural nets robustness againstIn practice adversarial training leads to low robust adversarial perturbations. training loss. However, a rigorous explanation for why this happens under natural conditions is still missing. Recently a convergence theory for standard (non-adversarial) training was developed by various groups for very over-parametrized nets. It is unclear how to extend these results to adversarial training because of the min-max objective. Recently, a Ô¨Årst step towards this direction was made by [14] using tools from online learning, but they require the width of the net and the running time to be exponential in input dimension d, and they consider an activation function that is not used in practice. Our work proves convergence to low robust training loss for polynomial width and running time, instead of exponential, under natural assumptions and with ReLU activation. Key element of our proof is showing that ReLU networks near initialization can approximate the step function, which may be of independent interest. 