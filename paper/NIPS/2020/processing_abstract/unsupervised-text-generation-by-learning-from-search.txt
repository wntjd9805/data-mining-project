In this work, we propose TGLS, a novel framework for unsupervised TextGeneration by Learning from Search. We start by applying a strong search algorithm (in particular, simulated annealing) towards a heuristically deﬁned objective that (roughly) estimates the quality of sentences. Then, a conditional generative model learns from the search results, and meanwhile smooth out the noise of search. The alternation between search and learning can be repeated for performance bootstrap-ping. We demonstrate the effectiveness of TGLS on two real-world natural language generation tasks, unsupervised paraphrasing and text formalization. Our model signiﬁcantly outperforms unsupervised baseline methods in both tasks. Especially, it achieves comparable performance to strong supervised methods for paraphrase generation.1 