Contrastive learning applied to self-supervised representation learning has seen a resurgence in recent years, leading to state of the art performance in the unsu-pervised training of deep image models. Modern batch contrastive approaches subsume or signiﬁcantly outperform traditional contrastive losses such as triplet,In this work, we extend the self-supervised max-margin and the N-pairs loss. batch contrastive approach to the fully-supervised setting, allowing us to effec-tively leverage label information. Clusters of points belonging to the same class are pulled together in embedding space, while simultaneously pushing apart clus-ters of samples from different classes. We analyze two possible versions of the supervised contrastive (SupCon) loss, identifying the best-performing formula-tion of the loss. On ResNet-200, we achieve top-1 accuracy of 81.4% on the Ima-geNet dataset, which is 0.8% above the best number reported for this architecture.We show consistent outperformance over cross-entropy on other datasets and twoResNet variants. The loss shows beneﬁts for robustness to natural corruptions, and is more stable to hyperparameter settings such as optimizers and data aug-mentations. Our loss function is simple to implement and reference TensorFlow code is released at https://t.ly/supcon 1. 