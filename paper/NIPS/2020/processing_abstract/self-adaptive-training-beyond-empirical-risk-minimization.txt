We propose self-adaptive training—a new training algorithm that dynamically calibrates training process by model predictions without incurring extra computa-tional cost—to improve generalization of deep learning for potentially corrupted training data. This problem is important to robustly learning from data that are corrupted by, e.g., random noise and adversarial examples. The standard empir-ical risk minimization (ERM) for such data, however, may easily overﬁt noise and thus suffers from sub-optimal performance. In this paper, we observe that model predictions can substantially beneﬁt the training process: self-adaptive training signiﬁcantly mitigates the overﬁtting issue and improves generalization over ERM under both random and adversarial noise. Besides, in sharp contrast to the recently-discovered double-descent phenomenon in ERM, self-adaptive training exhibits a single-descent error-capacity curve, indicating that such a phe-nomenon might be a result of overﬁtting of noise. Experiments on the CIFAR andImageNet datasets verify the effectiveness of our approach in two applications: classiﬁcation with label noise and selective classiﬁcation. The code is available at https://github.com/LayneH/self-adaptive-training. 