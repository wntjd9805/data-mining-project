Convolutional Neural Networks (CNNs) have shown impressive performance in computer vision tasks such as image classiﬁcation, detection, and segmentation.Moreover, recent work in Generative Adversarial Networks (GANs) has high-lighted the importance of learning by progressively increasing the difﬁculty of a learning task [26]. When learning a network from scratch, the information propa-gated within the network during the earlier stages of training can contain distortion artifacts due to noise which can be detremental to training. In this paper, we pro-pose an elegant curriculum-based scheme that smoothes the feature embedding of a CNN using anti-aliasing or low-pass ﬁlters. We propose to augment the train-ing of CNNs by controlling the amount of high frequency information propagated within the CNNs as training progresses, by convolving the output of a CNN fea-ture map of each layer with a Gaussian kernel. By decreasing the variance of theGaussian kernel, we gradually increase the amount of high-frequency informa-tion available within the network for inference. As the amount of information in the feature maps increases during training, the network is able to progressively learn better representations of the data. Our proposed augmented training scheme signiﬁcantly improves the performance of CNNs on various vision tasks without either adding additional trainable parameters or an auxiliary regularization objec-tive. The generality of our method is demonstrated through empirical performance gains in CNN architectures across four different tasks: transfer learning, cross-task transfer learning, and generative models. The code will soon be released at www.github.com/pairlab/CBS. 