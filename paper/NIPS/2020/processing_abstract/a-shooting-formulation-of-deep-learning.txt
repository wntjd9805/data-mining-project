A residual network may be regarded as a discretization of an ordinary differential equation (ODE) which, in the limit of time discretization, deﬁnes a continuous-depth network. Although important steps have been taken to realize the advantages of such continuous formulations, most current techniques assume identical lay-ers. Indeed, existing works throw into relief the myriad difﬁculties of learning an inﬁnite-dimensional parameter in a continuous-depth neural network. To this end, we introduce a shooting formulation which shifts the perspective from pa-rameterizing a network layer-by-layer to parameterizing over optimal networks described only by a set of initial conditions. For scalability, we propose a novel particle-ensemble parameterization which fully speciﬁes the optimal weight tra-jectory of the continuous-depth neural network. Our experiments show that our particle-ensemble shooting formulation can achieve competitive performance. Fi-nally, though the current work is inspired by continuous-depth neural networks, the particle-ensemble shooting formulation also applies to discrete-time networks and may lead to a new fertile area of research in deep learning parameterization. 