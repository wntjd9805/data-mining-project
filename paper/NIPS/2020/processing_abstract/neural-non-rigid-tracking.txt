We introduce a novel, end-to-end learnable, differentiable non-rigid tracker that enables state-of-the-art non-rigid reconstruction by a learned robust optimization.Given two input RGB-D frames of a non-rigidly moving object, we employ a convolutional neural network to predict dense correspondences and their conﬁ-dences. These correspondences are used as constraints in an as-rigid-as-possible (ARAP) optimization problem. By enabling gradient back-propagation through the weighted non-linear least squares solver, we are able to learn correspondences and conﬁdences in an end-to-end manner such that they are optimal for the task of non-rigid tracking. Under this formulation, correspondence conﬁdences can be learned via self-supervision, informing a learned robust optimization, where outliers and wrong correspondences are automatically down-weighted to enable effective track-ing. Compared to state-of-the-art approaches, our algorithm shows improved reconstruction performance, while simultaneously achieving 85× faster correspon-dence prediction than comparable deep-learning based methods. We make our code available at https://github.com/DeformableFriends/NeuralTracking. 