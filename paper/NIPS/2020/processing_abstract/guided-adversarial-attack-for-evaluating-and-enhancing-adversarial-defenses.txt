Advances in the development of adversarial attacks have been fundamental to the progress of adversarial defense research. Efﬁcient and effective attacks are crucial for reliable evaluation of defenses, and also for developing robust models.Adversarial attacks are often generated by maximizing standard losses such as the cross-entropy loss or maximum-margin loss within a constraint set using ProjectedGradient Descent (PGD). In this work, we introduce a relaxation term to the standard loss, that ﬁnds more suitable gradient-directions, increases attack efﬁcacy and leads to more efﬁcient adversarial training. We propose Guided AdversarialMargin Attack (GAMA), which utilizes function mapping of the clean image to guide the generation of adversaries, thereby resulting in stronger attacks. We evaluate our attack against multiple defenses and show improved performance when compared to existing attacks. Further, we propose Guided Adversarial Training (GAT), which achieves state-of-the-art performance amongst single-step defenses by utilizing the proposed relaxation term for both attack generation and training. 