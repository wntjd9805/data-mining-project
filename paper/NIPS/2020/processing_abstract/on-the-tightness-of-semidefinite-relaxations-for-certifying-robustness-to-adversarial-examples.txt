The robustness of a neural network to adversarial examples can be provably certiﬁed by solving a convex relaxation.If the relaxation is loose, however, then the resulting certiﬁcate can be too conservative to be practically useful. Recently, a less conservative robustness certiﬁcate was proposed, based on a semideﬁnite programming (SDP) relaxation of the ReLU activation function. In this paper, we describe a geometric technique that determines whether this SDP certiﬁcate is exact, meaning whether it provides both a lower-bound on the size of the smallest adversarial perturbation, as well as a globally optimal perturbation that attains the lower-bound. Concretely, we show, for a least-squares restriction of the usual adversarial attack problem, that the SDP relaxation amounts to the nonconvex projection of a point onto a hyperbola. The resulting SDP certiﬁcate is exact if and only if the projection of the point lies on the major axis of the hyperbola.Using this geometric technique, we prove that the certiﬁcate is exact over a single hidden layer under mild assumptions, and explain why it is usually conservative for several hidden layers. We experimentally conﬁrm our theoretical insights using a general-purpose interior-point method and a custom rank-2 Burer-Monteiro algorithm. 