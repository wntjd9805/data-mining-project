We propose a novel lightweight generative adversarial network for efﬁcient image manipulation using natural language descriptions. To achieve this, a new word-level discriminator is proposed, which provides the generator with ﬁne-grained training feedback at word-level, to facilitate training a lightweight generator that has a small number of parameters, but can still correctly focus on speciﬁc visual attributes of an image, and then edit them without affecting other contents that are not described in the text. Furthermore, thanks to the explicit training signal related to each word, the discriminator can also be simpliﬁed to have a lightweight structure. Compared with the state of the art, our method has a much smaller number of parameters, but still achieves a competitive manipulation performance. Extensive experimental results demonstrate that our method can better disentangle different visual attributes, then correctly map them to corresponding semantic words, and thus achieve a more accurate image modiﬁcation using natural language descriptions. 