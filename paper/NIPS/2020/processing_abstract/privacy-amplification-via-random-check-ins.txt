Differentially Private Stochastic Gradient Descent (DP-SGD) forms a fundamen-tal building block in many applications for learning over sensitive data. Two stan-dard approaches, privacy ampliﬁcation by subsampling, and privacy ampliﬁcation by shufﬂing, permit adding lower noise in DP-SGD than via na¨ıve schemes. A key assumption in both these approaches is that the elements in the data set can be uniformly sampled, or be uniformly permuted — constraints that may become prohibitive when the data is processed in a decentralized or distributed fashion.In this paper, we focus on conducting iterative methods like DP-SGD in the set-ting of federated learning (FL) wherein the data is distributed among many de-vices (clients). Our main contribution is the random check-in distributed protocol, which crucially relies only on randomized participation decisions made locallyIt has privacy/accuracy trade-offs similar to and independently by each client. privacy ampliﬁcation by subsampling/shufﬂing. However, our method does not require server-initiated communication, or even knowledge of the population size.To our knowledge, this is the ﬁrst privacy ampliﬁcation tailored for a distributed learning framework, and it may have broader applicability beyond FL. Along the way, we improve the privacy guarantees of ampliﬁcation by shufﬂing and show that, in practical regimes, this improvement allows for similar privacy and utility using data from an order of magnitude fewer users. 