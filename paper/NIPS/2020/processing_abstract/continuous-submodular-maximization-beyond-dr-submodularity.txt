In this paper, we propose the ﬁrst continuous optimization algorithms that achieve a constant factor approximation guarantee for the problem of monotone continuous submodular maximization subject to a linear constraint. We ﬁrst prove that a simple variant of the vanilla coordinate ascent, called COORDINATE-ASCENT+, achieves a ( e−1 2e−1 − ε)-approximation guarantee while performing O(n/ε) iterations, where the computational complexity of each iteration is roughly O(n/ε + n log n) (here, n denotes the dimension of the optimization problem). We then proposeCOORDINATE-ASCENT++, that achieves the tight (1 − 1/e − ε)-approximation guarantee while performing the same number of iterations, but at a higher computa-tional complexity of roughly O(n3/ε2.5 + n3 log n/ε2) per iteration. However, the computation of each round of COORDINATE-ASCENT++ can be easily parallelized so that the computational cost per machine scales as O(n/ε + n log n).√√ 