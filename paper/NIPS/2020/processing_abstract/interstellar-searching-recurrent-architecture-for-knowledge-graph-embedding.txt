Knowledge graph (KG) embedding is well-known in learning representations ofKGs. Many models have been proposed to learn the interactions between enti-ties and relations of the triplets. However, long-term information among multiple triplets is also important to KG. In this work, based on the relational paths, which are composed of a sequence of triplets, we deﬁne the Interstellar as a recurrent neural architecture search problem for the short-term and long-term information along the paths. First, we analyze the difﬁculty of using a uniﬁed model to work as the Interstellar. Then, we propose to search for recurrent architecture as theInterstellar for different KG tasks. A case study on synthetic data illustrates the importance of the deﬁned search problem. Experiments on real datasets demon-strate the effectiveness of the searched models and the efﬁciency of the proposed hybrid-search algorithm. 1 