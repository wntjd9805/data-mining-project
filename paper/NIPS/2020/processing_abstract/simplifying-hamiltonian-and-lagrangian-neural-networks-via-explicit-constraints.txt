Reasoning about the physical world requires models that are endowed with the right inductive biases to learn the underlying dynamics. Recent works im-prove generalization for predicting trajectories by learning the Hamiltonian or La-grangian of a system rather than the differential equations directly. While these methods encode the constraints of the systems using generalized coordinates, we show that embedding the system into Cartesian coordinates and enforcing the con-straints explicitly with Lagrange multipliers dramatically simpliﬁes the learning problem. We introduce a series of challenging chaotic and extended-body sys-tems, including systems with N -pendulums, spring coupling, magnetic ﬁelds, rigid rotors, and gyroscopes, to push the limits of current approaches. Our ex-periments show that Cartesian coordinates with explicit constraints lead to a 100x improvement in accuracy and data efﬁciency.Figure 1: By using Cartesian coordinates with explicit constraints, we simplify the Hamiltonians and La-grangians that our models learn, resulting in better long term predictions and data-efﬁciency than Neural ODEs and Hamiltonian Neural Networks (HNNs). Left: a spinning gyroscope with the ground truth trajectory and predictions of each model. Predicted trajectories by our model (CHNN) overlaps almost exactly with the ground truth (black). Middle: Geometric mean of the relative error over 100 timesteps as a function of number of training trajectories. On the gyroscope system, our model can be 100 times more data efﬁcient or 260 times more accurate. Right: The Hamiltonian expressed in Cartesian coordinates is simpler and easier to learn than when expressed in angular coordinates. 