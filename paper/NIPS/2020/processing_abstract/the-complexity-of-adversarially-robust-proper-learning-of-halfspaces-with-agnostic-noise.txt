We study the computational complexity of adversarially robust proper learning of halfspaces in the distribution-independent agnostic PAC model, with a focus on Lp perturbations. We give a computationally efﬁcient learning algorithm and a nearly matching computational hardness result for this problem. An interesting implication of our ﬁndings is that the L perturbations case is provably computationally harder than the case 2. p < 1 1 