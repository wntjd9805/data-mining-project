Automatic differentiation, as implemented today, does not have a simple mathe-matical model adapted to the needs of modern machine learning. In this work we articulate the relationships between differentiation of programs as implemented in practice and differentiation of nonsmooth functions. To this end we provide a simple class of functions, a nonsmooth calculus, and show how they apply to stochastic approximation methods. We also evidence the issue of artiÔ¨Åcial critical points created by algorithmic differentiation and show how usual methods avoid these points with probability one. 