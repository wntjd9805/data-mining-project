The objective in statistical Optimal Transport (OT) is to consistently estimate the optimal transport plan/map solely using samples from the given source and target marginal distributions. This work takes the novel approach of posing statisticalOT as that of learning the transport plan’s kernel mean embedding from sample based estimates of marginal embeddings. The proposed estimator controls over-ﬁtting by employing maximum mean discrepancy based regularization, which is complementary to φ-divergence (entropy) based regularization popularly employed in existing estimators. A key result is that, under very mild conditions, (cid:15)-optimal recovery of the transport plan as well as the Barycentric-projection based transport map is possible with a sample complexity that is completely dimension-free. More-over, the implicit smoothing in the kernel mean embeddings enables out-of-sample estimation. An appropriate representer theorem is proved leading to a kernelized convex formulation for the estimator, which can then be potentially used to performOT even in non-standard domains. Empirical results illustrate the efﬁcacy of the proposed approach. 