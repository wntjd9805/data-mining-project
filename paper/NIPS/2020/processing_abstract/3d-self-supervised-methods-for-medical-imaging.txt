Self-supervised learning methods have witnessed a recent surge of interest after proving successful in multiple application ﬁelds. In this work, we leverage these techniques, and we propose 3D versions for ﬁve different self-supervised methods, in the form of proxy tasks. Our methods facilitate neural network feature learning from unlabeled 3D images, aiming to reduce the required cost for expert annotation.The developed algorithms are 3D Contrastive Predictive Coding, 3D Rotation prediction, 3D Jigsaw puzzles, Relative 3D patch location, and 3D Exemplar networks. Our experiments show that pretraining models with our 3D tasks yields more powerful semantic representations, and enables solving downstream tasks more accurately and efﬁciently, compared to training the models from scratch and to pretraining them on 2D slices. We demonstrate the effectiveness of our methods on three downstream tasks from the medical imaging domain: i) BrainTumor Segmentation from 3D MRI, ii) Pancreas Tumor Segmentation from 3DCT, and iii) Diabetic Retinopathy Detection from 2D Fundus images. In each task, we assess the gains in data-efﬁciency, performance, and speed of convergence.Interestingly, we also ﬁnd gains when transferring the learned representations, by our methods, from a large unlabeled 3D corpus to a small downstream-speciﬁc dataset. We achieve results competitive to state-of-the-art solutions at a fraction of the computational expense. We publish our implementations1 for the developed algorithms (both 3D and 2D versions) as an open-source library, in an effort to allow other researchers to apply and extend our methods on their datasets. 