The performance of deep (reinforcement) learning systems crucially depends on the choice of hyperparameters. Their tuning is notoriously expensive, typically requiring an iterative training process to run for numerous steps to convergence.Traditional tuning algorithms only consider the ﬁnal performance of hyperparam-eters acquired after many expensive iterations and ignore intermediate information from earlier training steps. In this paper, we present a Bayesian optimization (BO) approach which exploits the iterative structure of learning algorithms for efﬁcient hyperparameter tuning. We propose to learn an evaluation function compress-ing learning progress at any stage of the training process into a single numeric score according to both training success and stability. Our BO framework is then balancing the beneﬁt of assessing a hyperparameter setting over additional train-ing steps against their computation cost. We further increase model efﬁciency by selectively including scores from different training steps for any evaluated hyper-parameter set. We demonstrate the efﬁciency of our algorithm by tuning hyperpa-rameters for the training of deep reinforcement learning agents and convolutional neural networks. Our algorithm outperforms all existing baselines in identifying optimal hyperparameters in minimal time. 