JSelf-supervised frameworks that learn denoising models with merely individual noisy images have shown strong capability and promising performance in various image denoising tasks. Existing self-supervised denoising frameworks are mostly built upon the same theoretical foundation, where the denoising models are required-invariant. However, our analyses indicate that the current theory and the to be-invariance may lead to denoising models with reduced performance. In thisJ work, we introduce Noise2Same, a novel self-supervised denoising framework. InNoise2Same, a new self-supervised loss is proposed by deriving a self-supervised upper bound of the typical supervised loss. In particular, Noise2Same requires-invariance nor extra information about the noise model and can be used neither in a wider range of denoising applications. We analyze our proposed Noise2Same both theoretically and experimentally. The experimental results show that ourNoise2Same consistently outperforms previous self-supervised denoising methods in terms of denoising performance and training efÔ¨Åciency.J 