The accuracy of deep convolutional neural networks (CNNs) generally improves when fueled with high resolution images. However, this often comes at a high computational cost and high memory footprint.Inspired by the fact that not all regions in an image are task-relevant, we propose a novel framework that performs efﬁcient image classiﬁcation by processing a sequence of relatively small inputs, which are strategically selected from the original image with reinforcement learning. Such a dynamic decision process naturally facilitates adaptive inference at test time, i.e., it can be terminated once the model is sufﬁciently conﬁdent about its prediction and thus avoids further redundant computation. Notably, our framework is general and ﬂexible as it is compatible with most of the state-of-the-art light-weighted CNNs (such as MobileNets, EfﬁcientNets and RegNets), which can be conveniently deployed as the backbone feature extractor. Experiments onImageNet show that our method consistently improves the computational efﬁciency of a wide variety of deep models. For example, it further reduces the average latency of the highly efﬁcient MobileNet-V3 on an iPhone XS Max by 20% without sacriﬁcing accuracy. Code and pre-trained models are available at https://github.com/blackfeather-wang/GFNet-Pytorch. 