Transfer learning is a widely-used paradigm in which models pre-trained on stan-dard datasets can efﬁciently adapt to downstream tasks. Typically, better pre-trained models yield better transfer results, suggesting that initial accuracy is a key aspect of transfer learning performance. In this work, we identify another such aspect: we ﬁnd that adversarially robust models, while less accurate, of-ten perform better than their standard-trained counterparts when used for trans-fer learning. Speciﬁcally, we focus on adversarially robust ImageNet classi-ﬁers, and show that they yield improved accuracy on a standard suite of down-stream classiﬁcation tasks. Further analysis uncovers more differences between robust and standard models in the context of transfer learning. Our results are consistent with (and in fact, add to) recent hypotheses stating that robustness leads to improved feature representations. Our code and models are available at https://github.com/Microsoft/robust-models-transfer. 