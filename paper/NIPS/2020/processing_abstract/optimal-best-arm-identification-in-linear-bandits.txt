We study the problem of best-arm identiﬁcation with ﬁxed conﬁdence in stochastic linear bandits. The objective is to identify the best arm with a given level of cer-tainty while minimizing the sampling budget. We devise a simple algorithm whose sampling complexity matches known instance-speciﬁc lower bounds, asymptoti-cally almost surely and in expectation. The algorithm relies on an arm sampling rule that tracks an optimal proportion of arm draws, and that remarkably can be updated as rarely as we wish, without compromising its theoretical guarantees.Moreover, unlike existing best-arm identiﬁcation strategies, our algorithm uses a stopping rule that does not depend on the number of arms. Experimental results suggest that our algorithm signiﬁcantly outperforms existing algorithms. The paper further provides a ﬁrst analysis of the best-arm identiﬁcation problem in linear bandits with a continuous set of arms. 