Temporal point process (TPP) models combined with recurrent neural networks provide a powerful framework for modeling continuous-time event data. While such models are ﬂexible, they are inherently sequential and therefore cannot beneﬁt from the parallelism of modern hardware. By exploiting the recent developments in the ﬁeld of normalizing ﬂows, we design TriTPP— a new class of non-recurrentTPP models, where both sampling and likelihood computation can be done in parallel. TriTPP matches the ﬂexibility of RNN-based methods but permits orders of magnitude faster sampling. This enables us to use the new model for variational inference in continuous-time discrete-state systems. We demonstrate the advantages of the proposed framework on synthetic and real-world datasets. 