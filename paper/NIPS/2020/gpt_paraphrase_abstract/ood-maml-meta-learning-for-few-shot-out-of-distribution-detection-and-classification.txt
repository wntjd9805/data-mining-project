We present a novel approach for identifying unseen classes and classifying known classes using only a few labeled examples. Our method, called OOD-MAML, utilizes model-agnostic meta learning and generates synthetic out-of-distribution (OOD) samples that resemble in-distribution samples. These initial fake samples are learned alongside the model initialization and can be quickly adapted to new tasks with minimal gradient updates. During testing, OOD-MAML converts the classification task into multiple OOD detection sub-tasks, allowing simultaneous classification and OOD detection without the need for re-training. This approach is advantageous when the number of classes in the test task differs from the training tasks. Our experiments on benchmark datasets demonstrate the effectiveness of OOD-MAML.