This paper presents a new framework for analyzing the convergence of various Q-learning algorithms from a switching system perspective. It demonstrates that the nonlinear ODE models associated with Q-learning and its variants can be formulated as affine switching systems. By leveraging their asymptotic stability, the paper achieves several noteworthy outcomes: (i) it offers a straightforward ODE analysis for the convergence of asynchronous Q-learning with minimal assumptions; (ii) it presents the first convergence analysis of the averaging Q-learning algorithm; and (iii) it establishes a new sufficient condition for the convergence of Q-learning with linear function approximation.