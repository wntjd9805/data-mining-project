This paper introduces competitive algorithms for a new type of online optimization problems that involve memory. In this scenario, the learner aims to minimize the combined cost of hitting and switching, where the switching cost depends on the previous p decisions. This extends the concept of Smoothed Online Convex Optimization. The proposed method, Optimistic Regularized Online Balanced Descent, achieves a competitive ratio that remains constant and independent of the problem's dimension. Additionally, we establish a relationship between online optimization with memory and online control with adversarial disturbances. This connection leads to a constant-competitive policy for a diverse range of online control problems.