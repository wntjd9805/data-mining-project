We investigate an online learning problem that considers individual fairness as a constraint, meaning that similar individuals should be treated similarly. Unlike previous research on individual fairness, we do not assume knowledge of the similarity measure among individuals or a specific parametric form for such measure. Instead, we utilize an auditor who can identify fairness violations without quantifying the measure. In each round, the auditor examines the learner's decisions and tries to detect unfair treatment towards a pair of individuals. We develop a general framework that reduces online classification in our model to standard online classification, allowing us to utilize existing online learning algorithms to achieve sub-linear regret and minimize fairness violations. Surprisingly, in the stochastic setting where data is independently drawn from a distribution, we can also establish PAC-style fairness and accuracy guarantees, even with limited fairness feedback. Our fairness generalization bound matches the uniform convergence bound of Rothblum and Yona (2018) qualitatively, while also providing a meaningful accuracy generalization guarantee. Our findings address a previously unanswered question by Gillen et al. (2018) by demonstrating the feasibility of online learning under an unknown individual fairness constraint without assuming a strong parametric form for the similarity measure.