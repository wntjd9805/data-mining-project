To effectively reason about the physical world, it is necessary to have models that possess the appropriate inductive biases to learn the underlying dynamics. Recent studies have improved generalization in trajectory prediction by teaching models the Hamiltonian or Lagrangian of a system instead of the differential equations directly. Although these methods incorporate the system's constraints using generalized coordinates, we demonstrate that embedding the system into Cartesian coordinates and explicitly enforcing the constraints with Lagrange multipliers greatly simplifies the learning task. We present a range of complex chaotic and extended-body systems, such as systems with multiple pendulums, spring coupling, magnetic fields, rigid rotors, and gyroscopes, to challenge current approaches. Our experiments reveal that utilizing Cartesian coordinates with explicit constraints results in a 100x enhancement in accuracy and data efficiency. Our approach simplifies the Hamiltonians and Lagrangians learned by our models, leading to better long-term predictions compared to Neural ODEs and Hamiltonian Neural Networks (HNNs). The spinning gyroscope example illustrates how our model (CHNN) achieves near-perfect overlap with the ground truth trajectory, outperforming other models. Additionally, we demonstrate that our model is 100 times more data efficient or 260 times more accurate on the gyroscope system. Furthermore, expressing the Hamiltonian in Cartesian coordinates proves to be simpler and easier to learn compared to expressing it in angular coordinates.