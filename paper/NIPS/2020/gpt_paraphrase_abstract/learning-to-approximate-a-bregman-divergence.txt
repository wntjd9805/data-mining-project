Bregman divergences are versatile measures used in various machine learning areas. This paper focuses on the challenge of approximating any Bregman divergence using supervision and presents a systematic approach for analyzing such approximations. The authors propose a formulation and algorithm that learn arbitrary Bregman divergences by approximating their underlying convex generating function with a piecewise linear function. The study provides theoretical bounds on the approximation and shows that the generalization error achieved using this framework matches the error of the more specific Mahalanobis metric learning approach. Empirical results demonstrate the effectiveness of the proposed method, particularly for clustering and ranking tasks, when compared to existing metric learning methods.