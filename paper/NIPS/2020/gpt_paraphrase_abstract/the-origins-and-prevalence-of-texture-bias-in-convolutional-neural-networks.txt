The widespread bias of ImageNet-trained CNNs to classify images based on texture rather than shape has been recently discovered. However, when these CNNs are trained on datasets containing conflicting shape and texture, they learn to classify by shape as easily as by texture. The texture bias in CNNs trained on ImageNet is influenced by various factors, including different unsupervised training objectives and architectures, although their effects are relatively small and independent. Despite the presence of shape information in their hidden representations, models trained with different objectives and architectures still predominantly make texture-based classification decisions. On the other hand, the impact of data augmentation is more significant. By employing less aggressive random crops during training and applying simple, naturalistic augmentation techniques such as color distortion, noise, and blur, models can be trained to classify ambiguous images based on shape most of the time. These models also outperform baselines on out-of-distribution test sets. Consequently, the dissimilarities in the processing of images by humans and ImageNet-trained CNNs may not primarily stem from differences in their internal workings, but rather from variations in the data they are exposed to.