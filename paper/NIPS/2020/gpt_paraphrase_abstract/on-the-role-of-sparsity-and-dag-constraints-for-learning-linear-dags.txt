Learning graphical structures based on Directed Acyclic Graphs (DAGs) is a challenging task due to the vast number of possible graphs. Previous research has approached this problem by formulating it as a constrained optimization task using least squares objective and an algebraic representation of DAGs. However, this formulation has limitations and can be difficult to optimize. In this study, we investigate the role of sparsity and DAG constraints in learning DAG models in both linear Gaussian and non-Gaussian scenarios. Based on our theoretical findings, we propose a likelihood-based score function that only requires soft sparsity and DAG constraints to learn an equivalent DAG to the true ground DAG. This results in an unconstrained optimization problem that is easier to solve. By employing gradient-based optimization and GPU acceleration, our approach can handle large networks with high accuracy. Extensive experiments demonstrate the efficacy of our method and highlight the advantages of the DAG-penalized likelihood objective over the least squares objective with a hard DAG constraint.