There is a growing interest in studying median-based algorithms for distributed non-convex optimization. Two notable examples are SIGNSGD with majority vote and MEDIANSGD. SIGNSGD effectively reduces communication through 1-bit compression, while MEDIANSGD ensures robustness against Byzantine workers. However, the convergence analyses of these algorithms assume that all distributed data are drawn independently and identically from the same distribution. In real-world applications like Federated Learning, data across different nodes or machines can be inherently diverse, violating the iid assumption. This study examines SIGNSGD and MEDIANSGD in distributed settings with heterogeneous data. It reveals that these algorithms do not converge when there is a disparity between the expected median and mean of the local gradients. To bridge this gap, a novel gradient correction mechanism is proposed, introducing noise to the local gradients. This correction technique effectively closes the gap between the mean and median of the gradients. The proposed methods maintain the desirable properties of the median-based algorithms, such as the low per-iteration communication complexity of SIGNSGD, and also achieve global convergence to stationary solutions. Additionally, the perturbation technique can be useful when estimating the mean through a median estimator.