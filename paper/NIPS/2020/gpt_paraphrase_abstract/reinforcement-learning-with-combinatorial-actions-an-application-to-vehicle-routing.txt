Value-function-based methods have been widely used in reinforcement learning. However, determining the best action based on a complex value function becomes challenging when the action space is too large to enumerate. In this study, we propose a framework for deep reinforcement learning with a combinatorial action space. We formulate the action selection problem as a mixed-integer optimization problem. To demonstrate the effectiveness of our framework, we apply it to the capacitated vehicle routing problem (CVRP), which involves optimizing the routing of a single vehicle with limited capacity to cover a set of locations. We model each action as the construction of a single route and use a deterministic policy that is improved through a simple policy iteration algorithm. Our approach is competitive with other reinforcement learning methods and achieves an average gap of 1.7% compared to state-of-the-art OR methods on medium-sized standard library instances.