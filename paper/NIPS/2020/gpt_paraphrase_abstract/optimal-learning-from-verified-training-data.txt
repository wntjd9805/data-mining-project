Standard machine learning algorithms assume that data is independently sampled from the distribution of interest. However, in reality, data often comes from self-interested agents with intentions that are not purely adversarial. To address this problem, we propose a Stackelberg competition model for least squares regression, where data is provided by agents who want specific predictions for their data. Despite the nonconvex nature of the optimization problem, we develop an algorithm that globally converges, surpassing existing approaches that only guarantee convergence to local optima. Additionally, we demonstrate the effectiveness of our algorithm compared to adversarial assumptions on two real-world datasets, the medical personal costs dataset and the red wine dataset, outperforming the current state-of-the-art algorithms.