We introduce a new class of generative models called manifold-learning flows (M-flows). These models are capable of simultaneously learning the data manifold and a tractable probability density on that manifold. By combining techniques from normalizing flows, GANs, autoencoders, and energy-based models, M-flows can more accurately represent datasets with a manifold structure. Additionally, they offer advantages in dimensionality reduction, denoising, and out-of-distribution detection. We propose a new training algorithm that separates updates for the manifold and density. In various experiments, we demonstrate how M-flows effectively learn the data manifold and enable improved inference compared to standard flows in the original data space.