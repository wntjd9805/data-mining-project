Normalizing flows (NFs) have become popular for deep generative models, but they are considered inefficient due to reduced expressiveness and high parameter complexity. To address this, we introduce NanoFlow, an alternative parameterization scheme that uses a single neural density estimator for multiple transformation stages. We propose a parameter decomposition method and flow indication embedding to enable density estimation from a single neural network. Our experiments on audio and image models demonstrate that NanoFlow offers a parameter-efficient solution for scalable NFs with significantly reduced parameter complexity.