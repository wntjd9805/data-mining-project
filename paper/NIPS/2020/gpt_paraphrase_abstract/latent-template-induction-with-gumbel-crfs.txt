Sentence structure control is a difficult problem in text generation. Current methods either rely on simplistic approaches or complex reinforcement learning-based structures. We investigate the use of structured variational autoencoders to deduce hidden templates for sentence generation through a soft, continuous relaxation. This allows us to employ reparameterization for training. To achieve this, we propose a Gumbel-CRF, which is a continuous relaxation of the CRF sampling algorithm utilizing a relaxed Forward-Filtering Backward-Sampling (FFBS) technique. The Gumbel-CRF provides more stable gradients compared to score-function based estimators, making it a reliable gradient estimator. Additionally, as a structured inference network, our model learns understandable templates during training, enabling us to control the decoder during testing. We validate the effectiveness of our approach through experiments on data-to-text generation and unsupervised paraphrase generation.