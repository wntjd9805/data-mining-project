The significance of explanations in time series models, particularly in critical fields like healthcare, has been largely overlooked in machine learning literature. In this study, we present FIT, a framework that assesses the importance of observations in a multivariate time-series black-box model by measuring the change in the predictive distribution over time. FIT determines the importance of an observation by evaluating its contribution to the distributional shift using KL-divergence, which compares the predictive distribution to a counterfactual scenario where the other features are unobserved. We also emphasize the necessity of accounting for time-dependent distribution shifts. Through comparisons with state-of-the-art methods on both simulated and real-world clinical data, we demonstrate that our approach excels in identifying crucial time points and observations throughout the time series.