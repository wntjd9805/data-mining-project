The ability to recognize new visual categories that are combinations of known components is crucial for learning in real-world domains like vision and language. However, learning systems often struggle with this compositional generalization because they rely on features that are correlated with class labels but not necessarily essential for them. This leads to misclassification of samples from new distributions. In this study, we propose a causal approach to compositional generalization. We view zero-shot inference as determining "which intervention caused the image" and develop a causal-inspired embedding model that learns disentangled representations of elementary components of visual objects. We evaluate this approach on two datasets, a synthesized images dataset and a real-world dataset of fine-grained shoe types, and demonstrate improvements compared to strong baselines. The code and data for this study are available at the provided GitHub link.