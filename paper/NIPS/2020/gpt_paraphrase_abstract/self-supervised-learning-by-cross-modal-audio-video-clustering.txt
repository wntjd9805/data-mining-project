Cross-Modal Deep Clustering (XDC) is a self-supervised method that utilizes the strong correlation and inherent differences between visual and audio modalities. By leveraging unsupervised clustering in one modality as a supervisory signal for the other, XDC enhances the learning of video and audio representations. Experimental results demonstrate that XDC surpasses single-modality clustering and other multi-modal approaches, achieving state-of-the-art accuracy on various video and audio benchmarks. Notably, the video model pretrained with XDC outperforms the same model pretrained with full-supervision on ImageNet and Kinetics for action recognition on HMDB51 and UCF101. XDC is the first self-supervised learning method known to outperform large-scale fully-supervised pretraining for action recognition on the same architecture.