Predicting the motion of pedestrians and human-driven vehicles is a crucial issue in autonomous driving. The safety and comfort of passengers are directly impacted by the accuracy of these predictions. However, this task remains challenging due to the high variability in the behavior of agents. This variability arises from the uncertainty in the agents' intent and the realization of that intent. To be effective in real-time autonomous driving systems, a motion prediction system must be able to describe and quantify this uncertainty efficiently. It should also avoid assigning significant probability to physically impossible trajectories. In this paper, we propose the PRANK method, which addresses these requirements. PRANK uses bird-eye images of the agent's surroundings as input and extracts scene features using a convolutional neural network. It then generates the conditional distribution of plausible trajectories for the agent in the given scene. The key innovation of PRANK is its representation of this distribution in latent trajectory space using nearest-neighbor methods, enabling efficient real-time inference. We evaluate PRANK on both in-house and Argoverse datasets, where it demonstrates competitive performance.