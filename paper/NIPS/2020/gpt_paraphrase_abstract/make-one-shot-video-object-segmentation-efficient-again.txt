The task of video object segmentation involves segmenting objects in each frame of a video. In the semi-supervised setting, the initial mask for each object is given at test time. Current methods for fine-tuning video object segmentation models train the model separately for each given object mask, but this approach is considered inefficient. To address this, we propose an efficient method called e-OSVOS. Unlike most approaches, e-OSVOS separates the object detection task and predicts only local segmentation masks using a modified version of Mask R-CNN. We optimize the test runtime and performance without the need for a time-consuming hyperparameter search. We achieve this by meta learning the model initialization and learning rates for the test time optimization. We also predict individual learning rates at a neuron level to achieve optimal learning behavior. Additionally, we continuously fine-tune the model on previous mask predictions using online adaptation to mitigate performance degradation throughout a sequence. e-OSVOS achieves state-of-the-art results on various datasets while significantly reducing the test runtime. The code is available at the provided GitHub link.