Multi-task learning is a complex problem in computer vision. Currently, there are two common approaches to conducting multi-task learning with deep neural networks. The first approach involves manually designing schemes that share some initial layers and then branch out at a certain point. The second approach uses separate task-specific networks with a feature sharing mechanism. However, these methods have limitations.  To address these limitations, we propose a new approach called AdaShare. AdaShare is an adaptive sharing approach that determines what to share across tasks to achieve the highest recognition accuracy while considering resource efficiency. Our approach involves learning a sharing pattern through a task-specific policy. This policy selectively chooses which layers to execute for a given task in the multi-task network.  To optimize the task-specific policy and network weights, we use standard back-propagation. We conducted experiments on various benchmark datasets with different numbers of tasks, and the results show that our approach outperforms state-of-the-art methods. For more information, please visit our project page at https://cs-people.bu.edu/sunxm/AdaShare/project.html.