To enhance learning diverse behaviors, it is important to consistently tackle new and unsolved tasks. While reinforcement learning has been successful in solving single-goal tasks, the selection of training goals significantly impacts the efficiency of learning in multi-task scenarios. In contrast, biological agents tend to learn in an organized and meaningful order. To replicate this, we propose an automatic curriculum for the agent's goals. Our key insight is that sampling goals at the frontier of achievable goals provides a stronger learning signal compared to random sampling. To implement this, we introduce a goal proposal module that prioritizes goals that maximize the uncertainty of the policy's Q-function. This technique allows for continual improvement by sampling goals that are neither too difficult nor too easy for the agent. We evaluate our method on multiple robotic and navigation tasks and demonstrate its superiority over current state-of-the-art approaches.