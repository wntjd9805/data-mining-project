Human-level performance on text-based games is a challenge, and previous studies have relied on manual representations and heuristics. This research explores how an agent can plan and generalize in text-based games using graph-structured representations learned from raw text. The proposed graph-aided transformer agent (GATA) infers and updates belief graphs during planning to improve action selection and capture game dynamics. GATA is trained using reinforcement and self-supervised learning. Results show that the learned graph-based representations help agents achieve better policies and generalize effectively across game configurations. Experiments on over 500 unique games demonstrate that our best agent surpasses text-based baselines by an average of 24.2%.