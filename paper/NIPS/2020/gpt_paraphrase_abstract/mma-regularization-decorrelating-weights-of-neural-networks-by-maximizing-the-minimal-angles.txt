To improve the generalization ability of neural networks, we introduce a novel diversity regularization method inspired by the Tammes problem. Our approach aims to distribute the normalized weight vectors of neurons or filters uniformly on a hypersphere by maximizing the minimal pairwise angles (MMA). This regularization method can be easily incorporated into the loss function without significant computational overhead. It is simple, efficient, and effective, making it suitable as a basic regularization technique in neural network training. Through extensive experiments, we demonstrate that the MMA regularization enhances the generalization ability of various modern models and achieves significant performance improvements on CIFAR100 and TinyImageNet datasets. Furthermore, our experiments on face verification show that MMA regularization is also effective for feature learning. The code for implementing this regularization method is available at: https://github.com/wznpub/MMA_Regularization.