Event cameras are a type of camera that capture visual information with high temporal precision, low data-rate, and high-dynamic range. They are particularly useful for scenarios with fast motion, challenging lighting conditions, and low latency requirements. However, event-based systems still have lower performance compared to traditional frame-based solutions due to several factors. These include the lower spatial resolution of event sensors, the lack of large-scale training datasets, and the absence of established deep learning architectures for event-based processing.This paper addresses these challenges in the context of object detection using event-based cameras. Firstly, the authors release a high-resolution large-scale dataset for object detection, consisting of over 14 hours of recordings from a 1 megapixel event camera in automotive scenarios. The dataset also includes 25 million bounding boxes labeled at a high frequency for cars, pedestrians, and two-wheelers. Secondly, the authors propose a novel recurrent architecture for event-based object detection and introduce a temporal consistency loss to improve training. The ability to compactly represent the sequence of events within the model's internal memory is crucial for achieving high accuracy. Their model outperforms existing feed-forward event-based architectures by a significant margin. Importantly, their method does not require reconstructing intensity images from events, demonstrating that training directly from raw events is more efficient and accurate than using intermediate intensity images.Experiments conducted on the newly introduced dataset, which includes both events and gray level images, show that the proposed method performs on par with highly optimized frame-based object detectors.