Deep graph learning models, such as node classification and network embedding, have achieved impressive performance. However, these models are vulnerable to small adversarial perturbations. The vulnerability of graph matching under adversarial attacks has not been thoroughly explored. This study proposes a new adversarial attack model with two innovative techniques to perturb the graph structure and decrease the accuracy of deep graph matching. The first technique involves using kernel density estimation to estimate and maximize node densities, making the perturbations imperceptible by moving attacked nodes to dense regions in both graphs. This makes them similar to their neighboring nodes. The second technique uses a meta learning-based projected gradient descent method to select attack starting points and enhance the search performance for generating effective perturbations. The effectiveness of the attack model is assessed on real datasets, and the results demonstrate that the attacks can be transferred to other graph learning models.