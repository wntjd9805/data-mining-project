We present MDP-GapE, a novel trajectory-based Monte-Carlo Tree Search algorithm designed for planning in a Markov Decision Process with limited transition support. We demonstrate that MDP-GapE requires a bounded number of calls to the generative model in order to identify a nearly optimal action with a high probability. This result, which depends on the specific problem, quantifies the sample complexity and is based on the sub-optimality gaps of the state-action pairs explored during the search. Our experimental results indicate that MDP-GapE is not only theoretically sound but also performs effectively in practical scenarios, distinguishing it from other algorithms that offer fixed-confidence sample complexity guarantees primarily in a theoretical context.