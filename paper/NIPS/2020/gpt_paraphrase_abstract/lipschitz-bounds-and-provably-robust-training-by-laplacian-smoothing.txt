We propose a graph-based learning framework to train models that are robust to adversarial perturbations. Unlike regularization-based approaches, we approach robust learning as a problem of minimizing loss with a Lipschitz constraint. We demonstrate that the saddle point of the associated Lagrangian can be characterized by a Poisson equation with a weighted Laplace operator. The weighting for the Laplace operator is determined by the Lagrange multiplier for the Lipschitz constraint, which controls the sensitivity of the minimizer to perturbations. To achieve provable robustness, we design a training scheme using graph-based discretization of the input space and a primal-dual algorithm to converge to the saddle point of the Lagrangian. Our analysis establishes a new connection between elliptic operators with constraint-enforced weighting and adversarial learning. Additionally, we address the problem of improving the robustness of minimizers by imposing a margin on their loss. This is formulated as a loss-constrained minimization problem of the Lipschitz constant. We propose a technique to obtain robust minimizers and evaluate fundamental lower bounds on the Lipschitz constant by minimizing gradient p-norms. Our results show that, for a desired nominal performance, there exists a fundamental lower bound on the sensitivity to adversarial perturbations. Any improvements in robustness beyond this bound come at the expense of nominal performance. Our training schemes achieve these bounds under constraints on performance and robustness.