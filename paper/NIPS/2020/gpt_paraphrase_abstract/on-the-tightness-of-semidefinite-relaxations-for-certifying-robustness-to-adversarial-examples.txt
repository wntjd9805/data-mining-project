The effectiveness of a neural network in handling adversarial examples can be mathematically proven by solving a convex relaxation. However, if the relaxation is not tight, the resulting proof may be overly cautious and not practically useful. A recent approach proposes a less cautious proof of robustness based on a semidefinite programming relaxation of the ReLU activation function. This paper introduces a geometric technique to determine whether this relaxation is exact, meaning it provides both a lower-bound on the smallest adversarial perturbation and the optimal perturbation achieving this lower-bound. Specifically, the relaxation is equivalent to projecting a point onto a hyperbola, and the proof is exact when the projection lies on the major axis of the hyperbola. Using this technique, it is proven that the certificate is exact for a single hidden layer under mild assumptions, while being conservative for multiple hidden layers. Experimental validation of the theoretical findings is conducted using an interior-point method and a custom rank-2 Burer-Monteiro algorithm.