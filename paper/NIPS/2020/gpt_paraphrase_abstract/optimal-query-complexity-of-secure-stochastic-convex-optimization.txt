This study focuses on the secure stochastic convex optimization problem, where a learner aims to find the optimal point of a convex function by querying a stochastic gradient oracle. However, there is an adversary who tries to infer the learner's learning outcome by observing the queries without access to the oracle's feedback. The learner seeks to maximize accuracy in estimating the optimal point while maintaining privacy and making it difficult for the adversary to infer the optimal point. The tradeoff between accuracy and privacy is formally quantified, and the lower and upper bounds on the learner's query complexity are characterized based on desired levels of accuracy and privacy. Information theoretical analysis is used to establish lower bounds, and a general template is provided for analysis, tailored to various problem families including stochastic convex optimization and noisy binary search. Additionally, a secure learning protocol is presented, achieving the matching upper bound with logarithmic factors.