In complex images, objects often overlap each other, making tasks like object detection and tracking, or robotic control planning difficult. To address this, it is crucial to understand the full extent of objects, even when they are occluded. This is known as amodal instance completion. In this study, we introduce Amodal-VAE, a variational generative framework for amodal completion. Unlike other methods, our approach does not require amodal labels during training, as it utilizes object instance masks that are widely available. We demonstrate the effectiveness of our approach in scene editing tasks, where users can interactively complete or erase objects in photographs. Our experiments on complex street scenes show that our method achieves state-of-the-art performance in amodal mask completion and produces high-quality scene editing results. Surprisingly, a user study reveals that humans prefer object completions generated by our model over those labeled by humans.