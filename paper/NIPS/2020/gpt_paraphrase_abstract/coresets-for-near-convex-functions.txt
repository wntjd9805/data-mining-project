Coresets are small subsets of weighted input points that can approximate the loss function for a given set of queries. They are commonly used in machine learning to improve the efficiency of existing algorithms on streaming distributed data. Sensitivity sampling is a method to obtain coresets, where the size of the coreset is proportional to the sum of sensitivities. However, computing the sensitivity for each point can be challenging. We propose a generic framework for computing sensitivities for a wide range of loss functions called near-convex functions. This framework utilizes the f-SVD factorization, which extends the SVD factorization of matrices to functions. We demonstrate the effectiveness of this approach through various applications, including SVM, logistic regression, M-estimators, and z-regression. Experimental results and open source code are also provided.