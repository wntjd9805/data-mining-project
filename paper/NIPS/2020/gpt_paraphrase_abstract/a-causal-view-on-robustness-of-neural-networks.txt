We introduce a perspective on the resilience of neural networks to alterations in input, applicable to both classification tasks and general measurement data. Using this perspective, we create a deep causal manipulation augmented model (deep CAMA) that explicitly considers possible alterations to specific causes that result in changes to the observed outcome. We also develop techniques for data augmentation and fine-tuning during testing to enhance the robustness of deep CAMA. In comparison to discriminative deep neural networks, our model demonstrates superior resilience against unforeseen alterations. Additionally, our model achieves a disentangled representation, effectively separating the representation of alterations from other underlying causes.