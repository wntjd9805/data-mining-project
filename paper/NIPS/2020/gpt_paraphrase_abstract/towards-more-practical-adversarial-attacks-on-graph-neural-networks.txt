We investigate black-box attacks on graph neural networks (GNNs) where attackers are limited to a subset of nodes and can only target a few of them. To address this constraint, we introduce a node selection step. We demonstrate that the structural biases of GNN models can be effectively exploited for such attacks. By leveraging the connection between GNN backward propagation and random walks, we extend gradient-based white-box attacks to the black-box setting using an importance score similar to PageRank. Empirical results show that attacks based on this score significantly increase the classification loss but do not significantly impact the mis-classification rate. Our analysis suggests a diminishing-return pattern between loss and mis-classification rate as the number of attacked nodes increases. To address this, we propose a greedy procedure that considers the diminishing-return pattern and corrects the importance score. Experimental results on real-world data confirm that our procedure can significantly increase the mis-classification rate of common GNNs without access to model parameters or predictions.