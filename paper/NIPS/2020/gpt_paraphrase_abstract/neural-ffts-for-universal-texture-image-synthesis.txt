Texture synthesis is a crucial task in graphics and vision, where the goal is to create larger texture images based on smaller exemplars. Traditional convolutional neural networks (CNNs) used for synthesis face limitations in generalizing to unseen images because they rely on convolutional and upsampling layers that operate locally. To address this issue, we propose a novel approach inspired by the repetitive nature of texture patterns. We consider texture synthesis as local upsampling in the Fast Fourier Transform (FFT) domain. However, FFT of natural images lacks local correlations and exhibits a high dynamic range. To overcome this, we introduce a framework that performs FFT upsampling in feature space using deformable convolutions, enabling CNNs to be trained on the synthesized textures and generalize to unseen images. Our method achieves state-of-the-art performance in both quantitative and qualitative evaluations.