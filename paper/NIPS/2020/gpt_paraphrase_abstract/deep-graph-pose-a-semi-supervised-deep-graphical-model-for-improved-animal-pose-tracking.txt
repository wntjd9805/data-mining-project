Noninvasive monitoring of animal behavior is crucial for scientific investigations. Recent advancements in transfer learning techniques have greatly improved the accuracy of behavioral tracking. However, these methods often treat each video frame and object independently. This study aims to enhance these methods, particularly in scenarios with limited training labels, by leveraging the spatial and temporal structures inherent in behavioral videos. The proposed approach, DeepGraph Pose (DGP), combines deep neural networks with a probabilistic graphical model to incorporate spatial and temporal constraints. By utilizing both labeled and unlabeled frames, the semi-supervised model achieves more accurate and robust tracking while reducing the need for extensive labeling. This improved tracking performance enhances downstream applications such as unsupervised segmentation of behavioral patterns and the estimation of interpretable low-dimensional representations of the video data. The source code for this project is publicly available.