The problem of finding suitable 3D shape representations for learning-based 3D reconstruction is still unresolved in the fields of machine learning and computer graphics. Previous research has shown the advantages and disadvantages of various representations such as point cloud, voxel, surface mesh, and implicit function. In this study, we propose a new parameterization called Deformable Tetrahedral Meshes (DEFTET) that utilizes volumetric tetrahedral meshes for reconstruction. Unlike existing methods, DEFTET optimizes both vertex placement and occupancy, and is differentiable with respect to standard 3D reconstruction loss functions. This makes it highly accurate, volumetric, and compatible with learning-based neural architectures. We demonstrate that DEFTET can represent complex shapes with arbitrary topology efficiently in terms of memory and computation. It also produces high-quality reconstructions with a smaller grid size compared to alternative volumetric approaches. The resulting surfaces are naturally defined as tetrahedral meshes, eliminating the need for post-processing. Our experiments show that DEFTET matches or surpasses the quality of previous methods and performs as well as the fastest ones. Moreover, our approach achieves high-quality tetrahedral meshes directly from noisy point clouds and is the first to achieve high-quality 3D tet-mesh results using only a single image as input. For further details, please visit our project webpage: https://nv-tlabs.github.io/DefTet/.