We introduce RELATE, a model that can generate realistic scenes and videos of multiple interacting objects. Like other generative approaches, RELATE is trained on unlabeled data and combines a GAN formulation with a model that considers correlations between objects. This enables the model to produce physically plausible scenes using interpretable parameters. We demonstrate that modeling object correlations is crucial for disentangling object positions and identities. Additionally, RELATE proves to be effective in physically realistic scene editing and outperforms previous methods in object-centric scene generation using both synthetic (CLEVR, ShapeStacks) and real-world data (cars). Unlike other state-of-the-art models, RELATE can also generate dynamic scenes and high-quality videos. More information, including source code, datasets, and additional results, can be found at http://geometry.cs.ucl.ac.uk/projects/2020/relate/.