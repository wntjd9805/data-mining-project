Advancements in adversarial attacks have played a crucial role in enhancing research on adversarial defense. Efficient and effective attacks are vital for accurately evaluating defense mechanisms and developing robust models. Typically, adversarial attacks involve maximizing standard losses like cross-entropy or maximum-margin loss within a given constraint set using Projected Gradient Descent (PGD). In this study, we introduce a relaxation term to the standard loss function, which helps identify more suitable gradient directions. This not only improves the effectiveness of attacks but also enhances the efficiency of adversarial training. We propose Guided Adversarial Margin Attack (GAMA) that employs a function mapping technique to guide the generation of adversaries, resulting in more powerful attacks. We evaluate our attack against various defense methods and demonstrate superior performance compared to existing attacks. Additionally, we present Guided Adversarial Training (GAT), which achieves state-of-the-art performance in single-step defenses. GAT utilizes the proposed relaxation term for both attack generation and training.