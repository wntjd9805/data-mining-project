Accurate quantification of uncertainty in deep neural networks is crucial for safety-critical applications. A well-calibrated model should be accurate when it is confident in its predictions and indicate high uncertainty when it is likely to be inaccurate. However, calibrating uncertainty is challenging since there is no ground truth available. To address this, we propose an optimization method that utilizes the relationship between accuracy and uncertainty. We introduce a differentiable loss function called accuracy versus uncertainty calibration (AvUC) that enables the model to learn to provide well-calibrated uncertainties while improving accuracy. We also demonstrate that this method can be applied to post-hoc uncertainty calibration on pretrained models. By employing mean-field stochastic variational inference, we compare our approach with state-of-the-art methods and conduct extensive experiments on large-scale image classification tasks with distributional shift. The results show that our approach achieves better model calibration than existing techniques.