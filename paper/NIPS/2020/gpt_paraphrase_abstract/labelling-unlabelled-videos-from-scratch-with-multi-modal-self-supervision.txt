Deep learning has been successful in large part due to the use of labelled data. However, labelling datasets, especially for videos, is costly. While there are methods to generate labels for unlabelled image datasets without supervision, this is not the case for videos. This study demonstrates that unsupervised labelling of video datasets is not easily achieved with strong feature encoders. The researchers propose a new clustering method that leverages the correspondence between audio and visual modalities to pseudo-label video datasets without human annotations. The resulting clusters are found to have significant semantic overlap with ground truth human labels. Additionally, the study presents benchmarking results for unsupervised labelling on various video datasets.