Meta-learning aims to enhance learning on new tasks by identifying shared patterns, but this comes at the expense of solving a complex optimization problem. We establish and define the balance between accurate modeling and ease of optimization in meta-learning. Traditional meta-learning algorithms consider the structure of meta-learning but face challenging optimization, while domain randomized search focuses on a single-level optimization and disregards the meta-learning structure. Using MAML as an example, we analyze this trade-off theoretically for various risk functions and linear regression, providing explicit error bounds for both modeling and optimization. Additionally, we conduct empirical research on this trade-off in meta-reinforcement learning benchmarks.