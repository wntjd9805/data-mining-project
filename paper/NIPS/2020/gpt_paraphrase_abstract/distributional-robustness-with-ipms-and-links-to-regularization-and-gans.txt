The fragility of deep neural networks to small changes has led to increased interest in robustness to adversarial attacks. Distributional Robust Optimization (DRO) has emerged as a promising approach, using divergence-based uncertainty sets to study robustness and inform regularization strategies. Previous work has focused on f-divergences, Wasserstein distances, and the Maximum Mean Discrepancy (MMD) to construct uncertainty sets. In this study, we expand upon existing research by considering Integral Probability Metrics (IPMs), a diverse set of divergences including MMD, Total Variation, and Wasserstein distances. Our main finding demonstrates that DRO using IPMs corresponds to a family of regularization penalties, improving upon previous results with MMD and Wasserstein distances. This result also shows how other IPMs correspond to commonly used penalties in machine learning. Additionally, we explore the relationship between IPMs and adversarial generative modeling, particularly f-GANs. Our findings reveal the robustness properties of the discriminator set and provide positive insights for penalty-based GAN methods such as Wasserstein-GANs, MMD-GANs, and Sobolev-GANs. Overall, our study connects GANs to distributional robustness and expands our understanding of the relationship between regularization and robustness.