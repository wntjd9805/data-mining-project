This study introduces innovative techniques for graph convolution, pooling, and unpooling that draw inspiration from finite differences and algebraic multigrid frameworks. By utilizing discretized differential operators and leveraging the graph mass, gradient, and Laplacian, a parameterized convolution kernel is constructed. This parameterization is independent of the graph structure and instead relies on the interpretation of network convolutions as differential operators. Additionally, hierarchical representations of the input are enabled through pooling and unpooling operations based on algebraic multigrid methods, typically employed in solving partial differential equations on unstructured grids. A comparison with standard convolutional neural networks is conducted, highlighting the similarities and connections between the two approaches on regular grids. Experimental evaluations, including classification and part-segmentation tasks, demonstrate the effectiveness of the proposed method, achieving comparable or superior results to state-of-the-art approaches. Furthermore, the computational cost of the proposed method is analyzed and compared to other graph convolutional networks.