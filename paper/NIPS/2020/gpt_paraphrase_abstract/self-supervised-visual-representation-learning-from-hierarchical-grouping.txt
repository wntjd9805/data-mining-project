We propose a framework for bootstrapping visual representation learning using a basic visual grouping capability. We achieve this by using a contour detector to divide an image into regions and then merging these regions into a hierarchical structure. We train this grouping capability using a small supervised dataset. Using this learned grouping capability, we can automatically predict the hierarchical structure of regions in a large unlabeled dataset. These predictions guide the self-supervised contrastive feature learning process, where a deep network is tasked with generating embeddings for each pixel that respect the hierarchy of regions. Our experiments show that this approach can be considered as state-of-the-art pre-training, providing benefits for downstream tasks. We also investigate the potential applications of our approach in semantic region search and video-based object instance tracking.