Planning efficiently in real time to control an agent in a complex environment with multiple agents is a challenge. Existing planners rely on fast simulators, but real-world scenarios are computationally demanding, limiting online planner performance. This study proposes influence-augmented online planning, which transforms a factored simulator into a local simulator that samples relevant state variables and captures incoming influence using machine learning. Experimentally, planning on this faster local simulator with POMCP yields higher real-time planning performance compared to planning on the entire environment simulator.