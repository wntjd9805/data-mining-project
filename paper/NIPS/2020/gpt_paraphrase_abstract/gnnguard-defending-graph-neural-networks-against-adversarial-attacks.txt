Deep learning methods for graphs have shown impressive performance in various domains. However, recent findings suggest that even small, imperceptible changes to the graph structure can significantly reduce the effectiveness of Graph Neural Networks (GNNs), even the most powerful and popular ones. In this study, we introduce GNNGUARD, a general algorithm that defends against different types of training-time attacks that manipulate the discrete graph structure. GNNGUARD can be easily integrated into any GNN. Its main idea is to identify and quantify the relationship between the graph structure and node features, and then utilize this relationship to mitigate the negative impact of the attack. GNNGUARD achieves this by assigning higher weights to edges connecting similar nodes and removing edges between unrelated nodes, enabling more robust propagation of neural messages within the GNN. Our approach incorporates two new components, neighbor importance estimation and layer-wise graph memory, both of which are essential for effective defense. Experimental results on five GNNs, three defense methods, and four datasets, including a complex human disease graph, demonstrate that GNNGUARD surpasses existing defense approaches by an average of 15.3%. Notably, GNNGUARD effectively restores the state-of-the-art performance of GNNs against various adversarial attacks, including targeted and non-targeted attacks, and provides defense against attacks on heterophily graphs.