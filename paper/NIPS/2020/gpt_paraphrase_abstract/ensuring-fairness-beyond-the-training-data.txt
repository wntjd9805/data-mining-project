We examine the concept of fair classifiers that can withstand changes in the training distribution. Despite some advancements, the fairness literature has largely neglected the development of fair and resilient classifiers. In this research, we create classifiers that maintain fairness not only for the training distribution but also for a range of weighted perturbations. To achieve this, we establish an objective function aimed at minimizing a training loss that is robust to distributional variations and discovering a fair classifier for a specific set of distributions. Initially, we simplify the problem by finding a fair classifier that can withstand the set of distributions. Through an iterative algorithm based on online learning techniques, we can guarantee convergence to a fair and resilient solution. Our experiments on standard fairness datasets in machine learning demonstrate that our classifier, compared to existing fair classifiers, maintains fairness and accuracy even when faced with various perturbations in the test set. Additionally, our experiments highlight the inherent trade-off between the robustness of fairness and the accuracy of such classifiers.