SATNet, a highly regarded MAXSAT solver, has been recognized for its ability to infer logical rules and integrate into deep neural networks as a differentiable layer. It has achieved success in visually solving Sudoku puzzles using images of puzzle digits, thus representing a significant milestone in combining pattern recognition and logical reasoning in AI. However, this paper reveals that SATNet fails to perform visual Sudoku without intermediate labels that link individual digit images with their logical representations, resulting in a test accuracy of 0%. This failure is attributed to SATNet's inability to learn how to assign symbols to perceptual phenomena, a challenge known as the symbol grounding problem. Addressing this problem, we propose a straightforward MNIST-based test that can serve as a benchmark for differentiable symbolic solvers. Naive applications of SATNet on this test demonstrate inferior performance compared to models lacking logical reasoning capabilities. We delve into the causes of SATNet's failure and provide insights on how to avoid them.