A useful technique for creating secure systems that protect sensitive data is to add Gaussian noise to the output of a function. However, implementing this technique with continuous distributions presents practical challenges. Computers cannot accurately represent continuous distributions, and even small numerical errors can compromise privacy. Additionally, when the original data is discrete (such as population counts), adding continuous noise makes the results less understandable. To address these issues, we propose and examine the use of discrete Gaussian noise in the context of differential privacy. Our theoretical and experimental analysis demonstrates that adding discrete Gaussian noise offers the same level of privacy and accuracy as continuous Gaussian noise. We also present a simple and efficient algorithm for sampling from this distribution, making it suitable for answering counting queries or other integer-based queries with low sensitivity.