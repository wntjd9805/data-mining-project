The emergence of machine learning as a service has raised concerns about the privacy of clients' data and providers' models. This has led to research in private inference (PI), which aims to process inferences without revealing inputs. Cryptographic techniques have been used to demonstrate the possibility of PI, but current solutions significantly increase inference latency, making them impractical. This paper proposes a new method called CryptoNAS, which uses a novel approach to tailor models specifically for PI. The key insight is that in PI, non-linear operations have a greater impact on latency than linear layers. The paper introduces the concept of a ReLU budget as a measure of inference latency and uses CryptoNAS to create models that maximize accuracy within a given budget. Experimental results show that CryptoNAS improves accuracy by 3.4% and reduces latency by 2.4 times compared to existing methods.