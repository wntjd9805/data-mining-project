Catastrophic forgetting in lifelong learning is caused by inaccessible historical data, but this issue can be overcome if the data is memorized perfectly. To address this, we propose a GAN memory for lifelong learning that can remember a series of datasets without forgetting. Our GAN memory utilizes sequential style modulations on a base GAN model, allowing us to generate targeted models while benefiting from previous knowledge. This GAN memory embodies lifelong learning principles by transferring and modulating information from prior tasks. Experimental results show that our method outperforms existing approaches and effectively mitigates catastrophic forgetting in lifelong classification problems. Code for our method is available at https://github.com/MiaoyunZhao/GANmemory_LifelongLearning.