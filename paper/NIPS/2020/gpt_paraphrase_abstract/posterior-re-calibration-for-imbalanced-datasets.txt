Neural Networks can struggle with imbalanced training label distributions and testing data that differs from the training distribution. To address this issue, we propose a post-training prior rebalancing technique based on the optimal Bayes classifier and optimized using KL-divergence. This method allows for efficient tuning of a hyper-parameter on a validation set to modify the classifier margin and handle the imbalance. We also integrate existing likelihood shift methods into our approach, providing a unified solution to both problems. Our algorithm is versatile and can be applied to probabilistic classification problems regardless of the underlying architectures. Experimental results on various datasets and architectures, including imbalanced datasets like iNaturalist and Synthia, demonstrate state-of-the-art accuracy. The implementation can be found at https://github.com/GT-RIPL/UNO-IC.git.