Adversarial training (AT) is a popular method for improving model robustness by adding adversarial examples to training data. However, current AT methods rely on specific attack algorithms, which limits their effectiveness against unseen attacks. Additionally, using a single attack algorithm may not explore the full range of perturbations. To address these issues, we propose adversarial distributional training (ADT), a new framework for training robust models. ADT formulates the problem as a minimax optimization, with the inner maximization learning an adversarial distribution to represent potential adversarial examples around a natural one. An entropic regularizer is used, and the outer minimization trains robust models by minimizing loss over the worst-case adversarial distributions. We provide a theoretical analysis and develop a general algorithm for solving ADT. Three approaches for parameterizing adversarial distributions are presented, including Gaussian and implicit distributions. Empirical results on various benchmarks demonstrate the effectiveness of ADT compared to state-of-the-art AT methods.