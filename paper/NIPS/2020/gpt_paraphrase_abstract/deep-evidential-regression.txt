We propose a new method for training neural networks (NNs) in safety critical areas, where accurate measures of uncertainty are essential. Our method allows non-Bayesian NNs to estimate both the target value and its associated evidence, capturing both aleatoric and epistemic uncertainty. We achieve this by adding evidential priors to the original Gaussian likelihood function and training the NN to infer the hyperparameters of the evidential distribution. We also introduce regularization during training to ensure the model's predicted evidence aligns with the correct output. Our method is efficient and scalable as it does not require sampling during inference or out-of-distribution examples for training. We demonstrate the effectiveness of our approach on various benchmarks, including complex computer vision tasks, and show robustness to adversarial and out-of-distribution test samples.