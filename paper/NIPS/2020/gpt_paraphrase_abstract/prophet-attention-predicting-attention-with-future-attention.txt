Attention based models have become popular in sequence-to-sequence learning systems, particularly in image captioning. However, these models often suffer from a "deviated focus" issue where they calculate attention weights based on previous words rather than the current one. This affects both grounding (associating words with image regions) and captioning performance. To address this problem, we propose the Prophet Attention, which employs future information during training to calculate "ideal" attention weights for image regions. These ideal weights are then used to regulate the deviated attention, resulting in correct grounding of image regions with words. The Prophet Attention can be easily integrated into existing image captioning models, leading to improved performance in both grounding and captioning. Experimental results on the Flickr30k Entities and MSCOCO datasets demonstrate that the proposed Prophet Attention consistently outperforms baselines in terms of automatic metrics and human evaluations. Notably, we achieve new state-of-the-art results on these benchmark datasets and secure the top position on the online MSCOCO benchmark leaderboard for the default ranking score (CIDEr-c40).