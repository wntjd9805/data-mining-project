In the early months of life, children form expectations about their surroundings. It is unclear how much of this knowledge is acquired through general learning from sensory information, and how much relies on inherent biases. While addressing this question comprehensively is currently impractical, we can make advancements in specific areas, such as the development of visual categories, thanks to improved data collection methods and advances in deep learning. This study aims to make progress in this area by employing modern self-supervised deep learning techniques and utilizing a recent dataset of egocentric videos recorded from the perspective of three young children. The findings reveal that powerful visual representations can emerge from natural videos using generic self-supervised learning objectives.