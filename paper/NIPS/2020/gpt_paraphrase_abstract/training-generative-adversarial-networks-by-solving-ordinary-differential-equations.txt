The instability of Generative Adversarial Network (GAN) training is often attributed to gradient descent. Recent methods have focused on modifying models and training procedures to stabilize discrete updates. However, we examine the continuous-time dynamics induced by GAN training and find that they are surprisingly stable. We propose that instabilities in GAN training arise from integration errors when discretizing the continuous dynamics. Through experiments, we confirm that well-known ODE solvers, like Runge-Kutta, can stabilize training when combined with a regularizer that controls integration errors. Our approach differs from previous methods that use adaptive optimization and stabilization techniques to constrain functional space. Evaluation on CIFAR-10 and ImageNet demonstrates the effectiveness of our method, surpassing strong baselines.