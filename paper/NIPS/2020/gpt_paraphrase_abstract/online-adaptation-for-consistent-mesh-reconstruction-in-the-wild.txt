This paper introduces an algorithm for reconstructing 3D meshes of deformable objects from videos without the need for explicit annotations. The algorithm is designed to adapt to any test video, treating video-based reconstruction as a self-supervised online adaptation problem. Initially, a category-specific 3D reconstruction model is trained using single-view images of the same category, which predicts the shape, texture, and camera pose. During inference, the model is adapted to the test video by incorporating self-supervised regularization terms that leverage temporal consistency to ensure that all reconstructed meshes have a shared texture map, base shape, and parts. The algorithm is capable of recovering accurate and consistent 3D structures from videos of non-rigid objects, including those captured in the wild, which is a challenging task that has been rarely addressed previously. The code and additional resources will be made available at https://sites.google.com/nvidia.com/vmr-2020.