Learning a canonical orientation for 3D surfaces is crucial in Computer Vision and Robotics. Traditionally, handcrafted algorithms have been used to determine this orientation based on geometric cues. However, we propose that machines can learn this orientation similarly to how humans do through experience. In our work, we demonstrate the possibility of learning a robust canonical orientation for surfaces represented as point clouds. To achieve this, we utilize Spherical CNNs, which can learn equivariant representations on the Special Orthogonal group SO(3). By employing spherical correlations, we compute feature maps that define 3D rotations. Through self-supervised training, our method learns these feature maps from raw data and selects a rotation to transform the input point cloud into the learned canonical orientation. We name our approach Compass and it is the first end-to-end learning method for defining and extracting the canonical orientation of 3D shapes. Experimental results on various datasets confirm its effectiveness in orienting local surface patches and whole objects.