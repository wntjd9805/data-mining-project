Modern vision systems often struggle when faced with new tasks or changes in the input data. This is due to a phenomenon known as supervision collapse, where the neural network representations underlying these systems discard information that may be important for transferring knowledge to new tasks or domains. To address this issue, we propose two methods. Firstly, we utilize self-supervised learning to encourage the development of more general features that can be easily transferred. Secondly, we introduce a new neural network architecture called CrossTransformers, which utilizes a Transformer-based approach to establish spatial correspondence between labeled images and an unlabeled query. By computing distances between corresponding features, this architecture can infer class membership. Our experiments on the Meta-Dataset, a benchmark for evaluating transfer learning, demonstrate that our approach yields a more robust classifier that can handle task and domain shifts effectively. The code for our method is available at: https://github.com/google-research/meta-dataset.