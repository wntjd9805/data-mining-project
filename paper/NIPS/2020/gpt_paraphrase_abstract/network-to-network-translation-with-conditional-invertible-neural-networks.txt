To optimize the computational costs of modern machine learning models, there is a need to find ways to reuse existing models and leverage the resources invested in their creation. Recent research suggests that the value of these large models lies in the representations they learn. Therefore, we propose a model that can establish relationships between different representations and address this task using a conditionally invertible network. Our network demonstrates its ability by offering generic transfer between diverse domains, enabling controlled content synthesis by modifying other domains, and aiding in the interpretation of existing representations by translating them into understandable domains like images. Our domain transfer network can translate between fixed representations without the need for additional learning or fine-tuning. This allows users to utilize various domain-specific expert models from previous studies that were trained using significant computational resources. Our approach has been validated through experiments on various tasks, including conditional image synthesis, image modification, and image-to-image and text-to-image generation. Notably, we have successfully translated between BERT and BigGAN, state-of-the-art text and image models, to achieve text-to-image generation, a task that neither model can accomplish individually.