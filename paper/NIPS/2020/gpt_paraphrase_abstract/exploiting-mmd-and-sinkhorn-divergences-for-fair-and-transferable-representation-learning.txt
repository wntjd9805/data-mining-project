Creating equitable learning methods that do not discriminate against specific groups within a population is a primary objective of algorithmic fairness. One approach to achieve this objective is by modifying the data representation to adhere to fairness constraints. In this study, we assess fairness based on demographic parity, which necessitates that the probability of model decisions remains unrelated to sensitive information. We propose that achieving demographic parity can be facilitated through multitask learning. We introduce a technique for acquiring a shared fair representation across multiple tasks, employing novel constraints based on MMD and Sinkhorn Divergences. We establish learning bounds that demonstrate the effectiveness of the acquired representation in transferring to new tasks. Through experiments on three real-world datasets, we demonstrate that our method outperforms existing approaches by a significant margin.