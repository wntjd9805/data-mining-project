This study examines how communication between nodes in an Erd˝os-Rényi random network affects distributed online convex optimization. The goal is to solve large-scale machine learning problems in dynamic environments. Each node makes a local decision, experiences a loss, and communicates with other nodes over the network. The objective is to minimize the system-wide loss over a finite time horizon. Different algorithms are considered for convex and strongly convex losses. The study establishes regret bounds based on the time horizon, network size, decision dimension, and network connectivity. The regret bounds match those of state-of-the-art algorithms and fundamental limits in centralized online optimization problems. For Erd˝os-Rényi networks, the tradeoff between communication overhead and computation accuracy is demonstrated based on the probability of link occurrence. Numerical studies validate the theoretical findings.