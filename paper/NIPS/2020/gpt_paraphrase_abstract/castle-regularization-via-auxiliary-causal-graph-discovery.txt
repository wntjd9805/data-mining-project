Regularization is a technique that improves the ability of supervised models to make accurate predictions on unseen data. Previous studies have shown that predicting the effect from the cause (causal direction) yields better results than predicting the cause from the effect (anti-causal direction). However, existing regularization methods do not take causality into account. In this study, we propose a new regularization method called Causal Structure Learning (CASTLE) that incorporates causal relationships between variables into the training of a neural network. CASTLE learns the causal directed acyclical graph (DAG) as an adjacency matrix within the input layers of the neural network, which helps identify the most optimal predictors. Unlike other regularizers, CASTLE efficiently reconstructs only the features in the causal DAG that have a causal neighbor, improving performance. We provide a theoretical analysis of our approach and conduct experiments on various synthetic and real datasets to demonstrate that CASTLE consistently outperforms other popular regularizers in making accurate predictions on unseen data.