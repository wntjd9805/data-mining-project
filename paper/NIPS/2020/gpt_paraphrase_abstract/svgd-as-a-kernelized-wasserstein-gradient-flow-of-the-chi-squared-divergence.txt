The Stein Variational Gradient Descent (SVGD) algorithm is commonly described as the kernelized gradient flow for the Kullback-Leibler divergence in optimal transport geometry. However, we present a new viewpoint that considers SVGD as the kernelized gradient flow of the chi-squared divergence. This alternative perspective demonstrates a high level of uniform exponential ergodicity, even with weak conditions such as a Poincar√© inequality. Based on this perspective, we propose a new algorithm called Laplacian Adjusted Wasserstein Gradient Descent (LAWGD). LAWGD can be implemented using the spectral decomposition of the Laplacian operator associated with the target density. We provide evidence that LAWGD has strong convergence guarantees and performs well in practical applications.