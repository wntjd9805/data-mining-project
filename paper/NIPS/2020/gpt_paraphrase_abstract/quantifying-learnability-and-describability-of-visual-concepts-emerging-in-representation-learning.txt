This study focuses on understanding and interpreting visual groupings discovered by deep neural networks, specifically unsupervised ones. While clustering methods can sometimes align with labeled datasets, they often do not, yet still possess an "intuitive interpretability." To quantify the interpretability of image groupings, including unsupervised ones, two concepts are introduced: visual learnability and describability. Visual learnability measures humans' ability to reproduce a grouping by generalizing from a small set of visual examples, while describability determines if a textual description can replace the visual examples. Human annotators are assessed as classifiers to eliminate subjective evaluation metrics, and a class-level captioning system is proposed for automated description generation, which is compared to human annotators using the describability metric.