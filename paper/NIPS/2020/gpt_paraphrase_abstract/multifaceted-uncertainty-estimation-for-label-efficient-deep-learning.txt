We propose a new method for uncertainty prediction in deep learning models that allows them to be trained with less labeled data. This approach utilizes subjective logic to analyze and decompose the predicted entropy into two types of uncertainty: vacuity, caused by a lack of evidence, and dissonance, caused by conflicting strong evidence. By understanding the nature of uncertainty, we can effectively explore large and high-dimensional unlabeled data. We introduce a novel loss function that incorporates uncertainty anchor sample identification to enhance evidence prediction. Our approach integrates and balances multiple sources of uncertainty using a data sampling function for active deep learning. Experimental results on synthetic and real data demonstrate the effectiveness of our model compared to other active learning methods.