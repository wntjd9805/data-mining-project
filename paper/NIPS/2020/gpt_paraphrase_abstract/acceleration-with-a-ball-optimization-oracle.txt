An oracle that finds the minimizer of a convex function within a given radius can be optimized to require fewer calls. By implementing an accelerated algorithm, we can achieve the same level of accuracy with fewer oracle queries. We also demonstrate the use of ball optimization oracles for functions with stable Hessians, using Newton's method or stochastic first-order methods. This improved algorithm has practical applications and achieves results comparable to the current state-of-the-art for regression problems.