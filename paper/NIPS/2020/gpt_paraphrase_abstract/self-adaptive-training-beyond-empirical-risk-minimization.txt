We propose a new training algorithm called self-adaptive training to improve the generalization of deep learning when dealing with potentially corrupted training data. This is crucial for learning from data that may be corrupted by random noise or adversarial examples. The commonly used empirical risk minimization (ERM) approach can easily overfit noise, leading to suboptimal performance. Our approach utilizes model predictions to dynamically adjust the training process and effectively mitigates overfitting. It outperforms ERM in handling both random and adversarial noise. Additionally, unlike ERM which exhibits a double-descent error-capacity curve, our self-adaptive training shows a single-descent curve, suggesting that the double-descent phenomenon may result from overfitting noise. We conducted experiments on CIFAR and ImageNet datasets, demonstrating the effectiveness of our approach in classification tasks with label noise and selective classification. The code for our algorithm is available at https://github.com/LayneH/self-adaptive-training.