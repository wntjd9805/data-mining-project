Both neuroscience and machine learning are interested in understanding how neural networks represent information. This study explores the relationship between the structure of neural representations and their ability to generalize and withstand perturbations. By comparing experimental findings on neural representations in mice with artificial neural networks, the researchers investigate the impact of a specific covariance spectrum on robustness. They empirically examine the advantages of this neural code in artificial networks and its role in multi-layer architectures. The results demonstrate that implementing the experimentally observed structure in artificial networks enhances their resilience against adversarial attacks. Additionally, these findings contribute to the existing theory on wide neural networks and kernel methods by highlighting the importance of intermediate representations.