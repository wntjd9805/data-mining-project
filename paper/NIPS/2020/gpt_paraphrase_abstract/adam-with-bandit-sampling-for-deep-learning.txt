A widely used optimization method for training deep learning models is Adam, which calculates adaptive learning rates for different parameters. This paper presents a generalized version of Adam called ADAMBS, which also adapts to different training examples based on their significance in the model's convergence. To achieve this, a distribution over all examples is maintained, and a mini-batch is selected in each iteration by sampling according to this distribution. The distribution is updated using a multi-armed bandit algorithm to ensure that examples that are more beneficial to the model training are sampled with higher probabilities. Theoretical analysis shows that ADAMBS improves the convergence rate of Adam in certain cases. Experimental results on various models and datasets demonstrate the fast convergence of ADAMBS compared to Adam.