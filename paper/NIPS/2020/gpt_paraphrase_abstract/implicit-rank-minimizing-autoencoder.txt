This study introduces a new type of autoencoder called the Implicit Rank-Minimizing Autoencoder (IRMAE), which focuses on minimizing the information capacity of the latent representation. This is achieved by adding extra linear layers between the encoder and decoder, which leads to the spontaneous learning of low-dimensional representations. The IRMAE model is straightforward, deterministic, and capable of learning compact latent spaces. The effectiveness of this method is demonstrated through various image generation and representation learning tasks.