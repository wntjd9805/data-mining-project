We present Sparse Symplectically Integrated Neural Networks (SSINNs), a new approach for learning Hamiltonian dynamical systems from data. SSINNs combine fourth-order symplectic integration with a learned parameterization of the Hamiltonian using sparse regression. This results in interpretable models that incorporate symplectic inductive biases and have low memory requirements. We evaluate SSINNs on four classical Hamiltonian dynamical problems and find that they outperform existing black-box prediction techniques by a significant margin in terms of system prediction and energy conservation. Additionally, SSINNs are able to converge to accurate governing equations even with limited and noisy data, suggesting potential use in discovering new physical governing equations.