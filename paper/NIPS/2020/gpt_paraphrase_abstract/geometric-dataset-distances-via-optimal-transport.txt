Current methods for quantifying task similarity in machine learning paradigms such as domain adaptation and meta-learning are often heuristic and rely on strong assumptions about label sets and architecture-dependent parameters. In this study, we propose a model-agnostic and training-free notion of distance between datasets that can compare datasets with completely disjoint label sets. This distance is based on optimal transport, which has a solid theoretical foundation and provides rich geometry awareness, interpretable correspondences, and well-understood properties. Our results demonstrate that this novel distance allows for meaningful dataset comparisons and is strongly correlated with transfer learning difficulty in various experimental settings and datasets.