Given a sufficient amount of labeled data, the non-convex low-rank matrix recovery problem does not have any spurious local minima. This means that a local optimization algorithm will always converge to a global minimum, regardless of the initial guess. However, the amount of data required for this theoretical guarantee is overly pessimistic, as it needs to prevent spurious local minima from existing anywhere, even in adversarial locations. Previous research, on the other hand, has shown that using good initial guesses can reduce the data requirements, as they allow spurious local minima to exist outside of a neighborhood of the solution. In this study, we aim to quantify the relationship between the quality of the initial guess and the corresponding reduction in data requirements. We use the restricted isometry constant as a measure of sample complexity and calculate a precise "threshold" number of samples needed to prevent each specific point on the optimization landscape from becoming a spurious local minimum. By optimizing this threshold across different regions of the landscape, we find that a linear improvement in the quality of the initial guess results in a constant factor improvement in sample complexity, particularly for initial points close to the ground truth.