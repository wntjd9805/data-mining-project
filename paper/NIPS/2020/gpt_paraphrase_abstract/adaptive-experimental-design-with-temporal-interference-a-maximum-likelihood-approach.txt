An online platform wants to compare two different policies, such as matching algorithms for ridesharing or inventory management algorithms for online retail. Traditional experimental approaches are biased and inefficient due to temporal interference between the policies. This study focuses on optimal experimental design for this scenario, treating the comparison as estimating the difference in reward between two unknown Markov chains. The estimation process uses non-parametric maximum likelihood. The goal is to find consistent and efficient experimental designs with minimum variance. This presents a challenging Markov decision problem, but through a novel application of classical martingale analysis, efficient designs can be characterized with a concise convex optimization problem. The study proposes an adaptive online experimental design that samples the two Markov chains in a consistent and efficient manner.