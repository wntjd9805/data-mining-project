We explore the characterization and discovery of optimal representations for supervised learning. Traditionally, this has been approached using the Information Bottleneck, which compresses inputs while still maintaining information about targets in a decoder-agnostic manner. However, in machine learning, our objective is not compression but rather generalization, which is closely linked to the desired predictive family or decoder, such as a linear classifier. To address this, we introduce the Decodable Information Bottleneck (DIB), which considers information retention and compression based on the desired predictive family. DIB produces representations that are optimal in terms of expected test performance and can be reliably estimated. Through empirical analysis, we demonstrate that this framework can be utilized to minimize the generalization gap in downstream classifiers and predict the generalization capability of neural networks.