Weighted sampling is a crucial tool in data analysis and machine learning pipelines. It is used to efficiently estimate statistics or create sparse representations of the data. In practice, weight distributions are often skewed, making without-replacement (WOR) sampling more effective than with-replacement (WR) sampling. WOR sampling provides a broader representation and higher accuracy with the same number of samples. We have developed new composable sketches for WOR sampling, specifically weighted sampling of keys based on their frequency raised to a power p between 0 and 2 (or for signed data, the sum of updates). Our sketches have a linearly growing size proportional to the sample size. Despite complex analysis, our design is simple and practical, utilizing widely implemented heavy hitters sketches like CountSketch. Our method is the first to offer WOR sampling for p values greater than 1 and the first to handle signed updates for p values greater than 0.