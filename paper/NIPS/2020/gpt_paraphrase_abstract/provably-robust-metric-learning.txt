Existing metric learning algorithms that aim to improve clean accuracy may actually result in metrics that are less robust against small adversarial perturbations compared to the Euclidean distance. To address this issue, we propose a novel metric learning algorithm that finds a Mahalanobis distance capable of withstanding adversarial perturbations. The resulting model's robustness is certifiable and experimental results demonstrate improvements in both certified robust errors and empirical robust errors (errors under adversarial attacks). Unlike neural network defenses, our method does not sacrifice clean errors in comparison to previous metric learning methods.