Traditional convolutional operations in deep networks are limited in their ability to connect distant locations within the network, as they operate locally and at a fixed scale. In this study, we introduce a new convolutional operator called fast Fourier convolution (FFC) that addresses this limitation. FFC incorporates non-local receptive fields and cross-scale fusion within the convolutional unit. By leveraging the spectral convolution theorem in Fourier theory, FFC globally affects all input features involved in the Fourier transform, allowing for the design of neural architectures with non-local receptive fields. FFC combines three different types of computations in a single operation unit: a local branch for small-kernel convolution, a semi-global branch for processing spectrally stacked image patches, and a global branch for manipulating image-level spectrum. These branches address different scales and are aggregated in FFC for cross-scale fusion. FFC can be directly substituted for traditional convolutions in existing networks without any adjustments and with comparable complexity. We evaluated FFC on three major vision benchmarks and consistently achieved significantly higher accuracies in image recognition, video action recognition, and human keypoint detection tasks.