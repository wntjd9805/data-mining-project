We present a practical approach to integrating uncertainty estimation into neural network methods for individual-level causal effect estimation. This is particularly important in safety-critical domains like healthcare, where accurately estimating and communicating uncertainty is crucial. Our approach effectively handles situations of "no-overlap" and covariate shift, which are common challenges in high-dimensional data and real-world deployments. By correctly modeling uncertainty, our methods prevent overconfident and potentially harmful recommendations. We demonstrate the effectiveness of our approach using various state-of-the-art models. Our uncertainty-equipped methods outperform standard approaches that rely on propensity scores to identify lack of overlap, and they provide decision makers with alerts when predictions are unreliable.