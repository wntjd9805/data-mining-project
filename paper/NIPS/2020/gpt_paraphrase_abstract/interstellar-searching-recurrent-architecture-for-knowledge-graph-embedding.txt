The abstract discusses the importance of long-term information in knowledge graph (KG) embedding and proposes a recurrent neural architecture search problem called Interstellar. It analyzes the challenges of using a unified model for Interstellar and suggests searching for recurrent architecture for different KG tasks. A case study on synthetic data highlights the significance of the proposed search problem, while experiments on real datasets validate the effectiveness of the searched models and the efficiency of the hybrid-search algorithm.