Multi-agent Imitation Learning (MAIL) is the process of agents learning to perform tasks in a multi-agent system by observing and imitating expert demonstrations, without knowledge of the environment's reward function. The field of MAIL has gained attention for its promising results on synthesized tasks and its potential application to complex real-world multi-agent tasks. However, sample efficiency and scalability are major challenges in MAIL. To address these challenges, this paper introduces Bayesian multi-type mean-field multi-agent imitation learning (BM3IL). Our method enhances sample efficiency by using a Bayesian formulation for MAIL and improves scalability through a novel multi-type mean-field approximation. We evaluate the performance of our algorithm against three state-of-the-art multi-agent imitation learning algorithms on various tasks, including solving a multi-agent traffic optimization problem in a real-world transportation network. The experimental results demonstrate that our algorithm consistently outperforms all other algorithms in all scenarios.