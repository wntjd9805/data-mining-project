Feature attribution methods are crucial for understanding complex deep learning models. However, ensuring meaningful explanations and interpreting the significance of attributed values is challenging. Additionally, these methods do not explain why features are assigned specific values. To address these limitations, we propose the deep attribution prior (DAPr) framework. DAPr utilizes additional predictive information for each feature to overcome these limitations. By jointly learning the relationship between prior information and feature importance, DAPr biases models to rely on features predicted to be important. Our framework improves generalization to new data and enables new methods for interpreting model behavior.