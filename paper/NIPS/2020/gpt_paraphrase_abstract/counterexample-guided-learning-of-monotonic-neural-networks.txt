Deep learning is widely adopted due to its ability to automatically construct features without bias. However, in real-world tasks, it is often necessary for the learned function to satisfy specific constraints. One common constraint is monotonicity, which requires the function's output to increase with increasing input values. We have developed a technique that can enforce monotonicity constraints at prediction time by using counterexamples. Furthermore, we propose a method to incorporate monotonicity as an inductive bias for deep learning. This involves iteratively including monotonicity counterexamples in the learning process. Unlike previous approaches, we target general ReLU neural networks without restricting the hypothesis space. Our implementation, called COMET, has been tested on real-world datasets and has achieved state-of-the-art results compared to existing monotonic learners. It has also improved model quality compared to models trained without considering monotonicity constraints.