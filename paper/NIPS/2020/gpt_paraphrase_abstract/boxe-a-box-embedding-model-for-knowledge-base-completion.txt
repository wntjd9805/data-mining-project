We propose a new embedding model called BoxE, which addresses the limitations of existing models in knowledge base completion (KBC). BoxE uses a spatio-translational approach, embedding entities as points and relations as hyper-rectangles. This allows BoxE to capture logical properties and support inference patterns, hierarchies, higher-arity relations, and logical rules. We conducted experiments that demonstrated BoxE's state-of-the-art performance on benchmark knowledge graphs and its ability to integrate logical rules.