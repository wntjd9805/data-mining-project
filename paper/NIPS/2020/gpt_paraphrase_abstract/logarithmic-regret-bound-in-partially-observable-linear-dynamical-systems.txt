This study focuses on the problem of system identification and adaptive control in partially observable linear dynamical systems. The collection of data introduces correlations, making adaptive and closed-loop system identification challenging. This paper introduces a model estimation method that provides finite-time guarantees for both open and closed-loop system identification. Using this method, the authors propose ADAPTON, an efficient reinforcement learning algorithm that adaptively learns the system dynamics and continuously updates its controller through online learning steps. ADAPTON estimates the model dynamics by occasionally solving a linear regression problem through interactions with the environment. It constructs counterfactual loss functions using policy re-parameterization and the estimated model to update the controller through online gradient descent. Over time, ADAPTON improves its model estimates and obtains more accurate gradient updates to enhance the controller. The study shows that ADAPTON achieves a regret upper bound of polylog(T) after T time steps of agent-environment interaction. ADAPTON is the first algorithm that achieves polylog(T) regret in adaptive control of unknown partially observable linear dynamical systems, including linear quadratic Gaussian (LQG) control.