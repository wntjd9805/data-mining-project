Normalization methods such as batch, weight, instance, and layer normalization have been widely used in modern machine learning. This study focuses on weight normalization (WN) and a variant called reparametrized projected gradient descent (rPGD) for overparametrized least squares regression. Both methods reparametrize the weights with a scale and unit vector, resulting in a non-convex objective function. It is shown that this non-convex formulation provides beneficial regularization effects compared to gradient descent. WN and rPGD adaptively regularize the weights and converge close to the minimum norm solution, even with non-zero initializations. Certain stepsizes of the scale and unit vector can lead to convergence close to the minimum norm solution. This behavior differs from gradient descent, which only converges to the minimum norm solution when initialized within the range space of the feature matrix and is more sensitive to initialization.