Imbalanced learning poses a challenge in developing unbiased models from class-imbalanced data. Existing methods such as resampling and reweighting have limitations in terms of performance stability, applicability, and computational cost when applied to complex tasks where their assumptions do not hold. This paper introduces a novel ensemble learning framework called MESA, which addresses these limitations. MESA adaptively resamples the training set in iterations to generate multiple classifiers, forming a cascade ensemble model. Unlike other meta-learning-based solutions, MESA separates model-training and meta-training, allowing the meta-sampler to be trained independently on task-agnostic meta-data. This makes MESA applicable to various existing learning models and efficient for new tasks. Extensive experiments on synthetic and real-world tasks demonstrate the effectiveness, robustness, and transferability of MESA. The code for MESA is available at https://github.com/ZhiningLiu1998/mesa.