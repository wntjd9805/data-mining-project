Current machine vision models are susceptible to image corruptions, such as blurring or compression artifacts, which limits their performance in real-world applications. However, popular benchmarks used to evaluate model robustness against these corruptions underestimate their actual performance in many scenarios. We propose utilizing multiple unlabeled examples of corruptions available in these scenarios for unsupervised online adaptation. By replacing the activation statistics estimated by batch normalization on the training set with the statistics of corrupted images, we consistently enhance the models' robustness across 25 different computer vision models. For instance, ResNet-50 achieves a 62.2% mCE on ImageNet-C with the corrected statistics, compared to 76.7% without adaptation. Moreover, by employing the more robust DeepAugment+AugMix model, we improve the ResNet50 model's state-of-the-art performance from 53.6% mCE to 45.4% mCE. Even adapting to a single sample enhances the robustness of the ResNet-50 and AugMix models, and as few as 32 samples are enough to surpass the current state-of-the-art for a ResNet-50 architecture. We advocate for the inclusion of results with adapted statistics when reporting scores in corruption benchmarks and other out-of-distribution generalization settings.