This study focuses on lossy image compression using deep latent variable models. Previous methods have used hierarchical variational autoencoders (VAEs) to learn inference networks and predict a compressed latent representation of each image. However, this conventional approach has limitations in terms of approximation. This study addresses three specific limitations, namely the amortization gap, discretization gap, and marginalization gap, by proposing solutions such as iterative inference, stochastic annealing, and bits-back coding. These remedies are applied to lossy compression for the first time. Through various experiments, including comparisons with existing methods and analysis of specific factors, this study achieves state-of-the-art performance in lossy image compression by modifying the inference method while maintaining the VAE architecture.