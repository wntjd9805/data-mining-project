Relational topic models (RTMs) have been created to analyze interconnected documents by considering both their link structure and content. However, these models have limited expressive capability. To overcome this limitation, we propose a new approach called graph Poisson factor analysis (GPFA). GPFA constructs a probabilistic model for interconnected documents and offers closed-form Gibbs sampling update equations, eliminating the need for complex approximate assumptions used in previous RTMs. Building upon GPFA, we introduce a hierarchical RTM called graph Poisson gamma belief network (GPGBN). Additionally, we present two Weibull distribution-based variational graph auto-encoders for efficient model inference and effective network information aggregation. Our experimental results demonstrate that our models can extract high-quality hierarchical latent document representations, leading to better performance compared to existing methods on various graph analytic tasks.