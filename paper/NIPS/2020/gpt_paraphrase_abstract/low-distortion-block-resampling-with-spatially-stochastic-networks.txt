We address the problem of generating diverse images by allowing unrestricted changes in specific areas while maintaining overall consistency. This is commonly encountered in generative modeling, where certain parts of the generated data are satisfactory while others need improvement. To tackle this, we enhance existing generative models by introducing a novel network architecture, training procedure, and an algorithm for resampling desired image parts.