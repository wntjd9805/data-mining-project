We investigate how to identify the best arm in stochastic linear bandits with fixed confidence while minimizing the number of samples taken. Our algorithm matches known lower bounds in terms of sampling complexity and provides reliable results. We utilize an arm sampling rule that can be updated infrequently without compromising its effectiveness. Additionally, our algorithm does not rely on the number of arms, unlike existing strategies. Experimental results demonstrate that our algorithm outperforms other methods. This paper also includes an analysis of the best-arm identification problem in linear bandits with a continuous set of arms.