Recent research has shown that CNN models used for image classification are susceptible to adversarial attacks, where small changes to an image can mislead the model. These attacks can also transfer between different models trained on the same dataset. Adversarial training is a technique used to improve the robustness of models by forcing them to learn features that are resistant to such attacks. However, this process is difficult and often requires models with large capacity, resulting in a significant decrease in accuracy on clean data. An alternative approach is to use ensemble methods, which involve training multiple sub-models that produce diverse outputs when faced with a transfer attack. This ensemble approach has been found to be effective in maintaining robustness with only a small decrease in clean accuracy. However, previous ensemble training methods have not been successful in inducing enough diversity among the sub-models to achieve robustness. To address this issue, we propose a new method called DVERGE, which isolates the vulnerability to adversarial attacks in each sub-model and diversifies this vulnerability to induce diverse outputs against transfer attacks. Our approach includes a novel diversity metric and training procedure, allowing DVERGE to achieve higher robustness compared to previous ensemble methods, even when more sub-models are added to the ensemble. The code for this work is available at the given GitHub link.