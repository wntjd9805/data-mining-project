Deep metric learning has gained significant attention in recent years by combining distance metric learning and deep neural networks. Efforts have been made to design pair-based angular loss functions that separate the magnitude and direction information of embedding vectors, ensuring consistency in training and testing measurements. However, these traditional angular losses fail to ensure that all sample embeddings lie on the same hypersphere during training, leading to unstable gradients and potentially hindering quick convergence in embedding learning. This study examines the impact of embedding norm in deep metric learning with angular distance and introduces a spherical embedding constraint (SEC) to regulate norm distribution. SEC dynamically adjusts the embeddings to align with the same hypersphere, facilitating more balanced direction updates. Extensive experiments in deep metric learning, face recognition, and contrastive self-supervised learning demonstrate that the SEC-based angular space learning approach greatly enhances state-of-the-art performance.