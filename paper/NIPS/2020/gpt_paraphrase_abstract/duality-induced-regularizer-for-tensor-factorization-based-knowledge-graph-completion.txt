Tensor factorization models have been successful in completing knowledge graphs but often suffer from overfitting. To address this issue, various regularizers have been proposed, but their limited applicability hinders their practical use. To overcome this challenge, we introduce a new regularizer called DUality-induced RegulArizer (DURA) that effectively improves the performance of existing models and can be applied to different methods. DURA is novel because it exploits the duality between tensor factorization models and distance-based models. Experimental results demonstrate that DURA consistently and significantly enhances performance on benchmark datasets.