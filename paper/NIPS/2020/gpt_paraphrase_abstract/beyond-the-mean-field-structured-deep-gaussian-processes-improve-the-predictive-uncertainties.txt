Deep Gaussian Processes (DGPs) are a type of model that can learn probabilistic representations for supervised learning by combining multiple Gaussian Processes. However, exact inference with DGPs is difficult and computationally expensive. In this study, we propose a new approach that uses a Gaussian variational family to approximate the posterior distribution while still retaining covariances between latent processes. This allows for fast convergence by marginalizing out all global latent variables. We also restrict the covariances to the most important ones for computational efficiency. We provide a proof of how this marginalization can be done and implement it efficiently. Our approach is tested on benchmark datasets and outperforms existing alternatives in terms of accuracy and calibrated uncertainty estimates.