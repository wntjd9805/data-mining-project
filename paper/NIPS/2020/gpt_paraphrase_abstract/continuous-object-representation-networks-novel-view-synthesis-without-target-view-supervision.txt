Novel View Synthesis (NVS) focuses on generating views from different camera angles based on input images. This process requires understanding the 3D structure of objects and unseen parts of the scene to create realistic results. Current approaches rely on supervised training with either accurate 3D models or multiple target images. In this study, we introduce Continuous Object Representation Networks (CORN), a conditional architecture that encodes the geometry and appearance of input images into a consistent 3D scene representation. We can train CORN with just two source images per object by combining it with a neural renderer. Notably, CORN does not rely on ground truth 3D models or target view supervision. Nevertheless, CORN performs well in challenging tasks like novel view synthesis and single-view 3D reconstruction, achieving comparable results to state-of-the-art approaches that use direct supervision. For more information, data, and code, please refer to our project page.