Most compilers for machine learning frameworks currently use heuristics-based algorithms to solve multiple correlated optimization problems, which can be difficult to maintain and often result in sub-optimal solutions for newer model architectures. Existing learning-based approaches in the literature are not efficient, as they tackle only one optimization problem and cannot generalize to unseen graphs, making them impractical for deployment. To overcome these limitations, we propose a transferable deep reinforcement learning method for computational graph optimization (GO) that uses a scalable sequential attention mechanism over an inductive graph neural network. Unlike previous methods, GO makes decisions on the entire graph rather than on individual nodes, significantly reducing search time. Additionally, we introduce recurrent attention layers to optimize dependent graph optimization tasks together, achieving a 33%-60% speedup compared to TensorFlow default optimization on three tasks. On a diverse set of representative graphs, including Inception-v3, Transformer-XL, and WaveNet with up to 80,000 nodes, GO outperforms human experts by an average of 21% and the previous state of the art by 18% with 15 times faster convergence on a device placement task evaluated in real systems.