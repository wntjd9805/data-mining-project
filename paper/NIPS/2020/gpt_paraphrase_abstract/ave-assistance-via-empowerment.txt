Using artificial agents to assist humans in achieving their goals is challenging due to the difficulty of accurately understanding and assisting with the person's goals. Current methods rely on inferring the human's goal, which is problematic when there are multiple potential goals or when identifying the set of candidate goals is challenging. To address this, we propose a new approach that focuses on enhancing the individual's ability to control their environment. We achieve this by integrating human empowerment into reinforcement learning, which allows the person to maintain autonomy and achieve any desired outcome. Our method outperforms goal inference-based assistance in scenarios where goal ambiguity or misspecification are present. However, estimating empowerment in continuous domains is computationally intensive, making it unsuitable for real-time learned assistance. To overcome this limitation, we introduce an efficient empowerment-inspired proxy metric. Using this metric, we successfully demonstrate our approach in a user study involving a challenging simulated teleoperation task with human-in-the-loop training.