Graph neural networks (GNNs) have achieved impressive results in semi-supervised node classification on graph data. However, GNNs have not addressed the issue of uncertainties associated with class probabilities, which can lead to misclassification in real-world scenarios. In this study, we propose a novel approach that combines GNNs with a multi-source uncertainty framework to incorporate various types of predictive uncertainties in both deep learning and belief/evidence theory domains for node classification predictions. Our method, called Graph-based Kernel Dirichlet distribution Estimation (GKDE), accurately predicts node-level Dirichlet distributions by leveraging evidence from the given labels of training nodes. It also effectively detects out-of-distribution (OOD) nodes. Through experiments on six real network datasets, we demonstrate that our proposed model outperforms state-of-the-art approaches in terms of both misclassification detection and OOD detection. Specifically, we found that dissonance-based detection performs best for misclassification detection, while vacuity-based detection is most effective for OOD detection. To provide further insights, we offer theoretical proof that explains the relationships between the different types of uncertainties considered in our work.