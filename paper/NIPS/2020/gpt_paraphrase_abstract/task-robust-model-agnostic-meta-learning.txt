Meta-learning methods have been successful in training models that can quickly learn new tasks. However, these methods focus on performing well on tasks from a specific distribution, rather than considering worst-case task performance. In this study, we introduce the concept of "task-robustness" by modifying the popular Model-Agnostic Meta-Learning (MAML) objective. Our approach aims to minimize the maximum loss across the observed meta-training tasks, making it equally important to perform well on difficult or rare tasks. This task-robust solution performs well on all task distributions, making it resilient to changes between meta-training and meta-testing. We propose an algorithm to solve this new formulation, which converges to an accurate point in both convex and nonconvex settings. We also provide an upper bound on the new task generalization error and demonstrate its advantage in sinusoid regression and image classification experiments.