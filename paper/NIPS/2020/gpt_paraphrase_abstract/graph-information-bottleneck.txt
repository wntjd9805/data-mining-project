Graph Neural Networks (GNNs) are effective in representing graph-structured data by incorporating information from both the network structure and node features. However, GNNs are vulnerable to adversarial attacks. To address this, we propose Graph Information Bottleneck (GIB), a principle that optimizes the trade-off between expressiveness and robustness in learned representations. GIB aims to find the minimal sufficient representation for a given task by maximizing the mutual information between the representation and the target, while constraining the mutual information between the representation and the input data. Unlike the general Information Bottleneck, GIB regularizes both the structural and feature information. We introduce two sampling algorithms for structural regularization and instantiate GIB with two new models: GIB-Cat and GIB-Bern. Through evaluation, we demonstrate that our models are more robust than existing graph defense models, achieving up to 31% improvement against adversarial attacks on both the graph structure and node features.