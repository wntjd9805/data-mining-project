Neural networks are susceptible to input disturbances such as noise and adversarial attacks, while human perception is more resistant to such disturbances. The Bayesian brain hypothesis suggests that human brains utilize an internal generative model to update their beliefs about sensory input. This process can be seen as aligning the maximum a posteriori estimation of the internal model with the external environment. Inspired by this hypothesis, we incorporate generative recurrent feedback into neural networks to enforce self-consistency. We apply this design to convolutional neural networks (CNNs) and call it Convolutional Neural Networks with Feedback (CNN-F). CNN-F introduces generative feedback with latent variables into existing CNN architectures and achieves consistent predictions through alternating MAP inference under a Bayesian framework. Experimental results demonstrate that CNN-F exhibits significantly improved resilience to adversarial attacks compared to conventional feedforward CNNs on standard benchmarks.