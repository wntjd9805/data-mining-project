To handle large amounts of data, it is common to compress vectors and matrices. While compression makes storage and transmission more efficient, it raises the question of whether processing the compressed data is also easier. This paper examines lossless compression schemes and explores whether computations can be performed on compressed data as efficiently as on the original uncompressed data. The focus is on basic linear algebra operations such as inner product, matrix-vector multiplication, and matrix multiplication. The goal is to determine if these operations can be executed on compressed representations with a time complexity of O(n) instead of O(N), where n is the compressed size and N is the original size. The answer to this question depends on the compression scheme used. While simple schemes like Run-Length-Encoding (RLE) allow for O(n) time complexity for inner product computation, we prove that this is not possible for more complex compression schemes like grammar-compressions, which include popular methods like the Lempel-Ziv family. These schemes provide greater compression but make computations significantly more difficult.