We address the problem of learning the best-fitting single neuron using gradient descent to minimize the empirical risk. The activation function used is arbitrary, making the optimization problem nonconvex and nonsmooth. We cover various activation functions commonly used in neural networks. In the agnostic PAC learning setting, where no assumptions are made about the relationship between the labels and inputs, we prove that gradient descent achieves a population risk close to the optimal risk in polynomial time and sample complexity. This holds true when the activation function is strictly increasing. Specifically, for ReLU activation, the population risk guarantee is also close to the optimal risk. When labels have a specific form with zero-mean sub-Gaussian noise, the population risk guarantees further improve. Our guarantees are independent of the dimension and do not require any additional assumptions beyond boundedness, except for ReLU activation where a nondegeneracy assumption is needed for the input distribution.