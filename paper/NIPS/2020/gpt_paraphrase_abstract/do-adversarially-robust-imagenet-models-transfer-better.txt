Transfer learning is a commonly used approach in which models pre-trained on standard datasets are adapted to new tasks. It is generally believed that better pre-trained models lead to better transfer learning results, indicating that initial accuracy is important for transfer learning performance. However, this study reveals another crucial factor: adversarially robust models, though less accurate, often outperform standard-trained models in transfer learning. Specifically, the study focuses on adversarially robust ImageNet classifiers and demonstrates that they achieve higher accuracy on downstream classification tasks. Further analysis uncovers additional distinctions between robust and standard models in the context of transfer learning. These findings support recent hypotheses suggesting that robustness improves the quality of feature representations. The code and models used in this study can be accessed at https://github.com/Microsoft/robust-models-transfer.