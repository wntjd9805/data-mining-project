Biological agents exhibit lifelong learning and adaptability. However, modern reinforcement learning (RL) approaches lack the ability to adapt to new information or perturbations once training is completed. To address this limitation, we propose a search method inspired by synaptic plasticity in biological brains. Instead of optimizing weight parameters directly, our method searches for synapse-specific Hebbian learning rules that allow neural networks to continuously self-organize their weights throughout the agent's lifetime. We apply this approach to various RL tasks, including navigating a dynamic 2D-pixel environment and teaching a simulated 3D quadrupedal robot to walk while adapting to morphological damage. Remarkably, our method achieves these tasks with random weights and without explicit reward or error signals in less than 100 timesteps. The code for our approach is available at https://github.com/enajx/HebbianMetaLearning.