Federated learning is a distributed approach to training models using data from multiple users, while keeping the data on their devices for efficiency and privacy. However, the data from different users often has variations in distribution, which affects the performance of the trained model. This paper aims to develop a robust federated learning algorithm that can handle distribution shifts in users' data. We propose a perturbation model that captures the heterogeneity in federated settings, such as variations in image quality. To address these distribution shifts, we introduce a Federated Learning framework Robust to Affine distribution shifts (FLRA). We also present a fast and efficient optimization method to solve FLRA's optimization problem. Additionally, we provide guarantees on convergence and performance using a gradient Descent Ascent (GDA) method. We conduct numerical experiments to support FLRA and demonstrate its superiority over standard federated learning and adversarial training methods in handling distribution shifts.