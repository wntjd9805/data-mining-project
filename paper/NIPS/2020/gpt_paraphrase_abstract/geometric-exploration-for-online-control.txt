We investigate the control of an unfamiliar linear dynamical system with convex costs. Our goal is to minimize regret in comparison to strongly-stable linear policies. Initially, we address the scenario where the cost functions are known. We propose a novel algorithm that has a polynomial-time complexity and achieves n3T -regret, where n represents the combined dimensions of the state and control input. This algorithm outperforms the previous best-known bound of T 2/3 and demonstrates optimal dependence on the horizon, T. The key feature of our algorithm is an innovative geometric exploration strategy that constructs a sequence of barycentric spanners in an over-parameterized policy space. Additionally, we explore the case of bandit feedback and present a polynomial-time algorithm that achieves poly(n)T -regret. This algorithm builds upon Stochastic Bandit Convex Optimization.