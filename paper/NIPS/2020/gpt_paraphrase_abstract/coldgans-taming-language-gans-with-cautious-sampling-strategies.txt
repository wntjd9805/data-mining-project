Training methods that rely on Maximum Likelihood Estimation (MLE) have limitations that result in the production of subpar text sequences. These limitations stem from the mismatch between training and inference, known as exposure bias. This bias is worsened by considering only the reference texts as correct, when in reality there could be multiple valid formulations. Generative Adversarial Networks (GANs) have the potential to address these limitations, but the discrete nature of text has made it challenging to apply GANs to language generation. Previous approaches based on Reinforcement Learning have been shown to perform worse than MLE. In this study, we examine the exploration step in GANs for text generation and demonstrate that traditional sampling leads to unstable training. To overcome this, we propose a GAN framework called ColdGANs, which utilizes alternative exploration strategies that encourage sampling closer to the distribution modes for smoother learning dynamics. Our language GANs, for the first time, outperform MLE and achieve improvements over the current state-of-the-art in three generative tasks: unconditional text generation, question generation, and abstractive summarization.