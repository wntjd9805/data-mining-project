Stochastic gradient descent (SGD) and its variations are widely used in large-scale machine learning problems due to their effectiveness and computational advantages. However, their application has been limited in cases where the data samples are correlated because the stochastic gradient is a biased estimator of the full gradient. This lack of understanding has hindered the use of SGD in correlated settings. This study focuses on Gaussian processes (GP) and aims to overcome this limitation by proving that minibatch SGD converges to a critical point of the full loss function and accurately recovers model hyperparameters. The convergence rate is O(1/K) with a statistical error term based on the minibatch size. Both simulated and real datasets confirm that minibatch SGD outperforms state-of-the-art GP methods in terms of generalization while reducing computational complexity. This opens up new possibilities for GPs in previously unexplored data size regimes.