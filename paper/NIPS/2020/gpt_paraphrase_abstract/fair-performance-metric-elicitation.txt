This abstract discusses the concept of fair performance metrics and explores the idea of metric elicitation as a means to select the most suitable metrics based on implicit preferences. The use of metric elicitation allows practitioners to customize performance and fairness metrics according to the specific task, context, and population involved. The abstract introduces a new approach for eliciting group-fair performance metrics in multiclass classification problems with multiple sensitive groups. This approach also involves the selection of a trade-off between predictive performance and fairness violation. The proposed elicitation strategy is resilient to both limited sample size and feedback noise, and it only requires relative preference feedback.