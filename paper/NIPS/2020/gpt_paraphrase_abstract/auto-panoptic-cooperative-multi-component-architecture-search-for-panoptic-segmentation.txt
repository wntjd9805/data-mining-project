This abstract discusses the development of an efficient and automated framework for panoptic segmentation, which involves simultaneously segmenting foreground objects and background elements in a scene. The current state-of-the-art network for panoptic segmentation is complex and relies on expert knowledge and extensive trials. The proposed framework utilizes a one-shot Network Architecture Search (NAS) paradigm to search for the main components of the segmentation pipeline, including the backbone, segmentation branches, and feature fusion module. The multi-component scenario is addressed by incorporating an intra-modular search space and an inter-modular search space. This approach allows for an optimal network architecture that performs well in both instance segmentation and semantic segmentation tasks and considers the relationship between foreground objects and background elements. To reduce computation burden, a path-priority greedy search policy is introduced. The resulting architecture, called Auto-Panoptic, achieves state-of-the-art performance on COCO and ADE20K benchmarks. Experiments demonstrate the effectiveness of the path-priority policy and the transferability of Auto-Panoptic across different datasets. The codes and models are available at the provided GitHub link.