Self-supervised depth estimators have made significant progress in single image depth estimation (SIDE) by leveraging the geometric relations between target and reference views in training data. However, existing methods have limitations in effectively handling occlusions between target and reference images, resulting in suboptimal performance. In this study, we propose a novel approach called "Forget About the LiDAR" (FAL) with Mirrored Exponential Disparity (MED) probability volumes for training monocular depth estimators from stereo images. Our MED representation allows us to generate occlusion maps using the Mirrored Occlusion Module (MOM), which does not impose a learning burden on our FAL-net. Unlike previous methods that regress disparity in the linear space, our FAL-net regresses disparity by binning it into the exponential space, enabling better detection of distant and nearby objects. We adopt a two-step training strategy, first training the FAL-net for view synthesis and then fine-tuning it for depth estimation with MOM. Our FAL-net is lightweight and outperforms state-of-the-art methods on the challenging KITTI dataset, with significantly fewer parameters and faster inference speeds. Extensive experimental results on the KITTI, CityScapes, and Make3D datasets validate the effectiveness of our method. To the best of our knowledge, our approach achieves the highest performance among all previous self-supervised methods.