Creating adaptive predictions based on input is a crucial skill for artificial intelligence. This study introduces a semi-parametric approach called Meta-Neighborhoods, which adapts predictions to the input's neighborhood. It is demonstrated that Meta-Neighborhoods is a generalization of k-nearest-neighbors and provides a more accurate representation of the predictive distribution p(y | x) due to the simpler manifold structure in local neighborhoods. To minimize memory and computation, induced neighborhoods are proposed to summarize training data into a smaller dictionary. A meta-learning training mechanism is then utilized to simultaneously learn the induced neighborhoods and the model. Extensive research confirms the effectiveness of the proposed method.