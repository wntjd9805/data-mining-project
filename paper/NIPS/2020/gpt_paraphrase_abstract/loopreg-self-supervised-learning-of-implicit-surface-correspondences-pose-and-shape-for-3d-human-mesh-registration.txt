We propose a solution to fitting 3D human models to 3D scans of dressed humans. Existing methods require close initialization to be reliable, and some use supervised correspondence predictors that can only process one scan at a time. Our main contribution is a learning framework called LoopReg, which registers a corpus of scans to a common 3D human model. We achieve this by creating a self-supervised loop using a backward map and a forward map. The backward map predicts the correspondence from scan points to the human model surface, while the forward map transforms the corresponding points back to the scan. To ensure the output of the neural network (NN) is on the human model surface, we define the surface implicitly as the zero level set of a distance field in 3D space. Additionally, we diffuse the human model to the 3D domain, allowing for mapping of slightly deviated NN predictions. Our results show that LoopReg can be trained mainly self-supervised, becoming more accurate as more unlabelled raw scans are processed. Our code and pre-trained models are available for research purposes.