Gradient clipping is commonly used in training deep neural networks to address the problem of exploding gradients. Recent research has shown that clipped Gradient Descent (GD) can converge faster than vanilla GD/SGD by introducing a new assumption called (L0, L1)-smoothness, which captures the violent fluctuations of gradients observed in deep neural networks. However, the iteration complexities of this approach are pessimistic, and there is a lack of theoretical justification for combining clipping with other important techniques like momentum acceleration. This paper aims to bridge this gap by presenting a general framework that considers clipping algorithms along with momentum methods. The convergence of the framework is analyzed in both deterministic and stochastic settings, and the results are compared with existing lower bounds to demonstrate their accuracy. These findings suggest that clipping methods remain efficient even in highly non-smooth regions. Experimental results further validate the superior performance of clipping-based methods in deep learning tasks.