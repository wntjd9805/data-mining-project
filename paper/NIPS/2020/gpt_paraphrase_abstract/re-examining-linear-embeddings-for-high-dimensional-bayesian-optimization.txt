Bayesian optimization (BO) is a popular method for optimizing black-box functions that are expensive to evaluate. However, a major challenge with BO is its scalability to high-dimensional parameter spaces while maintaining sample efficiency. To address this, previous research has suggested using linear embeddings to reduce the dimensionality of the space. In this study, we identify important issues and misconceptions regarding the use of linear embeddings in BO. We analyze existing literature on linear embeddings and demonstrate that certain design choices negatively impact their performance. Through empirical analysis, we show that addressing these issues significantly enhances the effectiveness of linear embeddings in BO across various problem domains, such as developing a gait policy for robot locomotion.