This study explores online convex optimization (OCO) and its assumption of Lipschitz continuity in functions to achieve sublinear regret. It also investigates the logarithmic regret when functions are strongly convex. Recently, researchers proposed the concepts of "relative Lipschitz continuity" and "relative strong convexity" as generalizations of the classical counterparts. It has been found that subgradient methods in the relative setting perform similarly to those in the classical setting. The study focuses on OCO for relative Lipschitz and relative strongly convex functions and extends the regret bounds of classical OCO algorithms to the relative setting. Specifically, regret bounds for follow the regularized leader algorithms and a variant of online mirror descent are presented. These results are applicable to a wide range of OCO algorithms due to the methods' generality. The study also extends the results to algorithms with additional regularization, such as regularized dual averaging.