A recent study has shown that a Graph Neural Network (GNN) can effectively reduce the running time of branch-and-bound algorithms for Mixed Integer Linear Programming (MILP). However, the GNN requires a GPU for inference, which limits its application as many users may not have access to high-end GPUs. This research aims to address two questions: 1) Can the GNN model still perform well in a realistic setting where only a CPU is available? 2) Can we develop a less computationally expensive model that retains the predictive power of the GNN architecture? The first question is answered negatively, and the second question is addressed by proposing a new hybrid architecture that combines GNNs with computationally inexpensive multi-layer perceptrons (MLP) for branching on CPU machines. The proposed architecture is evaluated on four classes of MILP problems and demonstrates up to a 26% reduction in solver running time compared to state-of-the-art methods without a GPU. The code for this project is publicly available at the provided GitHub link.