Differential architecture search (DARTS) is known for its efficient search process. However, it often selects network architectures with dominant skip connections, resulting in decreased performance. The lack of theoretical understanding in this area has hindered the development of more advanced methods. In this study, we address this issue by analyzing the effects of different operations on network optimization, such as convolution, skip connection, and zero operation. We prove that architectures with more skip connections can converge faster than other candidates, explaining why DARTS selects them. This is the first time the impact of skip connections on fast network optimization and their advantage over other operations in DARTS has been theoretically revealed. Based on this insight, we propose a theory-inspired path-regularized DARTS that includes a differential group-structured sparse binary gate to ensure fair competition among operations, and a path-depth-wise regularization to encourage search exploration for deep architectures that typically converge slower than shallow ones. Our experimental results on image classification tasks confirm the advantages of our approach.