Survival analysis is used to predict the time until a specific event occurs, such as leaving the hospital or being admitted to the ICU. A well-calibrated model accurately predicts the number of events within different time intervals. Currently, calibration is assessed after training the model. However, we introduce explicit calibration (X-CAL), which allows for calibration optimization during training. This enables practitioners to find the right balance between predictive power and calibration. We conducted experiments using various models on simulated data, a survival dataset, length-of-stay prediction, and brain cancer data. Our results show that the models we tested can be miscalibrated, but X-CAL significantly improves calibration without sacrificing concordance or likelihood.