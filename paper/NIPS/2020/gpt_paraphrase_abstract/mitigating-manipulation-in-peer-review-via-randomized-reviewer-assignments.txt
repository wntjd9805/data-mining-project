This abstract discusses three main challenges in conference peer review: (i) reviewers attempting to manipulate the system by purposely getting assigned to specific papers to provide positive reviews, potentially in exchange for favors from the authors; (ii) "torpedo reviewing," where reviewers intentionally try to get assigned to papers they dislike in order to reject them; (iii) the risk of reviewers' identities being revealed when similarities and reviewer assignments are released. The authors propose a framework that connects these problems and present a randomized algorithm for reviewer assignment that optimally solves the problem while considering constraints on the probability of assignment for each reviewer-paper pair. They also address the issue of restricting the joint probability of certain suspect pairs of reviewers being assigned to certain papers, proving its efficiency for a practical case. Experimental evaluation on past conference datasets shows that the proposed algorithms can limit the chances of malicious reviewers getting assigned to their desired paper to 50% while maintaining over 90% of the total optimal similarity.