Traditional computer vision methods heavily rely on supervised learning with curated datasets. In contrast, humans learn about their surroundings without external guidance. Inspired by infants who learn through play and interaction, we introduce a computational framework that allows an agent to discover objects and their physical properties through interaction. By placing the agent in an AI2THOR environment that closely resembles reality and incorporates physics, the agent learns about objects, their sizes, and relative masses without any external supervision. Our experiments demonstrate that the agent learns efficiently and effectively, not only for previously encountered objects but also for new instances from known categories and even novel object categories.