Current methods for certifying the adversarial robustness of classifiers are computationally expensive and limited to attacks that optimize manipulation based on a norm. This study addresses these limitations by examining the robustness properties of Nearest Prototype Classifiers (NPCs) such as learning vector quantization and large margin nearest neighbor. The focus is on the hypothesis margin, which is proven to be a reliable lower bound on the size of adversarial attacks. By using a dissimilarity measure induced by a seminorm, the hypothesis margin can be calculated efficiently. Additionally, it is demonstrated that NPCs trained with a triplet loss maximize the hypothesis margin and are therefore optimized for adversarial robustness. The evaluation shows that these NPCs are competitive with state-of-the-art methods and establish a new benchmark for computational complexity in robustness certification.