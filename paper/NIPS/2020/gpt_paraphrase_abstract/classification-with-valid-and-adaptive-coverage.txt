Conformal inference, cross-validation+, and the jackknife+ are methods used in machine learning to create prediction sets that guarantee coverage. In this study, we introduce specialized versions of these techniques for categorical and unordered response labels. These versions not only ensure marginal coverage but also adapt well to complex data distributions, resulting in favorable approximate conditional coverage compared to other methods. Our main contribution is a novel conformity score, which is shown to be effective and intuitive for classification problems. This score has potential applications beyond classification. Synthetic and real data experiments validate the practical value of our theoretical guarantees and demonstrate the statistical advantages of our proposed methods over existing alternatives.