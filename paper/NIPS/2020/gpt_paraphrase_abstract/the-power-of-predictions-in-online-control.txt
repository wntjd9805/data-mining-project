We examine the influence of predictions in online Linear Quadratic Regulator control under stochastic and adversarial disturbances in the dynamics. We determine the optimal strategy and establish precise limits on the minimum cost and dynamic regret in both scenarios. Surprisingly, our analysis reveals that the conventional greedy MPC approach is nearly optimal in both stochastic and adversarial contexts. In particular, for problems of length-T, MPC only needs O(log T) predictions to achieve O(1) dynamic regret, which aligns with our lower bound on the prediction horizon needed for constant regret.