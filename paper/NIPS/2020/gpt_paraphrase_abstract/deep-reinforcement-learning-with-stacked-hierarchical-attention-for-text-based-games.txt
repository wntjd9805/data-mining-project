We examine reinforcement learning (RL) in the context of text-based games, which are interactive simulations using natural language. Current RL agents lack the ability to reason in textual games, despite various methods to represent environment information and language actions. Our objective is to enable explicit reasoning in RL by utilizing knowledge graphs for decision making, ensuring that the agent's actions are generated and supported by an interpretable inference procedure. To achieve this, we introduce a stacked hierarchical attention mechanism that constructs a clear representation of the reasoning process by leveraging the knowledge graph's structure. We extensively evaluate our approach on multiple benchmark games and find that our method outperforms existing text-based agents.