Recent advancements in medical imaging classification have been made through the use of deep neural networks. However, these advanced models still require large and representative datasets for training, which is often impractical in realistic clinical settings. When trained on limited datasets, deep neural networks lack the ability to generalize, meaning that they may not be able to accurately classify data from different distributions. To address this issue, we propose a simple yet effective approach to improve the generalization capability of deep neural networks in medical imaging classification. By leveraging the compact domain variability of medical images, we suggest learning a representative feature space through variational encoding with a novel linear-dependency regularization term. This enables the neural network to capture and utilize shared information among medical data from different domains, resulting in improved generalization to unseen medical data. Experimental results on challenging medical imaging classification tasks demonstrate that our method outperforms state-of-the-art baselines in terms of cross-domain generalization capability.