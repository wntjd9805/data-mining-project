The choice of hyperparameters is crucial for the performance of deep learning systems. However, tuning these hyperparameters is often expensive and time-consuming. Traditional tuning algorithms only consider the final performance of hyperparameters and ignore intermediate information from earlier training steps. In this paper, we propose a Bayesian optimization approach that takes into account the iterative nature of learning algorithms for efficient hyperparameter tuning. We develop an evaluation function that compresses learning progress at any stage of the training process into a single numeric score based on training success and stability. Our framework balances the benefit of assessing a hyperparameter setting with the computation cost. We also improve model efficiency by selectively including scores from different training steps for each evaluated hyperparameter set. We demonstrate the effectiveness of our algorithm by tuning hyperparameters for deep reinforcement learning agents and convolutional neural networks. Our algorithm outperforms existing methods in identifying optimal hyperparameters in minimal time.