The goal of few-shot image generation is to create more data for a specific domain despite having limited training examples. Instead of relying solely on a small number of observations, such as emojis, we propose using a larger, related source domain as a pretraining step, such as human faces. The objective is to maintain the diversity of the source domain while adapting to the visual characteristics of the target domain. Our approach involves adapting a pretrained model without adding any extra parameters to accommodate the few examples available in the target domain. To ensure the preservation of the "information" from the source dataset while fitting the target, we introduce regularization to control the changes in the model weights during adaptation. Our algorithm effectively produces high-quality results for various target domains, even with extremely limited examples (e.g., â‰¤10). Additionally, we analyze the performance of our method considering factors such as the number of examples and the dissimilarity between the source and target domains.