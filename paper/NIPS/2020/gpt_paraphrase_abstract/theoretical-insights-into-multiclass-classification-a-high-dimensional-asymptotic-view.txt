Machine learning applications today often involve classifying data into multiple categories. However, there is still a lack of precise understanding regarding the statistical properties and behavior of classification algorithms, especially when dealing with a large number of classes. This paper aims to fill this gap by providing an accurate analysis of linear multiclass classification. Through our theoretical analysis, we are able to characterize how the test error varies based on different factors such as training algorithms, data distributions, problem dimensions, number of classes, inter/intra class correlations, and class priors. We find that classification accuracy is highly dependent on the data distribution, with different algorithms performing optimally under different conditions. Unlike linear regression or binary classification, the test error in multiclass classification relies on complex functions of the trained model, making it difficult to characterize its behavior. Even simple classifiers, like those minimizing square loss, face this challenge. However, our innovative theoretical techniques help overcome some of these difficulties. The insights gained from this analysis can potentially contribute to a better understanding of other classification algorithms as well.