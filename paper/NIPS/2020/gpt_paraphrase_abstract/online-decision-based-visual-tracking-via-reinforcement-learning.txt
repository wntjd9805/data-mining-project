A deep visual tracker is typically based on either object detection or template matching, but each method is only suitable for certain types of scenes. While it may seem logical to combine these methods for more reliable tracking, this is not advisable because they operate on different principles. In contrast to previous fusion-based approaches, we propose a new framework called DTNet, which utilizes hierarchical reinforcement learning to make online decisions for visual tracking. Our decision mechanism enables an intelligent switching strategy where the detection and template trackers compete to track objects in scenes they are best suited for. Additionally, we introduce a novel detection tracker that addresses the issue of incorrect proposals. Extensive results demonstrate that DTNet achieves state-of-the-art tracking performance while maintaining a balance between accuracy and efficiency. Further information can be found on our project website: https://vsislab.github.io/DTNet/.