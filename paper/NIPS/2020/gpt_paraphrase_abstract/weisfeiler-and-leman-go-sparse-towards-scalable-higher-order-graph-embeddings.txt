Graph kernels based on the 1-dimensional Weisfeiler-Leman algorithm and corresponding neural architectures have been effective for learning with graphs. However, these algorithms have limitations in capturing global patterns and can only handle binary relations. The k-dimensional Weisfeiler-Leman algorithm addresses these issues by considering k-tuples of vertices and defining adjacency between these tuples to capture higher-order interactions. However, this algorithm is not scalable and may suffer from overfitting. Therefore, there is a need for WL-based graph learning methods that are expressive, scalable, and non-overfitting. In this study, we propose local variants and neural architectures that consider a subset of the original neighborhood, making them more scalable and less prone to overfitting. Our algorithms have a higher ability to distinguish non-isomorphic graphs compared to the original algorithm. Experimental results show that the local algorithms significantly reduce computation times and prevent overfitting. The kernel version achieves state-of-the-art performance on graph classification benchmarks, while the neural version shows promising results on large-scale molecular regression tasks.