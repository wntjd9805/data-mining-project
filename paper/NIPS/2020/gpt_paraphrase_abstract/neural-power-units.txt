Current neural networks are limited in their ability to generalize beyond the numbers they were trained on, particularly in performing arithmetic operations. Existing neural arithmetic units are either restricted to positive numbers or only capable of representing a subset of arithmetic operations. To address these limitations, we introduce the Neural Power Unit (NPU), which operates on the entire domain of real numbers and can learn arbitrary power functions in a single layer. Unlike other approaches, our NPU utilizes complex arithmetic without the need for converting the network to complex numbers. We also present a simplified version called the RealNPU, which offers a transparent model. Through experiments on artificial arithmetic datasets, we demonstrate that NPUs outperform competing methods in terms of accuracy and sparsity. Additionally, the RealNPU showcases its ability to discover the governing equations of a dynamical system solely from data.