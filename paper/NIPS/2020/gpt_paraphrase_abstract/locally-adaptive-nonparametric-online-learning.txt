Online algorithms have the advantage of adapting to various types of data sequences. In nonparametric scenarios, where performance is evaluated against complex comparator functions, efficient algorithms that can effectively utilize local patterns are scarce. To address this gap, we propose efficient online algorithms that adapt to different local regularities. These regularities include the local Lipschitzness of the comparator function, the local metric dimension of the data sequence, and the local performance of the predictor in different regions of the data space. Our approach involves dynamically growing hierarchical Îµ-nets on the data space, with prunings representing different locality profiles. By using tree experts, we compete against all prunings simultaneously and efficiently, proving regret bounds that scale with the specific type of local regularity. Compared to previous approaches, our technique achieves significantly better regret bounds when competing against simple locality profiles. Moreover, our bounds do not have a worse time dependence than those obtained by ignoring any local regularities.