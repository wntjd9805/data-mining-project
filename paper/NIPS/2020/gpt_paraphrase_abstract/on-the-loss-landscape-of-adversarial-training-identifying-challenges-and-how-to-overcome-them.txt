We examine the impact of adversarial training on the loss landscape of machine learning models. We conduct analytical studies on the characteristics of adversarial loss functions with different levels of adversarial budgets. Our findings demonstrate that the loss landscape becomes less favorable for optimization when subjected to larger adversarial budgets, primarily due to increased curvature and more scattered gradients. Numerical analyses support our conclusions, revealing that training with high adversarial budgets hinders the model's ability to escape suboptimal random initialization, results in non-vanishing gradients, and leads to the discovery of sharper minima. To address these challenges, we propose a periodic adversarial scheduling (PAS) strategy, which effectively overcomes the limitations of standard adversarial training and produces superior results. Furthermore, PAS is less sensitive to the choice of learning rate.