Feature importance ranking is a valuable tool for explainable AI, but it presents difficulties for deep learning due to its combinatorial nature. To address this challenge, we propose a dual-net architecture comprising an operator and a selector. The operator is trained using supervised learning, with optimal feature subset candidates generated by the selector. We introduce an alternate learning algorithm that trains both nets simultaneously and incorporates a stochastic local search procedure to tackle the combinatorial optimization problem. In deployment, the selector generates an optimal feature subset and ranks feature importance, while the operator makes predictions based on this subset for test data. Our approach outperforms existing methods in feature importance ranking and supervised feature selection, as demonstrated through evaluations on synthetic, benchmark, and real datasets. The source code for our approach is available at https://github.com/maksym33/FeatureImportanceDL.