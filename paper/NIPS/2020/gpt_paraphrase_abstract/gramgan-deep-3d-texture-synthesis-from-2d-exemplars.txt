We introduce a new method for generating high-quality 3D textures using a 2D exemplar image. Our approach is inspired by recent advancements in natural texture synthesis and involves training deep neural models to combine noise frequencies and create realistic textures. We propose a unique loss function that combines elements from style transfer and generative adversarial networks to ensure the output is conditioned on the exemplar patch. Additionally, we suggest two architectural concepts and an extrapolation strategy that greatly improve the overall performance and generalization ability of the model. Through quantitative and qualitative evaluations on various exemplars, we demonstrate that our system outperforms previous state-of-the-art approaches. Furthermore, a user study confirms the effectiveness of our framework.