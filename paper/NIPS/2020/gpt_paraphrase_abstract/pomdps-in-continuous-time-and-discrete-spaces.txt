This abstract discusses the problem of optimal decision making in systems that evolve in discrete space and continuous time, such as engineering processes or biological population dynamics. The focus is on systems with partial observability, which combines optimal filtering and optimal control. Currently, there is a lack of a mathematical description for simultaneous decision making and filtering in continuous time with finite state and action spaces. This paper provides a mathematical description of a continuous-time partial observable Markov decision process (POMDP) and uses optimal filtering theory to derive a Hamilton-Jacobi-Bellman (HJB) equation that represents the optimal solution. By employing deep learning techniques, the resulting partial integro-differential equation is approximately solved. The paper presents an approach to solve the decision problem offline by learning an approximation of the value function, as well as an online algorithm that offers a solution in belief space using deep reinforcement learning. The applicability of the proposed methods is demonstrated through toy examples, which can pave the way for future solutions to high dimensional problems.