Researchers have primarily focused on recognizing object categories at specific levels of granularity, such as basic-level or sub-level. While sub-level categories provide more valuable information, acquiring training annotations for them is more challenging. Therefore, a significant problem is how to transfer knowledge learned from basic-level annotations to sub-level recognition. This paper introduces a new task called Hierarchical Granularity Transfer Learning (HGTL), which aims to recognize sub-level categories using basic-level annotations and semantic descriptions for hierarchical categories. Unlike other recognition tasks, HGTL faces a granularity gap where the two levels share an image space but have different category domains, making knowledge transfer difficult. To address this issue, the paper proposes a novel Bi-granularity Semantic Preserving Network (BigSPN) that bridges the granularity gap for robust knowledge transfer. BigSPN constructs specific visual encoders for different granularities, aligning them with a shared semantic interpreter using a novel subordinate entropy loss. Experimental results on three benchmarks with hierarchical granularities demonstrate that BigSPN is an effective framework for Hierarchical Granularity Transfer Learning.