Deep clustering is a powerful technique that combines embedding and clustering to achieve optimal nonlinear embedding spaces, which outperform traditional clustering methods in real-world scenarios. However, the clustering network's robustness is compromised when it faces adversarial attacks. Even a small perturbation in the embedding space can result in different clustering outcomes due to the absence of labels. To address this issue, we propose a robust deep clustering method that utilizes adversarial learning. Our approach defines adversarial samples in the embedding space for the clustering network and employs an adversarial attack strategy to identify samples that deceive the clustering layers without affecting the deep embedding's performance. Additionally, we present a simple yet effective defense algorithm to improve the clustering network's robustness. Experimental results on popular datasets demonstrate that our adversarial learning method significantly enhances robustness and overall clustering performance. Importantly, our method can be applied to various existing clustering frameworks to enhance their robustness. The source code for our approach is available at https://github.com/xdxuyang/ALRDC.