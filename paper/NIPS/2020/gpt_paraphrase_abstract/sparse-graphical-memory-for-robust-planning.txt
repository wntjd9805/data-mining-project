Agents need to be able to process high-dimensional sensory input and achieve various goals over long periods of time in order to function effectively in the real world. Although current deep reinforcement and imitation learning methods can handle high-dimensional inputs, they struggle with long-term tasks. On the other hand, classical graphical methods like A* search are capable of solving long-term tasks but assume that the state space is abstracted from raw sensory input. Recent attempts have been made to combine deep learning and classical planning, but these methods are still fragile and do not scale well with the size of the environment. In this study, we introduce Sparse Graphical Memory (SGM), a new data structure that stores states and feasible transitions in a sparse memory. SGM aggregates states based on a two-way consistency objective, which considers two states redundant when they can be interchanged as both goals and starting points. Theoretical analysis shows that merging nodes based on two-way consistency only increases the shortest path lengths linearly with the merging threshold. Experimental results demonstrate that SGM outperforms current state-of-the-art methods in long horizon, sparse-reward visual navigation tasks. Further information and access to the project video and code can be found at https://mishalaskin.github.io/sgm/.