This study focuses on the challenge of transforming adversarially robust learning into standard PAC learning. In other words, it aims to understand how to learn predictors that are resilient to adversaries using only a non-robust learner. Our research introduces a reduction technique that can effectively learn any hypothesis class C by utilizing a non-robust learner A for C. The number of times A needs to be called is logarithmically dependent on the number of permissible adversarial perturbations per example. We also provide evidence that this reduction is necessary through a lower bound analysis.