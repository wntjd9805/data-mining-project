This paper presents a new approach for efficiently pruning channels in convolutional neural networks (CNNs) at runtime using deep reinforcement learning (DRL). The proposed framework uses DRL to determine the optimal number and selection of channels to prune in each convolutional layer, based on the input instance at runtime. Unlike existing methods, which require storing all channel parameters for inference, our framework incorporates a static pruning component that reduces parameter storage consumption. Experimental results comparing our framework to existing methods demonstrate that it achieves a balance between dynamic flexibility and storage efficiency in runtime channel pruning.