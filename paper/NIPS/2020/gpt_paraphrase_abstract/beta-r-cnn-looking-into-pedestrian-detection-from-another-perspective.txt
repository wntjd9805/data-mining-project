Recent advancements have been made in pedestrian detection, but achieving accurate results in crowded and occluded scenes remains challenging. This difficulty can be attributed to the commonly used 2D axis-aligned bounding box representation of pedestrians, which only provides an approximate location and size of the object. The bounding box treats the object as a uniform distribution within its boundaries, making it difficult to distinguish pedestrians in crowded and occluded scenes due to high levels of noise. To address this issue, we propose a new representation called Beta Representation, which is based on a 2D beta distribution. This representation explicitly constructs the relationship between the full-body and visible boxes of a pedestrian and assigns different probability values to pixels, emphasizing the center of visual mass. As a result, Beta Representation is more effective in distinguishing heavily overlapped instances in crowded scenes, and we introduce a new non-maximum suppression strategy called BetaNMS to further enhance its performance. To fully utilize the benefits of Beta Representation, we also introduce a novel pipeline called Beta R-CNN, which includes the components BetaHead and BetaMask. This pipeline achieves high detection performance in occluded and crowded scenes. The code for Beta R-CNN is available at github.com/Guardian44x/Beta-R-CNN.