This paper presents a method for Byzantine resilient distributed multi-task learning in multi-agent networks with heterogeneous data sources. The current distributed algorithms for learning relatedness among tasks are not resilient in the presence of Byzantine agents. To address this issue, the authors propose an efficient online weight assignment rule that measures the accumulated loss between an agent's data and its neighbors' models. A small accumulated loss indicates a high similarity between the two tasks. To ensure Byzantine resilience, a filtering step is introduced to remove larger losses during aggregation at a normal agent. The approach is analyzed for convex models, demonstrating that normal agents converge resiliently towards the global minimum. Moreover, the proposed weight assignment rule always leads to improved expected regret compared to non-cooperative cases. Three case studies, including regression and classification problems, are presented to demonstrate the method's empirical performance, particularly for non-convex models like convolutional neural networks.