Prior research on building neural networks that are robust against adversarial attacks in image classification tasks has relied on large training sets and computationally intensive training procedures. However, existing few-shot learning methods are highly susceptible to adversarial examples. In this study, our objective is to develop networks that excel in both few-shot classification tasks and demonstrate resistance to adversarial attacks. To achieve this, we introduce a novel algorithm called Adversarial Querying (AQ) that generates meta-learners capable of withstanding adversarial attacks. We thoroughly investigate the factors contributing to adversarial vulnerability and identify the causes. Additionally, our approach outperforms robust transfer learning in terms of robust performance on few-shot image classification tasks like Mini-ImageNet and CIFAR-FS.