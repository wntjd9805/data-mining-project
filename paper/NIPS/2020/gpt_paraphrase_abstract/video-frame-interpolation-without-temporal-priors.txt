Video frame interpolation is an important area of research in computer vision, aiming to generate intermediate frames in a video sequence. Existing methods have achieved impressive results under specific assumptions, such as instant or known exposure time. However, in real-world scenarios, videos can have different temporal priors, such as frames per second (FPS) and frame exposure time, due to variations in camera sensors. This leads to significant misalignment issues when interpolating frames from test videos taken with different exposure settings than the training ones. In this study, we address the video frame interpolation problem in a general situation where input frames are acquired under uncertain exposure and interval time. Unlike previous methods limited to specific temporal priors, we propose a general curvilinear motion trajectory formula derived from either four consecutive sharp frames or two consecutive blurry frames without prior temporal information. Additionally, by incorporating constraints within adjacent motion trajectories, we develop a novel strategy for refining optical flow, resulting in improved interpolation results. Our experiments demonstrate that a single well-trained model can synthesize high-quality slow-motion videos even in complicated real-world situations. The codes for our approach are publicly available at https://github.com/yjzhang96/UTI-VFI.