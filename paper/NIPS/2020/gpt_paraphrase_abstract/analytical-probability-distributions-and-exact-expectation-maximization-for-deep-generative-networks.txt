Variational Autoencoders (VAEs) are commonly used to train Deep Generative Networks (DGNs) with probabilistic modeling. However, VAEs rely on approximations due to the lack of known analytical forms for the posterior and likelihood expectation. These approximations include Amortized Variational Inference (AVI) and Monte-Carlo sampling. In this study, we take advantage of the Continuous Piecewise Affine property of modern DGNs to derive their posterior and marginal distributions, as well as the first two moments of the latter. This new understanding allows us to develop an analytical Expectation-Maximization (EM) algorithm for gradient-free DGN learning. Empirical results demonstrate that training DGNs using EM produces higher likelihood compared to VAE training. Our novel framework also paves the way for improved VAE AVI methods that better approximate the true posterior. Additionally, it enables the application of standard statistical tools for tasks such as model comparison, anomaly detection, and missing data imputation.