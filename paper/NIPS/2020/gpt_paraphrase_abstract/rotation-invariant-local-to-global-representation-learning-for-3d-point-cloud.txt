We present a novel algorithm for learning representations of 3D point cloud data that can handle different geometric transformations, particularly rotation, without explicitly augmenting the data. Our approach utilizes graph convolutional neural networks to create a hierarchical descriptor system that encodes rotation-invariant shape information in a bottom-up manner. Descriptors at each level are generated using a neural network and a graph-based stochastic sampling method, ensuring robustness to input variations. Our algorithm achieves state-of-the-art performance on benchmarks for recognizing and segmenting rotation-augmented 3D objects. We also conduct comprehensive ablative experiments to analyze its characteristics.