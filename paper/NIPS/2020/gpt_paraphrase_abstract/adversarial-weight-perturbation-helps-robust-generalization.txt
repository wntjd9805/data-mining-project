The research on enhancing the resistance of deep neural networks to adversarial examples has seen significant growth in recent years. Adversarial training, which involves training on adversarially perturbed examples to flatten the input loss landscape, has shown the most promise. However, the impact of the weight loss landscape on adversarial training has been largely unexplored. In this study, we take a new perspective on the weight loss landscape and discover a clear correlation between the flatness of this landscape and robust generalization. Various improvements to adversarial training, such as early stopping, new objective functions, and leveraging unlabeled data, implicitly flatten the weight loss landscape. Building upon these findings, we propose a simple and effective method called Adversarial Weight Perturbation (AWP) to explicitly regularize the flatness of the weight loss landscape. AWP introduces a double-perturbation mechanism in the adversarial training framework by perturbing both the inputs and weights. Extensive experiments demonstrate that AWP successfully achieves a flatter weight loss landscape and can easily be incorporated into existing adversarial training methods to enhance their robustness against adversarial attacks.