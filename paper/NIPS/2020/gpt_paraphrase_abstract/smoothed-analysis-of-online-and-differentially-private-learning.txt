Robustness and privacy are essential qualities in algorithms, leading to the development of online adversarial and differentially private learning algorithms. The key measure of learnability in these algorithms is the Littlestone dimension of the hypothesis class. However, this measure is often seen as impossible to achieve due to classes like linear thresholds and neural networks having infinite Littlestone dimension. In this study, we employ the concept of smoothed analysis, where adversarial inputs are slightly perturbed by nature. By doing so, we demonstrate that stronger guarantees for regret and error are attainable compared to worst-case scenarios. Specifically, our results indicate that regret and privacy error bounds can be determined based on the VC dimension and bracketing number of the hypothesis class, as well as the magnitude of the perturbations.