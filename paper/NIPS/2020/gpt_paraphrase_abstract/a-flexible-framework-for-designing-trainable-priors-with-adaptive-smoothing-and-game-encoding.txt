We propose a general framework for creating and training neural network layers that can solve non-smooth convex optimization problems. These layers are based on optimization algorithms and are specifically designed for convex games, where local agents communicate through regularization functions. This approach is particularly useful for solving imaging problems because it allows the integration of traditional image priors into deep models that can be trained end to end. The image priors used in our approach include various techniques such as total variation, Laplacian regularization, bilateral filtering, sparse coding on learned dictionaries, and non-local self similarities. Our models are highly interpretable and efficient in terms of both parameters and data. Through experiments, we demonstrate the effectiveness of our models in diverse tasks like image denoising, compressed sensing for fMRI, and dense stereo matching.