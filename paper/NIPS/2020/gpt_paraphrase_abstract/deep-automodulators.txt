We present a new type of generative autoencoder called automodulators. These networks can accurately reproduce individual real-world images like regular autoencoders, but they can also generate a merged sample from a combination of multiple images. This allows for instant style-mixing and other novel applications. Automodulators separate the data flow of decoder operations from their statistical properties and use a latent vector to modulate the former based on the latter. We propose a method for disentangling decoder layers in a principled way. While previous work has explored similar decoder architectures with GANs, their focus has been on random sampling. In contrast, our autoencoder can operate on real input images. We demonstrate how to train this versatile model to produce sharp outputs in high resolution using new training techniques, showcasing its effectiveness on four image datasets. In addition to style-mixing, we achieve state-of-the-art results in autoencoder comparison and visually high-quality images that are almost indistinguishable from state-of-the-art GANs. We anticipate that automodulator variations will serve as valuable components for image applications and other data domains.