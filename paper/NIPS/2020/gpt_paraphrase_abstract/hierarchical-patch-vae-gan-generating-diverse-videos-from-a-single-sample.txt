We present a method for generating diverse and unique videos from a single video sample. While previous approaches have been successful in generating diverse images, they struggle to achieve diversity in video generation and often produce samples similar to the training video. To address this issue, we introduce a new patch-based variational autoencoder (VAE) that allows for greater diversity in generation. Our approach involves using the patch-VAE at coarse scales to ensure high diversity in samples, and then employing a patch-GAN at finer scales to capture fine details and produce high-quality videos. Experimental results demonstrate that our method successfully generates diverse samples in both the image and video domains. The code and supplementary material, including additional samples, can be found at https://shirgur.github.io/hp-vae-gan.