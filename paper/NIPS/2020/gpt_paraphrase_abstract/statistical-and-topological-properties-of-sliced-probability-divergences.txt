The concept of slicing divergences has been successful in comparing probability measures in machine learning applications. It involves calculating the expected value of a 'base divergence' between one-dimensional random projections of the measures. However, the implications of this technique in terms of topology, statistics, and computation have not been well-established. This paper aims to address this gap and explore the theoretical properties of sliced probability divergences. The authors demonstrate that slicing preserves the metric axioms and weak continuity of the divergence, indicating similar topological properties. They also provide specific results for base divergences belonging to the class of integral probability metrics. Additionally, they establish that the sample complexity of a sliced divergence is independent of the problem dimension under certain conditions. The authors further apply their findings to various base divergences and validate their theory through synthetic and real data experiments.