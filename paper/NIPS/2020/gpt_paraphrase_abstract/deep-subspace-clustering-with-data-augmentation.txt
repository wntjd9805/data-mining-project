Data augmentation techniques are commonly used in classification tasks to improve the performance of neural networks. These techniques involve applying transformations to input data to create slightly modified versions of the original data. However, in deep subspace clustering (DSC), where ground-truth labels are not available, data augmentation techniques cannot be easily used. In this study, we propose a method to incorporate data augmentation benefits into DSC algorithms. We achieve this by learning representations that maintain consistent subspaces for slightly transformed inputs. Specifically, we introduce a temporal ensembling component to the objective function of DSC algorithms, allowing the networks to maintain consistent subspaces for random transformations in the input data. Additionally, we present an unsupervised procedure to find effective data augmentation policies. These policies define image processing transformations with specific magnitudes and probabilities of being applied to each image in each epoch. Through a search process, we identify the best policy that maximizes the mean Silhouette coefficient in the clustering results of the DSC network on a target dataset. Our method outperforms existing techniques on four standard subspace clustering datasets. The source code for our approach is available at the provided GitHub repository.