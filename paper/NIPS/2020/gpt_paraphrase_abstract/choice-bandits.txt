In recent years, there has been significant interest in the problem of dueling bandits, where a learner plays a pair of arms and receives feedback through relative pairwise comparisons. This abstract introduces a natural generalization called choice bandits, where the learner plays a set of up to k â‰¥ 2 arms and receives limited feedback in the form of a single multiway choice. The study focuses on a general class of choice models that includes the multinomial logit (MNL) and multinomial probit (MNP) models, as well as random utility models with i.i.d. noise (IID-RUMs). The proposed algorithm, Winner Beats All (WBA), has a regret bound of O(log T) under all these choice models. Despite the challenge of a large decision space, the algorithm addresses this by extracting a limited number of statistics from multiway choices and leveraging the existence of a unique 'best' arm to construct sets with low regret. The upper bound result is complemented by a lower bound result, demonstrating its optimality. Experimental results show that the algorithm performs competitively with previous dueling bandit algorithms for k = 2 and outperforms the MaxMinUCB algorithm designed for the MNL model for the more general case of k > 2.