We propose a novel approach to analyzing experts' eye movements and verbal narrations in order to uncover important and understandable knowledge patterns that shed light on their decision-making processes. These patterns can be used to enhance data-driven statistical models by incorporating experts' domain knowledge, thereby supporting complex human-machine collaborative decision-making. Our main contribution is a dynamic Bayesian nonparametric model that assigns latent knowledge patterns to different phases of decision-making. Each phase is characterized by a unique distribution of word topics derived from verbal narrations and their interactions with eye movement patterns, which reveal experts' distinct perceptual behavior during specific decision-making stages. To efficiently explore the posterior state space, we have developed a new split-merge-switch sampler that improves the mixing rate. The effectiveness of our proposed model and the discovered knowledge patterns is demonstrated through case studies on diagnostic error prediction and disease morphology categorization.