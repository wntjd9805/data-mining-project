In real-world situations, decision makers often need to optimize multiple competing objectives efficiently and with limited samples. Multi-objective Bayesian optimization (BO) is a popular method, but the best acquisition functions for this approach often lack known analytic gradients and require significant computational resources. To address this, we utilize recent advancements in programming models and hardware acceleration for multi-objective BO using the Expected Hypervolume Improvement (EHVI) algorithm, which is known for its computational complexity. We introduce a new formulation called q-Expected Hypervolume Improvement (qEHVI) that extends EHVI to the parallel, constrained evaluation setting. qEHVI computes the joint EHVI of q new candidate points exactly (with only Monte-Carlo integration error). Unlike previous EHVI formulations that rely on gradient-free optimization or approximated gradients, we use auto-differentiation to calculate exact gradients of the Monte Carlo estimator. This enables efficient optimization using first-order and quasi-second-order methods. Our empirical evaluation shows that qEHVI is computationally feasible in many practical scenarios and outperforms state-of-the-art multi-objective BO algorithms in a fraction of the time.