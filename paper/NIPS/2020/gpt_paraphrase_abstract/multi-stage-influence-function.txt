Multi-stage training and knowledge transfer have greatly improved performance in natural language processing and computer vision. This paper introduces a multi-stage influence function score that traces predictions from a fine-tuned model back to the pretraining data. By using this score, we can identify the pretraining examples that contribute the most to a prediction in the fine-tuning task. This multi-stage influence function extends the original influence function to incorporate both pretrained and fine-tuned models. The method is tested in different scenarios, where pretrained embeddings are either fixed or updated during fine-tuning. Experimental results demonstrate the effectiveness and potential applications of the proposed approach.