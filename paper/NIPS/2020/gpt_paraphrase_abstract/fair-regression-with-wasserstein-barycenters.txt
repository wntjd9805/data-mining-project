We investigate the problem of learning a real-valued function that adheres to the Demo-graphic Parity constraint, which requires the predicted output distribution to be independent of a sensitive attribute. We focus on the scenario where the sensitive attribute is known for prediction. By connecting fair regression with optimal transport theory, we derive a mathematical expression for the optimal fair predictor. Specifically, we find that this optimum's distribution is the Wasserstein barycenter of distributions generated by the standard regression function on the sensitive groups. This finding provides an intuitive explanation of the optimal fair prediction and suggests a straightforward post-processing algorithm for achieving fairness. We establish guarantees for risk and distribution-free fairness with this approach. Numerical experiments demonstrate the effectiveness of our method in learning fair models, with a minor increase in error rate compared to the improvement in fairness.