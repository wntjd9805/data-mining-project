We explore the challenges of constrained submodular maximization problems, which arise in various applications such as personalized recommendation and revenue maximization through viral marketing. The size of these instances in modern applications can make existing algorithms too slow, and they often involve stochastic elements. To address these challenges, we revisit the problem of maximizing a submodular function subject to a knapsack constraint, even when the function is not necessarily monotone. We propose a randomized greedy algorithm that achieves a 5.83 approximation and runs in O(n log n) time, significantly faster than other state-of-the-art algorithms. Our approach is also robust and can be extended to a stochastic version of the problem, where we achieve a 9-approximation to the best adaptive policy, the first constant approximation for non-monotone objectives. We validate the performance of our algorithms through experimental evaluation using both real and synthetic data.