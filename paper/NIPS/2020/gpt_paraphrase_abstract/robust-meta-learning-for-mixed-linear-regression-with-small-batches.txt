In practical supervised learning, such as medical image processing and robotic interactions, there is a challenge of not having enough labeled examples for each task. However, by leveraging the similarities between tasks, it is possible to overcome this data scarcity. In this study, we investigate whether a large number of small-data tasks can make up for the lack of big-data tasks when each task is drawn from a mixture of linear regressions. Previous approaches have shown that this trade-off can be achieved efficiently with medium-sized tasks containing Ω(k1/2) examples each. However, these approaches are not robust in two important scenarios: when there are outliers in the dataset or when the medium-sized tasks have slightly fewer than o(k1/2) examples each. We propose a spectral approach that is robust in both scenarios. Firstly, we develop a novel algorithm for outlier-robust principal component analysis, which achieves optimal accuracy. Then, we use a sum-of-squares algorithm to extract information from higher order moments. This combined approach is robust against outliers and achieves a balanced statistical trade-off. It allows for smaller tasks, as small as O(log k), to compensate for the lack of Ω(k1/2)-size tasks.