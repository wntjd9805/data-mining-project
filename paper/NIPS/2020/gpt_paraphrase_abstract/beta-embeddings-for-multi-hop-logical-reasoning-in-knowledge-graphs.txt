One of the main challenges in Artificial Intelligence is performing complex logical reasoning over large and incomplete knowledge graphs (KGs). Previous approaches have used low-dimensional embeddings to find answer entities, but they have limitations in handling arbitrary first-order logic (FOL) queries. They are unable to support the negation operator and cannot naturally model uncertainty. In this study, we propose BETAE, a probabilistic embedding framework that can handle a complete set of FOL operations, including conjunction, disjunction, and negation. BETAE utilizes probabilistic distributions, specifically the Beta distribution, to embed queries/entities and accurately model uncertainty. Neural operators are used to perform logical operations in the embedding space. We evaluate BETAE on three large, incomplete KGs and demonstrate its improved performance compared to existing KG reasoning methods. BETAE increases relative performance by up to 25.4% and offers a more general solution that can handle various FOL queries.