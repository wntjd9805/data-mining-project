Deep reinforcement learning algorithms face challenges when dealing with high-dimensional image observations, as they must simultaneously learn representation and tasks. To address this, we propose the stochastic latent actor-critic (SLAC) algorithm, which explicitly learns latent representations to enhance RL from images. SLAC combines stochastic sequential models with RL by learning a compact latent representation and performing RL in this space. Our experiments show that SLAC outperforms both model-free and model-based alternatives in terms of performance and sample efficiency on various image-based control tasks. Code and result videos can be found on our website.