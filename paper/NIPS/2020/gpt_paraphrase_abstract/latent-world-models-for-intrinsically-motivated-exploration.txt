This study focuses on partially observable environments with sparse rewards. The researchers introduce a self-supervised representation learning approach for image-based observations. This approach organizes embeddings based on the temporal distance between observations. The resulting representation is resilient to stochasticity and can be used for detecting novel information using a predictive forward model. The researchers address both episodic and lifelong uncertainties by incorporating exploration guidance. They propose using a world model operating in the learned latent space to estimate missing information about the environment. The exploration problem in a tabular Partially Observable Labyrinth is examined as a motivation for the method. The effectiveness of the approach is demonstrated on challenging image-based exploration environments from the Atari benchmark, showing significant improvement compared to previous work. The source code for the method and all experiments can be accessed at https://github.com/htdt/lwm.