Due to their lack of expertise, average users often have to rely on uploading their private data to untrusted cloud servers in order to benefit from it. However, due to legal and privacy concerns, most users are only willing to contribute encrypted data and are not interested or lack the resources to participate in deep neural network (DNN) training in the cloud. A recent study proposes a fully homomorphic encryption (FHE)-based technique that allows for training DNNs on encrypted data in a non-interactive manner. However, this technique, which relies on lookup tables, significantly increases the training latency of private DNNs. In this paper, we introduce Glyph, a FHE-based technique that enables fast and accurate training of DNNs on encrypted data by utilizing both TFHE and BGV cryptosystems. Glyph leverages TFHE for implementing nonlinear activations and BGV for performing multiply-accumulations (MACs). Additionally, Glyph incorporates transfer learning in DNN training to enhance test accuracy and reduce the number of MACs between ciphertexts in convolutional layers. Experimental results demonstrate that Glyph achieves high accuracy and reduces training latency by 69% to 99% compared to previous FHE-based privacy-preserving techniques on encrypted datasets.