Learning from different types of data has been a long-standing goal in machine learning research, as natural phenomena are often described by multiple sources of information. However, existing generative models that approximate a multimodal evidence lower bound (ELBO) face challenges in training and learning the dependencies between different data types. In this study, we introduce a new objective function that efficiently utilizes the Jensen-Shannon divergence to handle multiple distributions. This objective function simultaneously approximates the individual and joint multimodal posteriors using a dynamic prior. Furthermore, we provide theoretical evidence that this new objective function optimizes an ELBO. Through extensive experiments, we demonstrate the superiority of our proposed model, called multimodal JS-divergence (mmJSD), compared to previous approaches in unsupervised, generative learning tasks.