This paper introduces a new approach to test-time augmentation in neural networks. While most current methods focus on augmenting datasets during training, this method selects suitable transformations for a test input. The approach involves an auxiliary module that predicts the loss of each possible transformation for the input. Lower predicted losses correspond to the transformations applied to the input. The network then averages the prediction results of augmented inputs to obtain the final results. Experimental results on image classification benchmarks demonstrate that this instance-aware test-time augmentation enhances the model's robustness against different corruptions.