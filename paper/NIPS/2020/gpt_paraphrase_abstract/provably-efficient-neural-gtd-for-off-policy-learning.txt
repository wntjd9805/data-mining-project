This study examines the use of a neural network (NN) function approximator in a gradient temporal difference (GTD) algorithm to minimize the mean squared Bellman error (MSBE). We demonstrate that for off-policy learning, the MSBE problem can be transformed into a min-max optimization involving two over-parameterized primal-dual NNs. This new formulation can be effectively solved using a neuralGTD algorithm. We conduct an analysis on the convergence of the proposed algorithm, utilizing a 2-layer ReLU NN architecture with m neurons. We prove that this algorithm computes an approximate optimal solution to the minimum MSBE problem as m → ∞.