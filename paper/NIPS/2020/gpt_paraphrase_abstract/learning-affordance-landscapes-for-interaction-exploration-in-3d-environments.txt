This study focuses on the ability of embodied agents to understand and navigate their surroundings in human spaces. The researchers propose a reinforcement learning approach that allows the agent to explore and learn about the affordances (i.e., the possibilities for interaction) of a new 3D environment, such as an unfamiliar kitchen. Using a combination of an RGB-D camera and high-level actions, the agent is rewarded for successfully interacting with objects and simultaneously trained to identify affordances through image-based segmentation. This approach enables the agent to efficiently act in new environments and prepares it for various interaction tasks. The researchers demonstrate their idea using AI2-iTHOR and show that agents can intelligently learn how to use new home environments and quickly adapt to different tasks.