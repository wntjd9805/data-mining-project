Regularization and transfer learning are commonly used techniques in machine learning to improve the generalization of models on unseen data. While regularization techniques are versatile and not specific to any particular task or architecture, they do not take full advantage of the available data. On the other hand, transfer learning methods can transfer knowledge from one domain to another but may struggle to generalize across different tasks and architectures, and can introduce additional training costs.  To address this gap, we propose a transferable perturbation called MetaPerturb, which is meta-learned to enhance generalization performance on unseen data. MetaPerturb is implemented as a lightweight network that operates on sets of inputs and is agnostic to input size and order, making it applicable across different layers. We then introduce a meta-learning framework to train the perturbation function concurrently on diverse tasks. Because MetaPerturb is trained on varied distributions across layers and tasks, it can generalize effectively to different tasks and architectures.  We validate the effectiveness and versatility of MetaPerturb by applying it to the training of various neural architectures on different datasets, compared to regularizers and fine-tuning. The results demonstrate that networks trained with MetaPerturb outperform baseline approaches on most tasks and architectures, with minimal increase in parameter size and no need for hyperparameter tuning.