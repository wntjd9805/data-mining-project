ContraGAN is a new approach to conditional image generation that improves upon existing methods by considering both pairwise relations between image and label embeddings, as well as relations between multiple image embeddings within the same batch. It achieves this by utilizing a conditional contrastive loss. The discriminator of ContraGAN determines the authenticity of samples and learns the relations between training images through a contrastive objective. The generator, on the other hand, aims to generate realistic images that deceive the discriminator and minimize the contrastive loss. Experimental results demonstrate that ContraGAN outperforms state-of-the-art models by 7.3% and 7.7% on the Tiny ImageNet and ImageNet datasets, respectively. Additionally, the researchers show that contrastive learning helps alleviate discriminator overfitting. To ensure a fair comparison, twelve state-of-the-art GANs were re-implemented using the PyTorch library, and the software package is accessible at https://github.com/POSTECH-CVLab/PyTorch-StudioGAN.