We examine the problem of robust linear regression in an online setting where data is received sequentially. We consider a corrupted Gaussian linear model with adversarial noise. Our focus is on an oblivious adversary, where the noise is independent of the data, as this is the only contamination model that allows for consistency. Existing algorithms require access to the entire dataset to identify and remove outliers. However, we demonstrate that using stochastic gradient descent on the L1 loss, we can converge to the true parameter vector at a rate of ˜O(1/(1-η)2n), regardless of the values of the contaminated measurements. Our proof relies on smoothing the non-smooth L1 loss using Gaussian data and a non-asymptotic analysis of Polyak-Ruppert averaged SGD. Experimental results support the effectiveness and scalability of our algorithm.