We propose a new lightweight generative adversarial network that efficiently manipulates images based on natural language descriptions. Our approach introduces a word-level discriminator to provide detailed training feedback to the generator, enabling it to focus on specific visual attributes without affecting other content not mentioned in the text. This word-level feedback also allows for a simplified and lightweight discriminator. Compared to existing methods, our approach has fewer parameters while still achieving competitive manipulation performance. Extensive experiments demonstrate that our method effectively disentangles visual attributes and accurately modifies images based on natural language descriptions.