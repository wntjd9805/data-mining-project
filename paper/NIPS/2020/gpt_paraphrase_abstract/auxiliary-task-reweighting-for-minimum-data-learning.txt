Supervised learning is limited by the availability of labeled data. One approach to address this issue is to use auxiliary tasks to provide additional supervision. However, the assignment and optimization of weights for these tasks are not well-studied. In this study, we propose a method to automatically adjust the weights of auxiliary tasks, reducing the data requirement for the main task. We formulate the weighted likelihood function of the auxiliary tasks as a surrogate prior for the main task. By minimizing the divergence between the surrogate prior and the true prior of the main task, we obtain a more accurate prior estimation, minimizing the amount of training data needed for the main task. Our algorithm proves effective in various experimental settings and outperforms previous task reweighting methods, even with limited labeled data. In extreme cases, such as few-shot domain adaptation, our algorithm shows significant improvement over the baseline. Our code and video demonstration are available at https://sites.google.com/view/auxiliary-task-reweighting.