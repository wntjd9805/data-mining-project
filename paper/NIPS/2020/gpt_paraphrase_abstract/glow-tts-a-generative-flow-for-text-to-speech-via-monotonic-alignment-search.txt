We present Glow-TTS, a novel flow-based generative model for text-to-speech (TTS) that eliminates the need for external aligners. Unlike previous parallel TTS models, Glow-TTS can be trained independently without guidance from autoregressive TTS models. By utilizing flows and dynamic programming, our model autonomously finds the most likely monotonic alignment between text and the latent speech representation. This approach ensures robust TTS performance, even for longer utterances, while also enabling fast, diverse, and controllable speech synthesis. In fact, Glow-TTS achieves a significant speed improvement compared to the autoregressive model, Tacotron 2, without compromising speech quality. Moreover, we demonstrate that our model can be easily extended to a multi-speaker scenario.