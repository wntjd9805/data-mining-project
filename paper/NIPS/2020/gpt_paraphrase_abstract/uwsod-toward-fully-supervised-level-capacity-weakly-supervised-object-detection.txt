This paper introduces a novel framework for weakly supervised object detection (WSOD) called UWSOD. WSOD is a technique that uses image-level annotations instead of bounding box annotations for training object detectors. However, WSOD methods still have lower performance compared to fully supervised object detection (FSOD) methods. The proposed UWSOD framework aims to address this limitation by incorporating three important components: object proposal generation, bounding box fine-tuning, and scale-invariant features.First, the authors propose an anchor-based self-supervised proposal generator that predicts object locations. This generator is trained end-to-end with supervision provided by UWSOD for objectness classification and regression. This approach helps generate high-quality bounding box proposals.Second, a step-wise bounding box fine-tuning technique is developed to refine the detection scores and coordinates. This process progressively selects high-confidence object proposals as positive samples, improving the quality of predicted bounding boxes.Third, a multi-rate resampling pyramid is constructed to aggregate contextual information at different scales. This feature hierarchy is the first in-network approach to handle scale variation in WSOD.Extensive experiments on PASCAL VOC and MS COCO datasets demonstrate that UWSOD achieves competitive results compared to state-of-the-art WSOD methods. Importantly, UWSOD does not require external modules or additional supervision. Furthermore, the upper-bound performance of UWSOD approaches that of Faster R-CNN, a fully supervised object detection model with class-agnostic ground-truth bounding boxes.Overall, UWSOD presents a unified framework for WSOD that achieves high-capacity object detection without the need for external modules or additional supervision. The proposed method shows promising results and outperforms existing WSOD techniques. The code for UWSOD is publicly available at https://github.com/shenyunhang/UWSOD.