There has been a recent surge of interest in disentangled representation learning, with a focus on optimizing various disentanglement metrics. The concept of "linear disentangled representation" was introduced through a mathematical framework that defined its characteristics. This framework showed that such representations depend on a specific decomposition of the symmetry group acting on the data, with actions being represented by irreducible group representations in independent subspaces. A model was proposed to induce and demonstrate linear disentangled representation in a VAE model. However, our empirical findings show that standard VAE models do not generally exhibit linear disentangled representations, and changing the loss landscape is necessary to induce them. We demonstrate that linear disentangled representations are desirable according to traditional disentanglement metrics. Additionally, we propose a method to induce irreducible representations without the need for labeled action sequences, as previous methods required. We explore the properties of this method, including its ability to learn from action sequences without knowledge of intermediate states and its robustness to visual noise. Furthermore, we show that it can successfully learn four independent symmetries directly from pixel data.