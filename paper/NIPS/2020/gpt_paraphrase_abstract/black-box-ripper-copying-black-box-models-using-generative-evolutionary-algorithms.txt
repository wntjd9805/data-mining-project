We investigate the challenge of replicating the functionality of black-box neural models, where we have limited knowledge of the model's inner workings and only have access to the output class probabilities for a set of input images. We assume that back-propagation through the black-box model is not possible and the training images used to train the model are not accessible. Our approach involves a teacher-student framework that distills the black-box model into a student model while minimizing accuracy loss. To generate effective training data for the student model, our framework (i) learns to generate images on a separate dataset that is different from the one used to train the black-box model, and (ii) employs an evolutionary strategy to ensure that each generated data sample produces a strong response for a specific class when fed into the black box. We compare our framework with various baseline and state-of-the-art methods on three benchmark datasets. Empirical results demonstrate that our model outperforms the considered baselines. Despite not being able to back-propagate through the black-box network, our method consistently surpasses state-of-the-art approaches that treat the teacher model as a transparent model. The code for our framework is available at: https://github.com/antoniobarbalau/black-box-ripper.