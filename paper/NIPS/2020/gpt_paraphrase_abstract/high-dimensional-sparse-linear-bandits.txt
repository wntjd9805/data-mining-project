Sparse linear bandits with high-dimensional features are commonly used in domains such as personalized medicine and online advertising. In this study, we establish a new lower bound for the regret of sparse linear bandits in scenarios where data is scarce, the horizon is smaller than the dimension, and the exploration distribution is well-conditioned. This lower bound is independent of the dimension and is determined to be Ω(n2/3). Additionally, we present an explore-then-commit algorithm that achieves an upper bound nearly matching the lower bound, confirming that Θ(n2/3) is the optimal rate in the data-poor regime. These findings complement existing bounds for the data-rich regime and highlight the importance of balancing information and regret. Lastly, we demonstrate an O(n) regret upper bound without dimension dependence, assuming a certain magnitude of the signal for relevant features.