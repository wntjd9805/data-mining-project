Neural architecture search (NAS) automates the exploration of design spaces to improve the efficiency of neural networks, particularly for on-device deployment. However, accurately obtaining performance metrics for models can be computationally expensive. Existing methods use proxies or layer-wise measurements to estimate hardware performance, but this imprecise prediction hinders the quality of NAS. To address this, we propose BRP-NAS, an efficient NAS that considers hardware and utilizes an accurate performance predictor based on graph convolutional network (GCN). Additionally, we enhance prediction quality by considering binary relations of models and employing an iterative data selection strategy. Our proposed method surpasses previous approaches on NAS-Bench-101 and NAS-Bench-201, and our predictor consistently learns valuable features from the DARTS search space, outperforming the second-order baseline. To emphasize the challenge of accurate latency estimation, we release LatBench, a latency dataset of NAS-Bench-201 models running on various devices.