The use of second-order information, such as Hessian- or Inverse-Hessian-vector products, is important for solving optimization problems. There has been recent interest in applying this information to deep neural networks, but little is known about the accuracy of existing approximations in this context. Our research addresses this issue, identifies problems with current approaches, and introduces a method called WoodFisher that accurately and efficiently estimates the inverse Hessian. We primarily focus on neural network compression using the Optimal Brain Damage/Surgeon framework. Our results show that WoodFisher outperforms other popular methods for one-shot pruning and even improves test accuracy compared to state-of-the-art approaches for iterative pruning. We also explore how our method can incorporate first-order information, set layer-wise pruning thresholds automatically, and handle compression with limited data. The code for WoodFisher is available at https://github.com/IST-DASLab/WoodFisher.