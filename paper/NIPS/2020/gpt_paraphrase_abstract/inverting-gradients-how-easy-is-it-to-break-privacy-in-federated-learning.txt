Federated learning involves training a neural network collaboratively on a server. Users receive the network's current weights and send parameter updates based on their local data. This approach aims to improve data efficiency and protect user privacy by keeping input data on devices and only sharing parameter gradients. However, the security of sharing parameter gradients has been questioned. Previous attacks have only succeeded in contrived scenarios, giving a false sense of security. Through the use of magnitude-invariant loss and optimization strategies, we demonstrate that it is indeed possible to accurately reconstruct high-resolution images from parameter gradients. This breach of privacy can occur even with trained deep networks. We analyze the impact of network architecture and parameters on the difficulty of image reconstruction and prove that any input to a fully connected layer can be reconstructed independently of the rest of the architecture. Additionally, we show that aggregating gradients over iterations or multiple images does not guarantee user privacy in federated learning applications.