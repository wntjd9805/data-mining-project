Imitation learning trains policies to mimic expert actions based on input observations. However, misattributing expert actions to irrelevant factors can be a challenge, especially when there is a shift in distribution. One common issue arises in partially observed settings where expert actions are highly correlated over time. In such cases, the imitator tends to cheat by predicting the previous action rather than the next one. To address this problem, we propose an adversarial approach that learns a feature representation eliminating the influence of the previous action while retaining the necessary information for predicting the next action. Our experiments demonstrate that this approach significantly enhances performance in various partially observed imitation learning tasks.