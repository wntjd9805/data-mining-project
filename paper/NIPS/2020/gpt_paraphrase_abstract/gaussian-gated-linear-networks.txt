We introduce the Gaussian Gated Linear Network (G-GLN), an expansion of the GLN deep neural network family. Instead of utilizing back-propagation for feature learning, GLNs employ a distributed and localized credit assignment mechanism that optimizes a convex objective. This approach offers various advantages such as universality, efficient online learning, easy interpretability, and resilience to catastrophic forgetting. By extending the GLN framework, we enable it to handle multiple regression and density modeling tasks through the adaptation of geometric mixing into a product of Gaussian densities. The G-GLN demonstrates competitive or state-of-the-art performance on various univariate and multivariate regression benchmarks. Additionally, we showcase its practical application in tasks like online contextual bandits and density estimation through denoising.