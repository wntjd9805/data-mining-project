This study addresses the need for fairness in machine learning classifiers, particularly in sensitive applications like job hiring and criminal justice. It introduces a kernel density estimation (KDE) methodology that respects fairness while maintaining a good balance between accuracy and fairness. The key advantage of this approach is that the fairness measure based on KDE can be differentiated with respect to model parameters, allowing for the use of gradient descent to solve optimization problems. The study focuses on classification tasks and two commonly used fairness measures: demographic parity and equalized odds. Experimental results demonstrate that the proposed algorithm performs as well as or better than previous fair classifiers in terms of accuracy, fairness, and training stability on both synthetic and benchmark datasets.