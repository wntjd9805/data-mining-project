State-of-the-art object recognition models, based on convolutional neural networks (CNNs), are easily fooled by small perturbations and struggle to recognize objects in corrupted images. By comparing with primate neural data, it was observed that CNN models with a hidden layer similar to primate primary visual cortex (V1) are more robust to adversarial attacks. Inspired by this, a new class of hybrid CNN vision models called VOneNets was developed. VOneNets consist of a fixed weight neural network front-end called VOneBlock, simulating primate V1, followed by a CNN back-end. VOneNets retain high ImageNet performance and are substantially more robust, outperforming base CNNs and state-of-the-art methods on a benchmark of adversarial attacks and image corruptions. The components of VOneBlock work together to improve robustness. Mimicking one stage of the primate visual system leads to new gains in ImageNet-level computer vision applications.