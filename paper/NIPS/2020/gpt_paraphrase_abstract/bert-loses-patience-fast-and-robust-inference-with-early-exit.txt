This paper introduces the concept of Patience-based Early Exit, a simple yet effective technique for enhancing the efficiency and reliability of a pretrained language model (PLM). The proposed method involves incorporating an internal classifier into each layer of the PLM and dynamically terminating the inference process when the intermediate predictions of these classifiers remain the same for a predetermined number of steps. By allowing the model to make predictions using fewer layers, our approach significantly improves inference efficiency. Moreover, experimental results conducted on an ALBERT model demonstrate that our method enhances the accuracy and robustness of the model by preventing excessive deliberation and leveraging multiple classifiers for prediction. As a result, our Patience-based Early Exit technique achieves a better balance between accuracy and speed compared to existing early exit methods.