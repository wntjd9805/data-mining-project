Developing AI systems to play MOBA games like Honor of Kings, League of Legends, and Dota 2 is challenging due to factors such as the complex action control, enormous state-action space, and multi-agent interactions. Existing AI approaches in this field struggle to handle the complexity caused by the many possible agent combinations, known as lineups, when expanding the hero pool. Consequently, no AI system has yet mastered playing full MOBA games without restrictions. To address this issue, this paper introduces a new MOBAAI learning paradigm that enables deep reinforcement learning for playing complete MOBA games. The proposed approach combines various learning techniques, including curriculum self-play learning, policy distillation, off-policy adaption, multi-head value estimation, and Monte-Carlo tree-search, to train AI agents on a large pool of heroes while effectively addressing scalability challenges. The effectiveness of the proposed AI is demonstrated through tests on the popular MOBA game Honor of Kings, where the AI agents outperform top esports players. This study represents the first large-scale performance evaluation of a MOBA AI agent in the existing literature.