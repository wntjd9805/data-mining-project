Probabilistic linear solvers are essential for addressing the challenges posed by machine learning in solving large-scale linear systems. These systems are characterized by their size, structure, randomness, and the importance of uncertainty. By combining previous research, we propose a new class of solvers that simultaneously infer the matrix, its inverse, and the solution based on observations of matrix-vector products. This class of solvers is derived from a set of fundamental requirements, which narrow down the possible algorithms and can recover the conjugate gradients method under specific circumstances. We also demonstrate how prior knowledge about the spectral properties of the matrix can be incorporated to accurately estimate uncertainty. Experimental results highlight the potential of these solvers in the context of machine learning.