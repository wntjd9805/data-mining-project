Linear relaxation based perturbation analysis (LiRPA) is a widely used method in verifying the robustness of neural networks by calculating linear bounds for output neurons under input perturbation. However, existing LiRPA-based methods are mostly designed for simple feed-forward networks and require manual derivations and implementations for other architectures. In this study, we propose an automatic framework that extends LiRPA algorithms to work on general computational graphs, thus enabling perturbation analysis on any neural network structure. Our framework offers flexibility, differentiability, and ease of use, allowing us to achieve state-of-the-art results in certifying the defense of complex networks like DenseNet, ResNeXt, and Transformer, which were previously not supported. Additionally, our framework introduces loss fusion, a technique that significantly reduces the computational complexity of LiRPA for certified defense. We demonstrate, for the first time, the application of LiRPA-based certified defense on Tiny ImageNet and Downscaled ImageNet, which were challenging due to their large number of classes. Moreover, we provide an open-source library that enables the broader application of LiRPA beyond adversarial robustness. For instance, we showcase the creation of a neural network with a provably flat optimization landscape by applying LiRPA to network parameters and considering perturbations on model weights. Our open-source library is available at https://github.com/KaidiXu/auto_LiRPA.