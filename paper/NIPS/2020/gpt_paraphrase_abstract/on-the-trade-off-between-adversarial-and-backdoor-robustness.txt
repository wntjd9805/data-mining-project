Research has shown that deep neural networks are vulnerable to adversarial attacks and backdoor attacks. While various defenses have been proposed against each type of attack individually, the relationship between the vulnerabilities to both types of attacks has not been thoroughly examined. This study conducts experiments to explore whether increasing a network's robustness against adversarial examples affects its vulnerability to backdoor attacks. The results reveal a trade-off, where enhancing adversarial robustness makes the network more susceptible to backdoor attacks. The cause behind this trade-off is investigated, and it is demonstrated how it can be exploited for both positive and negative purposes. These findings emphasize the need for future defense research to consider both adversarial and backdoor attacks in algorithm design and robustness measures to avoid false security and potential pitfalls.