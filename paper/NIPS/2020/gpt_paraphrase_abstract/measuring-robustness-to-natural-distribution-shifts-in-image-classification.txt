We examine the resilience of current ImageNet models to changes in data distribution caused by natural variations in datasets. Previous studies have primarily focused on the robustness of models to synthetic image perturbations, leaving a gap in understanding how well models can adapt to distribution shifts in real-world data. By evaluating 204 ImageNet models across 213 different test conditions, we discovered that there is limited transfer of robustness from synthetic to natural distribution shifts. Most existing techniques failed to provide robustness against natural distribution shifts in our experiments, except for training on larger and more diverse datasets, which showed some improvement but still fell short of closing performance gaps. Our findings highlight the need for further research on addressing distribution shifts in real data. We have made our testbed and data available as a resource for future studies at https://modestyachts.github.io/imagenet-testbed/.