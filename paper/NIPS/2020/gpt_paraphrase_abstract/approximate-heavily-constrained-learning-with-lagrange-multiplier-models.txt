In machine learning, optimization problems with a large number of constraints are common, especially in ranking fairness or fairness across different groups. These problems may even have a variable number of constraints, making the standard approach of using one Lagrange multiplier per constraint impractical. To address this, we propose using a feature vector for each constraint and learning a "multiplier model" that maps these vectors to the corresponding Lagrange multipliers. We provide guarantees for optimality, approximate feasibility, and generalization, assuming the flexibility of the multiplier model. Our method is demonstrated to be effective in real-world case studies.