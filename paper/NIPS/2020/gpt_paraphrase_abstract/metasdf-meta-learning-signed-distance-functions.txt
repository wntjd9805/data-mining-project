Neural implicit shape representations offer several advantages over traditional discrete representations, such as efficient memory usage and high spatial resolution. By learning priors over function spaces, these representations enable the reconstruction of geometry from incomplete or noisy observations. Current methods for generalizing across shapes using neural implicit representations involve conditioning a neural network on a low-dimensional latent code, which is obtained through regression or joint optimization. In this study, we approach the learning of shape spaces as a meta-learning problem and utilize gradient-based meta-learning algorithms to solve it. Our results show that this approach achieves comparable performance to auto-decoder based methods, but with significantly faster test-time inference. Additionally, our gradient-based method outperforms encoder-decoder based methods that use pooling-based set encoders.