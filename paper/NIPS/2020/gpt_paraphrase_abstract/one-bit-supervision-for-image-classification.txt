This paper introduces a new approach called one-bit supervision for learning from incomplete annotations in image classification. Instead of training a model using accurate labels, this approach requires the model to make a predicted label for each sample and learn from whether the guess is correct. This provides a binary (yes or no) information, making the annotation process easier compared to finding the accurate label from multiple candidate classes. There are two main challenges in training a model using one-bit supervision: improving the accuracy of the guesses and utilizing incorrect guesses. To address these challenges, the paper proposes a multi-stage training paradigm that incorporates negative label suppression into a semi-supervised learning algorithm. The proposed approach demonstrates higher efficiency in utilizing limited annotations in three popular image classification benchmarks. The answer format only outputs the abstraction.