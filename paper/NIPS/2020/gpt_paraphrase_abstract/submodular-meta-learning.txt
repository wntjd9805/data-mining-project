This paper introduces a new version of the Meta-learning framework that focuses on discrete tasks. Meta-learning is a technique that uses prior experience and data to improve performance on future tasks. While there are already several formulations for Meta-learning in the continuous domain, this paper proposes a novel framework for the discrete domain. In this framework, each task is treated as a maximization problem under a constraint. The goal is to train a proper initial solution set using prior data, so that it can be quickly adapted to new tasks with low computational cost. This approach provides personalized solutions for each task and reduces computational complexity compared to optimizing the solution from scratch for each new task. The paper presents deterministic and randomized algorithms for solving the challenging discrete optimization problem involved in training. Theoretical guarantees are provided for monotone and submodular tasks, even if the training objective may not be submodular. The effectiveness of the framework is demonstrated on two real-world problems, showing a significant reduction in computational complexity without a major loss in performance.