Graph neural networks have been successful in leveraging permutation equivariance and learning local structures to achieve good generalization. However, current architectures have limited representation power and struggle to learn basic graph properties. To address this, we propose a new message-passing framework that includes a one-hot encoding of nodes to learn a local context matrix. This matrix contains rich information about features and topology and can be pooled to build node representations. Additionally, we introduce methods for parametrizing message and update functions to ensure permutation equivariance. By having a representation independent of the one-hot encoding, our model can reason inductively and achieve better generalization. Experimental results show that our model outperforms previous methods in predicting graph properties and achieves state-of-the-art results in molecular graph regression on the ZINC dataset.