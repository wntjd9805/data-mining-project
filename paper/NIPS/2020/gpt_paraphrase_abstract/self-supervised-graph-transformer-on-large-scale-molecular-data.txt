Obtaining informative representations of molecules is crucial for AI-driven drug design. Current research uses Graph Neural Networks (GNNs) to represent molecules as graphs. However, GNNs face two challenges in real scenarios: a lack of labeled molecules for training and poor generalization to new molecules. To address these challenges, we propose GROVER, a framework that uses self-supervised tasks to learn structural and semantic information from unlabeled molecular data. GROVER integrates Message Passing Networks into a Transformer-style architecture to encode complex information. It can be trained efficiently on large-scale datasets without supervision, overcoming the aforementioned challenges. We pre-train GROVER on a massive dataset of 10 million unlabeled molecules, making it the largest GNN and training dataset in molecular representation learning. We then fine-tune GROVER for molecular property prediction and observe a significant improvement (over 6% on average) compared to current state-of-the-art methods on 11 challenging benchmarks. Our findings highlight the potential of well-designed self-supervision and expressive pre-trained models in boosting performance.