Many current advanced methods for reconstructing 3D objects from a single view rely on encoder-decoder architectures that produce shape parametrizations or implicit representations. However, these representations often fail to preserve the Euclidean structure of the objects in 3D space. This paper proposes a solution by introducing a 3-dimensional latent space that preserves the geometry of the objects, allowing the network to simultaneously learn global shape regularities and local reasoning in the object coordinate space. This approach significantly improves performance, as demonstrated on both synthetic ShapeNet images and real-world images, surpassing state-of-the-art methods. Furthermore, the single-view reconstruction pipeline can be easily extended to multi-view reconstruction.