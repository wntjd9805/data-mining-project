The problem of finding Nash equilibria in continuous games is important in machine learning for tasks like training GANs and robust models. Pure Nash equilibria have strict conditions that are often not met in practice, so mixed Nash equilibria are more commonly used. However, the existing method for finding mixed Nash equilibria, mirror descent, is not scalable in high dimensions. To overcome this, we propose a new approach that represents mixed strategies as mixtures of particles. These particles' positions and weights are updated using gradient descent-ascent. We analyze this approach as a gradient flow over measure spaces with the Wasserstein-Fisher-Rao metric. We prove that the related Langevin gradient-ascent dynamic globally converges to an approximate equilibrium. We also establish a law of large numbers that connects particle dynamics to mean-field dynamics. Our method effectively identifies mixed equilibria in high dimensions and has shown promise in training mixtures of GANs.