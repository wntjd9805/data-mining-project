A residual network can be seen as a discretization of an ordinary differential equation (ODE). Existing techniques for continuous formulations assume identical layers, but learning an infinite-dimensional parameter in a continuous-depth neural network poses significant challenges. To address this, we propose a shooting formulation that parameterizes optimal networks based on initial conditions instead of layer-by-layer. For scalability, we introduce a particle-ensemble parameterization that fully specifies the weight trajectory of the continuous-depth neural network. Experimental results demonstrate competitive performance using our particle-ensemble shooting formulation. Additionally, our approach can be applied to discrete-time networks and may open up new research opportunities in deep learning parameterization.