This study examines the impact of network architecture on the bias of deep classifiers. The authors focus on a simple task of classifying linearly separable distributions and find that some advanced convolutional neural networks struggle with this task depending on the direction of the discriminative feature. They introduce neural anisotropy directions (NADs) as vectors that represent the directional bias of an architecture and act as a signature for each network. The authors propose an efficient method to identify NADs for various CNN architectures and demonstrate that NADs determine the features used by CNNs to differentiate between classes in the CIFAR-10 dataset.