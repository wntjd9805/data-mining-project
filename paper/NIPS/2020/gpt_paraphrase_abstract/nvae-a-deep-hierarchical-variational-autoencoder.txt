Variational autoencoders (VAEs) are a popular framework for deep generative learning due to their fast sampling and easy access to encoding networks. However, they have been surpassed by other models like normalizing flows and autoregressive models. While most VAE research focuses on statistical challenges, we propose a new approach called Nouveau VAE (NVAE) that uses hierarchical architectures for image generation. NVAE utilizes depth-wise separable convolutions, batch normalization, and a residual parameterization of Normal distributions. It is trained with spectral regularization to improve stability. NVAE achieves state-of-the-art results on various datasets, including MNIST, CIFAR-10, CelebA 64, and CelebA HQ, and serves as a strong baseline for FFHQ. Notably, NVAE is the first successful VAE applied to large natural images of size 256Ã—256 pixels. The source code is available at https://github.com/NVlabs/NVAE.