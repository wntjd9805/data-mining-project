Despite achieving success in various vision-related problems, generative adversarial networks (GANs) often face performance issues, particularly in text generation, due to unstable training. To address this, we propose a novel training framework for variational GANs that ensures enhanced training stability. Our approach draws inspiration from the connection between GANs and reinforcement learning from a variational perspective. This connection yields two key components: (1) probability ratio clipping, which regulates generator training to prevent excessively large updates, and (2) a sample re-weighting mechanism that improves discriminator training by de-emphasizing low-quality fake samples. Furthermore, our variational GAN framework can effectively overcome the training problem encountered by many GANs where an optimal discriminator fails to provide informative gradients for training the generator. By integrating our training approach into various state-of-the-art GAN architectures, we achieve significantly improved performance across multiple tasks, including text generation, text style transfer, and image generation.