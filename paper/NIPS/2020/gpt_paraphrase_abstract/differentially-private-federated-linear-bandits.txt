This research focuses on the need for differentially-private cooperative learning in the rapidly expanding field of decentralized learning systems. Specifically, the study examines the contextual linear bandit problem, where a group of agents work together to solve a shared contextual bandit while maintaining privacy in their communication. The authors propose FEDUCB, a multiagent private algorithm for both centralized and decentralized federated learning. Through a technical analysis, they demonstrate the algorithm's effectiveness in terms of regret and improve upon existing results in cooperative bandit learning. Additionally, the authors provide rigorous privacy guarantees for their algorithm. Their approach achieves competitive performance in terms of pseudoregret bounds and is validated through empirical benchmark performance in various multi-agent scenarios.