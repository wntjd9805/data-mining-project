Off-policy policy evaluation (OPE) methods are used to estimate the performance of evaluation policies in sequential decision problems. However, these methods assume that decisions are solely based on observed features. In reality, there are often unobserved confounders, which are unrecorded variables that affect both decisions and outcomes. This study focuses on assessing the robustness of OPE methods when unobserved confounding is present. The researchers develop worst-case bounds to determine the performance of an evaluation policy under unobserved confounding. They find that even small amounts of per-decision confounding can heavily bias OPE methods when unobserved confounders can affect every decision in a sequence. However, in certain domains like healthcare, policy-making, and technology, unobserved confounders may only impact a single decision and influence future decisions through that initial one. Under this scenario, the researchers propose an efficient loss-minimization-based procedure to compute worst-case bounds and demonstrate its statistical consistency. The method is tested on simulated healthcare examples and shows that it can invalidate non-robust results and provide reliable measures of robustness, enabling the selection of policies under unobserved confounding.