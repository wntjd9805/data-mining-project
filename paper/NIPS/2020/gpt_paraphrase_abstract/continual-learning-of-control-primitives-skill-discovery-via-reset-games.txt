Reinforcement learning has the potential to automate complex behavior acquisition, but practical challenges must be addressed. One challenge is resetting the environment after task failure, which can be time-consuming in the real world. Another challenge is exploration, as random exploration is insufficient for acquiring complex behavior. This study introduces a method that allows an agent to acquire skills with minimal supervision and eliminates the need for resets. By learning a diverse set of "reset-skills," the agent can effectively handle different initial states. A general-sum game formulation is proposed to balance the objective of resetting and learning skills, resulting in improved performance on reset-free tasks. Furthermore, the acquired skills can significantly accelerate downstream learning.