This study introduces a novel challenge set for multimodal classification that focuses on identifying hate speech in multimodal memes. The dataset is designed in a way that unimodal models struggle, and only multimodal models can succeed. To make it challenging for unimodal models, difficult examples called "benign confounders" are included in the dataset, making it difficult to rely solely on unimodal signals. The task involves subtle reasoning and is evaluated as a binary classification problem. The study presents baseline performance results for unimodal models and various levels of sophistication for multimodal models. Interestingly, the findings reveal that current state-of-the-art methods perform poorly compared to human performance, highlighting the difficulty of this task and emphasizing the challenge it poses to the research community.