Continual learning agents face the challenge of retaining knowledge from previous tasks while adapting to new ones. We explore the merging of two recent continual learning approaches: meta-continual learning and continual-meta learning. However, both methods have limitations. In response, we propose a more comprehensive scenario called OSAKA, which requires agents to quickly solve new tasks while also facilitating fast memory recall. We demonstrate that existing techniques fail in this scenario. To address this, we introduce Continual-MAML, an online extension of the popular MAML algorithm, as a strong baseline. Through empirical study, we show that Continual-MAML outperforms standard continual learning and meta-learning approaches, making it better suited for the OSAKA scenario.