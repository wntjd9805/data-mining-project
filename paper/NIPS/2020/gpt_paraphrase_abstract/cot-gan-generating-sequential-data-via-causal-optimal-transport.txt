We propose COT-GAN, an adversarial algorithm for training implicit generative models that specialize in generating sequential data. The algorithm incorporates ideas from Causal Optimal Transport (COT) to formulate the loss function, combining traditional optimal transport methods with a temporal causality constraint. Surprisingly, this causality condition offers a natural framework for the discriminator to learn a robust distance as the cost function, allowing for the learning of time-dependent data distributions. Additionally, we include an entropic penalization term inspired by Genevay et al. (2018), enabling the use of the Sinkhorn algorithm for computing the optimal transport cost. Our experiments demonstrate the effectiveness and stability of COT-GAN in generating both low- and high-dimensional time series data. The algorithm's success is further supported by an enhanced version of the Sinkhorn divergence, which exhibits reduced bias in learning.