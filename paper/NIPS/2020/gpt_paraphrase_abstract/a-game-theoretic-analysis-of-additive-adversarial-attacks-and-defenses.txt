Adversarial learning research involves a constant back-and-forth between attackers and defenders, with new attacks being countered by new defenses. However, it is still unclear if there are situations where no better attacks or defenses can be developed. This paper introduces a game-theoretic framework to study attacks and defenses that exist in equilibrium. Using a locally linear decision boundary model, it is proven that the Fast Gradient Method attack and Randomized Smoothing defense form a Nash Equilibrium. The paper also demonstrates how this equilibrium defense can be approximated using a limited number of samples from a data-generating distribution, and provides a generalization bound for the performance of this approximation.