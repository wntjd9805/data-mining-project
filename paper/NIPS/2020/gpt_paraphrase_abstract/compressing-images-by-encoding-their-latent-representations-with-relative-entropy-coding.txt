Variational Autoencoders (VAEs) have been widely used for learned image compression. They enable the learning of meaningful latent representations that can be efficiently operated on by downstream compression techniques. A recent approach called 'bits-back' methods indirectly encodes the latent representation of images with a code length that is close to the relative entropy between the latent posterior and the prior. However, these methods are limited to lossless compression and are most effective when compressing multiple images together, making them inefficient for single image compression. To address this, we propose a new method called Relative EntropyCoding (REC) that directly encodes the latent representation with a code length close to the relative entropy, specifically for single images. Our empirical results on the Cifar10, ImageNet32, and Kodak datasets support the effectiveness of REC. Additionally, REC can be immediately applied to lossy compression and performs competitively with state-of-the-art methods on the Kodak dataset.