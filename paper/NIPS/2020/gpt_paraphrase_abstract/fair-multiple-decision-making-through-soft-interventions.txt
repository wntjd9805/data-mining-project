Current research on fair classification primarily focuses on a single decision model. However, in practical scenarios, there are often multiple decision models within a system, each potentially containing some form of discrimination. This introduces new challenges to achieving fairness in classification. Simply building decision models separately without considering the upstream models cannot guarantee fairness, as discrimination may be transmitted from upstream models to downstream models. In this study, we propose an approach that addresses this issue by simultaneously learning multiple classifiers and ensuring fairness for all of them. We treat each decision model as a soft intervention and infer the post-intervention distributions to formulate the loss function and fairness constraints. To smooth the loss function and constraints, we utilize surrogate functions. Theoretical analysis demonstrates that the excess risk of our proposed loss function can be bounded in a similar manner to traditional surrogate loss functions. Experimental results using both synthetic and real-world datasets validate the effectiveness of our approach.