This paper presents a unified theoretical framework for multi-class classification in AI applications where gold labels are missing or expensive. The framework focuses on learning from indirect supervision signals that have some mutual information with the gold label. The problem is determined by the transition probability from gold labels to the indirect supervision variables and the learner's prior knowledge about this transition. The framework relaxes assumptions made in previous studies and allows for learning with unknown, non-invertible, and instance-dependent transitions. The theory introduces a new concept called separation, which characterizes learnability and generalization bounds. The framework is applied to various learning scenarios, including learning with superset annotations and joint supervision signals.