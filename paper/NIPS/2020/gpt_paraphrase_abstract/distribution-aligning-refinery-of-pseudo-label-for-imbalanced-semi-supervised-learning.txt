Semi-supervised learning (SSL) is a useful approach for utilizing unlabeled data when labeled data is limited. However, current SSL algorithms assume balanced class distributions during training. This poses a problem when these algorithms are applied to imbalanced class distributions during testing, as they rely on biased pseudo-labels for majority classes. To address this issue, we propose a convex optimization problem to refine the pseudo-labels generated by a biased model. We introduce an iterative algorithm called DistributionAligning Refinery of Pseudo-label (DARP) to solve this problem effectively and efficiently. Through various experiments in class-imbalanced semi-supervised scenarios, we demonstrate the effectiveness of DARP and its compatibility with state-of-the-art SSL schemes.