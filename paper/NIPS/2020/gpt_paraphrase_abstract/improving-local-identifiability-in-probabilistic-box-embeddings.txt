Geometric embeddings have gained attention for their ability to represent asymmetric relations through containment. Box embeddings, which use hyperrectangles to represent objects, are a promising type of embedding due to their intersection closure and ease of volume calculation, making them suitable for representing calibrated probability distributions. However, geometric embeddings also face the challenge of local identifiability, where different parameter settings lead to the same loss, hindering the learning process. Previous approaches addressed this issue by approximating Gaussian convolution over the box parameters, but it resulted in increased sparsity of the gradient. In this study, we propose modeling the box parameters using min and maxGumbel distributions, which maintain closure under intersection. By considering all parameters in the calculation of the expected intersection volume, we experimentally demonstrate significant improvement in the learning ability of such models.