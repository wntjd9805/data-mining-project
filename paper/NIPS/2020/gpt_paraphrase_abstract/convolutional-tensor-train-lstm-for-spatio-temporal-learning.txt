Learning from spatio-temporal data has various practical uses, such as analyzing human behavior, tracking objects, compressing videos, and simulating physics. However, current methods are inadequate when it comes to challenging video tasks like long-term forecasting. The reason for this gap is that such tasks necessitate the understanding of long-term spatio-temporal relationships within the video sequence. To address this, we propose a more advanced model called the higher-order convolutional LSTM. This model efficiently learns these relationships by representing the history in a concise manner. Our model incorporates a novel tensor-train module, which combines convolutional features over time for prediction. To ensure computational and memory feasibility, we introduce a new convolutional tensor-train decomposition for the higher-order model. This decomposition reduces complexity by approximating a sequence of convolutional kernels using a low-rank tensor-train factorization. As a result, our model surpasses existing approaches while utilizing only a fraction of the parameters required by baseline models. We demonstrate state-of-the-art performance in various applications and datasets, including multi-step video prediction on the Moving-MNIST-2 and KTH action datasets, as well as early activity recognition on the Something-Something V2 dataset.