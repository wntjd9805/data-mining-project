We propose the Canonical 3D Deformer Map, a novel approach to representing the 3D shape of common objects using 2D images. By combining concepts from parametric deformation models, non-parametric 3D reconstruction, and canonical embeddings, our method learns to associate each image pixel with a canonical deformation model of the corresponding 3D object point. This allows us to reconstruct the 3D shape and texture of objects from single views, establish dense correspondences between object instances, and achieve state-of-the-art results in dense 3D reconstruction on public datasets of faces, cars, and birds. Our method requires only sparse 2D supervision during training.