Learning to represent complex scenes in terms of individual objects is a promising approach for efficient abstract reasoning. However, most deep learning methods fail to capture the compositional nature of natural scenes. This paper introduces the Slot Attention module, which interfaces with perceptual representations, such as those obtained from a convolutional neural network, and generates task-specific abstract representations called slots. These slots are flexible and can be assigned to any object in the input through a competitive process that occurs over multiple attention rounds. Through empirical experiments, we demonstrate that the Slot Attention module can extract object-centric representations that facilitate generalization to novel scene compositions, even when trained on unsupervised object discovery and supervised property prediction tasks.