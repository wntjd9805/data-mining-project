Discrete latent spaces in variational autoencoders have been proven effective in capturing the data distribution in various real-world applications, including natural language understanding, human intent prediction, and visual scene representation. However, the size of these discrete latent spaces needs to be sufficiently large to handle the complexities of real-world data, which poses computational challenges for downstream tasks. For example, performing motion planning in a high-dimensional latent representation of the environment can be impractical. This study addresses the problem of reducing the size of a trained conditional variational autoencoder's discrete latent space while preserving its ability to represent multiple modes. We propose a post hoc technique that employs evidential theory to identify the latent classes that directly receive evidence from a given input condition, filtering out those that do not. By applying this method, we demonstrate through experiments on various tasks, such as image generation and human behavior prediction, that our approach effectively reduces the sample space size of a model's discrete latent representation while still retaining its ability to represent multiple modes.