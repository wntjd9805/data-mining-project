We explore the problem of optimizing a nonsmooth Lipschitz continuous convex function over a convex constraint set using a (stochastic) first-order oracle (FO) for the function and a projection oracle (PO) for the constraint set. Previous research has shown that to achieve ε-suboptimality in high dimensions, Θ(ε^(-2)) FO calls are necessary. The projected subgradient method (PGD) achieves this, but it also requires O(ε^(-2)) PO calls, which can be computationally expensive. We propose the MOPES method, which combines Moreau-Yosida smoothing and accelerated first-order schemes, to improve the complexity of PO calls. This method only needs O(ε^(-1)) PO calls and the optimal O(ε^(-2)) FO calls to find a feasible ε-suboptimal solution. Additionally, if we only have a linear minimization oracle (LMO) to access the constraint set, our extended method, MOLES, finds a feasible ε-suboptimal solution using O(ε^(-2)) LMO calls and FO calls, matching known lower bounds. Our experiments demonstrate that these methods offer significant speedups compared to the state-of-the-art for problems with costly PO and LMO calls.