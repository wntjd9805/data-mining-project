Supervised deep learning in medical image analysis requires a large labeled dataset, which is often difficult to obtain. Self-supervised learning (SSL) offers a solution by pre-training a neural network with unlabeled data and then fine-tuning it with limited annotations. Contrastive learning is a powerful SSL technique for learning image-level representations. This study proposes strategies to extend the contrastive learning framework for segmenting volumetric medical images in a semi-supervised setting with limited annotations. It introduces novel contrasting strategies that leverage structural similarity across volumetric medical images and a local version of the contrastive loss to learn distinctive representations of local regions for per-pixel segmentation. The proposed method is evaluated on three MRI datasets and shows significant improvements compared to other SSL and semi-supervised learning techniques in the limited annotation setting. By combining the proposed method with a simple data augmentation technique, it achieves performance within 8% of the benchmark using only two labeled MRI volumes for training, which corresponds to just 4% of the training data used for the benchmark. The code for this method is publicly available at https://github.com/krishnabits001/domain_speciÔ¨Åc_cl.