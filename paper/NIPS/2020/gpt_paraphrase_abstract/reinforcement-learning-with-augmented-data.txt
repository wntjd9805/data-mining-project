Learning from visual observations is a difficult challenge in Reinforcement Learning (RL). While convolutional neural networks combined with algorithmic advancements have shown success, current methods still have limitations in terms of data efficiency and generalization to new environments. In this study, we introduce Reinforcement Learning with Augmented Data (RAD), a module that can enhance most RL algorithms. We conduct an extensive investigation of data augmentations for RL using both pixel-based and state-based inputs, and introduce two new augmentations - random translate and random amplitude scale. Our results demonstrate that augmentations such as random translate, crop, color jitter, patch cutout, random convolutions, and amplitude scale can improve the performance of simple RL algorithms, surpassing complex state-of-the-art methods on common benchmarks. RAD achieves state-of-the-art data efficiency and final performance on the DeepMind Control Suite benchmark for pixel-based control, as well as the OpenAI Gym benchmark for state-based control. Additionally, RAD significantly enhances test-time generalization on various OpenAI ProcGen benchmarks compared to existing methods. The RAD module and training code are publicly available at https://www.github.com/MishaLaskin/rad.