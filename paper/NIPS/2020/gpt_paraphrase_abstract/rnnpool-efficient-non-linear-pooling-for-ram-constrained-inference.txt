Standard Convolutional Neural Networks (CNNs) used in computer vision tasks often have large activation maps, requiring ample memory. This makes them unsuitable for resource-constrained devices used for edge inference. Downsampling techniques like pooling or strided convolutions can mitigate this issue, but they lead to a significant decrease in accuracy due to the excessive aggregation of the feature map. To address this problem, we propose RNNPool, a novel pooling operator based on Recurrent Neural Networks (RNNs). RNNPool efficiently aggregates features over large image patches and rapidly downsamples activation maps. Our empirical evaluation demonstrates that an RNNPool layer can effectively replace multiple blocks in various architectures, such as MobileNets and DenseNet, for image classification and face detection tasks. By using RNNPool, we can significantly reduce computational complexity and peak memory usage during inference while maintaining comparable accuracy. We demonstrate the effectiveness of RNNPool by integrating it into the standard S3FD architecture, achieving state-of-the-art mean average precision (MAP) for face detection on tiny ARM Cortex-M4 microcontrollers with less than 256 KB of RAM. The code for RNNPool is publicly available at https://github.com/Microsoft/EdgeML.