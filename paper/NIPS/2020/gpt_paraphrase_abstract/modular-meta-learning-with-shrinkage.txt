We propose a meta-learning approach for multi-speaker text-to-speech synthesis that eliminates the need for handcrafted task-specific architectures. Our approach utilizes Bayesian shrinkage to automatically discover and learn both task-specific and general reusable modules. Our empirical results demonstrate that our method outperforms existing meta-learning approaches in domains with limited task data and long adaptation horizons. We also show that popular meta-learning methods such as MAML, iMAML, and Reptile can be viewed as special cases of our approach.