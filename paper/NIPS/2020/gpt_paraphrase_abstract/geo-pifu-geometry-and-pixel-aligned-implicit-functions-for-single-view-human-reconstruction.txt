Geo-PIFu is a novel method proposed for recovering a 3D mesh from a color image of a clothed person. The approach utilizes a deep implicit function-based representation to learn latent voxel features, employing a structure-aware 3D U-Net. This allows the model to address feature ambiguities in query point encoding and serves as a coarse human shape proxy to regularize the high-resolution mesh and promote global shape regularity. The results demonstrate that Geo-PIFu outperforms competing methods in terms of reduced shape distortion and improved surface details in the reconstructed clothed human meshes. The evaluation is conducted on a large public dataset, surpassing the state of the art with a 42.7% reduction in Chamfer and Point-to-Surface Distances, as well as a 19.4% reduction in normal estimation errors.