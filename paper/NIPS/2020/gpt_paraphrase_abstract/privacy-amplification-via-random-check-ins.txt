Differentially Private Stochastic Gradient Descent (DP-SGD) is widely used for learning with sensitive data. Two common approaches, subsampling and shuffling, help reduce noise in DP-SGD. However, these approaches require uniform sampling or permutation, which can be challenging in decentralized or distributed settings. This paper focuses on conducting DP-SGD in federated learning, where data is distributed among multiple devices. The random check-in distributed protocol is introduced, which allows each client to make independent participation decisions without server-initiated communication or knowledge of population size. This is the first privacy amplification method tailored for distributed learning and may have broader applications. Additionally, the privacy guarantees of shuffling are improved, enabling similar privacy and utility with data from fewer users.