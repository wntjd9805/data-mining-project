One-stage detectors in object detection treat the task as dense classification and localization. They use Focal Loss for classification optimization and Dirac delta distribution for box location learning. Recently, one-stage detectors have introduced a separate branch for quality estimation to enhance detection performance. However, two problems have been identified: inconsistent usage of quality estimation and classification during training and inference, and the inflexible Dirac delta distribution for localization. To address these issues, this paper proposes new representations for these elements. The quality estimation is merged with the class prediction vector, and a vector is used to represent arbitrary distribution of box locations. These improved representations eliminate inconsistency and accurately capture the flexible distribution in real data. However, they involve continuous labels, which goes beyond the scope of Focal Loss. To tackle this, the paper introduces Generalized Focal Loss (GFL), which extends Focal Loss from discrete to continuous form for effective optimization. GFL achieves a 45.0% AP on COCO test-dev with ResNet-101 backbone, outperforming state-of-the-art SAPD (43.5%) and ATSS (43.6%) while maintaining comparable inference speed.