In recent years, statistical program learning based on neural models has emerged as an alternative to traditional rule-based systems for programming by example. Rule-based approaches offer unsupervised correctness guarantees by capturing logical rules, while neural models are more scalable to raw, high-dimensional input and can handle noisy I/O specifications. To combine the strengths of both approaches, we introduce PLANS (Program LeArning from Neurally inferred SpeciÔ¨Åcations), a hybrid model for program synthesis from visual observations. PLANS utilizes a neural architecture to extract abstract, high-level information from each raw input and a rule-based system to synthesize a program based on the extracted information as I/O specifications. To address the challenge of noise in the network's output, we propose a dynamic filtering algorithm for I/O specifications using selective classification techniques. Our approach achieves state-of-the-art performance in program synthesis from diverse demonstration videos in the Karel and ViZDoom environments, without requiring a ground-truth program for training.