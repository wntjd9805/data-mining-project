Federated Learning (FL) is a method where multiple devices collaborate to train a machine learning model while keeping the training data decentralized. Currently, the central model is refined by averaging the parameters of the server model and the updated parameters from the client side. However, this averaging is only possible if all models have the same structure and size, which can be limiting. In this study, we explore more powerful and flexible aggregation methods for FL. We propose ensemble distillation, which involves training the central classifier using unlabeled data from the outputs of client models. This knowledge distillation technique addresses privacy and cost concerns while allowing aggregation of heterogeneous client models that differ in size, precision, or structure. Through extensive experiments on various datasets and settings, including computer vision and natural language processing, we demonstrate that our approach significantly speeds up server model training. It requires fewer communication rounds compared to existing FL techniques.