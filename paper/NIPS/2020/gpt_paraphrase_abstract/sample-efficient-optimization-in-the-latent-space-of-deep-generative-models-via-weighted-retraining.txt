Existing machine learning techniques for optimizing expensive black-box objective functions over complex, high-dimensional input spaces lack sample efficiency. To address this, we propose an improved method that utilizes a deep generative model to learn a low-dimensional, continuous latent manifold. Unlike previous approaches, our method actively guides the generative model to maintain a useful latent manifold for efficient optimization. We achieve this by periodically retraining the generative model using queried data points along the optimization trajectory, weighting them based on their objective function value. This weighted retraining can easily be incorporated into existing methods and has been empirically demonstrated to significantly enhance efficiency and performance on both synthetic and real-world optimization problems.