Convolutional Neural Networks (CNNs) have achieved impressive results in computer vision tasks like image classification, detection, and segmentation. Recent studies have emphasized the importance of progressively increasing the difficulty of learning tasks in Generative Adversarial Networks (GANs). However, when training a network from scratch, the information propagated within the network at earlier stages can contain distortion artifacts due to noise, which can hinder training. In this paper, we propose a curriculum-based approach to address this issue. We suggest smoothing the feature embedding of a CNN using anti-aliasing or low-pass filters. Our method involves controlling the amount of high-frequency information propagated within the CNNs during training by convolving the output of each layer's feature map with a Gaussian kernel. By gradually reducing the variance of the Gaussian kernel, we increase the availability of high-frequency information for network inference. As the amount of information in the feature maps grows during training, the network progressively learns better representations of the data. Our proposed training scheme significantly enhances the performance of CNNs in various vision tasks without introducing additional trainable parameters or auxiliary regularization objectives. We demonstrate the effectiveness of our method through empirical performance improvements in CNN architectures across transfer learning, cross-task transfer learning, and generative models. Further details and the code can be found at www.github.com/pairlab/CBS.