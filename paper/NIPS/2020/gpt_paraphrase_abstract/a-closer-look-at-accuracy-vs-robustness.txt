Current techniques for training robust networks result in a decrease in test accuracy, suggesting a tradeoff between robustness and accuracy in deep learning. However, upon closer examination, we discover that real image datasets are actually separable. This leads us to the conclusion that both robustness and accuracy can be achieved for benchmark datasets using locally Lipschitz functions, implying that there is no inherent tradeoff between the two. Our experiments with robustness methods reveal that the gap between theory and practice stems from two limitations: either the methods fail to impose local Lipschitzness or they lack sufficient generalization. To address this, we investigate the combination of dropout with robust training methods, which yields improved generalization. In conclusion, achieving both robustness and accuracy in practice may necessitate the use of methods that enforce local Lipschitzness and augment them with deep learning generalization techniques.