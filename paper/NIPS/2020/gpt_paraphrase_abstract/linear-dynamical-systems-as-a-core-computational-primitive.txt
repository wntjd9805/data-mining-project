Running nonlinear recurrent neural networks (RNNs) for T steps requires a significant amount of time. However, our approach, LDStack, allows for approximate execution of these networks in parallel time of O(log T). By leveraging the concept of multiple-input, multiple-output (MIMO) linear dynamical systems (LDS), we demonstrate that nonlinear RNNs can be approximated by a stack of MIMO LDS, replacing temporal nonlinearity with depth-based nonlinearity. Additionally, we show that MIMO LDS can be further approximated by averaging or concatenating single-input, multiple-output (SIMO) LDS. Finally, we present an algorithm that enables the efficient execution and differentiation of SIMO LDS in O(log T) parallel time. In our experiments, LDStack achieves comparable accuracy to traditional RNNs while significantly reducing computation time. Furthermore, LDStack lends itself to analysis using linear systems theory, enhancing both speed and interpretability.