This paper explores Contextual Unsupervised Sequential Selection (USS), a new variation of the stochastic contextual bandits problem in which the loss of an arm cannot be deduced from observed feedback. The study focuses on a setup where arms have fixed costs and are ordered in a cascade. During each round, a context is presented, and the learner sequentially selects arms up to a certain depth. The total cost incurred by stopping at an arm includes the sum of fixed costs of the selected arms and the stochastic loss associated with each arm. The objective is to develop a decision rule that effectively maps contexts to arms, aiming to minimize the total expected loss. The problem is challenging due to the lack of supervision in estimating the total loss. However, learning becomes feasible when the optimal arm can be inferred from the problem structure, specifically when the problem instance satisfies the "Contextual Weak Dominance" (CWD) property. The paper proposes an algorithm for the contextual USS problem under CWD and demonstrates its sub-linear regret. The algorithm is validated through experiments conducted on both synthetic and real datasets.