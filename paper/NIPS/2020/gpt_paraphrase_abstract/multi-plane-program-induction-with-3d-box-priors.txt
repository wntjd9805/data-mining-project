We focus on two key aspects of image understanding and editing: representing regular patterns or textures in 2D planes and positioning these planes in a 3D scene. Unlike previous approaches, which assume a single visible 2D plane in the image, we introduce Box Program Induction (BPI). BPI infers a program-like representation of the scene that models repeated structures on multiple 2D planes, the position and orientation of these planes in 3D, and camera parameters, all from a single image. Our model assumes a box prior, meaning that the image captures either an inner or outer view of a 3D box. It utilizes neural networks to infer visual cues like vanishing points and wireframe lines, guiding a search-based algorithm to find the most suitable program to explain the image. This holistic, structured scene representation enables 3D-aware interactive image editing tasks such as inpainting missing pixels, adjusting camera parameters, and extrapolating image content.