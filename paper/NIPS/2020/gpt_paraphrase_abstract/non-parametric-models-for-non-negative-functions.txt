Linear models are widely used in various fields due to their effectiveness and flexibility. They are able to represent complex functions while maintaining convexity in optimization problems. However, linear models are not suitable for modeling non-negative functions, which are essential in unsupervised learning, density estimation, and non-parametric Bayesian methods. Existing state-of-the-art models either result in non-convex optimization problems or lack easy integration. This paper introduces a novel model for non-negative functions that possesses the desirable properties of linear models. The model is proven to have a representer theorem and an efficient dual formulation for convex problems. It is demonstrated that this model surpasses the representation power of generalized linear models. Additionally, the paper extends the model to functions with outputs in convex cones. Experimental evaluations confirm the effectiveness of the model in terms of formulation, algorithmic derivation, and practical results in density estimation, regression with heteroscedastic errors, and multiple quantile regression.