Traditional computer graphics techniques face challenges in achieving photo-realistic free-viewpoint rendering of real-world scenes due to the difficulty of capturing detailed appearance and geometry models. Recent studies have made progress by developing scene representations that encode both geometry and appearance without 3D supervision. However, existing approaches often produce blurry renderings due to limited network capacity or difficulties in accurately determining camera ray intersections with the scene geometry. Generating high-resolution images from these representations requires time-consuming optical ray marching. In this study, we propose Neural Sparse Voxel Fields (NSVF), a new neural scene representation that enables fast and high-quality free-viewpoint rendering. NSVF utilizes a set of voxel-bounded implicit fields organized in a sparse voxel octree to model local properties in each cell. We train the underlying voxel structures using a differentiable ray-marching operation with a set of posed RGB images. The sparse voxel octree structure allows for accelerated rendering of novel views by skipping irrelevant voxels. Our method is over 10 times faster than the state-of-the-art NeRF (Mildenhall et al., 2020) at inference time, while achieving superior quality results. Additionally, our explicit sparse voxel representation enables easy application to scene editing and composition. We demonstrate the effectiveness of our method in various challenging tasks, including multi-scene learning, free-viewpoint rendering of a moving human, and large-scale scene rendering.