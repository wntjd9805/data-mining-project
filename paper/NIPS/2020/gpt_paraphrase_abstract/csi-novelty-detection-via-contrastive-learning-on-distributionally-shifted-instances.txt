Reliable machine learning requires the ability to detect novelty, or determine if a given sample is outside the training distribution. Previous work has focused on learning representations and designing scores for novelty detection. This paper introduces a simple yet effective method called contrasting shifted instances (CSI), inspired by successful contrastive learning of visual representations. In addition to contrasting a sample with other instances, CSI also contrasts the sample with distributionally-shifted augmentations of itself. This approach leads to a new detection score specific to the proposed training scheme. Experimental results using various image benchmark datasets demonstrate the superiority of CSI in different novelty detection scenarios, including unlabeled one-class, unlabeled multi-class, and labeled multi-class settings. The code and pre-trained models for CSI are available at https://github.com/alinlab/CSI.