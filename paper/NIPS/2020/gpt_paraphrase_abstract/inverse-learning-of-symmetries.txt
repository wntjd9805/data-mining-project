We propose a model for learning symmetry transformations in complex domains, such as the chemical space, where invariances can be observed but not analytically formulated. Our model consists of two latent subspaces, with the first capturing the target and the second capturing the remaining invariant information. We use the deep information bottleneck with a continuous mutual information regularizer to learn the symmetry transformation. Unlike previous methods, we focus on minimizing mutual information in continuous domains. We calculate mutual information using correlation matrices and a bijective variable transformation. Our model outperforms state-of-the-art methods on artificial and molecular datasets, as demonstrated through extensive experiments.