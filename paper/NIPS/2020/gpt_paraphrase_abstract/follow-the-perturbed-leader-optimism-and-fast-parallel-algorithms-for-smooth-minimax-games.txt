We examine the problem of online learning and its application to solving minimax games. Follow the Perturbed Leader (FTPL) is a well-studied algorithm for online learning that provides optimal regret guarantees for convex and nonconvex losses. However, we propose a modification to FTPL that incorporates optimism and achieves even better regret guarantees for predictable sequences of loss functions, while still maintaining the optimal worst case regret guarantee for unpredictable sequences. The challenge lies in the stochastic and optimistic nature of the algorithm, which requires different analysis techniques than those typically used for FTPL. Our analysis is based on viewing perturbation as regularization. Although our algorithm has various applications, we specifically focus on minimax games. For smooth convex-concave games, our algorithm only needs access to a linear optimization oracle. For Lipschitz and smooth nonconvex-nonconcave games, our algorithm requires an optimization oracle that computes the perturbed best response. In both cases, our algorithm can solve the game with O accuracy using T calls to the optimization oracle. An important aspect of our algorithm is its high parallelizability, as it only requires O iterations with each iteration making O parallel calls to the optimization oracle.