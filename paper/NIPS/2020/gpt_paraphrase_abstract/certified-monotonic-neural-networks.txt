Learning monotonic models with respect to a subset of inputs is a desirable feature for addressing fairness, interpretability, and generalization issues. Current methods for learning monotonic neural networks are either too restrictive or complicated, or they cannot guarantee the learned model is monotonic on selected features. In this study, we propose a new approach to certify the monotonicity of general piece-wise linear neural networks by solving a mixed integer linear programming problem. This allows us to train neural networks with heuristic monotonicity regularizations and gradually increase the regularization magnitude until the learned network is certified monotonic. Our method does not require human-designed constraints on the weight space and provides more accurate results compared to prior works, such as Deep Lattice Networks. Empirical studies on various datasets demonstrate the efficiency of our approach.