Graph neural networks (GNNs) have been successful in learning graph representations. Most GNNs follow the aggregate-transform pattern, where they aggregate neighbors' attributes and transform the results with a learnable function. While these GNNs explain the differences between non-identical graphs, we still lack understanding of their similarity. To address this, we propose transform-sum-cat as an alternative to aggregate-transform, using kernel distance to reflect continuous similarity between node neighborhoods. This leads to a simple and efficient graph similarity measure called Weisfeiler-Leman similarity (WLS), which can be easily implemented with deep learning frameworks. In experiments, transform-sum-cat outperforms other neighborhood aggregation methods in graph classification, and we develop a fast GNN model based on it that achieves higher accuracy in node classification, lower absolute error in graph regression, and greater stability in adversarial training for graph generation.