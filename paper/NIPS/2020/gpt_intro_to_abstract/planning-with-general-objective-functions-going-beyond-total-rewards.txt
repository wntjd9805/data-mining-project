Markov decision processes (MDPs) have long been used as a model for sequential decision-making problems in computer science. However, the standard MDP model fails to capture certain types of decision-making tasks, such as those related to safety concerns or maximizing the minimum reward. In this paper, we propose a provably efficient algorithm for designing policies that optimize a wide range of objective functions. Our algorithm is able to handle objective functions that are symmetric, insensitive to small entries, and satisfy an approximate homogeneity condition. We provide examples of objective functions that meet these criteria, including symmetric norms and Lipschitz functions. Our algorithm is able to find near-optimal policies in tabular deterministic systems and has a polynomial-time complexity in certain cases. We also show that these three conditions are necessary for our algorithm to work effectively.