Bayesian optimization (BO) is a widely used technique for optimizing expensive-to-evaluate black-box functions in various domains. Existing acquisition policies for BO are typically one-step optimal and do not consider the long-term impact of exploration. This paper proposes a novel, scenario tree-based acquisition function for BO that performs multi-step lookahead and optimizes all decision variables in a one-shot fashion. The paper also introduces efficient methods for conditioning the Gaussian process (GP) model and parallelizing the implementation. Experimental results demonstrate significant improvements in optimization performance compared to one-step approaches. The paper presents the problem setting, the proposed approach, evaluation methods, and empirical results in subsequent sections.