Graphs are commonly used to model structured and relational data, such as social networks and the World Wide Web. The problem of semi-supervised learning on graphs, which aims to predict the categories of unlabeled nodes, has recently been tackled using graph neural networks (GNNs). However, GNNs suffer from issues such as over-smoothing and vulnerability to graph attacks. Additionally, standard training methods for GNNs can easily overfit scarce label information. Inspired by successful approaches in computer vision, this paper proposes the use of graph data augmentation and consistency regularization to address these issues. The proposed method, called GRAPH RANDOM NEURAL NETWORKS (GRAND), incorporates random propagation, which increases robustness by making nodes insensitive to specific neighborhoods, and separates feature propagation and transformation to reduce over-smoothing. Consistency regularization is used to improve generalization behavior, and empirical results demonstrate that GRAND achieves state-of-the-art semi-supervised learning results on benchmark datasets.