Realistic rendering in computer graphics is a complex task, especially when it comes to rendering real-world scenes from different viewpoints. Traditional approaches, such as image-based rendering, have limitations in terms of rendering quality and control over the results. To overcome these limitations, recent works have utilized deep neural networks to learn scene representations that combine geometry and appearance from 2D observations. However, existing approaches often result in blurry renderings and require time-consuming processes. In this paper, we propose Neural Sparse Voxel Fields (NSVF), a new implicit representation that allows for fast and high-quality free-viewpoint rendering. NSVF consists of a set of voxel-bounded implicit fields organized in a sparse voxel octree. Our method achieves superior rendering speed and quality compared to state-of-the-art approaches and can be used for tasks such as scene editing and compositing.