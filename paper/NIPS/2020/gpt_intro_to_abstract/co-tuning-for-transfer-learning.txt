The practice of fine-tuning pre-trained models, known as transfer learning, is prevalent in deep learning. This paper focuses on the challenge of transferring task-specific layers, which is hindered by the variation in categories between datasets. The authors propose a Co-Tuning framework that learns the relationship between source and target categories and translates target labels into probabilistic source labels for better transfer. The framework is empirically evaluated in multiple visual classification tasks, showing significant improvements over standard fine-tuning.