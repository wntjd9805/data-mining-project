Due to advancements in 3D sensing, there is a growing need for machine learning-based algorithms that analyze 3D imaging data. While this paper focuses on the application of these algorithms in medical imaging, their relevance to other 3D domains is also considered. Medical imaging plays a critical role in healthcare, but the expensive and time-consuming process of expert annotation hinders the utilization of machine learning algorithms. Additionally, the limited availability of data and annotations pose challenges for machine learning applications in medical imaging. Transfer learning has been used to overcome these challenges by reusing features from already trained neural networks, but the distribution differences between natural and medical images limit its effectiveness. As an alternative, self-supervised methods have proven successful in various domains and can provide cost-effective solutions for the challenges faced by supervised methods. However, the 3D nature of medical images has received little attention in self-supervised methods. Therefore, this work proposes five self-supervised tasks that leverage the full 3D spatial context for improved performance on downstream tasks. These tasks include 3D Contrastive Predictive Coding, 3D Rotation prediction, 3D Jigsaw puzzles, Relative 3D patch location, and 3D Exemplar networks. Extensive experiments are conducted to demonstrate the effectiveness of these tasks on different downstream tasks, ultimately leading to the publication of the task implementations for further evaluation by other researchers.