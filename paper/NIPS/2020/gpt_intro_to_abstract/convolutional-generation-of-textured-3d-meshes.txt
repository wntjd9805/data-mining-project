State-of-the-art image synthesis models based on the GAN framework have achieved impressive results in generating photo-realistic images. However, these models often ignore the concept of image formation, which limits their ability to control factors such as shape, color, pose, and lighting. Recent efforts have focused on disentangling factors of variation during the generation process, but these approaches have their limitations. In this work, we propose a GAN framework for generating triangle meshes and textures using 2D supervision from single-view natural images. We leverage recent advances in differentiable rendering and adopt a reconstruction framework to estimate meshes. Our model generates realistic meshes and can scale to high-resolution textures without requiring progressive growing. We showcase our approach under various settings and demonstrate conditional generation from text. We release our code and pretrained models for further exploration.