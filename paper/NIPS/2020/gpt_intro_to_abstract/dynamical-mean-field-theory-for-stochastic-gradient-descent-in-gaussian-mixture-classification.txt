Understanding how stochastic gradient descent (SGD) trains artificial neural networks with good generalization capabilities by exploring the high-dimensional non-convex loss landscape is a fundamental problem in machine learning theory. Despite some empirical evidence suggesting the existence of spurious local or global minima in the loss landscape, the stochastic gradient descent algorithm still achieves good generalization properties in practice. To explain this success, it is necessary to consider the entire trajectory of the algorithm, which remains a challenging task for state-of-the-art deep networks trained on real datasets.