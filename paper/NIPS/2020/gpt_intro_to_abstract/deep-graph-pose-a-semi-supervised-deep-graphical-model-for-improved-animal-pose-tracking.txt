Animal pose estimation (APE) plays a crucial role in understanding behavior in various fields such as ethology, psychology, and neuroscience. Recent advancements have adapted deep learning techniques from human pose estimation to APE, enabling new applications and scientific inquiries. However, the current methods still require significant user effort to label data and often encounter glitches in the tracking output. In this paper, we propose Deep Graph Pose (DGP), a probabilistic graphical model based on deep neural networks, to improve APE performance with sparse-labeled data. DGP leverages spatial and temporal constraints and utilizes labeled and unlabeled frames to achieve more accurate and robust tracking. We also demonstrate the enhanced performance of DGP in downstream applications, including unsupervised segmentation of behavioral "syllables" and estimation of low-dimensional representations of the entire behavioral video.