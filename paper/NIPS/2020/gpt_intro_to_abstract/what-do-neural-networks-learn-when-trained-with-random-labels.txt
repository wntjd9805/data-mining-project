Over-parameterization is beneficial for deep neural networks (DNNs) in real-life applications, despite their ability to fit random labels. This has led to research exploring the differences between real and random labels in terms of training time, sharpness of minima, layer embeddings, and sensitivity. However, it is not clear what DNNs learn when trained with random labels. This study aims to provide a partial answer to this question. Understanding DNN behavior under extreme conditions is essential for comprehending their functionality. Furthermore, analyzing DNNs trained with random labels can offer insights into critical stages, generalization in earlier layers, filter learning in the first layer, and the impact of pre-training. The paper presents experimental evidence and explanations for observed effects, demonstrates the alignment of network parameters with data, and investigates how specialization in later layers can overshadow the positive effects of pre-training. The alignment effect, previously unexplored in the literature, is proven to exist and has implications for both random and real label training.