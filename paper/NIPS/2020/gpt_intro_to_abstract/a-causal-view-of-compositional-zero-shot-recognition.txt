Compositional zero-shot recognition is the problem of recognizing new combinations of known components, which is a key aspect of human intelligence. However, current deep models struggle to generalize to new label compositions, leading to limitations in machine learning. This is due to distribution-shift inference and entanglement, where models learn correlations during training that hinder inference at test time. In this paper, we propose a new approach that models images as being generated by real-world entities, recognizing that the distribution of images is stable across train and test environments. We treat unseen combinations as generated by interventions on attribute and object labels, and propose a causal perspective for zero-shot inference. We also introduce a new embedding-based architecture that learns causally stable representations for compositional recognition. Experimental results demonstrate that our architecture outperforms previous methods in recognizing new unseen attribute-object compositions.