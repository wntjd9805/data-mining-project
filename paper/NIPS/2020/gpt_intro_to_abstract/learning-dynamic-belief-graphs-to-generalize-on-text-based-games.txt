Text-based games present a challenging environment for intelligent agents to communicate and interact with humans. Solving these games requires a combination of reinforcement learning and natural language processing techniques. However, challenges such as partial observability, long-term dependencies, sparse rewards, and combinatorial action spaces make these games very difficult. Previous approaches have relied on heuristics that exploit the game's structure, but this work aims to learn graph-structured state representations for text-based games in a data-driven manner. The proposed graph aided transformer agent (GATA) learns to construct and update graph-structured beliefs without heuristics, using self-supervised learning strategies. The agent is benchmarked on 500+ unique games and outperforms strong baselines, even in a partially observed setting. The results suggest that graph-structured representations are a useful inductive bias for learning and generalizing in text-based games.