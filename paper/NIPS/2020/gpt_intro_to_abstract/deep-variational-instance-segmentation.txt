In recent years, there has been significant progress in semantic segmentation, which involves classifying pixels into different object categories. However, to fully understand a scene, it is necessary to identify individual object instances along with their semantic labels, a task known as semantic instance segmentation. This task is particularly challenging due to similarities in appearance among instances of the same category, unknown instance numbers during prediction, and permutation-invariant labels. Traditional training objectives such as cross-entropy loss are not suitable for handling permutation-invariant instance labels. Existing approaches typically rely on two-stage methods combining detection and segmentation or search-based approaches that generate a large number of proposals. In this paper, we propose a deep variational instance segmentation (DVIS) approach, which directly predicts instance labels using a fully convolutional neural network (FCN). We introduce a novel variational objective that addresses the permutation-invariant nature of ground truth labels, allowing for end-to-end training. Compared to search-free instance segmentation methods, our approach achieves superior performance on the PASCAL VOC dataset and shows promising results on the MS-COCO dataset, with significantly faster speed.