This paper explores the question of how much early knowledge in infants can be learned by generic learning architectures without strong priors. The authors utilize self-supervised deep learning techniques and a longitudinal egocentric dataset of headcam videos to train models based on the visual experiences of developing children. The acquired visual representations are evaluated on their ability to distinguish common visual categories, demonstrating the emergence of powerful high-level visual representations from natural videos collected from a child's perspective. The results show high accuracy in visual categorization tasks, invariance to natural transformations, and generalization to unseen category exemplars.