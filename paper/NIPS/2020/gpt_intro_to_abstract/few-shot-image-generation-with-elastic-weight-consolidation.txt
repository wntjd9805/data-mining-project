This paper addresses the challenge of generating images in a low-data regime, such as in the artistic domain where hiring artists to create thousands of creations is impractical. The goal is to leverage prior experience and generalize from a few new examples. The authors propose a technique that adapts the pre-trained model's weights without introducing additional parameters, allowing for easy adaptation to new domains. The importance of each parameter is quantified, with an emphasis on preserving important parameters during the adaptation process. The authors demonstrate the effectiveness of their method in the artistic domain and evaluate it on various cross-domain source/target pairs.