This paper focuses on the problem of algorithmic fairness in machine learning algorithms. The goal is to ensure that sensitive information does not unfairly influence the outcomes of these algorithms. The authors study the problem of learning a regression function that complies with the fairness constraint of Demographic Parity while minimizing the mean squared error. They show that the distribution of the optimal fair predictor is the solution of a Wasserstein barycenter problem. The authors also propose a post-processing procedure that can transform any off-the-shelf estimator into a fair predictor. The paper presents numerical comparisons with the state-of-the-art methods and provides finite sample risk guarantees under certain assumptions.