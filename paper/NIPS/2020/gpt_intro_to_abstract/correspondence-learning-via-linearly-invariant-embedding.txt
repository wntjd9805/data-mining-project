Computing correspondences between geometric objects is a widely investigated task with numerous applications in various fields. Point cloud registration, especially in robotics, and the generalization of the problem to abstract domains like graphs are important areas of study. The non-rigid correspondence problem is particularly challenging due to shape deformations and input data noise. To address this problem, data-driven approaches have been proposed, including the functional map representation, which has been adapted for learning-based settings. These methods have shown success in obtaining accurate dense correspondences by learning optimal feature or descriptor functions. However, the current approaches are limited by a fixed functional basis tied to the Laplace-Belrtami eigen-basis, which is inadequate for handling diverse deformations and significant data noise. Inspired by these techniques, we introduce a fully-differentiable functional maps pipeline that learns both the probe functions and functional basis from data. Our approach formulates basis learning as computing an embedding into a higher-dimensional space, where non-rigid deformation becomes a linear transformation. We observe that learning a linearly-invariant embedding helps to regularize the learning process and improve performance. We demonstrate the effectiveness of our formulation in achieving accurate dense maps.