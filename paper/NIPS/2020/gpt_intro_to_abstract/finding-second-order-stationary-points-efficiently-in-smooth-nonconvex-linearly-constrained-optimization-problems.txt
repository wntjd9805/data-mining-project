This paper addresses a class of non-convex linearly constrained optimization problems that have applications in machine learning and data science. The paper aims to identify situations where finding a second-order stationary point (SOSP) for these problems is easy and to design efficient algorithms for this task. The paper highlights the challenges of extending existing algorithms that escape strict saddle points to problems with constraints or non-smooth regularizers.