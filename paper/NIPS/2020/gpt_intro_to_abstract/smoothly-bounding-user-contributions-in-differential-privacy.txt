The notion of Differential Privacy, introduced by [DMNS06], aims to capture the requirement that the output of an algorithm should not reveal much about the information provided by a single user. In many applications of differential privacy, a single user might contribute more than one data point. Most importantly, when a user contributes many data points, the algorithm designer must balance between the value of the information contained in these data points, and the added noise it will have to add to the output to make it private with respect to this user. This paper focuses on the problem of user contribution in private machine learning and proposes a weighted averaging method to smoothly bound user contributions. The authors compare this method to the sample limiting approach and demonstrate that the weighted averaging algorithm has lower error. The paper also extends the weighted averaging algorithm to empirical risk minimization and linear regression with label privacy, providing theoretical proofs and empirical results to support the proposed methods.