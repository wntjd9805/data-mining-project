Segmentation of anatomical structures in medical images often suffers from high inter-reader variability, which affects the performance of supervised machine learning models. This issue is particularly prominent in the medical domain due to the scarcity of labeled data. Variability in lesion characteristics and anatomical differences across patients make accurate identification of multiple sclerosis (MS) lesions and brain tumor segmentation difficult even for experienced experts. Existing pre-processing techniques, such as majority vote and similarity-based aggregation, attempt to mitigate inter-reader variations but assume equal reliability among experts. In this paper, we propose an end-to-end supervised segmentation method that simultaneously estimates the reliability of multiple annotators and true segmentation labels using only noisy labels. Our method utilizes two coupled CNNs, one for estimating the true segmentation probabilities and the other for modeling individual annotator characteristics by estimating pixel-wise confusion matrices. Unlike existing methods, our approach disentangles the complex mappings from input images to annotator behaviors and true labels. We evaluate our method on both simulated and real-world medical imaging datasets, demonstrating consistent improvement in segmentation performance compared to widely adopted label-fusion methods and other baselines, especially under low label availability and high annotator disagreement.