This paper introduces a new approach to the problem of learning a probability distribution over sequences of discrete actions in machine learning. The objective requires integrating over all possible sequences, which is intractable, and existing approximations are needed. The paper proposes a method that replaces the integral with optimization of a noisy objective function, providing new perspectives and methods for these hard problems. The resulting algorithm estimates the same quantity as standard approaches up to one finite difference approximation. The paper provides a comprehensive analysis of the new algorithm from both theoretical and empirical perspectives, expanding the toolbox of techniques and domain knowledge for tackling this problem.