Estimating distances between probability distributions is a crucial aspect in machine learning and statistics. Optimal Transport (OT), a popular class of distance measures, calculates the minimum cost of transporting a source distribution to a target distribution using a transportation cost function. OT has various advantageous properties, including structure preservation and applicability to both discrete and continuous distributions. However, OT is sensitive to outliers, leading to poor estimation of distributional distances. To address this issue, we propose leveraging recent formulations of unbalanced optimal transport, which relax OT's marginal constraints. We derive a computationally efficient dual form for the unbalanced OT optimization that is suited for practical deep learning applications, such as generative modeling and domain adaptation. Our proposed robust OT measure effectively handles outliers and improves the performance of applications like robust Wasserstein GANs and synthetic to real adaptation.