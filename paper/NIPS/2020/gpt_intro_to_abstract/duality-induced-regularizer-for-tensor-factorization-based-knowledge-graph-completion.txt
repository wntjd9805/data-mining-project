Knowledge graphs are valuable resources for representing structured human knowledge, but they often suffer from the problem of incompleteness. To address this issue, knowledge graph completion (KGC) has gained significant attention, aiming to predict missing links between entities automatically. Two important categories of KGC models are distance based (DB) models and tensor factorization based (TFB) models. While DB models have difficulty in modeling complex relation patterns, TFB models can handle them better but suffer from overfitting. To tackle this, researchers have proposed various regularizers, with the DURA regularizer being a novel approach based on the observation of duality between tensor factorization based models and closely associated distance based models. This paper introduces DURA as a widely applicable regularizer that effectively preserves the expressiveness of tensor factorization based models, leading to consistent and significant improvements in knowledge graph completion tasks. Specifically, incorporating DURA with RESCAL, one of the first KGC models, yields comparable or even better performance than state-of-the-art methods on multiple benchmarks.