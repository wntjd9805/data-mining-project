Planning is a fundamental aspect of artificial intelligence (AI), particularly in the field of robotics. AI planning involves specifying an initial state, a goal state, and a set of operators that dictate how to move from one state to another. However, traditional AI planning faces challenges due to the sparsity of the reward function. In this paper, we propose a novel automated dynamic curriculum strategy that utilizes deep reinforcement learning (RL) to improve plan search performance. Our approach involves selecting batches of sub-tasks to feed to the planning system or RL agent using a multi-armed bandit strategy, allowing the system to focus on sub-tasks that bridge the complexity gap between the current knowledge and the next level of problem difficulty. We demonstrate the effectiveness of our approach using the Sokoban planning domain, showing significant improvements in solving previously unsolved planning instances.