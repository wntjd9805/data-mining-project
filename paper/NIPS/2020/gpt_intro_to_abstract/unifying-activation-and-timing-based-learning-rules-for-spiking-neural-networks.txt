Spiking neural networks (SNNs) are attractive for their computational efficiency and resemblance to biological neural networks. However, SNNs face challenges in accurate gradient computation due to the non-differentiability of the binary activation function. Previous approaches for training SNNs have relied on either employing parameters trained in non-spiking neural networks or adapting the characteristics of spiking neurons. In this paper, we propose a new learning method called activation- and timing-based learning rule (ANTLR) that combines both activation-based and timing-based methods for more precise gradient computation. Experimental results on spike-train matching and benchmark tasks demonstrate the effectiveness of our approach in achieving higher accuracy with fewer spikes in training.