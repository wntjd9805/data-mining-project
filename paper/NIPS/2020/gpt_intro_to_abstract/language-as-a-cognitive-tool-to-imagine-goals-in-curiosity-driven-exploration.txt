Building autonomous machines with open-ended skill repertoires has been a longstanding goal in Artificial Intelligence. Children's intrinsic motivation, driven by brain processes that seek novelty and learning progress, can provide inspiration for achieving this goal. Intrinsically Motivated Goal Exploration Processes (IMGEP) enable agents to pursue their own goals without external rewards, but representing goal spaces and achievement functions remains challenging. Language, as demonstrated by children, can generate out-of-distribution goals by leveraging compositionality. This paper introduces IMAGINE, a learning architecture that uses natural language interactions with a social partner to explore scenes and interact with objects. IMAGINE learns to represent goals and discovers new goals through its own exploration and episode-level NL descriptions. It then trains autonomously on these imagined goals using an internal goal-achievement function.