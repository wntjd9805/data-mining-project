In this paper, we address the gap between the performance of kernel regression using the neural tangent kernel (NTK) and real-world neural networks (NNs). We introduce the concept of local elasticity in training NNs, which suggests that the interaction between examples is heavily influenced by their labels. We argue that the label-agnostic NTK construction fails to incorporate this label information, leading to potential problems in practice. To overcome this limitation, we propose two label-aware NTKs (LANTKs) that capture the label dependence in NNs. Through experiments on CIFAR-10, we demonstrate that our LANTKs outperform their label-agnostic counterparts in terms of generalization ability and local elasticity.