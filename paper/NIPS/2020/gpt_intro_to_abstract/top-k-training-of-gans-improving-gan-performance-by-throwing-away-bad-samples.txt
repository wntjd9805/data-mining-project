Generative Adversarial Networks (GANs) have been widely used for various applications, but training them is challenging. Most research focuses on modifying the training procedure to improve the generator's learning process. Recent work suggests that using samples closer to the data-manifold for gradient computation can lead to more realistic outputs. However, this method is complex and computationally expensive. In this paper, we propose a simpler technique of zeroing out the gradients from the least realistic samples in the batch. We provide evidence that gradients from "bad" samples can point away from the true data manifold. We conduct experiments on different datasets and demonstrate that our proposed modification improves the performance of GANs for various variations.