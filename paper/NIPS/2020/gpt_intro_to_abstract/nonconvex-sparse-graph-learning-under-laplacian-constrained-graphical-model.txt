Gaussian graphical models (GGM) have been widely used in various fields such as finance, bioinformatics, and image analysis. In this paper, we focus on learning a sparse graph under the Laplacian constrained GGM, where the precision matrix obeys Laplacian structural constraints. We explore the limitations of the commonly used â„“1-norm in promoting sparsity in the penalized maximum likelihood estimation of Laplacian constrained precision matrices. We propose a nonconvex penalized maximum likelihood estimation method and analyze the optimization performance guarantees and the statistical error under the Laplacian constrained GGM. Experimental results on synthetic and real-world datasets demonstrate the effectiveness of our method.