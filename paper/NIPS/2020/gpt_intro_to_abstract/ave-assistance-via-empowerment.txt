In this paper, we address the challenge of training artificial agents to assist humans in tasks with unknown goals. Previous approaches rely on inferring the human's goal through goal inference, but this can be problematic when the human model is incorrect or when the set of candidate goals is incorrect. To overcome these challenges, we propose a new method called Assistance via Empowerment (AvE), which prioritizes agent actions that increase the human's controllability of the environment. We demonstrate through experiments that our method significantly improves the human's success rate, especially in scenarios with large or misspecified goal sets. Additionally, we propose a computationally efficient proxy metric for empowerment and validate its effectiveness in a user study. Our contributions include the formalization of human-agent assistance using the empowerment method, a comparison with goal inference approaches, and the development of an efficient proxy for empowerment in continuous domains.