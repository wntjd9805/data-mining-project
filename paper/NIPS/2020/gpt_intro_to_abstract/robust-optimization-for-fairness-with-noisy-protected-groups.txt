This paper addresses the problem of training binary classifiers with fairness constraints when only noisy labels for protected groups are available. The authors investigate the impact of satisfying fairness constraints for noisy groups on the true groups, and propose two robust optimization methodologies that satisfy fairness criteria for the true groups while minimizing a training objective. The first approach is based on distributionally robust optimization, while the second approach uses a robust re-weighting of data based on soft protected group assignments. The authors provide theoretical analysis and empirical results demonstrating the effectiveness of their proposed approaches.