This paper addresses the problem of reconstructing 3D human pose from single 2D images. While recent methods have shown impressive progress in this task, they often fail when dealing with heavily occluded images, producing implausible reconstructions. To overcome this limitation, the authors propose a multi-hypothesis framework that generates a set of possible reconstructions and introduce a hypothesis reprojection loss to ensure consistency with the observed image. They also introduce the n-quantized-best-of-M mechanism to allow for flexible output and incorporate a pose prior learned through normalizing flows. Experimental results demonstrate the effectiveness of the proposed approach, achieving state-of-the-art accuracy in monocular mesh recovery.