Neural architecture search (NAS) has gained significant interest in recent years for automatically designing specialized neural architectures. Many NAS techniques involve optimizing an objective function over a large set of neural architectures. Previous work on NAS has focused on using standard encodings, but recent studies have shown that different encodings can greatly impact the performance of NAS algorithms. In this paper, we provide a formal study on NAS encoding schemes, including theoretical analysis and experimental results. We define encodings as multi-functions from architectures to real-valued tensors and identify two main paradigms: adjacency matrix-based encodings and path-based encodings. We characterize the scalability of each encoding and evaluate their performance in various subroutines of NAS algorithms. Our results demonstrate that the choice of encoding is crucial and can significantly affect the final performance of NAS algorithms. We provide recommendations for the best encodings to use in different settings, offering valuable guidance for future research in NAS.