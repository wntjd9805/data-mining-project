Integral operation is crucial in various machine learning applications, such as kernel approximation, variational inference, generative modeling, and variational autoencoders. However, directly calculating integrals is often infeasible, leading researchers to seek approximations. One common approximation method is Monte Carlo sampling, which involves calculating the average of independently and identically distributed (i.i.d.) sampled integrand values. To further improve the approximation accuracy, Quasi-Monte Carlo (QMC) methods utilize low discrepancy point sets instead of i.i.d. sampled points. In this paper, we focus on rank-1 lattice rules, a special case of QMC methods, which require only one generating vector to construct the entire point set. Traditional approaches for obtaining the generating vector involve exhaustive computer searches, which can be time-consuming for high dimensions and large numbers of points. To address this limitation, we propose a closed-form rank-1 lattice rule that directly computes the generating vector without the need for a search process. Our method generates a more evenly spaced lattice by reducing the number of distinct pairwise distances, resulting in a more regular lattice structure. We evaluate our approach on benchmark test problems and the kernel approximation problem, demonstrating improved approximation accuracy compared to existing methods.