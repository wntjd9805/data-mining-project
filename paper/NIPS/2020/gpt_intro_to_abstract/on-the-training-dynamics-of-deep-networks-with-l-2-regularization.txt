This paper explores the role of L2 regularization in deep learning for over-parameterized networks. The authors investigate the early stopping performance of models and observe that the number of steps until maximum performance is proportional to the L2 parameter. They find that performance improves with decreasing L2 and becomes independent of L2 for small enough values. The authors propose a method to predict the optimal value of the L2 parameter and introduce AUTOL2, a dynamical schedule for the L2 parameter. The empirical observations are supported by theoretical analysis of the loss landscape and the gradient flow update equations. The findings contribute to a better understanding of L2 regularization in deep learning and may help bridge the gap between theoretical and practical results.