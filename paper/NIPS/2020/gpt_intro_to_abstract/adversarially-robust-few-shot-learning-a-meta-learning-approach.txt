This paper introduces a new approach called adversarial querying for enhancing the robustness of neural networks in few-shot learning scenarios. The proposed method exposes the network to adversarial attacks during the query step of meta-learning, resulting in a feature extractor that is robust even without adversarial training during fine-tuning. Experimental results demonstrate that adversarial querying outperforms other robustness techniques in terms of clean accuracy and adversarial robustness. The minimax problem formulation is presented, and comparisons are made with other methods such as adversarial fine-tuning and pre-processing defenses, highlighting the effectiveness of adversarial querying.