Convolutional neural networks (CNNs) have been dominant in object recognition, surpassing human performance in some benchmarks. However, these CNNs are easily fooled by imperceptibly small perturbations and exhibit a surprising failure to recognize objects in images corrupted with different noise patterns. This fragility to image perturbations has received attention in the machine learning community. To address this issue, researchers have incorporated biological constraints into CNNs to make them behave more like human vision, but no neurobiological prior has significantly improved CNN robustness. In this paper, the authors propose VOneNets, a new class of hybrid CNNs that simulate primate V1, the primary visual cortex, as the front-end, followed by a traditional CNN back-end. The VOneNets outperform standard ImageNet trained CNNs in explaining V1 responses and exhibit higher robustness to adversarial attacks and image corruptions. The authors dissect the VOneBlock, the front-end component, and identify specific aspects that contribute to its robustness. Training with stochasticity at the VOneBlock level leads to more robust representations in downstream layers. The code and model weights are available for further exploration.