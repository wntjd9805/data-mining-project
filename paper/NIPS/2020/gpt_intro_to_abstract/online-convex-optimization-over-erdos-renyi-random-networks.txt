The online convex optimization paradigm has emerged as a prominent solution for machine learning in scenarios where data is generated sequentially over time, such as online routing and spam filtering. Rather than attempting to model the dynamic data, an online convex optimization framework adapts decisions in response to incoming, unpredictable data. The goal is to minimize regret, measured by the difference between the cumulative loss of online decisions and the best decision chosen in hindsight. In distributed online convex optimization, nodes make local decisions and experience local losses that are unknown to other nodes. By effectively sharing information with neighboring nodes, the accumulated system-wide loss can be minimized and regret bounds comparable to centralized cases can be achieved. This paper focuses on studying online convex optimization over Erd˝os-Rényi graphs, which serve as a benchmark for online learning over practical networks. The regret bounds and communication complexity for different scenarios are established, demonstrating the scalability and performance of the proposed algorithms.