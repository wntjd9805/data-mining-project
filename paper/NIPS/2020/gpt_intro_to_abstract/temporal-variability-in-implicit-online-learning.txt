The online learning paradigm has seen significant progress in the last two decades, particularly in the field of time series analysis. In this setting, a learning agent interacts with an environment in a sequential game, aiming to minimize regret by choosing the best model from a convex set. The agent's performance is evaluated based on the cumulative sum of losses compared to a fixed choice. Much of the progress in this field is driven by the model of Online Linear Optimization (OLO), which linearizes convex loss functions using gradient approximation. However, there is a need for algorithms that update the model directly using the loss function. This paper presents a refined analysis of Implicit algorithms within the Online Mirror Descent (OMD) framework, highlighting their potential advantages over gradient-based approaches. The authors introduce AdaImplicit, an adaptive Implicit algorithm that achieves a regret of O(VT + 1) when loss functions vary slowly over time. The algorithm's optimality is proven, and empirical analysis on real-world datasets demonstrates its practical benefits for classification and regression tasks.