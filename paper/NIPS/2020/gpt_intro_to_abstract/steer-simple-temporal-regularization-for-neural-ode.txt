This paper introduces a regularization technique for Neural Ordinary Differential Equations (ODEs) to reduce the computational cost of training. The authors propose randomly perturbing the end time parameter during training, achieving comparable performance to unregularized models at a significantly lower computational cost. The technique is demonstrated on various tasks, including continuous normalizing flows, irregularly sampled time series, and image recognition, showing improved performance. Additionally, the regularization technique performs well on instances of Stiff ODEs, which are important to address as deep learning models mature.