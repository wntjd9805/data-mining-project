Recent advancements in semantic segmentation have been driven by deep networks that learn visual representations from large-scale datasets. Spatial pyramid pooling (SPP) and attention mechanisms have been widely used to incorporate contextual information for improved segmentation accuracy. However, these methods focus on modeling either spatial or category relationships between pixels, while object-level relationships are crucial for semantic segmentation. In this paper, we propose the Region Attention Network (RANet) that leverages object regions to construct regional context and enhance pixel representations. RANet features a Region Construction Block (RCB) and a Region Interaction Block (RIB) to analyze boundary and semantic score maps, compute region decision maps, and capture spatial and category relationships between object regions. Extensive evaluations demonstrate the effectiveness of RANet, outperforming state-of-the-art methods on challenging segmentation datasets.