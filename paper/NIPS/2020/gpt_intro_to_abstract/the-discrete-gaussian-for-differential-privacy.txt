Differential Privacy is a standard technique used to protect individuals' private information in algorithmic outputs. It involves adding random noise to the aggregated results of a function, often using Laplace or Gaussian distributions. However, representing and sampling from these continuous distributions is challenging on finite computers, leading to privacy vulnerabilities. This paper introduces the concept of discrete distributions, specifically the discrete Laplace and discrete Gaussian distributions, which provide the same level of privacy and utility as their continuous counterparts. The paper also presents a practical and efficient procedure for sampling from the discrete Gaussian distribution, addressing the limitations of continuous distributions.