Reinforcement Learning (RL) and Control models are used to study learning through interaction in reactive environments. Feedback or reward/penalty plays a crucial role in enabling learning in RL/control. However, different applications have different feedback to the learning agent, such as "bandit feedback" in game-playing. This paper focuses on learning in linear dynamical systems with bandit feedback, specifically in a non-stochastic control model. The goal is to minimize regret compared to a class of disturbance action controllers. The paper presents efficient algorithms for this problem, both for known and unknown linear dynamical systems, with guarantees on the regret. The techniques used involve convex relaxation and non-stochastic system identification with adversarial perturbations.