With the increasing use of large machine learning models and the need for avoiding overfitting and providing good generalization performance, Bayesian learning frameworks have become essential. However, exact analytical solutions or sampling from exact posteriors are often impractical, leading to the need for approximate Bayesian methods such as Markov Chain Monte Carlo (MCMC) sampling techniques. This paper focuses on Langevin dynamics, a specific class of MCMC methods, as a means to sample from the posterior distribution and perform Bayesian machine learning. The paper discusses the convergence properties of Langevin dynamics and its variants, as well as its application in nonconvex settings and the computational efficiency compared to optimization methods. The exploration of higher-order Langevin diffusion and other MCMC schemes is also touched upon.