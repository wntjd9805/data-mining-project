Synaptic plasticity, crucial for learning and memory, is typically described using plasticity rules. However, current experimental techniques do not allow for tracking synaptic quantities over time at the population level, making it difficult to fully understand the relationship between the function of a network and the underlying mechanisms that shape its structure. In this paper, we propose a meta-learning framework that aims to deduce plasticity rules from indirect but accessible measurements, such as network function or architecture. By leveraging recent advancements in behavioural neuroscience and connectomics, we demonstrate the feasibility of inferring plasticity rules in three different neural network models. We also acknowledge the limitations of our approach and discuss potential future directions.