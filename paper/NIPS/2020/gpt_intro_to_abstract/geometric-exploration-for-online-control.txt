This paper focuses on the online control of an unknown linear dynamical system with general convex costs, which is a fundamental problem in control theory. It also addresses the challenge of balancing exploration and exploitation in continuous spaces, which is a central challenge in reinforcement learning. The paper introduces a polynomial-time algorithm for the case of known cost function, achieving optimal regret dependence on the time-horizon. It also presents a novel exploration strategy based on convex geometry, expanding the algorithmic toolbox for balancing exploration and exploitation. The paper highlights the importance of considering general convex costs, as opposed to the classical linear quadratic regulator with convex quadratic costs. Prior work in the field is discussed, and the paper introduces new techniques such as geometric exploration, disturbance estimation, and robustness to adversarial noise.