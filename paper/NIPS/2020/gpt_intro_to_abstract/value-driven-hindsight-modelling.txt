This paper explores the limitations of model-free reinforcement learning in effectively optimizing policies by ignoring valuable observations that can explain the outcome of actions taken. The authors propose augmenting model-free methods with a lightweight model that focuses on predicting only the relevant aspects of future observations. They introduce a special value function that learns from hindsight features to better predict future outcomes and improve representation learning. Experimental results demonstrate the superiority of the proposed approach over existing model-free RL methods in a challenging association task. The addition of hindsight value functions significantly increases performance in Atari games.