Algorithmic tools are increasingly being used in various domains, such as health care, education, lending, criminal justice, and child welfare. These tools are not meant to replace human decision-making, but rather to simplify and inform decision makers by providing risk scores or other distilled information. However, a common challenge in developing valid prediction models is the lack of randomized trials, as the available data is based on historical decisions and outcomes. In this paper, we focus on the concept of runtime confounding, where relevant factors are captured in the data but cannot be used in the prediction model due to feasibility, desirability, or ethical reasons. We propose a procedure using doubly-robust techniques to address this problem and provide a comprehensive evaluation process to assess the performance of our approach.