Multi-objective optimization problems are prevalent in various fields, including economics and civil engineering. These types of problems also arise in agent-based machine learning algorithms, such as generative adversarial networks and imaginative agents. However, carrying out the optimization and assessing the optimality of a solution remains challenging. In multi-agent optimization, finding equilibria in strategy spaces is a common approach. Nash equilibria provide a limited notion of optimality, while mixed Nash equilibria offer a more general notion and exist in games with infinite-dimensional strategy spaces. Identifying these equilibria is difficult, and efficient algorithms for finding them do not exist without additional assumptions on losses. Recent progress has been made with mirror-descent algorithms, but there is still a need for further research. In this paper, we formulate continuous two-player zero-sum games as a multi-agent optimization problem and propose gradient descent-ascent dynamics with a transport term. We show that these dynamics lead to approximate mixed Nash equilibria and introduce a gradient ascent-descent dynamics that updates positions and weights of mixed strategies to converge to exact equilibria. We also provide mean-field consistency results on the discretization of these dynamics and demonstrate their effectiveness in finding equilibria on synthetic games and training mixtures of GANs on real data.