Federated or collaborative learning has gained attention in machine learning due to the increasing data requirements and privacy concerns. The idea of federated learning is to train a machine learning model using gradients instead of sharing the original data. This paper explores the privacy limitations of federated learning, showing that reconstruction of input data from gradient information is possible for deep architectures. The findings suggest that even deep networks are vulnerable to privacy attacks. The implications of these findings for practical scenarios are also discussed, highlighting the possibility of reconstructing multiple input images from their averaged gradients.