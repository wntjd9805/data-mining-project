Finding pixel-wise correspondences between pairs of images is a fundamental problem in computer vision. State-of-the-art approaches rely on feature correlation layers, which evaluate dense pair-wise similarities between deep representations of two images. However, these layers often struggle to disambiguate multiple similar regions in an image, leading to inaccurate matching confidences. In this paper, we propose a new dense matching module, called GOCor, that addresses this limitation by incorporating additional information and constraints from both the reference and query images. Our module is formulated as an internal optimization procedure that minimizes a customizable matching objective, allowing for the integration of explicit and learnable constraints. We demonstrate the effectiveness of GOCor through extensive experiments and show that it outperforms the feature correlation layer in terms of accuracy and robustness.