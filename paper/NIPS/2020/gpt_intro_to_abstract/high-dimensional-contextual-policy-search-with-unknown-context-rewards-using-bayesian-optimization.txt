This paper introduces the problem of contextual policy optimization with unknown context rewards and proposes new Gaussian process (GP) models to improve existing Bayesian optimization (BO) approaches. The authors conduct a simulation study to analyze the scalability of the models and examine factors such as the number and distribution of contexts, as well as aggregate rewards and fairness. They also present a real-world problem of optimizing a contextual adaptive bitrate (ABR) policy and demonstrate the effectiveness of their models compared to alternative approaches. The proposed contextual GP models are shown to be successful in various contextual policy optimization use cases, including mobile data retrieval, cache eviction, and video streaming applications. Replication materials and code are available for reproducibility purposes.