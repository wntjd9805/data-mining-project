This paper presents a neuro-symbolic framework for learning entire rule systems from limited examples. The authors propose a synthesis-based approach that combines neural program synthesis with symbolic rule checking. Instead of training a model to predict outputs given inputs, the model is trained to induce the explicit system of rules governing the behavior of previously seen examples. This rule system can then be used to predict the behavior of new examples. The authors demonstrate the effectiveness of their approach on various tasks, including interpreting artificial languages and learning to interpret number words in unseen languages.