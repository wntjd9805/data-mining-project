We aim to build autonomous algorithms that can infer two important structures for compositional scene understanding and editing from a single image: the regular, program-like texture or patterns in 2D planes and the 3D posing of these planes in the scene. Our framework, Box Program Induction (BPI), jointly segments the image into multiple planes and infers the repeated structure on each plane. To enable efficient inference, we propose to utilize mid-level and high-level visual cues to constrain the search space of candidate programs. Our experiments show that BPI can accurately infer the structure and camera parameters for both indoor and outdoor scenes, and enable users to make 3D-aware interactive edits to images.