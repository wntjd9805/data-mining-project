This paper presents a novel approach to semantic segmentation in the domain adaptation setting, aiming to accurately predict pixel-level labels in the target domain with only out-of-domain annotations. The key challenge lies in transferring knowledge from the source domain to the target domain. While previous methods have focused on minimizing the domain gap using adversarial training or self-training techniques, this work proposes exploiting pixel-wise similarities across domains. A cyclic cross-domain pixel association is established, where associated pixel pairs are drawn closer based on their features. The method achieves significant improvement in mean Intersection-over-Union (mIoU) compared to networks trained with source data only, and performs favorably against state-of-the-art methods on two benchmark datasets.