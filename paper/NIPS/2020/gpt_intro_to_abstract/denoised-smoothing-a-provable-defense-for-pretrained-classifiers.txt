Image classification using deep learning has achieved remarkable success, but it is also vulnerable to adversarial attacks. Many heuristic defenses have been proposed, but they often fail against more powerful adversaries. To address this issue, researchers have developed certified defenses that provide robustness guarantees, but these defenses typically require training a classifier specifically for robust performance, which is computationally expensive. In this paper, we propose a novel approach that generates a provably robust classifier from a pretrained model without any additional training or fine-tuning. Our approach, called denoised smoothing, applies a custom-trained denoiser to the pretrained classifier and uses randomized smoothing to create a smoothed classifier. We demonstrate the effectiveness of our method through extensive experiments on ImageNet and CIFAR-10, achieving improved certified accuracy under adversarial perturbations. Additionally, we show that our method can be applied to black-box vision APIs, making them provably robust.