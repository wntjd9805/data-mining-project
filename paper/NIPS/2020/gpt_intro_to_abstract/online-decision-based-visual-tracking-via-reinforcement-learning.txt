Visual tracking is a fundamental task in computer vision that aims to estimate the trajectory of an object in a sequence of images. Recent visual tracking algorithms have utilized deep networks, particularly Convolutional Neural Networks (CNNs), for extracting deep representations of scenes. Two dominant tracking schemes have emerged: a detection approach that distinguishes the foreground target from the background, and a template matching approach that learns a similarity function to find the best image patch matching the target. However, each of these approaches has limitations in handling certain types of scenes, such as occlusion or deformation. In this paper, we propose an ensemble framework called DTNet that makes an online decision to switch between the detection and template trackers for different scenes. We use a hierarchical reinforcement learning approach to intelligently select the tracker that captures the target better in the current frame. Additionally, we introduce a proposal-free detection tracker that eliminates the need for candidate bounding box proposals. Experimental results show that our method achieves state-of-the-art performance on multiple benchmarks.