The focus of this paper is on extracting interpretable and actionable latent trajectories from high-dimensional neural activity. The authors compare two classes of methods: those that learn the transition function of an underlying dynamical system, and those that model the statistics of the latent processes directly. They propose a new family of Gaussian process (GP) covariance functions that capture the notion of "dynamics," incorporating a measure of second-order non-reversibility. These non-reversible kernels are shown to yield better model fits than reversible ones for datasets originating from dynamical systems. The authors also introduce a variant of Gaussian process factor analysis called GPFADS, which allows demixing of dynamical processes from other latent distractors. The effectiveness of GPFADS is demonstrated through its application to population recordings in monkey primary motor cortex.