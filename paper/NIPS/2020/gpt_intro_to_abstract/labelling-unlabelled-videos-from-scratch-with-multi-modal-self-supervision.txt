The aim of this paper is to develop methods for clustering video datasets without manual supervision, reducing the need for manual labelling. While previous research has achieved good results in clustering images, progress in clustering videos has been more limited. In this paper, we propose a solution that combines self-supervised representation learning with off-the-shelf clustering algorithms, showing strong baselines for video clustering. However, we also explore the potential for simultaneous learning of clustering and representation. We introduce our method, SeLaVi, which improves upon existing approaches by considering the multi-modal nature of video data and accounting for the skewed distribution of semantic video labels. We also propose a new initialization scheme and the learning of multiple orthogonal clustering functions to cover a wider space of valid solutions. In experiments on four video datasets, we demonstrate that our method outperforms previous approaches in clustering performance and produces semantically meaningful clusters. Our contributions include benchmark results, strong clustering baselines, and a tailored algorithm for clustering multi-modal data.