This paper addresses the challenge of performing optimally in a range of tasks in Reinforcement Learning (RL) by using meta-learning. Meta-RL involves training an agent on a set of tasks to learn their common features and transfer knowledge to unseen tasks. However, existing meta-RL methods assume dense task sampling, which is computationally expensive. This paper proposes an Information-Theoretic Task Selection (ITTS) algorithm that filters the training tasks to identify a subset that is diverse and relevant. The results demonstrate that task selection improves the performance of meta-RL algorithms in various domains, including a real-world application in device control for micro grids.