This paper introduces the problem of acquiring high-quality data from private data providers in the field of machine learning and data science. The traditional approach of issuing payment for data acquisition is vulnerable to manipulation by data providers. The authors propose reward mechanisms that incentivize truthful reporting of datasets, even without access to a test dataset. These mechanisms ensure individual rationality and budget feasibility, and guarantee that truthfully reporting datasets is always an equilibrium. The paper builds upon recent developments in the peer prediction literature, extending the peer prediction method to the data acquisition setting. The authors provide explicit sensitivity guarantees for their mechanisms, which is a significant technical contribution.