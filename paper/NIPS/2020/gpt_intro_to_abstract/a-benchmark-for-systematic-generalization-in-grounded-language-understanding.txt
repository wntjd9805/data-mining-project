This paper introduces grounded SCAN (gSCAN), a new benchmark that focuses on rule-based generalization in natural language understanding. Unlike the original SCAN dataset, gSCAN grounds the meaning of linguistic commands in states of a grid world. This allows gSCAN to evaluate eight types of compositional generalization, including context-sensitivity and modification-based compositionality. The authors test a baseline multi-modal model and a recent method proposed for compositional generalization on eight different generalization splits. The results demonstrate the challenges of accounting for natural language generalization with standard neural models and highlight gSCAN as a benchmark for developing models with more human-like learning skills.