Generative Adversarial Networks (GAN) have revolutionized the field of data generation, particularly in the realm of image synthesis. However, the instability of GAN dynamics and issues such as overfitting have posed challenges in training these networks. Previous approaches have attempted to address these problems by adopting well-behaved objectives and regularization techniques. Additionally, conditioning class information for the generator and discriminator has been found to be crucial for realistic image generation. In this paper, we propose a new framework called Contrastive Generative Adversarial Networks (ContraGAN), which utilizes a conditional contrastive loss to consider both data-to-class and data-to-data relations. Our experimental results on various datasets demonstrate that ContraGAN outperforms state-of-the-art models in terms of Frechet Inception Distance (FID). We also show that ContraGAN can benefit from consistency regularization and provide implementations of twelve state-of-the-art GANs for fair comparison.