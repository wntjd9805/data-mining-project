The rising demand for digital content and the availability of high-quality digital cameras has led to the need for tools and algorithms to democratize content creation. This paper proposes Generative View Synthesis (GVS), which combines the advantages of existing techniques by generating RGB images from a single semantic map, allowing for new arbitrary viewpoints. The key insight is that semantic maps provide valuable information about a scene's structure, while RGB images can result in unclear edges due to texture. The paper argues that preserving semantic information and converting it to an MPI-based representation improves the quality and consistency of the generated images. Experimental analysis on multiple datasets demonstrates the effectiveness of the proposed approach.