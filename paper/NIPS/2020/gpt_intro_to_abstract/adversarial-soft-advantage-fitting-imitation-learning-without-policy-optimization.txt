Imitation Learning (IL) is a popular approach in the field of control problems where traditional Reinforcement Learning (RL) methods struggle. IL can be categorized into two branches: Behavioral Cloning and Inverse Reinforcement Learning. While Behavioral Cloning requires a large amount of expert data and struggles with generalization, Inverse Reinforcement Learning aims to reduce compounding error by learning a reward function. However, implementing IL algorithms has become more complex due to recent advances. This paper proposes a simplified AIL framework called Adversarial Soft Advantage Fitting (ASAF), which combines discriminator learning and policy learning simultaneously. The paper presents a novel algorithm (ASAF) that imitates expert demonstrations without any Reinforcement Learning step and demonstrates its superior performance compared to prevalent IL algorithms on various control tasks.