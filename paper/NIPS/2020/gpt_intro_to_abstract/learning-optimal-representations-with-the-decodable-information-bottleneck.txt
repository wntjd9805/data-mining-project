In supervised machine learning, the choice of data representation is fundamental to the accuracy of predictions. While traditional approaches use predetermined encodings, recent advancements have focused on learning representations. This paper aims to understand the characteristics of an optimal representation in terms of generalization and proposes the decodable information bottleneck (DIB) objective as a solution. The DIB objective ensures minimal sufficient representations for a given predictive family and allows for the learning of representations that improve downstream classifier performance. The paper presents theoretical proofs, experimental results, and correlations between neural network generalization and the minimality of hidden representations.