Data-driven optimization problems are prevalent in various domains, ranging from protein design to neural network architectures. These problems involve optimizing unknown score functions using datasets of input-score pairs, without direct access to the score function itself. This becomes particularly challenging when valid inputs are confined to a low-dimensional manifold within the space of all inputs. Existing methods for solving such problems often rely on derivative-free optimization but require active data collection, which can be expensive for complex real-world processes. In this work, we aim to develop a method that can effectively solve data-driven optimization problems by operating on high-dimensional inputs, utilizing offline static data, and learning with minimal active data collection. We formally define the problem and propose using model inversion networks (MINs) to learn the inverse function mapping values to corresponding inputs. Our experimental results demonstrate the effectiveness of MINs in high-dimensional input spaces and outperform prior methods in contextual bandit optimization from logged data.