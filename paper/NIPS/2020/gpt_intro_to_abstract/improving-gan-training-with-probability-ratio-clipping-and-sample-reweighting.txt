Generative adversarial networks (GANs) have achieved success in image and video synthesis, but their training process is often unstable and subject to disturbances. Efforts to improve training stability have been made, but the instability issue remains, especially in text generation. In this paper, we present a novel variational GAN training framework that addresses the training stability problem by introducing stabilization techniques. We use probability ratio clipping to stabilize the generator and sample re-weighting to stabilize the discriminator. We demonstrate the effectiveness of our approach through extensive experiments on various tasks. Our framework also overcomes the issue of an optimal discriminator not providing informative gradients for the generator. Overall, our approach provides significant improvement over existing methods in terms of stability and performance.