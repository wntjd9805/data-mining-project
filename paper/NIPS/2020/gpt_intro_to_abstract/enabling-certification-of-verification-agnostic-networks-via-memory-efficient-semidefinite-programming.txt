Applications of neural networks to safety-critical domains require ensuring that they behave as expected under all circumstances. One way to achieve this is by ensuring that neural networks conform to a list of specific specifications, such as safety constraints, prior knowledge, or stability considerations. However, evaluating whether a network satisfies a given specification is a challenging task, and existing techniques have shown limitations in terms of robustness and scalability. In this paper, we propose a new approach based on semidefinite programming (SDP) relaxation and first-order methods to efficiently verify neural network specifications. We demonstrate the effectiveness of our approach on various verification-agnostic networks, achieving significantly tighter bounds on robustness compared to existing techniques. Our solver offers a more scalable and accurate solution for verifying neural networks in safety-critical applications.