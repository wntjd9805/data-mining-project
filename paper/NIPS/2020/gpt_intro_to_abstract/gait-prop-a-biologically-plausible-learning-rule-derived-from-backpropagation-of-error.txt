This paper introduces the concept of Target Propagation (TP) as a novel approach to overcome the limitations of biologically implausible backpropagation (BP) in deep learning networks. TP replaces the loss function at the output layer with layer-wise, local target activities, and propagates output targets backwards through the network using learned inverses of the forward pass. The authors develop a theoretical framework to analyze the relationship between TP and BP weight update rules, showing that they have the same local optima in deep linear networks. They also demonstrate that TP can be linked to BP in non-linear networks by introducing incremental targets. This approach, called GAIT-prop, is shown to be biologically plausible and identical to BP under orthogonal weight matrices. The authors further explore connections to activity recirculation and equilibrium propagation, and propose a circuit mechanism for local, error-based learning using target neural activities.