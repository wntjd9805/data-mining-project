This paper investigates whether vanilla neural networks possess the mutual exclusivity bias, a cognitive bias observed in children that aids in efficient word learning. By examining the performance of these networks in machine translation and object recognition benchmarks, we aim to determine if mutual exclusivity is a beneficial assumption for an optimal learner. We also compare word learning in children and machines to shed light on the limitations of deep learning algorithms in terms of sample efficiency and flexibility. Ultimately, this study seeks to understand the presence and relevance of the mutual exclusivity bias in neural networks.