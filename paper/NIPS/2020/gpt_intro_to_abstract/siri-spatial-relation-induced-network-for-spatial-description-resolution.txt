Visual localization tasks aim to locate target positions based on language descriptions, and they have various downstream applications such as visual question answering, visual grounding, and spatial description resolution. However, the spatial description resolution (SDR) task, particularly in the context of panoramic images, presents unique challenges that have not been well addressed in previous work. These challenges include difficulties in advanced object detection for complicated entities, the need for long descriptions with multiple spatial relationship words, and the complexity of visual details in street views. To address these challenges, we propose a spatial relationship induced (SIRI) network that leverages a graph-based global reasoning network for modeling object correlations and a local spatial relationship guided distillation module for distilling visual features according to specific spatial relationship words. Our proposed solution achieves significantly better performance than existing methods and demonstrates its effectiveness on a new extended dataset.