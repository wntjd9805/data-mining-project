Graph neural networks have become popular for processing and analyzing graph-structured data. Message-passing neural networks (MPNNs) have been widely adopted due to their ability to efficiently exploit graph sparsity and learn relationships between nearby nodes. However, MPNNs have limited expressive power and struggle with tasks that require understanding of the graph structure. To address these challenges, this paper introduces structural message-passing (SMP), a new type of graph neural network that is more powerful than MPNNs while still preserving their inductive bias. SMP achieves this by manipulating node identifiers in a permutation equivariant way, allowing for better generalization. The paper evaluates SMP on various structural tasks and achieves state-of-the-art performance in chemistry applications, demonstrating the effectiveness of the approach. Overall, SMP overcomes the limitations of MPNNs while still retaining their locality bias.