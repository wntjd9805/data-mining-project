The paper introduces the concept of robustness to adversarial attacks in deep neural networks and the use of Distributionally Robust Optimization (DRO) to address this challenge. It discusses the choice of divergence function in DRO and presents an identity that relates distributional robustness to regularization with a penalty term. The paper also examines the application of DRO to Generative Adversarial Networks (GANs) and provides insights into the robustness of GANs with respect to divergence-based uncertainty sets. The main contributions of the paper are summarized in three theorems that establish the connection between distributional robustness, regularization, and GANs.