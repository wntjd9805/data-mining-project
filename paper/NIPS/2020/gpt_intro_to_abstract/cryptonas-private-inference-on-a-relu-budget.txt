User privacy has become a significant concern in recent times, leading to the exploration of private inference (PI) techniques using deep learning models. This paper focuses on highly-secure solutions for PI using cryptographic primitives, such as homomorphic encryption (HE) and secure multi-party computation (MPC). However, these solutions suffer from significant slowdown, making it challenging to achieve practical inference latency. While previous work has primarily focused on developing systems and security protocols, little effort has been made in finding network architectures suitable for PI. This paper introduces the concept of a ReLU budget, highlighting how ReLUs are the primary latency bottleneck in PI. To address this, the paper proposes two optimization techniques: ReLU reduction and ReLU balancing. These techniques effectively reduce the number of ReLUs in a model without compromising accuracy and scale the number of channels in the core network while keeping the number of ReLUs constant. The authors present their automated search methodology, CryptoNAS, which discovers models that maximize accuracy within a given ReLU budget. The resulting networks outperform previous work in terms of accuracy and latency savings.