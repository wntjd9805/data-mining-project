Machine-learning-based decisioning systems are increasingly being used in high-stakes situations that have a direct or indirect impact on society. However, these systems have been found to produce morally repugnant outcomes in certain cases, such as encoding biases in hiring algorithms, discriminatory advertising systems, biased recidivism risk assessment software, and healthcare resource allocation systems. This has led to a growing body of research focusing on defining, measuring, and mitigating fairness and bias concerns in machine learning. The existing literature on algorithmic fairness has primarily focused on supervised and online learning, but there is a need to explore fairness in unsupervised learning as well. In this paper, we address the issue of fairness in clustering, which is a fundamental unsupervised learning problem. We propose a novel model that considers both the metric graph and the colors associated with each vertex in order to find a fair clustering. Previous work in this area has mostly focused on demographic parity, but we relax the assumption of deterministic color assignments and instead consider a distribution over colors for each vertex. Our model has applications in various real-world scenarios, such as clustering news articles without any dominant political viewpoint and supervised learning with uncertain class labels. We define fair clustering as satisfying upper and lower bound constraints on color proportions in expectation, and our proposed model captures deterministic fair clustering as a special case. The paper presents an overview of related research and contributions, defines two novel clustering models in the presence of probabilistic membership, presents approximation algorithms with theoretical guarantees, discusses the "large cluster" setting, and verifies the proposed approaches on real-world datasets.