In this paper, we address the challenges of solving text-based games through reinforcement learning (RL). Existing agents for text-based games can be classified as rule-based or learning-based agents, but both have limitations in flexibility and adaptability. We propose a new method called Stacked Hierarchical Attention with Knowledge Graphs (SHA-KG) to enhance the reasoning capability of RL agents by exploiting knowledge graphs (KGs). Our method incorporates sub-graphs of the KGs and utilizes a stacked hierarchical attention module to build effective state representations from multi-modal inputs. We evaluate our method on various text-based benchmark games and achieve favorable results compared to state-of-the-art methods.