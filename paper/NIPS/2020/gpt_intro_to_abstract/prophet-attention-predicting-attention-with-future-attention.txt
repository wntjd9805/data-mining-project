This paper introduces the novel Prophet Attention, a method to address the issue of current attention models in image captioning that have a "deviated focus" and incorrectly ground words to image regions. The Prophet Attention calculates "ideal" attention weights based on future generated words and uses them to guide attention calculation based on already generated words. The proposed method is evaluated on benchmark datasets and outperforms baselines in terms of grounding and captioning performance. The paper also explores the use of Prophet Attention in other language generation tasks. Experimental results and related work are discussed, and the paper concludes with a summary of the approach.