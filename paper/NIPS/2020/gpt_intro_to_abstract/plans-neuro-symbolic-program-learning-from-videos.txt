The problem of automatically generating a program from given specifications has long been a challenge in artificial intelligence. The field of inductive program synthesis, also known as programming by example, focuses on specifications formed by examples of desired input-output behavior. While existing systems typically handle simple data types and elementary data structures, extending programming by example to more complex input domains is beneficial for real-world applications. Sun et al. (2018) introduced the task of program synthesis from diverse demonstration videos, where the input is raw visual data and the desired output is a program summarizing the agent's decision-making logic. This task is important for imitation learning, as programs may offer better generalization, require less data, and allow formal verification of safety properties. Inductive synthesis techniques can be categorized into symbolic or rule-based approaches and statistical learning methods. Rule-based approaches provide guarantees of correctness and better generalization but are computationally expensive and struggle with scalability. Statistical approaches address these issues but require large labeled datasets. In this paper, we present PLANS, a hybrid model that combines neural and rule-based techniques to leverage the strengths of both approaches. PLANS includes a neural architecture for inferring high-level descriptions from raw visual observations and a rule-based solver for synthesizing programs based on the inferred information. By using less supervision than previous methods, PLANS outperforms existing techniques. The model also incorporates an adaptive filtering algorithm to handle noise in the neural network's output. We evaluate PLANS on the Karel and ViZDoom benchmarks and demonstrate significant performance improvements compared to state-of-the-art neural architectures.