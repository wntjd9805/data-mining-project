The increased use of machine learning in sensitive domains has raised concerns about bias, discrimination, and lack of fairness. To address these concerns, the paradigm of learning fair representations has emerged as a promising approach. In this paper, we propose a method for enforcing individual fairness in the machine learning model. Our approach is based on recent advances in training models with logical constraints and proving their satisfaction. We identify a practical class of fairness definitions captured via declarative constraints and train an individually fair representation. We provide an end-to-end implementation of our method and experimentally evaluate its performance on various datasets and fairness constraints. Our results show a significant increase in certified individuals compared to standard representation learning.