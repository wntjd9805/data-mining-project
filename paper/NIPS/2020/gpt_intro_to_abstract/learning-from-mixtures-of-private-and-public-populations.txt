Despite significant progress in privacy-preserving machine learning using differential privacy (DP), the current state of the art has limitations. Most existing works assume that the entire input dataset is sensitive and requires DP protection, which limits the feasibility of learning certain classes of functions. Recent works have explored a more relaxed model where the dataset consists of a private sample and a public sample, but still assumes that both samples come from the same population. In this paper, we introduce a new model called Private-Public Mixture (PPM) learners, where the algorithm has access to a mixed dataset of private and public examples from possibly different distributions. We demonstrate the applicability of this model by proving the first non-trivial result for learning halfspaces in this context. Our construction utilizes public examples to define a family of halfspaces and employs Helly's Theorem to find a collection of at most d halfspaces that can be used to reduce the learning task to DP learning of a finite class. We show that our bounds for learning halfspaces using the PPM model are comparable to non-private sample complexity and leave the possibility of improving these bounds for future research.