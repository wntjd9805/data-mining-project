Learning latent representations for registered meshes is crucial for various 3D tasks such as compression, reconstruction, animation, and simulation. While traditional methods like principal component analysis (PCA) and manually defined blendshapes have been used, recent approaches are inclined towards deep learning models. However, convolutional neural networks (CNNs) designed for regular grids cannot be directly applied to mesh data due to irregular sampling and connections. Existing workarounds involve mapping the mesh data to a predefined UV space and training a 2D CNN, but suffer from parameterization distortion and limitations in general mesh data. To address these issues, this paper proposes a fully-convolutional autoencoder for arbitrary registered meshes, including tetrahedrons and non-manifold meshes. The autoencoder incorporates novel mesh convolution and (un)pooling operators, with a key feature being a spatially-varying convolution kernel for each vertex. Experimental results on the D-FAUST dataset demonstrate superior performance in compression, reconstruction, and semantic interpolation compared to state-of-the-art models. Furthermore, the proposed architecture allows for localized latent codes, enabling better artistic manipulation and localized interpolation.