In this paper, we propose an agent that learns to discover objects and learn their physical properties in a self-supervised manner, inspired by how humans learn about their world through observation and interaction. The agent must choose a location to interact with, determine the nature of the interaction, interpret the visual feedback, and iterate effectively to learn about objects and their attributes. We present a model that learns to locate objects, predict geometric extents, and relative masses solely through interaction with the environment, without any external supervision. We use a memory bank with prioritized sampling for training stability, and evaluate our agent in the AI2THOR environment. Experimental evaluations demonstrate promising results for both seen and unseen object categories.