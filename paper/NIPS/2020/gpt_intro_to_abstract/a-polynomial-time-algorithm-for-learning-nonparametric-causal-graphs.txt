Modern machine learning methods have proven to be effective in various applications, but their complexity often leads to obscure decisions and incorrect outcomes. In this paper, we focus on the problem of learning directed acyclic graphs (DAGs) from data in a nonparametric setting, without requiring linearity or faithfulness. We propose a model-free and nonparametric approach using plug-in estimators, such as kernel smoothers and neural networks. We provide explicit finite sample complexity bounds and show that our method has polynomial time complexity. Our analysis is the first to provide simultaneous statistical and computational guarantees for learning nonparametric DAGs. We also compare our method with existing algorithms in a simulation study, demonstrating superior performance in various settings.