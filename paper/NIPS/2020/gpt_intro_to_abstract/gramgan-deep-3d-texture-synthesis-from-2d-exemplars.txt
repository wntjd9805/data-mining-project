Texture synthesis is a crucial area of research in computer vision and graphics, with applications in texture analysis, image manipulation, and photo-realistic rendering. Current synthesis techniques rely on real photos, which is time-consuming and requires expert knowledge. In this paper, we propose a novel texture synthesis framework that can generate high-quality 3D textures using an exemplar image as input. We classify existing techniques into photogrammetric and procedural approaches, highlighting their limitations. We then introduce our approach, which leverages deep learning and a multilayer perceptron to generate textures based on noise frequencies. We also propose a novel loss function and architectural framework to improve image quality and similarity to the exemplar texture. Our network architecture supports an extrapolation technique that enhances generalization to unseen textures. Our contributions include a deep MLP architecture, a GAN-inspired loss function, and an effective extrapolation strategy.