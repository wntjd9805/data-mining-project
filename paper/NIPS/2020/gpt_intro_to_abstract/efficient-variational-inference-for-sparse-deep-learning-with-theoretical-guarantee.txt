Dense neural networks (DNNs) have achieved great success in AI fields, but they suffer from problems such as storage and computation burdens. Compressing deep learning models is necessary for deployment on hardware-limited devices. Sparse neural networks, which recover sparsity structures, and Bayesian neural networks (BNNs), which offer robust prediction and uncertainty quantification, can address these issues. This work aims to resolve the challenges of sparse BNNs by using variational inference, reducing the computational problem and providing theoretical justifications. This is the first work to provide a comprehensive solution for sparse Bayesian DNNs.