This paper introduces a generic approach for domain-to-domain transfer of information between highly complex, off-the-shelf models. The proposed method does not alter or retrain the individual representations but retains the capabilities of the original models, allowing for efficient transfer between diverse domains. The authors employ a conditional invertible neural network (cINN) that captures transfer uncertainties and learns unique translations between domain representations. The approach achieves competitive text-to-image translation and enables content creation and model diagnostics. Importantly, the method is computationally affordable as it does not require gradient computations on the expert models.