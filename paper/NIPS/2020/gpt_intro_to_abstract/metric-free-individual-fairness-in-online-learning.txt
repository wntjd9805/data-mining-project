Machine learning algorithms are increasingly being used in various domains such as education, healthcare, criminal justice, and lending. This has led to a significant amount of research focused on making these algorithms fair. Most of the existing work approaches the problem from a statistical group fairness perspective, which aims to achieve parity across predefined groups based on protected attributes like race or gender. However, these approaches do not provide fairness guarantees at an individual level. In contrast, the individual fairness approach requires treating similar individuals similarly, but it often requires a task-specific fairness metric, which is rarely specified in practice. To address this limitation, this paper proposes metric-free online learning algorithms for individual fairness that rely on interactive human feedback. These algorithms minimize cumulative classification loss and the number of fairness violations without imposing strong assumptions on the similarity measure or fairness metric. The results of this study provide insights and solutions to several open questions in the field of individual fairness.