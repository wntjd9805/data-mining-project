Representation learning is a fundamental topic in machine learning that aims to discover meaningful and interpretable representations of data. In this paper, we address the challenge of learning disentangled representations by drawing a parallel between machine learning and physics. We propose a method for learning disentangled representations of dynamical environments by focusing on the structure of the symmetry group governing the environment's transformations. Our approach encodes observations as elements of a latent space and represents transformations as special orthogonal matrices. We also introduce a regularization technique to encourage the disentanglement of learned representations. Experimental results demonstrate the effectiveness of our method in learning the underlying structure of various explicitly symmetric environments.