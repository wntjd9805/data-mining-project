Spiking neural networks (SNNs) have garnered significant interest in the field of computer science due to their brain-inspired computational model and potential for energy-efficient processing. Despite recent advancements in SNNs and neuromorphic processor designs, fully exploiting the computing advantages of SNNs over traditional artificial neural networks (ANNs) remains challenging. Inspired by the success of error backpropagation (BP) in training deep neural networks (DNNs), various methods have emerged to train SNNs using BP. However, developing BP training methods for SNNs that match the performance of BP tools for ANNs is a nontrivial problem. This paper proposes a new SNNs BP method, called temporal spike sequence learning via BP (TSSL-BP), which aims to learn target output temporal spiking sequences. TSSL-BP addresses the challenges of complex neural dynamics, non-differentiability of spike events, and high computational latency by breaking down error backpropagation across inter-neuron and intra-neuron dependencies. The effectiveness and precision of TSSL-BP are demonstrated through improved accuracy and runtime efficiency on various image datasets.