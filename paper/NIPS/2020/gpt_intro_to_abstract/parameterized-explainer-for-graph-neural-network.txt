Graph Neural Networks (GNNs) have shown remarkable effectiveness in representing graph-structured data, but their predictions are not easily interpretable by humans. Existing approaches to explain deep neural networks are not suitable for explaining graph structures, which are crucial for GNNs. The first model-agnostic approach for GNNs, GNNExplainer, provides local interpretations for individual instances but lacks generalizability and efficiency. In this study, we propose PGExplainer, a method for explaining predictions made by GNNs on a set of instances collectively and inductively. PGExplainer utilizes a generative probabilistic model to uncover underlying structures and provide model-level explanations. Experimental results demonstrate that PGExplainer achieves consistent and accurate explanations, with significant improvement in AUC and speed-up compared to the state-of-the-art method.