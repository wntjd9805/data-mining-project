Traditional photo-editing tools are limited to manipulating existing pixels in an image. Machine learning offers the potential to incorporate visual knowledge from external datasets, enabling new editing operations. However, there is a conflict between the information gleaned from the dataset and the information retained from the input image. This conflict can be viewed as a disentanglement problem, where visual information specific to an image needs to be separated from information applicable across different images. In this work, we propose an unsupervised approach to discover a disentanglement suitable for image editing. Our method uses an autoencoder with two modular latent codes to capture within-image visual patterns and the remaining information. We enforce coherence among image patches with the same within-image code, resembling the definition of visual texture. We refer to these codes as texture and structure codes. We compare our method to unconditional and conditional GAN models, demonstrating the superiority of our approach for editing existing images. Our model is evaluated on multiple datasets and shows effectiveness in various downstream tasks.