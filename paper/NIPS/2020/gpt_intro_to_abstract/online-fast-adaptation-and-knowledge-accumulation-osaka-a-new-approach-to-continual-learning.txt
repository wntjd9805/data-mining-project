This paper explores the challenge of learning from non-i.i.d. data in supervised machine learning, specifically in the context of continual learning (CL). CL involves learning incrementally from a sequence of non-stationary data, while avoiding catastrophic forgetting of previously acquired knowledge. The authors draw inspiration from autonomous systems deployed in different environments and propose a task-incremental scenario where previous tasks reoccur and new tasks appear. The paper aims to measure the cumulative accuracy of models to evaluate their ability to adapt to new tasks and retain knowledge. This research has applications in various fields including robotics, autonomous driving, conversational agents, and time-series forecasting.