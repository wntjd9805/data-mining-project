In many machine learning applications, non-convex loss functions are optimized using simple descending algorithms like gradient descent. However, the theoretical justification for the good performance of these algorithms in the presence of non-convex landscapes remains a challenge. Recent research has focused on studying the geometrical properties of the loss landscape to distinguish between good and spurious minima. These studies have shown that under certain conditions, gradient descent converges to good minima. However, there are still many scenarios where both good and spurious minima coexist, but gradient descent still works effectively. This paper investigates learning with a single-layer neural network on data from the phase retrieval problem. The phase retrieval problem involves reconstructing a hidden vector using only the absolute values of its projections onto random directions. The paper explores the optimization problem associated with phase retrieval and proposes a gradient descent method to minimize the loss function. The authors also analyze the Hessian matrix of the problem to gain insights into its dynamics. Overall, this work contributes to the understanding of optimization in non-convex landscapes and its application in neural network learning.