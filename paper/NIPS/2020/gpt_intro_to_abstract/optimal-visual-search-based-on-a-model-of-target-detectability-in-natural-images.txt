Humans have a foveated visual system that receives higher spatial detail in the central visual field, resulting in target location uncertainty. Most models of human visual search and computer vision object detectors do not consider target detectability and cannot predict optimal eye movement sequences. This paper presents a novel approach for calculating the detectability of an object target in natural scenes, using signal detection theory and a logistic regression classifier. The approach takes into account both the uncertainty of the target position and the visual system's decreased performance in the periphery. The model is calibrated using human detection performance and compared to human search performance.