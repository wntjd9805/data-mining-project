This paper addresses the problem of learning to reconstruct 3D objects from 2D images, without access to 3D ground truth. The authors introduce the Canonical 3D Deformer Map (C3DM), a representation that combines parametric and non-parametric approaches to capture dense correspondences between different shapes. C3DM is able to reconstruct the shape of 3D objects from single images using only 2D supervision at training time. The authors extensively evaluate C3DM and compare it to a state-of-the-art method, showing that C3DM achieves higher 3D reconstruction accuracy and more realistic visual reconstruction on real-world datasets.