In this paper, the authors address the problem of nonsmooth convex optimization with First-order Oracle (FO) and Projection Oracle (PO). They introduce the MOreau Projection Efﬁcient Subgradient method (MOPES), which achieves an ε-suboptimal solution using O(ε−1) PO calls and optimal O(ε−2) FO calls. They also propose the MOLES algorithm for the Linear Minimization Oracle (LMO) setting, which achieves the optimal O(ε−2) LMO and FO calls without any additional dimension dependence. Both methods extend naturally to the Stochastic First-order Oracle (SFO) setting. The authors evaluate the performance of MOPES and MOLES on the nuclear norm constrained Matrix SVM problem and demonstrate significant speedups compared to baselines. Overall, their contributions provide improvements over existing methods in terms of PO/LMO and SFO calls complexities, making them valuable techniques for nonsmooth convex optimization problems.