Modern datasets are becoming increasingly large and are often stored and manipulated in a distributed manner. This decentralized setting, along with privacy concerns, has created a demand for efficient solvers that can train models locally at each agent while only sharing local parameter vectors. This approach has been adopted in various applications such as edge computing, cooperative multi-agent learning, and federated learning. However, achieving a consensus among all local agents with a model that performs as well as in the centralized setting becomes challenging due to the lack of global synchronization. Existing methods for decentralized optimization struggle to achieve accelerated rates in terms of the condition numbers of the objective function and the mixing matrix simultaneously. In this paper, we propose a novel primal approach using the accelerated augmented Lagrangian method that achieves optimal rates in terms of both condition numbers. We introduce a framework that unifies the convergence analysis of several existing decentralized algorithms and derive a new method for smooth and strongly convex local functions. Our theoretical findings are supported by extensive experiments.