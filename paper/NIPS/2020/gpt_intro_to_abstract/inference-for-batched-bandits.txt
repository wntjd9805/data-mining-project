Bandit algorithms have been widely used in real-world sequential decision-making problems. However, simply minimizing regret on a specific problem instance is often not enough. There is a need for statistical inference methods on bandit data to draw generalizable knowledge and inform decision making. In this paper, we focus on constructing confidence intervals for the margin—the difference in expected rewards of two bandit arms—from batched bandit data. We utilize asymptotic approximation methods to approximate the finite sample distribution of estimators and overcome the challenge of non-independence in bandit data. Our contributions include showing the dependence of the asymptotic normality of standard estimators on the margin value and introducing the Batched OLS (BOLS) estimator for reliable inference in non-stationary settings. BOLS is robust to non-stationarity in rewards and can be used for constructing valid confidence intervals even when the margin and baseline reward change over batches.