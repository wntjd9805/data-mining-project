Sampling from a target distribution is a fundamental task in machine learning. This paper focuses on the task of sampling from a distribution proportional to the exponential of a convex function in Euclidean space. The Langevin algorithm is commonly used for this task, producing iterates that are asymptotically distributed close to the target distribution. The algorithm performs gradient descent steps perturbed by a Gaussian vector. Nonasymptotic bounds have been established for the algorithm, and it has also been interpreted as an inexact gradient descent method for minimizing the Kullback-Leibler divergence. The function being minimized is often the sum of a smooth term and a nonsmooth term, which is the case in Bayesian statistics. The paper introduces the Proximal Stochastic Gradient Langevin Algorithm as a method that performs proximal stochastic gradient steps to efficiently minimize the function. However, when the nonsmooth term is not Lipschitz continuous, new approaches are needed.