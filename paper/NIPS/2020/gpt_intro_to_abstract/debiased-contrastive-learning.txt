Learning good representations without supervision has been a long-standing goal of machine learning. Self-supervised learning, which leverages auxiliary learning objectives that utilize observable labels without a human labeler, has shown promise in achieving this goal. Contrastive learning, a self-supervised representation learning approach, has recently out-performed supervised learning methods. However, a common issue in contrastive learning is sampling bias, where negative examples drawn from the training data may actually be similar to the positive examples. This bias can lead to a significant drop in performance. In this paper, we propose a new debiased contrastive objective that addresses this sampling bias. Our approach indirectly approximates the distribution of negative examples, resulting in improved performance over the state-of-the-art in vision, language, and reinforcement learning benchmarks. Theoretical analysis also demonstrates that optimizing the debiased contrastive loss corresponds to minimizing an upper bound on a supervised loss, leading to generalization guarantees. Overall, this work makes contributions in the form of a new debiased contrastive objective, experimental evaluations, and a theoretical analysis with generalization guarantees.