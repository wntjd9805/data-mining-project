Machine learning algorithms are being widely used for automated decision making, leading to increased concern about the ethical implications of these decisions. Researchers in algorithmic fairness have been developing tools to address these concerns. This paper focuses on the equalized odds criterion as a measure of fairness and presents a novel training scheme to approximate models that satisfy this criterion. The paper also introduces a hypothesis test to detect violations of the equalized odds criterion. Experimental results demonstrate improved performance compared to existing methods, particularly in regression and multi-class classification tasks, providing evidence for the effectiveness of the proposed approach.