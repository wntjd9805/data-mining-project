Data-driven algorithms have become pervasive in various aspects of our lives, from face recognition to recommender systems and machine translation. However, the use of predictive systems for making decisions that affect individuals, such as loan repayment or bail outcomes, can lead to accuracy disparities and discriminatory results. Two notions of fairness, individual fairness and group fairness, have been proposed to address these issues. In this paper, we focus on multicalibration criteria for group fairness, which requires that predicted values and average realized values are close for large subpopulations. We discuss previous work on finding multicalibrated predictors and deriving sample complexity, and propose new sample bounds for uniform convergence of predictor classes. Our approach emphasizes statistical generalization rather than algorithms, but it has implications for algorithmic decision-making. Our results improve upon previous sample complexity bounds and apply to more general settings, allowing for greater flexibility in optimization objectives and algorithms while still achieving accurate estimation of calibration error.