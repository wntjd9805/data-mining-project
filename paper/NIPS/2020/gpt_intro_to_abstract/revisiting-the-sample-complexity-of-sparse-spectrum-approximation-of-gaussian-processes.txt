In this paper, we address the scalability issue of Gaussian processes (GPs) in handling large datasets by proposing a new approximation scheme called sparse spectrum Gaussian processes (SSGP). We analyze the sample complexity and the impact on training and inference qualities of this approximation scheme. Additionally, we introduce a data partitioning algorithm that learns a cluster embedding for improved approximation quality. We provide empirical evidence of the computational efficiency and approximation quality of our proposed method compared to existing works.