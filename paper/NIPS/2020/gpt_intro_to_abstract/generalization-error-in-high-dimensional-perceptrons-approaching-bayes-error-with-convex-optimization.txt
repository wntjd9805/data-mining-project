In this paper, we investigate high-dimensional classification using convex linear estimation with data generated by a teacher perceptron. We focus on the generalization abilities of Bayes-optimal estimation compared to Empirical Risk Minimization (ERM), and analyze the limitations of standard generalization bounds in this simple yet non-trivial setting. The study is motivated by the need to understand the effectiveness of modern machine learning techniques and the limitations of classical statistical learning approaches. We present a thorough analysis of the synthetic data model and discuss the performance of different loss functions and regularization techniques. Our results contribute to the ongoing research in high-dimensional statistics and provide insights into the generalization performance of machine learning algorithms.