This paper introduces the concept of multimodal image fusion, the process of combining information from multiple imaging modalities, in order to exploit complementary information and relationships between modalities for downstream tasks. The paper presents a method called Contrastive Multimodal Image Representation for registration (CoMIR) that reduces the challenging task of multimodal registration to a simpler, monomodal one. The method learns representations called CoMIRs by maximizing Mutual Information Noise-Contrastive Estimation (InfoNCE) and produces dense representations for different imaging modalities that can be utilized for monomodal registration. The proposed CoMIRs possess the necessary equivariant properties to find a transformation between the original inputs. The contributions of the paper include demonstrating the effectiveness of contrastive learning for multimodal registration, showing the rotation equivariant properties of the proposed CoMIRs, and presenting a sophisticated scheme for generating training patches that requires minimal training data.