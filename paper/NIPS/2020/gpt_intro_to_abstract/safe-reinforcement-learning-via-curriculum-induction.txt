Safety is a major concern in the application of reinforcement learning (RL) to practical problems. The focus of RL safety notions is to ensure that the agent does not violate constraints, which is particularly important in scenarios like training a self-driving car's autopilot. Existing safe RL techniques make various assumptions about the environment, including access to accurate models or smoothness assumptions. In this paper, we propose a safe RL approach called Curriculum Induction for Safe Reinforcement learning (CISR), inspired by how humans help children learn safely. CISR involves an artificial teacher inducing a sequence of safety-ensuring training stages for an RL agent. Each stage is characterized by an intervention that ensures safety, such as the use of training wheels. The teacher's curriculum policy is optimized based on the learner's performance in order to gradually transition the learner to more challenging tasks.