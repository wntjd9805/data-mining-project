This paper introduces the concept of Hebbian Memory Networks (H-Mem) as a potential solution for complex memory tasks. The authors propose a network architecture inspired by cortical neuronal networks in the brain, where synapses are subject to Hebbian plasticity. They demonstrate that H-Mem can effectively store and retrieve associations, and outperform other memory models such as LSTM networks and memory-augmented neural networks. The results suggest that H-Mem has the potential to address the computational challenges of associative memory tasks.