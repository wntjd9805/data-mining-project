Recent advances in Generative Adversarial Networks (GANs) have made them popular for vision synthesis tasks like image and video generation, image editing, inpainting, and superresolution. However, generated outputs from GAN models can often be unrealistic. Current techniques for addressing this issue involve eliminating low-quality samples after the model is trained, but these methods are inefficient. In this paper, we propose dataset curation through instance selection as a solution. We demonstrate that removing low-density regions from the dataset prior to model optimization improves image sample quality, reduces model capacity requirements, and reduces training time. We evaluate different image embeddings and scoring functions, and show that Inceptionv3 and Gaussian likelihood are well-suited for their respective roles. Our contributions include proposing dataset curation, showing the predictive value of manifold density in the perceptual embedding space for GAN performance, achieving state-of-the-art results with reduced parameters and training time, and demonstrating computational savings with improved image fidelity.