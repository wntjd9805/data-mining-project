The introduction of this computer science paper discusses the success of deep learning in computer vision tasks and the need for network compression and acceleration methods to optimize neural networks. Specifically, the paper focuses on the quantization of neural networks, which represents parameters as low-bit values. While quantized networks have advantages in terms of memory usage and computation, they typically have lower performance compared to full-precision networks. Various methods have been proposed to improve the accuracy of quantized networks, but the accuracy gap remains significant. One common problem is the inaccurate optimization direction caused by estimated gradients for quantization functions. To address this, the paper presents a novel weight searching method that avoids non-differentiability issues and optimizes the probabilities of low-bit values. The effectiveness of the proposed method is validated through experiments on image classification and super-resolution tasks.