Image generation has made significant progress in recent years with the development of generative adversarial networks (GANs). In particular, the use of progressive growing in the generator has allowed for the learning of disentangled image styles at different spatial resolutions. StyleGAN, a GAN architecture, embeds latent codes into different resolutions to control scale-aware image styles. However, the disentanglement in StyleGAN is limited, making it difficult to further disentangle fine-grained semantics. In this paper, we propose a new approach called SariGAN that leverages the semantics of feature channels to achieve fine-grained semantic disentanglement. We introduce a similarity-based grouping module to cluster channels with the same semantics and design a mapping network to embed the input latent code into a semantic-aware intermediate latent space. The full model is optimized using several loss functions. Experimental results demonstrate that SariGAN can achieve high-fidelity image synthesis and improved interpretability.