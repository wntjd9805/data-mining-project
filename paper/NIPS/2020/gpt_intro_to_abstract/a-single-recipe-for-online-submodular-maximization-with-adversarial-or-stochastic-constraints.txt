Online optimization is a field that deals with decision-making problems where information is disclosed gradually and irreversible decisions must be made in the face of uncertainty. These problems can be seen as a repeated game between a decision maker and an adversary, where the decision maker selects an action from a fixed set and then receives feedback in the form of a utility or reward. The goal for the decision maker is to make better decisions over time to maximize the overall reward. The performance of online algorithms is typically evaluated using regret or competitive ratio. In regret analysis, the decision maker commits to an action before observing the reward function, aiming to design algorithms with sub-linear differences in accumulated reward compared to a benchmark with hindsight information. In the competitive analysis setting, the decision maker can observe the reward function before choosing an action, and the objective is to obtain bounds for the competitive ratio. While prior work in online learning has focused on maximizing overall reward without considering constraints, many practical applications require satisfying certain average constraints. Examples include balancing payments to workers in crowdsourcing markets within a budget and allocating limited advertising budget across different websites. Resource consumption in these cases is not known in advance, adding an additional complexity to the problem.