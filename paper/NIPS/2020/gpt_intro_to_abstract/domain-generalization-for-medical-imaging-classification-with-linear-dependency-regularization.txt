Due to the recent advancements in machine learning and deep learning, there have been significant successes in medical imaging tasks. However, a limitation of deep learning is its lack of generalization capability when the training data is limited. This becomes problematic when the testing data is dissimilar to the training data in terms of various factors, such as imaging protocol and patient populations. To address this domain shift problem, domain adaptation has been employed to transfer knowledge from a source domain to a relevant target domain. However, accessing target domain data in advance is often not feasible, making it challenging to train accurate deep neural networks. To overcome this, domain generalization has been proposed, which utilizes multiple source domains' information without accessing the target information. This paper introduces a novel approach that combines data augmentation and domain alignment to tackle the domain generalization problem in medical imaging classification. Instead of conducting direct image augmentation, the proposed method assumes linear dependency in a latent feature space among various domains. A deep neural network is trained with rank regularization and variational encoding to model this linear dependency and restrict the distribution of latent features. The empirical risk for any "unseen" target domain can be bounded under this formulation, mitigating the overfitting problem. Experimental results on skin lesion classification and spinal cord gray matter segmentation tasks demonstrate the superior generalization capability of the proposed method compared to existing baselines. Code for the proposed method is available at the provided GitHub link.