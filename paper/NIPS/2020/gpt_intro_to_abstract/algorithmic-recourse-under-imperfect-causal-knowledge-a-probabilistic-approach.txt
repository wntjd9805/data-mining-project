Machine learning algorithms are widely used in decision-making processes, making the need for explanations of these black-box models crucial. Counterfactual explanations, which identify alternative feature instantiations that would result in changed predictions, have been popular for providing some insight into the underlying classifier. However, these explanations do not directly translate into actionable recommendations for individuals, referred to as algorithmic recourse. Previous work has neglected the causal relationships between features, treating them as independently manipulable inputs. This paper proposes two probabilistic approaches for algorithmic recourse when limited causal knowledge is available, relaxing the assumption of a fully-specified structural causal model. The approaches involve averaging predictions over a family of structural causal models using Gaussian processes and estimating intervention effects for similar individuals using conditional variational autoencoders. Experimental results show the need for probabilistic approaches in achieving algorithmic recourse, and the importance of adopting subpopulation-based recourse when assumptions about the causal model do not hold. A user-friendly implementation of the proposed methods is available.