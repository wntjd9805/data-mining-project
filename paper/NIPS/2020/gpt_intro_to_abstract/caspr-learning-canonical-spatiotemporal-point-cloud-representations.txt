This paper introduces CaSPR, a method for learning Canonical Spatiotemporal Point Cloud Representations, to address the challenges of aggregating and encoding spatiotemporal changes in object shape as captured by 3D sensors. The authors propose a two-step approach, involving canonicalizing input point cloud sequences into a shared 4D container space using Normalized Object Coordinate Space (NOCS), and learning a continuous spatiotemporal latent representation on top of this canonicalized space using Neural Ordinary Differential Equations (Neural ODEs). They also leverage invertible Continuous Normalizing Flows (CNFs) to generate novel spatiotemporal point clouds. The authors demonstrate the usefulness of CaSPR in applications such as shape reconstruction, pose estimation, and information propagation, and highlight the contributions of their work in terms of the CaSPR encoder network, the representation of canonicalized point clouds using a Latent ODE, and its applications in various tasks.