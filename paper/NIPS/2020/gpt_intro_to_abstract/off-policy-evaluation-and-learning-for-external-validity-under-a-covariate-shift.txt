In various applications such as advertisement design, personalized medicine, search engines, and recommendation systems, there is a significant interest in evaluating and learning a new policy from historical data. This paper focuses on off-policy evaluation (OPE) and off-policy learning (OPL) methods to accomplish this goal. However, existing OPE methods assume that the distributions of covariates are the same between historical and evaluation data, which may not hold in many real-world scenarios. This paper addresses the problem of covariate shifts and proposes estimators that utilize importance weighting using the density ratio between the covariate distributions. The contributions of this paper include deriving an efficiency bound of OPE under covariate shift, proposing efficient estimators using nonparametric density ratio estimation, discussing and comparing alternative estimators, and proposing an OPL method based on the efficient estimators.