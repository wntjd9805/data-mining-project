Deep learning has experienced remarkable success in various machine learning problems, thanks to the use of deep neural networks (DNNs) in representing and learning unknown structures. While the effectiveness of neural networks in approximating functions has been extensively studied, their usage in expressing distributions is not well understood theoretically. This paper aims to address the fundamental question of how well DNNs can express probability distributions. The authors make contributions by providing conditions under which a ReLU DNN can approximate a target distribution closely, and by establishing complexity upper bounds for the depth and width of the DNN needed for a desired approximation error. The constructed DNN is explicit, and the paper concludes with a discussion of the implications of their findings.