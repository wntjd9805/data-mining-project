Depth estimation from stereo images is a fundamental task in computer vision, with applications in autonomous vehicles and graphics. Convolutional networks have improved the accuracy of depth estimation, but their discrete nature causes inaccuracy as the ground truth disparity and depth are real-valued. To address this, existing approaches predict a categorical distribution and compute the expected depth. However, this design choice can lead to inaccurate depth estimates around object boundaries. In this paper, we propose a novel neural network architecture that outputs a continuous distribution over disparity values, allowing us to directly take the mode as the prediction. We also introduce a new loss function based on the Wasserstein distance to provide a more informative training objective. Our approach is mathematically well-founded and compatible with existing stereo networks, leading to significant improvements in stereo disparity estimation, stereo depth estimation, and 3D object detection.