Open access to new datasets has greatly contributed to advances in machine learning, with ImageNet being a notable example. However, achieving state-of-the-art performance on large-scale datasets like ImageNet requires extensive computational resources and training time. This limitation hampers the exploration of methods and data, creates disparities in accessibility, biases research towards fast methods, and contributes to climate change. While smaller-scale datasets exist, they have limited value in developing and debugging powerful methods. Additionally, fixed datasets hinder exploration of non-i.i.d. learning paradigms and impede the evaluation of disentangled representations. To address these challenges, we introduce Synbols2, a dataset generator that offers a diverse set of latent features and enables quick iteration times. We conduct experiments using Synbols2 to investigate various machine learning settings and algorithms' behaviors. Our contributions include the Synbols dataset generator and insights into the performance of learning algorithms in different contexts.