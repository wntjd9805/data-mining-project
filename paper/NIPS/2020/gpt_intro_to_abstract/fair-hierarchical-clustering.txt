Algorithms and machine learned models are increasingly used in decision-making processes, from mortgage approval to court sentencing recommendations. However, it is important to ensure that these models are not biased towards certain groups, such as discriminating based on race or religion. Removing protected categories from the data is not a sufficient solution, as the correlation between sensitive features and other training data can still cause bias. This paper focuses on developing efficient fair clustering methods, specifically addressing hierarchical clustering. Hierarchical clustering is widely used in various domains, such as data analysis, social networks, and image/text organization. Fair hierarchical clustering is particularly useful in scenarios where the number of clusters is unknown, but fairness is desired. The contributions of this paper include extending the fairlets machinery to the hierarchical clustering problem and investigating the complexity of finding a fairlet decomposition. The authors also provide an empirical evaluation of their approach, demonstrating that ignoring protected attributes in hierarchical clustering can result in unfair clusters, while their proposed framework yields fair clusters with minimal degradation in objectives.