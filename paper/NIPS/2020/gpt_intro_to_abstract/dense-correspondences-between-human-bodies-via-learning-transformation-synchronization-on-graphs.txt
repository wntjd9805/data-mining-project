We present a novel approach for computing accurate and robust dense correspondences between partial scans of human subjects and a complete template model. Our method is efficient, capable of matching partial scans to templates in real-time, and addresses challenges such as input noise, pose variations, and non-rigid deformations. We leverage local geometric features and neural networks to compute dense correspondences and enforce priors through global regularization constraints. Our approach uses local rigid transformations as the data representation and formulates correspondence computation as synchronization of these transformations. We initialize the transformations using a learned shape descriptor and optimize them jointly through a recurrent neural network. Our technique achieves improved accuracy compared to the state-of-the-art on various benchmark datasets.