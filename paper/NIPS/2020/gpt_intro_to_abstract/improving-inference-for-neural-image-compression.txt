Deep learning methods have shown promising results in the field of data compression, particularly in image compression. This is important not only for its own applications but also as a stepping stone towards improving video codecs and reducing internet traffic. State-of-the-art neural methods for lossy image compression use variational autoencoders (VAEs) to map images to latent variables, which can then be used to reconstruct the images. However, the conventional amortized inference method used in VAEs for compression leaves room for improvement. In this paper, we propose three innovations: an improved amortization strategy that connects to existing iterative procedures, an improved method for discretizing the latent representation, and an improved entropy coding technique using bits-back coding. We evaluate these innovations and show that they significantly improve compression performance, resulting in a new state of the art in lossy image compression.