Computational modeling and machine learning have significantly contributed to scientific innovation in various fields. Bayesian optimization (BO) has emerged as a promising approach for solving resource-intensive optimization problems. While BO has seen advancements, there is a lack of a comprehensive framework that leverages computational advances, similar to what modern frameworks have done for deep learning. This paper introduces BOTORCH, a modular and scalable Monte Carlo framework for BO, built on modern computation paradigms and grounded in novel convergence results. The paper presents several contributions, including a novel approach to optimizing acquisition functions, convergence results for sample average approximation, an improved formulation of the Knowledge Gradient acquisition function, and model-agnostic abstractions for MC BO. The methodology, framework details, and numerical results are discussed in subsequent sections.