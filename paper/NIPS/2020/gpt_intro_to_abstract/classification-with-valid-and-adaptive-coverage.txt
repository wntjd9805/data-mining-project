In this paper, we address the problem of constructing prediction sets with marginal coverage for unseen labels in the presence of unknown distribution. We aim to develop classification methods that are provably valid in the marginal sense and attempt to approximate conditional coverage. We introduce the concept of an oracle classifier with perfect knowledge of the conditional distribution of labels given features, and define optimal prediction sets based on this knowledge. However, since we do not have access to such an oracle, we propose methods that approximate the unknown conditional distribution using black-box predictive models. We demonstrate that by adaptively choosing a threshold, we can guarantee finite-sample coverage on future test points.