Artificial Intelligence (AI) for games, known as Game AI, has been extensively researched for decades. AI agents have been successful in various game types, such as board games, video games, and card games. Multi-player Online Battle Arena (MOBA) games, a sub-genre of real-time strategy games, have gained attention due to their complex mechanics and large state-action space. However, mastering MOBA games remains a challenge for AI systems. This paper proposes a learning paradigm using deep reinforcement learning for playing full MOBA games. A distributed RL infrastructure and a unified actor-critic network architecture are developed to capture the playing mechanics of different heroes. Off-policy adaptation and multi-head value estimation are applied to handle policy deviations and uncertain state-action values. A curriculum learning approach is implemented to gradually increase the difficulty of learning, and student-driven policy distillation is used to transfer knowledge. Additionally, an efficient and effective drafting agent based on Monte-Carlo tree search is developed to handle hero selection. The proposed approach is tested using Honor of Kings and achieves high win-rates against professionals and high-ranking players. This paper presents a novel MOBA AI learning paradigm and conducts the first large-scale performance test of MOBA AI agents.