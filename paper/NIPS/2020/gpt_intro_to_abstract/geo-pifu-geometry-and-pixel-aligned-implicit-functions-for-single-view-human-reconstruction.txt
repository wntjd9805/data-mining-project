Image based modeling has revolutionized immersive content production, especially in capturing realistic human performance. However, existing methods for reconstructing clothed human meshes from monocular images suffer from under-constrained problems and lack consideration of fine-grained local shape patterns and global consistency. In this paper, we propose Geo-PIFU, an extension of pixel-aligned features that incorporates three-dimensional information to enrich feature representation and regularize the global shape of the reconstructed mesh. We introduce geometry-aligned shape features extracted from a latent voxel feature representation, which align with the human mesh in 3D space, and utilize uniform coarse occupancy volume losses and structure-aware 3D U-Nets architecture to supervise and generate latent voxel features, respectively. Our experiments demonstrate that Geo-PIFU outperforms existing methods, resulting in improved surface details and mesh topology regularities.