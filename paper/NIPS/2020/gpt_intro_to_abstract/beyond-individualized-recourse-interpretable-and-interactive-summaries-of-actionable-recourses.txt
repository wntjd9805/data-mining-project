This paper introduces a novel model-agnostic framework called Actionable Recourse Summaries (AReS) to address the problem of providing accurate and interpretable summaries of recourses in machine learning models. The framework aims to provide global counterfactual explanations that offer an understanding of model behavior and can assist decision makers in determining if a model is suitable for deployment. The objective function of the framework optimizes for correctness and interpretability of recourses while minimizing overall costs. The effectiveness of the framework is evaluated on three real-world datasets, demonstrating its ability to generate concise overviews of recourses. Additionally, the framework performs well in providing individual-level recourses and is effective in detecting biases and discrimination.