Deep neural network (DNN) models have achieved great success in various real-world tasks, but they often lack explanations or warnings when they make incorrect predictions. Predictive uncertainty estimation has become an important research area to inform users about potential errors and improve the reliability of these intelligent systems. There are three sources of predictive uncertainties in DNNs: model uncertainty, data uncertainty, and distributional uncertainty. Identifying the sources of uncertainty is useful for tasks like active learning and manual intervention in high-stakes applications. Bayesian neural network-based models can estimate uncertainty by approximating the true posterior of model parameters, but their success depends on the quality of approximations. Non-Bayesian approaches can train the network to produce sharp and uniform predictions, but they struggle to identify the source of uncertainty. In this paper, we propose a new approach using Dirichlet Prior Network (DPN) that separately models different uncertainty types and produces sharp and multi-modal Dirichlet distributions for out-of-distribution examples. We introduce a novel loss function to model the mean and precision of the output distributions, resulting in improved OOD detection performance. Experimental results on benchmark datasets confirm the effectiveness of our proposed approach.