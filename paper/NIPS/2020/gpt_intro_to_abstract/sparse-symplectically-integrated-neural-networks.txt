This paper introduces Sparse Symplectically Integrated Neural Networks (SSINNs), a new model that combines ideas from sparse regression equation discovery and black-box prediction techniques. SSINNs aim to parameterize the Hamiltonian equation of physical dynamical systems, while preserving the symplectic structure through a fourth-order symplectic integrator. The models incorporate interpretability by utilizing sparse regression to learn which terms in the governing equation are significant. Compared to black-box methods, SSINNs are interpretable, have fewer trainable parameters, and do not require specialized hardware. Experimental results show that SSINNs outperform black-box approaches and successfully learn nonlinear Hamiltonian equations from limited and noisy data.