The success of deep neural networks relies heavily on the quality of training data, but maintaining label quality for large datasets is expensive and often results in mislabeled data. Noisy labels greatly affect the generalization performance of deep neural networks, making it crucial to develop methods with theoretical guarantees for robust training against noisy labels, especially in safety-critical systems. Existing methods focus on estimating noise, designing robust loss functions, and correcting labels, but they have limitations and lack theoretical guarantees. This paper introduces CRUST, a principled technique that selects clean subsets of data to prevent overfitting while effectively learning from the training data. The method leverages recent results on neural network Jacobian matrices and demonstrates superior performance compared to state-of-the-art baselines on noisy datasets.