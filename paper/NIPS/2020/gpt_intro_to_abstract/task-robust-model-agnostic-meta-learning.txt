Despite recent advancements in computational power and data collection, there are still scenarios in which machine learning models must quickly adapt to new tasks. Meta-learning techniques have emerged as a way to learn how to learn efficiently from few samples by leveraging knowledge acquired from prior tasks. These techniques have shown promising results in areas like few-shot learning and reinforcement learning, sparking significant interest in the field. However, most existing offline meta-learning methods aim to minimize the expected loss on new tasks drawn from the same, unknown distribution as the meta-training tasks. This approach may perform poorly on difficult or rare meta-training tasks, which is problematic in critical applications such as object detection in self-driving cars where safety is essential. To address this issue, we propose a novel meta-learning formulation, Task-Robust MAML (TR-MAML), which minimizes the maximum task loss during meta-training, prioritizing performance on all observed tasks equally. We present an algorithm to solve this formulation and prove its convergence efficiency in both convex and nonconvex settings. Additionally, we provide a Rademacher complexity bound on the generalization error of new tasks within the convex hull of the meta-training tasks, demonstrating the generality of our approach. Experimental results on few-shot sinusoid regression and image classification tasks show improved performance compared to MAML.