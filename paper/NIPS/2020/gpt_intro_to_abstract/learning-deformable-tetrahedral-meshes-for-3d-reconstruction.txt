High-quality 3D reconstruction is essential for various applications in robotics, simulation, and VR/AR. The reconstruction process often involves working with noisy or imperfectly calibrated input data, such as images or point clouds. Data-driven approaches using deep learning have recently shown significant advancements in tackling this reconstruction problem. Various geometric representations, including points, voxels, surface meshes, and implicit functions, have been used with deep learning techniques. Each representation offers its own set of advantages and disadvantages. Voxel representations, while enabling the use of 3D convolutional neural networks, require high-resolution grids that are memory intensive or hierarchical structures that can be cumbersome to implement. Implicit functions and point clouds do not impose predetermined resolutions but require post-processing steps to obtain a mesh. Mesh representations directly produce meshed objects and have been shown to yield high-quality results but are limited by the predetermined genus. In this paper, we propose a novel representation called Deformable Tetrahedral Mesh (DEFTET), which utilizes tetrahedral meshes for volumetric shape reconstruction. DEFTET overcomes the limitations of other representations by offering arbitrary topology, better adaptation to object geometry through deformable triangular faces, and lower memory footprint. It also supports various downstream tasks and is computationally efficient. DEFTET is the first approach to directly produce tetrahedral meshes from noisy point clouds and images, a challenging problem in graphics. Additionally, we demonstrate the effectiveness of DEFTET in tetrahedral meshing of watertight surfaces.