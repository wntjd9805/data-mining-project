Learning robot control policies by imitation has been successfully applied to various tasks, including locomotion and grasping. In goal-conditioned tasks, expert demonstrations and control policies must also consider a representation of the goal. Previous approaches have used manually designed goal specifications, but these are inflexible and cannot be modified after deployment. In this paper, we propose using language as a flexible goal specification for imitation learning in manipulation tasks. We developed an end-to-end model for language-conditioned control of a robotic arm, utilizing a high-level semantic network to encode goals and a lower-level controller network to generate control policies. Our model was evaluated in a dynamic-enabled simulator, achieving a success rate of 84% in sequential tasks. We also conducted experiments with free-form natural-language instructions, with a success rate of 64%. Overall, our model showed promising results in achieving high success rates and flexible task specification.