In this paper, we address the challenge of strong generalization in neural networks for algorithmic reasoning tasks. We focus on imitating composable subroutines, such as selection sort and Dijkstra's algorithm, to understand the limitations of current models. We find that although a powerful sequence-to-sequence transformer model can learn subroutines for a specific data distribution, it fails to generalize strongly when the test distribution deviates from the training distribution. This failure is attributed to the difficulty of separating "what" to compute from "where" to compute, resulting in misprediction and compounding errors. To overcome this problem, we propose a solution called Neural Execution Engine (NEE), which leverages the transformer mask and predicts both a value and a pointer. We demonstrate that NEEs achieve near-perfect generalization over a significantly larger range of test values and can be applied to different algorithms without retraining. Additionally, we explore the use of binary numbers as a number representation system that allows for strong generalization and interpolation capabilities.