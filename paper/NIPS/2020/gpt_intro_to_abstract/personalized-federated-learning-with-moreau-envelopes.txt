The abundance of data generated by hand-held devices has led to the development of Federated Learning (FL), which aims to build a global model from clients' data while preserving privacy and reducing communication. However, FL faces challenges due to statistical diversity, where data distributions among clients are distinct. This leads to poor generalization of the global model on individual clients' data. In this paper, we propose a new FL scheme called pFedMe that minimizes the Moreau envelopes of clients' loss functions to optimize personalized models. We formulate a bi-level optimization problem for pFedMe and analyze its convergence properties. Empirical evaluations show that pFedMe outperforms existing algorithms in terms of convergence rate and local accuracy.