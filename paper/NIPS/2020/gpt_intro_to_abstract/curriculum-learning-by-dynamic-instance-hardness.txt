A curriculum plays a vital role in human learning, as it can greatly impact students' learning efficiency and performance. Similarly, in machine learning, recent work in curriculum learning has shown that manipulating the training data sequence can improve training efficiency and model accuracy. In this paper, we focus on the training dynamics of deep neural networks (DNNs) and propose a new measure called "dynamic instance hardness (DIH)" that captures the difficulty a model has in learning each training sample over time. We exploit several properties of DIH to develop a curriculum learning strategy called DIH guided curriculum learning (DIHCL), which selects training samples based on their DIH values. Empirical results on 11 datasets demonstrate that DIHCL outperforms other baselines in terms of efficiency and test set accuracy.