Mixed-Integer Linear Programs (MILPs) are widely used in various decision-making problems, but their integral value requirement makes them NP-hard. The B&B algorithm is commonly employed to solve MILPs, although it has exponential worst-case time complexity. In this paper, we focus on the decision problems related to B&B, such as node selection and variable selection, and explore the use of statistical learning approaches to improve these decisions. We specifically investigate a Graph Neural Network (GNN) model proposed by Gasse et al., which uses imitation learning to approximate a strong branching heuristic. While the GNN model shows promising results, its high computational cost for inference limits its applicability on CPU-only machines. To address this, we propose a hybrid architecture that combines a GNN model at the root node and a Multi-Layer Perceptron (MLP) at the remaining nodes, leveraging the structural information learned by the GNN. We also experiment with various training protocols and evaluate our approach on different MILP instances. Our results demonstrate state-of-the-art performance in CPU-restricted environments, with up to a 26% reduction in solving time compared to the default branching strategy. The hybrid model also maintains the ability to handle harder problems beyond its training set.