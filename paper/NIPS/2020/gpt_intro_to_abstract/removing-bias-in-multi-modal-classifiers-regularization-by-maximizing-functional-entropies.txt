Multi-modal data, which refers to data composed of different types of information, is widely used in various real-world applications. However, the current approach of training discriminative classifiers on multi-modal datasets using classical machine learning techniques is limited. Classical regularization methods favor simple models and tend to bias the learner towards a single modality, leading to inadequate utilization of the available information. In this paper, we propose a novel regularization term based on functional entropy to address this issue. This term encourages a balanced contribution from each modality in the classification process. We also present a method based on the log-Sobolev inequality to compute the functional entropy efficiently. Our approach shows promising results on challenging multi-modal datasets, outperforming state-of-the-art methods on popular benchmarks.