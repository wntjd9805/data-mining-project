Efficient billion-scale nearest neighbor search is a significant research problem in the field of computer science, motivated by the demands of machine learning applications. As datasets grow rapidly in size, it becomes challenging to find correspondences in large datasets while maintaining real-time responses. To address this issue, indexing structures such as approximate nearest neighbor search (ANNS) algorithms have been developed. Among these, similarity graphs like Hierarchical Navigable Small World (HNSW) and Navigating Spread-out Graph (NSG) have been shown to offer superior performance in terms of latency-vs-accuracy trade-off. However, existing similarity graphs suffer from the limitation of being memory-consuming, running out of memory with large datasets. In this paper, we propose a new ANNS algorithm called HM-ANN, which leverages Heterogeneous Memory (HM) to achieve fast and accurate ANN search at an extremely large scale. We present a solution that utilizes HM by combining cheap, slow memory with expensive, fast memory to strike a balance between cost, performance, and capacity. The algorithm makes use of full-precision vectors and accurate distance computation, and it employs memory management techniques to reduce search time and optimize performance. Extensive evaluation demonstrates that HM-ANN outperforms state-of-the-art compression-based solutions and achieves high recall rates in less than one millisecond, making it a promising approach for billion-scale ANNS.