This paper addresses the challenge of catastrophic forgetting in deep neural networks (DNNs), where previously acquired skills are quickly forgotten when learning new ones. Existing weight-regularisation methods do not consistently prevent forgetting, and existing functional-regularisation methods are computationally costly. To overcome these limitations, the authors propose a new method called Functional Regularisation of Memorable Past (FROMP), which regularises the network outputs at a few memorable past examples. Using a GP formulation of DNNs, FROMP achieves state-of-the-art performance on benchmarks and opens a new direction for lifelong learning methods.