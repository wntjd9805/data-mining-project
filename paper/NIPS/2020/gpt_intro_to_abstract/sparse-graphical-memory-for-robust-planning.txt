Learning-driven approaches to control in computer science, such as imitation learning and reinforcement learning, have had success in training agents to act from raw, high-dimensional input and to reach multiple goals. However, these approaches are limited to short horizon scenarios and struggle to scale to distant goals. On the other hand, classical planning algorithms have been successful in long-horizon tasks with distant goals by using graph search. In this paper, the authors propose a method called Sparse Graphical Memory (SGM) that combines the long-horizon ability of classic graph-based planning with the flexibility of modern, parametric, learning-driven control. They address the challenge of creating a sparse graph structure by using a similarity measure called two-way consistency (TWC) and dynamically merging similar nodes. The authors demonstrate the success of their method in various navigation environments, showing higher success rates and increased planning speed compared to previous methods.