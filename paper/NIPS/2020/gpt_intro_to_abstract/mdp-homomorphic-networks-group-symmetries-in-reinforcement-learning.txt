This paper introduces the concept of learning decision-making systems that utilize symmetries in the structure of the world. It discusses how deep reinforcement learning (DRL) algorithms, which are used for decision making, often require many samples to achieve convergence. The paper explores the use of Markov decision processes (MDPs) and MDP homomorphisms to reduce the size of the solution space and improve the learning process. It also proposes the use of MDP homomorphic networks, which are deep policies that satisfy the MDP homomorphism. The paper further discusses the utilization of group-structured equivariant neural networks and introduces a numerical algorithm for constructing equivariant layers. The contributions of the paper are the connection between MDP homomorphisms and group equivariant networks, and the introduction of an automated algorithm for building equivariant layers.