Event cameras provide a new approach to computer vision by capturing visual information as a sparse and asynchronous event stream, rather than a sequence of still images. Each event is represented by a tuple indicating the illuminance change at a specific pixel location and time, with polarity indicating whether the illuminance increased or decreased. Event cameras offer high temporal resolution and a large dynamic range, making them suitable for applications where traditional cameras may be limited by motion blur, saturation, and latency. Despite their advantages, the adoption of event cameras in real systems is limited due to a lack of algorithms, datasets, and tools. This paper focuses on object detection in automotive scenarios and introduces a large-scale dataset and a novel architecture for event-based object detection. The authors demonstrate that directly predicting object locations from event data is more efficient and accurate than using reconstructed gray-level images. Extensive experiments show comparable accuracy to frame-based detectors and improved state-of-the-art results for event-based detection.