This paper addresses the problem of out-of-distribution (OOD) data detection for deep learning models deployed in real-life applications. OOD data refers to input data that significantly deviates from the training data. It is known that neural network classifiers can misclassify OOD data, posing a challenge to the reliability and safety of AI. Existing OOD detection methods for deep classifiers cannot be applied to unsupervised models such as generative models. In this paper, the authors propose using likelihood estimates from deep generative models to detect OOD data. However, recent studies have shown that likelihood-based approaches fail to distinguish between training data and some obvious OOD input types. Alternative scores based on likelihood are proposed to address this issue, but they are not effective for Variational Auto-encoders (VAE). Therefore, the authors propose a new metric called Likelihood Regret (LR) for OOD sample detection with VAEs. Comprehensive experiments demonstrate that LR outperforms other scores in image OOD detection tasks.