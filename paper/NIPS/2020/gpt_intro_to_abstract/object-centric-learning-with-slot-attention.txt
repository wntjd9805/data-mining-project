Object-centric representations have the potential to improve sample efficiency and generalization of machine learning algorithms in various application domains. However, obtaining object-centric representations from raw perceptual input is challenging and often requires supervision or task-specific architectures. In this paper, we introduce the Slot Attention module, a differentiable interface between perceptual representations and a set of variables called slots. The Slot Attention module uses an iterative attention mechanism to produce output vectors with permutation symmetry. Unlike other approaches, the slots produced by Slot Attention do not specialize to one particular type or class of object, allowing for better generalization. We demonstrate the effectiveness of Slot Attention in unsupervised object discovery and supervised set prediction tasks. The module is simple and easy to implement, making it a versatile architectural component for extracting object representations from images.