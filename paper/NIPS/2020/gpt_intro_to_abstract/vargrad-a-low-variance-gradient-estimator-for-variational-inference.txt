Estimating the gradient of the expectation of a function is a fundamental problem in machine learning. This paper focuses on variational inference (VI) and analyzes a multi-sample estimator called VarGrad. The paper establishes a connection between VarGrad and an alternative divergence measure, known as the log-variance loss. It is shown that VarGrad can be computed by differentiating through the log-variance loss. The relationship between VarGrad and the score function estimator with optimal control variate coefficients is also studied. The paper demonstrates empirically that VarGrad outperforms other unbiased gradient estimators in terms of variance versus computation trade-off. Overall, VarGrad is a black-box, general-purpose estimator with favorable properties and computational efficiency.