In recent years, the research community has been working on developing defenses against adversarial examples. However, these defenses have proven to be highly vulnerable as they were often only tested against weak attacks and were easily circumvented by stronger attacks. The evaluation practices for these defenses have improved, with a greater emphasis on adaptive attacks specifically designed to target a defense. Despite these improvements, our analysis of thirteen selected defenses shows that all of them can still be circumvented, significantly reducing their claimed accuracy. We walk the reader through our process of analyzing each defense and demonstrate the shortcomings of the existing evaluation methodology. We emphasize the simplicity of attacks and highlight the need for appropriate tuning to each defense. To encourage independent re-evaluations, we release the code for all of our attacks.