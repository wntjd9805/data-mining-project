Imitation learning is a popular paradigm in computer science for teaching complex behaviors to agents using expert demonstrations. However, in partially observed settings, where only partial information is available to the agent, traditional imitation learning approaches may not be effective. This paper explores the limitations of training policies based on single-frame observations and introduces a new approach that leverages past observations to fill in missing state information. The authors empirically validate their approach and propose a novel imitation learning objective with an adversarial learning method to address the "copycat" problem. Their method is scalable and robust, requiring only an offline expert demonstration dataset. The effectiveness of the approach is demonstrated in six simulated continuous robotic control settings.