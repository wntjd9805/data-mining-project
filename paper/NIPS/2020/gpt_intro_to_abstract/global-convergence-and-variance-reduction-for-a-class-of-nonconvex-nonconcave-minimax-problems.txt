Minimax optimization problems, where a function is minimized with respect to one variable while maximized with respect to another, have gained significant interest in various applications such as machine learning and adversarial training. Gradient descent ascent (GDA) algorithms, commonly used to solve these problems, have shown empirical success but may fail to converge or converge to local optima. This paper focuses on the alternating gradient descent ascent (AGDA) algorithm and addresses the question of its convergence for general minimax problems. The authors introduce the two-sided Polyak-≈Åojasiewicz (PL) condition, which relaxes the convex-concavity requirement of the objective function and guarantees global convergence of AGDA and stochastic AGDA. They also propose a variance-reduced AGDA algorithm for minimax problems with a finite-sum structure and demonstrate its superior performance compared to traditional AGDA and stochastic AGDA algorithms. The paper concludes with the convergence analysis of AGDA on nonconvex-PL games.