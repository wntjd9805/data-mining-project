The design of heuristics for solving NP-hard combinatorial optimization problems over graphs has been a topic of interest among Computer Scientists. Recent advancements in Deep Learning and Graph Neural Networks have led to the idea of using recurrent structures in combinatorial objects to learn efficient heuristics with a Reinforcement Learning framework. While these approaches have shown promise in solving fundamental NP-hard problems, their applicability is still limited. Most of the problems solved heuristically with Deep Learning are those with a single decision-maker seeking to minimize a linear cost subject to linear constraints and integer requirements. However, many real-world situations involve decision-makers interacting with each other in a hierarchy. These problems are modeled as Multilevel Programming problems and are harder to solve than single-level problems. In this paper, we propose a curriculum to learn to solve a common type of multilevel combinatorial optimization problem using a budgeted zero-sum game played on a graph. We demonstrate the effectiveness of our approach on the Multilevel Critical Node problem and its variants, reporting results close to optimality on graphs of size up to 100.