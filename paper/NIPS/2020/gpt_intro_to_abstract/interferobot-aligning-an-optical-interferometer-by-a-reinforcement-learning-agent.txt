Reinforcement learning has achieved significant advancements in both computed environments and physical robotics, surpassing human performance in video games and defeating world champions in strategic games. However, most applications of reinforcement learning in robotics have focused on well-defined or toy environments, therefore lacking practical value. In this paper, we address the challenge of training an RL agent, called Interferobot, to solve a practical task in experimental optics: the alignment of a Mach-Zehnder interferometer. The main hurdle in applying RL methods to robotic training is the acquisition of large amounts of data, which can be inefficient and potentially dangerous. To overcome this, we propose using domain randomization in a simulated environment to bridge the domain gap between simulation and the real world. We demonstrate the effectiveness of our approach by simulating and transferring the policy to a physical setup without requiring any fine-tuning. Our work has the potential to greatly enhance the alignment process in tabletop optical experiments, which typically rely on skilled specialists and time-consuming procedures.