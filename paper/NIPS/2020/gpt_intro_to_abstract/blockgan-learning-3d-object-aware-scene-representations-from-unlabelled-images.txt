The computer graphics pipeline has been successful in generating high-quality images with user control, but it is expensive in terms of labor, time, and costs. Generative adversarial networks (GANs) have improved image quality, but most work focuses on property disentanglement rather than object compositionality. Current approaches treat objects as 2D layers, limiting manipulation of 3D properties and appearance interactions. In this paper, we introduce BlockGAN, a GAN that learns 3D object-oriented scene representations directly from unlabelled 2D images. By learning to generate 3D object features and combining them into deep 3D scene features, BlockGAN allows for manipulation of object pose and the addition/removal of objects. It is trained in an unsupervised manner and demonstrates the ability to separate objects and create novel scenes.