Stackelberg games involve sequential interactions between a leader and a follower, where the leader commits to an action and the follower responds based on the leader's commitment. These games have been applied to various scenarios, such as firm competition and resource allocation. The leader aims to find the best commitment while assuming rational behavior from the follower, leading to a strong Stackelberg equilibrium (SSE) with higher utility for the leader compared to a Nash equilibrium. However, in practical situations where the leader has limited information about the follower's payoffs, indirect methods are required to determine the optimal commitment. Active-learning-based approaches have been developed for computing SSEs, with recent research exploring adversarial deception by the follower to distort the SSE learned by the leader. This paper addresses the computation of SSEs in Stackelberg games, considering the follower's ability to use any payoff matrix without restrictions, which has been previously unexplored. The authors aim to resolve this computational problem and provide a solution that reflects the insecurity of learning to commit in Stackelberg games. They show that the follower can optimally deceive the learning leader by misreporting payoffs and compute a fake payoff matrix that maximizes the follower's true utility within polynomial time. Additionally, they address equilibrium selection issues and demonstrate the possibility of constructing a payoff matrix that induces a unique SSE with maximum follower utility.