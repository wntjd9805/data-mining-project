This paper explores the use of neural implicit shape representations in computer vision and machine learning. The authors address the challenges of parameterizing the shape functions and inferring the parameters from partial observations. They compare existing methods that use convolutional encoders and the auto-decoder framework, highlighting their limitations in terms of grid requirement, 3D transformation equivariance, and handling variable numbers of observations. They propose leveraging gradient-based meta-learning algorithms as an alternative approach, which offers faster inference time, flexibility in handling different observations, and improved performance compared to pooling-based set-encoder methods. The paper establishes a connection between neural implicit function spaces and meta-learning and presents the benefits of their proposed approach.