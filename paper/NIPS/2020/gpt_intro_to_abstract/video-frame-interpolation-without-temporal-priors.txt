Video frame interpolation is a widely researched topic in computer science, with applications in slow motion production, up-converting frame rate, and novel-view rendering. State-of-the-art methods often rely on optical flow to estimate object motion and occlusion, allowing for the direct synthesis of intermediate frames. However, the performance of these methods in real-world situations remains a question. In this paper, we revisit the principle of video frame acquisition, considering the exposure and readout phases of the camera. We highlight the challenges posed by exposure time and motion blur in video interpolation, and propose a more general approach to deliver accurate interpolation results. Our approach involves training a restoration network to synthesize the start and end states of each frame, considering both inter-frame and intra-frame interpolation. Additionally, we derive a curvilinear motion representation and refine the optical flow estimation using trajectory priors. Experimental results validate the effectiveness of our framework.