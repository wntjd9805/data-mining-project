In this paper, we study the minimax optimization problem of finding the equilibrium in a zero-sum two-player game. This problem has been extensively studied in game theory, economics, and computer science, and has applications in machine learning. We focus on the setting where the objective function is smooth, strongly convex with respect to one player's decision, and strongly concave with respect to the other player's decision. We consider a specific function class that captures these properties and propose new algorithms to address existing issues in achieving optimal convergence rates and dependency on condition numbers. Our contributions include the design of an algorithm with linear convergence and improved dependency on condition numbers, obtaining tighter upper bounds by reducing more general problems to the strongly convex-strongly concave problem, and studying the special case of quadratic functions. Theoretical analysis and proofs are provided to support our findings.