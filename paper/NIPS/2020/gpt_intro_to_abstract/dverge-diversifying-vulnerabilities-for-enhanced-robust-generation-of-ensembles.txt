Recent discoveries of adversarial attacks have raised concerns about the robustness of convolutional neural networks (CNNs). Adversarial examples, which are precisely crafted input perturbations that are imperceptible to humans but consistently lead to misclassification in CNN models, have been found to have widespread transferability. This transferability means that adversarial examples generated for one model can also fool other models trained on the same dataset. Previous research suggests that the vulnerability to adversarial attacks stems from deep learning models relying on non-robust features, which are highly correlated with output labels but visually insignificant and sensitive to noise. Adversarial training has been a popular method to enhance the robustness of CNN models, but it often results in decreased accuracy on clean data. In this paper, we propose a new ensemble training method called Diversifying Vulnerabilities for Enhanced Robust Generation of Ensembles (DVERGE) that focuses on diversifying the vulnerability in each sub-model. By distilling and diversifying the features related to each sub-model's vulnerability, we aim to reduce transferability of attacks within the ensemble while maintaining high accuracy on clean data. Our empirical results show that DVERGE successfully improves the ensemble's robustness against transfer attacks without significantly impacting clean accuracy. Additionally, DVERGE consistently improves robustness as the number of ensemble sub-models increases. Our approach is the first to utilize distilled features for training diverse ensembles and quantitatively relate it to the robustness against adversarial attacks.