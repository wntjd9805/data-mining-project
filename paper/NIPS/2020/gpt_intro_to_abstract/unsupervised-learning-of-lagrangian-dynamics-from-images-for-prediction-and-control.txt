In this paper, we propose the incorporation of physics priors to learn and control dynamics from image data, with the aim of gaining interpretability and data efficiency. Specifically, we introduce Lagrangian dynamics as the physics prior, enabling the representation of a broad range of physical systems. Existing approaches that incorporate Lagrangian/Hamiltonian dynamics require coordinate data, which may not always be available in real-world applications. We address this limitation by proposing an unsupervised neural network model that learns coordinates and Lagrangian dynamics from images of physical systems in motion. This model enforces Lagrangian dynamics, benefiting long-term prediction of the system. Additionally, we introduce a coordinate-aware variational autoencoder (VAE) that can infer interpretable rotational and translational coordinates from images without supervision. The interpretable coordinates and Lagrangian dynamics lay the foundation for introducing energy-based controllers for the learned dynamics.