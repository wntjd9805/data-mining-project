This paper introduces the problem of planning in large-scale Markov decision processes (MDPs) using a combination of online planning and feature representation. The goal is to design a randomized planning algorithm that efficiently produces an action for any given input state, by interacting with a simulator that models the MDP. The paper presents a solution to this problem under the assumption that the feature vectors of all states lie within the convex hull of a few selected "core states". The authors propose a relaxed approximate linear programming approach and a randomized saddle-point solver to achieve an O(ε + cε_approx)-optimal policy. The paper also provides background on MDPs, introduces the linear programming approach, and discusses related work.