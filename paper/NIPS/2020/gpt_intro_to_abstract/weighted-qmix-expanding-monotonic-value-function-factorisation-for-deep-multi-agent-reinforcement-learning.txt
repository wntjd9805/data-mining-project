This paper introduces the concept of multi-agent reinforcement learning (MARL) and its application in solving tasks involving multiple agents in the same environment. It explores the use of decentralised policies in MARL and highlights the limitations of the QMIX algorithm in representing nonmonotonic joint action value functions. The paper proposes a weighting function to improve the representation of the optimal joint action and introduces Centrally-Weighted (CW) QMIX and Optimistically-Weighted (OW) QMIX algorithms that demonstrate improved performance in environments with nonmonotonic value functions. Experimental results show the effectiveness of the proposed algorithms in solving complex coordination tasks and their robustness to exploration.