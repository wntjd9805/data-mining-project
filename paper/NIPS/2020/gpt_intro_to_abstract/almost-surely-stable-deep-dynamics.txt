In this paper, we address the challenge of interpreting and analyzing the stability of deep neural networks (DNNs) as black-box models for physical systems. We propose the construction of provably stable DNN-based dynamic models that retain the asymptotic behavior of the underlying dynamics. Specifically, we focus on stochastic systems and provide two methods for guaranteeing stability: leveraging the convexity of a Lyapunov function given by a neural network and using an implicit output layer. Additionally, we extend our framework from the deterministic case to the stochastic case.