This paper introduces the concept of using Hebbian plasticity in neural networks to enable agents to adapt and learn during their lifetime. Unlike traditional non-plastic networks, which have fixed neural architectures and static synaptic weights, the proposed approach allows for continuous variation of weights based on self-organization. The authors optimize for connection-specific Hebbian learning rules and demonstrate the effectiveness of this approach in two reinforcement learning tasks. The results show that the Hebbian network outperforms fixed-weight networks and exhibits adaptability to unseen conditions. The authors argue for the use of more dynamic neural networks that resemble biological counterparts and suggest that this research can contribute to understanding learning in the brain.