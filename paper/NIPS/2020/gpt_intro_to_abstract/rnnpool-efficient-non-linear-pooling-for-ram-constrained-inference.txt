Convolutional Neural Networks (CNNs) have made significant advancements in computer vision tasks, but their increased inference complexity makes them unsuitable for resource-constrained processors. To reduce inference complexity, various techniques have been proposed, but they still require large working memory. This paper introduces a novel pooling operator called RNNPool, which uses Recurrent Neural Networks (RNNs) to perform refined aggregation over a large receptive field of the activation map without compromising accuracy. RNNPool allows for rapid downsampling and can replace multiple CNN blocks in the initial stages of the network, reducing memory requirements without sacrificing accuracy. Experimental results demonstrate the effectiveness of RNNPool in various architectures and tasks, such as image classification and face detection. The proposed RNNPool operator offers a new approach to efficiently reduce the memory and compute requirements of CNN models for resource-constrained devices.