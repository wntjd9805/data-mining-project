Abstract
Message passing neural network (MPNN) has recently emerged as a successful framework by achieving state-of-the-art performances on many graph-based learn-ing tasks. MPNN has also recently been extended to multi-relational graphs (each edge is labelled), and hypergraphs (each edge can connect any number of vertices).
However, in real-world datasets involving text and knowledge, relationships are much more complex in which hyperedges can be multi-relational, recursive, and ordered. Such structures present several unique challenges because it is not clear how to adapt MPNN to variable-sized hyperedges in them. In this work, we ﬁrst unify exisiting MPNNs on different structures into G-MPNN (Generalised-MPNN) framework. Motivated by real-world datasets, we then propose a novel extension of the framework, MPNN-R (MPNN-Recursive) to handle recursively-structured data. Experimental results demonstrate the effectiveness of proposed instances of
G-MPNN and MPNN-R. The code is available. 1 1

Introduction
Message passing neural network (MPNN) has recently emerged as a successful framework by achieving state-of-the-art performances on many graph-based learning tasks [25]. The message-passing operation in the MPNN framework can be viewed as recursive neighbourhood aggregation, where local neighbourhood messages are aggregated and passed on to neighbouring vertices. MPNN has also recently been extended to multi-relational graphs in which each edge is labelled (and possibly directed), and separately to hypergraphs in which each edge can connect any number of vertices.
However, in real-world datasets involving text and knowledge, relationships are much more complex in which hyperedges can act as vertices recursively in other hyperedges. Hyperedges can also be multi-relational with vertices appearing in a ﬁxed order. We illustrate such structures with a toy example in Figure 1. Multi-relational ordered hypergraphs have been shown to provide more ﬂexible organisation of multi-ary relational facts than multi-relational directed edges and have been a recent research topic of interest [74, 19]. Recursive hypergraphs [55] have been shown to ﬂexibly represent a few sentence types such as claims about claims in natural language (e.g. A claimed that B claimed
C). Recursivesly structured hypergraphs are also seen in academic network datasets. Such structures present several unique challenges because it is not clear how to adapt MPNN to variable-sized hyperedges in them. Our contributions can be summarised as follows.
• We provide a uniﬁed MPNN-style framework, which we call G-MPNN (Generalised-MPNN), for multi-relational ordered hypergraphs. Several notable examples of models can be described using the uniﬁed framework 1https://github.com/naganandy/G-MPNN-R 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
Figure 1: (Best seen in colour) Organisation of text (A) and knowledge (B) for the example sentence:
Benedict was born at Chelsea hospital in the London district of Hammersmith to actors Timothy and
Wanda. A) A recursive hyperedge in which hyperedges (shown in different colours) act as vertices in other hyperedges (e.g. black-coloured hyperedge containing London, district as vertices acts as a vertex in the red-coloured hyperedge containing of, Hammersmith as vertices). B) A 5-ary hyperedge of the relation type: PERSON was born at HOSPITAL in DISTIRCT to FATHER and MOTHER.
• Motivated by real-world datasets, we explore the unexplored problem of inductive vertex embedding (embedding unseen vertices at test time) in multi-relational ordered hypergraphs.
We deomonstrate the strong inductive capability of G-MPNN on real-world multi-relational ordered hypergraph datasets.
• Motivated by recursively-structured datasets, we propose a novel extension of MPNN, termed MPNN-R (MPNN-Recursive) and show its effectiveness on real-world datasets. 2