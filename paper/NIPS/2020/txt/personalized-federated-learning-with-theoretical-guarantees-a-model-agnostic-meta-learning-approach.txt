Abstract
In Federated Learning, we aim to train models across multiple computing units (users), while users can only communicate with a common central server, without exchanging their data samples. This mechanism exploits the computational power of all users and allows users to obtain a richer model as their models are trained over a larger set of data points. However, this scheme only develops a common output for all the users, and, therefore, it does not adapt the model to each user. This is an important missing feature, especially given the heterogeneity of the underlying data distribution for various users. In this paper, we study a personalized variant of the federated learning in which our goal is to ﬁnd an initial shared model that current or new users can easily adapt to their local dataset by performing one or a few steps of gradient descent with respect to their own data. This approach keeps all the beneﬁts of the federated learning architecture, and, by structure, leads to a more personalized model for each user. We show this problem can be studied within the Model-Agnostic Meta-Learning (MAML) framework. Inspired by this connection, we study a personalized variant of the well-known Federated Averaging algorithm and evaluate its performance in terms of gradient norm for non-convex loss functions. Further, we characterize how this performance is affected by the closeness of underlying distributions of user data, measured in terms of distribution distances such as Total Variation and 1-Wasserstein metric. 1

Introduction
In Federated Learning (FL), we consider a set of n users that are all connected to a central node (server), where each user has access only to its local data [1]. In this setting, the users aim to come up with a model that is trained over all the data points in the network without exchanging their local data with other users or the central node due to privacy issues or communication limitations. More 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
formally, if we deﬁne fi : Rd → R as the loss corresponding to user i, the goal is to solve min w∈Rd f (w) := 1 n n (cid:88) i=1 fi(w). (1)
In particular, consider a supervised learning setting, where fi represents expected loss over the data distribution of user i, i.e., fi(w) := E(x,y)∼pi [li(w; x, y)] , where li(w; x, y) measures the error of model w in predicting the true label y ∈ Yi given the input x ∈ Xi, and pi is the distribution over Xi × Yi. The focus of this paper is on a data heterogeneous setting where the probability distribution pi of users are not identical. To illustrate this formulation, consider the example of training a Natural Language Processing (NLP) model over the devices of a set of users. In this problem, pi represents the empirical distribution of words and expressions used by user i. Hence, fi(w) can be expressed as fi(w) = (cid:80) pi(x, y)li(w; x, y), where Si is the data set corresponding to user i and pi(x, y) is the probability that user i assigns to a speciﬁc word which is proportional to the frequency of using this word by user i. (x,y)∈Si (2)
Indeed, each user can solve its local problem deﬁned in (2) without any exchange of information with other users; however, the resulted model may not generalize well to new samples as it has been trained over a small number of samples. If users cooperate and exploit the data available at all users, then their local models could obtain stronger generalization guarantees. A conventional approach for achieving this goal is minimizing the aggregate of local functions deﬁned in (1). However, this scheme only develops a common output for all the users, and therefore, it does not adapt the model to each user. In particular, in the heterogeneous settings where the underlying data distribution of users are not identical, the resulted global model obtained by minimizing the average loss could perform arbitrarily poorly once applied to the local dataset of each user. In other words, the solution of problem (1) is not personalized for each user. To highlight this point, recall the NLP example, where although the distribution over the words and expressions varies from one person to another, the solution to problem (1) provides a shared answer for all users, and, therefore, it is not fully capable of achieving a user-speciﬁc model.
In this paper, we overcome this issue by considering a modiﬁed formulation of the federated learning problem which incorporates personalization (Section 2). Building on the Model-Agnostic Meta-Learning (MAML) problem formulation introduced in [2], the goal of this new formulation is to ﬁnd an initial point shared between all users which performs well after each user updates it with respect to its own loss function, potentially by performing a few steps of a gradient-based method. This way, while the initial model is derived in a distributed manner over all users, the ﬁnal model implemented by each user differs from other ones based on her or his own data. We study a Personalized variant of the FedAvg algorithm, called Per-FedAvg, designed for solving the proposed personalized FL problem (Section 3). In particular, we elaborate on its connections with the original FedAvg algorithm [3], and also, discuss a number of considerations that one needs to take into account for implementing
Per-FedAvg. We also establish the convergence properties of the proposed Per-FedAvg algorithm for minimizing non-convex loss functions (Section 4). In particular, we characterize the role of data heterogeneity and closeness of data distribution of different users, measured by distribution distances, such as Total Variation (TV) or 1-Wasserstein, on the convergence of Per-FedAvg.