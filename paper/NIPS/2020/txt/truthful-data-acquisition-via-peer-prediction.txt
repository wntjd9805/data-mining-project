Abstract
We consider the problem of purchasing data for machine learning or statistical estimation. The data analyst has a budget to purchase datasets from multiple data providers. She does not have any test data that can be used to evaluate the col-lected data and can assign payments to data providers solely based on the collected datasets. We consider the problem in the standard Bayesian paradigm and in two settings: (1) data are only collected once; (2) data are collected repeatedly and each day’s data are drawn independently from the same distribution. For both settings, our mechanisms guarantee that truthfully reporting one’s dataset is always an equilibrium by adopting techniques from peer prediction: pay each provider the mutual information between his reported data and other providers’ reported data. Depending on the data distribution, the mechanisms can also discourage mis-reports that would lead to inaccurate predictions. Our mechanisms also guarantee individual rationality and budget feasibility for certain underlying distributions in the ﬁrst setting and for all distributions in the second setting. 1

Introduction
Data has been the fuel of the success of machine learning and data science, which is becoming a major driving force for technological and economic growth. An important question is how to acquire high-quality data to enable learning and analysis when data are private possessions of data providers.
Naively, we could issue a constant payment to data providers in exchange for their data. But data providers can report more or less data than they actually have or even misreport values of their data without affecting their received payments. Alternatively, if we have a test dataset, we could reward data providers according to how well the model trained on their reported data performs on the test data.
However, if the test dataset is biased, this could potentially incentivize data providers to bias their reported data toward the test set, which will limit the value of the acquired data for other learning or analysis tasks. Moreover, a test dataset may not even be available in many settings. In this work, we explore the design of reward mechanisms for acquiring high-quality data from multiple data providers when a data buyer doesn’t have access to a test dataset. The ultimate goal is that, with the designed mechanisms, strategic data providers will ﬁnd that truthfully reporting their possessed dataset is their best action and manipulation will lead to lower expected rewards. To make the mechanisms practical, we also require our mechanisms to always have non-negative and bounded payments so that data providers will ﬁnd it beneﬁcial to participate in (a.k.a. individual rationality) and the data buyer can afford the payments.
In a Bayesian paradigm where data are generated independently conditioned on some unknown parameters, we design mechanisms for two settings: (1) data are acquired only once, and (2) data 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
are acquired repeatedly and each day’s data are independent from the previous days’ data. For both settings, our mechanisms guarantee that truthfully reporting the datasets is always an equilibrium. For some models of data distributions, data providers in our mechanisms receive strictly lower rewards in expectation if their reported dataset leads to an inaccurate prediction of the underlying parameters, a property we called sensitivity.1 While sensitivity doesn’t strictly discourage manipulations of datasets that do not change the prediction of the parameters, it is a signiﬁcant step toward achieving strict incentives for truthful reporting one’s datasets, an ideal goal, especially because ﬁnding a manipulation without affecting the prediction of the parameters can be difﬁcult. Our mechanisms guarantee IR and budget feasibility for certain underlying distributions in the ﬁrst setting and for any underlying distributions in the second setting.
Our mechanisms are built upon recent developments [17, 16] in the peer prediction literature. The insight is that if we reward a data provider the mutual information [17] between his data and other providers’ data, then by the data processing inequality, if other providers report their data truthfully, this data provider will only decrease the mutual information, hence his reward, by manipulating his dataset. We extend the peer prediction method developed by [16] to the data acquisition setting, and to further guarantee IR and budget feasibility. One of our major technical contributions is the explicit sensitivity guarantee of the peer-prediction style mechanisms, which is absent in the previous work. 2