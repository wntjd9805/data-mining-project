Abstract
Multi-agent Imitation learning (MAIL) refers to the problem that agents learn to perform a task interactively in a multi-agent system through observing and mimicking expert demonstrations, without any knowledge of a reward function from the environment. MAIL has received a lot of attention due to promising results achieved on synthesized tasks, with the potential to be applied to complex real-world multi-agent tasks. Key challenges for MAIL include sample efﬁciency and scalability. In this paper, we proposed Bayesian multi-type mean ﬁeld multi-agent imitation learning (BM3IL). Our method improves sample efﬁciency through establishing a Bayesian formulation for MAIL, and enhances scalability through introducing a new multi-type mean ﬁeld approximation. We demonstrate the performance of our algorithm through benchmarking with three state-of-the-art multi-agent imitation learning algorithms on several tasks, including solving a multi-agent trafﬁc optimization problem in a real-world transportation network.
Experimental results indicate that our algorithm signiﬁcantly outperforms all other algorithms in all scenarios. 1

Introduction
Multi-agent imitation learning tries to infer a hidden reward function from expert demonstrations and optimizes a policy with the learned reward function for each agent in a multi-agent system. MAIL has received a lot of research attention and shown promising results over a variety of tasks, including the particle environments [15] and cooperative robotic control tasks based on OpenAI baselines [2], social group communication [17], driving simulation [1], sports [10, 11], and etc. [18] formulates the multi-agent generative adversarial imitation learning (MA-GAIL) by extending the single-agent generative adversarial imitation learning [4] to the multi-agent case. [7] incorporates MA-GAIL with an attention-actor-critic [6] to develop a multi-agent discriminator-actor-attention-critic (MA-DAAC) algorithm.
MAIL has the potential to solve real-world complex problems, such as optimizing driving routes in a city-scale transportation network [19], or optimizing the medical resource allocation to mitigate the spread of disease [9]. However, applying MAIL to real-world problems is not easy. MAIL is often formulated as solving a Markov game with unknown reward functions [18, 7]. To ﬁnd the optimal policy in a Markov game, each agent needs to take into consideration the policies of other agents [21].
The more agents in the environment, the more variance and uncertainty each agent has in the policy 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
search. Moreover, interacting with the environment to collect samples is an expensive operation [20].
As such, the two fundamental challenges are sample efﬁciency and scalability.
To improve the sample efﬁciency, we introduce a Bayesian approach for MAIL which learns a more stable reward function to more efﬁciently guide the policy search, and which enables an algorithm to converge faster. To improve the scalability, we introduce a new multi-type mean ﬁeld approximation to effectively gather the information from other agents, which approximates the interactions within the population of agents with those between a single agent and the average effect of the overall population. To this end, we develop a new imitation learning algorithm, the Bayesian multi-type mean ﬁeld multi-agent imitation learning (BM3IL).
The contributions of the paper are summarized as follows. (1) We introduce a Bayesian formulation of MAIL, which could improve the sample efﬁciency and convergence speed. (2) We introduce a new multi-agent mean ﬁeld approximation, which is more ﬂexible and can achieve a better approximation comparing to existing multi-type mean ﬁeld approximation. (3) We apply the multi-agent mean
ﬁeld approximation to a Bayesian formulation of multi-agent imitation learning and derive BM3IL, which is both sample efﬁcient and scalable to complex environments. (4) We demonstrate empirical performance through benchmarking with existing algorithms in several scenarios, including real-world city-scale transportation networks. 2