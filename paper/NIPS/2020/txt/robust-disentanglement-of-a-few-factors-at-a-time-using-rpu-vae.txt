Abstract
Disentanglement is at the forefront of unsupervised learning, as disentangled representations of data improve generalization, interpretability, and performance in downstream tasks. Current unsupervised approaches remain inapplicable for real-world datasets since they are highly variable in their performance and fail to reach levels of disentanglement of (semi-)supervised approaches. We introduce population-based training (PBT) for improving consistency in training variational autoencoders (VAEs) and demonstrate the validity of this approach in a supervised setting (PBT-VAE). We then use Unsupervised Disentanglement Ranking (UDR) as an unsupervised heuristic to score models in our PBT-VAE training and show how models trained this way tend to consistently disentangle only a subset of the generative factors. Building on top of this observation we introduce the recursive rPU-VAE approach. We train the model until convergence, remove the learned factors from the dataset and reiterate. In doing so, we can label subsets of the dataset with the learned factors and consecutively use these labels to train one model that fully disentangles the whole dataset. With this approach, we show striking improvement in state-of-the-art unsupervised disentanglement performance and robustness across multiple datasets and metrics. 1

Introduction
Deep Learning has been highly successful in academia as well as industry over the past years, largely in the supervised domain [1]. Unsupervised learning is becoming increasingly important, as for large amounts of datasets human annotation is either limited or not possible and therefore these datasets remain ’unused’. Disentanglement is a sub-ﬁeld of representation learning that tries to identify the low-dimensional generative factors of high-dimensional data [2]. Higgins et al. [3] introduced the
β-VAE, a stricter regularization of a variational auto-encoder (VAE) [4, 5], and showed that this model can ﬁnd generative factors in the dsprites dataset [6] without any supervision. Subsequently, the ﬁeld of disentanglement expanded quickly, as the potential beneﬁts of ﬁnding a disentangled representation of data are plentiful, i.e. they allow for more interpretability, cross-domain transfer, robustness, generalizability across machine learning disciplines, as well as improvement of the performance of downstream tasks, such as classiﬁcation [7, 8, 9, 10, 11, 12, 13].
Locatello et al. [7] showed that fully unsupervised disentanglement might not be possible without any inductive biases. Subsequently, Locatello et al. [14, 15] introduced weak and partial supervision for
∗contributed equally. Code: https://github.com/besterma/robust_disentanglement 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
training disentanglement models to tackle the aforementioned obstacle. There are no labels available for many real-life applications and for some data, generative factors of interest are hard or impossible for humans to annotate. Recently, Duan et al. [8] deﬁned a new, unsupervised heuristic for evaluating the disentanglement performance of models, based on the assumption that models that disentangle well are more likely to be similar to each other than the ones that do not disentangle [16, 17, 18, 19].
They demonstrate that this Unsupervised Disentanglement Ranking (UDR) correlates well with metrics that rely on previously annotated labels across various models and datasets [8]. Yet, the problem of extreme hyperparameter sensitivity and therefore a lack of performance and robustness in training disentanglement models remains a major challenge in disentanglement representation learning [7].
This paper introduces a systematic way to train models for disentanglement and increase overall performance and robustness. Our contributions are several-fold:
• We introduce Population Based Training (PBT) [20] for variational training to overcome hyperparameter sensitivity and achieve consistently high performing models.
• We demonstrate PBT-VAE training performance in the supervised and semi-supervised case and show how it can beat the state-of-the-art.
• We extend our approach to unsupervised learning using UDR (PBT-U-VAE (UDR)) and describe how this approach leads to a very consistent disentanglement of the factors with the highest variance in image space.
• We show how these factors can be used to label the dataset, and novel factors can be learned by removing the learned ones from the dataset.
• We demonstrate how these learned labels can be used to train a PBT-VAE and call our approach the recursive PBT-U-VAE (UDR) (rPU-VAE).
• We evaluate how the rPU-VAE disentangles different datasets in comparison to the state-of-the-art.
• We show how the performance of the rPU-VAE depends on the number of labels generated during training. 2