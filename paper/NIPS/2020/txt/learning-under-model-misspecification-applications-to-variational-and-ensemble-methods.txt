Abstract
Virtually any model we use in machine learning to make predictions does not perfectly represent reality. So, most of the learning happens under model misspeci-ﬁcation. In this work, we present a novel analysis of the generalization performance of Bayesian model averaging under model misspeciﬁcation and i.i.d. data using a new family of second-order PAC-Bayes bounds. This analysis shows, in simple and intuitive terms, that Bayesian model averaging provides suboptimal generalization performance when the model is misspeciﬁed. In consequence, we provide strong theoretical arguments showing that Bayesian methods are not optimal for learning predictive models, unless the model class is perfectly speciﬁed. Using novel second-order PAC-Bayes bounds, we derive a new family of Bayesian-like algorithms, which can be implemented as variational and ensemble methods. The output of these algorithms is a new posterior distribution, different from the Bayesian pos-terior, which induces a posterior predictive distribution with better generalization performance. Experiments with Bayesian neural networks illustrate these ﬁndings. 1

Introduction
All our models are idealizations which only provide an approximation to the real-world distributions generating the data (i.e. "all models are wrong" [9]). But whether our models are or not well-speciﬁed is a key consideration in Bayesian statistics. Suboptimal behaviors of Bayesian methods when the model family is misspeciﬁed have been widely reported in the literature [20, 21, 22, 26, 51], even questioning the principles of Bayesian statistics.
Figure 1: The exact Bayesian posterior and our new proposed (PAC2
T -Variational) posterior, and their respective posterior predictive distributions, for a linear regression model with a misspeciﬁed constant noise term (the data noise is higher than the linear model’s noise). The Bayesian posterior concentrates around the best single linear model, while our method estimates a posterior which introduces high variance in the intercept parameter θ0 to induce a posterior predictive distribution with higher noise that better ﬁts the data distribution (see Appendix C.2 for details).
∗Part of the work was done while AM was visiting the University of Copenhagen. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
The use of Bayesian methods in machine learning (see [5, 19] for an introduction) has been in general very successful, specially for discovering hidden patterns in the data by inspecting the Bayesian posterior [8, 39, 50]. And model misspeciﬁcation has not been considered as an unresolved issue
[36, 38, 53, 54]. The focus has been put on approximate inference methods [23, 45].
At the same time, many other works have shown that Bayesian methods are not superior methods when the sole purpose is to make predictions (not to identify the true unknown parameters of a model) [10, 15, 17]. Bayesian methods make predictions through Bayesian model averaging, which combines the predictions of the individual models of the family weighted by their posterior probability.
Ensemble models (see [12] for an introduction) are an alternative approach for model combination that have consistently provided very competitive generalization performance in a wide range of different problems, even in terms of well-calibrated probability predictions [49]. Recently, [56] provided strong evidence on how the generalization performance of Bayesian neural networks can be signiﬁcantly improved by considering different posteriors distributions for model averaging that largely deviate from the Bayesian posterior.
Contributions: This paper provides a novel theoretical analysis of the generalization properties of
Bayesian model averaging when the model family is misspeciﬁed. Our analysis shows that Bayesian model averaging provides suboptimal generalization performance because the Bayesian posterior is the minimum of a ﬁrst-order PAC-Bayes bound [42], which can be quite loose when the model family is misspeciﬁed. Based on this analysis, we introduce novel second-order PAC-Bayes bounds and, based on the minimization of these bounds, we derive a new sound and scalable family of Bayesian-like algorithms with better generalization properties. These new algorithms can be interpreted as generalized variational methods [29] and, even, as ensemble methods. The output of these algorithms is a new posterior distribution, different from the Bayesian posterior, which induces new posterior predictive distributions with better generalization capacity. See Figure 1 for an illustrative example.
Experiments with Bayesian neural networks also illustrate these ﬁndings. 2 Relevant prior work
PAC-Bayesian theory [42] provides probably approximately correct (PAC) bounds on the generaliza-tion risk (i.e., with probability 1 − ξ, the generalization risk is at most (cid:15) away from the training risk.)
Although PAC-Bayesian theory is mostly a frequentist method, connections between PAC-Bayes and Bayesian methods have been explored since the beginnings of the theory [33, 46]. But it was in
[18] were a neat connection was established between Bayesian learning and PAC-Bayesian theory.
However, they did not directly study the generalization performance of Bayesian model averaging and did not consider model misspeciﬁcation.
There is a large literature showing that Bayesian inference can behave suboptimally if the model is wrong [20, 21, 22, 26, 51]. The Safe Bayesian method is probably the best-known framework [20].
The main point of this approach is to guarantee the concentration of the Bayesian posterior around the best possible model. But this work shows that the concentration of the Bayesian posterior around the best possible model is the main reason behind the suboptimal generalization performance of Bayesian methods under model misspeciﬁcation.
Other related works [6, 11, 29, 34] propose Bayesian-like algorithms based on the use of alternative belief updating schemes which differs from the Bayesian approach. Again, the ﬁnal goal of these works is not to study the generalization risk of Bayesian model averaging. Some of them [6, 29] are based on the use of alternative loss functions, different from the log-likelihood function, to derive new Bayesian-like algorithms. In this sense, our proposed learning algorithms employ a special loss which includes a correcting term to account for model misspeciﬁcation.
Direct loss minimization [25, 48, 55] is a line of research close to our approach. These works analyze
Bayesian methods from the angle of regularized loss minimization. They also consider the direct optimization of the log-loss of the posterior predictive distribution. But they do not consider a generalization performance analysis and the role that model misspeciﬁcation has when justifying this approach with respect to standard Bayesian methods.
Zhang [60, 61] introduces information theoretical bounds which consider the log-loss and model misspeciﬁcation. But the bounded quantity is not the generalization error of Bayesian model averaging, and their focus is to ﬁnd the best single model, not the best model averaging distribution. 2
Robust Bayesian methods [4, 24, 28, 52, 54] also address the problem of model misspeciﬁcation. But their focus is mainly in how to ﬁx the inference procedure under small deviations from the assumptions (e.g. outliers, error measurements, etc) rather than systematically study the generalization performance under these circumstances. 3