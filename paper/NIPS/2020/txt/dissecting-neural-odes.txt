Abstract
Continuous deep learning architectures have recently re–emerged as Neural Or-dinary Differential Equations (Neural ODEs). This inﬁnite–depth approach theo-retically bridges the gap between deep learning and dynamical systems, offering a novel perspective. However, deciphering the inner working of these models is still an open challenge, as most applications apply them as generic black–box modules. In this work we “open the box”, further developing the continuous–depth formulation with the aim of clarifying the inﬂuence of several design choices on the underlying dynamics. 1

Introduction
Neural ODEs (Chen et al., 2018) represent the latest instance of continuous deep learning models, ﬁrst developed in the context of continuous recurrent networks (Cohen and Grossberg, 1983). Since their introduction, research on Neural ODEs variants (Tzen and Raginsky, 2019; Jia and Benson, 2019;
Zhang et al., 2019b; Yıldız et al., 2019; Poli et al., 2019) has progressed at a rapid pace. However, the search for concise explanations and experimental evaluations of novel architectures has left many fundamental questions unanswered.
In this work, we establish a general system–theoretic Neural ODE formulation (1) and dissect it into its core components; we analyze each of them separately, shining light on peculiar phenomena unique to the continuous deep learning paradigm. In particular, augmentation strategies are generalized beyond ANODEs (Dupont et al., 2019), and the novel concepts of data–control and adaptive–depth enriching (1) are showcased as effective approaches to learn maps such as reﬂections or concentric annuli without augmentation.
While explicit dependence on the depth–variable has been considered in the original formulation (Chen et al., 2018), a parameter depth–variance in continuous models has been overlooked. We provide a treatment in inﬁnite–dimensional space required by the true deep limit of ResNets, the solution of which leads to a Neural ODE variant based on a spectral discretization.
Neural Ordinary Differential Equation



˙z = fθ(s)(s, x, z(s)) z(0) = hx(x)
ˆy(s) = hy(z(s))
S (1) s
∈
Input
Output (Hidden) State
Parameters
Neural Vector Field
Input Network
Output Network x
ˆy z
θ(s) fθ(s) hx hy (cid:82)nx (cid:82)ny (cid:82)nz (cid:82)nθ (cid:82)nz (cid:82)nx (cid:82)nz (cid:82)nz (cid:82)ny
→
→
∗Equal contribution. Author order was decided by ﬂipping a coin. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
Depth–variance Vanilla Neural ODEs (Chen et al., 2018) cannot be considered the deep limit of
ResNets. We discuss the subtleties involved, uncovering a formal optimization problem in functional space as the price to pay for true depth–variance. Obtaining its solution leads to two novel variants of Neural ODEs: a Gal¨erkin–inspired spectral discretization (GalNODE) and a piecewise–constant model. GalNODEs are showcased on a task involving a loss distributed on the depth–domain, requiring the introduction of a generalized version of the adjoint in (Chen et al., 2018).
Augmentation strategies The augmentation idea of ANODEs (Dupont et al., 2019) is taken further and generalized to novel dynamical system–inspired and parameter efﬁcient alternatives, relying on different choices of hx in (1). These approaches, which include input–layer and higher– order augmentation, are veriﬁed to be more effective than existing methods in terms of performance and parameter efﬁciency.
Beyond augmentation: data–control and adaptive–depth We unveil that although important, augmentation is not always necessary in challenging tasks such as learning reﬂections or concentric annuli (Dupont et al., 2019). To start, we demonstrate that depth–varying vector ﬁelds alone are sufﬁcient in dimensions greater than one. We then provide theoretical and empirical results motivating two novel Neural ODE paradigms: adaptive–depth, where the integration bound is itself determined by an auxiliary neural network, and data–controlled, where fθ(s) is conditioned by the input data x, allowing the ODE to learn a family of vector ﬁelds instead of a single one. Finally, we warn against input networks hx of the multilayer, nonlinear type, as these can make Neural ODE ﬂows superﬂuous. 2 Continuous–Depth Models
A general formulation In the context of Neural ODEs we suppose to be given a stream of input– output data is a linearly–ordered ﬁnite subset of (cid:78)). The inference of Neural
K
ODEs is carried out by solving the inital value problem (IVP) (1), i.e. (xk, yk)
{ (where
}k
∈K (cid:18) (cid:90) (cid:19)
ˆy(S) = hy hx(x) + fθ(τ )(τ, x, z(τ ))dτ
S
Our degree of freedom, other than hx and hy, in the Neural ODE model is the choice of the parameter
θ inside a given pre-speciﬁed class
Well–posedness solution z deﬁned in the whole of absolutely continuous functions in turn implies that, for all k
ˆy = γ(θ, xk, s). For compactness, for any s (cid:82)nθ .
If fθ(s) is Lipschitz, for each xk the initial value problem in (1) admits a unique (cid:82)nx to the space
W × (cid:82)nz such that zk := φ(xk, θ) satisﬁes the ODE in (1). This (cid:0)φ(θ, xk)(s)(cid:1) satisﬁes
S →
. If this is the case, there is a mapping φ from
γ(s, xk, θ) := hy
, we denote φ(θ, xk)(s) by φs(θ, xk).
S (cid:55)→
, the map (θ, xk, s) of functions
∈ K (cid:55)→
W
S
∈ S
Training: optimal control (Chen et al., 2018) treated the training of constant–parameters Neural is the space of constant functions) considering only terminal loss functions depending
ODE (i.e. on the terminal state z(S). However, in the framework of Neural ODEs, the latent state evolves through a continuum of layers steering the model output ˆy(s) towards the label. It thus makes sense to introduce a loss function also distributed on the whole depth domain
, e.g.
W (cid:90)
S
The training can be then cast into the optimal control (Pontryagin et al., 1962) problem
S (cid:96) := L(z(S)) + l(τ, z(τ ))dτ min
θ
∈W 1 (cid:88) (cid:96)k
|K| k
∈K subject to ˙z(s) = fθ(s) (s, xk, z(s)) s z(0) = hx(xk), ˆy(s) = hy(z(s))
, k
∀
∈ K
∈ S (2) (3) solved by gradient descent. Here, if θ is constant, the gradients can be computed with efﬁciency by generalizing the adjoint sensitivity method in (Chen et al., 2018).
Proposition 1 (Generalized Adjoint Method). Consider the loss function (2). Then, (1) memory
O d(cid:96) dθ (cid:90)
= a(cid:62)(τ )
S
∂fθ
∂θ dτ where a(s) satisﬁes (cid:40)
˙a(cid:62)(s) = a(cid:62)
− a(cid:62)(S) = ∂L
∂z(S)
∂fθ
∂z −
∂l
∂z
Appendix B contains additional insights on the choice of activation, training regularizers and approxi-mation capabilities of Neural ODEs, along with a detailed derivation of the above result. 2
3 Depth-Variance: Inﬁnite Dimensions for Inﬁnite Layers
Bring residual networks to the deep limit Vanilla Neural ODEs, as they appear in the original paper (Chen et al., 2018), cannot be fully considered the deep limit of ResNets. In fact, while each residual block is characterized by its own parameters vector θs, the authors consider model
˙z = fθ(s, z(s)) where the depth variable s enters in the dynamics per se2 rather than in the map
θ(s). The ﬁrst attempt to pursue the true deep limit of ResNets is the hypernetwork approach of s (Zhang et al., 2019b) where another neural network parametrizes the dynamics of θ(s). (cid:55)→
However, this approach is not backed by any theoretical argument and it exhibits a considerable parameter inefﬁciency, as it generally scales polynomially in nθ. We adopt a different approach, setting out to tackle the problem theoretically in the general formulation. Here, we uncover an optimization problem in functional space, solved by a direct application of the adjoint sensitivity method in inﬁnite-dimensions. We then introduce two parameter efﬁcient depth–variant Neural ODE architectures based on the solution of such problem: Gal¨erkin Neural ODEs and Stacked Neural
ODEs.
Gradient descent in functional space When the model parameters are depth–varying, θ :
S → (cid:82)nθ , the nonlinear optimization problem (3) should be in principle solved by iterating a gradient descent algorithm in a functional space (Smyrlis and Zisis, 2004), e.g. θk+1(s) = θk(s)
ηδ(cid:96)k/δθ(s) (cid:82)nθ ) be the space of square– once the Gateaux derivative δ(cid:96)k/δθ(s) is computed. Let (cid:76)2( (cid:82)nθ ), then the loss (cid:82)nθ . Hereafter, we show that if θ(s) integrable functions
:= (cid:76)2( sensitivity to θ(s) can be computed through the adjoint method.
Theorem 1 (Inﬁnite–Dimensional Gradients). Consider the loss function (2) and let θ(s) (cid:82)nθ ). Then, sensitivity of (cid:96) with respect to θ(s) (i.e. directional derivative in functional space) is
S →
∈ W
S →
S →
S → (cid:76)2(
−
∈
δ(cid:96)
δθ(s)
= a(cid:62)(s)
∂fθ(s)
∂θ(s) where a(s) satisﬁes (cid:40)
˙a(cid:62)(s) =
− a(cid:62)(S) = ∂L
∂z(S) a(cid:62)(s) ∂fθ(s)
∂z −
∂l
∂z
Note that, although Theorem 1 provides a constructive method to compute the loss gradient in the inﬁnite–dimensional setting, its implementation requires choosing a ﬁnite dimensional approximation of the solution. We offer two alternatives: a spectral discretization approach relying on reformulating the problem on some functional bases and a depth discretization approach.
Spectral discretization: Galërkin Neural ODEs orthogonal basis of a predetermined subspace of (cid:76)2( term:
S →
The idea is to expand θ(s) on a complete (cid:82)nθ ) and truncate the series to the m-th
θ(s) =
αj (cid:12)
ψj(s) m (cid:88) j=1
In this way, the problem is turned into ﬁnite dimension and the training will aim to optimize the (cid:82)mnθ whose gradients can be computed as follows parameters α = (α1, . . . , αm)
Corollary 1 (Spectral Gradients). Under the assumptions of Theorem 1, if θ(s) = (cid:80)m
∂fθ(s)
∂θ(s)
ψ(τ )dτ, ψ = (ψ1, . . . , ψm) j=1 αj (cid:12) d(cid:96) dα a(cid:62)(τ )
ψj(s),
=
∈ (cid:90)
S
Depth discretization: Stacked Neural ODEs
An alternative approach to parametrize θ(s) is to
= (cid:83)p assume it piecewise constant in i=0 [si, si+1]. It is easy
, i.e. θ(s) = θi ∀ s
− to see how evaluating this model is equivalent to stacking p Neural ODEs with constant parameters,
[si, si+1] and
∈
S
S 1 z(S) = hx(x) + p 1 (cid:88)
− (cid:90) si+1 fθi(τ, x, z(τ ))dτ i=0
Here, the training is carried out optimizing the resulting pnθ parameters using the following:
Corollary 2 (Stacked Gradients). Under the assumptions of Theorem 1, if θ(s) = θi ∀ s
∂l d(cid:96)
∂z s dθi
˙a(cid:62)(s) =
− a(cid:62)(S) = ∂L
∂z(S) dτ where a(s) satisﬁes
∂fθi
∂z −
∂fθi
∂θi a(cid:62)(s) a(cid:62)(τ ) (cid:90) si si+1 (cid:40)
=
−
∈
∈
[si, si+1],
[si, si+1] s1 2In practice, s is often concatenated to z and fed to fθ. 3
The two approaches offer different perspectives on the problem of parametrizing the evolution of
θ(s); while the spectral method imposes a stronger prior to the model class, based on the chosen bases (e.g. Fourier series, Chebyshev polynomials, etc.) the depth–discretization method allows for more freedom. Further details on proofs, derivation and implementation of the two models are given in the Appendix.
Tracking signals via depth–variance Con-sider the problem of tracking a periodic sig-nal β(s). We show how this can be achieved without introducing additional inductive biases such as (Greydanus et al., 2019) through a syn-ergistic combination of a two–layer Galërkin
Neural ODEs and the generalized adjoint with 2 2. The integral loss l(s) := z(s)
β(s) (cid:107) (cid:107)
[0, 1] generalize accu-models, trained in s
∈ rately in extrapolation, recovering the dynamics.
Fig.2 showcases the depth–dynamics of θ(s) for
Galërkin and Stacked variants trained to solve a simple binary classiﬁcation problem. Additional insights and details are reported in Appendix.
−
Figure 1: Galërkin Neural ODEs trained with in-tegral losses accurately recover periodic signals.
Blue curves correspond to different initial condi-tions and converge asymptotically to the reference desired trajectory.
Depth–variance brings Neural ODEs closer to the ideal continuum of neural network layers with untied weights, enhancing their expressivity. 4 Augmenting Neural ODEs
Augmented Neural ODEs (ANODEs) (Dupont et al., 2019) propose solving the initial value problem (IVP) in a higher dimensional space to limit the complexity of learned ﬂows, i.e. having nz > nx. The nx augmented proposed approach of the seminal paper relies on initializing to zero the na := nz − dimensions: z(0) = [x, (cid:48)]. We will henceforth refer to this augmentation strategy as 0–augmentation.
In this section we discuss alternative augmentation strategies for Neural ODEs that match or improve on 0–augmentation in terms of performance or parameter efﬁciency.
Input–layer augmentation
Following the standard deep learning approach of increasing layer width to achieve improved model capacity, 0–augmentation can be generalized by introducing an
Figure 2: Galërkin and Stacked parameter-varying Neural ODE variants. Depth ﬂows (Above) and evolution of the parameters (Below). 4
input network hx : (cid:82)nx (cid:82)nz to compute z(0):
→ (4) z(0) = hx(x) leading to the general formulation of (1). This approach (4) gives the model more freedom in determining the initial condition for the IVP instead of constraining it to a concatenation of x and (cid:48), at a small parameter cost if hx is, e.g., a linear layer. We refer to this type of augmentation as input layer (IL) augmentation and to the model as IL–Neural ODE (IL–NODE).
Note that 0-augmentation is compatible with the general IL formulation, as it corresponds to
In applications where maintaining the structure of the ﬁrst nx dimensions is important, e.g. approxi-mation of dynamical systems, a parameter efﬁcient alternative of (4) can be obtained by modifying the (cid:82)na . input network hx to only affect the additional na dimensions, i.e. hx := [x, ξ(x)], ξ : (cid:82)nx
→ x (cid:55)→ (x, (cid:48)) := hx(x)
Higher–order Neural ODEs
Further parameter efﬁciency can be achieved by lifting the Neural
ODEs to higher orders. For example, let z(s) = [zq(s), zp(s)] a second–order Neural ODE of the form: equivalent to the ﬁrst–order system
¨zq(s) = fθ(s)(s, z(s)).
˙zq(s) = zp(s)
˙zp(s) = fθ(s)(s, zq(s), zp(s)) (5) (6)
The above can be extended to higher–order Neural ODEs as (cid:18) (cid:19)
,
,
,
· · · s, z, dz1 ds dn
− dsn z = [z1, z2, . . . , zn], zi dnz1 dsn = fθ(s) 1z1 1 or, equivalently, ˙zi = zi+1, ˙zn = fθ(s)(s, z). Note that the parameter efﬁciency of this method arises from the fact that fθ(s) : (cid:82)nz (cid:82)nz . A limitation of system (6) is that a naive extension to second–order requires a number of augmented dimensions na = nx. To allow for ﬂexible augmentations of few dimensions na < nx, the formulation of second–order Neural
ODEs can be modiﬁed to select only a few dimensions to have higher order dynamics. We include formulation and additional details of selective higher–order augmentation in the supplementary material. Finally, higher–order augmentation can itself be compatible with input–layer augmentation. (cid:82)nz/n instead of (cid:82)nz (cid:82)nz/n (7)
→
→
∈
−
Revisiting results for augmented Neural ODEs
In higher dimensional state spaces, such as those of image classiﬁcation settings, the beneﬁts of augmentation become subtle and manifest as performance improvements and a lower number of function evaluations (NFEs) (Chen et al., 2018).
We revisit the image classiﬁcation experiments of (Dupont et al., 2019) and evaluate four classes of depth–invariant Neural ODEs: namely, vanilla (no augmentation), ANODE (0–augmentation), IL-NODE (input–layer augmentation), and second–order. The input network hx is composed of a single, linear layer. Main objective of these experiments is to rank the efﬁcieny of different augmentation strategies; for this reason, the setup does not involve hybrid or composite Neural ODE architectures and data augmentation.
The results for ﬁve experiments are reported in Table 4. IL–NODEs consistently preserve lower NFEs than other variants, whereas second–order Neural ODEs offer a parameter efﬁcient alternative. The performance gap widens on CIFAR10, where the disadvantage of ﬁxed 0 initial conditions forces 0–augmented Neural ODEs into performing a high number of function evaluations.
NODE
ANODE
IL-NODE 2nd–Ord. (cid:12) CIFAR MNIST (cid:12)
MNIST (cid:12) (cid:12) CIFAR (cid:12) (cid:12)
Test Acc. (cid:12) 58.9 98.9 96.8 (cid:12) 70.8 71 (cid:12) 98 (cid:12)
NFE (cid:12) 169 (cid:12) 93 (cid:12) 37.1 20.4 (cid:12)
Param.[K] 21.4 (cid:12) (cid:12) 35.0
MNIST (cid:12)
MNIST (cid:12) (cid:12) CIFAR (cid:12) CIFAR (cid:12) (cid:12) (cid:12) 73.4 99.2 99.1 (cid:12) 72.8 43 (cid:12) 44 (cid:12) (cid:12) 59 (cid:12) 65 20.0 (cid:12) 20.7 (cid:12) (cid:12) 34.6 (cid:12) 36.1
Table 1: Mean test results across 10 runs on MNIST and CIFAR. We report the mean NFE at convergence.
Input layer and higher order augmentation improve task performance and preserve low NFEs at convergence. 5
1 0 1
) s ( z
− 0
Data–Controlled Neural ODEs x = 1
− 1 0 1
) s ( z
− 0 x = 1 s 1 s 1
Figure 3: Depth trajectories over vector ﬁeld of the data–controlled neural ODEs (9) for x = 1, x = 1. The model learns a family of vector ﬁelds conditioned by the input x to approximate ϕ(x).
−
It should be noted that prepending an input multi–layer neural network to the Neural ODE was the approach chosen in the experimental evaluations of the original Neural ODE paper (Chen et al., 2018) and that (Dupont et al., 2019) opted for a comparison between no input layer and 0–augmentation.
However, a signiﬁcant difference exists between architectures depending on the depth and expressivity of hx. Indeed, utilizing non–linear and multi–layer input networks can be detrimental, as discussed in Sec. 5.
Augmentation relieves Neural ODEs of their expressivity limitations. Learning initial condi-tions improves on 0–augmentation in terms of performance and NFEs. 5 Beyond Augmentation: Data–Control and Depth–Adaptation
Augmentation strategies are not always necessary for Neural ODEs to solve challenging tasks such as concentric annuli (Dupont et al., 2019). While it is indeed true that two distinct trajectories can never intersect in the state–space in the one–dimensional case, this does not necessarily hold in general. In fact, dynamics in the ﬁrst two spatial dimensions are substantially different e.g no chaotic behaviors are possible (Khalil and Grizzle, 2002). In the two–dimensions of (cid:82)2 (and so in (cid:82)n), inﬁnitely wider than (cid:82), distinct trajectories of a time–varying process can well intersect in the state–space, provided that they do not pass through the same point at the same time (Khalil and Grizzle, 2002).
This implies that, in turn, depth–varying models such as Gal¨erkin Neural ODEs can solve these tasks in all dimensions but (cid:82).
Starting from the one–dimensional case, we propose new classes of models allowing Neural ODEs to perform challenging tasks such as approximating reﬂections (Dupont et al., 2019) without the need of any augmentation. 5.1 Data–controlled Neural ODEs
We hereby derive a new class of models, namely data–controlled Neural ODEs.
To introduce the proposed approach, we start with an analytical result regarding the approximation of reﬂection maps such as ϕ(x) = x. The proof provides a design recipe for a simple handcrafted
ODE capable of approximating ϕ with arbitrary accuracy by leveraging input data x. We denote the conditioning of the vector ﬁeld with x necessary to achieve the desired result as data–control.
−
This result highlights that, through data–control, Neural ODEs can arbitrarily approximate ϕ without augmentation, providing a novel perspective on existing results about expressivity limitations of continuous models (Dupont et al., 2019). The result is the following:
Proposition 2. For all (cid:15) > 0, x
∈ (cid:82) there exists a parameter θ > 0 such that
< (cid:15),
ϕ(x) where z(1) is the solution of the Neural ODE
| z(1)
|
− (cid:26) ˙z(s) =
− z(0) = x
θ(z(s) + x)
, s
[0, 1] .
∈ (8) (9)
The proof is reported in the Appendix. Fig. (3) shows a version of model (9) where θ is trained with standard backpropagation. This model is indeed able to closely approximate ϕ(x) without augmentation, conﬁrming the theoretical result. From this preliminary example, we then deﬁne the 6
general data–controlled Neural ODE as
˙z(s) = fθ(s)(s, x, z(s)) z(0) = hx(x)
. (10)
Model (10) incorporates input data x into the vector ﬁeld, effectively allowing the ODE to learn a family of vector ﬁelds instead of a single one. Direct dependence on x further constrains the ODE to be smooth with respect to the initial condition, acting as a regularizer. Indeed, in the experimental evaluation at the end of Sec. 5, data–controlled models recover an accurate decision boundary.
Further experimental results with the latter general model on the representation of ϕ are reported in the Appendix.
It should be noted that (10) does not require explicit dependence of the vector ﬁeld on x. Computa-tionally, x can be passed to fθ(s) in different ways, such as through an additional embedding step. In this setting, data–control offers a natural extension to conditional Neural ODEs.
Data–control in normalizing ﬂows Condi-tional variants of generative models can be guided to produce samples of different character-istics depending on speciﬁc requirements. Data– control can be leveraged to obtain a conditional variant of continuous normalizing ﬂows (CNFs) (Chen et al., 2018). Here, we consider the stan-dard setting of learning an unknown data distri-bution p(x) given samples through a parametrized function pθ. Continuous normal-ing ﬂows (CNFs) (Chen et al., 2018; Grathwohl et al., 2018; Finlay et al., 2020) obtain pθ by change of variables using the ﬂow of an ODE to warp a (known) prior distribution q(z), i.e.
φS(x) log pθ(x) = log q(φS(x)) + log det
| where the log determinant of the Jacobian is computed via the ﬂuid mechanics identity xk}k
{
|∇
∈K
Figure 4: Data–controlled CNFs can morph prior distributions into distinct posteriors to produce con-ditional samples. This task often requires crossing trajectories and is not possible with vanilla CNFs. pθ(x) by sampling the known distribution zS ∼ z(0) = zS + (cid:90) 0 log det d ds (Villani, 2003).
|∇
φs(x)
|
=
∇ · fθ(t)(s, φs(x))
CNFs are trained via
, maximum–likelihood, i.e by minimizing the
Kullback–Leibler divergence between p and pθ, or equivalently (cid:96) := k log pθ(xk). A 1/
−
CNF can be then used as generative model for q(zS) and evolve zS backward in the depth domain:
|K| (cid:80) fθ(s)(s, z(s))ds
S
In this context, introducing data–control into fθ allows the CNF to be conditioned with data or task information. Data–controlled CNFs can thus be used in multi–objective generative tasks e.g using a single model to sample from N different distribution pθ by warping N predetermined know distributions qi. We train one–dimensional, data–controlled CNFs to approximate two different data distributions p1, p2 by sampling from two distinct priors q1, q2 and conditioning the vector ﬁeld with the samples zS of the prior distributions, i.e.
˙z(s) = fθ(zS, z), zS ∼ q1 or zS ∼ q2
Fig 4 shows how data–controlled CNFs are capable of conditionally sampling from two normal target data distributions. In this case we selected p1, p2 as univariate normal distributions with mean 1
− p1. The resulting learned vector ﬁeld strongly depends on the and 1, respectively and q1 ≡ value of the prior sample zS and it is almost constant in z, meaning that the prior distributions are just shifted almost rigidly along the ﬂow in a direction determined by the initial condition. This task is inaccessible to standard CNFs as it requires crossing ﬂows in z. Indeed, the proposed benchmark represents a density estimation analogue to the crossing trajectories problem. p2, q2 ≡ 7
5.2 Adaptive–Depth Neural ODEs
Let us come back to the approximation of ϕ(x). Indeed, without incorporating input data into fθ(s), it is not possible to realize a mapping x
φs(x) mimicking ϕ due to the topology pre-(cid:55)→ serving property of the ﬂows. Nevertheless, a Neural ODE can be employed to approximate ϕ(x) without the need of any crossing trajectory. In fact, if each input is integrated for in a different depth domain, (x) = [0, s∗x], it is possible to learn ϕ without crossing ﬂows as shown in Fig. 5.
In general, we can use a hypernetwork g trained to learn the integration depth of each sample. In this setting, we deﬁne the general adaptive depth class as Neural ODEs performing the mapping x
Adaptive Integration Depth
Inputs trajectories through network depth
φgω(x)(x), i.e. leading to
S (cid:33)
) s ( z 1 0 1 (cid:55)→ (cid:32) (cid:90) gω(x)
ˆy = hy hx(x) + fθ(s)(τ, x, z(τ ))dτ
, 0 where gω : (cid:82)nx (cid:82)nω (cid:82) is a neural net-work with trainable parameters ω. Appendix
B contains details on differentiation under the integral sign, required to backpropagate the loss gradients into ω.
→
×
− 0 1 s 2 3
Figure 5: Depth trajectories over vector ﬁeld of the adaptive—depth Neural ODEs. The reﬂection map can be learned by the proposed model. The key is to assign different integration times to the inputs, thus not requiring the intersection of trajectories.
Experiments of non–augmented models We inspect the performance of different Neural ODE variants: depth–invariant, depth–variant with s concatenated to z and passed to the vector ﬁeld,
Gal¨erkin Neural ODEs and data–controlled. The concentric annuli (Dupont et al., 2019) dataset is utilized, and the models are qualitatively evaluated based on the complexity of the learned ﬂows and on how accurately they extrapolate to unseen points, i.e. the learned decision boundaries. For
Gal¨erkin Neural ODEs, we choose a Fourier series with m = 5 harmonics as the eigenfunctions ψk, k = 1, . . . , 5 to compute the parameters θ(s), as described in Sec. 3.
Data–control allows Neural ODEs to learn a family of vector ﬁelds, conditioning on input data informa-tion. Depth–adaptation sidesteps known expressivity limitations of continuous–depth models.
Mind your input networks An alternative ap-proach to learning maps that prove to be chal-lenging to approximate for vanilla Neural ODEs involves solving the ODE in a latent state space.
Fig. 6 shows that with no augmentation, a net-work composed by a two fully–connected layers with non–linear activation followed by a Neu-ral ODE can solve the concentric annuli prob-lem. However, the ﬂows learned by the Neu-ral ODEs are superﬂuous: indeed, the clusters were already linearly separable after the ﬁrst non–linear transformation. This example warns against superﬁcial evaluations of Neural ODE architectures preceded or followed by several layers of non–linear input and output transformations.
In these scenarios, the learned ﬂows risk performing unnecessary transformations and in pathological cases can collapse into a simple identity map. To sidestep these issues, we propose visually inspecting trajectories or performing an ablation experiment on the Neural ODE block.
Figure 6: Solving concentric annuli without aug-mentation by prepending a nonlinear transforma-tion performed by a two–layer fully–connected network. 8
Figure 7: Depth-ﬂows of the data in the state–space. The resulting decision boundaries of output linear layer hy are indicated by the dotted orange line. 6