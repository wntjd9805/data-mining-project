Abstract
Humans easily interpret expressions that describe unfamiliar situations composed from familiar parts (“greet the pink brontosaurus by the ferris wheel”). Modern neural networks, by contrast, struggle to interpret novel compositions. In this paper, we introduce a new benchmark, gSCAN, for evaluating compositional general-ization in situated language understanding. Going beyond a related benchmark that focused on syntactic aspects of generalization, gSCAN deﬁnes a language grounded in the states of a grid world, facilitating novel evaluations of acquiring linguistically motivated rules. For example, agents must understand how adjectives such as ‘small’ are interpreted relative to the current world state or how adverbs such as ‘cautiously’ combine with new verbs. We test a strong multi-modal baseline model and a state-of-the-art compositional method ﬁnding that, in most cases, they fail dramatically when generalization requires systematic compositional rules. 1

Introduction
Human language is a fabulous tool for generalization. If you know the meaning of the word ‘small’, you can probably pick the ‘small wampimuk’ among larger ones, even if this is your ﬁrst encounter with wampimuks. If you know how to ‘walk cautiously,’ you can infer how to ‘bike cautiously’ through a busy intersection (see example in Figure 1). The ability to learn new words from limited data and use them in a variety of contexts can be attributed to our aptness for systematic compositionality
[9, 33]: the algebraic capacity to understand and produce potentially inﬁnite combinations from known components. Modern deep neural networks, while strong in many domains [29], have not mastered comparable language-based generalization challenges, a fact conjectured to underlie their sample inefﬁciency and inﬂexibility [26, 25, 8]. Recent benchmarks have been proposed for language-based generalization in deep networks [20, 16, 17], but they do not speciﬁcally test for a model’s ability to perform rule-based generalization, or do so only in limited contexts. Systematic, rule-based generalization is instead at the core of the recently introduced SCAN dataset [25] (see
[19, 3] for related ideas). In a series of studies, Lake, Baroni and colleagues [5, 30, 10] tested various standard deep architectures for their ability to extract general composition rules supporting zero-shot interpretation of new composite linguistic expressions (can you tell what ‘dax twice’ means, if you know the meaning of ‘dax’ and ‘run twice’?). In most cases, neural networks were unable to generalize correctly. Very recent work has shown that speciﬁc architectural or training-regime adaptations allow
∗Work done during an internship at Facebook Artiﬁcial Intelligence Research. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
Figure 1: gSCAN evaluates context sensitivity in situ-ated language understanding. In these two simpliﬁed examples, the same determiner phrase ‘the red small circle’ has different referents and demands different action sequences. Being cautious means looking both ways (‘L_turn R_turn R_turn L_turn’) before each step.
Figure 2: Examples showing how to ‘walk while spin-ning’ and how to ‘push.’ On the left, the agent needs to spin around (‘L_turn L_turn L_turn L_turn’) before it moves by one grid cell. On the right, it needs to push a square all the way to the wall. deep networks to handle at least some of the SCAN challenges [2, 27, 34, 36, 14]. However, it is unclear to what extent these proposals account for genuine compositional generalization, and to what extent they are ‘overﬁtting’ to the limitations of SCAN.
SCAN simulates a navigation environment through an interpretation function that associates linguistic commands (‘walk left’) to sequences of primitive actions (L_turn walk). SCAN, however, is not grounded, in that it lacks a ‘world’ with respect to which commands are interpreted: instead the agent must simply associate linguistic strings with ﬁxed sequences of action symbols, mapping syntactic strings (word sequences) to other syntactic strings (action label sequences). In real languages, by contrast, the process by which utterances are understood is both compositional and contextual: references to entities and descriptions of actions must be interpreted with respect to a particular state of the world. The interaction between compositionality and context introduces new types of generalization an intelligent agent might have to perform. For example, consider the meaning of size adjectives such as ‘small’ and ‘large’. The determiner phrases ‘the small bottle’ and ‘the large bottle’ might refer to the same bottle, depending on the sizes of the surrounding bottles. We wonder whether this and related notions of compositional generalization can be addressed using existing techniques, but SCAN’s context insensitivity makes it impossible to investigate broader notions of generalization.
We introduce grounded SCAN (gSCAN), a new benchmark that, like the original SCAN, focuses on rule-based generalization, but where meaning is grounded in states of a grid world accessible to the agent. This allows gSCAN to evaluate eight types of compositional generalization (mostly from a single training set), whereas most benchmarks focus on just one or two types. For example,
Figure 1 illustrates context-sensitivity in compositionality: how the target referent ‘the red small circle’, and the action sequence required to navigate there, will change based on the state of the world. It also illustrates modiﬁcation-based compositionality: once learning how to walk somewhere
‘cautiously’ (Figure 1 left), can models walk elsewhere cautiously or push an object cautiously (Figure 1 right)? On these and other generalizations, we test a baseline multi-modal model representative of contemporary deep neural architectures, as well as a recent method proposed to address compositional generalization in the original SCAN dataset (GECA, [2]). Across eight different generalization splits, the baseline dramatically fails on all but one split, and GECA does better on only one more split.
These results demonstrate the challenges of accounting for common natural language generalization phenomena with standard neural models, and afﬁrm gSCAN as a fruitful benchmark for developing models with more human-like compositional learning skills. 2