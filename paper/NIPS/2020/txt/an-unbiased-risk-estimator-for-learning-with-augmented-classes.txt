Abstract
This paper studies the problem of learning with augmented classes (LAC), where augmented classes unobserved in the training data might emerge in the testing phase. Previous studies generally attempt to discover augmented classes by exploit-ing geometric properties, achieving inspiring empirical performance yet lacking theoretical understandings particularly on the generalization ability. In this paper we show that, by using unlabeled training data to approximate the potential distribu-tion of augmented classes, an unbiased risk estimator of the testing distribution can be established for the LAC problem under mild assumptions, which paves a way to develop a sound approach with theoretical guarantees. Moreover, the proposed approach can adapt to complex changing environments where augmented classes may appear and the prior of known classes may change simultaneously. Extensive experiments conﬁrm the effectiveness of our proposed approach. 1

Introduction
Recent advances in machine learning encourage its application in high-stake scenarios, where the robustness is the central requirement [1, 2]. A robust learning system should be able to handle the distribution change in the non-stationary environments [3, 4, 5]. In this paper, we focus on the problem of learning with augmented classes (LAC) [6], where the class distribution changes during the learning process—some augmented classes unobserved in training data might emerge in testing.
To make reliable predictions, desired learning systems are required to identify augmented classes and retain good generalization performance over the testing distribution.
The main challenge of the LAC problem lies in how to depict relationships between known and augmented classes. A typical solution is to learn a compact geometric description of the known classes and take those beyond the description as augmented classes, where the anomaly detection or novelty detection approaches can be employed (such as one-class SVM [7, 8], kernel density estimation [9, 10] and iForest [11]). Da et al. [6] give the name of LAC and employ the low-density separation assumption to adjust the decision boundaries in a multi-class situation. In addition to the effort of machine learning community, the computer vision and pattern recognition communities also contribute to the study of the problem (or its cousin). Scheirer et al. [12] propose the notion of open space risk to penalize predictions outside the support of training data, based on which several approaches are developed [12, 13]. Later, approaches based on the nearest neighbor [14] and extreme value theory [15] are also developed. More discussions on related topics are deferred to Section 5.
Although various approaches are proposed with nice performance and some of them conduct the-oretical analysis, generalization properties of the LAC problem is less explored. Scheirer et al.
[12, 13], Rudd et al. [15] formally use the open space risk or extreme value theory to identify aug-mented classes, but the generalization error of learned models is not further analyzed. There are also works [16, 17, 18] focusing on the Neyman-Pearson (NP) classiﬁcation, which controls the novelty 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
Figure 1: Distribution of augmented classes can be estimated by those of labeled and unlabeled training data. detection ratio of augmented classes or false positive ratio of known classes with the constraint on another. By using unlabeled data, authors develop approaches with one-side PAC-style guarantees for the binary NP classiﬁcation whereas the generalization ability for the LAC problem is not studied.
To design approaches with generalization error guarantees for the LAC problem, it is necessary to assess the distribution of augmented classes in the training stage. Note that in many applications, during the training stage, in addition to labeled data, there are abundant unlabeled training data available. In this paper, we show that by exploiting unlabeled training data, an unbiased risk estimator over the testing distribution can be established under mild assumptions. The intuition is that, though instances from augmented classes are unobserved from labeled data, their distribution information may be contained in unlabeled data and estimated by separating the distribution of known classes from unlabeled data (Figure 1). More concretely, we propose the class shift condition to model the testing distribution as a mixture of known and augmented classes’ distributions. Under such a condition, classiﬁers’ risk over testing distribution can be estimated in the training stage, where minimizing its empirical estimator ﬁnally gives our EULAC approach, short for Exploiting Unlabeled data for
Learning with Augmented Classes. Moreover, the EULAC approach can further take the prior change on known classes into account, which enables its adaptivity to complex changing environments.
EULAC enjoys several favorable properties. Theoretically, our approach has both asymptotic (con-sistency) and non-asymptotic (generalization error bound) guarantees. Notably, the non-asymptotic analysis further justiﬁes the capability of our approach in exploiting unlabeled data, since the gener-alization error becomes smaller with an increasing number of unlabeled data. Moreover, extensive experiments validate the effectiveness of our approach. It is noteworthy to mention that our approach can now perform the standard cross validation procedure to select parameters, while most geometric-based approaches cannot due to the unavailability of the testing distribution, and their parameters setting heavily relies on the experience. We summarize main contributions of this paper as follows. (1) We propose the class shift condition to characterize the connection between known and augmented classes for the learning with augmented class problem. (2) Based on the class shift condition, we establish an unbiased risk estimator over the testing distribution for the LAC problem by exploiting the unlabeled data. Similar results are also attainable for a general setting of class distribution change. (3) We develop our EULAC approach with the unbiased risk estimator, whose theoretical effectiveness is proved by both consistency and generalization error analyses. We also conduct extensive experiments to validate its empirical superiority. 2 An Unbiased Risk Estimator for LAC problem
In this section, we formally describe the LAC problem, followed by the introduction of the class shift condition, based on which we develop the unbiased risk estimator over the testing distribution.
Moreover, we show the potential of our approach for adapting to complex changing environments. 2.1 Problem Setup and Class Shift Condition
LAC problem. In the training stage, the learner collects a labeled dataset DL = {(xi, yi)}nl i=1 sampled from distribution of known classes Pkc deﬁned over X × Y (cid:48), where X denotes the feature space and Y (cid:48) = {1, . . . , K} is the label space of K known classes. In the testing stage, the learner requires to predict instances from the testing distribution Pte, where augmented classes not observed before might emerge. Since the speciﬁc partition of augmented classes is unknown, the learner will predict all of them as a single augmented class ac. So the testing distribution is deﬁned over 2
X × Y, where Y = {1, . . . , K, ac} is the augmented label space. The goal of the learner is to train a classiﬁer f : X (cid:55)→ Y achieving good generalization ability by minimizing the expected risk
R(f ) = E(x,y)∼Pte [1(f (x) (cid:54)= y)] over the testing distribution, where 1(·) is the indicator function.
Unlabeled data. In our setup, the learner additionally receives a set of unlabeled data DU = {xi}nu i=1 sampled from the testing distribution and hopes to use it to enhance performance of the trained classiﬁer. This learning scenario happens when labeled training data fail to capture certain classes of the testing distribution due to the class distribution change, while we can easily collect a vast amount of unlabeled data from current environments. Essentially, the missed class information has already been contained in the training data (unlabeled data) though is not revealed in the supervision (labeled training data). We thus prefer to call such classes as the “augmented class” instead of “new class”.
Class shift condition. Although not explicitly stated, previous works [12, 6, 14] essentially rely on the assumption that the distribution of known classes remains unchanged when augmented classes emerge. Following the same spirit, we introduce the following class shift condition for the LAC problem to rigorously depict the connection between known and augmented class distributions.
Deﬁnition 1 (Class Shift Condition). The testing distribution Pte, the distribution of known classes
Pkc and the distribution of augmented classes Pac are under the class shift condition, if
Pte = θ · Pkc + (1 − θ) · Pac, (1) where θ ∈ [0, 1] is a certain mixture proportion.1
Class shift condition states that the testing distribution can be regarded as a mixture of those of known and augmented classes with a certain proportion θ, based on which we can evaluate classiﬁers’ risk over the testing distribution with labeled and unlabeled training data. 2.2 Convex Unbiased Risk Estimator
This part, we develop an unbiased risk estimator for the LAC problem under the class shift condition.
We ﬁrst introduce the notation conventions. The density function is denoted by the lowercase p, and the joint, conditional and marginal density functions are indicated by the subscripts XY , X|Y (Y |X) and X (Y ). For instance, pte
X (x) refers to the marginal density of the testing distribution over X .
OVR scheme. Suppose the joint testing distribution were available, the LAC problem would degener-ate to standard multi-class classiﬁcation, which can be then addressed by existing approaches. Among those approaches, we adopt the one-versus-rest (OVR) strategy, which enjoys sound theoretical guarantees [19] and nice practical performance [20]. The risk minimization is formulated as, min f1,...,fK+1
Rψ(f1, . . . , fK+1) = E(x,y)∼Pte (cid:104)
ψ(fy(x)) + (cid:88)K+1 k=1,k(cid:54)=y
ψ(−fk(x)) (cid:105)
, (2) where fk is the classiﬁer for the k-th class, k = 1, . . . , K; and fac is the classiﬁer for the augmented class. For simplicity, we substitute fac with fK+1 in the formulation. ψ : R (cid:55)→ [0, +∞) is a binary surrogate loss such as hinge loss. The OVR scheme predicts by f (x) = arg maxk∈{1,...,K,ac} fk(x).
Approximating the testing distribution. However, the joint testing distribution is unavailable in the training stage due to the absence of labeled instances from augmented classes. Fortunately, we show that given the mixture proportion θ, it can be approximated with the labeled and unlabeled data.
Under the class shift condition, the joint density of the testing distribution can be decomposed as
XY (x, y) (1)= θ · pkc pte
= θ · pkc
XY (x, y) + (1 − θ) · pac
XY (x, y) + 1(y = ac) · (1 − θ) · pac
XY (x, y)
X (x), (3)
XY (x, y) = 0 holds for all x ∈ X and y (cid:54)= ac.
XY (x, y) is accessible via the labeled data. The only unknown term is the second
X (x). Under the class shift condition, it can be where the last equality follows from the fact that pac
The ﬁrst part pkc part, the marginal density of the augmented class pac evaluated by separating the distribution of labeled data from unlabeled data as (1 − θ) · pac
X (x) = pte
X (x) − θ · pkc
X (x). (4)
Thus, by plugging (4) into (3), the testing distribution becomes attainable, and consequently, we can evaluate the OVR risk Rψ in the training stage through an equivalent risk RLAC. 1We redeﬁne all the distributions over the space X × Y, where pkc
XY (x, ac) = 0 for all x ∈ X 3
Proposition 1. Under the class shift condition, for measurable functions f1, . . . , fK, fac, we have
Rψ(f1, . . . , fK, fac) = RLAC(f1, . . . , fK, fac), where RLAC is deﬁned as,
RLAC = θ · E(x,y)∼Pkc [ψ(fy(x)) − ψ(−fy(x)) + ψ(−fac(x)) − ψ(fac(x))] (cid:88)K
+ Ex∼pte
X (x) (cid:104)
ψ(fac(x)) + (cid:105)
ψ(−fk(x))
. k=1 (5)
Remark 1. We can assess RLAC during training as the distribution of known classes Pkc and marginal testing distribution pte
X (x) can be estimated by labeled and unlabeled training data, respectively.
The remaining issue for the LAC risk RLAC is the non-convexity caused by terms −ψ(−fy(x)) and
−ψ(fac(x)), which are non-convex w.r.t the classiﬁers even with the convex binary surrogate loss ψ.
Inspired by studies [21, 22], we can eliminate the non-convexity by carefully choosing the surrogate loss satisfying ψ(z) − ψ(−z) = −z for all z ∈ R, and thereby RLAC enjoys a convex formulation
RLAC = θ · E(x,y)∼Pkc [fac(x) − fy(x)] + Ex∼pte
X (x) (cid:104)
ψ(fac(x)) + (cid:88)K k=1
ψ(−fk(x)) (cid:105)
. (6)
Many loss functions satisfy the above condition [22], such as logistic loss ψ(z) = log(1 + exp(−z)), square loss ψ(z) = (1 − z)2/4 and double hinge loss ψ(z) = max(−z, max(0, (1 − z)/2)). Since
LAC risk RLAC equals to the ideal OVR risk Rψ, its empirical estimator (cid:98)RLAC is unbiased over the testing distribution. We can thus perform the standard empirical risk minimization. Finally, we note that Proposition 1 can be generalized for arbitrary multiclass losses, if the convexity is not required, where more multiclass and binary losses can be used. We will take this as a future work. 2.3 Convex Unbiased Risk Estimator under Generalized Class Shift Condition
The class shift condition in Deﬁnition 1 models the appearance of augmented classes with the assumption that the distribution of known classes is identical to that in the testing stage. In real-world applications, however, the environments might be more complex, where the distribution of known classes could also shift. We consider a speciﬁc kind of class distribution change: in addition to the emerging augmented classes, the prior of each class pte
Y (y) varies from labeled data to testing data, while their conditional density remains the same, namely pte
X|Y (x|y) for all y ∈ [K].
To this end, we propose following generalized class shift condition to model such a case by further decomposing the distribution of known classes in the testing stage as a mixture of several components,
X|Y (x|y) = pkc
Pte = (cid:88)K k=1
θk te · Pk + (cid:18) 1 − (cid:88)K k=1 (cid:19)
θk te
· Pac, (7) where Pk is the distribution of the k-th known class whose marginal density equals to pkc te = pte
θk change on known classes, the generalized class shift condition recovers the vanilla version in (1).
X|Y (x|k), and
Y (k) is the prior of k-th known class in testing, for all k ∈ [K]. When there is no distribution
With the generalized class shift condition (7), following the similar argument in Section 2.2, we can evaluate the OVR risk for the testing distribution even if the prior of known classes has changed.
Proposition 2. Under the generalized class shift condition (7), by choosing the surrogate loss function satisfying ψ(z) − ψ(z) = −z for all z ∈ R, for measurable functions f1, . . . , fK, fac, we have Rψ(f1, . . . , fK, fac) = Rshif t
LAC (f1, . . . , fK, fac), where Rshif t
Rshif t te · E(x,y)∼Pk [fac(x) − fy(x)] + Ex∼pte
θk
LAC is deﬁned as, (cid:104) (cid:88)K
ψ(fac(x)) +
ψ(−fk(x)) (cid:88)K
LAC = (cid:105)
.
X (x) k=1 k=1
Proposition 2 implies that we can handle the augmented classes together with the distribution change on prior of known classes by empirically minimizing the risk Rshif t
LAC further decomposes the distribution of known classes into several components, it enjoys more ﬂexibility than
RLAC in evaluating the testing risk, yet requires more efforts in estimation of class prior θk te for each known class rather than mixture proportion θ only, which will be discussed next.
LAC . Note that since Rshif t 3 Approach
In this section, we develop two practical algorithms for the proposed EULAC approach to minimize the empirical version of the LAC risk RLAC (similar results can be extended for its generalization
Rshif t
LAC ). Meanwhile, we discuss how to estimate the mixture proportion θ and class prior θk te. 4
Kernel-based hypothesis space. We ﬁrst consider minimizing the empirical LAC risk (cid:98)RLAC in the reproducing kernel Hilbert space (RKHS) F associated to a PDS kernel κ : X × X (cid:55)→ R: min f1,...,fK ,fac∈F (cid:98)RLAC + λ (cid:16) (cid:88)K k=1 (cid:107)fk(cid:107)2
F + (cid:107)fac(cid:107)2
F (cid:17)
, where (cid:98)RLAC is the empirical approximation of the LAC risk (6) (cid:88)nl (cid:98)RLAC = 1 nu
According to the representer theorem [23], the optimal solution of (8) is provably in the form of (fac(xi) − fyi (xi)) +
ψ(fac(xi)) + (cid:88)nu i=1
ψ(−fk(xi)) (cid:88)K
θ nl k=1 i=1
. (cid:16) (cid:17) (8) (9) fk(·) = (cid:88) xi∈DL
αk i κ(·, xi) + (cid:88) xj ∈DU
αk j κ(·, xj), (10) where αk is the i-th coefﬁcient of the k-th classiﬁer. Plugging (10) into (8), we get a convex i optimization problem with respect to α, which can be solved efﬁciently. Since the risk estimator (cid:98)RLAC is assessed on the testing distribution directly, we can perform unbiased cross validation to select parameters. Then, after obtaining the binary classiﬁers f1, . . . , fK, fac, we follow the OVR rule to construct the ﬁnal predictor as f : X (cid:55)→ Y with f (x) = arg maxk∈{1,...,K,ac} fk(x).
Deep model. Our approach can be also implemented by deep neural networks. Since the deep models themselves are non-convex, we directly minimize the non-convex formulation of RLAC (5) by taking outputs of the deep model as OVR classiﬁers. However, as shown by Kiryo et al. [24], the direct minimization easily suffers from over-ﬁtting as the risk is not bounded from below by 0. To avoid the undesired phenomenon, we apply their proposed non-negative risk [24] to rectify the OVR scheme for training the deep model, whose effectiveness will be validated by experiments. More detailed elaborations for the rectiﬁed RLAC risk is presented in the full paper [25].
On the estimation of θ. Notice that minimizing (cid:98)RLAC requires estimating θ, which is known as the problem of Mixture Proportion Estimation (MPE) [26], where one aims to estimate the maximum proportion of distribution H in distribution F given their empirical observations. Many works have been devoted to developing theoretical foundations and efﬁcient algorithms [27, 17, 28, 29]. We employ the kernel mean embedding (KME) based algorithm proposed by Ramaswamy et al. [26], which guarantees that the estimator (cid:98)θ converges to true proportion θ in the rate of
O(1/(cid:112)min{nl, nu}) under the separability condition. Moreover, since the KME-based algorithm easily suffers from the curse of dimensionality in practice, inspired by the recent work [28], we further use a pre-trained model to reduce the dimensionality of original input to its probability outputs. We refer to the above estimator as KME-base, and the corresponding approach for LAC as EULAC-base.
Additionally, under the generalized class shift condition, we need more reﬁned estimations for each known class. Therefore, we use the above MPE estimator to estimate each class prior θk
LAC (2) via the labeled instances from the k-th known class and the unlabeled data, k ∈ [K]. We refer to such an estimator as KME-shift and the corresponding approach as EULAC-shift. Finally, we note that since the vanilla LAC can also be modeled with the generalized class shift condition, we can use KME-shift to estimate the mixture proportion (cid:98)θ by (cid:98)θ = (cid:80)K te. It turns out that KME-shift achieves comparable (even better) empirical performance with KME-base. te in Rshif t k=1 (cid:98)θk 4 Theoretical Analysis
In this section, we ﬁrst show the inﬁnite-sample consistency of the LAC risk RLAC. Then, we derive the generalization error bounds. All the proofs can be found in the full paper [25].
Inﬁnite-sample consistency. At ﬁrst, we show that the LAC risk RLAC is inﬁnite-sample consistent with the risk over the testing distribution with respect to 0-1 loss. Namely, by minimizing the expected risk of RLAC, we can get classiﬁers achieving the Bayes rule over the testing distribution.
Theorem 1. Under the class shift condition, suppose the surrogate loss ψ is convex, bounded below, differential, satisfying ψ(z) − ψ(−z) = −z and ψ(z) < ψ(−z) when z > 0, then for any (cid:15)1 > 0, there exists (cid:15)2 > 0 such that
RLAC(f1, . . . , fK, fac) ≤ R∗
LAC + (cid:15)2 =⇒ R(f ) ≤ R∗ + (cid:15)1 5
holds for all measurable functions f1, . . . , fK, fac and f (x) = arg maxk∈{1,...,K,ac} fk(x). Here,
LAC = minf1,...,fK ,fac RLAC(f1, . . . , fK, fac) and R∗ = minf R(f ) = E(x,y)∼Pte [1(f (x) (cid:54)=
R∗ y)] is the Bayes error over the testing distribution.
Theorem 1 follows from Proposition 1 and analysis in the seminal work of Zhang [19], who inves-tigates the consistency property of OVR risk in depth. Since the LAC risk RLAC is equivalent to the OVR risk Rψ, it is naturally inﬁnite-sample consistent. There are many loss functions satisfy assumptions in Theorem 1 such as the logistic loss ψ(z) = log(1 + exp(−z)) and the square loss
ψ(z) = (1 − z)2/4. In particular, we can obtain a more quantitative results for the square loss.
Theorem 2. Under the same condition of Theorem 1, when using ψ(z) = (1−z)2/4 as the surrogate loss function, we have R(f ) − R∗ ≤ 2(cid:0)RLAC(f1, . . . , fK, fac) − R∗ (cid:113) (cid:1).
LAC
Theorem 2 shows that the excess risk of RLAC upper bounds that of 0-1 loss. Thus, by minimizing the LAC risk RLAC, we can obtain well-behaved classiﬁers on the testing distribution w.r.t. 0-1 loss.
Remark 2. Theorems 1 and 2 show the consistency for RLAC under class shift condition. Similar results can be easily obtained for Rshif t
LAC with the generalized class shift condition, due to the equivalence of Rshif t
LAC and the OVR risk, even when prior of known classes have changed.
Finite-sample generalization error bound. We establish the generalization error bound for the pro-posed approach in this part. Since the approach actually minimizes the empirical risk estimator (cid:98)RLAC with a regularization term of the RKHS F, it is equivalent to investigate the generalization ability of classiﬁers f1, . . . , fK, fac in the kernel-based hypothesis set F = {x (cid:55)→ (cid:104)w, Φ(x)(cid:105) | (cid:107)w(cid:107)F ≤ Λ}, where Φ : x (cid:55)→ F is a feature mapping associated with the positive deﬁnite symmetric kernel κ, and w is an element in the RKHS F. We have the following generalization error bound.
Theorem 3. Assume that κ(x, x) ≤ r2 holds for all x ∈ X and the surrogate loss function ψ is bounded by Bψ ≥ 0 and is L-Lipschitz continuous.2 Then, for any δ > 0, with probability at least 1 − δ over the draw of labeled samples DL of size nl from the distribution of known classes Pkc and unlabeled samples DU of size nu from pte
X (x), the following holds for all f1, . . . , fK, fac ∈ F,
RLAC(f1, . . . , fK, fac) − (cid:98)RLAC(f1, . . . , fK, fac)
≤ 2(K + 1)Λr
√ nl
+ 6Λr (cid:115) 2 log(4/δ) nl
+ 2(K + 1)LΛr nu
√
+ 3(K + 1)Bψ (cid:115) log(4/δ) nu
.
Based on Theorem 3, by the standard argument [30, 31], we can obtain the estimation error bound.
Theorem 4. Under the same assumptions of Theorem 3 and let (cid:98)f1, . . . , (cid:98)fK, (cid:98)fac be the optimal solution of the optimization problem (8) with certain λ > 0, with high probability, we have (cid:19)
RLAC(f1, . . . , fK, fac) ≤ O
RLAC( (cid:98)f1, . . . , (cid:98)fK, (cid:98)fac) − inf f ∈F where f denotes (f1, . . . , fK, fac) and F = {f | f1, . . . , fK, fac ∈ F, (cid:80)K
λ}.
The parameter cλ > 0 is a constant related to λ in (8). We use the O-notation to keep the dependence on nu, nl and K only, where the full expression can be found in the full paper.
Remark 3. Theorem 3 and Theorem 4 show that, the estimation error of the trained classiﬁers decreases with a growing number of labeled and unlabeled data, which theoretically justiﬁes the effecacy of our approach in exploiting unlabeled data. Experiments also validate the same tendency. k=1 (cid:107)fk(cid:107)2
F+(cid:107)fac(cid:107)2
F ≤ c2
+
, (cid:18) K + 1
√ nl
K + 1
√ nu
Overview of theoretical results. Recall that the goal of the LAC problem is to obtain classiﬁers that approach Bayes rule over the testing distribution, so we need to minimize the excess risk (cid:1) − R∗. According to the consistency guarantee presented in Theorem 1,
R(cid:0) argmaxk∈{1,...,K,ac} fk it sufﬁces to minimize the excess risk RLAC(f ) − R∗
LAC, which can be further decomposed into the estimation error and the approximation error as follows,
RLAC(f ) − R∗
LAC = RLAC(f ) − inf f ∈F RLAC(f ) (cid:125) (cid:123)(cid:122) estimation error (cid:124)
+ inf f ∈F RLAC(f ) − R∗ (cid:124) (cid:123)(cid:122) approximation error
.
LAC (cid:125) 2Common surrogate loss functions satisfy these conditions, such as logistic loss, exp loss and square loss. 6
Theorem 4 shows that with an increasing number of labeled and unlabeled data, the excess risk converges to the irreducible approximation error, which measures how well the hypothesis set approximates the Bayes rule and is generally not accessible for learning algorithms [31]. Thus, the consistency and excess risk bounds theoretically justify the effectiveness of our approach. 5