Abstract
Global context is crucial for 3D point cloud scene understanding tasks. In this work, we extend the contextual encoding layer that was originally designed for 2D tasks to 3D point cloud scenarios. The encoding layer learns a set of code words in feature space of the 3D point cloud to characterize the global semantic context, and then based on these code words, the method learns a global contextual descriptor to reweight the feature maps accordingly. Moreover, compared to 2D scenarios, data sparsity becomes a major issue in 3D point cloud scenarios, and the performance of contextual encoding quickly saturates when the number of code words increases.
To mitigate this problem, we further propose a group contextual encoding method, which divides the channel into groups and then performs encoding on group-divided feature vectors. This method facilitates learning of global context in grouped subspace for 3D point clouds. We evaluate the effectiveness and generalizability of our method on three widely-studied 3D point cloud tasks. Experimental results have shown that the proposed method outperformed the VoteNet remarkably with 3 mAP on the benchmark of SUN-RGBD, with the metrics of mAP@0.25, and a much greater margin of 6.57 mAP on ScanNet with the metrics of mAP@0.5.
Compared to the baseline of PointNet++, the proposed method leads to an accuracy of 86%, outperforming the baseline by 1.5%. 1

Introduction
Object detection in 3D point clouds is a challenging problem because it requires localizing and classifying objects from sparse and irregularly-distributed points. Conventional methods such as
PointNet++ [16] and ASIS-PointNet++ [18] were proposed to solve this problem, which can learn the local features hierarchically. However, due to lack of global context modeling, the performance of PointNet [15] and PointNet++ [16] is limited. To resolve this issue, LG-PointNet++ [21] and
PointWeb [27] proposed to model the global context by computing the pair-wise relations of points.
However, their complexity is a quadratic function of the number of points, which is prohibitively expensive when dealing with large-scale point clouds.
On the other hand, for 2D Semantic Segmentation, Zhang et al., [24] proposed a contextual encoding layer to learn a descriptor to model the global context by encoding features with a dictionary with only a few code words and then aggregating the encoded information. In this paper, we extend the encoding approach to 3D point cloud, in which a dictionary containing only a few code words is learned to characterize the global semantic context, and then based on these code words, the method learns a global contextual descriptor to reweight the feature maps accordingly. Since the number of code words is constrained and much smaller than the number of data points, this method is computationally efﬁcient. However, directly applying the encoding layer to 3D point clouds is inadequate. Compared to 2D scenarios, data sparsity becomes a major issue in 3D point cloud scenarios, and the performance of global contextual encoding quickly saturates when the number of
∗This work is done in JD AI Research
†Corresponding authors: shiboxin@pku.edu.cn, xiaodong.he@jd.com 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
code words increases. To mitigate this problem, we further propose a Group Contextual Encoding (GCE) method, which divides the channel into groups and then performs encoding on group-divided feature vectors, to facilitate effective learning of global context in grouped subspaces for 3D point clouds.
We evaluate the effectiveness and generalizability of GCE-based method on three widely-studied 3D point cloud tasks. Experimental results have shown that the proposed method outperforms the
VoteNet [13] with 3 mAP on the benchmark of SUN-RGBD [17], by the evaluation metrics of mAP@0.25, and a much greater margin of 6.57 mAP on a more challenging dataset of ScanNet
[13], by a stricter evaluation metrics of mAP@0.5. We also demonstrate that our method can be generalized to other tasks like voxel labeling. Compared to the baseline of PointNet++ [16], the GCE layer leads to an accuracy of 86%, outperforming the baseline by 1.5%, which is the state-of-the-art performance on this benchmark.
To summarize, this work makes the contributions in the following aspects:
• We extend the contextual encoding layer to 3D point cloud scenarios to better model the global contextual information efﬁciently.
• We propose a group contextual encoding method dividing and encoding group-divided feature vectors to effectively learn global context in grouped subspaces for 3D point clouds.
• The proposed method shows better effectiveness and generalizability on multiple 3D benchmarks with state-of-the-art performance.
The source code3 has been released to facilitate the reproduction of our results. 2