Abstract
The work studies how node-to-node communications over an Erd˝os-Rényi random network inﬂuence distributed online convex optimization, which is vital in solving large-scale machine learning in antagonistic or changing environments. At per step, each node (computing unit) makes a local decision, experiences a loss evaluated with a convex function, and communicates the decision with other nodes over a network. The node-to-node communications are described by the Erd˝os-Rényi rule, where independently each link takes place with a probability p over a prescribed connected graph. The objective is to minimize the system-wide loss accumulated over a ﬁnite time horizon. We consider standard distributed gradient descents with full gradients, one-point bandits and two-points bandits for convex and strongly convex losses, respectively. We establish how the regret bounds scale with respect to time horizon T , network size N , decision dimension d, and an algebraic network connectivity. The regret bounds scaling with respect to T match those obtained by state-of-the-art algorithms and fundamental limits in the corresponding centralized
√ online optimization problems, e.g., O(
T ) and O(ln(T )) regrets are established for convex and strongly convex losses with full gradient feedback and two-points information, respectively. For classical Erd˝os-Rényi networks over all-to-all possi-ble node communications, the regret scalings with respect to the probability p are analytically established, based on which the tradeoff between the communication overhead and computation accuracy is clearly demonstrated. Numerical studies have validated the theoretical ﬁndings. 1

Introduction
The online convex optimization paradigm has become a central and canonical solution for machine learning where data is generated sequentially over time, e.g., online routing, ad. selection for search engines, and spam ﬁltering ([1–4]). Instead of attempting to model the dynamical data, which is often not possible due to fundamental complexity and efﬁciency challenges, an online convex optimization framework adapts decisions along with the arrival of unforeseen data. After committing to a decision, a convex loss is incurred that is unknown beforehand and may vary over time. There are two basic types of online convex optimization settings in terms of the knowledge that the learner possesses
∗The ﬁrst two authors contributed equally to the work. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
over the loss: with the full gradient feedback, the learner has access to a gradient oracle of the loss function; with the bandit feedback, the learner only observes the losses at points around the decisions.
The goal of the learner is then to minimize its regret by adapting the decisions along the streaming data, measured by the difference between the cumulative loss of online decisions and the loss of the best decision chosen in hindsight. How the regret scales in a ﬁnite time horizon T with problem parameters is a central theme in studies of different algorithms. The gradient descent algorithm was proved to guarantee regret bounds O(
T ) and O(ln(T )) for convex and strongly convex loss functions ([5, 6]), respectively, which were later shown to be minimax optimal ([7, 8]).
√
Distributed online convex optimization ([9, 10]) is preferable in learning over networks when the streaming data are collected at multiple nodes (e.g., sensor networks, smart phones or personal wearable devices). In distributed online convex optimization, the nodes commit to local decisions and then experience local losses that are unknown to the other nodes in the network. It turnes out that, by properly sharing information with neighbors, nodes can collaboratively minimize the accumulated system-wide loss and achieve regret bounds comparable to the centralized case. 1.1 The Framework
Consider N nodes indexed in the set V = {1, . . . , N }. At time t, node i ∈ V makes a decision xi,t ∈ K with K ∈ Rd being a convex set. As a learner, each node can have the following two types of loss information: (i) In the full information feedback, a loss function fi,t is revealed to node i at time t; (ii) In the bandit feedback, the function value of fi,t at one or two points around xi,t is revealed to node i at time t.
The network communication structure is described by a connected and undirected graph G = (V, E), which serves as a collection of all possible node-to-node communication channels. At time t, an
Erd˝os-Rényi graph Gt = (V, Et) is generated over the prescribed graph G, where independently with time and other links, {i, j} ∈ Et with a probability 0 < p < 1 for all {i, j} ∈ E. Note that in classical Erd˝os-Rényi graphs [11], G is a complete graph. Here we allow G to be any connected graph, for the sake of presenting a general online learning framework over networks, when all-to-all communications might not exist in practice. Some realizations of classical Erd˝os-Rényi graphs with
N = 300 and p = 0.006 are shown as follows: (a) Gt at t = 1 (b) Gt at t = 2 (c) Gt at t = 3 (d) Gt at t = 4
The objective is to design distributed online decision learning algorithms so that each node i identiﬁes the decision xi,t, t = 1, . . . , T to minimize the accumulated system-wide loss (cid:80)T i=1 fi,t(x).
When choosing xi,t+1, node i can utilize its previous local decisions xi,k, k ≤ t and revealed losses fi,k, k ≤ t, along with the information received from its neighbors over Gt. The performance of a distributed learning algorithm is captured by the regrets at various nodes compared with the best (cid:80)T
ﬁxed decision in the hindsight x∗ = argminx∈K fi,t(x). The regret of node j ∈ V is thus (cid:80)N t=1 t=1
N (cid:80) i=1
Reg(j, T ) =
T (cid:88)
N (cid:88) t=1 i=1 fi,t(xj,t) −
T (cid:88)
N (cid:88) t=1 i=1 fi,t(x∗). (1)
The motivation to study online convex optimization over Erd˝os-Rényi graphs is as follows. Firstly, the distributed online learning can happen in Internet of things or social networks, while the Erd˝os-Rényi 2
graph is one of the fundamental models for network communications or social interactions (see
[12, 13]), where information channels are represented by independent links that are either on with a probability p or off with a probability 1−p. Therefore, the performance of online convex optimization over Erd˝os-Rényi graphs would serve as a benchmark for online learning over practical networks.
Secondly, in the dense network, we tend to avoid communicating along each edge per iteration to decrease communication, for which Erd˝os-Rényi graphs can be viewed as a strategic way to organize node-to-node communications. As such, the probability p becomes a design parameter for tuning the trade-off between the communication overhead and the computation accuracy. It has been found that
Erd˝os-Rényi random graphs can outperform fully connected graphs in some distributed training tasks ([14]). Finally, Erd˝os-Rényi graphs allow us to intuitively have a deep theoretical characterization of how the graph topology and connectivity probability inﬂuence the network regret of online convex optimization, and paves the way to study distributed online convex optimization over other complex graph models. 1.2 Main Results
We consider online distributed gradient descents under Erd˝os-Rényi graphs, and establish the regret bounds explicitly in term of time horizon T , the underlying graph G, the probability p, and the decision complexity d.
Algorithms: The node adapts its decision with gradient descents and local averaging over Erd˝os-Rényi graphs. In the full information case, the local gradient ∇fi,t(xi,t) is utilized ﬁrst, and then the decision is made by averaging across its neighboring information and projecting onto a feasible set. When the nodes can only observe loss function values, the one-point bandit or two-points bandit around the current decision is used to get a randomized approximation of the gradient.
√
Regret Bounds: In the full gradient case, the algorithm achieves the regrets O(
T ) and O(ln(T )) for convex and strongly convex losses, respectively. The bounds O(d1/2T 3/4) (convex) and
O(d2/3T 2/3 ln1/3(T )) (strongly convex) are achieved in the one-point bandit case, while the bounds
T ) and O(d2 ln(T )) in the two-points bandit case. It is shown that the regrets are improved to O(d scale with network size N by a magnitude of N c where c takes 3 6 , depending on the convexity or strong convexity of the losses, and the information feedback type. In term of time horizon T , the regret scalings match those obtained by state-of-the-art algorithms in the centralized online convex optimization, and distributed online convex optimization with deterministic communications. In addition, for classical large-scale Erd˝os-Rényi networks over all-to-all possible node communications, the regret bounds scale with the probability p by a magnitude of pc where c = −1, −1/2, or −1/3.
The regret bounds along with the communication complexity over classical Erd˝os-Rényi graphs are shown in Table 1, while the communication complexity is measured by the expected rounds of node-to-node communications taken by each node over a time horizon T. 4 , or 7 2 , 5
√
Regrets for convex losses
Settings
Full information
One-point bandit
Two-points bandit
Table 1: Regret bounds and communication complexity over classical Erd˝os-Rényi graphs
Communication Complexity pN T pN T pN T
O(p−1/2d1/2N 5/4T 3/4) O(p−1/3d2/3N 7/6T 2/3 ln1/3(T ))
Regrets for strongly convex losses
O(p−1N 3/2 ln(T ))
O(p−1d2N 3/2 ln(T ))
O(p−1dN 3/2
O(p−1N 3/2
T )
T )
√
√ 1.3