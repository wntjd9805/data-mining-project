Abstract
Motivated by the problem of sampling from ill-conditioned log-concave distribu-tions, we give a clean non-asymptotic convergence analysis of mirror-Langevin diffusions as introduced in [Zha+20]. As a special case of this framework, we propose a class of diffusions called Newton-Langevin diffusions and prove that they converge to stationarity exponentially fast with a rate which not only is dimension-free, but also has no dependence on the target distribution. We give an application of this result to the problem of sampling from the uniform distribution on a convex body using a strategy inspired by interior-point methods. Our general approach fol-lows the recent trend of linking sampling and optimization and highlights the role of the chi-squared divergence. In particular, it yields new results on the convergence of the vanilla Langevin diffusion in Wasserstein distance. 1

Introduction
Sampling from a target distribution is a central task in statistics and machine learning with applications ranging from Bayesian inference [RC04; DM+19] to deep generative models [Goo+14]. Owing to a ﬁrm mathematical grounding in the theory of Markov processes [MT09], as well as its great versatility, Markov Chain Monte Carlo (MCMC) has emerged as a fundamental sampling paradigm.
While traditional theoretical analyses are anchored in the asymptotic framework of ergodic theory, this work focuses on ﬁnite-time results that better witness the practical performance of MCMC for high-dimensional problems arising in machine learning.
This perspective parallels an earlier phenomenon in the much better understood ﬁeld of optimiza-tion where convexity has played a preponderant role for both theoretical and methodological ad-vances [Nes04; Bub15]. In fact, sampling and optimization share deep conceptual connections that have contributed to a renewed understanding of the theoretical properties of sampling algo-rithms [Dal17a; Wib18] building on the seminal work of Jordan, Kinderlehrer and Otto [JKO98].
We consider the following canonical sampling problem. Let π be a log-concave probability measure over Rd so that π has density equal to e−V , where the potential V : Rd → R is convex. Throughout this paper, we also assume that V is twice continuously differentiable for convenience, though many of our results hold under weaker conditions.
Most MCMC algorithms designed for this problem are based on the Langevin diffusion (LD), that is the solution (Xt)t≥0 to the stochastic differential equation (SDE) dXt = −∇V (Xt) dt +
√ 2 dBt, (LD) 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
with (Bt)t≥0 a standard Brownian motion in Rd. Indeed, π is the unique invariant distribution of (LD) and suitable discretizations result in algorithms that can be implemented when V is known only up to an additive constant, which is crucial for applications in Bayesian statistics and machine learning.
A ﬁrst connection between sampling from log-concave measures and optimizing convex functions is easily seen from (LD): omitting the Brownian motion term yields the gradient ﬂow ˙xt = −∇V (xt), which results in the celebrated gradient descent algorithm when discretized in time [Dal17a; Dal17b].
There is, however, a much deeper connection involving the distribution of Xt rather than Xt itself, and this latter connection has been substantially more fruitful: the marginal distribution of a Langevin diffusion process (Xt)t≥0 evolves according to a gradient ﬂow, over the Wasserstein space of proba-bility measures, that minimizes the Kullback-Leibler (KL) divergence DKL(· (cid:107) π) [JKO98; AGS08;
Vil09]. This point of view has led not only to a better theoretical understanding of the Langevin diffusion [Ber18; CB18; Wib18; DMM19; VW19] but it has also inspired new sampling algorithms based on classical optimization algorithms, such as proximal/splitting methods [Ber18; Wib18;
Wib19; SKL20], mirror descent [Hsi+18; Zha+20], Nesterov’s accelerated gradient descent [Che+18;
Ma+19; DR20], and Newton methods [Mar+12; Sim+16; WL20].
Our contributions. This paper further exploits the optimization perspective on sampling by es-tablishing a theoretical framework for a large class of stochastic processes called mirror-Langevin diffusions (MLD) introduced in [Zha+20]. These processes correspond to alternative optimization schemes that minimize the KL divergence over the Wasserstein space by changing its geometry. They show better dependence in key parameters such as the condition number and the dimension.
Our theoretical analysis is streamlined by a technical device which is unexpected at ﬁrst glance, yet proves to be elegant and effective: we track the progress of these schemes not by measuring the objective function itself, the KL divergence, but rather by measuring the chi-squared divergence to the target distribution π as a surrogate. This perspective highlights the central role of mirror Poincar´e inequalities (MP) as sufﬁcient conditions for exponentially fast convergence of the mirror-Langevin diffusion to stationarity in chi-squared divergence, which readily yields convergence in other well-known information divergences, such as the Kullback-Leibler divergence, the Hellinger distance, and the total variation distance [Tsy09, §2.4].
We also specialize our results to the case when the mirror map equals the potential V . This can be understood as the sam-pling analogue of Newton’s method, and we therefore call it the Newton-Langevin diffusion (NLD). In this case, the mirror
Poincar´e inequality translates into the Brascamp-Lieb inequal-ity which automatically holds when V is twice-differentiable and strictly convex. In turn, it readily implies exponential con-vergence of the Newton-Langevin diffusion (Corollary 1) and can be used for approximate sampling even when the second derivative of V vanishes (Corollary 2). Strikingly, the rate of convergence has no dependence on π or on the dimension d and, in particular, is robust to cases where ∇2V is arbitrarily close to zero. This scale-invariant convergence parallels that of
Newton’s method in convex optimization and is the ﬁrst result of this kind for sampling.
This invariance property is useful for approximately sam-pling from the uniform distribution over a convex body C, which has been well-studied in the computer science litera-ture [FKP94; KLS95; LV07]. By taking the target distribution
π ∝ exp(−βV ), where V is any strictly convex barrier func-tion, and β, the inverse temperature parameter, is taken to be small (depending on the target accuracy), we can use the
Newton-Langevin diffusion, much in the spirit of interior point methods (as promoted by [LTV20]), to output a sample which is approximately uniformly distributed on C; see Corollary 3.
Figure 1: Samples from the poste-rior distribution of a 2D Bayesian logistic regression model using the Newton-Langevin Algorithm (NLA), the Unadjusted Langevin
Algorithm (ULA), and the Tamed
Unadjusted Langevin Algorithm (TULA) [Bro+19]. For details, see
Section E.2.
Throughout this paper, we work exclusively in the setting of continuous-time diffusions such as (LD).
We refer to the works [DM15; Dal17a; Dal17b; RRT17; CB18; Wib18; DK19; DMM19; DRK19;
Mou+19; VW19] for discretization error bounds, and leave this question open for future works. 2