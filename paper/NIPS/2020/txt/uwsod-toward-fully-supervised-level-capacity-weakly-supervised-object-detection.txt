Abstract
Weakly supervised object detection (WSOD) has attracted extensive research attention due to its great ﬂexibility of exploiting large-scale dataset with only image-level annotations for detector training. Despite its great advance in recent years, WSOD still suffers limited performance, which is far below that of fully supervised object detection (FSOD). As most WSOD methods depend on object proposal algorithms to generate candidate regions and are also confronted with challenges like low-quality predicted bounding boxes and large scale variation. In this paper, we propose a uniﬁed WSOD framework, termed UWSOD, to develop a high-capacity general detection model with only image-level labels, which is self-contained and does not require external modules or additional supervision. To this end, we exploit three important components, i.e., object proposal generation, bounding-box ﬁne-tuning and scale-invariant features. First, we propose an anchor-based self-supervised proposal generator to hypothesize object locations, which is trained end-to-end with supervision created by UWSOD for both objectness classiﬁcation and regression. Second, we develop a step-wise bounding-box ﬁne-tuning to reﬁne both detection scores and coordinates by progressively select high-conﬁdence object proposals as positive samples, which bootstraps the quality of predicted bounding boxes. Third, we construct a multi-rate resampling pyramid to aggregate multi-scale contextual information, which is the ﬁrst in-network feature hierarchy to handle scale variation in WSOD. Extensive experiments on PASCAL
VOC and MS COCO show that the proposed UWSOD achieves competitive results with the state-of-the-art WSOD methods while not requiring external modules or additional supervision. Moreover, the upper-bound performance of UWSOD with class-agnostic ground-truth bounding boxes approaches Faster R-CNN, which demonstrates UWSOD has fully-supervised-level capacity. The code is available at: https://github.com/shenyunhang/UWSOD. 1

Introduction
Different from fully supervised object detection (FSOD) [1–4] that requires bounding-box-level annotations, weakly supervised object detection (WSOD) [5–8] only needs image-level labels, which indicate the presence or absence of an object category. More recently, WSOD has attracted extensive attention to reducing the manual labelling effort to learn detectors. Unfortunately, due to the lack of
∗Corresponding author. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
Figure 1: The overall ﬂowchart of the proposed UWSOD. The full-image scale-invariant feature maps are ﬁrst computed. Then object proposal generation provides candidate boxes to extract proposal features in RoIPool layer. Finally, the object mining phase outputs initial detection scores, and bounding-box ﬁne-tuning phase further reﬁnes both scores and coordinates of proposals. instance-level annotations, WSOD is still challenging to obtain satisfactory performance. Therefore, there is still a huge performance gap between WSOD and FSOD methods.
The recent widely-used paradigm for WSOD is a two-phase learning procedure, i.e., object mining and instance reﬁnement. In the ﬁrst phase, multiple instance learning is employed to mine object from a set of candidate regions generated by object proposal algorithms, e.g., selective search [9] and edge boxes [10]. Then multiple parallel branches of instance reﬁnement are trained to reﬁne bounding boxes by using the preceding predictions as supervision. Although the above paradigm has achieved promising results, there still exist three major challenges: First, object proposal algorithms are adopted as external modules independent of the detectors. Such a multi-stage system hurts the detection accuracy and efﬁciency. Recent attempts in [11–13] learn to generate object proposals for WSOD. However, those methods are still not in an end-to-end fashion and require traditional object proposals [9, 10], motion segmentation [14] and additional video dataset [15, 16]. Second, the predicted bounding boxes may not cover object well, as they heavily relies on the quality of candidate boxes generated by object proposal algorithms, which limits further improvement with large margins. One way to reduce mislocalizations is to using bounding-box regression [17–20].
However, methods in [17–19] require super-pixel evidence and additional supervision to ﬁne-tune bounding boxes, and regression module in [20] failed to consider the trade-off between the precision and recall requirements in different branches of instance reﬁnement. Third, existing WSOD methods use multi-scale image pyramids [21] to remedy the scale-variation problem. However, they neglect the in-network feature hierarchy to handle large scale variations. And the increase of inference time and memory consumption makes the image pyramid infeasible for practical applications.
In this paper, we propose a uniﬁed WSOD framework, termed UWSOD, to develop a high-capacity general detection model with only image-level labels, which is self-contained and does not require external modules or additional supervision. In particular, we exploit three important components, i.e., object proposal generation, bounding-box ﬁne-tuning and scale-invariant features to address above challenges, as illustrated in Fig. 1. First, we propose an anchor-based self-supervised object proposal generator (SSOPG) to hypothesize object locations, which is trained end-to-end with supervision created by UWSOD for both objectness classiﬁcation and regression. Second, to reduce mislocaliza-tions, we propose a step-wise bounding-box ﬁne-tuning (SWBBFT) to reﬁne both detection scores and coordinates by progressively select high-conﬁdence object proposals as positive samples, which bootstraps the quality of predicted bounding boxes. Third, we construct a multi-rate resampling pyramid (MRRP) to aggregate multi-scale contextual information, which is the ﬁrst in-network feature hierarchy to handle scale variation in WSOD. Different to common FSOD that attach new parameter to build feature pyramids [22], MRRP does not need to learn new parameters and avoids over-ﬁtting by sharing the same parameters of pre-trained backbones.
The contributions of this work are concluded as follows:
• We propose a uniﬁed weakly supervised object detection (UWSOD) framework, which is self-contained and does not require external modules or additional supervision to develop a high-capacity general detection model with only image-level labels.
• An anchor-based self-supervised proposal generator is proposed to hypothesize candidate object locations, which is end-to-end trainable with supervision created by UWSOD.
• We propose a step-wise bounding-box ﬁne-tuning to reﬁne both detection scores and coordinates progressively, which aims to bootstrap the quality of predicted bounding boxes. 2
• A multi-rates resampling pyramid is constructed to aggregate multi-scale contextual infor-mation, which is the ﬁrst in-network feature hierarchy to handle scale variation in WSOD.
Extensive experiments on PASCAL VOC and MS COCO show that the proposed UWSOD achieves competitive results with the state-of-the-art methods while not requiring external modules or additional supervision. A crucial property of our model is that even with class-agnostic ground-truth bounding boxes, the upper-bound performance of UWSOD approach Faster R-CNN [2], thus having fully-supervised-level capacity. 2