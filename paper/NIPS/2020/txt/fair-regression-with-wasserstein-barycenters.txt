Abstract
We study the problem of learning a real-valued function that satisﬁes the Demo-graphic Parity constraint. It demands the distribution of the predicted output to be independent of the sensitive attribute. We consider the case that the sensitive attribute is available for prediction. We establish a connection between fair re-gression and optimal transport theory, based on which we derive a close form expression for the optimal fair predictor. Speciﬁcally, we show that the distribution of this optimum is the Wasserstein barycenter of the distributions induced by the standard regression function on the sensitive groups. This result offers an intuitive interpretation of the optimal fair prediction and suggests a simple post-processing algorithm to achieve fairness. We establish risk and distribution-free fairness guar-antees for this procedure. Numerical experiments indicate that our method is very effective in learning fair models, with a relative increase in error rate that is inferior to the relative gain in fairness. 1

Introduction
A central goal of algorithmic fairness is to ensure that sensitive information does not “unfairly” inﬂuence the outcomes of learning algorithms. For example, if we wish to predict the salary of an applicant or the grade of a university student, we would like the algorithm to not unfairly use additional sensitive information such as gender or race. Since today’s real-life datasets often contain discriminatory bias, standard machine learning methods behave unfairly. Therefore, a substantial effort is being devoted in the ﬁeld to designing methods that satisfy “fairness” requirements, while still optimizing prediction performance, see for example [5, 10, 13, 16, 18, 21, 23, 25, 26, 28, 32, 45– 47, 49] and references therein.
In this paper we study the problem of learning a real-valued regression function which among those complying with the Demographic Parity fairness constraint, minimizes the mean squared error.
Demographic Parity requires the probability distribution of the predicted output to be independent of the sensitive attribute and has been used extensively in the literature, both in the context of classiﬁcation and regression [1, 12, 20, 24, 34]. In this paper we consider the case that the sensitive
∗evgenii.chzhen@universite-paris-saclay.fr 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
attribute is available for prediction. Our principal result is to show that the distribution of the optimal fair predictor is the solution of a Wasserstein barycenter problem between the distributions induced by the unfair regression function on the sensitive groups. This result builds a bridge between fair regression and optimal transport, [see e.g., 38, 41].
We illustrate our result with an example. Assume that X represents a candidate’s skills, S is a binary attribute representing two groups of the population (e.g., majority or minority), and Y is the current market salary. Let f ∗(x, s) = E[Y
X=x, S=s] be the regression function, that is, the
| optimal prediction of the salary currently in the market for candidate (x, s). Due to bias present in the underlying data distribution, the induced distribution of market salary predicted by f ∗ varies across the two groups. We show that the optimal fair prediction g∗ transforms the regression function f ∗ as g∗(x, s) = psf ∗(x, s) + (1 ps)t∗(x, s) ,
− where ps is the frequency of group s and the correction t∗(x, s) is determined so that the ranking
S = s for group s (e.g., minority) is the same as the of f ∗(x, s) relative to the distribution of X
= s (e.g., majority). We elaborate on ranking of t∗(x, s) relative to the distribution of the group s(cid:48) this example after Theorem 2.3 and in Figure 1. The above expression of the optimal fair predictor naturally suggests a simple post-processing estimation procedure, where we ﬁrst estimate f ∗ and then transform it to get an estimator of g∗. Importantly, the transformation step involves only unlabeled data since it requires estimation of cumulative distribution functions.
|
Contributions and organization.
In summary we make the following contributions. First, in
Section 2 we derive the expression for the optimal function which minimizes the squared risk under Demographic Parity constraints (Theorem 2.3). This result establishes a connection between fair regression and the problem of Wasserstein barycenters, which allows to develop an intuitive interpretation of the optimal fair predictor. Second, based on the above result, in Section 3 we propose a post-processing procedure that can be applied on top of any off-the-shelf estimator for the regression function, in order to transform it into a fair one. Third, in Section 4 we show that this post-processing procedure yields a fair prediction independently from the base estimator and the underlying distribution (Proposition 4.1). Moreover, ﬁnite sample risk guarantees are derived under additional assumptions on the data distribution provided that the base estimator is accurate (Theorem 4.4). Finally, Section 5 presents a numerical comparison of the proposed method w.r.t. the state-of-the-art.