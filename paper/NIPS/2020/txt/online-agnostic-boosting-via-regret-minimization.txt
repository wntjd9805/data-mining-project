Abstract
Boosting is a widely used machine learning approach based on the idea of aggregat-ing weak learning rules. While in statistical learning numerous boosting methods exist both in the realizable and agnostic settings, in online learning they exist only in the realizable case. In this work we provide the ﬁrst agnostic online boosting algorithm; that is, given a weak learner with only marginally-better-than-trivial regret guarantees, our algorithm boosts it to a strong learner with sublinear regret.
Our algorithm is based on an abstract (and simple) reduction to online convex optimization, which efﬁciently converts an arbitrary online convex optimizer to a boosting algorithm. Moreover, this reduction extends to the statistical as well as the online realizable settings, thus unifying the 4 cases of statistical/online and agnostic/realizable boosting. 1

Introduction
Boosting is a fundamental methodology in machine learning that can boost the accuracy of weak learning rules into a strong one. Boosting was ﬁrst studied in the context of (realizable) PAC learning in a line of seminal works which include the celebrated Adaboost algorithm, as well an many other algorithms with various applications (see e.g. [29, 33, 17, 19]). It was later adapted to the agnostic
PAC setting and was extensively studied in this context as well [7, 31, 21, 27, 30, 26, 28, 16, 13, 18].
More recently, [14] and [9] studied boosting in the context of online prediction and derived boosting algorithms in the realizable setting (a.k.a. mistake-bound model).
In this work we study agnostic boosting in the online setting: let H be a class of experts and assume we have oracle access to a weak online learner for H with a non-trivial (yet far from desired) regret guarantee. The goal is to convert it into a strong online learner for H that exhibits vanishing regret.
Why online agnostic boosting? The setting of online realizable boosting poses a restriction on the possible input sequences: there must be an expert that attains near-zero mistake-bound on the input sequence. This is a non-standard assumption in online learning. In contrast, in the online agnostic setting we consider, there is no restriction on the input sequence and it can be chosen adversarially.
∗The research was done while author was co-afﬁliated with Google AI Princeton. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
Applications of online agnostic boosting. Apart from being a fundamental question in a well-studied learning setting, let us mention a few concrete incentives to study online agnostic boosting:
• Differential privacy and online learning: A recent line of work revealed deep connections between online learning and differentially private learning [5, 1, 6, 10, 32, 25, 22, 11]. In fact, these two notions are equivalent in the sense that a class H can be PAC learned by a differentially private algorithm if and only if it can be learned in the online setting with vanishing regret [6, 11]. However, the above equivalence is only known to hold from an information theoretic perspective, and deriving efﬁcient reductions between online and private learning is an open problem [32]. The only case where an efﬁcient reduction is known to exist is in converting a pure private learner to an online learner in the realizable setting [22]. This reduction relies heavily on the realizable online boosting algorithm by [9].
Moreover, the derivation of an agnostic online boosting algorithm is posed by [22] as an open problem towards extending their reduction to the agnostic setting.
• Time series prediction and online control: Recent machine learning literature considered the problem of controlling a dynamical system from the lens of online learning and regret minimization, see e.g. [3, 4, 24] and referenced work therein. The online learning approach also gave rise to the ﬁrst boosting methods in this context [2], and demonstrates the potential impact of boosting in the online setting. Thus, the current work aims at continuing the development of the boosting methodology in online learning, starting from the basic setting of learning from expert advice. 1.1 Main results
The weak learning assumption.
In this paper we follow the same formulation as [28] used for boosting in the agnostic statistical setting. Towards this end, it is convenient to measure the performance of online learners using gain rather than loss: let (x1, y1) . . . (xT , yT ) ∈ X × {±1} be an (adversarial and adaptive) input sequence of examples presented to an online learning algorithm
A; that is, in each iteration t = 1 . . . T , the adversary picks an example (xt, yt), then the learner
A ﬁrst gets to observe xt, and predicts (possibly in a randomized fashion) ˆyt ∈ {±1}, and lastly it observes yt and gains a reward of yt · ˆyt. The goal of the learner is to maximize the total gain (or correlation), given by (cid:80) t yt · ˆyt. Note that this is equivalent to the often-used notion of loss where in each iteration the learner suffers a loss of 1[yt (cid:54)= ˆyt] and its goal is to minimize the accumulated loss (cid:80) t 1[yt (cid:54)= ˆyt]. 2
Deﬁnition 1 (Agnostic Weak Online Learning). Let H ⊆ {±1}X be a class of experts, let T denote the horizon length, and let γ > 0 denote the advantage. An online learning algorithm W is a (γ, T )-agnostic weak online learner (AWOL) for H if for any sequence (x1, y1), ..., (xT , yT ) ∈ X × {±1}, at every iteration t ∈ [T ], the algorithm outputs W(xt) ∈ {±1} such that, (cid:34) T (cid:88)
E t=1 (cid:35)
W(xt)yt
≥ γ max h∈H
E t=1 (cid:34) T (cid:88) (cid:35) h(xt)yt
− RW (T ), where the expectation is taken w.r.t the randomness of the learner W and that of the possibly adaptive adversary, and RW : N → R+ is the additive regret: a non-decreasing, sublinear function of T .
Note the slight abuse of notation in the last deﬁnition: an online learner W is not an “X → {±1}” function; rather it is an algorithm with an internal state that is updated as it is fed new examples.
Thus, the prediction W(xt) depends on the internal state of W, and for notational convenience we avoid reference to the internal state.
Our agnostic online boosting algorithm has oracle access to N weak learners and predicts each label by combining their predictions. The number of weak learners N is a meta-parameter which can be tuned by the user according to the following trade-off: on the one hand, the regret bound improves as N increases, and on the other hand, a larger number of weak learners is more costly in terms of computational resources. 2Indeed, yt ˆyt = 1 − 2 · 1[yt (cid:54)= ˆyt] since yt, ˆyt ∈ {±1}. Therefore, the accumulated loss and correlation are afﬁnely related by (cid:80) yt · ˆyt = T − 2 · (cid:80) t 1[yt (cid:54)= ˆyt]. 2
Theorem 2 (Agnostic Online Boosting). Let H be a class of experts, let T ∈ N denote the horizon length, and let W1, . . . , WN be (γ, T )-AWOL for H with advantage γ and regret RW (T ) = o(T ) (see Deﬁnition 1). Then, there exists an online learning algorithm, which has oracle access to each
Wi, and has expected regret of at most
RW (T )
γ
+ O (cid:16) T
√
γ
N (cid:17)
.
To exemplify the interplay between RW (·) and N , imagine a scenario where RW (T ) ≈ often the case for regret bounds). Then, setting N ≈ T gives that the overall regret remains ≈
By setting both T and N to be O( 1
γ2(cid:15)2 ) for any (cid:15) > 0, an average regret of (cid:15) is obtained.
T (as is
√
T .
√
An abstract framework for boosting. Boosting and Regret Minimization algorithms are inti-mately related. This tight connection is exhibited in statistical boosting (see [20, 19, 34]). For example, AdaBoost can be interpreted as applying the Hedge algorithm to iteratively update proba-bility weights associated with the training examples [18]. Our algorithm is inspired by this fruitful connection and utilizes it. We derive a general framework which reduces boosting to online con-vex optimization. Moreover, this reduction applies to 4 learning settings: realizable-statistical, realizable-online, agnostic-statistical, and agnostic-online.
We note that in the agnostic boosting settings, both the assumption and the goal are stronger compared to the realizable case; an agnostic weak learner is assumed (which is stronger than a realizable weak learner), but the aim is to learn arbitrary distributions (which is a more challenging task than only learning realizable distributions). Therefore, a boosting algorithm for the realizable setting does not trivially follow from an agnostic boosting algorithm. A similar argument holds for the statistical vs. online boosting settings.
The general framework we derive in this work does apply to all the 4 aforementioned learning settings, with only slight modiﬁcation to the algorithm’s update rule. On a high-level, these modiﬁcation are based on the following observations: 1. Agnostic/Realizable: in the realizable setting the weights of instances (i.e. the x’s) are updated (e.g., in Adaboost [34]). In the agnostic setting the weights of labels (i.e. the y’s) are typically updated instead [16, 28]. Therefore, instances and labels are exchanged. 2. Statistical/Online: in the statistical setting, in each iteration a weak-hypothesis is produced and the weights of all examples are updated. In the online setting in each iteration a new example is processed and the weights corresponding to all weak-learners are updated [9].
Therefore, examples and weak learners are exchanged.
Thus, there is an interesting duality which “converts” between the 4 settings by replacing reweighting (realizable) with relabeling (agnostic), and between updating all learners per example (online) and updating all examples per learner (statistical). Our main contribution is showing that the fashion in which reweighting/relabelling is performed, which was previously given by ad hoc update-rules, can be abstracted to an application of an arbitrary online convex optimization algorithm.
Our general framework result may not come as a surprise given the well known connections between boosting and online convex optimization. However, we stress that the general reduction established here does introduce technical challenges. For instance, the ﬁnal output of the algorithm is not obtained via a standard weighted majority-vote, but rather a different projected aggregation of the weak learners’ predictions. Thus, albeit our uniﬁed framework being simple and intuitive, the analysis is not straightforwardly derived.
Paper structure.
In the next subsection we discuss related work. The main result of our agnostic online boosting algorithm, and the proof of Theorem 2, are given in Section 2. In Section 3 we demonstrate a general reduction, in the statistical setting, from both the agnostic (Subsection 3.1), and realizable (Subsection 3.2) boosting settings, to online convex optimization. Then, in Section 4, we give a similar result for the online realizable boosting setting. 3
1.2