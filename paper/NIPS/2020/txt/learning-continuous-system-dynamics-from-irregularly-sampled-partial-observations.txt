Abstract
Many real-world systems, such as moving planets, can be considered as multi-agent dynamic systems, where objects interact with each other and co-evolve along with the time. Such dynamics is usually difﬁcult to capture, and understanding and predicting the dynamics based on observed trajectories of objects become a critical research problem in many domains. Most existing algorithms, however, assume the observations are regularly sampled and all the objects can be fully observed at each sampling time, which is impractical for many applications. In this paper, we pro-pose to learn system dynamics from irregularly-sampled and partial observations with underlying graph structure for the ﬁrst time. To tackle the above challenge, we present LG-ODE, a latent ordinary differential equation generative model for modeling multi-agent dynamic system with known graph structure. It can simulta-neously learn the embedding of high dimensional trajectories and infer continuous latent system dynamics. Our model employs a novel encoder parameterized by a graph neural network that can infer initial states in an unsupervised way from irregularly-sampled partial observations of structural objects and utilizes neural
ODE to infer arbitrarily complex continuous-time latent dynamics. Experiments on motion capture, spring system, and charged particle datasets demonstrate the effectiveness of our approach. 1

Introduction
Learning system dynamics is a crucial task in a variety of domains, such as planning and control in robotics [1], predicting future movements of planets in physics [2], etc. Recently, with the rapid development of deep learning techniques, researchers have started building neural-based simulators, aiming to approximate complex system interactions with neural networks [1, 3, 2, 4, 5] which can be learned automatically from data. Existing models, such as Interaction Networks (IN) [3], usually decompose the system into distinct objects and relations and learn to reason about the consequences of their interactions and dynamics based on graph neural network (GNN). However, one major limitation is that they only work for fully observable systems, where the individual trajectory of each object can be accessed at every sampling time. In reality, many applications have to deal with partial observable states, meaning that the observations for different agents are not temporally aligned. For example, when a robot wants to push a set of blocks into a target conﬁguration, only the blocks in the top layer are visible to the camera [1]. More challengingly, the visibility of a speciﬁc object might 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
change over time, meaning that observations can happen at non-uniform intervals for each agent, i.e. irregularly-sampled observations. Such data can be caused by various reasons such as broken sensors, failed data transmissions, or damaged storage [6]. How to learn an accurate multi-agent dynamic system simulator with irregular-sampled partial observations remains a fundamental challenge.
Tang et al. [6] recently have studied a seemingly similar problem which is predicting the missing values for multivariate time series (MTS) as we can view the trajectory of each object as a time series.
They assumed there exist some close temporal patterns in many MTS snippets and proposed to jointly model local and global temporal dynamics for MTS forecasting with missing values, where the global dynamics is captured by a memory module. However, it differs from multi-agent dynamic systems in that the model does not assume a continuous interaction among each variable, i.e. the underlying graph structure is not considered. Such interaction plays a very important role in multi-agent dynamic systems which drives the system move forward.
Recently Rubanova et al. [7] has proposed a VAE-based latent ODE model for modeling irregularly-sampled time series, which is a special case of the multi-agent dynamic system where it only handles one object. They assume there exists a latent continuous-time system dynamics and model the state evolution using a neural ordinary differential equation (neural ODE) [8]. The initial state is drawn from an approximated posterior distribution which is parameterized by a neural network and is learned from observations.
Inspired by this, we propose a novel model for learning continuous multi-agent system dynamics under the same framework with GNN as the ODE function to model continuous interaction among objects. However, the main challenge lies in how to approximate the posterior distributions of latent initial states for the whole system, as now the initial states of agents are closely coupled and related to each other. We handle this challenge by ﬁrstly aggregating information from observations of neighborhood nodes, obtaining a contextualized representation for each observation, then employ a temporal self-attention mechanism to capture the temporal pattern of the observation sequence for each object. The beneﬁts of joint learning of initial states is twofold: First, it captures the complex interaction among objects. Second, when an object only has few observations, borrowing the information from its neighbors would facilitate the learning of its initial state. We conduct extensive experiments on both simulated and real datasets over interpolation and extrapolation tasks.
Experiment results verify the effectiveness of our proposed method. 2 Problem Formulation and Preliminaries
Consider a multi-agent dynamic system as a graph G = (cid:104)O, R(cid:105), where vertices O = {o1, o2 · · · oN } represent a set of N interacting objects, R = {(cid:104)i, j(cid:105)} represents relations. For each object, we have i }Ti i ∈ RD denotes the feature vector of a series of observations oi = {ot object i at time t, and {tj j=0 can be of variable length and values for each object. Observations are often at discrete spacings with non-uniform intervals and for different objects, observations may not be temporally aligned. We assume there exists a latent generative continuous-time dynamic system, i ∈ Rd for each object at any which we aim to uncover. Our goal is to learn latent representations zt given time, and utilize it to reconstruct missing observations and forecast trajectories in the future. i} at times {tj j=0,where ot i }Ti 2.1 Ordinary differential equations (ODE) for multi-agent dynamic system
In continuous multi-agent dynamic system, the dynamic nature of state is described for continuous values of t over a set of dependent variables. The state evolution is governed by a series of ﬁrst-order
N ) that drive the system states forward ordinary differential equations:
N ∈ Rd for every object, zt 0, z0 in inﬁnitesimal steps over time. Given the latent initial states z0 i is the solution to an ODE initial-value problem (IVP), which can be evaluated at any desired times using a numerical ODE solver such as Runge-Kutta [9]: dt = gi(zt i := dzt
˙zt 1 · · · z0 2 · · · zt 1, zt i i = z0 zT i + (cid:90) T t=0 gi(zt 1, zt 2 · · · zt
N )dt (1)
The ODE function gi speciﬁes the dynamics of latent state and recent works [8, 7, 10] have proposed to parameterize it with a neural network, which can be learned automatically from data. Different 2
from single-agent dynamic system, gi should be able to model interaction among objects. Existing works [3, 1, 2, 11] in discrete multi-agent dynamic system employ a shared graph neural network (GNN) as the state transition function. It deﬁnes an object function fO and a relation function fR to model objects and their relations in a compositional way. By adding residual connection and let the stepsize go to inﬁnitesimal, we can generalize such transition function to the continuous setting as shown in Eqn 2, where Ni is the set of immediate neighbors of object oi.
˙zt i := dzt i dt
= gi(zt 1, zt 2 · · · zt
N ) = fO( (cid:88) fR([zt i, zt j])) (2) j∈Ni
Given the ODE function, the latent initial state z0 i for each object determine the whole trajectories. 2.2 Latent ODE model for single-agent dynamic system
Continuous single-agent dynamic system is a special case in our setting. Recent work [7] has proposed a latent ODE model following the framework of variational autoencoder [12], where they assume a posterior distribution over the latent initial state z0. The encoder computes the posterior distribution q for the single object with an autoregressive model such as RNN, and sample latent initial state z0 from it. Then the entire trajectory is determined by the initial state z0 and the generative model deﬁned by ODE. Finally the decoder recovers the whole trajectory based on the latent state at each timestamp by sampling from the decoding likelihood p(oi|zi). z0| {oi, ti}N i=0 (cid:16) (cid:17)
We model multi-agent dynamic system under the same framework with GNN as the ODE function to model continuous interaction among objects. Since the latent initial states of each object are tightly coupled, we introduce a novel recognition network in the encoder to infer the initial states of all objects simultaneously. 3 Method
In this section, we present Latent Graph ODE (LG-ODE) for learning continuous multi-agent system dynamics. Following the structure of VAE, LG-ODE consists of three parts that are trained jointly: 1.) An encoder that infers the latent initial states of all objects simultaneously given their partially-observed trajectories; 2.) a generative model deﬁned by an ODE function that learns the latent dynamics given the sampled initial states. 3.) a decoder that recovers the trajectory based on the decoding likelihood p(ot i). The overall framework is depicted in Figure 1. In the following, we describe the three components in detail. i|zt 3.1 Encoder i=1 qφ(z0
Let Zt ∈ RN ×d denotes the latent state matrix of all N objects at time t. The encoder returns a factorized distribution of initial states: qφ(Z0|o1, o2 · · · oN ) = (cid:81)N i |o1, o2 · · · oN ). In multi-agent dynamic system, objects are highly-coupled and related. Instead of encoding temporal pattern for each observation sequence oi = {ot independently using an RNN [7], we incorporate structural information by ﬁrst aggregating information from neighbors’ observations, then employ a temporal self-attention mechanism to encode observation sequence for each object. Such process can be decomposed into two steps: 1.) Dynamic Node Representation Learning, where we aim to learn an encoding function fupdate that outputs structural contextualized representation ht i for each observation ot i. 2.) Temporal Self-Attention, where we learn an function faggre that aggregates the structural observation representations into a ﬁxed-dimensional sequence representation ui for each object. ui is then utilized to approximate the posterior distribution for each latent initial state z0 i . i}tTi i t=t0 i ht i = fupdate(oi, {oj|if j ∈ Ni}), ui = faggre(ht1 i , ht2 i tTi
· · · h i
) (3)
Dynamic Node Representation Learning. One naive way to incorporate structural information is to construct a graph snapshot at each timestamp [13, 14]. However, when system is partially observed, each snapshot may only contain a small portion of objects. For example in Figure 1 (a), 6 out of 7 3
Figure 1: Overall framework. timestamps only contains one object thus abundant structural information across different snapshots is ignored. We therefore preserve temporal edges and nodes across times to form a temporal graph, where every node is an observation, every edge exists when two objects are connected via a relation r ∈ R{(cid:104)i, j(cid:105)}. Suppose on average every object has K observations, and there are E relations among objects. The constructed temporal graph has O(EK 2 + (K − 1)KN ) edges, which grows rapidly with the increase of average observation number K. We therefore set a slicing time window that
ﬁlters out edges when the relative temporal gap is larger than a preset threshold.
To learn a structural representation for each observation, we propose a temporal-aware graph neural network characterized by the information propagation equation in Eqn 4, where hl−1 are the representations of target and source node from layer l − 1 respectively. (cid:88)
, hl−1 s t t = hl−1 hl t + σ( (Attention(hl−1 s
, hl−1 t
) · Message(hl−1
)) s (4) s∈Nt
To model temporal dependencies among nodes, a simple alternative is to introduce a time-dependent attention score [15] multiply by a linear transformation of the sender node W vhl−1
. However, the information loss of a sender node w.r.t different temporal gap is linear, as the Message of a sender node is time-independent. Recently Transformer [15] has proposed to add positional encoding to the sender node hl−1 and obtain a time-dependent Message. As adding is a linear operator, we hypothesize that taking a nonlinear transformation of the sender node as time-dependent Message would be more sufﬁcient to capture the complex nature of information loss caused by temporal gap between nodes. We deﬁne the nonlinear transformation w.r.t the temporal gap ∆t(s, t) as follows: s s
Message(hl−1 s
, ∆t(s, t)) = W v l−1
ˆh s
, l−1
ˆh s = σ(W t[hl−1 s
||∆tst]) + TE(∆tst)
TE(∆t)2i+1 = cos(∆t/100002i/d), TE(∆t)2i = sin(∆t/100002i/d) (5)
Attention(hl−1 s
, hl−1 t
, ∆t(s, t)) = (W k l−1
ˆh s
)T (W qhl−1 t
) · 1√ d where || is the concatenation operation and σ(·) is a non-linear activation function. d is the dimension of node embeddings and W t is a linear transformation applied to the concatenation of the sender node and temporal gap. We adopt the dot-product form of attention where W v, W k, W q projects input node representations into values, keys and queries. The learned attention coefﬁcient is normalized via softmax across all neighbors. Additionally, to distinguish the sender from observations of the object 4
itself, and observations from its neighbors, we learn two sets of projection matrices W k, W v for each of these two types. Finally, we stack L layers to get the ﬁnal representation for each observation as ht i). The overall process is depicted in Figure 1 (b). i = hL(ot
Temporal Self-Attention. To encode temporal pattern for each observation sequence, we design a non-recurrent temporal self-attention layer that aggregates variable-length sequences into ﬁxed-dimensional sequence representations ui, which is then utilized to approximate the posterior distribu-tion for each latent initial state z0 i . Compared with traditional recurrent models such as RNN,LSTM, self-attention mechanism can be better parallelized for speeding up training process and alleviate the vanishing/exploding gradient problem in these models [13, 15]. Note that we have introduced inter-time edges when creating temporal graph, the observation representations ht i already preserve temporal dependency across timestamps. To encode the whole sequence, we introduce a global sequence vector ai to calculate a weighted sum of observations as the sequence representation : ai = tanh(( 1
N (cid:88) t
ˆh i)W a), ui = t 1
N (cid:88)
σ(aT i t
ˆh i)ˆh t i t (6) where ai is a simple average of node representations with nonlinear transformation towards the system initial time tstart followed by a linear projection W a. The nonlinear transformation is deﬁned t as ˆh i = σ(W t[ht i||∆t]) + TE(∆t) with ∆t = (t − tstart), which is analogous to the Message calculation in step 1. Note that if we directly use the observation representation ht i from step 1, the sequence representation ui would be the same when we shift the timestamp for each observation by T , as we only utilize the relative temporal gap between observations. By taking the nonlinear transformation, we actually view each observation has an underlying inter-time edge connected to the virtual initial node at system initial time tstart. In this way, the sequence representation ui reﬂects latent initial state towards a given time tstart, and varies when the initial time changes. The process is depicted in Figure 1 (c). Finally, we have the approximated posterior distribution as in Eqn7 where f is a neural network translating the sequential representation into the mean and variance of z0 i . qφ(z0 i |o1, o2 · · · oN ) = N (cid:16)
µz0 i
, σz0 i (cid:17)
, where µz0 i
, σz0 i
= f (ui) (7) 3.2 Generative model and decoder
We consider a generative model deﬁned by an ODE whose latent initial state z0 i is sampled from the approximated posterior distribution qφ(z0 i |o1, o2 · · · oN ) from the encoder. We employ a graph neural network (GNN) in Eqn 2 as the ODE function gi to model the continuous interaction of objects.
A decoder is then utilized to recover trajectory from the decoding probability p(ot i), characterized by a neural network. i|zt i , z1 z0 i · · · zT z0 i ∼ p(z0 i ) ≈ qφ(z0 i = ODESolve(gi, [z0 i ∼ p(ot ot i |o1, o2 · · · oN ) 2 · · · z0 1, z0 i|zt i)
N ], (t0, t1 · · · tT )) (8) 3.3 Training
We jointly train the encoder, decoder and generative model by maximizing the evidence lower bound (ELBO) as shown below. As observations for each object are not temporally aligned in a minibatch, we take the union of these timestamps and output the solution of the ODE at them.
ELBO(θ, φ)
= EZ0∼qφ(Z0|o1,···oN )[log pθ(o1, . . . , oN )] − KL[qφ(Z0|o1, · · · , oN )(cid:107)p(Z0)] (9)
= E
Z0∼(cid:81)N i=1 qφ(z0 i |o1,··· ,oN )[log pθ(o1, · · · , oN )] − KL[(cid:81)N i=1 qφ(z0 i |o1, · · · , oN )(cid:107)p(Z0)] 5
4 Experiments 4.1 Datasets
We illustrate the performance of our model on three different datasets: particles connected by springs, charged particles ( Kipf et al. [2]) and motion capture data ( CMU [16]). The ﬁrst two are simulated datasets, where each sample contains 5 interacting particles in a 2D box with no external forces (but possible collisions with the box). The trajectories are simulated by solving two types of motion
PDE for spring system and charged system respectively [2] with the same number of forward steps 6000 and then subsampling each 100 steps. To generate irregularly-sampled partial observations, for each particle we sample the number of observations n from U(40, 52) and draw the n observations uniformly from the PDE steps to get the training trajectories. To evaluate extrapolation task, we additionally sample 40 observations following the same procedure from PDE steps [6000, 12000] for testing. The above sampling procedure is conducted independently for each object. We generate 20k training samples and 5k testing samples for these two datasets respectively. For motion capture data, we select the walking sequences of subject 35. Every sample is in the form of 31 trajectories, each tracking a single joint. Similar as simulated datasets, for each joint we sample the number of observations n from U(30, 42) and draw the n observations uniformly from ﬁrst 50 frames for training trajectories. For testing, we additionally sampled 40 observations from frames [51, 99]. We split the different walking trials into non-overlapping training (15 trials) and test sets (7 trials).
We conduct experiment on both interpolation and extrapolation tasks as proposed in Rubanova et al.
[7]. For all experiments, we report the mean squared error (MSE) on the test set. For all datasets, we rescale the time range to be in [0, 1]. Our implementation is available online1. More details can be found in the supplementary materials. 4.2 Baselines and Model Variants
Baselines. To the best of our knowledge, existing works on modeling multi-agent dynamic system with underlying graph structure cannot handle irregularly-sampled partial observations, in which these models require full observation at timestamp t in order to make prediction at timestamp t + 1 [2, 3]. Therefore, we ﬁrstly compare our model with different encoder structures to infer the initial states. Speciﬁcally, we consider Latent-ODE (Rubanova et al. [7]) which has shown to be successful for encoding single irregularly-sampled time series without considering graph interaction among agents. Edge-GNN (Gong and Cheng [17]) incorporates temporal information by viewing time gap as an edge attribute. Weight-Decay considers a simple exponential decay function for time gap as similar in Cao et al. [18], which models h(t + ∆t) = exp{−τ ∆t} · h(t) with a learnable decay parameter τ . The sequence representation of Edge-GNN and Weight-Decay is the weighted sum of observations within a sequence. We additionally compare LG-ODE against an RNN-based
MTS model for handling irregularly-sampled missing values [19] where the graph structure is not considered. It jointly imputes missing values for all agents by simple concatenation of their feature vectors. We compare it in the Interpolation Task which is to imputes missing values within the observed sequences. After imputation, we employ NRI [2] which is a multi-agent dynamic system model with regular observations and graph input to predict future sequences. We refer to this task as
Extrapolation Task. In what follows, we refer to the combination of these two models as RNN-NRI.
Model Variants. Our proposed encoder contains two modules: dynamic node representation network followed by a temporal self-attention. To further analyze the components within each module, we conduct an ablation study by considering ﬁve model variants. Firstly, module one contains two core components: attention mechanism and learnable positional encoding within GNN for capturing temporal and spatial dependency among nodes. We therefore remove them separately and get LG-ODE-no att, LG-ODE-no PE respectively. We additionally compare our learnable positional encoding with manually-designed positional encoding [15] denoted as LG-ODE-ﬁxed PE. Secondly, we apply various sequence representation methods to test the efﬁciency of module two: LG-ODE-ﬁrst takes the
ﬁrst observation in a sequence as sequence representation and LG-ODE-mean uses the mean pooling of all observations as sequence representation. 1https://github.com/ZijieH/LG-ODE.git 6
Table 1: Mean Squared Error(MSE) ×10−2 on Interpolation task.
Observed ratio 40% 0.5454
Latent-ODE 1.1634
Weight-Decay 1.3370
Edge-GNN 0.5225
NRI + RNN 0.3350
LG-ODE 1.3017
LG-ODE-ﬁrst 0.3896
LG-ODE-mean 0.5145
LG-ODE-no att
LG-ODE-no PE 0.4431
LG-ODE-ﬁxed PE 0.4285
Springs 60% 0.5036 1.1377 1.2786 0.4049 0.3170 1.1918 0.3901 0.4198 0.4278 0.4445 80% 0.4290 1.6217 0.8188 0.3548 0.2641 1.0796 0.3268 0.4510 0.3879 0.4083 40% 1.1799 2.8419 1.5795 1.3913 0.9234 2.5105 1.1246 0.9372 1.0450 0.9838
Charged 60% 1.1198 2.2547 1.5618 1.1659 0.8277 2.6714 1.0050 0.9503 1.0350 0.9775 80% 0.8332 1.5390 1.1420 1.0344 0.8046 2.3208 0.9133 0.9752 0.9621 0.9524 40% 0.7709 1.9007 2.7670 0.5845 0.4515 1.4904 0.6415 0.6991 0.4677 0.4215
Motion 60% 0.4826 2.0023 2.6582 0.5395 0.2870 1.3702 0.5834 0.6998 0.4808 0.4371 80% 0.3603 1.6894 1.8485 0.5204 0.3414 1.2107 0.5549 0.7452 0.4799 0.4313
Figure 2: Visualization of interpolation results for spring system. 4.3 Results on Interpolation Task
Set up. In this task, we condition on a subset of observations (40%, 60%, 80%) from time (t0, tN ) and aim to reconstruct the full trajectories in the same time range. We subsample timepoints for each object independently.
Table 1 shows the interpolation MSE across different datasets and methods. Latent-ODE performs well on encoding single timeseries but fails to consider the interaction among objects, resulting in its poor performance in the multi-agent dynamic system setting. Weight-Decay and Edge-GNN utilize ﬁxed linear transformation of sender node to model information loss across timestamps, which is not sufﬁcient to capture the complex temporal dependency. RNN-NRI though handles the irregular temporal information by a specially designed decay function, it conducts imputation without considering the graph interaction among objects and thus obtaining a poor performance.
By comparing model variants for temporal self-attention module, we notice that taking the ﬁrst observation as sequence representation produces high reconstruction error, which is expected as the
ﬁrst observable time for each sequence may not be the same so the inferred latent initial states are not aligned. Averaging over observations assumes equal contribution for each observation and ignores the temporal dependency, resulting in its poor performance. For module one, experiment results on model variants suggest that distinguishing the importance of nodes w.r.t time and incorporating temporal information via learnable positional encoding would beneﬁt model performance. Notably, the performance gap between LG-ODE and other methods increases when the observation percentage gets smaller, which indicates the effectiveness of LG-ODE on sparse data. When observation percentage increases, the reconstruction loss of all models tends to be smaller, which is expected.
Figure 2 visualizes the interpolation results of our model under different observation percentage for the spring system. Figure 3 visualizes the interpolation results for motion capture data with 60% observation percentage. 4.4 Results on Extrapolation Task
Set up. In this task we split the time into two parts: (t0, tN1) and (tN1 , tN ). We condition on the
ﬁrst half of observations and reconstruct the second half. For training, we condition on observations from (t1, t2) and reconstruct the trajectories in (t2, t3). For testing, we condition on the observations from (t1, t3) but tries to reconstruct future trajectories within (t3, t4). Similar to interpolation task, we experiment on conditioning only on a subset of observations in the ﬁrst half and run the encoder 7
(a) Groundtruth. (b) Predictions with 0.6 observation ratio.
Figure 3: Visualization of interpolation results for walking motion data. on the subset to estimate the latent initial states. We evaluate model’s performance on reconstructing the full trajectories in the second half.
Table 2: Mean Squared Error(MSE) ×10−2 on Extrapolation task.
Extrapolation
Observed ratio 40%
Latent-ODE 6.6923
Weight-Decay 6.1559
Edge-GNN 6.0417
NRI + RNN 2.6638 1.7839
LG-ODE
LG-ODE-ﬁrst 6.5742
LG-ODE-mean 2.2499
LG-ODE-no att 2.3847 1.7943
LG-ODE-no PE
LG-ODE-ﬁxed PE 1.7905
Springs 60% 4.2478 5.7416 4.9220 2.4003 1.8084 6.3243 2.1165 2.1216 1.8172 1.7634 80% 4.3192 5.3712 3.2281 2.5550 1.7139 5.7788 2.2516 1.9634 1.7332 1.7545 40% 13.5852 9.4764 9.2124 7.1776 6.5320 9.3782 9.1355 7.2958 6.9961 6.4520
Charged 60% 12.7874 9.1008 9.1410 6.9882 6.4338 9.2107 8.7820 7.3609 6.7208 6.4706 80% 20.5501 9.0886 8.8341 6.6736 6.2448 8.4765 8.4422 6.7026 6.5852 6.3543 40% 2.4186 16.8031 13.2991 3.5380 1.2843 3.8864 1.3169 3.4510 1.5054 1.4624
Motion 60% 2.9061 13.6696 13.9676 3.0119 1.2435 3.2849 1.3008 3.2178 1.2997 1.2517 80% 2.6590 13.6796 9.8669 2.6006 1.2010 3.0001 1.2534 3.9917 1.2029 1.1992
Figure 4: Visualization of extrapolation results for spring system. Semi-transparent paths denote observations from ﬁrst-half of time, from which the latent initial states are estimated. Solid paths denote model predictions.
Table 2 shows the MSE on extrapolation task. The average MSE in extrapolation task is greater than interpolation task, which is expected as predicting the future is a more challenging task. Similar as in interpolation task, when observation percentage increases, the prediction error of all models tends to become smaller. LG-ODE achieves better results across different datasets and settings, which veriﬁes the effectiveness of our design to capture structural dependency among objects, and temporal dependency within observation sequence. Speciﬁcally, RNN-NRI is a two-step model that
ﬁrst imputes each time series into regular-sampled one to make it a valid input for NRI, and then predict trajectories with the graph structure. LG-ODE instead is an end-to-end framework. The 8
prediction error for RNN-NRI is large and one possible reason is that we use estimated imputation values for missing data which would add noise to NRI. We also notice that the performance drop due to the sparsity of observations is small in LG-ODE compared with other baselines, which shows our model is more powerful especially when data is sparse. We illustrate the predicted trajectories of spring system under different observation percentage as shown in Figure 4. 5