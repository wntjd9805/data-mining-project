Abstract
This paper presents competitive algorithms for a novel class of online optimization problems with memory. We consider a setting where the learner seeks to minimize the sum of a hitting cost and a switching cost that depends on the previous p decisions. This setting generalizes Smoothed Online Convex Optimization. The proposed approach, Optimistic Regularized Online Balanced Descent, achieves a constant, dimension-free competitive ratio. Further, we show a connection between online optimization with memory and online control with adversarial disturbances.
This connection, in turn, leads to a new constant-competitive policy for a rich class of online control problems. 1

Introduction
This paper studies the problem of Online Convex Optimization (OCO) with memory, a variant of classical OCO [25] where an online learner iteratively picks an action yt and then suffers a convex loss gt(yt−p, · · · , yt), depending on current and previous actions. Incorporating memory into OCO has seen increased attention recently, due to both its theoretical implications, such as to convex body chasing problems [11, 8, 37, 12], and its wide applicability to settings such as data centers [32], power systems [30, 9, 26], and electric vehicle charging [26, 17]. Of particular relevance to this paper is the considerable recent effort studying connections between OCO with memory with online control in dynamical systems, leading to online algorithms that enjoy sublinear static regret [4, 5], low dynamic regret [29, 31], constant competitive ratio [23], and the ability to boost weak controllers [3].
Prior work on OCO with memory is typically limited in one of two ways. First, algorithms with the strongest guarantees, a constant competitive ratio, are restricted to a special case known as Smoothed
Online Convex Optimization (SOCO), or OCO with switching costs [16, 32, 24], which considers only one step of memory and assumes cost functions can be observed before actions are chosen.
Second, algorithms proposed for the general case typically only enjoy sublinear static regret [6], which is a much weaker guarantee, because static regret compares to the ofﬂine optimal static solution while competitive ratio directly compares to the true ofﬂine optimal. It is known that algorithms that achieve sublinear static regret can be arbitrarily worse than the true ofﬂine optimal [22], and also may have unbounded competitive ratios [7]. The pursuit of general-purpose constant-competitive algorithms for OCO with memory remains open.
Our work is also motivated by establishing theoretical connections between online optimization and control. Recently a line of work has shown the applicability of tools from online optimization
*Equal contributions. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver,
Canada.
for control, albeit in limited settings [4, 5, 28, 23]. Deepening these connections can potentially be impactful since most prior work studies how to achieve sublinear regret compared to the best static linear controller [20, 5, 4, 19]. However, the best static linear controller is a weak benchmark compared to the true optimal controller [22], which may be neither linear nor static. To achieve stronger guarantees, one must seek to bound either the competitive ratio [23] or dynamic regret
[29, 31], and connections to online optimization can provide such results. However, prior attempts either have signiﬁcant caveats (e.g., bounds depend on the path length of the instance [29, 31]) or only apply to very restricted control systems (e.g., invertible control actuation matrices and perfect knowledge of disturbances [23]). As such, the potential to obtain constant-competitive policies for general control systems via online optimization remains unrealized.
Main contributions. We partially bridge the two gaps highlighted above. First, we propose a novel setting, OCO with structured memory, where the cost function depends on the previous p decisions and is not known precisely before determining the action. This setting generalizes SOCO to include more than one step of memory and to eliminate the assumption that the cost function must be perfectly known before choosing the action. Second, we propose a novel algorithm, Optimistic
Regularized Online Balanced Descent, that has a constant and dimension-free competitive ratio for
OCO with structured memory. This is the ﬁrst algorithm with a constant competitive ratio for online optimization with memory longer than one step. Third, we provide a nontrivial reduction from a rich class of online control problems to OCO with structured memory and, via the reduction, show that a constant-competitive policy exists for this class of control problems. While not completely general, the class of problems is considerably more general than existing settings where competitive polices are known, e.g., the control matrix must be invertible and the disturbances are known in advance [23].
Finally, we use examples to (i) demonstrate the gap between the best ofﬂine linear policy and the true optimal ofﬂine policy can be arbitrarily large, and (ii) highlight that our algorithms can signiﬁcantly outperform the best ofﬂine linear controller, which serves as the benchmark of no-regret policies. 2