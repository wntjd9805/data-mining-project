Abstract
To reduce the human efforts in neural network design, Neural Architecture Search (NAS) has been applied with remarkable success to various high-level vision tasks such as classiﬁcation and semantic segmentation. The underlying idea for the
NAS algorithm is straightforward, namely, to enable the network the ability to choose among a set of operations (e.g.,convolution with different ﬁlter sizes), one is able to ﬁnd an optimal architecture that is better adapted to the problem at hand.
However, so far the success of NAS has not been enjoyed by low-level geometric vision tasks such as stereo matching. This is partly due to the fact that state-of-the-art deep stereo matching networks, designed by humans, are already sheer in size. Directly applying the NAS to such massive structures is computationally prohibitive based on the currently available mainstream computing resources. In this paper, we propose the ﬁrst end-to-end hierarchical NAS framework for deep stereo matching by incorporating task-speciﬁc human knowledge into the neural architecture search framework. Speciﬁcally, following the gold standard pipeline for deep stereo matching (ie.,, feature extraction – feature volume construction and dense matching), we optimize the architectures of the entire pipeline jointly.
Extensive experiments show that our searched network outperforms all state-of-the-art deep stereo matching architectures and is ranked at the top 1 accuracy on KITTI stereo 2012, 2015 and Middlebury benchmarks, as well as the top 1 on SceneFlow dataset with a substantial improvement on the size of the network and the speed of inference. The code is available at LEAStereo. 1

Introduction
Stereo matching attempts to ﬁnd dense correspondences between a pair of rectiﬁed stereo images and estimate a dense disparity map. Being a classic vision problem, stereo matching has been extensively studied for almost half a century [1]. Since MC-CNN [2], a large number of deep neural network architectures [3, 4, 5, 6] have been proposed for solving the stereo matching problem. Based on the adopted network structures, existing deep stereo networks can be roughly classiﬁed into two categories: I. direct regression and II. volumetric methods.
* Indicates equal contribution 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
Figure 1: Our proposed method, LEAStereo (Learning Effective Architecture Stereo), sets a new state-of-the-art on the KITTI 2015 test dataset with much fewer parameters and much lower inference time.
Direct regression methods are based on direct regression of dense per-pixel disparity from the input images, without taking into account the geometric constraints in stereo matching [7]. In the majority of cases, this is achieved by employing large U-shape encoder-decoder networks with 2D convolutions to infer the disparity map. While enjoying a fully data-driven approach, recent studies raise some concerns about the generalization ability of the direct regression methods. For example, the DispNet [3] fails the random dot stereo tests [8].
In contrast, the volumetric methods leverage the concept of semi-global matching [9] and build a 4D feature volume by concatenating features from each disparity-shift. To this end, the volumetric methods often make use of two building blocks, the so-called I. feature net and II. matching net.
As the names imply, the feature net extracts features from the input images and the matching net compute matching costs from the 4D feature volume with 3D convolutions. Different designs of the feature net and the matching net form variants of the volumetric networks [4, 10, 11, 12, 6].
Nowadays, the volumetric methods represent the state-of-the-art in deep stereo matching and top the leader-board across different benchmark datasets. Despite the success, designing a good architecture for volumetric methods remains an open question in deep stereo matching.
On a separate line of research and to reduce the human efforts in designing neural networks, Neural
Architecture Search (NAS) has mounted tremendous successes in various high-level vision tasks such as classiﬁcation [13, 14, 15], object detection [16, 17], and semantic segmentation [18, 19, 20].
Connecting the dots, one may assume that marrying the two parties, ie.,employing NAS to design a volumetric method for stereo matching, is an easy ride. Unfortunately this is not the case. In general, NAS needs to search through a humongous set of possible architectures to pick the network components (e.g.,the ﬁlter size of convolution in a certain layer). This demands heavy computational load (early versions of NAS algorithms [21, 22] need thousands of GPU hours to ﬁnd an architecture on the CIFAR dataset [23]). Add to this, the nature of volumetric methods are very memory hungry.
For example, the volumetric networks in [4, 11, 8, 24] require six to eight Gigabytes of GPU memory for training per batch! Therefore, end-to-end search of architectures for volumetric networks has been considered prohibitive due to the explosion of computational resource demands. This is probably why, in the only previous attempt1, Saikia et al. [25] search the architecture based on the direct regression methods, and they only search partially three different cell structures rather than the full architecture.
In this paper, we leverage the volumetric stereo matching pipeline and allow the network to automat-ically select the optimal structures for both the Feature Net and the Matching Net. Different from previous NAS algorithms that only have a single encoder / encoder-decoder architecture [18, 25, 20], our algorithm enables us to search over the structure of both networks, the size of the feature maps, the size of the feature volume and the size of the output disparity. Unlike AutoDispNet [25] that only searches the cell level structures, we allow the network to search for both the cell level structures and the network level structures, e.g.,the arrangement of the cells. To sum up, we achieve the ﬁrst end-to-end hierarchical NAS framework for deep stereo matching by incorporating the geometric knowledge into neural architecture search. We not only avoid the explosive demands of computational resources in searching architectures, but also achieve better performances compared to naively searching an architecture in a very large search space. Our method outperforms a large set of state-of-the-art algorithms on various benchmarks (e.g.,topping all previous studies on the KITTI and Middlebury 1To the best of our knowledge. 2
Figure 2: The pipeline of our proposed stereo matching network. Our network consists of four components: 2D Feature Net, 4D Feature Volume, 3D Matching Net, and Projection Layer. Given a pair of stereo images, the
Feature Net produces feature maps that are processed by the Matching Net to generate a 3D cost volume. The disparity map can be projected from the cost volume with soft-argmin operation. Since the Feature Net and the
Matching Net are the only two modules that contain trainable parameters, we utilize the NAS technique to select the optimal structures for them. benchmarks2 ). This includes man-designed networks such as [24, 26] and the NAS work of Saikia et al. [25], not only in accuracy but also in inference time and the size of the resulting network (as shown in Figure 1). 2 Our Method
In this section, we present our end-to-end hierarchical NAS stereo matching network. In particular, we have beneﬁted from decades of human knowledge in stereo matching and previous successful handcrafted designs in the form of priors towards architecture search and design. By leveraging task-speciﬁc human knowledge in the search space design, we not only avoid the explosion demands of computational resources in searching architectures for high resolution dense prediction tasks, but also achieve better accuracy compared to naively searching an architecture in a very large search space. 2.1 Task-speciﬁc Architecture Search Space
We recall that the deep solutions for dense prediction (e.g.,semantic segmentation, stereo matching), usually opt for an encoder-decoder structure [18, 25, 20]. Inspired by the Auto-DeepLab [18] for semantic segmentation, we propose a two-level hierarchical search that allows us to identify both cell-level and network-level structures3. Directly extending ideas from semantic segmentation might not necessarily lead to viable solutions for stereo matching. A fully data-driven U-shape encoder-decoder network is often hard to train, even with the help of NAS [25] in regressing disparity maps.
Volumetric stereo matching methods offer faster convergence and better performance as their pipeline makes use of inductive bias (ie.,human knowledge in network design). To be speciﬁc, volumetric solutions ﬁrst obtain a matching cost for all possible disparity levels at every pixel (based on the concepts of 3D geometry) and then use it to generate the disparity map (e.g.,by using a soft-argmin operation). One obvious drawback here is the overwhelming size of the resulting network. This, makes it extremely difﬁcult, if not impossible, to use volumetric solutions along the NAS framework.
In this work, we embed the geometric knowledge for stereo matching into our network architecture search. Our network consists of four major parts: a 2D feature net that extracts local image features, a 4D feature volume, a 3D matching net to compute and aggregate matching costs from concatenated features, and a soft-argmin layer that projects the computed cost volumes to disparity maps. Since only the feature net and the matching net involve trainable parameters, we leverage NAS technique to search these two sub-networks. The overall structure of our network is illustrated in Figure 2. More details about the cell and network level search are presented below. 2.1.1 Cell Level Search Space
A cell is deﬁned as a core searchable unit in NAS. Following [27], we deﬁne a cell as a fully-connected directed acyclic graph (DAG) with N nodes. Our cell contains two input nodes, one output node 2At the time of submitting this draft, our algorithm, LEAStereo, is ranked 1 in the KITTI 2015, and KITTI 2012 benchmark, and ranked 1 according to Bad 4.0, avgerr, rms, A95, A99 metrics on Middlebury benchmark. 3We would like to stress that our framework, in contrast to the Auto-DeepLab, searches for the full architecture (Auto-DeepLab only searches for the architecture of the encoder). 3
and three intermediate nodes. For a layer l, the output node is Cl and the input nodes are the output node of its two preceding layers (ie.,Cl−2, Cl−1). Let O be a set of candidate operations (e.g.,2D convolution, skip connection). During the architecture search, the functionality of an intermediate node s(j) is described by: s(j) = (cid:88) o(i,j)(cid:0)s(i)(cid:1) . i(cid:59)j
Here, (cid:59) denotes that node i is connected to j and o(i,j)(x) =
ν (cid:88) r=1 (cid:16) exp (cid:17)
α(i,j) r (cid:16) (cid:80)ν s=1 exp
α(i,j) s (cid:17) o(i,j) r (x) , (1) (2) r
ν
, α(i,j) 2
, · · · , α(i,j) being the r-th operation deﬁned between the two nodes. with o(i,j)
In effect, to identify the operation connecting node i to node j, we make use of a mixing weight vector α(i,j) = (α(i,j)
) along a softmax function. At the end of the search phase, a dis-1 crete architecture is picked by choosing the most likely operation between the nodes. That is, o(i,j) = o(i,j)
. Unlike [27, 25], we only need to search one type of cells for the feature and matching networks since the change of spatial resolution is handled by our network level search. DARTS [27] has a somehow inﬂexible search mechanism, in the sense that nodes
Cl−2, Cl−1, Cl are required to have the same spatial and channel dimensionalities. We instead allow the network to select different resolutions for each cell. To handle the divergence of resolutions in neighbouring cells, we ﬁrst check their resolutions and adjust them accordingly by upsampling or downsampling if there is a mismatch.
; r∗ = arg maxr α(i,j) r∗ r
Residual Cell. Previous studies opt for concatenating the outputs of all intermediate nodes to form the output of a cell (e.g.,[27, 18, 25]). We refer to such a design as a direct cell. Inspired by the residual connection in ResNet [28], we propose to also include the input of the cell in forming the output. See Figure 3 where the residual connection cells highlighted with a red line. This allows the network to learn residual mappings on top of direct mappings. Hereafter, we call this design the residual cell. We empirically ﬁnd that residual cells outperform the direct ones (see § 3.3).
Candidate Operation Selection. The candidate operations for the feature net and matching net differ due to their functionalities. In particular, the feature net aims to extract distinctive local features for comparing pixel-wise similarities. We empirically observe that removing two commonly used operations in DARTS, namely 1. dilated separable convolutions and 2. the pooling layers does not hurt the performance. Thus, the set of candidates operators for the feature net includes OF = { “3 × 3 2D convolution”, “skip connection”}. Similarly, we ﬁnd out that removing some of the commonly used operations from the candidate set for the matching net will not hurt the design. As such, we only include the following operations for the matching net, OM = { “3 × 3 × 3 3D convolution”, “skip connection”}. We will shortly see an ablation study regarding this (see § 3.3). 2.1.2 Network Level Search Space
We deﬁne the network level search space as the arrangement of cells, which controls the variations in the feature dimensionality and information ﬂow between cells. Drawing inspirations from [18], we aim to ﬁnd an optimal path within a pre-deﬁned L-layer trellis as shown in Figure 3. We associated a scalar with each gray arrow in that trellis. We use β to represent the set of this scalar. Considering the number of ﬁlters in each cell, we follow the common practice of doubling the number when halving the height and width of the feature tensor.
In the network level search space, we have two hyper-parameters to set: I. the smallest spatial resolution and II. the number of layers L. Empirically, we observe that setting the smallest spatial resolution to 1/24 of the input images work across a broad range of benchmarks and hence our choice in here. Based on this, we propose a four-level trellis with downsampling rates of {3, 2, 2, 2}, leading to the smallest feature map to be 1/24 of the input size (see Figure 3). In comparison to {2, 2, 2, 2, 2}, the downsampling to 1/3 will remove the need of upsampling twice and we empirically observed similar performance. At the beginning of the feature net, we have a three-layer “stem” structure, the ﬁrst layer of it is a 3 × 3 convolution layer with stride of three, followed by two layers of 3 × 3 convolution with stride of one. 4
Figure 3: The proposed search space. We illustrate our cell level search space on the left and our network level search space on the right. The red dash line on the left represents the proposed residual connection. We set
LF = 6 for Feature Net and LM = 12 for Matching Net.
Turning our attention to the the number of layers L, we have empirically observed that choosing
LF = 6 for the feature net and LM = 12 for the matching net provides a good balance between the computational load and performance of the network. This is interestingly much smaller than some recent developments in hand-crafting deep stereo matching networks. For example, GA-Net [24] uses 33 convolutional layers with an hourglass structure to extract features.
Similar to ﬁnding the best operation between the nodes, we will use a set of search parameters β to search over the trellis in order to ﬁnd a path in it that minimizes the loss. As shown in Fig 3, each cell in a level of the trellis can receive inputs from the preceding cell in the same level, one level below and one level above (if any of the latter two exists). 2.2 Loss Function and Optimization
Since our network can be searched and trained in an end-to-end manner, we directly apply supervisions on the output disparity maps, allowing the Feature Net and the Matching Net to be jointly searched.
We use the smooth (cid:96)1 loss as our training loss function as it is considered to be robust to disparity discontinuities and outliers. Given the ground truth disparity dgt, the loss function is deﬁned as:
L = (cid:96)(dpred − dgt), where (cid:96)(x) = (cid:26) 0.5x2,
|x| < 1,
|x| − 0.5, otherwise. (3)
After continuous relaxation, we can optimize the weight w of the network and the architecture param-eters α, β through bi-level optimization. We parameterize the cell structure and the network structure with α and β respectively. To speed up the search process, we use the ﬁrst-order approximation [18].
To avoid overﬁtting, we use two disjoint training sets trainI and trainII for w and α, β optimization respectively. We do alternating optimization for w and α, β:
• Update network weights w by ∇wL(w, α, β) on trainI
• Update architecture parameters α, β by ∇α,βL(w, α, β) on trainII
When the optimization convergence, we decode the discrete cell structures by retaining the top-2 strongest operations from all non-zero operations for each node, and the discrete network structures by ﬁnding a path with maximum probability [18]. 3 Experiments
In this section, we adopt SceneFlow dataset [3] as the source dataset to analyze our architecture search outcome. We then conduct the architecture evaluation on KITTI 2012 [29], KITTI 2015 [30] and
Middlebury 2014 [31] benchmarks by inheriting the searched architecture from SceneFlow dataset.
In our ablation study, we analyze the effect of changing search space as well as different search strategies. 3.1 Architecture Search
We conduct full architecture search on SceneFlow dataset [3]. It contains 35,454 training and 4370 testing synthetic images with a typical image dimension of 540 × 960. We use the “ﬁnalpass” version as it is more realistic. We randomly select 20,000 image pairs from the training set as our search-training-set, and another 1,000 image pairs from the training set are used as the search-validation-set following [18].
Implementation: We implement our LEAStereo network in Pytorch. Random crop with size 192×384 is the only data argumentation technique being used in this work. We search the architecture 5
Figure 4: The searched architecture. The top two graphs are the searched cell structures for the Feature Net and Matching Net. The bottom are the searched network level structures for both networks. The yellow dots present the pre-deﬁned “stem” layers and the blue dots denote the searchable cells. for a total of 10 epochs: the ﬁrst three epochs to initiate the weight w of the super-network and avoid bad local minima outcome; the rest epochs to update the architecture parameters α, β. We use SGD optimizer with momentum 0.9, cosine learning rate that decays from 0.025 to 0.001, and weight decay 0.0003. The entire architecture search optimization takes about 10 GPU days on an NVIDIA
V100 GPU.
The architecture found by our algorithm is shown in Figure 4. We manually add 2 skip connections for the Matching Net, one is between node 2 and 5, the other is 5 and 9. Noting that we only perform the architecture search once on the SceneFlow dataset and ﬁne-tuned the searched architecture weights on each benchmark separately. 3.2 Benchmark Evaluation
SceneFlow dataset We evaluate our LEAStereo network on SceneFlow [3] test set with 192 disparity level. We use average end point errors (EPE) and bad pixel ratio with 1 pixel threshold (bad 1.0) as our benchmark metrics. In Table 1, we can observe that LEAStereo achieves the best performance using only near one third of parameters in comparison to the SOTA hand-crafted methods (e.g., [6]). Furthermore, the previous SOTA NAS-based method AutoDispNet [25] has 20× more parameters than our architecture. We show some of the qualitative results in Figure 7.
Table 1: Quantitative results on Scene Flow dataset. Our method achieves state-of-the-art performance with only a fraction of parameters. The parentheses indicate the test set is used for hyperparameters tuning.
Methods
Params [M]
EPE [px] bad 1.0 [%]
Runtime [s]
GCNet [4] iResNet[5]
PSMNet [11]
GANet-deep [6]
AANet [26]
AutoDispNet [25]
LEAStereo 3.5 43.34 5.22 6.58 3.9 37 1.81 1.84 2.45 1.09 0.78 0.87 (1.51) 0.78 15.6 9.28 12.1 8.7 9.3
-7.82 0.9 0.2 0.4 1.9 0.07 0.34 0.3
KITTI benchmarks As shown in Table 2 and the leader board, our LEAStereo achieves top 1 rank among other human designed architectures on KITTI 2012 and KITTI 2015 benchmarks. Figure 5 provides some visualizations from the testsets.
I
T
T
I
K 2 1 0 2
I
T
T
I
K 5 1 0 2
Left Image
AutoDispNet-CSS [25]
GANet-deep [6]
LEAStereo
Figure 5: Qualitative results on KITTI 2012 and KITTI 2015 benchmarks.
Middlebury 2014 Middlebury 2014 is often considered to be the most challenging dataset for deep stereo networks due to restricted number of training samples and also the high resolution imagery 6
Table 2: Quantitative results on the KITTI 2012 and 2015 benchmark. Bold indicates the best.
KITTI 2012
KITTI 2015
Methods bad 2.0 noc [%] bad 3.0 Reﬂ 3.0 Avg All noc [%] noc [%]
[px]
Avg All
FG
Non Occ[%]
FG
Avg All
All Areas[%]
GCNet [4]
PSMNet [11]
GANet-deep [6]
DispNetC [3]
AANet [26]
AutoDispNet-CSS [25]
LEAStereo 2.71 2.44 1.89 7.38 2.90 2.54 1.90 1.77 1.49 1.19 4.11 1.91 1.70 1.13 10.80 8.36 6.22 16.04 10.51 5.69 5.35 0.7 0.6 0.5 1.0 0.6 0.5 0.5 5.58 4.31 3.39 3.72 1.80 2.98 2.65 2.61 2.14 1.84 4.05 2.32 2.00 1.51 6.16 4.62 3.91 4.41 1.99 3.37 2.91 2.87 2.32 2.03 4.34 2.55 2.18 1.65 with many thin objects. The full resolution of Middlebury is up to 3000 × 2000 with 800 disparity levels which is prohibitive for most deep stereo methods. This has forced several SOTA [11, 32] to operate on quarter-resolution images where details can be lost. In contrast, the compactness of our searched architecture compactness allows us to use images of size 1500 × 1000 with 432 disparity levels. In Table 3, we report the latest benchmark of volumetric based stereo matching method [11] and direct regression approaches [5, 26] for comparisons. Our proposed LEAStereo achieves the state-of-the-art rank on various metrics (e.g.,bad 4.0, all) among more than 120 stereo methods from the leader board. We also note that our network has better performance on large error thresholds, which might because of the downsampling operations prohibit the network to learn sub-pixel accuracy or the loss function that does not encourage sub-pixel accuracy.
Table 3: Quantitative results on the Middlebury 2014 Benchmark. Bold indicates the best. The red number on the top right of each number indicates the actual ranking on the benchmark.
Methods bad 2.0 [%] all nonocc bad 4.0 [%] Ave Err [px] all nonocc nonocc all
RMSE [px] all nonocc
A90 [px] all nonocc
A95 [px] all nonocc
PSMNet [11] 42.1108 47.2104 23.597 29.294 6.6869 8.7843 19.450 23.322 17.077 22.851 31.365 43.432 iResNet [5] 22.962 29.561 12.655 18.549 3.3130 4.677 11.38 13.96 6.6149 10.624 12.537 20.77
AANet+ [26] 15.444 22.040 10.845 16.442 6.3766 9.7749 23.573 29.442 7.5556 29.358 48.880 76.163 10.226 16.519 4.8317 9.688 2.072 3.442 10.34 13.43 2.1220 4.265 4.326 17.64
HSM [33] 2.751 6.331 1.431 2.891 8.111 13.75 1.688 2.621 2.651 6.351 7.1510 12.15
LEAStereo
Left image
HSM [33]
HSM [33] bad 4.0
LEAStereo
LEAStereo bad 4.0
Figure 6: Qualitative results on Middlebury 2014 Benchmark. 3.3 Ablation Study
In this part, we perform ablation studies using the SceneFlow dataset [3] to justify “hyper-parameters” of our algorithm. In particular, we look into the candidate operations O, differences between the residual and the direct cells, joint-search vs. separate-search of the Feature Net and the Matching
Net, and functionality analysis for each sub-net. We also provide a head-to-head comparison to
AutoDispNet [25].
Candidate Operations Here we evaluate two sets of candidate operations Olarge and Oours. The
Olarge consists of 8 operations including various types of convolution ﬁlters, pooling and connection mechanisms that are commonly used in [27, 18, 25]4. The Oours as described in § 2.1.1 only contains 3 × 3 convolution, skip connection and zero connection. For the Matching Net, we simply use the 4Namely, Olarge contains 3 × 3 and 5 × 5 depth-wise separable convolutions, 3 × 3 and 3 × 3 dilated separable convolutions with dilation factor 2, skip connection, 3 × 3 average pooling, 3 × 3 max pooling and zero connection. 7
Table 4: Ablation Studies of different searching strategies. The input resolution is 576 × 960, and EPE is measured on total SceneFlow test set.
Olarge
√
Oours
√
√
√
Architecture Variant
Sepa.
√
√
Join.
Direct
√
√
√
Residual
√
√
√
Achieved Network
FLOPS
Params
EPE 0.68M 2.00M 1.52M 1.81M 682.8G 782.4G 538.9G 782.2G 1.55px 0.86px 0.91px 0.78px
Left image
GT
Feature Net result
Full Network result
Figure 7: Functionality analysis for the Feature Net and the Matching Net. By using the learned features from the Feature Net directly, we already achieve reasonably good results as shown in the third sub-ﬁgure. After applying the Matching Net, we could further improve the results signiﬁcantly as evidenced by the gap between the third and fourth sub-ﬁgures. 3D variants of these operations. As shown in the ﬁrst two rows of Table 4, larger set of operations pool Olarge leads to a searched architecture with a much lower number of parameters but poor EPE performance when compared to Oours. The reason is that the algorithm favors skip connections in its design, leading to a low-capacity architecture. Similar observations, albeit in another context, are reported in [34].
Joint-search vs. Separate-search To analyze the effectiveness and efﬁciency of joint-search vs. separate-search, we report their performances on SceneFlow dataset with O and connection type ﬁxed.
From the metrics of row 2 and 4 in Table 4, we observe that joint-search outperforms separate-search by an improved margin of 9.30% for EPE and 10.50% reduction on the number of parameters. We conjecture that the joint-search increases the capacity and compatibility for both Feature Net and
Matching Net.
Residual cell vs. Direct cell We then study the differences between our proposed residual cell and direct cell. As shown in the last two rows of Table 4, using residual cell slightly generates more parameters and FLOPs but increase the performance by 14.29%.
Functionality analysis for each sub-net The Feature Net and the Matching Net own different roles in stereo matching. The Feature Net is designed to extract distinctive features from stereo pairs while the Matching Net is to compute matching costs from these features. To analyze and reﬂect the actual behaviour of each searched sub-net, we use the features from the Feature Net to directly compute a cost volume with dot products [2] and project it to a disparity map with the
Winner-Takes-All (WTA) strategy. As shown in Figure 7, this strategy already achieves a reasonably good result in correctly estimating disparity for most objects, which demonstrates that our Feature
Net is learning discriminative features for stereo matching. The difference between the third and fourth sub-ﬁgures (before and after the Matching Net) proves the contribution of the Matching Net in computing and aggregating the matching costs to achieve much better results. 3.4 Discussion
LEAStereo vs. AutoDispNet AutoDispNet [25] has a very different network design philosophy than ours. It is a large U-Net-like architecture and tries to directly regress disparity maps from input images in pixel space. In contrast, our design beneﬁts from task-speciﬁc physics and inductive bias, ie.,the gold standard pipeline for deep stereo matching and the reﬁne search space, thus achieves full architecture search within current physical constraints. Table 5 provides a head-to-head comparison on
KITTI Benchmark. It is worth noting that our method is 32.12% better than AutoDispNet-CSS [25] with only 1.81M parameters (which is 1.7% of the parameters required by AutoDispNet-CSS!)
Hints from the found architecture There are several hints from the found architecture: 1. The feature net does not need to be too deep to achieve a good performance; 2. Larger feature volumes lead to better performance (1/3 is better than 1/6); 3. A cost volume of 1/6 resolution seems 8
Table 5: LEAStereo vs. AutoDispNet
Methods
Search Level
Params
KITTI 2012
KITTI 2015
Runtime
AutoDispNet-CSS
LEAStereo
Cell
Full Network 111M 1.8M 1.70% 1.13% 2.18% 1.65% 0.9 s 0.3 s proper for good performance; 4. Multi-scale fusion seems important for computing matching costs (ie.,using a DAG to fuse multi-scale information). Note that the fourth hint has also been exploited by
AANet [26] which builds multiple multi-scale cost volumes and regularizes them with a multi-scale fusion scheme. Our design is tailored for the task of stereo matching and may not be considered as a domain agnostic solution for a different problem. For different domains, better task-dependent NAS mechanisms are still a suitable solution to efﬁciently incorporate inductive bias and physics of the problem into the search space. 4