Abstract
Biological systems face dynamic environments that require continual learning. It is not well understood how these systems balance the tension between ﬂexibility for learning and robustness for memory of previous behaviors. Continual learning without catastrophic interference also remains a challenging problem in machine learning. Here, we develop a novel learning rule designed to minimize interfer-ence between sequentially learned tasks in recurrent networks. Our learning rule preserves network dynamics within activity-deﬁned subspaces used for previously learned tasks. It encourages dynamics associated with new tasks that might other-wise interfere to instead explore orthogonal subspaces, and it allows for reuse of previously established dynamical motifs where possible. Employing a set of tasks used in neuroscience, we demonstrate that our approach successfully eliminates catastrophic interference and offers a substantial improvement over previous contin-ual learning algorithms. Using dynamical systems analysis, we show that networks trained using our approach can reuse similar dynamical structures across similar tasks. This possibility for shared computation allows for faster learning during sequential training. Finally, we identify organizational differences that emerge when training tasks sequentially versus simultaneously. 1

Introduction
Computations in the brain are thought to be implemented via the dynamical evolution of activity within large populations of neurons. This dynamical systems view has offered insight into computational mechanisms underlying motor control [1], decision making [2–4] and timing tasks [5]. In these studies, animals are trained to perform a single task and neural population activity is typically recorded only after learning. Little is known about how a single neural population can learn to perform multiple computations without interference or forgetting, as new tasks are learned in sequence.
Based on recent experimental results on neural population subspace structure [6–8], we hypothesize that a careful organization of population dynamics into either orthogonal or shared subspaces may provide a robust implementation of multi-task computations that could also prove beneﬁcial for se-quential task learning. Similar tasks could evolve under similar dynamics in a shared subspace, while
∗Equal Contribution
†Equal Contribution 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
dissimilar tasks, or dissimilar components of tasks, could be conﬁned to orthogonal subspaces. This organization would limit interference across unrelated computations and could allow for dynamics within each subspace to be learned independently.
To test and reﬁne these ideas, we turn to training and analysis of recurrent neural networks (RNNs).
Guided by the biological solution, we develop a novel algorithm for continual multi-task learning in
RNNs. Our approach is based on a modiﬁcation of the stochastic gradient descent (SGD) update to the network weights. Our learning rule aims to preserve network dynamics within subspaces used for previously learned tasks, and encourages interfering dynamics to explore orthogonal subspaces when learning new tasks.
We demonstrate our approach on networks trained to perform multiple tasks akin to those studied by neuroscientists in animal models [9]. Our proposed learning algorithm outperforms previous weight-regularization-based continual learning approaches on these tasks. We show that our learning rule encourages networks to utilize nearly orthogonal subspaces across tasks with opposite stimulus-response relationships that would otherwise interfere, but share subspaces for computations on similar tasks. Shared structure across similar tasks facilitates faster learning during sequential training.
We highlight key differences in task alignment for networks trained under our sequential approach compared with those trained simultaneously on all tasks.
Ultimately, developing better approaches for continual learning in RNNs will provide new tools to investigate the organization of dynamics across tasks, and will aid the development of hypotheses about and comparisons with multi-task computation in the brain. 2