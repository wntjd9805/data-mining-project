Abstract
We consider the problem of nonnegative submodular maximization in the online setting. At time step t, an algorithm selects a set St ∈ C ⊆ 2V where C is a feasible family of sets. An adversary then reveals a submodular function ft. The goal is to design an efﬁcient algorithm for minimizing the expected approximate regret.
In this work, we give a general approach for improving regret bounds in online submodular maximization by exploiting “ﬁrst-order” regret bounds for online linear optimization.
• For monotone submodular maximization subject to a matroid, we give an efﬁcient algorithm which achieves a (1 − c/e − ε)-regret of O((cid:112)kT ln(n/k)) where n is the size of the ground set, k is the rank of the matroid, ε > 0 is a constant, and c is the average curvature. Even without assuming any curvature (i.e., taking c = 1), this regret bound improves on previous results of Streeter et al. (2009) and Golovin et al. (2014).
√
• For nonmonotone, unconstrained submodular functions, we give an algorithm nT ), improving on the results of Roughgarden and Wang with 1/2-regret O( (2018). Our approach is based on Blackwell approachability; in particular, we give a novel ﬁrst-order regret bound for the Blackwell instances that arise in this setting. 1

Introduction
Submodular maximization is a ubiquitous optimization problem in machine learning, economics, and social networks [26]. A set function f : 2V → R on a ground set V is submodular if it satisﬁes the diminishing return property: f (X ∪ {i}) − f (X) ≥ f (Y ∪ {i}) − f (Y ) for X ⊆ Y and i ∈ V \ Y .
Given a nonnegative submodular function f and a set family C ⊆ 2V , submodular maximization is the optimization problem maxS∈C f (S). Although submodular maximization is NP-hard in general [11], approximation algorithms for various settings have been developed and they often perform very well in real-world applications [5, 6, 8, 12, 26, 31].
In this paper, we consider online submodular maximization in the full-information setting, which is formulated as the following repeated game between a player and an adversary. The player is given a set family C in a ground set V in advance. For each round t = 1, 2 . . ., the player plays a set St ∈ C possibly in a randomized manner and the adversary (perhaps knowing the player’s strategy but not the randomized outcome) selects a submodular function ft : 2V → [0, 1]. The player gains the reward 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
Table 1: A summary of our regret bounds and known bounds, where n = |V |, k is the rank of the matroid, c is the average curvature, ε > 0 is an arbitrary constant, and T is the time horizon. setting monotone+matroid (α = 1 − 1/e − ε) monotone+matroid
+ bounded curvature (α = 1 − c/e − ε) nonmonotone (α = 1/2) monotone+cardinality (α = 1 − 1/e) known results
√
O(k nT )
Golovin et al. [16]
— our results
O((cid:112)kT ln(n/k))
Theorem 3.1
O((cid:112)kT ln(n/k))
Theorem 3.1
√
√
T )
O(n
Roughgarden and Wang [27] kT ln n)
O(
Streeter and Golovin [29]
√ nT )
O(
Theorem 4.1
O((cid:112)kT ln(n/k))
Theorem 3.1 ft(St) and observes the submodular function ft.1 The performance is measured via the α-regret:
Regα(T ) := α max
S∗
T (cid:88) t=1 ft(S∗) −
T (cid:88) t=1 ft(St), where α ∈ (0, 1] corresponds to the ofﬂine approximation ratio. The goal of online submodular maximization is to design an efﬁcient algorithm for the player with a small α-regret in expectation. 1.1 Our contribution
We provide efﬁcient algorithms with improved regret bounds for various online submodular maxi-mization. Our results are summarized in Table 1.
• For the case of monotone functions and a matroid constraint, (i.e., ft is nonnegative, monotone, and submodular, and C is a matroid), we provide an algorithm whose expected (1 − c/e − ε)-regret is at most O((cid:112)kT ln(n/k)), where n = |V |, k is the rank of the matroid C, and ε > 0 is an arbitrary small constant. Here c is the curvature2 of (cid:80)T
T ) bound for the bounded curvature setting, generalizing the corresponding ofﬂine result [12, 31] to the online
√ setting. In the case where c = 1, this result improves the best-known bound of O(k nT ) [16, 30] by a factor of ˜Ω( kn). Note that the approximation ratio 1 − c/e is best possible for any algorithm making polynomially many queries to the objective function [31].
√
• For the nonmonotone and unconstrained setting (i.e., ft is nonnegative submodular and C = 2V ), nT ) expected 1/2-regret, where n = |V |. This improves the t=1 ft. This result is the ﬁrst O(
√
√ we devise an algorithm with O( best-known bound O(n
√
T ) [27] by a factor of n.
√
Finally, we remark that none of our algorithms require knowing the time horizon T in advance. 1.2 Technical overview
The common ingredient of our algorithms is the use of “ﬁrst-order” regret bounds for online linear optimization (OLO), which bound the regret of OLO algorithms in terms of the total gain or loss of the best single action rather than the time horizon T . We show that this data-dependent nature of ﬁrst-order bounds enables us to exploit the structures of OLO subproblems appearing in online submodular maximization and it yields better bounds for approximate-regret. Below, we provide detailed description of this idea for each submodular maximization problem we study.
Monotone Our algorithm is based on online continuous greedy [16, 30]. Roughly speaking, online continuous greedy reduces the problem to a series of OLO problems on a matroid polytope. For OLO on a matroid polytope, Golovin et al. [16] used follow the perturbed leader (FPL) [24], which gives 1Formally, each submodular function ft is given as a value oracle to the player after St is chosen. 2The curvature c of a nonnegative monotone submodular function f is deﬁned as c = 1 − mini∈V f (V \{i}) f ({i})
. 2
√ nT ) bound. The key observation to improving this bound is that the OLO subproblems that the O(k arise in this setting are structured in the sense that the sum of the rewards (across the subproblems) cannot be too large. Our technical contribution is a novel analysis of online continuous greedy showing that if one uses OLO algorithms with a ﬁrst-order regret bound [25], then online continuous greedy yields the improved O((cid:112)kT ln (n/k)) bound.
Furthermore, we show that combining the above techniques with the continuous greedy of Feldman
[12] gives an algorithm for maximization of monotone submodular functions with bounded curvature under a matroid constraint. In particular, we show that the expected (1 − c/e − ε)-regret is bounded by O((cid:112)kT ln(n/k)) where c is the curvature of the sum of the submodular functions. We note that our algorithm does not require knowledge of c beforehand.
√
Nonmonotone At a high level, our algorithm for the nonmonotone case is similar to online double greedy of Roughgarden and Wang [27], which we will review brieﬂy. They reduced the problem to a sequence of auxiliary online learning problems, called USM balance subproblems, for which they
T ) regret. They also showed that if one has algorithms for the USM designed an algorithm with O( balance subproblems with regret ri for i = 1, . . . , n, then online double greedy achieves O((cid:80) i ri) regret bound, which gives the O(n
T ) bound. Our contribution is a new algorithm for USM balance subproblems with a “ﬁrst-order” regret bound. Combining this algorithm with a novel analysis of
√ nT ) bound. To design the ﬁrst-order regret bound online double greedy, we obtain the improved O( for USM balance subproblems, we exploit the Blackwell approachability theorem [1] and online dual averaging. Note that Roughgarden and Wang [27] did not use the Blackwell theorem and it is not obvious how to obtain a similar “ﬁrst-order” bound from their analysis. We are not aware of other examples where similar regret bounds are known for Blackwell problems.
√ 1.3