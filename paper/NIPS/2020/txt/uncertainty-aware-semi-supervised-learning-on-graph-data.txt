Abstract
Thanks to graph neural networks (GNNs), semi-supervised node classiﬁcation has shown the state-of-the-art performance in graph data. However, GNNs have not considered different types of uncertainties associated with class probabilities to minimize risk of increasing misclassiﬁcation under uncertainty in real life.
In this work, we propose a multi-source uncertainty framework using a GNN that reﬂects various types of predictive uncertainties in both deep learning and belief/evidence theory domains for node classiﬁcation predictions. By collecting evidence from the given labels of training nodes, the Graph-based Kernel Dirichlet distribution Estimation (GKDE) method is designed for accurately predicting node-level Dirichlet distributions and detecting out-of-distribution (OOD) nodes. We validated the outperformance of our proposed model compared to the state-of-the-art counterparts in terms of misclassiﬁcation detection and OOD detection based on six real network datasets. We found that dissonance-based detection yielded the best results on misclassiﬁcation detection while vacuity-based detection was the best for OOD detection. To clarify the reasons behind the results, we provided the theoretical proof that explains the relationships between different types of uncertainties considered in this work. 1

Introduction
Inherent uncertainties derived from different root causes have realized as serious hurdles to ﬁnd effective solutions for real world problems. Critical safety concerns have been brought due to lack of considering diverse causes of uncertainties, resulting in high risk due to misinterpretation of uncertainties (e.g., misdetection or misclassiﬁcation of an object by an autonomous vehicle).
Graph neural networks (GNNs) [12, 21] have received tremendous attention in the data science community. Despite their superior performance in semi-supervised node classiﬁcation and regression, they didn’t consider various types of uncertainties in the their decision process. Predictive uncertainty estimation [11] using Bayesian NNs (BNNs) has been explored for classiﬁcation prediction and regression in the computer vision applications, based on aleatoric uncertainty (AU) and epistemic uncertainty (EU). AU refers to data uncertainty from statistical randomness (e.g., inherent noises in observations) while EU indicates model uncertainty due to limited knowledge (e.g., ignorance) in collected data. In the belief or evidence theory domain, Subjective Logic (SL) [9] considered vacuity (or a lack of evidence or ignorance) as uncertainty in a subjective opinion. Recently other uncertainty types, such as dissonance, consonance, vagueness, and monosonance [9], have been discussed based on SL to measure them based on their different root causes.
We ﬁrst considered multidimensional uncertainty types in both deep learning (DL) and belief and evi-dence theory domains for node-level classiﬁcation, misclassiﬁcation detection, and out-of-distribution (OOD) detection tasks. By leveraging the learning capability of GNNs and considering multi-dimensional uncertainties, we propose a uncertainty-aware estimation framework by quantifying 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
different uncertainty types associated with the predicted class probabilities. In this work, we made the following key contributions:
• A multi-source uncertainty framework for GNNs. Our proposed framework ﬁrst provides the estimation of various types of uncertainty from both DL and evidence/belief theory domains, such as dissonance (derived from conﬂicting evidence) and vacuity (derived from lack of evidence). In addition, we designed a Graph-based Kernel Dirichlet distribution Estimation (GKDE) method to reduce errors in quantifying predictive uncertainties.
• Theoretical analysis: Our work is the ﬁrst that provides a theoretical analysis about the rela-tionships between different types of uncertainties considered in this work. We demonstrate via a theoretical analysis that an OOD node may have a high predictive uncertainty under GKDE.
• Comprehensive experiments for validating the performance of our proposed framework:
Based on the six real graph datasets, we compared the performance of our proposed framework with that of other competitive counterparts. We found that the dissonance-based detection yielded the best results in misclassiﬁcation detection while vacuity-based detection best performed in OOD detection.
Note that we use the term ‘predictive uncertainty’ in order to mean uncertainty estimated to solve prediction problems. 2