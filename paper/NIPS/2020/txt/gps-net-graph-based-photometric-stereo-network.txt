Abstract
Learning-based photometric stereo methods predict the surface normal either in a per-pixel or an all-pixel manner. Per-pixel methods explore the inter-image intensity variation of each pixel but ignore features from the intra-image spatial domain. All-pixel methods explore the intra-image intensity variation of each input image but pay less attention to the inter-image lighting variation. In this paper, we present a Graph-based Photometric Stereo Network, which uniﬁes per-pixel and all-pixel processings to explore both inter-image and intra-image information.
For per-pixel operation, we propose the Unstructured Feature Extraction Layer to connect an arbitrary number of input image-light pairs into graph structures, and introduce Structure-aware Graph Convolution ﬁlters to balance the input data by appropriately weighting shadows and specular highlights. For all-pixel operation, we propose the Normal Regression Network to make efﬁcient use of the intra-image spatial information for predicting a surface normal map with rich details.
Experimental results on the real-world benchmark show that our method achieves excellent performance under both sparse and dense lighting distributions. 1

Introduction
Photometric stereo aims at estimating surface normals of a static object from a set of images acquired under various illumination conditions from a ﬁxed camera [1]. The pixel-wise estimation of surface orientation makes photometric stereo outstanding in acquiring high-resolution 3D information. Recent progress in deep learning has been veriﬁed to be effective in photometric stereo for general complex reﬂectance, showing superior accuracy over conventional methods on a benchmark dataset [2]. To design effective deep learning frameworks in the context of photometric stereo, the core problem is how to deal with a sequence of unordered and arbitrary numbers of input images under various illumination conditions. The ﬁrst deep photometric stereo network [3] ﬁxes the order and number of input images during training and testing. Following works focus on relaxing this unpractical assumption in dealing with unordered, arbitrary numbers of images, either in a per-pixel [4]–[6] or an all-pixel [7]–[9] manner, i.e., whether the observations of a single pixel or the whole image are fed to the network, according to a recent survey about data-driven photometric stereo [10].
As illustrated in the top row of Fig. 1, per-pixel methods explore the inter-image intensity1 variation by projecting the observations of each pixel into a ﬁxed-size observation map, according to the ﬁrst
∗Corresponding authors 1Throughout this paper, we assume the camera is radiometrically calibrated and the images are linearized, so we use “intensity" to refer to image irradiance for simplicity. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
Figure 1: Illustration of GPS-Net (bottom row) and state-of-the-art per-pixel [4]–[6] and all-pixel [7],
[8] learning-based photometric stereo methods (top row). two components of the two-degree-of-freedom normalized lighting directions (lx and ly) [4]–[6]. All-pixel methods explore the intra-image intensity variation by extracting features of each image-light pair separately using a shared-weight feature extractor before fusing them using a size-independent max-pooling layer [7], [8]. Then the unordered, arbitrary numbers of inputs are converted into a structured observation map or feature map, which can be fed into the subsequent CNN-based network to regress a pixel-wise surface normal or a complete normal map. Per-pixel methods ignore features from the intra-image spatial domain, and their observation maps have to take a trade off between resolution and density, which makes them difﬁcult to maintain good performance when the number of input images varies from sparse to dense. In contrast, the independent processing for each image in all-pixel methods prevents them from exploring the inter-image lighting variation, and their networks that make extensive use of 3×3 convolutional layers cause over-smoothing and loss of resolution details in the spatial domain.
In this paper, we present an end-to-end Graph-based Photometric Stereo Network, namely GPS-Net, which combines the advantages of per-pixel and all-pixel methods to explore both inter-image and intra-image variation, as shown in the bottom row of Fig. 1. To explore per-pixel information, the
Unstructured Feature Extraction Layer (UFE-Layer) is designed to connect an arbitrary number of inter-image observations of each pixel into a graph structure to avoid introducing the problem of the density of valid data; the Structure-aware Graph Convolution (SGC) ﬁlters in UFE-Layer are then adopted to deal with the topologically inconsistent graphs and extract a ﬁxed-size feature map from the unstructured data. SGC ﬁlters also learn adaptive weights for suppressing outliers (e.g., attached shadows and cast shadows), and emphasizing useful observations (e.g., specular highlights). To explore all-pixel information, the Normal Regression Network (NR-Net) is further designed to make efﬁcient use of the intra-image spatial information and regress a high-resolution and high-accuracy normal map. Experimental results demonstrate that GPS-Net achieves superior performance over state-of-the-art per-pixel and all-pixel methods, provides stable performance from sparse to dense lighting distributions, and maintains rich surface normal details for each pixel. 2