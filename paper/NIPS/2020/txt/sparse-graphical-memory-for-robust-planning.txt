Abstract
To operate effectively in the real world, agents should be able to act from high-dimensional raw sensory input such as images and achieve diverse goals across long time-horizons. Current deep reinforcement and imitation learning methods can learn directly from high-dimensional inputs but do not scale well to long-horizon tasks. In contrast, classical graphical methods like A* search are able to solve long-horizon tasks, but assume that the state space is abstracted away from raw sensory input. Recent works have attempted to combine the strengths of deep learning and classical planning; however, dominant methods in this domain are still quite brittle and scale poorly with the size of the environment. We introduce
Sparse Graphical Memory (SGM), a new data structure that stores states and feasible transitions in a sparse memory. SGM aggregates states according to a novel two-way consistency objective, adapting classic state aggregation criteria to goal-conditioned RL: two states are redundant when they are interchangeable both as goals and as starting states. Theoretically, we prove that merging nodes according to two-way consistency leads to an increase in shortest path lengths that scales only linearly with the merging threshold. Experimentally, we show that SGM signiﬁcantly outperforms current state of the art methods on long horizon, sparse-reward visual navigation tasks. Project video and code are available at https:
//mishalaskin.github.io/sgm/. 1

Introduction
Learning-driven approaches to control, like imi-tation learning and reinforcement learning, have been quite successful in both training agents to act from raw, high-dimensional input [34] as well as to reach multiple goals by condition-ing on them [1, 35]. However, this success has been limited to short horizon scenarios, and scal-ing these methods to distant goals remains ex-tremely challenging. On the other hand, clas-sical planning algorithms have enjoyed great success in long-horizon tasks with distant goals by reduction to graph search [18, 25]. For in-stance, A* was successfully used to control
Shakey the robot for real-world navigation over
ﬁve decades ago [7]. Unfortunately, the graph nodes on which these search algorithms operate
Figure 1: Illustration of Sparse Graphical Memory (SGM). New states are either merged with existing graph nodes according to our two-way consistency criterion, or a new node is generated. After graph construction, incorrect edges representing infeasi-ble transitions are corrected.
*Equal contribution. Author order determined randomly. {emmons, ajayj, mlaskin}@berkeley.edu 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
(a) Node merging example (b) Node creation example
Figure 2: Examples where two-way consistency (TWC) merges nodes (left) and creates a new node (right). Consider a directed graph with three nodes connected as A ↔ B → C. Given a new image in the dashed yellow box, should it be merged into an existing node or a new node be created? (a) On the left, we can merge the new image with node A safely. (b) On the right, the new image D contains a bottle which is about to fall off the table edge. While B is perceptually similar to the new image, the agent cannot move the bottle from D to A, but it can move from B to A. As we cannot transition to neighbors in the same manner, our TWC criterion is not satisﬁed and a new node is created. is abstracted away from raw sensory data via domain-speciﬁc priors, and planning over these nodes assumes access to well-deﬁned edges as well as a perfect controller to move between nodes. Hence, these planning methods struggle when applied to agents operating directly from high-dimensional, raw-sensory images [32].
How can we have best of both worlds, i.e., combine the long-horizon ability of classic graph-based planning with the ﬂexibility of modern, parametric, learning-driven control? One way is to build a graph out of an agent’s experience in the environment by constructing a node for every state and use a learning-based controller (whether RL or imitation) to move between those nodes. Some recent work has investigated this combination in the context of navigation [9, 41]; however, these graphs grow quadratically in terms of edges and quickly become unscalable beyond small mazes [9]. This strategy either leads to extremely brittle plans because such large graphs contain many errors (infeasible transitions represented by edges), or relies on human demonstrations for bootstrapping [41].
In this work, we propose to address challenges in combining the classical and modern paradigms by dynamically sparsifying the graph as the agent collects more experience in the environment to build what we call Sparse Graphical Memory (SGM), illustrated in Figure 1. In fact, building a sparse memory of key events has long been argued by neuroscientists to be fundamental to animal cognition.
The idea of building cognitive topological maps was ﬁrst demonstrated in rats by seminal work of [47].
The key aspect that makes building and reasoning over these maps feasible in the ever-changing, dynamic real world is the sparse structure enforced by landmark-based embedding [12, 14, 48]. Yet, in artiﬁcial agents, automatic discovery of sparse landmark nodes remains a key challenge.
One way to discover a sparse graph structure is to dynamically merge similar nodes. But how does one obtain a similarity measure? This is a subtle but central piece of the puzzle. States that look similar in the observation space may be far apart in the action space, and vice-versa. Consider the example in Figure 2, where the graph already contains 3 nodes {A, B, C}. In 2a, similar looking nodes can be merged safely. While in 2b, although the new node D is visually similar to B, but merging with
B would imply that the bottle can be saved from breaking. Therefore, a purely visual comparison of the scenes cannot serve as a viable metric. We propose to use an asymmetric distance function between nodes and employ two-way consistency (TWC) as the similarity measure for merging nodes dynamically. The basic idea is that two nodes are similar if they both can be reached with a similar number of steps from all their neighbors as well as if all their neighbors can be reached from both of them with similar effort. For our conceptual example, it is not possible to go back from the falling-bottle to the standing-bottle, and hence the two-way consistency does not align for scene B and the new state. Despite similar visual appearance, they will not be merged. We derive two-way consistency as an extension of prior Q-function based aggregation criteria to goal-conditioned tasks, and we prove that the sparse graphs that result from TWC preserve (up to an error factor that scales linearly with the merging threshold) the quality of the original dense graphs.
We evaluate the success of our method, SGM, in a variety of navigation environments. First, we observe in Table 1 that SGM has a signiﬁcantly higher success rate than previous methods, on average increasing the success rate by 2.1x across the environments tested. As our ablation experiments demonstrate, SGM’s success is due in large part to its sparse structure that enables efﬁcient correction 2
of distance metric errors. In addition, we see that the performance gains of SGM hold across a range of environment difﬁculties from a simple point maze to complex visual environments like ViZDoom and SafetyGym. Finally, compared to prior methods, planning with our proposed sparse memory can lead to nearly an order of magnitude increase in speed (see Appendix E). 2