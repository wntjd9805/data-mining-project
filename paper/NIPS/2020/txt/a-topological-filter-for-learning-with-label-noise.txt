Abstract
Noisy labels can impair the performance of deep neural networks. To tackle this problem, in this paper, we propose a new method for ﬁltering label noise. Unlike most existing methods relying on the posterior probability of a noisy classiﬁer, we focus on the much richer spatial behavior of data in the latent representational space. By leveraging the high-order topological information of data, we are able to collect most of the clean data and train a high-quality model. Theoretically we prove that this topological approach is guaranteed to collect the clean data with high probability. Empirical results show that our method outperforms the state-of-the-arts and is robust to a broad spectrum of noise types and levels. 1

Introduction
Corrupted labels are ubiquitous in real world data, and can severely impair the performance of deep neural networks with strong memorization ability [30, 12, 51]. Label noise may arise in mistakes of human annotators or automatic label extraction tools, such as crowd sourcing and web crawling for images [48, 42]. Improving the robustness of deep neural networks to label corruption is critical in many applications [29, 45], yet still remains a challenging problem and largely under-studied.
To combat label noise, state-of-the-art methods often segregate the clean data (i.e., samples with uncorrupted labels) from the noisy ones. These methods collect clean data iteratively and eventually train a high-quality model. The major challenge is to ensure that the data selection procedure is (1) careful enough to not accumulate errors; and (2) aggressive enough to collect sufﬁcient clean data to train a strong model. Existing methods under this category [27, 21, 16, 43, 31] typically select clean data based on the prediction of the noisy classiﬁer. It is generally assumed that if the noisy classiﬁers have strong and consistent conﬁdence on a particular label, this label is likely true.
However, most of these heuristics do not have a theoretical foundation and thus are not guaranteed to generalize to unseen datasets or noise patterns.
In this paper, we propose to investigate the problem in a novel topological perspective. We stipulate that while a noisy classiﬁer’s prediction is useful, its latent space representation of the data also contains rich information and should be exploited. Our method is motivated by the following observation: given an ideal feature representation, the clean data are clustered together while the corrupted data are spread out and isolated. This intuition is illustrated in Figure 1(a). We show the spatial distribution pattern of a corrupted dataset with an ideal representation, i.e., the penultimate layer activation (the layer before softmax) of a neural net trained on the original uncorrupted dataset.
As is shown in Figure 1(a)(left), the data are well separated into clusters, corresponding to their true labels. Meanwhile, noisy-labeled data (colorful crumbs sprinkled on each cluster) are surrounded by uncorrupted data and thus are isolated.
The above observation inspires us to utilize the spatial topological pattern for label noise ﬁltering.
We propose a new method, TopoFilter, that collects clean data by selecting the largest connected
∗Equal contributions. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
Figure 1: Different representations of a 40% uniformly corrupted CIFAR-10 dataset (visualized using t-SNE). (a) The ideal feature representation (trained on a clean dataset). On the left, we show the whole dataset. Colors correspond to different noisy labels. On the right, we draw all data with label 1.
Green points are clean data. Red points are data with corrupted labels. (b) A skewed representation of a noisy classiﬁer, namely, one trained using the corrupted dataset. (c) The learned representations by our algorithm. We show the data of label 1 using the continuously improved representations. The collected data by our method are highlighted with the blue contour. component of each class and dropping isolated data. Our method leverages the group behavior of data in the latent representation, which has been neglected by previous classiﬁer-conﬁdence-dependent approaches. The challenge is that the ideal representation is unavailable in practice. Training on noisy data leads to a skewed representation (Fig. 1(b)); and the topological intuition does not seem to hold.
To address this issue, we propose an algorithm that uses the topological intuition even with the
“imperfect” representation. Our algorithm essentially “peels” the outer most layer of the largest component so that only the core of the component is kept. One particular strength of our method is that it is theoretically guaranteed to be correct. We prove (1) purity: the collected data have a high chance to be uncorrupted; and (2) abundancy: the algorithm can collect a majority of the clean data.
These two guarantees ensure the algorithm can collect clean data both carefully and aggressively.
Our proof imposes weak assumptions on the representation: (1) the density of the data has a compact support, (2) the true conditional distributions of different labels are continuous, and (3) the decision region of each class of the Bayes optimal classiﬁer is connected. These relative weak assumptions ensures that the theorem still holds on the skewed representation (from a noisy classiﬁer).
We wrap our data collection algorithm to jointly learn the representation and select clean data. To learn the representation, we train a deep net classiﬁer only using the collected clean data. As the classiﬁer continuously improves, it further facilitates the data collection and ﬁnally converges to a strong one, as illustrated in Fig. 1(c). We empirically validate the proposed method on different datasets such as CIFAR-10, CIFAR-100 and Clothing1M [47]. Our method consistently outperforms the existing methods under a wide range of noise types and levels.
To summarize, we propose the ﬁrst theoretically guaranteed algorithm for label noise that exploits a topological view of the noisy data representation. Our paper offers both the algorithmic intuition and the theoretical rationale on how spatial pattern and group behavior of data in the latent space can be informative of the model training. We believe the geometry and topology of data in the latent space should be further explored for better understanding and regulating of neural networks.