Abstract
Progress in the ﬁeld of machine learning has been fueled by the introduction of benchmark datasets pushing the limits of existing algorithms. Enabling the design of datasets to test speciﬁc properties and failure modes of learning algorithms is thus a problem of high interest, as it has a direct impact on innovation in the ﬁeld.
In this sense, we introduce Synbols — Synthetic Symbols — a tool for rapidly generating new datasets with a rich composition of latent features rendered in low resolution images. Synbols leverages the large amount of symbols available in the Unicode standard and the wide range of artistic font provided by the open font community. Our tool’s high-level interface provides a language for rapidly generating new distributions on the latent features, including various types of textures and occlusions. To showcase the versatility of Synbols, we use it to dissect the limitations and ﬂaws in standard learning algorithms in various learning setups including supervised learning, active learning, out of distribution generalization, unsupervised representation learning, and object counting. 1

Introduction
Open access to new datasets has been a hallmark of machine learning progress. Perhaps the most iconic example is ImageNet [9], which spurred important improvements in a variety of convolutional architectures and training methods. However, obtaining state-of-the-art performances on ImageNet can take up to 2 weeks of training with a single GPU [51]. While it is beneﬁcial to evaluate our methods on real-world large-scale datasets, relying on and requiring massive computation cycles is limiting and even contributes to biasing the problems and methods we develop:
• Slow iteration cycles: Waiting weeks for experimental results reduces our ability to explore and gather insights about our methods and data.
• Low accessibility: It creates disparities, especially for researchers and organizations with limited computation and hardware budgets.
• Poor exploration: Our research is biased toward fast methods. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
• Climate change impact: Recent analyses [48, 28] conclude that the greenhouse gases emitted from training very large-scale models, such as transformers, can be equivalent to 10 years’ worth of individual emissions.1
A common alternative is to use smaller-scale datasets, but their value to develop and debug powerful methods is limited. For example, image classiﬁcation datasets such as MNIST [31], SVHN [38] or
CIFAR [24] each contain less than 100,000 low-resolution (32 × 32 pixels) images which enables short learning epochs. However, these datasets provide a single task and can prevent insightful model comparison since, e.g., modern learning models obtain above 99% accuracy on MNIST.
In addition to computational hurdles, ﬁxed datasets limit our ability to explore non-i.i.d. learning paradigms including out-of-distribution generalization, continual learning and, causal inference. I.e., the algorithms can latch onto spurious correlations, leading to highly detrimental consequences when the evaluation set comes from a different distribution [3]. Similarly, learning disentangled representations requires non i.i.d. data for both training and properly evaluating [34, 20, 46]. This raises the need for good synthetic datasets with a wide range of latent features.
We introduce Synbols2, an easy to use dataset generator with a rich composition of latent features for lower-resolution images. Synbols uses Pycairo, a 2D vector graphics library, to render UTF-8 symbols with a variety of fonts and patterns. Fig. 1 showcases generated examples from several attributes (§ 2 provides a complete discussion). To expose the versatility of Synbols, we probe the behavior of popular algorithms in various sub-ﬁelds of our community. Our contributions are:
• Synbols: a dataset generator with a rich latent feature space that is easy to extend and provides low resolution images for quick iteration times (§ 2).
• Experiments probing the behavior of popular learning algorithms in various machine-learning settings including: the robustness of supervised learning and unsupervised representation-learning approaches w.r.t. changes in latent-data attributes (§ 3.1 and 3.4) and to particular out-of-distribution patterns (§ 3.2), the efﬁcacy of different strategies and uncertainty calibration in active learning (§ 3.3), and the effect of training losses for object counting (§ 3.5).