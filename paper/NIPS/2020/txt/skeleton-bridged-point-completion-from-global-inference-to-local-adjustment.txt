Abstract
Point completion refers to complete the missing geometries of objects from partial point clouds. Existing works usually estimate the missing shape by decoding a latent feature encoded from the input points. However, real-world objects are usually with diverse topologies and surface details, which a latent feature may fail to represent to recover a clean and complete surface. To this end, we propose a skeleton-bridged point completion network (SK-PCN) for shape completion.
Given a partial scan, our method ﬁrst predicts its 3D skeleton to obtain the global structure, and completes the surface by learning displacements from skeletal points.
We decouple the shape completion into structure estimation and surface recon-struction, which eases the learning difﬁculty and beneﬁts our method to obtain on-surface details. Besides, considering the missing features during encoding input points, SK-PCN adopts a local adjustment strategy that merges the input point cloud to our predictions for surface reﬁnement. Comparing with previous methods, our skeleton-bridged manner better supports point normal estimation to obtain the full surface mesh beyond point clouds. The qualitative and quantitative experiments on both point cloud and mesh completion show that our approach outperforms the existing methods on various object categories. 1

Introduction
Shape completion shows its unique signiﬁcance in fundamental applications such as 3D data scanning
& acquisition and robot navigation. It focuses on completing the missing topologies and geometries of an object from partial and incomplete observations, e.g., point clouds captured under occlusion, weak illumination or limited viewpoints. Unlike image completion [15, 44, 23] that is well addressed with CNN-based approaches, point clouds present inherent irregularity and sparseness that challenge the direct application of grid-based convolutions to 3D shape completion.
Deep learning methods attempt to achieve this target with various representations, e.g., points
[28, 42, 32, 14, 36, 20, 40, 37], voxels [10, 2, 35, 8, 12] or implicit ﬁelds [19, 29, 22, 5]. Voxels discretize the shape volume into 3D grids. It preserves shape topology but ﬁne-detailed voxel quality relies on high resolution, improving which exponentially increases the time consumption. Implicit
ﬁelds represent shapes with a signed distance function (SDF). Theoretically it can achieve arbitrary resolution though, learning an accurate SDF still relies on the quality of voxel grids, and these methods require massive spatial sampling to obtain an SDF for a single object, which distinctly increases the inference time [19, 29, 22, 5]. Besides, both voxel and SDF methods do not preserve the surface information and present defective results on complex structures. Point cloud is a natural representation of shapes that discretizes the 2-manifold surface. Comparing with voxels and SDFs, 3D points are more controllable, scalable and efﬁcient for learning, which makes it popular for shape completion.
However, existing methods commonly adopt an encoder&decoder to parse 3D points [42, 32], making
† Work done during internship at Shenzhen Research Institute of Big Data, The Chinese Univerisity of
Hong Kong, Shenzhen (SRIBD, CUHKSZ).
∗ Corresponding author: hanxiaoguang@cuhk.edu.cn 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
Figure 1: From a partial scan of an object (green points), SK-PCN estimates its meso-skeleton (grey points) to explicitly extract the global structure, and pairs the local-global features for displacement regression to recover the full surface points (blue points) with normals for mesh reconstruction (right). them struggle to keep shape topology and produce coarse results. Mesh-based methods recover ordered surface points, but current methods predict object meshes by deforming templates (e.g., meshed spheres or planes [11]), making it restricted from recovering complex structures.
To preserve the shape structure and complete surface details, we provide a new completion manner, namely SK-PCN, that maps the partial scan to the complete surface bridged via the meso-skeleton
[38] (see Figure 1). Recovering the missing structure and details from an incomplete scan generally requires both global and local features. Instead of using encoders to extract a latent layer response as the global feature [41, 14, 42, 36], we explicitly learn the meso-skeleton as the global abstraction of objects, which is represented by 3D points located around the medial axis of a shape. Comparing with surface points, meso-skeleton holds a more smooth and compact shape domain, making networks easier to be trained. It also keeps the shape structure that helps predict topology-consistent meshes.
To further recover surface details, prior works usually expand the global feature with upsampling
[41, 18] or skip connections [36, 37] by revisiting local features from previous layers. Our method completes shape details with an interpretable manner, that is learning to grow surface points from the meso-skeleton. Speciﬁcally, SK-PCN dually extracts and pairs the local features from the partial scan and the meso-skeleton under multiple resolutions, to involve corresponding local features to skeletal points. As local structures are commonly with repetitive patterns (e.g., table legs are usually with the same geometry), we bridge these local-global feature pairs with a Non-Local Attention module to select and propagate those contributive local features from the global surface space onto skeletal points for missing shape completion. Moreover, to preserve the ﬁdelity on observable regions, we devise a local reﬁnement module and a patch discriminator to merge the original scan to the output.
Unlike previous methods where point coordinates are directly regressed, we complete the surface by learning displacements from skeletal points. It is not only because learning residuals is easier for training [13]. These displacement values show high relevance with surface normals [38], which better supports the point normal estimation for our mesh reconstruction.
Our contributions are three-fold. First, we provide a novel learning modality for point completion by mapping partial scans to complete surfaces bridged via meso-skeletons. This intermediate representation preserves better shape structure to recover a full mesh beyond point clouds. Second, we correspondingly design a completion network SK-PCN. It end-to-end aggregates the multi-resolution shape details from the partial scan to the shape skeleton, and automatically selects the contributive features in the global surface space for shape completion. Third, we fully leverage the original scan for local reﬁnement, where a surface adjustment module is introduced to ﬁne-tune our results for a high-ﬁdelity completion. Extensive experiments on various categories demonstrate that our method outperforms previous methods and reaches the-state-of-the-art. 2