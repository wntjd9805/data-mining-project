Abstract
We introduce an approach for establishing dense correspondences between par-tial scans of human models and a complete template model. Our approach’s key novelty lies in formulating dense correspondence computation as initializ-ing and synchronizing local transformations between the scan and the template model. We introduce an optimization formulation for synchronizing transforma-tions among a graph of the input scan, which automatically enforces smoothness of correspondences and recovers the underlying articulated deformations. We then show how to convert the iterative optimization procedure among a graph of the input scan into an end-to-end trainable network. The network design uti-lizes additional trainable parameters to break the barrier of the original optimiza-tion formulation’s exact and robust recovery conditions. Experimental results on benchmark datasets demonstrate that our approach considerably outperforms baseline approaches. Our result, pretrained model and code are publicly available at https://github.com/xiangruhuang/HumanCorresViaLearn2Sync. 1

Introduction
We introduce a novel approach for computing dense correspondences between partial scans of human subjects and a complete template model. The correspondences computed with our approach are more accurate than the state of the art, and are robust to input noise, pose of the scanned subject, and variations in body shape and other non-rigid deformations of the scan relative to the template. Our method is also efﬁcient, capable of matching a 3 000-point partial scan to a 6 890-vertex template in under 66 ms—suitable for real-time tracking applications running at 15 fps.
Algorithms for computing dense correspondences typically combine two key ideas. Local geometric features are used to match points on the source to candidate points on the target. Only a sparse set of prominent feature points can be reliably matched using these shape cues; to compute high-quality dense correspondences insensitive to noise, pose, and global symmetries (such as human bilateral symmetry), priors are enforced in the form of global regularization constraints (such as preservation of pairwise distances or orientation [23, 46]).
While early works used hand-crafted shape descriptors to identify geometric features [23], recent approaches [51, 15, 42, 31, 13, 17] have demonstrated that deep neural networks excel at this task.
However, the use of neural networks introduces a new challenge: there are many possible choices for how to represent the set of dense correspondences [3, 2, 19, 29, 38, 33], and this choice of data representation is critical, as it dictates which neural network architectures can be used and what types of regularization constraints can be enforced. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
Our approach is motivated by the observation that the human body behaves, to good approximation, as an articulated rigid body; poses can be explained by deformations that are almost rigid locally [44], away from the joints. Similarly, mappings between different subjects are also nearly piecewise-rigid, where variation in body shape can be explained by a small and almost-constant deviation away from a rigid transformation at the local scale. Our key idea, then, is to use local rigid transformations as the data representation for correspondences: we associate to each source point a rigid transformation that characterizes the local source-to-target deformation near that point, and formulate dense correspondence computation as synchronization of these local transformations over the graph of nearest neighbors on the input scan.
We initialize these local rigid transformations by ﬁtting dense correspondences derived from a learned shape descriptor, and then perform transformation synchronization to jointly optimize the local rigid transformations. Motivated by recent trends in formulating iterative optimization procedures as recurrent neural networks [58, 40, 24, 22, 50], and recent advances in graph convolution [57, 52], we formulate transformation synchronization as a recurrent neural network. Driven by a robust optimization formulation of transformation synchronization, an essential advantage of our approach is that it automatically enforces smoothness of correspondences, and these correspondences are locally explainable in terms of articulated rigid motion of the source away from the target. The entire network (including both transformation initialization and synchronization) admits end-to-end training.
We evaluate the proposed technique on multiple benchmark datasets. Our correspondences have mean accuracy of 1.90cm, and 4.81cm on FAUST correspondence task [6], and SHREC19 [34], which are 26.7% and 17.6% better than using the state-of-the-art SMPL model [33] for template matching.
When applying our approach to match complete shapes, i.e., by integrating correspondences between simulated scans and the template (c.f. [51]), our approach also considerably outperforms existing state-of-the-art [11, 51, 13, 10]. 2