Abstract
Resource scheduling and coordination is an NP-hard optimization requiring an efﬁcient allocation of agents to a set of tasks with upper- and lower bound temporal and resource constraints. Due to the large-scale and dynamic nature of resource coordination in hospitals and factories, human domain experts manually plan and adjust schedules on the ﬂy. To perform this job, domain experts leverage heterogeneous strategies and rules-of-thumb honed over years of apprenticeship.
What is critically needed is the ability to extract this domain knowledge in a heterogeneous and interpretable apprenticeship learning framework to scale beyond the power of a single human expert, a necessity in safety-critical domains. We propose a personalized and interpretable apprenticeship scheduling algorithm that infers an interpretable representation of all human task demonstrators by extracting decision-making criteria via an inferred, personalized embedding non-parametric in the number of demonstrator types. We achieve near-perfect LfD accuracy in synthetic domains and 88.22% accuracy on a planning domain with real-world data, outperforming baselines. Finally, our user study showed our methodology produces more interpretable and easier-to-use models than neural networks (p < 0.05). 1

Introduction
Coordinating resources in time and space is a challenging and costly problem worldwide, affecting everything from the medical supplies we need to ﬁght pandemics to the food on our tables. The manufacturing and healthcare industries account for a total of $35 trillion [18] and $8.1 trillion [28]
USD, respectively. In manufacturing, scheduling workers – whether they be humans or robots – to complete a set of tasks in a shared space with upper- and lower-bound temporal constraints (i.e., deadline and wait constraints) is an NP-hard optimization problem [5], typically approaching computational intractability for real-world problems of interest.
Human domain experts efﬁciently, if sub-optimally, solve these NP-hard problems to coordinate resources using heterogeneous rules-of-thumb and strategies honed over decades of apprenticeship, creating unique heuristics depending on experts’ varied experiences and personal preferences [23, 41].
Each expert has her own strategies, and it is common for factories and hospital wards to be run completely differently – yet effectively – across different shifts based upon the person in charge of coordinating the workers’ activities [27, 33, 38]. The challenge we pose is to develop new apprenticeship learning techniques for capturing these heterogeneous rules-of-thumb in order to scale beyond the power of a single expert. However, such heterogeneity is not readily handled by traditional apprenticeship learning approaches that assume demonstrator homogeneity. A canonical example of this limitation is of human drivers teaching an autonomous car to pass a slower-moving car, where some drivers prefer to pass on the left and others on the right. Apprenticeship learning 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
approaches assuming homogeneous demonstrations either ﬁt the mean (i.e., driving straight into the car ahead of you) or ﬁt a single mode (i.e., only pass to the left).
The ﬁeld of apprenticeship learning has recently begun working to relax the assumption of ho-mogeneous demonstrations by explicitly capturing modes in heterogeneous human demonstra-tions [6, 7, 21, 26, 43]. One such approach, InfoGAIL [26], uses a generative adversarial setting with variational inference to learn discrete, latent codes to describe multi-modal decision-making.
However, InfoGAIL requires access to an environment simulator, relies on a ground-truth reward signal, and is ill-suited to reasoning about resource scheduling and optimization problems, as we show in Section 5. Further, modern imitation learning frameworks lack interpretability, hampering adoption in safety-critical and legally-regulated domains [2, 10, 25, 44].
Contributions – Overcoming these key limitations of prior work, we develop a novel, data-efﬁcient apprenticeship learning framework for learning from heterogeneous scheduling demonstration. The key to our approach is a neural network architecture that serves as a function approximator speciﬁcally designed for sparsity to afford easy “discretization” into a Boolean decision tree after training as well as the ability to leverage variational inference to tease out each demonstrator’s unique decision-making criteria. In Section 5, we empirically validate that our approach, “Personalized Neural Trees”, outperforms baselines even after discretization into a decision tree. Our contributions are as follows: 1. Formulate a personalized and interpretable apprenticeship scheduling framework for het-erogeneous LfD that outperforms prior state-of-the-art approaches on both synthetic and real-world data across several domains (+51% and +11%, respectively) through the use of personalized embeddings without constraining the number of demonstrator types. 2. Develop a methodology for converting a personalized neural tree into an interpretable representation that directly translates decision-making behavior. Our discretized trees also outperform previous benchmarks on synthetic and real-world data across several domains. 3. Conduct a user study that shows our post-processed interpretable trees are more interpretable (p < 0.05), easier to simulate (p < 0.01), and quicker to validate (p < 0.01) than their black box neural network counterparts. 2