Abstract
One of the fundamental problems in Artiﬁcial Intelligence is to perform complex multi-hop logical reasoning over the facts captured by a knowledge graph (KG).
This problem is challenging, because KGs can be massive and incomplete. Recent approaches embed KG entities in a low dimensional space and then use these embeddings to ﬁnd the answer entities. However, it has been an outstanding challenge of how to handle arbitrary ﬁrst-order logic (FOL) queries as present methods are limited to only a subset of FOL operators. In particular, the negation operator is not supported. An additional limitation of present methods is also that they cannot naturally model uncertainty. Here, we present BETAE, a probabilistic embedding framework for answering arbitrary FOL queries over KGs. BETAE is the ﬁrst method that can handle a complete set of ﬁrst-order logical operations: conjunction (∧), disjunction (∨), and negation (¬). A key insight of BETAE is to use probabilistic distributions with bounded support, speciﬁcally the Beta distribution, and embed queries/entities as distributions, which as a consequence allows us to also faithfully model uncertainty. Logical operations are performed in the embedding space by neural operators over the probabilistic embeddings. We demonstrate the performance of BETAE on answering arbitrary FOL queries on three large, incomplete KGs. While being more general, BETAE also increases relative performance by up to 25.4% over the current state-of-the-art KG reasoning methods that can only handle conjunctive queries without negation. 1

Introduction
Reasoning is a process of deriving logical conclusion or making predictions from available knowl-edge/facts. Knowledge can be encoded in a knowledge graph (KG), where entities are expressed as nodes and relations as edges. Real-world KGs, such as Freebase [1], Yago [2], NELL [3], are large-scale as well as noisy and incomplete. Reasoning in KGs is a fundamental problem in Artiﬁ-cial Intelligence. In essence, it involves answering ﬁrst-order logic (FOL) queries over KGs using operators existential quantiﬁcation (∃), conjunction (∧), disjunction (∨), and negation (¬).
To ﬁnd answers, a given FOL query can be viewed as a computation graph which speciﬁes the steps needed. A concrete example of the computation graph for the query “List the presidents of European countries that have never held the World Cup” is shown in Fig. 1. The query can be represented as a conjunction of three terms: “Located(Europe,V)”, which ﬁnds all European countries; “¬Held(World
Cup,V)”, which ﬁnds all countries that never held the World Cup; and “President(V,V?)”, which ﬁnds presidents of given countries. In order to answer this query, one ﬁrst locates the entity “Europe” and then traverses the KG by relation “Located” to identify a set of European countries. Similar operations are needed for the entity “World Cup” to obtain countries that hosted the World Cup. One then needs to complement the second set to identify countries that have never held the World Cup and intersect the complement with the set of European countries. The ﬁnal step is to apply the relation 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
Figure 1: BETAE answers ﬁrst-order logic queries that include ∃, ∧, ∨ and ¬ logical operators. (A): A given query “List the presidents of European countries that have never held the World Cup” can be represented by its computation graph where each node represents a set of entities and each edge represents a logical operation. (B): BETAE models each node of the computation graph as a
Beta distribution over the entity embedding space and each edge of the computation graph transforms the distribution via a projection, negation, or intersection operation. BETAE applies a series of logical operators that each transform and shape the Beta distribution. The answer to the query are then entities that are probabilistically close to the embedding of the query (e.g., embedding of “Macron” is closer to the query embedding and the embedding of “Rebelo de Sousa”).
“President” to the resulting intersection set to ﬁnd the list of country presidents, which gives the query answer.
KG reasoning presents a number of challenges. One challenge is the scale of KGs. Although queries could be in principle answered by directly traversing the KG, this is problematic in practice since multi-hop reasoning involves an exponential growth in computational time/space. Another challenge is incompleteness, where some edges between entities are missing. Most real-world KGs are incomplete and even a single missing edge may make the query unanswerable.
Previous methods [4, 5, 6, 7, 8] aim to address the above challenges by using embeddings and this way implicitly impute the missing edges. Methods also embed logical queries into various geometric shapes in the vector space [9, 10, 11, 12]. The idea here is to design neural logical operators and embed queries iteratively by executing logical operations according to the query computation graph (Fig. 1). An advantage of these approaches is that they do not need to track all the intermediate entities, and that they can use the nearest neighbor search [13] in the embedding space to quickly discover answers. However, these methods only support existential positive ﬁrst-order (EPFO) queries, a subset of FOL queries with existential quantiﬁcation (∃), conjunction (∧) and disjunction (∨), but not negation (¬). Negation, however, is a fundamental operation and required for the complete set of FOL operators. Modeling negation so far has been a major challenge. The reason is that these methods embed queries as closed regions, e.g., a point [9, 11, 12] or a box [10] in the Euclidean space, but the complement (negation) of a closed region does not result in a closed region. Furthermore, current methods embed queries as static geometric shapes and are thus unable to faithfully model uncertainty.
Here we propose Beta Embedding (BETAE), a method for multi-hop reasoning over KGs using full
ﬁrst-order logic (FOL). We model both the entities and queries by probabilistic distributions with bounded support. Speciﬁcally, we embed entities and queries as Beta distributions deﬁned on the
[0, 1] interval. Our approach has the following important advantages: (1) Probabilistic modeling can effectively capture the uncertainty of the queries. BETAE adaptively learns the parameters of the distributions so that the uncertainty of a given query correlates well with the differential entropy of the probabilistic embedding. (2) We design neural logical operators that operate over these Beta distributions and support full ﬁrst-order logic: ∃, ∧, ∨ and most importantly ¬. The intuition behind negation is that we can transform the parameters of the Beta distribution so that the regions of high probability density become regions of low probability density and vice versa. (3) Our neural modeling of ∧ and ¬ naturally corresponds to the real operations and captures several properties of ﬁrst-order logic. For example, applying the negation operator twice will return the same input. (4) Using the
De Morgan’s laws, disjunction ∨ can be approximated with ∧ and ¬, allowing BETAE to handle a complete set of FOL operators and thus supporting arbitrary FOL queries.
Our model is able to handle arbitrary ﬁrst-order logic queries in an efﬁcient and scalable manner.
We perform experiments on standard KG datasets and compare BETAE to prior approaches [9, 10] that can only handle EPFO queries. Experiments show that our model BETAE is able to achieve state-of-the-art performance in handling arbitrary conjunctive queries (including ∃, ∧) with a relative 2
increase of the accuracy by up to 25.4%. Furthermore, we also demonstrate that BETAE is more general and is able to accurately answer any FOL query that includes negation ¬. Project website with data and code can be found at http://snap.stanford.edu/betae. 2