Abstract
The support/query (S/Q) episodic training strategy has been widely used in modern meta-learning algorithms and is believed to improve their generalization ability to test environments. This paper conducts a theoretical investigation of this training strategy on generalization. From a stability perspective, we analyze the general-ization error bound of generic meta-learning algorithms trained with such strategy.
We show that the S/Q episodic training strategy naturally leads to a counterintuitive generalization bound of O(1/ n), which only depends on the task number n but independent of the inner-task sample size m. Under the common assumption m << n for few-shot learning, the bound of O(1/ n) implies strong generaliza-tion guarantees for modern meta-learning algorithms in the few-shot regime. To further explore the inﬂuence of training strategies on generalization, we propose a leave-one-out (LOO) training strategy for meta-learning and compare it with S/Q training. Experiments on standard few-shot regression and classiﬁcation tasks with popular meta-learning algorithms validate our analysis.
√
√ 1

Introduction
Few-shot learning [16] is a highly challenging problem due to the scarcity of training samples.
Meta-learning [3, 32] provides promising solutions for this problem and has attracted a surge of interest recently. A meta-learning algorithm (meta-algorithm) trains over a large number of i.i.d. tasks sampled from a task distribution and learns an algorithm (inner-task algorithm) that can quickly adapt to a future task with few training data.
Early meta-algorithms directly minimize the averaged training error of a set of training tasks. To improve the generalization of meta-algorithms, the pioneering work of [35] proposes a novel training strategy – support/query episodic training strategy. In particular, episodic training treats each task as a training instance and updates the inner-task algorithm by episode (task by task). Support/query (S/Q) training mimics the test process in each task, i.e., a training set (support) for inner-task training and a test set (query) for measuring the inner-task algorithm’s performance. Meta-training proceeds by minimizing the error computed over the query set. This training strategy has been widely used to train modern meta-algorithms such as MAML [18] and ProtoNet [31].
Although it is widely believed that the S/Q training strategy can improve the generalization of meta-algorithms due to the match of training condition and test condition, there is barely any theoretical analysis of how it impacts generalization. Our key observation is that the generalization bound of meta-algorithms is closely related to the training strategy. The S/Q training strategy leads to a bound
∗Corresponding authors. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
√ different from the existing meta-learning bounds which do not involve any speciﬁc meta-training strategy. In this paper, we study the generalization error bounds of generic meta-algorithms trained with the S/Q scheme by employing tools from stability analysis [24, 5, 20].
√
Based on stability analysis, we derive a generalization bound of O(1/ n) for meta-algorithms trained with S/Q strategy, which is independent of the sample size m of each task. The result seems counterintuitive at the ﬁrst glance. However, it is natural if we carefully check the difference between
S/Q training and traditional meta-training strategies. We explain the key intuition of the bound
O(1/ n) as follows. For the traditional meta-training strategy, the bound of the generalization gap between the traditional empirical multi-task error and the transfer error consists of two terms, an inner-task gap (cid:15)(m) caused by observing limited inner-task training samples and an outer-task gap (cid:15)(n) caused by observing limited training tasks. For S/Q training, for any training task, the inner-task algorithm minimizes the inner-task training error of the support set and outputs a hypothesis. The
S/Q training error, i.e., the error of this inner-task hypothesis computed over the query set (unseen during inner-task training) is exactly the inner-task test error of this inner-task hypothesis, and thereby is an unbiased estimate to the inner-task generalization error of the inner-task hypothesis. Intuitively, the inner-task gap depending on the inner-task sample size m vanishes because S/Q training directly minimizes the inner-task test error. Correspondingly, the bound of the generalization gap between the
S/Q training error and the transfer error equals to the outer-task gap that only depends on the task number n.
To further explore the inﬂuence of training strategies on the generalization of meta-algorithms, we want to compare S/Q training with existing meta-training strategies. However, the traditional meta-training strategy cannot be used to train modern meta-algorithms such as MAML [18], Bilevel
Programming [19] and ProtoNet [31] which require support samples for inner-task training and queries for meta-training (see more discussions in Sec. 4). To compare with S/Q training, we introduce a new strategy for training modern meta-algorithms – leave-one-out (LOO) training, which minimizes the leave-one-out errors of training tasks. The key reason of studying LOO training is that it is similar to the traditional training strategy which computes the empirical error over the support set instead of the query set while can still be used to train modern meta-algorithms. Interestingly, although LOO training error is an “almost” unbiased estimate to the generalization error of the inner-task hypotheses of training tasks [14], the generalization bound of meta-algorithms with LOO training still depends on both the inner-task sample size m and the task number n. See Table 1 for a summary of these three training strategies.
Table 1: Comparisons of three meta-training strategies. Data set: the data set used for computing the empirical error for meta-training. Estimate: in each training task, the empirical error for meta-training is an unbiased/biased estimate to the generalization error of the inner-task hypothesis. Compatibility: the training strategy’s compatibility with modern meta-algorithms. Bound: the generalization bound.
Strategy
Traditional
Leave-one-out
Support/Query Query set
Data set
Support set
Support set
Estimate biased
“almost” unbiased unbiased
Compatibility Bound
× (cid:88) (cid:88) (cid:15)(n, m) (cid:15)(n, m) (cid:15)(n)
From a generalization perspective, our results clearly explain the success of the S/Q training strategy.
The sample-size free bound provides a ﬁrm theoretical support for the generalization of modern meta-learning algorithms in the few-shot learning setting. Furthermore, our theoretical results are empirically veriﬁed by experiments on standard few-shot classiﬁcation and regression tasks implemented with popular meta-algorithms [18, 31, 19]. 2