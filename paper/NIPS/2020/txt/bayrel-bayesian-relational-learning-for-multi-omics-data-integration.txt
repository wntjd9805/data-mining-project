Abstract
High-throughput molecular proﬁling technologies have produced high-dimensional multi-omics data, enabling systematic understanding of living systems at the genome scale. Studying molecular interactions across different data types helps reveal signal transduction mechanisms across different classes of molecules. In this paper, we develop a novel Bayesian representation learning method that infers the relational interactions across multi-omics data types. Our method, Bayesian
Relational Learning (BayReL) for multi-omics data integration, takes advantage of a priori known relationships among the same class of molecules, modeled as a graph at each corresponding view, to learn view-speciﬁc latent variables as well as a multi-partite graph that encodes the interactions across views. Our experiments on several real-world datasets demonstrate enhanced performance of BayReL in inferring meaningful interactions compared to existing baselines. 1

Introduction
Modern high-throughput molecular proﬁling technologies have produced rich high-dimensional data for different bio-molecules at the genome, constituting genome, transcriptome, translatome, proteome, metabolome, epigenome, and interactome scales [Huang et al., 2017, Hajiramezanali et al., 2018b, 2019b, Karimi et al., 2020, Pakbin et al., 2018]. Although such multi-view (multi-omics) data span a diverse range of cellular activities, developing an understanding of how these data types quantitatively relate to each other and to phenotypic characteristics remains elusive. Life and disease systems are highly non-linear, dynamic, and heterogeneous due to complex interactions not only within the same classes of molecules but also across different classes [Andrés-León et al., 2017]. One of the most important bioinformatics tasks when analyzing such multi-omics data is how we may integrate multiple data types for deriving better insights into the underlying biological mechanisms. Due to the heterogeneity and high-dimensional nature of multi-omics data, it is necessary to develop effective and affordable learning methods for their integration and analysis [Huang et al., 2017, Hajiramezanali et al., 2018a].
Modeling data across two views with the goal of extracting shared components has been typically performed by canonical correlation analysis (CCA). Given two random vectors, CCA aims to ﬁnd the linear projections into a shared latent space for which the projected vectors are maximally correlated, which can help understand the overall dependency structure between these two random vectors [Thompson, 1984]. However, it is well known that the classical CCA suffers from a lack of probabilistic interpretation when applied to high dimensional data [Klami et al., 2013] and it also cannot handle non-linearity [Andrew et al., 2013]. To address these issues, probabilistic CCA (PCCA) has been proposed and extended to non-linear settings using kernel methods and neural networks
∗Both authors contributed equally. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
[Bach and Jordan, 2005]. Due to explicit uncertainty modeling, PCCA is particularly attractive for biomedical data of small sample sizes but high-dimensional features [Ghahramani, 2015, Huo et al., 2020].
Despite the success of the existing CCA methods, their main limitation is that they do not exploit structural information among features that is available for biological data such as gene-gene and protein-protein interactions when analyzing multi-omics data. Using available structural information, one can gain better understanding and obtain more biologically meaningful results. Besides that, traditional CCA methods focus on aggregated association across data but are often difﬁcult to interpret and are not very effective for inferring interactions between individual features of different datasets.
The presented work contains three major contributions: 1) We propose a novel Bayesian relation learning framework, BayReL, that can ﬂexibly incorporate the available graph dependency structure of each view. 2) It can exploit non-linear transformations and provide probabilistic interpretation simultaneously. 3) It can infer interactions across different heterogeneous features of input datasets, which is critical to derive meaningful biological knowledge for integrative multi-omics data analysis. 2 Method
We propose a new graph-structured data integration method, Bayesian Relational Learning (BayReL), for integrative analysis of multi-omics data. Consider data for different molecular classes as corre-sponding data views. For each view, we are given a graph Gv = (Vv, Ev) with Nv = |Vv| nodes, adjacency matrix Av, and node features in a Nv × D matrix Xv. We note that Gv is completely deﬁned by Av, hence we use them interchangeably where it does not cause confusion. We deﬁne sets G = {G1, . . . GV } and X = {X1, . . . XV } as the input graphs and attributes of all V views.
The goal of our model is to ﬁnd inter-relations between nodes of the graphs in different views. We model these relations as edges of a multi-partite graph G. The nodes in the multi-partite graph G are the union of the nodes in all views, i.e. VG = (cid:83)V v=1 Vv; and the edges, that will be inferred in our model, are captured in a multi-adjacency tensor A = {Avv(cid:48) is the Nv × Nv(cid:48) bi-adjacency matrix between Vv and Vv(cid:48). We emphasize that unlike matrix completion models, none of the edges in G are assumed to be observed in our model. We infer our proposed probabilistic model using variational inference. We now introduce each of the involved latent variables in our model as well as their corresponding prior and posterior distributions. The graphical model of BayReL is illustrated in Figure 1. v,v(cid:48)=1,v(cid:54)=v(cid:48) where Avv(cid:48)
}V
Embedding nodes to the latent space. The ﬁrst step is to embed the nodes in each view into a Du dimensional latent space. We use view-speciﬁc latent representations, denoted by a set of Nv × Du matrices U = {Uv}V v=1, to reconstruct the graphs as well as inferring the inter-relations. In particular, we parametrize the distribution over the adjacency matrix of each view Av independently: (cid:90) pθ(G, U) dU =
V (cid:89) (cid:90) v=1 pθ(Av, Uv) dUv =
V (cid:89) (cid:90) v=1 pθ(Av | Uv) p(Uv) dUv, (1) where we employ standard diagonal Gaussian as the prior distribution for Uv’s. Given the input data
{Xv, Gv}V v=1, we approximate the distribution of U with a factorized posterior distribution: q(U | X , G) =
V (cid:89) v=1 q(Uv | Xv, Gv) =
V (cid:89)
Nv(cid:89) v=1 i=1 q(ui,v | Xv, Gv), (2) where q(ui,v | Xv, Gv) can be any parametric or non-parametric distribution that is derived from the input data. For simplicity, we use diagonal Gaussian whose parameters are a function of the input.
More speciﬁcally, we use two functions denoted by ϕemb,µ (Xv, Gv) to infer the mean and variance of the posterior at each view from input data. These functions could be highly
ﬂexible functions that can capture graph structure such as many variants of graph neural networks including GCN [Defferrard et al., 2016, Kipf and Welling, 2017], GraphSAGE [Hamilton et al., 2017], and GIN [Xu et al., 2019]. We reconstruct the graphs at each view by deploying inner-product decoder on view speciﬁc latent representations. More speciﬁcally, (Xv, Gv) and ϕemb,σ v v p(G | U) =
V (cid:89)
Nv(cid:89) v=1 i,j=1 p(Av ij | ui,v, uj,v); p(Av ij | ui,v, uj,v) = Bernoulli (cid:0)σ(ui,v uT j,v)(cid:1) , (3) 2
G1
...
GV
U
A
Z1
...
ZV
X1
...
XV
G1
...
GV
U
A
Z1
...
ZV
X1
...
XV
Figure 1: Graphical model for our proposed BayReL. Left: Inference; Right: Generative model. where σ(·) is the sigmoid function. The above formulation for node embedding ensures that similar nodes at each view are close to each other in the latent space.
Constructing relational multi-partite graph. The next step is to construct a dependency graph among the nodes across different views. Given the latent embedding U that we obtain as described previously, we construct a set of bipartite graphs with multi-adjacency tensor A = {Avv(cid:48)
}V v,v(cid:48)=1,v(cid:54)=v(cid:48), where Avv(cid:48) ij = 1 if the node i in view v is connected to the node j in view v(cid:48). We model the elements of these bi-adjacency matrices as Bernoulli random variables. More speciﬁcally, the distribution of bi-adjacency matrices are deﬁned as follows is the bi-adjacency matrix between Vv and Vv(cid:48). Avv(cid:48) p(Avv(cid:48)
| Uv, Uv(cid:48)) =
Nv(cid:89)
Nv(cid:48) (cid:89) i=1 j=1
Bernoulli (cid:16)
Avv(cid:48) ij
| ϕsim(ui,v, uj,v(cid:48)) (cid:17)
, (4) where ϕsim(·, ·) is a score function measuring the similarity between the latent representations of nodes. The inner-product link [Hajiramezanali et al., 2019a] decoder ϕsim ip (ui,v, uj,v(cid:48)) = j,v(cid:48)) and Bernoulli-Poisson link [Hasanzadeh et al., 2019] decoder ϕsim
σ(ui,v uT bp (ui,v, uj,v(cid:48)) = 1 − exp(− (cid:80)Du k=1 τk uik,v ujk,v(cid:48)) are two examples of potential score functions. In practice, we use the concrete relaxation [Gal et al., 2017, Hasanzadeh et al., 2020] during training while we sample from Bernoulli distributions in the testing phase.
We should point out that in many cases, we have a hierarchical structure between views. For example, in systems biology, proteins are products of genes. In these scenarios, we can construct the set of directed bipartite graphs, where the direction of edges embeds the hierarchy between nodes in different views. We may use an asymmetric score function or prior knowledge to encode the direction of edges. We leave this for future study.
Inferring view-speciﬁc latent variables. Having obtained the node representations U and the dependency multi-adjacency tensor A, we can construct view-speciﬁc latent variables, denoted by set of Nv × Dz matrices Z = {Zv}V v=1, which can be used to reconstruct the input node attributes. We parametrize the distributions for node attributes at each view independently as follows (cid:90) pθ(X , Z | G, A, U) dZ =
V (cid:89)
Nv(cid:89) (cid:90) v=1 i=1 pθ (zi,v | G, A, U) pθ(xi,v | zi,v) dzi,v. (5)
In our formulation, the distribution of X is dependent on the graph structure at each view as well as inter-relations across views. This allows the local latent variable zi,v to summarize the information from the neighboring nodes. We set the prior distribution over zi,v as a diagonal Gaussian whose parameters are a function of A and U. More speciﬁcally, ﬁrst we construct the overall graph consisting of all the nodes and edges in all multi-partite graphs. We can view U as node attributes on this overall graph. We apply a graph neural network over this overall graph and its attributes to construct the prior. More formally, the following prior is adopted: pθ(Z | G, A, U) =
V (cid:89)
Nv(cid:89) pθ(zi,v | G, A, U), pθ(zi,v | G, A, U) = N (µprior i,v
, σprior i,v
), (6) v=1 where µprior = [µprior
]i,v = ϕprior,µ(A, U), σprior = [σprior and ϕprior,σ are graph neural networks. Given input {Xv, Gv}V i=1 i,v i,v
]i,v = ϕprior,σ(A, U), and ϕprior,µ v=1, we approximate the posterior of 3
latent variables with the following variational distribution:
Nv(cid:89)
V (cid:89) q(Z | X , G) = q(zi,v | Xv, Gv), q(zi,v | Xv, Gv) = N (µpost i,v , σpost i,v ) (7) v=1 i=1 v (Xv, Gv)}V v=1, σpost = [σpost where µpost = [µpost i,v ]i,v = {ϕpost,µ v=1, and ϕpost,µ and ϕpost,σ are graph neural networks. The distribution over node attributes pθ(xi,v | zi,v) v v can vary based on the given data type. For instance, if X is count data it can be modeled by a Poisson distribution; if it is continuous, Gaussian may be an appropriate choice. In our experiments, we model the node attributes as normally distributed with a ﬁxed variance, and we reconstruct the mean of the node attributes at each view by employing a fully connected neural network ϕdec that operates on zi,v’s independently. i,v ]i,v = {ϕpost,σ (Xv, Gv)}V v v
Overall likelihood and learning. Putting everything together, the marginal likelihood is pθ(X , G) = (cid:90) V (cid:89) v=1 pθ(Xv | Zv) pθ(Zv | G, A, U) p(A | U) p(G | U) p(U) dZ1 . . . dZV dA dU.
We deploy variational inference to optimize the model parameters θ and variational parameters φ by minimizing the following derived Evidence Lower Bound (ELBO) for BayReL:
L =
V (cid:88) v=1 (cid:104)
Eqφ(Zv | G,X )log pθ(Xv | Zv) + Eqφ(Zv,U | G,X )log pθ(Zv | G, A, U)
− Eqφ(Zv | G,X )qφ(Zv | G, X ) (cid:105)
− KL (qφ(U | G, X ) || p(U)) , (8) where KL denotes the Kullback–Leibler divergence. 3