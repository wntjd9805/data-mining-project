Abstract
Vanilla convolutions in modern deep networks are known to operate locally and at
ﬁxed scale (e.g., the widely-adopted 3 × 3 kernels in image-oriented tasks). This causes low efﬁcacy in connecting two distant locations in the network. In this work, we propose a novel convolutional operator dubbed as fast Fourier convolution (FFC), which has the main hallmarks of non-local receptive ﬁelds and cross-scale fusion within the convolutional unit. According to spectral convolution theorem in
Fourier theory, point-wise update in the spectral domain globally affects all input features involved in Fourier transform, which sheds light on neural architectural design with non-local receptive ﬁeld. Our proposed FFC is inspired to capsulate three different kinds of computations in a single operation unit: a local branch that conducts ordinary small-kernel convolution, a semi-global branch that processes spectrally stacked image patches, and a global branch that manipulates image-level spectrum. All branches complementarily address different scales. A multi-branch aggregation step is included in FFC for cross-scale fusion. FFC is a generic operator that can directly replace vanilla convolutions in a large body of existing networks, without any adjustments and with comparable complexity metrics (e.g.,
FLOPs). We experimentally evaluate FFC in three major vision benchmarks (ImageNet for image recognition, Kinetics for video action recognition, MSCOCO for human keypoint detection). It consistently elevates accuracies in all above tasks by signiﬁcant margins. 1

Introduction
Deep neural networks have been the prominent driving force for recent dramatic progress in several research domains. The goal of this paper is the exposition of a novel convolutional unit codenamed fast Fourier convolution (FFC). Motivating our design of FFC, we consider two desiderata. First, one of the core concepts in deep convolutional neural networks (CNNs) is receptive ﬁeld that is deeply rooted in the visual cortex architecture. In convolutional networks, receptive ﬁeld refers to the image part that is accessible by one ﬁlter. A majority of modern networks have adopted the architecture of deeply stacking many convolutions with small receptive ﬁeld (3 × 3 in ResNet [11] for images or 3 × 3 × 3 in C3D [27] for videos). This still ensures that all image parts are visible to high layers, since stacking convolutional layers can increase the receptive ﬁeld either linearly or exponentially (e.g., using atrous convolutions [2]). However, for context-sensitive tasks such as human pose estimation, large receptive ﬁeld in convolutions is highly desired. Recent endeavor on enlarging receptive ﬁeld includes deformable convolution [9] and non-local neural networks [31].
Secondly, CNNs typically admit a chain-like topology. Neural layers provide different levels of feature abstraction. The idea of cross-scale fusion has celebrated its success in various scenarios.
For example, one can tailor and send high-level semantics to shallower layers for guiding more accurate spatial detection, as shown in the seminal work of FPN [18]. Recent studies have considered
∗Corresponding author. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
to reinforce cross-scale fusion in more complex patterns, as exempliﬁed by HRNet [29] and Auto-DeepLab [19]. Our work is also partly inspired by GoogLeNet [26], which is among the early exploration of capturing and fusing multi-scale information in an operation unit, rather than among distant neural blocks.
We thus seek for a novel convolution operator that efﬁciently implements non-local receptive ﬁeld and fuses multi-scale information. The key tool for our development is the spectral transform theory.
In particular, we choose Fourier transform for incarnation, leaving further exploration of many other choices (e.g., wavelet) as a future work. According to the spectral convolution theorem [15] in Fourier theory, updating a single value in the spectral domain globally affects all original data, which sheds light on design efﬁcient neural architectures with non-local receptive ﬁeld (e.g., [34, 7]). In speciﬁc, we design a collection of operations with varying receptive ﬁelds, among which non-local ones are accomplished via Fourier transform. These operations are applied to disjoint subsets of feature channels. Updated feature maps across scales are eventually aggregated as the output.
To our best knowledge, FFC is the ﬁrst work that explores an efﬁcient ensemble of local and non-local receptive ﬁelds in a single unit. It can be used in a plug-and-play fashion for easily replacing vanilla convolutions in mainstream CNNs without any additional effort. In contrast, existing non-local operators can only be sparsely inserted into the network pipeline due to their expensive computational cost. FFC consumes comparable GFLOPs and parameters with respect to vanilla convolutions, yet conveys richer information. In the experiments, we apply FFC for tackling a variety of computer vision tasks, including image recognition on ImageNet, video action recognition on Kinetics dataset, and human keypoint detection on Microsoft COCO data. The reported performances consistently outstrip previous models by signiﬁcant margins. We strongly believe that FFC can make inroads into domains of neural network design where uniform, local receptive ﬁeld had previously reigned supreme. 2