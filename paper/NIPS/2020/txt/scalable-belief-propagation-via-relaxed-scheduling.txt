Abstract
The ability to leverage large-scale hardware parallelism has been one of the key enablers of the accelerated recent progress in machine learning. Consequently, there has been considerable effort invested into developing efﬁcient parallel variants of classic machine learning algorithms. However, despite the wealth of knowledge on parallelization, some classic machine learning algorithms often prove hard to parallelize efﬁciently while maintaining convergence.
In this paper, we focus on efﬁcient parallel algorithms for the key machine learning task of inference on graphical models, in particular on the fundamental belief propagation algorithm. We address the challenge of efﬁciently parallelizing this classic paradigm by showing how to leverage scalable relaxed schedulers in this context. We present an extensive empirical study, showing that our approach outperforms previous parallel belief propagation implementations both in terms of scalability and in terms of wall-clock convergence time, on a range of practical applications. 1

Introduction
Hardware parallelism has been a key computational enabler for recent advances in machine learning, as it provides a way to reduce the processing time for the ever-increasing quantities of data required for training accurate models. Consequently, there has been considerable effort invested into developing efﬁcient parallel variants of classic machine learning algorithms, e.g. [28, 22, 23, 24, 15].
In this paper, we will focus on efﬁcient parallel algorithms for the fundamental task of inference on graphical models. The inference task in graphical models takes the form of marginalisation: we are given observations for a subset of the random variables, and the task is to compute the conditional distribution of one or a few variables of interest. The marginalization problem is known to be computationally intractable in general [10, 32, 9], but inexact heuristics are well-studied for practical inference tasks.
One popular heuristic for inference on graphical models is belief propagation [27], inspired by the exact dynamic programming algorithm for marginalization on trees. While belief propagation has no general approximation or even convergence guarantees, it has proven empirically successful in inference tasks, in particular in the context of decoding low-density parity check codes [8]. However, it remains poorly understood how to properly parallelize belief propagation.
Parallelizing belief propagation. To illustrate the challenges of parallelizing belief propagation, we will next give a simpliﬁed overview of the belief propagation algorithm, and refer the reader to Section 2 for full details. Belief propagation can be seen as a message passing or a weight 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
update algorithm. In brief, belief propagation operates over the underlying graph G = (V, E) of the graphical model, maintaining a vector of real numbers called a message µi→j for each ordered pair (i, j) corresponding to an edge {i, j} ∈ E (Fig. 1). The core of the algorithm is the message update rule which speciﬁes how to update an outgoing message µi→j at node i based on the other incoming messages at node i; for the purposes of the present discussion, it is sufﬁcient to view this as black box function f over these other messages, leading to the update rule
µi→j ← f (cid:0){µk→i : k ∈ N (i) \ {j}}(cid:1) .
This update rule is applied to messages until the values of messages have converged to a stable solution, at which point the algorithm is said to have terminated. (1)
Importantly, the message update rule does not specify in which order messages should be updated. The standard so-lution, called synchronous belief propagation, is to update all the message simultaneously. That is, in each global round t = 1, 2, 3, . . . , given message values µt i→j for all pairs (i, j), the new values µt+1 i→j ← f (cid:0){µt
µt+1 i→j are computed as k→i : k ∈ N (i) \ {j}}(cid:1)
However, there is evidence that updating messages one at a time leads to faster and more reliable convergence [14]; in particular, various proposed priority-based schedules— schedules that try to prioritize message updates that would make ‘more progress’—have proven empirically to con-verge with much fewer message updates than the synchronous schedule [14, 20, 37].
Figure 1: State of the belief propagation algorithm consist of two directed mes-sages for each edge.
Having to execute updates in a strict priority order poses a challenge for efﬁcient parallel imple-mentations of belief propagation: while the synchronous schedule is naturally parallelizable, as all message updates can be done independently, the more efﬁcient priority-based schedules are inherently sequential and thus seem difﬁcult to parallelize. Accordingly, existing work on efﬁcient parallel belief propagation has focused on designing custom schedules that try to import some features from the priority-based schedules while maintaining a degree of parallelism [15, 11].
Our contributions.
In this work, we address this challenge by studying how to efﬁciently par-allelize any priority-based schedule for belief propagation. The key idea is that we can relax the priority-based schedules by allowing limited out-of-order execution, concretely implemented using a relaxed scheduler, as we will explain next.
Consider a belief propagation algorithm that schedules the message updates according to a prior-ity function r by always updating the message µi→j with the highest priority r(µi→j) next; this framework captures existing priority-based schedules such as residual belief propagation [14] and its variants [20, 37]. Concretely, an iterative centralized version of this algorithm can be implemented by storing the messages in a priority queue Q, and iterating the following procedure: (1) Pop the top element for Q to obtain the message µi→j with highest priority r(µi→j). (2) Update message µi→j following (1). (3) Update the priorities in Q for messages affected by the update.
This template does not easily lend itself to efﬁcient parallelization, as the priority queue Q becomes a contention bottleneck. Previous work, e.g. [15, 11] investigated various heuristics for the parallel scheduling of updates in belief propagation, trading off increased parallelism with additional work in processing messages or even potential loss of convergence.
In this paper, we investigate an alternative approach, replacing the priority queue Q with a relaxed priority queue (scheduler) to obtain a efﬁcient parallel version of the above template. A relaxed scheduler [3, 1, 2, 5] is similar to a priority queue, but instead of guaranteeing that the top element is always returned ﬁrst, it only guarantees to return one of the top q elements by priority , where q is a variable parameter. Relaxed schedulers are popular in the context of parallel graph processing, e.g. [16, 26], and can induce non-trivial trade-offs between the degree of relaxation and the scalability of the underlying implementation, e.g. [1, 5]. 2
Figure 2: Running time (left) and number of updates until convergence (right) on a 1000×1000 Ising grid model on p ∈ {20, 35, 70} processes. Included algorithms are synchronous belief propagation, residual splash belief propagation of Gonzalez et al. [15] with splash size 10, and our relaxed residual belief propagation. The number of updates is relative to sequential residual belief propagation.
For belief propagation, relaxed schedulers induce a relaxed priority-based scheduling of the messages, roughly following the original schedule but allowing for message updates to be performed out of order, with guarantees on the maximum degree of priority inversion. We investigate the scalability-convergence trade-off between the degree of relaxation in the scheduler, and the convergence behavior of the underlying algorithm, both theoretically and practically. In particular: – We present a general scheme for parallelizing belief propagation schedules using relaxed sched-ulers with theoretical guarantees. While relaxed schedulers have been applied in other settings, and relaxed scheduling has been touched upon in belief propagation scheduling [15], no systematic study on relaxed belief propagation scheduling has been performed in prior work. – We provide a theoretical analysis on the effects of relaxed scheduling for belief propagation on trees. We exhibit both positive results–instance classes where relaxation overhead is negligible–and negative results, i.e., worst-case instances where relaxation causes signiﬁcant wasted work.
Experimental evaluation. We implement our relaxed priority-based scheduling framework with a
Multiqueue data structure [30] and instantiate it with several known priority-based schedules. In the benchmarks, we show that this framework gives state-of-the-art parallel scalability on a wide variety of Markov random ﬁeld models. As expected, the relaxed priority-based schedules require slightly more message updates than their exact counterparts, but this performance overhead is offset by their better scalability. In particular, we highlight the fact that the relaxed version of the popular residual belief propagation algorithm has state-of-the art parallel scaling while requiring no tuning parameters, making it an attractive practical solution for belief propagation. This ﬁnding is illustrated in Figure 2, and further substantiated in Section 5.
Full version. Full version of this paper is available at https://arxiv.org/abs/2002.11505. 2 Preliminaries and