Abstract
Communication lays the foundation for human cooperation. It is also crucial for multi-agent cooperation. However, existing work focuses on broadcast communi-cation, which is not only impractical but also leads to information redundancy that could even impair the learning process. To tackle these difﬁculties, we propose
Individually Inferred Communication (I2C), a simple yet effective model to enable agents to learn a prior for agent-agent communication. The prior knowledge is learned via causal inference and realized by a feed-forward neural network that maps the agent’s local observation to a belief about who to communicate with.
The inﬂuence of one agent on another is inferred via the joint action-value func-tion in multi-agent reinforcement learning and quantiﬁed to label the necessity of agent-agent communication. Furthermore, the agent policy is regularized to better exploit communicated messages. Empirically, we show that I2C can not only reduce communication overhead but also improve the performance in a variety of multi-agent cooperative scenarios, comparing to existing methods. 1

Introduction
Deep reinforcement learning has achieved remarkable success in a series of challenging tasks, e.g., game playing [12, 16, 23]. However, many real-world applications require multiple agents to learn to solve tasks collaboratively, such as autonomous driving [15], smart grid control [26], and intelligent trafﬁc control [25]. Unfortunately, there exist several challenges impeding the breakthroughs in multi-agent reinforcement learning (MARL). On one hand, during training, the agent policy keeps updating, leading to non-stationary environment and unstable model convergence. On the other hand, even for the centralized training and decentralized execution (CTDE) paradigm which is designed to mitigate non-stationarity, such as MADDPG [10], COMA [4], VDN [20], QMIX [14],
QTRAN [18], and MAAC [5], it is still hard for agents to act cooperatively during execution, since partial observability and stochasticity can easily break the learned cooperative strategy and result in catastrophic miscoordination [24].
Communication lays the foundation for human cooperation [2]. It also holds for multi-agent coopera-tion. Communication could help agents form a good knowledge of cooperative strategies. Recently, many researches focus on trainable communication channel which agents can use to obtain extra information during both training and execution to tackle the challenges aforementioned. For most existing work, such as [19, 17, 1, 27], once the decision of communication is made, messages will be broadcast to all other/predeﬁned agents. However, this requires lots of bandwidth and incurs additional delay in practice. More importantly, not every agent can provide useful information and redundant information could even impair the learning process [21, 8]. These limitations make it a less than ideal communication paradigm. Furthermore, it has never been the way how humans
†Corresponding author 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
communicate, since humans would use their prior knowledge to choose whom to communicate with if necessary. For example, one of the most important features in Quora, a question-and-answer website, is ask to answer. One can invite the person who is believed to be highly relevant to answer the question. Otherwise, one could be overwhelmed by massive answers, not to mention most are useless or misleading. Therefore, we argue that an excellent communication paradigm should take into consideration ﬁnding the right ones to communicate by enabling the agent to ﬁgure out who are highly relevant with its situation and ignore those are not.
In this paper, we propose Individually Inferred Communication (I2C), a simple yet effective model to enable agents to learn a prior for agent-agent communication. More speciﬁcally, each agent is capable of exploiting its learned prior knowledge to ﬁgure out which agent is relevant and inﬂuential by just local observation. The prior knowledge is learned via causal inference and realized by a feed-forward neural network that maps its local observation to a belief about who to communicate with. The inﬂuence of one agent on the other is captured by the causal effect of the agent’s action on the other’s policy. For any agent that can cause drastic change to the other’s policy, that agent is considered as relevant and inﬂuential. Unlike existing work [6] that utilizes social inﬂuence for reward shaping and hence encourages the agent to inﬂuence the behaviors of others, we quantify the causal effect inferred via the joint action-value function to label the necessity of agent-agent communication and thus a prior can be learned by supervised learning. Furthermore, correlation regularization is proposed to help the agent learn a better policy under the inﬂuence of the agents it communicates with.
I2C learns one-to-one communication instead of one/all-to-all communication adopted by existing work [19, 17, 1, 27], and hence makes agents focus only on relevant information. In addition, I2C restricts the communication range of agent to the ﬁeld of view. These together make I2C much more practical, since in real-world applications communication is always limited by bandwidth and range. As I2C infers the causal effect between agents by only the joint action-value function, it is compatible with many CTDE frameworks. Moreover, by alternatively capturing the casual effect of communicated messages, I2C can also serve as communication control to reduce overhead for full communication methods, e.g., TarMAC [1]. We implement I2C based on two CTDE frameworks to learn communication in MARL and evaluate it in three classic multi-agent cooperative scenarios, i.e., cooperative navigation, predator prey, and trafﬁc junction. In cooperative navigation and predator prey, we empirically demonstrate that I2C outperforms the existing methods with/without communication.
By ablation studies, we conﬁrm that the inferred causal effect indeed captures the necessity of agent-agent communication, cooperative strategy can be better learned by agent-agent communication, and correlation regularization indeed helps the agent develop better policy. In trafﬁc junction, I2C is implemented as communication control for full communication methods, and it is shown that I2C can not only reduce communication overhead but also improve the performance.
To the best of our knowledge, I2C is the ﬁrst work that learns one-to-one communication in MARL. 2