Abstract
Various differentially private algorithms instantiate the exponential mechanism, and require sampling from the distribution exp(−f ) for a suitable function f . When the domain of the distribution is high-dimensional, this sampling can be computa-tionally challenging. Using heuristic sampling schemes such as Gibbs sampling does not necessarily lead to provable privacy. When f is convex, techniques from log-concave sampling lead to polynomial-time algorithms, albeit with large poly-nomials. Langevin dynamics-based algorithms offer much faster alternatives under some distance measures such as statistical distance. In this work, we establish rapid convergence for these algorithms under distance measures more suitable for differential privacy. For smooth, strongly-convex f , we give the ﬁrst results proving convergence in Rényi divergence. This gives us fast differentially private algorithms for such f . Our techniques and simple and generic and apply also to underdamped Langevin dynamics. 1

Introduction
The Exponential Mechanism [McSherry and Talwar, 2007] is a commonly-used mechanism in differ-ential privacy [Dwork and Roth, 2014]. There is a large class of mechanisms in the differential privacy literature that instantiate the Exponential Mechanism with appropriate score functions, use it as a subroutine, or sample from exp(−f ) for some function f . This family includes differentially private mechanisms for several important problems, such as PCA [Chaudhuri et al., 2013, Kapralov and
Talwar, 2013], functional PCA [Awan et al., 2019], answering counting queries [Hardt and Talwar, 2010], robust regression [Asi and Duchi, 2020], some combinatorial optimization problems [Gupta et al., 2010], k-means clustering [Feldman et al., 2009], optimization of dispersed functions [Balcan et al., 2018], convex optimization [Bassily et al., 2014, Minami et al., 2016], Bayesian data analy-sis [Mir, 2013, Dimitrakakis et al., 2014, Wang et al., 2015, Wasserman and Zhou, 2010, Foulds et al., 2016], linear and quantile regression [Reimherr and Awan, 2019], etc.
Implementing these mechanisms requires sampling from a distribution given by exp(−f ) from some domain D, for a suitable score function f . When the domain D is ﬁnite and small, this sampling is straightforward. Several differentially private mechanisms instantiate the exponential mechanism where D = Rd, in which case this sampling is not straightforward.
Such sampling problems are not new and often occur in statistics and machine learning settings. The common practical approach is to use heuristic MCMC samplers such as Gibbs sampling, which often works well in problems arising in practice. However, given that convergence is not guaranteed, the
∗Part of this work performed while the author was an intern at Google Brain.
†Work performed while at Google Brain. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
resulting algorithms may not be differentially private. Indeed one can construct simple score functions on the hypercube for which the natural Metropolis chain run for any polynomial time leads to a non-private algorithm [Ganesh and Talwar, 2019]. There are also well-known complexity-theoretic barriers in exactly sampling from exp(−f ) if f is not required to be convex.
Several applications however involve convex functions f and this is the focus of the current work.
Indeed this is the problem of sampling from a log-concave distribution, which has attracted a lot of interest. Here, there are two broad lines of work. The classical results in this line of work (e.g.
[Applegate and Kannan, 1991, Lovász and Vempala, 2007]) show that given an oracle for computing the function, one can sample from a distribution that is ε-close3 to the target distribution in time polynomial in d and log 1
ε . Here the closeness is measured in statistical distance. By itself, this does not sufﬁce to give a differentially private algorithm, as DP requires closeness in more stringent notions of distance. The fact that the time complexity is logarithmic in 1
ε however allows for an exponentially small statistical distance in polynomial time. This immediately yields (ζ, δ)-DP algorithms, and with some additional work can also yield ζ-DP algorithms [Hardt and Talwar, 2010]. Techniques from this line of work can also sometimes apply to non-convex f of interest. Indeed Kapralov and Talwar
[2013] designed a polynomial time algorithm for the case of f being a Rayleigh quotient to allow for efﬁcient private PCA.
The runtime of these log-concave sampling algorithms however involves large polynomials. A beautiful line of work has reduced the dependence (of the number of function oracle calls) on the dimension from roughly d10 in Applegate and Kannan [1991] to d3 in Lovász and Vempala [2006],
Lovász and Vempala [2007]. Nevertheless, the algorithms still fall short of being efﬁcient enough to be implementable in practice for large d. A second, more recent, line of work [Dalalyan, 2017,
Durmus and Moulines, 2019] have shown that “ﬁrst order” Markov Chain Monte Carlo (MCMC) algorithms such as Langevin MCMC and Hamiltonian MCMC enjoy fast convergence, and have better dependence on the dimension. These algorithms are typically simpler and more practical but have polynomial dependence on the closeness parameter ε. This polynomial dependence on
ε makes the choice of distance more important. Indeed these algorithms have been analyzed for various measures of distance between distributions such as statistical distance, KL-divergence and
Wasserstein distance.
These notions of distance however do not lead to efﬁcient differentially private algorithms (see Ap-pendix F). This motivates the question of establishing rapid mixing in Rényi divergence for these algorithms. This is the question we address in this work, and show that when f is smooth and strongly convex, discretized Langevin dynamics converge in iteration complexity near-linear in the dimension.
This gives more efﬁcient differentially private algorithms for sampling for such f .
Vempala and Wibisono [2019] recently studied this question, partly for similar reasons. They consid-ered the Unadjusted (i.e., overdamped) Langevin Algorithm and showed that when the (discretized)
Markov chain satisﬁes suitable mixing properties (e.g. Log Sobolev inequality), then the discrete process converges in Rényi divergence to a stationary distribution. However this stationary distribu-tion of the discretized chain is different from the target distribution. The Rényi divergence between the stationary distribution and exp(−f ) is not very well-understood [Roberts and Tweedie, 1996,
Wibisono, 2018], and it is conceivable that the stationary distribution of the discrete process is not close in Rényi divergence to the target distribution and thus may not be differentially private. Thus the question of designing fast algorithms that sample from a distribution close to the distribution exp(−f ) in Rényi divergence was left open.
In this work we use a novel approach to address these questions of fast sampling from exp(−f ) using the discretized Langevin Algorithm. Interestingly, we borrow tools commonly used in differential privacy, though applied in a way that is not very intuitive from a privacy point of view. We upper bound the Rényi divergence between the output of the discrete Langevin Algorithm run for T steps, and the output of the continuous process run for time T η. The continuous process is known [Vempala and Wibisono, 2019] to converge very quickly in Rényi divergence to the target distribution. This allows us to assert closeness (in Rényi divergence) of the output of the discrete algorithm to the target distribution. This bypasses the question of the bias of the stationary distribution of the discrete process.
Moreover, this gives us a differentially private algorithm with iteration complexity near-linear in the 3The letter ε commonly denotes the privacy parameter in DP literature, and the distance to the target distribution in the sampling literature. Since most of the technical part of this work deals with sampling, we will reserve ε for distance, and will let ζ denote the privacy parameter. 2
f is L-smooth and
Process 1-strongly convex Overdamped
B-Lipschitz
Overdamped 1-strongly convex Underdamped
˜O
˜O (cid:16)
˜O
η (cid:17) (cid:16) 1
τ L4 ln2 α · ε2 d
ε2
B2+d (cid:17) 1
τ L4 ln2 α · (cid:16) 1
τ L ln α · ε√ d (Thm 9) (cid:17) (Thm 12) (Thm 16) (cid:17)
Iterations (cid:16) dτ 2L4 ln2 α
˜O
ε2 (cid:16) (B2+d)τ 2L4 ln2 α
ε2 dτ 2L ln α
ε (cid:16) √
˜O (cid:17) (cid:17)
˜O
Figure 1: Summary of results. For each family of functions and process (either overdamped or underdamped Langevin dynamics), an upper bound is listed on the step size η (and thus a bound on the iteration complexity) needed to ensure the α-Rényi divergence between the discrete and continuous processes is at most ε after time τ . Setting α = O(ln(1/δ)/ζ), ε = ζ/2 gives that the
δ-approximate max divergence is at most ζ, i.e. (ζ, δ)-differential privacy. dimension. Our result applies to log-smooth and strongly log-concave distributions. While results of this form may also be provable using methods from optimal transport, we believe that our techniques are simpler and more approachable to the differential privacy community, and may be more easily adaptable to other functions f of interest.
Our approach is general and simple. We show that it can be extended to the underdamped Langevin dynamics which have a better dependence on dimension, modulo proving fast mixing for the con-tinuous process. As a speciﬁc application, we show how our results lead to faster algorithms for implementing the mechanisms in Minami et al. [2016].
As is common in this line of work, we ignore numerical issues and assume real arithmetic. The results can be translated to the ﬁnite-precision arithmetic case by standard techniques, as long as the precision is at least logarithmic in d and T . The real arithmetic assumption thus simpliﬁes the presentation without affecting the generality of the results. 1.1 Other