Abstract
Despite achieving remarkable performance, deep graph learning models, such as node classiﬁcation and network embedding, suffer from harassment caused by small adversarial perturbations. However, the vulnerability analysis of graph matching under adversarial attacks has not been fully investigated yet. This paper proposes an adversarial attack model with two novel attack techniques to perturb the graph structure and degrade the quality of deep graph matching: (1) a kernel density estimation approach is utilized to estimate and maximize node densities to derive imperceptible perturbations, by pushing attacked nodes to dense regions in two graphs, such that they are indistinguishable from many neighbors; and (2) a meta learning-based projected gradient descent method is developed to well choose attack starting points and to improve the search performance for producing effective perturbations. We evaluate the effectiveness of the attack model on real datasets and validate that the attacks can be transferable to other graph learning models. 1

Introduction
Graph matching is one of the most important research topics in the graph domain, which aims to match the same entities (i.e., nodes) across two or more graphs [91, 98, 43, 46, 48, 72, 54, 105, 13, 75].
It has been widely applied to many real-world applications ranging from protein network matching in bioinformatics [33, 63], user account linking in different social networks [62, 51, 100, 37, 101, 21, 38], and knowledge translation in multilingual knowledge bases [87, 124], to geometric keypoint matching in computer vision [22]. Existing research efforts on graph matching can be classiﬁed into three broad categories: (1) structure-based techniques, which rely only upon the topological information to match two or multiple input graphs [43, 49, 95, 46, 54, 105, 13, 96, 84, 40, 67, 57, 38, 24]; (2) attribute-based approaches, which utilize highly discriminative structure and/or attribute features for ensuring the matching effectiveness [93, 94, 51, 10, 65, 16, 88, 100, 28, 39, 18, 97, 50, 52, 22]; and (3) heterogeneous methods, which employ heterogeneous structural, content, spatial, and temporal features to further improve the matching performance [92, 34, 44, 98, 83, 99, 77, 59, 102, 103, 21].
Recent literature has shown that both traditional and deep graph learning algorithms remain highly sensitive to adversarial attacks, i.e., carefully designed small perturbations in graph structure and attributes can cause the models to produce wrong prediction results [14, 126, 64, 125, 123, 69, 90, 74, 45, 85, 80, 127]. We have witnessed various effective attack models to cause failures of 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
node classiﬁcation [14, 126, 74, 86, 125, 71, 19, 70], community detection [9, 78, 7, 41], network embedding [6, 4, 5], link prediction [104], similarity search [15], malware detection [30], and knowledge graph embedding [90]. However, there is still a paucity of analyses of the vulnerability of graph matching under adversarial attacks, which is much more difﬁcult to study. Most of the existing models to fool other graph learning tasks conduct the adversarial attacks on a single graph but the graph matching task analyzes both intra-graph and inter-graph interactions of multiple graphs. In this work, we aim to answer the following questions: (1) Are graph matching algorithms sensitive to small perturbation of graph structure? (2) How do we develop effective and imperceptible perturbations for degrading the performance of deep graph matching models?
A large number of research advances in adversarial attacks on graph data utilize iterative gradient-based methods to produce effective adversarial perturbations that fool a graph learning model [68, 76, 14, 125, 86, 71, 89, 8]. However, a recent study reports that the iterative gradient-based methods, such as Fast Gradient Sign Method (FGSM) [26] and Projected Gradient Descent (PGD) [47], start the attacks from original examples and add perturbations monotonically along the direction of gradient descent, resulting in a lack of diversity and adaptability of generated iterative trajectories [61]. This often leads to invalid attacks since the iterative trajectories have difﬁculties crossing decision boundary of target learning model with small perturbation. Can we ﬁnd a shortcut across the decision boundary to derive more effective attacks by beginning from good attack starting points in the graph matching?
Traditionally, graph matching techniques are based on the assumption of feature consistency across graphs: Two nodes in different graphs are more likely to be found to be matching if they have similar topological and/or attribute features in respective graphs [98, 93, 10, 17, 28, 96]. These methods compute the similarity (or distance) scores between pairwise nodes across graphs and choose the node pairs with largest similarity (or smallest distance) as matching results [101, 88, 39, 38]. Intuitively, if an attacker perturbs a node by throwing it into a dense region in the graph with many similar nodes, i.e., a pile of nodes similar to each other, such that this attacked node is similar to many neighbors, then it is hard for humans or defender programs to recognize it from the node pile. In addition, if two matched nodes are simultaneously moved to such dense regions in respective graphs, then this dramatically increases the difﬁculty in matching them correctly among many similar candidate nodes.
To our best knowledge, this work is the ﬁrst to study adversarial attacks on graph matching.
We propose to utilize kernel density estimation (KDE) technique to estimate the probability density function of nodes in two graphs, to understand the intrinsic distribution of graphs. By maximizing the estimated densities of nodes to be attacked, we push them to dense regions in respective graphs to generate adversarial nodes that are indistinguishable from many neighbors in dense regions. This increases the chance of producing wrong matching results as well as reduces the risk of perturbations being detected by humans or by defender programs. Our analysis is the ﬁrst to introduce the KDE technique to conduct imperceptible attacks on graph data.
Searching for good attack starting points in large graphs is computationally inefﬁcient. We develop a meta learning-based projected gradient descent (MLPGD) model to quickly adapt to a variety of new search tasks on multiple batches of target nodes for deriving effective attacks. However, the
MLPGD model is non-smooth and non-differential, as the perturbation is a multi-step process and the projection at each step is non-differential. A Gaussian smoothing method is designed to approximate a smoothed model, and a Monte Carlo REINFORCE method is used to estimate the model gradient.
Empirical evaluation on real datasets demonstrates the superior performance of the GMA model against several state-of-the-art adversarial attack methods on graph data. Moreover, we validate that the attack strategies are transferable to other popular graph learning models in Appendix A.2. 2 Problem Deﬁnition 1, · · · , vs
Given two graphs G1 and G2 to be matched, each is denoted as Gs = (V s, Es) (s = 1 or 2), where j ) : 1 ≤ i, j ≤ N s} is the set of edges.
V s = {vs
N s } is the set of N s nodes and Es = {(vs
Each Gs has an N s × N s binary adjacency matrix As, where each entry As ij = 1 if there exists i: speciﬁes the ith row vector of As. In this paper, if an edge (vs there are no speciﬁc descriptions, we use vs i:, i.e., i = As vs i to denote a node vs ij to specify the jth dimension of vs i itself and its representation As ij = As i , i.e., vs ij. j ) ∈ Es; otherwise As i: and we utilize vs ij = 0. As i , vs i , vs 2
i , v2 k, v1 k)|v1 i ↔v2 i ∈ V 1, v2 k ∈ V 2}, where v1 k belong to the same entity. The latter, denoted by D = {(v1
The dataset is divided into two disjoint sets D(cid:48) and D. The former denotes a set of known matched node pairs D(cid:48) = {(v1 k indicates that two nodes v1 k, v1 k)|v1 i and v2 k ∈
V 2}, is used to evaluate the graph matching performance, where the nodes (but not their matchings) are also observed during training. The goal of graph matching is to utilize D(cid:48) as the training data to identify the one-to-one matching relationships between nodes v1 k in the test data D. By following the same idea in existing efforts [101, 88, 39, 38], this paper aims to minimize the distances between projected source nodes M (v1 i ) ∈ D(cid:48) and target ones v2 k) ∈ D with the smallest distances are selected as the matching results. k)∈D(cid:48) (cid:107)M (v1 k ∈ D(cid:48). The node pairs (v1
L where L = E i ↔v2 i , v2 i ∈ V 1, v2 i and v2 i ) − v2 i ↔v2 i , v2 k(cid:107)2 2 i ,v2 (1) (v1 min
M where M denotes an injective one-to-one matching function M : v1 i ∈ V 1 (cid:55)→ v2 k ∈ V 2.
The adversarial attack problem is deﬁned as maximally degrading the matching performance of
M on the test data D by injecting edge perturbations (including edge insertion and deletion) into
Gs = (V s, Es) (s = 1 or 2), leading to two adversarial graphs ˆGs = ( ˆV s, ˆEs). We assume the attacker has limited capability, so that he/she can only make small perturbations. 3
Imperceptible Attacks with Node Density Estimation and Maximization k(cid:107)2 k(cid:107)2 j ) − v2 2 < (cid:107)M (v1 i , such that (cid:107)M (v1 j similar to v1 i ) − v2 i , i.e., 2, then a k) will be generated. In addition, if there i , then it is hard to recognize v1 i from i to dense regions j s, then this dramatically increases j , v2 k) among j s are around i , it is difﬁcult for humans or defender
Intuitively, in Eq.(1), if there exist nodes v1 v1 j ≈ v1 j , v2 wrong matching (v1 are many such v1 j s around v1 a pile of similar nodes. Thus, if we move v1 that contain many similar v1 the possibility of deriving the wrong matching (v1 many similar candidate nodes. Also, as many v1 the adversarial node ˆv1 programs to detect ˆv1
Motivated by this, we propose to employ kernel density estima-tion (KDE) method to generate imperceptible perturbations. In statistics, the KDE is to estimate the probability density function i , as shown in a toy example in Figure 1.
Figure 1: Imperceptible Attacks f (x) of a random variable x with unknown distribution [55]. It helps reveal the intrinsic distribution. i , · · · , v1
Concretely, let v1 be a N 1-dimensional random variable to denote all nodes {v1
N 1} in graph
G1 with an unknown density f . A function ˆf (x) is estimated to best approximate f (x).
ˆf (v1) = 1
N 1det(B)
N 1 (cid:88)
K (cid:0)B−1 (cid:0)v1 − v1 i (cid:1)(cid:1) (2) i=1 where det(·) denotes the determinant operation. B > 0 is a bandwidth to be estimated. It is an N 1 × N 1 diagonal matrix B = diag(b1, · · · , bN 1 ), which has strong inﬂuence on the density estimation ˆf (v1). A good B should be as small as the data can allow. K is a product symmetric kernel that satisﬁes (cid:82) K(x)dx = 1 and (cid:82) xK(x)dx = 0. The above vector-wise form ˆf (v1) can be rewritten as an element-wise form, where v1 j represents the jth dimension in v1.
N 1 (cid:88)
N 1 (cid:89) (cid:16) v1 (cid:17) 1 bj
K j − v1 ij bj i=1 j=1
ˆf (v1) = 1
N 1
The derivative ∂ ˆf (v1)
∂bj
∂ ˆf (v1)
∂bj
= 1
N 1
N 1 (cid:88)
∂ i=1 w.r.t. each bandwidth bj in B is computed as follows, where K(x) = d log K(x) (cid:104) (cid:81)N 1 (cid:1)(cid:105) dx
.
= − 1
N 1
N 1 (cid:88) i=1 (cid:16) 1 bj
+ l − v1 v1 il b2 j
K(cid:0) v1 l − v1 il bj (cid:1)(cid:17) N 1 (cid:89) l=1 1 bl
K(cid:0) v1 l − v1 il bl (cid:1) l=1 l −v1 il bl
K(cid:0) v1 1 bl
∂bj (3) (4)
Traditional KDE methods often fail on high-dimensional data [29, 60, 32, 36], when bandwidths need to be selected for each dimension. A greedy search method is utilized to select bandwidths in 3
the KDE: If a dimension j is insigniﬁcant, then changing the bandwidth bj for that dimension should have a weak impact on ˆf (v1), while the changing bj for an important j should cause a large change in ˆf (v1). Fortunately, ∂ ˆf (v1) can differentiate these two types of dimensions. Based on the above
∂bj analysis, we greedily decrease bj with a sequence b0, b0s, b0s2, · · · for a parameter 0 < s < 1, until bj is smaller than a certain threshold τj, to see if a small change in bj can result in a large change in
ˆf (v1). The method also offers a good way to estimate (cid:2) ∂ ˆf (v1)
∂b1 (cid:3) along a sparse path.
, · · · , ∂ ˆf (v1)
∂bN 1
Concretely, ˆf (v1) is estimated by beginning with an initial B = diag(b0, · · · , b0) for a large b0, and then estimate ∂ ˆf (v1)
∂bj as follows and decrease bj if ∂ ˆf (v1)
∂bj is large.
∂ ˆf (v1)
∂bj
= 1
N 1 (cid:104) (cid:81)N 1 l=1
N 1 (cid:88)
∂ i=1 (cid:1)(cid:105) l −v1 il bl
K(cid:0) v1 1 bl
∂bj
= 1
N 1
N 1 (cid:88) i=1
K(cid:0) v1
K(cid:0) v1 j −v1 ij bj j −v1 ij bj (cid:1) (cid:1)
N 1 (cid:89) l=1
K(cid:0) v1 l − v1 il bl (cid:1) = 1
N 1
N 1 (cid:88) i=1
∂ ˆf (v1 i )
∂bj
The corresponding variance Var (cid:16) ∂ ˆf (v1)
∂bj (cid:17) is given below.
Var (cid:16) ∂ ˆf (v1)
∂bj (cid:17)
= Var (cid:16) 1
N 1
N 1 (cid:88) i=1 (cid:17)
∂ ˆf (v1 i )
∂bj (5) (6)
Theorems 1-5 in Appendix A.5 provide the theoretical analysis about the density estimation, deriva-tives, and variances for well understanding the KDE technique.
In this work, assuming that the graph data follow the Gaussian distribution, a product Gaussian kernel
K is used to estimate the node density ˆf (v1). ∂ ˆf (v1)
∂bj is accordingly updated as follows.
∂ ˆf (v1)
∂bj
=
=
C
N 1 1
N 1
N 1 (cid:88) i=1
N 1 (cid:88) i=1 (cid:16)(cid:0)v1 j − v1 ij (cid:1)2 − b2 j (cid:17) N 1 (cid:89) l=1
K(cid:0) v1 l − v1 il bl (cid:1) ∝ 1
N1
N1(cid:88) i=1 (cid:16)(cid:0)v1 j − v1 ij (cid:1)2 − b2 j (cid:17) N 1 (cid:89) l=1
K(cid:0) v1 l − v1 il bl (cid:1) (cid:16)(cid:0)v1 j − v1 ij (cid:1)2 − b2 j (cid:17) exp (cid:0) −
N 1 (cid:88) l=1 (cid:0)v1 l − v1 il 2b2 j (cid:1)2 (cid:1) (7) where C denotes a proportionality constant C = 1
. It can be safely ignored to avoid com-b3 j putation overﬂow when bl → 0 for large N 1. The bandwidth estimation is presented in Algorithm 1.
Based on the estimated B and the Gaussian kernel K, the closed form of ˆf (v1) is derived below. 1 bl (cid:81)N 1 l=1
ˆf (v1) = 1
N 1
N 1 (cid:88)
N 1 (cid:89) i=1 j=1
K(cid:0) v1 j − v1 ij bj (cid:115) (cid:1)
|B + Σ|
|Σ|
×exp (cid:0)− (v1 − µ)T (cid:0)Σ−1 − (B + Σ)−1(cid:1) (v1 − µ) 2 (cid:1) (8) where µ and Σ are the maximum likelihood estimation of the mean vector and covariance matrix of the Gaussian distribution. Please refer to Appendices A.6 and A.7 for detailed derivation of ˆf (v1).
As two graphs G1 and G2 often have different structures and distributions and thus the same KDE method as Algorithm 1 is utilized to estimate the density ˆg(v2) of v2. Based on the estimations ˆf (v1) and ˆg(v2), the attacker aims to maximize the following loss LD with imperceptible perturbations.
LD = (cid:88)
L(ˆv1 i , ˆv2 k) where L(ˆv1 i , ˆv2 k) = (cid:107)M (ˆv1 i ) − ˆv2 k)(cid:107)2 2 + ˆf (ˆv1 i ) + ˆg(ˆv2 k) (9) (ˆv1 i ,ˆv2 k)∈D i +δ1 k +δ2 i = v1 i (and ˆv2 k) denote adversarial versions of clean nodes v1 where ˆv1 k = v2 (and G2) by adding a small amount of edge perturbations δ1 method in the next section, such that M (ˆv1 decreased. In addition, we push v1 i and v2
ˆf (ˆv1
This reduces the possibility of perturbation detection by humans or defender programs. k) in G1 k) through our proposed MLPGD k and thus the matching accuracy is k, by maximizing k are indistinguishable from their neighbors in perturbed graphs. i ) is far away from ˆv2 k to dense regions to generate ˆv1 k), such that ˆv1 i ) and ˆg(ˆv2 i (and v2 i (and δ2 i and ˆv2 i and ˆv2 4
Algorithm 1 Bandwidth Matrix Estimation
Input: graph G1 = (V 1, E1), parameter 0 < s < 1, initial bandwidth b0, and parameter c.
Output: Bandwidth matrix B. 1: Initialize all b1, · · · , bN 1 with b0; 2: for each j = 1 to N 1 3: 4:
) in Eqs.(6)-(7); do
Estimate the derivative ∂f (v1) (cid:113)
∂bj
Compute the threshold τj = if (cid:12) (cid:12) (cid:12) (cid:12) > τj, then Update bj = bjs; and variance Var( ∂f (v1) 2 · Var( ∂f (v1)
∂bj
) · log(cN 1);
∂bj 5:
∂f (v1)
∂bj
∂f (v1)
∂bj 6: 7: while (cid:12) (cid:12) 8: Return B. (cid:12) (cid:12) > τj
Algorithm 2 Meta Learning-based Projected Gradient Descent (MLPGD)
Input: Batches D1, · · · , DC in a set D of node pairs, initial general policy parameters {θ1, θ2}, adaptation step size α, meta step size β.
Output: Optimized {θ1, θ2}. 1: Repeat until convergence
Sample C batches of anchor node pairs D1, · · · , DC ; 2: for c = 1 to C 3:
Estimate gradient ec = e(cid:0)Dc, {θ1, θ2}(cid:1); 4:
Compute adapted parameters {θ1 5: 6: Update parameters {θ1, θ2} = {θ1, θ2} + β
C 7: Return {θ1, θ2}. c } = {θ1, θ2} + αec; c=1 e(cid:0)Dc, {θ1 c }(cid:1); c , θ2 c , θ2 (cid:80)C 4 Effective Attacks via Meta Learning-based Projected Gradient Descent
In Figure 2, two dashed purple curves denote the deci-sion boundary of graph matching. If we move a clean node v1 i across the decision boundary to generate an adversarial node ˆv1 i , then we have other nodes v1 j to k become more similar than M (ˆv1 j ) and v2 make M (v1 i ) and v2 k) will be produced. Blue and green polylines denote attack tra-jectories starting from original and good starting pints with gradient descent method respectively. A shortcut k)0 is able to cr-from good starting points (v1 oss the peak of the decision boundary and converge quickly, while the trajectories from the original nodes v1 k, and thus a wrong matching (v1 k take long walks to cross the non-peak boundary.
Figure 2: Effective Attacks i )0 or (v2 i or v2 j , v2
Based on the attack loss in Eq.(9), we propose to integrate meta learning and PGD into an MLPGD model, to produce more effective adversarial nodes with good starting points towards graph matching. (10) (v1 i sgn(cid:2)ReLU(cid:0)∇(v1 i )(t+1) = Π(cid:52)1 sgn(cid:2)ReLU(cid:0)∇(v2 k)(t+1) = Π(cid:52)2 k)t denotes the adversarial nodes of v1 i )t L((v1 k)t L((v1 i )t, (v2 i )t, (v2 k (v2 i )t and (v2 k)t)(cid:1)(cid:3) k)t)(cid:1)(cid:3), t = 1, · · · , T i )t|1T (δ1
}, where (δ1 i )t = (cid:107)(v1 where (v1 i and v2 k derived at step t. (cid:15) speciﬁes i )t ∈ i = {(δ1 the budget of allowed perturbed edges for each attacked node. (cid:52)1
{0, 1}N 1 i (cid:107)2 i )t − v1 2, represents the constraint set of the projection operator Π, i is modiﬁed or not. (cid:52)2 i.e., it encodes whether an edge of v1 k. The composition of the ReLU and sign operators guarantees (v1
, as it adds (or removes) an edge or keeps it unchanged when an derivate in the gradient is positive (or i and ˆv2 negative). The outputs (v1 k. i , v2
Searching for attack starting points for each (v1 k) in large graphs is computationally inefﬁcient.
Meta learning techniques aim to train a general model with general parameters that can quickly adapt to a variety of new learning tasks with reﬁned parameters [23, 3, 42, 56]. This offers a great opportunity to ﬁnd good attack starting points (v1 k) ∈ D with lower cost, such that the generated ˆv1 k)0 for all (v1 k by the PGD model can maximize the attack loss LD in Eq.(9). k has the similar deﬁnition for v2 i )t ∈ {0, 1}N 1 and (v2 k)T at ﬁnal step T are used as the adversarial nodes ˆv1 k)t ∈ {0, 1}N 2 i )T and (v2 i )t ≤ (cid:15), (δ1 i )0 and (v2 i and ˆv2 i , v2 5
Algorithm 3 Gradient Estimation e(cid:0)Dc, {θ1, θ2}, N, λ(cid:1)
Input: Batch Dc, general parameters {θ1, θ2}, number of samples N in Monte Carlo REINFORCE, smoothing parameter λ.
Output: Gradient estimation of a. 1: Sample N i.i.d. Gaussian matrices g1, · · · , gN ∼ N (0, I); i=1 a(cid:0)Dc, {θ1, θ2} + λgi 2: Return gradient estimation 1
N λ (cid:80)N (cid:1)gi. c }(cid:1) c , θ2
Algorithm 4 Adversarial Attack a(cid:0)Dc, {θ1
Input: Batch Dc, perturbation budget (cid:15), speciﬁc parameters {θ1
Output: Attack loss LDc on Dc. 1: LDc = 0; 2: for each (v1 3: Generate attack starting points (v1 4: Utilize PGD attack to generate adversarial nodes (v1 5: Aggregate attack loss LDc + = L(cid:0)(v1 6: Return LDc . i )0 = h1(cid:0)v1 i )T , (v2 k) ∈ Dc i , v2 i |θ1 c k)T (cid:1) in Eq.(9); c , θ2 c } (cid:1) and (v2 i )T and (v2 k)0 = h2(cid:0)v2 (cid:1); k)T in Eq.(10); k|θ2 c (ˆv1 i ,ˆv2 k)∈Dc
Algorithm 2 presents the pseudo code of our MLPGD model. D is partitioned into C batches
D1, · · · , DC, each with equal size of |D|/C. The search process on each batch Dc (1 ≤ c ≤ C) is treated as a single task, which aims to ﬁnd good (v1 k)0 for Dc to maximize the attack loss LDc = (cid:80) k). A general model that has general parameters θ1, θ2 is learnt to
L(ˆv1 quickly adapt to search tasks on multiple batches. The learnt θ1, θ2 should be sensitive to changes of each Dc, such that small changes in θ1, θ2 will produce high rise on LDc over any of D1, · · · , DC.
Line 4 estimates the gradient of LDc by calling Algorithm 3. In Line 5, when adapting to the task on a new Dc, θ1, θ2 become speciﬁc parameters θ1 c for Dc. Here, we use {θ1 c , θ2 c } to denote the concatenation matrix of θ1 c . The parameters are trained by maximizing the attack loss c }(cid:1) w.r.t. general parameters θ1, θ2 across batches. The meta objective is given below. a(cid:0)Dc, {θ1 i )0 and (v2 c and θ2 i , ˆv2 c , θ2 c , θ2 max LDc = max
θ1,θ2
C (cid:88) c=1 a(cid:0)Dc, {θ1 c , θ2 c }(cid:1) =
C (cid:88) c=1 a(cid:0)Dc, {θ1, θ2} + αec (cid:1) (11)
In Line 6, the meta optimization is performed over the general θ1, θ2, while the objective is computed using the speciﬁc θ1 c . The general θ1, θ2 are updated in terms of the attack loss on each batch. c , θ2
{θ1, θ2} = {θ1, θ2} +
β
C
C (cid:88) c=1 e(cid:0)Dc, {θ1 c , θ2 c }(cid:1) (12)
Algorithm 4 exhibits the adversarial attack module a(cid:0)Dc, {θ1
Line 3, two neural networks h1 and h2 with speciﬁc parameters θ1 the attack starting points (v1 i )0 and (v2 composition of the ReLU [53] and Softsign [25] as activation function to ensure (v1 and (v2 nodes ˆv1 c }(cid:1) on a batch Dc (1 ≤ c ≤ C). In c and θ2 c are designed to generate k) ∈ Dc. The last layers of h1 and h2 use the i )0 ∈ {0, 1}N 1
. In Line 4, the PGD attack in Eq.(10) is utilized to generate the adversarial k. Line 5 calculates the attack loss LDc on Dc to provide task-speciﬁc feedback. k)0 ∈ {0, 1}N 2 i and ˆv2 k)0 of each (v1 i , v2 c , θ2
Standard meta learning models utilizes gradient ascent/descent techniques to compute the updated parameters on new tasks [23, 3, 42, 56]. However, the attack module in Algorithm 4 is non-smooth c , and θ2 and non-differential w.r.t. parameters θ1, θ2, θ1 c , since the perturbation is a multi-step process as well as the projection at each step is non-differential. Therefore, Algorithm 3 is proposed to employ Gaussian smoothing technique to approximate a smoothed attack module.
ˆa(cid:0)Dc, {θ1, θ2}(cid:1) ≈ (2π)− d 2 (cid:90) a(cid:0)Dc, {θ1, θ2} + λg(cid:1) exp (cid:0) −
= Eg∼N (0,I)a(cid:0)Dc, {θ1, θ2} + λg(cid:1) (cid:107)g(cid:107)2 2 (cid:1)dg 1 2 (13) where ˆa is the Gaussian smoothing of a and differentiable everywhere. λ is a smoothing parameter, and d is the number of entries in {θ1, θ2}. g ∼ N (0, I) that has the same size as {θ1 c } is interpreted as policy exploration directions, i.e., as perturbations in policy space to be explored. Thus, the policy perturbations in g are introduced to θ1 c respectively. ˆa is obtained by perturbing a at a given point along Gaussian directions and averaging the evaluations. And then, Algorithm 3 estimates the gradient of ˆa via Monte Carlo REINFORCE method [79]. c and θ2 c , θ2 6
Table 2: Mismatching rate (%) with 5% perturbed edges
AS
SNS
DBLP
Attack Model SNNA CrossMNA DGMC SNNA CrossMNA DGMC SNNA CrossMNA DGMC 53.9
Clean 57.5
Random 56.5
RL-S2V
Meta-Self 63.1 61.7
CW-PGD
GF-Attack 57.9
CD-ATTACK 59.0 64.2
GMA 56.1 59.8 62.6 65.7 68.7 64.9 64.0 74.2 45.2 48.8 51.3 55.1 54.9 52.9 54.0 61.2 34.7 37.6 36.5 45.0 49.6 39.5 42.7 54.9 41.6 46.8 45.8 51.3 49.6 47.9 50.2 55.7 46.6 49.9 51.8 55.1 59.1 53.7 51.7 62.9 50.4 52.0 53.2 64.8 63.0 59.6 59.8 69.6 51.9 54.0 56.7 63.7 66.6 61.1 61.8 74.3 63.2 68.8 69.3 73.3 75.4 69.1 72.0 80.7 e(cid:0)Dc, {θ1, θ2}(cid:1) ≈ ∇θ1,θ2 ˆa(cid:0)Dc, {θ1, θ2}(cid:1) ≈ (2π)− d 2 (cid:90) a(cid:0)Dc, {θ1, θ2} + λg(cid:1) exp (cid:0) − (cid:107)g(cid:107)2 2 (cid:1)gdg 1 2 a(cid:0)Dc, {θ1, θ2} + λgi (cid:1)gi, gi ∼ N (0, I) (14)
= 1
λ (cid:16)
Eg∼N (0,I)a
Dc, {θ1, θ2} + λg (cid:17) g ≈ 1
N λ
N (cid:88) i=1 5 Experimental Evaluation
Table 1: Experiment Datasets
Dataset
Graph
#Nodes
#Edges
#Matched Nodes
AS v1 v2
SNS
Last.fm LiveJournal 10,900 11,113 5,682 31,180 31,434 23,393 17,828 244,496 6,462 2,138
DBLP 2014 2013 28,478 26,455 128,073 114,588 4,000
BLP coauthor graphs [1], as shown in Table 1.
In this section, we will show the ef-fectiveness of the GMA model in this work for deep graph matching tasks over three groups of datasets: social networks (SNS) [98], au-tonomous systems (AS) [2], and D-Baselines. We compare the GMA model with six state-of-the-art graph attack models. Random
Attack randomly adds and removes edges to generate perturbed graphs. RL-S2V [14, 123] generates adversarial attacks on graph data based on reinforcement learning. Meta-Self [125] is a poisoning attack model for node classiﬁcation by using meta-gradients to solve the bilevel optimization problem.
CW-PGD [86] developed a PGD topology attack to attack a predeﬁned or a retrainable GNN. GF-Attack [5] attacks general learning methods by devising new loss and approximating the spectrum.
CD-ATTACK [41] hides nodes in the community by attacking the graph autoencoder model. The majority of existing efforts focus on adversarial attacks on single graph learning. To our best knowledge, there are no other attack baselines on graph matching available. We replace the original losses in the baselines with the matching loss for fair comparison in the experiments.
Variants of GMA model. We evaluate four variants of GMA to show the strengths of different components. GMA-KDE only uses the KDE and density maximization to generate imperceptible attacks. GMA-PGD only utilizes the basic PGD [47] to produce effective attacks. GMA-MLPGD employs our proposed MLPGD model to well choose good attack starting points in the PGD. GMA operates with the full support of both KDE and MLPGD components.
Graph matching algorithms. We validate the effectiveness of the above attack models with three representative deep graph matching methods. SNNA [39] is an adversarial learning framework to solve the weakly-supervised identity matching problem by minimizing the distribution distance.
CrossMNA [13] is a cross-network embedding-based supervised network alignment method by learning inter/intra-embedding vectors for each node and by computing pairwise node similarity scores across networks. Deep graph matching consensus (DGMC) [22] is a supervised graph matching method that reaches a data-driven neighborhood consensus between matched node pairs.
Evaluation metrics. We use two popular measures in graph matching to verify the attack qual-ity: Accuracy [93, 10, 95] and P recision@K [101, 13, 97]. A larger mismatching rate (i.e., 1 -Accuracy on test data) or a smaller P recision@K shows a better attack. K is ﬁxed to 30 in all tests.
Attack performance on various datasets with different matching algorithms. Table 2 exhibits the mismatching rates of three deep graph matching algorithms on test data by eight attack models over three groups of datasets. We randomly sample 10% of known matched node pairs as training data and the rest as test data. For all attack models, the number of perturbed edges is ﬁxed to 5% in these experiments. It is observed that among eight attack methods, no matter how strong the attacks are, the GMA method achieve the highest mismatching rates on perturbed graphs in most experiments, showing the effectiveness of GMA to the adversarial attacks. Compared to the graph matching results under other attack models, GMA, on average, achieves 21.3%, 18.8%, and 19.2% 7
(a) SNNA on SNS (b) DGMC on SNS (b) DGMC on SNS
Figure 4: Precision with varying training ratios
Figure 3: Precision with varying perturbed edges improvement of mismatching rates on AS, SNS, and DBLP respectively. In addition, the promising performance of GMA with all three graph matching models implies that GMA has great potential as a general attack solution to other graph matching methods, which is desirable in practice. (a) SNNA on SNS
Attack performance with varying perturbation edges. Figure 3 presents the graph matching quality under eight attack models by varying the ratios of perturbed edges from 2% to 25%. It is obvious that the attacking performance improves for each attacker with an increase in the number of perturbed edges. This phenomenon indicates that current deep graph matching methods are very sensitive to adversarial attacks. GMA achieves the lowest P recision values (< 0.488), which are still better than the other seven methods in most tests. Especially, when the perturbation ratio is large than 10%, the P recision values drop quickly.
Impact of training data ratios. Figure 4 shows the quality of two graph matching algorithms on
SNS by varying the ratio of training data from 2% to 25%. Here, the number of perturbed edges is
ﬁxed to 5%. We make the following observations on the performances by eight attack models. (1)
The performance curves keep increasing when the training data ratio increases. (2) GMA outperforms other methods in most experiments with the lowest P recision: < 0.482 with SNNA and < 0.571 with DGMC respectively. Even when there are many training data available (≥ 20%), the quality degradation by GMA is still obvious, although more training data makes the graph matching models be resilient to poisoning attacks under a small perturbation budget.
Ablation study. Figure 5 presents the mismatching rates of graph matching on SNS with four variants of the GMA attack model. We have observed the complete GMA achieves the highest mismatching rates (> 54.9%) on AS, (> 55.7%) over SNS, and (> 74.2%) on DBLP, which are obviously better than other versions. Notice that GMA-MLPGD performs quite well in most experiments, compared with GMA-PGD. A reasonable explanation is that searching from good attack starting points can help the MLPGD converge quickly by crossing the peak of the decision boundary. In addition, GMA-KDE achieves the better attack performance than GMA-MLPGD. A rational guess is that it is difﬁcult to correctly match two nodes results when they lie in dense regions with many similar nodes, although the main goal of KDE is to generate imperceptible attacks. These results illustrate both KDE and
MLPGD models are important in producing effective attacks in graph matching.
Impact of perturbation budget (cid:15). Figure 6 (a) measures the performance effect of (cid:15) in the MLPGD model for the graph matching by varying (cid:15) from 1 to 5. It is observed that when increasing (cid:15), the
P recision of the GMA model decreases substantially. This demonstrates that it is difﬁcult to train a robust graph matching model under large (cid:15) constraint. However, a large (cid:15) can be easily detected by humans or by defender programs. Notice that the average node degree of three groups of datasets is between 2.9 and 13.9. Thus we suggest generating both imperceptible and effective attacks for the graph matching task under (cid:15) between 2 and 3, such that (cid:15) is smaller than the average node degree.
Time complexity analysis Based on [20], the complexity of meta learning is O(d2), where d is the problem dimension. In the context of graph matching, it is the number of nodes in two graphs (N s, s = 1 or 2). Both density estimation and PGD have complexity of O((N s)2). Thus, the overall complexity is O((N s)2), which is the same as most existing attack methods that search the entire graphs to ﬁnd weak edges to attack.
Impact of meta step size α. Figure 6 (b) shows the impact of α in our MLPGD model over three groups of datasets. The performance curves initially raise when α increases. Intuitively, the MLPGD with large α can help the meta learning converge quickly. Later on, the performance curves keep relatively stable or even decreasing when α continuously increases. A reasonable explanation is that 8
(a) SNNA (b) DGMC
Figure 5: Mismatching rate (%) of GMA variants the too large α makes the meta learner take a big walk with rapid pace, such that it may miss the optimal meta parameters. Thus, it is important to determine the optimal α for the MLPGD model. (a) Perturbation budget (cid:15) (b) Meta step size α
Figure 6: Precision with varying parameters 6