Abstract
In high-stakes machine learning applications, it is crucial to not only perform well on average, but also when restricted to difﬁcult examples. To address this, we consider the problem of training models in a risk-averse manner. We propose an adaptive sampling algorithm for stochastically optimizing the Conditional Value-at-Risk (CVaR) of a loss distribution, which measures its performance on the α fraction of most difﬁcult examples. We use a distributionally robust formulation of the CVaR to phrase the problem as a zero-sum game between two players, and solve it efﬁciently using regret minimization. Our approach relies on sampling from structured Determinantal Point Processes (DPPs), which enables scaling it to large data sets. Finally, we empirically demonstrate its effectiveness on large-scale convex and non-convex learning tasks. 1

Introduction
Machine learning systems are increasingly deployed in high-stakes applications. This imposes reliability requirements that are in stark discrepancy with how we currently train and evaluate these systems. Usually, we optimize expected performance both in training and evaluation via empirical risk minimization (Vapnik, 1992). Thus, we sacriﬁce occasional large losses on “difﬁcult” examples in order to perform well on average. In this work, we instead consider a risk-averse optimization criterion, namely the Conditional Value-at-Risk (CVaR), also known as the Expected Shortfall. In short, the α-CVaR of a loss distribution is the average of the losses in the α-tail of the distribution.
Optimizing the CVaR is well-understood in the convex setting, where duality enables a reduction to standard empirical risk minimization using a modiﬁed, truncated loss function from Rockafellar et al. (2000). Unfortunately, this approach fails when stochastically optimizing the CVaR – especially on non-convex problems, such as training deep neural network models. A likely reason for this failure is that mini-batch estimates of gradients of the CVaR suffer from high variance.
To address this issue, we propose a novel adaptive sampling algorithm – ADA-CVAR (Section 4). Our algorithm initially optimizes the mean of the losses but gradually adjusts its sampling distribution to in-creasingly sample tail events (difﬁcult examples), until it eventually minimizes the CVaR (Section 4.1).
Our approach naturally enables the use of standard stochastic optimizers (Section 4.2). We provide convergence guarantees of the algorithm (Section 4.3) and an efﬁcient implementation (Appendix A).
Finally, we demonstrate the performance of our algorithm in a suite of experiments (Section 5). 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
2