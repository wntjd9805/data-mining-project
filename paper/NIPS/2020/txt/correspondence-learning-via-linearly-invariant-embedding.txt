Abstract
In this paper, we propose a fully differentiable pipeline for estimating accurate dense correspondences between 3D point clouds. The proposed pipeline is an extension and a generalization of the functional maps framework. However, instead of using the Laplace-Beltrami eigenfunctions as done in virtually all previous works in this domain, we demonstrate that learning the basis from data can both improve robustness and lead to better accuracy in challenging settings. We interpret the basis as a learned embedding into a higher dimensional space. Following the functional map paradigm the optimal transformation in this embedding space must be linear and we propose a separate architecture aimed at estimating the transformation by learning optimal descriptor functions. This leads to the ﬁrst end-to-end trainable functional map-based correspondence approach in which both the basis and the descriptors are learned from data. Interestingly, we also observe that learning a canonical embedding leads to worse results, suggesting that leaving an extra linear degree of freedom to the embedding network gives it more robustness, thereby also shedding light onto the success of previous methods. Finally, we demonstrate that our approach achieves state-of-the-art results in challenging non-rigid 3D point cloud correspondence applications. 1

Introduction
Computing correspondences between geometric objects is a widely investigated task. Its applications are countless: rigid and non-rigid registration methods are instrumental in engineering, medicine and biology [25, 29, 16] among other ﬁelds. Point cloud registration is important for range scan data, e.g., in robotics [19, 52], but the problem can also be generalized to abstract domains like graphs [58, 15].
The non-rigid correspondence problem is particularly challenging as a successful solution must deal with a large variability in shape deformations and be robust to noise in the input data. To address this problem, in recent years, several data-driven approaches have been proposed to learn the optimal transformation model from data rather than imposing it a priori, including [20, 61, 7] among others.
In this domain, a prominent direction is based on the functional map representation [39], which has been adapted to the learning-based setting [31, 22, 48, 13]. These methods have shown that optimal feature or descriptor functions (also known as “probe” functions) can be learned from data and then used successfully within the functional map pipeline to obtain accurate dense correspondences.
∗denotes equal contribution. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
Invariant
Embedding
Network
N
Invariant
Embedding
Network
N
Probe
Function
Network
G
Probe
Function
Network (cid:98)AX Y
Section 4.2-4.3
Section 4.1 a) Learn linearly-invariant basis
G
Section 4.2 b) Learn probe functions e) Match by
Nearest-Neighbor
Figure 1: Pipeline overview: starting from point cloud coordinates we obtain a set of linearly-invariant basis functions via the Invariant Embedding Network N (a), and descriptors using the Probe
Function Network G (b). The learned basis and probe functions are used to compute the optimal linear transformation (cid:98)AX Y (c). This transformation is used to align the two sets of bases (d). The correspondence between point clouds is then estimated using nearest neighbors between the aligned basis sets (e). Note that the underlying meshes are depicted only for sake of clarity of visualization. c) Optimal linear transformation d) Aligned basis
Unfortunately, the reduced functional basis, which forms the key ingredient in this approach, has so far been tied to the Laplace-Belrtami eigen-basis, speciﬁed and ﬁxed a priori. While this choice might be reasonable for near-isometric 3D shapes represented as triangle meshes, it does not allow to handle more diverse deformations classes of or signiﬁcant noise in the data.
Inspired by the success and robustness of these techniques, we propose the ﬁrst fully-differentiable functional maps pipeline, in which both the probe functions and the functional basis are learned from the data. Our key observation is that basis learning can be phrased as computing an embedding into a higher-dimensional space in which a non-rigid deformation becomes a linear transformation.
This follows the functional map paradigm in which functional maps arising from pointwise corre-spondences must always be linear [39] and computing such a linear transformation is equivalent to solving the non-rigid correspondence problem. In the process, we also observe that training a network that aims to compute a canonical embedding, in which optimal correspondences are simple nearest neighbors, leads to a drop in performance. As we discuss below, this suggests that the additional degree of freedom, by learning a linearly-invariant embedding, helps to regularize the learning process and avoid overﬁtting in challenging cases. Finally, we demonstrate that our simple (but effective) formulation leads to accurate dense maps. The code, datasets and our pre-trained networks can be found online: https://github.com/riccardomarin/Diff-FMaps. 2