Abstract
We address the problem of ﬁtting 3D human models to 3D scans of dressed humans.
Classical methods optimize both the data-to-model correspondences and the human model parameters (pose and shape), but are reliable only when initialized close to the solution. Some methods initialize the optimization based on fully supervised correspondence predictors, which is not differentiable end-to-end, and can only process a single scan at a time. Our main contribution is LoopReg, an end-to-end learning framework to register a corpus of scans to a common 3D human model.
The key idea is to create a self-supervised loop. A backward map, parameterized by a Neural Network, predicts the correspondence from every scan point to the surface of the human model. A forward map, parameterized by a human model, transforms the corresponding points back to the scan based on the model parameters (pose and shape), thus closing the loop. Formulating this closed loop is not straightforward because it is not trivial to force the output of the NN to be on the surface of the human model – outside this surface the human model is not even deﬁned. To this end, we propose two key innovations. First, we deﬁne the canonical surface implicitly as the zero level set of a distance ﬁeld in R3, which in contrast to more common UV parameterizations Ω ⊂ R2, does not require cutting the surface, does not have discontinuities, and does not induce distortion. Second, we diffuse the human model to the 3D domain R3. This allows to map the NN predictions forward, even when they slightly deviate from the zero level set. Results demonstrate that we can train LoopReg mainly self-supervised – following a supervised warm-start, the model becomes increasingly more accurate as additional unlabelled raw scans are processed. Our code and pre-trained models can be downloaded for research [5]. 1

Introduction
We propose a novel approach for model-based registration, i.e. ﬁtting parametric model to 3D scans of articulated humans. Registration of scans is necessary to complete, edit and control geometry, and is often a precondition for building statistical 3D models from data [82, 48, 58, 11].
Classical model-based approaches optimize an objective function over scan-to-model correspondences and the parameters of a statistical human model, typically pose, shape and non-rigid displacement.
When properly initialized, such approaches are effective and generalize well. However, when the variation in pose, shape and clothing is high, they are vulnerable to local minima. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
To avoid convergence to local minima, researchers proposed to use predictors to either initialize the latent parameters of a human model [32], or the correspondences between data points and the model [60, 76]. Learning to predict global latent parameters of a human model directly from a point-cloud is difﬁcult and such initializations to standard registration are not yet reliable. Instead, learning to predict correspondences to a 3D human model is more effective [10, 14].
Several important limitations are apparent with current approaches. First, supervising an initial regression model of correspondence requires labeled scans [60, 76, 81, 52], which are hard to obtain.
Second, although some approaches use predicted correspondences to initialize a subsequent, classical optimization-based registration, this process involves non-differentiable steps.
What is lacking is a joint end-to-end differentiable objective over correspondences and human model parameters, which allows to train the correspondence predictor, self-supervised, given a corpus of unlabeled scans. This is our motivation in introducing LoopReg.
Given a point-cloud, a backward map, parameterized by a neural network, transforms every scan point to a corresponding point on the canonical surface (the human model in a canonical pose and shape).
A forward map, parameterized by the SMPL human model [48], transforms canonical points under articulation, shape and non-rigid deformation, to ﬁt the original point-cloud, see Fig. 1. LoopReg creates a differentiable loop which supports the self-supervised learning of correspondences, along with pose, shape and non-rigid deformation, following a short supervised warm-start.
The design of LoopReg requires several technical innovations. First, we need a continuous represen-tation for canonical points, to be on the human surface manifold. We deﬁne the surface implicitly as the zero level set of a distance ﬁeld in R3 instead of the more common approach of using a 2D UV parameterization Ω ⊂ R2, which typically relies on manual interaction, and inevitably has distortion and boundary discontinuities [35]. We follow a Lagrangian formulation; during learning,
NN predictions which deviate from the implicit surface are penalized softly. Furthermore, we interpret the 3D human model as a function on the surface manifold. We diffuse the function onto the 3D domain via a distance transform (Fig. 3), which allows to map the NN predictions forward, when they slightly deviate from the surface during learning.
In summary, our key contributions are:
• LoopReg is the ﬁrst end-to-end learning process jointly deﬁned over a parametric human model and the data (scan / point cloud) to model correspondences.
• We propose an alternative to classical UV parameterization for correspondences. We deﬁne the canonical human surface implicitly as the zero levelset of a distance ﬁeld, and diffuse the SMPL function to the 3D domain. The formulation is continuous and differentiable.
• LoopReg supports self-supervision. We experimentally show that registration accuracy can be improved as more unlabeled data is added. 2