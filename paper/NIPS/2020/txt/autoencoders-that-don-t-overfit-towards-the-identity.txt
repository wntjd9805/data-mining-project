Abstract
Autoencoders (AE) aim to reproduce the output from the input. They may hence tend to overﬁt towards learning the identity-function between the input and output, i.e., they may predict each feature in the output from itself in the input. This is not useful, however, when AEs are used for prediction tasks in the presence of noise in the data. It may seem intuitively evident that this kind of overﬁtting is prevented by training a denoising AE [36], as the dropped-out features have to be predicted from the other features. In this paper, we consider linear autoencoders, as they facilitate analytic solutions, and ﬁrst show that denoising / dropout actually prevents the overﬁtting towards the identity-function only to the degree that it is penalized by the induced L2-norm regularization. In the main theorem of this paper, we show that the emphasized denoising AE [37] is indeed capable of completely eliminating the overﬁtting towards the identity-function. Our derivations reveal several new insights, including the closed-form solution of the full-rank model, as well as a new (near-)orthogonality constraint in the low-rank model. While this constraint is conceptually very different from the regularizers recently proposed in [11, 42, 14], their resulting effects on the learned embeddings are empirically similar. Our experiments on three well-known data-sets corroborate the various theoretical insights derived in this paper. 1

Introduction and Motivation
Autoencoders (AE) have been successful in various unsupervised problems, including machine translation (e.g. [34]), computer vision (e.g., [30]) and recommender systems (e.g., [41]). In machine learning applications, their prediction accuracy on noisy test-data is often more important than the learned encodings/representations. The latter are often simply a means for achieving high prediction accuracy. Given a data-point as input, an AE aims to reconstruct the feature-values of this data-point in its output-layer. Obviously, the trivial yet futile solution is to learn literally the identity-function between the input and output-layer (given sufﬁciently large model-capacity), i.e., to predict each feature i in the output-layer from the same feature i in the input-layer. As to achieve high prediction accuracy on noisy data, however, the AE should ideally learn all the relevant dependences/interactions among the various features, i.e., feature i in the output-layer should be predicted by taking into account all other features j (cid:54)= i it depends on in the input-layer. Intuitively speaking, when the learned AE makes predictions for a feature i in the output-layer by relying ‘too much’ on the same feature i in the input-layer (i.e., identity function), and ‘not enough’ on the other features j (cid:54)= i it depends on, we call this overﬁtting towards the identity function in this paper.1 Even if the model-capacity is limited, the training may still tend to overﬁt towards the identity-function, as we will show in this paper. 1Note that the objective in this paper is still to minimize the reconstruction error–by predicting feature i in the output-layer from the other features j (cid:54)= i in the input-layer, i.e., without learning literally the identity function or overﬁtting towards it. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
Applying denoising during training was found to be a very effective regularizer [36]. While there are different kinds of noise for corrupting the input (e.g., see [28]), in this paper we focus on denoising by random dropout [18], the most common approach. In recent years, there has been extensive work on understanding denoising and dropout based on different perspectives, like preventing co-adaptation [18, 32], ensemble-averaging [4, 2], marginalized analysis and L2-norm regularization
[10, 40, 28, 39, 16, 22, 20, 9] and others [36, 35, 25, 24].
In denoising, when a feature is randomly dropped out from a data-point in the input-layer, then the (uncorrupted) value of this feature in the output-layer has to be predicted based on the other features of that data-point. It hence seems intuitively evident that this may prevent the AE from overﬁtting towards the identity function. The fact that this intuition turns out to be only partially correct, as we will show, motivated this work.
In this paper, we consider the simpliﬁed case of a linear autoencoder (LAE) trained with least squares, as this facilitates analytic insights. Note that linear models have been used before to better understand deep nonlinear models, e.g., [31, 1, 29, 23]. After introducing notation in Section 2, we ﬁrst outline the limitations of denoising by dropout (Section 3): given that it is asymptotically equivalent to
L2-norm regularization in LAE (see also [7, 10, 40, 28, 39, 16, 20, 9]), we show that overﬁtting towards the identity is only prevented to the degree that it is penalized by L2-norm regularization.
In Section 4, we show that the so-called emphasized denoising AE [37] is indeed able to completely prevent overﬁtting towards the identity-function. The theoretical analysis of the emphasized denoising
LAE (EDLAE) is the central result of this paper, from which several new insights can easily be derived: the closed-form solution for the full-rank model, as well as a novel (near-)orthogonality-constraint in the low-rank EDLAE. This constraint encourages the learned latent embeddings to become more ‘spread out’ in the latent space, a similar effect as recently obtained with conceptually very different approaches: Parseval networks [11] to improve robustness to adversarial examples, as well as the spread-out [42] and GLaS [14] regularizers for extreme classiﬁcation problems. The experiments on three well-known data-sets in Section 6 empirically corroborate the various insights derived in this paper. 2 Model Deﬁnition and Notation
In this section, we introduce notation and deﬁne the training objective of EDLAE. We assume that the training data are given in terms of a matrix X ∈ Rr×m with r data points (rows) and m features (columns). As to facilitate an analytic solution, we focus on linear autoencoders (LAE) trained by least squares. Also in [31, 1, 29, 23], linear models were studied with the goal to better understand deep nonlinear models. Let the LAE be represented by a matrix B ∈ Rm×m. If B is of low rank, say of rank k, it may be written as B = UV(cid:62), where the rank-k matrices U, V ∈ Rm×k correspond to the encoder and decoder, respectively.
Denoising by randomly dropping out feature-values in the input-layer of the LAE, may be formalized as follows: assuming that the training is comprised of n epochs of gradient descent, we vertically stack n times the given (ﬁnite) training matrix X as to obtain the (uncorrupted) target-matrix
X(n) = [X(cid:62)...X(cid:62)](cid:62). Correspondingly, we generate the corrupted input-matrix Z(n) by applying dropout to each entry (independently of the other entries): Z(n) u,i for all u, i, where each
δu,i ∈ {0, 1} is the realization of a Bernoulli variable with success (i.e., 1) probability q = 1 − p, where p is the dropout probability. Given that X has r rows, note that X(n) and Z(n) each have n · r rows. We can now write down the training objective, using the squared error, as it facilitates analytic solutions. We consider the asymptotic limit where the number of training epochs n → ∞, i.e., the stochastic dropout-learning has converged: u,i = δu,i · X(n)
ˆB = argmin
B lim n→∞ (cid:13) (cid:13)A(n)1/2 (cid:12) (cid:13) (cid:16) 1 n
X(n) − Z(n) · B (cid:17)(cid:13) 2 (cid:13) (cid:13)
F
, (1) where || · ||F denotes the Frobenius norm. Following the deﬁnition of EDLAE [37], we introduce the weighting matrix A(n), where A(n) u,i = a if δu,i = 0 (where δu,i is the same realization as above), and A(n) u,i = b otherwise, with a ≥ b. In other words, compared to the default weight b, the error in predicting feature i in data point u in the output-layer is up-weighted by a (where a ≥ b) if this feature was dropped out in the input-layer–and hence has to be predicted based on the other 2
input-features. For this reason, it is apparent that the overﬁtting towards the identity-function is completely prevented for the choice a > b = 0 (called full emphasis in [37]), as it considers only the errors on those features that were dropped out in the input and hence have to be predicted based on the other features. In Eq. 1, A(n)1/2 is the elementwise square-root of A(n) as it is inside the squared error, and (cid:12) is the elementwise product. Given that dropout is applied only during the training of ˆB, the learned parameters have to be re-scaled when making predictions on new data points (without dropout) [18], resulting in the ﬁnal solution:
ˆB(EDLAE) = q · ˆB (2) 3 Denoising merely induces L2-Norm Regularization
In this section, we ﬁrst review the (standard) dropout-denoising (i.e., a = b) and outline that it is asymptotically equivalent to L2-norm regularization in LAE (see also [10, 40, 28, 39, 16, 20, 9]).
This prevents the overﬁtting towards the identity only to the degree that it is penalized by the L2-norm regularization induced by dropout, as is outlined in the following
Let the (standard) denoising linear autoencoder (DLAE) be denoted by B(DLAE) := B(EDLAE)
. The training objective of DLAE, as given by Eqs. 1 and 2 for a = b, can be simpliﬁed as follows upon convergence (i.e., in the asymptotic limit where the number of training epochs n → ∞): a=b
ˆB(DLAE) = argmin
B(DLAE) (cid:13) (cid:13) (cid:13)X − X · B(DLAE)(cid:13) 2 (cid:13) (cid:13)
F
+ (cid:13) (cid:13) (cid:13)Λ1/2 · B(DLAE)(cid:13) 2 (cid:13) (cid:13)
F (3) where X is the (ﬁnite) training data (deﬁned above). The second term is the L2-norm regularization induced by dropout-denoising, where Λ1/2 is the elementwise square root of the diagonal matrix
Λ = p q
· dMat(diag(X(cid:62)X)), (4) where dMat(·) denotes a diagonal matrix, diag(X(cid:62)X) is the vector on the diagonal of X(cid:62)X, and p is the dropout-probability (q = 1 − p). Eq. 3 can be derived easily (e.g., by expanding the squared error into its four parts), as done in several papers (e.g., [10, 40, 28, 39, 16, 20, 9]). Eq. 3 shows that dropout-denoising has no other effect than inducing L2-norm regularization in DLAE. 3.1 Overﬁtting towards the Identity
It may seem intuitively evident that denoising by dropping out a feature in the input-layer forces the autoencoder to rely on the other input-features as to predict this feature in the output-layer. In this section, we outline that dropout-denoising actually does not prevent the autoencoder from learning the identity matrix beyond the effect provided by the L2-norm regularization. This can be seen most easily in the case where B(DLAE) is of full rank2 in Eq. 3: this ridge-regression problem is solved by full
ˆB(DLAE) full
= (X(cid:62)X + Λ)−1X(cid:62)X = (X(cid:62)X + Λ)−1(X(cid:62)X + Λ − Λ)
= I − (X(cid:62)X + Λ)−1Λ. (5)
While the identity-matrix I is the solution when no L2-regularization is used (Λ = 0), as expected, we can see that L2-regularization (Λ (cid:54)= 0) gives rise to the off-diagonal entries being different from zero in general (due to the term (X(cid:62)X + Λ)−1Λ). The off-diagonal entries are responsible for predicting feature i based on the other features j (cid:54)= i. However, note that the diagonal of ˆB(DLAE) in
Eq. 5 is still non-zero in general, and hence the value of each feature i in the output-layer is to some part predicted by its own value in the input-layer. Hence, the overﬁtting towards the identity is not completely prevented by dropout-denoising (except for the futile case p → 1). full 2Even though the full-rank model does not provide an encoding (like a usual AE does), it is still a useful model for making predictions. It may also be viewed as the limit of low-rank models whose rank approaches full rank. A key advantage of the full-rank model is that it allows for a closed-form solution, from which new insights can be obtained. 3
3.2 Difference to Weight-Decay
Even though dropout-denoising does not prevent the overﬁtting to the identity, as just discussed, as an aside we outline in this section as to why the induced L2-norm regularization nevertheless is considerably more effective in preventing overﬁtting than is weight decay / parameter shrinkage, which are commonly used for training deep models. In this section, we review the crucial differences and provide new insights. It can most easily be seen by considering the low-rank model B(DLAE) =
UV(cid:62) with one hidden layer, where U, V ∈ Rm×k are rank-k matrices. There are two key differences to weight decay:
F + ||V(cid:62)||2
F . In contrast, dropout induces the L2-regularization ||B||2 1. In weight decay, each weight (model parameter) is penalized individually. This may be written as ||U||2
F =
||U · V(cid:62)||2
F . The latter regularization of the linear autoencoder B hence is invariant under different parametrizations of the same rank k (e.g., whether B = U · V(cid:62), or
B = W1 · ... · WL is comprised of L weight-matrices in a deep model). This difference in
L2-regularization leads to a huge improvement in prediction accuracy in our experiments, cf. rows (1) and (2) in Table 1. 2. Instead of using a constant regularization parameter λ across all features (like λ·||U·V(cid:62)||F ), dropout results in a feature-speciﬁc regularization parameter (i.e., Λ in Eq. 4): note that it is proportional to (X(cid:62)X)i,i for input-feature i, which is the (uncentered) second moment of the feature’s distribution. If all features were standardized (zero mean and unit variance), then this regularization became a constant Λi,i = p/q across all features i = 1, ..., m.
Hence, in dropout the regularization-parameter Λi,i automatically adapts to the distribution (i.e., second moment) of each feature i (see also [40, 39]). In our experiments, this makes yet another large difference, as shown in rows (2) and (3) in Table 1.
Apart from that, note that the dropout-regularization Λ is also proportional to the ratio p/(1 − p) and hence increases monotonically with the dropout-probability p, and diverges to inﬁnity as p → 1. This section is generalized to deep networks in the Supplement. 4 Emphasized Denoising can prevent the Overﬁtting towards the Identity
EDLAE overcomes the limitations of DLAE by using two different regularizers: preventing the overﬁtting towards the identity is now decoupled from the L2-norm regularization of the off-diagonal elements of B(EDLAE). The former is controlled by the weighting matrix A (see also Eq. 1), and the latter by the dropout-probability p. These facts, together with further insights outlined in the remainder of this paper, are based on the following simpliﬁcation of the training-objective of Eqs. 1 and 2 for EDLAE:
Theorem: In the general case a ≥ b, the solution ˆB(EDLAE) determined by Eqs. 1 and 2 is identical to the solution of the following quadratic minimization problem:
ˆB(EDLAE)= argmin
B(EDLAE) (cid:26) (cid:13) (cid:13) (cid:13) (cid:13)
X − X ·
B(EDLAE) − dMat(diag(B(EDLAE))) (cid:40)
+ (cid:13) (cid:13)
Λ1/2 · (cid:13) (cid:13) (cid:13)
B(EDLAE) − dMat(diag(B(EDLAE))) · 1 − (cid:18) 1 − (cid:32) b ap + bq
√ ab ap + bq (cid:19)(cid:27)(cid:13) 2 (cid:13) (cid:13) (cid:13)
F (cid:33)(cid:41)(cid:13) 2 (cid:13) (cid:13) (cid:13) (cid:13)
F (6) where Λ is given by Eq. 4, p is the dropout-probability, q = 1 − p, and weights a, b in A in Eq. 1.
Proof: The idea is to split the squared error in Eq. 1 into a sum over the different features, and for each feature into a sum over the different weights a and b in matrix A. The ﬁve-page derivation is provided in the Supplement. (cid:3)
The theorem shows that the diagonal of the matrix B(EDLAE) is partially subtracted during training, ab/(ap + bq) remaining in the squared-error and in the L2-norm with the fractions b/(ap + bq) and regularization, respectively. If a > b, we have that ab/(ap + bq) > b/(ap + bq), i.e., more of the diagonal of B(EDLAE) remains in the L2-regularization term than in the squared-error. Based on the choices for a and b, one can remove the diagonal to any degree. In one extreme (a = b), where
√
√ 4
nothing is subtracted from the diagonal, Eq. 6 immediately simpliﬁes to Eq. 3 for DLAE, as expected.
The other extreme is b = 0 (while a, p > 0), which was named full emphasis in [37]: Eq. 6 above shows that the diagonal is completely subtracted from B(EDLAE) during training in this case.
When the diagonal is removed to a larger degree during the training, it reduces the degree to which a feature i can be reconstructed from its own value in the input-layer. Hence, this increasingly forces the model to reconstruct each feature i based on all other features j (cid:54)= i during training, and hence increasingly reduces the overﬁtting towards the diagonal. In the extreme case where the diagonal is completely eliminated during training (b = 0), there is hence no overﬁtting to the diagonal. For this reason, we focus on this case in the next section.
Another remarkable insight from the Theorem is that the diagonal plays different roles during training vs. testing/prediction: the diagonal is (partially) removed when the model is ﬁtted to the data during training, while the learned model ˆB(EDLAE) (i.e., with the diagonal present) is later used for making predictions (on new data points).3 4.1 Full Emphasis
When training with full emphasis (b = 0), there is no overﬁtting towards the identity, as just shown.
In this section, we derive further insights for this case, for the full-rank model in Section 4.1.1, and for the low-rank model in Section 4.1.2. full full 4.1.1 Full-rank EDLAE
For full-rank2 EDLAE, all the entries in matrix B(EDLAE) are independent of each other. Conse-quently, the diagonal values in B(EDLAE) are undetermined in Eq. 6 if we set b = 0. However, if we consider the limit b → 0 for b > 0 and for ﬁxed a > 0, p > 0, the fraction of the diagonal remaining in the squared error in Eq. 6 is proportional to b, while it is proportional to b in the L2-norm regularization: on the diagonal, the regularization hence dominates over the squared error in the limit b → 0 for b > 0–hence, we obtain for the optimal diagonal: diag( ˆB(EDLAE)
) → 0. Continuing with diag(B(EDLAE) full with full emphasis:
) = 0, Eq. 6 now simpliﬁes for full-rank B(EDLAE) (cid:13) (cid:13) (cid:13)Λ1/2B(EDLAE) (cid:13)X − XB(EDLAE) (cid:13) (cid:13)
ˆB(EDLAE) full (cid:13) 2 (cid:13) (cid:13)
√ full full full full
+ (cid:13) 2 (cid:13) (cid:13)
F
F
= argmin
B(EDLAE) full
This optimization problem with the equality constraint diag(B(EDLAE)) = 0 can be easily solved with the method of Lagrangian multipliers, which yields the closed-form solution s.t. diag(B(EDLAE) full
) = 0 (7)
ˆB(EDLAE) full
= where
I − C · dMat(1 (cid:11) diag(C))
C = (cid:0)X(cid:62)X + Λ(cid:1)−1
, (8) (9) where I is the identity matrix, and (cid:11) denotes the elementwise division by the diagonal of the matrix
C. In C · dMat(1 (cid:11) diag(C)), each column i in C is divided by its corresponding diagonal element
Ci,i. Note that the multiplication with dMat(1 (cid:11) diag(C)) not only enforces the zero diagonal, but also affects the learned off-diagonal entries of ˆB(EDLAE)
, so that feature i is best predicted by the other features j (cid:54)= i. full
Comparison of DLAE and EDLAE for full-rank models: Even though DLAE merely applies
L2-norm regularization, while EDLAE with b = 0 completely prevents the overﬁtting towards the identity, the closed-form solutions of the full-rank DLAE (see Eq. 5) and the full-rank EDLAE (see Eq. 8), look surprisingly similar: the only difference is in the diagonal matrix that multiplies matrix C. In DLAE, the diagonal of Λ is p q diag(X(cid:62)X), while in EDLAE the corresponding diagonal is 1 (cid:11) diag(C) = 1 (cid:11) diag((X(cid:62)X + p q dMat(diag(X(cid:62)X)))−1), which exactly enforces a zero diagonal. As the latter is an elementwise inverse of the matrix inverse, the diagonals of both models become equal in the futile limit p → 1. 3Note that the diagonal of a low-rank ˆB(EDLAE) does generally not vanish due to its coupling with the off-diagonal elements, see Section 4.1.2. 5
4.1.2 Low-rank EDLAE
Even though a low-rank model obviously is unable to learn the identity exactly, it may still overﬁt towards it, especially in the case when the model-rank is large, for instance, about rank k ≥ 100 in Figure 1 (left), where the prediction accuracy of the (unconstrained) low-rank model starts to be below par, even when trained with denoising. low
In this section, we derive the underlying mechanism induced by low-rank EDLAE with full emphasis (b = 0). We consider the factorization B(EDLAE)
= UV(cid:62) with rank-k matrices U, V ∈ Rm×k. In the low-rank model, the diagonal diag(UV(cid:62)) cannot be assumed to be zero in general, unlike in the full-rank model above: even though the diagonal is not explicitly determined in Eq. 6 for b = 0 (as it is completely eliminated), it is still indirectly determined in Eq. 6 due to the learned off-diagonal elements in B(EDLAE)
= UV(cid:62), which induces a coupling of the low various entries in B(EDLAE) (cid:107)X − X · (cid:8)UV(cid:62) − dMat (cid:0)diag(UV(cid:62))(cid:1)(cid:9)(cid:107)2
F (10)
This optimization problem for U, V can be solved efﬁciently with the Alternating Directions Method of Multipliers (ADMM) [13, 12, 8], see Supplement for details. low
. Eq. 6 with b = 0 becomes for B(EDLAE)
F + (cid:107)Λ1/2 · (cid:8)UV(cid:62) − dMat (cid:0)diag(UV(cid:62))(cid:1)(cid:9)(cid:107)2 due to the factorization B(EDLAE)
= UV(cid:62): low low
Let us now consider the interesting case where the rank k of the low-rank model is ‘sufﬁciently’ large, in the sense that it can accurately approximate the full-rank solution. This is illustrated in Figure 1 (left), where the accuracy does not drop signiﬁcantly for matrix-ranks as low as about k ≈ 1, 000, which is considerably smaller than the full rank of 17,769 in this experiment. In this case, one can hence expect that the diagonal of the low-rank model is approximately equal to the diagonal of the full-rank model, which is zero (see Eq. 7). For ‘sufﬁciently’ large matrix-rank k, the optimization problem in 10 may hence be approximated by
ˆU, ˆV = argmin
U,V
||X − XUV(cid:62)||2
F + ||Λ1/2UV(cid:62)||2
F s.t. diag(UV(cid:62)) = 0 (11)
It can be solved with Alternating Least Squares, using closed-form updates for the optimal U given
V, and for the optimal V given U, where the optimum can be determined analytically using the method of Lagrangian multipliers, see Supplement for details.
Corollary: (Near-)Orthogonality Constraint: Eq. 11 reveals that training with full emphasis causes the latent embedding Ui,· in the encoder to be (approximately) orthogonal to the latent embedding Vi,· in the decoder for each feature i = 1, ..., m, when using a model of ‘sufﬁcienly’ large rank k.
Interestingly, this (near-)orthogonality constraint is in stark contrast to the intuition that ‘similar’ features should have ‘similar’ latent embeddings. This can be seen as follows: if two features i and j are similar, either one should be predictable from the other one. This means that the dot-product
ˆUi,· ˆV(cid:62) j,· should be large. The (near-)orthogonality constraint requires, however, that ˆUj,· ˆV(cid:62) j,· = 0 holds approximately. Hence, the latent embeddings ˆUi,· and ˆUj,· cannot be similar for similar features i and j. The analogous argument holds for the embeddings ˆVi,· and ˆVj,· being dissimilar.
In summary, even though the (near-)orthogonality constraint requires (approximate) orthogonality of the two embeddings ˆUi,· and ˆVi,· regarding (the same) feature i in two different matrices ˆU and
ˆV, this in turn causes the embeddings of (different) features i and j in the same matrix ˆU to be less similar (and analogously for the matrix ˆV). This theoretical insight is also corroborated by our experiments, as illustrated in Figure 1: it shows that the cosine-similarities among ‘similar’ features are considerably smaller when learned with the (near-)orthogonality constraint (like in EDLAE, center graph) than without it (like in DLAE, right graph). This holds for the embeddings in the encoder U (in blue) and in the decoder V (in red) in Figure 1. In fact, the embeddings of ‘similar’ items are close-to-orthogonal in the encoder in the blue histogram in the center graph in Figure 1.
See Section 6 for more details (like the deﬁnition of ‘similar’). 5