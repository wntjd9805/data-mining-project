Abstract
Recent works in geometric deep learning have introduced neural networks that allow performing inference tasks on three-dimensional geometric data by deﬁning convolution –and sometimes pooling– operations on triangle meshes. These meth-ods, however, either consider the input mesh as a graph, and do not exploit speciﬁc geometric properties of meshes for feature aggregation and downsampling, or are specialized for meshes, but rely on a rigid deﬁnition of convolution that does not properly capture the local topology of the mesh. We propose a method that com-bines the advantages of both types of approaches, while addressing their limitations: we extend a primal-dual framework drawn from the graph-neural-network literature to triangle meshes, and deﬁne convolutions on two types of graphs constructed from an input mesh. Our method takes features for both edges and faces of a 3D mesh as input, and dynamically aggregates them using an attention mechanism. At the same time, we introduce a pooling operation with a precise geometric interpretation, that allows handling variations in the mesh connectivity by clustering mesh faces in a task-driven fashion. We provide theoretical insights of our approach using tools from the mesh-simpliﬁcation literature. In addition, we validate experimentally our method in the tasks of shape classiﬁcation and shape segmentation, where we obtain comparable or superior performance to the state of the art. 1

Introduction
The development of deep-learning tools that operate on three-dimensional triangular meshes has recently received an increasing attention by the computer graphics, vision, and machine learning communities, due to the availability of large 3D datasets with semantic annotations [1, 2] and to the expressiveness and efﬁciency of meshes in representing non-uniform, irregular surfaces.
Compared to alternative representations often used for 3D geometry, such as voxels and point clouds, that scale poorly to high object resolutions [3], meshes allow representing structure more adaptively and compactly [4]; at the same time, they naturally provide connectivity information, as opposed to point clouds, and lend themselves to simple, commonly used rendering and processing algorithms [5, p. 14]. However, meshes have both a geometric and a topological component [6, p. 10], represented respectively by the vertices and by the connectivity of edges and faces [5, p. 19]; while the geometrical variability of the underlying surface encodes essential semantic information, the randomness in the discretization of the surface (which can include, e.g., variations in tessellation, isotropy, regularity, level-of-detail [5]) is to a certain extent not informative and independent of the
∗Work performed while at MIT. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
shape identity [7]. This is particularly relevant in the context of shape understanding and semantic-based object representation, where mesh processing requires abstracting from the low-level mesh elements to a higher-level structure-aware representation of the shape [8–10].
Handling 3D geometric data represented as meshes and performing deep learning tasks on them relates to the ﬁeld of geometric deep learning [11], that attempts to generalize tools from convolutional neural networks (CNNs) to non-Euclidean domains, including graphs and manifolds. Existing methods deﬁne speciﬁc convolution and (optionally) pooling/unpooling operations to operate on meshes [12].
We identify two main types of approaches: on the one hand, methods that process the input mesh as a graph [13–16], thus not exploiting important geometrical properties of meshes [17]; on the other hand, ad-hoc methods, which design convolution and pooling operations using geometric properties of triangular meshes. However, both types of approaches usually implement a form of non-dynamic feature aggregation. Indeed, they learn and apply shared isotropic kernels to all the vertices/edges of the mesh and use a weighting scheme that does not depend on the region of the mesh on which the operation is applied. This is a limiting factor, considering that meshes can exhibit large variations in the density and shape of their faces. Furthermore, graph-based methods often do not perform pooling, or they implement it through generic graph clustering algorithms [18], that do not exploit the mesh geometric characteristics. In contrast, the ad-hoc methods that deﬁne mesh-speciﬁc pooling operations [12] make strong assumptions on the mesh local topology, limiting the number of mesh elements which can be pooled.
Contributions. To address the limitations of the approaches above, we propose a method that combines a graph-neural-network framework with mesh-speciﬁc insights from ad-hoc approaches.
Our method, named PD-MeshNet, is the ﬁrst to perform dynamic, attention-based feature aggregation while also implementing a task-driven, mesh-speciﬁc pooling operation. Motivated by the inherent duality between topology and geometry in meshes, we build on the primal-dual graph convolutional framework of [19], and extend it to triangular meshes: starting from an input mesh, we construct two types of graphs, that allow assigning features to both edges and faces of a 3D mesh. The method enables the implementation of dynamic feature aggregation –where the relevance of each neighbor in the convolution operation is learned using an attention mechanism [20]– and at the same time allows to learn richer and more complex features [19]. On the other hand, we show that ad-hoc methods, such as [12], can be interpreted as an instantiation of our method where only a single graph is considered. Similarly to [12], we also introduce a task-driven pooling operation speciﬁc for meshes.
A unique feature of our pooling operation, however, is its geometrical interpretation: by collapsing graph edges based on the associated attention coefﬁcients, PD-MeshNet learns to form clusters of faces in the mesh, allowing both to downsample the number of features in the network and to abstract the computation from the low-level, noise-prone mesh elements, to larger areas in the shape. In addition, our pooling operation does not require assumptions on the topological type of the meshes nor has the topological limitations of [12]. We evaluate our method in the tasks of mesh classiﬁcation and segmentation, where we show results comparable or superior to state-of-the-art approaches. Our code is publicly available at https://github.com/MIT-SPARK/PD-MeshNet.
Notation. In the following, we assume the reader to be familiar with basic notions from graph theory (e.g., graph embedding, k-regularity [21, 22]) and meshes (e.g., 1-ring neighborhood, boundary edge/face [5, 6]). We denote the vertices of a generic triangle mesh M with lowercase letters (e.g., a), and its faces with uppercase letters (e.g., A). We refer to the set of all the faces of the mesh as F(M), and we denote the set of the faces adjacent to a generic face A ∈ F(M) as NA. For simplicity and comparability to [12], we assume the mesh M to be (edge-)manifold2. However, as we show in the
Supplementary Material, our framework allows to relax this assumption and process meshes of any topological type. 2