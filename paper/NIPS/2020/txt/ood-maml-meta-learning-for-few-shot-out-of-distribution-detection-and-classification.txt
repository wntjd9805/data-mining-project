Abstract
We propose a few-shot learning method for detecting out-of-distribution (OOD) samples from classes that are unseen during training while classifying samples from seen classes using only a few labeled examples. For detecting unseen classes while generalizing to new samples of known classes, we synthesize fake samples, i.e., OOD samples, but that resemble in-distribution samples, and use them along with real samples. Our approach is based on an extension of model-agnostic meta learning (MAML) and is denoted as OOD-MAML, which not only learns a model initialization but also the initial fake samples across tasks. The learned initial fake samples can be used to quickly adapt to new tasks to form task-speciﬁc fake samples with only one or a few gradient update steps using MAML. For testing,
OOD-MAML converts a K-shot N -way classiﬁcation task into N sub-tasks of
K-shot OOD detection with respect to each class. The joint analysis of N sub-tasks facilitates simultaneous classiﬁcation and OOD detection and, furthermore, offers an advantage, in that it does not require re-training when the number of classes for a test task differs from that for training tasks; it is sufﬁcient to simply assume as many sub-tasks as the number of classes for the test task. We also demonstrate the effective performance of OOD-MAML over benchmark datasets. 1

Introduction
Deep neural networks (DNNs) have demonstrated excellent performances in many machine learning tasks such as speech recognition [20], object detection [8], and image classiﬁcation [10]. However, they usually require large amounts of training data to perform well. When the amount of training data is small, DNNs often provide low levels of performance. This is a critical issue, because a large number of problems in the real world are confronted with the lack of training data. For example, the drug discovery problem involves the prediction of whether a molecule increases the pharmaceutical activity [1]. However, often only a small amount of data relating to molecules are available, which makes it difﬁcult to use DNNs for this task. The learning problem under the circumstance wherein only a few labeled examples are available is referred to as few-shot learning, and it has attracted signiﬁcant interest recently [24, 3, 21, 7]. “K-shot N -way" classiﬁcation is one of the major tasks that few-shot learning deals with, wherein a small number of samples K (such as 1,5, or 10) per each of N classes are available for training to classify a new sample into one of the N classes. Several methods, e.g., siamese network [13] and prototypical network (PN) [22], were proposed for K-shot
N -way problems.
In general, in few-shot classiﬁcation algorithms, it is assumed that the training and test data are drawn from the same distribution, and the algorithm requires a test sample to be classiﬁed into one of the known classes encountered during training. However, in many real-world applications, it is unreasonable to assume the same distribution for the training and test data [5, 23, 4]. If the test data are drawn from a different distribution, it is more desirable to have classiﬁcation algorithms that 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
not only classify the test samples drawn from the same distribution of training data, but also detect out-of-distribution (OOD) samples drawn from an unknown distribution. Humans can easily do this even in a few-shot scenario. For example, let us suppose that a child learns the alphabets ‘A’ and ‘B’ from a few examples. This child would then not only discriminate between ‘A’ and ‘B’, but also can say “I did not learn it" on seeing ‘C’ and ‘D’. In supervised learning settings, methods have been proposed for detecting OOD samples, and the majority of these methods are based on uncertainty quantiﬁcation (UQ) for predictions [15, 18]. However, the algorithms in previous studies are not designed for few-shot settings.
In this paper, we propose a method for detecting OOD samples from unseen classes during training while classifying samples from known classes under few-shot settings. There are two major challenges in the problem of few-shot OOD detection and classiﬁcation: (1) a lack of training data required for learning the distribution of the data from known classes and (2) the absence of OOD samples during training.
To address the ﬁrst challenge, we use meta-learning, which is a general paradigm for few-shot learning. The objective of meta-learning is to learn a learning strategy to learn quickly on new tasks.
In general, meta-learning algorithms involve two core processes: learning the transfer of knowledge across tasks and rapid adaptation to a new task. In this study, we use model-agnostic meta-learning (MAML) [7], which is a popular gradient-based meta-learning algorithm. The objective of MAML is to ﬁnd good initial parameters of a model (e.g., DNN), such that updating the initial parameters via one or a few gradient steps can result in a model that provides a good performance for a new task.
More details about MAML are presented in Section2.2.
Although meta-learning is a good approach to few-shot classiﬁcation, it does not address the second challenge. In the absence of OOD examples from unknown classes, meta-learning algorithms, including MAML, would generate trivial classiﬁers that predict all the examples as in-distribution examples. To address this issue, we propose the synthesis of OOD examples from unknown classes, which are then used along with in-distribution examples to learn a classiﬁer. We were inspired by
MetaGAN [26], which uses adversarial samples generated from GAN to help few-shot classiﬁers learn a sharper decision boundary. Similarly, we synthesize adversarial samples to represent an OOD class during training. However, instead of using GAN, we generate adversarial samples via gradient updating for special meta-parameters, called fake-sample parameters. This generation strategy allows us to avoid the difﬁculty of training the GAN. The proposed method is called OOD-MAML.
To facilitate the OOD detection, OOD-MAML is trained to adapt quickly for OOD tasks with respect to a single class. In meta-testing phase, given K-shot N -way samples, we construct N sub-tasks of
K-shot OOD detection with respect to each class. Then N classiﬁers are adapted to each sub-task with meta-knowledge. By merging the results of N OOD detection tasks, we can implement OOD detection and K-shot N -way classiﬁcation simultaneously. This approach has an advantage, in that it does not require re-training when the number of classes for the test tasks are changed. The code for
OOD-MAML is available at https://github.com/twj-KAIST/OOD-MAML. 2