Abstract
Deep probabilistic generative models enable modeling the likelihoods of very high dimensional data. An important application of generative modeling should be the ability to detect out-of-distribution (OOD) samples by setting a threshold on the likelihood. However, some recent studies show that probabilistic generative models can, in some cases, assign higher likelihoods on certain types of OOD samples, making the OOD detection rules based on likelihood threshold problematic. To address this issue, several OOD detection methods have been proposed for deep generative models. In this paper, we make the observation that many of these methods fail when applied to generative models based on Variational Auto-encoders (VAE). As an alternative, we propose Likelihood Regret, an efﬁcient OOD score for VAEs. We benchmark our proposed method over existing approaches, and empirical results suggest that our method obtains the best overall OOD detection performances when applied to VAEs. 1

Introduction
In order to make reliable and safe decisions, deep learning models that are deployed for real life applications need to be able to identify whether the input data is anomalous or signiﬁcantly different from the training data. Such data are called out-of-distribution (OOD) data. However, it is known that neural network classiﬁers can over-conﬁdently classify OOD data into one of the training categories
[37]. This observation poses a great challenge to the reliability and safety of AI [2], making OOD detection a problem of primary importance. Several approaches have been proposed to detect OOD data based on deep classiﬁers [17, 24, 13, 18]. Unfortunately, these methods cannot be applied to OOD detection for models trained without supervision, such as many generative models. An appealing OOD detection approach that may work for probabilistic generative models is to use their likelihood estimates. Such models can evaluate the likelihood of input data, and if a generative model
ﬁts the training data distribution well enough, it should assign high likelihood to samples from the training distribution and low likelihood to OOD samples.
Recent advances in deep probabilistic generative models [20, 46, 42, 21] make generative modeling of very high dimensional and complicated data such as natural images, sequences [38] and graphs [22]
∗equal contribution 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
possible. These models can evaluate the likelihood of input data easily and generate realistic samples, indicating that they succesfully approximate the distribution of training data. Therefore, it would appear promising to use deep generative models to detect OOD data [27]. However, some recent studies [34, 7] reveal a counter intuitive phenomenon that challenges the validity of unsupervised
OOD detection using generative models. They observe that likelihoods obtained from current state-of-the-art deep probabilistic generative models fail to distinguish between training data and some obvious OOD input types that are easily recognizable by humans. For example, [34] shows that generative models trained on CIFAR-10 output higher likelihood on SVHN than on CIFAR-10 itself, despite the fact that images in CIFAR-10 (contains dogs, trucks, horses, etc.) and SVHN (contains house numbers) have very different semantic content.
At this point, no effective method has been discovered to ensure these generative models make the correct likelihood assignment on OOD data. Alternatively, some new scores based on likelihood are proposed to alleviate this issue [40, 35, 43]. The OOD detection is performed by setting thresholds on the new scores rather than on likelihood. Some of these methods obtain impressive OOD detection performance on invertible ﬂow-based models [21] and auto-regressive models [42]. Interestingly, we observe that these scores can be much less effective for Variational Auto-encoders (VAE), an important type of probabilistic generative models. The failure of current OOD scores on VAE suggests that a new score is necessary. To this end, in this paper we propose a simple yet effective metric called Likelihood Regret (LR) to detect OOD samples with VAEs. The Likelihood Regret of a single input can be interpreted as the log ratio between its likelihood obtained by the posterior distribution optimized individually for that input and the likelihood approximated by the VAE. We conduct comprehensive experiments to evaluate our proposed score on a variety of image OOD detection tasks, and we show that it obtains the best overall performance. 2