Abstract
We consider the classical setting of optimizing a nonsmooth Lipschitz continuous convex function over a convex constraint set, when having access to a (stochastic)
ﬁrst-order oracle (FO) for the function and a projection oracle (PO) for the con-straint set. It is well known that to achieve ε-suboptimality in high-dimensions,
Θ(ε−2) FO calls are necessary [64]. This is achieved by the projected subgradient method (PGD) [11]. However, PGD also entails O(ε−2) PO calls, which may be computationally costlier than FO calls (e.g. nuclear norm constraints). Improving this PO calls complexity of PGD is largely unexplored, despite the fundamental nature of this problem and extensive literature. We present ﬁrst such improvement.
This only requires a mild assumption that the objective function, when extended to a slightly larger neighborhood of the constraint set, still remains Lipschitz and accessible via FO. In particular, we introduce MOPES method, which carefully combines Moreau-Yosida smoothing and accelerated ﬁrst-order schemes. This is guaranteed to ﬁnd a feasible ε-suboptimal solution using only O(ε−1) PO calls and optimal O(ε−2) FO calls. Further, instead of a PO if we only have a linear mini-mization oracle (LMO, à la Frank-Wolfe) to access the constraint set, an extension of our method, MOLES, ﬁnds a feasible ε-suboptimal solution using O(ε−2) LMO calls and FO calls—both match known lower bounds [54], resolving a question left open since [84]. Our experiments conﬁrm that these methods achieve signiﬁcant speedups over the state-of-the-art, for a problem with costly PO and LMO calls. 1

Introduction
In this paper, we consider the nonsmooth convex optimization (NSCO) problem with the First-order
Oracle (FO) and the Projection Oracle (PO) deﬁned as:
NSCO : min x f (x), s.t. x ∈ X , FO(x) ∈ ∂f (x), and PO(x) = PX (x) = argmin y∈X (cid:107)y − x(cid:107)2 2, (1) where f : Rd → R is a convex Lipschitz-continuous function, and X ⊆ Rd is a convex constraint.
When queried at a point x, FO returns a subgradient of f at x and PO returns the projection of x onto
X . NSCO is a fundamental problem with a long history and several important applications including support vector machines (SVM) [12], robust learning [44], and utility maximization in ﬁnance [82].
Finding an ε-suboptimal solution for this problem requires Ω(ε−2) FO calls in the worst case, when the dimension d is large [64]. This lower bound is tightly matched by the projected subgradient method (PGD). Unfortunately, PGD also uses one PO call after every FO call, resulting in a PO calls 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
Randomized Smoothing dimension dependent
O((G2 + σ2)/ε2) [27]
O(d1/4G/ε) [27]
√
SFO
PO
SFO O(
LMO d (G2 + σ2)2/ε4) [54] d G2/ε2) [54]∗
O(
√
State-of-the-art dimension-free
Our results (Theorems 1 and 2)
O((G2 + σ2)/ε2) [65] O((G2 + σ2)/ε2) Ω((G2 + σ2)/ε2) [64]
O(G/ε)
O(G2/ε2)(cid:63) [65]
Lower bound
Open problem
O((G2 + σ2)/ε2)†
O((G2 + σ2)2/ε4)†
O((G2 + σ2)/ε2) Ω((G2 + σ2)/ε2) [64]
O(G2/ε2)
Ω(G2/ε2) [54]
Table 1: Comparison of SFO (3), PO (1) & LMO (2) calls complexities of our methods and state-of-the-art algorithms, and corresponding lower-bounds for ﬁnding an approximate minimizer of a d-dimensional NSCO problem (1). We assume that f is convex and G-Lipschitz continuous, and is accessed through a stochastic subgradient oracle with a variance of σ2. (cid:63)requires using a minibatch of appropriate size, †approximates projections of PGD with FW method (FW-PGD, see Appendix B.2). complexity (PO-CC)—the number of times PO needs to be invoked—of Θ(ε−2). This can be a major bottleneck in solving several practical problems like collaborative ﬁltering [79], where the cost of a
PO is often higher than the cost of an FO call. This begs the natural question, which surprisingly is largely unexplored in the general nonsmooth optimization setting: Can we design an algorithm whose PO calls complexity is signiﬁcantly better than the optimal FO calls complexity O(ε−2)?
In this work, we answer the above question in the afﬁrmative. Our ﬁrst key contribution is MOreau
Projection Efﬁcient Subgradient method (MOPES), that obtains an ε-suboptimal solution using only
O(ε−1) PO calls, while still ensuring that the FO calls complexity (FO-CC)—the number of times
FO needs to be invoked—is optimal, i.e., O(ε−2). This requires a mild assumption that the function f extends to a slightly larger neighborhood of the constraint set X . Concretely, we assume that f is
Lipschitz continuous in this neighborhood and FO can be queried at points in this neighborhood. To the best of our knowledge, our result is the ﬁrst improvement over the O(ε−2) PO calls of PGD for minimizing a general nonsmooth Lipschitz continuous convex function.
We achieve this by carefully combining Moreau-Yosida regularization with accelerated ﬁrst-order methods [62, 81]. As accelerated methods cannot be directly applied to a nonsmooth f , we can instead apply them to minimize its Moreau envelope, which is smooth (as long as f is Lipschitz continuous). Although this idea has been explored, for example, in [25, 9], PO-CC has remained
O(ε−2), unless a much stronger and unrealistic oracle is assumed [9] with a direct access to the gradient of Moreau envelope. The key idea in breaking this barrier is to separate out the dependence on FO calls of f from PO calls to X by: (a) using Moreau-Yosida regularization to split the original problem into a composite problem, where one component consists of an unconstrained optimization of the function f and the other consists of a simple constrained optimization over the set X ; and (b) applying the gradient sliding algorithm [55] on this joint problem to ensure the above mentioned bounds for both FO and PO calls. We note that our results are limited to the Euclidean norm, since our results crucially depend on smoothness of the Moreau envelope and its regularizer, which is not known for Moreau envelopes based on general Bregman divergences [7].
In some high-dimensional problems, even a single call to the PO can be computationally prohibitive.
A popular alternative, pioneered by Frank and Wolfe [28], is to replace PO by a more efﬁcient Linear
Minimization Oracle (LMO), which returns a minimizer of any linear functional (cid:104)g, ·(cid:105) over the set X .
LMO (g) ∈ argmin (cid:104)g, s(cid:105) s∈X (2)
Linear minimization is much faster than projection in several practical ML applications such as a nuclear norm ball constrained problems [15], video-narration alignment [1], structured SVM [51], and multiple sequence alignment and motif discovery [89]. LMO based methods have an important additional beneﬁt of producing solutions that preserve desired structures such as sparsity and low rank.
For smooth f , there is a long history of conditional gradient (Frank-Wolfe) methods that use O(ε−1)
LMO calls and O(ε−1) FO calls to achieve ε-suboptimality, which achieve optimal LMO-CC [45].
For nonsmooth functions, starting from the work of [84], several approaches have been proposed, dε−2) which is some under more assumptions. The best known upper bound on LMO calls is O( achieved at the expense of signiﬁcantly larger O(ε−4) FO calls. Details of these are in Section 1.1.
√
Our second key contribution is the algorithm MOLES, which obtains an ε-suboptimal solution using the optimal O(ε−2) LMO and FO calls, without any additional dimension dependence. We 2
achieve this result by extending MOPES to work with approximate projections and using the classical
Frank-Wolfe (FW) method [28] to implement these approximate projections using LMO calls.
Finally, both of our methods extend naturally to the Stochastic First-order Oracle (SFO) setting, where we have access only to stochastic versions of the function’s subgradients. Stochastic versions of MOPES and MOLES still achieve the the same PO/LMO calls complexities as deterministic counterparts, while the SFO calls complexity (SFO-CC) is O (cid:0)(1 + σ2)(cid:15)−2(cid:1), where σ2 is the variance in SFO. This again matches information theoretic lower bounds [64].
Contributions: We summarize our contributions below and in Table 1. We assume that the function f extends to a slightly larger neighborhood of the constraint set X i.e., f continues to be Lipschitz continuous and (S)FO can be queried in this neighborhood.
• We introduce MOPES and show that it is guaranteed to ﬁnd an ε-suboptimal solution for any constrained nonsmooth convex optimization problem using O(ε−1) PO calls and optimal O(ε−2)
SFO calls. To the best of our knowledge, for the general problem, this achieves the ﬁrst improvement over O(ε−2) PO-CC and SFO-CC of stochastic projected subgradient method (PGD).
• For LMO setting, we extend our method to design MOLES, that achieves the optimal SFO-CC and
√
LMO-CC of O(ε−2), and improves over the best known LMO-CC by d.
• We also empirically evaluate MOPES and MOLES on the popular nuclear norm constrained Matrix
SVM problem [85], where they achieve signiﬁcant speedups over their corresponding baselines.
• Our main technical novelty is the use Moreau-Yosida regularization to separate out the constraint (PO/LMO) and function (SFO) accesses into two parts of a composite optimization problem. This enables a better control of how many times each of these oracles are accessed. This idea might be of independent interest, whenever a trade-off between PO-CC/LMO-CC and SFO-CC is desirable. 1.1