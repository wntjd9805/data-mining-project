Abstract
Backpropagation (BP) has been the most successful algorithm used to train artiﬁcial neural networks. However, there are several gaps between BP and learning in biologically plausible neuronal networks of the brain (learning in the brain, or simply BL, for short), in particular, (1) it has been unclear to date, if BP can be implemented exactly via BL, (2) there is a lack of local plasticity in BP, i.e., weight updates require information that is not locally available, while BL utilizes only locally available information, and (3) there is a lack of autonomy in BP, i.e., some external control over the neural network is required (e.g., switching between prediction and learning stages requires changes to dynamics and synaptic plasticity rules), while BL works fully autonomously. Bridging such gaps, i.e., understanding how BP can be approximated by BL, has been of major interest in both neuroscience and machine learning. Despite tremendous efforts, however, no previous model has bridged the gaps at a degree of demonstrating an equivalence to BP, instead, only approximations to BP have been shown. Here, we present for the ﬁrst time a framework within BL that bridges the above crucial gaps. We propose a BL model that (1) produces exactly the same updates of the neural weights as BP, while (2) employing local plasticity, i.e., all neurons perform only local computations, done simultaneously. We then modify it to an alternative BL model that (3) also works fully autonomously. Overall, our work provides important evidence for the debate on the long-disputed question whether the brain can perform BP. 1

Introduction
Backpropagation (BP) [1–3] as the main principle underlying learning in deep artiﬁcial neural net-works (ANNs) [4] has long been criticized for its biological implausibility (i.e., BP’s computational procedures and principles are unrealistic to be implemented in the brain) [5–10]. Despite such criticisms, growing evidence demonstrates that ANNs trained with BP outperform alternative frame-works [11], as well as closely reproduce activity patterns observed in the cortex [12–20]. As indicated in [10, 21], since we apparently cannot ﬁnd a better alternative than BP, the brain is likely to employ at least the core principles underlying BP, but perhaps implements them in a different way. Hence, bridging the gaps between BP and learning in biological neuronal networks of the brain (learning in the brain, for short, or simply BL) has been a major open question for both neuroscience and machine
∗Corresponding author. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
learning [10, 21–29]. Such gaps are reviewed in [30–33], the most crucial and most intensively studied gaps are (1) that it has been unclear to date, if BP can be implemented exactly via BL, (2) BP’s lack of local plasticity, i.e., weight updates in BP require information that is not locally available, while in BL weights are typically modiﬁed only on the basis of activities of two neurons (connected via synapses), and (3) BP’s lack of autonomy, i.e., BP requires some external control over the network (e.g., to switch between prediction and learning), while BL works fully autonomously.
Tremendous research efforts aimed at ﬁlling these gaps, trying to approximate BP in BL models.
However, earlier BL models were not scaling to larger and more complicated problems [8, 34–42].
More recent works show the capacity of scaling up BL to the level of BP [43–57]. However, to date, none of the earlier or recent models has bridged the gaps at a degree of demonstrating an equivalence to BP, though some of them [37, 48, 53, 58–60] demonstrate that they approximate BP, or are equivalent to BP under unrealistic restrictions, e.g., the feedback is sufﬁciently weak [61, 48, 62].
The unability to fully close the gaps between BP and BL is keeping the community’s concerns open, questioning the link between the power of artiﬁcial intelligence and that of biological intelligence.
Recently, an approach based on predictive coding networks (PCNs), a widely used framework for describing information processing in the brain [31], has partially bridged these crucial gaps.
This model employed a supervised learning algorithm for PCNs to which we refer as inference learning (IL) [48]. IL is capable of approximating BP with attractive properties: local plasticity and autonomous switching between prediction and learning. However, IL has not yet fully bridged the gaps: (1) IL is only an approximation of BP, rather than an equivalent algorithm, and (2) it is not fully autonomous, as it still requires a signal controlling when to update weights.
Therefore, in this paper, we propose the ﬁrst BL model that is equivalent to BP while satisfying local plasticity and full autonomy. The main contributions of this paper are brieﬂy summarized as follows:
•
•
•
To develop a BL approach that is equivalent to BP, we propose three easy-to-satisfy conditions for IL, under which IL produces exactly the same weight updates as BP. We call the proposed approach zero-divergent IL (Z-IL). In addition to being equivalent to BP, Z-IL also satisﬁes the properties of local plasticity and partial autonomy between prediction and learning.
However, Z-IL is still not fully autonomous, as weight updates in Z-IL still require a triggering signal. We thus further propose a fully autonomous Z-IL (Fa-Z-IL) model, which requires no control signal anymore. Fa-Z-IL is the ﬁrst BL model that not only produces exactly the same weight updates as BP, but also performs all computations locally, simultaneously, and fully autonomously.
We prove the general result that Z-IL is equivalent to BP while satisfying local plasticity, and that
Fa-Z-IL is additionally fully autonomous. Consequently, this work may bridge the crucial gaps between BP and BL, thus, could provide previously missing evidence to the debate on whether BP could describe learning in the brain, and links the power of biological and machine intelligence.
The rest of this paper is organized as follows. Section 2 recalls BP in ANNs and IL in PCNs. In
Section 3, we develop Z-IL in PCNs and show its equivalence to BP and its local plasticity. Section 4 focuses on how Z-IL can be realized with full autonomy. Sections 5 and 7 provide some further experimental results and a conclusion, respectively. 2 Preliminaries
We now brieﬂy recall artiﬁcial neural networks (ANNs) and predictive coding networks (PCNs), which are trained with backpropagation (BP) and inference learning (IL), respectively. For both models, we describe two stages, namely, (1) the prediction stage, when no supervision signal is present, and the goal is to use the current parameters to make a prediction, and (2) the learning stage, when a supervision signal is present, and the goal is to update the current parameters. Following [48], we use a slightly different notation than in the original descriptions to highlight the correspondence between the variables in the two models. The notation is summarized in Table 1 and will be introduced in detail as the models are described. To make the dimension of variables explicit, we denote vectors with a bar (e.g., x = (x1, x2, . . . , xn) and 0 = (0, 0, . . . , 0)). 2
Table 1: Notation for ANNs and PCNs. m r e t r o r r
E e d o n r o e v i t c e j b
O n o i t c n u f n o i t a v i t c
A n o i t c n u f t h g i e
W e z i s r e y a
L f o s r e y a l r e b m u
N t u p n
I l a n g i s n o i s i v r e p u
S l a n g i s e t a r g n i n r a e
L s t h g i e w r o f d e t c i d e r
P e d o n
-e u l a v y t i v i t c a –
µl i,t
δl i
εl i,t i,j wl
θl i,j
E
Ft f nl lmax + 1 sin i sout i
α p e t s n o i t a r g e t n
I e c n e r e f n i r o f –
γ e d o n
-e u l a
V y t i v i t c a yl i xl i,t
ANNs
PCNs
Figure 1: ANNs and PCNs trained with BP and IL, respectively. 2.1 ANNs trained with BP
Artiﬁcial neural networks (ANNs) [3] are organized in layers, with multiple neuron-like value nodes in each layer. Following [48], to make the link to PCNs more visible, we change the direction in which layers are numbered and index the output layer by 0 and the input layer by lmax. We denote i the input to the i-th node in the l-th layer. Thus, the connections between adjacent layers are: by yl j
), j=1 wl+1 i,j f (yl+1 i = (cid:80)nl+1 yl i,j is the weight from the jth node in the (l + 1)th layer to the where f is the activation function, wl+1 ith node in the lth layer, and nl+1 is the number of nodes in layer (l + 1). Note that, in this paper, we consider only the case where there are only weights as parameters and no bias values. However, all results of this paper can be easily extended to the case with bias values as additional parameters; see supplementary material.
Prediction: Given values of the input sin = (sin corresponding sin i , and then every y0
Learning: Given a pair (sin, sout) from the training set, y0 = (y0 from sin as input and compared with sout via the following objective function E: i is computed as the prediction via Eq. (1). n0 ) is computed via Eq. (1) in the ANN is set to the nlmax ), every ylmax 1 , . . . , sin 1, . . . , y0 (1) i
Backpropagation (BP) updates the weights of the ANN by:
E = 1 2 (cid:80)n0 i=1(sout i )2. y0 i − where α is the learning rate, and δl i is the error term, given as follows:
∆wl+1 i,j =
α
∂E/∂wl+1 i,j = α if (yl+1
δl j
),
·
·
− i = ∂E/∂yl (cid:40)
δl i = 2.2 PCNs trained with IL sout i − f (cid:48)(yl y0 i i)(cid:80)nl−1 k=1 δl−1 k wl k,i if l = 0 ; if l
∈ { 1, . . . , lmax
. 1
}
− (2) (3) (4)
Predictive coding networks (PCNs) [31] are a widely used model of information processing in the brain, originally developed for unsupervised learning. It has recently been shown that when a PCN 3
is used for supervised learning, it closely approximates BP [48]. As the learning algorithm in [48] involves inferring the values of hidden nodes, we call it inference learning (IL). Thus, we denote by t the time axis during inference. As shown in Fig. 1, a PCN contains value nodes (blue nodes, with the i,t), which are each associated with corresponding prediction-error nodes (error nodes: activity of xl red nodes, with the activity of εl i,t). Differently from ANNs, which propagate the activity between i,t: value nodes directly, PCNs propagate the activity between value nodes xl i,t via the error nodes εl i,t = (cid:80)nl+1
µl j=1 θl+1 i,j f (xl+1 j,t ) and εl i,t = xl i,t −
µl i,t, (5) i,j ’s are the connection weights, paralleling wl+1 where the θl+1 the prediction of xl computes the difference between the actual and the predicted xl that the overall energy Ft in εl i,t is minimized all the time: i,t based on the value nodes in a higher layer xl+1 i,j in the described ANN, and µl i,t denotes j,t . Thus, the error node εl i,t i,t is modiﬁed so i,t. The value node xl
Ft = (cid:80)lmax−1 l=0 (cid:80)nl i=1 1 2 (εl i,t)2 . (6) i,t tends to move close to µl
In this way, xl i,t is called inference, and it is running during both prediction and learning. Inference minimizes Ft by modifying xl i,t. Such a process of minimizing Ft by modifying all xl i,t, following a uniﬁed rule for both stages:
∆xl i,t =


 0
γ
γ 0
·
· i,t + f (cid:48)(xl
εl
εl i,t) (
− (
− i,t)(cid:80)nl−1 k=1 εl−1 k,t θl k,i) if l if l = lmax
∈ { 1, . . . , lmax if l = 0 during prediction if l = 0 during learning, 1
}
− (7) i,t + ∆xl i,t+1 = xl i,t. Here, ∆xl i during learning. ∆xl i,t, and γ is the integration step for xl where xl i,t is different between prediction and learning only for l = 0, as the output value nodes x0 i,t are left unconstrained during prediction and are ﬁxed to sout in both stages. Eqs. (5) and (7) can be evaluated in a network of simple neurons, as illustrated in Fig. 1.
Prediction: Given an input sin, the value nodes xlmax i,t error nodes εl nodes xl i . Then, all the
. Thus, the value i of the corresponding ANN with the same weights.
Learning: Given a pair (sin, sout) from the training set, the value nodes of both the input and the i,t = sin output layers are set to the training pair (i.e., xlmax i,t are optimized by the inference process and decay to zero as t i,t is zero for l = lmax, as xlmax i,t in the input layer are set to sin i,t, the same values as yl i,t converge to µl is ﬁxed to sin i i,t = sout i ); thus, i and x0
→ ∞ i,t = x0
ε0 i,t = sout
µ0
µ0 i,t. i −
Optimized by the inference process, the error nodes εl i,t can no longer decay to zero; instead, they converge to values as if the errors had been backpropagated. Once the inference converges to an equilibrium (t = tc), where tc is a ﬁxed large number, a weight update is performed. The weights θl+1 i,j are updated to minimize the same objective function Ft; thus, i,t − (8)
∆θl+1 i,j =
α
−
·
∂Ft/∂θl+1 i,j = α i,tf (xl+1
εl j,t ),
· (9) where α is the learning rate. By Eqs. (7) and (9), all computations are local (local plasticity) in IL, and, as stated, the model can autonomously switch between prediction and learning (some autonomy), via running inference. However, a control signal is still needed to trigger the weights update at t = tc; thus, full autonomy is not realized yet. The learning of IL is summarized in Algorithm 1. Note that detailed derivations of Eqs. (7) and (9) are given in the supplementary material (and in [48]). 3
IL with Zero Divergence from BP and with Local Plasticity
We now ﬁrst describe the temporal training dynamics of BP in ANNs and IL in PCNs. Based on this, we then propose IL in PCNs with zero divergence from BP (and local plasticity), called Z-IL.
Temporal Training Dynamics. We ﬁrst describe the temporal training dynamics of BP in ANNs and IL in PCNs; see Fig. 2. We assume that we train the networks on a pair (sin, sout) from the dataset, which is presented for a period of time T , before it is changed to another pair, moving to the next 4
is ﬁxed to sin, x0 0 is ﬁxed to sout. for each neuron i in each level l do
Algorithm 1 Learning one training pair (sin, sout) (presented for the duration T ) with IL
Require: xlmax 0 1: for t = 0 to T do 2: 3: 4: 5: 6: 7: 8: 9: end for
Update each θl+1 return i,j to minimize Ft via Eq. (9) i,t to minimize Ft via Eq. (7)
Update xl if t = tc then end if end for
// the brain rests
// presenting a training pair
// in parallel in the brain
// inference
// external control signal
Figure 2: Comparison of the temporal training dynamics of BP, IL, Z-IL, and Fa-Z-IL. We assume that we train the networks on a pair (sin, sout) from the dataset, which is presented for a period of time T , before it is changed to another pair, moving to the next training epoch h. Within a single training epoch h, (sin, sout) stays unchanged, and t runs from 0. As stated before, t is the time axis during inference, which means that IL (also Z-IL and Fa-Z-IL) in PCNs run inference starting from t = 0. The squares and rounded rectangles represent nodes in one layer and connection weights between nodes in two layers of a neural network, respectively: BP (ﬁrst row) only conducts weights updates in one training epoch, while IL (second row) conducts inference until it converges (t = tc) and updates weights (assuming T tc). Note that C1 is omitted in the ﬁgure for simplicity.
≥ training epoch h. Within a single training epoch h, (sin, sout) stays unchanged, and t runs from 0.
As stated before, t is the time axis during inference, which means that IL (also Z-IL and Fa-Z-IL, proposed below) in PCNs run inference starting from t = 0. In Fig. 2, squares and rounded rectangles represent nodes in one layer and connection weights between nodes in two layers of a neural network, respectively: BP (ﬁrst row) only conducts weights updates in one training epoch, while IL (second row) conducts inference until it converges (t = tc) and updates weights (assuming T tc).
In the rest of this section and in Section 4, we introduce zero-divergent IL (Z-IL) and fully autonomous zero-divergent IL (Fa-Z-IL) in PCNs, respectively: Z-IL (third row) also conducts inference but until speciﬁc inference moments t = l and updates weights between the layers l and l + 1, while Fa-Z-IL (fourth row) conducts inference all the time and weights update is trigged autonomously at the same inference moments as Z-IL.
≥
Zero-divergent IL. We now present three conditions C1 to C3 under which IL in a PCN, denoted zero-divergent IL (Z-IL), produces exactly the same weights as BP in the corresponding ANN (having the same initial weights as the given PCN) applied to the same datapoints s = (sin, sout). In the following, we ﬁrst describe the three conditions C1 to C3, and then formally state (and prove in the supplementary material) that Z-IL produces exactly the same weights as BP. i,t and every µl
C1: Every xl i in the corresponding ANN with input sin. In particular, this also implies that εl
. This condition is naturally satisﬁed in PCNs, if before the start of each training epoch over a training pair i,t = 0 at t = 0, for l
, at t = 0 is equal to yl 1, . . . , lmax 1, . . . , lmax i,t, l 1
} 1
}
∈ {
∈ {
−
− 5
is ﬁxed to sin, x0 i,0 for l 0 is ﬁxed to sout. 1 1, . . . , lmax
}
Algorithm 2 Learning one training pair (sin, sout) (presented for the duration T ) with Fa-Z-IL
Require: xlmax 0
Require: xl i,0 = µl 1: for t = 0 to T do 2: 3: 4: 5: 6: end for
// presenting a training pair
// in parallel in the brain
// inference i,t) i,j to minimize Ft via Eq. (9) with learning rate α
Update xl
Update each θl+1 for each neuron i in each level l do i,t to minimize Ft via Eq. (7) (C1), and γ = 1 (C3). end for
φ(εl
∈ {
−
· (sin, sout), the input sin has been presented, and the network has converged in the prediction stage (see Section 2.2). This condition corresponds to a requirement in BP, that it needs one forward pass from sin to compute the prediction before conducting weights updates with the supervision signal sout. Note that neither the forward pass for BP nor this initialization for IL are shown in Fig. 2. Note that this condition is also applied in [48].
C2: Every weight θl+1
, is updated at t = l, that is, at a very speciﬁc inference
} moment, related to the layer that the weight belongs to. This may seem quite strict, but it can actually be implemented with full autonomy (see Section 4).
C3: The integration step of inference γ is set to 1. Note that solely relaxing this condition (keeping
C1 and C2 satisﬁed) results in BP with a different learning rate for different layers, where γ is the decay factor of this learning rate along layers (see supplementary material). 0, . . . , lmax i,j , l 1
−
∈ {
To prove the above equivalence statement under C1 to C3, we develop two theorems in order (proved in the supplementary material). The following ﬁrst theorem formally states that the prediction error in the PCN with IL on s under C1 to C3 is equal to the error term in its ANN with BP on s.
Theorem 3.1. Let M be a PCN, M (cid:48) be its corresponding ANN (with the same initial weights as M ), and let s be a datapoint. Then, every prediction error εl
, in M trained with IL on s under C1 and C3 is equal to the error term δl 1
} i in M (cid:48) trained with BP on s. i,t at t = l, l 0, . . . , lmax
∈ {
−
We next formally state that every weights update in the PCN with IL on s under C1 to C3 is equal to the weights update in its ANN with BP on s. This then immediately implies that the ﬁnal weights of the PCN with IL on s under C1 to C3 are equal to the ﬁnal weights of its ANN with BP on s.
Theorem 3.2. Let M be a PCN, M (cid:48) be its corresponding ANN (with the same initial weights as M ), and let s be a datapoint. Then, every update ∆θl+1
, in M trained with
}
IL on s under C1 and C3 is equal to the update ∆wl+1 i,j in M (cid:48) trained with BP on s. i,j at t = l, l 0, . . . , lmax 1
−
∈ { 4 Z-IL with Full Autonomy
Both IL and Z-IL in PCNs optimize the uniﬁed objective function of Eq. (6) during prediction and learning. Thus, they both enjoy some autonomy already. Speciﬁcally, they can autonomously switch t is ﬁxed to sout between prediction and learning by running inference, depending only on whether x0 or left unconstrained. However, when to update the weights still requires the control signal at t = tc and t = l for IL and Z-IL, respectively.
Targeting at removing this control signal from Z-IL, we now propose Fa-Z-IL, which realizes Z-IL with full au-tonomy. Speciﬁcally, we propose a function φ(
), which
· i,t and modulates the learning rate α, producing takes in εl a local learning rate for θl+1 i,j . As can be seen from Fig. 1, i,t is directly connected to θl+1 i,j , meaning that φ(
) works
εl
· locally at a neuron scale. For each θl+1 i,t) produces a i,j , φ(εl spike of 1 at exactly the inference moment of t = l, which equals to triggering θl+1 i,j to be updated at t = l. In this way, we can let the inference and weights update run all
) modulating the local learning rate with the time with φ(
· 6
Table 2: Models and their properties.
P
B o t e c n e l a v i u q
E (cid:51) (cid:55) (cid:51) (cid:51) l a c o
L y t i c i t s a l p l a i t r a
P y m o n o t u a l l u
F y m o n o t u a (cid:55) (cid:51) (cid:51) (cid:51) (cid:55) (cid:51) (cid:51) (cid:51) (cid:55) (cid:55) (cid:55) (cid:51)
BP
IL
Z-IL
Fa-Z-IL
Table 3: Success rate of detecting inference moments t = l with φ( td 1 2 3 4 5 6
) of different td.
· 7 8 16
Success rate 93.4% 92.4% 99.6% 100.0% 100.0% 100.0% 100.0% 100.0% 100.0% local information; thus, the resulting model works fully autonomously, performs all computations locally, and updates weights at t = l, i.e., producing exactly Z-IL/BP, as long as C1 and C3 are satisﬁed. Fa-Z-IL is summarized in Algorithm 2. i,t−td+1 = 0, . . . , εl
) can detect the inference moment
As the core of Fa-Z-IL, we found that quite simple functions φ(
· i,t. Speciﬁcally, from Lemma A.3 in the supplementary material, we know that εl of t = l from εl i,t under C1 diverges from its stable states at exactly t = l, i.e., εl i,t and
= 0, where td is a hyperparameter. return 1 only if εl i,t−td = 0, εl i,t−1 = 0, εl i,t) detects the inference moment of t = l and produces a spike of 1 at exactly t = l.
In this way, φ(εl i,j produced at t = l is
In special cases where εl i,t to go across zero, also zero, since εl having a larger td means a more accurate detection. In experiments, φ(
) of td = 4 is already capable
· of detecting with 100% success rate; see Table 3. Furthermore, the function φ, as the only additional component introduced in Fa-Z-IL to realize full autonomy, is highly plausible that such a computation could be performed by biological neurons, because some types of neurons are well-known to respond predominantly to changes in their input [63]. i,t=l = 0, the detection fails, however, by Eq. (9), ∆θl+1 i,t=l = 0, so the failure does no harm. Since it is possible for εl t<l = 0. Thus, φ(
· i,t (cid:54)
) can take in εl
However, Fa-Z-IL does require the input to be presented before the teacher to satisfy C1, i.e., the convergence of a prediction phase before t = 0 is still needed. We consider this to be a requirement of the learning setup. Also, such a requirement is much weaker, compared to switching computational rules (BP) and detecting the convergence of global variables (IL). We leave the study of removing this requirement or putting it inside an autonomous neural system as future research. During this prediction phase before t = 0, it is notable that the error nodes change due to feedforward input, while during learning, the error nodes change due to feedback input. In order to prevent learning during prediction, φ is equal to 1 only if the change in error nodes is caused by feedback input.
Furthermore, experiments of classiﬁcation with Fa-Z-IL have been conducted, and Fa-Z-IL produces exactly the same result as Z-IL and BP, the numbers of which can be found in the supplementary material. It should also be noted that Fa-Z-IL loses formal equivalence to BP, but with td > 4, empirical equivalence always remains.
All proposed models are summarized in Table 2 (schematic algorithms are given in the supplementary material), where Fa-Z-IL is the only model that is not only equivalent to BP, but also performs all computations locally and fully autonomously. 5 Experiments
In this section, we complete the picture of this work with experimental results, providing ablation studies on MNIST and measuring the running time of the discussed approaches on ImageNet. 5.1 MNIST
We now show that zero-divergence cannot be achieved when strictly weaker conditions than C1,
C2, and C3 in Section 3 are satisﬁed only. Speciﬁcally, with experiments on MNIST, we show the divergence of PCNs trained with ablated variants of Z-IL from ANNs trained with BP.
Setup. We use the same setup as in [48]. Speciﬁcally, we train for 64 epochs with α = 0.001, batch size 20, and logistic sigmoid as f . To remove the stochasticity of the batch sampler, models in one group within which we measure divergence are set with the same seed. We evaluate three of such groups, each set with different randomly generated seeds (
),
}
{ and the ﬁnal numbers are averaged over them. The divergence is measured in terms of the error percentage on the test set summed over all epochs (test error, for short), as in [48, 37, 58, 53, 59], and of the ﬁnal weights, as in [59]. The divergence of the test error is the L1 distance between the corresponding test errors, averaged over 64 training iterations (the test error is evaluated after each training iteration). The divergence of the ﬁnal weights is the sum of the L2 distance between the 1482555873, 698841058, 2283198659 7
Figure 3: Ablation of C2, C3, and C1, where divergence is measured on test error and ﬁnal weights. corresponding weights, after the last training iteration. We conducted experiments on MNIST (with 784 input and 10 output neurons; the other settings are as in [64]). We investigated three different network structures with 1, 2, and 3 hidden layers, respectively (i.e., lmax
), each containing 32 neurons. 2, 3, 4
}
∈ {
Ablation of C1. Assuming C2 and C3 satisﬁed, to ablate C1, we consider situations when the network has not converged in the prediction stage before the training pair is presented, i.e., xl i,0. i,0 with different standard deviations σ, where
To simulate this, we sampled xl
σ = 0 corresponds to satisfying C1. We swipe σ =
. Fig. 3, 0, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100
}
{ right column, shows that zero divergence is only achieved when σ = 0, i.e., C1 is satisﬁed. A larger version of Fig. 3 is given in the supplementary material. i,0 around the mean of µl
= µl i,0 (cid:54)
, and to ablate C2, we swipe t =
Ablation of C2 and C3. Assuming C1 satisﬁed, to ablate C3, we swipe γ = 0.01, 0.1, 0.5, 1,
{
. Here, setting t to a ﬁxed number is 5, 10
} exactly the implementation of IL with tc set to this ﬁxed number. We set t = l between t = lmax 2 and t = lmax 1 (as argued in the supplementary material). Fig. 3, three left columns, shows that zero divergence is only achieved when t = l and γ = 1, i.e., C2 and C3 are satisﬁed. Note that the settings of t l, 0, 1, 2, 3, 4, 16, 64
}
{ 0.5 are typical for IL in [20]. 16 and γ
−
−
≥
≤ 5.2 ImageNet
We further conduct experiments on ImageNet to measure the running time of Z-IL and Fa-Z-IL on large datasets. In detail, we show that Z-IL and Fa-Z-IL create minor overheads over BP, which supports their scalability. The detailed implementation setup is given in the supplementary material.
Table 4 shows the averaged running time of each weights update of BP, IL, Z-IL, and Fa-Z-IL.
For IL, we set tc = 20, following [48]. As can be seen,
IL introduces large overheads, due to the fact that it needs at least td inference steps before conducting a weights update. In contrast, Z-IL and Fa-Z-IL run with minor overheads compared to BP, as they require at most lmax inference steps to complete one update of weights in all layers. Comparing Fa-Z-IL to Z-IL, it is also obvious that the function φ creates only minor overheads. These observations support the claim that
Z-IL and Fa-Z-IL are indeed scalable.
Table 4: Average runtime of each weights update (in ms) of BP, IL, Z-IL, and Fa-Z-IL.
Z-IL Fa-Z-IL
Devices BP
CPU
GPU 19.2 56.3 3.6 4.2 3.1 3.7 3.6 4.1
IL 6