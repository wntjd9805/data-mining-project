Abstract
Autonomous part assembly is a challenging yet crucial task in 3D computer vision and robotics. Analogous to buying an IKEA furniture, given a set of 3D parts that can assemble a single shape, an intelligent agent needs to perceive the 3D part geometry, reason to propose pose estimations for the input parts, and ﬁnally call robotic planning and control routines for actuation. In this paper, we focus on the pose estimation subproblem from the vision side involving geometric and re-lational reasoning over the input part geometry. Essentially, the task of generative 3D part assembly is to predict a 6-DoF part pose, including a rigid rotation and translation, for each input part that assembles a single 3D shape as the ﬁnal output.
To tackle this problem, we propose an assembly-oriented dynamic graph learn-ing framework that leverages an iterative graph neural network as a backbone. It explicitly conducts sequential part assembly reﬁnements in a coarse-to-ﬁne man-ner, exploits a pair of part relation reasoning module and part aggregation module for dynamically adjusting both part features and their relations in the part graph.
We conduct extensive experiments and quantitative comparisons to three strong baseline methods, demonstrating the effectiveness of the proposed approach. 1

Introduction
It is a complicated and laborious task, even for humans, to assemble an IKEA furniture from its parts. Without referring to any procedural or external guidance, e.g. reading the instruction manual, or watching a step-by-step video demonstration, the task of 3D part assembly involves exploring an extremely large solution spaces and reasoning over the input part geometry for candidate assembly proposals. To assemble a physically stable furniture, a rich set of part relations and constraints need to be satisﬁed for a successful assembly.
∗Equal contribution. Author ordering determined by coin ﬂip.
†Corresponding author. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
There are some literature in the computer vision and graphics ﬁelds that study part-based 3D shape modeling and synthesis. For example, [3, 29, 30] employ a third-party repository of 3D meshes for part retrieval to assemble a complete shape. Beneﬁting from recent large-scale part-level datasets
[24, 38] and the advent of deep learning techniques, some recent works [14, 27, 34] leverage deep neural networks to sequentially generate part geometry and posing transform for shape composition.
Though similar to our task, none of these works addresses the exactly same setting to ours. They either allow free-form part generation for the part geometry, or assume certain part priors, such as an available large part pool, a known part count and semantics for the entire category of shapes (e.g., for chairs, four semantic parts: back, seat, leg and arm). In our setting, we assume no semantic knowledge upon the input parts and assemble 3D shapes conditioned on a given set of ﬁne-grained part geometry with variable number of parts for different shape instances.
In this paper, we propose to use a dynamic graph learning framework that predicts a 6-DoF part pose, including a rigid rotation and translation, for each input part point cloud via forming a dynamically varying part graph and iteratively reasoning over the part poses and their relations. We employ an iterative graph neural network to gradually reﬁne the part pose estimations in a coarse-to-ﬁne manner. At the core of our method, we propose the dynamic part relation reasoning module and the dynamic part aggregation module that jointly learns to dynamically evolve part node and edge features within the part graph.
Lack of the real-world data for 3D part assembly, we train and evaluate the proposed approach on the synthetic PartNet dataset, which provides a large-scale benchmark with ground-truth part assem-bly for ShapeNet models at the ﬁne-grained part granularity. Although there is no previous work studying the exactly same problem setting as ours, we formulate three strong baselines inspired by previously published works on similar task domains and demonstrate that our method outperforms baseline methods by signiﬁcant margins.
Diagnostic analysis further indicates that in the iterative part assembly procedure, a set of central parts (e.g. chair back, chair seat) learns much faster than the other peripheral parts (e.g. chair legs, chair arms), which quickly sketches out the shape backbone in the ﬁrst several iterations. Then, the peripheral parts gradually adjust their poses to match with the central part poses via the graph message-passing mechanism. Such dynamic behaviors are automatically emerged without direct supervision and thus demonstrate the effectiveness for our dynamic graph learning framework. 2