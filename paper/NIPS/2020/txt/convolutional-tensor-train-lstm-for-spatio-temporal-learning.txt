Abstract
Learning from spatio-temporal data has numerous applications such as human-behavior analysis, object tracking, video compression, and physics simulation.
However, existing methods still perform poorly on challenging video tasks such as long-term forecasting. The gap partially is because these kinds of challenging tasks require learning long-term spatio-temporal correlations in the video sequence.
We propose a higher-order convolutional LSTM model that can efﬁciently learn these correlations with a succinct representation of the history. Our model relies on a novel tensor-train module that performs prediction by combining convolutional features across time. To make computation and memory requirements feasible, we develop a novel convolutional tensor-train decomposition of the higher-order model. This decomposition reduces the model complexity by jointly approximating a sequence of convolutional kernels as a low-rank tensor-train factorization. As a result, our model outperforms existing approaches but uses only a fraction of parameters, including the baseline models. Our results achieve state-of-the-art performance in a wide range of applications and datasets, including the multi-steps video prediction on the Moving-MNIST-2 and KTH action datasets as well as early activity recognition on the Something-Something V2 dataset. 1

Introduction
While computer vision has achieved remarkable successes, e.g., on image classiﬁcation, many real-life tasks remain out-of-reach for current deep learning systems, such as prediction from complex spatio-temporal data. Such data naturally arises in a wide range of applications such as autonomous driving, robot control [1], visual perception tasks such as action recognition [2] or object tracking [3], and even weather prediction [4]. This kind of video understanding problems is challenging, since they require learning spatial-temporal representations that capture both content and dynamics simultaneously.
Learning from (video) sequences. Most state-of-the-art video models are based on recurrent neural networks (RNNs), typically some variations of Convolutional LSTM (ConvLSTM) where spatio-temporal information is encoded explicitly in each cell [4–7]. These RNNs are ﬁrst-order Markovian models in nature, meaning that the hidden states are updated using information from the previous time step only, resulting in an intrinsic difﬁculty in capturing long-range temporal correlations.
∗Equal contribution
†This work was done while the ﬁrst author was an intern at NVIDIA.
Project page: https://sites.google.com/nvidia.com/conv-tt-lstm 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
Incorporating higher-order correlations. For one-dimensional sequence modeling, Soltani and
Jiang [8] and Yu et al. [9] proposed higher-order generalizations of RNNs for long-term forecasting problems. Higher-order RNNs explicitly incorporate an extended history of previous states in each update, which requires higher-order tensors to characterize the transition function (instead of a transition matrix as in the ﬁrst-order RNNs). However, this typically leads to an exponential blow-up in the complexity of the transition function. This problem is compounded when generalizing
ConvLSTM to higher-orders and no prior work explores these generalizations.
Scaling up with tensor methods. To avoid the exponential blow-up in the complexity of transition function, tensor decompositions [10] have been investigated within higher-order RNNs [9]. Tensor decomposition avoids the exponential growth of model complexity and introduces an information bottleneck that facilitates effective representation learning. This bottleneck restricts how much information can be passed on from one sub-system to another in a learning system [11, 12]. Previously, low-rank tensor factorization has been used to improve various deep network architectures [13–16].
However, its application has not been explored in the context of spatio-temporal LSTMs. The only approach that leveraged tensor factorization for compact higher-order LSTMs [9] considers exclusively sequence forecasting, which does not naturally extend to general spatio-temporal data.
Generalizing ConvLSTM to higher-orders. When extending to higher-orders, we aim to design a transition function that can leverage all previous hidden states and satisﬁes three properties: (i) The operations preserve the spatial structure of the hidden states; (ii) The receptive ﬁeld increases with time. In other words, the longer the temporal correlation is captured, the larger the spatial context should be; (iii) Finally, space and time complexities grow at most linearly with the number of times steps. Because previous transition functions in higher-order RNNs were designed for one-dimensional sequence, when directly extended to spatio-temporal data, they do not satisfy all three properties. A direct extension fails to preserve the spatial stricture or increases the complexity exponentially.
Contributions. In this paper, we propose a higher-order Convolutional LSTM model for complex spatio-temporal data satisfying all three properties. Our model incorporates a long history of states in each update while preserving their spatial structure using convolutional operations. Directly constructing such a model leads to an exponential growth of parameters in both spatial and temporal dimensions. Instead, our model is made computationally tractable via a novel convolutional tensor-train decomposition, which recursively performs a convolutional factorization of the kernels across time. Besides parameter reduction, this factorization introduces an information bottleneck enabling the learning of better representations. As a result, it achieves better results than previous works with only a fraction of parameters.
We empirically demonstrate our model’s performance on several challenging tasks, including early activity recognition and video prediction. We report an absolute increase of 8% accuracy over the state-of-the-art [7] for early activity recognition on the Something-Something v2 dataset. Our model outperforms both 3D-CNN and ConvLSTM by a large margin. We also report a new state-of-the-art for multi-step video prediction on both Moving-MNIST-2 and KTH datasets. 2