Abstract
Graph-based neural network models are producing strong results in a number of domains, in part because graphs provide ﬂexibility to encode domain knowledge in the form of relational structure (edges) between nodes in the graph. In practice, edges are used both to represent intrinsic structure (e.g., abstract syntax trees of programs) and more abstract relations that aid reasoning for a downstream task (e.g., results of relevant program analyses). In this work, we study the problem of learning to derive abstract relations from the intrinsic graph structure. Motivated by their power in program analyses, we consider relations deﬁned by paths on the base graph accepted by a ﬁnite-state automaton. We show how to learn these relations end-to-end by relaxing the problem into learning ﬁnite-state automata policies on a graph-based POMDP and then training these policies using implicit differentiation.
The result is a differentiable Graph Finite-State Automaton (GFSA) layer that adds a new edge type (expressed as a weighted adjacency matrix) to a base graph. We demonstrate that this layer can ﬁnd shortcuts in grid-world graphs and reproduce simple static analyses on Python programs. Additionally, we combine the GFSA layer with a larger graph-based model trained end-to-end on the variable misuse program understanding task, and ﬁnd that using the GFSA layer leads to better performance than using hand-engineered semantic edges or other baseline methods for adding learned edge types. 1

Introduction
Determining exactly which relationships to include when representing an object as a graph is not always straightforward. As a motivating example, consider a dataset of source code samples. One natural way to represent these as graphs is to use the abstract syntax tree (AST), a parsed version of the code where each node represents a logical component.1 But one can also add additional edges to each graph in order to better capture program behaviors. Indeed, adding additional edges to represent control ﬂow or data dependence has been shown to improve performance on code-understanding tasks when compared to a AST-only or token-sequence representation [1, 19].
An interesting observation is that these additional edges are fully determined by the AST, generally by using hand-coded static analysis algorithms. This kind of program abstraction is reminiscent of temporal abstraction in reinforcement learning (e.g., action repeats or options [30, 38]). In both cases, derived higher-level relationships allow reasoning more abstractly and over longer distances (in program locations or time).
In this work, we construct a differentiable neural network layer by combining two ideas: program analyses expressed as reachability problems on graphs [34], and mathematical tools for analyzing temporal behaviors of reinforcement learning policies [13]. This layer, which we call a Graph 1For instance, the AST for print(x + y) contains nodes for print, x, y, x + y, and the call as a whole. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
(a) LASTREAD edges for an (b) Learned behavior of GFSA (c) Learned behavior of GFSA example function. on LASTREAD task. on grid-world task.
Figure 1: (a) Target edges for the LASTREAD task starting from the ﬁnal use of y on a handwritten example function. (b) Learned behavior starting at the ﬁnal use of y (blue circle). Thickness represents probability mass, color and style represent the ﬁnite-state memory, and boxes represent AST nodes in the graph. The automaton changes to a reverse-execution mode (green) and steps backward to the while loop, then nondeterministically either looks at the condition or switches to a break-ﬁnding mode (orange) and jumps to the body. In the ﬁrst case, it checks for uses of y in the condition, then splits again between the previous print and the loop body. In the second, it walks upward until
ﬁnding a break statement, then transitions back to the reverse-execution mode. For simplicity, we hide backtracking trajectories and combine some intermediate steps. Note that only the start and end locations (colored boxes in (a)) are supervised; all intermediate steps are learned. (c) Colored arrows denote the path taken by the GFSA policy for each option, shown starting from four arbitrary start positions (white) on a grid-world layout not seen during training. The tabular agent can jump from each start position to the endpoint of any of its arrows in a single step.
Finite-State Automaton (GFSA), can be trained end-to-end to add derived relationships (edges) to arbitrary graph-structured data based on performance on a downstream task.2 We show empirically that the GFSA layer has favorable inductive biases relative to baseline methods for learning edge structures in graph-based neural networks. 2