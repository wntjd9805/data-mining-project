Abstract
We introduce an end-to-end learnable technique to robustly identify feature edges in 3D point cloud data. We represent these edges as a collection of parametric curves (i.e., lines, circles, and B-splines). Accordingly, our deep neural network, coined PIE-NET, is trained for parametric inference of edges. The network relies on a region proposal architecture, where a ﬁrst module proposes an over-complete collection of edge and corner points, and a second module ranks each proposal to decide whether it should be considered. We train and evaluate our method on the
ABC dataset, the largest publicly available dataset of CAD models, via ablation studies and compare our results to those produced by traditional (non-learning) processing pipelines, as well as a recent deep learning-based edge detector (EC-Net). Our results signiﬁcantly improve over the state-of-the-art, both quantitatively and qualitatively, and generalize well to novel shape categories. 1

Introduction
Edge estimation is a fundamental problem in image and shape processing. Often regarded as a low-level vision problem, edge detection has been intensely studied and by and large “solved” at the conceptual level – there are precise mathematical deﬁnitions of what an edge is over an image, or over the surface of a 3D shape.
In practice however, even state-of-the-art edge estimators are sensitive to parameter settings and they often underperform near soft edges, noise, and sparse data.
This is especially true for acquired point clouds, where these data artifacts are prevalent. We argue this is caused by the fact that edge detection is traditionally achieved by performing decisions based on manually designed local surface features; note that this resembles the use of hand-designed descriptors in pre-deep learning computer vision.
In this paper, we advocate for a data-driven approach to feature edge estimation from point clouds – one where priors to make this operation robust are learned from training data. More precisely, we develop PIE-NET, a deep neural network that is trained for Parameter Inference of feature Edges over a 3D point cloud, where the output consists of one or more parametric curves. Our method treats edge inference as a proposal and ranking problem – a solution that has shown to be extremely effective in computer vision for object detection. More speciﬁcally, in a ﬁrst phase, PIE-NET proposes a large collection of potentially invalid and/or redundant parametric curves, while in a second phase invalid proposals are suppressed, and the ﬁnal output is generated. The suppression is guided by learnt conﬁdence scores estimated by the network, as well as by how well the predicted curves ﬁt the data. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
Figure 1: Our deep neural network, PIE-NET, is trained for parametric inference of edges from point cloud. It ﬁrst detects edge and corner points, and then infers a collection of parametric curves representing edge features. In comparison, the only known deep method for this task only classiﬁes edge points, and produces results that are inferior to ours both visually and quantitatively.
Our approach is also motivated by recent success on employing neural networks for other low-level geometry processing tasks such as normal estimation [1], denoising [2], and upsampling [3]. We train
PIE-NET on the recently released ABC dataset by [4], which is composed of more than one million feature-rich CAD models with parametric edge representations. The combination of large-scale training data and a carefully designed end-to-end learnable pipeline allows PIE-NET to signiﬁcantly outperform traditional (non-learning) edge detection techniques, as well as recent learnable variants from both a quantitative and qualitative standpoint. 2