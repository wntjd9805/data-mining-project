Abstract
The literature on ranking from ordinal data is vast, and there are several ways to aggregate overall preferences from pairwise comparisons between objects. In par-ticular, it is well-known that any Nash equilibrium of the zero-sum game induced by the preference matrix deﬁnes a natural solution concept (winning distribution over objects) known as a von Neumann winner. Many real-world problems, how-ever, are inevitably multi-criteria, with different pairwise preferences governing the different criteria. In this work, we generalize the notion of a von Neumann winner to the multi-criteria setting by taking inspiration from Blackwell’s approachability.
Our framework allows for non-linear aggregation of preferences across criteria, and generalizes the linearization-based approach from multi-objective optimization.
From a theoretical standpoint, we show that the Blackwell winner of a multi-criteria problem instance can be computed as the solution to a convex optimization problem.
Furthermore, given random samples of pairwise comparisons, we show that a simple, “plug-in” estimator achieves (near-)optimal minimax sample complexity.
Finally, we showcase the practical utility of our framework in a user study on autonomous driving, where we ﬁnd that the Blackwell winner outperforms the von
Neumann winner for the overall preferences. 1

Introduction
Economists, social scientists, engineers, and computer scientists have long studied models for human preferences, under the broad umbrella of social choice theory [10, 7]. Learning from human preferences has found applications in interactive robotics for learning reward functions [45, 39], in medical domains for personalizing assistive devices [59, 9], and in recommender systems for optimizing search engines [15, 28]. The recent focus on safety in AI has popularized human-in-the-loop learning methods that use human preferences in order to promote value alignment [16, 46, 6].
The most popular form of preference elicitation is to make pairwise comparisons [51, 13, 33].
Eliciting such feedback involves showing users a pair of objects and asking them a query: Do you prefer object A or object B? Depending on the application, an object could correspond to a product in a search query, or a policy or reward function in reinforcement learning. A vast body of classical work dating back to Condorcet and Borda [17, 12] has focused on deﬁning and producing a “winning" object from the result of a set of pairwise comparisons.
In relatively recent work, Dudik et al. [22] proposed the concept of a von Neumann winner, corre-sponding to a distribution over objects that beats or ties every other object in the collection. They showed that under an expected utility assumption, such a randomized winner always exists and 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
(a) (b)
Figure 1. (a) Policy A focuses on optimizing comfort and policy B on speed, and these are compared pairwise in different environments. (b) Preference matrices, where entry (i, j) of the matrix contains the proportion of comparisons between the pair (i, j) that are won by object i. (The diagonals are set to half by convention). The overall pairwise comparisons are given by the matrix POverall
, and preferences ex along each of the criteria by matrices PComfort (the numbers here are illustrative of our user-study in Section 4). Policy R is a randomized policy 1/2 A +1/2 B. While the preference matrices satisfy the linearity assumption individually along speed and comfort, the assumption is violated overall, wherein R is preferred over both A and B. and PSpeed ex ex overcomes limitations of existing winning concepts—the Condorcet winner does not always exist, while the Borda winner fails an independence of clones test [47]. However, the assumption of expected utility relies on a strong hypothesis about how humans evaluate distributions over objects: it posits that the probability with which any distribution over objects π beats an object is linear in π.
Consequences of assuming linearity:
In order to better appreciate these consequences, consider as an example the task of deciding between two policies (say A and B) to deploy in an autonomous vehicle. Suppose that these policies have been obtained by optimizing two different objectives, with policy A optimized for comfort and policy B optimized for speed. Figure 1(a) shows a snapshot of these two policies. When compared overall, 60% of the people preferred Policy A over B – making it the von Neumann winner. The linearity assumption then posits that a randomized policy that mixes between A and B can never be better than both A and B; but we see that the Policy R = 1/2 A + 1/2 B is actually preferred by a majority over both A and B! Why is the linearity assumption violated here?
One possible explanation for such a violation is that the comparison problem is actually multi-criteria in nature. If we look at the preferences for the criterion speed and comfort individually in Figure 1(b), we see that Policy A does quite poorly on the speed axis while B lags behind in comfort. In contrast,
Policy R does acceptably well along both the criteria and hence is preferred overall to both Policies A and B. It is indeed impossible to come to this conclusion by only observing the overall comparisons.
This observation forms the basis of our main proposal: decompose the single overall comparison and ask humans to provide preferences along simpler criteria. This decomposition of the comparison task allows us to place structural assumptions on comparisons along each criterion. For instance, we may now posit the linearity assumption along each criterion separately rather than on the overall comparison task. In addition to allowing for simpliﬁed assumptions, breaking up the task into such simpler comparisons allows us to obtain richer and more accurate feedback as compared to the single overall comparison. Indeed, such a motivation for eliciting simpler feedback from humans ﬁnds its roots in the the study of cognitive biases in decision making, which suggests that the human mind resorts to simple heuristics when faced with a complicated questions [53].
Contributions:
In this paper, we formalize these insights and propose a new framework for preference learning when pairwise comparisons are available along multiple, possibly conﬂicting, criteria. As shown by our example in Figure 1, a single distribution which is the von Neumann winner along every criteria might not exist. To counter this, we formulate the problem of ﬁnding the “best” randomized policy by drawing on tools from the literature on vector valued pay-offs in game theory. Speciﬁcally, we take inspiration from Blackwell’s approachability [11] and introduce the notion of a Blackwell winner. This solution concept strictly generalizes the concept of a von
Neumann winner, and recovers the latter when there is only a single criterion present. Section 2 describes this framework in detail, and Section 3 collects our statistical and computational guarantees for learning the Blackwell winner from data. Section 4 describes a user study with an autonomous driving environment, in which we ask human subjects to compare self-driving policies along multiple 2
criteria such as safety, aggressiveness, and conservativeness. Our experiment demonstrates that the
Blackwell winner is able to better trade off utility along these criteria and produces randomized policies that outperform the von Neumann winner for the overall preferences.