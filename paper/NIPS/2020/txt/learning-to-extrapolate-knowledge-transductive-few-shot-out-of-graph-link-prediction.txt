Abstract
Many practical graph problems, such as knowledge graph construction and drug-drug interaction prediction, require to handle multi-relational graphs. However, handling real-world multi-relational graphs with Graph Neural Networks (GNNs) is often challenging due to their evolving nature, as new entities (nodes) can emerge over time. Moreover, newly emerged entities often have few links, which makes the learning even more difﬁcult. Motivated by this challenge, we introduce a realistic problem of few-shot out-of-graph link prediction, where we not only predict the links between the seen and unseen nodes as in a conventional out-of-knowledge link prediction task but also between the unseen nodes, with only few edges per node. We tackle this problem with a novel transductive meta-learning framework which we refer to as Graph Extrapolation Networks (GEN). GEN meta-learns both the node embedding network for inductive inference (seen-to-unseen) and the link prediction network for transductive inference (unseen-to-unseen). For transductive link prediction, we further propose a stochastic embedding layer to model uncertainty in the link prediction between unseen entities. We validate our model on multiple benchmark datasets for knowledge graph completion and drug-drug interaction prediction. The results show that our model signiﬁcantly outperforms relevant baselines for out-of-graph link prediction tasks.1 1

Introduction
Graphs have a strong expressive power to represent structured data, as they can model data into a set of nodes (objects) and edges (relations). To exploit the graph-structured data which works on a non-Euclidean domain, several recent works propose graph-based neural architectures, referred to as Graph Neural Networks (GNNs) [8, 19]. While early works mostly deal with simple graphs with unlabeled edges, recently proposed relation-aware GNNs [34, 35] consider multi-relational graphs with labels and directions on the edges. These multi-relational graphs expand the application of
GNNs to more real-world domains such as natural language understanding [23], modeling protein structure [12], drug-drug interaction prediction [62], retrosynthesis planning [37], to name a few.
Among multi-relational graphs, Knowledge Graphs (KGs), which represent knowledge bases (KBs) such as Freebase [2] and WordNet [24], receive the most attention. They represent entities as nodes and relations among the entities as edges, in the form of a triplet: (head entity, relation, tail entity) (e.g. (Louvre museum, is located in, Paris)). Although knowledge graphs in general contain a huge amount of triplets, they are well known to be highly incomplete [25]. Therefore, automatically completing knowledge graphs, which is known as the link prediction task, is a practically important problem for KGs. Prior works tackle this problem, i.e. inferring missing triplets, by learning embeddings of entities and relations from existing triplets, and achieve impressive performances [4, 57, 9, 28, 27]. 1Code is available at https://github.com/JinheonBaek/GEN 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
Figure 1: Concept (Left): An illustration of Out-of-Graph link prediction for emerging entities. Blue dotted arrows denote inferred relationships between seen and unseen entities, and red dotted arrows denote inferred relationships between unseen entities. (Center): An illustration of our meta-learning framework for the Out-of-Graph link prediction task. Orange arrows denote the support (training) set and green dotted arrows denote the query (test) set. Visualization of the learned embeddings (Right): Our transductive GEN embeds the unseen entities on the manifold of seen entities, while the baseline [48] embeds the unseen entities off the manifold.
Despite such success, the link prediction for KGs in real-world scenarios remains challenging for a couple of reasons.
First, knowledge graphs dynamically evolve over time, rather than staying static. Shi and Weninger [36] report that around 200 new entities emerge every day. Predicting links on these emerging entities pose a new challenge, especially when
Figure 2: Entity frequency distribution. predicting the links between emerging (unseen) entities them-selves. Moreover, real-world KGs generally exhibit long-tail distributions, where a large portion of the entities have only few triplets (See Figure 2). The embedding-based methods, however, usually assume that a sufﬁcient number of associative triplets exist for training, and cannot embed unseen entities. Thus they are highly suboptimal for learning and inference on evolving real-world graphs.
Motivated by the limitations of existing approaches, we introduce a realistic problem of Few-Shot
Out-of-Graph (OOG) link prediction for emerging entities. In this task, we not only predict the links between seen and unseen entities but also between the unseen entities themselves (Figure 1, left). To this end, we propose a novel meta-learning framework for OOG link prediction, which we refer to as
Graph Extrapolation Networks (GENs) (Figure 1, center). GENs are meta-learned to extrapolate the knowledge from seen to unseen entities, and transfer knowledge from entities with many to few links.
Speciﬁcally, given embeddings of the seen entities for a multi-relational graph, we meta-train two
GNNs to predict the links between seen-to-unseen, and unseen-to-unseen entities. The ﬁrst GNN, inductive GEN, learns to embed the unseen entities that are not observed, and predicts the links between seen and unseen entities. The second GNN, transductive GEN, learns to predict the links not only between seen and unseen entities, but also between unseen entities themselves. This transductive inference is possible since our meta-learning framework can simulate the unseen entities during meta-training, while they are unobservable in conventional learning schemes. Also, since link prediction for unseen entities is inherently unreliable, which gets worse when few triplets are available for each entity, we learn the distribution of unseen representations for stochastic embedding to account for the uncertainty. Further, we apply a transfer learning strategy to model the long-tail distribution. These lead GEN to represent the unseen entities that are well aligned with the seen entities (Figure 1, right).
We validate GENs for their OOG link prediction performance on three knowledge graph completion datasets, namely FB15K-237 [2], NELL-995 [55], and WN18RR [9]. We also validate GENs for
OOG drug-drug interaction prediction task on DeepDDI [31] and BIOSNAP-sub [63] datasets. The experimental results on ﬁve datasets show that our model signiﬁcantly outperforms the baselines, even when they are retrained from scratch with unseen entities considered as seen entities. Further analysis of each component shows that both inductive and transductive layers of GEN help with the accurate link prediction for OOG entities. In sum, our main contributions are summarized as follows:
• We tackle a realistic problem setting of few-shot out-of-graph link prediction, aiming to perform link prediction not only between seen and unseen entities but also among unseen entities for multi-relational graphs that exhibit long-tail distributions, where each entity has only few triplets.
• To tackle this problem, we propose a novel meta-learning framework, Graph Extrapolation
Network (GEN), which meta-learns the node embeddings for unseen entities, to obtain low error on link prediction for both seen-to-unseen (inductive) and unseen-to-unseen (transductive) cases.
• We validate GEN for few-shot out-of-graph link prediction tasks on ﬁve benchmark datasets for knowledge graph completion and drug-drug interaction prediction, on which it signiﬁcantly outperforms relevant baselines, even when they are retrained with the unseen entities. 2
2