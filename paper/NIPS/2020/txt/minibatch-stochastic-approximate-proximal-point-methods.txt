Abstract
We extend the Approximate-Proximal Point (APROX) family of model-based methods for solving stochastic convex optimization problems, including stochastic subgradient, proximal point, and bundle methods, to the minibatch setting. To do this, we propose two minibatched algorithms for which we prove a non-asymptotic upper bound on the rate of convergence, revealing a linear speedup in minibatch size. In contrast to standard stochastic gradient methods, these methods may have linear speedup in the minibatch setting even for non-smooth functions. Our algorithms maintain the desirable traits characteristic of the APROX family, such as robustness to initial step size choice. Additionally, we show improved convergence rates for "interpolation" problems, which (for example) gives a new parallelization strategy for alternating projections. We corroborate our theoretical results with extensive empirical testing, which demonstrates the gains provided by accurate modeling and minibatching. 1

Introduction
We develop parallel stochastic approximate proximal point methods (APROX) for solving the stochas-tic optimization problem minimize f (x) = EP [F (x; S)] = subject to x ∈ X . (cid:90)
S
F (x; s)dP (s) (1)
Here the set S is a sample space, and for each s ∈ S, the function F (·; s) : Rn → R is a closed convex function, subdifferentiable on the closed convex set X ⊂ Rn. While stochastic gradient methods (SGM) are the de facto choice for problem (1) [32, 22, 8, 29]—enjoying several convergence guarantees [32], with straightforward parallel extensions that make them practically attractive [18, 11, 13]—they are very sensitive to the objective f , noise, and hyperparameter tuning [19, 1, 2]. For example, stochastic gradient methods are extremely sensitive to stepsize, and they may even diverge for objectives that do not satisfy their convergence criteria [2].
Motivated by these limitations, several researchers [6, 16, 10, 12, 2] have developed stochastic (approximate) proximal-point and model-based methods as a more robust alternative to standard gradient methods. These APROX methods, as we explain more carefully in Section 1.1, construct a model of the function at each iterate and update by minimizing a regularized version of the model.
∗Denotes equal contribution; authors listed in alphabetical order 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
Recent results demonstrate the improvements of these frameworks over standard stochastic gradient methods, as the methods demonstrate robustness to stepsize choice, are adaptive to problem difﬁculty, and converge on a broader range of problems than the stochastic gradient method [12, 2]. Yet these
APROX methods are inherently sequential, and as we hit physical limits on processor speeds, it is becoming clear that opportunities for improvements in large-scale computation and energy use must focus on parallelization [14]; it is not immediately apparent how to efﬁciently parallelize stochastic model-based and proximal point methods.
Contributions Motivated by these advantages of APROX over SGM and the importance of parallel computation in large scale stochastic optimization, we propose extensions of APROX to the minibatch setting that allow fast parallelization. We show that our extensions maintain the desirable robustness properties of APROX and enjoy signiﬁcant speedups in the minibatch size. In contrast to standard optimization methods, which can only guarantee speedups for smooth functions [18, 11], we show that our APROX extensions have speedups even for non-smooth and non-Lipschitz functions assuming a weak form of strong convexity. Moreover, these algorithms exhibit speedup robust to stepsize choices, unlike naive stochastic gradient methods, which require careful stepsize tuning to achieve the desired speedup. Finally, we show on a class of interpolation problems [4, 5] that minibatched
APROX algorithms enjoy a linear convergence that also improves linearly with minibatch size. Our experimental investigation illustrates the importance of our APROX extensions over standard stochastic gradient methods. Please visit github.com/garyxcheng/parallel-aprox for the code for our methods and experiments. 1.1 Preliminaries
The starting point of our methods is the APROX framework [10, 12, 2]. The APROX algorithms rely on creating models of the function F , where the model Fx of F at x satisﬁes the conditions (C.i) The function y (cid:55)→ Fx(y; s) is convex and subdifferentiable on X . (C.ii) The model Fx satisﬁes the equality Fx(x; s) = F (x; s) and Fx(y; s) ≤ F (y; s) for all y.
With said model, at iterate k, APROX algorithms perform the update xk+1 := argmin x∈X (cid:26)
Fxk (x; Sk) + (cid:107)x − xk(cid:107)2 2 (cid:27)
. 1 2αk (2)
The APROX framework builds on the idea that using better models in the update (2) results in more stable algorithms with better guarantees. The following models are key to illustrating our methods:
• Stochastic gradient methods: for some F (cid:48)(x; s) ∈ ∂F (x; s), use the linear model
Fx(y; s) := F (x; s) + (cid:104)F (cid:48)(x; s), y − x(cid:105). (3)
• Proximal point methods: use the full proximal model
Fx(y; s) := F (y; s).
• Truncated methods: for some F (cid:48)(x; s) ∈ ∂F (x; s), use a truncated version of the function (4)
Fx(y; s) := max (cid:26)
F (x; s) + (cid:104)F (cid:48)(x; s), y − x(cid:105), inf z∈X (cid:27)
F (z; s)
. (5)
The truncated model (5) is often easy to apply. In most machine learning applications, loss functions are non-negative, so F is readily modeled by Fxk (x; s) = [F (xk; s) + (cid:104)F (cid:48)(xk; s), x − xk(cid:105)]+. We note that it is possible to use a lower bound instead of the inﬁmum in (5). The full proximal (4) and truncated (5) models provide more accurate approximations of F than the linear model (3); which
Asi and Duchi [2, 1], motivated by previous work in the area [16, 15, 10], show yields more robust algorithms with better theoretical and practical convergence.
Notation For a convex function f , ∂f (x) denotes its subgradient set at x, and f (cid:48)(x) ∈ ∂f (x) denotes an arbitrary element of the subdifferential. We let X (cid:63) = argminx∈X f (x) denote the set of minimizers for problem (1) and x(cid:63) ∈ X (cid:63) denote a single minimizer. We let Fk := σ(S1, . . . , Sk) be the σ-ﬁeld generated by the ﬁrst k random variables Si, so xk ∈ Fk−1 for all k under iteration (2).
We defer proofs to the appendix. 2
1.2