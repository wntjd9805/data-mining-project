Abstract
Recently, we have witnessed great progress in the ﬁeld of medical imaging classiﬁ-cation by adopting deep neural networks. However, the recent advanced models still require accessing sufﬁciently large and representative datasets for training, which is often unfeasible in clinically realistic environments. When trained on limited datasets, the deep neural network is lack of generalization capability, as the trained deep neural network on data within a certain distribution (e.g. the data captured by a certain device vendor or patient population) may not be able to gener-alize to the data with another distribution. In this paper, we introduce a simple but effective approach to improve the generalization capability of deep neural networks in the ﬁeld of medical imaging classiﬁcation. Motivated by the observation that the domain variability of the medical images is to some extent compact, we propose to learn a representative feature space through variational encoding with a novel linear-dependency regularization term to capture the shareable information among medical data collected from different domains. As a result, the trained neural network is expected to equip with better generalization capability to the “unseen" medical data. Experimental results on two challenging medical imaging classiﬁca-tion tasks indicate that our method can achieve better cross-domain generalization capability compared with state-of-the-art baselines. 1

Introduction
Due to the breakthrough in machine learning and deep learning, recent years have witnessed numerous signiﬁcant successes in various medical imaging tasks. However, one of the limitations of deep learning is that it lacks generalization capability when the number of training data is not sufﬁcient
[43]. In practice, it is often the case that the testing data (a.k.a. target domain) can be dissimilar to the training data (a.k.a. source domain) in terms of many factors, such as imaging protocol, device vendors and patient populations. Such domain shift problem can lead to a signiﬁcantly negative impact on the performance of medical imaging classiﬁcation. To tackle such domain shift problem, domain adaptation [30] aims to transfer the knowledge from a source domain to a different but relevant target domain. Recently, many studies have been conducted to improve the transferable capability in the ﬁeld of medical imaging classiﬁcation with domain adaptation by assuming that target domain data are accessible [42, 8].
In many cases, requiring to access the target domain data in advance may not be feasible. For example, in the real-time clinical application scenario, it is difﬁcult to collect sufﬁcient target domain data to 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
help with network training. For another example, it is also difﬁcult to access the target domain data as many medical data are protected by privacy regulation. Thus, it is natural to ask whether we can still learn a generalized deep neural network without any prior knowledge regarding the target domain.
Domain generalization has been proposed to tackle this problem by assuming to have no access to the target information but utilizing multiple source domains’ information to better generalize to the
“unseen" new domain for testing.
Generally speaking, current research regarding domain generalization in the ﬁeld of medical imaging classiﬁcation can be categorized into two streams. The ﬁrst stream aims at conducting data aug-mentation based on medical imaging data in terms of image quality, image appearance and spatial shape [41]. Although the variation of medical images turns out to be more compact as the capturing environment can be ﬁxed in advanced compared with the images captured in our daily life, it may be difﬁcult to choose suitable augmentation types and magnitudes for clinical deployment purposes in a certain environment. The other stream leverages the advantage of domain alignment or meta-learning methods for feature representation learning [38, 7]. However, the learned feature representation may still suffer from the overﬁtting problem, as the feature representations are only shareable among multiple source domains which may not be able to generalize to target.
In this work, we propose to marriage the advantage of data augmentation and domain alignment to tackle the domain generalization problem for medical imaging classiﬁcation. Instead of directly conducting augmentation in the image domain through some linear transformations with pre-deﬁned parameters [41], we assume that there exists linear dependency in a latent space among various domains. To model such linear dependency, we propose to train a deep neural network with a novel rank regularization term on latent feature space by setting the rank of latent feature to be the number of categories. Meanwhile, we also propose to restrict the distribution of latent features to follow a pre-deﬁned prior distribution through variational encoding. We theoretically prove that an upper bound on the empirical risk of any “unseen" but related target domain can be achieved under our formulation, such that the overﬁtting problem can be alleviated. Experimental results on two challenging medical imaging classiﬁcation tasks, including imbalanced-category based skin lesion classiﬁcation as well as spinal cord gray matter segmentation (which can be treated as pixel-wise classiﬁcation), indicate that our proposed method can achieve much better generalization capability compared with other state-of-the-art baselines. The code is available at https://github.com/wyf0912/LDDG. 2