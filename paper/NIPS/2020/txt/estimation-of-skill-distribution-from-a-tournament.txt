Abstract
In this paper, we study the problem of learning the skill distribution of a population of agents from observations of pairwise games in a tournament. These games are played among randomly drawn agents from the population. The agents in our model can be individuals, sports teams, or Wall Street fund managers. Formally, we postulate that the likelihoods of outcomes of games are governed by the parametric
Bradley-Terry-Luce (or multinomial logit) model, where the probability of an agent beating another is the ratio between its skill level and the pairwise sum of skill levels, and the skill parameters are drawn from an unknown, non-parametric skill density of interest. The problem is, in essence, to learn a distribution from noisy, quantized observations. We propose a surprisingly simple and tractable algorithm that learns the skill density with near-optimal minimax mean squared error scaling as n−1+ε, for any ε > 0, so long as the density is smooth. Our approach brings together prior work on learning skill parameters from pairwise comparisons with kernel density estimation from non-parametric statistics. Furthermore, we prove information theoretic lower bounds which establish minimax optimality of the skill parameter estimation technique used in our algorithm. These bounds utilize a continuum version of Fano’s method along with a careful covering argument.
We apply our algorithm to various soccer leagues and world cups, cricket world cups, and mutual funds. We ﬁnd that the entropy of a learnt distribution provides a quantitative measure of skill, which in turn provides rigorous explanations for popular beliefs about perceived qualities of sporting events, e.g., soccer league rankings. Finally, we apply our method to assess the skill distributions of mutual funds. Our results shed light on the abundance of low quality funds prior to the
Great Recession of 2008, and the domination of the industry by more skilled funds after the ﬁnancial crisis. 1

Introduction
It is a widely-held belief among soccer enthusiasts that English Premier League (EPL) is the most competitive amongst professional leagues even though the likely eventual winner is often one of a handful of usual suspects [1, 2]. Similarly, the Cricket World Cup in 2019 is believed to be the most exciting in the modern history of the sport, and ended with one of the greatest matches of all
The author ordering is alphabetical. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
Table 1: Comparison of our contributions with prior works. The notation ˜O and ˜Ω hide poly(log(n)) terms, and ε > 0 is any arbitrarily small constant.
Estimation problem Loss function
Smooth C∞ skill PDF MSE
BTL skill parameters
BTL skill parameters relative (cid:96)∞-norm (cid:96)1-norm
Upper bound
˜O(n−1+ε) (Theorem 3)
˜O(n−1/2) [10]
O(n−1/2) [10]
Lower bound
Ω(n−1) [5, 9]
˜Ω(n−1/2) (Theorem 1)
˜Ω(n−1/2) (Theorem 2) time [3, 4]. But is any of this backed up by data, or are they just common misconceptions? In this work, we answer this question by quantifying such observations, beyond mere sports punditry and subjective opinions, in a data-driven manner. We then illustrate that a similar approach can be used to quantify the evolution of the overall quality and relative skills of mutual funds over the years.
To this end, we posit that the population of agents in a tournament, e.g., EPL teams or mutual fund managers, has an associated distribution of skills with a probability density function (PDF)
Pα over R+. Our goal is to learn this Pα. Traditionally, in the non-parametric statistics literature, cf. [5], one observes samples from the distribution directly to estimate Pα. In our setting, however, we can only observe extremely noisy, quantized values. Speciﬁcally, given n individuals, teams, or players participating in a tournament, indexed by [n] (cid:44) {1, . . . , n}, let their skill levels be
αi, i ∈ [n], which are sampled independently from Pα. We observe the outcomes of pairwise games or comparisons between them. More precisely, for each i (cid:54)= j ∈ [n], with probability p ∈ (0, 1], we observe the outcomes of k ≥ 1 games, and with probability 1 − p, we observe nothing. Let
G(n, p) denote the induced Erd˝os-R´enyi random graph on [n] with edge {i, j} ∈ G(n, p) if games between i and j are observed. (Note that G(n, p) is independent of α1, . . . , αn.) For {i, j} ∈ G(n, p), let Zm(i, j) ∈ {0, 1} denote whether j beats i, i.e., value 1 if j beats i and 0 otherwise, in game m ∈ [k]. By deﬁnition, Zm(i, j) + Zm(j, i) = 1. We assume the Bradley-Terry-Luce (BTL) [6, 7] or multinomial logit model [8] where:
P(Zm(i, j) = 1 | α1, . . . , αn) (cid:44) αj
αi + αj
, (1) independently of the outcomes of all other games. Our objective is to learn Pα from the observations
{Zm(i, j) : {i, j} ∈ G(n, p), m ∈ [k]}, instead of αi, i ∈ [n] (as in traditional statistics [5]). For a given, ﬁxed set of αi, i ∈ [n], learning them from pairwise comparison data {Zm(i, j) : {i, j} ∈
G(n, p), m ∈ [k]} has been extensively studied in the recent literature [10–12]. Nevertheless, this line of research does not provide any means to estimate the underlying skill distribution Pα.
Contributions. As the main contribution of this work, we develop a statistically near-optimal and computationally tractable method for estimating the skill distribution Pα from a subset of pairwise comparisons. Our estimation method is a two-stage algorithm that uses the (spectral) rank centrality estimator [11, 12] followed by the Parzen-Rosenblatt kernel density estimator [13, 14] with carefully chosen bandwidth. We establish that the minimax mean squared error (MSE) of our method scales as
˜O(n−η/(η+1)) for any Pα belonging to an η-H¨older class. Thus, if Pα is smooth (C∞) with bounded derivatives, then the minimax MSE is ˜O(n−1+ε) for any ε > 0; see Theorem 3 for details. Somewhat surprisingly, although we do not directly observe αi, i ∈ [n], this minimax MSE rate matches the minimax MSE lower bound of Ω(n−1) for smooth Pα even when αi, i ∈ [n] are observed [5, 9].
As a key step in our estimation method, we utilize the rank centrality algorithm [11, 12] for estimating
αi, i ∈ [n]. While the optimal learning rate of the rank centrality algorithm with respect to relative (cid:96)2-loss is well-understood [10–12], the optimal learning rates with respect to relative (cid:96)∞ and (cid:96)1-losses are not known since we only know upper bounds [10], but not matching minimax lower bounds. In
Theorems 1 and 2, we prove minimax lower bounds of ˜Ω(n−1/2) with respect to both relative (cid:96)∞ and (cid:96)1-losses. These bounds match the learning rates of the rank centrality algorithm obtained in [10] with respect to both (cid:96)∞ and (cid:96)1-losses, and hence, identify the optimal minimax rates. We derive these information theoretic lower bounds by employing a recent variant of the generalized Fano’s method with covering arguments. (Our main technical results are all delineated in Table 1.)
Finally, we illustrate the utility of our algorithm through four experiments on real-world data: cricket world cups, soccer world cups, European soccer leagues, and mutual funds. Intuitively, a concentrated 2
skill distribution, i.e., one that is close to a Dirac delta measure, corresponds to a balanced tournament with players that are all equally skilled. Hence, the outcomes of games are random or unpredictable.
On the other hand, a skill distribution that is close to uniform suggests a wider spread of players’ skill levels. So, the outcomes of games are driven more by skill rather than luck (or random chance).
We, therefore, propose to use the negative entropy of a learnt skill distribution as a way to measure the “overall skill score,” because negative entropy captures distance to the uniform distribution.
For cricket world cups, we ﬁnd that negative entropy decreases from 2003 to 2019. Indeed, this corroborates with fan experience, where in 2003, Australia and India dominated but all other teams were roughly equal, while in 2019, there was a healthy spread of skill levels making many teams potential contenders for the championship. In soccer, we observe that the EPL and World Cup have high negative entropy, which indicates that most teams are competitive, and thus, it is very difﬁcult to predict outcomes up front. Lastly, the negative entropy of US mutual funds decreases signiﬁcantly during the Great Recession of 2008, and we see ﬂatter skill distributions post 2008. This reveals that mutual funds became more competent to avoid being weeded out of the market by the ﬁnancial crisis.
It is worth mentioning that there are several reasons to estimate Pα rather than the individual skill levels α1, . . . , αn. Although speciﬁc functionals of Pα, e.g., moments or variance, may be directly estimated from estimates of skill levels, estimating Pα simultaneously recovers information about all such functionals. Indeed, it can be shown that MSE guarantees for estimating Pα yield uniform guarantees on estimating bounded statistics of the form E[f (α)] for functions f : R+ → R. Since different functionals are pertinent for different applications, a good estimate of the skill distribution
Pα is very useful. For example, we utilize negative entropy of Pα to deﬁne overall skill scores.
Standard non-parametric plug-in estimators for entropy in the literature, e.g., integral, resubstitution, or splitting data estimators [15], require an estimate of Pα to compute entropy. Therefore, in the context of this work, estimating Pα is eminently desirable.