Abstract
Conditional image generation is the task of generating diverse images using class label information. Although many conditional Generative Adversarial Networks (GAN) have shown realistic results, such methods consider pairwise relations between the embedding of an image and the embedding of the corresponding label (data-to-class relations) as the conditioning losses. In this paper, we propose
ContraGAN that considers relations between multiple image embeddings in the same batch (data-to-data relations) as well as the data-to-class relations by using a conditional contrastive loss. The discriminator of ContraGAN discriminates the authenticity of given samples and minimizes a contrastive objective to learn the relations between training images. Simultaneously, the generator tries to generate realistic images that deceive the authenticity and have a low contrastive loss. The experimental results show that ContraGAN outperforms state-of-the-art-models by 7.3% and 7.7% on Tiny ImageNet and ImageNet datasets, respectively.
Besides, we experimentally demonstrate that contrastive learning helps to relieve the overﬁtting of the discriminator. For a fair comparison, we re-implement twelve state-of-the-art GANs using the PyTorch library. The software package is available at https://github.com/POSTECH-CVLab/PyTorch-StudioGAN. 1

Introduction
Generative Adversarial Networks (GAN) [1] have introduced a new paradigm for realistic data gener-ation. Many approaches have shown impressive improvements in un/conditional image generation tasks [2, 3, 4, 5, 6, 7, 8, 9]. The studies on non-convexity of objective landscapes [10, 11, 12] and gradient vanishing problems [3, 11, 13, 14] emphasize the instability of the adversarial dynamics.
Therefore, many approaches have tried to stabilize the training procedure by adopting well-behaved objectives [3, 13, 15] and regularization techniques [4, 7, 16]. In particular, spectral normaliza-tion [4] with a projection discriminator [17] made the ﬁrst success in generating images of ImageNet dataset [18]. SAGAN [5] shows using spectral normalization on both the generator and discriminator can alleviate training instability of GANs. BigGAN [6] dramatically advances the quality of generated images by scaling up the number of network parameters and batch size.
On this journey, conditioning class information for the generator and discriminator turns out to be the secret behind realistic image generation [17, 19, 20]. ACGAN [19] validates this direction by training a softmax classiﬁer along with the discriminator. ProjGAN [17] utilizes a projection discriminator with probabilistic model assumptions. Especially, ProjGAN shows surprising image synthesis results and becomes the basic model adopted by SNGAN [4], SAGAN [7], BigGAN [6], CRGAN [7], and
LOGAN [9]. However, GANs with the projection discriminator have overﬁtting issues, which lead to the collapse of adversarial training [21, 9, 22, 23]. The ACGAN is known to be unstable when the number of classes increases [17, 19]. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
In this paper, we propose a new conditional generative adversarial network framework, namely
Contrastive Generative Adversarial Networks (ContraGAN). Our approach is motivated by an interpretation that ACGAN and ProjGAN utilize data-to-class relation as the conditioning losses.
Such losses only consider relations between the embedding of an image and the embedding of the corresponding label. In contrast, ContraGAN is based on a conditional contrastive loss (2C loss) to consider data-to-data relations in the same batch. ContraGAN pulls the multiple image embeddings closer to each other when the class labels are the same, but it pushes far away otherwise. In this manner, the discriminator can capture not only data-to-class but also data-to-data relations between samples.
We perform image generation experiments on CIFAR10 [24], Tiny ImageNet [25], and ImageNet [18] datasets using various backbone architectures, such as DCGAN [2], ResGAN [26, 16], and Big-GAN [6] equipped with spectral normalization [4]. Through exhaustive experiments, we verify that the proposed ContraGAN improves the state-of-the-art-models by 7.3% and 7.7% on Tiny ImageNet and ImageNet datasets respectively, in terms of Frechet Inception Distance (FID) [27]. Also, Con-traGAN gives comparable results (1.3% lower FID) on CIFAR10 with the art model [6]. Since
ContraGAN can learn plentiful data-to-data relations from a properly sized batch, it reduces FID signiﬁcantly without hard negative and positive mining. Furthermore, we experimentally show that 2C loss alleviates the overﬁtting problem of the discriminator. In the ablation study, we demonstrate that ContraGAN can beneﬁt from consistency regularization [7] that uses data augmentations.
In summary, the contributions of our work are as follows:
• We propose novel Contrastive Generative Adversarial Networks (ContraGAN) for condi-tional image generation. ContraGAN is based on a novel conditional contrastive loss (2C loss) that can learn both data-to-class and data-to-data relations.
• We experimentally demonstrate that ContraGAN improves state-of-the-art-results by 7.3% and 7.7% on Tiny ImageNet and ImageNet datasets, respectively. Contrastive learning also helps to relieve the overﬁtting problem of the discriminator.
• ContraGAN shows favorable results without data augmentations for consistency regulariza-tion. If consistency regularization is applied, ContraGAN can give superior image generation results.
• We provide implementations of twelve state-of-the-art GANs for a fair comparison. Our implementation of the prior arts for CIFAR10 dataset achieves even better performances than FID scores reported in the original papers. 2