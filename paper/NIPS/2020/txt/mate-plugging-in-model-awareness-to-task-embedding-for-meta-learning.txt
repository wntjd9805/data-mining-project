Abstract
Meta-learning improves generalization of machine learning models when faced with previously unseen tasks by leveraging experiences from different, yet re-lated prior tasks. To allow for better generalization, we propose a novel task representation called model-aware task embedding (MATE) that incorporates not only the data distributions of different tasks, but also the complexity of the tasks through the models used. The task complexity is taken into account by a novel variant of kernel mean embedding, combined with an instance-adaptive attention mechanism inspired by an SVM-based feature selection algorithm. Together with conditioning layers in deep neural networks, MATE can be easily incorporated into existing meta learners as a plug-and-play module. While MATE is widely applicable to general tasks where the concept of task/environment is involved, we demonstrate its effectiveness in few-shot learning by improving a state-of-the-art model consistently on two benchmarks. Source codes for this paper are available at https://github.com/VITA-Group/MATE. 1

Introduction
Human can often quickly learn new concepts after seeing only a few examples or having minutes of experience. Prevalent deep neural networks, on the other hand, require enormous amount of data to learn to generalize well [32]. To avoid overﬁtting, these gigantic deep learning models must integrate prior knowledge like humans do. For example, we can quickly learn to distinguish between several characters in a brand-new language we have never learned before because we can exploit past experiences and concepts that we have acquired in our native language. In machine learning, computer vision, and robotics, prior experience often comes in the form of tasks and their relationships. For example, after teaching a robot to walk, we expect that it should be able to learn to run faster by exploiting the related skills acquired from the previous task. Therefore, it is vital for more efﬁcient meta-learning to ﬁnd a method that can summarize and make use of the prior experience.
The key of meta-learning, or learning to learn, is to learn an inductive bias for the new task using data from previous tasks [3, 46]. In principle, machine learning problems can be viewed as a problem of searching for the best hypothesis in a hypothesis space F that characterizes the inductive bias. Maximum margin bias for support vector machine (SVM) [52] and minimum feature bias for the feature selection algorithms [8] are examples of how the inductive bias can be incorporated.
Furthermore, the architectures of deep neural networks used, e.g., the popular 2D-convolution blocks 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
and residual/dense connections [15, 18], are now increasingly viewed as a form of inductive bias too
[51, 16, 9]. Finding the most suitable inductive bias for the problem at hand not only ensures that good solutions can be found by a learning algorithm, but can also expedite the learning.
In general, the structure of the hypothesis space F determines 1) its capacity; and thus 2) the performance of the optimal hypothesis f ∗ ∈ F; moreover, 3) the difﬁculty of identifying f ∗ in
F. On the one hand, the family of deep networks characterizes a gigantic and special hypothesis space which potentially contains good solutions, but is notoriously difﬁcult to train. Training deep networks from scratch on each task with limited amount of data often lead to overﬁtting. On the other hand, let us consider an extreme case where the hypothesis space only contains one element, i.e.,
F = {f ∗} where f ∗ denotes the optimal solution. This effectively reduces the sample complexity to zero, i.e., no learning is required. In this sense, the core problem of meta-learning is to construct a suitable hypothesis space that contains an optimal solution and is at the same time easy to learn.
Model-Agnostic Meta-Learning (MAML) [10] can be perceived as constraining the hypothesis space to be within the neighborhood of the meta-parameters. Since the optimal parameters for different tasks are assumed to lie in this neighborhood, they can be reached via a few steps of gradient decent.
The above reasoning implies our core idea to advocate in this paper: the model learned in each task is itself part of the inductive bias. Knowing which models work best for previous tasks should contribute to improving transferability to new tasks that employ similar models. A natural idea that follows is to extract representations of the tasks, and to establish a relationship between the tasks and their corresponding best models. Most previous works that either implicitly or explicitly leverage task representations only refer to the data distribution when constructing the representation [35, 49], with a recent exception in [1]. However. we conjecture such might not sufﬁce for sufﬁcient inductive bias.
Take few-shot classiﬁcation, which will be a main application scenario considered by this paper, as an example. In a typical few-shot setting, due to the small class number as well as the small training sample size, it is reasonable to assume a model will make more use of compact, essential features to differentiate classes, compared to general classiﬁcation with abundant training data covering vast variations. For instance, a few-shot classiﬁer might ﬁnd it sufﬁcient to classify dog and car, by just examining ear and fur features. However, those “essential” features vary with tasks, e.g., the same ear-and-fur feature will become no longer “essential” if learning a few-shot dog-cat classiﬁer.
Therefore, in addition to the data distribution, the features that a classiﬁer learns to focus on can contribute complementary information to characterizing the tasks and constructing the embeddings. 1.1 Our Contributions
Framework. In order to inject the model inductive bias, we propose a model-aware task embedding (MATE) framework which is generally applicable as a plug-in module to most meta-learning (single) models. The proposed representation is based on the novel Hilbert space embedding of distributions
[43, 29] which can capture information of both data distribution and the model used in learning.
Although similar embeddings have been implicitly applied to meta-learning [1, 35, 49], our framework is the ﬁrst to: 1) be model-aware via the incorporation of the model information into the embedding, instead of relying only on data distribution; 2) explicitly draw a connection between meta learning and Hilbert space embedding of distributions [43, 29] from a theoretical perspective.
Methodology. For incorporating model information, we propose an instance-adaptive soft feature-selection method inspired by a ﬁrst-order variable selection method in [37], which adaptively em-phasizes essential features that vary per each task. We view it interpretable and generalizable to meta-learning applications even beyond few-shot learning (a main study subject of this paper).
Experiments. We demonstrate that MATE can help the learning agent to adapt faster and better to new tasks, thanks to the new model-aware inductive prior guiding to constrain the hypothesis space.
We illustrate that this new inductive bias is highly informative and adaptive across tasks, as a result of the proposed instance-adaptive soft feature-selection. We empirically demonstrate on two few-shot learning benchmarks that MATE improve up to 1% 5-shot accuracy, on top of a state-of-the-art meta learner “backbones", showing MATE to be generally effective and easy-to-use. 2