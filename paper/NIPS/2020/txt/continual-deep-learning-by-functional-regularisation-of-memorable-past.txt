Abstract
Continually learning new skills is important for intelligent systems, yet standard deep learning methods suffer from catastrophic forgetting of the past. Recent works address this with weight regularisation. Functional regularisation, although computationally expensive, is expected to perform better, but rarely does so in practice. In this paper, we ﬁx this issue by using a new functional-regularisation approach that utilises a few memorable past examples crucial to avoid forgetting.
By using a Gaussian Process formulation of deep networks, our approach enables training in weight-space while identifying both the memorable past and a functional prior. Our method achieves state-of-the-art performance on standard benchmarks and opens a new direction for life-long learning where regularisation and memory-based methods are naturally combined. 1

Introduction
The ability to quickly adapt to changing environments is an important quality of intelligent systems.
For such quick adaptation, it is important to be able to identify, memorise, and recall useful past experiences when acquiring new ones. Unfortunately, standard deep-learning methods lack such qualities, and can quickly forget previously acquired skills when learning new ones [18]. Such catastrophic forgetting presents a big challenge for applications such as robotics, where new tasks can appear during training, and data from previous tasks might be unavailable for retraining.
In recent years, many methods have been proposed to address catastrophic forgetting in deep neural networks (DNNs). One popular approach is to keep network weights close to the values obtained for the previous tasks/data [12, 18, 22, 37]. However, this may not always ensure the quality of predictions on previous tasks. Since the network outputs depend on the weights in a complex way, such weight-regularisation may not be effective. A better approach is to use functional-regularisation, where we directly regularise the network outputs [5], but this is costly because it requires derivatives of outputs at many input locations. Existing approaches reduce these costs by carefully selecting the locations, e.g. by using a working memory [5] or Gaussian-Process (GP) inducing points [34], but currently they do not consistently outperform existing weight-regularisation methods.
* These two authors contributed equally.
† This work is conducted during an internship at RIKEN Center for AI project, Tokyo, Japan.
‡ Corresponding authors: emtiyaz.khan@riken.jp, ss2163@cam.ac.uk 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
(a) FROMP for continual deep learning (b) Most (left) vs least (right) memorable
Figure 1: (a) Our FROMP method consists of three main steps where we convert a DNN to GP using
Khan et al. [16], ﬁnd memorable examples, and train weights with functional regularisation of those examples. (b) Memorable past on MNIST – they are difﬁcult to classify and close to the boundary.
To address this issue, we propose a new functional-regularisation method called Functional Regu-larisation of Memorable Past (FROMP). Our key idea is to regularise the network outputs at a few memorable past examples that are crucial to avoid forgetting. We use a GP formulation of DNNs to obtain a weight-training method that exploits correlations among memorable examples in the function space (see Fig. 1a). FROMP involves a slight modiﬁcation of Adam and a minor increase in computa-tion cost. It achieves state-of-the-art performance on standard benchmarks, and is consistently better than both the existing weight-regularisation and functional-regularisation methods. Our work in this paper focuses on avoiding forgetting, but it also opens a new direction for life-long learning methods where regularisation methods are naturally combined with memory-based methods.1 1.1