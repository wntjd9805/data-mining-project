Abstract
The state-of-the art machine learning approach to training deep neural networks, backpropagation, is implausible for real neural networks: neurons need to know their outgoing weights; training alternates between a bottom-up forward pass (computation) and a top-down backward pass (learning); and the algorithm often needs precise labels of many data points. Biologically plausible approximations to backpropagation, such as feedback alignment, solve the weight transport problem, but not the other two. Thus, fully biologically plausible learning rules have so far remained elusive. Here we present a family of learning rules that does not suffer from any of these problems. It is motivated by the information bottleneck principle (extended with kernel methods), in which networks learn to compress the input as much as possible without sacriﬁcing prediction of the output. The resulting rules have a 3-factor Hebbian structure: they require pre- and post-synaptic ﬁring rates and an error signal – the third factor – consisting of a global teaching signal and a layer-speciﬁc term, both available without a top-down pass. They do not require precise labels; instead, they rely on the similarity between pairs of desired outputs. Moreover, to obtain good performance on hard problems and retain biological plausibility, our rules need divisive normalization – a known feature of biological networks. Finally, simulations show that our rules perform nearly as well as backpropagation on image classiﬁcation tasks. 1

Introduction
Supervised learning in deep networks is typically done using the backpropagation algorithm (or backprop), but in its present form it cannot explain learning in the brain [1]. There are three reasons for this: weight updates require neurons to know their outgoing weights, which they do not (the weight transport problem); the forward pass for computation and the backward pass for weight updates need separate pathways and have to happen sequentially (preventing updates of earlier layers before the error is propagated back from the top ones, see Fig. 1A); and a large amount of precisely labeled data is needed.
While approximations to backprop such as feedback alignment [2, 3] can solve the weight transport problem, they do not eliminate the requirement for a backward pass or the need for labels. There have been suggestions that a backward pass could be implemented with apical dendrites [4], but it’s not clear how well the approach scales to large networks, and the backward pass still has to follow the forward pass in time. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
A input
Top-down error signals (e.g. backprop) layer k-1 layer k layer k k
W
B global  teaching signal error input sequential  error propagation simultaneous error propagation
Layer-wise error signals layer k-1 layer k layer k global  teaching signal k
W
W local local error error local error
Figure 1: A. The global error signal is propagated to each layer from the layer above, and used to update the weights. B. The global error signal is sent directly to each layer.
Backprop is not, however, the only way to train deep feedforward networks. An alternative is to use so-called layer-wise update rules, which require only activity in adjacent (and thus connected) layers, along with a global error signal (Fig. 1B). Layer-wise training removes the need for both weight transport and a backward pass, and there is growing evidence that such an approach can work as well as backprop [5, 6, 7]. However, while such learning rules are local in the sense that they mainly require activity only in adjacent layers, that does not automatically imply biological plausibility.
Our work focuses on ﬁnding a layer-wise learning rule that is biologically plausible. For that we take inspiration from the information bottleneck principle [8, 9], in which every layer minimizes the mutual information between its own activity and the input to the network, while maximizing the mutual information between the activity and the correct output (e.g., a label). Estimating the mutual information is hard [10], so [11] proposed the HSIC bottleneck: instead of mutual information they used “kernelized cross-covariance” called Hilbert-Schmidt independence criterion (HSIC). HSIC was originally proposed in as a way to measure independence between distributions [12]. Unlike mutual information, HSIC is easy to estimate from data [12], and the information bottleneck objective keeps its intuitive interpretation. Moreover, as we will see, for classiﬁcation with roughly balanced classes it needs only pairwise similarities between labels, which results in a binary teaching signal.
Here we use HSIC, but to achieve biologically plausible learning rules we modify it in two ways: we replace the HSIC between the input and activity with the kernelized covariance, and we approximate
HSIC with “plausible HSIC”, or pHSIC, the latter so that neurons don’t need to remember their activity over many data points. (However, the objective function becomes an upper bound to the
HSIC objective.) The resulting learning rules have a 3-factor Hebbian structure: the updates are proportional to the pre- and post-synaptic activity, and are modulated by a third factor (which could be a neuromodulator [13]) speciﬁc to each layer. In addition, to work on hard problems and remain biologically plausible, our update rules need divisive normalization, a computation done by the primary visual cortex and beyond [14, 15].
In experiments we show that plausible rules generated by pHSIC work nearly as well as backprop on MNIST [16], fashion-MNIST [17], Kuzushiji-MNIST [18] and CIFAR10 [19] datasets. This signiﬁcantly improves the results from the original HSIC bottleneck paper [11]. 2