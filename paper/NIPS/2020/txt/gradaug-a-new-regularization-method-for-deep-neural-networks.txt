Abstract
We propose a new regularization method to alleviate over-ﬁtting in deep neural networks. The key idea is utilizing randomly transformed training samples to regularize a set of sub-networks, which are originated by sampling the width of the original network, in the training process. As such, the proposed method introduces self-guided disturbances to the raw gradients of the network and therefore is termed as Gradient Augmentation (GradAug). We demonstrate that GradAug can help the network learn well-generalized and more diverse representations. Moreover, it is easy to implement and can be applied to various structures and applications.
GradAug improves ResNet-50 to 78.79% on ImageNet classiﬁcation, which is a new state-of-the-art accuracy. By combining with CutMix, it further boosts the performance to 79.67%, which outperforms an ensemble of advanced training tricks. The generalization ability is evaluated on COCO object detection and instance segmentation where GradAug signiﬁcantly surpasses other state-of-the-art methods. GradAug is also robust to image distortions and FGSM adversarial attacks and is highly effective in low data regimes. Code is available at https:
//github.com/taoyang1122/GradAug 1

Introduction
Deep neural networks have achieved great success in computer vision tasks such as image classiﬁca-tion [1, 2], image reconstruction [3, 4], object detection [5, 6] and semantic segmentation [7, 8]. But deep neural networks are often over-parameterized and easily suffering from over-ﬁtting. Regular-ization [9, 10] and data augmentation [1, 11] are widely used techniques to alleviate the over-ﬁtting problem. Many data-level regularization methods [10, 12, 13] have achieved promising performance in image classiﬁcation. These methods are similar to data augmentation where they put constraints on the input images. Although effective in image classiﬁcation, these methods are hard to apply to downstream tasks such as object detection and segmentation due to their special operations. For example, the state-of-the-art CutMix [13] can not be directly applied to object detection because
ﬁrst, mixing samples will destroy the semantics in images; second, it is hard to interpolate the labels in these tasks. Another category of regularization methods imposes constraints on the network structures. [14] proposes that adding noises to the network gradients can improve generalization.
Other methods [9,15,16] randomly drop some connections in the network, which implicitly introduce random noises in the training process. These methods are usually more generic but not as effective as data-level regularization.
In this paper, we introduce Gradient Augmentation (GradAug), which generates meaningful distur-bances to the gradients by the network itself rather than just adding random noises. The idea is that when a random transformation (e.g., random rotation, random scale, random crop, etc.) is applied to an image, a well-generalized network should still recognize the transformed image as the same object.
Different from the regular data augmentation technique which only regularizes the full-network, we regularize the representations learned by a set of sub-networks, which are randomly sampled 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
from the full network in terms of the network width (i.e., number of channels in each layer). Since the representation of the full network is composed of sub-networks’ representations due to weights sharing during the training, we expect sub-networks to learn different representations from different transformations, which will lead to a well-generalized and diversiﬁed full network representation.
We conduct a comprehensive set of experiments to evaluate the proposed regularization method.
Using a simple random scale transformation, GradAug can improve the ImageNet Top-1 accuracy of ResNet-50 from 76.32% to 78.79%, which is a new state-of-the-art accuracy. By leveraging a more powerful data augmentation technique – CutMix [13], we can further push the accuracy to 79.67%. The representation’s generalization ability is evaluated on COCO object detection and instance segmentation tasks (Section 4.4). Our ImageNet pretrained model alone can improve the baseline MaskRCNN-R50 by +1.2 box AP and +1.2 mask AP. When applying GradAug to the detection framework, it can outperform the baseline by +1.7 box AP and +2.1 mask AP. Moreover, we demonstrate that GradAug is robust to image corruptions and adversarial attacks (Section 4.5) and is highly effective in low data settings (Section 4.6). 2