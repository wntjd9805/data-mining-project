Abstract
Tensor factorization based models have shown great power in knowledge graph completion (KGC). However, their performance usually suffers from the overﬁtting problem seriously. This motivates various regularizers—such as the squared Frobe-nius norm and tensor nuclear norm regularizers—while the limited applicability signiﬁcantly limits their practical usage. To address this challenge, we propose a novel regularizer—namely, DUality-induced RegulArizer (DURA)—which is not only effective in improving the performance of existing models but widely applica-ble to various methods. The major novelty of DURA is based on the observation that, for an existing tensor factorization based KGC model (primal), there is often another distance based KGC model (dual) closely associated with it. Experiments show that DURA yields consistent and signiﬁcant improvements on benchmarks. 1

Introduction
Knowledge graphs contain quantities of factual triplets, which represent structured human knowledge.
In the past few years, knowledge graphs have made great achievements in many areas, such as natural language processing [37], question answering [13], recommendation systems [30], and computer vision [18]. Although commonly used knowledge graphs usually contain billions of triplets, they still suffer from the incompleteness problem that a lot of factual triplets are missing. Due to the large scale of knowledge graphs, it is impractical to ﬁnd all valid triplets manually. Therefore, knowledge graph completion (KGC)—which aims to predict missing links between entities based on known links automatically—has attracted much attention recently.
Distance based (DB) models and tensor factorization based (TFB) models are two important categories of KGC models. DB models use the Minkowski distance to measure the plausibility of a triplet.
Although they can achieve state-of-the-art performance, many of them still have difﬁculty in modeling complex relation patterns, such as one-to-many and many-to-one relations [16, 33]. TFB models treat knowledge graphs as partially observed third-order binary tensors and formulate KGC as a tensor completion problem. Theoretically, these models are highly expressive and can well handle complex relations. However, their performance usually suffers from the overﬁtting problem seriously and consequently cannot achieve state-of-the-art.
To tackle the overﬁtting problem of TFB models, researchers propose various regularizers. The squared Frobenius norm regularizer is a popular one that applies to various models [22, 34, 28].
However, experiments show that it may decrease performance for some models (e.g., RESCAL) [23].
More recently, motivated by the great success of the matrix trace norm in the matrix completion problem [25, 5], Lacroix et al. [15] propose a tensor nuclear p-norm regularizer. It gains signiﬁcant improvements against the squared Frobenius norm regularizer. However, it is only suitable for canonical polyadic (CP) decomposition [12] based models, such as CP and ComplEx [28], but
∗Corresponding author. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
not appropriate for a more general class of models, such as RESCAL [22]. Therefore, it is still challenging to ﬁnd a regularizer that is both widely applicable and effective.
In this paper, we propose a novel regularizer for tensor factorization based KGC models—namely,
DUality-induced RegulArizer (DURA). The major novelty of DURA is based on the observation called duality—for an existing tensor factorization based KGC model (primal), there is often another distance based KGC model closely associated with it (dual). The duality can be derived by expanding the squared score functions of the associated distance based models. Then, the cross-term in the expansion is exactly a tensor factorization based KGC model, and the squared terms in it give us a regularizer. Using DURA, we can preserve the expressiveness of tensor factorization based KGC models and prevent them from the overﬁtting problem. DURA is widely applicable to various tensor factorization based models, including CP, ComplEx, and RESCAL. Experiments show that, DURA yields consistent and signiﬁcant improvements on datasets for the knowledge graph completion task.
It is worth noting that, when incorporated with DURA, RESCAL [22]—which is one of the ﬁrst knowledge graph completion models—performs comparably to state-of-the-art methods and even beats them on several benchmarks. 2 Preliminaries
In this section, we review the background of this paper in Section 2.1 and introduce the notations used throughout this paper in Section 2.2. 2.1