Abstract
In this work we propose a graph-based learning framework to train models with provable robustness to adversarial perturbations. In contrast to regularization-based approaches, we formulate the adversarially robust learning problem as one of loss minimization with a Lipschitz constraint, and show that the saddle point of the associated Lagrangian is characterized by a Poisson equation with weighted Laplace operator. Further, the weighting for the Laplace operator is given by the Lagrange multiplier for the Lipschitz constraint, which modulates the sensitivity of the minimizer to perturbations. We then design a provably robust training scheme using graph-based discretization of the input space and a primal-dual algorithm to converge to the Lagrangian’s saddle point. Our analysis establishes a novel connection between elliptic operators with constraint-enforced weighting and adversarial learning. We also study the complementary problem of improving the robustness of minimizers with a margin on their loss, formulated as a loss-constrained minimization problem of the Lipschitz constant. We propose a technique to obtain robustiﬁed minimizers, and evaluate fundamental Lipschitz lower bounds by approaching Lipschitz constant minimization via a sequence of gradient p-norm minimization problems. Ultimately, our results show that, for a desired nominal performance, there exists a fundamental lower bound on the sensitivity to adversarial perturbations that depends only on the loss function and the data distribution, and that improvements in robustness beyond this bound can only be made at the expense of nominal performance. Our training schemes provably achieve these bounds both under constraints on performance and robustness. 1

Introduction
Sensitivity to adversarial perturbations is one of the main limitations of data-driven models, and a hurdle to their deployment in safety-critical applications. Improving adversarial robustness requires adjusting the worst-case sensitivity of the data-driven input-output map, which is characterized by its Lipschitz constant. Training under a Lipschitz regularization or constraint is therefore a natural way of improving adversarial robustness, which has led to many works on the subject [1, 2]. Yet, a fundamental understanding of the limitations of this approach, as well as a general framework for training models that are provably robust to adversarial perturbations, remain critically lacking. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
Motivated by this need, we consider the problem of adversarially robust learning, formulated as a loss minimization problem with a Lipschitz constraint: inf
Lip(X;Y)
∈ f (x,y)
E (cid:124)
∼
,
σ [(cid:96) (f (x), y)] (cid:125) (cid:123)(cid:122) (cid:44)Lσ(f ) s.t. lip(f )
α,
≤ (1) where X and Y are the input and output spaces equipped with distance functions, (cid:96) is the loss function for the learning problem, σ the data-generating distribution and the search space is the space Lip(X; Y) of Lipschitz-continuous maps from X to Y with an upper bound α on the Lipschitz constant. This class of problems includes, for instance, the problem of image classiﬁcation with a constraint on the Lipschitz constant of the classiﬁer. In this case, x denotes an image, y a probability vector over the space of labels and σ captures the relation between images and labels. In (1), we do not restrict our attention to any ﬁnite-dimensional subspace of Lip(X; Y), as done when a particular machine learning model is chosen (for instance, neural network, where the dimension of the search space is speciﬁed by the network structure). Instead, we focus on the inﬁnite-dimensional learning problem to derive insights and fundamental bounds for the underlying adversarial learning problem.
Finally, imposing a hard constraint on the Lipschitz constant (as opposed to a regularization term) allows us to provide hard guarantees on the robustness of the minimizer to adversarial perturbations.
Contributions. In this paper we characterize fundamental robustness bounds for machine learning algorithms, and design provably robust training schemes. Our approach creates, to the best of our knowledge, a novel and useful bridge between the nascent theory of provably robust learning and the classic theories of elliptic operators, partial differential equations, and numerical integration.
The technical contributions of this paper are twofold. First, in Section 2 we consider Problem (1) of designing a data-driven map to minimize the loss function, with a desired bound on the map’s
Lipschitz constant. Under assumptions on strict convexity of the loss function and compactness of the input and output spaces, we show that the problem has a unique minimizer and characterize the saddle point of the corresponding Lagrangian for the problem as the (weak) solution to a Poisson partial differential equation involving a weighted Laplace operator, with the weighting given by the
Lagrange multiplier for the constraint. This result provides key insights into the nature of the optimal data-driven map satisfying robustness constraints. We then design a provably robust training scheme based on a graph discretization of the domain to numerically solve for the minimizer of the problem.
Second, we consider the problem of minimizing the Lipschitz constant of a data-driven map with a guaranteed bound (margin) on its loss. We show that the Lipschitz constant is tightly and inversely related to the loss, thereby revealing a fundamental tradeoff between the robustness of a data-driven map and its performance. This result implies that the Lipschitz contant of any data-driven algorithm achieving a desired level of performance has a fundamental lower bound that depends only on the loss function (cid:96) and the data-generating distribution σ, which constitutes a fundamental lower bound to benchmark any training algorithm and learning problem. We also provide a training scheme for further improving the robustness of a minimizer with a margin on the loss, by using a graph-based iterative procedure that involves solving a series of p-Poisson equations, decsribed in Section 3.