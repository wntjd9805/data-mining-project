Abstract
Self-supervised depth estimators have recently shown results comparable to the supervised methods on the challenging single image depth estimation (SIDE) task, by exploiting the geometrical relations between target and reference views in the training data. However, previous methods usually learn forward or backward image synthesis, but not depth estimation, as they cannot effectively neglect occlusions be-tween the target and the reference images. Previous works rely on rigid photometric assumptions or on the SIDE network to infer depth and occlusions, resulting in limited performance. On the other hand, we propose a method to “Forget About the
LiDAR” (FAL), with Mirrored Exponential Disparity (MED) probability volumes for the training of monocular depth estimators from stereo images. Our MED repre-sentation allows us to obtain geometrically inspired occlusion maps with our novel
Mirrored Occlusion Module (MOM), which does not impose a learning burden on our FAL-net. Contrary to the previous methods that learn SIDE from stereo pairs by regressing disparity in the linear space, our FAL-net regresses disparity by binning it into the exponential space, which allows for better detection of distant and nearby objects. We deﬁne a two-step training strategy for our FAL-net: It is ﬁrst trained for view synthesis and then ﬁne-tuned for depth estimation with our MOM. Our FAL-net is remarkably light-weight and outperforms the previous state-of-the-art methods with 8× fewer parameters and 3× faster inference speeds on the challenging KITTI dataset. We present extensive experimental results on the KITTI, CityScapes, and Make3D datasets to verify our method’s effectiveness.
To the authors’ best knowledge, the presented method performs the best among all the previous self-supervised methods until now. 1

Introduction
Single Image Depth Estimation (SIDE) is a critical computer vision task that has been pushed forward by the recent advances in deep convolutional neural networks (DCNNs). In particular, the self-supervised SIDE methods, which exploit geometrical dependencies in the training data, have shown promising results [11, 12, 31], even compared to those of the methods that are supervised with depth ground-truth [2, 3, 17, 30]. However, the previous self-supervised SIDE methods [11, 12, 31] fail because they are not trained directly for depth estimation, but indirectly for view synthesis. In these methods, the occluded regions among the training images prevent them from learning precise depth.
We present a self-supervised method that can accurately learn the SIDE with our novel Mirrored
Exponential Disparity (MED) probability volumes. We show that our self-supervised SIDE method achieves superior performance than the state-of-the-art (SOTA) self-, semi- and fully-supervised meth-34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
Figure 1: Our proposed FAL-net with and without our novel Mirror Occlusion Module (MOM). ods on the challenging KITTI [5] dataset. Hence, we propose to “Forget About the LiDAR”(FAL), or 3D laser scanning, for the supervised training of SIDE DCNNs. We recognize that instead of focusing our efforts on developing unnecessary complex (and large) DCNN architectures, it is more worthwhile to focus on loss functions and training strategies that can better exploit the geometrical dependencies in the data for effective self-supervision. Our network, which we call FAL-net, incorporates our proposed MED Probability Volumes into SIDE and achieves higher performance than all the most recent SOTA methods of [11, 12], with almost 8× fewer model parameters. Moreover, our proposed method performs inference of full-resolution depth maps more than 3× faster than [11, 12]. The main contributions of our work are summarized as follows: 1. A novel Mirrored Occlusion Module (MOM), which is a multi-view occlusion mask generation module. The generated masks are very realistic and are used to ﬁlter the invalid image regions due to parallax for two images with known (or estimated) camera positions (see Fig.1-(a)). 2. A new two-stage training strategy: Firstly, we train our FAL-net for stereoscopic view synthesis penalizing the synthetic right-view in all image regions (see Fig.1-(b)); Secondly, we train our
FAL-net for SIDE using our MOM to remove the burden of learning the synthesis of right-occluded contents which are not related to depth, and to provide self-supervision signals for the left-occluded regions which are ignored in the photometric reconstructions (see Fig.1-(c)). 3. We shed light on the effectiveness of Mirrored Exponential Disparity (MED) representations for self-supervised SIDE. This small change from the linear to the exponential domain makes our
FAL-net, even without MOM, perform surprisingly well, compared to the current SOTA methods.
In the following section, we quickly review the most recent related works, followed by our method in
Section 3, and our experimental results in Section 4. We conclude our work in Section 5. 2