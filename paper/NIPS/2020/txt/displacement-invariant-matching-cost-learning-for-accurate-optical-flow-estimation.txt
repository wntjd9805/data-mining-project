Abstract
Learning matching costs has been shown to be critical to the success of the state-of-the-art deep stereo matching methods, in which 3D convolutions are applied on a 4D feature volume to learn a 3D cost volume. However, this mechanism has never been employed for the optical ﬂow task. This is mainly due to the signiﬁcantly increased search dimension in the case of optical ﬂow computation, i.e., a straightforward extension would require dense 4D convolutions in order to process a 5D feature volume, which is computationally prohibitive. This paper proposes a novel solution that is able to bypass the requirement of building a 5D feature volume while still allowing the network to learn suitable matching costs from data. Our key innovation is to decouple the connection between 2D displacements and learn the matching costs at each 2D displacement hypothesis independently, i.e., displacement-invariant cost learning. Speciﬁcally, we apply the same 2D convolution-based matching net independently on each 2D displacement hypothesis to learn a 4D cost volume. Moreover, we propose a displacement-aware projection layer to scale the learned cost volume, which reconsiders the correlation between different displacement candidates and mitigates the multi-modal problem in the learned cost volume. The cost volume is then projected to optical ﬂow estimation through a 2D soft-argmin layer. Extensive experiments show that our approach achieves state-of-the-art accuracy on various datasets, and outperforms all published optical ﬂow methods on the Sintel benchmark. The code is available at https://github.com/jytime/DICL-Flow. 1

Introduction
Both the optical ﬂow estimation and stereo matching aim to ﬁnd per-pixel dense correspondences between a pair of input images. In essence, stereo matching can be viewed as a special case of optical ﬂow where the general 2D ﬂow vector search reduces to 1D search along the epipolar lines.
Despite this similarity, current leading deep stereo matching methods [15, 44, 41] and leading deep optical ﬂow methods [12, 29, 37] seem to follow very different matching strategies and network architectures. In particular, while both stereo matching and optical ﬂow estimation rely on the cost volume representation, they differ in how to build the cost volumes.
The state-of-the-art deep stereo matching methods [15, 44, 41] learn the matching costs between shifted features of left and right images, whereas most existing deep optical ﬂow methods often rely on non-learned metrics such as dot product [12, 29] and cosine similarity [37]. With the introduction of
* Indicates equal contribution 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
learned costs, stereo matching methods can directly obtain disparity maps from the cost volumes with a 1D soft-argmin layer. It has been recognised that learning data-adaptive matching cost is the key to the recent signiﬁcant advancement of stereo matching methods [15, 44, 41], yet no similar conclusion has been made for the task of deep optical ﬂow. One of the main reasons for such a discrepancy is due to the prohibitive computational cost if one attempts to naively apply the matching cost learning mechanism to optical ﬂow. To learn the matching costs, stereo matching methods only need to construct a 4D feature volume (2L × D × H × W , where L, D, H, W denote the feature dimension, disparity range, image height, and image width respectively) by traversally concatenating feature maps between stereo pairs on each disparity shift and compute the 3D cost volume through a series of 3D convolutions. In stark contrast, in optical ﬂow estimation, since the searching space becomes two-dimensional, a direct extension would result in a 5D feature volume (2L × U × V × H × W , where U, V are the 2D search window dimension) and need 4D convolutions to process it, which is computationally very expensive and limited by current computing resources.
In this paper, we propose a novel solution which bypasses dense 4D convolutions and allows the network to learn matching costs from data without constructing a 5D feature volume. By our network design, the matching costs are efﬁciently learned through a series of 2D convolutions. Compared with the methods using non-learned metrics, our method achieves a much higher accuracy without obviously sacriﬁcing computational speed. The key idea is to decouple the connections between different 2D displacements in learning the matching costs, which is called displacement-invariant cost learning (DICL). Speciﬁcally, we apply the same 2D convolution-based matching net independently on each 2D displacement candidates to form a 4D cost volume (U × V × H × W ).
Compared with applying 4D convolutions to a 5D feature volume, our proposed matching net has decoupled the connection along 2D displacements, which removes the correlation between different displacement hypothesis. Therefore, we further propose a displacement-aware projection (DAP) layer to scale the learned cost volume along the displacement dimension and mitigate the mutli-modal problem [15] in the learned cost volume. The scaled cost volume is then projected to an optical ﬂow prediction by a 2D soft-argmin layer.
Our contributions are summarized as: 1) To our best knowledge, our method is the ﬁrst one to learn matching costs from concatenated features for optical ﬂow estimation, through introducing a displacement-invariant cost learning module; 2) We propose a displacement-aware projection layer to reconsider the correlation between different motion hypothesis; and 3) Our method achieves state-of-the-art accuracy on multiple datasets and outperforms all published optical ﬂow estimation methods on the Sintel benchmark. We also provide extensive quantitative and qualitative analysis to verify the effectiveness of our approach. 2