Abstract
As the class size grows, maintaining a balanced dataset across many classes is challenging because the data are long-tailed in nature; it is even impossible when the sample-of-interest co-exists with each other in one collectable unit, e.g., multiple visual instances in one image. Therefore, long-tailed classiﬁcation is the key to deep learning at scale. However, existing methods are mainly based on re-weighting/re-sampling heuristics that lack a fundamental theory. In this paper, we establish a causal inference framework, which not only unravels the whys of previous methods, but also derives a new principled solution. Speciﬁcally, our theory shows that the SGD momentum is essentially a confounder in long-tailed classiﬁcation. On one hand, it has a harmful causal effect that misleads the tail prediction biased towards the head. On the other hand, its induced mediation also beneﬁts the representation learning and head prediction. Our framework elegantly disentangles the paradoxical effects of the momentum, by pursuing the direct causal effect caused by an input sample. In particular, we use causal intervention in training, and counterfactual reasoning in inference, to remove the “bad” while keep the “good”. We achieve new state-of-the-arts on three long-tailed visual recognition benchmarks1: Long-tailed CIFAR-10/-100, ImageNet-LT for image classiﬁcation and LVIS for instance segmentation. 1

Introduction
Over the years, we have witnessed the fast development of computer vision techniques [1, 2, 3], stemming from large and balanced datasets such as ImageNet [4] and MS-COCO [5]. Along with the growth of the digital data created by us, the crux of making a large-scale dataset is no longer about where to collect, but how to balance. However, the cost of expanding them to a larger class vocabulary with balanced data is not linear — but exponential — as the data will be inevitably long-tailed by
Zipf’s law [6]. Speciﬁcally, a single sample increased for one data-poor tail class will result in more samples from the data-rich head. Sometimes, even worse, re-balancing the class is impossible. For example, in instance segmentation [7], if we target at increasing the images of tail class instances like
“remote controller”, we have to bring in more head instances like “sofa” and “TV” simultaneously in every newly added image [8].
Therefore, long-tailed classiﬁcation is indispensable for training deep models at scale. Recent work [9, 10, 11] starts to ﬁll in the performance gap between class-balanced and long-tailed datasets, while new long-tailed benchmarks are springing up such as Long-tailed CIFAR-10/-100 [12, 10],
ImageNet-LT [9] for image classiﬁcation and LVIS [7] for object detection and instance segmentation.
Despite the vigorous development of this ﬁeld, we ﬁnd that the fundamental theory is still missing. We conjecture that it is mainly due to the paradoxical effects of long tail. On one hand, it is bad because 1Our code is available on https://github.com/KaihuaTang/Long-Tailed-Recognition.pytorch 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
Figure 1: (a) The proposed causal graph explaining the causal effect of momentum. See Section 3 for details. (b) The mean magnitudes of feature vectors for each class i after training with momentum
µ = 0.9, where i is ranking from head to tail. (c) The relative change of the performance on the basis of µ = 0.98 shows that the few-shot tail is more vulnerable to the momentum. the classiﬁcation is severely biased towards the data-rich head. On the other hand, it is good because the long-tailed distribution essentially encodes the natural inter-dependencies of classes — “TV” is indeed a good context for “controller” — any disrespect of it will hurt the feature representation learning [10], e.g., re-weighting [13, 14] or re-sampling [15, 16] inevitably causes under-ﬁtting to the head or over-ﬁtting to the tail.
Inspired by the above paradox, latest studies [10, 11] show promising results in disentangling the
“good” from the “bad”, by the naïve two-stage separation of imbalanced feature learning and balanced classiﬁer training. However, such disentanglement does not explain the whys and wherefores of the paradox, leaving critical questions unanswered: given that the re-balancing causes under-ﬁtting/over-ﬁtting, why is the re-balanced classiﬁer good but the re-balanced feature learning bad? The two-stage design clearly deﬁes the end-to-end merit that we used to believe since the deep learning era; but why does the two-stage training signiﬁcantly outperform the end-to-end one in long-tailed classiﬁcation?
In this paper, we propose a causal framework that not only fundamentally explains the previous methods [15, 16, 17, 9, 11, 10], but also provides a principled solution to further improve long-tailed classiﬁcation. The proposed causal graph of this framework is given in Figure 1 (a). We ﬁnd that the momentum M in any SGD optimizer [18, 19] (also called betas in Adam optimizer [20]), which is indispensable for stabilizing gradients, is a confounder who is the common cause of the sample feature X (via M → X) and the classiﬁcation logits Y (via M → D → Y ). In particular, D denotes the X’s projection on the head feature direction that eventually deviates X. We will justify the graph later in Section 3. Here, Figure 1 (b&c) sheds some light on how the momentum affects the feature X and the prediction Y . From the causal graph, we may revisit the “bad” long-tailed bias in a causal view: the backdoor [21] path X ← M → D → Y causes the spurious correlation even if
X has nothing to do with the predicted Y , e.g., misclassifying a tail sample to the head. Also, the mediation [22] path X → D → Y mixes up the pure contribution made by X → Y . For the “good” bias, X → D → Y respects the inter-relationships of the semantic concepts in classiﬁcation, that is, the head class knowledge contributes a reliable evidence to ﬁlter out wrong predictions. For example, if a rare sample is closer to the head class “TV” and “sofa”, it is more likely to be a living room object (e.g., “remote controller”) but not an outdoor one (e.g., “car”).
Based on the graph that explains the paradox of the “bad” and “good”, we propose a principled solution for long-tailed classiﬁcation. It is a natural derivation of pursuing the direct causal effect along
X → Y by removing the momentum effect. Thanks to causal inference [23], we can elegantly keep the “good” while remove the “bad”. First, to learn the model parameters, we apply de-confounded training with causal intervention: while it removes the “bad” by backdoor adjustment [21] who cuts off the backdoor confounding path X ← M → D → Y , it keeps the “good” by retaining the mediation X → D → Y . Second, we calculate the direct causal effect of X → Y as the ﬁnal prediction logits. It disentangles the “good” from the “bad” in a counterfactual world, where the bad effect is considered as the Y ’s indirect effect when X is zero but D retains the value when X = x. In contrast to the prevailing two-stage design [11] that requires unbiased re-training in the 2nd stage, our solution is one-stage and re-training free. Interestingly, as discussed in Section 4.4, we show that why the re-training is inevitable in their method and why ours can avoid it with even better performance. 2
On image classiﬁcation benchmarks Long-tailed CIFAR-10/-100 [12, 10] and ImageNet-LT [9], we outperform previous state-of-the-arts [10, 11] on all splits and settings, showing that the performance gain is not merely from catering to the long tail or a speciﬁc imbalanced distribution. In object detec-tion and instance segmentation benchmark LVIS [7], our method also has a signiﬁcant advantage over the former winner [17] of LVIS 2019 challenge. We achieve 3.5% and 3.1% absolute improvements on mask AP and box AP using the same Cascade Mask R-CNN with R101-FPN backbone [24]. 2