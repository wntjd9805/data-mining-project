Abstract
Real-world timeseries have complex underlying temporal dynamics and the detec-tion of anomalies is challenging. In this paper, we propose the Temporal Hierar-chical One-Class (THOC) network, a temporal one-class classiﬁcation model for timeseries anomaly detection. It captures temporal dynamics in multiple scales by using a dilated recurrent neural network with skip connections. Using multiple hyperspheres obtained with a hierarchical clustering process, a one-class objective called Multiscale Vector Data Description is deﬁned. This allows the temporal dynamics to be well captured by a set of multi-resolution temporal clusters. To further facilitate representation learning, the hypersphere centers are encouraged to be orthogonal to each other, and a self-supervision task in the temporal domain is added. The whole model can be trained end-to-end. Extensive empirical studies on various real-world timeseries demonstrate that the proposed THOC network outperforms recent strong deep learning baselines on timeseries anomaly detection. 1

Introduction
In complex cyber-physical systems such as power plants, data centers and smart factories, there are tons of sensors operating and generating substantial amounts of measurements continuously. To help monitor the system’s real-time working conditions, it is critical to be able to ﬁnd anomalies such that potential risks and ﬁnancial losses can be avoided. The problem of identifying the system’s abnormal status in each time step of the timeseries data is called timeseries anomaly detection [31].
A comprehensive survey on the traditional techniques can be found in [6].
An effective timeseries anomaly detection method should be able to model the complex nonlinear temporal dynamics of the underlying system’s normal behavior, while being robust and can be generalized to unseen anomalies. However, the development of such a technique is very challenging.
First, real-world timeseries have highly nonlinear temporal dependencies and complex interactions among variables. Moreover, anomalies are often rare. The ﬁnding and labeling of these anomalies are very time-consuming and expensive in practice. Hence, timeseries anomaly detection is usually formulated in the unsupervised learning setting [28], which is also the focus in this paper.
One-class classiﬁcation [19] is a popular paradigm for anomaly detection. The idea is that by assuming that most of the training data are normal, their characteristics are captured and learned by a model. An outlier is then detected when the current observation cannot be well-ﬁtted by the model.
Two well-known and closely related one-class classiﬁcation models are the one-class support vector machine (OC-SVM) [26], which uses a hyperplane to separate the normal data from anomalous data; and the support vector data description (SVDD) [29], which uses a hypersphere to enclose the normal 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
data. While they have been successfully used in many real-world applications [3, 15, 32], they are often limited to data-rich scenarios so that the normal patterns can be sufﬁciently captured.
The OC-SVM and SVDD rely on the kernel trick [27] to map input features to a high-dimensional space for data separation. Motivated by the immense success of deep learning in various applications such as computer vision, speech recognition and natural language processing [12, 25], recent efforts try to integrate the powerful representation learning ability of deep networks into the traditional one-class classiﬁers. For example, deep SVDD [22] replaces the kernel-induced feature space in
SVDD by the feature space learned in a deep network. DAGMM [34] is a density-based one-class classiﬁer that integrates a deep autoencoder with the Gaussian mixture model (GMM), such that the normal data can be well-captured by the GMM in a low-dimensional latent space. As in other deep networks, these models can all be conveniently trained via back-propagation in an end-to-end manner.
The above-mentioned traditional/deep one-class classiﬁers are designed for ﬁxed-dimensional input data. It is still an open issue on how to extend them for timeseries anomaly detection. A simple approach is to run a sliding window on the timeseries data. A ﬁxed-dimensional vector containing the history information is then extracted and fed to the one-class classiﬁer. However, this fails to adequately capture the underlying temporal dependency. To alleviate this problem, a number of models based on recurrent networks have been recently proposed for timeseries anomaly detection.
An early attempt is a LSTM-based encoder-decoder model [17], and an anomaly score is deﬁned based on the reconstruction error on the timeseries. However, it suffers from error accumulation on decoding a long sequence. Other more powerful deep generative models, such as the recurrent variational autoencoder [28], and variants of the generative adversarial network (GAN) (e.g., MAD-GAN [13] and BeatGAN [33]) have also been proposed. However, training of the GAN is usually difﬁcult, and requires a careful balance between the discriminator and generator [10].
Inspired by deep SVDD, we propose in this paper the Temporal Hierarchical One-Class (THOC) network. First, it uses the dilated recurrent neural network (RNN) [2] with skip connections to efﬁciently extract multi-scale temporal features from the timeseries. Instead of using only the lowest-resolution features obtained at the top layer of the dilated RNN, THOC fuses features from all intermediate layers together by a differentiable hierarchical clustering mechanism. At each resolution, normal behaviors are represented by multiple hyperspheres. This captures the complex characteristics in real-world timeseries data, and is more powerful than the use of a single hypersphere in deep
SVDD. A multiscale support vector data description (MVDD), which is a one-class objective deﬁned based on the difference between the fused multiscale features and hypersphere centers, allows the whole model to be trained end-to-end. Finally, a novelty score, which measures how the current observation deviates from the normal behaviors represented by the hyperspheres, is used for anomaly detection on an unseen observation. Experiments performed on a number of real-world timeseries data sets show that the proposed model outperforms the recent state-of-the-arts. 2