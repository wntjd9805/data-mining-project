Abstract
Hybrid Privacy-Preserving Neural Network (HPPNN) implementing linear layers by Homomorphic Encryption (HE) and nonlinear layers by Garbled Circuit (GC) is one of the most promising secure solutions to emerging Machine Learning as a Service (MLaaS). Unfortunately, a HPPNN suffers from long inference latency, e.g., ∼ 100 seconds per image, which makes MLaaS unsatisfactory. Because
HE-based linear layers of a HPPNN cost 93% inference latency, it is critical to select a set of HE parameters to minimize computational overhead of linear layers.
Prior HPPNNs over-pessimistically select huge HE parameters to maintain large noise budgets, since they use the same set of HE parameters for an entire network and ignore the error tolerance capability of a network.
In this paper, for fast and accurate secure neural network inference, we propose an automated layer-wise parameter selector, AutoPrivacy, that leverages deep reinforcement learning to automatically determine a set of HE parameters for each linear layer in a HPPNN. The learning-based HE parameter selection policy outperforms conventional rule-based HE parameter selection policy. Compared to prior HPPNNs, AutoPrivacy-optimized HPPNNs reduce inference latency by 53% ∼ 70% with negligible loss of accuracy. 1

Introduction
Machine Learning as a Service (MLaaS) is an emerging computing paradigm that uses powerful cloud infrastructures to provide machine learning inference services to clients. However, in the setting of MLaaS, cloud servers can arbitrarily access input and output data of clients, thereby introducing privacy risks. Privacy is important when clients upload their sensitive information, e.g., healthcare records and ﬁnancial data, to cloud servers. Recent works [1, 2, 3, 4, 5] create Hybrid Privacy-Preserving Neural Networks (HPPNNs) to achieve both low inference latency and high accuracy using a combination of Homomorphic Encryption (HE) and Garbled Circuit (GC). Particularly,
DELPHI [5] obtains the state-of-the-art inference latency and accuracy through implementing linear layers by HE, and computing activation layers by GC. However, HPPNNs still suffer from long inference latency. For instance, inferring one single CIFAR-10 image by DELPHI ResNet-32 [5] costs ∼ 100 seconds and has to exchange 2GB data. Particularly, the HE-based linear layers of
DELPHI cost 93% of its inference latency, thereby becoming its performance bottleneck.
The computational overhead of HE-based linear layers in prior HPPNNs is decided by their HE parameters including the plaintext modulus p, the ciphertext modulus q, and the polynomial degree n.
HE enables homomorphic additions and multiplications on ciphertexts by manipulating polynomials whose total term number and coefﬁcients are deﬁned by p, q and n. Each HE operation introduces 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
Figure 1: The bottleneck analysis, working ﬂow and HE parameter selection of DELPHI. a small noise. Decrypting a HE output may have errors, if the total noise accumulated along a HE computation path exceeds the noise budget decided by p, q and n. Fully HE adopts bootstrapping operations to eliminate noises, and thus is not sensitive to noise budget. However, to avoid extremely slow bootstrapping operations of fully HE, prior HPPNNs use leveled HE that allows only a limited noise budget. A large noise budget requires large p, q and n, signiﬁcantly increasing computational overhead of polynomial additions and multiplications.
In order to keep a ﬁxed (and extremely small) decryption failure rate for correct ciphertext decryption, prior HPPNNs over-pessimistically assume huge noise budgets using large p, q and n. First, prior
HPPNNs do not consider the error tolerance of neural networks when deﬁning their HE parameters p, q and n. We found that a HPPNN can tolerate some decryption errors without degrading private inference accuracy. Second, prior HPPNNs assume the same p, q and n for all layers. Different layers in a neural network have different architectures, e.g., weight kernel size and output channel number, and thus different error tolerances. Therefore, assuming the same worst case HE parameters for all layers substantially increases the computational overhead of a HPPNN. However, deﬁning a set of p, q and n for each layer via hand-crafted heuristics is so complicated that even HE and machine learning experts may obtain only sub-optimal results. In this paper, we propose an automated layer-wise HE parameter selection technique, AutoPrivacy, for fast and accurate HPPNN inferences. 2