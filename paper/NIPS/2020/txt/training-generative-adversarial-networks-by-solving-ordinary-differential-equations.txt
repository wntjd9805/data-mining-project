Abstract
The instability of Generative Adversarial Network (GAN) training has frequently been attributed to gradient descent. Consequently, recent methods have aimed to tailor the models and training procedures to stabilise the discrete updates. In contrast, we study the continuous-time dynamics induced by GAN training. Both theory and toy experiments suggest that these dynamics are in fact surprisingly stable. From this perspective, we hypothesise that instabilities in training GANs arise from the integration error in discretising the continuous dynamics. We experi-mentally verify that well-known ODE solvers (such as Runge-Kutta) can stabilise training – when combined with a regulariser that controls the integration error. Our approach represents a radical departure from previous methods which typically use adaptive optimisation and stabilisation techniques that constrain the functional space (e.g. Spectral Normalisation). Evaluation on CIFAR-10 and ImageNet shows that our method outperforms several strong baselines, demonstrating its efﬁcacy. 1

Introduction
The training of Generative Adversarial Networks (GANs) [11] has seen signiﬁcant advances over the past several years. Most recently, GAN based methods have, for example, demonstrated the ability to generate images with high ﬁdelity and realism such as the work of Brock et al. [3] and Karras et al. [15]. Despite this remarkable progress, there remain many questions regarding the instability of training GANs and their convergence properties.
In this work, we attempt to extend the under-standing of GANs by offering a different per-spective. We study the continuous-time dynam-ics induced by gradient descent on the GAN ob-jective for commonly used losses. We ﬁnd that under mild assumptions, the dynamics should converge in the vicinity of a differential Nash equilibrium, and that the rate of convergence is independent of the rotational part of the dynam-ics if we can follow the dynamics exactly. We thus hypothesise that the instability in training
GANs arises from discretisation of the continu-ous dynamics, and we should focus on accurate integration to impart stability.
Figure 1: Left: divergence of integration with Eu-ler’s method – for a strong rotational ﬁeld, step-size 0.01. Right: convergence with a second-order
ODE solver (Heun’s method) under the same step size and vector ﬁeld. For details see Section 3.2.2.
Consistent with this hypothesis, we demonstrate that we can use standard methods for solving ordinary differential equations (ODEs) – such as Runge-Kutta – to solve for GAN parameters. In particular, we observe that more accurate time integration of the ODE yields better convergence as well as better 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
performance overall; a result that is perhaps surprising given that the integrators have to use noisy gradient estimates. We ﬁnd that the main ingredient we need for stable GAN training is to avoid large integration errors, and a simple regulariser on the generator gradients is sufﬁcient to achieve this.
This alleviates the need for hard constraints on the functional space of the discriminator (e.g. spectral normalisation [21]) and enables GAN training without advanced optimisation techniques.
Overall, the contributions of this paper are as follows:
• We present a novel and practical view that frames GAN training as solving ODEs.
• We design a regulariser on the gradients to improve numerical integration of the ODE.
• We show that higher-order ODE solvers lead to better convergence for GANs. Surprisingly, our algorithm (ODE-GAN) can train GANs to competitive levels without any adaptive optimiser (e.g., Adam [16]) and explicit functional constraints (Spectral Normalisation). 2