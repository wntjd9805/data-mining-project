Abstract
In real-world classiﬁcation tasks, each class often comprises multiple ﬁner-grained
“subclasses.” As the subclass labels are frequently unavailable, models trained using only the coarser-grained class labels often exhibit highly variable performance across different subclasses. This phenomenon, known as hidden stratiﬁcation, has important consequences for models deployed in safety-critical applications such as medicine. We propose GEORGE, a method to both measure and mitigate hidden stratiﬁcation even when subclass labels are unknown. We ﬁrst observe that unlabeled subclasses are often separable in the feature space of deep models, and exploit this fact to estimate subclass labels for the training data via clustering techniques. We then use these approximate subclass labels as a form of noisy supervision in a distributionally robust optimization objective. We theoretically characterize the performance of GEORGE in terms of the worst-case generalization error across any subclass. We empirically validate GEORGE on a mix of real-world and benchmark image classiﬁcation datasets, and show that our approach boosts worst-case subclass accuracy by up to 14 percentage points compared to standard training techniques, without requiring any information about the subclasses. 1

Introduction
In many real-world classiﬁcation tasks, each labeled class consists of multiple semantically distinct subclasses that are unlabeled. Because models are typically trained to maximize global metrics such as average performance, they often underperform on important subclasses [52, 40]. This phenomenon—recently termed hidden stratiﬁcation—can lead to skewed assessments of model quality and result in unexpectedly poor performance when models are deployed [36]. For instance, a medical imaging model trained to classify between benign and abnormal lesions may achieve high overall performance, yet consistently mislabel a rare but critical abnormal subclass as “benign” [17].
Modern robust optimization techniques can improve performance on poorly-performing groups when the group identities are known [43]. However, in practice, a key obstacle is that subclasses are often unlabeled, or even unidentiﬁed. This makes even detecting such performance gaps—let alone mitigating them—a challenging problem. Nevertheless, recent empirical evidence [36] encouragingly suggests that feature representations of deep neural networks often carry information about unlabeled subclasses (see Figure 1). Motivated by this observation, we propose a method for addressing hidden stratiﬁcation, by both measuring and improving worst-case subclass performance in the setting where subclass labels are unavailable. Our work towards this is organized into four main sections.
First, in Section 3 we propose a simple generative model of the data labeling process. Using this model, we show that when label annotations are insufﬁciently ﬁne-grained—as is often the case in real-world datasets—hidden stratiﬁcation can naturally arise. For instance, an image classiﬁcation task might be to classify birds vs. frogs; if labels are only provided for these broad classes, they may 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
fail to capture visually meaningful ﬁner-grained, intra-class variation (e.g., “bird in ﬂight” versus
“bird in nest”). We show that in the setting of our generative model, standard training via empirical risk minimization (ERM) can result in arbitrarily poor performance on underrepresented subclasses.
Second, in Section 4 we use insights from this gen-erative model to motivate GEORGE, a two-step pro-cedure for alleviating hidden stratiﬁcation by ﬁrst estimating the subclass labels and then exploiting these estimates to train a robust classiﬁer. To esti-mate subclass labels, we train a standard model on the task, and split each class (or “superclass,” for clarity) into estimated subclasses via unsupervised clustering in the model’s feature space. We then ex-ploit these estimated subclasses by training a new model to optimize worst-case performance over all estimated subclasses using group distributionally ro-bust optimization (GDRO [43]).
In this way, our framework allows ML practitioners to automatically detect poorly-performing subclasses and improve per-formance on them, without needing to resort to ex-pensive manual relabeling of the data.
Figure 1: Benign class examples in the fea-ture space of a model classfying skin lesions as benign or malignant. Benign examples containing a brightly colored patch (blue) and those without a patch (red) are separable in model feature space, even though the labels do not specify the presence of patches.
Third, in Section 5 we use our generative framework to prove that—under conditions on the data distribution and the quality of the recovered clusters—
GEORGE can reduce the subclass performance gap, attaining the same asymptotic sample complexity rates as if the true subclass labels were known.
Fourth, in Section 6 we empirically validate the ability of GEORGE to both measure and mitigate hidden stratiﬁcation on four image classiﬁcation tasks, comprising both robustness benchmarks and real-world datasets. We show that the ﬁrst step of GEORGE—training an ERM model and clustering the superclass features—often recovers clusters that align closely with true subclasses. We evaluate the ability of these clusters to measure the worst-case subclass (i.e., “robust”) performance: on average, the gap between worst-case cluster performance and worst-case subclass performance is less than 40% of the gap between overall and worst-case subclass performance, indicating that
GEORGE enables more accurate measurement of robust performance. Next, we show that the second stage of GEORGE—retraining a robust model using cluster assignments as proxy subclass labels— reduces average worst-case subclass error rates by over 23%. For comparison, the state-of-the-art
“oracle” GDRO method that does require subclass labels [43] reduces average worst-case subclass error rates by 50%. As an extension, we show that leveraging recent pretrained image embeddings
[27] for clustering can substantially further improve the robust performance of GEORGE, in some cases to match the performance of GDRO trained using the true subclass labels. 2