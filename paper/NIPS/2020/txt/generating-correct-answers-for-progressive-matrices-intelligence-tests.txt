Abstract
Raven’s Progressive Matrices are multiple-choice intelligence tests, where one tries to complete the missing location in a 3 × 3 grid of abstract images. Previous attempts to address this test have focused solely on selecting the right answer out of the multiple choices. In this work, we focus, instead, on generating a correct answer given the grid, without seeing the choices, which is a harder task, by deﬁnition. The proposed neural model combines multiple advances in generative models, including employing multiple pathways through the same network, using the reparameterization trick along two pathways to make their encoding compatible, a dynamic application of variational losses, and a complex perceptual loss that is coupled with a selective backpropagation procedure. Our algorithm is able not only to generate a set of plausible answers, but also to be competitive to the state of the art methods in multiple-choice tests. 1

Introduction
Multiple choice questions provide the examinee with the ability to compare the answers, in order to eliminate some choices, or even guess the correct one. Even when validating the choices one by one, the examinee can beneﬁt from comparing each choice with the query and infer patterns that would have been missed otherwise. Indeed, it is the ability to synthesize de-novo answers from the space of correct answers that is the ultimate test for the understanding of the question.
In this work, we consider the task of generating a correct answer to a Raven Progressive Matrix (RPM) type of intelligence test [8, 2]. Each query (a single problem) consists of eight images placed on a grid of size 3 × 3. The task is to generate the missing ninth image, which is on the third row of the third column, such that it matches the patterns of the rows and columns of the grid.
The method we developed has some similarities to previous methods that recognize the correct answer out of eight possible choices. These include encoding each image and aggregating these encodings along rows and columns. However, the synthesis problem demands a new set of solutions.
Our architecture combines three different pathways: reconstruction, recognition, and generation. The reconstruction pathway provides supervision, that is more accessible to the network when starting to train, than the other two pathways, which are much more semantic. The recognition pathway shapes the representation in a way that makes the semantic information more explicit. The generation pathway, which is the most challenging one, relies on the embedding of the visual representation from the ﬁrst task, and on the semantic embedding obtained with the assistance of the second, and maps the semantic representation of a given query to an image.
In the intersection of the reconstruction and the generation pathways, two embedding distributions need to become compatible. This is done through variational loss terms on the two paths. Since there are many different answers for every query, the variational formulation is also used to introduce randomness. However, since the representation obtained from the generation task is conditioned on a 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
Figure 1: Example of a PGM problem with a 3 × 3 grid and 8 choices.
Figure 2: Each row has equivalent answers for some attribute (from top: shape type, shape num-ber, and line color) complex pattern, uniform randomness can be detrimental. For this reason, we present a new form of a variational loss, which varies dynamically for each condition, to support partial randomness.
Due to the non-deterministic nature of the problem and to the high-level reasoning required, the generation pathway necessitates a semantic loss. For this reason, we employ a perceptual loss that is based on the learned embedding networks. Since the suitability of the generated image is only exposed in the context of the row and column to which it belongs, the perceptual representation requires a hierarchical encoding.
Given the perceptual representation, a contrastive loss is used to compare the generated image to both the correct, ground truth, choice images, as well as to the other seven distractors. Since the networks that encode the images and subsequently the rows and columns also deﬁne the context embedding for the image generation, backpropogration needs to be applied with care. Otherwise, the networks that deﬁne the perceptual loss would adapt in order to reduce the loss, instead of the generating pathway that we wish to improve.
Our method presents very convincing generation results. The state of the art recognition methods regard the generated answer as the right one in a probability that approaches that of the ground truth answer. This is despite the non-deterministic nature of the problem, which means that the generated answer is often completely different pixel-wise from the ground truth image. In addition, we demonstrate that the generation capability captures most rules, with little neglect of speciﬁc ones.
Finally, the recognition network, which is employed to provide an auxiliary loss, is almost as effective as the state of the art recognition methods. 2