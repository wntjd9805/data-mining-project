Abstract
The rapid proliferation of decentralized learning systems mandates the need for differentially-private cooperative learning. In this paper, we study this in context of the contextual linear bandit: we consider a collection of agents cooperating to solve a common contextual bandit, while ensuring that their communication remains private. For this problem, we devise FEDUCB, a multiagent private algorithm for both centralized and decentralized (peer-to-peer) federated learning. We provide a rigorous technical analysis of its utility in terms of regret, improving several results in cooperative bandit learning, and provide rigorous privacy guarantees as well.
Our algorithms provide competitive performance both in terms of pseudoregret bounds and empirical benchmark performance in various multi-agent settings. 1

Introduction
The multi-armed bandit is the classical sequential decision-making problem, involving an agent sequentially choosing actions to take in order to maximize a (stochastic) reward [44]. It embodies the central exploration-exploitation dilemma present in sequential decision-making. Practical applications of the multi-armed bandit range from recommender systems [52] and anomaly detection [11] to clinical trials [15] and ﬁnance [24]. Increasingly, however, such large-scale applications are becoming decentralized, as their data is often located with different entities, and involves cooperation between these entities to maximize performance [14, 22]. This paradigm is now known as federated learning1.
The objective of the federated paradigm is to allow cooperative estimation with larger amounts of data (from multiple clients, devices, etc.) while keeping the data decentralized [27]. There has been a surge of interest in this problem from both academia and industry, owing to its overall applicability. Most research on provably private algorithms in the federated setting has been on distributed supervised learning [28] and optimization [20]. The contextual bandit problem, however, is a very interesting candidate for private methods, since the involved contexts and rewards both typically contain sensitive user information [38]. There is an increasing body of work on online learning and multi-armed bandits in cooperative settings [13, 31, 39], and private single-agent learning [41, 38], but methods for private federated bandit learning are still elusive, despite their immediate applicability.
Contributions. In this paper, we study the federated contextual bandit problem under constraints of differential privacy. We consider two popular paradigms: (a) centralized learning, where a central controller coordinates different clients [27, 49] and (b) decentralized peer-to-peer learning with delays, where agents communicate directly with each other, without a controller [39, 31, 30, 32]. We provide a rigorous formulation of (ε, δ)-differential privacy in the federated contextual bandit, and present two variants of FEDUCB, the ﬁrst federated algorithm ensuring that each agent is private with respect to the data from all other agents, and provides a parameter to control communication. 1Originally, federated learning referred to the algorithm proposed in [28] for supervised learning, however, now the term broadly refers to the distributed cooperative learning setting [27]. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
Next, we prove rigorous bounds on the cumulative group pseudoregret obtained by FEDUCB.
In the centralized setting, we prove a high probability regret bound of (cid:101)O(d3/4(cid:112)M T /ε) which matches the non-private bound in terms of its dependence on T and M .
In the decentralized case, we prove a corresponding regret bound of (cid:101)O(d3/4(cid:112)(diameter(G))M T /ε), where G is the communication network between agents. In addition to the regret bounds, we present a novel analysis of communication complexity, and its connections with the privacy budget and regret. 2