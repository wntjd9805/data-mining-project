Abstract
As a fundamental issue in lifelong learning, catastrophic forgetting is directly caused by inaccessible historical data; accordingly, if the data (information) were memorized perfectly, no forgetting should be expected. Motivated by that, we propose a GAN memory for lifelong learning, which is capable of remembering a stream of datasets via generative processes, with no forgetting. Our GAN memory is based on recognizing that one can modulate the “style” of a GAN model to form perceptually-distant targeted generation. Accordingly, we propose to do sequential style modulations atop a well-behaved base GAN model, to form sequential targeted generative models, while simultaneously beneﬁting from the transferred base knowledge. The GAN memory – that is motivated by lifelong learning – is therefore itself manifested by a form of lifelong learning, via forward transfer and modulation of information from prior tasks. Experiments demonstrate the superiority of our method over existing approaches and its effectiveness in alleviating catastrophic forgetting for lifelong classiﬁcation problems. Code is available at https:// github.com/MiaoyunZhao/GANmemory_LifelongLearning. 1

Introduction
Lifelong learning (or continual learning) is a long-standing challenge for machine learning and artiﬁcial intelligence systems [76, 28, 73, 11, 14, 60], concerning the ability of a model to continually learn new knowledge without forgetting previously learned experiences. An important issue associated with lifelong learning is the notorious catastrophic forgetting of deep neural networks [48, 36, 87], i.e., training a model with new information severely interferes with previously learned knowledge.
To alleviate catastrophic forgetting, many methods have been proposed, with most focusing on discriminative/classiﬁcation tasks [36, 65, 95, 55, 94]. Reviewing existing methods, [77] revealed generative replay (or pseudo-rehearsal) [72, 69, 86, 66, 88] is an effective and general strategy for lifelong learning, with this further supported by [40, 78]. That revelation is anticipated, for if the characteristics of previous data are remembered perfectly (e.g., via realistic generative replay), no forgetting should be expected for lifelong learning. Compared with the coreset idea, that saves representative samples of previous data [55, 65, 11], generative replay has advantages in addressing privacy concerns and remembering potentially more complete data information (via the generative process). However, most existing generative replay methods either deliver blurry generated samples
[10, 40] or only work well on simple datasets [40, 78, 40] like MNIST; besides, they often don’t scale well to practical situations with high resolution [60] or a long sequence [86], sometimes even with negative backward transfer [96, 82]. Therefore, it’s challenging to continually learn a well-behaved generative replay model [40], even for moderately complex datasets like CIFAR10.
We seek a realistic generative replay framework to alleviate catastrophic forgetting; going further, we consider developing a realistic generative memory with growing (expressive) power, believed to be a fundamental building block toward general lifelong learning systems. We leverage the popular
∗Equal Contribution. Correspondence to: Miaoyun Zhao <miaoyun9zhao@gmail.com>. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
GAN [25] setup as the key component of that generative memory, which we term GAN memory, because (i) GANs have shown remarkable power in synthesizing realistic high-dimensional samples
[9, 51, 33, 34]; (ii) by modeling the generative process of training data, GANs summarize the data statistical information in the model parameters, consequently also protecting privacy (the original data need not be saved); and (iii) a GAN often generates realistic samples not observed in training data, delivering a synthetic data augmentation that potentially beneﬁts better performance of downstream tasks [80, 8, 9, 21, 33, 26, 27]. Distinct from existing methods, our GAN memory leverages transfer learning [6, 16, 46, 92, 58] and (image) style transfer [18, 30, 41]. Its key foundation is a discovery that one can leverage the modiﬁed variants of style-transfer techniques [64, 98] to modulate a source generator/discriminator into a powerful generator/discriminator for perceptually-distant target domains (see Section 4.1), with a limited amount of style parameters. Exploiting that discovery, our GAN memory sequentially modulates (and also transfers knowledge from) a well-behaved base/source GAN model to realistically remember a sequence of (target) generative processes with no forgetting. Note by “well-behaved” we mean the shape of source kernels is well trained (see
Section 4.1 for details); empirically, this requirement can be readily satisﬁed if (i) the source model is pretrained on a (moderately) large dataset (e.g., CelebA [43]; often a dense dataset is preferred
[85]) and (ii) it’s sufﬁciently trained and shows relatively high generation quality. Therefore, many pretrained GANs can be “well-behaved”,2 showing great ﬂexibility in selecting the base/source model.
Our experiments will show that ﬂexibility roughly means source and target data should have the same data type (e.g., images).
Our GAN memory serves as a solution to the fundamental memory issue of general lifelong learning, and its construction also leverages a form of lifelong learning.
In practice, the GAN memory can be used, for example, as a realistic generative replay to alleviate catastrophic forgetting for challenging downstream tasks with high-dimensional data and a long (and varying) task sequence.
Our contributions are as follows.
• Based on FiLM [64] and AdaFM [98], we develop modiﬁed variants, termed mFiLM and mAdaFM, to better adapt/transfer the source fully connected (FC) and convolutional (Conv) layers to target domains, respectively. We demonstrate that mFiLM and mAdaFM can be leveraged to modulate the “style” of a source GAN model (including both the generator and discriminator) to form a generative/discriminative model capable of addressing a perceptually-distant target domain.
• Based on the above discovery, we propose our GAN memory, endowed with growing (expressive) generative power, yet with no forgetting of existing capabilities, by leveraging a limited amount of task-speciﬁc style parameters. We analyze the roles played by those style parameters and reveal their further compressibility.
• We generalize our GAN memory to its conditional variant, followed by empirically verifying its effectiveness in delivering realistic synthesized samples to alleviate catastrophic forgetting for challenging lifelong classiﬁcation tasks. 2