Abstract
A conventional camera often suffers from over- or under-exposure when recording a real-world scene with a very high dynamic range (HDR). In contrast, a mod-ulo camera with a Markov random ﬁeld (MRF) based unwrapping algorithm can theoretically accomplish unbounded dynamic range but shows degenerate perfor-mances when there are modulus-intensity ambiguity, strong local contrast, and color misalignment. In this paper, we reformulate the modulo image unwrapping problem into a series of binary labeling problems and propose a modulo edge-aware model, named as UnModNet, to iteratively estimate the binary rollover masks of the modulo image for unwrapping. Experimental results show that our approach can generate 12-bit HDR images from 8-bit modulo images reliably, and runs much faster than the previous MRF-based algorithm thanks to the GPU acceleration. 1

Introduction
Real-world scenes have a very high dynamic range (HDR) so that object contours are mostly lost in the over-exposed and under-exposed regions when captured by a conventional camera with a limited dynamic range and saved as an 8-bit image. To increase the dynamic range of captured images, many
HDR reconstruction approaches have been proposed to increase the camera bit depth via hardware modiﬁcations [22, 36], as well as using computational methods to merge multi-bracketed captures
[5] or a series of bursts [17]. Yet the dynamic range they can achieve is limited and the details of the
HDR content often cannot be faithfully recovered. A modulo camera [59] can theoretically achieve unbounded dynamic range by recording the least signiﬁcant bits of the irradiance signal, i.e., the camera hardware “resets” the scene radiance arriving at the sensor before reading it out whenever it reaches saturation (e.g., for an 8-bit image, 256 will be reset to 0 and re-start the counting again as long as the shutter keeps open). By unwrapping the captured modulo image with a customized
Markov random ﬁeld (MRF) based algorithm, the HDR image could be practically restored, as shown in Figure 1 (top left). We denote the irradiance of an HDR image as I = {I(x, y, c)}, and its corresponding modulo image as Im = {Im(x, y, c)}, where (x, y) is the pixel coordinate and c denotes the color channel index. Im is equivalent to the least signiﬁcant N bits of I. As illustrated in the bottom row of Figure 1, their relationship can be expressed as:
Im = mod(I, 2N ) or
I = Im + 2N · K, (1) where K = {K(x, y, c)} is the number of rollovers per pixel.
∗Corresponding author. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
Figure 1: Top left: a modulo camera mods (“resets”) the scene radiance and turns it into a modulo image, and the HDR reconstruction algorithm unwraps the modulo image back to the ground truth.
Top right: fundamental problems of the MRF-based algorithm [59] and how the proposed UnModNet solves these issues; blue, red, and yellow boxes highlight examples for modulus-intensity ambiguity, strong local contrast, and color misalignment, respectively. Bottom row: the relationship between the ground truth HDR image I, the modulo image Im (examples of modulo fringes are marked with green arrows), and the number of rollovers K (linearly scaled to [0, 255] for visualization) in
Equation (1).
However, as shown in Figure 1 (top right), the MRF-based unwrapping algorithm [59] is not robust due to several fundamental issues: (1) Modulus-intensity ambiguity. It is difﬁcult to discriminate whether a pixel value is a modulus or an intensity (non-modulus). The previous method would often incorrectly unwrap non-modulo pixels as it used a cost function without a data term during optimization. (2) Strong local contrast. Dense modulo fringes (marked with green arrows in the bottom row of Figure 1) are usually caused by strong local contrast in irradiance. The previous method often fails around these regions as it only focused on local smoothness and ignored contextual information and structural patterns. (3) Color misalignment. The previous method independently unwraps each color channel, resulting in severe color misalignment artifacts across three channels, so it cannot handle
RGB images robustly.
In this paper, we reformulate the unwrapping of a modulo image into a series of binary labeling problems and propose a learning-based framework named UnModNet, as shown in Figure 2, to iteratively estimate the binary rollover mask of the input modulo image. Concretely, we have some key observations on the characteristics of modulo images: continuous irradiance regions are split up by the modulo operation, resulting in a large edge magnitude around modulo fringes; the over-exposed regions are concentratedly distributed in an image, which makes the modulo pixels likely to cluster in local regions. Based on these unique features of modulo pixels and edges, we design UnModNet to be two-stage accordingly: the ﬁrst stage is a modulo edge separator that estimates channel-wise edges unique to modulo images; the second stage is a rollover mask predictor that achieves high-accuracy rollover mask prediction with the guidance of modulo edges.
To summarize, our learning strategy for modulo image unwrapping proposes three customized model designs to solve the three issues in the previous MRF-based algorithm [59] as follows: (1) Modulo edge separator is proposed to distinguish the semantic and boundary information of the scene to relieve the modulus-intensity ambiguity and indicate correct regions to unwrap in a context-aware manner. (2) Rollover mask predictor is adopted to deal with strong local contrast and dense modulo fringes to increase the capability of unwrapping a higher dynamic range in a structure-aware manner. 2
(3) Consistent color prediction is achieved by joint unwrapping across RGB channels, so that our model restores natural color appearance reliably.
Experimental results show that our approach can generate 12-bit HDR images from 8-bit modulo images reliably, and runs much faster than the previous MRF-based algorithm [59] thanks to the GPU acceleration. 2