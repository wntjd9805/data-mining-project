Abstract
Non-local self-similarity in natural images has been well studied as an effective prior in image restoration. However, for single image super-resolution (SISR), most existing deep non-local methods (e.g., non-local neural networks) only exploit similar patches within the same scale of the low-resolution (LR) input image.
Consequently, the restoration is limited to using the same-scale information while neglecting potential high-resolution (HR) cues from other scales. In this paper, we explore the cross-scale patch recurrence property of a natural image, i.e., similar patches tend to recur many times across different scales. This is achieved using a novel cross-scale internal graph neural network (IGNN). Speciﬁcally, we dynamically construct a cross-scale graph by searching k-nearest neighboring patches in the downsampled LR image for each query patch in the LR image. We then obtain the corresponding k HR neighboring patches in the LR image and aggregate them adaptively in accordance to the edge label of the constructed graph.
In this way, the HR information can be passed from k HR neighboring patches to the LR query patch to help it recover more detailed textures. Besides, these internal image-speciﬁc LR/HR exemplars are also signiﬁcant complements to the external information learned from the training dataset. Extensive experiments demonstrate the effectiveness of IGNN against the state-of-the-art SISR methods including existing non-local networks on standard benchmarks. 1

Introduction
The goal of single image super-resolution (SISR) [9] is to recover the sharp high-resolution (HR) counterpart from its low-resolution (LR) observation. Image SR is an ill-posed problem, since there are multiple HR solutions for a LR input. To solve this inverse problem, many convolutional neural networks (CNNs) [6, 38, 17, 23, 43, 13, 5] have been proposed to capture useful priors by learning mappings between LR and HR images. While immense performance has been achieved, learning from external training data solely still falls short in recovering detailed textures for speciﬁc images, especially when the up-scaling factor is large.
Apart from exploiting external paired data, internal image-speciﬁc information [30] has also been widely studied in image restoration. Some classical non-local methods [2, 4, 25, 10] have shown the values of capturing correlation among non-local self-similar patches for improving the restoration quality. However, convolutional operations are not able to capture such patterns due to the locality of convolutional kernels. Though the receptive ﬁelds are large in the deep networks, some long-range dependencies still cannot be well maintained. Inspired by the classical non-local means method [2], non-local neural networks [37] are proposed to capture long-range dependencies for video classiﬁcation. Non-local neural networks are thereafter introduced to image restoration tasks [24, 44].
∗Corresponding Author. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
These methods, in general, perform self-attention weighting of full connection among positions in the features. Besides non-local neural networks, the neural near-est neighbors network [29] and graph-convolutional denoiser network [36] have been proposed to aggregate k nearest neigh-boring patches for image restoration. How-ever, all these methods only exploit cor-relations of recurrent patches within the same scale, without harvesting any high-resolution information. Different from im-age denoising, the aggregation of multiple similar patches at the same scale (subpixel misalignments) only improves the perfor-mance slightly for SR.
Figure 1: Example of patch recurrence across scales of a single image (a), and illustration of Graph Construction (b) and Patch Aggregation (c) in the image domain. The IL and
IL↓s are input LR image and its s downsampled counterpart.
Gk is the constructed cross-scale graph and IL↑s is the patch aggregated result with LR↑s scale.
The proposed the cross-scale internal graph neural network (IGNN) is inspired by the traditional self-example based SR methods [7, 3, 14]. Our IGNN is based on cross-scale patch recurrence property veriﬁed statistically in [46, 9, 28] that patches in a natural image tend to recur many times across scales. An illustrative example is shown in Figure 1 (a). Given a query patch (yellow square) in the
LR image IL, many similar patches (solid-marked green squares) can be found in the downsampled image IL↓s. Thus the corresponding HR patches (dashed-marked green squares) in the LR image
IL can also be obtained. Such cross-scale patches provide an indication of what the unknown HR patches of the query patch might look like. The cross-scale patch recurrence property is previously utilized as example-based SR constraints to estimate a HR image [9, 40] or a SR kernel [28].
In this paper, we model this internal correlations between cross-scale similar patches as a graph, where every patch is a vertex and the edge is similarity-weighted connection of two vertexes from two different scales. Based on this graph structure, we then present our IGNN to process this irregular graph data and explore cross-scale recurrence property effectively. Instead of using this property as constraints [9, 28], IGNN intrinsically aggregates HR patches using the proposed graph module, which includes two operations: graph construction and patch aggregation. More speciﬁcally, as shown in Figure 1 (b)(c), we ﬁrst dynamically construct a cross-scale graph Gk by searching k-nearest neighboring patches in the downsampled LR image IL↓s for each query patch in the LR image IL.
After mapping the regions of k neighbors from IL↓s to IL scale, the constructed cross-scale graph
Gk can provide k LR/HR patch pairs for each query patch. In Gk, the vertexes are the patches in LR image IL and their k HR neighboring patches and the edges are correlations of these matched LR/HR patches. Inspired by Edge-Conditioned Convolution [31], we formulate an edge-conditioned patch aggregation operation based on the graph Gk. The operation aggregates k HR patches conditioned on edge labels (similarity of two matched patches). Different from previous non-local methods that explore and aggregate neighboring patches at the same scale, we search for similar patches at the downsampled LR scale but aggregate HR patches. It allows our network to perform more efﬁciently and effectively for SISR.
The proposed IGNN obtains k image-speciﬁc LR/HR patch correspondences as helpful complements to the external information learned from a training dataset. Instead of learning a LR-to-HR mapping only from external data as other SR networks do, the proposed IGNN makes full use of k most likely
HR counterparts found from the LR image itself to recover more detailed textures. In this way, the ill-posed issue in SR can be alleviated in IGNN. We thoroughly analyze and discuss the proposed graph module via extensive ablation studies. The proposed IGNN performs favorably against state-of-the-art CNN-based SR baselines and existing non-local neural networks, demonstrating the usefulness of cross-scale graph convolution for image super-resolution. 2 Methodology
In this section, we start by brieﬂy reviewing the general formulation of some previous non-local methods. We then introduce the proposed cross-scale graph aggregation module (GraphAgg) based on graph message aggregation methods [8, 11, 19, 42, 31]. Built on GraphAgg module, we ﬁnally present our cross-scale internal graph neural network (IGNN). 2
2.1