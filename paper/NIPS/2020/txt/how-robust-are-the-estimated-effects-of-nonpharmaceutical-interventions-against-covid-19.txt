Abstract
To what extent are effectiveness estimates of nonpharmaceutical interventions (NPIs) against COVID-19 inﬂuenced by the assumptions our models make? To answer this question, we investigate 2 state-of-the-art NPI effectiveness models and propose 6 variants that make different structural assumptions. In particular, we investigate how well NPI effectiveness estimates generalise to unseen countries, and their sensitivity to unobserved factors. Models that account for noise in disease transmission compare favourably. We further evaluate how robust estimates are to different choices of epidemiological parameters and data. Focusing on models that assume transmission noise, we ﬁnd that previously published results are remarkably robust across these variables. Finally, we mathematically ground the interpretation of NPI effectiveness estimates when certain common assumptions do not hold. 1

Introduction
Nonpharmaceutical interventions (NPIs), such as business closures, gathering bans, and stay-at-home orders, are a central part of the ﬁght against COVID-19. Yet it is largely unknown how effective different NPIs are at reducing transmission [2, 7]. With a global rise of COVID-19 cases and an unknown number of waves to come, better understanding is urgently needed to guide policy. Indeed, knowing the effectiveness of different NPIs would enable countries to efﬁciently suppress the disease without imposing unnecessary burden on the population.
Data-driven NPI modelling is one of the best approaches for inferring NPI effect sizes. These models assume that the implementation of an NPI affects the course of a country’s epidemic in a particular way. Then, using publicly available incidence and fatality data, as well as a list of NPIs with their implementation dates, the NPI model can be inverted, yielding NPI effectiveness estimates.
⇤Equal contribution.
Correspondence to <mrinank@robots.ox.ac.uk>, <soren.mindermann@cs.ox.ac.uk>,
<jan.brauner@cs.ox.ac.uk>. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
However, it is impossible to construct a model without making assumptions. Given the importance and the policy-relevance of NPI effectiveness estimates, we must ask to what extent are our NPI effectiveness estimates inﬂuenced by the assumptions our models make? If our estimates ﬂuctuate widely under different plausible assumptions, our results cannot be used to inform policy.
Additionally, it is challenging to collect data about NPI implementation dates in several countries, so all analyses are limited to a subset of countries. Also, epidemiological parameters describing COVID are required by NPI effectiveness models, but they are only known with uncertainty. In order for effectiveness estimates to be used by policymakers, we must also assess their robustness to these factors.
To address these challenges, we empirically investigate the inﬂuence of common assumptions made by NPI effectiveness models. We build on previous state of the art NPI effectiveness models [2, 7] and construct 6 variants that make different structural assumptions. Without access to ground-truth
NPI effectiveness estimates, we evaluate models by assessing how well their estimates generalise to unseen countries, and how much their estimates are inﬂuenced by unobserved factors. We ﬁnd that assuming transmission noise yields more robust estimates that also generalise better.
Furthermore, we systematically validate all of our models, assessing how sensitive NPI effectiveness estimates are to variations in the input data and assumed epidemiological parameters. We ﬁnd that systematic trends in effectiveness estimates obtained from our models when varying model structure, data, and epidemiological parameters. In particular, closing schools and universities in conjunction was consistently highly effective; the effect size of stay-at-home orders is modest; the additional beneﬁt of closing most nonessential businesses was smaller than targeted closures of high exposure businesses; and the effectiveness of gathering bans increased as the maximum gathering size decreased. Our model implementations and sensitivity analyses can be found at https://github.com/epidemics/COVIDNPIs/tree/neurips.
Finally, we mathematically ground the interpretation of NPI effectiveness estimates when common assumptions do not hold. In particular, we conclude that our estimates should be interpreted as average, marginal effectiveness estimates, where the average is taken over the situations in which each NPI was active. As such, we urge caution in interpreting results from data driven NPI effectiveness models.
For instance, mask-wearing mandates for (some) public spaces were only activated in our data when several other NPIs were also activated. Therefore, we can only reason about the effectiveness of mask-wearing mandates in the presence of many other NPIs.
We hope that these results will advance understanding and best practices of COVID-19 NPI effective-ness models, ultimately helping countries efﬁciently suppress virus transmission.
Disclaimer. Note that this paper uses the same data as our previous work [2] (medRvix Version 4) and references previously reported results in several places. While our latest results use an updated dataset and model, the results in this paper have not been updated. The difference does not affect the claims made here. The exact models and data used to produce these results can be found on Github. 2 Common assumptions in NPI modelling
To investigate the inﬂuence of speciﬁc assumptions, we must ﬁrst understand why these assumptions are made. To infer NPI effect sizes, data-driven NPI effectiveness models must somehow link the course of a country’s epidemic to NPI implementation dates. Fig. 1 broadly outlines the approach that our models take. In short, these models assume that implementing an effective NPI immediately reduces transmission of COVID-19. This transmission is measured using the reproduction number,
R. R is the expected number of people directly infected by one infected person. Therefore, given a list of NPIs, their effectiveness estimates, and an estimate of the transmission that occurs when no
NPIs are active (the basic reproduction number, R0), we can compute R on a speciﬁc day.
However, R is insufﬁcient to calculate the number of infections on a particular day; we also need to know the time delay between a person becoming infected and then subsequently infecting R others. This is the Generation Interval (GI), but published estimates vary and often depend on the speciﬁc country studied. Furthermore, we also need to know the time delay between infection and case/death reporting to link the number of infections to the number of reported cases and deaths (our observations). These time delays are also only known with uncertainty. 2
Figure 1: Approach Overview. Data-driven NPI effectiveness models assume that interventions affect the course of a country’s epidemic. Note: the right subplot shows simulated data with only one
NPI. In reality, most countries implemented several NPIs, in different orders.
Without making assumptions, our models would be unable to infer NPI effectiveness estimates. The key question we seek to answer is not whether these assumptions hold in reality (since they do not), but rather the extent to which our results are the product of a particular assumption.
We proceed by collecting and reviewing the assumptions of our previous work [2]. We then propose alternative plausible assumptions that would lead to different models. We discuss key assumptions in this section, but include a more detailed discussion in the Supplement (Section A.5).
Notation. We index time with t and country with c. The reproduction number R is the expected number of infections caused by one infection (if all members of the population were susceptible).
The basic reproduction number for country c (i.e., R in the absence of any observed NPIs) is R0,c.
The time-varying (instantaneous [8]) reproduction number at time t in country c is Rt,c, which we use as the measure of transmission. xi,t,c are binary NPI activation features with xi,t,c = 1 indicating that NPI i is active in country c at time t. y(C) t,c and y(D) represent the number of daily reported cases t,c
. Nt,c represents (constant-scaled) numbers and deaths respectively. The set of NPIs is denoted as
I
R parameterises the effectiveness of NPI i and ↵i > 0 is interpreted of new daily infections. ↵i 2 as NPI i being effective. Superscript (C) represents terms corresponding to reported cases, while superscript (D) corresponds to reported deaths. 2.1 Default Model Outline
To link NPI implementation dates to reported cases and deaths, our models require knowledge of
COVID-19. For example, the generation interval describes the time between successive infection events. Further, we also need to know the delay between infection and case/death reporting i.e., the time delay between a person becoming infected, and their case/death being reported in national statistics. Since these delays vary across countries and over time, they are difﬁcult to estimate. This motivates the following assumption.
Assumption 1. Epidemiological parameters are constant across countries and time [7, 1, 3, 22, 28, 2].
We also need to link NPI implementation and effectiveness estimates to our measure of COVID-19 transmission, Rt,c. This is a challenging task. In reality, NPI effectiveness will vary over time as adherence changes, and will also depend on the speciﬁc NPI implementation in a particular country.
For instance, some countries required residents to complete a form to leave their home during a stay-at-home order, whilst others did not. A common approach to address this is to pool estimates across countries and time, which motivates the following assumptions.
Assumption 2 (Constant NPI Effectiveness). (a) The effectiveness of NPI i is independent of country
[7, 1, 3, 28, 2]. (b) The effectiveness of NPI i is independent of time [7, 1, 3, 28, 2].
In addition, the effectiveness of different NPIs may depend on the other active interventions. Social distancing measures may reduce the effectiveness of mandatory mask wearing. However, our data is 3
limited. Since we don’t observe all combinations of NPIs in each country, it is challenging to model
NPI interactions. Instead, it is common to assume multiplicative, independent NPI effects.
Assumption 3 (Multiplicative NPI Effects). NPIs have multiplicative effects on Rt,c [7, 1, 3, 2].
Assumption 4 (No NPI Interactions). The effectiveness of NPI i is independent of the other NPIs that are active [7, 1, 5, 2].
Finally, many factors will affect COVID-19 transmission, such as behavioural change and unrecorded interventions. However, our models assume that only observed NPIs inﬂuence Rt.
Assumption 5 (No Unobserved Factors). Rt,c depends only on R0,c and the active NPIs i.e., xi,t,c}i
{
With Assumptions 2 to 5, we can write:
. Therefore, each NPI has its full effect on Rt,c immediately [7, 1, 3, 2]. 2I
Rt,c = R0,c exp(
 
↵ixi,t,c). (1)
Yi 2I
Rt,c is computed as the basic reproduction number in country c multiplied by country-independent factors, each of which correspond to active NPIs. We are now able to link NPI implementations to the time-varying reproduction number, Rt,c, for each country.
We now wish to use Rt to compute the number of daily infections. We will use the discrete time growth rate, gt,c to do so. gt,c describes the change in the number of daily infections, and satisﬁes
Nt,c = gt,cNt 1,c. In other words, the number of infections of day t in country c, is equal to the number of infections on the previous day, multiplied by the growth rate. If gt,c = 1, then there is no change in the number of infections on subsequent days. How can we link Rt,c to gt,c?
Assumption 6. Rt,c may be converted to gt,c by assuming constant exponential growth [32]:
  1
GI (R  is the inverse moment-generating function of the generation interval distribution [2], [7] gt,c = exp 1 t,c )
M   (2)
, 1
 
  where M  
GI (in their sensitivity analysis).
Note that to convert Rt,c to a daily growth rate, we required parameters of the generation interval distribution: the distribution describing the time between one infection and the subsequent generated infections. For example, if the generation interval distribution was a delta distribution at t = 5 days, an infected person would infect Rt others after exactly 5 days.
Since we observe both cases and deaths, we model two sets of daily infection counts. N (C) represents t,c the daily number of infections on day t in country c that will lead to reported cases after a time delay.
Similarly, N (D) represents the daily number of infections on day t in country c that will lead to t,c reported deaths after a longer time delay. We also introduce noise on the daily growth rate, gt,c to account for unobserved factors inﬂuencing transmission, which partially relaxes Assumption 5 (No
Unobserved Factors).
Assumption 7 (Transmission Noise). (a) There is multiplicative noise on the measure of transmission (usually gt,c or Rt,c) [2] (similarly used in older epidemic models [8, 29]). (b) In expectation, the measure of transmission is the same for cases and deaths [2].
We can now write: t t
N (C) t,c = N (C) 0,c gt0,c · exp
"(C) t0,c
, N (D) t,c = N (D) 0,c gt0,c · exp
"(D) t0,c
, (3)
⌘i t0,c ⇠N
Yt0=1 h t0,c , "(D)
Yt0=1 h
⇣ with noise terms "(C) (0,  2 g). Transmission noise partially relaxes Assumption 5 (No
Unobserved Factors) as this noise can account for unobserved factors that inﬂuence R. If the timing of an unobserved factor is uncorrelated with the observed NPIs [5], we expect the unobserved factor to be attributed to noise. However, if unobserved NPI i is correlated with observed NPI j, the effect of NPI i may be attributed to NPI j. As our NPI effectiveness models operate with many unobserved factors, caution is needed in drawing causal conclusions from such observational studies. We discuss this further in the Supplement A.5.
⌘i
⇣
In addition, this noise can model time-varying changes in the rate of case/death reporting. Speciﬁcally, transmission noise allows for time-varying changes in the Ascertainment Rate, ARc, (the proportion of infected cases that are subsequently reported) and the Infection-Fatality Rate, IFRc, (the proportion of infected cases that subsequently die) since "(C) t0 [2]. For example, for all t t0,c affects N (C) t,c
  4
= log 1.2 = 0.18, which will increase all future case numbers. if the proportion of infections tested in country c increases by 20% on day t0, the model can set
"(C) c,t0
Of course, there are also time-invariant differences in case and death reporting, as well as healthcare quality (that would inﬂuence the proportion of infections that die). However, these differences in IFRc and ARc are accounted for by latent variables N (C) 0,c , which represent infection numbers of the ﬁrst day of analysis. Concretely, if the true number of infections in country c is the same as country c0 for all t, but c tests a greater proportion of the population, we may infer N (C) 0,c and N (D)
. 0,c > N (C) 0,c0
With the above assumptions, we are able to compute the daily number of infections over a time period if an initial outbreak size, N0,c, is provided. We now seek to map infection counts to our observations: reported cases and deaths. The daily infections that are eventually reported, N (C) t,c , and the daily infections that eventually result in death, N (D) t,c , are convolved with the delays between infection and case/death reporting to produce the expected number of new reported cases ¯y(C) t,c and deaths ¯y(D) t,c : 31
¯y(C) t,c =
⌧ =0
X 47
⌧ =0
X
N (C) t
 
⌧,c⇡C[⌧ ],
¯y(D) t,c =
N (D) t
 
⌧,c⇡D[⌧ ]. (4)
⇡C[⌧ ] represents the probability of the delay between infection and case reporting being ⌧ days, while
⇡D[⌧ ] represents the probability of the delay between infection and death reporting being ⌧ days. For computational reasons, we right-truncate these delay distributions at a maximum delay of 31 days (cases) and 47 days (deaths).
Assumption 8. The output distribution of (observed) reported cases y(C)
Negative Binomial (NB) distribution [7, 2, 1]: t,c ,  (C)),
NB(µ = ¯y(C)
NB(µ = ¯y(D) (5) where  (C) and  (D) are the dispersion parameters (larger   correspond to less noise) for cases and deaths, which are inferred from the data. The negative binomial distribution is suitable as it has support over N0, and allows for over-dispersion, with independent mean and variance parameters. t,c and deaths y(D) t,c ,  (D)), y(D) t,c ⇠ y(C) t,c ⇠ follows a t,c 2.2 Alternative Assumptions
We now propose alternative assumptions to those of the default model. We later use these assumptions to construct alternative models.
Additive Effects. Instead of Assumption 3 (Multiplicative NPI Effects), we could assume additive
NPI effects.
Assumption 9 (Additive NPI Effects). The introduction of NPI i has an additive effect on Rt,c by affecting a non-overlapping, constant proportion of initial transmission, R0,c. The introduction of
NPI i eliminates all transmission related to i.
This may be intuitively understood as follows. Transmission occurring in the absence of NPIs may be due to non-overlapping fractions. For example, 25% of R0 could be associated with educational institutes, 35% with businesses, and 40% unaffected by NPIs. Closing businesses would eliminate the corresponding 35% of transmission. This leads to:
Rt,c = R0,c
ˆ↵ +
↵i (1 xi,t,c)
, with ˆ↵ +
↵i = 1, (6)
! i and ˆ↵> 0. ↵i is the proportion of transmission eliminated by introducing NPI i while
↵i > 0
ˆ↵> 0 represents the proportion of transmission that remains even when all NPIs are active.
Xi 2I
Xi 2I 8
 
Different Effects. It is possible to simultaneously relax Assumptions 4 (No NPI Interactions) and 2a (Constant NPI Effectiveness over Countries) by allowing NPI effects to vary across countries. For example, if we ﬁnd a relatively higher effectiveness for NPI i in country c, this could be caused by interactions with the other NPIs that were active in country c when i was implemented, or by other country-speciﬁc factors such as country c’s population demographics.
Assumption 10 (Different NPI Effects). Country-speciﬁc NPI effectiveness parameters, drawn i.i.d. according to across countries.
↵i,c}c, are
{
↵).  ↵ is a hyperparameter describing the variance in effectiveness (↵i,  2
N 5  
Noisy-R. Transmission noise could instead be applied directly to Rt,c rather than to gt,c (Eq. 3):
R(C) t,c = ¯Rt,c exp "(C)
R). t,c , R(D) t,c = ¯Rt,c exp "(D) t,c , (7) (0,  2 t,c ⇠N t,c , "(D) where "(C)
Discrete Renewal Infection Process. We previously converted Rt,c to gt,c by assuming constant exponential growth (Assumption 6). We can alternatively use a discrete renewal process that does not make this assumption [6, 28]. We then write: 28 28
N (C) t,c = R(C) t,c
N (C) t
 
⌧,c ·
⇡GI [⌧ ], N (D) t,c = R(D) t,c
N (D) t
 
⌧,c ·
⇡GI [⌧ ], (8)
⌧ =1
X
⌧ =1
X
Under this infection model, transmission noise would be applied to Rt,c as in Eq. (7). ⇡GI [⌧ ] is the truncated, discretised generation interval distribution.
No Transmission Noise. Recall that transmission noise can be used to explain time-varying changes in reporting and treatment, as well as unobserved factors. Alternatively, output noise could be used to model these factors.
Assumption 11 (No Transmission Noise). There is no noise in the measure of transmission (Rt,c or gt,c) [7, 22, 1]. 3 Experiments & Methodology
We now use previously outlined assumptions to construct 8 models that make different structural assumptions. By comparing NPI effectiveness estimates under these models, we effectively compare effectiveness estimates under different assumptions. This will allow us to assess how the assumptions made inﬂuence our NPI effectiveness estimates.
The models that we construct are: Default, the model used our previous work [2] (medRvix Version 4); Additive Effects, where the NPI interaction is additive; Different Effects, where NPI effectiveness is allowed to vary per country; Noisy-R, where noise is applied to Rt,c rather than gt,c; Discrete
Renewal (DR), where the infection model is a discrete renewal process and noise is applied on Rt,c;
Deaths-Only DR — identical to the DR model, except only deaths are modelled; Flaxman et al. [7], which is identical to Deaths-Only DR, but has no transmission noise; and Default (No Transmission
Noise), which is identical to Default but has no transmission noise. Fig. 4 (Supplement) outlines the differences between these models.
Model Evaluation. While our models are reasonable a priori, we must also empirically validate them. In particular, an analysis of holdout predictive performance is required, even though prediction is not our purpose [11, 12]. Holdout predictive performance can be used to rule out models—since we expect that a signiﬁcant fraction of variation in national cases and deaths can be explained by
NPIs, there is little reason to trust an NPI model that entirely fails to predict on held-out data. We measure holdout predictive likelihood on a test-set of 6 countries, having tuned hyperparameters by cross-validation.
In addition, we must assess how NPI effectiveness estimates from these models are inﬂuenced by unobserved factors. Our data does not capture all NPIs implemented in each region, and transmission is also inﬂuenced by other variables, including behaviour change not attributable to our NPIs. Here, we assess sensitivity to unobserved factors by evaluating how inferred NPI effectiveness parameters change when previously observed NPIs become unobserved (NPI leave-outs), as well as when previously unobserved NPIs are observed [30]. Additional NPIs are drawn from the Oxford COVID-19 Government Response Tracker (OxCGRT) NPI dataset [14]. We favour models with stable effectiveness estimates under these conditions, as this indicates the model assigns unobserved effects to noise and not to our NPIs. std[median( ˜↵i)],
We report sensitivity to unobserved factors using the following loss: where the standard deviation is over multiple test conditions of analysis category c e.g., if c =
NPI leave-outs, the standard deviation is taken over several model runs where one NPI at a time is made unobserved and all else is equal. We compute the standard deviation in posterior median NPI effectiveness across tests for every NPI, and then average this over our NPIs. ˜↵i is the effectiveness of NPI i in units “percentage reduction in R”;. Larger
P 2I
|I| i
Lc = 1
Lc indicates higher sensitivity.
Model Robustness. Finally, following our previous work [2], we perform extensive sensitivity experiments across 6 additional categories for these models. To examine sensitivity to data we vary: 6
Figure 2: Model comparison. Left: holdout performance, measured using predictive log-likelihood on a test-set of 6 regions Right: sensitivity to unobserved factors. the included countries, by holding out each country one at a time; the cumulative threshold for case masking; and the threshold for death masking. Recall that all NPI studies are limited to a limited number of countries due to data collection difﬁculties. Additionally, since epidemiological parameters are only known with uncertainty, we examine sensitivity to epidemiological parameters by varying the parameters of the generation interval; the infection to case reporting delay; the infection to death reporting delay distributions; the prior mean over R0,c; and the prior over NPI effectiveness. In total, the sensitivity analysis includes over 600 experimental conditions.
Data & Implementation. We use our previous NPI dataset [2], composed of data on the implemen-tation of 9 NPIs in 41 countries between January and end of May 2020 (validated with independent double entry). Data on reported cases and deaths is from the Johns Hopkins CSSE tracker [19].
Please see Supplement A.7.1 for further details. We implement our models in PyMC3 [31], using
Hamiltonian Monte Carlo NUTS [15] for inference. We use 4 chains with 1250 samples per chain.
For runs with default settings, we ensure that the Gelman-Rubin ˆR is less than 1.05 and that there are no divergent transitions. Our sensitivity analyses and model implementations are available online.