Abstract
Contrastive learning (CL) is a popular technique for self-supervised learning (SSL) of visual representations. It uses pairs of augmentations of unlabeled training examples to deﬁne a classiﬁcation task for pretext learning of a deep embedding.
Despite extensive works in augmentation procedures, prior works do not address the selection of challenging negative pairs, as images within a sampled batch are treated independently. This paper addresses the problem, by introducing a new family of adversarial examples for constrastive learning and using these examples to deﬁne a new adversarial training algorithm for SSL, denoted as CLAE. When compared to standard CL, the use of adversarial examples creates more challenging positive pairs and adversarial training produces harder negative pairs by accounting for all images in a batch during the optimization. CLAE is compatible with many
CL methods in the literature. Experiments show that it improves the performance of several existing CL baselines on multiple datasets. 1

Introduction
Deep networks have enabled signiﬁcant advances in many machine learning tasks over the last decade.
However, this usually requires supervised learning, based on large and carefully curated datasets.
Self-supervised learning (SSL) [25] aims to alleviate this limitation, by leveraging unlabeled data to deﬁne surrogate tasks that can be used for network training. Early advances in SSL were mostly due to the introduction of many different surrogate tasks [2, 51, 34, 78, 81, 33], including solving image [47, 27] or video [3] puzzles, ﬁlling image patches [51, 15, 44] or discriminating between image rotations [18]. Recently, there have also been advances in learning techniques speciﬁcally tailored to SSL, such as contrastive learning (CL) [78, 12, 22, 74, 63, 23, 55, 39], which is the focus of this paper. CL is based on a surrogate task that treats instances as classes and aims to learn an invariant instance representation. This is implemented by generating a pair of examples per instance, and feeding them through an encoder, which is trained with a constrastive loss. This encourages the embeddings of pairs generated from the same instance, known as positive pairs, to be close together and embeddings originated from different instances, known as negative pairs, to be far apart.
The design of positive pairs is one of the research focuses of CL [5]. These pairs can include data from one or two modalities. For single-modality approaches, a common procedure is to rely on data augmentation techniques. For example, instances from image datasets are frequently subject to transformations such as rotation, color jittering, or scaling [12, 78, 22, 74, 39] to generate the corresponding pairs. This type of data augmentation has been shown critical for the success of CL, with different augmentation approaches having a different impact on SSL performance [12]. For video datasets, positive pairs are usually derived from temporal coherence constraints [56, 21]. For multi-view data, augmentations can be more elaborate. For example, [63] considers augmentations of color channels, depth or surface normal and shows that the performance of CL improves as the augmentations increase in diversity. Multi-modal CL approaches tend to rely on audio and video from a common video clip to design positive pairs [52]. In general, CL beneﬁts from deﬁnitions of positive pairs that pose a greater challenge to the learning of the invariant instance representation. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
Unlike the plethora of positive pair selection proposals, the design of negative pairs has received less emphasis in the CL literature. Since CL resembles approaches such as noise contrastive estimation (NCE) [20] and N-pair [59] losses, it can leverage hard negative pair mining schemes proposed for these approaches [7, 59]. However, because they treat each instance independently, previous
SSL works do not consider CL algorithms that select difﬁcult negative pairs within a batch. This is unlike CL methods based on metric learning [30, 59, 54, 62], which seek to construct batches with challenging negative samples.
In this work, we seek a general algorithm for the generation of diverse positive and challenging negative pairs. This is framed as the search for instance augmentation sets that induce the largest optimization cost for CL. A natural approach to synthesize these sets is to leverage adversarial examples [79, 10, 19, 11, 76, 76], which are crafted to attack the network and can thus be seen as the most challenging examples that it can process. We note that the goal is not to enhance robustness to adversarial attacks, but to produce a better representation for SSL. This is in line with recent studies in the adversarial literature, showing that adversarial examples can be used to improve supervised [75, 77] and semi-supervised [41] learning. We explore whether the same beneﬁts can ensue for SSL. One difﬁculty is, however, that no attention has been previously devoted to the design of adversarial attacks for SSL, where no class labels are available. In fact, for SSL embeddings trained by CL, the classical deﬁnition of adversarial attack does not even apply, since CL operates on pairs of examples. We show, however, that it is possible to leverage the interpretation of CL as instance classiﬁcation to produce a sensible generalization of classiﬁcation attacks to the CL problem.
The new attacks are then combined with recent techniques from the adversarial literature [75, 77], which treat adversarial training as multi-domain training, to produce more invariant representations for SSL.
Overall, the paper makes three contributions. First, we show that adversarial data augmentation can be used to improve the performance of SSL learning. Second, we propose a novel procedure for training Contrastive Learning with Adversarial Examples (CLAE) for SSL models. Unlike the attacks classically developed in the supervised learning literature, the new attacks produce pairs of examples that account for both the positive and negative pairs in a batch to maximize contrastive loss. To the best of our knowledge neither the use of attacks to improve SSL nor the design of adversarial examples with this property have been previously discussed in the literature. Finally, extensive experiments demonstrate that (1) adversarial examples can indeed be leveraged to improve
CL, and (2) CLAE boosts the performance of several CL baselines across different datasets. 2