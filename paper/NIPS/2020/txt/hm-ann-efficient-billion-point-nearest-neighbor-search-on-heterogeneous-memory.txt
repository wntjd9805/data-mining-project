Abstract
The state-of-the-art approximate nearest neighbor search (ANNS) algorithms face a fundamental tradeoff between query latency and accuracy, because of small main memory capacity: To store indices in main memory for fast query response,
They have to limit the number of data points or store compressed vectors, which hurts search accuracy. The emergence of heterogeneous memory (HM) brings opportunities to largely increase memory capacity and break the above tradeoff:
Using HM, billions of data points can be placed in main memory on a single machine without using any data compression. However, HM consists of both fast (but small) memory and slow (but large) memory, and using HM inappropriately slows down query time signiﬁcantly. In this work, we present a novel graph-based similarity search algorithm called HM-ANN, which takes both memory and data heterogeneity into consideration and enables billion-scale similarity search on a single node without using compression. On two billion-sized datasets BIGANN and
DEEP1B, HM-ANN outperforms state-of-the-art compression-based solutions such as L&C [13] and IMI+OPQ [12] in recall-vs-latency by a large margin, obtaining 46% higher recall under the same search latency. We also extend existing graph-based methods such as HNSW and NSG with two strong baseline implementations on HM. At billion-point scale, HM-ANN is 2X and 5.8X faster than our HNSW and NSG baselines respectively to reach the same accuracy. 1

Introduction
Efﬁcient billion-scale nearest neighbor search has become a signiﬁcant research problem [6, 7, 22, 23], inspired by the needs of machine learning based applications. Since the number of entities (images, documents, etc) grows enormously fast, it becomes challenging to ﬁnd correspondences in large datasets when there is a requirement for real-time responses (e.g., in several milliseconds). Exhaustive search is infeasible at billion-point scales, because it is extremely computational demanding. Hence, practitioners resort to indexing structures that perform the approximate nearest neighbor search (ANNS) by restricting a query to search only a subset of the dataset that includes the desired neighbors [10, 19, 25]. Among those ANNS, it has been demonstrated that similarity graphs, such as
Hierarchical Navigable Small World (HNSW) [29] and Navigating Spread-out Graph (NSG) [16], obtain superior performance relative to tree structure based [9, 10, 31, 46], locality sensitive hashing (LSH) based [18], and inverted multi-index (IMI) based [25] approaches, and they overall provide the best-in-class latency-vs-accuracy trade-off on most public benchmark datasets.
While obtaining good search speed and accuracy, one major limitation of existing similarity graphs is that they are very memory consuming and easily run out of memory with a few hundred millions of vectors. When the dataset becomes too large to ﬁt on a single machine, the compressed representations of the database points are used, such as Hamming codes [33] and product quantization [13, 17, 21, 24, 32]. However, the performance of these methods deteriorates rapidly at higher recall targets, 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
because they calculate approximate distance based on compressed vectors instead of on the original data vectors. Douze et. al. [13] propose Link-and-Code (L&C), which combines a similarity graph with quantized nodes and exploits neighbor nodes to reﬁne the estimation of distance. However, this approach still works poorly at high recall targets. In [40], the authors explore slow storage to achieve billion-scale ANNS in a single machine. However, this approach is based on a fundamental assumption that the persistent media such as SSD is several orders of magnitude slower than DRAM.
Based on this assumption, data accesses to the persistent media during search should be zero. As a result, it maintains a copy of compressed data in memory with product quantization [40], which results in loss of in-memory search quality. It then preforms a re-ranking using full-precision coordinates stored on SSD, using block-level data accesses but with expensive SSD accessing time.
In this work, we present a fast and accurate approximate nearest neighbor search algorithm for extremely large scale ANN search, called HM-ANN, which is built on top of Heterogeneous Memory.
Heterogeneous Memory (HM) combines cheap, slow but extremely large memory with expensive, fast but small memory (e.g., traditional DRAM) to achieve a good balance between production cost, memory performance and capacity. The emergence of HM brings opportunities to signiﬁcantly improve ANNS. Because of the large memory capacity, HM can use full-precision vectors with accurate distance computation. Since memory access latency/bandwidth of slow memory component in HM is much faster than slow storage such as SSD, it is possible to occasionally access data in slow memory during search without paying expensive cost of data accesses. That being said, releasing full performance potential of HM for ANNS is challenging. Although the slow memory such as PMM performs ∼80X times faster than SSD, it is still ∼3X slower than DRAM in terms of random access latency. Therefore, a naive data placement strategy can hurt the search efﬁciency badly. It then raises the following research question: can we leverage HM for ANNS to achieve both high search accuracy and low search latency, especially when the dataset cannot in DRAM (fast memory)? Speciﬁcally, the algorithm should have a clear advantage over the state-of-the-art ANNS solutions.
HM-ANN enables fast and highly accurate billion-scale ANNS on HM. In particular, we make the following contributions. (1) We present a fast and accurate billion-scale nearest neighbor search solution on a single node without compression. Specially, we generalize the HNSW construction algorithm to have a top-down insertion phase and a bottom-up promotion phase. The top-down phase creates navigable small world graph as the bottom-most layer, which is also the largest, placed to the slow memory; The bottom-up promotion phase promotes pivot points from the bottom layer graph to form upper layers that are placed in the fast memory, which allows most search accesses to happen in fast memory without losing much accuracy. (2) We explore memory management techniques such as dynamic migration to prefetch to-be-accessed data from slow memory to fast memory and parallel search to reduce search time in slow memory. (3) We introduce a performance model to select search-related hyperparameters that satisfy search time and recall constraints. (4) We conduct extensive evaluation and show that on two billion-scale datasets, HM-ANN provides 95% top-1 recall in less than one millisecond; HM-ANN outperforms state-of-the-art compression-based solutions such as L&C [13] and IMI+OPQ [12] in terms of recall-vs-latency by a large margin, getting 46% higher recall under the same search latency budget; Since NSG and HNSW have never been scaled up to a billion vector on a single machine, we create two strong baselines for them: using ﬁrst-touch
NUMA and hardware-managed caching, respectively. Our results show that for 95% top-1 recall,
HM-ANN outperforms the baselines by 2X-5.8X in terms of search latency. 2 Preliminary and