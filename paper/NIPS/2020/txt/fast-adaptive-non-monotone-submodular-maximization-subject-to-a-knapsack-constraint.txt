Abstract
Constrained submodular maximization problems encompass a wide variety of applications, including personalized recommendation, team formation, and revenue maximization via viral marketing. The massive instances occurring in modern-day applications can render existing algorithms prohibitively slow. Moreover, frequently those instances are also inherently stochastic. Focusing on these chal-lenges, we revisit the classic problem of maximizing a (possibly non-monotone) submodular function subject to a knapsack constraint. We present a simple random-ized greedy algorithm that achieves a 5.83 approximation and runs in O(n log n) time, i.e., at least a factor n faster than other state-of-the-art algorithms. The robustness of our approach allows us to further transfer it to a stochastic version of the problem. There, we obtain a 9-approximation to the best adaptive policy, which is the ﬁrst constant approximation for non-monotone objectives. Experimental evaluation of our algorithms showcases their improved performance on real and synthetic data. 1

Introduction
Constrained submodular maximization is a fundamental problem at the heart of discrete optimization.
The reason for this is as simple as it is clear: submodular functions capture the notion of diminishing returns present in a wide variety of real-world settings.
Consequently to its striking importance and coinciding NP-hardness [22], extensive research has been conducted on submodular maximization since the seventies (e.g., [16, 44]), with focus lately shifting towards handling the massive datasets emerging in modern applications. With a wide variety of possible constraints, often regarding cardinality, independence in a matroid, or knapsack-type restrictions, the number of applications is vast. To name just a few, there are recent works on feature selection in machine learning [14, 15, 34], inﬂuence maximization in viral marketing [3, 33], and data summarization [45, 40, 47]. Many of these applications have non-monotone submodular objectives, meaning that adding an element to an existing set might actually decrease its value. Two such examples are discussed in detail in Section 5. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
Modern-day applications increasingly force us to face two distinct, but often entangled challenges.
First, the massive size of occurring instances fuels a need for very fast algorithms. As the running time is dominated by the objective function evaluations (also known as value oracle calls), it is typically measured (as in this work) by their number. So, here the goal is to design algorithms requiring an almost linear number of such evaluations. There is extensive research focusing on this issue, be it in the standard algorithmic setting [41], or in streaming [4, 10, 26, 1] and distributed submodular maximization [40, 13]. The second challenge is the inherent uncertainty in problems like sensor placement or revenue maximization, where one does not learn the exact marginal value of an element until it is added to the solution (and thus “paid for”). This, too, has motivated several works on adaptive submodular maximization [27, 28, 30, 43]. Note that even estimating the expected value to a partially unknown objective function can be very costly and this makes the reduction of the number of such calls all the more important.
Knapsack constraints are one of the most natural types of restriction that occurs in real-world problems and are often hard budget, time, or size constraints. Other combinatorial constraints like partition matroid constraints, on the other hand, model less stringent requirements, e.g., avoiding too many similar items in the solution. As the soft versions of such constraints can be often hardwired in the objective itself (see the Video Recommendation application in Section 5), we do not deal with them directly here. The nearly-linear time requirement, without large constants involved, leaves little room for using sophisticated approaches like continuous greedy methods [24] or enumeration of initial solutions [46]. To further highlight the delicate balance between function evaluations and approximation, it is worth mentioning that, even for the monotone case, the ﬁrst result combining e
O(n log n) oracle calls with an approximation better than 2 is the very recent e−1 -approximation algorithm of Ene and Nguyen [17]. While this is a very elegant theoretical result, the huge constants involved render it unusable in practice.
At the same time, there is a strikingly simple 3-approximation variant of the modiﬁed density greedy algorithm of Wolsey [49] that deals well with both issues in the monotone case: Sort the items in decreasing order according to their marginal value over cost ratio and pick as many items as possible in that order without violating the constraint. Finally, return the best among this solution and the best single item.1 For simplicity, by modiﬁed density greedy we will refer to this algorithm. When combined with lazy evaluations [39], it requires only O(n log n) value oracle calls and can be adjusted to work well for adaptive submodular maximization [27]. For non-monotone objectives, however, the only practical algorithm is the (10 + ε)-approximation FANTOM algorithm of Mirzasoleiman et al. [41] requiring O(n2 log n) value oracle calls (see also Remark 1). Moreover, there is no known algorithm for the adaptive setting that can handle anything beyond a cardinality constraint [28].
We aim to tackle both aforementioned challenges for non-monotone submodular maximization under a knapsack constraint, by revisiting the simple algorithmic principle of the modiﬁed density greedy algorithm. Our approach is along the lines of recent results on random greedy combinatorial algorithms [7, 25], which show that introducing randomness into greedy algorithms can extend their guarantees to the non-monotone case. Here, we give the ﬁrst such algorithm for a knapsack constraint. 1.1 Contribution and Outline
The modiﬁed density greedy algorithm may produce arbitrarily poor solutions when the objective is non-monotone. In this work we show that introducing some randomization leads to a simple algorithm, SAMPLEGREEDY, that outperforms existing algorithms both in theory and in practice.
SAMPLEGREEDY ﬂips a coin before greedily choosing any item in order to decide whether to include it to the solution or ignore it. The algorithmic simplicity of such an approach keeps SAMPLEGREEDY fast, easy to implement, and ﬂexible enough to adjust to other related settings. At the same time the added randomness prevents it from getting trapped in solutions of poor quality.
In particular, in Section 3 we show that SAMPLEGREEDY is a 5.83-approximation algorithm using only O(n log n) value oracle calls. When all singletons have small value compared to an optimal solution, the approximation factor improves to almost 4. This is the ﬁrst constant-factor approximation algorithm for the non-monotone case using this few queries. The only other algorithm fast enough to 1A somewhat more elaborate 2.8-approximation algorithm is given by Wolsey [49]. For completeness, in the supplementary material we show the approximation guarantee of the simpliﬁed version we mention here. 2
be suitable for large instances is the aforementioned FANTOM [41] which, for a knapsack constraint,2 achieves an approximation factor of (10 + ε) with O(nrε−1 log n) queries, where r is the size of the largest feasible set and can be as large as Θ(n). Even if we modify FANTOM to use lazy evaluations, we still improve the query complexity by a logarithmic factor (see Remark 1).
Then we study the problem in the adaptive submodular maximization framework of Golovin and
Krause [27] and Gotovos et al. [28], where the stochastic submodular objective is learned as we build the solution and its value depends only on the state of the elements in the evaluated set. For this adaptive variant, we show in Section 4 that a natural adaptation of our algorithm, ADAPTIVEGREEDY, still guarantees a 9-approximation to the best adaptive policy. This is not only a relatively small loss given the considerably stronger benchmark, but is in fact the ﬁrst constant approximation known for the problem in this framework. Hence we ﬁll a notable theoretical gap, given that models with incomplete prior information, or those capturing evolving settings, are becoming increasingly important in practice.
From a technical point of view, our algorithm combines the simple principle of always choosing a high-density item with maintaining a careful exploration-exploitation balance, as is the case in many stochastic learning problems. It is therefore directly related to the recent simple randomized greedy approaches for maximizing non-monotone submodular objectives subject to other (i.e., non-knapsack) constraints [7, 10, 25]. However, there are underlying technical difﬁculties that make the analysis for knapsack constraints signiﬁcantly more challenging. Every single result in this line of work critically depends on making a random choice in each step, in a way so that “good progress” is consistently made. This is not possible under a knapsack constraint. Instead, we argue globally about the value of the SAMPLEGREEDY output via a comparison with a carefully maintained almost integral solution.
When it comes to extending this approach to the adaptive non-monotone submodular maximization framework, we crucially use the fact that the algorithm builds the solution iteratively, committing in every step to all the past choices. This is the main technical reason why it is not possible to adjust algorithms with multiple “parallel” runs, like FANTOM, to the adaptive setting.
Our algorithms provably handle well the aforementioned emerging, modern-day challenges, i.e., stochastically evolving objectives and rapidly growing real-world instances. In Section 5 we showcase the fact that our theoretical results indeed translate into applied performance. We focus on two applications that ﬁt within the framework of non-monotone submodular maximization subject to a knapsack constraint, namely video recommendation and inﬂuence-and-exploit marketing. We run experiments on real and synthetic data that indicate that SAMPLEGREEDY consistently performs better than FANTOM while being much faster. For ADAPTIVEGREEDY we highlight the fact that its adaptive behavior results in a signiﬁcant improvement over non-adaptive alternatives. 1.2