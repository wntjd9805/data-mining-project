Abstract
Emergentism and pragmatics are two research ﬁelds that study the dynamics of linguistic communication along substantially different timescales and intelligence levels. From the perspective of multi-agent reinforcement learning, they correspond to stochastic games with reinforcement training and stage games with opponent awareness. Given that their combination has been explored in linguistics, we propose computational models that combine short-term mutual reasoning-based pragmatics with long-term language emergentism. We explore this for agent com-munication referential games as well as in Starcraft II, assessing the relative merits of different kinds of mutual reasoning pragmatics models both empirically and theoretically. Our results shed light on their importance for making inroads towards getting more natural, accurate, robust, ﬁne-grained, and succinct utterances. 1

Introduction
In many linguistic theories (Zipf, 1935; Lewis, 1969; Grice, 1975), language is viewed as a special kind of social coordination system, in which multiple agents make interdependent decisions of how to express and comprehend messages in order to successfully communicate real-world information.
Drawing on advances in artiﬁcial intelligence, recent work considers referential games (Lazaridou et al., 2018) to model language learning from raw sensory input, adopting techniques from computer vision, language processing, and multi-agent reinforcement learning. Considering agent communica-tion issues in multi-agent learning not only beneﬁts the coordination of agents for tasks with common objectives, but also manifests properties of human linguistics and suggests a potential path towards more intelligent natural language processing techniques (Lazaridou et al., 2018).
However, in traditional linguistics, language is studied along different timescales and different levels of deliberation, while recent work on referential games only focuses on long-term language evolution, i.e., modeling how long-term habits develop. In this work, we propose integrated models that consider not only long-term evolution but also short-term equilibrium ﬁnding. On the one hand, agents are expected to conform to evolved language habits; on the other hand, in a separate pragmatic stage after the long-term evolution, they are expected to make rational decisions within a particular context so as to communicate more successfully. Our models achieve both of these goals, drawing on psychological game theory (Battigalli et al., 2019), where the payoffs reﬂect prior beliefs about the strategies, instead of just the ﬁnal outcome.
Contributions. Our key contributions can be summarized as follows:
• We propose a new computational framework that more comprehensively models language dynamics at different timescales. While previous work on referential games considers long-term language evolution (also known as emergentism in linguistics), our model additionally incorporates a subsequent procedure of opponent-aware pragmatic reasoning. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
• To this end, we consider action costs of speakers and listeners that can account for several notions of pragmatics, including a game-theoretic pragmatics version that allows us to assess the limits of rational deliberation.
• We conduct a series of experiments that evaluate the relative merits of different pragmatic models, showing that they can improve the empirical communication accuracy both in typical referential game settings (Lazaridou et al., 2018) and in a StarCraft II simulation (Wang et al., 2019b). 2