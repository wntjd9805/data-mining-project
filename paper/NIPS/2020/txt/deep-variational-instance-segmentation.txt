Abstract
Instance segmentation, which seeks to obtain both class and instance labels for each pixel in the input image, is a challenging task in computer vision. State-of-the-art algorithms often employ a search-based strategy, which ﬁrst divides the output image with a regular grid and generate proposals at each grid cell, then the proposals are classiﬁed and boundaries reﬁned. In this paper, we propose a novel algorithm that directly utilizes a fully convolutional network (FCN) to predict instance labels. Speciﬁcally, we propose a variational relaxation of instance segmentation as minimizing an optimization functional for a piecewise-constant segmentation problem, which can be used to train an FCN end-to-end. It extends the classical Mumford-Shah variational segmentation algorithm to be able to handle the permutation-invariant ground truth in instance segmentation. Experiments on
PASCAL VOC 2012 and the MSCOCO 2017 dataset show that the proposed approach efﬁciently tackles the instance segmentation task. The source code and trained models are released at https://github.com/jia2lin3yuan1/2020-instanceSeg. 1

Introduction
Recent years have witnessed rapid development in semantic segmentation [30; 33; 10; 20], i.e., classifying pixels into different object categories such as car or person. However, in order to fully understand a scene, we need to identify individual object instances, along with their semantic labels.
This task, called semantic instance segmentation [13; 16; 26], is much more challenging, because (1) different instances may have similar appearances if they belong to the same category; (2) the number of instances is often unknown during prediction; and (3) labels of the instances are permutation-invariant, i.e., randomly permuting instance labels in the training ground truth should not change the learning outcome (Fig. 1).
For such permutation-invariant instance labels, one cannot directly train the model using conventional objectives such as the cross-entropy (CE) loss. One popular strategy is to combine detection and segmentation into a two-stage approach. One network generates object proposals, while another one classiﬁes and reﬁnes each proposal [17; 24; 39; 11; 18; 28; 9; 42; 1]. To ensure all instances are segmented, these methods often need to generate a signiﬁcant amount of proposals (1, 000 − 3, 000 per image), and many are based on a sliding window approach that is similar to a complete search on a low-resolution image with anchor boxes. These proposals are veriﬁed with an object classiﬁer and a smaller but still signiﬁcant amount (200 − 2, 000) are sent to the second stage for classiﬁcation and reﬁnement. To improve the efﬁciency, some recent works remove the anchor boxes by directly dividing the output image into a regular grid cell and segmenting the object that is centered in each 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
(a) Input Image (b) GT (c) Real-valued Predicted Labels
Figure 1: (a): An example from PASCAL VOC [13] with 8 bottles. (b) Ground truth. Labels of the bottles can be either 1 to 8 or 8 to 1. (c) Our approach solves a variational relaxation of the problem and predict real-valued labels on the image (best in color) cell [45; 46; 47; 8]. However, they still require a signiﬁcant amount of proposals. Another alternative solution is the search-free approach, which do not explicitly generate object proposals. Most methods learn to predict surrogates for instance labels for each pixel, and then use heuristic post-processing procedures to segment each instance [50; 49; 41; 3; 21; 27].
We note that the goal of instance segmentation is to generate piecewise-constant predictions on each pixel that match with a given ground truth. This resonates with the classic and elegant varia-tional principle introduced to computer vision almost three decades ago. Such variational methods, originated from the Mumford-Shah model [32], parse an image into meaningful sub-regions by
ﬁnding a piecewise smooth approximation. These approaches were traditionally limited to simple problems such as image restoration and active contours, mainly because the difﬁculties at that time to estimate nonlinear functions from an image. However, they could be inherently appealing in a deep network setting, since these variational objectives work with real-valued inputs and outputs. e.g., the
Mumford-Shah functional, that are naturally differentiable.
We believe such variational approaches could be very powerful when combined with deep learning, since they enable us to solve deep learning problems that are difﬁcult for conventional objective functions such as cross-entropy. On the other hand, parametrizing variational approaches with a deep network enables them to model complex functions originating from an image. It also allows them to generalize to testing images. In this paper, we propose deep variational instance segmentation (DVIS), which is a fully convolutional neural network (FCN) that directly predicts instance labels – a piecewise-constant function, with each constant sub-region corresponding to a different instance.
A novel variational objective is proposed to accommodate the permutation-invariant nature of the ground truth in instance segmentation, which leads to end-to-end training of the network.
With this proposed approach, we are directly gazing at instances from a top-down FCN viewpoint without the need to generate bounding box proposals using search protocols. Our approach outper-forms the other search-free instance segmentation methods on the PASCAL VOC dataset [13; 16] and it is the ﬁrst search-free method tested on the MS-COCO dataset [26], obtaining a performance close to these search-based methods, but with signiﬁcantly faster speed. 2