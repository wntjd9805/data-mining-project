Abstract
Nonlinear dimensionality reduction of high-dimensional data is challenging as the low-dimensional embedding will necessarily contain distortions, and it can be hard to determine which distortions are the most important to avoid. When annotation of data into known relevant classes is available, it can be used to guide the embedding to avoid distortions that worsen class separation. The supervised mapping method introduced in the present paper, called ClassNeRV, proposes an original stress function that takes class annotation into account and evaluates embedding quality both in terms of false neighbors and missed neighbors. ClassNeRV shares the theoretical framework of a family of methods descending from Stochastic Neighbor
Embedding (SNE). Our approach has a key advantage over previous ones: in the literature supervised methods often emphasize class separation at the price of distorting the data neighbors’ structure; conversely, unsupervised methods provide better preservation of structure at the price of often mixing classes. Experiments show that ClassNeRV can preserve both neighbor structure and class separation, outperforming nine state of the art alternatives. 1

Introduction
Dimensionality Reduction (DR) methods aim at mapping a high dimensional dataset as points in a lower dimensional embedding space, while preserving some similarity measure between data points.
DR may be supervised by taking advantage of class information. Hence, supervised methods compute the mapping both from relative positions of data (also used by non-supervised methods) and from the class labels. DR techniques [1, 2, 3] can be used as a pre-processing step for classiﬁcation or clustering, or to visualize (labeled) data as a scatterplot. When mapping labeled data, there are two contradictory objectives:
• Classiﬁcation is typical of supervised DR techniques: class separation is emphasized and measured with classiﬁcation accuracy in the embedding space. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
(a) 3D dataset (b) tSNE (unsupervised) (c) S-UMAP (supervised) (d) ClassNeRV
Figure 1: ClassNeRV is designed to preserve both classes and neighbors: data are sampled from three 3D Gaussian clusters (a), a cluster of circles purely of the blue class, a cluster of squares halved by a plane separating blue and orange classes, and a cluster of diamonds with randomly distributed green and pink classes. Different planar embeddings of these data are shown: the unsupervised tSNE (b) preserves clusters well, but overlaps the orange and blue classes in the cluster of squares as it ignores the labels. The supervised S-UMAP (c) splits the clusters of squares and diamonds forcing class separation. Hence, it is misleading about the original spatial adjacency of orange and blue classes, and mixing of green and pink classes. ClassNeRV (d) is designed to better preserve the three-clusters structure as well as classes’ adjacency.
• Exploratory data analysis is typical of unsupervised DR techniques which operate without knowledge of class information: data neighborhood structure is prioritized and measured as a discrepancy between data similarities in both original and embedding spaces.
These objectives derive from visual analytic tasks [3, 4]. They are contradictory unless class and data neighborhood structures match each other well in both the data and embedding spaces: each class constitutes distinct areas with no cross-class neighborhood relations. Unfortunately, this ideal case is very unlikely because the data neighborhood structure and classes do not always match in the data space, and low dimensional embeddings of high-dimensional data come with unavoidable distortions
[3]: false neighbors which are neighboring points in the embedding but not in the data, and missed neighbors which are neighbors in the data but not in the embedding.
In this work, we propose ClassNeRV, a supervised DR technique to accomplish the exploratory analysis objective while taking class information into account. Our solution is similar in principle to the earlier ClassiMap [5] distance-based projection, but we derive our approach from the same well-grounded probabilistic framework as NeRV [6, 7], SNE [8], and tSNE [9]. Our solution differs notably from other previous supervised methods which tend to force class separation at the expense of neighbors’ structure, e.g. S-Isomap [10], S-NeRV [11] and S-UMAP [12]. Figure 1 illustrates the essential characteristics of ClassNeRV.
Our contribution is two-fold: we propose ClassNeRV which utilizes class information to ensure a better preservation of classes when embedding high dimensional labeled data into a low dimensional space. Its stress function, derived from the unsupervised NeRV [6, 7], steers the optimization so that the unavoidable distortions of the neighborhood structure are placed where they are less harmful to the class structure. Harmful distortions are avoided by emphasizing penalization of false neighbors between classes and missed neighbors within classes. We also derive two new class-aware quality indicators from the standard Trustworthiness and Continuity quality indicators [13], to account speciﬁcally for the distortions affecting class preservation. 2