Abstract
Graph neural networks have shown superior performance in a wide range of applications providing a powerful representation of graph-structured data. Recent works show that the representation can be further improved by auxiliary tasks.
However, the auxiliary tasks for heterogeneous graphs, which contain rich semantic information with various types of nodes and edges, have less explored in the literature. In this paper, to learn graph neural networks on heterogeneous graphs we propose a novel self-supervised auxiliary learning method using meta-paths, which are composite relations of multiple edge types. Our proposed method is learning to learn a primary task by predicting meta-paths as auxiliary tasks. This can be viewed as a type of meta-learning. The proposed method can identify an effective combination of auxiliary tasks and automatically balance them to improve the primary task. Our methods can be applied to any graph neural networks in a plug-in manner without manual labeling or additional data. The experiments demonstrate that the proposed method consistently improves the performance of link prediction and node classiﬁcation on heterogeneous graphs. 1

Introduction
Graph neural networks [1] have been proven effective to learn representations for various tasks such as node classiﬁcation [2], link prediction [3], and graph classiﬁcation [4]. The powerful representation yields state-of-the-art performance in a variety of applications including social network analysis [5], citation network analysis [2], visual understanding [6, 7], recommender systems [8], physics [9], and drug discovery [10]. Despite the wide operating range of graph neural networks, employing auxiliary (pre-text) tasks has been less explored for further improving graph representation learning.
Pre-training with an auxiliary task is a common technique for deep neural networks. Indeed, it is the de facto standard step in natural language processing and computer vision to learn a powerful backbone networks such as BERT [11] and ResNet [12] leveraging large datasets such as BooksCorpus [13],
English Wikipedia, and ImageNet [14]. The models trained on the auxiliary task are often beneﬁcial for the primary (target) task of interest. Despite the success of pre-training, few approaches have been generalized to graph-structured data due to their fundamental challenges. First, graph structure (e.g., the number of nodes/edges, and diameter) and its meaning can signiﬁcantly differ between domains. So the model trained on an auxiliary task can harm generalization on the primary task, i.e., negative transfer [15]. Also, many graph neural networks are transductive approaches. This often makes transfer learning between datasets inherently infeasible. So, pre-training on the target
∗First two authors have equal contribution. § is the corresponding author.
†This work was done when the author worked at NAVER CLOVA. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
dataset has been proposed using auxiliary tasks: graph kernel [16], graph reconstruction [17], and attribute masking [18]. These assume that the auxiliary tasks for pre-training are carefully selected with substantial domain knowledge and expertise in graph characteristics to assist the primary task.
Since most graph neural networks operate on homogeneous graphs, which have a single type of nodes and edges, the previous pre-training/auxiliary tasks are not speciﬁcally designed for heterogeneous graphs, which have multiple types of nodes and edges. Heterogeneous graphs commonly occur in real-world applications, for instance, a music dataset has multiple types of nodes (e.g., user, song, artist) and multiple types of relations (e.g., user-artist, song-ﬁlm, song-instrument).
In this paper, we proposed a framework to train a graph neural networks with automatically selected auxiliary self-supervised tasks which assist the target task without additional data and labels. Our approach ﬁrst generates meta-paths from heterogeneous graphs without manual labeling and train a model with meta-path prediction to assist the primary task such as link prediction and node classiﬁcation. This can be formulated as a meta-learning problem. Furthermore, our method can be adopted to existing GNNs in a plug-in manner, enhancing the model performance.
Our contribution is threefold: (i) We propose a self-supervised learning method on a heterogeneous graph via meta-path prediction without additional data. (ii) Our framework automatically selects meta-paths (auxiliary tasks) to assist the primary task via meta-learning. (iii) We develop Hint Network that helps the learner network to beneﬁt from challenging auxiliary tasks. To the best of our knowledge, this is the ﬁrst auxiliary task with meta-paths speciﬁcally designed for leveraging heterogeneous graph structure. Our experiment shows that meta-path prediction improves the representational power and the gain can be further improved to explicitly optimize the auxiliary tasks for the primary task via meta-learning and the Hint Network, built on various state-of-the-art GNNs. 2