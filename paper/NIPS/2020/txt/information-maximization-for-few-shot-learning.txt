Abstract
We introduce Transductive Infomation Maximization (TIM) for few-shot learning.
Our method maximizes the mutual information between the query features and their label predictions for a given few-shot task, in conjunction with a supervision loss based on the support set. Furthermore, we propose a new alternating-direction solver for our mutual-information loss, which substantially speeds up transductive-inference convergence over gradient-based optimization, while yielding similar accuracy. TIM inference is modular: it can be used on top of any base-training feature extractor. Following standard transductive few-shot settings, our compre-hensive experiments2 demonstrate that TIM outperforms state-of-the-art methods signiﬁcantly across various datasets and networks, while used on top of a ﬁxed feature extractor trained with simple cross-entropy on the base classes, without resorting to complex meta-learning schemes. It consistently brings between 2% and 5% improvement in accuracy over the best performing method, not only on all the well-established few-shot benchmarks but also on more challenging scenarios, with domain shifts and larger numbers of classes. 1

Introduction
Deep learning models have achieved unprecedented success, approaching human-level performances when trained on large-scale labeled data. However, the generalization of such models might be seriously challenged when dealing with new (unseen) classes, with only a few labeled instances per class. Humans, however, can learn new tasks rapidly from a handful of instances, by leveraging context and prior knowledge. The few-shot learning (FSL) paradigm [29, 8, 45] attempts to bridge this gap, and has recently attracted substantial research interest, with a large body of very recent works, e.g., [14, 7, 37, 49, 28, 5, 34, 19, 40, 48, 10, 38, 9], among many others. In the few-shot setting, a model is ﬁrst trained on labeled data with base classes. Then, model generalization is evaluated on few-shot tasks, composed of unlabeled samples from novel classes unseen during training (the query set), assuming only one or a few labeled samples (the support set) are given per novel class.
Most of the existing approaches within the FSL framework are based on the “learning to learn” paradigm or meta-learning [9, 38, 45, 40, 22], where the training set is viewed as a series of balanced tasks (or episodes), so as to simulate test-time scenario. Popular works include prototypical networks
[38], which describes each class with an embedding prototype and maximizes the log-probability of query samples via episodic training; matching network [45], which represents query predictions as
∗Corresponding author: malik.boudiaf.1@etsmtl.net 2Code publicly available at https://github.com/mboudiaf/TIM 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
linear combinations of support labels and employs episodic training along with memory architectures;
MAML [9], a meta-learner, which trains a model to make it "easy" to ﬁne-tune; and the LSTM meta-learner in [35], which suggests optimization as a model for few-shot learning. A large body of meta-learning works followed-up lately, to only cite a few [37, 33, 30, 40, 49]. 1.1