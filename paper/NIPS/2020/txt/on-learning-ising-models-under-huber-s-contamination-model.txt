Abstract
We study the problem of learning Ising models in a setting where some of the samples from the underlying distribution can be arbitrarily corrupted. In such a setup, we aim to design statistically optimal estimators in a high-dimensional scaling in which the number of nodes p, the number of edges k and the maximal node degree d are allowed to increase to inﬁnity as a function of the sample size n.
Our analysis is based on exploiting moments of the underlying distribution, coupled with novel reductions to univariate estimation. Our proposed estimators achieve an optimal dimension independent dependence on the fraction of corrupted data in the contaminated setting, while also simultaneously achieving high-probability error guarantees with optimal sample-complexity. We corroborate our theoretical results by simulations. 1

Introduction
Undirected graphical models (also known as Markov random ﬁelds (MRFs)) have gained signiﬁcant attention as a tool for discovering and visualizing dependencies among covariates in multivariate data. Graphical models provide compact and structured representations of the joint distribution of multiple random variables using graphs that represent conditional independences between the individual random variables. They are used in domains as varied as natural language processing[38], image processing [9, 24, 27], spatial statistics [44] and computational biology [23], among others.
Given samples drawn from the distribution, a key problem of interest is to recover the underlying dependencies represented by the graph. A slew of recent results [40, 43, 45] have shown that it is possible to learn such models even in domains and settings where the number of samples is potentially smaller than the number of variables. These results however make the common assumption that the sample data is clean, and have no corruptions. However, modern data sets that arise in various branches of science and engineering are no longer carefully curated. They are often collected in a decentralized and distributed fashion, and consequently are plagued with the complexities of outliers, and even adversarial manipulations.
Huber [28] proposed the �-contamination model as a framework to study such datasets with potentially arbitrary corruptions. In this setting, instead of observing samples directly from the true distribution
P�, we observe samples drawn from P�, which for an arbitrary distribution Q is deﬁned as a mixture
∗Equal Contribution 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
model,
� + �Q.
−
�)P
P� = (1 (1)
Then, given n samples from P�, the goal is to recover functionals of P�. There has been a lot of classical work on estimators for the �-contamination model setting that largely trade off computational versus statistical efﬁciency (see [29] and references therein). Moreover, there has been substantial progress [3, 7, 15, 16, 18, 32, 35, 42] on designing provably robust estimators which are computa-tionally tractable while achieving near-optimal contamination dependence (i.e. dependence on the fraction of outliers �). However, to the best of our knowledge, there are no known results for learning general graphical models robustly. 1.1