Abstract
Many important problems in science and engineering, such as drug design, in-volve optimizing an expensive black-box objective function over a complex, high-dimensional, and structured input space. Although machine learning techniques have shown promise in solving such problems, existing approaches substantially lack sample efﬁciency. We introduce an improved method for efﬁcient black-box optimization, which performs the optimization in the low-dimensional, continu-ous latent manifold learned by a deep generative model. In contrast to previous approaches, we actively steer the generative model to maintain a latent manifold that is highly useful for efﬁciently optimizing the objective. We achieve this by periodically retraining the generative model on the data points queried along the optimization trajectory, as well as weighting those data points according to their objective function value. This weighted retraining can be easily implemented on top of existing methods, and is empirically shown to signiﬁcantly improve their efﬁciency and performance on synthetic and real-world optimization problems. 1

Introduction
Many important problems in science and engineering can be formulated as optimizing an objective function over an input space. Solving such problems becomes particularly challenging when 1) the input space is high-dimensional and/or structured (i.e. discrete spaces, or non-Euclidean spaces such as graphs, sequences, and sets) and 2) the objective function is expensive to evaluate. Unfortunately, many real-world problems of practical interest have these characteristics. A notable example is drug design, which has a graph-structured input space, and is evaluated using expensive wet-lab experiments or time-consuming simulations. Recently, machine learning has shown promising results in many problems that can be framed as optimization, such as conditional image [68, 47] and text
[51] generation, molecular and materials design [17, 58], and neural architecture search [16]. Despite these successes, using machine learning on structured input spaces and with limited data is still an open research area, making the use of machine learning infeasible for many practical applications.
One promising approach which tackles both challenges is a two-stage procedure that has emerged over the past few years, which we will refer to as latent space optimization (LSO) [20, 37, 41, 42, 48].
In the ﬁrst stage, a (deep) generative model is trained to map tensors in a low-dimensional continuous space onto the data manifold in input space, effectively constructing a low-dimensional and continuous analog of the optimization problem. In the second stage, the objective function is optimized over this learned latent space using a surrogate model. Despite many successful applications in a variety of ﬁelds including chemical design [20, 28, 37, 9] and automatic machine learning [41, 42], LSO is primarily applied in a post-hoc manner using a pre-trained, general purpose generative model rather
∗equal contribution 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
(a) Starting Point (b) Standard LSO (c) LSO with Weighted Retraining
Figure 1: Schematic illustrating LSO with and without weighted retraining. The cartoon illustrates the input/latent space of the generative model (top). The latent manifold from Section 6.2’s 2D shape area maximization task is shown for comparison (bottom). Each image in the manifold shows the result of decoding a latent point on a uniform square grid in a 2D latent space; images are centered on the original grid points. Red/green regions correspond to points with low/high objective function values respectively. The yellow star is the global optimum in X . Coloured circles are data points; their radius represents their weight. The dashed line surrounds the region of X modelled by g (i.e. g(Z), the image of Z). (a) The status of the generative model g at the start of optimization. (b) The result of standard LSO with g ﬁxed, which queries the points in orange. It is only able to ﬁnd points close to the training data used to learn Z, resulting in slow and incomplete exploration of X . (c) The result midway (left) and at the end (right) of LSO with our proposed approach, which weights data points according to their objective function value and retrains g to incorporate newly queried data.
This continually adjusts Z to focus on modelling the most promising regions of X , speeding up the optimization and allowing for substantial extrapolation beyond the initial training data. than one trained speciﬁcally for the explicit purpose of downstream optimization. Put differently, the training of the generative model is effectively decoupled from the optimization task.
In this work, we identify and examine two types of decoupling in LSO. We argue that they make optimization unnecessarily difﬁcult and fundamentally prevent LSO from ﬁnding solutions that lie far from the training data. Motivated by this, we propose weighting of the data distribution and periodic retraining of the generative model to effectively resolve this decoupling. We argue that these two modiﬁcations are highly complementary, fundamentally transforming LSO from a local optimizer into an efﬁcient global optimizer capable of recursive self-improvement. Our contributions are: 1. We identify and describe two critical failure modes of previous LSO-based methods which severely limit their efﬁciency and performance, and thus practical applicability (Section 3). 2. We propose to combine dataset weighting with periodic retraining of the generative model used within LSO as an effective way to directly address the issued identiﬁed (Section 4). 3. We empirically demonstrate that weighted retraining signiﬁcantly beneﬁts LSO across a variety of application domains and generative models, achieving substantial improvements over state-of-the-art methods on a widely-used chemical design benchmark (Section 6). 2 Problem Statement and