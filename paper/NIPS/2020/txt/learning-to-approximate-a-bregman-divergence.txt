Abstract
Bregman divergences generalize measures such as the squared Euclidean distance and the KL divergence, and arise throughout many areas of machine learning.
In this paper, we focus on the problem of approximating an arbitrary Bregman divergence from supervision, and we provide a well-principled approach to ana-lyzing such approximations. We develop a formulation and algorithm for learning arbitrary Bregman divergences based on approximating their underlying convex generating function via a piecewise linear function. We provide theoretical ap-proximation bounds using our parameterization and show that the generalization error Op(m−1/2) for metric learning using our framework matches the known generalization error in the strictly less general Mahalanobis metric learning setting.
We further demonstrate empirically that our method performs well in comparison to existing metric learning methods, particularly for clustering and ranking problems. 1

Introduction
Bregman divergences arise frequently in machine learning. They play an important role in clus-tering [3] and optimization [7], and speciﬁc Bregman divergences such as the KL divergence and squared Euclidean distance are fundamental in many areas. Many learning problems require di-vergences other than Euclidean distances—for instance, when requiring a divergence between two distributions—and Bregman divergences are natural in such settings. The goal of this paper is to provide a well-principled framework for learning an arbitrary Bregman divergence from supervision.
Such Bregman divergences can then be utilized in downstream tasks such as clustering, similarity search, and ranking.
A Bregman divergence [7] Dφ : X × X → R+ is parametrized by a strictly convex function
φ : X → R such that the divergence of x1 from x2 is deﬁned as the approximation error of the linear approximation of φ(x1) from x2, i.e. Dφ(x1, x2) = φ(x1) − φ(x2) − ∇φ(x2)T (x1 − x2). A signiﬁcant challenge when attempting to learn an arbitrary Bregman divergences is how to appropriately parameterize the class of convex functions; in our work, we choose to parameterize
φ via piecewise linear functions of the form h(x) = maxk∈[K] aT k x + bk, where [K] denotes the set {1, . . . , K} (see the left plot of Figure 1 for an example). As we discuss later, such max-afﬁne functions can be shown to approximate arbitrary convex functions via precise bounds. Furthermore we prove that the gradient of these functions can approximate the gradient of the convex function that they are approximating, making it a suitable choice for approximating arbitrary Bregman divergences.
The key application of our results is a generalization of the Mahalanobis metric learning problem to non-linear metrics. Metric learning is the task of learning a distance metric from supervised data such that the learned metric is tailored to a given task. The training data for a metric learning algorithm is typically either relative comparisons (A is more similar to B than to C) [19, 24, 26] or 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
Figure 1: (Left) Approximating a quadratic function via a max-afﬁne function. (Middle-left)
Bregman divergence approximation from every 2-d sample point to the speciﬁc point A in the data, as x varies around the circle. x to the speciﬁc point A in the data (Middle-right) Switches the roles of x and A (recall the BD is asymmetric) (Right) distances from points x to A using a Mahalanobis distance learned via linear metric learning (ITML). When this BD is used to deﬁne a Bregman divergence, points within a given class have a small learned divergence, leading to clustering, k-nn, and ranking performance of 98%+ (see experimental results for details). similar/dissimilar pairs (B and A are similar, B and C are dissimilar) [10]. This supervision may be available when underlying training labels are not directly available, such as from ranking data [20], but can also be obtained directly from class labels in a classiﬁcation task. In each of these settings, the learned similarity measure can be used downstream as the distance measure in a nearest neighbor algorithm, for similarity-based clustering [3, 19], to perform ranking [23], or other tasks.
Existing metric learning approaches are often divided into two classes, namely linear and non-linear methods. Linear methods learn linear mappings and compute distances (usually Euclidean) in the mapped space [10, 26, 11]; this approach is typically referred to as Mahalanobis metric learning.
These methods generally yield simple convex optimization problems, can be analyzed theoretically
[4, 8], and are applicable in many general scenarios. Non-linear methods, most notably deep metric learning algorithms, can yield superior performance but require a signiﬁcant amount of data to train and have little to no associated theoretical properties [28, 16]. As Mahlanaobis distances themselves are within the class of Bregman divergences, this paper shows how one can generalize the class of linear methods to encompass a richer class of possible learned divergences, including non-linear divergences, while retaining the strong theoretical guarantees of the linear case.
To highlight our main contributions, we
• Provide an explicit approximation error bound showing that piecewise linear functions can be used to approximate an underlying Bregman divergence with error O(K −1/d)
• Discuss a generalization error bound for metric learning in the Bregman setting of
Op(m−1/2), where m is the number of training points; this matches the bound known for the strictly less general Mahalanobis setting [4]
• Empirically validate our approach problems of ranking and clustering, showing that our method tends to outperform a wide range of linear and non-linear metric learning baselines.
Due to space constraints, many additional details and results have been put into the supplementary material; these include proofs of all bounds, discussion of the regression setting, more details on algorithms, and additional experimental results. 2