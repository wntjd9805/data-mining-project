Abstract
Learning disentangled representations is a key step towards effectively discovering and modelling the underlying structure of environments. In the natural sciences, physics has found great success by describing the universe in terms of symme-try preserving transformations. Inspired by this formalism, we propose a frame-work, built upon the theory of group representation, for learning representations of a dynamical environment structured around the transformations that generate its evolution. Experimentally, we learn the structure of explicitly symmetric en-vironments without supervision from observational data generated by sequential interactions. We further introduce an intuitive disentanglement regularisation to ensure the interpretability of the learnt representations. We show that our method enables accurate long-horizon predictions, and demonstrate a correlation between the quality of predictions and disentanglement in the latent space. 1

Introduction
Representation learning occupies a central place in the machine learning literature (Bengio et al. (2013); Ridgeway (2016)). A good representation should ideally reﬂect and disentangle the under-lying data generation mechanisms, and can be used to efﬁciently predict, classify, or generalize. For example, a robot learning to grasp a variety of objects would beneﬁt from having access to a repre-sentation that distinguishes between scene properties such as object color, size, or orientation (Suter et al. (2019)). However, learning interpretable representations of data that explicitly disentangle the underlying mechanisms structuring observational data is still a challenge.
To address this challenge, one can begin by drawing a parallel between the pursuit of underlying structure in machine learning and in physics. In machine learning, data is structured by its under-lying generative factors, which can be understood as the degrees of freedom that, when changed, independently and tractably modify the generated data. Physics often searches for structure using group representation theory by considering the inﬁnitesimal transformations that generate the sym-metry group of a physical environment (Lie (1893); Weinberg (1995)). In both physics and machine learning, one has to ﬁnd a faithful – and, ideally, interpretable – representation of these generative factors to structure the representation one has of the environment. This connection between repre-sentation learning in machine learning and representations in physics was previously highlighted in
Higgins et al. (2018). However, although Higgins et al. (2018) formalise a deﬁnition of disentangled representations by analogy to physics, if and how such disentangled representations can be learnt from environmental observations remains an open question.
∗All authors contributed equally 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
In this work, we address these challenges and extend the work of Higgins et al. (2018) by proposing a method for learning disentangled representations of dynamical environments from a dataset of past interactions. Our method focuses on learning the structure of the symmetry group ruling the environment’s transformations, where symmetry transformations are understood as transformations that do not change the nature of the objects in the environment. For this purpose, we represent dynamical environments by encoding observations as elements of a latent space and representing transformations as special orthogonal matrices that act linearly on the latent space. We also introduce an intuitive regularisation that encourages the disentanglement of the learned representations, and experimentally demonstrate that our method successfully learns the underlying structure of several different explicitly symmetric environments. 2