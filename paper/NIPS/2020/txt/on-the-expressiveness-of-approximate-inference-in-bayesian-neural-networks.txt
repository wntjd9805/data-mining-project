Abstract
While Bayesian neural networks (BNNs) hold the promise of being ﬂexible, well-calibrated statistical models, inference often requires approximations whose con-sequences are poorly understood. We study the quality of common variational methods in approximating the Bayesian predictive distribution. For single-hidden layer ReLU BNNs, we prove a fundamental limitation in function-space of two of the most commonly used distributions deﬁned in weight-space: mean-ﬁeld Gaus-sian and Monte Carlo dropout. We ﬁnd there are simple cases where neither method can have substantially increased uncertainty in between well-separated regions of low uncertainty. We provide strong empirical evidence that exact inference does not have this pathology, hence it is due to the approximation and not the model.
In contrast, for deep networks, we prove a universality result showing that there exist approximate posteriors in the above classes which provide ﬂexible uncertainty estimates. However, we ﬁnd empirically that pathologies of a similar form as in the single-hidden layer case can persist when performing variational inference in deeper networks. Our results motivate careful consideration of the implications of approximate inference methods in BNNs. 1

Introduction
Bayesian neural networks (BNNs) [27, 30] aim to combine the strong inductive biases and ﬂexibility of neural networks (NNs) with the probabilistic framework for uncertainty quantiﬁcation provided by Bayesian statistics. However, performing exact inference in BNNs is analytically intractable and requires approximations. A variety of scalable approximate inference techniques have been proposed, with mean-ﬁeld variational inference (MFVI) [15, 4] and Monte Carlo dropout (MCDO) [11] among the most used methods. These methods have been succesful in applications such as active learning and out-of-distribution detection [9, 33]. However, it is unclear to what extent the successes (and failures) of BNNs are attributable to the exact Bayesian predictive, rather than the peculiarities of the approximation method. From a Bayesian modelling perspective, it is therefore crucial to ask, does the approximate predictive distribution retain the qualitative features of the exact predictive?
Frequently, BNN approximations deﬁne a simple class of distributions over the model parameters, (an approximating family), and choose a member of this family as an approximation to the posterior.
∗Equal contribution. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
Both MFVI and MCDO follow this paradigm. For such a method to succeed, two criteria must be met:
Criterion 1 The approximating family must contain good approximations to the posterior.
Criterion 2 The method must then select a good approximate posterior within this family.
For nearly all tasks, the performance of a BNN only depends on the distribution over weights to the extent that it affects the distribution over predictions (i.e. in ‘function-space’). Hence for our purposes, a ‘good’ approximation is one that captures features of the exact posterior in function-space that are relevant to the task at hand. However, approximating families are often deﬁned in weight-space for computational reasons. Evaluating Criterion 1 therefore involves understanding how weight-space approximations translate to function-space, which is a non-trivial task for highly nonlinear models such as BNNs.
In this work we provide both theoretical and empirical analyses of the ﬂexibility of the predictive mean and variance functions of approximate BNNs. Our major ﬁndings are: 1. For shallow BNNs, there exist simple situations where no mean-ﬁeld Gaussian or MC dropout distribution can faithfully represent the exact posterior predictive uncertainty (Criterion 1 is not satisﬁed). We prove in section 3 that in these instances the variance function of any fully-connected, single-hidden layer ReLU BNN using these families suffers a lack of ‘in-between uncertainty’: increased uncertainty in between well-separated regions of low uncertainty. This is especially problematic for lower-dimensional data where we may expect some datapoints to be in between others. Examples include spatio-temporal data, or Bayesian optimisation for hyperparameter search, where we frequently wish to make predictions in unobserved regions in between observed regions.
We verify that the exact posterior predictive does not have this limitation; hence this pathology is attributable solely to the restrictiveness of the approximating family. 2. In section 4 we prove a universal approximation result showing that the mean and variance functions of deep approximate BNNs using mean-ﬁeld Gaussian or MCDO distributions can uni-formly approximate any continuous function and any continuous non-negative function respectively.
However, it remains to be shown that appropriate predictive means and variances will be found when optimising the ELBO. To test this, we focus on the low-dimensional, small data regime where comparisons to references for the exact posterior such as the limiting GP [30, 22, 28] are easier to make. In section 4.2 we provide empirical evidence that in spite of its theoretical ﬂexibility, VI in deep BNNs can still lead to distributions that suffer from similar pathologies to the shallow case, i.e. Criterion 2 is not satisﬁed.
In section 5, we provide an active learning case study on a real-world dataset showing how in-between uncertainty can be a crucial feature of the posterior predictive. In this case, we provide evidence that although the inductive biases of the BNN model with exact inference can bring considerable beneﬁts, these are lost when MFVI or MCDO are used. Code to reproduce our experiments can be found at https://github.com/cambridge-mlg/expressiveness-approx-bnns. 2