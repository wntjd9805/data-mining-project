Abstract
In many real-world scenarios, decision makers seek to efﬁciently optimize multiple competing objectives in a sample-efﬁcient fashion. Multi-objective Bayesian opti-mization (BO) is a common approach, but many of the best-performing acquisition functions do not have known analytic gradients and suffer from high computational overhead. We leverage recent advances in programming models and hardware acceleration for multi-objective BO using Expected Hypervolume Improvement (EHVI)—an algorithm notorious for its high computational complexity. We derive a novel formulation of q-Expected Hypervolume Improvement (qEHVI), an acqui-sition function that extends EHVI to the parallel, constrained evaluation setting. qEHVI is an exact computation of the joint EHVI of q new candidate points (up to
Monte-Carlo (MC) integration error). Whereas previous EHVI formulations rely on gradient-free acquisition optimization or approximated gradients, we compute exact gradients of the MC estimator via auto-differentiation, thereby enabling efﬁ-cient and effective optimization using ﬁrst-order and quasi-second-order methods.
Our empirical evaluation demonstrates that qEHVI is computationally tractable in many practical scenarios and outperforms state-of-the-art multi-objective BO algorithms at a fraction of their wall time. 1

Introduction
The problem of optimizing multiple competing objectives is ubiquitous in scientiﬁc and engineering applications. For example in automobile design, an automaker will want to maximize vehicle durability and occupant safety, while using lighter materials that afford increased fuel efﬁciency and lower manufacturing cost [44, 72]. Evaluating the crash safety of an automobile design experimentally is expensive due to both the manufacturing time and the destruction of a vehicle. In such a scenario, sample efﬁciency is paramount. For a different example, video streaming web services commonly use adaptive control policies to determine the bitrate as the stream progresses in real time [47]. A decision maker may wish to optimize the control policy to maximize the quality of the video stream, while minimizing the stall time. Policy evaluation typically requires using the suggested policy on segments of live trafﬁc, which is subject to opportunity costs. If long evaluation times are the limiting factor, multiple designs may be evaluated in parallel to signiﬁcantly decrease end-to-end optimization time. For example, an automaker could manufacture multiple vehicle designs in parallel or a web service could deploy several control policies to different segments of trafﬁc at the same time. 1.1