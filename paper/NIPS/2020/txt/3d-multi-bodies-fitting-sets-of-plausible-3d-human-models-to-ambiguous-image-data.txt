Abstract
We consider the problem of obtaining dense 3D reconstructions of humans from single and partially occluded views. In such cases, the visual evidence is usu-ally insufﬁcient to identify a 3D reconstruction uniquely, so we aim at recovering several plausible reconstructions compatible with the input data. We suggest that ambiguities can be modelled more effectively by parametrizing the possible body shapes and poses via a suitable 3D model, such as SMPL for humans. We propose to learn a multi-hypothesis neural network regressor using a best-of-M loss, where each of the M hypotheses is constrained to lie on a manifold of plausible human poses by means of a generative model. We show that our method outperforms alternative approaches in ambiguous pose recovery on standard benchmarks for 3D humans, and in heavily occluded versions of these benchmarks. 1

Introduction
We are interested in reconstructing 3D human pose from the observation of single 2D images. As humans, we have no problem in predicting, at least approximately, the 3D structure of most scenes, including the pose and shape of other people, even from a single view. However, 2D images notori-ously [9] do not contain sufﬁcient geometric information to allow recovery of the third dimension.
Hence, single-view reconstruction is only possible in a probabilistic sense and the goal is to make the posterior distribution as sharp as possible, by learning a strong prior on the space of possible solutions.
Recent progress in single-view 3D pose reconstruction has been impressive. Methods such as
HMR [17], GraphCMR [20] and SPIN [19] formulate this task as learning a deep neural network that maps 2D images to the parameters of a 3D model of the human body, usually SMPL [26]. These methods work well in general, but not always (ﬁg. 2). Their main weakness is processing heavily occluded images of the object. When a large part of the object is missing, say the lower body of a sitting human, they output reconstructions that are often implausible. Since they can produce only one hypothesis as output, they very likely learn to approximate the mean of the posterior distribu-tion, which may not correspond to any plausible pose. Unfortunately, this failure modality is rather common in applications due to scene clutter and crowds.
In this paper, we propose a solution to this issue. Speciﬁcally, we consider the challenge of recover-ing 3D mesh reconstructions of complex articulated objects such as humans from highly ambiguous
∗work completed during internship at Facebook AI Research 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
Figure 1: Human mesh recovery in an ambiguous setting. We propose a novel method that, given an occluded input image of a person, outputs the set of meshes which constitute plausible human bodies that are consistent with the partial view. The ambiguous poses are predicted using a novel n-quantized-best-of-M method. image data, often containing signiﬁcant occlusions of the object. Clearly, it is generally impossible to reconstruct the object uniquely if too much evidence is missing; however, we can still predict a set containing all possible reconstructions (see ﬁg. 1), making this set as small as possible. While ambiguous pose reconstruction has been previously investigated, as far as we know, this is the ﬁrst paper that looks speciﬁcally at a deep learning approach for ambiguous reconstructions of the full human mesh.
Our primary contribution is to introduce a principled multi-hypothesis framework to model the am-biguities in monocular pose recovery. In the literature, such multiple-hypotheses networks are often trained with a so-called best-of-M loss — namely, during training, the loss is incurred only by the best of the M hypothesis, back-propagating gradients from that alone [12]. In this work we opt for the best-of-M approach since it has been show to outperform alternatives (such as variational auto-encoders or mixture density networks) in tasks that are similar to our 3D human pose recovery, and which have constrained output spaces [34].
A major drawback of the best-of-M approach is that it only guarantees that one of the hypotheses lies close to the correct solution; however, it says nothing about the plausibility, or lack thereof, of the other M − 1 hypothe-ses, which can be arbitrarily ‘bad’.2 Not only does this mean that most of the hypotheses may be uninformative, but in an application we are also unable to tell which hy-pothesis should be used, and we might very well pick a
‘bad’ one. This has also a detrimental effect during learn-ing because it makes gradients sparse as prediction errors are back-propagated only through one of the M hypothe-ses for each training image.
In order to address these issues, our ﬁrst contribution is a hypothesis reprojection loss that forces each member of the multi-hypothesis set to correctly reproject to 2D image keypoint annotations. The main beneﬁt is to con-strain the whole predicted set of meshes to be consistent with the observed image, not just the best hypothesis, also addressing gradient sparsity.
Figure 2: Top: Pretrained SPIN model tested on an ambiguous example, Bot-tom: SPIN model after ﬁne-tuning to ambiguous examples. Note the network tends to regress to the mean over plau-sible poses, shown by predicting the missing legs vertically downward — ar-guably the average position over the training dataset.
Next, we observe that another drawback of the best-of-M pipelines is to be tied to a particular value of M , whereas in applications we are often interested in tuning the num-ber of hypothesis considered. Furthermore, minimizing the reprojection loss makes hypotheses geometrically consistent with the observation, but not necessarily likely. Our second contribution is thus to improve the ﬂexibility of best-of-M models by allowing them to output any smaller number 2 Theoretically, best-of-M can minimize its loss by quantizing optimally (in the sense of minimum expected distortion) the posterior distribution, which would be desirable for coverage. However, this is not the only solution that optimizes the best-of-M training loss, as in the end it is sufﬁcient that one hypothesis per training sample is close to the ground truth. In fact, this is exactly what happens; for instance, during training hypotheses in best-of-M are known to easily become degenerate and ‘die off’, a clear symptom of this problem. 2
n < M of hypotheses while at the same time making these hypotheses more representative of likely poses. The new method, which we call n-quantized-best-of-M , does so by quantizing the best-of-M model to output weighed by a explicit pose prior, learned by means of normalizing ﬂows.
To summarise, our key contributions are as follows. First, we deal with the challenge of 3D mesh reconstruction for articulated objects such as humans in ambiguous scenarios. Second, we introduce a n-quantized-best-of-M mechanism to allow best-of-M models to generate an arbitrary number of n < M predictions. Third, we introduce a mode-wise re-projection loss for multi-hypothesis prediction, to ensure that predicted hypotheses are all consistent with the input.
Empirically, we achieve state-of-the-art monocular mesh recovery accuracy on Human36M, its more challenging version augmented with heavy occlusions, and the 3DPW datasets. Our ablation study validates each of our modelling choices, demonstrating their positive effect. 2