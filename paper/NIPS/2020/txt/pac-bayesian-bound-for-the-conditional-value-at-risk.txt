Abstract
Conditional Value at Risk (CVAR) is a family of “coherent risk measures” which generalize the traditional mathematical expectation. Widely used in mathematical
ﬁnance, it is garnering increasing interest in machine learning, e.g., as an alternate approach to regularization, and as a means for ensuring fairness. This paper presents a generalization bound for learning algorithms that minimize the CVAR of the empirical loss. The bound is of PAC-Bayesian type and is guaranteed to be small when the empirical CVAR is small. We achieve this by reducing the problem of estimating CVAR to that of merely estimating an expectation. This then enables us, as a by-product, to obtain concentration inequalities for CVAR even when the random variable in question is unbounded. 1

Introduction
=
[
`
`
` (
E
̂
R n i
X
R 1 `
∈ H h, X h, X h, X h, Xi 0, where
∶ H × X → is given by R
H n. When choosing an hypothesis ˆh based on the empirical risk
R
The goal in statistical learning is to learn hypotheses that generalize well, which is typically formalized by seeking to minimize the expected risk associated with a given loss function. In general, a loss func-tion is a map ` is an hypotheses space. In this case, is a feature space and the expected risk associated with a given hypothesis h
.
≥
Since the data-generating distribution is typically unknown, the expected risk is approximated using observed i.i.d. samples X1, . . . , Xn of X, and an hypothesis is then chosen to minimize the empirical
)]
R, risk
ˆh, X
` one would like to know how close
; only then can one
̂
)] ∶= ∑
)￿ infer something about the generalization property of the learned hypothesis ˆh. (
[
Generalization bounds—in which the expected risk is bounded in terms of its empirical version up to some error—are at the heart of many machine learning problems. The main techniques leading to such bounds comprise uniform convergence arguments (often involving the Rademacher complexity of the set
), algorithmic stability arguments (see e.g. [Bousquet and Elisseeff, 2002] and more recently the work from [Abou-Moustafa and Szepesvári, 2019, Bousquet et al., 2019, Celisse and
Guedj, 2016]), and the PAC-Bayesian analysis for non-degenerate randomized estimators [McAllester, 2003]. Behind these techniques lies concentration inequalities, such as Chernoff’s inequality (for the PAC-Bayesian analysis) and McDiarmid’s inequality (for algorithmic stability and the uniform convergence analysis), which control the deviation between population and empirical averages [see
Boucheron et al., 2003, 2013, McDiarmid, 1998, among others]. is to the actual risk R
ˆh, X
)] ∶=
H
)]
)]
̂ ( ( ( (
`
[
[
[
Standard concentration inequalities are well suited for learning problems where the goal is to minimize the expected risk E
. However, the expected risk—the mean performance of an algorithm—might fail to capture the underlying phenomenon of interest. For example, when h, X
` 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
[ (
)]
dealing with medical (responsitivity to a speciﬁc drug with grave side effects, etc.), environmental (such as pollution, exposure to toxic compounds, etc.), or sensitive engineering tasks (trajectory evaluation for autonomous vehicles, etc.), the mean performance is not necessarily the best objective to optimize as it will cover potentially disastrous mistakes (e.g., a few extra centimeters when crossing another vehicle, a slightly too large dose of a lethal compound, etc.) while possibly improving on average. There is thus a growing interest to work with alternative measures of risk (other than the expectation) for which standard concentration inequalities do not apply directly. Of special interest are coherent risk measures [Artzner et al., 1999] which possess properties that make them desirable in mathematical ﬁnance and portfolio optimization [Allais, 1953, Ellsberg, 1961, Rockafellar et al., 2000], with a focus on optimizing for the worst outcomes rather than on average. Coherent risk measures have also been recently connected to fairness, and appear as a promising framework to control the fairness of an algorithm’s solution [Williamson and Menon, 2019]. 0, 1 and random variable Z, CVAR↵
A popular coherent risk measure is the Conditional Value at Risk (CVAR; see Pﬂug, 2000); for measures the expectation of Z conditioned on the
↵ event that Z is greater than its
-th quantile. CVAR has been shown to underlie the classical
SVM [Takeda and Sugiyama, 2008], and has in general attracted a large interest in machine learning over the past two decades [Bhat and Prashanth, 2019, Chen et al., 2009, Chow and Ghavamzadeh, 2014, Huo and Fu, 2017, Morimura et al., 2010, Pinto et al., 2017, Prashanth and Ghavamzadeh, 2013, Takeda and Kanamori, 2009, Tamar et al., 2015, Williamson and Menon, 2019].
∈ (
Z
↵
− 1 (
)
)
[
]
, under different assumptions on
Various concentration inequalities have been derived for CVAR↵
Z, which bound the difference between CVAR↵
Z with high probability [Bhat and Prashanth, 2019, Brown, 2007, Kolla et al., 2019, Prashanth and Ghavamzadeh, 2013, Wang and Gao, 2010]. However, none of these works extend their results to the statistical
] learning setting where the goal is to learn an hypothesis from data to minimize the conditional value at risk. In this paper, we ﬁll this gap by presenting a sharp PAC-Bayesian generalization bound when the objective is to minimize the conditional value at risk. and its standard estimator
[
CVAR↵
￿
Z
]
]
[
[
Z