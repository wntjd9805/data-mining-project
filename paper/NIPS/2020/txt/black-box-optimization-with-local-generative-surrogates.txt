Abstract
We propose a novel method for gradient-based optimization of black-box simu-lators using differentiable local surrogate models. In ﬁelds such as physics and engineering, many processes are modeled with non-differentiable simulators with intractable likelihoods. Optimization of these forward models is particularly chal-lenging, especially when the simulator is stochastic. To address such cases, we introduce the use of deep generative models to iteratively approximate the simu-lator in local neighborhoods of the parameter space. We demonstrate that these local surrogates can be used to approximate the gradient of the simulator, and thus enable gradient-based optimization of simulator parameters. In cases where the dependence of the simulator on the parameter space is constrained to a low dimensional submanifold, we observe that our method attains minima faster than baseline methods, including Bayesian optimization, numerical optimization, and approaches using score function gradient estimators. 1

Introduction
Computer simulation is a powerful method that allows for the modeling of complex real-world systems and the estimation of a system’s parameters given conditions and constraints. Simulators drive research in many ﬁelds of engineering and science [13] and are also used for the generation of synthetic labeled data for various tasks in machine learning [52, 49, 50, 7]. A common challenge is to ﬁnd optimal parameters of a simulated system in terms of a given objective function, e.g., to optimize a real-world system’s design or efﬁciency using the simulator as a proxy, or to calibrate a simulator to generate data that match a real-data distribution. A typical simulator optimization problem can be deﬁned as ﬁnding ψ∗ = arg minψ x R(F (x, ψ)), where R is an objective we (cid:80)
∗Equal contribution 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
Figure 1: Simulation and surrogate training. Black: forward propagation. Red: error backpropagation. would like to minimize and F is a simulator that we take as a black box with parameters ψ ∈ Rn and inputs x ∈ Rd.
In this work, we focus on cases where the simulator and its inputs are stochastic, so that y = F (x, ψ) is a random variable y ∼ p(y|x; ψ), the inputs are x ∼ q(x), and the objective is expressed as the expectation Ep(y|x;ψ)[R(y)]. Note that the choice of modeling the simulator inputs x as random reﬂects the situation common in scientiﬁc simulation settings, and our methods are equally applicable for the case without stochastic inputs such that y ∼ p(y; ψ).
In many settings the cost of running the simulator is high, and thus we aim to minimize the number of simulator calls needed for optimization. Such stochastic simulator optimization occurs in an array of scientiﬁc and engineering domains, especially in cases of simulation-based optimization relying on Monte Carlo techniques. Examples include optimization for particle scattering simulators [56], radiation transport simulators [4], and molecular dynamics simulation [1]. In some domains, this is also referred to as design optimization [44].
Several methods exist for such optimization, depending on the availability of gradients for the objective function [36]. While gradient-based optimization has been demonstrated to work well for differentiable objective functions [30, 11, 14, 15], non-differentiable objective functions occur frequently in practice, e.g., where one aims to optimize the parameters of a system characterized by a
Monte Carlo simulator that may only produce data samples from an intractable likelihood [13]. In such cases, genetic algorithms [44, 5], Bayesian optimization [58, 55], or numerical differentiation [62] are frequently employed. More recently stochastic gradient estimators [41] such as the REINFORCE [65] estimator, have been employed to estimate gradients of non-differentiable functions [60, 12] and subsequently perform gradient-based optimization.
In order to utilize the strengths of gradient-based optimization while avoiding the high variance often observed with score function gradient estimators, our approach employs deep generative models as differentiable surrogate models to approximate non-differentiable simulators, as described in
Figure 1. Using these surrogates, we show that we can both approximate the stochastic behavior of the simulator and enable direct gradient-based optimization of an objective by parameterizing the surrogate model with the relevant parameters of the simulator. In high-dimensional parameter spaces, training such surrogates over the complete parameter space becomes computationally expensive. Our technique, which we name local generative surrogate optimization (L-GSO), addresses this by using successive local neighborhoods of the parameter space to train surrogates at each step of parameter optimization. Our method works especially well when the parameters, which are seemingly high dimensional, live on a lower dimensional submanifold, as seen in practice in a variety of settings [29].
L-GSO relies primarily on two assumptions: (a) that the objective function is continuous and differentiable, and (b) that the parameters ψ are continuous variables. The ﬁrst assumption may be relaxed by incorporating the objective into the surrogate.
In Section 2 we describe the L-GSO algorithm. We cover related work in Section 3. In Section 4 we evaluate L-GSO on a set of toy problems and compare it with frequently used methods including numerical differentiation, Bayesian optimization, and score function-based approaches, and present results of a realistic use case in the high-energy physics domain. Section 5 presents our conclusions. 2 Method
Problem Statement We target an optimization formulation applicable in domains where a simulator characterized by parameters ψ takes stochastic inputs x ∼ q(x) and produces outputs (observations) 2
y ∼ p(y|x; ψ). For example in the case of designing the shape of an experimental device, x may represent random inputs to an experimental apparatus, ψ deﬁnes the shape of the apparatus, and p(y|x; ψ) encodes the impact of the apparatus on the input to produce observations y. A task-speciﬁc objective function R(y) encodes the quality of observations and may be optimized over the parameters ψ of the observed distribution. In cases when a simulator F can only draw samples from the distributions p(y|x; ψ) the optimization problem can be approximated as
ψ∗ = arg min
E[R(y)] = arg min
ψ
ψ (cid:90)
R(y)p(y|x; ψ)q(x)dxdy
≈ arg min
ψ 1
N
N (cid:88) i=1
R(F (xi; ψ)) (1) where yi = F (xi; ψ) ∼ p(y|x; ψ), xi ∼ q(x) and a Monte Carlo approximation to the expected value of the objective function is computed using samples drawn from the simulator. Note that F represents a stochastic process, which may itself depend on latent random variables. 2.1 Deep generative models as differentiable surrogates
Given a non-differentiable simulator F , direct gradient-based optimization of Eq. 1 is not possible. We propose to approximate F with a learned differentiable model, denoted a surrogate, ¯y = Sθ(z, x; ψ) that approximates F (x; ψ), where z ∼ p(z) are latent variables accounting for the stochastic variation of the distribution p(y|x; ψ), θ are surrogate model parameters, and ¯y are surrogate outputs.
When the samples ¯y are differentiable with respect to ψ, direct optimization of Eq. 1 can be done with the surrogate gradient estimator:
∇ψ E[R(y)] ≈ 1
N
N (cid:88) i=1
∇ψR(Sθ(zi, xi; ψ)) . (2)
To obtain a differentiable surrogate capable of modeling a stochastic process, Sθ is deﬁned as a deep generative model whose parameters θ are learned. Generative model learning can be done independently of the simulator optimization in Eq. 1 as it only requires samples from the simulator to learn the stochastic process. Once learned, the generative surrogate can produce differentiable samples that are used to approximate the integration for the expected value of the objective function. Several types of generative models can be used, including generative adversarial networks (GANs) [21], variational autoencoders [35, 48], or ﬂow-based models [47]. We present results using conditional variants of two recently proposed models, Cramer GAN [8] and the FFJORD continuous ﬂow model [23], to show the independence of L-GSO from the choice of generative model. 2.2 Local generative surrogates
The L-GSO optimization algorithm is summarized in Algorithm 1. Using a sample of values for ψ and input samples of x, a set of training samples for the surrogate are created from the simulator
F . The surrogate training step 8 refers to the standard training procedures for the chosen generative model (details on model architectures and hyperparameters are given in Appendix A). The learned surrogate is used to estimate the gradient of the objective function with backpropagation through the computed expectation of Eq. 2 with respect to ψ. Subsequently ψ is updated with a gradient descent procedure, denoted SGD (stochastic gradient descent) in the algorithm. Due to the use of SGD, an inherently noisy optimization algorithm, the surrogate does not need to be trained until convergence but only sufﬁciently well to provide gradients correlated with the true gradient that produce useful
SGD updates. The level of correlation will control the speed of convergence of the method.
For high-dimensional ψ, a large number of parameter values ψ must be sampled to accurately train a single surrogate model. Otherwise the surrogate would not provide sufﬁciently well estimated gradients over the full parameter space that may be explored by the optimization. Thus optimization using a single upfront training of the surrogate model over all ψ becomes unfeasible. As such, we utilize a trust-region-like approach [59] to train a surrogate model locally in the proximity of the current parameter value ψ. We sample new ψ(cid:48) around the current point ψ from the set
U ψ i − ψi| ≤ (cid:15), ∀i ∈ {1, . . . , n}}. Using this local model, a gradient at the current point
ψ can be obtained and a step of SGD performed. After each SGD update of ψ, a new local surrogate (cid:15) = {ψ(cid:48) : |ψ(cid:48) 3
is trained. As a result, we do not expect domain shift to impact L-GSO as it is retrained at each new parameter point. in step 3 of Algorithm 1.
In local optimization there are several hyper-parameters that require tuning either prior to or dynamically during optimization. One must choose the sampling algorithm for ψ values in the region U ψ
In (cid:15) high-dimensional space, uniform sampling is inefﬁcient, thus we have adopted the Latin Hy-percubes algorithm [31].2 One must also choose a proximity hyperparameter (cid:15), that controls the size of the region of ψi in which a set of ψ val-ues is chosen to train a local surrogate.3 This hyperparameter is similar to the step size used in numerical differentiation, affecting the speed of convergence as well as the overall behavior of the optimization algorithm; if (cid:15) is too large or too small the algorithm may diverge. In this paper we report experimental results with this hyperparameter tuned based on a grid search.
The value of (cid:15) = 0.2 was found to be robust and work well in all experiments except the "three hump problem" which required a slightly larger value of (cid:15) = 0.5. More details can be found in
Appendix C.
Algorithm 1 Local Generative Surrogate Opti-mization (L-GSO) procedure
Require: number N of ψ, number M of x for surro-gate training, number K of x for ψ optimization step, trust region U(cid:15), size of the neighborhood (cid:15),
Euclidean distance d 6: j}M j=1 ∼ q(x) (cid:15) , i = 1, . . . , N 1: Choose initial parameter ψ 2: while ψ has not converged do i in the region U ψ
Sample ψ(cid:48) 3:
For each ψ(cid:48) i, sample inputs {xi 4:
Sample M × N training examples from 5: j; ψ(cid:48) simulator yij = F (xi i)
Store yij, xi j, ψ(cid:48) i in history H i = 1, . . . , N ; j = 1, . . . , M
Extract all yl, xl, ψ(cid:48) iff d(ψ, ψ(cid:48)
Train generative surrogate model
Sθ(zl, xl; ψ(cid:48) l), where zl ∼ N (0, 1)
Fix weights of the surrogate model θ
Sample ¯yk = Sθ(zk, xk; ψ), zk ∼ N (0, 1), xk ∼ q(x), k = 1, . . . , K l from history H, l) < (cid:15) 7: 8: 9: 10: 11: ∇ψ E[R( ¯y)] ← 1
∂R
∂ ¯yk
K 12: ψ ← SGD(ψ, ∇ψ E[R( ¯y)]) 13: end while
K (cid:80) k=1
∂Sθ (zk,xk;ψ)
∂ψ
The number of ψ values sampled in the neigh-borhood is another key hyperparameter. We ex-pect the optimal value to be highly correlated with the dimensionality and complexity of the problem.
In our experiments, we examine the quality of gradient estimates as a function of the number of points used for training the local surrogate. We observe that it is sufﬁcient to sample O(D) samples in the neighborhood of ψ, where D is the full parameter space dimensionality of ψ. In this case, our approach is observed to be similar to numerical optimization which expects O(D) samples for performing a gradient step [62]. However, in cases where the components of ψ relevant for the optimization lie on a manifold of dimensionality lower than D, i.e., intrinsic dimensionality d is smaller than D, we observe that L-GSO requires O(d) samples for producing a reasonable gradient step, thus leading to the faster convergence of L-GSO than other methods.
Previously sampled data points can also be stored in history and later reused in our local optimization procedure (Algorithm 1). This provides additional training points for the surrogate as the optimization progresses and results in a better surrogate model and, consequently, better gradient estimation. The ability of L-GSO to reuse previous samples is a crucial point to reduce the overall number of calls to the simulator. This procedure was observed to aid both FFJORD and GAN models to attain the minimum faster and to prevent the optimization from diverging once the minimum has been attained.
A beneﬁt of our approach in comparison with numerical gradient estimation is that a deep generative surrogate can learn more complex approximations of the objective function than a linear approxima-tion, which can be beneﬁcial to obtain gradients for surfaces with high curvature. We believe that this is mainly due to the implicit regularization afforded by generative neural network architectures [67].
In addition, using generative neural networks as surrogates provides other potential beneﬁts such as
Hessian estimation, that may be used for second-order optimization algorithms and/or uncertainty estimation, and possible automatic determination of a low-dimensional parameter manifold. While we do not have theoretical guarantees for the convergence of L-GSO, empirically we do not observe bias in the estimated gradients when performing gradient descent as seen in Section 4. 2A detailed study of alternative sampling techniques is left for future work. 3For a deterministic simulator this parameter could be chosen proportionally to learning rate. If the objective function is stochastic, one might want to choose (cid:15) big enough so that E |R(yψ−(cid:15))−R(yψ+(cid:15)))| > Var(R(yψ)). 4
3