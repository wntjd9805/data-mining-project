Abstract
Data augmentation has been actively studied for robust neural networks. Most of the recent data augmentation methods focus on augmenting datasets during the training phase. At the testing phase, simple transformations are still widely used for test-time augmentation. This paper proposes a novel instance-level test-time augmentation that efﬁciently selects suitable transformations for a test input.
Our proposed method involves an auxiliary module to predict the loss of each possible transformation given the input. Then, the transformations having lower predicted losses are applied to the input. The network obtains the results by averaging the prediction results of augmented inputs. Experimental results on several image classiﬁcation benchmarks show that the proposed instance-aware test-time augmentation improves the model’s robustness against various corruptions. 1

Introduction
Various autonomous systems (e.g., autonomous vehicle [11], medical diagnosis [2, 58], fault detection in the manufacturing process [27]) try to adopt neural networks as visual recognition module. The neural networks efﬁciently learn visual patterns to classify critical objects such as humans on the roads, cancers in our body, and manufacturing products’ faults. Although recent research on deep learning with the benchmark datasets has shown promising results [5, 44], robustness problems can arise in real-world applications. As shown in previous works [19, 20, 15], the classiﬁcation result can be easily broken even with slight deformations to the input image. In processing an input image using neural networks in real-world situations, several variations or corruptions can occur, leading to unexpected results [38]. Ensuring robustness is mission-critical in many applications, so many researchers have focused on the problem of neural networks [16, 51, 35, 3, 39, 31].
Recently, advanced data augmentation techniques have been proposed to improve the robustness of neural networks [47, 57, 7, 59, 55, 5, 29]. Automatically searching augmentation policies in a data-driven manner [5, 29] is critical to achieve the state-of-the-art result [23, 44]. Although the methods enhance the robustness of networks signiﬁcantly, there are potentials to improve the performance with data augmentation in the testing phase. We empirically observe that simple deformations of input images at test time cause signiﬁcant performance drop even the network is trained with advanced data augmentation. Moreover, we verify that there is still a large room to improve the trained network’s performance with the appropriate data transformation at the testing phase.
Test-time augmentation of the input data has often been used to produce more robust prediction results. Given a test input image, it averages the network’s predictions over multiple transformations
∗Equal Contribution.
†Corresponding Author. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
Figure 1: Conceptual comparison between conventional test-time augmentation and the proposed test-time augmentation. (a) Conventional test-time augmentation. (b) Our proposed test-time aug-mentation. Previous test-time augmentations use preﬁxed transformations regardless of input. On the other hand, our method predicts the loss value for each transformation before choosing one or a few.
Note that this ﬁgure shows only one augmentation is selected by predicted losses, i.e. k = 1. for ensemble effect [26, 43, 18]. However, previous test-time augmentation methods have adopted simple geometric transformations such as horizontal, vertical ﬂips, and rotations of 90 degrees
[4, 53]. To validate the naive transformations, they augment every input image in substantial amounts
[24, 50, 49]. The procedures naturally increase the inference cost at test time. More recently, [32] proposed a learnable test-time augmentation method to ﬁnd static policies from extended search space.
Nevertheless, it performs a greedy search on the test set that is not optimal for each input image. It also requires an average ensemble of dozens of augmented inputs to improve the performance.
In this work, we propose an instance-aware test-time augmentation algorithm. With a pre-trained target network, the proposed method aims to select optimal transformations for each test input dynamically. The method requires measuring the expected effects of each candidate transformation to classify the image accurately. We develop a separate network to predict the loss of transformed images (see Figure 1). Note that the loss reﬂects both the correctness and the certainty of the classiﬁcation result. To produce the ﬁnal classiﬁcation result, we average the target network’s average classiﬁcation outputs over the transformations having lower predicted losses. We compare the proposed test-time augmentation with the previous approaches on two benchmark datasets. The results demonstrate that our proposed method achieves more robust performances on deformed datasets. The proposed method is efﬁcient: 1) the loss prediction network is compact, and 2) the instance-level selection can signiﬁcantly reduce the number of augmentations for ensembling. To the best of our knowledge, the proposed method is the ﬁrst instance-aware test-time augmentation method.
Our main contributions can be summarized as follows:
• We propose the instance-aware test-time augmentation algorithm based on the loss predictor.
The method enhances image classiﬁcation performances by dynamically selecting test-time transformations according to the expected losses.
• The proposed loss predictor can efﬁciently predict relative losses for all candidate trans-formations. The predictor makes it possible to select appropriate transformations at the instance level without a high computational burden.
• Compared with predeﬁned test-time augmentation methods, we demonstrate the effective-ness of the proposed method on image classiﬁcation tasks. Especially, we validate the enhanced robustness of the proposed method empirically against deformations at test time. 2