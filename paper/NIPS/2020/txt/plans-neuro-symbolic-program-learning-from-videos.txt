Abstract
Recent years have seen the rise of statistical program learning based on neural models as an alternative to traditional rule-based systems for programming by example. Rule-based approaches offer correctness guarantees in an unsupervised way as they inherently capture logical rules, while neural models are more realisti-cally scalable to raw, high-dimensional input, and provide resistance to noisy I/O speciﬁcations. We introduce PLANS (Program LeArning from Neurally inferred
Speciﬁcations), a hybrid model for program synthesis from visual observations that gets the best of both worlds, relying on (i) a neural architecture trained to extract abstract, high-level information from each raw individual input (ii) a rule-based system using the extracted information as I/O speciﬁcations to synthesize a pro-gram capturing the different observations. In order to address the key challenge of making PLANS resistant to noise in the network’s output, we introduce a dynamic
ﬁltering algorithm for I/O speciﬁcations based on selective classiﬁcation tech-niques. We obtain state-of-the-art performance at program synthesis from diverse demonstration videos in the Karel and ViZDoom environments, while requiring no ground-truth program for training. 1

Introduction
The problem of automatically generating a program satisfying given speciﬁcations is a long-standing challenge of artiﬁcial intelligence (Waldinger, Lee, 1969). The sub-area of inductive program synthesis, also known as programming by example (Gulwani, 2011), focuses on speciﬁcations formed of examples of desired I/O program behavior. In existing systems, I/O examples typically are instances of simple programming data types such as booleans, integers, ﬂoats or strings, or elementary data structures such as lists. Extending programming by example to more complex input domains is a very useful task, as it opens the range of possible real-world applications. Sun et al. (2018) made an important step in this direction by introducing the task of program synthesis from diverse demonstrations videos. This is a supervised learning problem in which the input is a set of videos of an agent’s behavior provided as raw visual input, and the desired output is a program summarizing the decision making logic (or policy) of this agent. From the point of view of imitation learning, this task is important because policies represented as programs might generalize more strongly outside the training distribution, require less data to learn, and allow formal veriﬁcation of safety properties.
Inductive synthesis techniques can be divided in two categories. The traditional symbolic or rule-based approaches (Jha et al., 2010; Alur et al., 2013) typically rely on efﬁcient search through a user-deﬁned domain speciﬁc language, leveraging constraint solvers based on SAT and SMT solving for search-space pruning. Alternatively, recent efforts aim at leveraging statistical learning methods, by phrasing inductive synthesis as a supervised learning task (Gaunt et al., 2016; Parisotto et al., 2017). Rule-based approaches have several advantages: they offer guarantees that the generated program is correct (i.e., satisﬁes the provided speciﬁcations). Additionally, they demonstrate better generalization to unseen inputs. The latter was experimentally shown by Gaunt et al. (2016) in the 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
Terpret framework, and conﬁrmed by Devlin et al. (2017) on the FlashFill benchmark (Gulwani et al., 2012). However, they are computationally expensive and can suffer from scalability issues.
As a result, they are inherently unable to handle raw visual input. Besides, they struggle to deal with incorrect input as they systematically attempt to satisfy all examples. Statistical approaches (see Allamanis et al. (2018) for a survey) appear as a way to mitigate these problems, by handling images (Ellis et al., 2018), scenes (Liu et al., 2019) or videos (Sun et al., 2018) as inputs, and learning to be robust against noise (Devlin et al., 2017). But this comes at the cost of generating large datasets labeled with ground-truth programs for training.
We introduce PLANS, a hybrid model for program synthesis from demonstration videos that combines neural and rule-based techniques in order to get the best of both worlds. It has two components:
First, a neural architecture is trained to infer a high-level description of each individual behavior from raw visual observation. Second, a rule-based solver uses the information inferred by the network as
I/O speciﬁcations to synthesize a program capturing the different behaviors. The neural component allows to handle raw visual input by transforming it into abstract speciﬁcations, while the rule-based system removes the need for ground-truth programs by inherently capturing logical rules. Therefore, our model uses strictly less supervision than prior work. We address the key challenge of making
PLANS robust to the noise introduced by the imperfect inference of speciﬁcations, which has a dramatic impact on the solver’s performance if not properly handled. Speciﬁcally, we introduce an adaptive ﬁltering algorithm for I/O speciﬁcations based on selective classiﬁcation techniques, in which only high-conﬁdence predictions are passed to the solver. Using this method, PLANS clearly outperforms previous methods (Sun et al., 2018; Duan et al., 2019). Finally, our model maintains a reasonable temporal complexity, as it relies on several independent solver calls that can be performed in parallel. To summarize, we make the following contributions:
• We develop a neural architecture for inferring I/O speciﬁcations from videos and an encoding of the synthesis task into an off-the-shelf rule-based solver (Rosette (Torlak, Bodik, 2013)).
• We address the key problem of making the rule-based solver robust to noise in the network’s output by developing an adaptive ﬁltering algorithm for speciﬁcations.
• We evaluate PLANS on the Karel and ViZDoom benchmarks and show signiﬁcant perfor-mance improvements compared to state-of-the-art end-to-end neural architectures, despite using strictly less supervision signals. 2