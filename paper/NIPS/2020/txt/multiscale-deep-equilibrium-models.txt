Abstract
We propose a new class of implicit networks, the multiscale deep equilibrium model (MDEQ), suited to large-scale and highly hierarchical pattern recognition domains.
An MDEQ directly solves for and backpropagates through the equilibrium points of multiple feature resolutions simultaneously, using implicit differentiation to avoid storing intermediate states (and thus requiring only O(1) memory consumption).
These simultaneously-learned multi-resolution features allow us to train a single model on a diverse set of tasks and loss functions, such as using a single MDEQ to perform both image classiﬁcation and semantic segmentation. We illustrate the effectiveness of this approach on two large-scale vision tasks: ImageNet classiﬁ-cation and semantic segmentation on high-resolution images from the Cityscapes dataset. In both settings, MDEQs are able to match or exceed the performance of recent competitive computer vision models: the ﬁrst time such performance and scale have been achieved by an implicit deep learning approach. The code and pre-trained models are at ❤tt♣s✿✴✴❣✐t❤✉❜✳❝♦♠✴❧♦❝✉s❧❛❜✴♠❞❡q. 1

Introduction
State-of-the-art pattern recognition systems in domains such as computer vision and audio processing are almost universally based on multi-layer hierarchical feature extractors [33, 35, 36]. These models are structured in stages: the input is processed via a number of consecutive blocks, each operating at a different resolution [32, 54, 51, 26]. The architectures explicitly express hierarchical structure, with up- and downsampling layers that transition between consecutive blocks operating at different scales.
An important motivation for such designs is the prominent multiscale structure and extremely high signal dimensionalities in these domains. A typical image, for instance, contains millions of pixels, which must be processed coherently by the model.
An alternative approach to differentiable modeling is exempliﬁed by recent progress on implicit deep networks, such as Neural ODEs (NODEs) [12] and deep equilibrium models (DEQs) [5]. These constructions replace explicit, deeply stacked layers with analytical conditions that the model must satisfy, and are able to simulate models with “inﬁnite” depth within a constant memory footprint. A notable achievement for implicit modeling is its successful application to large-scale sequences in natural language processing [5].
Is implicit deep learning relevant for general pattern recognition tasks? One clear challenge here is that implicit networks do away with ﬂexible “layers” and “stages”. It is therefore not clear whether they can appropriately model multiscale structure, which appears essential to high discriminative power in some domains. This is the challenge that motivates our work. Can implicit models that forego deep sequences of layers and stages attain competitive accuracy in domains characterized by rich multiscale structure, such as computer vision?
To address this challenge, we introduce a new class of implicit networks: the multiscale deep equilib-rium model (MDEQ). It is inspired by DEQs, which attained high accuracy in sequence modeling [5].
We expand upon the DEQ construction substantially to introduce simultaneous equilibrium modeling 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
of multiple signal resolutions. MDEQ solves for equilibria of multiple resolution streams simul-taneously by directly optimizing for stable representations on all feature scales at the same time.
Unlike standard explicit deep networks, MDEQ does not process different resolutions in succession, with higher resolutions ﬂowing into lower ones or vice versa. Rather, the different feature scales are maintained side by side in a single “shallow” model that is driven to equilibrium.
This design brings two major advantages. First, like the basic DEQ, our model does not require backpropagation through an explicit stack of layers and has an O(1) memory footprint during training.
This is especially important as pattern recognition systems are memory-intensive. Second, MDEQ rectiﬁes one of the drawbacks of DEQ by exposing multiple feature scales at equilibrium, thereby providing natural interfaces for auxiliary losses and for compound training procedures such as pretraining (e.g., on ImageNet) and ﬁne-tuning (e.g., on segmentation or detection tasks). Multiscale modeling enables a single MDEQ to simultaneously train for multiple losses deﬁned on potentially very different scales, whose equilibrium features can serve as “heads” for a variety of tasks.
We demonstrate the effectiveness of MDEQ via extensive experiments on large-scale image classiﬁca-tion and semantic segmentation datasets. Remarkably, this shallow implicit model attains comparable accuracy levels to state-of-the-art deeply-stacked explicit ones. On ImageNet classiﬁcation, MDEQs outperform baseline ResNets (e.g., ResNet-101) with similar parameter counts, reaching 77.5% top-1 accuracy. On Cityscapes semantic segmentation (dense labeling of 2-megapixel images), identical
MDEQs to the ones used for ImageNet experiments match the performance of recent explicit models while consuming much less memory. Our largest MDEQ surpasses 80% mIoU on the Cityscapes validation set, outperforming strong convolutional networks and coming tantalizingly close to the state of the art. This is by far the largest-scale application of implicit deep learning to date and a remarkable result for a class of models that until recently were applied largely to “toy” domains. 2