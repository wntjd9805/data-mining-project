Abstract
In machine learning applications such as ranking fairness or fairness over intersec-tional groups, one often encounters optimization problems with extremely large numbers of constraints. In particular, with ranking fairness tasks, there may even be a variable number of constraints, e.g. one for each query in the training set. In these cases, the standard approach of optimizing a Lagrangian while maintaining one Lagrange multiplier per constraint may no longer be practical. Our proposal is to associate a feature vector with each constraint, and to learn a “multiplier model” that maps each such vector to the corresponding Lagrange multiplier. We prove optimality, approximate feasibility and generalization guarantees under assump-tions on the ﬂexibility of the multiplier model, and empirically demonstrate that our method is effective on real-world case studies. 1

Introduction
Constrained optimization has proven to be useful for a variety of machine learning applications, including churn reduction, Neyman-Pearson classiﬁcation, and the imposition of statistical fairness constraints [e.g. 1, 2]. In such problems, there are generally only a handful of constraints: for example, in a fairness problem, there will typically be only one constraint per protected group. As a result, while optimizing such a constrained ML problem is more difﬁcult than optimizing an unconstrained problem, the difference is usually relatively small.
In some cases, however, it may be desirable to include an extremely large number of constraints. For example, in a fairness problem in which the data are partitioned into protected groups in multiple distinct ways (e.g. race, gender, age buckets, etc.), enforcing a constraint independently for each of the individual groups may not satisfy the constraint for each intersection of those groups [3].
Therefore, it may be necessary to impose a separate constraint for each such intersection. As one tries to impose statistical fairness requirements along an increasing number of such dimensions, the total number of constraints can quickly get out of hand.
Despite the difﬁculties with such a setting, the situation in such an intersectional statistical fairness problem isn’t as bad as it could be, since there are still a known, ﬁnite number of constraints. In other settings, even this might not be the case. In many ranking problems, for example, the workﬂow is that a “query” is provided, with each query being associated with some set of “documents”, which are then handed off to a model to be ranked. Here, we’re mainly interested in the problem of imposing fairness constraints on a per-query basis. When statistical fairness constraints (such as ranking analogues to demographic parity or equal opportunity [4], adapted to the ranking setting as in Narasimhan et al. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
[5]) are imposed on a ranking problem, they are generally enforced on average across all queries [e.g. 6, 5]. As a result, any particular query might be “unfair” (w.r.t. whatever fairness metric is being used), as long as this unfairness averages out. Existing work on per-query fairness metrics is, so far as we’re aware, restricted to post-processing approaches [7–9]. Our goal is to formulate such a problem as an explicit constrained optimization problem, with one (or potentially more) fairness constraints per query. One of the main difﬁculties of this setting is that, while one could think of there being one constraint per query in the training set, it would be more accurate to imagine that there are potentially an inﬁnite number of constraints, one for each possible query, and those corresponding to the training set are merely those that we happen to be able to easily observe. This raises the interesting question of how well such constraints generalize.
A third example we consider is a variant of robust optimization, speciﬁcally in a statistical fairness setting in which protected group information isn’t available, but we do have access to correlated
“noisy” features. In one canonical example, “zip codes” serve as a noisy proxy for “race”. Wang et al.
[10] proposed using a robust-optimization-like approach to this problem, in which the correlations between the “true” and “noisy” groups were assumed to be known (or estimated from a side-dataset), and the fairness constraints were required to hold for the worst true-group labeling that was consistent with both the known proxy-group labeling and these known correlations. Applied to their problem, our approach differs only formally, in that instead of imposing one constraint for the worst consistent labeling, we have a separate constraint for each such labeling, and want all of them to hold.
The unifying property of the above tasks is that each includes either a very large constraint set, or worse, an inﬁnite one. In the former case, the model being learned could easily have insufﬁcient capacity to satisfy all of the constraints simultaneously (i.e. the problem could be infeasible), while in the latter case, unless the constraints are highly-structured, expecting all of them to hold is unrealistic.
For this reason, our approach does not attempt to satisfy all of the constraints simultaneously. Instead, it is based on the Lagrangian formulation, and parameterizes the Lagrange multipliers using a model.
In general, as the complexity of this model increases, so too does its ability to satisfy the constraints. If it is under-parameterized (as will typically be the case), then some constraints are likely to be violated (Section 4 provides some intuition on how our approach copes with this situation). However, if we use e.g. a neural network, then because the same set of weights will be used for every constraint, the model will be capable of learning relationships and redundancies between constraints, and therefore could perform better than its apparent complexity might indicate.
We make ﬁve main contributions: (i) in Section 3, we introduce the idea of using the Lagrangian formulation when the Lagrange multipliers are not taken to be a simple vector, but instead are the output of a model, given some set of features; (ii) in Deﬁnition 1 of Section 5, we introduce a new notion of how one can measure constraint violations in our Lagrangian-model setting, in a way that permits theoretical results to be proved; (iii) later in Section 5, we prove a suboptimality and infeasibility guarantee; (iv) in Section 5.2 we prove a generalization result that applies to the per-query ranking fairness setting described above; (v) in Section 6, we provide an extensive experimental evaluation of several of the highly-constrained settings we have discussed. 2