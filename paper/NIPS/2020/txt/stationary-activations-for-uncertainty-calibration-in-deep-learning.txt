Abstract
We introduce a new family of non-linear neural network activation functions that mimic the properties induced by the widely-used Matérn family of kernels in
Gaussian process (GP) models. This class spans a range of locally stationary models of various degrees of mean-square differentiability. We show an explicit link to the corresponding GP models in the case that the network consists of one inﬁnitely wide hidden layer. In the limit of inﬁnite smoothness the Matérn family results in the RBF kernel, and in this case we recover RBF activations. Matérn activation functions result in similar appealing properties to their counterparts in
GP models, and we demonstrate that the local stationarity property together with limited mean-square differentiability shows both good performance and uncertainty calibration in Bayesian deep learning tasks. In particular, local stationarity helps calibrate out-of-distribution (OOD) uncertainty. We demonstrate these properties on classiﬁcation and regression benchmarks and a radar emitter classiﬁcation task. 1

Introduction
Deep feedforward neural networks (see, e.g., [26, 28]) have become an essential component of modern machine learning. Their black box nature results in a lack of interpretability, an issue that has been tackled recently from many directions, one of which is the study of random (untrained) networks in order to examine what prior assumptions they impose over functions. By assuming a probability distribution on the network parameters, a distribution is induced from the inputs to the outputs of the network. While we typically want networks to have high modelling capability (or
ﬂexibility), large networks can be hard to analyse directly. This difﬁculty motivates instead the study of the limiting behaviour of the networks, which can provide new insight and better interpretation.
This is also of interest for Bayesian deep learning, where the concept of assigning priors on neural networks only makes sense if the effects of prior assumptions can be understood.
Along the line of studying random networks, Neal [47] showed that under certain assumptions, random neural networks with one hidden layer converge to a Gaussian process (GP, [53]) in the limit of inﬁnite width. Since then, explicit links between common neural network activation functions and
GP covariance (kernel) functions have been shown (e.g., ERF and RBF activations by [68] and ReLU and step activations by [8], see Fig. 1). Recently, this equivalence was extended to deep networks
[14, 39]. Gal and Ghahramani [21] leveraged the connection for approximate variational inference in neural networks. The call for more work on deep net priors (e.g., [19, 49, 62]) is also motivated by empirical ﬁndings [67], and we recognize two separate problems in deep learning: (i) designing network architectures that support our domain knowledge of the modelling task (prior assumptions), and (ii) performing inference and learning with the model. Recent interest in Bayesian deep learning has been in (ii) (see, e.g., [4, 35, 41, 55]), while we tackle (i), and choose to apply a simple and conservative inference method—we resort to Monte Carlo (MC) dropout in our experiments. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
ArcCos-0 kernel [8]
ArcCos-1 kernel[8]
ERF-NN kernel [68]
RBF-NN kernel [68]
Matérn- 5 2 kernel
MLP with step activation
ReLU activation
ERF (sigmoidal) activation
RBF activation
Matérn- 5 2 activation (this paper)
Figure 1: Illustrative comparisons on the Banana classiﬁcation data set. The top row shows decision boundaries and marginal predictive variance (low high) for various GP priors (inﬁnite-width networks), and the bottom row shows ﬁnite-width MLP neural network results (one hidden layer, 50 nodes, MC dropout) with the network activation function matching the GP prior on the top row.
Orthogonal to deep learning, in support vector machines [10], kernel methods [36], spatial statistics
[11], and GP models, the focus is on the choice and crafting of a kernel (covariance/covariogram function). The kernel captures prior assumptions related to the model functions such as continuity, differentiability, periodicity, invariances, etc. Stationarity (translation invariance of the kernel) is often a sought-after property in these models as it induces the behaviour of functions reverting back to the prior outside informative regions in the problem domain (decision boundaries/data samples).
Arguably the most used GP kernel is the Matérn class [42, 53], which features stationary kernels with continuous sample functions of various degree of smoothness. This class has the RBF (squared exponential or Gaussian) and the exponential (Ornstein–Uhlenbeck) covariance functions as limiting cases of inﬁnite smoothness and non-differentiable sample paths, respectively (see, e.g., [53]).
Previous approaches have sought to map various activation functions to their kernel counterparts.
We take the opposite approach by introducing a new family of non-linear neural network activation functions that mimic the widely-used Matérn family in GP models. The derivation is made possible by rekindling the link between classical control theory and neural networks. The class we propose spans a range of locally stationary models of various degrees of mean-square differentiability. We show an explicit link to the corresponding GP models in the case of one inﬁnitely wide hidden layer. These activation functions result in similar appealing properties to their counterparts in GP models, and we demonstrate that the local stationarity property together with limited mean-square differentiability shows good performance and uncertainty quantiﬁcation in Bayesian deep learning tasks. In particular, the local stationarity can help in tackling overconﬁdence in out-of-distribution detection. 1.1