Abstract
Non-linear spectral decompositions of images based on one-homogeneous func-tionals such as total variation have gained considerable attention in the last few years. Due to their ability to extract spectral components corresponding to ob-jects of different size and contrast, such decompositions enable ﬁltering, feature transfer, image fusion and other applications. However, obtaining this decomposi-tion involves solving multiple non-smooth optimisation problems and is therefore computationally highly intensive. In this paper, we present a neural network ap-proximation of a non-linear spectral decomposition. We report up to four orders of magnitude (×10, 000) speedup in processing of mega-pixel size images, compared to classical GPU implementations. Our proposed network, TVSpecNET, is able to implicitly learn the underlying PDE and, despite being entirely data driven, inherits invariances of the model based transform. To the best of our knowledge, this is the
ﬁrst approach towards learning a non-linear spectral decomposition of images. Not only do we gain a staggering computational advantage, but this approach can also be seen as a step towards studying neural networks that can decompose an image into spectral components deﬁned by a user rather than a handcrafted functional. 1

Introduction
Transforming and processing information such as images in a frequency domain to facilitate analysis and manipulation is a classical and very successful approach. A prominent example of a linear spectral decomposition is the Fourier transform that uses the trigonometric basis to represent a signal or an image. However, this linear transform is not optimal for images that contain discontinuities (edges), which can only be represented using high frequencies. To overcome this, a non-linear spectral decomposition based on the edge-preserving total variation (TV) functional was proposed in [17, 18]. The TV transform enables a scale representation based on the size and contrast of the structures contained in an image. The spectral components are related to eigenfunctions induced by the TV functional such as indicator functions of disks and other smooth convex shapes. Similarly to the linear case, the spectral components of an image deﬁned by the non-linear TV transform can be ﬁltered, extracted and attenuated at different scales. Manipulation and analysis of images using the spectral TV decomposition has found various successful applications ranging from image 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
Figure 1: Visual comparison of our proposed TVspecNET decomposition and the ground truth (GT)
[18] on an example image from MS COCO [32]. For this image, the resulting evaluation measures are: SSIM: 0.9849, PSNR: 32.046, sLMSE: 0.6062 denoising [37] through texture extraction and separation [6, 24] and image fusion [4, 48, 21, 34] to non-linear segmentation in biomedical imaging [45]. Especially in image fusion applications, spectral TV decomposition is able to overcome challenges in relation to edge and detail preservation where other methods fail [48]. The theory of non-linear spectral decomposition has been extended to arbitrary one-homogeneous functionals in [8, 9, 7] and p-homogeneous functionals (p ∈ (1, 2)) in [14]. Recently, spectral TV decomposition has additionally been generalised from the Euclidean space to surfaces [15].
In order to obtain the spectral TV decomposition of an image, the solution to the TV ﬂow needs to be computed at every scale. This involves solving multiple non-smooth optimisation problems and is therefore computationally costly. To overcome this issue, we consider training a neural network (NN) to reproduce the spectral TV decomposition at a considerably reduced computational cost.
Since the TV transform can be seen as a non-linear analogue to the Fourier transform, we aim to obtain an analogue to the Fast Fourier Transform (FFT) in our approach. The availability of a fast computational method is arguably one of the reasons for the success of the Fourier transform in signal and image processing. Fast methods for non-linear spectral decomposition therefore have the potential to become an equally important tool for image and data analysis.
Decomposing images into task dependent components via deep learning has been used in multiple imaging tasks, such as denoising [46, 33, 47] (components are the noise-free image and noise), segmentation [41, 2, 16], material decomposition [43, 36, 30] (e.g. separation to bones and soft-tissues in medical imaging) and intrinsic image decomposition [38, 26, 29, 31] (shading and reﬂectance). The task of obtaining a non-linear spectral decomposition is, however, different. While in the examples above, the components are deﬁned semantically, i.e. they depend on the contents of the image, spectral TV decompositions are based on a PDE, hence to learn a spectral decomposition, the network has to implicitly learn a PDE. This allows one to apply the trained network to images signiﬁcantly different from the training set.
Training a NN that reproduces an analytical spectral decomposition based on a handcrafted functional is a ﬁrst step towards an even more ambitious goal of learning user deﬁned (data driven) decom-positions. This would involve training a NN to reproduce the desired behaviour on user deﬁned
’eigenfunctions’, which can be then transferred to real images.
Contributions
In this paper, we propose a neural network that we call TVspecNET that can reproduce the spectral TV decomposition of images while signiﬁcantly (by more than three orders of magnitude) reducing the computation time to obtain the decomposition once the network is trained.
Our main contributions are as follows
• We approximate a highly non-trivial function by means of deep learning to obtain the non-linear spectral decomposition where model-driven approaches have been cumbersome and computationally complex;
• We achieve a substantial computational speed up compared to the classical, model-driven approach that is based on solving a gradient ﬂow; 2
(a) Input f (b) TV-Spectrum S(t) (c) TV-High-pass
ﬁltered (blue) (d) TV-Band-pass
ﬁltered (green) (e) TV-Low-pass
ﬁltered (red)
Figure 2: Example of the ﬁltered spectral responses of a natural image f at different scales t. (a) the initial image with (b) the spectrum S(t). TV High- (blue), band- (green) and low-pass ﬁltered (red) spectral bands depicting small to large structures (c)–(e) separating the sprinkles from the donuts.
The input image is taken from MS COCO [32].
• We demonstrate that our network is indeed capable of learning intrinsic properties of the non-linear spectral decomposition such as one-homogeneity, and rotational and translational invariance. Moreover, we demonstrate that the network not only learns the decomposition, but also implicitly learns the theoretically predicted behaviour on isolated eigenfunctions even if no isolated eigenfunctions were present in the training set. Hence the network generalises well and is able to unlock the inherent structure of the non-linear spectral decomposition;
• We perform a comprehensive comparative study that shows the optimality of our architecture for non-linear spectral decomposition;
• To the best of our knowledge, we are the ﬁrst ones to propose a deep learning approach to approximate the non-linear spectral decomposition of images. 2