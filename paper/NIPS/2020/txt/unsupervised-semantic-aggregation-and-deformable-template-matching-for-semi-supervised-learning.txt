Abstract
Unlabeled data learning has attracted considerable attention recently. However, it is still elusive to extract the expected high-level semantic feature with mere unsu-pervised learning. In the meantime, semi-supervised learning (SSL) demonstrates a promising future in leveraging few samples. In this paper, we combine both to propose an Unsupervised Semantic Aggregation and Deformable Template Match-ing (USADTM) framework for SSL, which strives to improve the classiﬁcation performance with few labeled data and then reduce the cost in data annotating.
Speciﬁcally, unsupervised semantic aggregation based on Triplet Mutual Informa-tion (T-MI) loss is explored to generate semantic labels for unlabeled data. Then the semantic labels are aligned to the actual class by the supervision of labeled data.
Furthermore, a feature pool that stores the labeled samples is dynamically updated to assign proxy labels for unlabeled data, which are used as targets for cross-entropy minimization. Extensive experiments and analysis across four standard semi-supervised learning benchmarks validate that USADTM achieves top performance (e.g., 90.46% accuracy on CIFAR-10 with 40 labels and 95.20% accuracy with 250 labels). The code is released at https://github.com/taohan10200/USADTM. 1

Introduction
Deep learning is booming driven by massive labeled data over the past few years, such as image classiﬁcation [1, 2], semantic segmentation [3, 4], object detection [5, 6], natural language processing
[7, 8]. Besides, learning with unlabeled data also makes much progress in reducing the labeling costs
[9–11]. The two most important branches are unsupervised and semi-supervised learning. For the image classiﬁcation task, semi-supervised learning has shown that it can achieve a performance close to supervised results under certain conditions, while unsupervised learning remains a huge challenge for machine learning. A new perspective is to combine unsupervised learning with supervised learning to achieve better performance.
In this paper, we are working on the following problems. 1) Most of the unsupervised methods cannot directly output the classiﬁcation results of the object [12–14]. Some end-to-end unsupervised learning methods [9] also output a semantic label that does not correspond to the actual category. The speciﬁc category to which the object belongs still depends on the clustering [15, 16]. 2) Due to the lack of manually injected supervised information, unsupervised learning split the data on their own.
To verify, as shown in Fig. 1, we create a classiﬁcation task of circles, triangles, and pentagons. The left samples are given color to the border, while the right samples are ﬁlled in the entire graph. We expect the unsupervised classiﬁcation in these two different datasets to yield circles, triangles, and
† T. Han and J. Gao are co-ﬁrst authors of the paper.
∗ Q. Wang is the corresponding author. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
Figure 1: Two simple experiments on unsupervised classiﬁcation with IIC [9]. Both of which we expect would yield shape-based categorization results. However, the data on the right, with the interference of color information, deviated far from our expectations. pentagons. Nevertheless, the box on the left gives us a result based on shape, and the box on the right gives us a result based on color. The results are not expected. So it demonstrates that the features extracted by unsupervised learning with no supervised information are not all useful in promoting the task, even in some cases deviate far from the expectation. 3) Pure unsupervised learning is still difﬁcult to deal with complex classiﬁcation tasks. Taking the excellent IIC [9] as an example, it can achieve 99.2% accuracy in the simple handwritten numeric dataset MNIST [17], but it can only achieve 25.7% accuracy on the CIFAR100-20 [18].
To extract the beneﬁcial feature and ignore the useless information in unsupervised learning, we make a constraint by injecting a part of the supervised information into unsupervised learning. In other words, this paper aims to establish an SSL framework combining unlabeled data with few labeled data. Unlike the existing excellent SSL methods based on consistent regularization and entropy minimization [19–22], we propose a new SSL framework via unsupervised semantic aggregation and deformable template matching. Speciﬁcally, the unlabeled data are explored to make self-supervised learning by maximizing mutual information. Then, few annotated samples are provided to align the semantic labels with the real categories. Besides, for further leveraging the unlabeled data, we establish a dynamic pattern pool for each class and assign proxy labels by template matching in the feature-level. It is a new and more reasonable pseudo label generation method that compares with other semi-supervised methods.
For problem 1), such a framework can eliminate the clustering operations that the traditional unsuper-vised learning required. For problem 2), the introduced supervised information can be an effective measure that helps unsupervised networks learn the expected representation under the interference of useless information (e.g., background, color). For question 3), maximum mutual information applied in semi-supervision learning will further enhance the classiﬁcation performance on the complex datasets. Our main contributions are the following:
• Exploit triplet mutual information loss to achieve semantic labels clustering for unlabeled data in SSL, which has a better performance in unsupervised semantic aggregation than single paired MI loss.
• Propose a deformable template matching method for generating pseudo labels, which assigns proxy labels for unlabeled data in the high-level feature space. It is a more effective way compared with conﬁdence based methods.
• Experiments on several standard classiﬁcation benchmarks demonstrate that USADTM achieves state-of-the-art by integrating the supervised learning with unsupervised learning. 2