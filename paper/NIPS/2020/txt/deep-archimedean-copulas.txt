Abstract
A central problem in machine learning and statistics is to model joint densities of random variables from data. Copulas are joint cumulative distribution functions with uniform marginal distributions and are used to capture interdependencies in isolation from marginals. Copulas are widely used within statistics, but have not gained traction in the context of modern deep learning. In this paper, we introduce
ACNet, a novel differentiable neural network architecture that enforces structural properties and enables one to learn an important class of copulas–Archimedean
Copulas. Unlike Generative Adversarial Networks, Variational Autoencoders, or
Normalizing Flow methods, which learn either densities or the generative process directly, ACNet learns a generator of the copula, which implicitly deﬁnes the cumulative distribution function of a joint distribution. We give a probabilistic interpretation of the network parameters of ACNet and use this to derive a simple but efﬁcient sampling algorithm for the learned copula. Our experiments show that
ACNet is able to both approximate common Archimedean Copulas and generate new copulas which may provide better ﬁts to data. 1

Introduction
Modeling dependencies between random variables is a central problem in machine learning and statistics. Copulas are a special class of cumulative density functions which specify the dependencies between random variables without any restriction on their marginals. This has led to long lines of research in modeling and learning copulas [15, 7], as well as their applications in ﬁelds such as
ﬁnance and healthcare [5, 3]. Amongst the most common class of copulas are Archimedean Copulas, which are deﬁned by a one-dimensional function ϕ, known as the generator, and often favored for their simplicity and ability to model extreme distributions. A key problem in the application of
Archimedean Copulas is the selection of the parametric form of ϕ as well as the limitations on the expressiveness of commonly used copula. Present workarounds include the selection of the best model between a ﬁxed set of commonly used copulas, the use of methods based on information criterion such as Akaike and Bayesian Information Criterion (AIC, BIC), as well as more modern nonparametric methods.
In this paper, we propose ACNet, a novel network architecture which models the generator of an
Archimedean copula using a deep neural network, allowing for network parameters to be learnt using backpropagation and gradient descent. The core idea behind ACNet is to model the generator as a sum of convex combination of a ﬁnite set of exponential functions with varying rates of decay, while exploiting their invariance to convex combinations and multiplications with other exponentials. ACNet is built from simple, differentiable building blocks, ensuring that log-likelihood is a differentiable function of ϕ, ensuring ease of training via backpropagation. By possessing a larger set of parameters, ACNet is able to approximate all copulas with completely monotone generators, a large class which encompasses most of the commonly used copulas, but also other Archimedean 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
copulas which have no straightforward closed forms. To our knowledge, ACNet is the ﬁrst method to utilize deep representations to model generators for Archimedean copulas directly.
ACNet enjoys several theoretical properties, such as a simple interpretation of network weights in terms of a Markov reward process, resulting in a numerically stable, dimension independent method of sampling from the copula. Using this interpretation, we show that deep variants of ACNet are theoretically able to represent generators which shallow nets may not. By modeling the cumulative density directly, ACNet is able to provide a wide range of probabilistic quantities such as conditional densities and distributions using a single trained model. This ﬂexibility in expression extends to both inference and training and is not possible with other deep methods such as Generative Adversarial
Networks (GANs) or Normalizing Flows, which at best allow for the evaluation of densities.
Empirical results show that ACNet is able to learn standard copula with little to no hyperparameter tuning. When tested on real-world data, we observed that ACNet was able to learn new generators which are a better qualitative description of observed data compared to commonly used Archimedean copulas. Lastly, we demonstrate the effectiveness of ACNet in situations where measurements are uncertain within known boundaries. This task is challenging for methods which learn densities as evaluating probabilities would then involve the costly numerical integration of densities.
We (i) propose ACNet, the ﬁrst network to learn completely monotone generating functions for the purpose of learning copulas, (ii) study the theoretical properties of ACNet, including a simple interpretation of network weights and an efﬁcient sampling process, (iii) show how ACNet may be used to compute probabilistic quantities beyond log-likelihood and cumulative densities, and (iv) evaluate ACNet on both synthetic and real-world data, demonstrating that ACNet combines the ease of use enjoyed by commonly used copulas and the representational capacity of Archimedean copulas.
The source code for this paper may be found at https://github.com/lingchunkai/ACNet. 2 CDFs and Copulas
Consider a d-dimensional continuous random vector X = {X1, X2, · · · Xd} with marginals Fi(xi) =
P(Xi ≤ xi). Given a x ∈ Rd, the distribution function F (x) = P (X1 ≤ x1, · · · Xd ≤ xd) speciﬁes all marginal distributions Fi(xi) as well as any dependencies between X. This paper focuses on continuous distribution functions which have well-deﬁned densities. 2.1 Copulas
Of particular interest is a special type of distribution function known as a copula. Informally, copulas are distribution functions with uniform marginals in [0, 1]. Formally, C(u1, · · · , ud) : [0, 1]d → [0, 1] is a copula if the following 3 conditions are satisﬁed.
• (Grounded) It is equal to 0 if any of its arguments are 0, i.e., C(. . . , 0, . . . ) = 0.
• It is equal to ui if all other arguments 1, i.e., for all i ∈ [d], C(1, · · · , 1, ui, 1, · · · , 1) = ui.
• (d-increasing) For all u = (u1, . . . , ud) and v = (v1, . . . , vd) where ui < vi for all i ∈ [d], (cid:88) (−1)|i:wi=ui|C(w1, . . . , wd) ≥ 0. (1) (w1,...wd)∈×d i=1{ui,vi}
Heuristically, the d-increasing property states that the probability assigned to any non-negative d-dimensional rectangle is non-negative.
Observe that the ﬁrst 2 conditions are stronger than the limiting conditions required for distribution functions—in fact, groundedness coupled with the d-increasing property sufﬁciently deﬁne any distribution function. In particular, the second condition implies that Copulas have uniform marginals and hence, are special cases of distribution functions. Copulas have found numerous real world applications in engineering, medicine, and quantitative ﬁnance. The proliferation of applications may be attributed to Sklar’s theorem (see appendix for details). Loosely speaking, Sklar’s theorem states that any d-dimensional continuous joint distribution may be uniquely decomposed into d marginal distribution functions and a single copula C. The copula precisely captures dependencies between random variables in isolation from marginals. This allows for the creation of non-independent distributions by combining marginals—potentially from different families and tying them together using a suitable copula. 2
2.2 Archimedean copulas
In this paper, we will restrict ourselves to Archimedean copulas. Archimedean copulas enjoy simplicity by modeling dependencies in high dimensions using a single 1-dimensional function:
C(u1, · · · , ud) = ϕ (cid:0)ϕ−1(u1) + ϕ−1(u1) + · · · ϕ−1(ud)(cid:1) , (2) where ϕ : [0, ∞) → [0, 1] is d-monotone, i.e., (−1)kϕ(k)(t) ≥ 0 for all k ≤ d, t ≥ 0.
Here, ϕ is known as the generator of C. A single d-monotone function ϕ deﬁnes a d-dimensional copula which satisﬁes the conditions laid out in Section 2.1. We say that ϕ is completely monotone if (−1)kϕ(k)(t) ≥ 0 for all values of k. Completely monotone generators deﬁne copula regardless of the dimension d. Most (but not all) Archimedean copula are deﬁned by completely monotone generators. For this reason, we focus on Archimedean copula with completely monotone generators, also known in the literature as extendible Archimedean copula. The following theorem by Bernstein (see [27] for details) characterizes all completely monotone ϕ as a mixture of exponential functions.
Theorem 1 (Bernstein-Widder). A generator ϕ is completely monotone if and only if ϕ is the Laplace transform of a positive random variable M , i.e., ϕ(t) = EM (exp(−tM )) and P(M > 0) = 1.
In fact, [25] show that C has an easy interpretation in terms of the random variable M . Speciﬁcally, if U = (U1, · · · , Ud) ∼ C, where C is generated by ϕ, which is in turn the Laplace transform of some non-negative random variable M which almost never takes the value 0, then, we have
Ui = ϕ(Ei/M ), where Ei ∼ Exp(1). It follows that sampling from C is easy and efﬁcient given access to a sampler for M and an oracle for ϕ, which is the case for most commonly used copulas. 2.3