Abstract
Self- and semi-supervised learning frameworks have made signiﬁcant progress in training machine learning models with limited labeled data in image and language domains. These methods heavily rely on the unique structure in the domain datasets (such as spatial relationships in images or semantic relationships in language). They are not adaptable to general tabular data which does not have the same explicit structure as image and language data. In this paper, we ﬁll this gap by proposing novel self- and semi-supervised learning frameworks for tabular data, which we refer to collectively as VIME (Value Imputation and Mask Estimation). We create a novel pretext task of estimating mask vectors from corrupted tabular data in addition to the reconstruction pretext task for self-supervised learning. We also introduce a novel tabular data augmentation method for self- and semi-supervised learning frameworks. In experiments, we evaluate the proposed framework in multiple tabular datasets from various application domains, such as genomics and clinical data. VIME exceeds state-of-the-art performance in comparison to the existing baseline methods. 1

Introduction
Tremendous successes have been achieved in a variety of applications (such as image classiﬁcation [1], object detection [2], and language translation [3]) with deep learning models via supervised learning on large labeled datasets such as ImageNet [4]. Unfortunately, collecting sufﬁciently large labeled datasets is expensive and even impossible in several domains (such as medical datasets concerned with a particularly rare disease). In these settings, however, there is often a wealth of unlabeled data available - datasets are often collected from a large population, but target labels are only available for a small group of people. The 100,000 Genomes project [5], for instance, sequenced 100,000 genomes from around 85,000 NHS patients affected by a rare disease, such as cancer. By deﬁnition rare diseases occur in (less than) 1 in 2000 people. Datasets like these present huge opportunities for self- and semi-supervised learning algorithms, which can leverage the unlabeled data to further improve the performance of a predictive model.
Unfortunately, existing self- and semi-supervised learning algorithms are not effective for tabular data1 because they heavily rely on the spatial or semantic structure of image or language data. A 1Tabular data is a database that is structured in a tabular form. It arranges data elements in vertical columns (features) and horizontal rows (samples). 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
standard self-supervised leaning framework designs a (set of) pretext task(s) to learn informative representations from the raw input features. For the language domain, BERT introduces 4 different pretext tasks (e.g. predicting future words from previous words) to learn representations of the language data [6]. In the image domain, rotation [7], jigsaw puzzle [8], and colorization [9] can be utilized as pretext tasks to learn representations of the images. Standard semi-supervised learning methods also suffer from the same problem, since the regularizers they use for the predictive model are based on some prior knowledge of these data structures. For example, the consistency regularizer encourages the predictive model to have the same output distribution on a sample and its augmented variants, e.g. an image and its rotated variants [7], or two images and their convex combination(s) [10].
The notion of rotation simply does not exist in tabular data. Moreover, in many settings, variables are often categorical, and do not admit meaningful convex combinations. Even in a setting where all variables are continuous, there is no guarantee that the data manifold is convex and as such taking convex combinations will either generate out-of-distribution samples (therefore degrading model performances) or be restricted to generating samples that are very close to real samples (limiting the effectiveness of the data augmentation), for more details see the Supplementary Materials (Section 4).
Contribution: In this paper, we propose novel self- and semi-supervised learning frameworks for tabular data. For self-supervised learning, we introduce a novel pretext task, mask vector estimation in addition to feature vector estimation. To solve those pretext tasks, an encoder function learns to construct informative representations from the raw features in the unlabeled data. For semi-supervised learning, we introduce a novel tabular data augmentation scheme. We use the trained encoder to generate multiple augmented samples for each data point by masking each point using several different masks and then imputing the corrupted values for each masked data point. Finally, we propose a systematic self- and semi-supervised learning framework for tabular data, VIME (Value
Imputation and Mask Estimation), that combines our ideas to produce state-of-the-art performances on several tabular datasets with a few labeled samples, from various domains. 2