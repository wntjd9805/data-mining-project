Abstract
Incorporating relational reasoning into neural networks has greatly expanded their capabilities and scope. One deﬁning trait of relational reasoning is that it operates on a set of entities, as opposed to standard vector representations. Existing end-to-end approaches for relational reasoning typically extract entities from inputs by directly interpreting the latent feature representations as a set. We show that these approaches do not respect set permutational invariance and thus have funda-mental representational limitations. To resolve this limitation, we propose a simple and general network module called Set Reﬁner Network (SRN). We ﬁrst use syn-thetic image experiments to demonstrate how our approach effectively decomposes objects without explicit supervision. Then, we insert our module into existing rela-tional reasoning models and show that respecting set invariance leads to substantial gains in prediction performance and robustness on several relational reasoning tasks. Code can be found at github.com/CUAI/BetterSetRepresentations. 1

Introduction
Modern deep learning models perform many tasks well, from speech recognition to object detection.
However, despite their success, a criticism of deep learning is its limitation to low-level tasks as opposed to more sophisticated reasoning. This gap has drawn analogies to the difference in so-called
“System 1” (i.e., low-level perception and intuitive knowledge) and “System 2” (i.e., reasoning, planning, and imagination) thinking from cognitive psychology [3, 9]. Proposals for moving towards
System 2 reasoning in learning systems involve creating new abilities for composition, combinatorial generalization, and disentanglement [2, 13, 17].
One approach for augmenting neural networks with these capabilities is performing relational reasoning over structured representations, such as sets or graphs. This approach is effective in computer vision for tasks such as visual question answering, image captioning, and video under-standing [7, 15, 19]. For relational reasoning, these systems are commonly split into two stages: (1) a perceptual stage that extracts structured sets of vector representations, intended to correspond to entities from the raw data, and (2) a reasoning stage that uses these representations. As the underlying data is unstructured (e.g., images or text), designing end-to-end models that generate set representations is challenging. Typical differentiable methods directly map the input to latent features using a feedforward neural network and partition the latent features into a set representation for downstream reasoning [1, 10, 15, 22].
However, this class of existing methods has a fundamental ﬂaw that prevents them from extracting certain desired sets of entities — the so-called responsibility problem [24]. At a high level, if there
∗equal contribution 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
Figure 1: Overview of our Set Reﬁner Network (SRN) and the responsibility problem. The top row shows an overview of the relational reasoning paradigm. Under the assumptions of Theorem 1, a perceptual stage that effectively recovers the underlying set structure must be discontinuous. The second row shows a visualization of the perceptual stage for (a) existing methods and (b) the SRN on a reconstruction task. Each of the 9 color-coded panels corresponds to one of the 9 set elements. As existing methods (a) can only represent continuous functions, it is not able to recover the underlying object structure of the image. However, the SRN (b) allows us to model discontinuities and thus can recover the underlying object structure. exists a continuous map that generates inputs from sets of entities, then any function that can map such inputs to a list representation of the entities must be discontinuous (under a few assumptions that we formalize in Section 2). For relational reasoning tasks, this implies the perceptual stage must contain discontinuous jumps. Existing methods use feedforward neural networks to approximate such a discontinuous map, so entities from certain inputs cannot be represented faithfully as shown in
Figure 1. We demonstrate this problem extensively in Sections 2.2 and 3.1.
Here, we introduce the Set Reﬁner Network (SRN), a novel module that iteratively reﬁnes a proposed set using a set encoder to manage the aforementioned responsibility problem. The main idea of our module is that instead of directly mapping an input embedding to a set, we instead search for a set representation that can be encoded to the input embedding. This search for a set is implemented via an iterative inference procedure, which is a better model for the discontinuous jumps required to address the responsibility problem. As shown in Figure 1, the SRN can produce set representations that are “properly decomposed,” meaning that each set element corresponds to the entirety of one underlying entity or nothing at all. In extensive experiments, we demonstrate that the SRN can effectively decompose entities in a controlled setting (Section 2.2).
Furthermore, we hypothesize that proper decomposition obtained via SRNs can improve both the accuracy and robustness of downstream reasoning modules, in line with prior work which suggests that disentanglement is desirable for downstream tasks [17]. Intuitively, with a proper decomposition of entities, a reasoning module only needs to learn relations between two set elements to reason about two entities. On the other hand, if an entity is split amongst multiple set elements, the relational reasoning module needs to learn more complex relationships to perform the same task.
Indeed, we ﬁnd that incorporating our SRN into relational reasoning pipelines in computer vision, reinforcement learning, and natural language processing tasks improves predictions substantially. On the Sort-of-CLEVR [15] benchmark, simply adding the SRN to a Relational Network reduces the relative error by over 50% on the most challenging question category. We also show that the SRN can improve the robustness of these relational reasoning modules. For example, even though a Relational
Network has high test accuracy on easy questions within Sort-of-CLEVR, we show that the learned model is startlingly brittle, producing incorrect answers when the input is perturbed in a way that should not affect the answer. Again, simply plugging our SRN into the Relational Network resolves this issue, increasing robustness signiﬁcantly. 1.1