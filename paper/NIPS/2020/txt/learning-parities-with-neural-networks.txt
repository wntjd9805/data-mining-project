Abstract
In recent years we see a rapidly growing line of research which shows learnability of various models via common neural network algorithms. Yet, besides a very few outliers, these results show learnability of models that can be learned using linear methods. Namely, such results show that learning neural-networks with gradient-descent is competitive with learning a linear classiﬁer on top of a data-independent representation of the examples. This leaves much to be desired, as neural networks are far more successful than linear methods. Furthermore, on the more conceptual level, linear models don’t seem to capture the “deepness" of deep networks. In this paper we make a step towards showing leanability of models that are inherently non-linear. We show that under certain distributions, sparse parities are learnable via gradient decent on depth-two network. On the other hand, under the same distributions, these parities cannot be learned efﬁciently by linear methods. 1

Introduction
The remarkable success of neural-networks has sparked great theoretical interest in understanding their behavior. Impressively, a large number of papers [4, 26, 10, 8, 6, 15, 11, 20, 2, 3, 7, 28, 25, 13, 21, 5, 7, 16, 19, 18, 9] have established polynomial-time learnability of various models by neural networks algorithms (i.e. gradient based methods). Yet, to the best of our knowledge, with the single exception of learning one neuron [27], all these results prove learnability of linear models. Namely, models that can be realized by a linear classiﬁer, on top of a (possibly random) embedding that is
ﬁxed and does not depend on the data. This is not surprising, as the majority of these papers prove learnability via “linearization" of the network at the vicinity of the initial random weights.
While these results achieved remarkable progress in understanding neural-networks, they are still disappointing in some sense. Indeed, in practice, neural-networks’ performance is far better than linear methods, a fact that is not explained by these works. Moreover, learning a linear classiﬁer on top of a ﬁxed embedding seems to completely miss the “deepness" of deep learning.
How far can neural network theory go beyond linear models? In this work we show a family of distributions on which neural-networks trained with gradient-descent achieve small error. On the other hand, approximating the same family using a linear classiﬁer on top of an embedding of the input space in RN , requires N which grows exponentially, or otherwise requires a linear classiﬁer with exponential norm. Speciﬁcally, we focus on a standard and notoriously difﬁcult family of target functions: parities over small subsets of the input bits. We show that this family is learnable with neural-networks under some speciﬁc choice of distributions. This implies that neural-networks algorithms are strictly stronger than linear methods, as the same family cannot be approximated by any polynomial-size linear model. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
1.1