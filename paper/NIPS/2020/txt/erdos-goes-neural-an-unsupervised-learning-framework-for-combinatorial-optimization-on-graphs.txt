Abstract
Combinatorial optimization (CO) problems are notoriously challenging for neural networks, especially in the absence of labeled instances. This work proposes an unsupervised learning framework for CO problems on graphs that can provide integral solutions of certiﬁed quality. Inspired by Erd˝os’ probabilistic method, we use a neural network to parametrize a probability distribution over sets. Crucially, we show that when the network is optimized w.r.t. a suitably chosen loss, the learned distribution contains, with controlled probability, a low-cost integral solution that obeys the constraints of the combinatorial problem. The probabilistic proof of existence is then derandomized to decode the desired solutions. We demonstrate the efﬁcacy of this approach to obtain valid solutions to the maximum clique problem and to perform local graph clustering. Our method achieves competitive results on both real datasets and synthetic hard instances. 1

Introduction
Combinatorial optimization (CO) includes a wide range of computationally hard problems that are omnipresent in scientiﬁc and engineering ﬁelds. Among the viable strategies to solve such problems are neural networks, which were proposed as a potential solution by Hopﬁeld and Tank [30]. Neural approaches aspire to circumvent the worst-case complexity of NP-hard problems by only focusing on instances that appear in the data distribution.
Since Hopﬁeld and Tank, the advent of deep learning has brought new powerful learning models, reviving interest in neural approaches for combinatorial optimization. A prominent example is that of graph neural networks (GNNs) [28, 60], whose success has motivated researchers to work on CO problems that involve graphs [35, 87, 39, 27, 43, 53, 7, 56] or that can otherwise beneﬁt from utilizing a graph structure in the problem formulation [69] or the solution strategy [27]. The expressive power of graph neural networks has been the subject of extensive research [82, 47, 17, 59, 58, 8, 26].
Encouragingly, GNNs can be Turing universal in the limit [46], which motivates their use as general-purpose solvers.
Yet, despite recent progress, CO problems still pose a signiﬁcant challenge to neural networks.
Successful models often rely on supervision, either in the form of labeled instances [45, 62, 35] or of expert demonstrations [27]. This success comes with drawbacks: obtaining labels for hard problem instances can be computationally infeasible [86], and direct supervision can lead to poor generalization [36]. Reinforcement learning (RL) approaches have also been used for both classical
CO problems [16, 87, 85, 41, 20, 38, 7] as well as for games with large discrete action spaces, like
Starcraft [75] and Go [64]. However, not being fully-differentiable, they tend to be harder and more time consuming to train. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
Figure 1: Illustration of the “Erd˝os goes neural” pipeline. First, a differentiable loss is derived for a given problem using the probabilistic method. Next, a GNN is trained in an unsupervised way using the derived loss to output a probability distribution over the nodes, essentially providing a probabilistic certiﬁcate for the existence of a low cost feasible solution. At inference time, a discrete solution satisfying the certiﬁcate is obtained in a sequential and deterministic manner by the method of conditional expectation.
An alternative to these strategies is unsupervised learning, where the goal is to model the problem with a differentiable loss function whose minima represent the discrete solution to the combinatorial problem [65, 10, 2, 3, 69, 85]. Unsupervised learning is expected to aid in generalization, as it allows the use of large unlabeled datasets, and it is often envisioned to be the long term goal of artiﬁcial intelligence. However, in the absence of labels, deep learning faces practical and conceptual obstacles. Continuous relaxations of objective functions from discrete problems are often faced with degenerate solutions or may simply be harder to optimize. Thus, successful training hinges on empirically-identiﬁed correction terms and auxiliary losses [10, 3, 71]. Furthermore, it is especially challenging to decode valid (with respect to constraints) discrete solutions from the soft assignments of a neural network [45, 69], especially in the absence of complete labeled solutions [62].
Our framework aims to overcome some of the aforementioned obstacles of unsupervised learning: it provides a principled way to construct a differentiable loss function whose minima are guaranteed to be low-cost valid solutions of the problem. Our approach is inspired by Erd˝os’ probabilistic method and entails two steps: First, we train a GNN to produce a distribution over subsets of nodes of an input graph by minimizing a probabilistic penalty loss function. Successfully optimizing our loss is guaranteed to yield good integral solutions that obey the problem constraints. After the network has been trained, we employ a well-known technique from randomized algorithms to sequentially and deterministically decode a valid solution from the learned distribution. The procedure is schematically illustrated in Figure 1.
We demonstrate the utility of our method in two NP-hard graph-theoretic problems: the maximum clique problem [12] and a constrained min-cut problem [15, 66] that can perform local graph clustering [4, 77]. In both cases, our method achieves competitive results against neural baselines, discrete algorithms, and mathematical programming solvers. Our method outperforms the CBC solver (provided with Google’s OR-Tools), while also remaining competitive with the SotA commercial solver Gurobi 9.0 [29] on larger instances. Finally, our method outperforms both neural baselines and well-known local graph clustering algorithms in its ability to ﬁnd sets of good conductance, while maintaining computational efﬁciency. 1 2