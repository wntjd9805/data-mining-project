Abstract
We study reinforcement learning (RL) for text-based games, which are interactive simulations in the context of natural language. While different methods have been developed to represent the environment information and language actions, existing
RL agents are not empowered with any reasoning capabilities to deal with textual games. In this work, we aim to conduct explicit reasoning with knowledge graphs for decision making, so that the actions of an agent are generated and supported by an interpretable inference procedure. We propose a stacked hierarchical attention mechanism to construct an explicit representation of the reasoning process by exploiting the structure of the knowledge graph. We extensively evaluate our method on a number of man-made benchmark games, and the experimental results demonstrate that our method performs better than existing text-based agents. 1

Introduction
Language plays a core role in human intelligence and cognition [14, 43]. Text-based games [13, 20], where both the states and actions are described by textual descriptions, are suitable simulation environments for studying the language-informed decision making process. These games can be regarded as an intersection of natural language processing (NLP) and reinforcement learning (RL) tasks [35]. To solve text-based games via RL, the agent has to tackle many challenges, such as learning representation from text [42], making decisions based on partial observations [4], handling combinatorial action space [57] and sparse rewards [56]. Generally, existing agents for text-based games can be classiﬁed as rule-based agents and learning-based agents. Rule-based agents, such as
NAIL [21], solve the games based on pre-deﬁned rules, engineering tricks, and pre-trained language models. By heavily relying on prior knowledge of the games, these agents lack ﬂexibility and adaptability. With the progress of deep reinforcement learning [38, 39], learning-based agents such as LSTM-DRQN [42] become increasingly popular since they learn purely from interaction without requiring expensive human knowledge as prior. Recently, considering the rich information that can be maintained by its structural memory, knowledge graphs (KGs) have been incorporated into RL agents to facilitate solving text-based games [1, 4, 3].
∗Equal contribution. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
While a lot of studies have been conducted on representing useful information from text observations
[3, 4, 42] and reducing action spaces [20, 57], few RL agent addresses the reasoning process for text-based games. Going beyond mapping a question to an answer, human beings have the ability of reasoning − they can reuse the knowledge [50], or compose the supporting facts (e.g., the relation between objects in the scene) from the question and the knowledge base to interpret the answer [10, 30]. We believe that RL agents empowered with reasoning capabilities will be better mimicking human decisions in solving text-based games and achieving enhanced performance. In terms of RL agents, we consider enhancing the reasoning capability of the agent by exploiting KGs.
While existing studies [3, 4, 58] treat KGs as a part of the observation to handle partial observability, they ignore the potential of KGs for reasoning [12, 27]. Furthermore, the effectiveness of reasoning is constrained by two problems. Firstly, existing KG-based agents construct one single KG, so that
ﬁne-grained information (e.g., the types of object relationship, the newness/oldness of information) is hard to be maintained. Secondly, the multi-modal inputs, such as textual observations and KGs, are aggregated via simple concatenation so that their respective beneﬁts cannot be sufﬁciently exploited.
We believe that an intelligent agent should have the ability to conduct explicit reasoning with relational and temporal awareness being taken into consideration to make decisions. In this paper, our goal is to design an enhanced RL agent with a reasoning process for text-based games. We propose a new method, named as Stacked Hierarchical Attention with Knowledge Graphs (SHA-KG)2, to enable the agent to perform multi-step reasoning via a hierarchical architecture on playing games.
Brieﬂy, to leverage the structure information of a KG that maintains the agent’s knowledge about the game environment, we ﬁrst consider the sub-graphs of the KG with different semantic meanings so that relational and temporal awareness will be taken into account. Secondly, a stacked hierarchical attention module is devised to build effective state representation from multi-modal inputs, so that their respective importance will be considered.
Our contributions include four aspects. Firstly, our work is a ﬁrst step in pursuing reasoning in solving text-based games. Secondly, we propose to incorporate sub-graphs of the KG into decision making to introduce the reasoning process. Thirdly, we propose a new stacked hierarchical attention mechanism for RL approach featured by multi-level and multi-modal reasoning. Fourthly, we extensively evaluate our method on a wide range of text-based benchmark games, achieving favorable results compared with the state-of-the-art methods. 2