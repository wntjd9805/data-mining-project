Abstract
Training neural network models with discrete (categorical or structured) latent variables can be computationally challenging, due to the need for marginalization over large or combinatorial sets. To circumvent this issue, one typically resorts to sampling-based approximations of the true marginal, requiring noisy gradient estimators (e.g., score function estimator) or continuous relaxations with lower-variance reparameterized gradients (e.g., Gumbel-Softmax). In this paper, we propose a new training strategy which replaces these estimators by an exact yet ef-ﬁcient marginalization. To achieve this, we parameterize discrete distributions over latent assignments using differentiable sparse mappings: sparsemax and its struc-tured counterparts. In effect, the support of these distributions is greatly reduced, which enables efﬁcient marginalization. We report successful results in three tasks covering a range of latent variable modeling applications: a semisupervised deep generative model, a latent communication game, and a generative model with a bit-vector latent representation. In all cases, we obtain good performance while still achieving the practicality of sampling-based approximations. 1

Introduction
Neural latent variable models are powerful and expressive tools for ﬁnding patterns in high-dimensional data, such as images or text [1–3]. Of particular interest are discrete latent variables, which can recover categorical and structured encodings of hidden aspects of the data, leading to compact representations and, in some cases, superior explanatory power [4, 5]. However, with discrete variables, training can become challenging, due to the need to compute a gradient of a large sum over all possible latent variable assignments, with each term itself being potentially expensive.
This challenge is typically tackled by estimating the gradient with Monte Carlo methods [MC; 6], which rely on sampling estimates. The two most common strategies for MC gradient estimation are the score function estimator [SFE; 7, 8], which suffers from high variance, or surrogate methods that rely on the continuous relaxation of the latent variable, like straight-through [9] or Gumbel-Softmax
[10, 11] which potentially reduce variance but introduce bias and modeling assumptions.
∗Work partially done while VN was at the Instituto de Telecomunicações, Lisbon. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
In this work, we take a step back and ask: Can we avoid sampling entirely, and instead deter-ministically evaluate the sum with less computation? To answer afﬁrmatively, we propose an alternative method to train these models by parameterizing the discrete distribution with sparse mappings — sparsemax [12] and two structured counterparts, SparseMAP [13] and a novel mapping top-k sparsemax. Sparsity implies that some assignments of the latent variable are entirely ruled out.
This leads to the corresponding terms in the sum evaluating trivially to zero, allowing us to disregard potentially expensive computations.
Contributions. We introduce a general strategy for learning deep models with discrete latent vari-ables that hinges on learning a sparse distribution over the possible assignments. In the unstructured categorical case our strategy relies on the sparsemax activation function, presented in §3, while in the structured case we propose two strategies, SparseMAP and top-k sparsemax, presented in §4. Unlike existing approaches, our strategies involve neither MC estimation nor any relaxation of the discrete latent variable to the continuous space. We demonstrate our strategy on three different applications: a semisupervised generative model, an emergent communication game, and a bit-vector variational autoencoder. We provide a thorough analysis and comparison to MC methods, and — when feasi-ble — to exact marginalization. Our approach is consistently a top performer, combining the accuracy and robustness of exact marginalization with the efﬁciency of single-sample estimators.2
Notation. We denote scalars, vectors, matrices, and sets as a, a, A, and A, respectively. The indicator vector is denoted by ei, for which every entry is zero, except the ith, which is 1. The simplex is denoted △K := {ξ ∈ RK : h1, ξi = 1, ξ ≥ 0}. H(p) denotes the Shannon entropy of a distribution p(z), and KL [p||q] denotes the Kullback-Leibler divergence of p(z) from q(z). The number of non-zeros of a sequence z is denoted kzk0 := |{t : zt 6= 0}|. Letting z ∈ Z be a random variable, we write the expectation of a function f : Z → R under distribution p(z) as Ep(z)[f (z)]. 2