Abstract
In this paper we provide a new efﬁcient algorithm for approximately computing the proﬁle maximum likelihood (PML) distribution, a prominent quantity in symmetric property estimation. We provide an algorithm which matches the previous best known efﬁcient algorithms for computing approximate PML distributions and improves when the number of distinct observed frequencies in the given instance is small. We achieve this result by exploiting new sparsity structure in approximate
PML distributions and providing a new matrix rounding algorithm, of independent interest. Leveraging this result, we obtain the ﬁrst provable computationally efﬁcient implementation of PseudoPML, a general framework for estimating a broad class of symmetric properties. Additionally, we obtain efﬁcient PML-based estimators for distributions with small proﬁle entropy, a natural instance-based complexity measure. Further, we provide a simpler and more practical PseudoPML implementation that matches the best-known theoretical guarantees of such an estimator and evaluate this method empirically. 1

Introduction
In this paper we consider the fundamental problem of symmetric property estimation: given access to n i.i.d. samples from an unknown distribution, estimate the value of a given symmetric property (i.e. one invariant to label permutation). This is an incredibly well-studied problem with numerous applications
[Cha84, BF93, CCG+12, TE87, Für05, KLR99, PBG+01, DS13, RCS+09, GTPB07, HHRB01] and proposed property-speciﬁc estimators, e.g. for support [VV11b, WY15], support coverage [ZVV+16,
OSW16], entropy [VV11b, WY16a, JVHW15], and distance to uniformity [VV11a, JHW16].
However, in a striking recent line of work it was shown that there is a universal approach to achieving sample optimal1 estimators for a broad class of symmetric properties, including those above.
[ADOS16] showed that the value of the property on a distribution that (approximately) maximizes the likelihood of the observed proﬁle (i.e. multiset of observed frequencies) is an optimal estimator up to accuracy2 (cid:15) (cid:29) n−1/4. Further, [ACSS20] which in turn built on [ADOS16, CSS19a], provided a polynomial time algorithm to compute an exp(−O( n log n))-approximate proﬁle maximum likelihood distribution (PML). Together, these results yield efﬁcient sample optimal estimators for various symmetric properties up to accuracy (cid:15) (cid:29) n−1/4.
√ 1Sample optimality is up to constant factors. See [ADOS16] for details. 2We use (cid:15) (cid:29) n−c to denote (cid:15) > n−c+α for any constant α > 0. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
Despite this seemingly complete picture of the complexity of PML, recent work has shown that there is value in obtaining improved approximate PML distributions. In [CSS19b, HO19] it was shown that variants of PML called PseudoPML and truncated PML respectively, which compute an approximate
PML distribution on a subset of the coordinates, yield sample optimal estimators in broader error regime for a wide range of symmetric properties. Further, in [HO20] an instance dependent quantity known as proﬁle entropy was shown to govern the accuracy achievable by PML and their analysis holds for all symmetric properties with no additional assumption on the structure of the property.
Additionally, in [HS20] it was shown that PML distributions yield a sample optimal universal estimator up to error (cid:15) (cid:29) n−1/3 for a broad class of symmetric properties. However, the inability to n log n)) has obtain approximate PML distributions of approximation error better than exp(−O( limited the provably efﬁcient implementation of these methods.
√
In this paper we enable many of these applications by providing improved efﬁcient approximations to
PML distributions. Our main theoretical contribution is a polynomial time algorithm that computes an exp(−O(k log n))-approximate PML distribution where k is the number of distinct observed
√ n, our work generalizes the previous best known frequencies. As k is always upper bounded by result from [ACSS20] that computed an exp(−O( n log n))-approximate PML. Leveraging this result, our work provides the ﬁrst provably efﬁcient implementation of PseudoPML. Further, our work also yields the ﬁrst provably efﬁcient estimator for proﬁle entropy and efﬁcient estimators with instance-based high-accuracy guarantees via proﬁle entropy. We obtain our approximate PML result by leveraging interesting sparsity structure in convex relaxations of PML [ACSS20, CSS19a] and additionally provide a novel matrix rounding algorithm that we believe is of independent interest.
√
Finally, beyond the above theoretical results we provide a simpliﬁed instantiation of these results that is sufﬁcient for implementing PseudoPML. We believe this result is a key step towards practical
PseudoPML. We provide preliminary experiments in which we perform entropy estimation using the
PseudoPML approach implemented using our simpler rounding algorithm. Our results match other state-of-the-art estimators for entropy, some of which are property speciﬁc.
Notation and basic deﬁnitions: Throughout this paper we assume to receive a sequence of n independent samples from an underlying distribution p ∈ ∆D, where D is a domain of elements and
∆D is the set of all discrete distributions supported on this domain. We let [a, b] and [a, b]R denote
R |(cid:13) (cid:13)q(cid:13) the interval of integers and reals ≥ a and ≤ b respectively, so ∆D def= {q ∈ [0, 1]D (cid:13)1 = 1}. Let
Dn be the set of all length n sequences and yn ∈ Dn be one such sequence with yn i denoting its ith element. Let f(yn, x) def= |{i ∈ [n] | yn i = x}| and px be the frequency and probability of x ∈ D respectively. For a sequence yn ∈ Dn, let M = {f(yn, x)}x∈D\{0} be the set of all its non-zero distinct frequencies and m1, m2, . . . , m|M| be these distinct frequencies. The proﬁle of a sequence def= |{x ∈ D | f(yn, x) = mj}| is the number yn denoted φ = Φ(yn) is a vector in Z|M| of domain elements with frequency mj. We call n the length of proﬁle φ and let Φn denote the set of all proﬁles of length n. The probability of observing sequence yn and proﬁle φ with respect to a distribution p are as follows, (cid:89)
+ , where φj (cid:88)
P(p, yn) = pf(yn,x) x and
P(p, φ) =
P(p, yn) . x∈D
{yn∈Dn | Φ(yn)=φ}
For a proﬁle φ ∈ Φn, pφ is a proﬁle maximum likelihood (PML) distribution if pφ ∈ arg maxp∈∆D
P(p, φ). Further, a distribution pβ
φ, φ) ≥ β · P(pφ, φ).
For a distribution p and n, let X be a random variable that takes value φ ∈ Φn with probability
Pr (p, φ). The distribution of X depends only on p and n and we call H(X) (entropy of X) the proﬁle entropy with respect to (p, n) and denote it by H(Φn, p).
φ is a β-approximate PML distribution if P(pβ
We use (cid:101)O(·), (cid:101)Ω(·) notation to hide all polylogarithmic factors in n and N .
Paper organization:
In Section 2 we formally state our results. In Section 3, we provide the convex relaxation [CSS19a, ACSS20] for the PML objective. Using this convex relaxation, in Section 4 we state our algorithm that computes an exp(−O(k log n))-approximate PML and sketch its proof.
Finally, in Section 5, we provide a simpler algorithm that provably implements the PseudoPML approach; we implement this algorithm and provide experiments in the same section. Due to space constraints, we defer most of the proofs to appendix. 2
2 Results
Here we provide the main results of our paper on computing approximations to PML where the ap-proximation quality depends on the number of distinct frequencies, as well as efﬁciently implementing results on proﬁle entropy and PseudoPML.
Distinct frequencies: Our main approximate PML result is the following.
Theorem 2.1 (Approximate PML). There is an algorithm that given a proﬁle φ ∈ Φn with k distinct frequencies, computes an exp (−O(k log n))-approximate PML distribution in time polynomial in n.
Our result generalizes [ACSS20] which computes an exp(−O( n log n))-approximate PML.
Through [ADOS16] our result also provides efﬁcient optimal estimators for class of symmetric properties when (cid:15) (cid:29) n−1/4. Further, for distributions that with high probability output a proﬁle with
O(n1/3) distinct frequencies, through [HS20] our algorithm enables efﬁcient optimal estimators for the same class of properties when (cid:15) (cid:29) n−1/3. In Section 4 we provide a proof sketch for the above theorem and defer all the proof details to Appendix A.
√
Proﬁle entropy: One key application of our instance-based, i.e. distinct-frequency-based, approxi-mation algorithm is the efﬁcient implementation of the following approximate PML version of the proﬁle entropy result from [HO20].3. See Section 1 for the deﬁnition of proﬁle entropy.
Lemma 2.2 (Theorem 3 in [HO20]). Let f be a symmetric property. For any p ∈ ∆D and a proﬁle
φ ∼ p of length n with k distinct frequencies, with probability at least 1 − O(1/ n),
√
|f (p) − f (pβ
φ)| ≤ 2(cid:15)f (cid:32) (cid:101)Ω(n) (cid:100)H(Φn, p)(cid:101) (cid:33)
, where pβ
φ is any β-approximate PML distribution for β > exp(−O(k log n)) and (cid:15)f (n) is the smallest error that can be achieved by any estimator with sample size n and success proability4 9/10
As the above result requires an exp(−O(k log n))-approximate PML, our Theorem 2.1 immediately provides an efﬁcient implementation of it. Lemma 2.2 holds for any symmetric property with no additional assumptions on the structure. Further, it trivially implies a weaker result in [ADOS16] where (cid:100)H(Φn, p)(cid:101) is replaced by n. For further details and motivation, see [HO20].
√
PseudoPML: Our approximate PML algorithm also enables the efﬁcient implementation of Pseu-doPML [CSS19b, HO19]. Using PseudoPML, the authors in [CSS19b, HO19] provide a general estimation framework that is sample optimal for many properties in wider parameter regimes than the previous universal approaches. At a high level, in this framework, the samples are split into two parts based on the element frequencies. The empirical estimate is used for the ﬁrst part and for the second part, they compute the estimate corresponding to approximate PML. To efﬁciently implement the approach of PseudoPML required efﬁcient algorithms with either strong or instance dependent approximation guarantees and our result (Theorem 2.1) achieves the later. We ﬁrst state a lemma that relates the approximate PML computation to the PseudoPML.
Lemma 2.3 (PseudoPML). Let φ ∈ Φn be a proﬁle with k distinct frequencies and (cid:96), u ∈ [0, 1]. If there exists an algorithm that runs in time T (n, k, u, (cid:96)) and returns a distribution p(cid:48) such that
P(p(cid:48), φ) ≥ exp (−O((u − (cid:96))n log n + k log n)) max q∈∆D
[(cid:96),u]
P(q, φ) , (1) where ∆D with the following guarantees,
[(cid:96),u] def= {p ∈ ∆D(cid:12) (cid:12) (cid:12)px ∈ [(cid:96), u] ∀x ∈ D}. Then we can implement the PseudoPML approach
• For entropy, when error parameter (cid:15) > Ω (cid:17) (cid:16) log N
N 1−α for any constant α > 0, the estimator is sample complexity optimal and runs in T (n, O(log n), O(log n/n), 1/poly(n)) time. 3Theorem 3 in [HO20] discuss instead exact PML and the authors discuss the approximate PML case in the comments; we conﬁrmed the sufﬁciency of approximate PML claimed in the theorem through private communication with the authors. 4Please refer [HO20] for general success probability 1 − δ; our work also holds for the general case. 3
• For distance to uniformity, when (cid:15) > Ω (cid:0) 1
N 1−α (cid:1) for any constant α > 0, the estimator is sample complexity optimal and runs in T (n, (cid:101)O(1/(cid:15)), O(1/N ), Ω(1/N )) time.
The proof of the lemma is divided into two main steps. In the ﬁrst step, we relate (1) to conditions considered in PseudoPML literature. In the second step, we leverage this relationship and the analysis in [CSS19b, HO19] to obtain the result. See Appendix B.3 for the proof of the lemma and other details. As discussed in [CSS19b, HO19], the above results are interesting because we have a general framework (PseudoPML approach) that is sample optimal in a broad range of non-trivial estimation settings; for instance when (cid:15) < log N
N for entropy and (cid:15) < 1
N C for distance to uniformity where
C > 0 is a constant, we know that the empirical estimate is optimal.
As our approximate PML algorithm (Theorem 2.1) runs in time polynomial in n (for all values of k) and returns a distribution that satisﬁes the condition of the above lemma; we immediately obtain an efﬁcient implementation of the results in Lemma 2.3. However for practical purposes, we present a simpler and faster algorithm that outputs a distribution which sufﬁces for the application of
PseudoPML. We summarize this result in the following theorem.
Theorem 2.4 (Efﬁcient PseudoPML). There exists an algorithm that implements Lemma 2.3 in time
T (n, k, u, (cid:96)) = (cid:101)O(n kω−1 log u (cid:96) ), where ω is the matrix multiplication constant. Consequently, this provides estimators for entropy and distance to uniformity in time (cid:101)O(n) and (cid:101)O(n/(cid:15)ω−1) under their respective error parameter restrictions.
See Section 5 for a description of the algorithm and proof sketch. The running time in the above result involves: solving a convex program, n/k number of linear system solves of k × k matrices and other low order terms for the remaining steps. In our implementation we use CVX[GB14] with package CVXQUAD[FSP17] to solve the convex program. We use couple of heuristics to make our algorithm more practical and we discuss them in Appendix B.4. 2.1