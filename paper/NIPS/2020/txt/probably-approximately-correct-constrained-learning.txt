Abstract
As learning solutions reach critical applications in social, industrial, and medical domains, the need to curtail their behavior has become paramount. There is now ample evidence that without explicit tailoring, learning can lead to biased, unsafe, and prejudiced solutions. To tackle these problems, we develop a generalization theory of constrained learning based on the probably approximately correct (PAC) learning framework. In particular, we show that imposing requirements does not make a learning problem harder in the sense that any PAC learnable class is also
PAC constrained learnable using a constrained counterpart of the empirical risk minimization (ERM) rule. For typical parametrized models, however, this learner involves solving a constrained non-convex optimization program for which even obtaining a feasible solution is challenging. To overcome this issue, we prove that under mild conditions the empirical dual problem of constrained learning is also a
PAC constrained learner that now leads to a practical constrained learning algorithm based solely on solving unconstrained problems. We analyze the generalization properties of this solution and use it to illustrate how constrained learning can address problems in fair and robust classiﬁcation. 1

Introduction
Learning has become a core component of the modern information systems we increasingly rely upon to select job candidates, analyze medical data, and control “smart” applications (home, grid, city). As these systems become ubiquitous, so does the need to curtail their behavior. Left untethered, they can fail catastrophically as evidenced by the growing number of reports involving biased, prejudiced models or systems prone to tampering (e.g., adversarial examples), unsafe behaviors, and deadly accidents [1–6]. Typically, learning is constrained by using domain expert knowledge to either construct models that embed the required properties (see, e.g., [7–13]) or tune the training objective so as to promote them (see, e.g., [14–17]). The latter approach, known as regularization, is ubiquitous in practice even though it need not yield feasible solutions [18]. In fact, existing results from classical learning theory guarantee generalization with respect to the regularized objective, which says nothing about meeting the requirements it may describe [19, 20]. While the former approach guarantees that the solution satisﬁes the requirements, the scale and opacity of modern machine learning (ML) systems render this model design impractical.
Since ML models are often trained using empirical risk minimization (ERM), an alternative solution is to explicitly add constraints to these optimization problems. Since requirements are often expressed as constraints in the ﬁrst place, this approach overcomes the need to tune regularization parameters.
What it more, any solution automatically satisﬁes the requirements. Nevertheless, this approach suffers from two fundamental drawbacks. First, its involves solving a constrained optimization problem that is non-convex for typical parametrizations (e.g., neural networks). Though gradient descent can often be used to obtain good minimizers for differentiable models, it does not guarantee 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
constraint satisfaction. Indeed, there is typically no straightforward way to project onto the feasibility set (e.g., the set of fair classiﬁers) and strong duality need not hold for non-convex programs [18].
Second, even if we could solve this constrained ERM, the issue remains of how its solutions generalize since classical learning theory is involved only with unconstrained problems [19, 20].
In this work, we address these issues in two steps. We begin by formalizing the concept of constrained learning using the probably approximately correct (PAC) framework. We prove that any hypothesis class that is unconstrained learnable is constrained learnable and that the constrained counterpart of the ERM rule is a PAC constrained learner. Hence, we establish that, from a learning theoretic perspective, constrained learning is as hard as unconstrained (classical) learning. This, however, does not resolve the practical issue of learning under requirements due to the non-convexity of the constrained ERM problem. To do so, we proceed by deriving an empirical saddle-point problem that is a (representation-independent) PAC constrained learner. We show that its approximation error depends on the richness of the parametrization and the difﬁculty of satisfying the learning constraints. Finally, we put forward practical constrained learning algorithm that we use to illustrate how constrained learning can address problems involving fairness and robustness. 2