Abstract
Stochastic Approximation (SA) is a popular approach for solving ﬁxed-point equations where the information is corrupted by noise. In this paper, we consider an SA involving a contraction mapping with respect to an arbitrary norm, and show its ﬁnite-sample error bounds while using different stepsizes. The idea is to construct a smooth Lyapunov function using the generalized Moreau envelope, and show that the iterates of SA have negative drift with respect to that Lyapunov function. Our result is applicable in Reinforcement Learning (RL). In particular, we use it to establish the ﬁrst-known convergence rate of the V-trace algorithm for off-policy TD-learning [18]. Importantly, our construction results in only a logarithmic dependence of the convergence bound on the size of the state-space. 1

Introduction
Reinforcement Learning (RL) captures an important facet of machine learning going beyond predic-tion and regression: sequential decision making, and has had great impact in various problems of practical interest [37, 29, 35]. At the heart of RL is the problem of iteratively solving the Bellman’s equation using noisy samples, i.e. solving a ﬁxed-point equation of the form H(x) = x. Here, H is a contractive operator with respect to a suitable norm, where we only have access to samples from noisy versions of the operator. Such ﬁxed-point equations, more broadly, are solved through the framework of Stochastic Approximation (SA) algorithms [33], with several RL algorithms such as Q-learning and TD-learning being examples there-of. This paper focuses on understanding the evolution of such a noisy ﬁxed-point iteration through the lens of SA, and providing ﬁnite-sample convergence results.
More formally, the SA algorithm for solving the ﬁxed-point equation H(x) = x is of the form xk+1 = xk + (cid:15)k (H(xk) − xk + wk), where {(cid:15)k} is the stepsize sequence, and {wk} is the noise sequence. To derive ﬁnite-sample bounds, three conditions are pertinent: (a) The norm in which the operator H contracts, (b) The mean zero noise when conditioned on the past, and (c) The nature of the bound on the conditional second moment of the noise.
In prior literature, if the conditional second moment of the noise {wk} is uniformly bounded by a constant, then the norm with respect to which H being a contraction becomes irrelevant, and it is possible to derive ﬁnite-sample convergence guarantees [3, 4, 19, 17]. When the second moment of the noise is not uniformly bounded, then ﬁnite-sample bounds can be derived in the case where the norm for contraction of H is the Euclidean norm [5, 11]. However, in many RL problems, the contraction of H occurs with respect to a different norm (e.g. the (cid:96)∞-norm [47] or a weighted variant 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
[44]). Further, conditioned on the past, the second moment of the norm of the noise scales afﬁnely with the current iterate (again w.r.t. an arbitrary norm), and in general, no uniform bound exists.
An important practical application of this setting with (cid:96)∞-norm contraction and unbounded noise is the well-known V-trace algorithm for solving the policy evaluation problem using off-policy
TD-learning [39]. Its variants form the basis of today’s distributed RL platforms like IMPALA [18] and TorchBeast [25] for multi-agent training. It has been used at scale in the recent Deepmind City
Navigation Project “Street Learn” [29]. Therefore, deriving ﬁnite-sample convergence results for
SA under contraction of H with respect to general norms, and handling unbounded noise are of fundamental interest. In this paper, we answer the following general question in the afﬁrmative:
Can we provide ﬁnite-sample convergence guarantees for the SA algorithm when the norm of contraction of H is arbitrary, and the second moment of the noise conditioned on the past scales afﬁnely with respect to the squared-norm of the current iterate?
To the best of our knowledge, except under special conditions on the norm for contraction of H and/or strong assumptions on the noise, such ﬁnite-sample error bounds have not been established.
The following table summarizes the results for related works. In Table 1, d-dependence refers to the dependence on the dimension d of the iterate xk. To clarify, in the corresponding d-dependence of this work for general contractive SA, we write log(d) ((cid:107) · (cid:107)∞) to indicate that the dimension dependence is log(d) when the norm of contraction is the (cid:96)∞-norm (cid:107) · (cid:107)∞.
Table 1: Comparison to existing bounds
Topic
Contraction
Noise
Q-learning [3, 4]
Q-learning [46]
Q-learning [46]
SGD [11]
SGD [11]
Q-learning
[this work]
V-Trace
[this work] (cid:107) · (cid:107)∞ (cid:107) · (cid:107)∞ (cid:107) · (cid:107)∞ (cid:107) · (cid:107)2 (cid:107) · (cid:107)2
Bounded
Bounded
Bounded
Afﬁne
Afﬁne
Step size
Constant 1 1+(1−γ)k 1 kξ
Constant
β
γ+k
Rate
Geometric
O(1/k)
O(1/kξ) d dependence d2 log(d) log(d)
Geometric
Independent
O(1/k)
Independent (cid:107) · (cid:107)∞
Bounded
Constant
Geometric (cid:107) · (cid:107)∞
Afﬁne (cid:15) k+K
O(1/k) log(d) log(d)
Contractive SA
[this work]
Arbitrary norm
Afﬁne
Constant &
Diminishing
Corollary 2.1
Corollary 2.2 log(d) ((cid:107) · (cid:107)∞)
The main contributions of this paper are as follows. 1. Finite-Sample Convergence Guarantees for SA. We present a novel approach for deriving
ﬁnite-sample error bounds of the SA algorithm under a general norm contraction. The key idea is to study the drift of a carefully constructed potential/Lyapunov function. We obtain such a potential function by smoothing the norm-squared function using a generalized Moreau envelope. We then study the error bound under either constant or diminishing stepsizes. Speciﬁcally, we show that the iterates converge to a ball with radius proportional to the stepsize when using constant stepsize, and converge with rate roughly O(1/k) when using properly chosen diminishing stepsizes. 2. Performance of the V-trace Algorithm. To demonstrate the effectiveness of the theoretical result in an entirely novel setting in RL, we consider the V-trace algorithm for solving the policy evaluation problem using off-policy sampling [18]. Interestingly in this case, it is not clear if the iterates of the V-trace algorithm are uniformly bounded by a constant (e.g. as in Q-learning [21]). Therefore, existing techniques are not applicable. Using our approach, we establish the ﬁrst known ﬁnite-sample error bounds, and show that the convergence rate is logarithmic in the state-space dimension. In our result, the logarithmic dimension dependence relies on the general form of the Moreau envelope obtained by the inﬁmal convolution with a suitable smooth squared-norm. The freedom in selecting such norm allows us to obtain the logarithmic dependence. Moreover, our approach also recovers 2
the existing state-of-the-art error bounds [46] for Q-learning including logarithmic dependence on dimension (Appendix C), which may be of independent interest. 1.1 Summary of our techniques
We now give a more detailed description of the techniques we used. To provide intuition, assume for now that the norm (cid:107) · (cid:107)c with respect to which H being a contraction is the (cid:96)p-norm for p ∈ [2, ∞), i.e., (cid:107)H(x) − H(y)(cid:107)p ≤ γ(cid:107)x − y(cid:107)p for all x, y ∈ Rd, where γ ∈ (0, 1) is the contraction factor.
Denote the ﬁxed-point of H by x∗. Consider the Ordinary Differential Equation (ODE) associated with this SA: ˙x(t) = H(x(t)) − x(t). It is shown in [9] (Chapter 10) that W (x) = (cid:107)x − x∗(cid:107)p satisﬁes d dt W (x(t)) ≤ −αW (x(t)) for some α > 0, which implies the solution x(t) of the ODE converges to its equilibrium point x∗ geometrically fast. The term α corresponds to a negative drift.
In order to obtain ﬁnite-sample bounds, in this paper we study the SA directly, and not the ODE.
Then, the Lyapunov function W (x) cannot be directly used to analyze the SA algorithm due to the discretization error and stochastic error. However, suppose we can ﬁnd a function M (x) that gives negative drift, and in addition: (a) M (x) is L – smooth w.r.t. some norm (cid:107) · (cid:107)s [1], (b) the noise {wk} is zero mean conditioned on the past, and (c) the conditional second moment of (cid:107)wk(cid:107)n (where (cid:107) · (cid:107)n is again some arbitrary norm) can be bounded afﬁnely by the current iterate (cid:107)xk(cid:107)2 n. Then, we have a handle to deal with the discretization error and error caused by the noise to obtain: k))E[M (xk − x∗)] + O((cid:15)2 (1) which implies a contraction in E[M (xk+1 − x∗)]. Therefore, a ﬁnite-sample error bound can be obtained by recursively applying the previous inequality. The key point is that M (x)’s smoothness and its negative drift with respect to the ODE produces a contraction (1 − O((cid:15)k) + O((cid:15)2 k)) for {xk}.
Based on the above analysis, we see that the Lyapunov function for the SA in the case of (cid:96)p-norm contraction should be M (x) = 1
E[M (xk+1 − x∗)] ≤ (1 − O((cid:15)k) + O((cid:15)2 p, which is known to be (p − 1) – smooth [1]. 2 (cid:107)x − x∗(cid:107)2 k),
However, in the case where (cid:107) · (cid:107)c is some arbitrary norm, since the function f (x) = 1 c is not necessarily smooth, the key difﬁculty is to construct a smooth Lyapunov function. An important special case is when (cid:107) · (cid:107)c = (cid:107) · (cid:107)∞, which is applicable to many RL algorithms. We provide a solution to this where we construct a smoothed convex envelope M (x) called the Generalized
Moreau Envelope that is smooth w.r.t. some norm (cid:107) · (cid:107)s, and it is a tight approximation to f (x), i.e. aM (x) ≤ f (x) ≤ bM (x) for some constants a, b > 0. Further, it is a Lyapunov function for the
ODE with a negative drift. This essentially lets us prove a convergence result akin to the case when f (x) is smooth. 2 (cid:107)x − x∗(cid:107)2 1.2