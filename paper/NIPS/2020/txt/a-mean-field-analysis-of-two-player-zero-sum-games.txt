Abstract
Finding Nash equilibria in two-player zero-sum continuous games is a central problem in machine learning, e.g. for training both GANs and robust models. The existence of pure Nash equilibria requires strong conditions which are not typically met in practice. Mixed Nash equilibria exist in greater generality and may be found using mirror descent. Yet this approach does not scale to high dimensions. To address this limitation, we parametrize mixed strategies as mixtures of particles, whose positions and weights are updated using gradient descent-ascent. We study this dynamics as an interacting gradient ﬂow over measure spaces endowed with the
Wasserstein-Fisher-Rao metric. We establish global convergence to an approximate equilibrium for the related Langevin gradient-ascent dynamic. We prove a law of large numbers that relates particle dynamics to mean-ﬁeld dynamics. Our method identiﬁes mixed equilibria in high dimensions and is demonstrably effective for training mixtures of GANs. 1

Introduction
Multi-objective optimization problems arise in many ﬁelds, from economics to civil engineering.
Tasks that require optimizing multiple objectives have also become a routine part of many agent-based machine learning algorithms including generative adversarial networks (Goodfellow et al., 2014), imaginative agents (Racanière et al., 2017), hierarchical reinforcement learning (Wayne and Abbott, 2014) and multi-agent reinforcement learning (Bu et al., 2008). It not only remains difﬁcult to carry out the necessary optimization, but also to assess the optimality of a given solution.
Multi-agent optimization is generally cast as ﬁnding equilibria in the space of strategies. The classic notion of equilibrium is due to Nash (Nash, 1951): a Nash equilibrium is a set of agent strategies for which no agent can unilaterally improve its loss value. Pure Nash equilibria, in which each agent 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
adopts a single strategy, provide a limited notion of optimality because they exist only under restrictive conditions. On the other hand, mixed Nash equilibria (MNE), where agents adopt a strategy from a probability distribution over the set of all strategies, exist in much greater generality (Glicksberg, 1952). Importantly, MNE exist for games with inﬁnite-dimensional compact strategy spaces, in which each player observes a loss function that is continuous in its strategy. We encounter this setting in different game formulations of machine learning problems, like GANs (Goodfellow et al., 2014).
Although MNE are guaranteed to exist, it is difﬁcult to identify them. Indeed, worst-case complexity analyses have shown that without additional assumptions on the losses there is no efﬁcient algorithm for ﬁnding a MNE, even in the case of two-player ﬁnite games (Daskalakis et al., 2009). Some recent progress has been made; (Hsieh et al., 2019) proposed a mirror-descent algorithm with convergence guarantees, which is approximately realizable in high-dimension.
Contributions. Following Hsieh et al. (2019), we formulate continuous two-player zero-sum games as a multi-agent optimization problem over the space of probability measures on strategies. We describe two gradient descent-ascent dynamics in this space, both involving a transport term.
•
•
•
We show that the stationary points of a gradient ascent-descent ﬂow with Langevin diffusion over the space of mixed strategies are approximate MNE.
We analyse a gradient ascent-descent dynamics that jointly updates the positions and weights of two mixed strategies to converge to an exact MNE. This dynamics corresponds to a gradient descent-ascent ﬂow over the space of measures endowed with a Wasserstein-Fisher-Rao (WFR) metric (Chizat, Peyré, et al., 2018).
We discretize both dynamics in space and time to obtain implementable training algorithms.
We provide mean-ﬁeld type consistency results on the discretization. We demonstrate numerically how both dynamics overcome the curse of dimensionality for ﬁnding MNE on synthetic games. On real data, we use WFR ﬂows to train mixtures of GANs, that explicitly discover data clusters while maintaining good performance. 2