Abstract
The wide-spread availability of rich data has fueled the growth of machine learning applications in numerous domains. However, growth in domains with highly-sensitive data (e.g., medical) is largely hindered as the private nature of data prohibits it from being shared. To this end, we propose Gradient-sanitized Wasser-stein Generative Adversarial Networks (GS-WGAN), which allows releasing a sanitized form of the sensitive data with rigorous privacy guarantees. In contrast to prior work, our approach is able to distort gradient information more precisely, and thereby enabling training deeper models which generate more informative samples.
Moreover, our formulation naturally allows for training GANs in both centralized and federated (i.e., decentralized) data scenarios. Through extensive experiments, we ﬁnd our approach consistently outperforms state-of-the-art approaches across multiple metrics (e.g., sample quality) and datasets. 1

Introduction
Releasing statistical and sensory data to a broad community has contributed towards advances in numerous machine learning (ML) techniques e.g., object recognition (ImageNet [11]), language modeling (RCV [24]), recommendation systems (Netﬂix ratings [6]). However, in many sensitive domains (e.g., medical, ﬁnancial), similar advances are often held back as the private nature of collected data prohibits release in its original form. Privacy-preserving data publishing [5, 13, 17] provides a reasonable solution, where only a sanitized form of the original data (with rigorous privacy guarantees) is publicly released.
Traditionally, sanitization is performed in a differentially private (DP) framework [12]. The saniti-zation method employed is often hand-crafted for the given input data [28, 30, 43] and the speciﬁc data-dependent task the sanitized data is intended for (e.g., answering linear queries) [7, 14, 21, 36].
As a result, such sanitization techniques greatly restrict the expressiveness of the released data distribution and fail to generalize to novel tasks unanticipated by the publisher. Instead, recent privacy-preserving techniques [5, 41, 42, 44] build on top of successes in generative adversarial network (GANs) [18] literature, to generate synthetic data faithful to the original input distribution.
Speciﬁcally, GANs are trained using a privacy-preserving algorithm (e.g., using DP-SGD [1]) and demonstrate promising results in modeling a variety of real-world high-dimensional data distributions.
Common to most privacy-preserving training algorithms for neural network models is manipulating the gradient information generated during backpropagation. Manipulation most commonly involves clipping the gradients (to bound sensitivity) and adding calibrated random noise (to introduce stochas-ticity). Although recent techniques that employ such an approach demonstrate reasonable success, they are mostly limited to shallow networks and fail to sufﬁciently capture the sample quality of the original data.
In this paper, towards the goal of a generative model capable of synthesizing high-quality samples in a privacy-preserving manner, we propose a differentially private GAN. We ﬁrst identify that in 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
such a data-publishing scenario, only a subset of the trained model (speciﬁcally the generator) and its parameters need to be publicly-released. This insight allows us to surgically manipulate the gradient information during training, and thereby allowing more meaningful gradient updates. By coupling the approach with a Wasserstein [2] objective with gradient-penalty term [19], we further improve the amount of gradient information ﬂow during training. The Wasserstein objective additionally allows us to precisely estimate the gradient norms and analytically determine the sensitivity values. As an added beneﬁt, we ﬁnd our approach bypasses an intensive and fragile hyper-parameter search for
DP-speciﬁc hyperparameters (particularly clipping values). (i) A novel gradient-sanitized Wasserstein GAN (GS-WGAN), which is capable
Contributions. of generating high-dimensional data with DP guarantee; (ii) Our approach naturally extends to both centralized and decentralized datasets. In the case of decentralized scenarios, our work can provide user-level DP guarantee [26] under an untrusted server; (iii) Extensive evaluations on various datasets demonstrate that our method signiﬁcantly improves the sample quality of privacy-preserving data over state-of-the-art approaches. 2