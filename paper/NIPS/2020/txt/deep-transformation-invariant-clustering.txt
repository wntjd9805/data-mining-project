Abstract
Recent advances in image clustering typically focus on learning better deep repre-sentations. In contrast, we present an orthogonal approach that does not rely on abstract features but instead learns to predict transformations and performs cluster-ing directly in pixel space. This learning process naturally ﬁts in the gradient-based training of K-means and Gaussian mixture model, without requiring any additional loss or hyper-parameters. It leads us to two new deep transformation-invariant clustering frameworks, which jointly learn prototypes and transformations. More speciﬁcally, we use deep learning modules that enable us to resolve invariance to spatial, color and morphological transformations. Our approach is conceptually simple and comes with several advantages, including the possibility to easily adapt the desired invariance to the task and a strong interpretability of both cluster cen-ters and assignments to clusters. We demonstrate that our novel approach yields competitive and highly promising results on standard image clustering bench-marks. Finally, we showcase its robustness and the advantages of its improved interpretability by visualizing clustering results over real photograph collections. 1

Introduction
Gathering collections of images on a topic of interest is getting easier every day: simple tools can aggregate data from social media, web search, or specialized websites and ﬁlter it using hashtags,
GPS coordinates, or semantic labels. However, identifying visual trends in such image collections remains difﬁcult and usually involves manually organizing images or designing an ad hoc algorithm.
Our goal in this paper is to design a clustering method which can be applied to such image collections, output a visual representation for each cluster and show how it relates to every associated image.
Directly comparing image pixels to decide if they belong to the same cluster leads to poor results because they are strongly impacted by factors irrelevant to clustering, such as exact viewpoint or lighting. Approaches to obtain clusters invariant to these transformations can be broadly classiﬁed into two groups. A ﬁrst set of methods extracts invariant features and performs clustering in feature space. The features can be manually designed, but most state-of-the-art methods learn them directly from data. This is challenging because images are high-dimensional and learning relevant invariances thus requires huge amounts of data. For this reason, while recent approaches perform well on simple datasets like MNIST, they still struggle with real images. Another limitation of these approaches is that learned features are hard to interpret and visualize, making clustering results difﬁcult to analyze.
A second set of approaches, following the seminal work of Frey and Jojic on transformation-invariant clustering [11, 12, 13], uses explicit transformation models to align images before comparing them.
These approaches have several potential advantages: (i) they enable direct control of the invariances to consider; (ii) because they do not need to discover invariances, they are potentially less data-hungry; (iii) since images are explicitly aligned, clustering process and results can easily be visualized.
However, transformation-invariant approaches require solving a difﬁcult joint optimization problem.
In practice, they are thus often limited to small datasets and simple transformations, such as afﬁne 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
(a) Classical versus Deep Transformation-Invariant clustering (b) Deep transformation module Tfk (c) Prototypes learned from unﬁltered Instagram images associated to different hashtags
Figure 1: Overview. (a) Given a sample xi and prototypes c1 and c2, standard clustering such as
K-means assigns the sample to the closest prototype. Our DTI clustering ﬁrst aligns prototypes to the sample using a family of parametric transformations - here rotations - then picks the prototype whose alignment yields the smallest distance. (b) We predict alignment with deep learning. Given an image xi, each parameter predictor fk predicts parameters for a sequence of transformations - here afﬁne
T aff
- to align prototype ck to xi. (c) Examples
βaff of interpretable prototypes discovered from large images sets (15k each) associated to hashtags in
Instagram using our DTI clustering with 40 clusters. Each cluster contains from 200 to 800 images.
, and thin plate spline T tps
βtps
, morphological T mor
βmor transformations, and to the best of our knowledge they have never been evaluated on large standard image clustering datasets.
In this paper, we propose a deep transformation-invariant (DTI) framework that enables to perform transformation-invariant clustering at scale and uses complex transformations. Our main insight is to jointly learn deep alignment and clustering parameters with a single loss, relying on the gradient-based adaptations of K-means [38] and GMM optimization [9]. Not only is predicting transformations more computationally efﬁcient than optimizing them, but it enables us to use complex color, thin plate spline and morphological transformations without any speciﬁc regularization. Because it is pixel-based, our deep transformation-invariant clustering is also easy to interpret: cluster centers and image alignments can be visualized to understand assignments. Despite its apparent simplicity, we demonstrate that our DTI clustering framework leads to results on par with the most recent feature learning approaches on standard benchmarks. We also show it is capable of discovering meaningful modes in real photograph collections, which we see as an important step to bridge the gap between theoretically well-grounded clustering approaches and semi-automatic tools relying on hand-designed features for exploring image collections, such as AverageExplorer [52] or ShadowDraw [32].
We ﬁrst brieﬂy discuss related works in Section 2. Section 3 then presents our DTI framework (Fig. 1a). Section 4 introduces our deep transformation modules and architecture (Fig. 1b) and discuss training details. Finally, Section 5 presents and analyzes our results (Fig. 1c).
Contributions. – a deep transformation-invariant clustering approach that jointly learns to cluster and align images, – a deep image transformation module to learn spatial alignment, color modiﬁcations and for the
In this paper we present:
ﬁrst time morphological transformations, – an experimental evaluation showing that our approach is competitive on standard image clustering benchmarks, improving over state-of-the-art on Fashion-MNIST and SVHN, and provides highly interpretable qualitative results even on challenging web image collections. 2
Code, data, models as well as more visual results are available on our project webpage1. 2