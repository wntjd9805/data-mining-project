Abstract
Training models with discrete latent variables is challenging due to the difﬁculty of estimating the gradients accurately. Much of the recent progress has been achieved by taking advantage of continuous relaxations of the system, which are not always available or even possible. The Augment-REINFORCE-Merge (ARM) estimator provides an alternative that, instead of relaxation, uses continuous augmentation. Applying antithetic sampling over the augmenting variables yields a relatively low-variance and unbiased estimator applicable to any model with binary latent variables. However, while antithetic sampling reduces variance, the augmentation process increases variance. We show that ARM can be improved by analytically integrating out the randomness introduced by the augmentation process, guaranteeing substantial variance reduction. Our estimator, DisARM, is simple to implement and has the same computational cost as ARM. We evaluate DisARM on several generative modeling benchmarks and show that it consistently outperforms
ARM and a strong independent sample baseline in terms of both variance and log-likelihood. Furthermore, we propose a local version of DisARM designed for optimizing the multi-sample variational bound, and show that it outperforms
VIMCO, the current state-of-the-art method. 1

Introduction
We often require the gradient of an expectation with respect to the parameters of the distribution. In all but the simplest settings, the expectation is analytically intractable and the gradient is estimated using Monte Carlo sampling. This problem is encountered, for example, in modern variational inference, where we would like to maximize a variational lower bound with respect to the parameters of the variational posterior. The pathwise gradient estimator, also known as the reparameterization trick, comes close to this ideal and has been instrumental to the success of variational autoencoders (Kingma and Welling, 2014; Rezende et al., 2014). Unfortunately, it can only be used with continuous random variables, and ﬁnding a similarly effective estimator for discrete random variables remains an important open problem.
Score-function estimators (Glynn, 1990; Fu, 2006), also known as REINFORCE (Williams, 1992), have historically been the estimators of choice for models with discrete random variables due to their unbiasedness and few requirements. As they usually exhibit high variance, previous work has augmented them with variance reduction methods to improve their practicality (Williams, 1992;
Ranganath et al., 2014; Mnih and Gregor, 2014). Motivated by the efﬁciency of the pathwise estimator, recent progress in gradient estimators for discrete variables has primarily been driven by leveraging gradient information. The original system may only be deﬁned for discrete inputs and hence gradients w.r.t. the random variables may not be deﬁned. If we can construct a continuous relaxation of the
Code and additional information: https://sites.google.com/view/disarm-estimator. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
system, then we can compute gradients of the continuous system and use them in an estimator (Gu et al., 2016; Jang et al., 2017; Maddison et al., 2017; Tucker et al., 2017; Grathwohl et al., 2018).
While such relaxation techniques are appealing because they result in low variance estimators by taking advantage of gradient information, they are not always applicable. In some cases, the function we compute the expectation of will not be differentiable w.r.t. the random variables, e.g. if it is a table indexed by the variables. In other cases, the computational cost of evaluating the function at the relaxed variable values will be prohibitive, e.g. in conditional computation (Bengio et al., 2013), where discrete variables specify which parts of a large model should be evaluated and using a relaxation would require evaluating the entire model every time.
The recently introduced Augment-REINFORCE-Merge (ARM) estimator (Yin and Zhou, 2019) provides a promising alternative to relaxation-based estimators for binary latent variables. Instead of relaxing the variables, ARM reparameterizes them as deterministic transformations of the underlying continuous variables. Applying antithetic sampling to the REINFORCE estimator w.r.t. the parame-ters of the underlying continuous distribution yields a highly competitive estimator. We observe that the continuous augmentation, which is the ﬁrst step in ARM, increases the variance of the REIN-FORCE estimator, and antithetic sampling is the only reason ARM outperforms REINFORCE on the original binary distribution. We improve on ARM by integrating over the augmenting variables, thus eliminating the unnecessary randomness introduced by the augmentation and reducing the variance of the estimator substantially. We show that the resulting estimator, DisARM, consistently outperforms
ARM and is highly competitive with RELAX. Concurrently, Yin et al. (2020) discovered the same estimator, calling it the U2G estimator and demonstrating promising performance on best subset selection tasks. We also derive a version of DisARM for the multi-sample variational bound and show that it outperforms the current state-of-the-art gradient estimator for that objective. 2