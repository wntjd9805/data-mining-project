Abstract
We propose the Gaussian Gated Linear Network (G-GLN), an extension to the recently proposed GLN family of deep neural networks. Instead of using back-propagation to learn features, GLNs have a distributed and local credit assignment mechanism based on optimizing a convex objective. This gives rise to many desirable properties including universality, data-efﬁcient online learning, trivial interpretability and robustness to catastrophic forgetting. We extend the GLN framework from classiﬁcation to multiple regression and density modelling by generalizing geometric mixing to a product of Gaussian densities. The G-GLN achieves competitive or state-of-the-art performance on several univariate and mul-tivariate regression benchmarks, and we demonstrate its applicability to practical tasks including online contextual bandits and density estimation via denoising. 1

Introduction
Recent studies have demonstrated that backpropagation-free deep learning, particularly the Gated
Linear Network (GLN) family [1, 2, 3], can yield surprisingly powerful models for solving classiﬁca-tion tasks. This is particularly true in the online regime where data efﬁciency is paramount. In this paper we extend GLNs to model real-valued and multi-dimensional data, and demonstrate that their theoretical and empirical advantages apply to far broader domains than previously anticipated.
The distinguishing feature of a GLN is distributed and local credit assignment. A GLN associates a separate convex loss to each neuron such that all neurons (1) predict the target distribution directly, and (2) are optimized locally using online gradient descent. A half-space “context function” is applied per neuron to select which weights to apply as a function of the input features, allowing the GLN to learn highly nonlinear functions. This architecture gives rise to many desirable properties previously shown in a classiﬁcation setting: (1) trivial interpretability given its piecewise linear structure, (2) exceptional robustness to catastrophic forgetting, and (3) provably universal learning; a sufﬁciently large GLN can model any well-behaved, compactly supported density function to any accuracy, and any no-regret convex optimization method will converge to the correct solution given enough data.