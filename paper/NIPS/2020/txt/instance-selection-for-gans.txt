Abstract
Recent advances in Generative Adversarial Networks (GANs) have led to their widespread adoption for the purposes of generating high quality synthetic imagery.
While capable of generating photo-realistic images, these models often produce unrealistic samples which fall outside of the data manifold. Several recently proposed techniques attempt to avoid spurious samples, either by rejecting them after generation, or by truncating the model’s latent space. While effective, these methods are inefﬁcient, as a large fraction of training time and model capacity are dedicated towards samples that will ultimately go unused. In this work we propose a novel approach to improve sample quality: altering the training dataset via instance selection before model training has taken place. By reﬁning the empirical data distribution before training, we redirect model capacity towards high-density regions, which ultimately improves sample ﬁdelity, lowers model capacity requirements, and signiﬁcantly reduces training time. Code is available at https://github.com/uoguelph-mlrg/instance_selection_for_gans. 1

Introduction
Recent advances in Generative Adversarial Networks (GANs) have enabled these models to be considered a tool of choice for vision synthesis tasks that demand high ﬁdelity outputs, such as image and video generation [6, 12], image editing [41], inpainting [35], and superresolution [32]. However, when sampling from a trained GAN model, outputs may be unrealistic just as often as they appear photo-realistic.
GANs ﬁt a model to a data distribution with the help of a discriminator network. Low quality samples produced by these models are often attributed to poor modeling of the low-density regions of the data manifold [11]. The majority of current techniques attempt to eliminate low quality samples after the model is trained, either by changing the model distribution by truncating the latent space [2, 11] or by performing some form of rejection sampling using a trained discriminator to inform the rejection process [1, 5, 31]. Nevertheless, these methods are inefﬁcient with respect to model capacity and training time, since much of the capacity and optimization efforts dedicated to representing the sparse regions of the data manifold are wasted.
In this paper, we analyze the use of instance selection [21] in the generative setting. We address the problem of uneven model sample quality before GAN model training has begun, rather than after it has ﬁnished. We note that dataset collection is a noisy process, and that many of the currently used datasets for generative model training and evaluation were not purposely created for this task.
Thus, through a dataset curation step, we remove low density regions from the data manifold prior to model optimization and show that this direct dataset intervention (1) improves overall image sample quality in exchange for some reduction in diversity, (2) lowers model capacity requirements, and (3) reduces training time. To remove the sparsest parts of the image manifold, images are ﬁrst projected into an embedding space of perceptually meaningful representations. A scoring function is then ﬁt to asses the manifold density in the neighbourhood of each embedded data point in the dataset. Finally, data points with the lowest manifold density scores are removed from the dataset. In 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
our experiments, we evaluate a variety of image embeddings and scoring functions, observing that
Inceptionv3 and Gaussian likelihood are well suited for the respective roles. Overall, we make the following contributions:
• We propose dataset curation via instance selection to improve the output quality of GANs.
• We show that the manifold density in the perceptual embedding space of a given dataset is predictive of GAN performance, and therefore a good scoring function for instance selection.
• We demonstrate the model capacity savings of instance selection by achieving state-of-the-art performance (in terms of FID) on 64 × 64 resolution ImageNet generation using a
Self-Attention GAN with 1/2 the amount of trainable parameters of the current best model.
• We demonstrate training time savings by training a 128 × 128 resolution BigGAN on
ImageNet in 1/4 the time of the baseline, while also achieving superior performance across all image ﬁdelity metrics.
• We exhibit the overall computational savings of instance selection by training a 256 ×256 resolution BigGAN on ImageNet with only 4 V100 GPUs in 11 days. Our model achieves better image ﬁdelity than the baseline model while using 1/2 as many trainable parameters. 2