Abstract
In this paper, we study Contextual Unsupervised Sequential Selection (USS), a new variant of the stochastic contextual bandits problem where the loss of an arm cannot be inferred from the observed feedback. In our setup, arms are associated with ﬁxed costs and are ordered, forming a cascade. In each round, a context is presented, and the learner selects the arms sequentially till some depth. The total cost incurred by stopping at an arm is the sum of ﬁxed costs of arms selected and the stochastic loss associated with the arm. The learner’s goal is to learn a decision rule that maps contexts to arms with the goal of minimizing the total expected loss.
The problem is challenging as we are faced with an unsupervised setting as the total loss cannot be estimated. Clearly, learning is feasible only if the optimal arm can be inferred (explicitly or implicitly) from the problem structure. We observe that learning is still possible when the problem instance satisﬁes the so-called
‘Contextual Weak Dominance’ (CWD) property. Under CWD, we propose an algorithm for the contextual USS problem and demonstrate that it has sub-linear regret. Experiments on synthetic and real datasets validate our algorithm. 1

Introduction
Industrial systems, such as those found in medical, airport security, and manufacturing, utilize a suite of tests or classiﬁers for monitoring patients, people, and products. Tests have costs with the more intrusive and informative ones resulting in higher monetary costs and higher latency. For this reason, they are often organized as a classiﬁer cascade (Chen et al., 2012; Trapeznikov and Saligrama, 2013;
Wang et al., 2015), so that new input is ﬁrst probed by an inexpensive test then a more expensive one.
The goal of a cascaded system is to resolve easy to handle examples early so that the overall system maintains high accuracy at low average costs.
Over time, due to environmental changes or test calibrations, sequential testing protocols (STP) may no longer be accurate, resulting in higher costs. While one can leverage off-line methods such as supervised training of cascades (Wang et al., 2015), they require new annotated data collection. In many scenarios, new data cannot be collected in-situ, and system shutdown is not an option. In the absence of annotated data, we face a dilemma. While we can observe test outcomes, we cannot ascertain their reliability due to the absence of ground truth, necessitating unsupervised sequential selection (USS) methods, where an arm represents a test/classiﬁer. Recent works (Hanawal et al., 2017; Verma et al., 2019a, 2020a) propose methods for solving the USS problem; however, they 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
focus exclusively on the non-contextual setting, which in essence requires inputs (people, objects, or products) to be homogeneous, and as such, these methods are unrealistic since contexts (high vs. low risk) can guide the arm selection.
In this context, we propose the contextual USS. In our setup, inputs arrive sequentially, and the learner observes a continuous-valued context as input. While the learner knows the costs of each arm, he does not know the associated stochastic loss. Furthermore, the learner does not beneﬁt from feedback from his arm selection, in contrast to the conventional contextual bandit works (Beygelzimer et al., 2011). Thus, while being agnostic to the true loss, the learner must sequentially choose the arm that leads to the smallest total loss, where the total loss is the sum of the cost of using an arm and the mean loss associated with the arm. As such, our proposed problem is a special case of the stochastic partial monitoring problem with contextual inputs (Lattimore and Szepesvári, 2020, Chapter 37).
Most of the prior work on partial monitoring problem is restricted to cases where observed feedback can identify the losses for selected actions. However, in many areas like crowd-sourcing (Bonald and
Combes, 2017; Kleindessner and Awasthi, 2018), resource allocation (Verma et al., 2019b), medical diagnosis (Verma et al., 2020b), and many others, feedback from actions may not even be sufﬁcient to identify the losses.
While we draw upon several concepts introduced in earlier work (Hanawal et al., 2017), there are additional challenges in the contextual case due to the unsupervised nature of the problem. First, unlike vanilla-USS, the loss here is context-dependent. We propose notions of contextual weak dominance as a means to relate observed disagreements to differences in losses between any two arms.
We then propose a parameterized Generalized Linear Model (GLM) to model the context-conditional disagreement probability between any two arms and validate the model empirically.
A fundamental technical challenge is in the estimation of disagreement probabilities uniformly across all contexts in the ﬁnite time while ensuring sufﬁcient exploration between different arm selection protocols, required for honing in on the optimal selection strategy. In particular, since contexts are continuous-valued, and because we have no control over inputs, the contextual observations, in the
ﬁnite time, may not persistently span the whole space, and estimates are often unreliable. To this end, we adapt techniques from parameterized contextual bandits (Chu et al., 2011; Li et al., 2017) for our unsupervised setting. We propose an algorithm based on the principle of optimism, namely, the larger indexed arm in cascade is chosen when uncertain. We show that our algorithm navigates the exploration-exploitation tradeoffs in different ways and lead to sub-linear cumulative regret. We then validate it on several problem instances derived from synthetic and real datasets.