Abstract
This paper studies minimax optimization problems minx maxy f (x, y), where f (x, y) is mx-strongly convex with respect to x, my-strongly concave with respect to y and (Lx, Lxy, Ly)-smooth. Zhang et al.
[42] provided the fol-lowing lower bound of the gradient complexity for any ﬁrst-order method: (cid:16)(cid:113) Lx mx
Ω
+
L2 xy mxmy
+ Ly my (cid:17) ln(1/(cid:15))
. This paper proposes a new algorithm with (cid:17) (cid:16)(cid:113) Lx mx ln (1/(cid:15))
+ Ly my
+ L·Lxy mxmy (cid:17) (cid:16)(cid:112)L2/mxmy ln3 (1/(cid:15)) gradient complexity upper bound ˜O
, where
L = max{Lx, Lxy, Ly}. This improves over the best known upper bound
˜O by Lin et al. [24]. Our bound achieves linear con-vergence rate and tighter dependency on condition numbers, especially when
Lxy (cid:28) L (i.e., when the interaction between x and y is weak). Via reduction, our new bound also implies improved bounds for strongly convex-concave and convex-concave minimax optimization problems. When f is quadratic, we can further improve the upper bound, which matches the lower bound up to a small sub-polynomial factor. 1

Introduction
In this paper, we study the following minimax optimization problem min x∈Rn max y∈Rm f (x, y). (1)
This problem can be thought as ﬁnding the equilibrium in a zero-sum two-player game, and has been studied extensively in game theory, economics and computer science. This formulation also arises in many machine learning applications, including adversarial training [26, 37], prediction and regression problems [41, 38], reinforcement learning [12, 10, 29] and generative adversarial networks [15, 2].
We study the fundamental setting where f is smooth, strongly convex w.r.t. x and strongly concave w.r.t. y.
In particular, we consider the function class F(mx, my, Lx, Lxy, Ly), where mx is the strong convexity modulus, my is the strong concavity modulus, Lx and Ly characterize the smoothness w.r.t. x and y respectively, and Lxy characterizes the interaction between x and y (see
Deﬁnition 2). The reason to consider such a function class is twofold. First, the strongly convex-strongly concave setting is fundamental. Via reduction [24], an efﬁcient algorithm for this setting implies efﬁcient algorithms for other settings, including strongly convex-concave, convex-concave, and non-convex-concave settings. Second, Zhang et al. [42] recently proved a gradient complexity
, which naturally depends on the above parameters. 1 lower bound Ω
· ln (cid:0) 1 (cid:1)(cid:17)
+
L2 xy mxmy
+ Ly my (cid:16)(cid:113) Lx mx (cid:15) 1This lower bound is also proved by Ibrahim et al. [20]. Although their result is stated for a narrower class of algorithms, their proof actually works for the broader class of algorithms considered in [42]. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
Figure 1: Comparison of previous upper bound [24], lower bound [42] and the results in this paper when Lx = Ly, mx < my, ignoring logarithmic factors. The upper bounds and lower bounds are shown as a function of Lxy while other parameters are ﬁxed.
In this setting, classic algorithms such as Gradient Descent-Ascent and ExtraGradient [22] can achieve linear convergence [40, 42]; however, their dependence on the condition number is far from optimal. Recently, Lin et al. [24] showed an upper bound of ˜O
, which has a much tighter dependence on the condition number. In particular, when Lxy > max{Lx, Ly}, the de-pendence on the condition number matches the lower bound. However, when Lxy (cid:28) max{Lx, Ly}, this dependence would no longer be tight (see Fig. 1 for illustration). In particular, we note that, when x and y are completely decoupled (i.e., Lxy = 0), the optimal gradient complexity bound is
Θ (the upper bound can be obtained by simply optimizing x and y separately). Moreover, Lin et al.’s result does not enjoy a linear rate, which may be undesirable if a high precision solution is needed. (cid:16)(cid:112)Lx/mx + Ly/my · ln (1/(cid:15)) (cid:17) (cid:16)(cid:112)L2/mxmy ln3(1/(cid:15)) (cid:17)
In this work, we propose new algorithms in order to address these two issues. Our contribution can be summarized as follows. 1. For general functions in F(mx, my, Lx, Lxy, Ly), we design an algorithm called Proximal
Best Response (Algorithm 4), and prove a convergence rate of (cid:32)(cid:115)
˜O
Lx mx
+
Lxy · L mxmy
+
Ly my (cid:33) ln(1/(cid:15))
.
It achieves linear convergence, and has a better dependence on condition numbers when
Lxy is small (see Theorem 3 and the red line in Fig. 1). 2. We obtain tighter upper bounds for the strongly-convex concave problem and the general convex-concave problem, by reducing them to the strongly convex-strongly concave problem (See Corollary 1 and 2). 3. We also study the special case where f is a quadratic function. We propose an algorithm called Recursive Hermitian-Skew-Hermitian Split (RHSS(k)), and show that it achieves an upper bound of (cid:32)(cid:115)
O
Lx mx
+
L2 xy mxmy
+
Ly my (cid:18) L2 (cid:19)o(1) mxmy (cid:33) ln(1/(cid:15))
.
Details can be found in Theorem 4 and Corollary 3. We note that the lower bound by Zhang et al. [42] holds for quadratic functions as well. Hence, our upper bound matches the gradient complexity lower bound up to a sub-polynomial factor. 2 Preliminaries
In this work we are interested in strongly-convex strongly-concave smooth problems. We ﬁrst review some standard deﬁnitions of strong convexity and smoothness. A function f : Rn → Rm is 2
L-Lipschitz if ∀x, x(cid:48) ∈ Rn (cid:107)f (x) − f (x(cid:48))(cid:107) ≤ L(cid:107)x − x(cid:48)(cid:107). A function f : Rn → Rm is L-smooth if
∇f is L-Lipschitz. A differentiable function φ : Rn → R is said to be m-strongly convex if for any x, x(cid:48) ∈ Rn, φ(x(cid:48)) ≥ φ(x) + (x(cid:48) − x)T ∇φ(x) + m 2 (cid:107)x(cid:48) − x(cid:107)2. If m = 0, we recover the deﬁnition of convexity. If −φ is m-strongly convex, φ is said to be m-strongly concave. For a function f (x, y), if ∀y, f (·, y) is strongly convex, and ∀x, f (x, ·) is strongly concave, then f is said to be strongly convex-strongly concave.
Deﬁnition 1. A differentiable function f : Rn × Rm → R is said to be (Lx, Lxy, Ly)-smooth if 1. For any y, ∇xf (·, y) is Lx-Lipschitz; 2. For any x, ∇yf (x, ·) is Ly-Lipschitz; 3. For any x, ∇xf (x, ·) is Lxy-Lipschitz; 4. For any y, ∇yf (·, y) is Lxy-Lipschitz.
In this work, we are interested in functions that are strongly convex-strongly concave and smooth.
Speciﬁcally, we study the following function class.
Deﬁnition 2. The function class F (mx, my, Lx, Lxy, Ly) contains differentiable functions from
Rn ×Rm to R such that: 1. ∀y, f (·, y) is mx-strongly convex; 2. ∀x, f (x, ·) is my-strongly concave; 3. f is (Lx, Lxy, Ly)-smooth.
In the case where f (x, y) is twice continuously differentiable, denote the Hessian of f at (x, y) (cid:20)Hxx Hxy
Hyx Hyy (cid:21)
. Then F(mx, my, Lx, Lxy, Ly) can be characterized with the Hessian; in by H := particular we require mxI (cid:52) Hxx (cid:52) LxI, myI (cid:52) −Hyy (cid:52) LyI and (cid:107)Hxy(cid:107)2 ≤ Lxy.
For notational simplicity, we assume that Lx = Ly when considering algorithms and upper bounds.
This is without loss of generality, since one can deﬁne g(x, y) := f ((Ly/Lx)1/4x, (Lx/Ly)1/4y) in order to make the two smoothness constants equal. It is not hard to show that this rescaling will not change Lx/mx, Ly/my, Lxy and mxmy, and L = max{Lx, Lxy, Ly} will not increase. Hence, we can make the following assumption without loss of generality. 2
Assumption 1. f ∈ F(mx, my, Lx, Lxy, Ly), and Lx = Ly.
The optimal solution of the convex-concave minimax optimization problem minx maxy f (x, y) is the saddle point (x∗, y∗) deﬁned as follows.
Deﬁnition 3. (x∗, y∗) is a saddle point of f : Rn × Rm → R if ∀x ∈ Rn, y ∈ Rm f (x, y∗) ≥ f (x∗, y∗) ≥ f (x∗, y).
For strongly convex-strongly concave functions, it is well known that such a saddle point exists and is unique. Meanwhile,the saddle point is a stationary point, i.e. ∇f (x∗, y∗) = 0, and is the minimizer of φ(x) := maxy f (x, y). For the design of numerical algorithms, we are satisﬁed with a close enough approximate of the saddle point, called (cid:15)-saddle points.
Deﬁnition 4. (ˆx, ˆy) is an (cid:15)-saddle point of f if maxy f (ˆx, y) − minx f (x, ˆy) ≤ (cid:15).
Alternatively, we can also characterize optimality with the distance to the saddle point. In particular, let z∗ := [x∗; y∗], ˆz := [ˆx; ˆy], then one may require (cid:107)ˆz − z∗(cid:107) ≤ (cid:15). This implies that3 max y f (ˆx, y) − min x f (x, ˆy) ≤
L2 min{mx, my} (cid:15)2. 3