Abstract
Previous methods decompose blind super resolution (SR) problem into two sequen-tial steps: i) estimating blur kernel from given low-resolution (LR) image and ii) restoring SR image based on estimated kernel. This two-step solution involves two independently trained models, which may not be well compatible with each other. Small estimation error of the ﬁrst step could cause severe performance drop of the second one. While on the other hand, the ﬁrst step can only utilize limited information from LR image, which makes it difﬁcult to predict highly accurate blur kernel. Towards these issues, instead of considering these two steps separately, we adopt an alternating optimization algorithm, which can estimate blur kernel and re-store SR image in a single model. Speciﬁcally, we design two convolutional neural modules, namely Restorer and Estimator. Restorer restores SR image based on predicted kernel, and Estimator estimates blur kernel with the help of restored SR image. We alternate these two modules repeatedly and unfold this process to form an end-to-end trainable network. In this way, Estimator utilizes information from both LR and SR images, which makes the estimation of blur kernel easier. More importantly, Restorer is trained with the kernel estimated by Estimator, instead of ground-truth kernel, thus Restorer could be more tolerant to the estimation error of Estimator. Extensive experiments on synthetic datasets and real-world images show that our model can largely outperform state-of-the-art methods and produce more visually favorable results at much higher speed. The source code is available at https://github.com/greatlog/DAN.git. 1

Introduction
Single image super resolution (SISR) aims to recover the high-resolution (HR) version of a given degraded low-resolution (LR) image.
It has wide applications in video enhancement, medical imaging, as well as security and surveillance imaging. Mathematically, the degradation process can be expressed as y = (x ⊗ k) ↓s +n where x is the original HR image, y is the degraded LR image, ⊗ denotes the two-dimensional convolution of x with blur kernel k, n denotes Additive White Gaussian Noise (AWGN), and ↓s denotes the standard s-fold downsampler, which means keeping only the upper-left pixel for each (1)
∗Corresponding author 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
distinct s × s patch [35]. Then SISR refers to the process of recovering x from y. It is a highly ill-posed problem due to this inverse property, and thus has always been a challenging task.
Recently, deep neural networks (DNNs) have achieved remarkable results on SISR. But most of these methods [39, 2, 40, 23, 8, 21] assume that the blur kernel is predeﬁned as the kernel of bicubic interpolation. In this way, large number of training samples can be manually synthesized and further used to train powerful DNNs. However, blur kernels in real applications are much more complicated, and there is a domain gap between bicubically synthesized training samples and real images. This domain gap will lead to severe performance drop when these networks are applied to real applications.
Thus, more attention should be paid to SR in the context of unknown blur kernels, i.e. blind SR.
In blind SR, there is one more undetermined variable, i.e. blur kernel k, and the optimization also becomes much more difﬁcult. To make this problem easier to be solved, previous methods [37, 32, 38, 35] usually decompose it into two sequential steps: i) estimating blur kernel from LR image and ii) restoring SR image based on estimated kernel. This two-step solution involves two independently trained models, thus they may be not well compatible to each other. Small estimation error of the ﬁrst step could cause severe performance drop of the following one [14]. But on the other hand, the ﬁrst step can only utilize limited information from LR image, which makes it difﬁcult to predict highly accurate blur kernel. As a result, although both models can perform well individually, the ﬁnal result may be suboptimal when they are combined together.
Instead of considering these two steps separately, we adopt an alternating optimization algorithm, which can estimate blur kernel k and restore SR image x in the same model. Speciﬁcally, we design two convolutional neural modules, namely Restorer and Estimator. Restorer restores SR image based on blur kernel predicted by Estimator, and the restored SR image is further used to help Estimator estimate better blur kernel. Once the blur kernel is manually initialized, the two modules can well corporate with each other to form a closed loop, which can be iterated over and over. The iterating process is then unfolded to an end-to-end trainable network, which is called deep alternating network (DAN). In this way, Estimator can utilize information from both LR and SR images, which makes the estimation of blur kernel easier. More importantly, Restorer is trained with the kernel estimated by
Estimator, instead of ground-truth kernel. Thus during testing Restorer could be more tolerant to the estimation error of Estimator. Besides, the results of both modules could be substantially improved during the iterations, thus it is likely for our alternating optimization algorithm to get better ﬁnal results than the direct two-step solutions. We summarize our contributions into three points: 1. We adopt an alternating optimization algorithm to estimate blur kernel and restore SR image for blind SR in a single network (DAN), which helps the two modules to be well compatible with each other and likely to get better ﬁnal results than previous two-step solutions. 2. We design two convolutional neural modules, which can be alternated repeatedly and then unfolded to form an end-to-end trainable network, without any pre/post-processing. It is easier to be trained and has higher speed than previous two-step solutions. To the best of our knowledge, the proposed method is the ﬁrst end-to-end network for blind SR. 3. Extensive experiments on synthetic datasets and real-world images show that our model can largely outperform state-of-the art methods and produce more visually favorable results at much higher speed. 2