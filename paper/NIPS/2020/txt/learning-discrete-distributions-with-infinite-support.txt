Abstract
We present a novel approach to estimating discrete distributions with (potentially) inﬁnite support in the total variation metric. In a departure from the established paradigm, we make no structural assumptions whatsoever on the sampling distribu-tion. In such a setting, distribution-free risk bounds are impossible, and the best one could hope for is a fully empirical data-dependent bound. We derive precisely such bounds, and demonstrate that these are, in a well-deﬁned sense, the best possible.
Our main discovery is that the half-norm of the empirical distribution provides tight upper and lower estimates on the empirical risk. Furthermore, this quantity decays at a nearly optimal rate as a function of the true distribution. The optimality follows from a minimax result, of possible independent interest. Additional structural results are provided, including an exact Rademacher complexity calculation and apparently a ﬁrst connection between the total variation risk and the missing mass. 1

Introduction
Estimating a discrete distribution in the total variation (TV) metric is a central problem in computer science and statistics (see, e.g., Han et al. [2015], Kamath et al. [2015], Orlitsky and Suresh [2015] and the references therein). The TV metric, which we use throughout the paper, is a natural and abundantly motivated choice [Devroye and Lugosi, 2001]. For support size d, a sample of size O(d/ε2) sufﬁces for the maximum-likelihood estimator (MLE) to be ε-close (with constant probability) to the unknown target distribution. A matching lower bound is known [Anthony and Bartlett, 1999], and has been computed down to the exact constants [Kamath et al., 2015].
Classic VC theory — and, in particular, the aforementioned results — imply that for inﬁnite support, no distribution-free sample complexity bound is possible. If µ is the target distribution and (cid:98)µm is its empirical (i.e., MLE) estimate based on m iid samples, then Berend and Kontorovich [2013] showed that 1 4
Λm(µ) − 1
√ m 4
≤ E [(cid:107)µ − (cid:98)µm(cid:107)TV] ≤ Λm(µ), m ≥ 2, where
Λm(µ) = (cid:88) j∈N:µ(j)<1/m
µ(j) + 1
√ m 2 (cid:88) (cid:112)µ(j). j∈N:µ(j)≥1/m 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada. (1) (2)
The quantity Λm(µ) has the advantage of always being ﬁnite and of decaying to 0 as m → ∞. The bound in (1) suggests that Λm(µ), or a closely related measure, controls the sample complexity for learning discrete distributions in TV. Further supporting the foregoing intuition is the observation that for ﬁnite support size d and m (cid:29) 1, we have Λm (cid:46) (cid:112)d/m, recovering the known minimax rate. Additionally, a closely related measure turns out to control a minimax risk rate in a sense made precise in Theorem 2.5.
One shortcoming of (1) is that the lower bound only holds for the MLE, leaving the possibility that a different estimator could achieve signiﬁcantly improved bounds. Another shortcoming of (1) and related estimates is that they are not empirical, in that they depend on the unknown quantity we are trying to estimate. A fully empirical bound, on the other hand, would give a high-probability estimate on (cid:107)µ − (cid:98)µm(cid:107)TV solely in terms of observable quantities such as (cid:98)µm. Of course, such a bound should also be non-trivial, in the sense of improving with growing sample size and approaching 0 as m → ∞.
A further desideratum might be something akin to instance optimality: We would like the rate at which the empirical bound decays to be “the best” possible for the given µ, in an appropriate sense.
Our analogue of instance optimality is inspired by, but distinct from, that of Valiant and Valiant
[2016], as discussed in detail in