Abstract
Team sports is a new application domain for agent modeling with high real-world impact. A fundamental challenge for modeling professional players is their large number (over 1K), which includes many bench players with sparse participation in a game season. The diversity and sparsity of player observations make it difﬁcult to extend previous agent representation models to the sports domain. This paper develops a new approach for agent representations, based on a Markov game model, that is tailored towards applications in professional ice hockey. We introduce a novel framewwork player representation via player generation, where a variational encoder embeds player information with latent variables. The encoder learns a context-speciﬁc shared prior to induce a shrinkage effect for the posterior player representations, allowing it to share statistical information across players with different participation rates. To capture the complex play dynamics in sequential sports data, we design a Variational Recurrent Ladder Agent Encoder (VaRLAE).
This architecture provides a contextualized player representation with a hierarchy of latent variables that effectively prevents latent posterior collapse. We validate our player representations in three major sports analytics tasks. Our experimental results, based on a large dataset that contains over 4.5M events, show state-of-the-art performance for our VarLAE on facilitating 1) identifying the acting player, 2) estimating expected goals, and 3) predicting the ﬁnal score difference. 1

Introduction
Team sports deﬁne complex interactions with a rich action space and a heterogeneous state space [1].
As more and larger event stream datasets for professional sports matches become available, advanced machine learning algorithms have been applied to model the complex dynamics of sports games.
These models facilitate many applications with high real-world impact, such as predicting match outcomes [2], assessing the performance of players or teams [3, 4, 5, 6], and recommending tactics to coaches [7]. However, previous models often pool observations of different players without capturing the speciﬁc roles and behaviors of each athlete. Neglecting the special characteristics of individual players signiﬁcantly compromises the model performance for the application tasks [8].
A promising approach to incorporating player information into sports statistics is deep agent rep-resentation. Learning agent representation in a sports game raises new challenges that require a novel solution for several reasons: 1) Previous methods commonly learn a representation of agents’ policy [9, 10, 11, 12, 13, 14]. The policy embedding methods model only how a player acts in a given match context, and thus fail to capture the statistical information about which match contexts players are likely to act in, as well as their immediate outcomes (rewards). 2) Although policy embeddings can facilitate the construction of an artiﬁcial agent in control problems, the goal of agent representation 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
in sports analytics is predicting game-relevant events using player identity information [8, 7]. 3)
Previous agent representation models are often validated in virtual games instead of physical sports.
They assume a limited number of agents (usually less than 10) and sufﬁcient observations for each of them. In contrast, professional sports leagues often have upwards of one-thousand players, and many bench (backup) players play only a few (less than 20) games in a season. The large number of agents and unbalanced observations result in unstable embedding models that overﬁt to players with high participation during training, which undermines both the training convergence and the predictive performance of underlying policy representations [11].
This work describes a novel player representation framework that learns player representations via player generation. Conditioning on the current game context, the generation model predicts the distribution of the currently acting player. During this process, we learn a distribution of latent variables as the context-speciﬁc prior, allowing a neural encoder to derive an approximate posterior as a contextualized representation for the observed player. We train the encoder by maximizing an Evidence Lower Bound (ELBo, Equation (9)) that moves the posterior for each player toward the prior mode. This shrinkage effect [15] is ideal for player representations, because: 1) It allows information to be transferred between the observations of different players and draws closer the representations of players who share statistical similarities. 2) A shrinkage estimator prevents the encoder from overﬁtting to players with high participation, allowing our representation to generalize to the diversity and the sparsity of context-aware player distributions.
Following our representation framework, we design a Variational Recurrent Ladder Agent Encoder (VaRLAE) to learn player representations. VaRLAE utilizes a ladder structure [16] where, in each layer, latent variables condition on a context variable and the representations from upper layers, based on a causal dependence of latent variables that follows a Markov Game Model [17]. To incorporate play history into player representations, VaRLAE applies a recurrent network to sequential sports data. The ladder hierarchy of latent variables embeds both context and player information, which effectively improves the generative performance and prevents posterior-collapse [16, 18].
We demonstrate the generative performance of our VaRLAE on a massive National Hockey League (NHL) dataset containing over 4.5M events. VaRLAE achieves a leading identiﬁcation accuracy (>12% for the players with sparse participation) over other deterministic encoders and policy rep-resentation models. To study how much the learned player representations improve downstream applications, we assess two major tasks in sports analytics: Predicting expected goals and ﬁnal match score differences. Empirical results show the improvement in predictive accuracy after incorporating the embeddings generated by VaRLAE as input. 2