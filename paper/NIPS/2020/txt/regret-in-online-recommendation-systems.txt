Abstract
This paper proposes a theoretical analysis of recommendation systems in an online setting, where items are sequentially recommended to users over time. In each round, a user, randomly picked from a population of m users, requests a recommen-dation. The decision-maker observes the user and selects an item from a catalogue of n items. Importantly, an item cannot be recommended twice to the same user.
The probabilities that a user likes each item are unknown. The performance of the recommendation algorithm is captured through its regret, considering as a reference an Oracle algorithm aware of these probabilities. We investigate various structural assumptions on these probabilities: we derive for each structure regret lower bounds, and devise algorithms achieving these limits. Interestingly, our analysis reveals the relative weights of the different components of regret: the component due to the constraint of not presenting the same item twice to the same user, that due to learning the chances users like items, and ﬁnally that arising when learning the underlying structure. 1

Introduction
Recommendation systems [28] have over the last two decades triggered important research efforts (see, e.g., [9, 10, 21, 3] for recent works and references therein), mainly focused towards the design and analysis of algorithms with improved efﬁciency. These algorithms are, to some extent, all based on the principle of collaborative ﬁltering: similar items should yield similar user responses, and similar users have similar probabilities of liking or disliking a given item. In turn, efﬁcient recommendation algorithms need to learn and exploit the underlying structure tying the responses of the users to the various items together.
Most recommendation systems operate in an online setting, where items are sequentially recom-mended to users over time. We investigate recommendation algorithms in this setting. More precisely, we consider a system of n items and m users, where m ≥ n (as this is typically the case in practice).
In each round, the algorithm needs to recommend an item to a known user, picked randomly among the m users. The response of the user is noisy: the user likes the recommended item with an a priori unknown probability depending on the (item, user) pair. In practice, it does not make sense to recommend an item twice to the same user (why should we recommend an item to a user who already considered or even bought the item?). We restrict our attention to algorithms that do not recommend an item twice to the same user, a constraint referred to as the no-repetition constraint. The objective is to devise algorithms maximizing the expected number of successful recommendations over a time horizon of T rounds. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
We investigate different system structures. Speciﬁcally, we ﬁrst consider the case of clustered items and statistically identical users – the probability that a user likes an item depends on the item cluster only. We then study the case of unclustered items and statistically identical users – the probability that a user likes an item depends on the item only. The third investigated structure exhibits clustered items and clustered users – the probability that a user likes an item depends on the item and user clusters only. In all cases, the structure (e.g., the clusters) is initially unknown and has to be learnt to some extent. This paper aims at answering the question: How can the structure be optimally learnt and exploited?
To this aim, we study the regret of online recommendation algorithms, deﬁned as the difference between their expected number of successful recommendations to that obtained under an Oracle algorithm aware of the structure and of the success rates of each (item, user) pair. We are interested in regimes where n, m, and T grow large simultaneously, and T = o(mn) (see §3 for details). For the aforementioned structures, we ﬁrst derive non-asymptotic and problem-speciﬁc regret lower bounds satisﬁed by any algorithm. (i) For clustered items and statistically identical users, as T (and hence m) grows large, the minimal
, T
∆m }, where K is the number of item clusters, and ∆ denotes regret scales as K max{ the minimum difference between the success rates of items from the optimal and sub-optimal clusters. (ii) For unclustered items and statistically identical users, the minimal satisﬁcing regret1 scales as
, T mε }, where ε denotes the threshold deﬁning the satisﬁcing regret (recommending max{ log(m) log( m log(m)
)
T log(m) log( m log(m)
) an item in the top ε percents of the items is assumed to generate no regret). (iii) For clustered items and users, the minimal regret scales as m
∆ or as m the values of the success rate probabilities.
We also devise algorithms that provably achieve these limits (up to logarithmic factors), and whose regret exhibits the right scaling in ∆ or ε. We illustrate the performance of our algorithms through experiments presented in the appendix.
∆ log(T /m), depending on
T
Our analysis reveals the relative weights of the different components of regret. For example, we can explicitly identify the regret induced by the no-repetition constraint (this constraint imposes us to select unrecommended items and induces an important learning price). We may also characterize the regret generated by the fact that the item or user clusters are initially unknown. Speciﬁcally, fully exploiting the item clusters induces a regret scaling as K T
∆m . Whereas exploiting user clusters has a much higher regret cost scaling as least as m
∆ .
In our setting, deriving regret lower bounds and devising optimal algorithms cannot be tackled using existing techniques from the abundant bandit literature. This is mainly due to the no-repetition constraint, to the hidden structure, and to the speciﬁcities introduced by the random arrivals of users. Getting tight lower bounds is particularly challenging because of the non-asymptotic nature of the problem (items cannot be recommended inﬁnitely often, and new items have to be assessed continuously). To derive these bounds, we introduce novel techniques that could be useful in other online optimization problems. The design and analysis of efﬁcient algorithms also present many challenges. Indeed, such algorithms must include both clustering and bandit techniques, that should be jointly tuned.
Due to space constraints, we present the pseudo-codes of our algorithms, all proofs, numerical experiments, as well as some insightful discussions in the appendix. 2