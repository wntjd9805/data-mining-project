Abstract
Neuroimaging studies produce gigabytes of spatio-temporal data for a small number of participants and stimuli. Rarely do researchers attempt to model and examine how individual participants vary from each other – a question that should be addressable even in small samples given the right statistical tools. We propose
Neural Topographic Factor Analysis (NTFA), a probabilistic factor analysis model that infers embeddings for participants and stimuli. These embeddings allow us to reason about differences between participants and stimuli as signal rather than noise. We evaluate NTFA on data from an in-house pilot experiment, as well as two publicly available datasets. We demonstrate that inferring representations for participants and stimuli improves predictive generalization to unseen data when compared to previous topographic methods. We also demonstrate that the inferred latent factor representations are useful for downstream tasks such as multivoxel pattern analysis and functional connectivity. 1

Introduction
Analyzing functional neuroimaging studies is both a large data problem and a small data problem.
A single scanning run typically comprises hundreds of full-brain scans that each consist of tens of thousands of spatial locations (known as voxels). At the same time, neuroimaging studies tend to have limited statistical power [Cremers et al., 2017]; a typical study considers a cohort of 20-50 participants undergoing tens of stimuli from ten (or fewer) stimulus categories. This poses a signiﬁcant problem for the over fourteen-thousand functional neuroimaging studies that seek to address both fundamental and translational research questions in cognitive neuroscience on individual differences in functional neural activity [Elliott et al., 2020]. A largely unsolved challenge in this domain is to develop analysis methods that appropriately account for both the commonalities and variations among participants and stimuli effects, scale to tens of gigabytes of data, and reason about uncertainty.
In this paper, we develop Neural Topographic Factor Analysis (NTFA)2, a generative model for neuroimaging data that explicitly represents variation among participants and stimuli. NTFA extends
Topographic Factor Analysis (TFA) and Hierarchical Topographic Factor Analysis (HTFA) [Manning et al., 2014b, 2018]. It differs from these models in that it learns a prior that maps embeddings (i.e. vectors of features) for each participant and stimulus to a conditional distribution over spatial factors and weights, instead of imposing a single global prior. The result is a structured probabilistic model that learns a representation of each participant and each stimulus.
∗Equal contribution 2Source code submitted with paper and available upon request. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
Figure 1: Overview of Neural Topographic Factor Analysis (NTFA): We decompose the fMRI signal into Gaussian factors (shown in red, green and blue in the ﬁgure) that correspond to spatially and temporally related brain activity across individuals. A typical fMRI study consists of multiple trials of participants undergoing scans while experiencing different stimuli (or performing different tasks). In our generative model we represent these participants (purple) and stimuli (orange) with embedding vectors. A multilayer perceptron then predicts the factors’ location, size, and weights.
NTFA offers two advantages over other dimensionality reduction methods that project data into a low-dimensional space: Our embeddings factorize the generative contributions of participants from those of stimuli, and they supply uncertainty measures by which we can measure the scale of the embedding space. Having the embedding space “scaled” by uncertainty allows us more conﬁdence in resolving differences: if the means for embeddings of stimuli lie several standard deviations apart from each other, we can be conﬁdent they reﬂect signiﬁcant differences in the neural repsonse.
We perform a qualitative evaluation of inferred embeddings on four datasets:
• We show that in a synthetic dataset, simulated from distinguishable clusters of participants and stimuli, inference recovers the underlying cluster structure.
• We present results for our own pilot study investigating whether threat-relevant stimuli from three categories induce the same or different patterns of neural response. NTFA infers stimulus embeddings that show differences in patterns of neural response between stimulus categories.
• We analyze and evaluate two publicly available datasets. In the ﬁrst, participants with major depressive disorder and controls listened to emotionally valenced sounds and music [Lepping et al., 2016]. In the second, participants viewed images of faces, cats, ﬁve categories of man-made objects, and scrambled pictures [Haxby et al., 2001]. In both cases, NTFA infers an embedding structure that is consistent with previously reported ﬁndings.
Because NTFA is, to our knowledge, the ﬁrst model to explicitly infer embeddings for participants and stimuli, we devise two simple baselines as comparisons. The ﬁrst is to apply PCA directly to the input data, and the second is to compute post-hoc embeddings after training a shared response model (SRM) [Chen et al., 2015]. PCA fails to recover participant and stimulus structure, whereas the SRM yields point-estimates that are qualitatively similar but lack uncertainty estimates.
As a sanity check, we also compare predictive performance on a validation set of brain images across
NTFA and HTFA. We hold out trials by their stimulus-participant pairs, requiring our model to generalize from other trials in which the same stimulus or participant were seen. PCA, the SRM, and
TFA cannot recombine representations to predict such novel combinations in this way.
This work makes both neuroscientiﬁc and machine learning contributions. From a machine learning perspective, NTFA is a novel neural extension of probabilistic factor analysis methods. The inferred embeddings capture similarities in the neural response across participants and stimuli. This improves prediction on held-out data, while requiring fewer trainable parameters. From a neuroscientiﬁc perspective, the generative model in NTFA contributes to our ability to characterize individual variation in whole-brain analyses. Psychological states (e.g. emotions and memories) involve patterns of activation distributed widely throughout voxel space [Haxby et al., 2001, Satpute and Lindquist, 2019]. Existing whole-brain analyses such as multivoxel pattern analysis (MVPA) thus often rely on 2
Table 1: Comparison of factor analysis methods for fMRI data. When a method considers participant and stimulus variations dependently, we consider it to model variation in the independent factor. Our method (NTFA) is shown in the bottom row.
Model
PCA
SRM
TFA
HTFA
TLSA
NTFA
Spatial factors (cid:55) (cid:55) (cid:51) (cid:51) (cid:51)
Participant variation (cid:55) (cid:51) (cid:55) (cid:55) (cid:51)
Stimulus variation (cid:55) (cid:55) (cid:55) (cid:55) (cid:55)
Scanning run variation (cid:55) (cid:51) (cid:55) (cid:51) (cid:55) (cid:51) (cid:51) (cid:51) (cid:51) supervised feature selection using labels for stimulus categories or participant groups[Pereira et al., 2009]. In contrast, latent factors from NTFA and HTFA enable unsupervised whole-brain MVPA, and can be used to create data-driven functional connectomes.
Figure 1 outlines our proposed approach. Section 2 covers related work in factor analysis for neuroimaging data, primarily the spatially topographic methods on which we build. Section 3 develops the NTFA model. Section 4 discusses our architectural details, preprocessing steps, and experiments, then discusses and evaluates experimental results. Section 5 concludes. 2