Abstract
In this paper, we introduce a discrete variant of the Meta-learning framework.
Meta-learning aims at exploiting prior experience and data to improve performance on future tasks. By now, there exist numerous formulations for Meta-learning in the continuous domain. Notably, the Model-Agnostic Meta-Learning (MAML) formulation views each task as a continuous optimization problem and based on prior data learns a suitable initialization that can be adapted to new, unseen tasks after a few simple gradient updates. Motivated by this terminology, we propose a novel Meta-learning framework in the discrete domain where each task is equivalent to maximizing a set function under a cardinality constraint. Our approach aims at using prior data, i.e., previously visited tasks, to train a proper initial solution set that can be quickly adapted to a new task at a relatively low computational cost. This approach leads to (i) a personalized solution for each task, and (ii) signiﬁcantly reduced computational cost at test time compared to the case where the solution is fully optimized once the new task is revealed. The training procedure is performed by solving a challenging discrete optimization problem for which we present deterministic and randomized algorithms. In the case where the tasks are monotone and submodular, we show strong theoretical guarantees for our proposed methods even though the training objective may not be submodular. We also demonstrate the effectiveness of our framework on two real-world problem instances where we observe that our methods lead to a signiﬁcant reduction in computational complexity in solving the new tasks while incurring a small performance loss compared to when the tasks are fully optimized. 1

Introduction
Many applications in artiﬁcial intelligence necessitate exploiting prior data and experience to enhance quality and efﬁciency on new tasks. This is often manifested through a set of tasks given in the training phase from which we can learn a model or representation that can be used for new unseen tasks in the test phase. In this regard, Meta-learning aims at exploiting the data from the available tasks to learn model parameters or representation that can be later used to perform well on new unseen tasks, in particular, when we have access to limited data and computational power at the test time [1–4]. By now, there are several formulations for Meta-learning, but perhaps one of the most successful ones is the Model-Agnostic Meta-Learning (MAML) [5]. In MAML, we aim to train the 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
model parameters such that applying a few steps of gradient-based updates with a small number of samples from a new task would perform well on that task. MAML can also be viewed as a way to provide a proper initialization, from which performance on a new task can be optimized after a few gradient-based updates. Alas, this scheme only applies to settings in which the decision variable belongs to a continuous domain and can be adjusted using gradient-based methods at the test time.
Our goal is to extend the methodology of MAML to the discrete setting. We consider a setting that our decision variable is a discrete set, and our goal is to come up with a good initial set that can be quickly adjusted to perform well over a wide range of new tasks. In particular, we focus on submodular maximization to represent the tasks which is an essential class of discrete optimization.
There are numerous applications where the submodular meta-learning framework can be applied to ﬁnd a personalized solution for each task while signiﬁcantly reducing the computation load. In general, most recommendation tasks can be cast as an instance of this setting [6–8]. Consider the task of recommending a set of items, e.g., products, locations, ads, to a set of users. One approach for solving such a problem is to ﬁnd the subset of items that have the highest score over all the previously-visited users and recommend that subset to a new user. Indeed, this approach leads to a reasonable performance at test time; however, it does not provide a user-speciﬁc solution for a new user. Another approach is to ﬁnd the whole subset at the test time when the new user arrives. In contrast to the previous approach, this scheme leads to a user-speciﬁc solution, but at the cost of running a computationally expensive algorithm to select all the elements at the test time.
In our Meta-learning framework, the process of selecting set items to be recommended to a new user is done in two parts: In the ﬁrst part, a set of items are selected ofﬂine according to prior experience.
These are the most popular items to the previously-visited users (depending on the context). In the second part, which happens at the test time, a set of items that is personalized to the coming user is selected. These are items that are computed speciﬁcally according to the features of the coming user. In this manner, the computation for each coming user would be reduced to the selection of the second part, which typically constitutes a small portion of the ﬁnal set of recommended items. The
ﬁrst part can be done ofﬂine with a lower frequency. For instance, in a real recommender system, the
ﬁrst part can be computed once every hour, and the second part can be computed speciﬁcally for each coming user (or for a class of similar users). While we have mentioned recommendation (or more generally facility location) as a speciﬁc example, it is easy to see that this framework can be easily used to reduce computation in other notable applications of submodular optimization.
Contributions. Our contributions are threefold:
• We propose a novel discrete Meta-learning framework where each task is equivalent to maximizing a set function under some cardinality constraint. Our framework aims at using prior data, i.e., previously visited tasks, to train a proper initial solution set that can be quickly adapted to a new task at a low computational cost to obtain a task-speciﬁc solution.
• We present computationally efﬁcient deterministic and randomized meta-greedy algorithms to solve the resulting meta-learning problem. When the tasks are monotone and submodular, we prove that the solution obtained by the deterministic algorithm is at least 0.53-optimal, and the solution of the randomized algorithm is (1 − 1/e − o(1))-optimal in expectation, where the o(1) term vanishes by the size of the solution. These guarantees are obtained by introducing new techniques, despite that the meta-learning objective is not submodular.
• We study the performance of our proposed meta-learning framework and algorithms for movie recommendation and ride-sharing problems. Our experiments illustrate that the solution of our proposed meta-learning scheme, which chooses a large portion of the solution in the training phase and a small portion adaptively at test time, is very close to the solution obtained by choosing the entire solution at the test time when a new task is revealed. 1.1