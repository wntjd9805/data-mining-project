Abstract
Many real-world problems, including multi-speaker text-to-speech synthesis, can greatly beneﬁt from the ability to meta-learn large models with only a few task-speciﬁc components. Updating only these task-speciﬁc modules then allows the model to be adapted to low-data tasks for as many steps as necessary without risking overﬁtting. Unfortunately, existing meta-learning methods either do not scale to long adaptation or else rely on handcrafted task-speciﬁc architectures.
Here, we propose a meta-learning approach that obviates the need for this often sub-optimal hand-selection. In particular, we develop general techniques based on Bayesian shrinkage to automatically discover and learn both task-speciﬁc and general reusable modules. Empirically, we demonstrate that our method discovers a small set of meaningful task-speciﬁc modules and outperforms existing meta-learning approaches in domains like few-shot text-to-speech that have little task data and long adaptation horizons. We also show that existing meta-learning methods including MAML, iMAML, and Reptile emerge as special cases of our method. 1

Introduction
The goal of meta-learning is to extract shared knowledge from a large set of training tasks to solve held-out tasks more efﬁciently. One avenue for achieving this is to learn task-agnostic modules and reuse or repurpose these for new tasks. Reusing or repurposing modules can reduce overﬁtting in low-data regimes, improve interpretability, and facilitate the deployment of large multi-task models on limited-resource devices as parameter sharing allows for signiﬁcant savings in memory. It can also enable batch evaluation of reused modules across tasks, which can speed up inference time on GPUs.
These considerations are important in domains like few-shot text-to-speech synthesis (TTS), char-acterized by large speaker-adaptable models, limited training data for speaker adaptation, and long adaptation horizons [1]. Adapting the model to a new task for more optimization steps generally improves the model capacity without increasing the number of parameters. However, many meta-learning methods are designed for quick adaptation, and hence are inapplicable in this few data and long adaptation regime. For those that are applicable [2–5], adapting the full model to few data can then fail because of overﬁtting. To overcome this, modern TTS models combine shared core modules with handcrafted, adaptable, speaker-speciﬁc modules [6, 1, 7, 8]. This hard coding strategy is often suboptimal. As data increases, these hard-coded modules quickly become a bottleneck for further improvement, even in a few-shot regime. For this reason, we would like to automatically learn the smallest set of modules needed to adapt to a new speaker and then adapt these for as long as needed.
Automatically learning reusable and broadly applicable modular mechanisms is an open challenge in
∗Equal contribution. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
causality, transfer learning, and domain adaptation [9–12]. In meta-learning, most existing gradient-based algorithms, such as MAML [13], do not encourage meta-training to develop reusable and general modules, and either ignore reusability or manually choose the modules to ﬁx [14, 15, 5, 16–18].
Some methods implicitly learn a simple form of modularity for some datasets [17, 19] but it is limited.
In this paper, we introduce a novel approach for automatically ﬁnding reusable modules. Our approach employs a principled hierarchical Bayesian model that exploits a statistical property known as shrinkage, meaning that low-evidence estimates tend towards their prior mean; e.g., see Gelman et al. [20]. This is accomplished by ﬁrst partitioning any neural network into arbitrary groups of parameters, which we refer to as modules. We assign a Gaussian prior to each module with a scalar variance. When the variance parameter shrinks to zero for a speciﬁc module, as it does if the data does not require the module parameters to deviate from the prior mean, then all of the module’s parameters become tied to the prior mean during task adaptation. This results in a set of automatically learned modules that can be reused at deployment time and a sparse set of remaining modules that are adapted subject to the estimated prior.
Estimating the prior parameters in our model corresponds to meta-learning, and we present two principled methods for this based on maximizing the predictive log-likelihood. Importantly, both methods allow many adaptation steps. By considering non-modular variants of our model, we show that MAML [13], Reptile [2], and iMAML [3] emerge as special cases. We compare our proposed shrinkage-based methods with their non-modular baselines on multiple low-data, long-adaptation domains, including a challenging variant of Omniglot and TTS. Our modular, shrinkage-based meth-ods exhibit higher predictive power in low-data regimes without sacriﬁcing performance when more data is available. Further, the discovered modular structures corroborate common knowledge about network structure in computer vision and provide new insights about WaveNet [21] layers in TTS.
In summary, we introduce a hierarchical Bayesian model for modular meta-learning along with two parameter-estimation methods, which we show generalize existing meta-learning algorithms. We then demonstrate that our approach enables identiﬁcation of a small set of meaningful task-speciﬁc modules. Finally, we show that our method prevents overﬁtting and improves predictive performance on problems that require many adaptation steps given only small amounts of data. 1.1