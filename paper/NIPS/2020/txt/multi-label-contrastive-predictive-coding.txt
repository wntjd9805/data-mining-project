Abstract
Variational mutual information (MI) estimators are widely used in unsupervised representation learning methods such as contrastive predictive coding (CPC). A lower bound on MI can be obtained from a multi-class classiﬁcation problem, where a critic attempts to distinguish a positive sample drawn from the underlying joint distribution from (m − 1) negative samples drawn from a suitable proposal distribution. Using this approach, MI estimates are bounded above by log m, and could thus severely underestimate unless m is very large. To overcome this limitation, we introduce a novel estimator based on a multi-label classiﬁcation problem, where the critic needs to jointly identify multiple positive samples at the same time. We show that using the same amount of negative samples, multi-label
CPC is able to exceed the log m bound, while still being a valid lower bound of mutual information. We demonstrate that the proposed approach is able to lead to better mutual information estimation, gain empirical improvements in unsupervised representation learning, and beat a current state-of-the-art knowledge distillation method over 10 out of 13 tasks. 1

Introduction
Learning efﬁcient representations from data with minimal supervision is a critical problem in machine learning with signiﬁcant practical impact [37, 12, 38, 41, 6]. Representations obtained using large amounts of unlabeled data can boost performance on downstream tasks where labeled data is scarce.
This paradigm is already successful in a variety of domains; for example, representations trained on large amounts of unlabeled images can be used to improve performance on detection [55, 18, 9].
In the context of learning visual representations, contrastive objectives based on variational mutual information (MI) estimation are among the most successful ones [49, 3, 13, 40, 47]. One such approach, named Contrastive Predictive Coding (CPC, [49]), obtains a lower bound to MI via a multi-class classiﬁcation problem. In CPC, a critic is generally trained to distinguish a pair of representations from two augmentations of the same image (positive), apart from (m − 1) pairs of representations from different images (negative). The representation network is then trained to increase the MI estimates given by the critic. This brings together the two representations from the positive pair and pushes apart the two representations from the negative pairs.
It has been empirically observed that factors leading to better MI estimates, such as training for more iterations and increasing the complexity of the critic [9, 10], can generally result in improvements over downstream tasks. In the context of CPC, increasing the number of negative samples per positive sample (i.e. increasing m) also helps with downstream performance [53, 18, 9, 47]. This can be explained from a mutual information estimation perspective that CPC estimates are upper bounded by log m, so increasing m could reduce bias when the actual mutual information is much higher [35].
However, due to constraints over compute, memory and data, there is a limit to how many negative samples we can obtain per positive sample. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
In this paper, we propose generalizations to CPC that can increase the log m bound without additional computational costs, thus decreasing bias. We ﬁrst generalize CPC through by re-weighting the inﬂuence of positive and negative samples in the underlying the classiﬁcation problem. This increases the log m bound and leads to bias reduction, yet the re-weighted CPC objective is no longer guaranteed to be a lower bound to mutual information.
To this end, we introduce multi-label CPC (ML-CPC) which poses mutual information estimation as a multi-label classiﬁcation problem. Instead of identifying one positive sample for each classiﬁcation task (as in CPC), the critic now simultaneously identiﬁes multiple positive samples that come from the same batch. We prove for ML-CPC that under certain choices of the weights, we can increase the log m bound and reduce bias, while guaranteeing that the new objective is still lower bounded by mutual information. This provides an practical algorithm whose upper bound is close to the theoretical upper limit by any distribution-free, high-conﬁdence lower bound estimators of mutual information [36].
Re-weighted ML-CPC encompasses a range of mutual information lower bound estimators with dif-ferent bias-variance trade-offs, which can be chosen with minimal impact on the computational costs.
We demonstrate the effectiveness of re-weighted ML-CPC over CPC empirically on several tasks, including mutual information estimation, knowledge distillation and unsupervised representation learning. In particular, ML-CPC is able to beat the current state-of-the-art method in knowledge distillation [47] on 10 out of 13 distillation tasks for CIFAR-100. 2 Contrastive Predictive Coding and Mutual Information
In representation learning, we are interested in learning a (possibly stochastic) network h : X → Y that maps some data x ∈ X to a compact representation h(x) ∈ Y. For ease of notation, we denote p(x) as the data distribution, p(x, y) as the joint distribution for data and representations (denoted as y), p(y) as the marginal distribution of the representations, and X, Y as the random variables associated with data and representations. The InfoMax principle [32, 4, 13] for learning representations considers variational maximization of the mutual information I(X; Y ):
I(X; Y ) := E(x,y)∼p(x,y) (cid:20) log (cid:21) p(x, y) p(x)p(y) (1)
A variety of mutual information estimators with different bias-variance trade-offs have been proposed for representation learning [39, 48, 3, 40]. Contrastive predictive coding (CPC, also known as
InfoNCE [49]), poses the MI estimation problem as an m-class classiﬁcation problem. Here, the goal is to distinguish a positive pair (x, y) ∼ p(x, y) from (m − 1) negative pairs (x, y) ∼ p(x)p(y). If the optimal classiﬁer is able to distinguish positive and negative pairs easily, it means x and y are tied to each other, indicating high mutual information.
For a batch of n positive pairs {(xi, yi)}n
L(g) := E (cid:34) 1 n n (cid:88) i=1 log i=1, the CPC objective is deﬁned as1: (cid:35) m · g(xi, yi) g(xi, yi) + (cid:80)m−1 j=1 g(xi, yi,j) (2) for some positive critic function g : X × Y → R+, where the expectation is taken over n positive pairs (xi, yi) ∼ p(x, y) and n(m − 1) negative pairs (xi, yi,j) ∼ p(x)p(y). 2.1 CPC is a lower bound to mutual information
Oord et al. [49] interpreted the CPC objective as a lower bound to MI, but only proved the case for a lower bound approximation of CPC, where a term containing −E[log g] is replaced by − log E[g]; so their arguments alone cannot prove that CPC is a lower bound of mutual information. Poole et al. [40] proved a lower bound argument for the objective where m = n and negative samples are tied to other positive samples in the same batch. To bridge the gap between theory (that CPC instantiates
InfoMax) and practice (where negative samples can be chosen independently from positive samples of the same batch, such as MoCo [18]), we present another proof for the general CPC objective as 1We suppress the dependencies on n and m in L(g) (and in subsequent objectives) for conciseness. 2
presented in L(g). First, we show the following result for variational lower bounds of KL divergences between general distributions where batches of negative samples are used to estimate the divergence.
Then, as mutual information is a KL divergence between two speciﬁc distributions, the lower bound argument for CPC simply follows.
Theorem 1. For all probability measures P, Q over sample space X such that P (cid:28) Q, the following holds for all functions r : X → R+ and integers m ≥ 2:
DKL(P (cid:107)Q) ≥ Ex∼P,y1:m−1∼Qm−1 log (cid:34) m · r(x) r(x) + (cid:80)m−1 i=1 r(yi) (cid:35)
. (3)
Proof. In Appendix A, using the variational representations of f -divergences [39] and Prop. 1.
The argument about CPC being a lower bound to MI is simply a corollary of the above statement where P is p(x, y) (joint) and Q is p(x)p(y) (product of marginals); we state the claim below.
Corollary 1. ∀n ≥ 1, m ≥ 2, ∀g : X × Y → R+, the following is true: L(g) ≤ I(X; Y ).
Therefore, one can train g and h to maximize L(g) (recall that L depends on h via y = h(x)), which is guaranteed to be lower than I(X; Y ) in expectation. 2.2 CPC is an estimator with high bias
For ﬁnite m, since g(xi, yi) appears in both the numerator and denominator of Equation (2) and g is positive, the density ratio estimates can be no larger than m, and the value of L(g) is thus upper bounded by log m [49]. While this is acceptable for certain low dimensional scenarios, this can lead to high-bias if the true mutual information is much larger than log m. In fact, the required m can be unacceptable in high dimensions since MI can scale linearly with dimension, which means an exponential number of negative samples are needed to achieve low bias.
For example, if X and Y are 1000-dimensional random variables where the marginal distribution for each dimension is standard Gaussian, and for each dimension d, Xd and Yd has a correlation of 0.2, then the mutual information I(X; Y ) is around 20.5, which means that m has to be greater than 4 × 108 in order for CPC estimates to approach this value. In comparison, state-of-the-art image representation learning methods use a m that is around 65536 and representation dimensions between 128 to 2048 [53, 18, 9] due to batch size and memory limitations, as one would need a sizeable batch of positive samples in order to apply batch normalization [24]. 2.3 Re-weighted Contrastive Predictive Coding
Under the computational limitations imposed by m (i.e., we cannot obtain too many negative samples per positive sample), we wish to develop generalizations to CPC that reduce bias while still being lower bounds to the mutual information. We do not consider other types of estimators such as
MINE [3] or NWJ [39] because they would exhibit high variance on the order of O(eI(X;Y )) [44], and thus are much less stable to optimize.
One possible approach is to decrease the weights of the positive sample when calculating the sum in the denominator; this leads to the following objective, called α-CPC: (cid:34)
Lα(g) := E 1 n n (cid:88) i=1 log m · g(xi, yi) (cid:80)m−1
αg(xi, yi) + m−α m−1 j=1 g(xi, yi,j) (cid:35) (4) where the positive sample is weighted by α and negative samples are weighted by m−α m−1 . The purpose of adding weights to negative samples is to make sure the the weights sum to m, like in the original case where each sample has weight 1 and there are m samples in total. Clearly, the original CPC objective is a special case when α = 1.
On the one hand, Lα(g) is now upper bounded by log m
α , which is larger than log m when α ∈ (0, 1).
Thus, α-CPC has the potential to reduce bias when log m is much smaller than I(X; Y ). On the other hand, when we set a smaller α, the variance of the estimator becomes larger, and the objective
Lα(g) becomes more difﬁcult to optimize [21, 22]. Therefore, selecting an appropriate α to balance the bias-variance trade-off is helpful for optimization of the objective in practice. 3
However, it is now possible for Lα(g) to be larger than I(X; Y ) as the number of classes m grows to inﬁnity, so optimizing Lα(g) does not necessarily recover a lower bound to mutual information. We illustrate this via the following example (more details in Appendix C).
Example 1. Let X, Y be two binary r.v.s such that Pr(X = 1, Y = 1) = Pr(X = 0, Y = 0) = 0.5.
Then I(X; Y ) = log 2 ≈ 0.69. However, when α = 0.5 and n = m = 3, we can analytically compute Lα(g) ≈ 0.72 ≥ I(X; Y ) for g(x, y) = 1 if x = y and near 0 otherwise. 3 Multi-label Contrastive Predictive Coding
While α-CPC could be useful empirically, we lack a principled way to select proper values of α as
Lα(g) may no longer be a lower bound to mutual information. In the following sections, we propose an approach that allows us to achieve both, i.e., for all α in a certain range (that only depends on n and m), we can achieve an upper bound of log m
α while ensuring that the objective is still a lower bound on mutual information. This allows us to select different values of α to reﬂect different preferences over bias and variance, all while keeping the computational cost identical.
We consider solving a “nm-class, n-label” classiﬁcation problem, where given n positive samples and n(m − 1) negative samples yj,k ∼ p(y) , we wish to jointly identify the top-n samples that are most likely to be the positive ones. Concretely, this has the following objective function: nm · g(xi, yi) (cid:35) (cid:34)
J(g) := E n (cid:88) log 1 n i=1 (cid:80)n j=1 g(xj, yj) + (cid:80)n where the expectation is taken over the n positive samples (xi, yi) ∼ p(x, y) for i ∈ [n] and the n(m − 1) negative samples yj,k ∼ p(y) for j ∈ [n], k ∈ [m − 1]. We call this multi-label contrastive predictive coding (ML-CPC), since the classiﬁer now needs to predict n positive labels from nm options at the same time, instead of 1 positive label from m options as in traditional CPC (performed for n times for a batch size of n). k=1 g(xj, yj,k) (cid:80)m−1 j=1 (5)
Distinctions from CPC Despite its similarity compared to CPC (both are based on classiﬁcation), we note that the multi-label perspective is fundamentally different from the CPC paradigm in three aspects, and cannot be treated as simply increasing the number of negative samples. 1. The ML-CPC objective value depends on the batch size n, whereas the CPC objective does not. 2. In CPC the positive pair and negative pairs share a same element (xi in Eq.(2) where the positive sample is (xi, yi)), whereas in ML-CPC the negative pairs no longer have such restrictions; this could be useful for smaller datasets D when the number of possible negative pairs increases from
O(|D|) to O(|D|2). 3. The optimal critic for CPC is g(cid:63) = c(x) · p(x, y)/(p(x)p(y)), where c is any positive function of x [35]. In ML-CPC, different x values are tied within the same batch, so the optimal critic for
ML-CPC is g(cid:63) = c · p(x, y)/(p(x)p(y)), where c is a positive constant. As a result, ML-CPC reduces the amount of optimal solutions, and forces the similarity of any positive pair to be higher than that of any negative pair, unlike CPC where the positive pair only needs to have higher similarity than any negative pairs with the same x.
Computational cost of ML-CPC To compute CPC with a batch size of n, one would need nm critic evaluations and compute n sums in the denominator, each over a different set of m evaluations.
To compute ML-CPC, one needs nm critic evaluations, and compute 1 sum over all nm evaluations.
Therefore, ML-CPC has almost the same computational cost compared to CPC which is O(mn). We perform a similar analysis in Appendix A to show that evaluating the gradients of the objectives also has similar costs, so ML-CPC is computationally as efﬁcient as CPC. 3.1 Re-weighted Multi-label Contrastive Predictive Coding
Similar to α-CPC, we can modify the multi-label objective J(g) by re-weighting the critic predictions, which results in the following objective called α-ML-CPC: n (cid:88) nm · g(xi, yi) (cid:35) (6) (cid:34)
Jα(g) := E 1 n log i=1
α (cid:80)n j=1 g(xj, yj) + m−α m−1 (cid:80)n j=1 (cid:80)m−1 k=1 g(xj, yj,k) 4
Figure 1: MI estimates with CPC and ML-CPC under different α.
For α ∈ (0, 1), we down-weight the positive critic outputs by α and up-weight the negative critic outputs by m−α m−1 (similar to α-CPC). Setting a smaller α has the potential to reduce bias, since the upper bound of log m is changed to log m
α , which is larger when α ∈ (0, 1). In contrast to α-CPC,
Jα(g) is now guaranteed to be a lower bound of mutual information for a wide range of α, as we show in the following statements. Similar to the case of CPC, we ﬁrst show a more general argument, for which the weighted ML-CPC is a special case.
Theorem 2. For all probability measures P, Q over sample space X such that P (cid:28) Q, the following holds for all functions r : X → R+, integers n ≥ 1, m ≥ 2, and real numbers α ∈ [ n(m−1)+1 , 1]: (cid:34) (cid:35) m 1 n n (cid:88) i=1 log mn · r(xi)
α (cid:80)n j=1 r(xj) + m−α m−1 (cid:80)m−1 k=1 r(yj,k)
. (7)
DKL(P (cid:107)Q) ≥ Ex1:n∼P n,yi,1:m−1∼Qm−1
Proof. In Appendix A, using the variational representations of f -divergences [39] and Prop. 2.
The above theorem extends existing variational lower bound estimators of KL divergences (that are generally interpreted as binary classiﬁcation [46, 39]) into a family of lower bounds that can be interpreted as multi-label classiﬁcation. The argument about re-weighted ML-CPC being a lower bound to MI is simply a corollary where P is p(x, y) and Q is p(x)p(y); we state the claim below. n(m−1)+1 . If α ∈ [αm,n, 1], then ∀g : X × Y → R+,
Corollary 2. ∀n ≥ 1, m ≥ 2, deﬁne αm,n = (8)
Jα(g) ≤ I(X; Y ) m
The above theorem shows that for an appropriate range of α values, the objective Jα(g) is still guaranteed to be a variational lower bound to mutual information, like the original CPC objective.
Selecting α within this range results in estimators with different bias-variance trade-offs. Here, a smaller α could lead to low-bias high-variance estimates; this achieves a similar effect to increasing the number of classes m to nearly m/α, but without the actual additional computational costs that comes with obtaining more negative samples in CPC.
Illustrative example We consider the case of X, Y being binary and equal random variables in
Example 1, where I(X; Y ) = log 2 ≈ 0.69, the optimal critic g is known, and both Lα(g) and Jα(g) can be computed in closed-form for any α and g in O(m) time (details in Appendix C). We plot the
CPC (Eq.(4)) and ML-CPC (Eq.(6)) objectives with different choices of α and m in Figure 1. The estimates of ML-CPC when α ≥ αm,n are lower bounds to the ground truth MI, which indeed aligns with our theory.
Furthermore, in Figure 2 we illustrate the bias-variance trade-offs for CPC and αm,n-ML-CPC as we vary the number of classes m (for simplicity, we choose n = m). Despite having slightly higher variance in the estimates, αm,n-ML-CPC has signiﬁcantly less bias than CPC, which suggests that it is helpful in cases where lower bias is preferable than lower variance. In practice, the user could select different values of α to indicate the desired trade-off, all without having to change the number of negative samples and increase computational costs.
We include the pseudo-code and a PyTorch implementation to α-ML-CPC in Appendix B. 4