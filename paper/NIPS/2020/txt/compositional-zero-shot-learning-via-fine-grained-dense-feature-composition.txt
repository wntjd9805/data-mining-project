Abstract
We develop a novel generative model for zero-shot learning to recognize ﬁne-grained unseen classes without training samples. Our observation is that generating holistic features of unseen classes fails to capture every attribute needed to dis-tinguish small differences among classes. We propose a feature composition framework that learns to extract attribute-based features from training samples and combines them to construct ﬁne-grained features for unseen classes. Feature composition allows us to not only selectively compose features of unseen classes from only relevant training samples, but also obtain diversity among composed features via changing samples used for composition. In addition, instead of build-ing a global feature of an unseen class, we use all attribute-based features to form a dense representation consisting of ﬁne-grained attribute details. To recognize unseen classes, we propose a novel training scheme that uses a discriminative model to construct features that are subsequently used to train itself. Therefore, we directly train the discriminative model on composed features without learning separate generative models. We conduct experiments on four popular datasets of DeepFashion, AWA2, CUB, and SUN, showing that our method signiﬁcantly improves the state of the art. 1

Introduction
Zero-shot learning is the important yet challenging task of recognizing unseen class without training samples from samples of seen classes. This setting often arises when dealing with ﬁne-grained recognition problems where some classes have a few or no training samples due to their scarcity [1], such as identifying new fashion trends [2, 3, 4, 5] or endangered species [6, 7, 8, 9, 10, 11]. We argue that classes exhibit compositional structures [12, 13, 14] in which we only need to recognize basic attributes such as color, shape, or material to recognize a large number of classes expressible in terms of these attributes. We propose a zero-shot learning method that reuses attributes of seen classes to construct features of unseen classes for training.
To address the lack of training samples, recent zero-shot works rely upon generative models [15, 16, 17, 18, 19, 20] to synthesize features of unseen classes. These works infer features of unseen classes from features of seen classes. However, methods based on Generative Adversarial Networks
[19, 15, 16] suffer from low diversity in generated features. On the other hand, likelihood-based methods [21, 16, 17, 18, 22] promote diversity among generated features, but their generated features are often non-discriminative. These issues are most severe for unseen classes as the feature generation process cannot be regulated without training samples.
Leveraging the remarkable performance of Convolutional Neural Networks [23, 24], most works extract image features by pooling local information from image regions into holistic representations
[15, 25, 17, 18, 26, 11]. Although holistic features encode discriminative information among classes, 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
Figure 1: Left: Conventional generative models synthesize holistic features from random codes lacking ﬁne-grained details. Right: Our compositional model constructs dense attribute-based features from training samples.
By selecting different relevant samples for composition, our method builds diverse features for unseen classes. they are not trained to capture attribute details needed for alignment between visual and semantic spaces. Therefore, generating holistic features cannot describe ﬁne-grained details of unseen classes.
Few works have explored learning compositional structures in the few-shot setting [12, 13, 27, 28].
[12, 13] enforce decomposition of representation that requires at least a few samples per class and cannot generalize to unseen classes. Although [28, 29] can compose classiﬁers for novel concepts, they produce holistic features which fail to preserve attribute details.
Contributions: We develop a novel framework that addresses the limitations of aforementioned methods. Instead of generating holistic features as in Figure 1 (left), we extract attribute-based features from seen classes and learn to combine them to effectively construct features of unseen classes, see
Figure 1 (right). We augment a discriminative model with a prior distribution to construct features of unseen classes based on class predictions and use these features to update the discriminative model.
Our method has several advantages over the state of the art: – Our framework selectively composes features of unseen classes from semantically related training samples. It also allows specifying different sample sets used for composition that leads to the diversity of composed features. Therefore, we can control the composition process by constraining the samples that are used to build attribute-based features of unseen classes. – Instead of generating holistic features, which lack ﬁne-grained details, we build a dense feature consisting of attribute-based features that scales to hundreds of attributes. – Instead of using a generative model to ﬁrst build features and then train a discriminative model, we use a discriminative model to compose features of unseen classes in order to train itself. This makes the learning process efﬁcient by removing the need for learning additional generative models. 2