Abstract
We study dropout in two-layer neural networks with rectiﬁed linear unit (ReLU) ac-tivations. Under mild overparametrization and assuming that the limiting kernel can separate the data distribution with a positive margin, we show that dropout training with logistic loss achieves (cid:15)-suboptimality in test error in O(1/(cid:15)) iterations. 1

Introduction
Dropout is an algorithmic regularization approach that endows deep learning models with excellent generalization ability despite the non-convex nature of the underlying learning problem and the capac-ity of modern over-parameterized models to over-ﬁt. Introduced by Hinton et al. [2012], Srivastava et al. [2014], dropout involves randomly pruning the network at every iteration of backpropagation by turning off a random subset of hidden nodes. Like many popular algorithmic approaches that emerged as heuristics from practitioners with deep insight into the learning problem, dropout, while extremely successful in practice, lacks a strong theoretical justiﬁcation, especially from a computational learning theoretic perspective.
Dropout has been successful in several application areas including computer vision [Szegedy et al., 2015], natural language processing [Merity et al., 2017], and speech recognition [Dahl et al., 2013].
Motivated by explaining the empirical success of dropout, and inspired by simple, intuitive nature of the method, numerous works in recent years have focused on understanding its theoretical un-derpinnings [Baldi and Sadowski, 2013, Wager et al., 2013, Helmbold and Long, 2015, Gal and
Ghahramani, 2016, Wei et al., 2020]. Most of these works, however, steer clear from the algorithmic and computational learning aspects of dropout. More precisely, none of the prior work, to the best of our knowledge, yields insights into the runtime of learning using dropout on non-linear neural networks. In this paper, we initiate a study into the iteration complexity of dropout training for achieving (cid:15)-suboptimality on true error – the misclassiﬁcation error with respect to the underlying population – in two-layer neural networks with ReLU activations.
We leverage recent advances in the theory of deep learning in over-parameterized settings with extremely (or inﬁnitely) wide networks [Jacot et al., 2018, Lee et al., 2019]. Analyzing two-layer
ReLU networks in such a regime has led to a series of exciting results recently establishing that gradient descent (GD) or stochastic gradient descent (SGD) can successfully minimize the empirical error and the true error [Li and Liang, 2018, Du et al., 2019, Daniely, 2017, Zou et al., 2018, Allen-Zhu et al., 2019, Song and Yang, 2019, Arora et al., 2019, Cao and Gu, 2019, Oymak and Soltanolkotabi, 2020]. In a related line of research, several works attribute generalization in over-parametrized settings to the implicit inductive bias of optimization algorithms (through the geometry of local search methods) [Neyshabur et al., 2017]. However, many real-world state-of-the-art systems employ various explicit regularizers, and there is growing evidence that implicit bias may be unable to explain generalization even in a simpler setting of stochastic convex optimization [Dauber et al., 2020]. Here, we extend convergence guarantees and generalization bounds for GD-based methods with explicit 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
regularization due to dropout. We show that the key insights from analysis of GD-based methods in over-parameterized settings carry over to dropout training.
We summarize our key contributions as follows. 1. We give precise non-asymptotic convergence rates for achieving (cid:15)-subotimality in the test error via dropout training in two-layer ReLU networks. 2. We show that dropout training implicitly compresses the network. In particular, we show that there exists a sub-network, i.e., one of the iterates of dropout training, that can generalize as well as any complete network. 3. This work contributes to a growing body of work geared toward a theoretical understanding of GD-based methods for regularized risk minimization in over-parameterized settings.
The rest of the paper is organized as follows. In Section 2, we survey the related work. In Section 3, we formally introduce the problem setup and dropout training, state the key assumptions, and introduce the notation. In Section 4, we give the main results of the paper. In Section 5, we present a sketch of the proofs of our main results – the detailed proofs are deferred to the Appendix. We conclude the paper by providing empirical evidence for our theoretical results in Section 6. 2