Abstract
We introduce a new and completely online contextual bandit algorithm called
Gated Linear Contextual Bandits (GLCB). This algorithm is based on Gated Linear
Networks (GLNs), a recently introduced deep learning architecture with properties well-suited to the online setting. Leveraging data-dependent gating properties of the GLN we are able to estimate prediction uncertainty with effectively zero algorithmic overhead. We empirically evaluate GLCB compared to 9 state-of-the-art algorithms that leverage deep neural networks, on a standard benchmark suite of discrete and continuous contextual bandit problems. GLCB obtains mean
ﬁrst-place despite being the only online method, and we further support these results with a theoretical study of its convergence properties. 1

Introduction
The contextual bandit setting has been a focus of much recent attention, beneﬁting from both being sufﬁciently constrained as to be theoretically tractable, yet broad enough to capture many different types of real world applications such as recommendation systems. The linear contextual bandit problem in particular has been subject to intense theoretical investigation; the recent book by [1] gives a comprehensive overview. This line of investigation has yielded principled online algorithms such as LINUCB [2], that work well given informative features. To work around the limitations of linear representations in more difﬁcult problems, these algorithms are often used in combination with an ofﬂine nonlinear feature extraction technique such as deep learning. A limitation with such approaches is that the feature extraction component is treated as a black box, which runs the risk of ignoring the uncertainty introduced by the ofﬂine feature extraction component.
Recent advances in posterior approximation for deep networks has led to the introduction of a variety of approximate Thompson Sampling based contextual bandits algorithms that perform well in practice. A reoccurring theme across these works is to leverage some kind of efﬁciently approximated surrogate notion of the estimation accuracy to drive exploration. Noteworthy examples include the use of random value functions [3, 4], Bayes by Backprop [5], and noise injection [6]. An empirical comparison of neural network based Bayesian methods can be found in [7]. A major drawback of these methods is that they are not online, and often require expensive retraining at regular intervals.
Another line of investigation has focused on using count-based approaches to drive exploration via the optimism in the face of uncertainty principle. Here various types of conﬁdence bounds on action value estimates are obtained directly from the state/context-action visitation counts, with algorithms typically choosing an action greedily with respect to the upper conﬁdence bound. Count-based methods have seen noteworthy success in ﬁnite armed bandit problems [8], tabular reinforcement learning [9, 10]), planning in MDPs [11], amongst others. For the most part however, the usage of count based approaches has been limited to low dimensional settings, as counts get exponentially
∗Equal contributions. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
Figure 1: (A) Illustration of half-space gating for a 2D context. Color represents how many half-spaces intersect with the data point x. Within each region of constant color (each polytope), the gated weights for a G-GLN network are constant.. (B) A graphical depiction of a Gated Linear Network.
Each neuron receives inputs from the previous layer as well as the broadcasted side information z.
The side information is passed through all the gating functions, whose outputs sij = cij(z) determine the active weight vectors (shown in blue). The dot-product of these vectors with input x forms the output after being passed through a sigmoid function. sparser as the state/context-action dimension increases. As a remedy to this problem, [12] proposed a notion of “pseudocounts”, which utilize density-like approximations to generalize counts across high-dimensional states/contexts. Impressive performance was obtained in popular reinforcement learning settings such as Atari game playing when using this technique to drive exploration. Another approach which pursued the idea of generalizing counts to higher dimensional state spaces was the work of [13], who proposed an elegant approach that used the SimHash [14] variant of locality-sensitivity hashing to map the original state space to a smaller space for which counting state-visitation is tractable. This approach led to strong results in both Atari and continuous control reinforcement learning tasks.
In this work, we introduce a new online contextual bandit algorithm that combines the beneﬁts of scalable non-linear action-value estimation with a notion of hash based pseudocounts. For action-value estimation we use a Gated Linear Network (GLN) that employs half-space gating, which has recently been shown to give rise to universal function approximation capabilities [15, 16]. To drive exploration, our key insight is to exploit the close connection between half-space gating and the
SimHash variant of locality-sensitivity hashing; by associating a counter to each neurons gated weight vector, we can deﬁne a pseudo-count based exploration mechanism that can generalise in a way similar to the work of [13], with essentially no additional computational overhead beyond obtaining a
GLN based action-value estimate. Furthermore, since the gating in a GLN is directly responsible for determining its inductive bias, our notion of pseudocount is tightly coupled to the networks parameter uncertainty, which allows us to naturally deﬁne a UCB-like [8] policy as a function the pseudocounts.
We demonstrate the empirical efﬁcacy of our method across a set of real-world and synthetic datasets, where we show that our policy outperforms all of the state-of-the-art neural Bayesian methods considered in the recent survey of [7] in terms of mean rank. 2