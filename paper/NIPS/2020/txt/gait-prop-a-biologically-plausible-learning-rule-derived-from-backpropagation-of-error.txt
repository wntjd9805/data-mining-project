Abstract
Traditional backpropagation of error, though a highly successful algorithm for learning in artiﬁcial neural network models, includes features which are biologi-cally implausible for learning in real neural circuits. An alternative called target propagation proposes to solve this implausibility by using a top-down model of neural activity to convert an error at the output of a neural network into layer-wise and plausible ‘targets’ for every unit. These targets can then be used to produce weight updates for network training. However, thus far, target propagation has been heuristically proposed without demonstrable equivalence to backpropagation. Here, we derive an exact correspondence between backpropagation and a modiﬁed form of target propagation (GAIT-prop) where the target is a small perturbation of the forward pass. Speciﬁcally, backpropagation and GAIT-prop give identical updates when synaptic weight matrices are orthogonal. In a series of simple computer vision experiments, we show near-identical performance between backpropagation and GAIT-prop with a soft orthogonality-inducing regularizer. 1

Introduction
One of the fundamental tenets of modern systems neuroscience is that the brain learns by selectively strengthening and weakening synaptic connections. Much research in theoretical neuroscience was guided by the Hebbian principle of strengthening connections between co-active neurons [1–3]. How-ever, it appears that purely Hebbian learning rules may not be effective at learning complex behavioral tasks. In the last ﬁfteen years, the ﬁelds of machine learning and AI have been revolutionized by the large-scale adoption of deep networks trained by backpropagation (BP) [4–6]. Deep networks have been shown to mimic the hierarchy of cortical representations [7–9], suggesting a connection between deep learning and the brain. However, BP has since long been considered as biologically implausible [10], based in part on its use of non-local information at individual synapses which carry out weight updates. How such information could be stored, transmitted and leveraged has been a cause for concern [10, 11].
To overcome these implausible aspects of the BP algorithm, approaches have been proposed to approximate or replace implausible computations with more realistic and plausible elements [12– 16]. Alternatively methods which approximate backpropagation through energy-based models have also been proposed [17–20]. Among those methods, contrastive Hebbian learning, and generalized recirculation have been shown to produce BP-equivalent updates under speciﬁc regimes [18, 21], though these methods require a, rather artiﬁcial, alternation between positive and negative phases in order to compute updates.
Target Propagation (TP) is a simpler and more scalable approach which proposes that the loss function at the output layer be replaced with layer-wise, local target activities for individual neurons [22, 23], 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
an approach which was also partially investigated some years prior [24]. The principle of TP is to propagate an output target ‘backwards’ through a network using (learned) inverses of the forward pass. Under a perfect inverse, these layer-wise targets are equivalent to the outputs of hidden layers which would have precisely produced the desired output. In a recent review paper, Lillicrap and co-authors suggested an approach named ‘neural gradient representation by activity differences’ (NGRAD) [25]. They conjecture that the most plausible implementation of an effective learning rule in the brain would consist of projecting error-based information into layer-wise neural activity.
Given this conjecture, they highlight TP as a feasible and promising approach. However, it remains unclear how updates computed by TP relate to BP and the associated gradients which would optimise network performance.
In this paper, we develop a theoretical framework to analyse the link between the TP and the BP weight update rules. In particular, we show that TP and BP have the same local optima in a deep linear network. Furthermore, we show that in deep linear networks the two update rules are identical when the weight matrices are orthogonal. However, standard TP cannot be easily linked to BP in the non-linear case, even under conditions of orthogonality. A connection to BP can be fully restored by introducing incremental targets – targets which are an inﬁnitesimal shift of the forward pass toward a target output. Using this approach we derive the gradient-adjusted incremental target propagation algorithm (GAIT-prop), a biologically plausible approach to learning in non-linear networks that is identical to BP under orthogonal weight matrices. Unlike TP, this approach can also be approximated in the equilibrium state of network with constant input and weak feedback coupling, connecting our method to activity recirculation and equilibrium propagation [18, 19]. Furthermore, our approach to local, error-based learning encodes the exact gradient descent information desired for optimal learning within target neural activities in a plausible circuit mechanism [25].
To derive the theoretical relations between BP, TP, and GAIT-prop we make use of invertible networks.
While a perfect inverse model is not biologically plausible, it affords rigorous theoretical comparisons between these learning algorithms. We also relax this invertible network assumption by training networks with hidden layers of different widths – a case in which there is information loss through the network but which nonetheless can be trained accurately. 2