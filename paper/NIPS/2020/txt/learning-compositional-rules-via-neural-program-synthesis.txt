Abstract
Many aspects of human reasoning, including language, require learning rules from very little data. Humans can do this, often learning systematic rules from very few examples, and combining these rules to form compositional rule-based systems. Current neural architectures, on the other hand, often fail to generalize in a compositional manner, especially when evaluated in ways that vary systematically from training. In this work, we present a neuro-symbolic model which learns entire rule systems from a small set of examples. Instead of directly predicting outputs from inputs, we train our model to induce the explicit system of rules governing a set of previously seen examples, drawing upon techniques from the neural program synthesis literature. Our rule-synthesis approach outperforms neural meta-learning techniques in three domains: an artiﬁcial instruction-learning domain used to evaluate human learning, the SCAN challenge datasets, and learning rule-based translations of number words into integers for a wide range of human languages. 1

Introduction
Humans have a remarkable ability to learn compositional rules from very little data. For example, a person can learn a novel verb “to dax" from a few examples, and immediately understand what it means to “dax twice" or “dax around the room quietly." When learning language, children must learn many interrelated concepts simultaneously, including the meaning of both verbs and modiﬁers (“twice", “quietly", etc.), and how they combine to form complex meanings. People can also learn novel artiﬁcial languages and generalize systematically to new compositional meanings (see
Figure 3). Fodor and Marcus have argued that this systematic compositionality, while critical to human language and thought, is incompatible with classic neural networks (i.e., eliminative connectionism) [1, 2, 3]. Despite advances, recent work shows that contemporary neural architectures still struggle to generalize in systematic ways when directly learning rule-like mappings between input sequences and output sequences [4, 5]. Given these ﬁndings, Marcus continues to postulate that hybrid neural-symbolic architectures (implementational connectionism) are needed to achieve genuine compositional, human-like generalization [3, 6, 7].
An important goal of AI is to build systems which possess this sort of systematic rule-learning ability, while retaining the speed and ﬂexibility of neural inference. In this work, we present a neural-symbolic framework for learning entire rule systems from examples. As illustrated in Figure 1B, our key idea is to leverage techniques from the program synthesis community [8], and frame the problem as explicit rule-learning through fast neural proposals and rigorous symbolic checking.
Instead of training a model to predict the correct output given a novel input (Figure 1A), we train our model to induce the explicit system of rules governing the behavior of all previously seen examples (Figure 1B; Grammar proposals). Once inferred, this rule system can be used to predict the behavior of any new example (Figure 1B; Symbolic application).
∗Correspondence to mnye@mit.edu. Code can be found here: github.com/mtensor/rulesynthesis 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
Figure 1: Illustration of our synthesis-based rule learner and comparison to previous work. A)
Previous work [9]: Support examples are encoded into an external neural memory. A query output is predicted by conditioning on the query input sequence and interacting with the external memory via attention. B) Our model: Given a support set of input-output examples, our model produces a distribution over candidate grammars. We sample from this distribution, and symbolically check consistency of each sampled grammar against the support set until a grammar is found which satisﬁes the input-output examples in the support set. This approach allows much more effective search than selecting the maximum likelihood grammar from the network.
This explicit rule-based approach confers several advantages compared to a pure input-output ap-proach. Instead of learning a blackbox input-output mapping, and applying it to each new query item for which we would like to predict an output (Figure 1A), we instead search for an explicit program which we can check against previous examples (the support set). This allows us to propose and check candidate programs, sampling programs from the neural model and only terminating search when the proposed solution is consistent with prior data.
The program synthesis framing also allows immediate and automatic generalization: once the correct rule system is learned, it can be correctly applied in novel scenarios which are a) arbitrarily complex and b) outside the distribution of previously seen examples. We draw on work in the neural program synthesis literature [10, 11] to solve complex rule-learning problems that pose difﬁculties for both neural and traditional symbolic methods. Our neural synthesis approach is distinctive in its ability to simultaneously and ﬂexibly attend over a large number of input-output examples, allowing it to integrate different kinds of information from varied support examples.
Our training scheme is inspired by meta-learning. Assuming a distribution of rule systems, or a
“meta-grammar," we train our model by sampling grammar-learning problems and training on these sampled problems. We can interpret this as an approximate Bayesian grammar induction, where our goal is to maximize the likelihood of a latent program which explains the data [12].
We demonstrate that, when trained on a general meta-grammar of rule-systems, our rule-synthesis method can outperform neural meta-learning techniques. Concretely, our main contributions are:
• We present a neuro-symbolic program synthesis model which can learn novel rule systems from few examples. Our model employs a symbolic program representation for compo-sitional generalization and neural program synthesis for fast and ﬂexible inference. This allows us to leverage search in the space of programs, for a guess-and-check approach.
• We show that our model can learn to interpret artiﬁcial languages from few examples, solving SCAN and outperforming 10 alternative models.
• Finally, we show that our model can outperform baselines in learning how to interpret number words in unseen languages from few examples. 2
Figure 2: Illustration of our synthesis-based rule learner neural architecture and grammar application.
Support examples are encoded via BiLSTMs. The decoder LSTM attends over the resulting vectors and decodes a grammar, which can be symbolically applied to held out query inputs. Middle: an example of a fully synthesized grammar which solves the task in Figure 3. 2