Abstract
We introduce a framework for designing primal methods under the decentralized optimization setting where local functions are smooth and strongly convex. Our approach consists of approximately solving a sequence of sub-problems induced by the accelerated augmented Lagrangian method, thereby providing a systematic way for deriving several well-known decentralized algorithms including EXTRA [47] and SSDA [43]. When coupled with accelerated gradient descent, our framework yields a novel primal algorithm whose convergence rate is optimal and matched by recently derived lower bounds. We provide experimental results that demonstrate the effectiveness of the proposed algorithm on highly ill-conditioned problems. 1

Introduction
Due to their rapidly increasing size, modern datasets are typically collected, stored and manipulated in a distributed manner. This, together with strict privacy requirements, has created a large demand for efﬁcient solvers for the decentralized setting in which models are trained locally at each agent, and only local parameter vectors are shared. This approach has become particularly appealing for applications such as edge computing [30, 48], cooperative multi-agent learning [8, 38] and federated learning [31, 49]. Clearly, the nature of the decentralized setting prevents a global synchronization, as only communication within the neighboring machines is allowed. The goal is then to arrive at a consensus on all local agents with a model that performs as well as in the centralized setting.
Arguably, the simplest approach for addressing decentralized settings is to adapt the vanilla gradient descent method to the underlying network architecture [11, 18, 34, 53]. To this end, the connections between the agents are modeled through a mixing matrix which dictates how agents average over their neighbors’ parameter vectors. Perhaps surprisingly, when the stepsizes are constant, simply averaging over the local iterates via the mixing matrix only converges to a neighborhood of the optimum [47, 58]. A recent line of works [17, 35, 36, 39, 46, 47] proposed a number of alternative methods that linearly converge to the global minimum. Extensions to the composite setting are also studied [1, 2, 27, 55].
The overall complexity of solving decentralized optimization problems is typically determined by two factors: (i) the condition number of the objective function κf , which measures the hardness of solving the underlying optimization problem, and (ii) the condition number of the mixing matrix κW , which quantiﬁes the severity of ‘information bottlenecks’ present in the network. Lower complexity bounds recently derived for distributed settings [3, 5, 43, 52] show that one cannot expect to have
κW . Notably, despite the recent a better dependence on the condition numbers than
κf and
√
√ 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
considerable progress, none of the methods mentioned above is able to achieve accelerated rates, that is, a square root dependence for both κf and κW —simultaneously.
An extensive effort has been devoted to obtaining acceleration for decentralized algorithms under various settings [12, 13, 16, 26, 40, 43, 44, 51, 54, 57, 59]. When a dual oracle is available, that is, access to the gradients of the dual functions is provided, optimal rates can be attained for smooth and strongly convex objectives [43]. However, having access to a dual oracle is a very restrictive assumption, and resorting to a direct ‘primalization’ through inexact approximation of the dual gradients leads to sub-optimal worst-case theoretical rates [51]. In this work, we propose a novel primal approach that leads to optimal rates in terms of dependency on κf and κW .
Our contributions can be summarized as follows.
• We introduce a novel framework based on the accelerated augmented Lagrangian method for designing primal decentralized methods. The framework provides a simple and systematic way for deriving several well-known decentralized algorithms [17, 46, 47], including EXTRA [47] and SSDA [43], and uniﬁes their convergence analyses.
• Using accelerated gradient descent as a sub-routine, we derive a novel method for smooth and strongly convex local functions which achieves optimal accelerated rates on both the condition numbers of the problem, κf and κW , using primal updates, see Table 2.
• We perform a large number of experiments which conﬁrm our theoretical ﬁndings, and demon-strate a signiﬁcant improvement when the objective function is ill-conditioned and κf (cid:29) κW . 2 Decentralized Optimization Setting
We consider n computational agents and a network graph G = (V, E) which deﬁnes how the agents are linked. The set of vertices V = {1, · · · , n} represents the agents and the set of edges E ∈ V × V speciﬁes the connectivity in the network, i.e., a communication link between agents i and j exists if and only if (i, j) ∈ E. Each agent has access to local information encoded by a loss function fi : Rd → R. The goal is to minimize the global objective over the entire network, min x∈Rd f (x) := n (cid:88) i=1 fi(x). (1)
In this paper, we assume that the local loss functions fi are differentiable, L-smooth and µ-strongly convex.1 Strong convexity of the component functions fi implies that the problem admits a unique solution, which we denote by x∗.
We consider the following computation and communication models [43]:
• Local computation: Each agent is able to compute the gradients of fi and the cost of this computation is one unit of time.
• Communication: Communication is done synchronously, and each agent can only exchange information with its neighbors, where i is a neighbor of j if (i, j) ∈ E. The ratio between the communication cost and computation cost per round is denoted by τ .
We further assume that propagation of information is governed by a mixing matrix W ∈ Rn×n
[34, 43, 58]. Speciﬁcally, given a local copy of the decision variable xi ∈ Rd at node i ∈ [1, n], one round of communication provides the following update xi ← (cid:80)n i=1 Wijxj. The following standard assumptions regarding the mixing matrix [43] are made throughout the paper.
Assumption 1. The mixing matrix W satisﬁes the following: 1. Symmetry: W = W T . 2. Positiveness: W is positive semi-deﬁnite. 3. Decentralized property: If (i, j) /∈ E and i (cid:54)= j, then Wij = Wji = 0. 4. Spectrum property: The kernel of W is given by the vector of all ones Ker(W ) = R1n. 1 f is L-smooth if ∇f is L-Lipschitz; f is µ-strongly convex if f − µ 2 (cid:107)x(cid:107)2 is convex. 2
Algorithm 1 Decentralized Augmented Lagrangian framework
Input: mixing matrix W , regularization parameter ρ, stepsize η. 1: for k = 1, 2, ..., K do 2: Xk = arg min (cid:8)Pk(X) := F (X) + ΛT 3: Λk+1 = Λk + η WXk. 4: end for k X + ρ 2 (cid:107)X(cid:107)2 (cid:9).
W
A typical choice of the mixing matrix is the (weighted) Laplacian matrix of the graph. Another common choice is to set W as I − ˜W where ˜W is a doubly stochastic matrix [7, 10, 47]. By
Assumption 1.4, all the eigenvalues of W are strictly positive, except for the smallest one. We let
λmax(W ) denote the maximum eigenvalue, and let λ+ min(W ) denote the smallest positive eigenvalue.
The ratio between these two quantities plays an important role in quantifying the overall complexity of this problem.
Theorem 1 (Decentralized lower bound [43]). For any ﬁrst-order black-box decentralized method, the number of time units required to reach an (cid:15)-optimal solution for (1) is lower bounded by (cid:18)√
Ω
κf (1 + τ
√
κW ) log (cid:19)(cid:19)
, (cid:18) 1 (cid:15) (2) where κf = L/µ is the condition number of the loss function and κW = λmax(W )/λ+ condition number of the mixing matrix. min(W ) is the
κf log(1/(cid:15)), and b)
The lower bound decomposes as follows: a) computation cost, given by communication cost, given by τ
κf κW log(1/(cid:15)). The computation cost matches lower bounds for centralized settings [4, 37], while the communication cost introduces an additional term which depends on κW and accounts for the ‘price’ of communication in decentralized models. It follows that the effective condition number of a given decentralized problem is κW κf .
√
√
Clearly, the choice of the matrix W can strongly affect the optimal attainable performance. For example, κW can get as large as n2 in the line/cycle graph, or be constant in the complete graph.
In this paper, we do not focus on optimizing over the choice of W for a given graph G; instead, following the approach taken by existing decentralized algorithms, we assume that the graph G and the mixing matrix W are given and aim to achieve the optimal complexity (2) for this particular choice of W . 3