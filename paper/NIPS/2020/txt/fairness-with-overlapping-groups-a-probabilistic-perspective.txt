Abstract
In algorithmically fair prediction problems, a standard goal is to ensure the equal-ity of fairness metrics across multiple overlapping groups simultaneously. We reconsider this standard fair classiﬁcation problem using a probabilistic population analysis, which, in turn, reveals the Bayes-optimal classiﬁer. Our approach uniﬁes a variety of existing group-fair classiﬁcation methods and enables extensions to a wide range of non-decomposable multiclass performance metrics and fairness measures. The Bayes-optimal classiﬁer further inspires consistent procedures for algorithmically fair classiﬁcation with overlapping groups. On a variety of real datasets, the proposed approach outperforms baselines in terms of its fairness-performance tradeoff. 1

Introduction
Machine learning informs an increasingly large number of critical decisions in diverse settings. They assist medical diagnosis [17], guide policing [18], and power credit scoring systems [23]. While they have demonstrated their value in many sectors, they are prone to unwanted biases, leading to discrimination against protected subgroups within the population. For example, recent studies have revealed biases in predictive policing and criminal sentencing systems [18, 6]. The blossoming body of research in algorithmic fairness aims to study and address this issue by introducing novel algorithms guaranteeing a certain level of non-discrimination in the predictions. Each such algorithm relies on a speciﬁc deﬁnition of fairness, which falls into one of two categories: Individual fairness [9, 26] or group fairness [4, 14, 11]. The vast majority of the algorithmic group fairness literature has focused on the simplest case where there are only two groups. In this paper, we consider the more nuanced case of group fairness with respect to multiple groups.
The simplest setting is the independent case, with only one sensitive attribute which can take multiple values, e.g., race only. The presence of multiple sensitive attributes (e.g., race and gender simultaneously) leads to non-equivalent deﬁnitions of group fairness. On the one hand, fairness can be considered independently per sensitive attribute, leading to overlapping subgroups. For example, consider a model restricted to demographic parity between subgroups deﬁned by ethnicity.
Simultaneously, the model can be constrained to fulﬁll demographic parity between subgroups deﬁned by gender. We term fairness in this situation independent group fairness. On the other hand, one can consider all subgroups deﬁned by intersections of sensitive attributes (e.g., ethnicity and gender), leading to intersectional group fairness. A given algorithm can be independently group fair, e.g., when considering race and gender in isolation, but not intersectionally group fair, e.g., when considering intersections of racial and gender groups. For example, Buolamwini and Gebru [3], showed how facial recognition software had a particularly poor performance for black women. This phenomenon, called fairness gerrymandering, has been studied by Kearns et al. [15]. Intersectional
∗Work completed while an intern at Google Accra. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
fairness is often considered ideal. However, it comes with major statistical and computational hurdles such as data scarcity at intersections of minority groups, and the potentially exponential number of subgroups. Indeed, current algorithms consist of either brute force enumeration or searching via a cost-sensitive classiﬁcation problem, and intersectional groups are often empty with ﬁnite samples [15]. On the other hand, independent group fairness still provides a broad measure of fairness and is much easier to enforce.
We seek to design unifying statistically consistent strategies for group fairness and to clarify the relationship between the existing deﬁnitions. Our main results and algorithms apply to arbitrary overlapping group deﬁnitions. Our contributions are summarized in the following.
• Probabiistic results. We characterize the population optimal (also known as the Bayes-optimal) prediction procedure for multiclass classiﬁcation, where all the metrics are general linear functions of the confusion matrix. We consider both overlapping (independent, gerrymandering) and non-overlapping (unrestricted, intersectional) group fairness.
• Algorithms and statistical results. Inspired by the population optimal, we propose simple plugin and weighted empirical risk minimization (ERM) approaches for algorithmically fair classiﬁcation, and prove their consistency, i.e., the empirical estimator converges to the population optimal with sufﬁciently large samples. Our general approach recovers existing results for plugin and weighted ERM group-fair classiﬁers.
• Comparisons. We compare independent group fairness to the overlapping case. We show that intersectional fairness implies overlapping group fairness under weak conditions. However, the converse is not true, i.e., overlapping fairness may not imply intersectional fairness. This result formalizes existing observations on the dangers of gerrymandering.
• Evaluation. Empirical results are provided to highlight our theoretical claims.
Taken together, our results unify and advance the state of the art with respect to the probabilistic, statistical, and algorithmic understanding of group-fair classiﬁcation. The generality of our approach gives signiﬁcant ﬂexibility to the algorithm designer when constructing algorithmically-fair learners. 2 Problem Setup and Notation
Throughout the paper, we use uppercased bold letters to represent matrices, and lowercased bold letters to represent vectors. Let ei represent the ith standard basis whose ith dimension is 1 and 0 otherwise ei = (0, · · · , 1, · · · , 0). We denote 1 as the all-ones vector with dimension inferred from context. Given two matrices A, B of same dimension, (cid:104)A, B(cid:105) = (cid:80) i,j aijbij is the Frobenius inner product. For any quantity q, ˆq denotes an empirical estimate. Due to limited space, proofs are presented in the appendix.
Group notation. We assume M sensitive attributes, where each attribute is indicated by a group
{Am}m∈[M ]. For example, A1 may correspond to race, A2 may correspond to gender, and so on. Combined, the sensitive group indicator is represented by a M -dimensional vector a ∈ A =
A1 × A2 × · · · AM . In other words, each instance is associated with M subgroups simultaneously.
Probabilistic notation. Consider the multiclass classiﬁcation problem where Z denotes the instance space and Y = [K] denotes the output space with K classes. We assume the instances, outputs and groups are samples from a probability distribution P over the domain Y × Z × A. A dataset is given by n samples (y(i), z(i), a(i)) i.i.d∼ P, i ∈ [n]. To simplify notation, let X = Z × A, so x = (z, a). Deﬁne the set of randomized classiﬁers Hr = {h : X × A → (∆K)}, where
∆q = { p ∈ [0, 1]q : (cid:80)q i=1 pi = 1 } is the q − 1 dimensional probability simplex. A classiﬁer h is associated with the random variable h ∈ [K] deﬁned by P(h = k|x) = hk(x). If h is deterministic, then we can write h(x) = eh(x).
Confusion matrices. For any multiclass classiﬁer, let η(x) ∈ ∆K denote the class probabilities for any given instance x and sensitive attribute a, whose kth element is the conditional probability of the output belonging to class k, i.e., ηk(x) = P(Ym = k | X = x). The population confusion matrix is
C ∈ [0, 1]K×K, with elements deﬁned for k, (cid:96) ∈ [K] as Ck,(cid:96) = P(Y = k, h = (cid:96)), or equivalently,
Ck,(cid:96) = (cid:90) x
ηk(x)h(cid:96)(x) dP(x). 2
Group-speciﬁc confusion matrices. Let G represent a set of subsets of the instances, i.e., potentially overlapping partitions of the instances X . We leave G as generic for now, and will specify cases speciﬁc to fairness in the following. Given any group g ∈ G, we can deﬁne the group-speciﬁc confusion matrix Cg ∈ [0, 1]K×K, with elements deﬁned for k, (cid:96) ∈ [K], where (cid:90)
Cg k,(cid:96) =
ηk(x)h(cid:96)(x) dP(x|x ∈ g). x
We will abbreviate the event {x ∈ g} to simply g when it is clear from context. Let πg = P(X ∈ g) be the probability of group g. It is clear that when the groups G form a partition, i.e., a ∩ b = ∅ ∀a, b ∈ G and (cid:83) g∈G g = X , the population confusion may be recovered by a weighted average of group confusions, C = (cid:80) g∈G πgCg. yi = k k,(cid:96)[h] =
The sample confusion matrix is deﬁned as (cid:98)C[h] = 1 i=1 (cid:98)C(i)[h], where (cid:98)C(i)[h] ∈ [0, 1]K×K, n (cid:80)K and (cid:98)C (i) k,(cid:96)[h] = 1. The empirical group-speciﬁc confusion matrices (cid:98)Cg are computed by conditioning on groups. In the empirical case, it is convenient to represent group memberships via indices alone, i.e., xi ∈ g as i ∈ g. We have (cid:98)Cg[h] = 1
|g| (cid:80)n is the indicator function, so (cid:80)K i∈g (cid:98)C(i)[h]. h(cid:96)(xi). Here, (cid:96)=1 (cid:98)C (i) (cid:80) k=1 (cid:75) (cid:74) (cid:74) (cid:75)
·
Fairness constraints. Let Gfair represent the (potentially overlapping) set of groups across which we wish to enforce fairness. The following states our formal assumptions on Gfair.
Assumption 2.1. Gfair is a function of the sensitive attributes A only.
We will focus the discussion on common cases in the literature. These include non-overlapping (unrestricted, intersectional), and overlapping (independent, gerrymandering) group partitions. They are computed for an example in ﬁgure 1.
• Unrestricted case. The simplest case is where the group is deﬁned by a single sensitive attribute (when there are multiple sensitive attributes, all but one are ignored). These have been the primary settings addressed by past literature [11, 20, 1]. Thus for some ﬁxed i ∈ [M ], gj = {(z, a)|ai = j}, so |Gunrestricted| = |Ai|. In the special case of binary sensitive attributes, |Gunrestricted| = 2.
• Intersectional groups. Here, the non-overlapping groups are associated with all possible combina-m∈M |Am|. tions of sensitive features. Thus ga = {(z, a(cid:48))|a(cid:48) = a} ∀a ∈ A so |Gintersectional| = (cid:81)
In the special case of binary sensitive attributes, |Gintersectional| = 2M .
• Independent groups. Here, the groups are overlapping, with a set of groups associated with each fairness attribute separately. It is convenient to denote the groups based on indices representing each attribute, and each potential setting. Thus gi,j = {(z, a)|ai = j}, so |Gindependent| = (cid:80) m∈M |Am|. In the special case of binary sensitive attributes, |Gindependent| = 2M .
• Gerrymandering intersectional groups. Here, group intersections are deﬁned by any subset of the sensitive attributes, leading to overlapping subgroups. Ggerrymandering = {{(z, a) : aI = s} : I ⊂ [M ], s ∈ AI } where aI denotes a restricted to the entries indexed by I.
It is also the closure of Gindependent under intersection. As a result, Gintersectional ⊆ Ggerrymandering, and
Gindependent ⊆ Ggerrymandering. In the special case of binary sensitive attributes, |Ggerrymandering| = 3M .
Fairness metrics. We formulate group fairness by upper bounding a fairness violation func-tion V : H (cid:55)→ RJ which can be represented as a linear function of the confusion matrices, i.e. V(h) = Φ(C[h], {Cg[h]}g∈Gfair) where ∀j ∈ [J], V(h)j = φj(C[h], {Cg[h]}g∈Gfair ) = j , Cg(cid:11). This formulation is sufﬁciently ﬂexible to include the fairness statis-(cid:104)Uj, C(cid:105) − (cid:80) tics we are aware of in common use as special cases. For example, demographic parity for binary classiﬁers [9] can be deﬁned by ﬁxing Cg 1,1 across groups. Equal opportunity [12] is recovered by ﬁxing the group-speciﬁc true positives, using population speciﬁc weights, i.e., 0,0 + Cg (cid:10)Vg g∈Gfair
DP = ±(Cg
φ± 0,1 +Cg 1,1 −C0,1 +C1,1)−ν, φ±
EO = ± (cid:18) 1
P(Y = 1 | g)
Cg 1,1 − 1
P(Y = 1) (cid:19)
C1,1
−ν, using both a positive and negative constraint to penalize both positive and negative deviations between the group and the population, and relaxation ν.
Performance metrics. We consider an error metric E : H (cid:55)→ R+ that is a linear function of the population confusion E(h) = ψ(C) = (cid:104)D, C[h](cid:105). This setting has been studied in binary 3
G
F
H
E
B
D
A
C
Old
Young
Female
W hite
Male
Black
Independent groups:
{Female = A ∪ B ∪ E ∪ F, Male = C ∪ D ∪ G ∪ H,
Old = A ∪ C ∪ E ∪ G, Young = B ∪ D ∪ F ∪ H,
Black = A ∪ B ∪ C ∪ D, White = E ∪ F ∪ G ∪ H}
Intersectional groups:
{A, B, C, D, E, F, G, H}
Gerrymandering groups:
{Female, Male, Old, Young, Black, White,
Fe &{Od, Bk, Yg, Wt} = A ∪ E, A ∪ B, B ∪ F, E ∪ F,
Me &{Od, Bk, Yg, Wt} = C ∪ G, C ∪ D, D ∪ H, G ∪ H,
Od &{Bk, Wt} = A ∪ C, E ∪ G,
Yg &{Bk, Wt} = B ∪ D, F ∪ H,
A, B, C, D, E, F, G}
Figure 1: Independent, intersectional and gerrymandering intersectional group fairness refer to satisfying equality of a certain metric across prescribed sets of groups at various levels of granularity, shown above for an example with M = 3 protected attributes corresponding to sex, age, and race. classiﬁcation [25], multiclass classiﬁcation [21], multilabel classiﬁcation [16], and multioutput classiﬁcation [24]. For instance, standard classiﬁcation error corresponds to setting D = 1 − I. The goal is to learn the Bayes-optimal classiﬁer with respect to the given metric, which, when it exists, is given by: h∗ ∈ argminh E(h) s.t. V(h) ≤ 0. (1)
We denote the optimal error as E ∗ = E(h∗). We say a classiﬁer hN constructed using ﬁnite data of
P
−→ 0, as n → ∞. We also consider empirical size N is {E, V}-consistent if E(hn) versions of error ˆE(h) = ψ( (cid:98)C[h]) and fairness violation (cid:98)V(h) = Φ( (cid:98)C[h { (cid:98)Cg[h]}g).
P
−→ E ∗ and V(hn) 3 Bayes-Optimal Classiﬁers
In this section, we identify a parametric form for the Bayes-optimal group-fair classiﬁer under standard assumptions. To begin, we introduce the following general assumption on the joint distribution.
Assumption 3.1 (η-continuity). Assume P({η(x) = c}) = 0 ∀c ∈ ∆K. Furthermore, let Q = η(x) be a random variable with density pη(Q), where pη(Q) is absolutely continuous with respect to the
Lebesgue measure restricted to ∆K.
This assumption imposes that the conditional probability as a random variable has a well-deﬁned density. Analogous regularity assumptions are widely employed in literature on designing well-deﬁned complex classiﬁcation metrics and seem to be unavoidable (we refer interested reader to Yan et al. [25], Narasimhan et al. [21] for details). Next, we deﬁne the general form of weighted multiclass classiﬁers, which are the Bayes-optimal classiﬁers for linear metrics.
Deﬁnition 3.2. [Narasimhan et al. [21]] Given a loss matrix W ∈ RK×K, a weighted classiﬁer h satisﬁes hi(x) > 0 only if i ∈ arg mink∈[K] (cid:104)Wk, η(x)(cid:105).
Next we present our ﬁrst main result identifying the Bayes-optimal group-fair classiﬁer.
Theorem 3.1. Under Assumption 2.1 and Assumption 3.1, if (1) is feasible (i.e., a solution exists), the Bayes-optimal classiﬁer is given by h∗(x) = h∗(z, a) = βah1(x) + (1 − βa)h2(x), where
βa ∈ (0, 1), ∀a ∈ A and hi(x) are weighted classiﬁers with weights {{Wi,a}i∈{1,2}}a∈A.
One key observation is that pointwise, the Bayes-optimal classiﬁer can be decomposed based on intersectional groups Gintersectional = A, even when Gfair is overlapping. This observation will prove useful for algorithms. 3.1
Intersectional group fairness implies overlapping group fairness
Recent research [15] has shown how imposing overlapping group fairness using independent fairness restrictions can lead to violation of intersectional fairness, primarily via examples. This observation 4
Algorithm 1: GroupFair, Group-fair classiﬁcation with overlapping groups,
Input: ψ : [0, 1]K×K → [0, 1], Φ : [0, 1]K×K × ([0, 1]K×K)Gfair → [0, 1]J samples {(x1, y1), . . . , (xn, yn)}.
Initialize λ1 ∈ [0, B]J ; for t = 1, . . . , T do ht ← MinOracleh∈H(L(h, λt), zn);
λt+1 ← Updatet(λt, Φ( (cid:98)C[ht], { (cid:98)Cg[ht]}g∈Gfair) − ε); end
¯hT ← 1
T return (¯hT , ¯λT ) (cid:80)T t=1 ht,
¯λT ← 1
T (cid:80)T t=1 λt; led to the term fairness gerrymandering. Here, we examine this claim more formally, showing that enforcing intersectional fairness controls overlapping fairness, although the converse is not always true, i.e., enforcing overlapping fairness does not imply intersectional fairness. We show this result for the general case of quasi-convex fairness measures, with linear fairness metrics recovered as a special case.
Proposition 3.2. For any Gfair that satisﬁes assumption 2.1, suppose φ : [0, 1]K×K ×[0, 1]K×K → R+ is quasiconvex, φ(C, Cg) ≤ 0 ∀g ∈ Gintersectional =⇒ φ(C, Cg) ≤ 0 ∀g ∈ Gfair. The converse does not hold.
Remark 3.3. Note that the converse claim of Proposition 3.2, does not apply to Ggerrymandering.
Controlling the gerrymandering fairness violation implies control of the intersectional fairness violation, since Gintersectional ⊆ Ggerrymandering. 4 Algorithms
Here we present GroupFair, a general empirical procedure for solving (1). The Lagrangian of the constrained optimization problem (1) is L(h, λ) = E(h) + λ(cid:62)V(h) with empirical Lagrangian
ˆL(h, λ) = ˆE(h) + λ(cid:62)(V(h) − ε), where ε is a buffer which allows us to compare the loss of the computed predictor to that of the optimal fair predictor, when proving generalization properties of our algorithm.
Our approach involves ﬁnding a saddle point of the Lagrangian by alternating between computing the minimizer of the current Lagrangian, and updating the Lagrange multipliers based on the current fairness violations. The returned classiﬁers will be probabilistic combinations of classiﬁers in H, i.e. the procedure returns a classiﬁer in conv(H). In the following, we ﬁrst assume the dual parameter λ is
ﬁxed, and describe ways of computing the minimization by calling standard classiﬁcation algorithms.
We consider both plugin and weighted ERM. In brief, the plugin estimator ﬁrst proceeds assuming
η(x) is known, then we plugin the empirical estimator ˆη(x) in its place. The plugin approach has the beneﬁt of low computational complexity once ﬁxed. On the other hand, the weighted ERM estimator requires the solution of a weighted classiﬁcation problem in each round, but avoids the need for estimating ˆη(x). 4.1 Weighted ERM Oracle
In the weighed ERM approach we parametrize h : X → [K] by a function class F of functions f : X → RK. The classiﬁcation is the argmax of the predicted vector, h(x) = argmaxj(f (x)j), so we denote the set of classiﬁers as Hwerm = argmax ◦F. The following special case of Deﬁnition 1 in [22] outlines the required conditions for weighted multiclass classiﬁcation calibration. This is commonly referred to as cost-sensitive classiﬁcation [1] when applied to binary classiﬁcation.
Deﬁnition 4.1 (W-calibration [22]). Let W ∈ RK×K to be W-calibrated if
. A surrogate function L : RK → RK
+ is said
+
∀p ∈ ∆K : inf u:argmax(u) /∈argmink(p(cid:62)W)k p(cid:62)L(u) > inf u p(cid:62)L(u). 5
Note that the weights are sample (group) speciﬁc – which, while uncommon, is not new, e.g., Ávila
Pires et al. [27].
Proposition 4.1. The weighted ERM estimator for average fairness violation is given by: h(x) = argmaxj(f ∗(x)j), f ∗ = minf ∈F ˆL(f ); where ˆL(f ) = ˆE[yT L(f )] is a multiclass classiﬁcation surrogate for the weighted multiclass error with group-dependent weights ∀a ∈ A

W(x) =
D + (cid:18)
λj
Uj −
J (cid:88) j=1 1a∈g
ˆπ(g)
Vg j (cid:88) g∈Gfair
 (cid:19)
 . (2) 4.2 The Plugin Oracle
The plugin hypothesis class are the weighted classiﬁers, identiﬁed by Theorem 3.1 as Hplg =
{h(x) = argminj∈[K](ˆη(x)(cid:62)B(x))j : B(x) ∈ RK×K}. Here, we focus on the average violation case only. By simply-reordering terms, the population problem can be determined as follows.
Proposition 4.2. The plug-in estimator for average fairness violation is given by ˆh(x) = argmink∈[K](η(x)(cid:62)W(x))k, where W(x) is deﬁned in (2). 4.3 GroupFair, a General Group-Fair Classiﬁcation Algorithm
We can now present GroupFair, a general algorithm for group-fair classiﬁcation with overlapping groups, as outlined in Algorithm 1. As outlined, our approach proceeds in rounds, updating the clas-siﬁer oracle and the dual variable. Interleaved with the primal update is a dual update Updatet(λ, v) via gradient descent on the dual variable. The resulting classiﬁer is the average over the oracle classiﬁers.
Recovery of existing methods. When the groups are non-overlapping, GroupFair with the Plugin oracle and projected gradient ascent update recovers FairCOCO [20]. Similarly, when the groups are non-overlapping, and the labels are binary, GroupFair with the weighted ERM oracle and exponentiated gradient update recovers FairReduction [1] (see also Table 1). Importantly, GroupFair enables a straightforward extension to overlapping groups. 5 Consistency
Here we discuss the consistency of the weighted ERM and the plugin approaches. For any class
H = {h : X → [K]}, denote Hk = {1{h(x)=k} : h ∈ H}. We assume WLOG that VC(H1) = . . . =
VC(HK) and denote this quantity as VC(H). Next, we give a theorem relating the performance and satisfaction of constraints of an empirical saddle point to an optimal fair classiﬁer.
Theorem 5.1. Suppose ψ : [0, 1]K×K → [0, 1] and Φ : [0, 1]K×K × ([0, 1]K×K)Gfair → [0, 1]J are ρ-Lipschitz w.r.t. (cid:107) · (cid:107)∞. Recall ˆL(h, λ) = ˆE(h) + λ(cid:62)( ˆV(h) − ε1). Deﬁne γ(n(cid:48), H, δ) = (cid:113) VC(H) log(n)+log(1/δ) n is a ν-saddle point of maxλ∈[0,B]J minh∈conv H ˆL(h, λ),
. If nmin = ming∈Gfair ng, ε = Ω (ργ(nmin, H, δ)) then w.p. 1 − δ: in the sense that
ˆL(h, ¯λ) ≤ ν, and h∗ ∈ conv(H) satisﬁes V(h∗) ≤ 0,
If maxλ∈[0,B]J ˆL(¯h, λ) − minh∈conv(H) then (¯h, ¯λ)
E(¯h) ≤ E(h∗) + ν + O (ργ(n, H, δ)) , (cid:107)V(¯h)(cid:107)∞ ≤ 1 + ν
B
+ O (ργ(nmin, H, δ)) + ε.
Thus, as long as we can ﬁnd an arbitrarily good saddle point, which weighted ERM grants if Hwerm is expressive enough while having ﬁnite VC dimension, then we obtain consistency. A saddle point can be found by running a gradient ascent algorithm on λ conﬁned to [0, B]J , which repeatedly
ˆL(h, λt); the ﬁnal (¯h, ¯λ) are the averages of the primal and dual computes ht = argminh∈H variables computed throughout the algorithm.
Although Theorem 5.1 captures the spirit of the argument for the plugin algorithm, it only applies naturally to the weighted ERM algorithm. This is because the plugin algorithm is solving a subtly different minimization problem: it returns ht as the population minimum, if the estimated regression function ˆη replaces the true regression function. 6
MinOracleh∈H(L(h, λt), zn)
FairReduction
H ◦ argminf ∈F
ˆL(f )
B
FairCOCO plugin(ˆη, (ˆπg)g∈Gfair , ψ, Φ, λt)
Updatet(λ, v) exp(log λ−ηtv)
B−(cid:80)M j=1 λj +(cid:80)M proj[0,B]M (λ + ηtv) j=1 exp(log λi−ηtvi)
Table 1: The oracles shown are plugin (6) and ERM on the reweighted ˆL (7). H =
[argmaxk∈[K](·)k] converts a function X → RK to a classiﬁer. In FairCOCO, ˆη is estimated from samples z1:n/2 = {(x1, y1), . . . , (xn/2, yn/2)} and all of the other probability estimates (ˆπg)g and
{ (cid:98)Cg[ht]}g are estimated from zn/2: = zn \ z1:n/2. is run as
Theorem 5.2. With probability at
Updatet(λ, v) = proj[0,B]J (λ + ηv) for T iterations with step size η = 1 and for t =
√
B 1, . . . , T, ht = plugin(ˆη, (ˆπg)g∈Gfair, ψ, Φ), letting ρ = max{(cid:107)ψ(cid:107)1, (cid:107)φ1(cid:107)1, . . . , (cid:107)φM (cid:107)1}, ρg = (cid:80)J j=1 (cid:107)Uj(cid:107)∞, ∆η = E(cid:107)η(x) − ˆη(x)(cid:107)1, ˇn = ming∈Gfair ng, then if projected gradient ascent least 1 − δ,
T j (cid:107)∞, ρX = (cid:107)D(cid:107)∞ + (cid:80)J j=1 (cid:107)Vg
 (cid:115)
κ := O
Jρ
K 2 log(ˇn) + log( |Gfair|K2
ˇn
δ
)


 + ∆η
ρX +
 (cid:115)
 + (cid:88) g∈Gfair
ρg
πg log( |Gfair| n
δ
) (cid:88) g∈Gfair
ρg
π2 g
=⇒ Eψ(¯hT ) ≤ E ∗
ψ +
JB
√
T
+ O (BJκ) , (cid:107)Vφ(¯hT )(cid:107)∞ ≤ 2J
√
T
+ O (Jκ) .
A key point in the presented analyses (for both procedures) is that the dominating statistical properties depend on the number of fairness groups. We note that |Gfair| (cid:28) |Gintersectional| = |A| for the independent case, so this signiﬁcantly improves results. More broadly, we conjecture that the statistical bounds depend on min(|Gfair|, |Gintersectional|), and leave the details to future work. We also note the statistical dependence on the size of the smallest group. This seems to be unavoidable, as we need an estimate of the group fairness violation in order to control it. To this end, group violations may be scaled by group size, which leads instead to a dependence on the VC dimension of Gfair, improving statistical dependence with small groups at the cost of some fairness [15]. We expect that the bounds may be improved by a more reﬁned analysis, or modiﬁed algorithms with stronger assumptions. We leave this detail to future work. 5.1 Additional