Abstract
We study the problem of improving the performance of online algorithms by in-corporating machine-learned predictions. The goal is to design algorithms that are both consistent and robust, meaning that the algorithm performs well when predictions are accurate and maintains worst-case guarantees. Such algorithms have been studied in a recent line of work initiated by Lykouris and Vassilvit-skii (ICML ’18) and Kumar, Purohit and Svitkina (NeurIPS ’18). They provide robustness-consistency trade-offs for a variety of online problems. However, they leave open the question of whether these trade-offs are tight, i.e., to what extent to such trade-offs are necessary. In this paper, we provide the ﬁrst set of non-trivial lower bounds for competitive analysis using machine-learned predictions. We focus on the classic problems of ski rental and non-clairvoyant scheduling and provide optimal trade-offs in various settings. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
1

Introduction
The vast gains in predictive ability by machine learning models in recent years have made them an attractive approach for algorithmic problems under uncertainty: One can train a model to predict outcomes on historical data and then respond according to the model’s predictions in future scenarios.
For example, when renting cloud servers, a company might need to decide whether to pay on-demand or reserve cloud servers for an entire year. The company could try to optimize their purchasing based on a model learned from past demand. However, a central concern for applications like these is the lack of provable bounds on worst-case performance. Modern machine learning models may produce predictions that are embarrassingly inaccurate (e.g., [SZS+14]), especially when trying to generalize to unfamiliar inputs. The potential for such non-robust behavior is be problematic in practice, when users of machine learning-based systems desire at least some baseline level of performance in the worst case.
On the other hand, the algorithms literature has long studied algorithms with worst-case guarantees.
In particular, the theory of online algorithms focuses on algorithms that perform well under uncer-tainty, even when inputs are chosen adversarially. A key metric in this literature is the competitive ratio, which is the ratio between the worst-case performance of an algorithm (without knowledge of the future) and that of an ofﬂine optimal algorithm (that has full knowledge of the future).1 That is, an times worse than any other algorithm, even in algorithm with a competitive ratio of hindsight. The classical study of online algorithms, however, focuses on the worst-case outcome over all possible inputs. This approach can be far too pessimistic for many real-world settings, leaving room for improvement in more optimistic scenarios where the algorithm designer has some prior signal about future inputs. does at most
C
C
Recent works by Lykouris and Vassilvitskii [LV18] and Kumar, Purohit and Svitkina [KPS18] intertwine these two approaches to algorithms under uncertainty by augmenting algorithms with machine learned predictions. The former studies the online caching problem, whereas the latter focuses on the classical problems of ski-rental and non-clairvoyant job scheduling. They design algorithms that (1) perform excellently when the prediction is accurate and (2) have worst-case guarantees in the form of competitive ratios. For such augmented online algorithms, they introduce the metrics of consistency, which measures the competitive ratio in the case where the machine learning prediction is perfectly accurate, and robustness, which is the worst-case competitive ratio over all possible inputs. Moreover, the algorithms they design have a natural consistency-robustness trade-off, where one can improve consistency at the cost of robustness and vice versa. These two works, however, do not discuss the extent to which such trade-offs are necessary, i.e., whether the given trade-offs are tight.2
In this work, we provide the ﬁrst set of optimal results for online algorithms using machine-learned predictions. Our results are the following: (i) For the ski-rental problem, we give tight lower bounds on the robustness-consistency trade-off in both deterministic and randomized settings, matching the guarantees of the algorithms given by [KPS18]. (ii) For the non-clairvoyant job scheduling problem, we provide a non-trivial lower bound that is tight at the endpoints of the trade-off curve.
Moreover, for the case of two jobs, we give matching upper and lower bounds on the full trade-off. The algorithm improves signiﬁcantly upon that of [KPS18].
Conceptually, our results show that merely demanding good performance under perfect prediction can require substantial sacriﬁces in overall robustness. That is, this trade-off between good performance in the ideal setting and overall robustness is deeply intrinsic to the design of learning-augmented online algorithms. 1.1 Our results 1For randomized algorithms, one considers the expected competitive ratio, which compares the expected cost (taken over the randomness of the algorithm) to the cost of the ofﬂine optimal. 2We remark that Lykouris and Vassilvitski [LV18] prove for the online caching problem that one can achieve constant competitiveness under perfect predictions while having O(log k) competitiveness in the worst case.
This bound is optimal up to constant factors by the classical algorithms for online caching [FKL+91]. 2
Ski-rental. The ski rental problem is a classical online algorithms problem [KMRS88] with a particularly simple model of decision-making under uncertainty. In the prob-lem, there is a skier who is out to ski for an unknown num-ber of days. The ﬁrst morning, the skier must either rent skis for a cost of $1 or buy skis for a cost of $B. Each day thereafter, the skier must make the same decision again as long as she has not yet purchased skis. The goal for the skier is to follow a procedure that minimizes com-petitive ratio. Variations of the ski-rental problem have been used to model a diverse set of scenarios, including snoopy caching [KMRS88], dynamic TCP acknowledge-ment [KKR03], and renting cloud servers [KKP13].
Figure 1: randomized trade-offs augmented ski-rental.
Tight deterministic and learning-for
In our setting of ski-rental with a machine-learned predic-tion, we assume that, in addition to knowing B, the skier has access to a prediction y for the number of days she will ski. Let η denote the absolute error of the prediction y (i.e., if she actually skis for x days, then
η =
). Furthermore, deﬁne c(η) to be the skier’s worst-case competitive ratio over all y given
|
β.
η. We say that the procedure is γ-robust if c(η)
≤
We prove deterministic and randomized lower bounds on the robustness-consistency trade-off that match the algorithmic results in [KPS18]. Speciﬁcally, we show:
γ for any η and that it is β-consistent if c(0) x
|
≤
− y
Theorem 1.1 (Deterministic Lower Bound for Ski-Rental; also in [GP19, ADJ+20]). Let λ (0, 1) be a ﬁxed parameter. Any (1 + λ)-consistent deterministic algorithm for ski-rental with machine-learned prediction problem is at least (1 + 1/λ)-robust.
∈
We remark that this deterministic bound is simple to prove and has also appeared in two prior works [GP19, ADJ+20].
Theorem 1.2 (Randomized Lower Bound for Ski-Rental). Any (randomized) algorithm for ski-rental with machine-learned prediction that achieves robustness γ must have consistency
β
≥
γ log 1 + (cid:18) 1
γ 1 (cid:19)
−
.
In particular, any (randomized) algorithm achieving robustness γ with machine-learned prediction problem must have consistency β 1/(1
λ/(1
−
−
≤
≥ e− e−
λ) for the ski-rental
λ).
Non-clairvoyant scheduling. The non-clairvoyant job scheduling problem was ﬁrst studied in an online setting by Motwani, Phillips, and Torng [MPT94]. This problem models scheduling jobs on a single processor, where the jobs have unknown processing times and the objective is to minimize the completion time (i.e., the sum of the job completion times). More formally, the algorithm initially receives n job requests with unknown processing times
, xn and is asked to schedule them on a single x1, x2, machine, allowing for preemptions.
If the completion time of job i is ti, then the total completion time of the algorithm is
· · · n i=1 ti. (cid:80)
In the learning-augmented version of the problem, we additionally provide the algorithm with predictions y1, y2,
, xn.
, yn of the processing times x1, x2,
· · ·
· · · be the (cid:96)1 error of the prediction
Let η = xi − i | and c(η) be the algorithm’s worst-case competitive ratio given η. As before, we say an algorithm is
γ-robust if c(η)
β. Our ﬁrst result is a lower bound on the robustness-consistency trade-off in the general case. yi|
γ for any η and β-consistent if c(0)
Figure 2: Tight trade-offs for scheduling two jobs (cid:80)
≤
≤ 3
Theorem 1.3 (Lower bound for non-clairvoyant scheduling with n jobs). Any (1 + λ)-consistent algorithm for non-clairvoyant scheduling with machine-learned prediction must have robustness n + n(n + 1)λ 1 + λ(n + 1)(n + 2)/2
.
γ
≥
This bound is tight at the endpoints of the trade-off. When λ = 0, we have c(η) achieved by any (non-idling) algorithm. On the other hand, when λ = 1 we have c(η) 2 n+1 (so 1 + λ = 2 2 n+1 , which is the tight bound of [MPT94] (achieved by round-robin).3
−
≥ 2 n, which is 2 n+1 ),
−
≥
−
−
−
λ)-robust for λ
On the other hand, Kumar, Purohit and Svitkina [KPS18] give an algorithm that is (1 + λ)/2λ-consistent and 2/(1 (0, 1). In the case of n = 2, the robustness can be improved to 4/(3 3λ). We provide a signiﬁcantly better trade-off (Figure 2) and a matching lower bound in this regime. Our algorithm is 2-competitive over all parameter choices, while their algorithm has robustness tends to inﬁnity as consistency goes to 1.
Theorem 1.4 (Tight bound for non-clairvoyant scheduling of 2 jobs). In the case of 2 jobs, there is an algorithm that achieves (1 + λ)-consistency and (1 + 1/(1 + 6λ))-robustness for non-clairvoyant scheduling with machine-learned prediction, for any λ (0, 1/3).4 Moreover, this bound is tight.
∈
∈ 1.2