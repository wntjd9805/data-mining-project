Abstract
We formulate a general framework for building structural causal models (SCMs) with deep learning components. The proposed approach employs normalising
ﬂows and variational inference to enable tractable inference of exogenous noise variables—a crucial step for counterfactual inference that is missing from existing deep causal learning methods. Our framework is validated on a synthetic dataset built on MNIST as well as on a real-world medical dataset of brain MRI scans. Our experimental results indicate that we can successfully train deep SCMs that are capable of all three levels of Pearl’s ladder of causation: association, intervention, and counterfactuals, giving rise to a powerful new approach for answering causal questions in imaging applications and beyond. The code for all our experiments is available at https://github.com/biomedia-mira/deepscm. 1

Introduction
Many questions in everyday life as well as in scientiﬁc inquiry are causal in nature: “How would the climate have changed if we’d had less emissions in the ’80s?”, “How fast could I run if I hadn’t been smoking?”, or “Will my headache be gone if I take that pill?”. None of those questions can be answered with statistical tools alone, but require methods from causality to analyse interactions with our environment (interventions) and hypothetical alternate worlds (counterfactuals), going beyond joint, marginal, and conditional probabilities [1]. Even though these are natural lines of reasoning, their mathematical formalisation under a uniﬁed theory is relatively recent [2].
In some statistics-based research ﬁelds, such as econometrics or epidemiology, the use of causal inference methods has been established for some time [3, 4]. However, causal approaches have been introduced into deep learning (DL) only very recently [5]. For example, research has studied the use of causality for disentanglement [6, 7], causal discovery [8, 9], and for deriving causality-inspired explanations [10, 11] or data augmentations [12]. Causal DL models could be capable of learning relationships from complex high-dimensional data and of providing answers to interventional and counterfactual questions, although current work on deep counterfactuals is limited by modelling only direct cause-effect relationships [11] or instrumental-variable scenarios [13], or by not providing a full recipe for tractable counterfactual inference [14].
The integration of causality into DL research promises to enable novel scientiﬁc advances as well as to tackle known shortcomings of DL methods: DL is known to be susceptible to learning spurious correlations and amplifying biases [e.g. 15], and to be exceptionally vulnerable to changes in the input distribution [16]. By explicitly modelling causal relationships and acknowledging the difference between causation and correlation, causality becomes a natural ﬁeld of study for improving the transparency, fairness, and robustness of DL-based systems [17, 18]. Further, the tractable inference of deep counterfactuals enables novel research avenues that aim to study causal reasoning on a
⇤Joint ﬁrst authors. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
per-instance rather than population level, which could lead to advances in personalised medicine as well as in decision-support systems, more generally.
In this context, our work studies the use of DL-based causal mechanisms and establishes effective ways of performing counterfactual inference with fully speciﬁed causal models with no unobserved confounding. Our main contributions are: 1) a uniﬁed framework for structural causal models using modular deep mechanisms; 2) an efﬁcient approach to estimating counterfactuals by inferring exogenous noise via variational inference or normalising ﬂows; 3) case studies exemplifying how to apply deep structural causal models and perform counterfactual inference. The paper is organised as follows: we ﬁrst review structural causal models and discuss how to leverage deep mechanisms and enable tractable counterfactual inference. Second, we compare our work to recent progress in deep causal learning in light of Pearl’s ladder of causation [19]. Finally, we apply deep structural causal models to a synthetic experiment as well as to modelling brain MRI scans, demonstrating the practical utility of our framework in answering counterfactual questions. 2 Deep Structural Causal Models
We consider the problem of modelling a collection of K random variables x = (x1, . . . , xK). By considering causal relationships between them, we aim to build a model that not only is capable of generating convincing novel samples, but also satisﬁes all three rungs of the causation ladder [19].
The ﬁrst level, association, describes reasoning about passively observed data. This level deals with correlations in the data and questions of the type “What are the odds that I observe. . . ?”, which relates purely to marginal, joint, and conditional probabilities. Intervention concerns interactions with the environment. It requires knowledge beyond just observations, as it relies on structural assumptions about the underlying data-generating process. Characteristic questions ask about the effects of certain actions: “What happens if I do. . . ?”. Lastly, counterfactuals deal with retrospective hypothetical scenarios. Counterfactual queries leverage functional models of the generative processes to imagine alternative outcomes for individual data points, answering “What if I had done A instead of B?”.
Arguably, such questions are at the heart of scientiﬁc reasoning (and beyond), yet are less well-studied in the ﬁeld of machine learning. The three levels of causation can be operationalised by employing structural causal models (SCMs)2, recapitulated in the next section. 2.1