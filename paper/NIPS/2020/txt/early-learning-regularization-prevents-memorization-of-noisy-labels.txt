Abstract
We propose a novel framework to perform classiﬁcation via deep learning in the presence of noisy annotations. When trained on noisy labels, deep neural networks have been observed to ﬁrst ﬁt the training data with clean labels during an “early learning” phase, before eventually memorizing the examples with false labels.
We prove that early learning and memorization are fundamental phenomena in high-dimensional classiﬁcation tasks, even in simple linear models, and give a theoretical explanation in this setting. Motivated by these ﬁndings, we develop a new technique for noisy classiﬁcation tasks, which exploits the progress of the early learning phase. In contrast with existing approaches, which use the model output during early learning to detect the examples with clean labels, and either ignore or attempt to correct the false labels, we take a different route and instead capitalize on early learning via regularization. There are two key elements to our approach. First, we leverage semi-supervised learning techniques to produce target probabilities based on the model outputs. Second, we design a regularization term that steers the model towards these targets, implicitly preventing memorization of the false labels. The resulting framework is shown to provide robustness to noisy annotations on several standard benchmarks and real-world datasets, where it achieves results comparable to the state of the art. 1

Introduction
Deep neural networks have become an essential tool for classiﬁcation tasks [19, 15, 11]. These models tend to be trained on large curated datasets such as CIFAR-10 [18] or ImageNet [9], where the vast majority of labels have been manually veriﬁed. Unfortunately, in many applications such datasets are not available, due to the cost or difﬁculty of manual labeling (e.g. [13, 32, 25, 1]).
However, datasets with lower quality annotations, obtained for instance from online queries [5] or crowdsourcing [49, 53], may be available. Such annotations inevitably contain numerous mistakes or label noise. It is therefore of great importance to develop methodology that is robust to the presence of noisy annotations.
When trained on noisy labels, deep neural networks have been observed to ﬁrst ﬁt the training data with clean labels during an early learning phase, before eventually memorizing the examples with 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
Clean labels
Wrong labels
Cross Entropy
Early-learning
Regularization
Figure 1: Results of training a ResNet-34 [15] neural network with a traditional cross entropy loss (top row) and our proposed method (bottom row) to perform classiﬁcation on the CIFAR-10 dataset where 40% of the labels are ﬂipped at random. The left column shows the fraction of examples with clean labels that are predicted correctly (green) and incorrectly (blue). The right column shows the fraction of examples with wrong labels that are predicted correctly (green), memorized (the prediction equals the wrong label, shown in red), and incorrectly predicted as neither the true nor the labeled class (blue). The model trained with cross entropy begins by learning to predict the true labels, even for many of the examples with wrong label, but eventually memorizes the wrong labels. Our proposed method based on early-learning regularization prevents memorization, allowing the model to continue learning on the examples with clean labels to attain high accuracy on examples with both clean and wrong labels. false labels [3, 54]. In this work we study this phenomenon and introduce a novel framework that exploits it to achieve robustness to noisy labels. Our main contributions are the following:
•
•
•
In Section 3 we establish that early learning and memorization are fundamental phenomena in high dimensions, proving that they occur even for simple linear generative models.
In Section 4 we propose a technique that utilizes the early-learning phenomenon to counteract the inﬂuence of the noisy labels on the gradient of the cross entropy loss. This is achieved through a regularization term that incorporates target probabilities estimated from the model outputs using several semi-supervised learning techniques.
In Section 6 we show that the proposed methodology achieves results comparable to the state of the art on several standard benchmarks and real-world datasets. We also perform a systematic ablation study to evaluate the different alternatives to compute the target probabilities, and the effect of incorporating mixup data augmentation [55]. 2