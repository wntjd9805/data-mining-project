Abstract
In clustering problems, a central decision-maker is given a complete metric graph over vertices and must provide a clustering of vertices that minimizes some ob-jective function. In fair clustering problems, vertices are endowed with a color (e.g., membership in a group), and the requirements of a valid clustering might also include the representation of colors in the solution. Prior work in fair clustering assumes complete knowledge of group membership. In this paper, we generalize this by assuming imperfect knowledge of group membership through probabilistic assignments, and present algorithms in this more general setting with approxi-mation ratio guarantees. We also address the problem of “metric membership”, where group membership has a notion of order and distance. Experiments are conducted using our proposed algorithms as well as baselines to validate our ap-proach, and also surface nuanced concerns when group membership is not known deterministically. 1

Introduction
Machine-learning-based decisioning systems are increasingly used in high-stakes situations, many of which directly or indirectly impact society. Examples abound of automated decisioning systems resulting in, arguably, morally repugnant outcomes: hiring algorithms may encode the biases of human reviewers’ training data Bogen and Rieke [2018], advertising systems may discriminate based on race and inferred gender in harmful ways Sweeney [2013], recidivism risk assessment software may bias its risk assessment improperly by race Angwin et al. [2016], and healthcare resource allocation systems may be biased against a speciﬁc race Ledford [2019]. A myriad of examples such as these and others motivate the growing body of research into deﬁning, measuring, and (partially) mitigating concerns of fairness and bias in machine learning. Different metrics of algorithmic fairness have been proposed, drawing on prior legal rulings and philosophical concepts; Mehrabi et al. [2019] give a recent overview of sources of bias and fairness as presently deﬁned by the machine learning community.
The earliest work in this space focused on fairness in supervised learning Luong et al. [2011], Hardt et al. [2016] as well as online learning Joseph et al. [2016]; more recently, the literature has begun expanding into fairness in unsupervised learning Chierichetti et al. [2017]. In this work, we address a novel model of fairness in clustering—a fundamental unsupervised learning problem. Here, we are given a complete metric graph where each vertex also has a color associated with it, and we are concerned with ﬁnding a clustering that takes both the metric graph and vertex colors into account.
Most of the work in this area (e.g., Ahmadian et al. [2019a], Bercea et al. [2018], Chierichetti et al.
[2017]) has deﬁned a fair clustering to be one that minimizes the cost function subject to the constraint that each cluster satisﬁes a lower and an upper bound on the percentage of each color it contains—a form of approximate demographic parity or its closely-related cousin, the p%-rule Biddle [2006]. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
We relax the assumption that a vertex’s color assignment is known deterministically; rather, for each vertex, we assume only knowledge of a distribution over colors.
Our proposed model addresses many real-world use cases. Ahmadian et al. [2019a] discuss clustering news articles such that no political viewpoint—assumed to be known deterministically—dominates any cluster. Here, the color membership attribute—i.e., the political viewpoint espoused by a news article—would not be provided directly but could be predicted with some probability of error using other available features. Awasthi et al. [2019] discuss the case of supervised learning when class labels are not known with certainty (e.g., due to noisy crowdsourcing or the use of a predictive model).
Our model addresses such motivating applications in the unsupervised learning setting, by deﬁning a fair cluster to be one where the color proportions satisfy the upper and lower bound constraints in expectation. Hence, it captures standard deterministic fair clustering as a special case.
Outline & Contributions. We begin (§2) with an overview of related research in general clustering, fairness in general machine learning, as well as recent work addressing fairness in unsupervised learning. Next (§3), we deﬁne two novel models of clustering when only probabilistic membership is available: the ﬁrst assumes that colors are unordered, and the second embeds colors into a metric space, thus endowing them with a notion of order and distance. This latter setting addresses use cases where, e.g., we may want to cluster according to membership in classes such as age or income, whose values are naturally ordered. Following this (§4), we present two approximation algorithms with theoretical guarantees in the settings above. We also brieﬂy address the (easier but often realistic)
“large cluster” setting, where it is assumed that the optimal solution does not contain pathologically small clusters. Finally (§5), we verify our proposed approaches on four real-world datasets. We note that all proofs are put in the appendix due to the page limit. 2