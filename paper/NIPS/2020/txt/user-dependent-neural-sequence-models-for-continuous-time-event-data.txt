Abstract
Continuous-time event data are common in applications such as individual behavior data, ﬁnancial transactions, and medical health records. Modeling such data can be very challenging, in particular for applications with many different types of events, since it requires a model to predict the event types as well as the time of occurrence.
Recurrent neural networks that parameterize time-varying intensity functions are the current state-of-the-art for predictive modeling with such data. These models typically assume that all event sequences come from the same data distribution.
However, in many applications event sequences are generated by different sources, or users, and their characteristics can be very different. In this paper, we extend the broad class of neural marked point process models to mixtures of latent embeddings, where each mixture component models the characteristic traits of a given user. Our approach relies on augmenting these models with a latent variable that encodes user characteristics, represented by a mixture model over user behavior that is trained via amortized variational inference. We evaluate our methods on four large real-world datasets and demonstrate systematic improvements from our approach over existing work for a variety of predictive metrics such as log-likelihood, next event ranking, and source-of-sequence identiﬁcation. 1

Introduction
Event sequences in continuous time occur across many contexts, leading to a variety of data analysis applications such as forecasting consumer purchases, fraud detection in transaction data, and predic-tion in clinical medicine. In such data, each event is typically associated with one of K event types, also known as marks, and a timestamp. There has been signiﬁcant amount of prior work in statistics for clustering [Du et al., 2015, Xu and Zha, 2017], factorizing [Schein et al., 2015], and generative modeling of such data, typically under the framework of marked temporal point process (MTPP) models [Daley and Vere-Jones, 2007]. We are primarily interested in the third of these objectives.
The multivariate Hawkes process [Hawkes, 1971, Liniger, 2009], Poisson-network [Rajaram et al., 2005], piecewise-continuous conditional intensity model [Gunawardana et al., 2011], and proximal graphic event model [Bhattacharjya et al., 2018] are some examples of the many different MTPP models previously explored. MTPP models characterize the instantaneous rate of occurrence of each event type, the so-called intensity function, conditioned on the history of past events. However, strong parametric assumptions in these traditional models limit their ﬂexibility for modeling real-world phenomena.
Recent work in machine learning has sought to address these limitations via the use of deep recurrent neural networks (RNNs). These models, such as Du et al. [2016], use expressive representations for the intensity function, use event embeddings to avoid parameter explosion, and optimize the associated log-likelihood via stochastic gradient methods. A variety of approaches have been explored to address the complex mix of discrete events and continuous time that occur in real-world event 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
Figure 1: Personalized event sequence. We predict (or evaluate the likelihood of) the semi-transparently drawn sequence on the right conditioned on (i) a training set (left), (ii) a few reference sequences from the same user (left, blue), and (iii) a preﬁx Hu t of the current sequence (right). sequences [Mei and Eisner, 2017, Wang et al., 2017, Zhang et al., 2019b, Türkmen et al., 2019]. In general, these neural-based MTPPs have been found empirically to provide systematically better predictions than their traditional counterparts, due to their more ﬂexible representations for capturing the inﬂuence of past events on future ones (both their time stamps and their types), as well as being better able to handle the signiﬁcant data sparsity associated with large event vocabularies. However, a common implicit assumption in these approaches is that all of the modeled sequences originate from the same source (or user), which is often not the case in real-world datasets such as online consumer data or medical history records. Sufﬁciently powerful neural-based MTPPs can internally adjust for this heterogeneity after conditioning on a signiﬁcant portion of a history; however, they exhibit large predictive uncertainty at the beginning of sequences. Thus, it is important to develop techniques that personalize predictions to account for heterogeneity across users.
To develop personalized MTPPs, we propose using variational autoencoders (VAEs) [Kingma and
Welling, 2014] in conjunction with previous neural-based MTPPs. VAEs are well-suited to address the problem of personalization (e.g., Liang et al. [2018]) since they distinguish between global and local parameters, which are treated differently during training/inference. In our setup, global model parameters capture properties that are common across all sequences regardless of associated user.
By contrast, local parameters describe user-speciﬁc traits and preferences. They therefore have to be inferred from fewer, user speciﬁc data, motivating a Bayesian treatment by the VAE. We further employ a mixture-of-experts approach [Shi et al., 2019] to account for heterogeneity within each user.
We demonstrate that our proposed scheme yields systematic improvements in a variety of tasks on four large, real world datasets. 2 Personalized Event Sequences
Problem Statement We consider the problem of modeling sequences of events (t, k) that occur at irregular times t. Each event carries a mark k corresponding to one of a ﬁnite number K of different possible event types. Since all our training sets are ﬁnite, each event sequence is bounded by some time horizon T > 0, i.e., it can be written as a ﬁnite history sequence of the form (1)
HT = (cid:0)(t1, k1), (t2, k2), . . . , (t|HT |, k|HT |)(cid:1) with times 0 ≤ t1 < t2 < · · · < t|HT | ≤ T and marks ki ∈ {1, . . . , K} ∀i. For brevity, let H ≡ HT .
Since our goal is personalization, we assume that each event sequence is associated with a user1 u.
Our objective is to forecast (or evaluate the likelihood of) an event sequence for a given user u conditioned on three sources of information, illustrated in Figure 1: (i) a large training set of event sequences from many users, possibly including u (Figure 1, left); (ii) a smaller (possibly empty) set of reference sequences from the same user u, that may or may not be part of the training set (blue box in left part of Figure 1); and (iii) a preﬁx, i.e., a (possibly empty) partial sequence Hu t of events performed by user u just before the time t where we start predicting (solid circles in right part of
Figure 1). Conditioned on these three sources of information, we aim to predict the continuation of the full sequence Hu t+∆ (half-transparent circles in Figure 1, right) for some remaining time span ∆.
For example, in an online store, the training set (i) contains many shopping sessions by many users; the reference sequences (ii) are previous sessions of a given user u; and the preﬁx (iii) is the already 1More generally, “user” denotes any source of event sequences, e.g., an individual, organization, or system. 2
observed part of a currently ongoing session. This setup is quite general, covering many applications with recurring users, e.g., social media platforms, music streaming services, or e-commerce websites.
The above enumeration arranges the three types of input information (i)-(iii) as nested subsets organized from global to local context. It thus reﬂects the assumption that the predicted event sequence Hu t+∆ follows some general characteristics (e.g., similarities or incompatibilities between different event types) that can be learned from the entire data set (i). At the same time, we assume that Hu t+∆ also exhibits some individual traits of the associated user u, which can therefore only be inferred from reference sequences (ii) from the same user. Finally, a user’s current goal or mood may still vary somewhat over time and can therefore only be inferred from very recent observations in the preﬁx Hu t (iii).
While the relevance for the current prediction increases as we go from (i) to (iii), the data size shrinks from (i) to (iii). This motivates different treatments of the data sources (i)-(iii) in our models in terms of point estimated global model parameters, a user-speciﬁc Bayesian inference variable zu, and the local state of a recurrent neural network, respectively. The rest of this section provides an overview over the proposed framework, deferring a more detailed discussion to Section 3.
Overview of the Proposed Solution Forecasting discrete event sequences amounts to both pre-dicting an ordering of future event types ki as well as their time stamps ti. This is a challenging problem due to the strong correlations between these two data modalities. We consider a broad class of stochastic dynamics models—neural marked temporal point processes (neural MTPPs)—that autoregressively generate events one after another. For the ith event, we draw its time stamp ti and mark ki conditioned on the hidden state hi of a “decoder” recurrent neural network (RNN). The RNN state hi gets updated after each generated event, conditioned on the event it just generated, and on an embedding vector zu that represents the user u. This leads to the following stochastic recursion: (ti+1, ki+1) ∼ pθ(ti+1, ki+1 | hi, zu) with hi = fDec(hi−1, [ki; zu], ti; η) and h0 = tanh(W0zu + b0) (2) where [ · ; · ] denotes vector concatenation, ki is a learnable continuous vector embedding for the mark ki of the ith event, and fDec is the recurrent unit of the decoder neural network DECθ with learnable parameters θ that include η, W0, and b0.
Apart from the user embedding zu, which is speciﬁc to our personalization scheme, Eq. 2 covers several MTPP models in the literature. Section 3 summarizes models that ﬁt into our framework. Note that we are not considering any side-information from users (e.g., age, location, gender, etc.); however, depending on the application these should be straightforward to incorporate into the framework.
Eq. 2 models the generation of event sequences probabilistically: each successive event (ti+1, ki+1) is sampled from pθ(ti+1, ki+1 | hi, zu) rather than being generated deterministically. Probabilistic models allow for the ability to estimate complex statistics, such as the expected time until next event of a speciﬁc type, how much more likely event A will come before event B, etc. Many of these questions would be hard or impossible to answer with a deterministic model.
Eq. 2 further reﬂects our problem setting with diverse information sources (i)-(iii) discussed above.
The decoder parameters θ are identical for all generated sequences and can thus be trained on the entire data set (i). The user embedding zu stays constant within each event sequence but varies from user to user. Thus, zu has to be inferred from reference sequences (ii) from the same user.
By concatenating the user embedding to the mark embedding, we effectively create personalized representations of events for that user. Additionally, by computing the initial stochastic state h0 from zu, we allow for personalized predictions across the entire time window from t = 0 to t = T . Finally, when completing a partial sequence, the preﬁx (iii) can be encoded into the initial RNN state hi by unrolling the RNN update (second line of Eq. 2) on the events in the preﬁx. 3 Model Parameterization and Inference
This section speciﬁes the details for representing and estimating user embedding zu, the underly-ing data generating process for sequential event data, how existing neural MTPP models can be extended to become personalized by incorporating user embeddings, as well as the loss function being optimized. Figure 2 shows operational diagrams of the encoding and decoding processes. 3
Figure 2: On the left is the encoding process for three reference sequences from user u that belong to the reference set Ru. This results in the approximate posterior mixture distribution q(zu | Ru) that is then sampled and used in the decoding process on the right for a target sequence Hu. fλ is the model speciﬁc transformation of hidden state hi and time t ∈ (ti, ti+1] to intensity rates across marks.
Encoding User Embeddings The user embedding zu in Eq. 2 allows us to personalize predictions for a given user u. zu is a real-valued vector, and for our results the dimensionality ranges from 32 to 64 depending on the dataset (see supplement for more information). The vector zu can be interpreted as the sequence and user-speciﬁc dynamics for a single history of events. We infer zu from a reference set Ru = {Hu,1, . . . , Hu,nu
} of nu sequences that we have already observed from the same user. This leads to two complications: ﬁrst, the amount of data in each reference set Ru is much smaller than the whole training set of sequences from all users; second, learning an individual user embedding zu for thousands of users would be expensive. We address both complications by an approximate Bayesian treatment of zu via amortized variational inference (amortized VI) [Kingma and Welling, 2014, Rezende et al., 2014, Zhang et al., 2019a].
The typically small amount of data in each reference set Ru motivates a Bayesian treatment via a probabilistic generative process with a prior p(zu) and the likelihood in Eq. 2. For simplicity, we assume a standard normal prior: zu ∼ N (0, I). Bayesian inference seeks the posterior probability p(zu|Ru). As ﬁnding the true posterior is computationally infeasible, VI approximates the posterior with a parameterized variational distribution q(zu|Ru) by minimizing the Kullback-Leibler diver-gence from the true posterior to q. The inferred approximate posterior q(zu|Ru) can then be used to sample a user embedding zu for a personalized prediction, i.e., zu ∼ (cid:26)N (0, I) q(zu | Ru) for unconditional generation; for personalized prediction. (3)
In principle, one could ﬁt an individual variational distribution q(zu|Ru) for each user u. As this would be expensive, we instead use amortized VI [Kingma and Welling, 2014] We ﬁrst model q(zu|Ru) by a mixture of experts [Shi et al., 2019] where each expert q(zu|Hu) is conditioned only on a single reference sequence Hu ∈ Ru, q(zu | Ru) = 1 nu (cid:80)nu i=1 q(zu | Hu,i). (4) q(zu | Ru) represents the various modes of dynamics for a given user u as deﬁned by their past sequences Ru. Further, each expert distribution q(zu|Hu) is a fully factorized normal distribution where the means µ and variances σ2 are further parameterized by an encoder neural network ENCφ with parameters φ that are shared across all users, q(zu | Hu) = N (cid:0)zu; µ, diag(σ2)(cid:1) where (µ, log σ) = ENCφ(Hu). (5)
ENCφ contains a bidirectional RNN (more speciﬁcally gated recurrent units) that takes embedded times and marks of the reference sequence as inputs. The mark embeddings are learned and the time embeddings are continuous versions of the ﬁxed positional embeddings [Cho et al., 2014,
Vaswani et al., 2017]. The last hidden states from both directions are concatenated and then linearly transformed to result in µ and log σ. Precise details for this process can be found in the supplement.
Eqs. 4-5 specify the variational family. We optimize over the variational parameters φ using standard methods for Black Box VI [Blei et al., 2017, Zhang et al., 2019a], i.e., by stochastic maximization of the evidence lower bound. 4
Distributions for Events Marked temporal point processes (MTPP) are a broad class of processes used for modeling seqeunces of events H. A common method to fully characterize a MTPP is through an intensity function,
λ(t|Ht) = lim
δ↓0 1
δ P (cid:0)|Ht+δ| − |Ht| = 1 (cid:12) (cid:12) Ht (cid:1), (6) where |Ht| counts the number of events up to time t. The intensity function measures the instantaneous rate of occurrence for events at time t, conditioned on the history up until time t. Mark-speciﬁc intensity functions are deﬁned as the product of the overall intensity function and the conditional categorical distribution over marks, λk(t|Ht) = p(k|t, Ht)λ(t|Ht). We denote the vector of rates
#»
λ (t|Ht). The log-likelihood of a sequence H works out to be over all marks as log p(H) = (cid:80)|H| i=1 log λki(ti|Hti ) − (cid:82) T
Intuitively, the summation in the ﬁrst term rewards the model when the intensity values are high for the actual observed marks within the history, whereas the negative integral term penalizes high overall intensity values when there is no event. 0 λ(t|Ht)dt. (7)
Intensity functions have been parameterized in both simple forms for interpretability as well as with neural networks for ﬂexibility. Our proposed approach can in principle be used to add personalization to most existing neural MTPP models. We selected two of the most well-known and widely-cited such models to serve as base architectures which we extend for personalization as described in Sec. 2:
• The Recurrent Marked Temporal Point Process (RMTPP) [Du et al., 2016], which parameterizes
−→
λ RMTPP(t|Ht) = the intensity function explicitly as a piece-wise exponentially decaying rate: exp{W hi + w(t − ti) + b}, where ti < t ≤ ti+1, and W , w, and b are learnable parameters. For this model, fDec from Eq. 2 is a gated recurrent unit (GRU).
• The Neural Hawkes Process (NHP) [Mei and Eisner, 2017], which describes a procedure to
−→
λ NHP(t|Ht) = softplus(W hi(t)) where W is a obtain an interpolated hidden state h(t), deﬁnes learnable matrix with ti < t ≤ ti+1. and has fDec from Eq. 2 be a continuous-time LSTM unit. t , zu). Note that by deﬁning t , zu) and fDec, we effectively deﬁne p(ti+1, ki+1 | hi, zu) in Eq. 2, as well as the general
By incorporating zu as speciﬁed in Eq. 2,
−→
λ (t|Hu decoding process, DECθ. t ) becomes
−→
λ (t|Hu
−→
λ (t|Hu
All MTPP models can be sampled via a thinning procedure [Ogata, 1981], if not directly. Similarly, the integral in Eq. 7 can be computed by Monte-Carlo estimation, if not analytically. In our experiments, we perform the former for all models for consistency. More precise details on this can be found in the supplement.
Optimization The objective function for the proposed personalized neural MTPP models is the
β − VAE objective [Higgins et al., 2016] which is deﬁned for a single target sequence Hu as:
Lβ(φ, θ; Hu) = Eqφ(zu|Ru)[log pθ(Hu|zu)] − βKL(qφ(zu|Ru)||p(zu)), which the right-hand side is a variant of what is known as the evidence lower bound (ELBO). The expectation is estimated with a Monte-Carlo estimate. During training, a single sample for the estimate turned out to be sufﬁcient, whereas during testing we utilized 5 samples to reduce variance. (8) 4 Experimental Results
To measure the effectiveness of this framework in general, using the NHP and RMTPP base models we trained each in their standard conﬁguration (i.e., a decoder-only setup) and in the proposed variational mixture-of-experts setup (referred to as MoE-NHP and MoE-RMTPP).2 We rated these models on their held-out log-likelihood values, next event predictions, and user/source identiﬁcation capabilities as described below.3 Furthermore, all tests were conducted using sequences from new users to emphasize the added ability to adapt to new sources. 2Our source code for modeling and experiments can be found at the following repository: https://github. com/ajboyd2/vae_mpp. 3Sampling quality was also evaluated. Details and results can be found in the Supplement. 5
Table 1: Statistics for the four datasets. Columns (left to right) are: total time window T for every sequence; number K of unique marks; mean sequence length |H|; mean number |Ru| of sequences per user; total number of sequences and number of unique users in training/validation/test splits.
Dataset
Meme
Reddit
Amazon
LastFM 1 Day
T 1 Week 1 Week 1 Month
K 5000 1000 737 15
Mean Mean
|Ru|
|H| 6.9 23.4 4.9 65.2 4.0 10.7 347 45.6
# Sequences
Train Valid 271K 343K 262K 289K
Test 9K 21K 15K 34K 8K 20K 15K 49K
# Unique Users
Train Valid Test 3K 31K 7K 49K 5K 28K 105 833 1K 3K 2K 44
Models were trained by minimizing Eq. 7 and Eq. 8, averaged over training sequences, for the decoder-only and MoE variants respectively via the Adam optimizer with default hyperparameters
[Kingma and Ba, 2014] and a learning rate of 0.001. A linear warm-up schedule for the learning rate over the ﬁrst training epoch was used as it led to more stable training across runs. We also performed cyclical annealing on β in Eq. 8 from 0 to 0.001 with a period of 20% of an epoch to help prevent the posterior distribution from collapsing to the prior [Fu et al., 2019]. 4.1 Datasets
All models were trained and evaluated on four real-world datasets (see Table 1). The MemeTracker dataset [Leskovec and Krevl, 2014] relates to common phrases (memes). We deﬁned the meme as the “user” and the website it was posted to as the mark. The mark vocabulary is the set of top 5000 websites by volume of utterances. Sequences were deﬁned as one-week-long chunks spanning
August 2008 to April 2009, and event times were measured in hours. The Reddit comments dataset
[Baumgartner et al., 2020] relates to user-comments on posts in the social media site reddit.com.
One month of data (October 2018) was used to extract user sequences, and the mark vocabulary was deﬁned as the top 1000 communities (subredits) by comment volume. The month was divided into multiple sequences consisting of week-long windows per user, with event times in units of hours.
Amazon Reviews [Ni et al., 2019] consists of timestamped product reviews between May 1996 and
October 2018, with marks deﬁned as 737 different product categories. User sequences were deﬁned as 4-week windows with event times in units of days (with a small amount of uniformly distributed noise to avoid having multiple events co-occur). The 4th dataset, LastFM [Celma, 2010], has time-stamped records of songs listened to (both artists and track names) for nearly 1,000 users on the last.fm website. Marks were deﬁned as one of 15 possible genres for a song, via the discogs.com API.
User sequences corresponded to 1 day of listening in units of hours. For all datasets event times were calculated relative to the start-time of a user sequence. All datasets were ﬁltered to include sequences with at least ﬁve events and no more than 200. Training, validation, and test sets were split so that there were no users in common between them. 4.2 Results
Training Data Size Ablation We ﬁrst investigate differences in predictive performance between the two proposed Mixture of Experts (MoE) models and their decoder-only counterparts, as a function of the size of the training data. We therefore trained each model on various subsets of the training data, using 10%, 20%, 30%, 50%, 70%, 90%, and 100% of the full training set. For efﬁciency reasons, we generated these trained models using curriculum learning, i.e., we ﬁrst trained each model on the 10% subset until convergence, then added 10% more training points and trained on the resulting 20% subset, and so on. Convergence on each subset was determined when validation log-likelihood improved by less than 0.1. The training subsets were generated via random sampling of users. All models were evaluated on the same ﬁxed-size test dataset.
The results can be seen in Figure 3(a). The proposed MoE models (solid lines) systematically yield better predictions in terms of test log-likelihood over their non-MoE counterparts (dotted lines). This trend suggests that our personalization scheme could beneﬁt most, if not all, neural MTPP models and that these beneﬁts appear for even small amounts of training data.
Likelihood Over Time Having seen that the proposed MoE models have better predictive log-likelihoods than their decoder-only counterparts, we now investigate where exactly they achieve these 6
Figure 3: (a) Mean test negative log-likelihood performance for models trained at varying percentages of the training data across the four datasets and (b) mean test cross entropy up to time t (see Eq. 9) for models trained on 100% of the training data (lower is better for both). Results for NHP-based models are shown in blue, RMTPP models are orange, decoder-only models are dotted lines, and the proposed mixture-of-experts models are solid lines. performance gains. Using λk(t|Ht) = p(k|t, Ht)λ(t|Ht), we can factor Eq. 7 as follows:
− log p(H) = |H| (cid:0)SCE(H) + PP+(H)(cid:1) + T PP−(H) (9) (cid:80)|Ht| where SCE(Ht) ≡ −1 i=1 log p(ki|ti, Hti), is the average cross entropy of a sequential, non-|Ht| i=1 log λ(ti|Hti), PP−(Ht) ≡ continuous time based, classiﬁcation model, and PP+(Ht) ≡ −1
|Ht| (cid:82) t 1 0 λ(τ |Hτ )dτ respectively represent the average positive and negative evidence of a sequence, t ignoring the associated marks (the two together make up the terms in the log-likelihood of a non-marked temporal point process). All of these terms can assist in identifying issues within MTPPs, especially when investigated as a function of t. We presume that most of the heterogeneity between sequences in datasets resides in the categorical distributions of marks. Here we focus our analysis on the SCE term—see the supplementary material for discussion of other terms. (cid:80)|Ht|
Figure 3(b) shows average SCE values over time. The decoder-only models (dotted) tend to have high
SCE values near the beginning of sequences (left side of x-axis), as the model adapts to the type of sequence and user it is making predictions for. In contrast, the MoE models (solid) have much lower
SCE near the beginning of sequences, i.e., are making signiﬁcantly better categorical predictions for marks early on. The decoder-only models gradually approach the performance of the MoE models over time, but never close the gap, indicating the user information (via zu) provides signiﬁcant beneﬁt in mark prediction that is difﬁcult for an RNN decoder model to learn from the sequence itself.
Ranking of Next Event Predictions One use case of MTPP models is to predict what a user will do next and when they will do it during an ongoing sequence. As an example scenario, we conditioned the models on a preﬁx Hu t10 of the ﬁrst 10 events in each test sequence and evaluated the predictive performance for the next event (t11, k11). Predicted times and marks were estimated by marginalizing over marks and times respectively to minimize Bayes risk, similar to Mei and Eisner [2017]—see the supplement for details. The choice of 10 events in the preﬁx was made to simulate making predictions early in a sequence, where there is still a good deal of variability for the next event.
The predicted marks were evaluated by the ranking of the true mark’s predicted probability, averaged over all sequences in the test set for each dataset. Table 2(a) shows our results. MoE models achieve superior performance than the other models on all datasets, with particularly large gains for the Meme and Reddit data. The results for predicted times were not found to be consistently different between the MoE and non-personalized models. One possible reason for this might be that there is not a strong user-speciﬁc signal in event timing information that cannot already be detected in the sequence being 7
Table 2: (a) Mean predicted mark rank for the proposed MoE-NHP and MoE-RMTPP models versus the non-personalized NHP and RMTPP models. More precision is shown for datasets with fewer total marks. (b) Source identiﬁcation error rates for MoE-NHP, MoE-RMTPP, and Bayesian
Poisson process baseline across the four datasets. For both, lower percentages are better and the best performance within a grouping is bolded. In all categories, one of our proposed models is the best. (a) Mean Predicted Rank (ˆk11)
Dataset MoE-NHP NHP MoE-RMTPP RMTPP
Meme
Reddit
Amazon
LastFM 159 35.6 22.9 2.04 283 35.2 22.8 2.04 143 20.0 21.6 2.01 225 19.4 21.6 2.02 (b) Source Identiﬁcation Error Rate
Dataset MoE-NHP MoE-RMTPP Bayes PP
Meme 5.04% 1.38%
Reddit 8.34%
Amazon
LastFM 28.44% 4.64% 2.02% 9.94% 33.90% 9.18% 3.24% 12.88% 39.94% decoded, thus causing the personalization models to focus more on event types than on times. In terms of predictive performance, it appears that the biggest beneﬁt of personalization is more accurate predictions of marks rather than times. All results for predicted times can be found in the supplement.
Source Identiﬁcation The personalized MoE models naturally lend themselves to being able to detect anomalous events for a given user. We evaluate how well the models can identify the source of a given event sequence. As discussed in Sec. 2, the MoE models were designed such that conditioning on a user embedding, subsequent sequences from the same user would be more likely (hence being personalized), and in turn sequences from different users would be less likely. We assessed this behavior on all four datasets by randomly selecting target sequences and pairing them up with one reference sequence from the same user and one reference sequence from a different user. After conditioning on the reference sequences, the models evaluated the likelihood of the target sequence and the two results were ranked amongst each other. This was done 5,000 times for each test dataset (10,000 total likelihood calculations each). The target sequences were truncated to 10 events in order to simulate identifying users from only a portion of events into a session.
The MoE-NHP and MoE-RMTPP models were compared against a Bayesian Poisson process baseline with a Gamma prior where the prior expected value was determined by the MLE of the training data and the strength of the prior was tuned on the validation set. Each target sequence was then evaluated on the posterior distribution conditioned on the reference sequence—more details can be found in the supplement. The results in Table 2(b) show that both of the MoE models have signiﬁcantly lower error rates than the baseline on this task, across all four datasets. 5