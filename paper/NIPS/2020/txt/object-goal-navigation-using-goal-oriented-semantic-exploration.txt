Abstract
This work studies the problem of object goal navigation which involves navigating to an instance of the given object category in unseen environments. End-to-end learning-based navigation methods struggle at this task as they are ineffective at exploration and long-term planning. We propose a modular system called, ‘Goal-Oriented Semantic Exploration’ which builds an episodic semantic map and uses it to explore the environment efﬁciently based on the goal object category. Empirical results in visually realistic simulation environments show that the proposed model outperforms a wide range of baselines including end-to-end learning-based methods as well as modular map-based methods and led to the winning entry of the CVPR-2020 Habitat ObjectNav Challenge. Ablation analysis indicates that the proposed model learns semantic priors of the relative arrangement of objects in a scene, and uses them to explore efﬁciently. Domain-agnostic module design allows us to transfer our model to a mobile robot platform and achieve similar performance for object goal navigation in the real-world.

Introduction 1
Autonomous navigation is a core requirement in building intelligent embodied agents. Consider an autonomous agent being asked to navigate to a ‘dining table’ in an unseen environment as shown in
Figure 1. In terms of semantic understanding, this task not only involves object detection, i.e. what does a ‘dining table’ look like, but also scene understanding of where ‘dining tables’ are more likely to be found. The latter requires a long-term episodic memory as well as learning semantic priors on the relative arrangement of objects in a scene. Long-term episodic memory allows the agent to keep track of explored and unexplored areas. Learning semantic priors allows the agent to also use the episodic memory to decide which region to explore next in order to ﬁnd the target object in the least amount of time.
How do we design a computational model for building an episodic memory and using it effectively based on semantic priors for efﬁcient navigation in unseen environments? One popular approach is to use end-to-end reinforcement or imitation learning with recurrent neural networks to build episodic memory and learn semantic priors implicitly [31, 17, 50, 32]. However, end-to-end learning-based methods suffer from large sample complexity and poor generalization as they memorize object locations and appearance in training environments.
Recently, Chaplot et al. [10] introduced a modular learning-based system called ‘Active Neural
SLAM’ which builds explicit obstacle maps to maintain episodic memory. Explicit maps also allow analytical path planning and thus lead to signiﬁcantly better exploration and sample complexity.
However, Active Neural SLAM, designed for maximizing exploration coverage, does not encode
†Correspondence: chaplot@cs.cmu.edu
∗Equal Contribution 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
Figure 1: Semantic Skills required for Object Goal navigation. Efﬁcient Object Goal navigation not only requires passive skills such as object detection, but also active skills such as an building an episodic memory and using it effective to learn semantic priors abour relative arrangements of objects in a scene. semantics in the episodic memory and thus does not learn semantic priors. In this paper, we extend the Active Neural SLAM system to build explicit semantic maps and learn semantic priors using a semantically-aware long-term policy.
The proposed method, called ‘Goal-Oriented Semantic Exploration’ (SemExp), makes two improve-ments over [10] to tackle semantic navigation tasks. First, it builds top-down metric maps similar to [10] but adds extra channels to encode semantic categories explicitly. Instead of predicting the top-down maps directly from the ﬁrst-person image as in [10], we use ﬁrst-person predictions fol-lowed by differentiable geometric projections. This allows us to leverage existing pretrained object detection and semantic segmentation models to build semantic maps instead of learning from scratch.
Second, instead of using a coverage maximizing goal-agnostic exploration policy based only on obstacle maps, we train a goal-oriented semantic exploration policy which learns semantic priors for efﬁcient navigation. These improvements allow us to tackle a challenging object goal navigation task.
Our experiments in visually realistic simulation environments show that SemExp outperforms prior methods by a signiﬁcant margin. The proposed model also won the CVPR 2020 Habitat ObjectNav
Challenge [3]3. We also demonstrate that SemExp achieves similar performance in the real-world when transferred to a mobile robot platform. 2