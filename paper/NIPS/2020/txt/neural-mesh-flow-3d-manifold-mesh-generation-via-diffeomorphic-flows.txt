Abstract
Meshes are important representations of physical 3D entities in the virtual world.
Applications like rendering, simulations and 3D printing require meshes to be manifold so that they can interact with the world like the real objects they represent.
Prior methods generate meshes with great geometric accuracy but poor manifold-ness. In this work we propose Neural Mesh Flow (NMF) to generate two-manifold meshes for genus-0 shapes. Speciﬁcally, NMF is a shape auto-encoder consisting of several Neural Ordinary Differential Equation (NODE)[1] blocks that learn accurate mesh geometry by progressively deforming a spherical mesh. Training
NMF is simpler compared to state-of-the-art methods since it does not require any explicit mesh-based regularization. Our experiments demonstrate that NMF facil-iates several applications such as single-view mesh reconstruction, global shape parameterization, texture mapping, shape deformation and correspondence. Impor-tantly, we demonstrate that manifold meshes generated using NMF are better-suited for physically-based rendering and simulation. Code and data are released.1

Introduction 1
Polygon meshes allow an efﬁcient virtual representation of 3D objects, enabling applications in graphics rendering, simulations, modeling and manufacturing. Consequently, mesh generation or reconstruction from images or point sets has received signiﬁcant recent attention. While prior approaches have primarily focused on obtaining geometrically accurate reconstructions, we posit that physically-based applications require meshes to also satisfy manifold properties. Intuitively, a mesh is manifold if it can be physically realized, for example, by 3D printing. Typically, reconstructed meshes are post-processed with humans in the loop for manifoldness, in order to enable ray tracing, slicing or Boolean operations. In contrast, we propose a novel deep network that directly generates manifold meshes (Fig. 1), alleviating the need for manual post-processing.
A manifold is a topological space that locally resembles Euclidean space in the neighbourhood of each point. A manifold mesh is a discretization of the manifold using a disjoint set of simple 2D polygons, such as triangles, which allows designing simulations, rendering and other manifold calculations.
While a mesh data structure can simply be deﬁned as a set (V, E, F) of vertices V and corresponding edges E or face F, not every mesh (V, E, F) is manifold. Mathematically, we list various constraints on a singly connected mesh with the set (V, E, F) that enables manifoldness2.
• Each edge e ∈ E is common to exactly 2 faces in F (Fig. 2a)
• Each vertex v ∈ V is shared by exactly one group of connected faces (Fig. 2b)
• Adjacent faces Fi, Fj have normals oriented in same direction (Fig. 2c) 1https://kunalmgupta.github.io/projects/NeuralMeshflow.html and try our colab notebook. 2In the scope of this work, meshes do not exhibit defects like duplicate elements, isolated vertices, degenerate faces and inner surfaces that can also cause a mesh to be non-manifold. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
MeshRCNN[2]
AtlasNet[3]
AtlasNet-O[3]
Pixel2Mesh[4]
GEOMetrics[5] 3D-R2N2[6]
PSG[7]
OccNet[8]
Approach Vertex Edge (cid:55) (cid:51) (cid:51) (cid:51) (cid:51) (cid:55) (cid:55) (cid:55) explicit explicit explicit explicit explicit implicit implicit implicit (cid:55) (cid:55) (cid:51) (cid:51) (cid:51) (cid:55) (cid:55) (cid:55)
Face Non-Int. (cid:55) (cid:55) (cid:55) (cid:55) (cid:55) (cid:55) (cid:55) (cid:55) (cid:55) (cid:55) (cid:51) (cid:51) (cid:51) (cid:51) (cid:51) (cid:51)
NMF (Ours) explicit (cid:51) (cid:51) (cid:51) (cid:51) (a) Inputs (b) Manifoldness of prior work
Figure 1: Given an input as either a 2D image or a 3D point cloud (a) Existing methods generate corresponding 3D mesh that fail one or more manifoldness conditions (b) yielding unsatisfactory results for various applications including physically based rendering (c). NeuralMeshFlow generates manifold meshes which can directly be used for high resolution rendering, physics simulations (see supplementary video) and be 3D printed without the need for any prepossessing or repair effort. (c) Applications enabled by NMF Manifold Meshes
Figure 2: Non-manifold geometries for a part of singly connected mesh: (a) An edge that is shared by either exactly one (red) or more than two (red dashed) faces. (b) A vertex (red) shared by more than one group of connected faces. (c)
Adjacent faces that have normals (red-arrow) oriented in opposite directions. (d) Faces intersecting other triangles of the same mesh.
The above mentioned constraints on a mesh (V, E, F) guarantee it to be a manifold in the limit of inﬁnitesimally small discretization. That is not the case when dealing with practical meshes with large and non-uniformly distributed triangles. To ensure physical realizability, we tighten the deﬁnition with a fourth practical constraint that no two triangles may intersect (Fig. 2d).
In this work, we pose the task of 3D shape generation as learning a diffeomorphic ﬂow from a template genus-0 manifold mesh to a target mesh. Our key insight is that manifoldness is conserved under a diffeomorphic ﬂow due to their uniqueness [9, 10] and orientation preserving property [11, 12]. In contrast to methods that learn “deformations” of a template manifold using an MLP or graph-based network [3–5], our approach ensures manifoldness of the generated mesh. We use Neural ODEs
[1] to model the diffeomorphic ﬂow, however, must overcome their limited capability to represent a wide variety of shapes [9, 10, 13], which has restricted prior works to single-category representations
[14, 15]. We propose novel architectural features such as an instance normalization layer that enables generating 3D shapes across multiple categories and a series of diffeomorphic ﬂows to gradually reﬁne the generated mesh. We show quantitative comparisons to prior works and more importantly, compare resulting meshes on physically meaningful tasks such as rendering, simulation and 3D printing to highlight the importance of manifoldness.
Toy example: regularizer’s dilemma Consider the task of deforming a template unit spherical mesh S (Fig. 3a) into a target star mesh T (Fig. 3b). We approximate the deformation with a multi-layer perceptron (MLP) fθ with a unit hidden layer of 256 neurons with relu and output layer with tanh activation. We train fθ by minimizing various losses over the points sampled from
S, T . A conventional approach involves minimizing the Chamfer Distance Lc between S, T , leading to accurate point predictions but several edge-intersections (Fig. 3c). By introducing edge length regularization [4] Le, we get fewer edge-intersections (Fig. 3d) but the solution is also geometrically sub-optimal. We can further reduce edge-intersections with Laplacian regularization [4] (Fig. 3e), but this takes a bigger toll on geometric accuracy. Thus, attempting to reduce self-intersections by explicit regularization not only makes the optimization hard, but can also lead to predictions with lower geometric accuracy. In contrast, our proposed use of NODE (with dynamics fθ) is designed by construction [9, 10] to prevent self-intersections without explicit regularization (Fig. 3f).
In summary, we make the following contributions:
• A novel approach to 3D mesh generation, Neural Mesh Flow (NMF), with a series of NODEs that learn to deform a template mesh (ellipsoid) into a target mesh with greater manifoldness. 2
Figure 3: 2D Toy Example: For the task of deforming a manifold template mesh (a) to a target mesh (b) using explicit mesh regularization (c-e) trades edge-intersections for geometric accuracy . In contrast, a NODE [1] (f) is implicitly regularized preventing edge-intersections without loosing geometric accuracy.
• Extensive comparisons to state-of-the-art mesh generation methods for physically based rendering and simulation (see supplementary video), highlighting the advantage of NMF’s manifoldness.
• New metrics to evaluate manifoldness of 3D meshes and demonstration of applications to single-view reconstruction, 3D deformation, global parameterization and correspondence. 2