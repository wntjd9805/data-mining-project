Abstract
This paper presents a new matching-based framework for semi-supervised video object segmentation (VOS). Recently, state-of-the-art VOS performance has been achieved by matching-based algorithms, in which feature banks are created to store features for region matching and classiﬁcation. However, how to effectively organize information in the continuously growing feature bank remains under-explored, and this leads to an inefﬁcient design of the bank. We introduced an adaptive feature bank update scheme to dynamically absorb new features and discard obsolete features. We also designed a new conﬁdence loss and a ﬁne-grained segmentation module to enhance the segmentation accuracy in uncertain regions. On public benchmarks, our algorithm outperforms existing state-of-the-arts. 1

Introduction
Video object segmentation (VOS) is a fundamental step in many video processing tasks, like video editing and video inpainting. In the semi-supervised setting, the ﬁrst frame annotation is given, which depicts the objects of interest of the video sequence. The goal is to segment mask of that object in the subsequent frames. Many deep learning based methods have been proposed to solve this problem in recent years. When people tackle the semi-supervised VOS task, the segmentation performance is affected by two main steps: (1) distinguish the object regions from the background, (2) segment the object boundary clearly.
A key question in VOS is how to learn the cues of target objects. We divide recent works into two categories, implicit learning and explicit learning. Conventional implicit approaches include detection-based and propagation-based methods [3, 27, 10, 32, 2, 13, 23]. They often adopt the fully convolutional network (FCN) [20] pipeline to learn object features by the network weights implicitly; then, before segmenting a new video, these methods often need an online learning to ﬁne-tune their weights to learn new object cues from the video. Explicit approaches learn object appearance explicitly. They often formulate the segmentation as pixel-wise classiﬁcation in a learnt embedding space [31, 4, 24, 11, 33, 18, 12, 25, 17]. These approaches ﬁrst construct an embedding space to memorize the object appearance, then segment the subsequent frames by computing similarity.
Therefore, they are also called matching-based methods. Recently, matching-based methods achieve the state-of-the-art results in the VOS benchmark.
A fundamental issue in matching-based VOS segmentation is how to effectively exploit previous frames’ information to segment the new frame. Since the memory size is limited, it is not possible and unnecessary to memorize information from all the previous frames. Most methods [24, 33, 31, 18, 25] only utilize the ﬁrst and the latest frame or uniformly sample key frames. However, when the given video becomes longer, these methods often either miss sampling on some key-frames or encounter
∗Corresponding author. Codes are available at https://github.com/xmlyqing00/AFB-URR. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
out-of-memory crash. To tackle this problem, we propose an adaptive feature bank (AFB) to organize the target object features. This adaptive feature bank absorbs new features by weighted averaging and discards obsolete features according to the least frequently used (LFU) index. As results, our model could memorize the characteristics of multi objects and segment them simultaneously in long videos under a low memory consumption.
Besides identifying the target object, clearly segmenting object boundary is also critical to VOS performance: (1) People are often sensitive to boundary segmentation. (2) When estimated masks on some boundary regions are ambiguous and hard to classify, their misclassiﬁcaton is easily accumulated in video. However, most recent VOS methods follow an encoder-decoder mode to estimate the object masks, the boundary of the object mask becomes vague when it is iteratively upscaled from a lower resolution. Therefore, we propose an uncertain-region reﬁnement (URR) scheme to improve the segmentation quality. It includes a novel classiﬁcation conﬁdence loss to estimate the ambiguity of segmentation, and a local ﬁne-grained segmentation to reﬁne the ambiguous regions.
Our main contributions are three-folded: (1) We proposed an adaptive and efﬁcient feature bank to maintain most useful information for video object segmentation. (2) We introduced a conﬁdence loss to estimate the ambiguity of the segmentation results. We also designed a local ﬁne-grained segmentation module to reﬁne these ambiguous regions. (3) We demonstrated the effectiveness of our method on segmenting long videos, which are often seen in practical applications. 2