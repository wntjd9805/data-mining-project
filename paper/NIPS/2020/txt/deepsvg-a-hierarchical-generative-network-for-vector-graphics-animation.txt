Abstract
Scalable Vector Graphics (SVG) are ubiquitous in modern 2D interfaces due to their ability to scale to different resolutions. However, despite the success of deep learning-based models applied to rasterized images, the problem of vector graphics representation learning and generation remains largely unexplored. In this work, we propose a novel hierarchical generative network, called DeepSVG, for complex
SVG icons generation and interpolation. Our architecture effectively disentangles high-level shapes from the low-level commands that encode the shape itself. The network directly predicts a set of shapes in a non-autoregressive fashion. We introduce the task of complex SVG icons generation by releasing a new large-scale dataset along with an open-source library for SVG manipulation. We demonstrate that our network learns to accurately reconstruct diverse vector graphics, and can serve as a powerful animation tool by performing interpolations and other latent space operations. Our code is available at https://github.com/alexandre01/ deepsvg.
Figure 1: DeepSVG generates vector graphics by predicting draw commands, such as lines and
Bézier curves. Our latent space allows meaningful animations between complex vector graphics icons. 1

Introduction
Despite recent success of rasterized image generation and content creation, little effort has been directed towards generation of vector graphics. Yet, vector images, often in the form of Scalable
Vector Graphics [20] (SVG), have become a standard in digital graphics, publication-ready image assets, and web-animations. The main advantage over their rasterized counterpart is their scaling ability, making the same image ﬁle suitable for both tiny web-icons or billboard-scale graphics.
Generative models for vector graphics could serve as powerful tools, allowing artists to generate, manipulate, and animate vector graphics, potentially enhancing their creativity and productivity. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
(a) One-stage autoregressive (b) DeepSVG (ours)
Figure 2: One-stage autoregressive autoencoder architectures [5, 11, 17] (a) take the entire draw commands as input and decode the latent vector one command at a time. Our approach (b) exploits the hierarchical nature of vector graphics in both the encoder and decoder, and decodes the draw commands with a single forward pass (non-autoregressively).
Raster images are most often represented as a rectangular grid of pixels containing a shade or color value. The recent success of deep learning on these images much owes to the effectiveness of convolutional neural networks (CNNs) [9], learning powerful representations by taking advantage of the inherent translational invariance. On the other hand, vector images are generally represented as lists of 2D shapes, each encoded as sequence of 2D points connected by parametric curves. While this brings the task of learning SVG representations closer to that of sequence generation, there are fundamental differences with other applications, such as Natural Language Processing. For instance, similar to the translation invariance in raster images, an SVG image experiences permutation invariance as the order of shapes in an SVG image is arbitrary. This brings important challenges in the design of both architectures and learning objectives.
We address the task of learning generative models of complex vector graphics. To this end, we propose a Hierarchical Transformer-based architecture that effectively disentangles high-level shapes from the low-level commands that encode the shape itself. Our encoder exploits the permutation invariance of its input by ﬁrst encoding every shape separately, then producing the latent vector by reasoning about the relations between the encoded shapes. Our decoder mirrors this 2-stage approach by ﬁrst predicting, in a single forward pass, a set of shape representations along with their associated attributes. These vectors are ﬁnally decoded into sequences of draw commands, which combined produce the output SVG image. A schematic overview of our architecture is given in Fig. 2.
Contributions Our contributions are three-fold: 1. We propose DeepSVG, a hierarchical transformer-based generative model for vector graphics. Our model is capable of both encoding and predicting the draw commands that constitute an SVG image. 2. We perform comprehensive experiments, demonstrating successful interpolation and manipulation of complex icons in vector-graphics format.
Examples are presented in Fig. 1. 3. We introduce a large-scale dataset of SVG icons along with a framework for deep learning-based SVG manipulation, in order to facilitate further research in this area. To the best of our knowledge, this is the ﬁrst work to explore generative models of complex vector graphics, and to show successful interpolation and manipulation results for this task. 2