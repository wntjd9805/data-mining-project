Abstract
Convex relaxations have emerged as a promising approach for verifying desirable properties of neural networks like robustness to adversarial perturbations. Widely used Linear Programming (LP) relaxations only work well when networks are trained to facilitate veriﬁcation. This precludes applications that involve veriﬁcation-agnostic networks, i.e., networks not specially trained for veriﬁcation. On the other hand, semideﬁnite programming (SDP) relaxations have successfully be applied to veriﬁcation-agnostic networks, but do not currently scale beyond small networks due to poor time and space asymptotics. In this work, we propose a ﬁrst-order dual SDP algorithm that (1) requires memory only linear in the total number of network activa-tions, (2) only requires a ﬁxed number of forward/backward passes through the net-work per iteration. By exploiting iterative eigenvector methods, we express all solver operations in terms of forward and backward passes through the network, enabling efﬁcient use of hardware like GPUs/TPUs. For two veriﬁcation-agnostic networks on MNIST and CIFAR-10, we signiﬁcantly improve ` veriﬁed robust accuracy from 1% 40% respectively. We also demonstrate tight veriﬁcation of a quadratic stability speciﬁcation for the decoder of a variational autoencoder. 88% and 6%
Ñ
Ñ 8 1

Introduction
Applications of neural networks to safety-critical domains requires ensuring that they behave as expected under all circumstances [32]. One way to achieve this is to ensure that neural networks conform with a list of speciﬁcations, i.e., relationships between the inputs and outputs of a neural network that ought to be satisﬁed. Speciﬁcations can come from safety constraints (a robot should never enter certain unsafe states [40, 29, 12]), prior knowledge (a learned physical dynamics model should be consistent with the laws of physics [49]), or stability considerations (certain transformations of the network inputs should not signiﬁcantly change its outputs [57, 7]).
Evaluating whether a network satisﬁes a given speciﬁcation is a challenging task, due to the difﬁculty of searching for violations over the high dimensional input spaces. Due to this, several techniques that claimed to enhance neural network robustness were later shown to break under stronger attacks
[61, 5]. This has motivated the search for veriﬁcation algorithms that can provide provable guarantees on neural networks satisfying input-output speciﬁcations.
Popular approaches based on linear programming (LP) relaxations of neural networks are compu-tationally efﬁcient and have enabled successful veriﬁcation for many speciﬁcations [37, 18, 30, 21].
LP relaxations are sound (they would never incorrectly conclude that a speciﬁcation is satisﬁed) but
˚ Equal contribution. Alphabetical order.
: Code available at https://github.com/deepmind/jax_verify. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
incomplete (they may fail to verify a speciﬁcation even if it is actually satisﬁed). Consequently, these approaches tend to give poor or vacuous results when used in isolation, though can achieve strong results when combined with speciﬁc training approaches to aid veriﬁcation [22, 51, 67, 21, 54, 6].
In contrast, we focus on veriﬁcation-agnostic models, which are trained in a manner agnostic to the veriﬁcation algorithm. This would enable applying veriﬁcation to all neural networks, and not just those trained to be veriﬁable. First, this means training procedures need not be constrained by the need to verify, thus allowing techniques which produce empirically robust networks, which may not be easily veriﬁed [38]. Second, ML training algorithms are often not easily modiﬁable, e.g. production-scale ML models with highly speciﬁc pipelines. Third, for many tasks, deﬁning formal speciﬁcations is difﬁcult, thus motivating the need to learn speciﬁcations from data. In particular, in recent work [24, 50, 66], natural perturbations to images like changes in lighting conditions or changes in the skin tone of a person, have been modeled using perturbations in the latent space of a generative model. In these cases, the speciﬁcation itself is a veriﬁcation-agnostic network which the veriﬁcation must handle even if the prediction network is trained with the veriﬁcation in mind.
In contrast to LP-based approaches, the semideﬁnite programming (SDP) relaxation [52] has enabled robustness certiﬁcation of veriﬁcation-agnostic networks. However, the interior point methods n4 commonly used for SDP solving are computationally expensive with O q p memory requirements, where n is the number of neurons in the network [41, 60]. This limits applicability of SDPs to small fully connected neural networks. runtime and O n6 p q
Within the SDP literature, a natural approach is to turn to ﬁrst-order methods, exchanging precision for scalability [63, 53]. Because veriﬁcation only needs a bound on the optimal value of the relaxation (and not the optimal solution), we need not design a general-purpose SDP solver, and can instead operate directly in the dual. A key beneﬁt is that the dual problem can be cast as minimizing the maximum eigenvalue of an afﬁne function, subject only to non-negativity constraints. This is a standard technique used in the SDP literature [25, 42] and removes the need for an expensive projection operation onto the positive semideﬁnite cone. Further, since any set of feasible dual variables provides a valid upper bound, we do not need to solve the SDP to optimality as done previously [52], and can instead stop once a sufﬁciently tight upper bound is attained.
In this paper, we show that applying these ideas to neural network veriﬁcation results in an efﬁcient n4 implementation both in theory and practice. Our solver requires O q p for interior point methods, and each iteration involves a constant number of forward and backward passes through the network. memory rather than O n p q
Our contributions. The key contributions of our paper are as follows: 1. By adapting ideas from the ﬁrst-order SDP literature [25, 42], we observe that the dual of the SDP formulation for neural network veriﬁcation can be expressed as a maximum eigenvalue problem with only interval bound constraints. This formulation generalizes [52] without loss of tightness, and applies to any quadratically-constrained quadratic program (QCQP), including the standard adversarial robustness speciﬁcation and a variety of network architectures.
Crucially, when applied to neural networks, we show that subgradient computations are expressible purely in terms of forward or backward passes through layers of the neural network. Consequently, applying a subgradient algorithm to this formulation achieves per-iteration complexity comparable to a constant number of forward and backward passes through the neural network. 2. We demonstrate the applicability of ﬁrst-order SDP techniques to neural network veriﬁcation. We
ﬁrst evaluate our solver by verifying ` robustness of a variety of veriﬁcation-agnostic networks on
MNIST and CIFAR-10. We show that our approach can verify large networks beyond the scope of existing techniques. For these veriﬁcation-agnostic networks, we obtain bounds an order of magni-tude tighter than previous approaches (Figure 1). For an adversarially trained convolutional neural network (CNN) with no additional regularization on MNIST (✏ 0.1), compared to LP relaxations, we improve the veriﬁed robust accuracy from 1% to 88%. For the same training and architecture on CIFAR-10 (✏ 255), the corresponding improvement is from 6% to 40% (Table 1).
{
“
“ 2 8 3. To demonstrate the generality of our approach, we verify a different quadratic speciﬁcation on the stability of the output of the decoder for a variational autoencoder (VAE). The upper bound on speciﬁcation violation computed by our solver closely matches the lower bound on speciﬁcation violation (from PGD attacks) across a wide range of inputs (Section 6.2). 2
2