Abstract
We extensively study how to combine Generative Adversarial Networks and learned compression to obtain a state-of-the-art generative lossy compression system.
In particular, we investigate normalization layers, generator and discriminator architectures, training strategies, as well as perceptual losses. In contrast to previous work, i) we obtain visually pleasing reconstructions that are perceptually similar to the input, ii) we operate in a broad range of bitrates, and iii) our approach can be applied to high-resolution images. We bridge the gap between rate-distortion-perception theory and practice by evaluating our approach both quantitatively with various perceptual metrics, and with a user study. The study shows that our method is preferred to previous approaches even if they use more than 2 the bitrate.
× 1

Introduction
The ever increasing availability of cameras produces an endless stream of images. To store them efﬁciently, lossy image compression algorithms are used in many applications. Instead of storing the raw RGB data, a lossy version of the image is stored, with—hopefully—minimal visual changes to the original. Various algorithms have been proposed over the years [50, 43, 54], including using state-of-the-art video compression algorithms for single image compression (BPG [7]). At the same time, deep learning-based lossy compression has seen great interest [45, 5, 31], where a neural network is directly optimized for the rate-distortion trade-off, which led to new state-of-the-art methods.
However, all of these approaches degrade images signiﬁcantly as the compression factor increases.
While classical algorithms start to exhibit algorithm-speciﬁc artifacts such as blocking or banding, learning-based approaches reveal issues with the distortion metric that was used to train the networks.
Despite the development of a large variety of “perceptual metrics” (e.g., (Multi-Scale) Structural
Similarity Index ((MS-)SSIM) [53, 52], Learned Perceptual Image Patch Similarity (LPIPS) [57]), the weakness of each metric is exploited by the learning algorithm, e.g., checkerboard artifacts may appear when targeting neural network derived metrics, relying on MS-SSIM can cause poor text reconstructions, and MSE yields blurry reconstructions.
In [3], Agustsson et al. demonstrated the potential of using GANs to prevent compression artifacts with a compression model that produces perceptually convincing reconstructions for extremely low bitrates (<0.08 bpp). However, their reconstructions tend to only preserve high-level semantics, deviating signiﬁcantly from the input.
Recent work by Blau and Michaeli [9] characterized this phenomenon by showing the existence of a triple “rate-distortion-perception” trade-off, formalizing “distortion” as a similarity metric comparing pairs of images, and “perceptual quality” as the distance between the image distribution pX and the distribution of the reconstructions p ˆX produced by the decoder, measured as a distribution divergence.
They show that at a ﬁxed rate, better perceptual quality always implies worse distortion. Conversely, only minimizing distortion will yield poor perceptual quality. To overcome this issue, distortion can
∗Work done while interning at Google Research.
†Work done while at Google Research.
Project page and demo: hific.github.io
Correspondence: eirikur@google.com 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
Original
Original
HiFiCLo: 0.198bpp
HiFiCLo: 0.198bpp
BPG: 0.224bpp
BPG: 0.224bpp
BPG: 0.446bpp
HiFiCLo (Ours): 0.198bpp
Original
Figure 1: Comparing our method, HiFiC, to the original, as well as BPG at a similar bitrate and at the bitrate. We can see that our GAN model produces a high-ﬁdelity reconstruction that is very 2
× close to the input, while BPG exhibits blocking artifacts, that are still present at double the bitrate. In the background, we show a split to the original to further indicate how close our reconstruction is.
We show many more visual comparisons in Appendix B, including more methods, more bitrates, and
Best viewed on screen. various datasets.
BPG: 0.446bpp be traded for better perceptual quality by minimizing the mismatch between the distributions of the input and the reconstruction, e.g., with Generative Adversarial Networks (GANs) [17]. While [9] presents comprehensive theoretical results, the rate-distortion-perception trade-off is only explored empirically on toy datasets.
In this paper, we address these issues with the following contributions:
× 1. We propose a generative compression method to achieve high quality reconstructions that are very close to the input, for high-resolution images (we test up to 2000 2000 px). In a user study, we show that our approach is visually preferred to previous approaches even when these approaches use more than 2 higher bitrates, see Fig. 3.
× 2. We quantitatively evaluate our approach with FID [18], KID [8], NIQE [35], LPIPS [57], and the classical distortion metrics PSNR, MS-SSIM, and show how our results are consistent with the rate-distortion-perception theory. We also show that no metric would have predicted the full ranking of the user study, but that FID and KID are useful in guiding exploration. Considering this ensemble of diverse perceptual metrics including no-reference metrics, pair-wise similarities, and distributional similarities, as well as deep feature-based metrics derived from different network architectures, ensures a robust perceptual evaluation. 3. We extensively study the proposed architecture and its components, including normalization layers, generator and discriminator architectures, training strategies, as well as the loss, in terms of perceptual metrics and stability. 2