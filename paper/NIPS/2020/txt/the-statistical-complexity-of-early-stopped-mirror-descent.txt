Abstract
Recently there has been a surge of interest in understanding implicit regu-larization properties of iterative gradient-based optimization algorithms. In this paper, we study the statistical guarantees on the excess risk achieved by early-stopped unconstrained mirror descent algorithms applied to the unregularized empirical risk with the squared loss for linear models and kernel methods. By completing an inequality that characterizes convexity for the squared loss, we identify an intrinsic link between oﬀset Rademacher complexities and potential-based convergence analysis of mirror descent methods. Our observation immediately yields excess risk guarantees for the path traced by the iterates of mirror descent in terms of oﬀset complexities of certain function classes depending only on the choice of the mirror map, initialization point, step-size, and the number of iterations. We apply our theory to recover, in a clean and elegant manner via rather short proofs, some of the recent results in the implicit regularization literature, while also showing how to improve upon them in some settings.1 1

Introduction
In a typical statistical learning setup, we observe a dataset Dn of n input-output pairs (xi, yi) ∈ Rd × R sampled i.i.d. from some unknown distribution P . When learning with respect to the quadratic loss, the goal is to output a function bg = bg(Dn) : Rd → R which minimizes the risk R(bg) deﬁned as follows, for any square-integrable function g:
R(g) = E(X,Y )∼P h (g(X) − Y )2i
.
Among the most studied statistical estimators is the empirical risk minimization (ERM) algorithm, which given a function class G outputs a function bgG = bgG(Dn) deﬁned as bgG ∈ arg min g∈G
Rn(g), where Rn(g) := 1 n n
X i=1 (g(xi) − yi)2, (1) in some cases with a regularization penalty term added to the optimization objective Rn(g), such as ‘p norm of the model parameters. We consider the non-realizable or agnostic setting, i.e., the case in which there is no assumption that E[ Y |X] is determined by a well-speciﬁed model from a reference class of functions. In the agnostic case, a key performance measure of an estimator bg is its excess risk with respect to some reference class of functions F:
E(bg, F) = R(bg) − inf
R(f ). f ∈F 1For a full version of this paper see [39]. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
(a) Explicit regularization. (b) Implicit regularization.
Figure 1: Consider a distribution P such that X ∼ N (0, Id) and Y |X = x ∼ hα0, xi+N (0, 52) for some parameter α0 ∈ Rd. Fix n = 200, d = 100 and let α0 be a 10-sparse vector with non-zero entries equal to ±1. Due to the sparsity of α0, explicit regularization via ‘1 penalization results in a class of models (αλ)λ≥0 that at its minimum achieves signiﬁcantly lower risk than the class of models generated via ‘2 penalization (cf. Figure 1a). Figure 1b demonstrates a similar phenomenon from an implicit regularization point of view. Due to the sparsity of α0, the choice of a hyperbolic entropy mirror map (cf. Section 4) yields an optimization path that at its minimum achieves excess risk nearly an order of magnitude lower than the path generated by the vanilla gradient descent updates. In the plot above, the solid lines denote means over 100 runs whereas the shaded regions correspond to the 10th and the 90th percentiles.
Traditionally, in learning theory, statistical and computational properties of ERM estimators have been considered separately. From a statistical point of view, localized complexity measures have become a default tool in statistical learning theory and empirical processes theory for controlling the excess risk of ERM algorithms bgG with respect to the function class G itself, i.e., for controlling E(bgG, G) [7, 20]. A rich and general theory regarding these complexity measures has been developed and used to provide excess risk bounds in both classiﬁcation and regression settings, yielding minimax-optimal results in several cases. Such complexity measures depend on combinatorial or geometric parameters of interest, such as the VC-dimension or eigenvalue decay of the kernel matrix and, in particular, they serve as a guiding principle to choose a suitable explicit regularizer for a set of candidate models (bgGλ)λ∈Λ, where λ ∈ Λ is a hyper-parameter that controls the amount of regularization. In practice, some λ? ∈ Λ is then chosen via some model selection procedure such as cross-validation, aiming to select a model with the smallest risk. From a computational point of view, computing the estimators (bgGλ)λ∈Λ can be done by solving the corresponding optimization problems deﬁned in Equation (1), one for each λ ∈ Λ. An appealing aspect of this approach is that the design and analysis of eﬃcient optimization algorithms, exploiting the geometry of Gλ that arises from the the structure of the model as well as the distribution
P , can be done independently of the statistical analysis of its performance.
Recent years have also witnessed an increased interest in directly studying the statistical properties of models trained by gradient-based methods, particularly in relation to the notions of implicit regularization and early stopping. For a family of functions G = {gα : α ∈ Rm} parametrized by a vector α, such methods are fully characterized by the initialization point
α0 and an update rule, which given αt and the gradient of the empirical risk at αt, generates the next iterate αt+1, yielding a set of candidate estimators (bgαt)t≥0. Early stopping has an eﬀect akin to explicit regularization discussed above, and the stopping time t? can be chosen in practice via cross-validation, just as in the case of choosing the explicit regularization parameter λ? corresponding to the best model among (bgGλ)λ∈Λ.
In modern large-scale machine learning applications, early stopping is often the preferred way to perform model selection, since obtaining a new model is as cheap as performing a step of gradient descent, as opposed to solving a new optimization problem with a diﬀerent regularization parameter.
In Figure 1, we demonstrate that diﬀerent choices of optimization algorithms applied to the unregularized empirical risk Rn yield diﬀerent statistical performance along the optimization 2
path (bgαt)t≥0, in a similar way that a choice of an explicit regularizer aﬀect the statistical performance along the corresponding regularization path.
It is by now well understood that changing the update rule that generates the sequence (bgαt)t≥0, e.g., by changing the optimization algorithm or parametrization of the model class, can directly aﬀect both the statistical properties of the iterates bgαt, as well as computational properties, such as an upper-bound on the optimal stopping time t?. However, most of the literature has focused on the investigation of vanilla gradient descent updates:
αt+1 = αt − η∇αtRn(bgαt) (cf. Section 2.1). The existing theory does not easily generalize to other update rules corresponding to diﬀerent problem geometries. A general theory that connects the notion of early stopping for a more general class of update rules with the well-established theory of localized complexities is still missing. More broadly, a general
“language” to reason about the statistical properties of trajectories traced by optimization algorithms applied to the unregularized empirical risk is still lacking.
In this paper, we study a family of update rules given by the mirror descent algorithm [27, 9].
Mirror descent, which includes vanilla gradient descent as a special case, is increasingly becoming the tool of choice in optimization and machine learning, applied well beyond the traditional settings of convex optimization and online learning. Among the properties that make mirror descent appealing are its ability to exploit non-Euclidean geometries via properly designed mirror maps, the fact that the algorithm admits a general potential-based convergence analysis in terms of Bregman divergences, and its ability to represent a large class of algorithms in a uniﬁed and well-developed framework.
We consider a setting where conditionally on the observed data Dn there exists a matrix
Z ∈ Rn×m such that the parametric family of functions {gα : α ∈ Rm} satisﬁes gα(xi) = (Zα)i for all i = 1, . . . , n. As special cases, our setup admits linear regression and kernel methods (cf. Section 4), cornerstones of modern statistics and machine learning. Our work reveals an inherent connection between the statistical properties of the mirror descent iterates (bgαt)t≥0 and the notion of oﬀset Rademacher complexity [23]. Consequently, our work unearths a simple and elegant way to simultaneously analyze upper-bounds on the stopping time t?, as well as the excess risk E(bgαt, F) for all t ≤ t? in terms of the mirror map, the initialization point α0, the step-size, and the function class F. Through a simple one page analysis, we are able to rederive (nearly identical) results from prior work connecting early stopping and (optimal) statistical performance that previously involved several pages of low-level arguments.2 Additionally, in the well-studied case of Euclidean gradient descent, our work improves upon the prior results connecting early stopping to localized complexity measures
[32, 42] by providing upper-bounds on the expected excess risk without any distributional assumptions on P other than boundedness (cf. Section 2.1). 1.1