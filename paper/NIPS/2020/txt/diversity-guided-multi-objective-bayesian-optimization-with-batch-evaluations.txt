Abstract
Many science, engineering, and design optimization problems require balancing the trade-offs between several conﬂicting objectives. The objectives are often black-box functions whose evaluations are time-consuming and costly. Multi-objective
Bayesian optimization can be used to automate the process of discovering the set of optimal solutions, called Pareto-optimal, while minimizing the number of performed evaluations. To further reduce the evaluation time in the optimization process, testing of several samples in parallel can be deployed. We propose a novel multi-objective Bayesian optimization algorithm that iteratively selects the best batch of samples to be evaluated in parallel. Our algorithm approximates and analyzes a piecewise-continuous Pareto set representation. This represen-tation allows us to introduce a batch selection strategy that optimizes for both hypervolume improvement and diversity of selected samples in order to efﬁciently advance promising regions of the Pareto front. Experiments on both synthetic test functions and real-world benchmark problems show that our algorithm predom-inantly outperforms relevant state-of-the-art methods. The code is available at https://github.com/yunshengtian/DGEMO. 1

Introduction
Various experimental design problems in science and engineering seek optimal solutions that require simultaneous optimization of a number of conﬂicting objectives. Typically the objectives are black-box functions that are expensive to evaluate. Hence the number of evaluated experiments is severely limited and designing experiments by hand does not provide optimal performance. Recently, there has been an increasing interest in effective data-driven algorithms to efﬁciently guide the experimental design process and lead to the best performing designs. Some use cases include material design [53], battery optimization [1], clinical drug trials [50, 47], and chemical design [16]. An approach that has proven to be powerful in optimizing the expensive-to-evaluate black-box functions is Bayesian optimization (BO) [20, 41]. A fundamental concept behind the BO is two-fold: ﬁrst, a inexpensive surrogate model is used to model the black-box objective function based on the evaluated experiments; second, an acquisition function is employed to adaptively sample the design space and efﬁciently improve the set of optimal solutions. Both single- and multi-objective Bayesian optimization (MOBO) have been studied.
In a variety of physical experimental setups, evaluating several experiments in parallel, e.g., in batches, reduces the time and cost of the optimization process. Experiments can take days, weeks, even months to complete; hence taking advantage of batching is important. Furthermore, in design problems with multiple conﬂicting objectives, in most cases, there is no single optimal solution, but rather a set of optimal designs with different trade-offs. These designs often tend to group in different regions based on their properties and performance. In this paper, we develop a novel MOBO approach
⇤Equal contribution. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
with a batch selection strategy that combines the knowledge from both design and performance space.
Our selection strategy enforces the exploration of diverse identiﬁed regions in approximated optimal space. In addition, it measures which regions are the most beneﬁcial for optimization to explore by taking into consideration the hypervolume improvement[37]. A relatively limited amount of literature can be found on the batch selection for MOBO that applies to the problem setup we are trying to address [6, 52]. To the best of our knowledge, no previous published work has considered diversity in both design and performance space in the batch selection strategy.
In summary, the key contributions of this paper are the following:
•
•
•
We propose a novel approach, referred to as DGEMO (Diversity-Guided Efﬁcient Multi-objective Optimization), for solving multi-objective optimization problems of black-box functions, while minimizing the number of function evaluations. Our algorithm is based on multi-objective Bayesian optimization that operates on batches of evaluated samples in each iteration and can handle an arbitrary batch size.
Our batch selection strategy is guided by diversity in both design and performance space of selected samples. The selection strategy divides the space into diversity regions that provide additional information in terms of shared properties and performance of optimal solutions. This information can be valuable for further physical experiments and problem understanding.
We conduct comprehensive experiments on both synthetic test functions and real-world benchmark problems. Our algorithm exhibits consistent high-quality performance and outperforms the relevant existing works in the ﬁeld. 2