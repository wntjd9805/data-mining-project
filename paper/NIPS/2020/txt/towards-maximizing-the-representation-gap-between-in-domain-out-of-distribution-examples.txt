Abstract
Among existing uncertainty estimation approaches, Dirichlet Prior Network (DPN) distinctly models different predictive uncertainty types. However, for in-domain examples with high data uncertainties among multiple classes, even a DPN model often produces indistinguishable representations from the out-of-distribution (OOD) examples, compromising their OOD detection performance. We address this short-coming by proposing a novel loss function for DPN to maximize the representation gap between in-domain and OOD examples. Experimental results demonstrate that our proposed approach consistently improves OOD detection performance. 1

Introduction
Deep neural network (DNN) based models have achieved impeccable success to address various real-world tasks [1, 2, 3]. However, when these intelligent systems fail, they do not provide any explanation or warning. Predictive uncertainty estimation has emerged as an important research direction to inform users about possible wrong predictions and allow users to react in an informative manner, thus improving their reliability.
Predictive uncertainties of DNNs can come from three different sources: model uncertainty, data uncertainty, and distributional uncertainty [4, 5]. Model uncertainty or epistemic uncertainty captures the uncertainty in estimating the model parameters, conditioning on training data [4]. Data uncertainty (or aleatoric uncertainty) arises from the natural complexities of the underlying distribution, such as class overlap, label noise, homoscedastic and heteroscedastic noise, etc [4]. Distributional uncertainty or dataset shift arises due to the distributional mismatch between the training and test examples, that is, the test data is out-of-distribution (OOD) [6, 5].
It is useful to determine the sources of predictive uncertainties. In active learning, distributional un-certainty indicates that the classiﬁer requires additional data for training. For real-world applications, where the cost of errors are high, such as in autonomous vehicles [7], medical diagnosis [8], ﬁnancial, and legal ﬁelds [9], the source of uncertainty can allow manual intervention in an informed way.
Notable progress has been made for predictive uncertainty estimation. Bayesian neural network-based models conﬂate the distributional uncertainty through model uncertainty [10, 4, 11, 12, 13].
However, since the true posterior for their model parameters are intractable, their success depend on the nature of approximations. In contrast, non-Bayesian approaches can explicitly train the network in a multi-task fashion, incorporating both in-domain and OOD examples to produce sharp and uniform categorical predictions respectively [14, 15]. However, these approaches cannot robustly determine the source of predictive uncertainty [5]. In particular, the presence of high data uncertainty among multiple classes leads them to produce uniform categorical predictions for in-domain examples, often making them indistinguishable from the OOD examples.
Dirichlet Prior Network (DPN) separately models different uncertainty types by producing sharp uni-modal Dirichlet distributions for in-domain examples, and ﬂat Dirichlet distributions for OOD 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
examples [5, 16]. It uses a loss function that explicitly incorporates Kullback-Leibler (KL)-divergence between the model output and a target Dirichlet with a pre-speciﬁed precision value. However, we show that for in-domain examples with high data uncertainties, their proposed loss function distributes the target precision values among the overlapping classes, leading to much ﬂatter distributions. Hence, it often produces indistinguishable representations for such in-domain misclassiﬁed examples and
OOD examples, compromising the OOD detection performance.
In this work, we propose an alternative approach for a DPN classiﬁer that produces sharp, multi-modal
Dirichlet distributions for OOD examples to maximize their representation gap from in-domain examples. We design a new loss function that separately models the mean and the precision of the output Dirichlet distributions by introducing a novel explicit precision regularizer along with the cross-entropy loss. Experimental results on several benchmark datasets demonstrate that our proposed approach achieves the best OOD detection performance. 2