Abstract
We ﬁnd separation rates for testing multinomial or more general discrete distribu-tions under the constraint of α-local differential privacy. We construct efﬁcient randomized algorithms and test procedures, in both the case where only non-interactive privacy mechanisms are allowed and also in the case where all sequen-tially interactive privacy mechanisms are allowed. The separation rates are faster in the latter case. We prove general information theoretical bounds that allow us to establish the optimality of our algorithms among all pairs of privacy mechanisms and test procedures, in most usual cases. Considered examples include testing uniform, polynomially and exponentially decreasing distributions. 1

Introduction
Hypothesis testing of discrete distributions is intensively used as a ﬁrst step in data based decision making and it is now also a component of many machine learning algorithms. Given samples from an unknown probability distribution p and a known reference distribution p0, the goal of a goodness-of-ﬁt test is to decide whether p ﬁts p0, or is signﬁcantly different to it in some suitable sense. Here we will measure distance between distributions using either the L1 norm or the L2 norm, with our alternative hypotheses consisting of all distributions p whose distance from p0 is above a certain threshold. Our goal is to make accurate decisions, i.e. with low error probabilities, for distributions p as close to p0 as possible. The smallest separation between p0 and the alternative hypothesis for which it remains possible to reliably distinguish between the two hypotheses is known as the uniform separation rate, δ. Its optimality is proven by showing that, whenever p is closer to p0 than
δ, no test procedure will be able to distinguish them with small error probabilities. As shown by
Valiant and Valiant [2014, 2017], the dependence of δ on p0 in the standard problem without privacy constraints is pronounced and intricate.
In this work, we quantify how the constraint of local differential privacy affects the optimal separa-tion rate. Differential privacy Dwork et al. [2006] is the most popular formalism under which the analyst statistically randomizes data to be published in order to protect the privacy of the individuals in the study. The way in which the data is randomized, known as the privacy mechanism, must be carefully chosen to preserve the information in the data that is most pertinent for the task at hand, though it is well-established that the cost of protecting privacy is necessarily a deterioration in statis-tical performance. Local differential privacy, in which there is no trusted curator who has access to all the original data, is more stringent than the original differential privacy constraint, and it is often observed in the literature that in this context we experience a further deterioration of the achievable performance of estimation and test procedures, which are allowed to use private data only.
Local differential privacy can be attained through several kinds of privacy mechanisms. They can be non-interactive (also known as private-coin) when the users independently randomize the sample 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
they receive, or interactive in the sense that some information is shared. We consider a large class of sequentially interactive mechanisms where some information (e.g. the previously privatized sample) can be transmitted from one user to the next. In this setup, the set of public-coin mechanisms, such as those considered in Acharya et al. [2019c], is a subset of all sequentially interactive mechanisms where the shared information is the original seed the ﬁrst user employed. 1.1 Our contributions
We ﬁnd the optimal separation rate around an arbitrary discrete distribution p0 on N under local differential privacy constraints and this optimality involves two steps. On the one hand, we provide efﬁcient and statistically optimal pairs of privacy mechanisms and their associated test procedures whose error probabilities are small for all distributions p further from p0 than δ. On the other hand, we show that whenever p is closer to p0 than the separation rate δ, no pair of privacy mechanism and test procedure is able to distinguish p and p0. We show that faster rates are attainable using interactive privacy mechanisms rather than non-interactive. As indicated below, previous works have found optimal rates in the special case of p0 being a uniform distribution, and upper bounds for general ﬁnite supported p0, in the L1 problem. Here, we provide optimal rates for general p0 supported on N that can be quicker than in the uniform case (see Table 1), we treat both the L1 and the L2 test problems in parallel, we introduce new privacy mechanisms and test procedures, and we provide shorter proofs and more explicit upper and lower bounds. The interactive mechanism that we use is a two-step procedure: for the ﬁrst half of the sample we employ a Laplace mechanism and estimate the unknown probabilities, for the second half we randomize encoding this information and build a (cid:96)2-type statistic. Our optimality results show that the separation rates are optimal in most usual cases. Let us stress the fact that the second part of Theorem 5 is particularly useful in the case of noninteractive mechanisms where, as it was also noted by Lam-Weil et al. [2020], the usual inequalities in Duchi et al. [2018] can only result in suboptimal lower bounds. We highlight the examples of (nearly) uniform distributions, and distributions with polynomially or exponentially decreasing tails. All results are valid non-asymptotically, that is with a ﬁnite number of samples. 1.2