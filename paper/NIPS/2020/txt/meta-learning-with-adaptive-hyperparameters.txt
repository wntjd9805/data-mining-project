Abstract
The ability to quickly learn and generalize from only few examples is an essential goal of few-shot learning. Meta-learning algorithms effectively tackle the problem by learning how to learn novel tasks. In particular, model-agnostic meta-learning (MAML) encodes the prior knowledge into a trainable initialization, which allowed for fast adaptation to few examples. Despite its popularity, several recent works question the effectiveness of MAML initialization especially when test tasks are different from training tasks, thus suggesting various methodologies to improve the initialization. Instead of searching for a better initialization, we focus on a complementary factor in MAML framework, the inner-loop optimization (or fast adaptation). Consequently, we propose a new weight update rule that greatly enhances the fast adaptation process. Speciﬁcally, we introduce a small meta-network that can adaptively generate per-step hyperparameters: learning rate and weight decay coefﬁcients. The experimental results validate that the Adaptive
Learning of hyperparameters for Fast Adaptation (ALFA) is the equally important ingredient that was often neglected in the recent few-shot learning approaches.
Surprisingly, fast adaptation from random initialization with ALFA can already outperform MAML. 1

Introduction
Inspired by the capability of humans to learn new tasks quickly from only few examples, few-shot learning tries to address the challenges of training artiﬁcial intelligence that can generalize well with the few samples. Meta-learning, or learning-to-learn, tackles this problem by investigating common prior knowledge from previous tasks that can facilitate rapid learning of new tasks. Especially, gradient (or optimization) based meta-learning algorithms are gaining increased attention, owing to its potential for generalization capability. This line of works attempts to directly modify the conventional optimization algorithms to enable fast adaptation with few examples.
One of the most successful instances for gradient-based methods is model-agnostic meta-learning (MAML) [8], where the meta-learner attempts to ﬁnd a good starting location for the network parameters, from which new tasks are learned with few updates. Following this trend, many recent studies [3, 9, 11, 30, 39, 41] focused on learning a better initialization. However, research on the training strategy for fast adaptation to each task is relatively overlooked, typically resorting to conventional optimizers (e.g. SGD). Few recent approaches explore better learning algorithms for inner-loop optimization [6, 15, 26, 27], however they lack the adaptation property in weight updates, which is validated to be effective from commonly used adaptive optimizers, such as Adam [16].
In this paper, we turn our attention to an important but often neglected factor for MAML-based formulation of few-shot learning, which is the inner-loop optimization. Instead of trying to ﬁnd a better initialization, we propose Adaptive Learning of hyperparameters for Fast Adaptation1, named ALFA, that enables training to be more effective with task-conditioned inner-loop updates 1The code is available at https://github.com/baiksung/ALFA 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
Figure 1: Overview of our proposed inner-loop optimization for few-shot learning. (a) Conventional optimizer (e.g., SGD) updates the parameters in the direction of the gradient of task-speciﬁc loss
∇θLDi with a ﬁxed learning rate α. The updates guide the parameters to the optimal values for
Ti training (or support) dataset, θ∗ si. (b) ALFA adapts the learning rate αi,j and the regularization hyperparameter βi,j w.r.t. the i-th task and the j-th inner-loop update step. The adaptive regulariza-tion effects of ALFA aims to facilitate better generalization to arbitrary unseen tasks, pushing the parameters closer to the true optimal values θ∗ i . from any given initialization. Our algorithm dynamically generates two important hyperparameters for optimization: learning rates and weight decay coefﬁcients. Speciﬁcally, we introduce a small meta-network that generates these hyperparameters using the current weight and gradient values for each step, enabling each inner-loop iteration to be adaptive to the given task. As illustrated in
Figure 1, ALFA can achieve better training and generalization, compared to conventional inner-loop optimization approaches, owing to per-step adaptive regularization and learning rates.
With the proposed training scheme ALFA, fast adaptation to each task from even a random initial-ization shows a better few-shot classiﬁcation accuracy than MAML. This suggests that learning a good weight-update rule is at least as important as learning a good initialization. Furthermore,
ALFA can be applied in conjunction with existing meta-learning approaches that aim to learn a good initialization. 2