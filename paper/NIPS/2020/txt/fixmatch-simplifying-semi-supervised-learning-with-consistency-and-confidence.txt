Abstract
Semi-supervised learning (SSL) provides an effective means of leveraging unla-beled data to improve a model’s performance. This domain has seen fast progress recently, at the cost of requiring more complex methods. In this paper we propose
FixMatch, an algorithm that is a signiﬁcant simpliﬁcation of existing SSL methods.
FixMatch ﬁrst generates pseudo-labels using the model’s predictions on weakly-augmented unlabeled images. For a given image, the pseudo-label is only retained if the model produces a high-conﬁdence prediction. The model is then trained to predict the pseudo-label when fed a strongly-augmented version of the same image. Despite its simplicity, we show that FixMatch achieves state-of-the-art performance across a variety of standard semi-supervised learning benchmarks, including 94.93% accuracy on CIFAR-10 with 250 labels and 88.61% accuracy with 40 – just 4 labels per class. We carry out an extensive ablation study to tease apart the experimental factors that are most important to FixMatch’s success. The code is available at https://github.com/google-research/fixmatch. 1

Introduction
Deep neural networks have become the de facto model for computer vision applications. Their success is partially attributable to their scalability, i.e., the empirical observation that training them on larger datasets produces better performance [30, 20, 42, 55, 41, 21]. Deep networks often achieve their strong performance through supervised learning, which requires a labeled dataset. The performance beneﬁt conferred by the use of a larger dataset can therefore come at a signiﬁcant cost since labeling data often requires human labor. This cost can be particularly extreme when labeling must be done by an expert (for example, a doctor in medical applications).
A powerful approach for training models on a large amount of data without requiring a large amount of labels is semi-supervised learning (SSL). SSL mitigates the requirement for labeled data by providing a means of leveraging unlabeled data. Since unlabeled data can often be obtained with minimal human labor, any performance boost conferred by SSL often comes with low cost. This has led to a plethora of SSL methods that are designed for deep networks [33, 46, 24, 51, 4, 54, 3, 25, 45, 52].
A popular class of SSL methods can be viewed as producing an artiﬁcial label for unlabeled images and training the model to predict the artiﬁcial label when fed unlabeled images as input. For example, pseudo-labeling [25] (also called self-training [32, 55, 44, 47]) uses the model’s class prediction as a label to train against. Similarly, consistency regularization [2, 46, 24] obtains an artiﬁcial label using the model’s predicted distribution after randomly modifying the input or model function.
∗Equal contribution. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
Figure 1: Diagram of FixMatch. A weakly-augmented image (top) is fed into the model to obtain predictions (red box). When the model assigns a probability to any class which is above a threshold (dotted line), the prediction is converted to a one-hot pseudo-label. Then, we compute the model’s prediction for a strong augmentation of the same image (bottom). The model is trained to make its prediction on the strongly-augmented version match the pseudo-label via a cross-entropy loss.
In this work, we break the trend of recent state-of-the-art methods that combine increasingly complex mechanisms [4, 54, 3] and produce a method that is simpler, but also more accurate. Our algorithm,
FixMatch, produces artiﬁcial labels using both consistency regularization and pseudo-labeling.
Crucially, the artiﬁcial label is produced based on a weakly-augmented unlabeled image (e.g., using only ﬂip-and-shift data augmentation) which is used as a target when the model is fed a strongly-augmented version of the same image. Inspired by UDA [54] and ReMixMatch [3], we leverage
Cutout [14], CTAugment [3], and RandAugment [11] for strong augmentation, which all produce heavily-distorted versions of a given image. Following the approach of pseudo-labeling [25], we only retain an artiﬁcial label if the model assigns a high probability to one of the possible classes. A diagram of FixMatch is shown in ﬁg. 1.
Despite its simplicity, we show that FixMatch obtains state-of-the-art performance on the most commonly-studied SSL benchmarks. For example, FixMatch achieves 94.93% accuracy on CIFAR-10 with 250 labeled examples compared to the previous state-of-the-art of 93.73% [3] in the standard experimental setting from [36]. We also explore the limits of our approach by applying it in the extremely-scarce-labels regime, obtaining 88.61% accuracy on CIFAR-10 with only 4 labels per class. Since FixMatch is a simpliﬁcation of existing approaches but achieves substantially better performance, we include an extensive ablation study to determine which factors contribute the most to its success. A key beneﬁt of FixMatch being a simpliﬁcation of existing methods is that it requires many fewer additional hyperparameters. As such, it allows us to perform an extensive ablation study of each of them. Our ablation study also includes basic fully-supervised learning experimental choices that are often ignored or not reported when new SSL methods are proposed (such as the optimizer or learning rate schedule). 2 FixMatch
FixMatch is a combination of two approaches to SSL: Consistency regularization and pseudo-labeling.
Its main novelty comes from the combination of these two ingredients as well as the use of a separate weak and strong augmentation when performing consistency regularization. In this section, we ﬁrst review consistency regularization and pseudo-labeling before describing FixMatch in detail. We also describe the other factors, such as regularization, which contribute to FixMatch’s empirical success.
For an L-class classiﬁcation problem, let X = (cid:8)(xb, pb) : b ∈ (1, . . . , B)(cid:9) be a batch of B labeled examples, where xb are the training examples and pb are one-hot labels. Let U = (cid:8)ub : b ∈ (1, . . . , µB)(cid:9) be a batch of µB unlabeled examples where µ is a hyperparameter that determines the relative sizes of X and U. Let pm(y | x) be the predicted class distribution produced by the model for input x. We denote the cross-entropy between two probability distributions p and q as H(p, q).
We perform two types of augmentations as part of FixMatch: strong and weak, denoted by A(·) and
α(·) respectively. We describe the form of augmentation we use for A and α in section 2.3. 2
2.1