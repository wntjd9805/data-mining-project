Abstract
In a social system, the self-interest of agents can be detrimental to the collective good, sometimes leading to social dilemmas. To resolve such a conﬂict, a central designer may intervene by either redesigning the system or incentivizing the agents to change their behaviors. To be effective, the designer must anticipate how the agents react to the intervention, which is dictated by their often unknown payoff functions. Therefore, learning about the agents is a prerequisite for intervention. In this paper, we provide a uniﬁed framework for learning and intervention in games.
We cast the equilibria of games as individual layers and integrate them into an end-to-end optimization framework. To enable the backward propagation through the equilibria of games, we propose two approaches, respectively based on explicit and implicit differentiation. Speciﬁcally, we cast the equilibria as the solutions to variational inequalities (VIs). The explicit approach unrolls the projection method for solving VIs, while the implicit approach exploits the sensitivity of the solutions to VIs. At the core of both approaches is the differentiation through a projection operator. Moreover, we establish the correctness of both approaches and identify the conditions under which one approach is more desirable than the other. The analytical results are validated using several real-world problems. 1

Introduction
The history of human societies may be viewed as an evolutionary process through which countless self-interested individuals learn to cooperate with each other [20]. While human self-interest can be channeled towards socially desirable ends, interventions—in the form of laws, social norms and incentives—are often required. Indeed, even the “invisible hand” of Adam Smith would not work without proper regulations and policing. This process continues, as it uncovers and resolves previously unknown or non-existent conﬂicts between self- and collective interest. For example, the potential conﬂict between overpopulation and welfare states has been heatedly debated among biologists, social scientists, philosophers and alike [21, 16]. In economics, externalities (a.k.a. neighboring effects) lead to market failures because self-interested agents do not bear the cost/beneﬁt of their actions in its entirety. Lloyd’s common devastated by excessive grazing [34] and Pigou’s road jammed by selﬁsh drivers [50] are two classical examples. More recently, Braess [10] shows expanding a road network could worsen trafﬁc congestion. This paradoxical phenomenon, related closely to the price of anarchy [28], demonstrates vividly how unregulated self-interest may be detrimental to the social good. In this paper, we develop a general framework aiming to regulate various systems comprised of self-interested agents.
Game theory is often used to determine the most likely outcomes of a system in which agents pursue self-interest and interact with each other [27, 18]. Although a game-theoretic model of the real-world 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
is a simpliﬁcation, it can be useful for not only explaining and predicting system outcomes, but also engineering desired ones [43]. For example, many phenomena in ecosystems can be explained as the outcome of the population, in the game of survival, adopting an evolutionarily stable strategy
[55]. Stackelberg games [61], which concern the strategic interactions between leaders and followers, have seen applications in economics [5], national security [51] and environment protection [65].
Congestion game [52], in which the utility of agents depends on a resource whose cost increases with the number of users, is another example. Many social and engineering systems can be modeled as a congestion game, with applications ranging from planning transportation infrastructure [6], managing wireless communication networks [30], to operating ride-hail companies [12].
In a game-theoretic system, we deﬁne the central designer as an authority whose action can inﬂuence the outcome of the game. The central designer can intervene in order to guide the self-interested behavior toward a socially desirable outcome. There are generally two types of interventions: redesign the system or modify the payoffs of the agents through incentives. Take transportation planning as example. To alleviate congestion, the owner of the road network (typically the “government”), has the power to add capacities at selected locations in the network [37, 64]. Alternatively, it may charge road users a “congestion toll”, in the spirit of Pigou [50] and Vickrey [60], to incentivize them to change travel behaviors (route, departure time, mode, etc.). In order to intervene effectively, the central designer must anticipate the reaction of the agents, which is dictated by their often unknown payoff functions. Thus, an equally important task is to infer, from empirical observations, how the agents evaluate their payoffs. To this end, the random utility theory [41] is widely used to estimate behavioral parameters of agents in marketing [40], environmental studies [59] and travel forecasting
[7]. Alternatively, the learning-theoretic approach is increasingly used to learn, among other things, the optimal strategy of agents [32] or unknown parameters of games [33].
Contribution. This paper provides a uniﬁed framework for learning and interventions in games.
It is well known that the equilibria of many games can be formulated as either a complementarity problem [66] or an optimization problem [45], and both can be interpreted as a variational inequality (VI) problem [47]. Therefore, we propose to cast the equilibria of games, in the form of VI, as individual layers in an end-to-end optimization framework. Such a general representation of the game-theoretic system in an end-to-end framework poses the challenge of performing forward and backward propagation through the VI layers.
Along the above line, our contributions are as follows. (1) We present a uniﬁed optimization model for learning and interventions in games that can be solved by gradient descent methods. (2) We devise a Newton’s method for forward propagation over VI layers. Unlike other Newton-type methods for solving VI, e.g. [8, 56], we directly ﬁnd the solution via root-ﬁnding. (3) We propose two methods for backward propagation over VI layers based on explicit and implicit differentiation, respectively.
The explicit approach unrolls the projection methods for solving VIs, and the implicit approach performs differentiation on the ﬁxed-point formulation of VI [26]. The implicit approach is more efﬁcient than the explicit approach but is applicable only when the VI problem is strongly monotone locally. In contrast, the explicit approach works as long as the convergence of the projection method is guaranteed, which only requires monotoncity. (4) We give real-world examples to demonstrate the potential applications of the proposed framework.