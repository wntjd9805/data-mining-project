Abstract
Intra-saliency and inter-saliency cues3 have been extensively studied for co-saliency detection (Co-SOD). Model-based methods produce coarse Co-SOD results due to hand-crafted intra- and inter-saliency features. Current data-driven models exploit inter-saliency cues, but undervalue the potential power of intra-saliency cues. In this paper, we propose an Intra-saliency Correlation Network (ICNet) to extract intra-saliency cues from the single image saliency maps (SISMs) predicted by any off-the-shelf SOD method, and obtain inter-saliency cues by correlation techniques.
Speciﬁcally, we adopt normalized masked average pooling (NMAP) to extract latent intra-saliency categories from the SISMs and semantic features as intra cues. Then we employ a correlation fusion module (CFM) to obtain inter cues by exploiting correlations between the intra cues and single-image features. To improve Co-SOD performance, we propose a category-independent rearranged self-correlation feature (RSCF) strategy. Experiments on three benchmarks show that our ICNet outperforms previous state-of-the-art methods on Co-SOD. Abla-tion studies validate the effectiveness of our contributions. The PyTorch code is available at https://github.com/blanclist/ICNet. 1

Introduction
Co-Saliency Object Detection (Co-SOD) aims to discover the commonly salient objects in a group of relevant images [36]. It serves as a preliminary step for various computer vision tasks, e.g., co-segmentation [9], co-localization [27], and image retrieval [21], etc. The saliency information within a single image (intra-saliency cue) and the occurrence of saliency within a group of images (inter-saliency cue) are essential to the success of existing Co-SOD methods, which can be roughly divided into model-based (non-deep) methods [4, 14, 15] and data-driven (deep) ones [13, 29, 32].
The model-based (non-deep) methods [4, 14, 15] utilize hand-crafted features with manually designed detection pipelines. Most of them leverage as intra cues the single image saliency maps (SISMs) predicted by off-the-shelf SOD methods [5, 44], and compute various inter cues based on subjective priors and hand-crafted features of salient regions in SISMs. Unfortunately, hand-crafted features are usually inconsistent in expressing high-level semantics [36, 43], e.g., versatile viewpoints, complex shapes, and illuminant changes, etc, leading to undesirable Co-SOD predictions [8, 14]. Besides, with subjective priors [4, 8], e.g., low-rank constraint, central bias rule, co-saliency distribution consistency and histogram-based contrast, these Co-SOD methods [4, 8] are usually unstable in capturing robust inter cues in complex real-world scenarios [36, 43].
∗Wen-Da Jin and Jun Xu are joint ﬁrst authors.
†Yi Zhang is the corresponding author. 3To simplify writing, we abbreviate intra-saliency and inter-saliency cues as intra and inter cues, respectively. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
Recently, data-driven (deep) methods [11, 13, 39] are proposed to learn discriminative features with great performance gains on Co-SOD. Among these methods, [38, 39, 40] learn intra and inter cues from scratch to discover similar foregrounds within an image group while distinguishing the foreground and background in each image. The methods of [13, 32] focus on capturing inter cues by imposing various architectures, e.g., recurrent module and group-level concatenation. The works of [10, 11] obliquely take the SISMs as supervisions of the networks and constrain the inter consistency via energy minimization. Despite with promising results, previous Co-SOD networks [28, 29] undervalue the potential power of intra cues for Co-SOD. Recently, the SISMs produced by some SOD networks [35, 42] achieve comparable results with popular Co-SOD networks on Co-SOD benchmarks [2, 33, 37] by standard metrics [1, 3, 6], as will be shown in §4. This indicates that a stronger Co-SOD network can be developed if we well exploit the intra cues in SISMs.
In this paper, we propose an Intra-saliency Cor-relation Network (ICNet) for ﬁne-grained Co-SOD performance. Our ICNet directly integrates the intra cues and correlation techniques into a deep network for end-to-end learning. We ex-tract intra cues by adopting normalized masked average pooling (NMAP) [25] to combine single image saliency maps (SISMs) predicted by any
SOD method and deep features. To explore the inter cues for Co-SOD, we employ a correlation fusion module (CFM) to capture the correlations between the extracted intra cues and single-image features. In order to further improve our ICNet on Co-SOD, we design a rearranged self-correlation feature (RSCF) strategy to maintain the feature independence upon semantic categories, while beneﬁt-ing from global receptive ﬁelds. Our main idea is illustrated in Figure 1, from which we can see that co-saliency information can be obtained by exploring correlations between intra-saliency categories.
Extensive experiments on three Co-SOD benchmarks demonstrate that our ICNet outperforms state-of-the-art Co-SOD methods on standard objective metrics and subjective visual quality. Ablation studies also validate the effectiveness of each component in our ICNet.
Figure 1: The main idea of our ICNet.
In summary, our major contributions are manifold:
• We propose a novel Intra-saliency Correlation Network (ICNet) for Co-SOD, by integrating intra-saliency features of SISMs and correlation techniques. Ablation studies show that
SISMs clearly improve the performance of the proposed ICNet for Co-SOD.
• We validate that well exploiting SISMs improves Co-SOD performance. By leveraging normalized masked average pooling (NMAP) and a correlation fusion module (CFM), intra and inter cues can be well captured from SISM and deep features for Co-SOD.
• We introduce a rearranged self-correlation feature (RSCF) strategy to obtain robust co-saliency features with the inter cues. Beneﬁting from the independence upon semantic categories and positions, our ICNet with RSCF achieves better Co-SOD performance.
• Experimental results demonstrate that the proposed ICNet outperforms previous state-of-the-art Co-SOD methods on three benchmarks. 2