Abstract
Binary source code matching, especially on function-level, has a critical role in the ﬁeld of computer security. Given binary code only, ﬁnding the corresponding source code improves the accuracy and efﬁciency in reverse engineering. Given source code only, related binary code retrieval contributes to known vulnerabilities conﬁrmation. However, due to the vast difference between source and binary code, few studies have investigated binary source code matching. Previously published studies focus on code literals extraction such as strings and integers, then utilize traditional matching algorithms such as the Hungarian algorithm for code matching. Nevertheless, these methods have limitations on function-level, because they ignore the potential semantic features of code and a lot of code lacks sufﬁcient code literals. Also, these methods indicate a need for expert experience for useful feature identiﬁcation and feature engineering, which is time-consuming. This paper proposes an end-to-end cross-modal retrieval network for binary source code matching, which achieves higher accuracy and requires less expert experience. We adopt Deep Pyramid Convolutional Neural Network (DPCNN) for source code feature extraction and Graph Neural Network (GNN) for binary code feature extraction. We also exploit neural network-based models to capture code literals, including strings and integers. Furthermore, we implement
"norm weighted sampling" for negative sampling. We evaluate our model on two datasets, where it outperforms other methods signiﬁcantly. 1

Introduction
Binary source code matching is an essential task in computer security. Most applications focus on binary to source matching, including code clone detection [1], open-source code reuse identiﬁcation
[2, 3, 4], and reverse engineering [5, 6]. At the same time, source to binary matching is also useful.
When we have source code, it is signiﬁcant for us to know whether its corresponding binary code is included in a binary ﬁle, so that we could use it for vulnerability risk warning. The binary source code matching task is difﬁcult because the differences between source code and binary code are enormous.
Previous methods usually extract the code literals, including strings, integers, if/else numbers [2], recursions [5], etc. Then traditional matching algorithms, such as the Hungarian algorithm [7], are adopted to compute the code similarity. However, these methods have two main problems. Firstly, they could not achieve high accuracy, because only the code literals of the code are used. The potential features, which may contain much more information, are ignored. Secondly, these methods need expert experience to choose the features and do feature engineering, which costs a lot of time.
Our model is built on function-level. Compared with previous library-level tasks [1, 2, 3, 4, 5, 6], function-level inputs have fewer strings, and fewer integers, so the designed model needs to be more
∗Corresponding author. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
Figure 1: An example of a source-binary code pair. (a) shows the binary code, and (b) shows its corresponding source code. (c) and (d) are the literals of the source and binary code, which are integers and strings. precise. For ease of understanding, we show a function-level source-binary code pair in Figure 1.
The strings are the same in the source code and the binary code, but this feature is coarse-grained because the strings are few and different functions may have the same strings. The set of integers is another useful feature, but they are not equal because address numbers may appear in binary code.
Also, it is a coarse-grained feature because the same integers may appear in different functions. As a consequence, more features should be extracted to increase the accuracy of code matching. From
Figure 1 we could see that there are many potential semantic features between the source code and the binary code. For example, the function call in the source code could be matched with the lower left block in the binary code’s CFG. To show more clearly, we color the matching code in both source and binary code. This is similar to cross-modal tasks, such as image caption. Even if the data belongs to different formats, the potential semantic relationship still exists. If these semantic features could be extracted, the matching accuracy will be signiﬁcantly improved.
Based on these insights, we propose an overall framework for binary source code matching. We ﬁrst put this scenario into the cross-modal retrieval task, whose modalities are source code and binary code.
Cross-modal retrieval is used in many applications, including text-image [8, 9], audio-image [10], text-audio [11, 12], etc. With the development of deep learning in recent years, a general framework for cross-modal retrieval tends to be popular. The two modalities are ﬁrst put into modality-speciﬁc encoders and computed into two vectors, and then different negative sampling methods and different loss functions are designed in respective tasks. For example, in the recipe-image task [8], they adopt
Hierarchical-LSTM [13] and Resnet [14] to extract the recipe feature and the image feature separately, then use adversarial loss, triplet loss and hard sample mining for better training.
After proposing the overall framework, we design encoders for extracting the features of source code and binary code. For source code, we use the deep pyramid convolutional neural network (DPCNN)
[15]. We ﬁnd DPCNN powerful for character-level source code sequences. For binary code, we design a graph neural network (GNN) method. Instead of using pre-training methods for node embeddings [16], we build an end-to-end HBMP model [17] to generate the node embeddings, and then use GGNN [32] and Set2Set [33] model to compute the semantic embedding of the binary code.
Also, we exploit two models for strings and integers to extract the code literal features. We build an
LSTM model taking integers as input to capture the volatile integers, and produce a hierarchical-LSTM model for strings. We combine these three features for both source code and binary code.
Additionally, we design a norm weighted sampling method, which could accelerate training and signiﬁcantly increase accuracy.
Our contributions are as follows: 1) We deﬁne the function-level binary source code matching problem, which is vital in the computer security area. We categorize this problem into the cross-modal retrieval task and propose an overall framework to solve it. 2
2) For source code, we use the DPCNN model on character-level, which leads to a satisfactory performance. Also, using character source code as input is more robust and faster than parsing the code into an abstract syntax tree (AST). For binary code, we produce an end-to-end model instead of pre-training methods, which increases both accuracy and efﬁciency. The models can extract the potential semantic features of source and binary code, thereby signiﬁcantly improving the accuracy. 3) We propose methods for extracting code literals, including strings and integers. Meanwhile, we design a new negative sampling method called "norm weighted sampling", which accelerates training and improves results. 4) We conduct experiments on two datasets. On both datasets our model outperforms other models a lot. In particular, on our dataset with 10,000 samples, the recall@1/recall@10 result achieves 90.2%/98.3%, which meets the requirement of actual use. 2