Abstract
Stochastic gradient algorithm is a key ingredient of many machine learning methods, particularly appropriate for large-scale learning. However, a major caveat of large data is their incompleteness. We propose an averaged stochastic gradient algorithm handling missing values in linear models. This approach has the merit to be free from the need of any data distribution modeling and to account for heterogeneous missing proportion. In both streaming and ﬁnite-sample settings, we prove that this algorithm achieves convergence rate of O( 1 n ) at the iteration n, the same as without missing values. We show the convergence behavior and the relevance of the algorithm not only on synthetic data but also on real data sets, including those collected from medical register. 1

Introduction
Stochastic gradient algorithms (SGD) [20] play a central role in machine learning problems, due to their cheap computational cost and memory per iteration. There is a vast literature on its variants, for example using averaging of the iterates [19], some robust versions of SGD [18, 11] or adaptive gradient algorithms like Adagrad [6]; and on theoretical guarantees of those methods [16, 1, 4, 23, 8, 17]. More globally, averaging strategies have been used to stabilize the algorithm behaviour and reduce the impact of the noise, giving better convergence rates without requiring strong convexity.
The problem of missing values is ubiquitous in large scale data analysis. One of the key challenges in the presence of missing data is to deal with the half-discrete nature of the data which can be seen as a mixed of continuous data (observed values) and categorical data (the missing values). In particular for gradient-based methods, the risk minimization with incomplete data becomes intractable and the usual results cannot be directly applied.
Context.
In this paper, we consider a linear regression model, for i ≥ 1, yi = X T i: β(cid:63) + (cid:15)i, (1) parametrized by β(cid:63) ∈ Rd, where yi ∈ R, (cid:15)i ∈ R is a real-valued centered noise and Xi: ∈ Rd stands for the real covariates of the i-th observation. The (Xi:)’s are assumed to be only partially known, since some covariates may be missing: our objective is to derive stochastic algorithms for estimating the parameters of the linear model, which handle missing data, and come with strong theoretical guarantees on excess risk.