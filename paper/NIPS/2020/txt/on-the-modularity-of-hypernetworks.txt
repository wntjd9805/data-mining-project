Abstract
In the context of learning to map an input I to a function hI : X → R, two alternative methods are compared: (i) an embedding-based method, which learns a
ﬁxed function in which I is encoded as a conditioning signal e(I) and the learned function takes the form hI (x) = q(x, e(I)), and (ii) hypernetworks, in which the weights θI of the function hI (x) = g(x; θI ) are given by a hypernetwork f as
θI = f (I). In this paper, we deﬁne the property of modularity as the ability to effectively learn a different function for each input instance I. For this purpose, we adopt an expressivity perspective of this property and extend the theory of [6] and provide a lower bound on the complexity (number of trainable parameters) of neural networks as function approximators, by eliminating the requirements for the approximation method to be robust. Our results are then used to compare the complexities of q and g, showing that under certain conditions and when letting the functions e and f be as large as we wish, g can be smaller than q by orders of magnitude. This sheds light on the modularity of hypernetworks in comparison with the embedding-based method. Besides, we show that for a structured target function, the overall number of trainable parameters in a hypernetwork is smaller by orders of magnitude than the number of trainable parameters of a standard neural network and an embedding method. 1

Introduction
Conditioning refers to the existence of multiple input signals. For example, in an autoregressive model, where the primary input is the current hidden state or the output of the previous time step, a conditioning signal can drive the process in the desired direction. When performing text to speech with WaveNets [35], the autoregressive signal is concatenated to the conditioning signal arising from the language features. Other forms of conditioning are less intuitive. For example, in Style
GANs [16], conditioning takes place by changing the weights of the normalization layers according to the desired style.
In various settings, it is natural to treat the two inputs x and I of the target function y(x, I) as nested, i.e., multiple inputs x correspond to the ‘context’ of the same conditioning input I. A natural modeling [4, 30, 27] is to encode the latter by some embedding network e and to concatenate it to x when performing inference q(x, e(I)) with a primary network q. A less intuitive solution, commonly referred to as a hypernetwork, uses a primary network g whose weights are not directly learned. Instead, g has a ﬁxed architecture, and a second network f generates its weights based on the conditioning input as θI = f (I). The network g, with the weights θI can then be applied to any input x.
Hypernetworks hold state of the art results on numerous popular benchmarks [1, 36, 2, 37, 22], especially due to their ability to adapt g for different inputs I. This allows the hypernetwork to model tasks effectively, even when using a low-capacity g. This lack of capacity is offset by using very large networks f . For instance, in [21], a deep residual hypernetwork that is trained from scratch 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
outperforms numerous embedding-based networks that rely on ResNets that were pre-trained on
ImageNet.
The property of modularity means that through f , the network g is efﬁciently parameterized. Consider the case in which we ﬁt individual functions g(cid:48)
I to model each function yI = y(·, I) independently (for any ﬁxed I). To successfully ﬁt any of these functions, g(cid:48)
I would require some degree of minimal complexity in the worst case. We say that modularity holds if the primary network g whose weights are given by f (I) has the same minimal complexity as required by g(cid:48)
I in the worst case.
In this paper, we seek to understand this phenomenon. For this purpose, we compare two alternatives: the standard embedding method and the hypernetwork. Since neural networks often have millions of weights while embedding vectors have a dimension that is seldom larger than a few thousand, it may seem that f is much more complex than e. However, in hypernetworks, often the output of f is simply a linear projection of a much lower dimensional bottleneck [21]. More importantly, it is often the case that the function g can be small, and it is the adaptive nature (where g changes according to
I) that enables the entire hypernetwork (f and g together) to be expressive.
In general, the formulation of hypernetworks covers embedding-based methods. This implies that hypernetworks are at least as good as the embedding-based method and motivates the study of whether hypernetworks have a clear and measurable advantage. Complexity analysis provides a coherent framework to compare the two alternatives. In this paper, we compare the minimal parameter complexity needed to obtain a certain error in each of the two alternatives.
Contributions
The central contributions of this paper are: (i) Thm. 1 extends the theory of [6] and provides a lower bound on the number of trainable parameters of a neural network when approximating smooth functions. In contrast to previous work, our result does not require that the approximation method is robust. (ii) In Thms. 2-4, we compare the complexities of the primary functions under the two methods (q and g) and show that for a large enough embedding function, the hypernetwork’s primary g can be smaller than q by orders of magnitude. (iii) In Thm. 5, we show that under common assumptions on the function to be approximated, the overall number of trainable parameters in a hypernetwork is much smaller than the number of trainable parameters of a standard neural network. (iv) To validate the theoretical observations, we conducted experiments on synthetic data as well as on self-supervised learning tasks.
To summarize, since Thm. 1 shows the minimal complexity for approximating smooth target functions, and Thm. 4 demonstrates that this is attainable by a hypernetwork, we conclude that hypernetworks are modular. In contrast, embedding methods are not since, as Thms. 2-3 show, they require a signiﬁcantly larger primary.