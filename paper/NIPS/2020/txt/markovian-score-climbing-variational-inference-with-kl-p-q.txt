Abstract
Modern variational inference (VI) uses stochastic gradients to avoid intractable expectations, enabling large-scale probabilistic inference in complex models.
VI posits a family of approximating distributions q and then ﬁnds the mem-ber of that family that is closest to the exact posterior p. Traditionally, VI algorithms minimize the “exclusive Kullback-Leibler (KL)” KL (q p), often for computational convenience. Recent research, however, has also focused on the “inclusive KL” KL (p q), which has good statistical properties that makes it more appropriate for certain inference problems. This paper develops a simple algorithm for reliably minimizing the inclusive KL using stochastic gradients with vanishing bias. This method, which we call Markovian score climbing (MSC), converges to a local optimum of the inclusive KL. It does not suffer from the systematic errors inherent in existing methods, such as Reweighted
Wake-Sleep and Neural Adaptive Sequential Monte Carlo, which lead to bias in their ﬁnal estimates. We illustrate convergence on a toy model and demonstrate the utility of MSC on Bayesian probit regression for classiﬁcation as well as a stochastic volatility model for ﬁnancial data. k k 1

Introduction
Variational inference (VI) is an optimization-based approach for approximate posterior inference.
It posits a family of approximating distributions q and then ﬁnds the member of that family that is closest to the exact posterior p. Traditionally, VI algorithms minimize the “exclusive Kullback-Leibler (KL)” KL (q p) [28, 6], which leads to a computationally convenient optimization. For a restricted class of models, it leads to coordinate-ascent algorithms [20]. For a wider class, it leads to efﬁcient computation of unbiased gradients for stochastic optimization [51, 58, 52].
However, optimizing the exclusive KL results in an approximation that underestimates the pos-terior uncertainty [42]. To address this limitation, VI researchers have considered alternative divergences [35, 15]. One candidate is the “inclusive KL” KL (p q) [22, 7, 19]. This diver-gence more accurately captures posterior uncertainty, but results in a challenging optimization problem. k k
In this paper, we develop Markovian score climbing (MSC), a simple algorithm for reliably minimizing the inclusive KL. Consider a valid Markov chain Monte Carlo (MCMC) method [55], a Markov chain whose stationary distribution is p. MSC iteratively samples the Markov chain z[k], and then uses those samples to follow the score function of the variational approximation log q(z[k]) with a Robbins-Monro step-size schedule [54]. Importantly, we allow the MCMC r method to depend on the current variational approximation. This enables a gradual improvement 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
of the MCMC as the VI converges. We illustrate this link between the methods by using conditional importance sampling (CIS) or conditional sequential Monte Carlo (CSMC) [2].
Other VI methods have targeted the same objective, including reweighted wake-sleep (RWS)
[7] and neural adaptive sequential Monte Carlo (SMC) [22]. However, these methods involve biased gradients of the inclusive KL, which leads to bias in their ﬁnal estimates. In contrast, MSC provides consistent gradients for essentially no added cost while providing better variational approximations. MSC provably converges to an optimum of the inclusive KL.
In empirical studies, we demonstrate the convergence properties and advantages of MSC. First, we illustrate the systematic errors of the biased methods and how MSC differs on a toy skew-normal model. Then we compare MSC with expectation propagation (EP) and importance sampling (IS)-based optimization [7, 19] on a Bayesian probit classiﬁcation example with benchmark data.
Finally, we apply MSC and SMC-based optimization [22] to ﬁt a stochastic volatility model on exchange rate data.
Contributions. The contributions of this paper are (i) developing Markovian score climbing, a simple algorithm that provably minimizes KL (p q); (ii) studying systematic errors in existing methods that lead to bias in their variational approximation; and (iii) empirical studies that conﬁrm convergence and illustrates the utility of MSC. k