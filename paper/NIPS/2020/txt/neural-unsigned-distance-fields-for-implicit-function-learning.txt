Abstract
In this work we target a learnable output representation that allows contin-uous, high resolution outputs of arbitrary shape. Recent works represent 3D surfaces implicitly with a Neural Network, thereby breaking previous barriers in resolution, and ability to represent diverse topologies. However, neural implicit representations are limited to closed surfaces, which divide the space into inside and outside. Many real world objects such as walls of a scene scanned by a sensor, clothing, or a car with inner structures are not closed. This constitutes a signiﬁcant barrier, in terms of data pre-processing (objects need to be artiﬁcially closed creating artifacts), and the ability to output open surfaces. In this work, we propose Neural Distance Fields (NDF), a neural network based model which predicts the unsigned distance
ﬁeld for arbitrary 3D shapes given sparse point clouds. NDF represent surfaces at high resolutions as prior implicit models, but do not require closed surface data, and signiﬁcantly broaden the class of representable shapes in the output. NDF allow to extract the surface as very dense point clouds and as meshes. We also show that NDF allow for surface normal calculation and can be rendered using a slight modiﬁcation of sphere tracing.
We ﬁnd NDF can be used for multi-target regression (multiple outputs for one input) with techniques that have been exclusively used for rendering in graphics. Experiments on ShapeNet [13] show that NDF, while simple, is the state-of-the art, and allows to reconstruct shapes with inner structures, such as the chairs inside a bus. Notably, we show that NDF are not restricted to 3D shapes, and can approximate more general open surfaces such as curves, manifolds, and functions. Code is available for research at [1]. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
SDF/Occ
Closed Surfaces (cid:51) (cid:51)
Open Surfaces (cid:55) (cid:51)
Functions (cid:55) (cid:51)
Manifolds (cid:55) (cid:51)
Complex surfaces (cid:55) (cid:51)
NDF
Figure 2: Recent works rely on occupancies or signed distances to represent surfaces, which limits shapes to be closed. In NDF, we learn with an un-signed distance ﬁeld representation, allowing us to reconstruct a broader class of shapes. 1

Introduction
Reconstructing continuous and renderable surfaces from unstructured and incomplete 3D point-clouds is a fundamental problem in robotics, vision and graphics. The choice of shape representation is central for eﬀective learning. There have been a growing number of papers on implicit function learning (IFL) for shape representation and reconstruction tasks [53, 14, 49, 68, 15, 27, 11, 10]. The idea is to train a neural network which classiﬁes continuous points in 3D as inside or outside the surface via occupancies or signed distance
ﬁelds (SDF). Compared to point, mesh or voxels-based methods, IFL can output continuous surfaces of arbitrary resolution and can handle more topologies.
A major limitation of existing IFL approaches is that they can only output closed surfaces – that is, surfaces which divide the 3D space into inside and outside the surface. Many real world objects such as cars, cylinders, or a wall of a scanned 3D scene can not be represented.
This is a barrier, both in terms of tedious data pre-processing — surfaces need to be closed which often leads to artifacts and loss of detail — and more importantly the ability to output open surfaces.
In this paper, we introduce Neural Distance Fields (NDF), which do not suﬀer from the above limitations and are a more general shape representation for learning. NDF directly predict the unsigned distance ﬁeld (UDF) to the surface – we regress, for a point p ∈ Rd, the distance to the surface S ⊂ Rd with a learned function f (p) : Rd 7→ R+ 0 whose zero-levelset f (p) = 0 represents the surface. In contrast to SDFs or occupancies, this allows to naturally represent surfaces which are open, or contain objects inside, like the bus with chairs inside in Figure 2. Furthermore, NDF is not limited to 3D shape representation (d = 3), but allows to represent functions, open curves and surface manifolds (we experimented with d = 2, 3), which is not possible when using occupancy or SDFs.
Learning with UDF poses new challenges. Several applications require extracting point clouds, meshes or directly rendering the implicit surface onto an image, which requires
ﬁnding its zero-levelset. Most classical methods, such as marching cubes [48] and volume rendering [23], ﬁnd the zero-levelset by detecting ﬂips from inside to outside and vice versa, which is not possible with UDF. However, exploiting properties of UDFs and fast gradient evaluation of NDF, we introduce easy to implement algorithms to compute dense point clouds and meshes, as well as rendered images from NDF.
Experiments on ShapeNet [13] demonstrate that NDF signiﬁcantly outperform the state-of-the-art (SOTA) and, unlike all IFL competitors except [5], do not require pre-computing closed meshes for training. More importantly, in comparison to all IFL methods (including [5]), we can represent and reconstruct shapes with inner structures and layering. To demonstrate the wide applicability of NDF beyond 3D shape reconstruction, we use them for classical regression tasks – we interpolate linear, quadratic and sinusoidal functions, as well as manifold data, such as spirals, which is not possible with occupancies or SDFs. In contrast to standard regression based on L2 or L1 losses which tends to average multiple modes, NDF can naturaly produce multiple outputs for a single input. Interestingly, we show that function regression y = f (x) can be cast as sphere tracing the NDF, eﬀectively leveraging a classical graphics technique for a core machine learning task.
In summary, we make the following contributions: 2
• We introduce NDF as a new representation for 3D shape learning, which in contrast to occupancies or SDFs, do not require to artiﬁcially close shapes for training, and can represent open surfaces, shapes with inner structures, and open manifolds.
• We obtain SOTA results on reconstruction from point clouds on ShapeNet using
NDF.
• We contribute simple yet eﬀective algorithms to generate dense point-clouds, normals, meshes and render images from NDF.
• To encourage further research in this new direction, we make code and model publicly available at https://virtualhumans.mpi-inf.mpg.de/ndf/. 2