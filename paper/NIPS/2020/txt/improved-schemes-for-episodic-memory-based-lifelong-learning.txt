Abstract
Current deep neural networks can achieve remarkable performance on a single task. However, when the deep neural network is continually trained on a sequence of tasks, it seems to gradually forget the previous learned knowledge. This phe-nomenon is referred to as catastrophic forgetting and motivates the ﬁeld called lifelong learning. Recently, episodic memory based approaches such as GEM [1] and A-GEM [2] have shown remarkable performance. In this paper, we provide the ﬁrst uniﬁed view of episodic memory based approaches from an optimization’s perspective. This view leads to two improved schemes for episodic memory based lifelong learning, called MEGA-I and MEGA-II. MEGA-I and MEGA-II mod-ulate the balance between old tasks and the new task by integrating the current gradient with the gradient computed on the episodic memory. Notably, we show that GEM and A-GEM are degenerate cases of MEGA-I and MEGA-II which consistently put the same emphasis on the current task, regardless of how the loss changes over time. Our proposed schemes address this issue by using novel loss-balancing updating rules, which drastically improve the performance over
GEM and A-GEM. Extensive experimental results show that the proposed schemes signiﬁcantly advance the state-of-the-art on four commonly used lifelong learning benchmarks, reducing the error by up to 18%. Implementation is available at: https://github.com/yunhuiguo/MEGA

Introduction 1
A signiﬁcant step towards artiﬁcial general intelligence (AGI) is to enable the learning agent to acquire the ability of remembering past experiences while being trained on a continuum of tasks
[3, 4, 5]. Current deep neural networks are capable of achieving remarkable performance on a single task [6]. However, when the network is retrained on a new task, its performance drops drastically on previously trained tasks, a phenomenon which is referred to as catastrophic forgetting
[7, 8, 9, 10, 11, 12, 13, 14]. In stark contrast, the human cognitive system is capable of acquiring new knowledge without damaging previously learned experiences.
The problem of catastrophic forgetting motivates the ﬁeld called lifelong learning [4, 11, 14, 15, 16, 17, 18, 19]. A central dilemma in lifelong learning is how to achieve a balance between the performance on old tasks and the new task [4, 7, 18, 20]. During the process of learning the new task, the originally learned knowledge will typically be disrupted, which leads to catastrophic forgetting.
On the other hand, a learning algorithm biasing towards old tasks will interfere with the learning of the new task. Several lines of methods are proposed recently to address this issue. Examples include regularization based methods [4, 21, 22], knowledge transfer based methods [23] and episodic memory based methods [1, 2, 24]. Especially, episodic memory based methods such as Gradient
Episodic Memory (GEM) [1] and Averaged Gradient Episodic Memory (A-GEM) [2] have shown remarkable performance. In episodic memory based methods, a small episodic memory is used for storing examples from old tasks to guide the optimization of the current task.
⇤ Equal contribution. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
In this paper, we present the ﬁrst uniﬁed view of episodic memory based lifelong learning methods, including GEM [1] and A-GEM [2], from an optimization’s perspective. Speciﬁcally, we cast the problem of avoiding catastrophic forgetting as an optimization problem with composite objective.
We approximately solve the optimization problem using one-step stochastic gradient descent with the standard gradient replaced by the proposed Mixed Stochastic Gradient (MEGA). We propose two different schemes, called MEGA-I and MEGA-II, which can be used in different scenarios. We show that both GEM [1] and A-GEM [2] are degenerate cases of MEGA-I and MEGA-II which consistently put the same emphasis on the current task, regardless of how the loss changes over time.
In contrast, based on our derivation, the direction of the proposed MEGA-I and MEGA-II balance old tasks and the new task in an adaptive manner by considering the performance of the model in the learning process.
Our contributions are as follows. (1) We present the ﬁrst uniﬁed view of current episodic memory based lifelong learning methods including GEM [1] and A-GEM [2]. (2) From the presented uniﬁed view, we propose two different schemes, called MEGA-I and MEGA-II, for lifelong learning problems. (3) We extensively evaluate the proposed schemes on several lifelong learning benchmarks, and the results show that the proposed MEGA-I and MEGA-II signiﬁcantly advance the state-of-the-art performance. We show that the proposed MEGA-I and MEGA-II achieve comparable performance in the existing setting for lifelong learning [2]. In particular, MEGA-II achieves an average accuracy 0.10% on Permuted MNIST, which is 2% better than the previous state-of-the-art model. of 91.21
On Split CIFAR, our proposed MEGA-II achieves an average accuracy of 66.12 1.93%, which is about 5% better than the state-of-the-art method. (4) Finally, we show that the proposed MEGA-II outperforms MEGA-I when the number of examples per task is limited. We also analyze the reason for the effectiveness of MEGA-II over MEGA-I in this case.
±
± 2