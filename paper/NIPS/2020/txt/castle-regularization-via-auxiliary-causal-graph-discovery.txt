Abstract
Regularization improves generalization of supervised models to out-of-sample data.
Prior works have shown that prediction in the causal direction (effect from cause) results in lower testing error than the anti-causal direction. However, existing regularization methods are agnostic of causality. We introduce Causal Structure
Learning (CASTLE) regularization and propose to regularize a neural network by jointly learning the causal relationships between variables. CASTLE learns the causal directed acyclical graph (DAG) as an adjacency matrix embedded in the neural network’s input layers, thereby facilitating the discovery of optimal predictors. Furthermore, CASTLE efﬁciently reconstructs only the features in the causal DAG that have a causal neighbor, whereas reconstruction-based regularizers suboptimally reconstruct all input features. We provide a theoretical generalization bound for our approach and conduct experiments on a plethora of synthetic and real publicly available datasets demonstrating that CASTLE consistently leads to better out-of-sample predictions as compared to other popular benchmark regularizers. 1

Introduction
A primary concern of machine learning, and deep learning in particular, is generalization performance on out-of-sample data. Over-parameterized deep networks efﬁciently learn complex models and are, therefore, susceptible to overﬁt to training data. Common regularization techniques to mitigate overﬁtting include data augmentation [1, 2], dropout [3, 4, 5], adversarial training [6], label smoothing
[7], and layer-wise strategies [8, 9, 10] to name a few. However, these methods are agnostic of the causal relationships between variables limiting their potential to identify optimal predictors based on graphical topology, such as the causal parents of the target variable. An alternative approach to regularization leverages supervised reconstruction, which has been proven theoretically and demonstrated empirically to improve generalization performance by obligating hidden bottleneck layers to reconstruct input features [11, 12]. However, supervised auto-encoders suboptimally reconstruct all features, including those without causal neighbors, i.e., adjacent cause or effect nodes.
Naively reconstructing these variables does not improve regularization and representation learning for the predictive model. In some cases, it may be harmful to generalization performance, e.g., reconstructing a random noise variable.
∗Equal contribution 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
Although causality has been a topic of research for decades, only recently has cause and effect rela-tionships been incorporated into machine learning methodologies and research. Recently, researchers at the conﬂuence of machine learning and causal modeling have advanced causal discovery [13, 14], causal inference [15, 16], model explainability [17], domain adaptation [18, 19, 20] and transfer learning [21] among countless others. The existing synergy between these two disciplines has been recognized for some time [22], and recent work suggests that causality can improve and complement machine learning regularization [23, 24, 25]. Furthermore, many recent causal works have demon-strated and acknowledged the optimality of predicting in the causal direction, i.e., predicting effect from cause, which results in less test error than predicting in the anti-causal direction [21, 26, 27, 28].
Contributions.
In this work, we introduce a novel regularization method called CASTLE (CAusal
STructure LEarning) regularization. CASTLE regularization uses causal graph discovery as an auxiliary task when training a supervised model to improve the generalization performance of the primary prediction task. Speciﬁcally, CASTLE learns the causal directed acyclical graph (DAG) under continuous optimization as an adjacency matrix embedded in a feed-forward neural network’s input layers. By jointly learning the causal graph, CASTLE can surpass the beneﬁts provided by feature selection regularizers by identifying optimal predictors, such as the target variable’s causal parents. Additionally, CASTLE further improves upon auto-encoder-based regularization [12] by reconstructing only the input features that have neighbors (adjacent nodes) in the causal graph.
Regularization of a predictive model to satisfy the causal relationships among feature and target variables effectively guide the model towards the direction of better out-of-sample generalization guarantees. We provide a theoretical generalization bound for CASTLE and demonstrate improved performance against a variety of benchmark methods on a plethora of real and synthetic datasets. 2