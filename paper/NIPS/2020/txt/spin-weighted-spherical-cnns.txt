Abstract
Learning equivariant representations is a promising way to reduce sample and model complexity and improve the generalization performance of deep neural net-works. The spherical CNNs are successful examples, producing SO(3)-equivariant representations of spherical inputs. There are two main types of spherical CNNs.
The ﬁrst type lifts the inputs to functions on the rotation group SO(3) and applies convolutions on the group, which are computationally expensive since SO(3) has one extra dimension. The second type applies convolutions directly on the sphere, which are limited to zonal (isotropic) ﬁlters, and thus have limited expressivity.
In this paper, we present a new type of spherical CNN that allows anisotropic
ﬁlters in an efﬁcient way, without ever leaving the spherical domain. The key idea is to consider spin-weighted spherical functions, which were introduced in physics in the study of gravitational waves. These are complex-valued functions on the sphere whose phases change upon rotation. We deﬁne a convolution between spin-weighted functions and build a CNN based on it. The spin-weighted functions can also be interpreted as spherical vector ﬁelds, allowing applications to tasks where the inputs or outputs are vector ﬁelds. Experiments show that our method outperforms previous methods on tasks like classiﬁcation of spherical images, classiﬁcation of 3D shapes and semantic segmentation of spherical panoramas. 1

Introduction
Learning representations from data enables a variety of applications that are not possible with other methods. Convolutional neural networks (CNNs) are powerful tools in representation learning, in great part due to their translation equivariance property that allows weight-sharing, exploiting the natural structure of audio, image, or video inputs.
Recently, there has been signiﬁcant work extending equivariance to other groups of transforma-tions [20, 9, 13, 44, 33, 17, 45, 40, 43, 18, 4] and designing equivariant CNNs on non-Euclidean domains [11, 16, 26, 37, 35, 8, 27, 37, 48]. Successful applications have been demonstrated in tasks such as 3D shape analysis [16, 18], medical imaging [42, 3], satellite/aerial imaging [13, 21], cosmology [13, 35], physics/chemistry [11, 26, 1]. Favorable results were also shown on popular upright natural image datasets such as CIFAR10/100 [39].
Rotation equivariant CNNs are the natural way to learn feature representations on spherical data.
There are two prevailing designs, (a) convolution between spherical functions and zonal (isotropic; constant per latitude) ﬁlters [16], and (b) convolutions on SO(3) after lifting spherical functions to the rotation group [11]. There is a clear distinction between these two designs: (a) is more efﬁcient allowing to build representational capacity through deeper networks, and (b) has more expressive
ﬁlters but is computationally expensive and thus is constrained to shallower networks. The question we consider in this paper is: how can we achieve the expressivity/representation capacity of SO(3) convolutions with the efﬁciency and scalability of spherical convolutions? 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
In this paper, we propose to leverage spin-weighted spherical functions (SWSFs), introduced by
Newman and Penrose [34] in the study of gravitational waves. These are complex-valued functions on the sphere that, upon rotation, suffer a phase change besides the usual spherical translation.
Our key observation is that a combination of SWSFs al-lows more expressive representations than scalar spherical functions, avoiding the need to lift features to the higher dimensional SO(3). It also enables anisotropic ﬁlters, removing the ﬁlter constraint of purely spherical CNNs.
We deﬁne convolutions and cross-correlations of SWSFs.
For bandlimited inputs, the operations can be computed exactly in the spectral domain, and are equivariant to the continuous group SO(3). We build a CNN where ﬁlters and features are sets of SWSFs, and adapt nonlinearities, batch normalization, and pooling layers as necessary.
Besides more expressive and efﬁcient representations, we can interpret the spin-weighted features as equivariant vector ﬁelds on the sphere, enabling applications where the inputs or outputs are vector ﬁelds. Current spherical
CNNs [11, 16, 26, 35] cannot achieve equivariance in this sense, as illustrated in Fig. 1.
To evaluate vector ﬁeld equivariance, we introduce a vari-ation of MNIST where the images and their gradients are projected to the sphere. We propose three tasks on this dataset: 1) vector ﬁeld classiﬁcation, 2) vector ﬁeld pre-diction from scalar ﬁelds, 3) scalar ﬁeld prediction from vector ﬁelds. We also evaluate our model on spherical image classiﬁcation, 3D shape classiﬁcation, and semantic segmentation of spherical panoramas.
To summarize our contributions,
Figure 1: Colors represent a scalar ﬁeld, and the green vectors represent a vector
ﬁeld. Upon rotation, scalar ﬁelds trans-form by simply moving values to an-other position, while vector ﬁelds move and also rotate. Treating vector ﬁelds as multi-channel scalars (bottom-right) results in incorrect behavior. The spin-weighted spherical CNNs equivariantly handle vector ﬁelds as inputs or outputs. 1. We deﬁne the convolution and cross-correlation between sets of spin-weighted spherical functions. These are SO(3) equivariant operations that respect the SWSFs properties. 2. We build a CNN based on these operations and adapt usual CNN components for sets of
SWSFs as features and ﬁlters. This is, to the best of our knowledge, the ﬁrst spherical CNN that operates on vector ﬁelds. 3. We demonstrate the efﬁcacy of the spin-weighted spherical CNNs (SWSCNNs) on a variety of tasks including spherical image and vector ﬁeld classiﬁcation, predicting vector ﬁeld from images and conversely, 3D shape classiﬁcation and spherical image segmentation. 4. We will make our code and datasets publicly available at https://github.com/ daniilidis-group/swscnn. 2