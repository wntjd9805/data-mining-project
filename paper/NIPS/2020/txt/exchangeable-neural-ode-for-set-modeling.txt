Abstract
Reasoning over an instance composed of a set of vectors, like a point cloud, requires that one accounts for intra-set dependent features among elements. However, since such instances are unordered, the elements’ features should remain unchanged when the input’s order is permuted. This property, permutation equivariance, is a challenging constraint for most neural architectures. While recent work has proposed global pooling and attention-based solutions, these may be limited in the way that intradependencies are captured in practice. In this work we propose a more general formulation to achieve permutation equivariance through ordinary differential equations (ODE). Our proposed module, Exchangeable Neural ODE (ExNODE), can be seamlessly applied for both discriminative and generative tasks.
We also extend set modeling in the temporal dimension and propose a VAE based model for temporal set modeling. Extensive experiments demonstrate the efﬁcacy of our method over strong baselines. 1

Introduction
Rd. In some cases, however, the inputs may contain a set of instances, x =
The vast majority of machine learning models operate on an independent and identically distributed n (i.i.d.) vector, x i=1, which jointly determine the target. We note that instances within a set may interact with each other.
For instance, the points inside a point cloud jointly determine the global structure. In this work, we build both discriminative and generative models on sets, which explore the intradependencies within a set to capture both global and local structures. xi}
∈
{
A set is a collection of data that does not possess any inherent ordering of its elements. In statistics, a set is described as an exchangeable sequence of random variables whose joint probability distribution does not change under any permutation π, i.e., p(x1, . . . , xn) = p(xπ1 , . . . , xπn ). (1)
∗equal contribution 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
Discriminative models that operate on a set must predict a target y that is invariant to all permutations.
Applications for such models include population statistics estimation, point cloud classiﬁcation, etc. A naive approach where training data are augmented with random permutations and treated as sequences has been empirically proven insufﬁcient [1]. Previous works [2, 3] developed simple permutation invariant operations by processing each element independently and then aggregating them using a pooling operation (max, mean, etc). However, such an operation largely ignores the intradependencies between elements within the set. In this work, we introduce an inductive bias into the model to exploit said intradependencies across elements. Speciﬁcally, we introduce a permutation equivariant module to explicitly model the dependencies among set elements.
Set generative models with tractable, exchangeable likelihoods have recently been investigated (that is, likelihoods which are invariant to permutations) [3, 4, 5]. Simple approaches that estimate likelihood for each instance independently are insufﬁcient since global structures cannot be inferred.
To overcome this shortcoming, we construct a ﬂow-based generative model for tractable likelihood estimation on sets.
The key for both discriminative and generative set models is a powerful equivariant transformation that captures set intradependencies. In order to compute the likelihood for a ﬂow based generative model, the transformation additionally requires to be invertible. In this work, we propose an exchangeable, invertible ﬂow transformation, ExNODE, based on Neural Ordinary Differential Equation (NODE)
[6]. Invertibility is guaranteed via the NODE framework since integration backward in time is always possible. We implement ExNODE by parametrizing a differential equation with a permutation equivariant architecture.
In addition to modeling the sets in spatial dimensions, we extend ExNODE to the temporal dimension and propose a temporal set modeling task. Such a set model has many potential applications, including modeling the evolution of galaxies, pedestrian tracking, etc. Here, we utilize a VAE-based framework with our proposed set generative model as the decoder. The temporal evolution is captured by another
ODE in the latent space. After training, our model can interpolate and extrapolate to generate sets at unseen (potentially fractional) time steps.
Our contributions are as follows: 1) We propose ExNODE, an exchangeable module for set modeling, which explicitly captures the intradependencies among set elements. 2) ExNODE represents a type of invertible ﬂow transformation on which the invariant set likelihood can be achieved. 3) We propose a temporal set modeling task and a VAE-based model for time variant set modeling. The temporal
VAE utilizes differential equations to transit hidden states in time. To the best of our knowledge, our model is the ﬁrst one designed for temporal sets. 4) We achieve state-of-the-art performance for both point cloud classiﬁcation and likelihood estimation. 2