Abstract
While semi-supervised learning (SSL) has proven to be a promising way for leveraging unlabeled data when labeled data is scarce, the existing SSL algorithms typically assume that training class distributions are balanced. However, these SSL algorithms trained under imbalanced class distributions can severely suffer when generalizing to a balanced testing criterion, since they utilize biased pseudo-labels of unlabeled data toward majority classes. To alleviate this issue, we formulate a convex optimization problem to softly reﬁne the pseudo-labels generated from a biased model, and develop a simple iterative algorithm, named Distribution
Aligning Reﬁnery of Pseudo-label (DARP) that solves it provably and efﬁciently.
Under various class-imbalanced semi-supervised scenarios, we demonstrate the effectiveness of DARP and its compatibility with state-of-the-art SSL schemes. 1

Introduction
It has been repeatedly shown that deep neural networks (DNNs) can achieve human- or super-human-level performances on various tasks [1, 17, 32]. This success, however, crucially relies on the availability of large-scale labeled datasets, which typically requires a lot of human efforts to be constructed. For example, the cost for labeling sequential (such as video and speech) data is often proportional to their lengths. Furthermore, some speciﬁc domain knowledge is often critical for labeling (such as medical) data. Semi-supervised learning (SSL) is one of promising, conventional ways to bypass this cost by leveraging unlabeled data for improving the performance of DNNs, given a small amount of labeled data [4, 5, 42]. The common approach of these modern state-of-the-art
SSL algorithms is producing pseudo-labels for unlabeled data based on a model’s prediction and then utilize the generated pseudo-labels for training the model iteratively [28, 36].
Most previous works on the line usually assume a balanced class distribution for both labeled and unlabeled datasets. However, in many realistic scenarios, the underlying class distribution of training data is highly imbalanced [27, 37]. It is well known that such an imbalanced class distribution hurts the generalization of DNNs, i.e., makes their predictions to be biased toward majority classes [13].
In other words, DNNs trained under an imbalanced class distribution suffer when generalizing to a balanced testing criterion. This issue can be more problematic for SSL algorithms since they generate pseudo-labels of unlabeled data from the model’s biased predictions, i.e., pseudo-labels are even more severely imbalanced compared to true labels of labeled or unlabeled data. For example, when we train a Wide ResNet [43] on CIFAR-10 [12] under the imbalance ratio γ = 1501 using a recent 1The number of training samples of a class (in both labeled and unlabeled datasets) is up to 150 times smaller than that of another class. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
(a) Imbalanced class distribution (b) Bias of pseudo-labels (c) Accuracy gain from SSL
Figure 1: Experimental results on CIFAR-10 under the imbalance ratio γ = 150. (a) Class distribution of labeled and unlabeled data. (b) Relative size of pseudo-labels compares to size of true labels for each SSL algorithm. It is noticeable that the models fail to generate pseudo-labels on minority classes; hence the imbalance ratio of pseudo-labels is much larger than a true ratio γ = 150. (c) Test accuracy gain due to SSL algorithms compares to the vanilla model trained using only labeled data.
SSL algorithm, MixMatch [5], the resulting imbalance ratio of pseudo-labels becomes γ = 1046, which is much larger than the true ratio γ = 150 (see Figure 1(b) for detailed class-wise statistics).
Due to the aforementioned reason, we found that the performance of classiﬁers trained by recent
SSL algorithms under the imbalanced class distribution often degrades on minority classes, even compared to the vanilla scheme using only labeled training samples (see Figure 1(c)). This implies that utilizing imbalanced unlabeled data for training can be dangerous for the classes having relatively small number of samples. Identifying a potential risk under class-imbalanced SSL scenarios is an important but under-explored research problem, up to date.
Contribution. To handle the issue, we propose a simple technique, coined distribution aligning reﬁnery of pseudo-label (DARP), applicable to any existing SSL scheme utilizing pseudo-labels of unlabeled data. Our high-level idea is to reﬁne the original, biased pseudo-labels so that their distribution can match the true class distribution of unlabeled data. Importantly, we also constrain our reﬁned pseudo-labels to be not too far from the original pseudo-labels (constructed by an SSL algorithm). Without such a constraint, the individual quality of reﬁned pseudo-labels can be poor, even when their overall distribution matches the true distribution. Motivated by the insight, we formulate an optimization problem for constructing reﬁned pseudo-labels: minimizing the distortion from the original pseudo-labels, while matching the true class distribution.
The DARP algorithm is an efﬁcient, iterative procedure to solve the proposed (convex) optimization with a provable guarantee. It ﬁnds the unique optimal solution by solving the Lagrangian dual of the original optimization. To further enhance the quality of the reﬁned pseudo-labels, we additionally suggest removing some small and noisy entries in the original pseudo-labels when running DARP.
We demonstrate the effectiveness of the proposed approach under various realistic scenarios by varying the imbalanced class distributions. Despite its simplicity, the proposed DARP algorithm improves recent state-of-the-art SSL algorithms in all test cases, e.g., our method improves MixMatch
[5], ReMixMatch [4] and FixMatch [35] with up to 77.2%, 31.4% and 53.1% relative reduction on the balanced test error, respectively. As expected, we ﬁnd that our method is more effective when the (class) distribution mismatch between labeled and unlabeled data becomes severe. We believe that
DARP method can be a strong baseline when other researchers pursue the related tasks in the future. 2