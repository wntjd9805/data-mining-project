Abstract
This paper describes a simple technique to analyze Generative Adversarial Net-works (GANs) and create interpretable controls for image synthesis, such as change of viewpoint, aging, lighting, and time of day. We identify important latent direc-tions based on Principal Component Analysis (PCA) applied either in latent space or feature space. Then, we show that a large number of interpretable controls can be deﬁned by layer-wise perturbation along the principal directions. Moreover, we show that BigGAN can be controlled with layer-wise inputs in a StyleGAN-like manner. We show results on different GANs trained on various datasets, and demon-strate good qualitative matches to edit directions found through earlier supervised approaches. 1

Introduction
Generative Adversarial Networks (GANs) [8], like BigGAN [5] and StyleGAN [10, 11], are powerful image synthesis models that can generate a wide variety of high-quality images, and have already been adopted by digital artists [2]. Unfortunately, such models provide little direct control over image content, other than selecting image classes or adjusting StyleGAN’s style vectors. Current attempts to add user control over the output focus on supervised learning of latent directions [9, 7, 25, 19, 16],
GAN training with labeled images [12, 22, 21]. However, this requires expensive manual supervision for each new control to be learned. A few methods provide useful control over spatial layout of the generated image [14, 26, 4, 3], provided a user is willing to paint label or edge maps.
This paper shows how to identify new interpretable control directions for existing GANs, without re-quiring post hoc supervision or expensive optimization: rather than setting out to ﬁnd a representation for particular concepts (“show me your representation for smile”), our exploratory approach makes it easy to browse through the concepts that the GAN has learned. We build on two main discoveries.
First, we show that important directions in GAN latent spaces can be found by applying Principal
Component Analysis (PCA) in latent space for StyleGAN, and feature space for BigGAN. Second, we show how BigGAN can be modiﬁed to allow StyleGAN-like layer-wise style mixing and control, without retraining. Using these ideas, we show that layer-wise decomposition of PCA edit directions leads to many interpretable controls. Identifying useful control directions then involves an optional one-time user labeling effort.
These mechanisms are algorithmically extremely simple, but lead to surprisingly powerful controls.
They allow control over image attributes that vary from straightforward high-level properties such as object pose and shape, to many more-nuanced properties like lighting, facial attributes, and landscape attributes (Figure 1). These directions, moreover, provide understanding about how the
GAN operates, by visualizing its “EiGANspace.” We show results with BigGAN512-deep and many different StyleGAN and StyleGAN2 models, and demonstrate many novel types of image controls.
One approach is to attempt to train new GANs to be disentangled, e.g., [17]. However, training general models like BigGAN requires enormous computational resources beyond the reach of nearly all potential researchers and users. Hence, we expect that research to interpret and extend the capabilities of existing GANs will become increasingly important. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
Initial image change color
E(v22, 9-10)
E(v41, 9-10) add grass
E(v0, 0-4) rotate
E(v16, 3-5) change type
Initial image add wrinkles hair color
E(v20, 6)
E(v57, 7-8)
E(v23, 3-5) expression
E(v27, 8-17) overexpose s r a
C 2
N
A
G e l y t
S 2
N
A
G e l y t
S
Q
H
F
F p e e d
-2 1 5
N
A
G g i
B r e t t e s h s i r
I
Initial image rotate zoom out show horizon change scenery
E(u3, all)
E(u12, all)
E(u15, 1-5)
E(u61, 4-7)
Figure 1: Sequences of image edits performed using control discovered with our method, applied to three different GANs. The white insets specify the edits using notation explained in Section 2.3. 2 Discovering GAN Controls
This section describes our new techniques for augmenting existing GANs with new control variables.
Our techniques are, algorithmically, very simple. This simplicity is an advantage: for very little effort, these methods enable a range of powerful tools for analysis and control of GANs, that have previously not been demonstrated, or else required expensive supervision. In this paper, we work exclusively with pretrained GANs. 2.1