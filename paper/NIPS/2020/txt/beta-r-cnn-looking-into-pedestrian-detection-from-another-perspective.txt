Abstract
Recently signiﬁcant progress has been made in pedestrian detection, but it remains challenging to achieve high performance in occluded and crowded scenes. It could be attributed mostly to the widely used representation of pedestrians, i.e., 2D axis-aligned bounding box, which just describes the approximate location and size of the object. Bounding box models the object as a uniform distribution within the boundary, making pedestrians indistinguishable in occluded and crowded scenes due to much noise. To eliminate the problem, we propose a novel representation based on 2D beta distribution, named Beta Representation. It pictures a pedestrian by explicitly constructing the relationship between full-body and visible boxes, and emphasizes the center of visual mass by assigning different probability values to pixels. As a result, Beta Representation is much better for distinguishing highly-overlapped instances in crowded scenes with a new NMS strategy named
BetaNMS. What’s more, to fully exploit Beta Representation, a novel pipeline
Beta R-CNN equipped with BetaHead and BetaMask is proposed, leading to high detection performance in occluded and crowded scenes. Code will be released at github.com/Guardian44x/Beta-R-CNN. 1

Introduction
Pedestrian detection is a critical research topic in computer vision ﬁeld with various real-world applications such as autonomous vehicles, intelligent video surveillance, robotics, and so on. During the last decade, with the rise of deep convolutional neural networks (CNNs), great progress has been achieved in pedestrian detection. However, it remains challenging to accurately distinguish pedestrians in occluded and crowded scenes.
Although extensive methods have been attempted for occlusion and crowd issues, the performance is still limited by pedestrian representation, i.e., 2D bounding box representation. The axis-aligned minimum bounding box is widely utilized to explicitly deﬁne a distinct object, with its approximate location and size. Although box representation has advantages such as parameterization- and annotation-friendly as the identity of an object, some nonnegligible drawbacks are limiting the performance of pedestrian detection especially in occluded and crowded scenes. Firstly, the bounding box can be regarded as modeling the object as a uniform distribution in the box, but it actually goes against our intuitive perception. Given an occluded pedestrian, what attracts our attention should be the visible part rather than the occluded noise. Secondly, based on box representation, intersection
∗These authors contributed equally 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
Figure 1: Beta distributions have ﬂexible shapes with different peaks and FWHMs.
Figure 2: Beta Representation samples and compar-isons between IoU and KL divergence. over union (IoU) serves as the metric to measure the difference between objects, which results in difﬁculty to distinguish highly-overlapped instances in crowded scenes. As shown in Fig. 2, even if the detectors succeed to identify different human instances in a crowded scene, the highly-overlapped detections may also be suppressed by the post-processing of non-maximum suppression (NMS). Last, the full-body and visible boxes treat a distinct person as two separate parts, which omit their inner relationship as a whole and lead to difﬁculty for model optimization.
To eliminate the weaknesses of box representation and preserve its advantages in the meanwhile, we propose a novel representation for pedestrians based on 2D beta distribution, named Beta
Representation. In probability theory, the beta distribution is a family of continuous probability distribution deﬁned in the interval [0, 1], as depicted in Fig. 1. By assigning different values to α, β, we could control the shape of the beta distribution, especially the peak and the full width at half maximum (FWHM), which is naturally suitable for pedestrian representation with unpredictable visible patterns. We take each pedestrian as a 2D beta distribution on the image and generate eight new parameters as the Beta Representation. As illustrated in Fig. 2, the boundary of 2D beta distribution is consistent with the full-body box, while the peak along with FWHM depends on the relation between the visible part and full-body box. Compared with paired boxes, i.e., full-body and visible boxes, 2D beta distribution treats each pedestrian more like an integrated whole and emphasizes the object center of visual mass meanwhile.
Besides, instead of IoU, Kullback-Leibler (KL) divergence is adopted as a new metric to measure the distance of two objects and the beta-distribution-based NMS strategy is named BetaNMS. Fig. 2 illustrates that while the bounding boxes are too close to distinguish (fIoU > 0.5, vIoU > 0.32), the 2D beta distributions still maintain high discrimination (KL > 7) between each other, thereby leading to better performance in distinguishing highly-overlapped instances.
Moreover, to fully exploit Beta Representation in pedestrian detection, we design a novel pedestrian detector named Beta R-CNN, equipped with two different key modules, i.e., BetaHead and BetaMask.
BetaHead is utilized to regress the eight beta parameters and the class score, while BetaMask serves as an attention mechanism to modulate the extracted feature with beta-distribution-based masks.
Experiments on the extremely crowded benchmark CrowdHuman [1] and CityPersons [2] show that our proposed approach can outperform the state-of-the-art results, which strongly validate the superiority of our method. 2