Abstract
The Learnable Tree Filter presents a remarkable approach to model structure-preserving relations for semantic segmentation. Nevertheless, the intrinsic geomet-ric constraint forces it to focus on the regions with close spatial distance, hindering the effective long-range interactions. To relax the geometric constraint, we give the analysis by reformulating it as a Markov Random Field and introduce a learnable unary term. Besides, we propose a learnable spanning tree algorithm to replace the original non-differentiable one, which further improves the ﬂexibility and robust-ness. With the above improvements, our method can better capture long-range de-pendencies and preserve structural details with linear complexity, which is extended to several vision tasks for more generic feature transform. Extensive experiments on object detection/instance segmentation demonstrate the consistent improvements over the original version. For semantic segmentation, we achieve leading perfor-mance (82.1% mIoU) on the Cityscapes benchmark without bells-and-whistles.
Code is available at https://github.com/StevenGrove/LearnableTreeFilterV2. 1

Introduction
In the last decade, the vision community has witnessed the extraordinary success of deep convolutional networks in various vision tasks [1–8]. However, in deep convolutional layers, the distribution of impact within an effective receptive ﬁeld is found to be limited to a local region and converged to the gaussian [9], which brings difﬁculties to the long-range dependencies modeling. To address this problem, numerous local-based approaches [10–12] have been proposed to increase the receptive region of convolutional kernels by using pooling [13] or dilated operations [14]. Meanwhile, various global-based approaches [15–19] have been explored to aggregate features by modeling the pairwise relations based on the visual attention mechanism. However, there is still a conﬂict between long-range dependencies modeling and object details preserving.
Recently, the learnable tree ﬁlter module [20] (LTF-V1 module) tries to bridge this gap by performing feature aggregation on a minimum spanning tree. Since the minimum spanning tree is generated by the low-level guided features, it can retain the structural details with efﬁciency. Nevertheless, the geometric constraint and the construction process in the LTF-V1 module are found to be its Achilles’ heels, which impede the usage for more generic feature transform. Firstly, the interactions with distant nodes along the spanning tree need to pass through nearby nodes, which brings the intrinsic geometric constraint to the tree ﬁlter. As illustrated in Fig. 1, this property forces the LTF-V1 module
∗Corresponding author. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
Figure 1: The comparison of the aggregation processes between the LTF-V1 module [20] and the proposed LTF-V2 module. One of the sink nodes is marked by the red square, and the corresponding source nodes with the highest ﬁltering weights are presented as the blue squares. Limited by the intrinsic geometric constraint, the LTF-V1 can only give priority to the regions with close spatial distance. Different from it, our proposed LTF-V2 is more generic by adding a learnable unary term, which relaxes the geometric constraint and allows the ﬁlter to focus on the distant regions of interest. to focus on the nearby regions. In addition, the construction process of the minimum spanning tree is non-differentiable, which is overly sensitive to the quality of guided features and prevents the LTF-V1 module from entirely learnable.
To remedy the shortages mentioned above, we rethink the learnable tree ﬁlter from the perspective of Markov Random Field [21] (MRF) and present the Learnable Tree Filter V2 Module (LTF-V2 module) for more generic feature transform. Speciﬁcally, it complements the LTF-V1 module by introducing a learnable unary term and a learnable spanning tree algorithm. The former one provides a modulation scalar [22–24] for each node, which can relax the geometric constraint and enable effective long-range interactions. Intuitively, as shown in the Fig. 1, the proposed unary term guides the LTF-V2 to focus on the coarsely distant regions of interest, and the tree-based pairwise term further reﬁnes the regions to ﬁt original structures, bringing powerful semantic representations.
Meanwhile, the proposed learnable spanning tree algorithm offers a simple and effective strategy to create a gradient tunnel between the spanning tree process and the feature transform module. This algorithm enables the LTF-V2 module to be more robust and ﬂexible. Moreover, the LTF-V2 module maintains linear computational complexity and highly empirical efﬁciency of the LTF-V1 2.
Overall, in this paper, we present a more generic method for structure-preserving feature transform with linear complexity. To demonstrate the effectiveness of the LTF-V2 module, we conduct extensive ablation studies on object detection, instance segmentation, and semantic segmentation. Both quantitative and qualitative experiments demonstrate the superiority of the LTF-V2 module over previous approaches. Even compared with other state-of-the-art works, the LTF-V2 module achieves competitive performance with much less resource consumption. Speciﬁcally, when applied to Mask R-CNN [25] (with ResNet50-FPN [26]), the LTF-V2 module obtains 2.4% and 1.8% absolute gains over the baseline on COCO benchmark for APbox and APseg respectively, with negligible computational overhead. Meanwhile, the LTF-V2 module achieves 82.1% mIoU on Cityscapes benchmark without bells-and-whistles, reaching leading performance on semantic segmentation. 2