Abstract
Neural networks have been shown to perform incredibly well in classiﬁcation tasks over structured high-dimensional datasets. However, the learning dynamics of such networks is still poorly understood. In this paper we study in detail the training dynamics of a simple type of neural network: a single hidden layer trained to perform a classiﬁcation task. We show that in a suitable mean-ﬁeld limit this case maps to a single-node learning problem with a time-dependent dataset determined self-consistently from the average nodes population. We specialize our theory to the prototypical case of a linearly separable data and a linear hinge loss, for which the dynamics can be explicitly solved in the inﬁnite dataset limit. This allows us to address in a simple setting several phenomena appearing in modern networks such as slowing down of training dynamics, crossover between rich and lazy learning, and overﬁtting. Finally, we assess the limitations of mean-ﬁeld theory by studying the case of large but ﬁnite number of nodes and of training samples. 1

Introduction
Despite their proven ability to tackle a large class of complex problems [1], neural networks are still poorly understood from a theoretical point of view. While general theorems prove them to be universal approximators [2], their ability to obtain generalizing solutions given a ﬁnite set of examples remains largely unexplained. This behavior has been observed in multiple settings. The huge number of parameters and the optimization algorithms employed to optimize them (gradient descent and its variations) are thought to play key roles in it [3–5].
In consequence, a large research effort has been devoted in recent years to understanding the training dynamics of neural networks with a very large number of nodes [6–8]. Much theoretical insight has been gained in the training dynamics of linear [9, 10] and nonlinear networks for regression problems, often with quadratic loss and in a teacher-student setting [11–14], highlighting the evolution of correlations between data and network outputs. More generally, the input-output correlation and its effect on the landscape has been used to show the effectiveness of gradient descent [15, 16]. Other approaches have focused on inﬁnitely wide networks to perform a mean-ﬁeld analysis of the weights dynamics [17–22], or study its neural tangent kernel (NTK, or “lazy”) limit [23–26]. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
In this work, we investigate the learning dynamics for binary classiﬁcation problems, by considering one of the most common cost functions employed in this setting: the linear hinge loss. The idea behind the hinge loss is that examples should contribute to the cost function if misclassiﬁed, but also if classiﬁed with a certainty lower than a given threshold. In our case this cost is linear in the distance from the threshold, and zero for examples classiﬁed above threshold, that we shall call satisﬁed henceforth. This speciﬁc choice leads to an interesting consequence: the instantaneous gradient for each node due to unsatisﬁed examples depends on the activation of the other nodes only through their population, while that due to satisﬁed examples is just zero. Describing the learning dynamics in the mean-ﬁeld limit amounts to computing the effective example distribution for a given distribution of parameters: each node then evolves “independently” with a time-dependent dataset determined self-consistently from the average nodes population.
Contribution. We provide an analytical theory for the dynamics of a single hidden layer neural network trained for binary classiﬁcation with linear hinge loss. In Sec. 2 we obtain the mean-ﬁeld theory equations for the training dynamics. Those equations are a generalizations of the ones obtained for mean-square loss in [17–22]. In Sec. 3 we focus on linearly separable data with spherical symmetry and present an explicit analytical solution of the dynamics of the nodes parameters. In this setting we provide a detailed study of the cross-over between the lazy [23] and rich [27] learning regimes (Sec. 3.2). Finally, we assess the limitations of mean-ﬁeld theory by studying the case of large but ﬁnite number of nodes and ﬁnite number of training samples (Sec. 3.3). The most important new effect is overﬁtting, which we are able to describe by analyzing corrections to mean-ﬁeld theory.
In Sec. 3.4 we show that introducing a small fraction of mislabeled examples induces a slowing down of the dynamics and hastens the onset of the overﬁtting phase. Finally in Sec. 4 we present numerical experiments on a realistic case, and show that the associated nodes dynamics in the ﬁrst stage of training is in good agreement with our results.
The merit of the model we focused on is that, thanks to its simplicity, several effects happening in real networks can be studied analytically. Our analytical theory is derived using reasoning common in theoretical physics, which we expect can be made rigorous following the lines of [17–22]. All our results are tested throughout the paper by numerical simulations which conﬁrm their validity.