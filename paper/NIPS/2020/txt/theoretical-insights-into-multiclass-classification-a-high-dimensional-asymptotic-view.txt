Abstract
Contemporary machine learning applications often involve classiﬁcation tasks with many classes. Despite their extensive use, a precise understanding of the statistical properties and behavior of classiﬁcation algorithms is still missing, especially in modern regimes where the number of classes is rather large. In this paper, we take a step in this direction by providing the ﬁrst asymptotically precise analysis of linear multiclass classiﬁcation. Our theoretical analysis allows us to precisely character-ize how the test error varies over different training algorithms, data distributions, problem dimensions as well as number of classes, inter/intra class correlations and class priors. Speciﬁcally, our analysis reveals that the classiﬁcation accuracy is highly distribution-dependent with different algorithms achieving optimal per-formance for different data distributions and/or training/features sizes. Unlike linear regression/binary classiﬁcation, the test error in multiclass classiﬁcation relies on intricate functions of the trained model (e.g., correlation between some of the trained weights) whose asymptotic behavior is difﬁcult to characterize. This challenge is already present in simple classiﬁers, such as those minimizing a square loss. Our novel theoretical techniques allow us to overcome some of these chal-lenges. The insights gained may pave the way for a precise understanding of other classiﬁcation algorithms beyond those studied in this paper.

Introduction 1
Multiclass classiﬁcation is fundamental to a large number of real-world machine learning applica-tions that demand the ability to automatically distinguish between thousands of different classes.
Applications include essentially any problem with categorical outputs spanning natural language processing [SVL14], where a seq2seq decoder has to choose the correct word token, reinforcement learning [JGP16, MXSS20], where the agent has to choose the correct action, to recommendation systems, where the model should recommend the correct movie out of many other options. For instance, YouTube’s recommendation system is modeled as an extreme multiclass problem with more than a million classes where each video corresponds to a viable class [CAS16].
The growing list of applications motivate an in-depth exploration of multiclass classiﬁcation algo-rithms. Despite their extensive use however, a precise understanding of the statistical properties and behavior of classiﬁcation algorithms is still missing with many open questions: What is the total and per class test accuracy? How does this quantity depend on various problem parameters such as data distributions, problem dimensions, etc.? What is the highest test accuracy achievable by any algorithm? What is the best algorithm for each scenario? Which algorithm achieves the highest accuracy on rare or minority classes? How does the answer to the above question change in modern regimes where the number of classes is large?
Asymptotic analysis in modern high-dimensional regimes where the number of training data and feature sizes grow in tandem with each other provides a promising setting for precisely quantifying the accuracy of classiﬁcation algorithms as a function of problem variables and resolving the questions above. However, despite the rich literature on precise high-dimensional estimation and more recently 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
binary classiﬁcation, multiclass classiﬁcation is an under-explored venue possibly due to the difﬁculty of capturing the intricate dependencies between the classes even for relatively simple linear classiﬁers.
Contributions. We initiate a precise asymptotic study of linear multiclass classiﬁcation in the modern high-dimensional regime, where the sizes of the training data and of the feature vectors grow large at a proportional rate. A key promise of such a precise analysis is that it allows us to accurately compare between different classiﬁcation algorithms and data models. Compared to linear regression/binary classiﬁcation, we identify the following crucial challenge: the test accuracy in multiclass classiﬁcation relies on intricate cross-correlations between the trained weights of the classiﬁer. This has two consequences that drive our analysis. First, in order to obtain sharp asymptotics on the test error of any classiﬁer, it is a prerequisite to precisely quantify the asymptotics of these cross-correlations. Second, the test error does not depend on the correlations in closed-form expressions. Thus, to compare between different classiﬁers, we need efﬁcient numerical and analytic means to evaluate the test error in terms of the correlation matrices. Interestingly, we show that these challenges are already present in simple classiﬁers, such as minimizing the square loss, and in stylized distributional settings, such as Gaussian features. Our contributions are as follows:
We study two different data models: a Gaussian Mixtures Model (GMM) and a Multinomial Logit
Model (MLM) with Gaussian features. For each one of them, we provide a precise characterization of total and class-wise test accuracy for three different training algorithms: (i) a least-squares (LS) based
● classiﬁer, (ii) a weighted least-squares (WLS) based classiﬁer, and (iii) a simple per class averaging (Avg) estimator. For the least-squares based classiﬁers, we develop a new technique to overcome the technical challenge of characterizing the limiting behavior of the weights’ cross-correlations. For the per class averaging classiﬁer, we show that it is Bayes optimal for a GMM with equal priors.
We discuss efﬁcient means of evaluating the test accuracy as a function of the weights’ cross-correlations. This, together with the derived asymptotic formulae for the latter, lead to the ﬁrst precise high-dimensional characterization of how the total/class-wise accuracy varies for different algorithms,
● data distributions, problem dimensions as well as number of classes, the inter/intra class correlations and class priors. For special problem geometries, we derive precise conditions on the data distribution and on the relative size of the training set over which each of the two studied algorithms dominates.
We present and discuss numerical simulations that corroborate our theoretical ﬁndings. For instance, with an eye towards making classiﬁcation algorithms more fair/equitable, we use our precise characterization of the class-wise accuracy to demonstrate how different algorithms behave in the
● presence of rare/minority classes. We also empirically compare the algorithms studied in this paper to other popular losses such as cross-entropy minimization. This allows us to better understand the performance of various algorithms in modern regimes of large number of classes.