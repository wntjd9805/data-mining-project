Abstract
Standard Convolutional Neural Networks (CNNs) designed for computer vision tasks tend to have large intermediate activation maps. These require large working memory and are thus unsuitable for deployment on resource-constrained devices typically used for inference on the edge. Aggressively downsampling the images via pooling or strided convolutions can address the problem but leads to a signiﬁ-cant decrease in accuracy due to gross aggregation of the feature map by standard pooling operators. In this paper, we introduce RNNPool, a novel pooling operator based on Recurrent Neural Networks (RNNs), that efﬁciently aggregates features over large patches of an image and rapidly downsamples activation maps. Empirical evaluation indicates that an RNNPool layer can effectively replace multiple blocks in a variety of architectures such as MobileNets, DenseNet when applied to stan-dard vision tasks like image classiﬁcation and face detection. That is, RNNPool can signiﬁcantly decrease computational complexity and peak memory usage for in-ference while retaining comparable accuracy. We use RNNPool with the standard
S3FD [50] architecture to construct a face detection method that achieves state-of-the-art MAP for tiny ARM Cortex-M4 class microcontrollers with under 256 KB of RAM. Code is released at https://github.com/Microsoft/EdgeML. 1

Introduction
Convolutional Neural Networks (CNNs) have become ubiquitous for computer vision tasks such as image classiﬁcation and face detection. Steady progress has led to new CNN architectures that are increasingly accurate, but also require larger memory and more computation for inference. The increased inference complexity renders these models unsuitable for resource-constrained processors that are commonplace on the edge in IoT systems and battery-powered and privacy-centric devices.
To reduce inference complexity, several techniques like quantization [44], sparsiﬁcation [9, 27], cheaper CNN blocks [37, 22], or neural architecture search [41] have been proposed to train CNN models with lower inference cost and model size while retaining accuracy. However, these models still require large working memory for inference. Memory tends to be the most constrained resource on low power devices as it occupies a large fraction of the device die and has high sustained power requirement [24]. Most low power ARM Cortex-M* microcontrollers have less than 256 KB RAM.
Typical CNNs have large intermediate activation maps, as well as many convolution layers, which put together require large amount of RAM for inference (see Proposition 1). A standard approach to reducing working memory is to use pooling operators or strided convolution to bring down size of the activation map. In fact, standard CNNs have multiple such layers. However, such pooling operators aggregate the underlying activation map in a simplistic manner, which can lead to a signiﬁcant loss of accuracy. As a result, their use is limited to small receptive ﬁelds, typically no larger than 3 × 3, and they can not be used to aggressively reduce the activation map by aggregating larger receptive ﬁelds. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
In this paper, we propose a novel pooling op-erator RNNPool that uses Recurrent Neural
Networks (RNNs) to perform a more reﬁned aggregation over a large receptive ﬁeld of the activation map without compromising on accu-racy. RNNPool can be applied to any tensor structured problem, but we focus on 2D images for ease of exposition. For images, RNNPool uses RNNs to aggregate information along rows
& columns in a given patch. RNNPool has three parameters – patch size or receptive ﬁeld, stride, and output dimension – to control its ex-pressiveness and ability to downsample. The
RNNPool operator matches standard pooling operators syntactically, so can be used to replace them in convolutional networks.
Figure 1: The RNNPool operator applied to patches of size r × c with stride s. It summarizes the patch with two RNNs into a vector of size 4h2.
RNNPool allows rapid down-sampling of images and activation maps, eliminating the need for many memory-intensive intermediate layers. RNNPool is most effective when used to replace multiple
CNN blocks in the initial stages of the network where the activation map sizes are large, and hence, require the most memory and compute. There, a single layer of RNNPool can down-sample by a factor of 4 or 8. For example, RNNPool applied to a 640 × 640 × 3 image with patch-size 16, stride 8, and 32 output channels results in a 80 × 80 × 32 activation map, which can be stored in about 200 KB, and can be computed one patch at a time without signiﬁcant memory cost. Replacing a few blocks using RNNPool reduces peak memory requirement signiﬁcantly for typical CNN architectures without much loss of accuracy.
Our experiments demonstrate that RNNPool can be used as an effective replacement for multi-layered, expensive CNN blocks in a variety of architectures such as MobileNets, DenseNets, S3FD, and for varied tasks such as image classiﬁcation and face detection. For example, in a 10-class image classiﬁcation task, RNNPool+MobileNetV2 reduces the peak memory requirement of MobileNetV2 by up to 10× and MAdds (MAdds refers to Multiply-Adds as in MobileNetV2 [37]) by about 25%, while maintaining the same accuracy. Additionally, due to its general formulation, RNNPool can replace pooling layers anywhere in the architecture. For example, it can replace the ﬁnal average pool layer in MobileNetV2 and improve accuracy by ∼ 1%.
Finally, we modify the S3FD [50] architecture with RNNPool to construct an accurate face detection model which needs only 225 KB RAM – small enough to be deployed on a Cortex-M4 based device – and achieves 0.78 MAP on the medium category of the WIDER FACE dataset [47] using 80× fewer
MAdds than EXTD [48] – a state-of-the-art resource-constrained face detection method.
In summary, we make the following contributions:
• A novel pooling operator that can rapidly down-sample input in a variety of standard CNN architectures, e.g., MobileNetV2, DenseNet121 while retaining the expressiveness.
• Demonstrate that RNNPool can reduce working memory and compute requirements for image classiﬁcation and Visual Wake Words signiﬁcantly while retaining comparable accuracy.
• By combining RNNPool with S3FD, we obtain a state-of-the-art face detection model for ARM
Cortex-M4 class devices. 2