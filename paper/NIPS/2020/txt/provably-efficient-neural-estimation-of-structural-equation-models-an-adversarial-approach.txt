Abstract
Structural equation models (SEMs) are widely used in sciences, ranging from economics to psychology, to uncover causal relationships underlying a complex system under consideration and estimate structural parameters of interest. We study estimation in a class of generalized SEMs where the object of interest is deﬁned as the solution to a linear operator equation. We formulate the linear operator equation as a min-max game, where both players are parameterized by neural networks (NNs), and learn the parameters of these neural networks using the stochastic gradient descent. We consider both 2-layer and multi-layer NNs with
ReLU activation functions and prove global convergence in an overparametrized regime, where the number of neurons is diverging. The results are established using techniques from online learning and local linearization of NNs, and improve in several aspects the current state-of-the-art. For the ﬁrst time we provide a tractable estimation procedure for SEMs based on NNs with provable convergence and without the need for sample splitting. 1

Introduction
Structural equation models (SEMs) are widely used in economics [50], psychology [9], and causal inference [41]. In the most general form [41, 42], an SEM deﬁnes a joint distribution over p observed random variables tXjup j“1 as Xj “ fjpXpaDpjq, εjq, j “ 1, . . . , p, where tfju are unknown functions of interest, tεju are mutually independent noise variables, D is the underlying directed acyclic graph (DAG), and paDpjq denotes the set of parents of Xj in D. The joint distribution of tXju is Markov with respect to the graph D.
In most cases, estimation of SEMs are based on the conditional moment restrictions implied by the model. For example, some observational data can be thought of as coming from the equilibrium of a dynamic system. Examples include dynamic models where an agent interacts with the environment, such as in reinforcement learning [17], consumption-based asset pricing models [20], and rational expectation models [25]. In these models, the equilibrium behavior of the agent is characterized by conditional moment equations. A second example is instrument variable (IV) regression, where conditional moment equations also play a fundamental role. IV regression is used to estimate causal effects of input X on output Y in the presence of confounding noise e [38]. Finally, in time-series and panel data models, observed variables exhibit temporal or cross-sectional dependence that can also be depicted by conditioning [46]. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
For these reasons, we study estimation of structural parameters based on the conditional moment restrictions implied by the model. We propose the generalized structural equation model, which takes the form of a linear operator equation
Af “ b, (1) where A : H Ñ E is a conditional expectation operator, which in most settings is only accessible by sampling, H and E are separable Hilbert spaces of square integrable functions with respect to some random variables, f P H is the structural function of interest, and b P E is known or can be estimated.
Section 1.1 provides a number of important examples from causal inference and econometrics that ﬁt into the framework (1).
Our contribution is threefold. First, we propose a new min-max game formulation for estimating f in (1), where we parameterize both players by neural networks (NN). We derive a stochastic gradient descent algorithm to learn the parameters of both NNs. In contrast to several recent works that rely on RKHS theory [16, 36, 44], our method enjoys expressiveness thanks to the representation power of NNs. Moreover, our algorithm does not need sample splitting, which is a common issue in some recent works [26, 32]. Second, we analyze convergence rates of the proposed algorithm in the setting of 2-layer and deep NNs using techniques from online learning and neural network linearization. We show the algorithm ﬁnds a globally optimal solution as the number of iterations and the width of NNs go to inﬁnity. In comparison, recent works incorporating NNs into SEM [26, 32, 7] lack convergence results. Furthermore, we derive a consistency result under suitable smoothness assumptions on the unknown function f . Finally, we demonstrate that our model enjoys wide application in econometric and causal inference literature through concrete examples, including non-parametric instrumental variable (IV) regression, supply and demand equilibrium model, and dynamic panel data model. 1.1 Examples of generalized SEM
We describe three examples of generalized SEM: IV regression, simultaneous equations models, and dynamic panel data model. In Appendix A, we introduce two more examples: proxy variables of unmeasured confounders in causal inference [34] and Euler equations in consumption-based asset pricing model [20]. Other examples that ﬁt into the generalized SEM framework, but are not detailed in the paper, include nonlinear rational expectation models [25], policy evaluation in reinforcement learning, inverse reinforcement learning [40], optimal control in linearly-solvable MDP [16], and hitting time of stationary process [16].
Example 1 (Instrumental Variable Regression [38, 26, 28]). In many applied problems endogeneity in regressors arises from omitted variables, measurement error, and simultaneity [50]. IV regression provides a general solution to the problem of endogenous explanatory variables. Without loss of generality, consider the model of the form
Y “ g0pXq ` ε, Erε | Zs “ 0, where g0 is the unknown function of interest, Y is the response, X is a vector of explanatory variables, Z is a vector of instrument variables, and ε is the noise term. To see how the model
ﬁts our framework, deﬁne the operator A : L2pXq Ñ L2pZq, pAgqpzq “ ErgpXq | Z “ zs. Let bpzq “ ErY | Z “ zs P L2pZq. The structural equation (2) can be written as Ag “ b.
Example 2 (Simultaneous Equations Models). Dynamic models of agent’s optimization problems or of interactions among agents often exhibit simultaneity. Consider a demand and supply model as a prototypical example [33]. Let Q and P denote the quantity sold and price of a product, respectively.
Then (2)
Q “ D pP, Iq ` U1 , P “ S pQ, W q ` U2,
ErU1 | I, W s “ 0 , ErU2 | I, W s “ 0, (3) where D and S are functions of interest, I denotes consumers’ income, W denotes producers’ input prices, U1 denotes an unobservable demand shock, and U2 denotes an unobservable supply shock.
Each observation of tP, Q, I, W u is a solution to the equation (3). In Appendix A we cast it into the form (1). The knowledge of D is essential in predicting the effect of ﬁnancial policy. For example, let τ be a percentage tax paid by the purchaser. Then the resulting equilibrium quantity is the solution
ˆQ to the equation ˆQ “ D
Example 3 (Dynamic Panel Data Models [46]). Exploiting how outcomes vary across units and over time in the dataset is a common approach to identifying causal effects [1]. Panel data are comprised p1 ` τ qpSp ˆQ, Iq ` U1q, W
` U2.
`
˘ 2
of observations of multiple units measured over multiple time periods. We consider a dynamic model that includes time-varying regressors and allows us to investigate the long-run relationship between economic factors [46]:
Yit “ m pYi,t´1, Xitq ` αi ` εit,
Erεit | Y i,t´1, X its “ 0, i “ 1, . . . , N, t “ 1, . . . , T. (4)
Here Xit is a pˆ1 vector of regressors, m is the unknown function of interest, αi’s are the unobserved individual-speciﬁc ﬁxed effects, potentially correlated with Xit, and εit’s are idiosyncratic errors.
JqJ and Y i,t´1 :“ pYi,t´1, . . . , Yi1q J are the history of individual i up to
X it :“ pXit time t. After ﬁrst differencing, we can cast (4) into equation of the form (1) (see Appendix A).
J, . . . , Xi1 1.2