Abstract
Despite tremendous success in many application scenarios, deep learning faces serious intellectual property (IP) infringement threats. Considering the cost of designing and training a good model, infringements will signiﬁcantly infringe the interests of the original model owner. Recently, many impressive works have emerged for deep model IP protection. However, they either are vulnerable to ambiguity attacks, or require changes in the target network structure by replacing its original normalization layers and hence cause signiﬁcant performance drops.
To this end, we propose a new passport-aware normalization formulation, which is generally applicable to most existing normalization layers and only needs to add another passport-aware branch for IP protection. This new branch is jointly trained with the target model but discarded in the inference stage. Therefore it causes no structure change in the target model. Only when the model IP is suspected to be stolen by someone, the private passport-aware branch is added back for ownership veriﬁcation. Through extensive experiments, we verify its effectiveness in both image and 3D point recognition models. It is demonstrated to be robust not only to common attack techniques like ﬁne-tuning and model compression, but also to ambiguity attacks. By further combining it with trigger-set based methods, both black-box and white-box veriﬁcation can be achieved for enhanced security of deep learning models deployed in real systems. 1

Introduction
Deep learning has achieved huge success in broad artiﬁcial intelligent tasks, such as image recognition
[1, 2, 3], object detection [4, 5, 6], and neural language processing [7, 8]. In order to obtain high-performance deep models, we often need to design a good network architecture, collect massive high-quality training dataset, and consume expensive computation resources. Therefore, these deep models are of great commercial value and may even be the core techniques for some companies.
However, recent works [9, 10, 11] have shown that deep models are vulnerable to IP infringement.
For example, the attackers can utilize transfer learning to adapt the target model to a new task by
ﬁne-tuning [12] or even get a new efﬁcient model by model compression techniques [13]. All these attack methods will seriously infringe the interests of the original model owner.
∗Equal Contribution, † Dongdong Chen is the corresponding Author 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
In the past several years, deep model IP protection has drawn much attention from both academia and industry and many great works emerge. The main idea of these works is to add some special watermarks into the network weights [9, 14] or predictions [10, 15, 11, 16] while trying to maintain the original model performance. In detail, a weight regularizer is added into the objective loss function in [9, 14] so that the learned weights can follow some special distribution. In contrast, prediction watermarking [10, 15, 11] adds a special image trigger set into the training process, so that the learned network can classify them into some pre-deﬁned labels. Despite the effectiveness in resisting the aforementioned IP attacks, a recent work [17] shows that these methods are all fragile to ambiguity attacks, i.e., the attackers can embed another watermark into the watermarked model for ownership claim, thus causing ambiguous forensics. To address this problem, a passport-based method is proposed by modulating the network performance based on the passport correctness. In other words, the target model can get good performance only when the correct passport is given and they use such “ﬁdelity veriﬁcation" to resist ambiguity attacks. However, since the passport learning and target model learning are coupled too tightly in [17], we ﬁnd they have a major limitation: they need to change the network structure by replacing normalization layers, which may affect the original model performance signiﬁcantly. Both of them are unfriendly and harmful to service quality for the end-users.
This paper shares a similar spirit in defending against ambiguity attacks, but targets at no network structure change and less performance drop. To this end, a new passport-aware normalization formulation is proposed. It is generally applicable to most popular normalization layers and only needs to add an extra passport-aware branch for IP protection. During training, some secret passports are pre-deﬁned and these extra branches are jointly trained with the target model. After training, both these secret passports and new branches will be kept by the model owner for future ownership veriﬁcation, and only the original target model is delivered to end-users to run the inference. Therefore, from the end-users’ perspective, there is no network structure change. Moreover, since the normalization statistics (e.g., the running mean and variance of Batch Normalization) of the passport-aware branch are designed to be computed independently, less performance inﬂuence will be introduced to the target model.
When we suspect one model is illegally derived from the target model, we can add the private passport-aware branch back for ownership veriﬁcation. More speciﬁcally, the target model performance will remain intact only when the correct passport is given, or seriously degrade for the forged passport.
The effectiveness of our method is veriﬁed on both image and 3D point recognition models via comprehensive experiments, which demonstrate our method is not only robust to common removal attack techniques like ﬁne-tuning and model compression but also to ambiguity attacks. By further combining it with trigger-set based watermarking schemes, we can achieve initial veriﬁcation without the need of detailed model structure and weight access, which is known as the black-box veriﬁcation.
To summarize, our main contributions are two-fold: 1) We propose a new and general passport-aware normalization formulation for deep model IP protection, which is compatible with most popular normalization layers. To the best of our knowledge, this is also the ﬁrst passport-based method without the need of network structure change while achieving much less model performance degradation. 2) We have conducted extensive experiments on both image and 3D point recognition tasks with different network structures and normalization layers, which well demonstrate the effectiveness and robustness of our method against both removal attacks and ambiguity attacks. 2