Abstract
We propose a new Stein self-repulsive dynamics for obtaining diversiﬁed sam-ples from intractable un-normalized distributions. Our idea is to introduce Stein variational gradient as a repulsive force to push the samples of Langevin dynam-ics away from the past trajectories. This simple idea allows us to signiﬁcantly decrease the auto-correlation in Langevin dynamics and hence increase the ef-fective sample size. Importantly, as we establish in our theoretical analysis, the asymptotic stationary distribution remains correct even with the addition of the repulsive force, thanks to the special properties of the Stein variational gradient.
We perform extensive empirical studies of our new algorithm, showing that our method yields much higher sample efﬁciency and better uncertainty estimation than vanilla Langevin dynamics. 1

Introduction
Drawing samples from complex un-normalized distributions is one of the most basic problems in statistics and machine learning, with broad applications to enormous research ﬁelds that rely on probabilistic modeling. Over the past decades, large amounts of methods have been proposed for approximate sampling, including both Markov Chain Monte Carlo (MCMC) [e.g., Brooks et al., 2011] and variational inference [e.g., Wainwright et al., 2008, Blei et al., 2017].
MCMC works by simulating Markov chains whose stationary distributions match the distributions of interest. Despite nice asymptotic theoretical properties, MCMC is widely criticized for its slow convergence rate in practice. In difﬁcult problems, the samples drawn from MCMC are often found to have high auto-correlation across time, meaning that the Markov chains explore very slowly in the conﬁguration space. When this happens, the samples returned by MCMC only approximate a small local region, and under-estimate the probability of the regions un-explored by the chain.
Stein variational gradient descent (SVGD) [Liu and Wang, 2016] is a different type of approximate sampling methods designed to overcome the limitation of MCMC. Instead of drawing random sam-ples sequentially, SVGD evolves a pre-deﬁned number of particles (or sample points) in parallel with a special interacting particle system to match the distribution of interest by minimizing the KL divergence. In SVGD, the particles interact with each other to simultaneously move towards the high probability regions following the gradient direction, and also move away from each other due to a special repulsive force. As a result, SVGD allows us to obtain diversiﬁed samples that correctly represent the variation of the distribution of interest. SVGD has found applications in various chal-lenging problems [e.g., Feng et al., 2017, Haarnoja et al., 2017, Pu et al., 2017, Liu et al., 2017a,
Gong et al., 2019]. See Han and Liu [e.g., 2018], Chen et al. [e.g., 2018], Liu et al. [e.g., 2019],
Wang et al. [e.g., 2019a] for examples of extensions.
However, one problem of SVGD is that it theoretically requires to run an inﬁnite number of chains in parallel in order to approximate the target distribution asymptotically [Liu, 2017]. With a ﬁnite
∗Equal Contribution 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
number of particles, the ﬁxed point of SVGD does still provide a prioritized, partial approxima-tion to the distribution in terms of the expectation of a special case of functions [Liu and Wang, 2018]. Nevertheless, it is still desirable to develop a variant of “single-chain SVGD”, which only requires to run a single chain sequentially like MCMC to achieve the correct stationary distribution asymptotically in time, with no need to take the limit of inﬁnite number of parallel particles.
In this work, we propose an example of single-chain SVGD by integrating the special repulsive mechanism of SVGD with gradient-based MCMC such as Langevin dynamics. Our idea is to use repulsive term of SVGD to enforce the samples in MCMC away from the past samples visited at previous iterations. Such a new self-repulsive dynamics allows us to decrease the auto-correlation in
MCMC and hence increase the mixing rate, but still obtain the same stationary distribution thanks to the special property of the SVGD repulsive mechanism. We provide thorough theoretical analysis of our new method, establishing its asymptotic convergence to the target distribution. Such result is highly non-trivial, as our new self-repulsive dynamic is a non-linear high-order Markov process.
Empirically, we evaluate our methods on an array of challenging sampling tasks, showing that our method yields much better uncertainty estimation and larger effective sample size. 2