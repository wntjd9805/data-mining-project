Abstract
Boolean tensor has been broadly utilized in representing high dimensional logical data collected on spatial, temporal and/or other relational domains. Boolean
Tensor Decomposition (BTD) factorizes a binary tensor into the Boolean sum of multiple rank-1 tensors, which is an NP-hard problem. Existing BTD methods have been limited by their high computational cost, in applications to large scale or higher order tensors. In this work, we presented a computationally efﬁcient
BTD algorithm, namely Geometric Expansion for all-order Tensor Factorization (GETF), that sequentially identiﬁes the rank-1 basis components for a tensor from a geometric perspective. We conducted rigorous theoretical analysis on the validity as well as algorithemic efﬁciency of GETF in decomposing all-order tensor.
Experiments on both synthetic and real-world data demonstrated that GETF has signiﬁcantly improved performance in reconstruction accuracy, extraction of latent structures and it is an order of magnitude faster than other state-of-the-art methods. 1

Introduction
A tensor is a multi-dimensional array that can effectively capture the complex multidimensional features. A Boolean tensor is a tensor that assumes binary values endowed with the Boolean algebra.
Boolean tensor has been widely adopted in many ﬁelds, including knowledge graph, recommendation system, spatial-temporal data etc [1, 2, 3, 4, 5]. Tensor decomposition is a powerful tool in extracting meaningful latent structures in the data, for which the popular CANDECOMP/PARAFAC (CP) decomposition is a generalization of the matrix singular value decomposition to tensor [6]. However, these algorithms are not directly usable for Boolean tensors. In this study, we focus on Boolean tensor decomposition (BTD) under similar framework to the CP decomposition.
As illustrated in Figure 1, BTD factorizes a binary tensor X as the Boolean sum of multiple rank 1 tensors. In cases when the error distribution of the tensor data is hard to model, BTD applied to binarized data can retrieve more desirable patterns with better interpretation than regular tensor decomposition [7, 8]. This is probably due to the robustness of logic representation of BTD. BTD is an NP-hard problem [7]. Existing BTD methods suffer from low efﬁciency due to high space/time complexity, and particularly, most BTD algorithms adopted a least square updating approach with substantially high computational cost [9, 10]. This has hindered their application to either large scale datasets, such as social network or genomics data, or tensors of high-order.
We proposed an efﬁcient BTD algorithm motivated by the geometric underpinning of rank-1 tensor bases, namely GETF (Geometric Expansion for all-order Tensor Factorization). To the best of our knowledge, GETF is the ﬁrst algorithm that can efﬁciently deal with all-order Boolean tensor decomposition with an O(n) complexity, where n represents the total number of entries in a tensor.
Supported by rigorous theoretical analysis, GETF solves the BTD problem via sequentially identifying the ﬁbers that most likely coincides with a rank-1 tensor basis component. Our synthetic and real-world data based experiments validated the high accuracy of GETF and its drastically improved efﬁciency compared with existing methods, in addition to its potential utilization on large scale or high order data, such as complex relational or spatial-temporal data. The key contributions of 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
Figure 1: Boolean tensor decomposition this study include: (1) Our proposed GETF is the ﬁrst method capable of all-order Boolean tensor decomposition; (2) GETF has substantially increased accuracy in identifying true rank-1 patterns, with less than a tenth of the computational cost compared with state-of-the-art methods; (3) we provided thorough theoretical foundations for the geometric properties for the BTD problem. 2 Preliminaries 2.1 Notations
Notations in this study follow those in [11]. We denote the order of a tensor as k, which is also called ways or modes. Scalar value, vector, matrix, and higher order tensor are represented as lowercase character x, bold lowercase character x, uppercase character X, and Euler script X, respectively. Super script with mark × indicates the size and dimension of a vector, matrix or tensor while subscript speciﬁes an entry. Speciﬁcally, a k-order tensor is denoted as Xm1×m2...×mk and the entry of position i1, i2, . . . , ik is represented as Xi1i2. . . ik . For a 3-order tensor, we denote its ﬁbers as X:i2i3,
Xi1:i3 or Xi1i2: and its slices Xi1::, X:i2:, X::i3. For a k-order tensor, we denote its mode-p ﬁber as
Xi1...ip−1:ip+1...ik with all indices ﬁxed except for ip. ||X|| represents the norm of a tensor, and |X| the
L1 norm in particular. The basic Boolean operations include ∧(and, 1 ∧ 1 = 1, 1 ∧ 0 = 0, 0 ∧ 0 = 0),
∨(or, 1 ∨ 1 = 1, 1 ∨ 0 = 1, 0 ∨ 0 = 0), and ¬(not, ¬1 = 0, ¬0 = 1). Boolean entry-wise sum, subtraction and product of two matrices are denoted as A⊕B = A∨B, A(cid:9)B = (A∧¬B)∨(¬A∧B) and A (cid:126) B = A ∧ B. The outer Boolean product in this paper is considered as the addition of rank-1 tensors, which follows the scope of CP decomposition [6]. Speciﬁcally, a three-order Rank-1 tensor can be represented as the Boolean outer product of three vectors, i.e. Xm1×m2×m3 = am1 ⊗ bm2 ⊗ cm3. Similarly, for higher order tensor, Xm1×m2...×mk of rank l is the outer product
⊗ Am2×l,2
... ⊗ Amk×l,k of Am1×l,1, Am2×l,2, ..., Amk×l,k, i.e. Xm1×m2...×mk = ∨l
)
:j
:j
...Amk×l,k and Xi1i2,...,ik = ∨l
), j = 1...l represents the rank-1 tensor ikj components of a rank l CP decomposition of X. In this paper, we denote Ami×l,i, i = 1...k as the pattern matrix of the ith order of X, its jth column Ami×l,i as the jth pattern ﬁber of the ith order,
... ⊗ Amk×l,k and Am1×l,1
:j
:j
:j as the j-th rank-1 tensor pattern. j=1(Am1×l,1 i1j j=1(Am1×l,1
∧ Am2×l,2 i2j
⊗ Am2×l,2
:j
:j 2.2 Problem statement
As illustrated in Figure 1, for a binary k-order tensor X ∈ {0, 1}m1×m2...×mk and a con-vergence criteria parameter τ , the Boolean tensor decomposition problem is to identify low rank binary pattern matrices Am1×l,1∗, Am2×l,2∗, ...Amk×l,k∗, the outer product of which best
ﬁt X, where Am1×l,1∗, Am2×l,2∗, ..., Amk×l,k∗ are matrices of l columns.
In other words, (Am1×l,1∗, Am2×l,2∗, ...Amk×l,k∗) = argminA1,A2,...,Ak (γ(Am1×l,1, Am2×l,2, ..., Amk×l,k; X)|τ )
Here γ(Am1×l,1, Am2×l,2, ...Amk×l,k; X) is the cost function. In general, γ is deﬁned to the re-construction error γ(Am1×l,1∗, ...Amk×l,k∗; X) = ||X (cid:9) (Am1×l,1∗ ⊗ ... ⊗ Amk×l,k∗)||Lp , and p is usually set to be 1. 2.3