Abstract
We propose a novel learning framework based on neural mean-ﬁeld dynamics for simultaneous inference and estimation problems of diffusions on networks. Our new framework is derived from the Mori-Zwanzig formalism to obtain an exact evolution of the node infection probabilities, which renders a delay differential equation with memory integral approximated by learnable time convolution op-erators, resulting in a highly structured and interpretable RNN. Directly using cascade data, our framework can jointly learn the structure of the diffusion network and the evolution of infection probabilities, which are cornerstone to important downstream applications such as inﬂuence maximization. Connections between parameter learning and optimal control are also established. Empirical study shows that our approach is versatile and robust to variations of the underlying diffusion network models, and signiﬁcantly outperforms existing approaches in accuracy and efﬁciency on both synthetic and real-world data. 1

Introduction
Continuous-time information diffusion on heterogeneous networks is a prevalent phenomenon [4, 39, 43]. News spreading on social media [13, 15, 49], viral marketing [23, 25, 52], computer malware propagation, and epidemics of contagious diseases [3, 36, 43, 47] are all examples of diffusion on networks, among many others. For instance, a piece of information (such as a tweet) can be retweeted by users (nodes) with followee-follower relationships (edge) on the Twitter network. We call a user infected if she retweets, and her followers see her retweet and can also become infected if they retweet in turn, and so on. Such information diffusion mimics the epidemic spread where an infectious virus can spread to individuals (human, animal, or plant) and then to many others upon their close contact.
In this paper, we are mainly concerned with the estimation of individual node infection probabilities as well as inference of the underlying diffusion network structures directly using cascade data of historical diffusion events on the network. For infection probability estimation, our goal is to compute the evolution of the probability of each node being infected during a diffusion initiated from a set of source nodes. For network structure inference, we aim at learning the edges as well as the strength of interactions (through the edges) between the nodes on the diffusion network. Not surprisingly, both problems are very challenging due to the extremely large scale of modern networks, the heterogeneous inter-dependencies among the nodes, and the randomness exhibited in cascade data. Most existing works focus on one problem only, e.g., either to solely infer the network structure from cascade data, or to estimate inﬂuence without providing insights into the underlying network structure.
We propose a novel learning framework, called neural mean-ﬁeld (NMF) dynamics, to simultaneously tackle both of the estimation and inference problems mentioned above. Speciﬁcally: (i) We develop a neural mean-ﬁeld dynamics framework to model the evolution of diffusion on a network. Our new framework is derived from the Mori-Zwanzig formalism to obtain an exact time evolution of the node infection probability with dimension linear in the network size; (ii) We show that the memory term of 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
the Mori-Zwanzig equation can be approximated by a trainable convolution network, which renders the dynamical system into a delay differential equation. We also show that the time discretization of such system reduces to a recurrent neural network. The approximate system is highly interpretable, and in particular, the training accepts sample cascades as input, and returns both individual probability estimates (and hence the inﬂuence function) as well as structure information of the diffusion network as outputs; (iii) We show that the parameters learning in NMF can be reduced to an optimal control problem with the parameters as time invariant control inputs, maximizing the total Hamiltonian of the system; and (iv) Our empirical analysis shows that our approach is robust to the variation of the unknown underlying diffusion models, and it also signiﬁcantly outperforms existing approaches for both synthetic and real-world diffusion networks.
The remainder of this paper is organized as follows.
In Section 2, we introduce the diffusion network models and related background information, including the inﬂuence predication and structure inference problems. In Section 3, we develop the proposed framework of neural mean-ﬁeld dynamics for inference and prediction on diffusion networks, as well as an optimal control formulation for parameter learning. We demonstrate the performance of the proposed method on inﬂuence estimation and maximization on a variety of synthetic and real-world networks in Section 4. A discussion of the related work is given in Section 5. Section 6 concludes the paper. 2 Preliminaries on Diffusion Networks
Throughout this paper, we use boldfaced lower (upper) letter to denote vector (matrix) or vector-valued (matrix-valued) function, and (·)k (or (·)ij) for its kth component (or (i, j)-th entry). All vectors are column vectors unless otherwise noted. We follow the Matlab syntax and use [x; y] to denote the vector that stacks x and y vertically. We denote inner product by x·y and component-wise multiplication by x (cid:12) y. Time is denoted by t in either continuous (t ∈ [0, T ]) or discrete case (t = 0, 1, . . . , T ) for some time horizon T ∈ R+ (N in discrete case). Derivative (cid:48) is with respect to t, and gradient ∇x is with respect to x. Probability is denoted by Pr(·), and expectation with respect to
X (or pX ) is denoted by EX [ · ].
Diffusion network models Consider a diffusion network model, which consists of a network (directed graph) G = (V, E) with node set V = [n] := {1, . . . , n} and edge set E ⊂ V × V, and a diffusion model that describes the distribution p(t; αij) of the time t node i takes to infect a healthy neighbor j ∈ {j(cid:48) : (i, j(cid:48)) ∈ E} for every (i, j) ∈ E. Then, given a source (seed) set S of nodes that are infected at time 0, they will infect their healthy neighbors with infection time following p, and the infected neighbors will then infect their healthy neighbors, and so on, such that the infection initiated from S at time 0 propagates to other nodes of the network.
Typical diffusion network models are assumed to be progressive where infected node cannot recover and the infections on different edges are independent. For example, the standard diffusion model with exponential distribution p(t; α) = αe−αt is mostly widely used; other distributions can also be considered, as is done in this paper. For simplicity, we focus on uni-parameter distributions or distributions with multiple parameters but only one can vary across different edges with the consequence that the parameter αij ≥ 0 indicates the strength of impact node i has on node j.
Cascade data Observation data D of a diffusion network are often in the form of sample cascades
D := {Ck = (Sk, τk) ∈ 2V × Rn
+ : k ∈ [K]}, where the kth cascade Ck records its source set
Sk ⊂ V and the time (τk)i ≥ 0 which indicates when node i was infected (if i was not infected during Ck then (τk)i = ∞). We also equate Ck with { ˆx(k)(t) ∈ {0, 1}n : i ∈ [n], t ≥ 0} such that ( ˆx(k)(t))i = 1 if the node i is in the infected status at time t and 0 otherwise. For example,
ˆx(k)(0) = χSk where (χSk )i = 1 if i ∈ Sk and 0 otherwise. Such cascade data are collected from historical events for training purposes.
Inﬂuence prediction and inference of diffusion network Given the network G = (V, E), as well as the diffusion model and A, where (A)ji = αij is the parameter of p(t; αij) for edge (i, j), the inference prediction (or inﬂuence estimation) is to compute x(t; χS ) = [x1(t; χS ), . . . , xn(t; χS )](cid:62) ∈ [0, 1]n (1) 2
for all time t ≥ 0 and any source set S ⊂ V. In (1), xi(t; χS ) is the probability of node i being infected at time t given a source set S (not necessarily observed as a source set in D). Note that we use χS and S interchangeably hereafter. The probability x(t; χS ) can also be used to compute the inﬂuence function σ(t; S) := 1(cid:62) n x(t; χS ), the expected number of infected nodes at time t. Note that an analytic solution of (1) is intractable due to the exponentially large state space of the complete dynamical system of the diffusion problem [19, 48].
On the other hand, network inference refers to learning the network connectivity E and A given cascade data D. The matrix A is the distribution parameters if the diffusion model p is given, or it simply qualitatively measures the strength of impact node i on j if no speciﬁc p is known.
Inﬂuence prediction may also require network inference when only cascade data D are available, resulting in a two-stage approach: a network inference is performed ﬁrst to learn the network structure
E and the diffusion model parameters A, and then an inﬂuence estimation is used to compute the inﬂuence for the source set S. However, approximation errors and biases in the two stages will certainly accumulate. Alternatively, one can use a one-stage approach to directly estimate x(t; χS ) of any S from the cascade data D, which is more versatile and less prone to diffusion model misspeciﬁcation. Our method is a such kind of one-stage method. Additionally, it allows knowledge of E and/or A, if available, to be integrated for further performance improvement.
Inﬂuence maximization Given cascade data D, inﬂuence maximization is to ﬁnd the source set
S that generates the maximal inﬂuence σ(t; S) at t among all subsets of size n0, where t > 0 and 1 ≤ n0 < n are prescribed. Namely, inﬂuence maximization can be formulated as max
S
σ(t; S), s.t. S ⊂ V,
|S| ≤ n0. (2)
There are two main ingredients of an inﬂuence maximization method for solving (2): an inﬂuence prediction subroutine that evaluates the inﬂuence σ(t; S) for any given source set S, and an (ap-proximate) combinatorial optimization solver to ﬁnd the optimal set S of (2) that repeatedly calls the subroutine. The combinatorial optimization problem is NP-hard and is often approximately solved by greedy algorithms with guaranteed sub-optimality when σ(t; S) is submodular in S. In our experiment, we show that a standard greedy approach equipped with our proposed inﬂuence estimation method outperforms other state-of-the-art inﬂuence maximization algorithms. 3 Neural Mean-Field Dynamics
Modelling diffusion by stochastic jump processes We begin with the jump process formulation of network diffusion. Given a source set χS , let Xi(t; χS ) denote the infection status of the node i at time t. Namely, Xi(t) = 1 if node i is infected by time t, and 0 otherwise. Then {Xi(t) : i ∈ [n]} are a set of n coupled jump processes, such that Xi(t; χS ) jumps from 0 to 1 when the node i is infected by any of its infected neighbors at t. Let λ∗ i (t) be the conditional intensity of Xi(t; χS ) given the history H(t) = {Xi(s; χS ) : s ≤ t, i ∈ [n]}, i.e.,
λ∗ i (t) := lim
τ →0+
E[Xi(t + τ ; χS ) − Xi(t; χS )|H(t)]
τ
. (3)
Note that the numerator of (3) is also the conditional probability Pr(Xi(t + τ ) = 1, Xi(t) = 0|H(t)) for any τ > 0. In inﬂuence prediction, our goal is to compute the probability x(t; χS ) = [xi(t; χS )] in (1), which is the expectation of Xi(t; χS ) conditioning on H(t): xi(t; χS ) = EH(t)[Xi(t; χS )|H(t)].
To this end, we adopt the following notations (for notation simplicity we temporarily drop χS in this subsection as the source set S is arbitrary but ﬁxed): (4) xI (t) = EH(t) (cid:2)(cid:81) i∈I Xi(t; χS )(cid:12) (cid:12)H(t)(cid:3) , yI (t) = (cid:81) i∈I xi(t), eI (t) = xI (t) − yI (t) (5) for any I ⊂ [n] and |I| ≥ 2. Then we can derive the evolution of z := [x; e]. Here x(t) ∈ [0, 1]n is the resolved variable whose value is of interests and samples can be directly observed from the cascade data D, and e(t) = [· · · , eI (t), · · · ] ∈ RN −n where N = 2n − 1 is the unresolved variable that captures all the second and higher order moments. The complete evolution equation of z is given in the following theorem, where the proof is provided in Appendix B.1. 3
Theorem 1. The evolution of z(t) = [x(t); e(t)] follows the nonlinear differential equation:
¯f (z) = ¯f (x, e) = (cid:2)f (x; A) − (A (cid:12) E)1; · · · , fI (x, e); · · ·(cid:3) , z(cid:48) = ¯f (z), where with initial value z0 = [χS ; 0] ∈ RN , E = [eij] ∈ Rn×n, and f (x; A) = Ax − diag(x)Ax, fI (x, e) = (cid:88) (cid:88) i∈I j /∈I
αji(yI − yI∪{j} + eI − eI∪{j}) − (cid:88) i∈I yI\{i} (cid:88) j(cid:54)=i
αji(xj − yij − eij). (6) (7) (8)
The evolution (6) holds true exactly for the standard diffusion model with exponential distribution, but also approximates well for other distributions p, as shown in the empirical study below. In either case, the dimension N of z grows exponentially fast in network size n and hence renders the computation infeasible in practice. To overcome this issue, we employ the Mori-Zwanzig formalism [7] to derive a reduced-order model of x with dimensionality n only.
Mori-Zwanzig memory closure We employ the Mori-Zwanzig (MZ) formalism [7] that allows to introduce a generalized Langevin equation (GLE) of the x part of the dynamics (6). The GLE of x is derived from the original equation (6) describing the evolution of z = [x; e], while maintaining the effect of the unresolved part e. This is particularly useful in our case, as we only need x for infection probability estimation and inﬂuence prediction.
Deﬁne the Liouville operator L such that L[g](z) := ¯f (z) · ∇zg(z) for any real-valued function g of z. Let etL be the Koopman operator associated with L such that etLg(z(0)) = g(z(s)) where z(t) solves (6). Then L is known to satisfy the semi-group property for all g, i.e., etLg(z) = g(etLz). Now consider the projection operator P as the truncation such that (Pg)(z) = (Pg)([x; e]) = g([x; 0]) for any z = [x; e], and its orthogonal complement as Q = I − P where I is the identity operator.
The following theorem describes the exact evolution of x(t), and the proof is given in Appendix B.2.
Theorem 2. The evolution of x speciﬁed in (6) can also be described by the following GLE: x(cid:48) = f (x; A) + (cid:90) t 0 k(t − s, x(s)) ds, (9) where f is given in (7), and k(t, x) := PLetQLQLx.
Note that, (9) is not an approximation—it is an exact representation of the x part of the original problem (6). The equation (9) can be interpreted as a mean-ﬁeld equation, where the two terms on the right hand side are called the streaming term (corresponding to the mean-ﬁeld dynamics) and memory term, respectively. The streaming term provides the main drift of the evolution, and the memory term in the convolution form is for vital adjustment. This inspires us to approximate the memory term as a time convolution on x, which naturally yields a delay differential equation and further reduces to a structured recurrent neural network (RNN) after discretization, as shown in the next subsection.
Delay differential equation and RNN To compute the evolution (9) of x, we consider an approxi-mation of the Mori-Zwanzig memory term by a neural net ε with time convolution of x as follows, (cid:90) t 0 k(t − s, x(s)) ds ≈ ε(x(t), h(t); η) where h(t) = (cid:90) t 0
K(t − s; w)x(s) ds. (10)
In (10), K(·; w) is a convolutional operator with parameter w, and ε(x, h; η) is a deep neural net with (x, h) as input and η as parameter. Both w and η are to be trained by the cascade data D.
Hence, (9) reduces to a delay differential equation which involves a time integral h(t) of past x: x(cid:48) = ˜f (x, h; θ) := f (x; A) + ε(x, h; η). (11)
The initial condition of (11) with source set S is given by x(0) = χS , h(0) = 0, and x(t) = h(t) = 0,
∀ t < 0. (12)
We call the system (11) with initial (12) the neural mean-ﬁeld (NMF) dynamics.
The delay differential equation (11) is equivalent to a coupled system of (x, h). In addition, we show that the discretization of this system reduces to a structured recurrent neural network if K(t; w) is a (linear combination of) matrix convolutions in the following theorem. 4
Theorem 3. The delay differential equation (11) is equivalent to the following coupled system: x(cid:48) = ˜f (x, h; A, η) = f (x; A) + ε(x, h; η) h(cid:48) = (cid:82) t 0 K(t − s; w) ˜f (x(s), h(s); A, η) ds (13a) (13b) l=1 Ble−Clt for some L ∈ N with with initial condition (12). w = {(Bl, Cl)l : BlCl = ClBl, ∀ l ∈ [L]}, then (13) can be solved by a non-delay system of (x, h) with (13a) and h(cid:48) = (cid:80)L l=1(Blx − Clh). The discretization of such system (with step size normalized to 1) reduces to an RNN with hidden layers (xt, ht) for t = 0, 1, . . . , T − 1:
In particular, if K(t; w) = (cid:80)L xt+1 = xt + f (xt; A) + ε(xt, ht; η) ht+1 = ht + (cid:80)L l=1(Blxt+1 − Clht) where the input is given by x0 = χS and h0 = 0. (14a) (14b)
The proof is given in Appendix B.3. The matrices Bl and Cl in (14b) correspond to the weights on xt+1 and ht to form the linear transformation, and the neural network ε wraps up (xt, ht) to approximate the nonlinear effect of the memory term in (10).
We here consider a more general convolution kernel K(·; w) than the exponential kernel. Note that, in practice, the convolution weight K on older state x in (10) rapidly diminishes, and hence the memory kernel K can be well approximated with a truncated history of ﬁnite length τ > 0, or τ ∈ N after discretization. Hence, we substitute (14b) by ht = Kwmt where Kw = [Kw 0 , . . . , Kw
τ ] and mt = [xt; . . . ; xt−τ ]. (15)
Then we formulate the evolution of the augmented state mt deﬁned in (15) and follow (14a) to obtain a single evolution of mt for t = 0, . . . , T − 1: mt+1 = g(mt; θ), where g(m; θ) := [J0m + ˜f (J0m, Kwm; θ); J0m; . . . ; Jτ −1m] (16) and Js := [· · · , I, · · · ] ∈ Rn×(τ +1)n has identity I as the (s + 1)th block and 0 elsewhere (thus
Jsmt extracts the (s + 1)th block xt−s of mt) for s = 0, . . . , τ − 1. If (14b) is considered, a simpler augmented state mt = [xt; ht] can be formed similarly; we omit the details here. We will use the dynamics (16) of the augmented state mt in the training below.
An optimal control formulation of parameter learning Now we consider the training of the network parameters θ = (A, η, w) of (16) using cascade data D. Given a sample cascade ˆx = (S, τ ) from D, we can observe its value in {0, 1}n at each of the time points t = 1, . . . , T and obtain the corresponding infection states, i.e., ˆx = { ˆxt ∈ {0, 1}n : t ∈ [T ]} (see Section 2). Maximizing the log-likelihood of ˆx for the dynamics xt = xt(θ) ∈ [0, 1]n induced by θ is equivalent to minimizing the loss function (cid:96)(x, ˆx): (cid:96)(x, ˆx) = (cid:80)T t=1 ˆxt · log xt + (1 − ˆxt) · log(1 − xt), (17) where the logarithm is taken componentwisely. We can add a regularization term r(θ) to (17) to impose prior knowledge or constraint on θ. In particular, if E is known, we can enforce a constraint such that A must be supported on E only. Otherwise, we can add (cid:107)A(cid:107)1 or (cid:107)A(cid:107)0 (the l1 or l0 norm of the vectorized A) if E is expected to be sparse. In general, A can be interpreted as the convolution to be learned from a graph convolution network (GCN) [26, 53]. The support and magnitude of A imply the network structure and strength of interaction between nodes, respectively. We provide more details of our numerical implementation in Section 4 and Appendix D.1.
The optimal parameter θ can be obtained by minimizing the loss function in (17) subject to the NMF dynamics (16). This procedure can also be cast as an optimal control problem to ﬁnd θ that steers mt to ﬁt data D through the NMF in (16):
J (θ) := (1/K) · (cid:80)K k=1 (cid:96)(x(k), ˆx(k)) + r(θ) min
θ s.t. m(k) t+1 = g(m(k) t
; θ), m(k) 0 = [χSk , 0, . . . , 0], t ∈ [T ] − 1, k ∈ [K], (18a) (18b) where x(k) for all t and k. The problem of optimal control has been well studied in both continuous and discrete cases in the past decades [2]. In particular, the discrete optimal control t = J0m(k) t 5
with nonlinear difference equations and the associated maximum principle have been extensively exploited. Recently, an optimal control viewpoint of deep learning has been proposed [32]—the network parameters of a neural network play the role of control variable in a discretized differential equation, and the training of these parameters for the network output to minimize the loss function can be viewed as ﬁnding the optimal control to minimize the objective function at the terminal state.
The Pontryagin’s Maximum Principle (PMP) provides an important optimality condition of the optimal control [2, 32]. In standard optimal control, the control variable can be chosen freely in the allowed set at any given time t, which is a key in the proof of PMP. However, the NMF dynamics derived in (13) or (14) require a time invariant control θ throughout. This is necessary since θ corresponds to the network parameter and needs to be shared across different layers of the RNN, either from the linear kernel case with state [x; h] in (14) or the general case with state m in (16).
Therefore, we need to modify the original PMP and the optimality condition for our NMF formulation.
To this end, consider the Hamiltonian function
H(m, p; θ) = p · g(m; θ) − 1
T r(θ), (19) and deﬁne the total Hamiltonian of the system (14) as (cid:80)T −1 that the optimal solution θ∗ is a time invariant control satisfying a modiﬁed PMP as follows.
Theorem 4. Let x∗ be the optimally controlled state process by θ∗, then there exists a co-state (adjoint) p∗ which satisﬁes the backward differential equation t ; θ∗), t+1 · ∇mg(m∗ 0 = [χSk ; 0; . . . ; 0],
T = −∇mT (cid:96), t=0 H(mt, pt+1; θ). Then we can show t+1 = g(m∗ t = p∗ p∗ m∗ t ; θ∗), p∗ t = 0, . . . , T − 1, t = T − 1, . . . , 0. (20a) (20b) m∗
Moreover, the optimal θ∗ maximizes the total Hamiltonian: for any θ, there is (cid:80)T −1 t=0 H(m∗
In addition, for any given θ, there is ∇θJ (θ) = − (cid:80)T −1 0 ≤ t ≤ T } are obtained by the forward and backward passes (20a)-(20b) with θ. t=0 ∂θH(mθ t=0 H(m∗ t+1; θ∗) ≥ (cid:80)T −1 t+1; θ). t , pθ t , p∗ t , p∗ t+1; θ), where {mθ t , pθ t
: (21)
The proof is given in Appendix B.4. We introduced the total Hamiltonian (cid:80)T −1 t=0 H(mt, pt+1; θ) in
Theorem 4 since the NMF dynamics (14) (or (16)) suggest a time invariant control θ independent of t, which corresponds to θ shared by all layers in an RNN. This is particularly important for time series analysis, where we perform regression on data observed within limited time window, but often want to use the learned parameters to predict events in distant future. Theorem 4 also implies that performing gradient descent to minimize J in (18a) with back-propagation is equivalent to maximizing the total Hamiltonian in light of (21).
Our numerical implementation of the proposed NMF is summarized in Algorithm 1. From training cascade data D, NMF can learn the parameter θ = (A, η, w). The support (indices of nonzero entries) of the matrix A reveals the edge E of the diffusion network G = (V, E), and the values of A are the corresponding infection rates on the edges. In addition to the diffusion network parameters inferred by A, we can also estimate (predict) the inﬂuence {xt : t ∈ [T ]} of any new source set x0 ∈ Rn by a forward pass of NMF dynamics (16) with the learned θ. Note that this forward pass can be computed on the ﬂy, which is critical to those downstream applications (such as inﬂuence maximization) that call inﬂuence estimation as a subroutine repeatedly during the computations. 4 Numerical Experiments
Infection probability and inﬂuence function estimation We ﬁrst test NMF on a set of synthetic networks that mimic the structure of real-world diffusion network. Two types of the Kronecker network model [27] are used: hierarchical (Hier) [8] and core-periphery (Core) [28] networks with parameter matrices [0.9,0.1;0.1,0.9] and [0.9,0.5;0.5,0.3], respectively. For each type of network model, we generate 5 networks consisting of 128 nodes and 512 edges. We simulate the diffusion where the infection times are modeled by exponential distribution (Exp) and Rayleigh distribution (Ray). For each distribution, we draw αji from Unif[0.1,1] to simulate the varying interactions between nodes. We generate training data consists of K=10,000 cascades, which is formed by 10 sample cascades for each of 1,000 source sets (a source set is generated by randomly selecting 1 to 6
Algorithm 1 Neural mean-ﬁeld (NMF) algorithm for network inference and inﬂuence estimation
Input: D = {Ck : k ∈ [K]} where Ck = { ˆx(k)(t) ∈ {0, 1}n : t = 0, 1, . . . , T }.
Initialization: Parameter θ = (A, η, w). for k = 1, . . . , K do
Sample a mini-batch ˆD ⊂ D of cascades.
Compute {mt : t ∈ [T ]} using (16) with θ and m0 = [χS ; 0] for each C ∈ ˆD. (Forward pass)
Compute ˆ∇θJ = (cid:80) (Backward pass)
Update parameter θ ← θ − τ ˆ∇θJ .
C∈ ˆD ∇θ(cid:96)(x, ˆx) with (cid:96) in (17). end for
Output: Network parameter θ. 10 nodes from the network). All networks and cascades are generated by SNAP [29]. Our numerical implementation of NMF is available at https://github.com/ShushanHe/neural-mf.
We compare NMF to two baseline methods: InﬂuLearner [12] which is a state-of-the-art method that learns the coverage function of each node for any ﬁxed time, and a conditional LSTM (LSTM for short) [22], which are among the few existing methods capable of learning infection probabilities of individual nodes directly from cascade data as ours. For InﬂuLearner, we set 128 as the feature number for optimal accuracy as suggested in [12]. For LSTM, we use one LSTM block and a dense layer for each t. To evaluate accuracy, we compute the mean absolute error (MAE) of node infection probability and inﬂuence over 100 source sets for each time t. More details of the evaluation criteria are provided in Appendix D.1. The results are given in Figure 1, which shows the mean (center line) and standard deviation (shade) of the three methods. NMF generally has lowest MAE, except at some early stages where InﬂuLearner is better. Note that InﬂuLearner requires and beneﬁts from the knowledge of the original source node for each infection in the cascade (provided in our training data), which is often unavailable in practice and not needed in our method.
We also tested NMF on a real dataset [54] from Sina Weibo social platform consisting of more that 1.78 million users and 308 million following relationships among them. Following the setting in
[12], we select the most popular tweet to generate diffusion cascades from the past 1,000 tweets of each user. Then we recreate the cascades by only keeping nodes of the top 1,000 frequency in the pooled node set over all cascades. For testing, we uniformly generate 100 source sets of size 10 and use t = 1, 2, . . . , 10 as the time steps for observation. Finally, we test 100 source sets and compare our model NMF with the InﬂuLearner and LSTM. The MAE of all methods are shown in Figure 2a which shows that NMF signiﬁcantly outperforms LSTM and is similar to InﬂuLearner. However, unlike InﬂuLearner that requires re-training for every t and is computationally expensive, NMF learns the evolution at all t in a single sweep of training and is tens of time faster.
We also test robustness of NMF for varying network density |E|/n. The MAE of inﬂuence and infection probabilty by NMF on a hierarchical network with n = 128 are shown in Figure 2c and 2b, respectively. NMF remains accurate for denser networks, which can be notoriously difﬁcult for other methods such as InﬂuLearner.
Network structure inference The interpretable parameterization of NMF allows us to explicitly learn the weight matrix A. In this test, we examine the quality of the learned A. We set the recovered adjacency matrix E to the binary indicator matrix A(cid:62) ≥ (cid:15), i.e., (E)i,j = 1 if (A)ji ≥ 0.01. To evaluate the quality of E and A, we use four metrics: precision (Prc), recall (Rcl), accuracy (Acc), and correlation (Cor), deﬁned as follows,
, Rcl(E, E ∗) = |E∩E ∗|
Prc(E, E ∗) = |E∩E ∗|
|E ∗| (cid:107)A(cid:107)F (cid:107)A∗(cid:107)F where E ∗ and A∗ are their true values, respectively. In Acc, the edge set E is also interpreted as a matrix, and |E| counts the number of nonzeros in E. In Cor, (cid:107)A(cid:107)2
F = tr(A(cid:62)A) is the Frobenius norm of the matrix A. Prc is the ratio of edges in E ∗ that are recovered in E. Rcl is the ratio of correctly recovered edges in E. Acc indicates the ratio of the number of common edges shared by
E and E ∗ against the total number of edges in them. Cor measures similarity between A and A∗ by taking their values into consideration. All metrics are bounded between [0, 1], and higher value indicates better result. For comparison, we also test NETRATE [16] to the cascade data and learn A with Rayleigh distribution. Evaluation by four metrics are shown in Table 1, which indicates that
|E|+|E ∗| , Cor(A, A∗) = tr(A(cid:62)A∗)
, Acc(E, E ∗) = 1− |E−E ∗|
|E|
. 7
(a) Hier + Exp (b) Hier + Ray (c) Core + Exp (d) Core + Ray (e) Hier + Exp (f) Hier + Ray (g) Core + Exp (h) Core + Ray
Figure 1: MAE of inﬂuence (top row) and node infection probability (bottom row) by LSTM,
InﬂuLearner, and NMF on different combinations of Hierarchical (Hier) and Core-periphery (Core) networks, and exponential (Exp) and Rayleigh (Ray) diffusion models. Mean (centerline) and standard deviation (shade) over 100 tests are shown.
Table 1: Performance of structure inference using NETRATE and the proposed NMF on Random,
Hierarchical, and Core-periphery networks with Rayleigh distribution as the diffusion time model on edges. Quality of the learned edge set E and distribution parameter A are measured by precision (Prc), recall (Rcl), accuracy (Acc), and correlation (Cor). Higher value indicates better quality.
Network
Random
Hierarchical
Core-periphery
Method
Prc
Rcl
Acc
Cor
NETRATE
NMF
NETRATE
NMF
NETRATE
NMF 0.481 0.858 0.659 0.826 0.150 0.709 0.399 0.954 0.429 0.978 0.220 0.865 0.434 0.903 0.519 0.893 0.178 0.779 0.465 0.950 0.464 0.938 0.143 0.931
NMF outperforms NETRATE in all metrics. Note that NMF learns A along with the NMF dynamics for infection probability estimation in its training, whereas NETRATE can only learn the matrix A.
Inﬂuence maximization We use NMF as an inﬂuence estimation subroutine in a classical greedy algorithm [38] (NMF+Greedy), and compare with a state-of-the-art method DIFFCELF[42] for inﬂuence maximization (IM). Like NMF+Greedy, DIFFCELF also only requires infection time features, but not network structures as in most existing methods. We generate 1000 cascades with unique source (as required by DIFFCELF but not ours) on a hierarchical network of 128 nodes and 512 edges, and use exponential distribution for the transmission function with A generated from
Unif[1,10]. Time window is T = 20. For each source set size n0 = 1, . . . , 10, NMF+Greedy and
DIFFCELF are applied to identify the optimal source sets, whose inﬂuence are computed by averaging 10,000 MC simulated cascades. Figure 2d shows that the source sets obtained by NMF+Greedy generates greater inﬂuence than DIFFCELF consistently for every source size n0. 5