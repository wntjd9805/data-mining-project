Abstract
We introduce a novel, end-to-end learnable, differentiable non-rigid tracker that enables state-of-the-art non-rigid reconstruction by a learned robust optimization.
Given two input RGB-D frames of a non-rigidly moving object, we employ a convolutional neural network to predict dense correspondences and their conﬁ-dences. These correspondences are used as constraints in an as-rigid-as-possible (ARAP) optimization problem. By enabling gradient back-propagation through the weighted non-linear least squares solver, we are able to learn correspondences and conﬁdences in an end-to-end manner such that they are optimal for the task of non-rigid tracking. Under this formulation, correspondence conﬁdences can be learned via self-supervision, informing a learned robust optimization, where outliers and wrong correspondences are automatically down-weighted to enable effective track-ing. Compared to state-of-the-art approaches, our algorithm shows improved reconstruction performance, while simultaneously achieving 85× faster correspon-dence prediction than comparable deep-learning based methods. We make our code available at https://github.com/DeformableFriends/NeuralTracking. 1

Introduction
The capture and reconstruction of real-world environments is a core problem in computer vision, enabling numerous VR/AR applications. While there has been signiﬁcant progress in reconstructing static scenes, tracking and reconstruction of dynamic objects remains a challenge. Non-rigid recon-struction focuses on dynamic objects, without assuming any explicit shape priors, such as human or face parametric models. Commodity RGB-D sensors, such as Microsoft’s Kinect or Intel’s Realsense, provide a cost-effective way to acquire both color and depth video of dynamic motion. Using a large number of RGB-D sensors can lead to an accurate non-rigid reconstruction, as shown by Dou et al.
[8]. Our work focuses on non-rigid reconstruction from a single RGB-D camera, thus eliminating the need for specialized multi-camera setups.
The seminal DynamicFusion by Newcombe et al. [23] introduced a non-rigid tracking and mapping pipeline that uses depth input for real-time non-rigid reconstruction from a single RGB-D camera.
Various approaches have expanded upon this framework by incorporating sparse color correspon-dences [13] or dense photometric optimization [10]. DeepDeform [4] presented a learned corre-spondence prediction, enabling signiﬁcantly more robust tracking of fast motion and re-localization.
Unfortunately, the computational cost of the correspondence prediction network (∼ 2 seconds per frame for a relatively small number of non-rigid correspondences) inhibits real-time performance.
∗Denotes equal contribution. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
e c r u o
S t e g r a
T
Correspondence
Correspondence
Differentiable n o i t a r g e t n
I h t p e
D
RGB-D Input Stream
Neural Non-Rigid Tracker
Prediction
Weighting
Solver
Final
Reconstruction
Figure 1: Neural Non-Rigid Tracking: based on RGB-D input data of a source and a target frame, our learned non-rigid tracker estimates the non-rigid deformations to align the source to the target frame. We propose an end-to-end approach, enabling correspondences and their importance weights to be informed by the non-rigid solver. Similar to robust optimization, this provides robust tracking, and the resulting deformation ﬁeld can then be used to integrate the depth observations in a canonical volumetric 3D grid that implicitly represents the surface of the object (ﬁnal reconstruction).
Simultaneously, work on learned optical ﬂow has shown dense correspondence prediction at real-time rates [30]. However, directly replacing the non-rigid correspondence predictions from Božiˇc et al. [4] with these optical ﬂow predictions does not produce accurate enough correspondences for comparable non-rigid reconstruction performance. In our work, we propose a neural non-rigid tracker, i.e., an end-to-end differentiable non-rigid tracking pipeline which combines the advantages of classical deformation-graph-based reconstruction pipelines [23, 13] with novel learned components. Our end-to-end approach enables learning outlier rejection in a self-supervised manner, which guides a robust optimization to mitigate the effect of inaccurate correspondences or major occlusions present in single RGB-D camera scenarios.
Speciﬁcally, we cast the non-rigid tracking problem as an as-rigid-as-possible (ARAP) optimization problem, deﬁned on correspondences between points in a source and a target frame. A differentiable
Gauss-Newton solver allows us to obtain gradients that enable training a neural network to predict an importance weight for every correspondence in a completely self-supervised manner, similar to robust optimization. The end-to-end training signiﬁcantly improves non-rigid tracking performance. Using our neural tracker in a non-rigid reconstruction framework results in 85× faster correspondence prediction and improved reconstruction performance compared to the state of the art.
In summary, we propose a novel neural non-rigid tracking approach with two key contributions:
• an end-to-end differentiable Gauss-Newton solver, which provides gradients to better inform a correspondence prediction network used for non-rigid tracking of two frames;
• a self-supervised approach for learned correspondence weighting, which is informed by our differentiable solver and enables efﬁcient, robust outlier rejection, thus, improving non-rigid reconstruction performance compared to the state of the art. 2