Abstract
Modeling dependencies in multivariate discrete data is a challenging problem, especially in high dimensions. The Potts model is a versatile such model, suitable when each coordinate is a categorical variable. However, the full Potts model has too many parameters to be accurately ﬁt when the number of categories is large.
We introduce a variation on the Potts model that allows for general categorical marginals and Ising-type multivariate dependence. This reduces the number of parameters from Ω(d2K 2) in the full Potts model to O(d2 + Kd), where K is the number of categories and d is the dimension of the data. We show that the complexity of ﬁtting this new Potts-Ising model is the same as that of an Ising model. In particular, adopting the neighborhood regression framework, the model can be ﬁt by solving d separate logistic regressions. We demonstrate the ability of the model to capture multivariate dependencies in real data by comparing with existing approaches. 1

Introduction
Modeling multivariate discrete data is a basic problem in statistics and machine learning, especially in high dimensions. Discrete data are rarely independent and a fundamental modeling task is to characterize dependencies (correlation, causation, conditional independence, etc.) among variables.
The problem is exacerbated when the data are high-dimensional. One of the most ﬂexible tools available for modeling multivariate distributions are graphical models. The Potts model [1] is a versatile such model for discrete data, suitable when each coordinate is a categorical variable. The categorical nature of the model provides much more ﬂexibility over Poisson-type count models. The
Potts model is the natural extension of the well-known Ising model for binary data [2].
The full Potts model, however, has too many parameters to be accurately ﬁt when the number of categories K is large. The large number of parameters also precludes easy interpretation. We introduce a variation on the Potts model that allows for general categorical marginals and an Ising-type multivariate dependence. This reduces the number of parameters from Ω(d2K 2) in the full Potts model to O(d2 + Kd), where d is the dimension of the data.
Our motivating example is the toxicity data collected in cancer clinical trials. Patients undergoing treatment may experience multiple toxicity types (such as nausea, diarrhea, etc) with grades of severity varying from 1, corresponding to a mild symptom, to 5 indicating death. The overall number of toxicities observed in cancer clinical trial is often more than 100. Furthermore, there is a rich dependence structure in toxicity data. For example, diarrhea can cause dehydration which leads to hypokalemia, hence the three toxicities are likely positively correlated, while some toxicities such as diarrhea and constipation are negatively correlated. The toxicity datasets are both high-dimensional and with rich dependencies.
The variation on the Potts model that we propose, which we refer to as the Potts-Ising model (POIS), has several attractive features. The marginals of the distribution are modeled after general 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
multinationals, hence provide a much better ﬁt than Poisson, to sparse data with limited range.
Moreover, the dependence structure is much simpler than the full model, captured by only a single matrix Γ which allows for easy interpretation. The ﬁtting of the model is no harder than ﬁtting d logistic regression problems. One can choose from a versatile array of regularization techniques to produce sparse or highly interpretable estimates of Γ, a surrogate for the correlation matrix.
Our model is suitable for any discrete data that has a special level, usually denoted as “0”, and the dependence is captured by the presence of this level or its absence. The model is, for example, good for rating (or survey) data, where one level often has a special meaning. For example, in rating movies, products, etc., 0 often means “not rated” rather than the lowest rating (which starts at 1).
Another example is the toxicity data, where “0” is signiﬁcantly different from a rating of 1 or above, signifying that no symptom was observed for that particular adverse event. Although we take 0 to be the special level, any other level could work: our model is categorical, hence, any level can be designated as “0”. Our model also work surprisingly well with count data as long as they are sparse enough so that the total number of unique values observed in the dataset is relatively low.
We demonstrate all the above points in the sequel and show the effectiveness of the model with extensive simulations and comparison with a wide selection of existing approaches. The code for these simulations is available at GitHub repository aaamini/pois_comparisons.