Abstract
Low-dimensional embeddings, from classical spectral embeddings to modern neural-net-inspired methods, are a cornerstone in the modeling and analysis of complex networks. Recent work by Seshadhri et al. (PNAS 2020) suggests that such embeddings cannot capture local structure arising in complex networks. In particular, they show that any network generated from a natural low-dimensional model cannot be both sparse and have high triangle density (high clustering coefﬁ-cient), two hallmark properties of many real-world networks.
In this work we show that the results of Seshadhri et al. are intimately connected to the model they use rather than the low-dimensional structure of complex networks.
Speciﬁcally, we prove that a minor relaxation of their model can generate sparse graphs with high triangle density. Surprisingly, we show that this same model leads to exact low-dimensional factorizations of many real-world networks. We give a simple algorithm based on logistic principal component analysis (LPCA) that succeeds in ﬁnding such exact embeddings. Finally, we perform a large number of experiments that verify the ability of very low-dimensional embeddings to capture local structure in real-world networks. 1

Introduction
Graphs naturally model a wide variety of complex systems including the internet, social networks, transportation networks, protein-protein interaction networks, the human brain, and co-authorship networks. Understanding and analyzing such networks lies at the heart of computer science. In recent years there has been a surge of interest in developing node embedding techniques that map the nodes of a graph to low-dimensional Euclidean space in such way that the geometry of the embedding reﬂects important structure in the graph. Speciﬁcally, a node embedding method takes as input a graph G with n nodes v1, . . . , vn and maps each node vi to a vector xi ∈ Rk, where k is an embedding dimension typically with k (cid:28) n. The learned embeddings can be used as input for downstream machine learning tasks such as clustering, classiﬁcation, and link prediction [HYL17].
Geometric representations of graphs and low-rank factorizations have a long history, cf. the text of Lovász and Vesztergombi [LV99], and important successes including spectral clustering
[SM00, NJW02], Laplacian eigenmaps [BN03], IsoMap [TDSL00], locally linear embeddings
[RS00], and community detection algorithms [ABH15, McS01, RCY+11, CRV15]. The stunning successes of deep learning in recent years have also led to a new generation of neural network-based node embedding methods. Such methods include DeepWalk [PARS14], node2vec [GL16], LINE
[TQW+15], NetMF [QDM+18], and many others [TQM15, CLX16, KW16, WCZ16]. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
Figure 1: Reconstructions of a toy graph with 100 triangles connected in a loop and a self-loops on each vertex. Top: Zoomed in to the ﬁrst 24 vertices, i.e., the ﬁrst 8 triangles; Bottom: Whole graph.
Left: True adjacency matrix; Middle: rank-5 approximation produced by our logistic PCA variant (LPCA); Right: rank-15 approximation with truncated SVD (TSVD) method [SSSG20].
This recent explosion of novel node embedding methods has already proved valuable for numerous graph mining tasks. But what are their limitations? This question was recently posed by Seshadhri et al. in their PNAS paper [SSSG20]. Seshadhri et al. remark that (i) regardless of the node embedding method, the goal is to produce a low-dimensional embedding that captures as much structure in
G as possible, and that (ii) it is well-known that real-world networks are sparse in edges, and rich in triangles. They ask an intriguing question: can low-dimensional node embeddings represent triangle-rich complex networks? Their key conclusion is that graphs generated from low-dimensional embeddings cannot contain many triangles on low-degree vertices, and thus the answer to the aforementioned question is negative. See Theorem 4 in Section 2 for a formal statement of this result.
In this work, we prove that the results in [SSSG20] are a consequence of the model they use, rather than a general property of low-dimensional embeddings. We state our contributions as informal results; for the formal statements, see Section 3. Our ﬁrst main result is:
Result 1. Low-dimensional node embeddings are able to represent triangle-rich graphs.
Figure 1 give an illustrative example of Result 1. Consider the family of graphs consisting of a set of triangles connected in a cycle. This family is a hard instance according to result of [SSSG20] since it has near maximum triangle density given its low maximum degree. Indeed, we can observe that an optimal 15-dimensional representation using the proposed method of [SSSG20] preserves very little structure in the graph. However, as Figure 1 shows, there exists a rank-5 representation which nearly fully captures the graph structure. We discuss the details of this toy experiment in Section 4.
Our second key result is a low-dimensional model that can perfectly capture all bounded degree graphs, regardless of structure. An important corollary of this result is that preferential attach-n)-rank factorization with high probability without losing any ment graphs [BA99] admit a Θ( information about their structure. Furthermore, our result is constructive.
√
Result 2. There exists a low-rank factorization algorithm that provably produces exact low-dimensional embeddings for bounded degree graphs.
We believe such exact embeddings are of independent interest to researchers working on the inter-play between privacy and node embeddings, e.g., [ECS+19, ZCZ+20] and on graph autoencoders
[TGC+14, WCZ16, PHL+18, SHV19].
We complement our results with several experiments on real-world networks. We observe that a simple algorithm can produce very low-dimensional exact representations, that go below the theoretical bounds we prove in Result 2, and still preserve all local structure. See Table 1 for a preview of our results on some popular datasets. We show that even lower dimensional factorizations, while not exact, sufﬁce to capture important structure such as degree and triangle density.
Result 3. Empirically we observe that our proposed algorithm produces very low-dimensional embeddings that preserve the local structure of large real-world networks. 2
Dataset
# Nodes Mean Degree Exact Factorization Dimension
Pubmed ca-HepPh
BlogCatalog
Citeseer
Cora 19 581 11 204 10 312 3 327 2 708 4.48 21.0 64.8 2.74 3.90 48 32 128 16 16
Table 1: Preview of our results; real-world graphs admit exact low-rank factorizations. For details and results on more datasets, see Section 4. 2