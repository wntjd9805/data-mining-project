Abstractions
Tom Yan
Carnegie Mellon University
Facebook AI Research tyyan@cmu.edu
Christian Kroer
Columbia University
Facebook Core Data Science christian.kroer@columbia.edu
Alexander Peysakhovich
Facebook AI Research alexpeys@fb.com
Abstract
Can we predict how well a team of individuals will perform together? How should individuals be rewarded for their contributions to the team performance?
Cooperative game theory gives us a powerful set of tools for answering these questions: the Characteristic Function (CF) and solution concepts like the Shapley
Value (SV). There are two major difﬁculties in applying these techniques to real world problems: ﬁrst, the CF is rarely given to us and needs to be learned from data.
Second, the SV is combinatorial in nature. We introduce a parametric model called cooperative game abstractions (CGAs) for estimating CFs from data. CGAs are easy to learn, readily interpretable, and crucially allow linear-time computation of the SV. We provide identiﬁcation results and sample complexity bounds for CGA models as well as error bounds in the estimation of the SV using CGAs. We apply our methods to study teams of artiﬁcial RL agents as well as real world teams from professional sports. 1

Introduction
Suppose we have a group of individuals out of which we need to select a team to perform a task. Besides maximizing team performance, we also wish to reward individuals fairly for their contributions to the team [25]. This general problem arises in many real world contexts: choosing athletes for a sports team [22], choosing workers for a project [28], choosing a subset of classiﬁers to use in an ensemble [27] etc. In this paper we ask: how can we use data on past performance to ﬁgure out which individuals complement each other? How can we then fairly compensate team members?
Standard game theory (sometimes called ‘non-cooperative’ game theory) explicitly speciﬁes actions, players, and utility functions. By contrast, cooperative game theory abstracts away from the ‘rules of the game’ and simply has as primitives the agents and the characteristic function (henceforth CF).
The CF measures how much utility a coalition can create. Solution concepts in cooperative game theory have been developed to be ‘fair’ divisions of the total utility created by the coalition. These solution concepts can be viewed either as prescriptive (i.e. this is what an individual ‘deserves’ to get given their contribution) or predictive of what will happen in real world negotiations, where the intuition is that coalitions (or individuals) that don’t receive fair compensations will opt to leave the game and simply transact amongst themselves.
These tools are useful for answering our main questions. The CF tells us how well a team will perform and the solution concepts will tell us how to divide value across individuals. For the purposes 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
of this paper, we consider one of the most prominent solution concepts: the Shapley Value (SV).
However, there are two hurdles to overcome. 1. The CF is unknown to us, and is combinatorial in nature, thus requiring a sensible parametric model through which we can learn the CF from team performance data. 2. The SV requires an exponential number of operations to compute.
We introduce the cooperative game abstraction (CGA) model that simultaneously addresses both of these issues. In addition, CGA models are interpretable so as to aid analysts in understanding group synergy. Our main idea is motivated by a particular decomposition of the CF into an additive series of weights that capture m-way interaction between the n players for m = 1, ..., n. When we zero out terms of order order k + 1 and higher, this leaves behind an abstraction, a sketched version of the real cooperative game, which we refer to as a kth order CGA.
Our Contribution: To the best of our knowledge, we are the ﬁrst to estimate characteristic functions with lossy abstractions [12] of the true characteristic function using parametric models, and bound the error of the estimated CF and SV. The second order variant of the CGA was ﬁrst proposed in
[9]. We generalize this work to study CGA models of any order. Our theoretical contributions are as follows: (i) sample complexity characterization of when a CGA model of order k (for any order k) is identiﬁable from data (ii) sensitivity analysis of how the estimation error of the characteristic function propagates into the downstream task of estimating the Shapley Value.
Empirically, we ﬁrst validate the usefulness of CGAs in artiﬁcial RL environments, in which we can verify the predictions of CGAs on counterfactual teams. Then, we model real world data from the
NBA, for which we do not have ground truth, using CGAs and show that its predictions are consistent with expert knowledge and various metrics of team strength and player value. 2