Abstract
In online convex optimization (OCO), Lipschitz continuity of the functions is commonly assumed in order to obtain sublinear regret. Moreover, many algorithms have only logarithmic regret when these functions are also strongly convex. Re-cently, researchers from convex optimization proposed the notions of “relative
Lipschitz continuity” and “relative strong convexity”. Both of the notions are generalizations of their classical counterparts. It has been shown that subgradient methods in the relative setting have performance analogous to their performance in the classical setting.
In this work, we consider OCO for relative Lipschitz and relative strongly convex functions. We extend the known regret bounds for classical OCO algorithms to the relative setting. Speciﬁcally, we show regret bounds for the follow the regularized leader algorithms and a variant of online mirror descent. Due to the generality of these methods, these results yield regret bounds for a wide variety of OCO algorithms. Furthermore, we further extend the results to algorithms with extra regularization such as regularized dual averaging. 1

Introduction
In online convex optimization (OCO), at each of many rounds a player has to pick a point from a convex set while an adversary chooses a convex function that penalizes the player’s choice. More precisely, in each round t ∈ N, the player picks a point xt from a ﬁxed convex set X ⊆ Rn and an adversary picks a convex function ft depending on xt. At the end of the round, the player suffers a loss of ft(xt). Besides modeling a wide range of online learning problems [Shalev-Shwartz, 2011], algorithms for OCO are often used in batch optimization problems due to their low computational cost per iteration. For example, the widely used stochastic gradient descent (SGD) algorithm can be viewed as a special case of online gradient descent [Hazan, 2016, Chapter 3] and AdaGrad [Duchi et al., 2011] is a foundational adaptive gradient descent method originally proposed in the OCO setting. The performance measure usually used for OCO algorithms is the regret. It is the difference between the cost incurred to the player and a comparison point z ∈ X ⊆ Rn (usually with minimum cumulative loss), that is to say,
RegretT (z) :=
T (cid:88) t=1 ft(xt) −
T (cid:88) t=1 ft(z).
∗Equal contributions. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
√
Classical results show that if the cost functions are Lipschitz continuous, then there are algorithms which suffer at most O(
T ) regret in T rounds [Zinkevich, 2003]. Additionally, if the cost functions are strongly convex, there are algorithms that suffer at most O(log T ) regret in T rounds [Hazan et al., 2007b]). However, not all loss functions that appear in applications, such as in inverse Poisson problems [Antonakopoulos et al., 2020] and support vector machines training [Lu, 2019], satisfy these conditions on the entire feasible set.
Recently, there has been a line of work investigating the performance of optimization methods beyond conventional assumptions [Bauschke et al., 2017, Lu et al., 2018, Lu, 2019]. Intriguingly, much of this line of work proposes relaxed assumptions under which classical algorithms enjoy convergence rates similar to the ones from the classical setting.
In particular, Lu [2019] proposed the notion of relative Lipschitz-continuity and showed how mirror descent (with properly chosen regularizer/mirror map) converges at a rate of O(1/
T ) in T iter-ations for non-smooth relative Lipschitz-continuous functions. Furthermore, they show a O(1/T ) convergence rate when the function is also relatively strongly-convex (a notion proposed by Lu et al.
T ) regret bound for online mirror
[2018]). Although the former result can be translated to a O( descent (OMD), the latter does not directly yield regret bounds in the online setting. Moreover,
Orabona and Pál [2018] showed that OMD is not suitable when we do not know a priori the number of iterations since it may suffer linear regret in this case. Finally, at present it is not known how foundational OCO algorithms such as follow the regularized leader (FTRL) [Shalev-Shwartz, 2011,
Hazan, 2016] and regularized dual averaging [Xiao, 2010] (RDA) perform in the relative setting.
√
√
Our results. We analyze the performance of two general OCO algorithms: FTRL and dual-stabilized OMD (DS-OMD, see [Fang et al., 2020]). We give O(
T ) regret bounds in T rounds for relative Lipschitz loss functions. Moreover, this is the ﬁrst paper to show O(log T ) regret if the loss functions are also relative strongly-convex.1 In addition, we are able to extend these bounds for problems with composite loss functions, such as adding the (cid:96)1-norm to induce sparsity. The generality of these algorithms lead to regret bounds for a wide variety of OCO algorithms (see Shalev-Shwartz
[2011], Hazan [2016] for some reductions). We demonstrate this ﬂexibility by deriving convergence rates for dual averaging Nesterov [2009] and regularized dual averaging [Xiao, 2010].
√ 1.1