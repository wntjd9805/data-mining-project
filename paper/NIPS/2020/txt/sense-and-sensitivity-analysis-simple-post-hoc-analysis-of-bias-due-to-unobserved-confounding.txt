Abstract
It is a truth universally acknowledged that an observed association without known mechanism must be in want of a causal estimate. However, Causal estimates from observational data will be biased in the presence of ‘unobserved confound-ing’. Nevertheless, we might hope that the inﬂuence of unobserved confounders is weak relative to a ‘large’ estimated effect. The purpose of this paper is to develop
Austen plots, a sensitivity analysis tool to aid such judgments by making it easier to reason about potential bias induced by unobserved confounding. We formalize confounding strength in terms of how strongly the unobserved confounding in-ﬂuences treatment assignment and outcome. For a target level of bias, an Austen plot shows the minimum values of treatment and outcome inﬂuence required to induce that level of bias. Austen plots generalize the classic sensitivity analy-sis approach of Imbens [Imb03]. Critically, Austen plots allow any approach for modeling the observed data. We illustrate the tool by assessing biases for several real causal inference problems, using a variety of machine learning approaches for the initial data analysis. Code, demo data, and a tutorial are available at at github.com/anishazaveri/austen plots. 1

Introduction
The high costs of randomized controlled trials coupled with the relative availability of (large scale) observational data motivate attempts to infer causal relationships from observational data. For ex-ample, we may wish to use a database of electronic health records to estimate the effect of a treat-ment. Causal inference from observational data must account for possible confounders that inﬂu-ence both treatment assignment and the outcome; e.g., wealth may be a common cause inﬂuenc-ing whether a patient takes an expensive drug and whether they recover. Often, causal inference is based on the assumption of ‘no unobserved confounding’; i.e., the assumption that the observed co-variates include all common causes of the treatment assignment and outcome. This assumption is fundamentally untestable from observed data, but its violation can induce bias in the estimation of the treatment effect—the unobserved confounding may completely or in part explain the observed association. Our aim in this paper is to develop a sensitivity analysis tool to aid in reasoning about potential bias induced by unobserved confounding.
Intuitively, if we estimate a large positive effect then we might expect the real effect is also posi-tive, even in the presence of mild unobserved confounding. For example, consider the association between smoking and lung cancer. One could argue that this association arises from a genetic mu-tation that predisposes carriers to both an increased desire to smoke and to a greater risk of lung cancer. However, the association between smoking and lung cancer is large—is it plausible that some unknown genetic association could have a strong enough inﬂuence to explain the association?
Answering such questions requires a domain expert to make a judgment about whether plausible 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
confounding is “mild” relative to the “large” effect. In particular, the domain expert must trans-late judgments about the strength of the unobserved confounding into judgments about the bias induced in the estimate of the effect. Accordingly, we must formalize what is meant by strength of unobserved confounding, and to show how to translate judgments about confounding strength into judgments about bias.
A prototypical example, due to Imbens [Imb03] (building on [RR83]), illustrates the broad ap-proach. The observed data consists of a treat-ment T , an outcome Y , and covariates X that may causally affect the treatment and outcome.
Imbens [Imb03] then posits an additional un-observed binary confounder U for each patient, and supposes that the observed data and un-observed confounder were generated according to:
Ui
Ti | Xi, Ui
Yi | Xi, Ti, Ui iid∼ Bern(1/2) ind∼ Bern(sig(γXi +αUi)) ind∼ Norm(τ Ti +βXi +δUi, σ2). where sig is the sigmoid function. If we had ob-served Ui, we could estimate (ˆτ , ˆγ, ˆβ, ˆα, ˆδ, ˆσ2) from the data and report ˆτ as the estimate of the average treatment effect. Since Ui is not observed, it is not possible to identify the pa-rameters from the data.
Instead, we make (subjective) judgments about plausible values of α—how strongly Ui affects the treatment assignment—and δ—how strongly Ui affects the outcome. Contingent on plausible α = α∗ and δ = δ∗, the other parameters can be esti-mated. This yields an estimate of the treatment effect ˆτ (α∗, δ∗) under the presumed values of the sensitivity parameters.
Figure 1: Austen plot showing how strong an unob-served confounder would need to be to induce a bias of 2 in an observational study of the effect of combination blood pressure medications on diastolic blood pressure
[Dor+16]. We chose this bias to equal the nominal aver-age treatment effect estimated from the data. We model the outcome with Bayesian Additive Regression Trees and the treatment assignment with logistic regression—
Austen plots accommodate any choice of models. The curve shows all values treatment and outcome inﬂuence that would induce a bias of 2. The colored dots show the inﬂuence strength of (groups of) observed covariates, given all other covariates. For example, an unobserved confounder with as much inﬂuence as the patient’s age might induce a bias of about 2.
The approach just outlined has a major draw-back: it relies on a parametric model for the full data generating process. The assumed model is equivalent to assuming that, had U been observed, it would have been appropriate to use logistic regression to model treatment assignment, and linear re-gression to model the outcome. This assumption also implies a simple, parametric model for the re-lationships governing the observed data. This restriction is out of step with modern practice, where we use ﬂexible machine-learning methods to model these relationships. For example, the assump-tion forbids the use of neural networks or random forests, though such methods are often state-of-the-art for causal effect estimation.
Austen plots The purpose of this paper is to introduce Austen plots, an adaptation of Imbens’ ap-proach that fully decouples sensitivity analysis and modeling of the observed data. An example
Austen plot is shown in Figure 1. The high-level idea is to posit a generative model that uses a sim-ple, interpretable parametric form for the inﬂuence of the unobserved confounder, but that puts no constraints on the model for the observed data. We then use the parametric part of the model to for-malize “confounding strength” and to compute the induced bias as a function of the confounding.
We further adapt two innovations pioneered by Imbens [Imb03]. First, we ﬁnd a parameterization of the model so that the sensitivity parameters, measuring strength of confounding, are on a standard-ized, unitless scale. This allows us to compare the strength of hypothetical unobserved confounding to the strength of observed covariates, measured from data. Second, we plot the curve of all values of the sensitivity parameter that would yield given level of bias. This moves the analyst judgment from “what are plausible values of the sensitivity parameters?” to “are sensitivity parameters this extreme plausible?” 2
Figure 1, an Austen plot for an observational study of the effect of combination medications on di-astolic blood pressure, illustrates the idea. A bias of 2 would sufﬁce to undermine the qualitative conclusion that the blood-pressure treatment is effective. Examining the plot, an unobserved con-founder as strong as age could induce this amount of confounding, but no other (group of) observed confounders has so much inﬂuence. Accordingly, if a domain expert thinks an unobserved con-founder as strong as age is unlikely then they may conclude that the treatment is likely effective. Or, if such a confounder is plausible, they may conclude that the study fails to establish efﬁcacy.
The purpose of this paper is adapting Imbens’ sensitivity analysis approach to allow for arbitrary models for observed data. The contributions are: 1. Positing a generative model that is both eas-ily interpretable and where the required bias calculations are tractable. 2. Deriving a reparameter-ization that standardizes the scale of inﬂuence strength, and showing how to estimate the inﬂuence strength of observed covariates for reference. And, 3. illustrative examples showing that Austen plots preserve the key elements of Imbens’ approach and are informative about sensitivity to unob-served confounding in real-world data.
The key advantages of Austen plots as a sensitivity analysis method are1 1. Plausibility judgments are made on directly interpretable quantities, the total confounding inﬂuence on Y and T . Addition-ally, the Austen plot model does not rely on the detailed nature of the unobserved confounding— there may be one or many unobserved confounders, with any sort of distribution—all that matters is the total confounding inﬂuence. 2. The unobserved strength of confounding can be directly com-pared to the strength of observed covariates. 3. The method is entirely post-hoc. That is, the analyst does not need to consider any aspect of the sensitivity analysis when modeling the observed data. In particular, producing Austen plots requires only predictions from the data models. We provide soft-ware and a tutorial for producing the plots.2
Notation For concreteness, we focus on the estimation of the average effect of a binary treatment.
The data are generated independently and identically (Yi, Ti, Xi, Ui) iid∼ P , where Ui is not ob-served and P is some unknown probability distribution. The average treatment affect (ATE) is
ATE = E[Y | do(T = 1)] − E[Y | do(T = 0)].
The use of Pearl’s do notation indicates that the effect of interest is causal. The results that follow can also be simply adapted to the average treatment effect on the treated, see appendix A.
The traditional approach to causal estimation assumes that the observed covariates X contain all common causes of Y and T . If this ‘no unobserved confounding’ assumption holds, then the ATE is equal to parameter, τ , of the observed data distribution, where
τ = E[E[Y | X, T = 1] − E[Y | X, T = 0]]. (1.1)
The parameter τ can be estimated from a ﬁnite data sample. The general approach proceeds in two steps. First, we produce estimates ˆg and ˆQ for the propensity score g and the conditional expected outcome Q, where
Deﬁnition 1. The propensity score g is g(x) = P(T = 1 | X = x) and the conditional expected outcome Q is Q(t, x) = E[Y | T = t, X = x].
In modern practice, Q and g are often estimated by ﬁtting ﬂexible machine learning models. The second step is to plug the estimated ˆQ and ˆg in to some downstream estimator ˆτ . For example, following 1.1, the estimator
ˆτ Q = 1 n (cid:88) i
ˆQ(1, xi) − ˆQ(0, xi), is a natural choice. Other estimators incorporate ˆg.
We are interested in the case of possible unobserved confounding. That is, where U causally affects
Y and T . If there is unobserved confounding then the parameter τ is not equal to the ATE, so ˆτ is a biased estimate. Inference about the ATE then divides into two tasks. First, the statistical task: 1See section 5 for a more detailed comparison with related work. 2github.com/anishazaveri/austen plots 3
estimating τ as accurately as possible from the observed data. And, second, the causal (domain-speciﬁc) problem of assessing bias = ATE − τ . We emphasize that our focus here is bias due to causal misidentiﬁcation, not the statistical bias of the estimator. Our aim is to reason about the bias induced by unobserved confounding—the second task—in a way that imposes no constraints on the modeling choices for ˆQ, ˆg and ˆτ used in the initial analysis. 2 Sensitivity Model
Our sensitivity analysis should impose no constraints on how the observed data is modeled. How-ever, sensitivity analysis demands some assumption on the relationship between the observed data and the unobserved confounder.
It is convenient to formalize such assumptions by specifying a probabilistic model for how the data is generated. The strength of confounding is then formalized in terms of the parameters of the model (the sensitivity parameters). Then, the bias induced by the confounding can be derived from the assumed model. Our task is to posit a generative model that both yields a useful and easily interpretable sensitivity analysis, and that avoids imposing any as-sumptions about the observed data.
To begin, consider the functional form of the sensitivity model used by Imbens [Imb03]. logit P(T = 1 | x, u) = h(x) + αu
E[Y | t, x, u] = l(t, x) + δu, (2.1) (2.2) for some functions h and l. That is, the propensity score is logit-linear in the unobserved confounder, and the conditional expected outcome is linear.
By rearranging (2.1) to solve for u and plugging in to (2.2), we see that it’s equivalent to assume
E[Y | t, x, u] = ˜l(t, x) + ˜δ logit P(T = 1 | x, u). That is, the unobserved confounder u only inﬂuences the outcome through the propensity score. Accordingly, by positing a distribution on
P(T = 1 | x, u) directly, we can circumvent the need to explicitly articulate U (and h).
Deﬁnition 2. Let ˜g(x, u) = P(T = 1 | x, u) denote the propensity score given observed covariates x and the unobserved confounder u.
The insight is that we can posit a sensitivity model by deﬁning a distribution on ˜g directly. The logit-linear model does not directly lead to a tractable sensitivity analysis. Instead, we choose:
˜g(X, U ) | X ∼ Beta(g(X)(1/α−1), (1−g(X))(1/α−1)).
The sensitivity parameter α plays the same role as in Imbens’ model: it controls the inﬂuence of the unobserved confounder U on treatment assignment. When α is close to 0 then ˜g(X, U ) | X is tightly concentrated around g(X), and the unobserved confounder has little inﬂuence. That is, U minimally affects our belief about who is likely to receive treatment. Conversely, when α is close to 1 then ˜g concentrates near 0 and 1; i.e., knowing U would let us accurately predict treatment assignment. Indeed, it can be shown that α is the change in our belief about how likely a unit was to have gotten the treatment, given that they were actually observed to be treated (or not):
α = E[˜g(X, U ) | T = 1] − E[˜g(X, U ) | T = 0]. (2.3)
With the ˜g model in hand, we deﬁne our sensitivity model:
Assumption 1 (Sensitivity Model).
˜g(X, U ) | X ∼ Beta(g(X)(1/α−1), (1−g(X))(1/α−1))
T | X, U ∼ Bern(˜g(X, U ))
E[Y | T, X, U ] = Q(T, X) + δ(cid:0) logit ˜g(X, U ) − E[logit ˜g(X, U ) | X, T ](cid:1).
This model has been constructed to satisfy the requirement that the propensity score and conditional expected outcome are the g and Q actually present in the observed data:
P(T = 1 | X) = E[E[T | X, U ] | X] = E[˜g(X, U ) | X] = g(X)
E[Y | T, X] = E[E[Y | T, X, U ] | T, X] = Q(T, X). 4
The sensitivity parameters are α, controlling the dependence between the unobserved confounder the treatment assignment, and δ, controlling the relationship with the outcome. In effect, by making an assumption about the propensity score directly, we have sidestepped the need to explicitly articulate the parts of the observed/unobserved relationship that are not actually relevant for the treatment effect estimation.
Bias We now turn to calculating the bias induced by unobserved confounding. By assumption, X and U together sufﬁce to render the average treatment effect identiﬁable as:
ATE = E[E[Y | T = 1, X, U ] − E[Y | T = 0, X, U ]].
Plugging in our sensitivity model yields,
ATE = E[Q(1, X) − Q(0, X)] + δ(E[logit ˜g(X, U ) | X, T = 1] − E[logit ˜g(X, U ) | X, T = 0]).
The ﬁrst term is the observed-data estimate τ , so bias = δ(E[logit ˜g(X, U ) | X, T = 1] − E[logit ˜g(X, U ) | X, T = 0]).
Then, by invoking Beta-Bernoulli conjugacy and standard Beta identities, we arrive at,
Theorem 3. Under our sensitivity model, Assumption 1, an unobserved confounder with inﬂuence
α and δ induces bias in the estimated treatment effect equal to bias = δE(cid:2)ψ(cid:0)g(X)(1/α − 1) + 1(cid:1) − ψ(cid:0)(1 − g(X))(1/α − 1)(cid:1)
− ψ(cid:0)g(X)(1/α − 1)(cid:1) + ψ(cid:0)(1 − g(X))(1/α − 1) + 1(cid:1)(cid:3), where ψ is the digamma function
Reparameterization The model in the previous section provides a formalization of confounding strength and tells us how much bias is induced by a given strength of confounding. This lets us translate judgments about confounding strength to judgments about bias. However, δ may be difﬁ-cult to interpret. Following Imbens [Imb03], we will reexpress the outcome-confounder strength in terms of the partial coefﬁcient of determination:
R2
Y,par(α, δ) =
E(Y − Q(T, X))2 − E(Y − E[Y | T, X, U ])2
E(Y − Q(T, X))2
.
This parameterization has two advantages over δ. First, R2
Y,par has a familiar interpretation—the proportion of previously unexplained variation in Y that is explained by the unobserved covariate
U . Second, R2
Y,par has a ﬁxed, unitless scale—enabling easy comparisons with reference values.
The key to computing the reparameterization is the following result (proof in appendix):
Theorem 4. Under our sensitivity model, Assumption 1, the outcome inﬂuence is
R2
Y,par(α, δ) = δ2 1 (cid:88)
E(cid:2)ψ1 (cid:0)g(X)t(1 − g(X))1−t(1/α − 1) + 1[T = t](cid:1)(cid:3) t=0
E[(Y − Q(T, X))2]
, where ψ1 is the trigamma function.
We do not reparameterize the strength of confounding on treatment assignment because, by design,
α is already interpretable and on a ﬁxed, unitless scale.
Estimating bias In combination, Theorems 3 and 4 yield an expression for the bias in terms of α
Y,par. In practice, we can estimate the bias induced by confounding by ﬁtting models for ˆQ and R2 and ˆg and replacing the expectations by means over the data. To avoid problems associated with overﬁtting, we recommend a data splitting approach. Namely, split the data into k folds and, for each fold, estimate Q(ti, xi) and g(xi) by ﬁtting the ˆQ and ˆg models on the other k − 1 folds. 3 Calibration using observed data
The analyst must make judgments about the inﬂuence a hypothetical unobserved confounder might have on treatment assignment and outcome. To calibrate such judgments, we’d like to have a refer-ence point for how much the observed covariates inﬂuence the treatment assignment and outcome. 5
In the sensitivity model, the degree of inﬂuence is measured by partial R2 sure the degree of inﬂuence of an observed covariate Z given the other observed covariates X\Z.
Y and α. We want to mea-For the outcome, this can be measured as:
R2
Y ·Z|T,X\Z :=
E(Y − E[Y | T, X\Z])2 − E(Y − Q(T, X))2
E(Y − E[Y | T, X\Z])2
.
In practice, estimate the quantity by ﬁtting a new regression model ˆQZ that predicts Y from T and
X\Z. Then we compute
R2
Y ·Z|T,X\Z = 1 n (cid:80) i(yi − ˆQZ(ti, xi\zi))2 − 1 n (cid:80) i(yi − ˆQ(ti, xi))2 (cid:80) 1 n i(yi − ˆQZ(ti, xi\zi))2
.
It is less clear how to produce the analogous estimate for the inﬂuence on treatment assignment. To facilitate the estimation, we reexpress α in a more convenient form (proof in appendix):
Theorem 5. Under our sensitivity model, Assumption 1,
α = 1 −
E[˜g(X, U )(1 − ˜g(X, U ))]
E[g(X)(1 − g(X))]
.
Then, we can measure inﬂuence of observed covariate Z on treatment assignment given X\Z in an analogous fashion to the outcome. We deﬁne gX\Z(X\Z) = P(T = 1 | X\Z), then ﬁt a model for gX\Z by predicting T from X\Z, and estimate
ˆαZ|X\Z = 1 − 1 n
Grouping covariates The estimated values ˆαX\Z and ˆR2
Y,X\Z measure the inﬂuence of Z conditioned on all the other confounders. In some cases, this can be misleading. For example, if some piece of information is impor-tant but there are multiple covariates providing redundant measurements, then the estimated inﬂuence of each covariate will be small. To avoid this, we suggest grouping together related or strongly dependent covariates and computing the inﬂuence of the en-tire group in aggregate. For example, grouping income, location, and race as ‘socioeconomic variables’. 4 Examples
We now examine several examples of Austen plots for sensitivity anal-ysis, showing: (1) We preserve the qualitative usefulness of Imbens’ ap-proach, without any modeling re-strictions. (2) Austen plots are in-formative about bias due to unob-served confounding in real observa-tional studies. (3) The bias estimates tend to be conservative. (cid:80) 1 n i ˆg(xi)(1 − ˆg(xi)) i ˆgX\Z(xi\zi)(1 − ˆgX\Z(xi\zi))
. (cid:80)
Figure 2: Austen plots preserve the qualitative conclusions of Im-bens’ analysis without imposing any restriction on the modeling of the observed data. In each plot, the black solid line indicates the partial R2 and α values that would induce a bias of at least $1000.
Each plot also includes estimates for the strength of confounding for each of the nine covariates (red circles) as well as recent lag in earnings (RE75 and pos75, yellow circles), and the all preprogram earnings (RE74, pos74, RE75, pos75, green circles). 6
Imbens’ analysis To demonstrate the use of Austen plots, we replicate Imbens [Imb03] example and produce sensitivity plots for variations on the LaLonde job training data [LaL86]. We use exactly the same data splitting and adjustment sets as Imbens [Imb03]. We ﬁnd that the conclusions about the effects of unobserved confounding are substantively the same as Imbens [Imb03]. That is, we arrive at sensible sensitivity conclusions while liberating ourselves from the need for parametric assumptions on the observed data. We report bias for the average treatment effect on the treated.
The original purpose of the LaLonde job training data was to analyze the effect of a job training program on the annual earnings of a participant. The data consists of both an experimental (ran-domly assigned) part, and an observational sample from the Panel Study of Income Dynamics (PSID). We test on (1) the experimental sample, (2) the experimental treated with observational controls, (3) the same as 2, except with outcome deﬁned as change in earnings since 1974, and (4) the same as 2, except individuals with high earnings pretreatment (>$5000) are dropped. We ad-just for: married, age, education, race, and earnings in 1974 and 1975. There are large differences in these background covariates between the experimental sample and the PSID controls—this is a main challenge for the LaLonde setup.
Deviating from Imbens, we ﬁt random forests for ˆQ and ˆg. This demonstrates the sensitivity analysis in the case where the observed data model does not have a simple parametric speciﬁcation.
Austen plots for these analyses are displayed in Figure 2. Following Imbens, we choose a bias of
$1000 (for context, the effect estimate from the RCT is about $1800). The experimental sample (panel A) is robust to unobserved confounding: inducing a bias of $1000 would require an unob-served confounder with a much stronger effect than any of the measured covariates or earning vari-ables. By contrast, the non-experimental samples (panels B and C) are much more sensitive to un-observed confounding. Several of the covariates, if unobserved, would sufﬁce to bias the estimate by $1000. Note that the sensitivity curves are the same for both B and C, since the outcome is just a linear transformation. Finally, the restricted sample (panel D) is both signiﬁcantly more robust to bias than the full non-experimental samples, and the inﬂuence of the observed covariates is much reduced. Imposing the restriction mitigates the treatment-control population mismatch.
Practical relevance Figure 3 shows Austen plots for two effects estimated from observational data. The ﬁrst study is based on data from the Infant Health and Development Program (IHDP)
[BG+92], an experiment targeted at low-birth-weight, premature infants that provided child care and home visits. We look at a study mea-suring the effect of the level of par-ticipation in IHDP child development centers in the two years preceding an IQ test on the outcome of the IQ test [Hil11, §6.1]. Level of partici-pation is not randomly assigned, so
Hill [Hil11] estimates the effect by using Bayesian Additive Regression
Trees (BART) [Chi+10] to control for a range of covariates.
The second plot corresponds to the estimate of the effect of combina-tion blood pressure medications on diastolic blood pressure described in
[Dor+16]. The data is derived from an American survey that includes a variety of socioeconomic and health factors. We again use BART.
Figure 3: Austen plots are informative when applied to real data analysis. The left-hand plot is for the estimated effect of IHDP participation level on child IQ. The conclusions of this study seem robust to unobserved confounding—even the observed covariate groups do not have sufﬁcient inﬂuence to undo the qualitative con-clusion of the model. The right-hand plot is for the estimated effect of combination treatment on diastolic blood pressure. In this case, whether the study conclusions are reliable depends on whether an unobserved confounder as inﬂuential as age is credible—we should consult with an expert. In both cases, we model the out-come with Bayesian Additive Regression Trees, and the propen-sity score with logistic regression.
The Austen plots are informative for these examples. In the ﬁrst case, the
Austen plot increases our conﬁdence in the qualitative result. In the second case, it suggests we should be cautious about the conclusions unless unobserved confounders as strong as age are deemed unlikely. 7
Table 1: The sensitivity model tends to be conservative in its bias estimates. Bias estimates for leaving out a confounding covariate are computed according to the sensitivity model (using the left-out covariate data) and by comparing non-parametric effect estimates from the full data (τx), and the left-out covariate data (τx\z). In all cases, the sensitivity model estimate is larger.
Study: LaLonde Restricted Blood Pressure
Omitted covariate:
Education
τx
τx\z
Nonparametric bias
Sensitivity Model |bias| 2508.63 1982.54 526.09 986.90
Age
−2.33
−2.86 0.53 1.91
IHDP
Socioeconomic 12.72 13.35
−0.63 0.75
Sensitivity model conservatism Any sensitivity analysis must be predicated on some assumption about the inﬂuence of the unobserved confounder. The bias curves and inﬂuence estimates in Austen plots are contingent on the assumed sensitivity model, Assumption 1. We motivated our particular choice by simplicity and tractibility. We also expect that our associated sensitivity model will often yield conservative values for bias; i.e., the bias anticipated by the sensitivity model is higher than the true bias induced by the real, physical, mechanism of confounding. The reason is that bias is monotonically increasing in both treatment and outcome inﬂuence. In reality, hidden confounders can have more complicated relationships that ‘cancel out’. For example, the effect of age in the blood pressure example might be: blood pressure increases with age, but young patients don’t take their medication (preferring diet and exercise), middle age patients take it at a base rate, and old patients don’t take the medication (fatalism). These effects cancel out somewhat, reducing the bias induced by failing to adjust for age. Assumption 1 does not allow for such cancellations.
To test conservativism, we create deliberately confounded datasets by removing an ob-served confounder from our baseline data. We compute the bias anticipated by our model, bias(R2
Y,X\Z, αX\Z), using the measured inﬂuence strength of the covariate. We compute a non-parametric estimate of the bias by estimating the effect with the full data, estimating the effect with the deliberately confounded data, and taking the difference. The results are shown in table 1, and conﬁrm the conservatism-in-practice. This increases our conﬁdence that when an Austen plot sug-gests robustness to unobserved confounding we do indeed have such robustness. 5