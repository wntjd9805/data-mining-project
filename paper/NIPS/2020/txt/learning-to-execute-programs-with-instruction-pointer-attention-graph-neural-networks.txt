Abstract
Graph neural networks (GNNs) have emerged as a powerful tool for learning software engineering tasks including code completion, bug ﬁnding, and program repair. They beneﬁt from leveraging program structure like control ﬂow graphs, but they are not well-suited to tasks like program execution that require far more sequential reasoning steps than number of GNN propagation steps. Recurrent neural networks (RNNs), on the other hand, are well-suited to long sequential chains of reasoning, but they do not naturally incorporate program structure and generally perform worse on the above tasks. Our aim is to achieve the best of both worlds, and we do so by introducing a novel GNN architecture, the Instruction
Pointer Attention Graph Neural Network (IPA-GNN), which achieves improved systematic generalization on the task of learning to execute programs using control
ﬂow graphs. The model arises by considering RNNs operating on program traces with branch decisions as latent variables. The IPA-GNN can be seen either as a continuous relaxation of the RNN model or as a GNN variant more tailored to execution. To test the models, we propose evaluating systematic generalization on learning to execute using control ﬂow graphs, which tests sequential reasoning and use of program structure. More practically, we evaluate these models on the task of learning to execute partial programs, as might arise if using the model as a heuristic function in program synthesis. Results show that the IPA-GNN outperforms a variety of RNN and GNN baselines on both tasks. 1

Introduction
Static analysis methods underpin thousands of programming tools from compilers and debuggers to
IDE extensions, offering productivity boosts to software engineers at every stage of development.
Recently machine learning has broadened the capabilities of static analysis, offering progress on challenging problems like code completion [5], bug ﬁnding [2, 13], and program repair [25]. Graph neural networks in particular have emerged as a powerful tool for these tasks due to their suitability for learning from program structures such as parse trees, control ﬂow graphs, and data ﬂow graphs.
These successes motivate further study of neural network models for static analysis tasks. However, existing techniques are not well suited for tasks that involve reasoning about program execution.
Recurrent neural networks are well suited for sequential reasoning, but provide no mechanism for learning about complex program structures. Graph neural networks generally leverage local program structure to complete static analysis tasks. For tasks requiring reasoning about program execution, we expect the best models will come from a study of both RNN and GNN architectures. We design 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
a novel machine learning architecture, the Instruction Pointer Attention Graph Neural Network (IPA-GNN), to share a causal structure with an interpreter, and ﬁnd it exhibits close relationships with both RNN and GNN models.
To evaluate this model, we select two tasks that require reasoning about program execution: full and partial program execution. These “learning to execute” tasks are a natural choice for this evaluation, and capture the challenges of reasoning about program execution in a static analysis setting. Full program execution is a canonical task used for measuring the expressiveness and learnability of RNNs
[29], and the partial program execution task aligns with the requirements of a heuristic function for programming by example. Both tasks require the model produce the output of a program, without actually running the program. In full program execution the model has access to the full program, whereas in partial program execution some of the program has been masked out. These tasks directly measure a model’s capacity for reasoning about program execution.
We evaluate our models for systematic generalization to out-of-distribution programs, on both the full and partial program execution tasks. In the program understanding domain, systematic generalization is particularly important as people write programs to do things that have not been done before.
Evaluating systematic generalization provides a strict test that models are not only learning to produce the results for in-distribution programs, but also that they are getting the correct result because they have learned something meaningful about the language semantics. Models that exhibit systematic generalization are additionally more likely to perform well in a real-world setting.
We evaluate against a variety of RNN and GNN baselines, and ﬁnd the IPA-GNN outperforms baseline models on both tasks. Observing its attention mechanism, we ﬁnd it has learned to produce discrete branch decisions much of the time, and in fact has learned to execute by taking short-cuts, using fewer steps to execute programs than used by the ground truth trace.
We summarize our contributions as follows:
• We introduce the task of learning to execute assuming access only to information available for static analysis (Section 3).
• We show how an RNN trace model with latent branch decisions is a special case of a GNN (Section 4).
• We introduce the novel IPA-GNN model, guided by the principle of matching the causal structure of a classical interpreter.
• We show this outperforms other RNN and GNN baselines. (Section 5).
• We illustrate how these models are well-suited to learning non-standard notions of execution, like executing with limited computational budget or learning to execute programs with holes. 2