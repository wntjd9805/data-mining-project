Abstract
J
Self-supervised frameworks that learn denoising models with merely individual noisy images have shown strong capability and promising performance in various image denoising tasks. Existing self-supervised denoising frameworks are mostly built upon the same theoretical foundation, where the denoising models are required
-invariant. However, our analyses indicate that the current theory and the to be
-invariance may lead to denoising models with reduced performance. In this
J work, we introduce Noise2Same, a novel self-supervised denoising framework. In
Noise2Same, a new self-supervised loss is proposed by deriving a self-supervised upper bound of the typical supervised loss. In particular, Noise2Same requires
-invariance nor extra information about the noise model and can be used neither in a wider range of denoising applications. We analyze our proposed Noise2Same both theoretically and experimentally. The experimental results show that our
Noise2Same consistently outperforms previous self-supervised denoising methods in terms of denoising performance and training efﬁciency.
J 1

Introduction
The quality of deep learning methods for signal reconstruction from noisy images, also known as deep image denoising, has beneﬁted from the advanced neural network architectures such as ResNet [8],
U-Net [19] and their variants [29, 16, 26, 31, 25, 14]. While more powerful deep image denoising models are developed over time, the problem of data availability becomes more critical.
Most deep image denoising algorithms are supervised methods that require matched pairs of noisy and clean images for training [27, 29, 2, 7]. The problem of these supervised methods is that, in many denoising applications, the clean images are hard to obtain due to instrument or cost limitations. To overcome this problem, Noise2Noise [13] explores an alternative training framework, where pairs of noisy images are used for training. Here, each pair of noisy images should correspond to the same but unknown clean image. Note that Noise2Noise is basically still a supervised method, just with noisy supervision.
Despite the success of Noise2Noise, its application scenarios are still limited as pairs of noisy images are not available in some cases and may have registration problems. Recently, various of denoising frameworks that can be trained on individual noisy images [23, 17, 28, 10, 1, 12] have been developed.
These studies can be divided into two categories according to the amount of extra information required.
Methods in the ﬁrst category requires the noise model to be known. For example, the simulation-based methods [17, 28] use the noise model to generate simulated noises and make individual noisy images noisier. Then a framework similar to Noise2Noise can be applied to train the model with pairs of noisier image and the original noisy image. The limitation is obvious as the noise model may be too complicated or even not available. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
On the other hand, algorithms in the second category target at more general cases where only individual noisy images are available without any extra information [23, 10, 1, 12]. In this category, self-supervised learning [30, 6, 24] has been widely explored, such as Noise2Void [10], Noise2Self [1], and the convolutional blind-spot neural network [12]. Note that these self-supervised models can be improved as well if information about the noise model is given. For example, Laine et al. [12] and
Krull et al. [11] propose the Bayesian post-processing to utilize the noise model. However, with the proposed post-processing, these methods fall into the ﬁrst category where applicability is limited.
In this work, we stick to the most general cases where only individual noisy images are provided and focus on the self-supervised framework itself without any post-processing step. We note that all of these existing self-supervised denoising frameworks are built upon the same theoretical background, where the denoising models are required to be
-invariant (Section 2). We perform in-depth analyses on the
-invariance property and argue that it may lead to denoising models with reduced performance. Based on this insight, we propose Noise2Same, a novel self-supervised denoising framework, with a new theoretical foundation. Noise2Same comes with a new self-supervised loss by deriving a self-supervised upper bound of the typical supervised loss. In particular, Noise2Same requires neither
-invariance nor extra information about the noise model. We analyze the effect of the new loss theoretically and conduct thorough experiments to evaluate Noise2Same. Result show that our Noise2Same consistently outperforms previous self-supervised denoising methods.
J
J
J 2