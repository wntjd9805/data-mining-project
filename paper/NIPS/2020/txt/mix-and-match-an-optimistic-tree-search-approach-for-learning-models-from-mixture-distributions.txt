Abstract
We consider a covariate shift problem where one has access to several different training datasets for the same learning problem and a small validation set which possibly differs from all the individual training distributions. The distribution shift is due, in part, to unobserved features in the datasets. The objective, then, is to ﬁnd the best mixture distribution over the training datasets (with only observed features) such that training a learning algorithm using this mixture has the best validation performance. Our proposed algorithm, Mix&Match, combines stochastic gradient descent (SGD) with optimistic tree search and model re-use (evolving partially trained models with samples from different mixture distributions) over the space of mixtures, for this task. We prove a novel high probability bound on the ﬁnal SGD iterate without relying on a global gradient norm bound, and use it to show the advantages of model re-use. Additionally, we provide simple regret guarantees for our algorithm with respect to recovering the optimal mixture, given a total budget of SGD evaluations. Finally, we validate our algorithm on two real-world datasets. 1

Introduction
Suppose a predictive healthcare company has collected data from several regions of the world for a prediction task, and would like to deploy their model in a new region where only preliminary data has been collected. Obtaining more data before product deployment is prohibitively expensive, so they hope to leverage the data they have to deploy their product in this new region. The differences between the distributions from these different regions might arise due to shifts in the observed variables such as weight and height, but might also be caused by shifts in unobserved variables not considered or available during data collection, such as prevalence and expression of different conditions, genes, etc.
A natural idea, which allows exploiting the large amount of data from various regions, is to train models on several different mixture distributions over these datasets, and deploy the model that performs best when validated on the small validation data from the new region. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
In this paper, we study the problem of correcting for distribution shift using mixture search. Given large datasets from several sources for a common task, and a small validation (enough to validate, but not train a model), we show how to design an algorithm to utilize the large amount of data available for training to train a model performing well on the target distribution.
A notable challenge in our setting is that, in contrast to the typical covariate shift setting, the validation distribution could have shifted due to both observed and unobserved variables. As we discuss in
Section 4 and Remark 1 common techniques from the covariate shift and domain adaptation literature such as importance weighting [37] and moment matching [13] can fail when these shifts are due in part to shifts in unobserved variables. Hence, our goal is to design a method which is provably robust to such shifts and is also useful in practice.
Perhaps surprisingly, we show that searching over mixtures of training distributions provably recovers the optimal model for the validation dataset under mild conditions, even when training and validation distribution shift occurs in part due to shifts caused by latent variables (Proposition 1). Further, we show how to efﬁciently explore this mixture search space by leveraging models trained on near-by mixture distributions. The main contributions in this paper are as follows: (i) Search based methods for covariate shift: With latent/unobserved features, we show in Section 4 that traditional methods such as moment matching cannot learn the best mixture distribution (over input datasets) that optimizes performance with respect to a validation set. Instead, we show that searching over input mixture distributions using validation loss results in the recovery of the true model (with respect to the validation, Proposition 1). This motivates our tree search based approach. (ii) Mix&Match – Optimistic tree search over models: We propose Mix&Match – an algorithm that is built on SGD and a variant of optimistic tree-search (closely related to Monte Carlo Tree
Search). Given a budget (denoted as Λ) on the total number of online SGD iterations, Mix&Match adaptively allocates this budget to different population reweightings (mixture distributions over input datasets) through an iterative tree-search procedure (Section 5). Importantly, Mix&Match expends a majority of the SGD iteration budget on reweightings that are "close" to the optimal reweighting mixture by using two important ideas: (a) Parsimony in expending iterations: For a reweighting distribution that we have low conﬁdence of being “good,” Mix&Match expends only a small number of SGD iterations to train the model; doing so, however, results in biased and noisy evaluation of this model, due to early stopping in training. (b) Re-use of models: Rather than train a model from scratch, Mix&Match reuses and updates a partially trained model from past reweightings that are “close” to the currently chosen reweighting (effectively re-using SGD iterations from the past). (iii) SGD concentrations without global gradient bounds: The analysis of Mix&Match requires a new concentration bound on the error of the ﬁnal iterate of SGD. Instead of assuming a uniform bound on the norm of the stochastic gradient over the domain, as is typical in the stochastic optimization literature, we directly exploit properties of the averaged loss (strong convexity) and individual loss (smoothness) combined with a bound on the norm of the stochastic gradient at a single point to bound the norm of the stochastic gradient at each iterate. Using a single parameter (Λ, the budget allocated to Mix&Match), we are able to balance the worst-case growth of the norm of the stochastic gradient with the probability of failure of the SGD concentration. This new result (Theorem 5) provides tighter high-probability guarantees on the error of the ﬁnal SGD iterate in settings where the diameter of the domain is large and/or cannot be controlled. 2