Abstract
In this paper, we propose a new iterative hierarchical data augmentation (IHDA) method to ﬁne-tune trained deep neural networks to improve their generalization performance. The IHDA is motivated by three key insights: (1) Deep networks (DNs) are good at learning multi-level representations from data. (2) Performing data augmentation (DA) in the learned feature spaces of DNs can signiﬁcantly im-prove their performance. (3) Implementing DA in hard-to-learn regions of a feature space can effectively augment the dataset to improve generalization. Accordingly, the IHDA performs DA in a deep feature space, at level l, by transforming it into a distribution space and synthesizing new samples using the learned distributions for data points that lie in hard-to-classify regions, which is estimated by analyzing the neighborhood characteristics of each data point. The synthesized samples are used to ﬁne-tune the parameters of the subsequent layers. The same procedure is then repeated for the feature space at level l + 1. To avoid overﬁtting, the concept of dropout probability is employed, which is gradually relaxed as the IHDA works towards high-level feature spaces. IHDA provided a state-of-the-art performance on
CIFAR-10, CIFAR-100, and ImageNet for several DNs, and beat the performance of existing state-of-the-art DA approaches for the same networks on these datasets.
Finally, to demonstrate its domain-agnostic properties, we show the signiﬁcant improvements that IHDA provided for a deep neural network on a non-image wearable sensor-based activity recognition benchmark. 1

Introduction
Despite the tremendous success of deep neural networks in solving discriminative tasks, improving the generalization ability of these models remains as one of the most difﬁcult challenges. There exist several ways to solve this problem, such as dropout, batch normalization, pretraining, transfer learning, and data augmentation (DA) [1, 2, 3, 4, 5]. The goal of DA is to present the predictor with a more comprehensive set of data points, during training, to minimize the distance between the training and the test sets.
DA increases the size of the training data set, generally, in two ways. The ﬁrst approach expands the training data by performing expert-deﬁned content preserving transformations to existing data points [2]. In the case of images, such alterations may include image rotation, ﬂipping, random cropping, random erasing, and color space augmentation, etc. The second approach, on the other hand, inﬂates the training data through deep learning. These include feature space augmentation [6, 7, 8], adversarial training [9, 10], generative-adversarial-network based augmentation [11, 12, 13, 14], and meta-learning data augmentations (MLDA) [15, 16, 17, 18, 19]. MLDA employs prepended
∗Corresponding author. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
neural networks to learn data augmentations; the learned augmentation strategies may include mixing images, neural style transfer, and a series of geometric transformations. Recently, [20] proposed a new DA method which performs implicit semantic data augmentation (ISDA). The ISDA is different from other DA methods because it does not require training/inferring auxiliary networks or explicitly generating extra training samples. It achieves DA implicitly by minimizing a derived closed-form upper bound of the expected cross-entropy loss.
There are some valuable lessons to be learned from the existing works on DA, and on machine learning, in general. The ﬁrst is that DA is not as straightforward to apply in all domains as it is for images [8]. The second is that performing DA in the learned feature space instead of the input space can be beneﬁcial, especially for domain-independent DA [7, 8]. The third is that the success of deep networks can be attributed to their ability to exploit the unknown structure in the input distribution to discover useful features at multiple levels. In this multi-level representations, the higher-level learned features are deﬁned in terms of lower-level features [21]. Finally, the learning or classiﬁcation difﬁculty associated with different samples in the feature space could be different [22].
In this paper, based on the lessons that we mentioned above, we propose and implement an iterative hierarchical data augmentation (IHDA) algorithm for deep networks. In IHDA, we do augmentation in the feature space, but unlike [7] which generates new samples in the feature space using extrapolation and interpolation, we generate new samples by learning a generative model over the feature space.
Furthermore, unlike all existing works where the DA is performed once before or during the learning phase, we do it in the feature spaces of a learned model in an iterative manner, and use the augmented data to ﬁne tune the model’s parameters. More speciﬁcally, we start by training a deep network w.r.t a supervised loss on a given labeled training data without any augmented samples. Then, we generate augmented samples at each level of the representation learning part of the network and use them to ﬁne-tune the subsequent levels of the representation learning part (results in learning of new hierarchical representations) as well as the predictor part of the network. Another vital property of the algorithm is that instead of blindly or randomly generating new samples for augmentation, it identiﬁes regions that are hard to classify by assigning a potential value to each point in the learned feature space. Only the points having positive potential can act as sources for generating new data. Although it has a computationally expensive training phase, the proposed IHDA algorithm is signiﬁcantly effective. Extensive empirical evaluations on several competitive image and non-image classiﬁcation benchmarks showed that the IHDA consistently improved the generalization performance of popular deep networks and outperformed the existing state of the art DA algorithms for deep networks. 2