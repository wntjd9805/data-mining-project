Abstract
The brain takes uncertainty intrinsic to our world into account. For example, associating spatial locations with rewards requires to predict not only expected reward at new spatial locations but also its uncertainty to avoid catastrophic events and forage safely. A powerful and ﬂexible framework for nonlinear regression that takes uncertainty into account in a principled Bayesian manner is Gaussian process (GP) regression. Here I propose that the brain implements GP regression and present neural networks (NNs) for it. First layer neurons, e.g. hippocampal place cells, have tuning curves that correspond to evaluations of the GP kernel.
Output neurons explicitly and distinctively encode predictive mean and variance, as observed in orbitofrontal cortex (OFC) for the case of reward prediction. Because the weights of a NN implementing exact GP regression do not arise with biological plasticity rules, I present approximations to obtain local (anti-)Hebbian synaptic learning rules. The resulting neuronal network approximates the full GP well compared to popular sparse GP approximations and achieves comparable predictive performance. 1

Introduction
Predictive processing represents one of the fundamental principles of neural computations [1]. In the motor domain the brain employs predictive forward models [2], and a fundamental aspect of learned behavior is the ability to form associations between predictive environmental events and rewarding outcomes. These are just two examples of the general task of regression, to predict a dependent target variable given explanatory input variable(s), that the brain has to solve. The brain does not only predict point estimates but takes uncertainty into account, which led to coinage of the term “Bayesian brain” [3]. On the behavioral level, sensory and motor uncertainty have been shown to be integrated in a Bayesian optimal way [4]. There is also neurophysiological evidence, e.g. in the case of reward learning individual neurons in the orbitofrontal cortex (OFC) encode (average) value [5], while others explicitly encode the variance or ‘risk’ of the reward [6].
Above experimental ﬁndings lead to the corollary that the brain performs (non)linear regression while taking uncertainty into account. A principled framework to do so is a Gaussian process (GP) that has enjoyed prominent success in the machine learning community [7]. Furthermore, behavioral work in cognitive science suggests that people indeed use GPs for function learning [8, 9, 10]. In this paper I propose how the brain can implement (sparse) GP regression ((S)GPR).
Contributions While the correspondence between inﬁnitely wide Bayesian neural networks (NN) and GPs is well known [11], I show how the equations for the GP’s predictive mean and variance can be mapped onto a speciﬁc NN of ﬁnite size. Further training its weights using standard deep learning techniques, it outperforms Probabilistic Back-propagation [12] and Monte Carlo Dropout [13]. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
Although a network wiring exists that exactly implements (S)GPR, it does not arise with biologically plausible plasticity rules. I present approximations to obtain local (anti-)Hebbian [14, 15] synaptic learning rules that result in a neuronal network with comparable performance as the exact NN.
Biological evidence Tuning curves of my ﬁrst layer neurons correspond to the GP kernel evaluated at training or inducing points for full or sparse GPs respectively. Prominent examples of neural tuning curves resembling (RBF) kernels are orientation tuning in visual cortex [16], place cells in hippocampus [17], and tuning curves in primary motor cortex [18]. Output neurons, e.g. in OFC for predicting reward, explicitly and distinctively encode predictive mean [5] and variance [6] of the encoded function evaluated at the current input. Synaptic learning rules are local and rely on prediction and risk prediction errors respectively, both of which have strong neurophysiological evidence [19, 20]. All other (hyper) parameters, such as the tuning curve centers [21], can be optimized using REINFORCE gradient estimates [22], which avoids biologically implausible error back-propagation. Using REINFORCE for biologically plausible updates was discussed by [23].