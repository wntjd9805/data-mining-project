Abstract
A fundamental difﬁculty of causal learning is that causal models can generally not be fully identiﬁed based on observational data only. Interventional data, that is, data originating from different experimental environments, improves identiﬁability.
However, the improvement depends critically on the target and nature of the interventions carried out in each experiment. Since in real applications experiments tend to be costly, there is a need to perform the right interventions such that as few as possible are required. In this work we propose a new active learning (i.e. experiment selection) framework (A-ICP) based on Invariant Causal Prediction (ICP) [27].
For general structural causal models, we characterize the effect of interventions on so-called stable sets, a notion introduced by [30]. We leverage these results to propose several intervention selection policies for A-ICP which quickly reveal the direct causes of a response variable in the causal graph while maintaining the error control inherent in ICP. Empirically, we analyze the performance of the proposed policies in both population and ﬁnite-regime experiments. 1

Introduction
Causal models [24] capture the causal relationships between variables and allow us to predict how a system behaves under interventions or distribution changes. Hence, they are more powerful than probabilistic models, and can be seen as abstractions of more accurate mechanistic or physical models while retaining enough power to answer interventional or counterfactual questions [28]. Therefore, they maintain their predictive power in new, previously unseen environments [13, 35, 31, 30].
The question remains if for systems of interest such models can be learned directly from data. This problem is known in the literature as causal learning, and it is to causal models what statistical learning is to probabilistic models. Just like statistical learning, it suffers from the inherent difﬁculty of determining properties of a distribution from ﬁnite-sized samples. Additionally, causal learning is challenged by the fact that, even with full knowledge of the underlying observational distribution, some causal relationships cannot be established and causal models can generally not be fully identiﬁed from observational data alone [24]. For causal directed acyclic graph models, this limit of identiﬁabil-ity implies that, from observational data alone, the true graph cannot be distinguished from others that lie in the same Markov equivalence class [38]. Under additional assumptions about the model class and noise distributions, full identiﬁability is still possible [15, 3, 34, 25, 26]. In the general case, however, identiﬁability can only be improved by performing interventions (experiments). Examples of such interventions are abundant in the empirical sciences, from gene knockout experiments in biology to chemical compound selection in drug discovery [22]. Since such experiments tend to be costly, there is a need to pick the right interventions, in the sense of having to do as few of them as 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
possible. In the remainder of this section, we review existing work that addresses this problem before summarizing our contributions. 1.1