Abstract
Homomorphic Encryption (HE) based secure Neural Networks(NNs) inference is one of the most promising security solutions to emerging Machine Learning as a
Service (MLaaS). In the HE-based MLaaS setting, a client encrypts the sensitive data, and uploads the encrypted data to the server that directly processes the encrypted data without decryption, and returns the encrypted result to the client.
The client’S data privacy is preserved since only the client has the private key.
Existing HE-enabled Neural Networks (HENNs), however, suffer from heavy computational overheads. The state-of-the-art HENNs adopt ciphertext packing techniques to reduce homomorphic multiplications by packing multiple messages into one single ciphertext. Nevertheless, rotations are required in these HENNs to implement the sum of the elements within the same ciphertext. We observed that HENNs have to pay signiﬁcant computing overhead on rotations, and each of rotations is ∼ 10× more expensive than homomorphic multiplications between ciphertext and plaintext. So the massive rotations have become a primary obstacle of efﬁcient HENNs.
In this paper, we propose a fast, frequency-domain deep neural network called
Falcon, for fast inferences on encrypted data. Falcon includes a fast Homomor-phic Discrete Fourier Transform (HDFT) using block-circulant matrices to ho-momorphically support spectral operations. We also propose several efﬁcient methods to reduce inference latency, including Homomorphic Spectral Convolu-tion and Homomorphic Spectral Fully Connected operations by combining the batched HE and block-circulant matrices. Our experimental results show Falcon achieves the state-of-the-art inference accuracy and reduces the inference latency by 45.45% ∼ 85.34% over prior HENNs on MNIST and CIFAR-10. 1

Introduction
Homomorphic Encryption (HE)-enabled neural networks (NNs) [1, 2, 3] are designed for secure
Machine Learning as a Service (MLaaS). In HE-enabled MLaaS, a client encrypts his/her data and uploads the encrypted data to a server in the cloud. The server computes inferences on the encrypted data and returns the encrypted output to the client. The server cannot decrypt the encrypted input or output during an inference. However, HE naturally supports only linear layers of a neural network.
Some interactive HE-enabled NNs (HENNs) [4, 5, 6] take advantage of multi-party computation (MPC) to get the client involved in the computation of activation layers by exchanging several gigabyte data with the client during an inference, while other non-interactive HENNs [1, 2, 3] approximate activations by a square function to perform secure inferences without involving the 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
client. A non-interactive HE-enabled NN is a practical MLaaS solution with competitive accuracy for particular clients who have limited computing power and small network bandwidth.
However, both interactive and non-interactive HE-enabled inferences are slow. An inference of state-of-the-art HENNs [5, 3] on an encrypted CIFAR-10 image costs several hundred seconds. Their long inference latency is caused by expensive HE rotations. Modern HE cryptosystems, e.g., BFV [7], pack a vector consisting of small integers into a single large integer, so that they can allow concurrent
HE arithmetic operations to happen on individual integers by performing a single operation on the large integer. The single instruction multiple data (SIMD) computing style of HE signiﬁcantly reduces inference latency of HENNs from multiple hours to several hundred seconds. However, each accumulation in linear layers of a HE-enabled NN requires a rotation operation to shufﬂe small integers packed into a large integer. As a result, rotations consume > 90% of inference latency of a
HE-enabled NN on an encrypted CIFAR-10 image.
Recent interactive HENNs [4, 8] use frequency-domain convolutions [9, 10] to perform only element-wise multiplications in their linear layers to eliminate expensive HE rotations. A plaintext image of a client is ﬁrst converted to its frequency-domain representation by discrete Fourier transform (DFT), encrypted to a ciphertext, and then sent to a cloud server. Instead of HE multiply-accumulate (MAC) operations, only HE element-wise multiplications are required to perform frequency-domain convolutions on the server. After receiving the encrypted frequency-domain linear layer output, the client decrypts it and converts the plaintext frequency-domain output to a normal linear layer output by inverse DFT (IDFT). At last, the client performs activations on the normal linear layer output, and then moves to the next layer. The frequency-domain convolutions greatly reduce inference latency of interactive HENNs by 30% ∼ 40%.
However, naïvely using frequency-domain convolutions in non-interactive HENNs prolongs inference latency. Each HE operation introduces a certain amount of noise into the encrypted data. When the accumulated noise in the encrypted data is larger than the noise budget of a HENN, the encrypted data cannot be correctly decrypted. Therefore, the total number of HE operations along the critical path of a HENN decides the noise budget. A larger noise budget increases the latency of each HE operation. In interactive HENNs, the server sends the output to the client at the end of each linear layer. The client has to participate the computation of each activation layer. The client performs
DFT and IDFT on plaintext data, and thus does not increase the number of HE operations at all.
On the contrary, non-interactive HENNs homomorphically compute all linear and activation layers on the server without involving client. DFT and IDFT applied in non-interactive HENNs happen on the encrypted data, and thus should be homomorphic. Homomorphic DFT and IDFT greatly increase the noise budget of a non-interactive HENN by adding more HE operations to its critical path. Based on our estimation, the enlarged noise budget signiﬁcantly prolongs inference latency of a frequency-domain non-interactive HENN by > 100%.
In this paper, we propose Falcon for fast non-interactive privacy-preserving inference. Our contribu-tions can be summarized as follows.
• We propose a novel HE DFT algorithm to homomorphically and efﬁciently convert an encrypted input to its encrypted frequency-domain representation.
• We propose a fast HE-enable convolution technique and a fully-connected technique on spectral domain using block circulant weight matrices.
• We consider the improvements and overhead of proposed techniques on both HE noise growth and HE parameters selection. Our experiments prove that Falcon reduces the inference latency by 45.45% ∼ 85.34% over prior HENNs on MNIST and CIFAR-10.
Figure 1: Different HENNs schemes.
Figure 2: A homomorphic dot-product. 2
2