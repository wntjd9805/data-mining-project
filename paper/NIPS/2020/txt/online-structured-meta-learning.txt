Abstract
Learning quickly is of great importance for machine intelligence deployed in online platforms. With the capability of transferring knowledge from learned tasks, meta-learning has shown its effectiveness in online scenarios by continuously updating the model with the learned prior. However, current online meta-learning algorithms are limited to learn a globally-shared meta-learner, which may lead to sub-optimal results when the tasks contain heterogeneous information that are distinct by nature and difﬁcult to share. We overcome this limitation by proposing an online structured meta-learning (OSML) framework. Inspired by the knowledge organization of human and hierarchical feature representation, OSML explicitly disentangles the meta-learner as a meta-hierarchical graph with different knowledge blocks. When a new task is encountered, it constructs a meta-knowledge pathway by either utilizing the most relevant knowledge blocks or exploring new blocks.
Through the meta-knowledge pathway, the model is able to quickly adapt to the new task. In addition, new knowledge is further incorporated into the selected blocks.
Experiments on three datasets demonstrate the effectiveness and interpretability of our proposed framework in the context of both homogeneous and heterogeneous tasks. 1

Introduction
Meta-learning has shown its effectiveness in adapting to new tasks with transferring the prior experience learned from other related tasks [7, 34, 38]. At a high level, the meta-learning process involves two steps: meta-training and meta-testing. During the meta-training time, meta-learning aims to obtain a generalized meta-learner by learning from a large number of past tasks. The meta-learner is then applied to adapt to newly encountered tasks during the meta-testing time. Despite the early success of meta-learning on various applications (e.g., computer vision [7, 40], natural language processing [14, 36]), almost all traditional meta-learning algorithms make the assumption that tasks are sampled from the same stationary distribution. However, in human learning, a promising characteristic is the ability to continuously learn and enhance the learning capacity from different tasks.
To equip agents with such capability, recently, Finn et al. [10] presented the online meta-learning framework by connecting meta-learning and online learning. Under this setting, the meta-learner not only beneﬁts the learning process from the current task but also continuously updates itself with accumulated new knowledge.
Although online meta-learning has shown preliminary success in handling non-stationary task distri-bution, the globally shared meta-learner across all tasks is far from achieving satisfactory performance when tasks are sampled from complex heterogeneous distribution. For example, if the task distri-bution is heterogeneous with disjoint modes, a globally shared meta-learner is not able to cover the information from all modes. Under the stationary task distribution, a few studies attempt to
∗Part of the work was done while the author interned at Salesforce Research 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
address this problem by modulating the globally shared meta-learner with task-speciﬁc informa-tion [27, 41, 42, 39]. However, the modulating mechanism relies on a well-trained task representation network, which makes it impractical under the online meta-learning scenario. A recent study by [15] applied Dirichlet process mixture of hierarchical Bayesian model on tasks. However, this study requires the construction of a totally new meta-learner for the dissimilar task, which limits the
ﬂexibility of knowledge sharing.
To address the above challenges, we propose a meta-learning method with a structured meta-learner, which is inspired by both knowledge organization in human brain and hierarchical representations.
When human learn a new skill, relevant historical knowledge will facilitate the learning process.
The historical knowledge, which is potentially hierarchically organized and related, is selectively integrated based on the relevance to the new task. After mastering a new task, the knowledge representation evolves continuously with the new knowledge. Similarly, in meta-learning, we aim to construct a well-organized meta-learner that can 1) beneﬁt fast adaptation in the current task with task-speciﬁc structured prior; 2) accumulate and organize the newly learned experience; and 3) automatically adapt and expand for unseen structured knowledge.
We propose a novel online structured meta-learning (OSML) framework. Speciﬁcally, OSML disentangles the whole meta-learner as a meta-hierarchical graph with multiple structured knowledge blocks, where each block represents one type of structured knowledge (e.g., a similar background of image tasks). When a new task arrives, it automatically seeks for the most relevant knowledge blocks and constructs a meta-knowledge pathway in this meta-hierarchical graph. It can further create new blocks when the task distribution is remote. Compared with adding a full new meta-learner (e.g., [15]) in online meta-learning, the block-level design provides 1) more ﬂexibility for knowledge exploration and exploitation; 2) reduces the model size; and 3) improves the generalization ability.
After solving the current task, the selected blocks are enhanced by integrating with new information from the task. As a result, the model is capable of handling non-stationary task distribution with potentially complex heterogeneous tasks.
To sum up, our major contributions are three-fold: 1) we formulate the problem of online meta-learning under heterogeneous distribution setting and propose a novel online meta-learning framework by maintaining meta-hierarchical graph; 2) we demonstrate the effectiveness of the proposed method empirically through comprehensive experiments; 3) the constructed meta-hierarchical tree captures the structured information in online meta-learning, which enhances the model interpretability. 2 Notations and Problem Settings i i with N supp i with N query i samples (i.e., Dsupp samples (i.e., Dquery
= {(xi,1, yi,1), . . . , (xi,N supp
= {(xi,1, yi,1), . . . , (xi,N query
Few-shot Learning and Meta-learning.
In few-shot learning, a task Ti is comprised of a support set Dsupp
)}) and a query i set Dquery
)}), where the i support set only includes a few samples. Given a predictive model f with parameter w, the task-speciﬁc parameter wi is trained by minimizing the empirical loss L(w, Dsupp
) on support set Dsupp
.
Here, the loss function is typically deﬁned as mean square loss or cross-entropy for regression and classiﬁcation problems, respectively. The trained model fwi is further evaluated on query set
Dquery is extremely small, it cannot optimize w with a satisfactory i performance on Dquery
. To further improve the task-speciﬁc performance within limited samples, a natural solution lies in distilling more information from multiple related tasks. Building a model upon these related tasks, meta-learning are capable of enhancing the performance in few-shot learning.
. However, when the size of Dsupp
, yi,N supp
, yi,N query i i i i i i i i
By training from multiple related tasks, meta-learning generalizes an effective learning strategy to beneﬁt the learning efﬁciency of new tasks. There are two major steps in meta-learning: meta-training and meta-testing. Taking model-agnostic meta-learning (MAML) [8] as an example, at meta-training time, it aims to learn a well-generalized initial model parameter w∗ 0 over T available meta-training tasks {Ti}T i=1. In more detail, for each task Ti, MAML performs one or few gradient steps to infer task-speciﬁc parameter wi by using support set Dsupp
)). Then, the query set Dquery are used to update the initial parameter w0. Formally, the bi-level optimization process can be formulated as: (i.e., wi = w0 − αL(w, Dsupp i i i w∗ 0 ← arg min w0
T (cid:88) i=1
L(w0 − αL(w, Dsupp i
), Dquery i
). (1) 2
In practice, the inner update can perform several gradient steps. At meta-testing time, for the new 0 on support set Dsupp task Tnew, the optimal task parameter wnew can be reached by ﬁnetuning w∗ new .
Online Meta-learning. A strong assumption in the meta-learning setting is that all task follows the same stationary distribution. In online meta-learning, instead, the agents observe new tasks and update meta-learner (e.g., model initial parameter) sequentially. It then tries to optimize the performance of the current task. Let w0,t denote the learned model initial parameter after having task Tt and wt represent the task-speciﬁc parameter. Following FTML (follow the meta leader) algorithm [10], the online meta-learning process can be formulated as: w0,t+1 = arg min w t (cid:88) i=1
Li(wi, Dquery i
) = arg min w t (cid:88) i=1
Li(w − α∇(w, Dsupp i
), Dquery i
), (2) i and Dquery i t=1 represent a sequence of loss functions for task {Tt}∞ where {Lt}∞ t=1. In the online meta-learning setting, both Dsupp can be represented as different sample batches for task Ti. For brevity, we denote the inner update process as M(w, Dsupp
). After obtaining the best initial parameter w0,t+1, similar to the classical meta-learning process, the task-speciﬁc parameter wt+1 is optimized by performing several gradient updates on support set Dsupp t+1 . Based on the meta-learner update paradigm in equation (2), the goal for FTML is to minimize the regret, which is formulated as
) = w − α∇(w, Dsupp i i
RegretT =
T (cid:88) i=1
Li(Mi(w0,i)) − min w
T (cid:88) i=1
Li(Mi(w)). (3)
By achieving the sublinear regret, the agent is able to continuously optimize performance for sequential tasks with the best meta-learner. 3 Online Structured Meta-learning
In this section, we describe the proposed OSML algorithm that sequentially learns tasks from a non-stationary and potentially heterogeneous task distribution. Figure 1 illustrates the pipeline of task learning in OSML. Here, we treat a meta-learner as a meta-hierarchical graph, which consists of multiple knowledge blocks. Each knowledge block represents a speciﬁc type of meta-knowledge and is able to connect with blocks in the next level. To facilitate the learning of a new task, a
“search-update" mechanism is proposed. For each task, a “search" operation is ﬁrst performed to create meta-knowledge pathways. An “update" operation is then performed for the meta-hierarchical graph. For each task, this mechanism forms a pathway that links the most relevant neural knowledge block of each level in the meta-hierarchical structure. Simultaneously, novel knowledge blocks may also be spawned automatically for easier incorporation of unseen (heterogeneous) information. These selected knowledge blocks are capable of quick adaptation for the task at hand. Through the created meta-knowledge pathway, the initial parameters of knowledge blocks will be then iteratively updated by incorporating the new information. In the rest of this section, we will introduce the two key components: meta-knowledge pathway construction and knowledge-block update. 3.1 Meta-knowledge Pathway Construction
The key idea of meta-knowledge pathway construction is to automatically identify the most relevant knowledge blocks from the meta-hierarchy. When the task distribution is non-stationary, the current task may contain distinct information, which will increase the likelihood of triggering the use of novel knowledge blocks. Because of this, a meta-knowledge pathway construction mechanism should be capable of automatically exploring and utilizing knowledge blocks depending on the task distribution.
We elaborate the detailed pathway construction process in the following paragraphs.
At time step t, we denote the meta-hierarchy with initial parameter w0,t as Rt, which has L layers with Bl knowledge blocks in each layer l. Let {w0bl,t}Bl bl=1 denote the initial parameters in knowledge blocks of layer l. To build the meta-knowledge pathway, we search the most relevant knowledge block for each layer l. An additional novel block is further introduced in the search process for new knowledge exploration. Similar to [21], we further relax the categorical search process to a differentiable manner to improve the efﬁciency of knowledge block searching. For each layer l with the input representation gl−1,t, the relaxed forward process in meta-hierarchical graph Rt is 3
Figure 1: Illustration of OSML. The meta-hierarchical graph is comprised of several knowledge blocks in each layer. Different colors represent different meta-knowledge. Orange blocks denote the input and output. Given a new task Tt, it automatically searches for the most relevant knowledge block and constructs the meta-knowledge pathway (i.e., blue line). Simultaneously, the task is encouraged to explore novel meta-knowledge blocks during the search process (i.e., the red dashed block). After building the meta-knowledge pathway, the new task is used to update its corresponding meta-knowledge blocks. The meta-updated knowledge blocks are ﬁnally used for ﬁne-tuning and evaluation on Tt. formulated as: gl,t =
Bl+1 (cid:88) bl=1 exp(obl ) (cid:80)Bl+1 (cid:48) l =1 b exp(ob
) (cid:48) l
Mt(w0bl,t)(gl−1,t), (4) where Mt(w0bl,t) = w0bl,t − α∇w0bl ,t L(w0,t, Dsupp t
), b1=1, . . . , {obL }BL where o = {{ob1 }B1 bL=1} are used to denote the importance of different knowledge blocks in layer l. The above equation (4) indicates that the inner update in the knowledge block searching process, where all existing knowledge blocks and the novel blocks are involved. After inner update, we obtain the task speciﬁc parameter wt, which is further used to meta-update the initial parameters w0,t in the meta-hierarchical structure and the importance coefﬁcient o. The meta-update procedure is formulated as: w0,t ← w0,t − β1∇w0,t L(wt, o; Dquery o ← o − β2∇oL(wt, o; Dquery
), t t
), (5) where β1 and β2 represent the learning rates at the meta-updating time. Since the coefﬁcient o suggests the importance of different knowledge blocks, we ﬁnally select the task-speciﬁc knowledge block in layer l as b∗ l = arg maxbl∈[1,Bl] obl . After selecting the most relevant knowledge blocks, the
L,t} is generated by connecting these blocks layer by layer. meta-knowledge pathway {w0b∗ 1 ,t, . . . , w0b∗ 3.2 Knowledge Block Meta-Updating
In this section, we discuss how to incorporate the new task information with the best path of functional regions. Following [10], we adopt a task buffer B to memorize the previous tasks. When a new task arrives, it is automatically added in the task buffer. After constructing the meta-knowledge pathway, the shared knowledge blocks are updated with the new information. Since different tasks may share knowledge blocks, we iteratively optimize the parameters of the knowledge blocks from low-level to high-level. In practice, to optimize the knowledge block bl in layer l, it is time-consuming to apply second-order meta-optimization process on w0bl,t. Instead, we apply ﬁrst-order approximation to avoid calculating the second-order gradients on the query set. Formally, the ﬁrst order approximation for knowledge block b∗ l in layer l is formulated as: w0b∗ l ,t ← w0b∗ l ,t − β3
K (cid:88) k=1
∇wbl ,k L(wk; Dquery k
), (6) where wt = w0,t − β4∇wL(w; Dsupp k
).
By applying the ﬁrst-order approximation, we are able to save update time while maintaining comparable performance. After updating the selected knowledge blocks, we ﬁne-tune the enhanced meta-knowledge pathway {w0b∗
L,t} on the new task Tt by using both support and query sets as follows: 1 ,t, . . . , w0b∗ wb∗ 1 ,t = w0b∗ l ,t − β5∇wL(w; Dsupp t
⊕ Dquery t
). (7) 4
from Tt to search the functional regions {w0b∗ 1 ,t . . . w0b∗
L,t} by (4) and (5)
Algorithm 1 Online Meta-learning Pipeline of OSML t for l = 1 . . . L do
, Dquery t and Dquery t
Add B ← B + [Tt]
Sample Dsupp t
Use Dsupp for nm = 1 . . . Nmeta steps do
Require: β1, β2, β3,β4, β5: learning rates 1: Initialize Θ and the task buffer as empty, B ← [] 2: for each task Tt in task sequence do 3: 4: 5: 6: 7: 8: 9: 10: 11: 12: 13: 14: 15: 16: end for end for
Concatenate Dsupp and Dquery t
Use Dall to ﬁnetune {w0b∗ 1 ,t . . . w0b∗
Evaluate the performance on Dtest t
Sample task Tk that also use w0b∗
Sample minibatches Dsupp
Use Dsupp and Dquery k end for k t t l ,t from buffer B and Dquery k from Tk k to update the knowledge block w0b∗ l ,t by (6) t = Dsupp as Dall
L,t} t
⊕ Dquery t
The generalization performance of task Tt are further evaluated in a held-out dataset Dtest procedure are outlined in Algorithm 1. t
. The whole 4 Experiments
In this section, we conduct experiments on both homogeneous and heterogeneous datasets to show the effectiveness of the proposed OSML. The goal is to answer the following questions:
• How does OSML perform (accuracy and efﬁciency) compared with other baselines in both homogeneous and heterogeneous datasets?
• Can the knowledge blocks explicitly capture the (dis-)similarity between tasks?
• What are causing the better performance of OSML: knowledge organization or model capacity?
The following algorithms are adopted as baselines, including (1) Non-transfer (NT), which only uses support set of task Tt to train the base learner; (2) Fine-tune (FT), which continuously ﬁne-tunes the base model without task-speciﬁc adaptation. Here, only one knowledge block each layer is involved and ﬁne-tuned for each task and no meta-knowledge pathway is getting constructed; (3)
FTML [10] that incorporates MAML into online learning framework, where the meta-learner is shared across tasks; (4) DPM [15], which uses the Dirichlet process mixture to model task changing; (5) HSML [41], which customizing model initializations by involving hierarchical clustering structure.
However, the continual adaptation setting in original HSML is evaluated under the stationary scenario.
Thus, to make comparison we evaluate HSML under our setting by introducing task-awared parameter customization and hierarchical clustering structure. 4.1 Homogeneous Task Distribution
Dataset Description. We ﬁrst investigate the performance of OSML when the tasks are sampled from a single task distribution. Here, we follow [10] and create a Rainbow MNIST dataset, which contains a sequence of tasks generated from the original MNIST dataset. Speciﬁcally, we change the color (7 colors), scale (2 scales), and angle (4 angles) of the original MNIST dataset. Each combination of image transformation is considered as one task and thus a total of 56 tasks are generated in the Rainbow MNIST dataset. Each task contains 900 training samples and 100 testing samples. We adopt the classical four-block convolutional network as the base model. Additional information about experiment settings are provided in Appendix A.1.
Results and Analysis. The results of Rainbow MNIST shown in Figure 2. It can be observed that our proposed OSML consistently outperforms other baselines, including FTML, which shares the meta-learner across all tasks. Additionally, after updating the last task, we observe that the number of 5
knowledge blocks for layer 1-4 in the meta-hierarchical graph is 1, 1, 2, 2, respectively. This indicates that most tasks share the same knowledge blocks, in particular, at the lower levels. This shows that our method does learn to exploit shared information when the tasks are more homogeneous and thus share more knowledge structure. This also suggests that our superior performance is not because of increased model size, but rather better utilization of the shared structure.
Metric
NT
FT
FTML [10]
DPM [15]
HSML [41]
OSML
Acc.
AR 85.09 ± 1.07% 87.71 ± 0.97% 91.41 ± 5.15% 90.80 ± 5.38% 90.36 ± 4.60% 92.65 ± 4.44% 5.63 4.64 2.67 3.14 3.41 1.50
Figure 2: Rainbow MNIST results. Top: Accuracy over all tasks; Bottom: Performance statistics.
Here, Average Ranking (AR) is calculated by ﬁrst rank all methods for each dataset, from higher to lower. Each method receive a score corresponds to its rank, e.g. rank one receives one point. The scores for each method are then averaged to form the reported AR. Lower AR is better. 4.2 Heterogeneous Task Distribution
Datasets Descriptions. To further verify the effectiveness of OSML when the tasks contain po-tentially heterogeneous information, we created two datasets. The ﬁrst dataset is generated from mini-Imagenet. Here, a set of artistic ﬁlters – "blur", "night" and "pencil" ﬁlter are used to pro-cess the original dataset [15]. As a result, three ﬁltered mini-Imagenet sub-datasets are obtained, namely, blur-, night- and pencil-mini-Imagenet. We name the constructed dataset as multi-ﬁltered mini-Imagenet. We create the second dataset called Meta-dataset by following [37, 41]. This dataset includes three ﬁne-grained sub-datasets: Flower, Fungi, and Aircraft. Detailed descriptions of hetero-geneous datasets construction are discussed in Appendix A.2. For each sub-dataset in multi-ﬁltered miniImagenet or Meta-dataset, it contains 100 classes. We then randomly split 100 classes to 20 non-overlapped 5-way tasks. Thus, both datasets include 60 tasks in total and we shufﬂe all tasks for online meta-learning. Similar to Rainbow MNIST, the four-block convolutional layers are used as the base model for each task. Note that, for Meta-dataset with several more challenging ﬁne-grained datasets, the initial parameter values of both baselines and OSML are set from a model pre-trained from the original mini-Imagenet. We report hyperparameters and model structures in Appendix A.2.
Results. For multi-ﬁltered miniImagenet and Meta-dataset, we report the performance in Figure 3 and Figure 4, respectively. We show the performance over all tasks in the top ﬁgure and summarize the performance in the bottom table. First, all online meta-learning methods (i.e., FTML, DPM,
HSML, OSML) achieves better performance than the non-meta-learning ones (i.e., NT, FT), which further demonstrate the effectiveness of task-speciﬁc adaptation. Note that, NT outperforms FT in
Meta-dataset. The reason is that the pre-trained network from mini-Imagnent is loaded in Meta-dataset as initial model, continuously updating the structure (i.e., FT) is likely to stuck in a speciﬁc local optimum (e.g., FT achieves satisfactory results in Aircraft while fails in other sub-datasets).
In addition, we also observe that task-speciﬁc online meta-learning methods (i.e., OSML, DPM, and HSML) achieve better performance than FTML. This is further supported by the summarized performance of Meta-dataset (see the bottom table of Figure 4), where FTML achieved relatively better performance in Aircraft compared with Fungi and Flower. This suggests that the shared meta-learner is possibly attracted into a speciﬁc mode/region and is not able to make use of the information from all tasks. Besides, OSML outperforms DPM and HSML in both datasets, indicating that the meta-hierarchical structure not only effectively capture heterogeneous task-speciﬁc information, but also encourage more ﬂexible knowledge sharing. 6
Models
Blur Acc.
Night Acc.
Pencil Acc.
Overall Acc.
AR
NT
FT 49.80 ± 3.91% 47.70 ± 2.91% 47.55 ± 5.18% 48.35 ± 2.39% 5.48 51.50 ± 4.90% 49.00 ± 3.82% 50.90 ± 5.30% 50.47 ± 2.73% 4.87
FTML [10]
DPM [15]
HSML [41] 58.90 ± 3.52% 56.40 ± 3.53% 54.60 ± 5.46% 56.63 ± 2.50% 3.50 62.35 ± 2.95% 56.80 ± 4.28% 56.20 ± 4.70% 58.45 ± 2.44% 2.85 62.42 ± 3.80% 57.57 ± 2.78% 57.88 ± 5.00% 59.25 ± 2.36% 2.63
OSML 64.10 ± 3.12% 65.25 ± 3.24% 60.35 ± 3.65% 63.23 ± 2.00% 1.67
Figure 3: Multi-ﬁltered miniImagenet results. Top : classiﬁcation accuracy of all tasks. Bottom : the statistics of accuracy with 95% conﬁdence interval and average ranking (AR) for each sub-dataset
Models
Aircraft Acc.
Flower Acc.
Fungi Acc.
Overall Acc.
AR
NT
FT 59.40 ± 3.97% 60.15 ± 5.23% 46.15 ± 3.57% 55.23 ± 2.98% 4.75 66.45 ± 3.80% 52.20 ± 4.55% 42.90 ± 3.45% 53.85 ± 3.35% 4.47
FTML [10]
DPM [15]
HSML [41] 65.85 ± 3.85% 59.05 ± 4.83% 48.00 ± 2.78% 57.63 ± 2.93% 3.92 66.67 ± 4.07% 63.40 ± 4.89% 50.15 ± 3.53% 60.07 ± 3.02% 3.15 65.86 ± 3.13% 63.12 ± 3.88% 55.65 ± 3.11% 61.54 ± 2.22% 2.85
OSML 67.99 ± 3.52% 68.55 ± 4.59% 58.45 ± 2.89% 65.00 ± 2.46% 1.87
Figure 4: Meta-dataset Results. Top: performace of online meta-learning tasks. Bottom: performance statistics on each sub-dataset.
Analysis of Constructed Meta-pathway and Knowledge Blocks. In Figure 5, we analyze the selected knowledge blocks of all tasks after the online meta-learning process. Here, for each knowledge block, we compute the selected ratio of every sub-dataset in Meta-dataset (see Appendix
B for results and analysis in Multi-ﬁltered mini-Imagenet). For example, if the knowledge block 1 in layer 1 is selected 3 times by tasks from Aircraft and 2 times from Fungi. The corresponding ratios of Aircraft and Fungi are 60% and 40%, respectively. From these ﬁgures, we see that some knowledge blocks are dominated by different sub-datasets whereas others have shared across different tasks. This indicates that OSML is capable of automatically detecting distinct tasks and their feature representations, which also demonstrate the interpretability of OSML. We also observe that tasks from fungi and ﬂower are more likely to share blocks (e.g., block 7 in layer 1). The potential reason is that tasks from fungi and ﬂower sharing similar background and shapes, and therefore have higher probability of sharing similar representations. 7
(a) : Layer 1 (b) : Layer 2 (c) : Layer 3 (d) : Layer 4
Figure 5: Selected ratio of knowledge blocks for each sub-dataset in Meta-dataset. Figure (a)-(d) illustrate the knowledge blocks in layer 1-4.
Effect of Model Capacity. Though the model capacity of OSML is the same as all baselines during task training time (i.e., a network with four convolutional blocks), OSML maintains a larger network to select the most relevant meta-knowledge pathway. To further investigate the reason for improvements, we increase the numbers blocks in NT, FT, and FTML to the number of blocks in the meta-hierarchical graph after passing all tasks. We did not include DPM and HSML since they already have more parameters than OSML. These baselines with larger representation capacity are named as NT-Large, FT-Large, and FTML-Large. We compare and report the summary of performance in Table 6 (see the results of Meta-dataset in Appendix C). First, we observe that increasing the number of blocks in NT worsens the performance, suggesting the overﬁtting issue. In FT and
FTML, increasing the model capacity does not achieve signiﬁcant improvements, indicating that the improvements do not stem from larger model capacity. Thus, OSML is capable of detecting heterogeneous knowledge by automatically selecting the most relevant knowledge blocks.
Models
NT
NT-Large
FT
FT-Large
Blur Acc.
Night Acc.
Pencil Acc.
Overall Acc.
AR 49.80 ± 3.91% 47.70 ± 2.91% 47.55 ± 5.18% 53.32 ± 2.30% 43.05 ± 3.99% 41.30 ± 2.66% 43.25 ± 4.24% 42.53 ± 2.15% 3.92
-51.50 ± 4.90% 49.00 ± 3.82% 50.90 ± 5.30% 50.47 ± 2.73% 54.60 ± 2.99% 50.35 ± 2.64% 52.45 ± 3.92% 52.46 ± 1.91% 2.82
-FTML
FTML-Large 58.90 ± 3.52% 56.40 ± 3.53% 54.60 ± 5.46% 56.63 ± 2.50% 57.55 ± 3.76% 56.70 ± 3.92% 56.30 ± 4.05% 56.85 ± 2.26% 2.13
-OSML 64.10 ± 3.12% 65.25 ± 3.24% 60.35 ± 3.65% 63.23 ± 2.00% 1.13
Figure 6: Comparison between OSML with baselines with increased model capacity. We list orignial
NT, FT, FTML are listed for comparison without providing AR.
Learning Efﬁciency Analysis. In heterogeneous datasets, the performances ﬂuctuate across different tasks due to the non-overlapped classes. Similar to [10], the learning efﬁciency is evaluated by the number of samples in each task. We conduct the learning efﬁciency analysis by varying the training samples and report the performance in Table 1. Here, two baselines (FTML and DPM) are selected for comparison. In this table, we observe that OSML is able to consistently improve the performance under different settings. The potential reason is that selecting meaningful meta-knowledge pathway captures the heterogeneous task information and further improve the learning efﬁciency. For the homogeneous data, we analyze the amount of data needed to learn each task in Appendix D and the results indicate that the ability of OSML to efﬁciently learn new tasks. 8
Table 1: Performance w.r.t. the number of samples per task on Meta-dataset.
# of Samples Models
Aircraft Acc.
Flower Acc.
Fungi Acc.
Overall Acc. 200 300 400
FTML
DPM
OSML
FTML
DPM
OSML
FTML
DPM
OSML 55.92 ± 3.13% 54.65 ± 4.52% 45.69 ± 2.97% 52.08 ± 2.51% 57.15 ± 3.29% 53.34 ± 5.38% 44.33 ± 2.77% 51.60 ± 2.79% 60.18 ± 2.89% 58.28 ± 4.80% 48.25 ± 3.02% 55.57 ± 2.59% 62.88 ± 3.10% 58.37 ± 5.02% 47.96 ± 2.49% 56.40 ± 2.59% 64.43 ± 3.26% 59.72 ± 5.37% 48.10 ± 2.60% 57.42 ± 2.83% 66.57 ± 3.27% 65.07 ± 4.38% 53.72 ± 2.81% 61.78 ± 2.63% 65.85 ± 3.85% 59.05 ± 4.83% 48.00 ± 2.78% 57.63 ± 2.93% 66.67 ± 4.07% 63.40 ± 4.89% 50.15 ± 3.53% 60.07 ± 3.02% 67.99 ± 3.52% 68.55 ± 4.59% 58.45 ± 2.89% 65.00 ± 2.46% 5 Discussion with