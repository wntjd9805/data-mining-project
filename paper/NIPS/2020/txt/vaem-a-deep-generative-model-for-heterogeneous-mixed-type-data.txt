Abstract
Deep generative models often perform poorly in real-world applications due to the heterogeneity of natural data sets. Heterogeneity arises from data containing different types of features (categorical, ordinal, continuous, etc.) and features of the same type having different marginal distributions. We propose an extension of variational autoencoders (VAEs) called VAEM to handle such heterogeneous data. VAEM is a deep generative model that is trained in a two stage manner such that the ﬁrst stage provides a more uniform representation of the data to the second stage, thereby sidestepping the problems caused by heterogeneous data. We provide extensions of VAEM to handle partially observed data, and demonstrate its performance in data generation, missing data prediction and sequential feature selection tasks. Our results show that VAEM broadens the range of real-world applications where deep generative models can be successfully deployed. 1

Introduction
Variational Autoencoders (VAEs) [15] are highly ﬂexible probabilistic models, making them promis-ing tools for enabling automated decision making under uncertainty in real-life scenarios. They are typically applied in standard settings in which each data dimension has a similar type and similar statistical properties (e.g. consider the pixels of an image). However, many real-world datasets contain variables with different types. For instance, in healthcare applications, a patient record may contain demographic information such as nationality which is of categorical type, the age which is ordinal, the height which is continuous.
Naively applying vanilla VAEs to such mixed type heterogeneous data can lead to unsatisfying results. The reason for this is that it requires the use of different likelihood functions (e.g. Gaussian likelihoods for real-valued variables and Bernoulli likelihoods for binary variables). In this case, the contribution that each likelihood makes to the training objective can be very different, leading to challenging optimization problems [13] in which some data dimensions may be poorly-modeled in favor of others. Figure 1 (c) shows an example in which a vanilla VAE ﬁts some of the categorical variables, but performs poorly on the continuous ones.
To overcome the limitations of VAEs in this setting, we propose Variational Auto-encoder for heterogeneous mixed type data (VAEM) and study its performance for decision making in real-world
∗This work was performed when the authors were (part-time) associated with Microsoft Research, Cambridge 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
(a) Ground Truth (b) VAEM (ours) (c) VAE (d) VAE-extended (e) VAE-balanced (f) VAE-HI
Figure 1: Pair plots of 3-dimensional data generated from 5 different models (deﬁned in Section 5.1) and actual Bank data used to train them. In each subﬁgure, diagonal plots show marginal histograms for each variable. VAEM can correctly capture both continuous and discrete variables correctly both in terms of marginal distribution (diagonal plots) and pair-wise dependces (off-diagnal plots). applications. VAEM uses a hierarchy of latent variables which is ﬁt in two stages. In the ﬁrst stage, we learn one type-speciﬁc VAE for each dimension. These initial one-dimensional VAEs capture marginal distribution properties and provide a latent representation that is more homogeneous across dimensions. In the second stage, another VAE is used to capture dependencies among the one-dimensional latent representations from the ﬁrst stage.
Our contributions are the following:
• We present VAEM, a novel deep generative model for heterogeneous mixed-type data which alleviates the limitations of VAEs discussed above (See Section 2). We study the data generation quality of VAEM comparing with several existing VAE baselines on 5 different datasets. Our results show that VAEM can model mixed-type data more successfully than other baselines.
• We extend VAEM to handle missing data and perform conditional data generation, and derive algorithms that enable it to be used for sequential active information acquisition (Section 2.3). We show that VAEM obtains strong performance for conditional data generation as well as sequential active information acquisition in cases where VAEs perform poorly. 2 VAE for heterogeneous mixed type data
In this section, we ﬁrst review VAEs and their naive application to heterogeneous mixed-typed data.
Then, we describe our proposed VAEM, a two stage model developed for such heterogeneous mixed type data, and the corresponding amortized inference method. Finally, we brieﬂy discuss connecions of VAEM with variational lower bounds and with data standardization methods. 2
2.1