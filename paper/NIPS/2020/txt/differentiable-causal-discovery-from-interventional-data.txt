Abstract
Learning a causal directed acyclic graph from data is a challenging task that involves solving a combinatorial problem for which the solution is not always iden-tiﬁable. A new line of work reformulates this problem as a continuous constrained optimization one, which is solved via the augmented Lagrangian method. However, most methods based on this idea do not make use of interventional data, which can signiﬁcantly alleviate identiﬁability issues. This work constitutes a new step in this direction by proposing a theoretically-grounded method based on neural networks that can leverage interventional data. We illustrate the ﬂexibility of the continuous-constrained framework by taking advantage of expressive neural architectures such as normalizing ﬂows. We show that our approach compares favorably to the state of the art in a variety of settings, including perfect and imperfect interventions for which the targeted nodes may even be unknown. 1

Introduction
The inference of causal relationships is a problem of fundamental interest in science. In all ﬁelds of research, experiments are systematically performed with the goal of elucidating the underlying causal dynamics of systems. This quest for causality is motivated by the desire to take actions that induce a controlled change in a system. Achieving this requires to answer questions, such as “what would be the impact on the system if this variable were changed from value x to y?”, which cannot be answered without causal knowledge [33].
In this work, we address the problem of data-driven causal discovery [16]. Our goal is to design an algorithm that can automatically discover causal relationships from data. More formally, we aim to learn a causal graphical model (CGM) [36], which consists of a joint distribution coupled with a directed acyclic graph (DAG), where edges indicate direct causal relationships. Achieving this based on observational data alone is challenging since, under the faithfulness assumption, the true DAG is only identiﬁable up to a Markov equivalence class [46]. Fortunately, identiﬁability can be improved by considering interventional data, i.e., the outcome of some experiments. In this case, the DAG is identiﬁable up to an interventional Markov equivalence class, which is a subset of the Markov equivalence class [48, 15], and, when observing enough interventions [9, 11], the DAG is exactly identiﬁable. In practice, it may be possible for domain experts to collect such interventional data, resulting in clear gains in identiﬁability. For instance, in genomics, recent advances in gene editing technologies have given rise to high-throughput methods for interventional gene expression data [6].
∗ Equal contribution.
Correspondence to: {philippe.brouillard, sebastien.lachapelle}@umontreal.ca 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
Figure 1: Different intervention types (shown in red). In imperfect interventions, the causal relation-ships are altered. In perfect interventions, the targeted node is cut out from its parents.
Nevertheless, even with interventional data at hand, ﬁnding the right DAG is challenging. The solution space is immense and grows super-exponentially with the number of variables. Recently,
Zheng et al. [52] proposed to cast this search problem as a constrained continuous-optimization problem, avoiding the computationally-intensive search typically performed by score-based and constraint-based methods [36]. The work of Zheng et al. [52] was limited to linear relationships, but was quickly extended to nonlinear ones via neural networks [27, 49, 53, 32, 21, 54]. Yet, these approaches do not make use of interventional data and must therefore rely on strong parametric assumptions (e.g., gaussian additive noise models). Bengio et al. [1] leveraged interventions and continuous optimization to learn the causal direction in the bivariate setting. The follow-up work of Ke et al. [23] generalized to the multivariate setting by optimizing an unconstrained objective with regularization inspired by Zheng et al. [52], but lacked theoretical guarantees. In this work, we propose a theoretically-grounded differentiable approach to causal discovery that can make use of interventional data (with potentially unknown targets) and that relies on the constrained-optimization framework of [52] without making strong assumptions about the functional form of causal mechanisms, thanks to expressive density estimators. 1.1 Contributions
• We propose Differentiable Causal Discovery with Interventions (DCDI): a general differen-tiable causal structure learning method that can leverage perfect, imperfect and unknown-target interventions (Section 3). We propose two instantiations, one of which is a universal density approximator that relies on normalizing ﬂows (Section 3.4).
• We show that the exact maximization of the proposed score will identify the I-Markov equivalence class [48] of the ground truth graph (under regularity conditions) for both the known- and unknown-target settings (Thm. 1 in Section 3.1 & Thm. 2 in Section 3.3, respectively).
• We provide an extensive comparison of DCDI to state-of-the-art methods in a wide variety of conditions, including multiple functional forms and types of interventions (Section 4). 2