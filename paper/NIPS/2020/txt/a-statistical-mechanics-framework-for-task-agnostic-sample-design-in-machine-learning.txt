Abstract
In this paper, we present a statistical mechanics framework to understand the effect of sampling properties of training data on the generalization gap of machine learn-ing (ML) algorithms. We connect the generalization gap to the spatial properties of a sample design characterized by the pair correlation function (PCF). In partic-ular, we express generalization gap in terms of the power spectra of the sample design and that of the function to be learned. Using this framework, we show that space-ﬁlling sample designs, such as blue noise and Poisson disk sampling, which optimize spectral properties, outperform random designs in terms of the generalization gap and characterize this gain in a closed-form. Our analysis also sheds light on design principles for constructing optimal task-agnostic sample designs that minimize the generalization gap. We corroborate our ﬁndings using regression experiments with neural networks on: a) synthetic functions, and b) a complex scientiﬁc simulator for inertial conﬁnement fusion (ICF). 1

Introduction
Machine learning (ML) techniques have led to incredible advances in a wide variety of commercial applications, and similar approaches are rapidly being adopted in several scientiﬁc and engineering problems. Traditionally, ML research has focused on developing modeling techniques and training algorithms to learn generalizable models from historic labeled data (i.e., a known set of inputs and their corresponding responses). However, in several applications, we encounter a key challenge even before building the model – determining the input samples for which the responses should be collected (referred to as task-agnostic sample design problem). This is particularly true for emerging applications in physical sciences and engineering where curated datasets are not available a priori and data acquisition involves time-consuming computational simulations or expensive real-world experiments. For example, in inertial conﬁnement fusion (ICF) [2], one needs to build a high-ﬁdelity mapping from the process inputs, say target and laser settings, to process outputs, such as ICF implosion neutron yield and X-ray diagnostics. In such scenarios, the properties of collected data directly control the generalization error of ML models. However, determining the right samples to use for model training hinges on understanding the intricate interplay between sampling properties and the ML generalization error. Unfortunately, our theoretical understanding is very limited in this regard, and hence existing sample design approaches rely upon a variety of heuristics, e.g., generating so called space-ﬁlling sample designs [15] to cover the input space as uniformly as possible.
Most existing theoretical frameworks only study the generalization properties of random i.i.d. de-signs or other simple probabilistic variants. Intuitively, this assumption ignores the dependency of generalization gap on data properties except the sample size (data-independent bounds). While some efforts exist to obtain data-dependent bounds, they still focus on studying model design related questions while ignoring sample design aspects. To the best of our knowledge, there does not exist 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
a framework in the literature that can help study the generalization error of generic sample designs (e.g., space-ﬁlling). This paper proposes to study generalization error from the viewpoint of the sampler generating the training data. We ﬁll a crucial gap by developing a framework capable of characterizing the generalization performance of generic sample designs based on metrics from statistical mechanics, which are expressive enough to quantify a broad range of sample distributions.
Contributions: We develop a framework for studying the generalization behavior of sample designs through the lens of statistical mechanics. First, we model sample design as a stochastic point process and obtain a corresponding representation in the spectral domain using tools from [18]. This approach allows us to study the behavior of a larger class of sample designs (including space-ﬁlling). In particular, for our subsequent analysis, we focus on the blue noise [13, 17] and Poisson disk sampling (PDS) [16, 18] designs (see Figure 1 in the supplementary material). Next, we reformulate the generalization gap in the spectral domain and obtain an explicit closed-form relation of generalization gap with the power spectra of both the sample design and the function to be learned. Using our framework, we are able to theoretically show that space-ﬁlling designs outperform random designs.
We further characterize the gains obtained with two state-of-the-art space-ﬁlling designs, namely blue noise and PDS samples, over a random design in a closed-form. This analysis further enables us to formulate design principles to construct optimal sampling methods for speciﬁc ML problems. We also make interesting (counter-intuitive) observations on the convergence behavior of generalization error with increasing dimensions. Speciﬁcally, we ﬁnd that analysis with traditional metrics leads to inconsistent results in high dimensions. To overcome this issue, we develop novel spectral metrics to obtain meaningful convergence results for different sampling patterns (see supplementary material).
Finally, we corroborate our ﬁndings by carrying out regression experiments on synthetic functions and a complex scientiﬁc simulator for inertial conﬁnement fusion [3]. 2