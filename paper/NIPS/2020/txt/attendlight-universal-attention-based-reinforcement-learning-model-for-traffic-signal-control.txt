Abstract
We propose AttendLight, an end-to-end Reinforcement Learning (RL) algorithm for the problem of trafﬁc signal control. Previous approaches for this problem have the shortcoming that they require training for each new intersection with a different structure or trafﬁc ﬂow distribution. AttendLight solves this issue by training a single, universal model for intersections with any number of roads, lanes, phases (possible signals), and trafﬁc ﬂow. To this end, we propose a deep RL model which incorporates two attention models. The ﬁrst attention model is introduced to handle different numbers of roads-lanes; and the second attention model is intended for enabling decision-making with any number of phases in an intersec-tion. As a result, our proposed model works for any intersection conﬁguration, as long as a similar conﬁguration is represented in the training set. Experiments were conducted with both synthetic and real-world standard benchmark data-sets.
Our numerical experiment covers intersections with three or four approaching roads; one-directional/bi-directional roads with one, two, and three lanes; differ-ent number of phases; and different trafﬁc ﬂows. We consider two regimes: (i) single-environment training, single-deployment, and (ii) multi-environment train-ing, multi-deployment. AttendLight outperforms both classical and other RL-based approaches on all cases in both regimes. 1

Introduction
With the emergence of urbanization and the increase in household car ownership, trafﬁc congestion has been one of the major challenges in many highly-populated cities. Trafﬁc congestion can be mitigated by road expansion/correction, sophisticated road allowance rules, or improved trafﬁc signal controlling. Although either of these solutions could decrease the travel times and fuel costs, optimizing the trafﬁc signals is more convenient due to the limited funding resources and opportunity of ﬁnding more effective strategies. This paper introduces a framework for learning a general trafﬁc control policy that can be deployed in an intersection of interest and ease the trafﬁc ﬂow.
Approaches for controlling signalized intersections could be categorized into two main classes, namely conventional methods and adaptive methods. In the former, customarily rule-based ﬁxed cycles and phase times are determined a priori and ofﬂine based on historical measurements as well 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
as some assumptions about the underlying problem structure. However, since trafﬁc behavior is dynamically changing, that makes most conventional methods highly inefﬁcient. In adaptive methods, decisions are made based on the current state of the intersection. Self-organizing Trafﬁc Light Control (SOTL) [12] and Max-pressure [28] are among the most popular adaptive methods that consider the number of approaching vehicles to the intersection in their trafﬁc control algorithm (See, e.g., [14] for more details). These methods bring considerable improvements in trafﬁc signal control; nonetheless, they are short-sighted and do not consider the long-term effects of the decisions on the trafﬁc. Besides, these methods do not use the feedback from previous actions toward making more efﬁcient decisions.
In response, more sophisticated algorithms have been proposed. Using artiﬁcial intelligence (AI) for controlling trafﬁc signals has recently attracted a lot of attention, due to the major potential beneﬁts that it can bring toward having less-congested cities. Reinforcement Learning (RL) [26], which has been ﬂourished in recent years in the AI community, has shown superior performance for a wide range of problems such as games [25], robotics [13], ﬁnance [11], and operations research [7], only to name a few. This coincides with growing applications of RL in trafﬁc signal control problem (TSCP) [15, 16, 22, 29, 37].
In spite of immense improvements achieved by RL methods for a broad domain of intersections, the main limitation for the majority of the methods is that the proposed model needs to be re-designed and re-trained from scratch whenever it faces a different intersection either with different topology or trafﬁc distribution. Learning specialized policies for each individual intersection can be problematic, as not only do RL agents have to store a distinct policy for each intersection but in practice data collection resources and preparation impose costs. These costs include the burden on human-experts’ time to setup a new model, and computational resources to train and tune a new model. Thus, it is not clear whether such a cumbersome procedure is feasible for a city with thousands of distinct intersections. There exists some prior work on partially alleviating such issues [30, 37] using transfer learning; however, the trained models still need to be manipulated for different intersection structures and require retraining to achieve reasonable performance.
To address these issues, we bring ideas from attentional models [5] into TSCP. Rather than specializing on a single intersection, our goal is to design a mechanism with satisfactory performance across a group of intersections. Attentional mechanisms are a natural choice, since they allow uniﬁed system representations by handling variable-length inputs. We propose the AttendLight framework, a reinforcement learning algorithm, to train a “universal” model which can be used for any intersection, with any number of roads, lanes, phase, trafﬁc distribution, and type of sensory data to measure the trafﬁc. In other words, once the model is trained under a comprehensive set of phases, roads, lanes, and trafﬁc distribution, our trained model can be used for new unseen intersection, and it provides reasonable performance as long as the intersection conﬁguration follows a pattern present in the training set. We ﬁnd that AttendLight architecture can extract an abstract representation of the intersection status, without any extra grounding or redeﬁnition, and reuse this information for fast deployment. We show that our approach substantially outperforms purely conventional controls and
FRAP [37], one of the state-of-the-art RL-based methods. 2