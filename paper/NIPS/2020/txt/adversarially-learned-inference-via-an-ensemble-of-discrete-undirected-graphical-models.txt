Abstract
Undirected graphical models are compact representations of joint probability dis-tributions over random variables. To solve inference tasks of interest, graphical models of arbitrary topology can be trained using empirical risk minimization.
However, to solve inference tasks that were not seen during training, these models (EGMs) often need to be re-trained. Instead, we propose an inference-agnostic adversarial training framework which produces an inﬁnitely-large ensemble of graphical models (AGMs). The ensemble is optimized to generate data within the GAN framework, and inference is performed using a ﬁnite subset of these models. AGMs perform comparably with EGMs on inference tasks that the latter were speciﬁcally optimized for. Most importantly, AGMs show signiﬁcantly bet-ter generalization to unseen inference tasks compared to EGMs, as well as deep neural architectures like GibbsNet and VAEAC which allow arbitrary conditioning.
Finally, AGMs allow fast data sampling, competitive with Gibbs sampling from
EGMs. 1

Introduction
Probabilistic graphical models [Koller and Friedman, 2009, Murphy, 2012] are compact representa-tions of joint probability distributions. We focus on discrete pairwise undirected graphical models, which represent the independence structure between pairs of random variables. Algorithms such as belief propagation allow for inference on these graphical models, with arbitrary choices of observed, query and hidden variables. When the graph topology is loopy, or when the structure is mis-speciﬁed, inference through belief propagation is approximate [Murphy et al., 2013].
A purely generative way to train such a model is to maximize the likelihood of training data (ML), under the probability distribution induced by the model. However, evaluating the gradient of this objective involves computing marginal probability distributions over the random variables. As these marginals are approximate in loopy graphs, the applicability of likelihood-trained models to discriminative tasks is diminished [Kulesza and Pereira, 2008]. In these tasks, the model is called upon to answer queries expressed compactly as (XE = xE , XQ, XH), where from a data point (x1, . . . , xN ) sampled from a certain data distribution P, we observe the values of a subset E of the indices, and have to predict the values at indices in Q from a discrete set X , with the possibility of some hidden variable indices H which have to be marginalized over:
P(Xi = x|XE = xE ), ∀i ∈ Q. arg max x∈X (1)
A distribution over queries of this form will be referred to as an inference task. If the distribution over queries that the model will be called upon to answer is known a priori, then the model’s performance can be improved by shaping the query distribution used at parameter estimation time, accordingly.
In degenerate tasks, E, Q and H are ﬁxed across queries. When this is the case and H is empty, we could use a Bayesian feed-forward neural network [Husmeier and Taylor, 1999] to model the 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
distribution in (1) and train it by backpropagation. The empirical risk minimization of graphical models (EGM) framework of Stoyanov et al. [2011] and Domke [2013] generalizes this gradient-descent-based parameter estimation idea to graphical models. Their framework allows retaining any given graphical model structure, and back-propagating through a differentiable inference procedure to obtain model parameters that facilitate the query-evaluation problem. EGM allows solving the most general form of problems expressed as (1), where E, Q and H are allowed to vary. Information about this query distribution is used at training time to sample choices of evidence, query and hidden variable indices (E, Q, H), as well the observed values xE across data points. The whole imperfect system is then trained end-to-end through gradient propagation [Domke, 2010]. This approach improves the inference accuracy on this speciﬁc query distribution, by orders of magnitude compared to the ML approach. One signiﬁcant drawback of the EGM approach is that the training procedure is tailored to one speciﬁc inference task. To solve a different inference task, the model often has to be completely re-trained (as we see in section 4).
Instead, we would like to learn discrete undirected graphical models which generalize over different or multi-modal inference tasks. Our adversarially trained graphical model (AGM) strategy is built on the GAN framework [Goodfellow et al., 2014]. It allows us to formulate a learning objective for our graphical models, aimed purely at optimizing the generation of samples from the model.
No information about inference tasks is baked into this learning approach. Our only assumption during training is that the training and testing data points come from the same underlying distribution.
Although our undirected graphical models need to be paired to a neural learner for the adversarial training, they are eventually detached from the learner, with an ensemble of parameterizations. When using one of the parameterizations, our graphical model is indistinguishable from one that was trained using alternative methods. We propose a mechanism for performing inference with the whole ensemble, which provides the desired generalization properties across inference tasks, improving over EGM performance. Our learning approach is essentially generative, but the ensemble of models increases the expressive power of the ﬁnal model, making up for approximations in inference and model mis-speciﬁcation which affected the ML approach discussed above.
In the next sections, we discuss related work (2) and introduce our adversarial training framework (3) for undirected graphical models. Our ﬁrst experiment (4.1), shows that although undirected graphical models with empirical risk minimization (EGMs) are trained speciﬁcally for certain inference tasks, our adversarially-trained graphical models (AGMs) can perform comparatively, despite having never seen those tasks prior to training. The second experiment (4.2) is our main experiment which showcases the generalization capabilities of AGMs across unseen inference tasks on images. We also compare AGMs against state-of-the-art neural models GibbsNet and VAEAC which, like AGMs, were designed for arbitrary conditioning. In the last experiment (4.3), we show that the combination of AGMs and their neural learner provide a viable alternative for sampling from joint probability distributions in one shot, compared to Gibbs samplers deﬁned on EGMs. 2