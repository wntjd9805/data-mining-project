Abstract
We present a consistent algorithm for constrained classiﬁcation problems where the objective (e.g. F-measure, G-mean) and the constraints (e.g. demographic parity fairness, coverage) are deﬁned by general functions of the confusion matrix. Our approach reduces the problem into a sequence of plug-in classiﬁer learning tasks.
The reduction is achieved by posing the learning problem as an optimization over the intersection of two sets: the set of confusion matrices that are achievable and those that are feasible. This decoupling of the constraint space then allows us to solve the problem by applying Frank-Wolfe style optimization over the individual sets. For objective and constraints that are convex functions of the confusion matrix, our algorithm requires O(1/✏2) calls to the plug-in subroutine, which improves on the O(1/✏3) calls needed by the reduction-based algorithm of Narasimhan (2018)
[29]. We show empirically that our algorithm is competitive with prior methods, while being more robust to choices of hyper-parameters. 1

Introduction
In an increasing number of machine learning tasks, one is required to train a classiﬁer with constraints on multiple metrics such as fairness, coverage, recall, etc [16, 17, 2, 9, 10]. Often, the objective and constraints in these problems are not simple metrics such as classiﬁcation error, and may have a more complex non-decomposable structure, i.e. may not be expressible a simple average of errors on individual data points. Examples of such metrics include the F-measure and G-mean used in class-imbalanced problems [27, 24], the predictive parity criteria used in ML fairness [7], KL-divergence based metrics used in distribution matching tasks [12, 14], and many more.
A common feature of the above metrics is that they can all be deﬁned as a function of a classiﬁer’s confusion matrix. We are therefore interested in constrained learning problems where the objectives and constraints are general functions of the confusion matrix. Our goal is to design a statistically consistent algorithm for solving these problems, i.e. an algorithm that converges in the limit of inﬁnite training data to an optimal feasible classiﬁer for these problems.
In previous work, Narasimhan (2018) [29] provide consistent algorithms for constrained learning problems by reducing them into a sequence of easy-to-solve sub-problems. Each of these sub-problems is a linear metric minimization task and involves learning a plug-in classiﬁer, a classiﬁer constructed by ﬁne-tuning a threshold (or a weight matrix for multiclass problems) on a pre-trained class probability model. For convex functions of the confusion matrix, their method requires O(1/✏3) calls to the plug-in learning routine to converge to a classiﬁer that is ✏-optimal and ✏-feasible. In this 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
paper, we build on their work and provide an algorithm which requires only O(1/✏2) calls to the plug-in routine to reach a classiﬁer of the same quality.
Like the prior method, the key to our approach is to translate the constrained learning problem into an optimization problem over a ﬁnite dimensional space. While Narasimhan (2008) formulate this optimization problem over the space of confusion matrices that are achievable by a classiﬁer, we formulate the problem over the intersection of two convex sets: the set of confusion matrices that are achievable, and the set of confusion matrices that are feasible, i.e. satisfy the constraints.
The decoupling of the search space into two sets then allows us to adapt the Frank-Wolfe based algorithm of Gidel et al. (2018) [15] to solve the optimization. Our approach makes use of two oracle subroutines, both of which can be implemented efﬁciently. The ﬁrst oracle minimizes a linear function over the space of achievable confusion matrices, which amounts to learning a plug-in classiﬁer. The second performs a linear minimization over the space of feasible matrices, which is often a straight-forward convex program.
The proposed algorithm enjoys several practical beneﬁts. Firstly, the algorithm is computationally efﬁcient to implement: given a pre-trained class probability model (e.g. logistic regression), the algorithm performs a sequence of efﬁcient threshold optimizations on the predicted class probability outputs. Secondly, it can be applied readily to multi-class problems and fairness problems with multiple groups. Thirdly, the number of optimization parameters needed by our algorithm scales linearly with the number of classes and groups, and does not directly depend of the number of constraints. This is in contrast to the method of Narasimhan (2018), which maintains an explicit parameter for each constraint. Our approach instead solves a linear minimization problem over the feasible matrices, which has the advantage of leveraging specialized convex solvers that exploit redundancies in the constraints.
Contributions. The following are the main contributions in this paper. (i) We provide an algorithm for complex constrained classiﬁcation problems , which solves a sequence of plug-in learning tasks (see Section 3). (ii) We show that our algorithm is statistically consistent and enjoys improved convergence guarantees (see Section 4). (iii) We present experiments on benchmark fairness datasets and show that the proposed algorithm performs at least as well as existing methods, while being more robust to choices of hyper-parameters (see Section 5).