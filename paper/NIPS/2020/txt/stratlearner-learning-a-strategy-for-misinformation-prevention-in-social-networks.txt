Abstract
Given a combinatorial optimization problem taking an input, can we learn a strategy to solve it from the examples of input-solution pairs without knowing its objective function? In this paper, we consider such a setting and study the misinformation prevention problem. Given the examples of attacker-protector pairs, our goal is to learn a strategy to compute protectors against future attackers, without the need of knowing the underlying diffusion model. To this end, we design a structured prediction framework, where the main idea is to parameterize the scoring function using random features constructed through distance functions on randomly sampled subgraphs, which leads to a kernelized scoring function with weights learnable via the large margin method. Evidenced by experiments, our method can produce near-optimal protectors without using any information about the diffusion model, and it outperforms other possible graph-based and learning-based methods by an evident margin. 1

Introduction
The online social network has been an indispensable part of today’s community, but it is also making misinformation like rumor and fake news widespread [1, 2]. During COVID-19, there have been more than 150 rumors identiﬁed by Snopes.com [3]. Misinformation prevention (MP) limits the spread of misinformation by launching a positive cascade, assuming that the users who have received the positive cascade will not be conceived by the misinformation. Such a strategy has been considered as feasible [4], and now fact-checking services are trending on the web, such as Snopes.com [5] and
Factcheck.org [6]. Formally, information cascades start to spread from their seed nodes, and the propagation process is governed by an underlying diffusion model. Given the seed nodes (attacker) of the misinformation, the MP problem seeks the seed nodes (protector) of the positive cascade such that the spread of misinformation can be maximally limited.
MP without Knowing the Diffusion Model. Existing works often assume that the parameters in the diffusion model are known to us, and they focus primarily on algorithmic analysis for selecting seed nodes [7, 8]. However, the real propagation process is often complicated, and in reality, we can only have certain types of historical data with little to none prior knowledge of the underlying diffusion model. In this paper, we adopt the well-known triggering model [9] to formulate the diffusion process and assume that the parameters are unknown. Now we are given the social graph together with a collection of historical attacker-protector pairs where the protectors were successful, and the goal is to design a learning scheme to compute the best protector against a new attacker. Given the ground set
V of the users, the MP problem is given by a mapping arg maxP f (M, P ) : 2V → 2V , where f is the objective function determined by the underlying diffusion model to quantify the prevention effect of the protector P ⊆ V against the attacker M ⊆ V . Therefore, our problem is nothing but to learn a mapping from 2V (attacker) to 2V (protector) using training examples {(cid:0)Mi, arg maxP f (Mi, P )(cid:1)}. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
Figure 1: Learning a MP strategy. Suppose that we are given the graph and the information that when the attackers are {a, c}, {a} and {c, g}, the best protectors are, respectively, {d, f }, {b} and {b, d}.
Which is the best protector against the attacker {b}?
See Fig. 1 for an illustration. While this problem is supervised by the attacker-protector pairs, it is somehow different from the common ones in that it attempts to learn a solution to an optimization problem. One challenge in solving it is that the input and output are sets, while machine learning methods often struggle to deal with objects invariant to permutation [10]. Another challenge lies in properly integrating the graph information into the learning design. As we will see later, directly applying existing methods like graph convolutional networks [11] cannot produce good protectors.
StratLearner. We propose a method called StratLearner to solve the considered problem.
StratLearner aims to learn a scoring function f ∗(M, S) that satisﬁes f (cid:0)M, arg max f ∗(M, P )(cid:1) ≈ max f (cid:0)M, P (cid:1)
P
P for each M , and if successful, the prediction arg maxP f ∗(M, P ) ensures a good protector. The key idea of StratLearner is to parameterize f ∗(M, P ) by f ∗(M, P ) = wTG(M, P ) where G(M, P ) ∈
RK is a feature function constructed through K ∈ Z+ random subgraphs with w ∈ RK being the tunable weights. Our parameterization is justiﬁed by the fact that for each distribution over (M, P ) and any possible f given by a triggering model, there exists a wTG(M, P ) that can be arbitrarily close to f in the Hilbert space provided that K is sufﬁciently large. Therefore, StratLearner ﬁrst generates a collection of random features to obtain G(M, P ), and then learns the weight w through structural SVM, where a new loss-augmented inference method has been designed to overcome the
NP-hardness in computing the exact inference. Our experiments not only show that StratLearner can produce high-quality protectors but also veriﬁes that StratLearner indeed beneﬁts from the proposed feature construction. 2 Problem Setting
We proceed by introducing the diffusion model followed by deﬁning the MP problem together with the learning settings. 2.1 Model
We consider a social network given by a directed graph G = (V, E). Each node u ∈ V is associated with a distribution N u(S) over 2N − u being the set of the in-neighbors of u; each edge (u, v) ∈ E is associated with a distribution T (u,v)(x) over (0, +∞) denoting the transmission time.
Suppose that there are two cascades: misinformation M and positive cascade P, with seed sets M ⊆ V (attacker) and P ⊆ V (protector), respectively. We speak of each node as being the state of M-active,
P-active, or inactive. Following the triggering model [9, 12], the diffusion process unfolds as follows: u with N −
• Initialization: Each node u samples a subset Au ⊆ N − u from N u. Each edge (u, v) samples a real number t(u,v) > 0 from T (u,v).
• Time 0: The nodes in M (resp, P ) are M-active (resp,. P-active) at time 0.1
• Time t: When a node u becomes M-active (resp., P-active) at time t, each inactive node v such that u in Av will be activated by u and become M-active (resp., P-active) at time t + t(u,v). Each node will be activated by the ﬁrst in-neighbor attempting to activate them and never deactivated. When a node v is activated by two or more in-neighbors with different states at the same time, v will become M-active. 2 1Without loss generality, we assume that M ∩ P = ∅. 2This setting is not critical. See Supplementary D for a discussion. 2
Remark 1. When there is only one cascade, the above model subsumes classic models, including
Discrete-time independent cascade (DIC) model [9], Discrete-time linear threshold (DLT) model [9],
Continuous-time independent cascade (CIC) model [12]. An example for illustrating the diffusion process is given in Supplementary A. 2.2 Misinformation Prevention and Learning Settings
Given the seed sets M and P , we use f (M, P ) : 2V × 2V → R to denote the expected number of the nodes that are not activated by the misinformation and call f the prevention function. Formally, they form a class of functions.
Deﬁnition 1 (Class F PF). Over the choices of N u and T (u,v), we use F PF to denote the class of the prevention functions, i.e.,
F P F := f (M, P ) : 2V × 2V → R | N u for each u; T (u,v) for each (u, v) (1) (cid:111)
. (cid:110)
When the misinformation M is detected, our goal is to launch a positive cascade such that the misinformation can be maximally prevented [7, 13, 14].
Problem 1 (Misinformation Prevention). Under a budget constraint given by k ∈ Z+, the misin-formation prevention problem aims to compute
F (M ) := arg max f (M, P |∅) := f (M, P ) − f (M, ∅). (2)
P ⊆V \M, |P |≤k
In this paper, we assume that the social graph G is known but the diffusion model (i.e., N u and
T (u,v)) is unknown, and given a new attacker M , we aim to solve Problem 1 from historical data: a collection of samples S = {(Mi, Pi)}n i=1 where Pi is the optimal or suboptimal solution to Problem 1 associated with input Mi. That is, we aim to learn a strategy F ∗ : 2V → 2V that computes the protector F ∗(M ) for a future attacker M ⊆ V , hoping that F ∗(M ) can maximize f (M, P ) with respective to P . Since f (M, P ) is unknown to us, F ∗(M ) is examined by the training pairs.
For a training pair (M, P ), we consider a function L(P, S) that quantiﬁes the loss for using some
S ⊆ V instead of P as the protector. Assuming that the attacker M of the misinformation follows an 2V L(cid:0)F (M ), F ∗(M )(cid:1) d M(M ) unknown distribution M, we aim to learn a F ∗ such that the risk (cid:82) is minimized, and we attempt to achieve this by minimizing the empirical risk
RS = 1 n (cid:88) i
L(Pi, F ∗(Mi)). (3) 3 StratLearner
The overall idea is to learn a scoring function f ∗ such that arg maxP ⊆V, |P |≤k f ∗(M, P ) can be a good protector. Note that the prevention function f itself is the perfect score function, but it is not known to us and no data is available for learning it. Nevertheless, we are able to construct a hypothesis space that not only covers the class of prevention function (Sec. 3.1) but also enables simple and robust learning algorithm for searching a scoring function within it (Sec. 3.2). 3.1 Parameterization
To construct the desired hypothesis space, let us consider a function class derived through distance functions on subgraphs.
Deﬁnition 2 (Class F Φ). Let Ψ be the set of the weighted subgraphs of G over all possible weights and structures, and let Φ be the set of all distributions over Ψ. For each subgraph g ∈ Ψ and v ∈ V , deﬁne that fg(M, P |∅) := (cid:80) g (M, P |∅) with v∈V f v f v g (M, P |∅) := (cid:26)1 disg(P, v) < disg(M, v) and disg(M, v) (cid:54)= ∞ 0 otherwise (distance function) (4) where we have disg(S, v) := minu∈S disg(S, v) and disg(u, v) is the length of the shortest path from u to v in g. The class F Φ is deﬁned as F Φ :=
Ψ φ(g) · fg(M, P |∅) dg | φ ∈ Φ (cid:110) (cid:82) (cid:111) 3
Theorem 1. F PF is a subclass of F Φ.
The above result indicates that the prevention function can be factorized as an afﬁne combination of the distance functions (i.e. f v g (M, P |θ)) over subgraphs with weights given by some φ(g). While the class F Φ is still not friendly for searching as no parameterization of φ(g) is given, the function therein can be further approximated by using the subgraphs randomly drawn from some ﬁxed distribution in
Φ, as shown in the following.
Deﬁnition 3 (Class F G). For a subset G = {g1, ..., gK} ⊆ Ψ, let us consider the function class
F G := (cid:110) K (cid:88) i=1 wi · fgi(M, P |∅) | wi ∈ R (cid:111)
. (5)
Let φ∗ be any distribution in Φ with φ∗(g) > 0 for each g ∈ Ψ, and let G = {g1, ..., gK} be a collection of random subgraphs generated iid from φ∗. The following result shows the convergence bound for approximating functions in F Φ via functions in F G, which is inspired by standard analysis of random features [15].
Theorem 2. Let χ be any distribution over 2V × 2V and (cid:15), δ > 0 be the given parameters. For each f1 ∈ F Φ associated with certain φ1 ∈ Φ, when K is no less than max(2 ln 1
δ
, 1) ·
C 2|V |2 (cid:15)2 with probability at least 1 − δ over g1, ..., gK, there exists a f2 ∈ F G such that (cid:115)(cid:90) 2V ×2V (cid:16) f2(x) − f1(x) (cid:17)2 dχ(x) ≤ 2(cid:15), (6) where C := supg
φ1(g)
φ∗(g) measures the deviation between φ1 and φ∗.
Theorems 1 and 2 together imply that each prevention function in F PF can be well-approximated by some function in F G provided that G had a sufﬁcient number of random graphs and the weights were correctly chosen. Given that the underlying prevention function is the perfect scoring function, we now have a good reason to search a scoring function in F G, and we will do so by learning the weights wi, guided by the empirical risk Eq. (3). Now let us assume that the subgraphs {g1, ..., gK} have been generated, and we focus on learning the weights. 3.2 Margin-based Structured Prediction
Given the subgraphs G = {g1, ..., gK}, according to Eq. (5), our scoring function takes the form (cid:17) of wTG(M, P ) where we have deﬁned G(M, P ) as G(M, P ) := and w ∈ RK are the parameters to learn. For a collection of training pairs {(Mi, Pi)}n i=1, the condition of zero training error requires that wTG(M, P ) identiﬁes Pi to be the best protector corresponding to Mi, and it is therefore given by the constrains fg1(M, P |∅), ..., fgK (M, P |∅) (cid:16) wTG(Mi, Pi) ≥ wTG(Mi, S), ∀i ∈ [n], ∀S : |S| ≤ k and S (cid:54)= Pi.
In addition, we requires that the weights are non-negative for several reasons. First, the proof of
Theorem 2 tells that non-negative weights are sufﬁcient to achieve the convergence bound, so such a requirement would not invalidate the function approximation guarantees. Second, as discussed later in this section, restricting the weights to be non-negative can simplify the inference problem. Finally, as observed in experiments, such a constraint can lead to a fast convergence in the training process, without scarifying the performance. In the case that Eq. (7) is feasible but the solution is not unique, we aim at the solution with the maximum margin. The standard analysis of SVM yields the following quadratic programming: (7) min s.t. (cid:107)w(cid:107)2 2 1 2 wTG(Mi, Pi) − wTG(Mi, S) ≥ 1, ∀S : |S| ≤ k and S (cid:54)= Pi; w ≥ 0. 4
Algorithm 1 Modular-Modular Procedure 1: Input: H(M,P )(S); 2: X0 = P ; 3: repeat
Xt+1 ← arg min|S|=k H 4: t ← t + 1; 5: 6: until stop criteria met;
Xt (M,P )(S);
In general, the loss function L(P, S) can be derived from the similarity functions SIM(P, S) by
L(P, S) := SIM(P, P ) − SIM(P, S), where SIM(P, S) ≥ 0 has a unique maximum at S = P . For example, the Hamming loss is given by the similarity function 1(S = P ). For the MP problem, since the graph structure is given, we can measure the similarity of two sets in terms of the overlap of their neighborhoods. Speciﬁcally, for each S ⊆ V and j ∈ [n], we denote by H j
S ⊆ V the set of the nodes within j hop(s) from any node in S, including S itself, and the similarity between two sets V1 and V2 can be measured by SIMj
∩ H j
|. We call the loss function derived from such
V2 similarities as j-hop loss. hop(V1, V2) := |H j
V1
Incorporating the loss function into the training process by re-scaling the margin [16], we have min 1 2 (cid:107)w(cid:107)2 2 +
C 2n n (cid:88) i=1
ξi s.t. wTG(Mi, Pi) − wTG(Mi, S) ≥ α · L(Pi, S) − ξi, ∀i ∈ [n], ∀S : |S| ≤ k, S (cid:54)= Pi; (8) w ≥ 0. where α is a hyperparameter to control the scale of the loss. While this programming consists of an exponential number of constraints for each pair (Mi, Pi), these constraints are equivalent to min
|S|≤k
α · SIM(Pi, S) − wTG(Mi, S) ≥ α · SIM(Pi, Pi) − wTG(Mi, Pi) − ξi.
Therefore, the number of constraints can be reduced to polynomial provided that min
|S|≤k
H(M,P )(S) := α · SIM(P, S) − wTG(M, S) (loss-augmented inference) (9) can be easily solved, which is the loss-augmented inference (LAI) problem. Unfortunately, such a task is not trivial, even under the Hamming loss.
Theorem 3. The loss-augmented inference problem is NP-hard under the hamming loss or j-hop loss. Furthermore, it cannot be approximated within a constant factor under the j-hop loss unless
N P belongs to DT IM E(npoly log n).
For the hamming loss, minimizing H(M,P )(S) is simply to maximize wTG(M, S), which is a submodular function (See proof of Theorem 4), and thus we can utilize the greedy algorithm for an (1 − 1/e)-approximation [17]. For the j-hop loss, the next result reveals a useful combinatorial property of H(M,P )(S) for solving the LAI problem.
Theorem 4. For each X ⊆ V , there exists a polynomial-time computable modular upper bound
H
X (M,P )(S) of H(M,P )(S) that is tight at X.
This result immediately yields a heuristic algorithm for minimizing H(M,P )(S), as shown in Alg. 1. The algorithm is adapted from the modular-modular procedure for DS programming [18], and it guarantees that H(M,P )(S) is decreased after each iteration.
Property 1. Alg. 1 guarantees that H(Xt+1) < H(Xt), and each iteration takes O(K|V |2 +
K|V ||E|).
Once the LAI problem is solved, the weights w can be learned using standard structural SVM. We adopt the one-slack cutting plane algorithm [19]. See Alg. 2 in Supplementary C. 5
3.3 StratLearner
Putting the above modules together, we have the following learning strategy: given the social graph and a collection of samples {(Mi, Pi)}n i=1, (a) select a distribution φ∗ in Φ and a loss function; (b) generate K random subgraphs {g1, ..., gK} using φ∗; (c) run the one-slack cutting plane algorithm to obtain w = {w1, ..., wK}, where the LAI problem is solved by Alg. 1. Given a new attacker M , the protector is computed by arg maxS⊆V, |S|≤k wTG(M, S), which is the cardinality-constrained submodular maximization problem and therefore can be approximated again by the greedy algorithm
[17]. Here we see that enforcing the weights w to be nonnegative can make this problem much more tractable, as otherwise, the objective function would not be submodular.
Remark 2. Alg. 1 is conceptually simple but practically time-consuming. One can use a limit on the iterations as a simple stop criteria. In our experiment, using only one iteration in each run of Alg. 1 is sufﬁcient to achieve a high training efﬁcacy. For selecting φ∗, the requirement that φ∗(g) > 0 for each g ∈ Ψ is more technical than practical. Given that no prior information of the diffusion model is available, generating subgraphs uniformly at random is a natural choice, which has been effective in our experiments. 4 Experiments
The experiment aims to explore: (a) the performance of StratLearner compared with other possible methods in terms of maximizing f (M, P |∅); (b) the number of features and training pairs needed by StratLearner to achieve a reasonable performance; (c) the impact of the distribution φ used for generating random subgraphs. The implementations are maintained online [20]. 4.1 Settings
Social Graph and Diffusion Model. We adopt three types of social graphs: a Kronecker graph [21] with 1024 nodes and 2655 edges, an Erd˝os-Rényi graph with 512 nodes and 6638 edges, and a power-law graph [22] with 768 nodes and 1532 edges. Following the classic triggering model [23, 24], the transmission time T (u,v) of each edge (u, v) follows a Weibull distribution with parameters randomly selected from {1, ..., 10}, and for each u, we have N u(S) (cid:26)1/dv S = {v}, v ∈ N − otherwise 0 u with dv being the in-degree of v. For each attacker M , the budget k of the protector P is |M |.
StratLearner. Each subgraph is generated by selecting each edge independently at random with a probability of 0.01, where each selected edge has a weight of 1.0. We denote such a distribution as
φ1.0 0.01. The number of subgraphs (i.e. features) is enumerated from {100, 400, 800, 1600}. We adopt the one-hop loss, and the hyperparameter α in Eq. (8) is ﬁxed as 1000.
Other Methods. To set some standards, we denote by Rand the method that randomly selects the protector. Since the graph structure is known to us, we adopt two popular graph-based methods:
HighDegree (HD), which selects the nodes with the highest degree as the protector, and Proximity (Pro), which selects the neighbors of the attacker as the protector. Recall that our problem can be treated as a supervised learning problem from 2V to 2V , so off-the-shelf learning methods are also applicable. In particular, we have implemented Naive Bayes (NB), MLP, Graph Convolutional
Network (GCN) [11], and Deep Set Prediction Networks (DSPN) [10]. GCN can make use of graph information, and DSPN is designed to process set inputs.
Training and Evaluation. The size of each attacker M is randomly generated following the power-law distribution with parameter 2.5, and the nodes in M are selected uniformly at random from V .
The best protector Ptrue is computed using the method in [25] which is one of the algorithms for
Problem 1 that gives the best possible approximation ratio. In each run, the training and testing set, given their sizes, are randomly selected from a pool of 2500 pairs, where the training size is enumerated in {270, 540, 1080, 2160} and the testing size is 270. The subgraphs used in StratLearner are also randomly generated in each run. For each method, the whole training and testing process is repeated ﬁve times, and we report the average results with standard deviations. For each predicted protector Ppred , its quality is measured by the performance ratio f (M,Ppred|∅) f (M,Ptrue|∅) ∈ [0, 1], where f (M, P |∅) is computed using 10000 simulations. Higher is better. 6
Table 1: Main Result. Each cell shows the mean of performance ratio with the standard deviation.
Dataset 100
StratLearner (φ1.0 400 800 0.01) 1600
NB
MLP
GCN
DSPN
ML Methods 270 540 1080 2160 270 540 1080 2160 270 540 1080 2160
Kro-necker
Power-law
Erd˝os-Rényi 0.699 (8E-3) 0.759 (7E-3) 0.785 (1E-2) 0.810 (9E-3) 0.707 (5E-3) 0.743 (8E-3) 0.780 (9E-3) 0.813 (7E-3) 0.708 (2E-2) 0.760 (1E-2) 0.782 (8E-3) 0.817 (5E-3) 0.701 (1E-2) 0.756 (1E-2) 0.792 (5E-3) 0.821 (8E-3) 0.643 (3E-2) 0.607(2E-2) 0.650(2E-3) 0.659(9E-3) 0.657(5E-3) 0.602 (9E-3) 0.653 (1E-3) 0.650(1E-2) 0.658(5E-3) 0.632 (2E-2) 0.657 (1E-3) 0.650(1E-2) 0.655 (3E-3) 0.661 (1E-2) 0.648 (1E-3) 0.666(6E-3)
Other Methods: Rand: 0.190 (5E-3) HD : 0.639 (4E-3) Pro: 0.670 (6E-3) 0.707 (1E-2) 0.839 (6E-3) 0.881 (1E-2) 0.902 (8E-3) 0.686 (2E-2) 0.858 (8E-3) 0.878 (2E-2) 0.909 (9E-3) 0.680 (4E-2) 0.823 (2E-2) 0.890 (4E-3) 0.920 (7E-3) 0.682 (1E-2) 0.853 (2E-2) 0.889 (1E-2) 0.911 (3E-3) 0.272 (1E-2) 0.271 (2E-3) 0.271 (1E-3) 0.242 (3E-2) 0.294 (1E-2) 0.327 (2E-3) 0.279 (6E-4) 0.247 (1E-2) 0.294 (1E-2) 0.418 (2E-2) 0.281 (8E-4) 0.242 (2E-2) 0.302 (3E-3) 0.489 (1E-2) 0.275 (6E-4) 0.235 (1E-2)
Other Methods: Rand: 0.047 (4E-3) HD: 0.318 (1E-3) ; Pro: 0.770 (8E-3) 0.661 (2E-2) 0.853 (6E-3) 0.873 (1E-2) 0.892(3E-3) 0.673 (2E-2) 0.861 (1E-2) 0.876 (6E-3) 0.897(1E-2) 0.688 (3E-2) 0.844 (9E-3) 0.870 (1E-2) 0.899 (8E-3) 0.674 (2E-2) 0.857 (2E-2) 0.873 (5E-3) 0.903 (3E-3) 0.106 (5E-2) 0.246 (2E-2) 0.085 (6E-4) 0.088 (1E-2) 0.104 (5E-3) 0.340 (2E-2) 0.088 (1E-3) 0.095 (7E-3) 0.111 (6E-3) 0.410 (2E-2) 0.091 (5E-4) 0.090 (4E-3) 0.115 (2E-3) 0.484 (2E-2) 0.101 (8E-4) 0.090 (8E-3)
Other Methods: Rand: 0.052 (2E-2) HD : 0.102 (5E-3) Pro: 0.776 (5E-3)
The details of data generation and the implementations of the tested methods can be found in
Supplementary E, which also includes the result on a Facebook graph. 4.2 Observations
On StratLearner. The main results are given in Table 1. We see that StratLearner performs better when more training examples or more features are given, and it is pretty robust in terms of deviation.
In addition, StratLearner is more sensitive to the number of features than to the number of training examples - the performance ratio does not increase much when more training examples are given but increases signiﬁcantly with more features.
Comparison between Different Methods. With 400 features from φ1.0 0.01, StratLearner has already outperformed all other methods, regardless of the types of the social graph. Plausibly, DSPN and
NB are unable to utilize the information of the social graph; GCN is unable to process set structures;
HD and Pro ignore the training data. While GCN can make use of the social graph, it merely uses the adjacency between nodes without considering the triggering model. In contrast, StratLearner samples subgraphs and seeks the best combination of them through learning the weights, which, according to Theorem 2, is essentially to approximate the diffusion process under the triggering model. This enables StratLearner to leverage the social graph to learn the unknown parameter in a more explicit way. In another issue, StratLearner, with a moderate number of features, can achieve a performance ratio no less than 0.7 on all the three graphs, but other learning methods (i.e., NB,
MLP, GCN) are quite sensitive to the graph structure. In particular, they perform relatively well on Kronecker but poorly on Power-law and Erd˝os-Rényi. For example, MLP can achieve a ratio comparable to that of HD and Pro on Kronecker, but it is not much better than Rand on Erd˝os-Rényi.
For graph-based methods, HD is also sensitive to the graph structure, while Pro can consistently offer moderate performance, though worse than StratLearner. Overall, the performance of StratLearner is exciting.
The Impact of φ. One interesting question is how the distribution used for generating random subgraphs may affect the performance of StratLearner. First, to test the density of the subgraphs, we consider two distributions φ1.0 0.1, where each edge is selected with probability, respectively, 0.005 (less dense) and 0.1 (more dense), with edge weights remaining as 1.0. The results of this part are given in Fig. 2. Comparing φ1.0 0.1 to φ1.0 0.01, on Power-law and Erd˝os-Rényi, we observe an increased performance ratio when the subgraphs become denser, but on Kronecker, decreasing the density also results in a better performance ratio. We can imagine that increasing the subgraph density 0.005 and φ1.0 0.005 and φ1.0 7
(a) Kronecker (b) Power-law (c) Erd˝os-Rényi
Figure 2: StratLearner with different φ. The y-axis denotes the performance ratio and the x-axis 1.0 and φ+ denotes the number of features. Each graph plots ﬁve curves for φ1.0
+, respectively. The precise values are given in Table 2 in Supplementary E. 0.005, φ1.0 0.01, φ1.0 0.1, φ1.0 does not necessarily increase the performance. Considering the extreme setting φ1.0 1.0 where each edge is always selected, since there is only one feature, StratLearner reduces to simply maximizing the distance function over the entire graph with uniform weight. As we can see from Fig. 2, StratLearner does not perform well under φ1.0 1.0. This is very intuitive as the searching space is too simple to ﬁnd a good scoring function. Second, we leak some information of the underlying model to φ1.0 0.1 and construct φ+
+ where the edge is selected with a probability of 1/dv, exactly the same as that in the underlying model, with edge weights sampled from their associated Weibull distributions. While φ+
+ is not obtainable under our learning setting, the goal here is to verify that StratLearner can beneﬁt more from such cheat subgraphs. Indeed, as shown in Fig. 2, StratLearner can produce the protector that is almost as good as the optimal one. With only 100 features from φ+
+, the performance ratio is no less than 0.95 on all three graphs. This conﬁrms that StratLearner does work the way it is supposed to, and it also suggests that such prior knowledge, if any, can be easily handled by StratLearner. 5 Further Discussions and