Abstract
Linear systems are the bedrock of virtually all numerical computation. Machine learning poses speciﬁc challenges for the solution of such systems due to their scale, characteristic structure, stochasticity and the central role of uncertainty in the ﬁeld. Unifying earlier work we propose a class of probabilistic linear solvers which jointly infer the matrix, its inverse and the solution from matrix-vector product observations. This class emerges from a fundamental set of desiderata which constrains the space of possible algorithms and recovers the method of conjugate gradients under certain conditions. We demonstrate how to incorporate prior spectral information in order to calibrate uncertainty and experimentally showcase the potential of such solvers for machine learning. 1

Introduction
Arguably one of the most fundamental problems in machine learning, statistics and scientiﬁc com-n putation at large is the solution of linear systems of the form Ax sym is a
× symmetric positive deﬁnite matrix [1–3]. Such matrices usually arise in the context of second-order or quadratic optimization problems and as Gram matrices. Some of the numerous application areas in machine learning and related ﬁelds are least-squares regression [4], kernel methods [5], Kalman
ﬁltering [6], Gaussian (process) inference [7], spectral graph theory [8], (linear) differential equations
[9] and (stochastic) second-order methods [10].
= b, where A
Rn
∈
∗
Linear systems in machine learning are typically large-scale, have characteristic structure arising from generative processes, and are subject to noise. These distinctive features call for linear solvers that can explicitly make use of such structural information. While classic solvers are highly optimized for general problems, they lack key functionality for machine learning. In particular, they do not consider generative prior information about the matrix.
An important example are kernel Gram matrices, which exhibit speciﬁc sparsity structure and spectral properties, depending on the kernel choice and the generative process of the data. Exploiting such prior information is a prime application for probabilistic linear solvers, which aim to quantify numerical uncertainty arising from limited computational resources. Another key challenge, which we will not yet address here, are noisy matrix evaluations arising from data subsampling. Ultimately, linear algebra for machine learning should integrate all sources of uncertainty in a computational pipeline – aleatoric, epistemic and numerical – into one coherent probabilistic framework.
Contribution This paper sets forth desiderata for probabilistic linear solvers which establish ﬁrst principles for such methods. From these, we derive an algorithm incorporating prior information 1, which jointly estimates both via repeated application of A. on the matrix A or its inverse A−
This results in posterior beliefs over the two operators and the solution which quantify numerical uncertainty. Our approach uniﬁes and extends earlier formulations and constitutes a new way of 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.
Figure 1: Illustration of a probabilistic linear solver. Given a prior for A or H modelling the linear 1, posterior beliefs are inferred via observations yi = Asi. This operator A and its inverse A− induces a distribution on the solution x
, quantifying numerical uncertainty arising from ﬁnite computation. The plot shows k = 3 iterations of Algorithm 1 on a toy problem of dimension n = 5.
∗ interpreting linear solvers. Further, we propose a prior covariance class which recovers the method of conjugate gradients as its posterior mean and uses prior spectral information for uncertainty calibration, one of the primary shortcomings of probabilistic linear solvers. We conclude by presenting simpliﬁed examples of promising applications of such solvers within machine learning. 2 Probabilistic Linear Solvers
∗
∗ n
∈
= b be a linear system with A
Rn. Probabilistic linear
Rn
Let Ax sym positive deﬁnite and b
× 1 or the solvers (PLS) [11–13] iteratively build a model for the linear operator A, its inverse H = A− solution x
, represented by random variables A, H or x. In the framework of probabilistic numerics
[14, 15] such solvers can be seen as Bayesian agents performing inference via linear observations k given by an internal
Y = [y1, . . . , yk] policy π(s
A, H, x, A, b). For a matrix-variate prior p(A) or p(H) encoding prior (generative) information, our solver computes posterior beliefs over the matrix, its inverse and the solution of the linear system. An illustration of a probabilistic linear solver is given in Figure 1. k resulting from actions S = [s1, . . . , sk]
Rn
Rn
∈
∈
∈
×
×
|
Desiderata We begin by stipulating a fundamental set of desiderata for probabilistic linear solvers.
To our knowledge such a list has not been collated before. Connecting previously disjoint threads, the following presents a roadmap for the development of these methods. Probabilistic linear solvers 1 must assume matrix-variate distributions which are expressive enough to modelling A and A− capture structure and generative prior information either for A or its inverse. The distribution choice must also allow computationally efﬁcient sampling and density evaluation. It should encode symmetry and positive deﬁniteness and must be closed under positive linear combinations. Further, the two models for the system matrix or its inverse should be translatable into and consistent with each other.
Actions si of a PLS should be model-based and induce a tractable distribution on linear observations yi = Asi. Since probabilistic linear solvers are low-level procedures, their inference procedure must be computationally lightweight. Given (noise-corrupted) observations this requires tractable posteriors over A, H and x, which are calibrated in the sense that at convergence the true solution x
∗ represents a draw from the posterior p(x
Y , S). Finally, such solvers need to allow preconditioning of the problem and ideally should return beliefs over non-linear properties of the system matrix extending the functionality of classic methods. These desiderata are summarized concisely in Table 1.
| 2.1 Bayesian Inference Framework
Guided by these desiderata, we will now outline the inference framework for A, H and x forming the base of the algorithm. The choice of a matrix-variate prior distribution is severely limited by the desideratum that conditioning on linear observations yi = Asi must be tractable. This reduces the choice to stable distributions [16] and thus excludes candidates such as the Wishart, which has measure zero outside the cone of symmetric positive semi-deﬁnite matrices. For symmetric matrices, this essentially forces use of the symmetric matrix-variate normal distribution, introduced in this n context by Hennig [11]. Given A0, W A sym , assume a prior distribution
×
Rn 0 ∈ p(A) =
N (A; A0, W A 0
W A 0 ), (cid:15)(cid:23) 2
Table 1: Desired properties of probabilistic linear solvers. Symbols ( properties are encoded in our proposed solver (see Algorithm 1) and to what degree.
, ∼,
) indicate which
No.
Property
Formulation (1) (2) (3) (4) (5) distribution over matrices symmetry positive deﬁniteness positive linear combination in same distribution family corresponding priors on the matrix and its inverse (6) model-based policy (7) matrix-vector product in tractable distribution family (8) (9) (10) noisy observations tractable posterior calibrated uncertainty (11) (12) preconditioning distributions over non-linear derived quantities of A
A
∼ D
A = A
= 0 : v(cid:124) v
∀
αj > 0 : (cid:80)
∀ p(A)
, pD(A) (cid:124) a.s.
Av > 0 a.s. j αjAj p(H)
∼ D si
π(s
←→
A, b, A, H, x)
∼ (cid:48)
|
As
A, S) =
Y , S) or p(H
∼ D
N (Y ; AS, Λ)
Y , S) (E[x], Cov[x])
| p(Y
| p(A
| x∗
∼ N (P −(cid:124)AP −1)P x∗ = P −(cid:124)b (cid:124)
L, . . . det(A), σ(A), A = L
∼
∼ (cid:15)(cid:23) denotes the symmetric Kronecker product [17].1 The symmetric matrix-variate Gaussian where induces a Gaussian distribution on linear observations. While it has non-zero measure only for symmetric matrices, its support is not the positive deﬁnite cone. However, positive deﬁniteness can still be enforced post-hoc (see Proposition 1). We assume noise-free linear observations of the form yi = Asi, leading to a Dirac likelihood p(Y
|
A, S) = lim
↓
ε 0 N (Y ; AS, ε2I
I) = δ(Y
AS).
− (cid:15) (cid:124)
S, Y ) = (A; Ak, Σk) with
The posterior distribution follows from the properties of Gaussians [4] and has been investigated in detail in previous work [18, 11, 13]. It is given by p(A
Ak = A0 + ∆A 0 U
Σk = W A 0 (In −
| (cid:124)
+ U (∆A 0 )
U S
− (cid:124)
W A 0 (In − 1. We aim to construct a probabilistic model where ∆A 1 consistent with the model A as well. However, not even in the
H for the inverse H = A− scalar case does the inverse of a Gaussian have ﬁnite mean. We ask instead what Gaussian model for H is as consistent as possible with our observational model for A. For a prior of the form (H; H0, W H
HY ), we analogously to the p(H) = 0
A-model obtain a posterior distribution p(H
N (cid:124)∆A 0 U (cid:124)
) 0 ) and likelihood p(S
A0S and U = W A 0 S(S(cid:124)W A (cid:15)(cid:23) 0 S)−
H, Y ) = δ(S
S, Y ) = 0 = Y
W H
SU
SU
N (cid:15)(cid:23)
−
) (cid:124)
|
Hk = H0 + ∆H
ΣH 0 (In − k = W H (cid:124) 0 (U H)
N
| (cid:124)
+ U H(∆H 0 )
− (cid:124)
W H
Y (U H) 0 (In −
) (cid:15)(cid:23) 0 Y (Y (cid:124)W H
− (H; Hk, ΣH k ) with (cid:124) (cid:124)∆H 0 (U H) (cid:124)
)
U HY
Y (U H) 0 = S 1. In Section 3 we will derive a covariance where ∆H class, which establishes correspondence between the two Gaussian viewpoints for the linear operator and its inverse and is consistent with our desiderata.
H0Y and U H = W H 0 Y )−
− 2.2 Algorithm
The above inference procedure leads to Algorithm 1. The degree to which the desiderata are encoded in our formulation of a PLS can be found in Table 1. We will now go into more detail about the policy, the choice of step size, stopping criteria and the implementation.
Policy and Step Size via actions si determined by the policy π(s
In each iteration our solver collects information about the linear operator A 1 is
A, H, x, A, b). The next action si =
E[H]ri
|
−
− 1See Sections S2 and S3 of the supplementary material for more detail on Kronecker-type products and matrix-variate normal distributions. 3 (cid:54)
Algorithm 1: Probabilistic Linear Solver with Uncertainty Calibration ri(cid:107)2) > max(δrtol (cid:107) 7 6 4 3 5 1 x0 ← r0 ← while min( b tr(Cov[x]),
E[H]ri 1 procedure PROBLINSOLVE(A(
), b, A, H)
·
E[H]b 2
Ax0 − (cid:112) si ← −
Asi yi ← (cid:124) (cid:124) i ri i yi)− 1(s s
αi ← −
− xi 1 + αisi xi ←
− 1 + αiyi ri ri ←
INFER(A, si, yi)
A
←
INFER(H, si, yi)
H
←
Φ, Ψ (xk, Cov[Hb])
CALIBRATE(S, Y )
←
−
− 1 8 9 x return (x, A, H)
← N 10 11 12 13 14
# prior for A or H
# initial guess b (cid:107) (cid:107)2, δatol) do
# stopping criteria
# compute action via policy
# make observation
# optimal step size
# update solution estimate
# update residual
# infer posterior distributions
# (see Section 2.1)
# calibrate uncertainty
# belief over solution chosen based on the current belief about the inverse. If E[H] = A− the inverse equals the true inverse, then Algorithm 1 converges in a single step since 1, i.e. if the solver’s estimate for xi 1 + si = xi
E[H]ri 1 = xi
−
−
The step size minimizing the quadratic q(xi + αsi) = 1 (cid:124) along the action si is given by αi = arg minα q(xi + αsi) = s i (b
−
− b) = A− 1(Axi
A− 1 −
− 2 (xi + αsi)(cid:124)A(xi + αsi)
−
− (cid:124) i Asi)−
Axi)(s 1b = x
∗ b(cid:124)(xi + αsi) 1.
. 1 − 1 − (cid:107) (cid:107) b
∗ − (cid:107)2 ≤ max(δrtol
Axi −
Stopping Criteria Classic linear solvers typically use stopping criteria based on the current residual (cid:107)2, δatol) for relative and absolute tolerances δrtol and δatol. of the form b
However, this residual may oscillate or even increase in all but the last step even if the error xi(cid:107)2 is monotonically decreasing [19, 20]. From a probabilistic point of view, we should stop x (cid:107) if our posterior uncertainty is sufﬁciently small. Assuming the posterior covariance is calibrated, it 2 (cid:107)2])2 2] = tr(Cov[x]). Hence given calibration, we holds that (Ex∗ [ x
E[x] (cid:107) (cid:107) can bound the expected (relative) error between our estimate and the true solution by terminating when (cid:112) (cid:107)2, δatol). A probabilistic criterion is also necessary for an extension to b the noisy setting, where classic convergence criteria become stochastic. However, probabilistic linear solvers typically suffer from miscalibration [21], an issue we will address in Section 3. tr(Cov[x]) max(δrtol
Ex∗ [
E[x] x (cid:107)
∗ −
∗ −
≤
≤ (cid:107)
Implementation We provide an open-source implementation of Algorithm 1 as part of PROBNUM, a Python package implementing probabilistic numerical methods, in an online code repository: https://github.com/probabilistic-numerics/probnum
The mean and covariance up- and downdates in Section 2.1 when performed iteratively are of low rank. In order to maintain numerical stability these updates can instead be performed for their respective Cholesky factors [22]. This also enables computationally efﬁcient sampling or evaluation of probability density functions downstream. 2.3 Theoretical Properties
This section details some theoretical properties of our method such as its convergence behavior and computational complexity. In particular we demonstrate that for a speciﬁc prior choice Algorithm 1 recovers the method of conjugate gradients as its solution estimate. All proofs of results in this section and the next can be found in the supplementary material. We begin by establishing that our solver is a conjugate directions method and therefore converges in at most n steps in exact arithmetic.
Theorem 1 (Conjugate Directions Method)
Given a prior p(H) = actions si of Algorithm 1 are A-conjugate, i.e. for 0 (H; H0, W H 0
W H
N (cid:15)(cid:23) 0 ) such that H0, W H i, j 0 ∈ k with i
≤
≤ n
Rn sym positive deﬁnite, then
× (cid:124) i Asj = 0.
= j it holds that s 4 (cid:54)
We can obtain a better convergence rate by placing stronger conditions on the prior covariance class as outlined in Section 3. Given these assumptions, Algorithm 1 recovers the iterates of (preconditioned)
CG and thus inherits its favorable convergence behavior (overviews in [23, 10]).
Theorem 2 (Connection to the Conjugate Gradient Method)
Given a scalar prior mean A0 = H − xi of Algorithm 1 are identical to the ones produced by the conjugate gradient method. 0 = αI with α > 0, assume (1) and (2) hold, then the iterates 1
A common phenomenon observed when implementing conjugate gradient methods is that due to cancellation in the computation of the residuals, the search directions si lose A-conjugacy [24, 25, 3].
In fact, they can become independent up to working precision for i large enough [25]. One way to combat this is to perform complete reorthogonalization of the search directions in each iteration as originally suggested by Lanczos [26]. Algorithm 1 does this implicitly via its choice of policy which depends on all previous search directions as opposed to just si 1 for (naive) CG.
− (kn2) for k iterations without
Computational Complexity The solver has time complexity uncertainty calibration. Compared to CG, inferring the posteriors in Section 2.1 adds an overhead of four outer products and four matrix-vector products per iteration, given (1) and (2). Uncertainty (k3) per iteration depending on the calibration outlined in Section 3 adds between
O sophistication of the scheme. Already for moderate n this is dominated by the iteration cost. In practice, means and covariances do not need to be formed in memory. Instead they can be evaluated (kn). lazily as linear operators v
Lv, if S and Y are stored. This results in space complexity (1) and
O
O (cid:55)→
O 2.4