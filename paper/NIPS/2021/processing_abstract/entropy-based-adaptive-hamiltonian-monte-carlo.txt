Hamiltonian Monte Carlo (HMC) is a popular Markov Chain Monte Carlo (MCMC) algorithm to sample from an unnormalized probability distribution. A leapfrog integrator is commonly used to implement HMC in practice, but its per-formance can be sensitive to the choice of mass matrix used therein. We develop a gradient-based algorithm that allows for the adaptation of the mass matrix by encouraging the leapfrog integrator to have high acceptance rates while also ex-ploring all dimensions jointly. In contrast to previous work that adapt the hyper-parameters of HMC using some form of expected squared jumping distance, the adaptation strategy suggested here aims to increase sampling efﬁciency by maxi-mizing an approximation of the proposal entropy. We illustrate that using multiple gradients in the HMC proposal can be beneﬁcial compared to a single gradient-step in Metropolis-adjusted Langevin proposals. Empirical evidence suggests that the adaptation method can outperform different versions of HMC schemes by ad-justing the mass matrix to the geometry of the target distribution and by providing some control on the integration time. 