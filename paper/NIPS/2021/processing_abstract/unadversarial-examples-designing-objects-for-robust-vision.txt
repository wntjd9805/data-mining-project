We study a class of computer vision settings wherein one can modify the de-sign of the objects being recognized. We develop a framework that leverages this capability—and deep networks’ unusual sensitivity to input perturbations—to de-sign “robust objects,” i.e., objects that are explicitly optimized to be conﬁdently classiﬁed. Our framework yields improved performance on standard benchmarks, a simulated robotics environment, and physical-world experiments.1 