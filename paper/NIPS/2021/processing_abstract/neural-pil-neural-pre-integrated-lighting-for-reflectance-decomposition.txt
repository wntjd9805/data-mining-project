Decomposing a scene into its shape, reﬂectance and illumination is a fundamen-tal problem in computer vision and graphics. Neural approaches such as NeRF have achieved remarkable success in view synthesis, but do not explicitly per-form decomposition and instead operate exclusively on radiance (the product of reﬂectance and illumination). Extensions to NeRF, such as NeRD, can perform decomposition but struggle to accurately recover detailed illumination, thereby signiﬁcantly limiting realism. We propose a novel reﬂectance decomposition network that can estimate shape, BRDF and per-image illumination given a set of object images captured under varying illumination. Our key technique is a novel illumination integration network called Neural-PIL that replaces a costly illumination integral operation in the rendering with a simple network query. In addition, we also learn deep low-dimensional priors on BRDF and illumination representations using novel smooth manifold auto-encoders. Our decompositions can result in considerably better BRDF and light estimates enabling more ac-curate novel view-synthesis and relighting compared to prior art. Project page: https://markboss.me/publication/2021-neural-pil/ 