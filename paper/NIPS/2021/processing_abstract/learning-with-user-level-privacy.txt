We propose and analyze algorithms to solve a range of learning tasks under user-level differential privacy constraints. Rather than guaranteeing only the privacy of individual samples, user-level DP protects a user’s entire contribution (m ≥ 1 samples), providing more stringent but more realistic protection against informa-tion leaks. We show that for high-dimensional mean estimation, empirical risk minimization with smooth losses, stochastic convex optimization, and learning hy-pothesis classes with ﬁnite metric entropy, the privacy cost decreases as O(1/ m) as users provide more samples. In contrast, when increasing the number of users n, the privacy cost decreases at a faster O(1/n) rate. We complement these results with lower bounds showing the minimax optimality of our algorithms for mean estimation and stochastic convex optimization. Our algorithms rely on novel tech-niques for private mean estimation in arbitrary dimension with error scaling as the concentration radius τ of the distribution rather than the entire range.√ 