Variational Autoencoders (VAEs) are powerful probabilistic models to learn rep-resentations of complex data distributions. One important limitation of VAEs is the strong prior assumption that latent representations learned by the model follow a simple uni-modal Gaussian distribution. Further, the variational training procedure poses considerable practical challenges. Recently proposed regular-ized autoencoders offer a deterministic autoencoding framework, that simpliﬁes the original VAE objective and is signiﬁcantly easier to train. Since these mod-els only provide weak control over the learned latent distribution, they require an ex-post density estimation step to generate samples comparable to those ofVAEs. In this paper, we propose a simple and end-to-end trainable deterministic autoencoding framework, that efﬁciently shapes the latent space of the model during training and utilizes the capacity of expressive multi-modal latent distri-butions. The proposed training procedure provides direct evidence if the latent distribution adequately captures complex aspects of the encoded data. We show in experiments the expressiveness and sample quality of our model in various challenging continuous and discrete domains. An implementation is available at https://github.com/boschresearch/GMM_DAE. 