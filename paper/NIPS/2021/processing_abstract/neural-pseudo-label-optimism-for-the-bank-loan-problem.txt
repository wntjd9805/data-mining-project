We study a class of classiﬁcation problems best exempliﬁed by the bank loan problem, where a lender decides whether or not to issue a loan. The lender only observes whether a customer will repay a loan if the loan is issued to begin with, and thus modeled decisions affect what data is available to the lender for future decisions. As a result, it is possible for the lender’s algorithm to “get stuck” with a self-fulﬁlling model. This model never corrects its false negatives, since it never sees the true label for rejected data, thus accumulating inﬁnite regret.In the case of linear models, this issue can be addressed by adding optimism directly into the model predictions. However, there are few methods that extend to the function approximation case using Deep Neural Networks. We present Pseudo-Label Optimism (PLOT), a conceptually and computationally simple method for this setting applicable to DNNs. PLOT adds an optimistic label to the subset of decision points the current model is deciding on, trains the model on all data so far (including these points along with their optimistic labels), and ﬁnally uses the resulting optimistic model for decision making. PLOT achieves competitive performance on a set of three challenging benchmark problems, requiring minimal hyperparameter tuning. We also show that PLOT satisﬁes a logarithmic regret guarantee, under a Lipschitz and logistic mean label model, and under a separability condition on the data. 