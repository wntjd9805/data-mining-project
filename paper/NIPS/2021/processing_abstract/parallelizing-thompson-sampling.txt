How can we make use of information parallelism in online decision making prob-lems while efﬁciently balancing the exploration-exploitation trade-off? In this paper, we introduce a batch Thompson Sampling framework for two canonical online decision making problems, namely, stochastic multi-arm bandit and lin-ear contextual bandit with ﬁnitely many arms. Over a time horizon T , our batchThompson Sampling policy achieves the same (asymptotic) regret bound of a fully sequential one while carrying out only O(log T ) batch queries. To achieve this ex-ponential reduction, i.e., reducing the number of interactions from T to O(log T ), our batch policy dynamically determines the duration of each batch in order to bal-ance the exploration-exploitation trade-off. We also demonstrate experimentally that dynamic batch allocation dramatically outperforms natural baselines such as static batch allocations. 