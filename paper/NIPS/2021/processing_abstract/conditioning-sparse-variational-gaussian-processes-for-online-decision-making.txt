OWith a principled representation of uncertainty and closed form posterior updates,Gaussian processes (GPs) are a natural choice for online decision making. However, (n2) computations for n trainingGaussian processes typically require at least points, limiting their general applicability. Stochastic variational Gaussian pro-cesses (SVGPs) can provide scalable inference for a dataset of ﬁxed size, but are difﬁcult to efﬁciently condition on new data. We propose online variational conditioning (OVC), a procedure for efﬁciently conditioning SVGPs in an online setting that does not require re-training through the evidence lower bound with the addition of new data. OVC enables the pairing of SVGPs with advanced look-ahead acquisition functions for black-box optimization, even with non-Gaussian likelihoods. We show OVC provides compelling performance in a range of applica-tions including active learning of malaria incidence, and reinforcement learning onMuJoCo simulated robotic control tasks. 