Implicit neural representations are a promising new avenue of representing gen-eral signals by learning a continuous function that, parameterized as a neural net-work, maps the domain of a signal to its codomain; the mapping from spatial coordinates of an image to its pixel values, for example. Being capable of convey-ing ﬁne details in a high dimensional signal, unboundedly of its domain, implicit neural representations ensure many advantages over conventional discrete repre-sentations. However, the current approach is difﬁcult to scale for a large number of signals or a data set, since learning a neural representation—which is parameter heavy by itself—for each signal individually requires a lot of memory and com-putations. To address this issue, we propose to leverage a meta-learning approach in combination with network compression under a sparsity constraint, such that it renders a well-initialized sparse parameterization that evolves quickly to represent a set of unseen signals in the subsequent training. We empirically demonstrate that meta-learned sparse neural representations achieve a much smaller loss than dense meta-learned models with the same number of parameters, when trained to ﬁt each signal using the same number of optimization steps. 