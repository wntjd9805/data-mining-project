Contrastive learning (CL) can learn generalizable feature representations and achieve state-of-the-art performance of downstream tasks by ﬁnetuning a linear classiﬁer on top of it. However, as adversarial robustness becomes vital in image classiﬁcation, it remains unclear whether or not CL is able to preserve robustness to downstream tasks. The main challenge is that in the ‘self-supervised pretraining+ supervised ﬁnetuning’ paradigm, adversarial robustness is easily forgotten due to a learning task mismatch from pretraining to ﬁnetuning. We call such challenge‘cross-task robustness transferability’. To address the above problem, in this paper we revisit and advance CL principles through the lens of robustness enhancement.We show that (1) the design of contrastive views matters: High-frequency com-ponents of images are beneﬁcial to improving model robustness; (2) AugmentingCL with pseudo-supervision stimulus (e.g., resorting to feature clustering) helps preserve robustness without forgetting. Equipped with our new designs, we pro-pose ADVCL, a novel adversarial contrastive pretraining framework. We show thatADVCL is able to enhance cross-task robustness transferability without loss of model accuracy and ﬁnetuning efﬁciency. With a thorough experimental study, we demonstrate that ADVCL outperforms the state-of-the-art self-supervised robust learning methods across multiple datasets (CIFAR-10, CIFAR-100 and STL-10) and ﬁnetuning schemes (linear evaluation and full model ﬁnetuning). Code is available at https://github.com/LijieFan/AdvCL. 