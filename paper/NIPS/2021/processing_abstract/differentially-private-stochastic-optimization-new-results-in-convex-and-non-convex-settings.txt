log d nεWe study differentially private stochastic optimization in convex and non-convex settings. For the convex case, we focus on the family of non-smooth generalized linear losses (GLLs). Our algorithm for the ℓ2 setting achieves optimal excess population risk in near-linear time, while the best known differentially private algorithms for general convex losses run in super-linear time. Our algorithm for theℓ1 setting has nearly-optimal excess population risk ˜O, and circumvents the dimension dependent lower bound of [AFKT21] for general non-smooth convex losses. In the differentially private non-convex setting, we provide several new algorithms for approximating stationary points of the population risk. For theℓ1-case with smooth losses and polyhedral constraint, we provide the ﬁrst nearly dimension independent rate, ˜O in linear time. For the constrained ℓ2-case with smooth losses, we obtain a linear-time algorithm with rate ˜O. (cid:0)Finally, for the ℓ2-case we provide the ﬁrst method for non-smooth weakly convex (cid:0) (cid:1) stochastic optimization with rate ˜O n1/4 + d which matches the best existing non-private algorithm when d = O(√n). We also extend all our results above for the non-convex ℓ2 setting to the ℓp setting, where 1 < p 2, with only polylogarithmic (in the dimension) overhead in the rates. n1/3 + d 2/3 d log (nε)1/3 1/6 (nε)1/3 1/5 (nε)2/5 (cid:0)q≤ (cid:1) (cid:0) (cid:1) (cid:1) 1 1 