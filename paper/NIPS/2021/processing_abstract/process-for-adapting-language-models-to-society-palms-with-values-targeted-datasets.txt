Language models can generate harmful and biased outputs and exhibit un-desirable behavior according to a given cultural context. We propose aProcess for Adapting Language Models to Society (PALMS) with Values-Targeted Datasets, an iterative process to signiﬁcantly change model behav-ior by crafting and ﬁne-tuning on a dataset that reﬂects a predetermined set of target values. We evaluate our process using three metrics: quantitative metrics with human evaluations that score output adherence to a target value, toxicity scoring on outputs; and qualitative metrics analyzing the most common word associated with a given social category. Through each iteration, we add additional training dataset examples based on observed shortcomings from evaluations. PALMS performs signiﬁcantly better on all metrics compared to baseline and control models for a broad range ofGPT-3 language model sizes without compromising capability integrity. Weﬁnd that the eﬀectiveness of PALMS increases with model size. We show that signiﬁcantly adjusting language model behavior is feasible with a small, hand-curated dataset. 