When data are scarce, meta-learning can improve a learner’s accuracy by harness-ing previous experience from related learning tasks. However, existing methods have unreliable uncertainty estimates which are often overconﬁdent. Addressing these shortcomings, we introduce a novel meta-learning framework, calledF-PACOH, that treats meta-learned priors as stochastic processes and performs meta-level regularization directly in the function space. This allows us to directly steer the probabilistic predictions of the meta-learner towards high epistemic uncer-tainty in regions of insufﬁcient meta-training data and, thus, obtain well-calibrated uncertainty estimates. Finally, we showcase how our approach can be integrated with sequential decision making, where reliable uncertainty quantiﬁcation is imper-ative. In our benchmark study on meta-learning for Bayesian Optimization (BO),F-PACOH signiﬁcantly outperforms all other meta-learners and standard baselines. 