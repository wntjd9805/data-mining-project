The ability to form complex plans based on raw visual input is a litmus test for current capabilities of artiﬁcial intelligence, as it requires a seamless combination of visual processing and abstract algorithmic execution, two traditionally separate areas of computer science. A recent surge of interest in this ﬁeld brought advances that yield good performance in tasks ranging from arcade games to continuous control; these methods however do not come without signiﬁcant issues, such as limited generalization capabilities and difﬁculties when dealing with combina-torially hard planning instances. Our contribution is two-fold: (i) we present a method that learns to represent its environment as a latent graph and leverages state reidentiﬁcation to reduce the complexity of ﬁnding a good policy from exponential to linear (ii) we introduce a set of lightweight environments with an underlying discrete combinatorial structure in which planning is challenging even for humans.Moreover, we show that our methods achieves strong empirical generalization to variations in the environment, even across highly disadvantaged regimes, such as“one-shot” planning, or in an ofﬂine RL paradigm which only provides low-quality trajectories.Figure 1: Planning from Pixels with Graph Search. Our method leverages learned latent dynamics to efﬁciently build and search a graph representation of the environment. Resulting policies show unrivaled performance across a distribution of hard combinatorial tasks. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).