We propose a novel cost aggregation network, called Cost Aggregation Transform-ers (CATs), to ﬁnd dense correspondences between semantically similar images with additional challenges posed by large intra-class appearance and geometric variations. Cost aggregation is a highly important process in matching tasks, which the matching accuracy depends on the quality of its output. Compared to hand-crafted or CNN-based methods addressing the cost aggregation, in that either lacks robustness to severe deformations or inherit the limitation of CNNs that fail to discriminate incorrect matches due to limited receptive ﬁelds, CATs explore global consensus among initial correlation map with the help of some architectural de-signs that allow us to fully leverage self-attention mechanism. Speciﬁcally, we include appearance afﬁnity modeling to aid the cost aggregation process in order to disambiguate the noisy initial correlation maps and propose multi-level aggregation to efﬁciently capture different semantics from hierarchical feature representations.We then combine with swapping self-attention technique and residual connections not only to enforce consistent matching, but also to ease the learning process, which we ﬁnd that these result in an apparent performance boost. We conduct experiments to demonstrate the effectiveness of the proposed model over the latest methods and provide extensive ablation studies. Code and trained models are available at https://sunghwanhong.github.io/CATs/. 