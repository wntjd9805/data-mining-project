As predictive models are increasingly being deployed in high-stakes decision mak-ing (e.g., loan approvals), there has been growing interest in post-hoc techniques which provide recourse to affected individuals. These techniques generate re-courses under the assumption that the underlying predictive model does not change.However, in practice, models are often regularly updated for a variety of reasons (e.g., dataset shifts), thereby rendering previously prescribed recourses ineffective.To address this problem, we propose a novel framework, RObust AlgorithmicRecourse (ROAR), that leverages adversarial training for ﬁnding recourses that are robust to model shifts. To the best of our knowledge, this work proposes theﬁrst ever solution to this critical problem. We also carry out theoretical analysis which underscores the importance of constructing recourses that are robust to model shifts: 1) We quantify the probability of invalidation for recourses generated without accounting for model shifts. 2) We prove that the additional cost incurred due to the robust recourses output by our framework is bounded. Experimental evaluation on multiple synthetic and real-world datasets demonstrates the efﬁcacy of the proposed framework. 