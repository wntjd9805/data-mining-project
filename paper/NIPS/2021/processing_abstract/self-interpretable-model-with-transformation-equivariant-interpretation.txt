With the proliferation of machine learning applications in the real world, the de-mand for explaining machine learning predictions continues to grow especially in high-stakes ﬁelds. Recent studies have found that interpretation methods can be sensitive and unreliable, where the interpretations can be disturbed by per-turbations or transformations of input data. To address this issue, we propose to learn robust interpretations through transformation equivariant regularization in a self-interpretable model. The resulting model is capable of capturing valid interpretations that are equivariant to geometric transformations. Moreover, since our model is self-interpretable, it enables faithful interpretations that reﬂect the true predictive mechanism. Unlike existing self-interpretable models, which usu-ally sacriﬁce expressive power for the sake of interpretation quality, our model preserves the high expressive capability comparable to the state-of-the-art deep learning models in complex tasks, while providing visualizable and faithful high-quality interpretation. We compare with various related methods and validate the interpretation quality and consistency of our model. 