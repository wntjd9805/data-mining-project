We develop scalable methods for producing conformal Bayesian predictive in-tervals with ﬁnite sample calibration guarantees. Bayesian posterior predictive distributions, p(y | x), characterize subjective beliefs on outcomes of interest, y, conditional on predictors, x. Bayesian prediction is well-calibrated when the model is true, but the predictive intervals may exhibit poor empirical coverage when the model is misspeciﬁed, under the so called M-open perspective. In contrast, conformal inference provides ﬁnite sample frequentist guarantees on predictive conﬁdence intervals without the requirement of model ﬁdelity. Using ‘add-one-in’ importance sampling, we show that conformal Bayesian predictive intervals are efﬁciently obtained from re-weighted posterior samples of model parameters. Our approach contrasts with existing conformal methods that require expensive reﬁtting of models or data-splitting to achieve computational efﬁciency. We demonstrate the utility on a range of examples including extensions to partially exchangeable settings such as hierarchical models. 