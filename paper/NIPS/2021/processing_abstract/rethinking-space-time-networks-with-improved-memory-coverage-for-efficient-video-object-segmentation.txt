This paper presents a simple yet effective approach to modeling space-time cor-respondences in the context of video object segmentation. Unlike most existing approaches, we establish correspondences directly between frames without re-encoding the mask features for every object, leading to a highly efﬁcient and robust framework. With the correspondences, every node in the current query frame is inferred by aggregating features from the past in an associative fashion. We cast the aggregation process as a voting problem and ﬁnd that the existing inner-product afﬁnity leads to poor use of memory with a small (ﬁxed) subset of memory nodes dominating the votes, regardless of the query. In light of this phenomenon, we propose using the negative squared Euclidean distance instead to compute the afﬁnities. We validate that every memory node now has a chance to contribute, and experimentally show that such diversiﬁed voting is beneﬁcial to both memory efﬁciency and inference accuracy. The synergy of correspondence networks and diversiﬁed voting works exceedingly well, achieves new state-of-the-art results on both DAVIS and YouTubeVOS datasets while running signiﬁcantly faster at 20+FPS for multiple objects without bells and whistles. 