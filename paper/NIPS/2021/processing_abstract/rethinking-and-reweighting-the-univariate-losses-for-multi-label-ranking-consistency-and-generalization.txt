The (partial) ranking loss is a commonly used evaluation measure for multi-label classiﬁcation, which is usually optimized with convex surrogates for computational efﬁciency. Prior theoretical efforts on multi-label ranking mainly focus on (Fisher) consistency analyses. However, there is a gap between existing theory and practice— some inconsistent pairwise losses can lead to promising performance, while some consistent univariate losses usually have no clear superiority in practice. To take a step towards ﬁlling up this gap, this paper presents a systematic study from two complementary perspectives of consistency and generalization error bounds of learning algorithms. We theoretically ﬁnd two key factors of the distribution (or dataset) that affect the learning guarantees of algorithms: the instance-wise class imbalance and the label size c. Speciﬁcally, in an extremely imbalanced case, the algorithm with the consistent univariate loss has an error bound of O(c), while c) as shown in prior the one with the inconsistent pairwise loss depends on O( work. This may shed light on the superior performance of pairwise methods in practice, where real datasets are usually highly imbalanced. Moreover, we present an inconsistent reweighted univariate loss-based algorithm that enjoys an error bound of O( c) for promising performance as well as the computational efﬁciency of univariate losses. Finally, experimental results conﬁrm our theoretical ﬁndings.√√ 