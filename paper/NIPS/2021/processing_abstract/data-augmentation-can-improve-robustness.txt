Adversarial training suffers from robust overﬁtting, a phenomenon where the robust test accuracy starts to decrease during training. In this paper, we focus on reducing robust overﬁtting by using common data augmentation schemes. We demonstrate that, contrary to previous ﬁndings, when combined with model weight averaging, data augmentation can signiﬁcantly boost robust accuracy. Furthermore, we com-pare various data augmentations techniques and observe that spatial composition techniques work best for adversarial training. Finally, we evaluate our approach on CIFAR-10 against (cid:96)∞ and (cid:96)2 norm-bounded perturbations of size (cid:15) = 8/255 and (cid:15) = 128/255, respectively. We show large absolute improvements of +2.93% and +2.16% in robust accuracy compared to previous state-of-the-art methods. In particular, against (cid:96)∞ norm-bounded perturbations of size (cid:15) = 8/255, our model reaches 60.07% robust accuracy without using any external data. We also achieve a signiﬁcant performance boost with this approach while using other architectures and datasets such as CIFAR-100, SVHN and TINYIMAGENET. 