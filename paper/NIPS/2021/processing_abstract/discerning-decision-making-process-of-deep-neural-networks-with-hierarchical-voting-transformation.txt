Neural network based deep learning techniques have shown great success for numerous applications. While it is expected to understand their intrinsic decision-making processes, these deep neural networks often work in a black-box way. To this end, in this paper, we aim to discern the decision-making processes of neural networks through a hierarchical voting strategy by developing an explainable deep learning model, namely Voting Transformation-based Explainable Neural Net-work (VOTEN). Speciﬁcally, instead of relying on massive feature combinations,VOTEN creatively models expressive single-valued voting functions between ex-plicitly modeled latent concepts to achieve high ﬁtting ability. Along this line, weﬁrst theoretically analyze the major components of VOTEN and prove the relation-ship and advantages of VOTEN compared with Multi-Layer Perceptron (MLP), the basic structure of deep neural networks. Moreover, we design efﬁcient algorithms to improve the model usability by explicitly showing the decision processes ofVOTEN. Finally, extensive experiments on multiple real-world datasets clearly validate the performances and explainability of VOTEN. 