Image classiﬁcation models tend to make decisions based on peripheral attributes of data items that have strong correlation with a target variable (i.e., dataset bias).These biased models suffer from the poor generalization capability when evalu-ated on unbiased datasets. Existing approaches for debiasing often identify and emphasize those samples with no such correlation (i.e., bias-conﬂicting) without deﬁning the bias type in advance. However, such bias-conﬂicting samples are signiﬁcantly scarce in biased datasets, limiting the debiasing capability of these approaches. This paper ﬁrst presents an empirical analysis revealing that training with “diverse” bias-conﬂicting samples beyond a given training set is crucial for debiasing as well as the generalization capability. Based on this observation, we propose a novel feature-level data augmentation technique in order to synthesize diverse bias-conﬂicting samples. To this end, our method learns the disentangled representation of (1) the intrinsic attributes (i.e., those inherently deﬁning a certain class) and (2) bias attributes (i.e., peripheral attributes causing the bias), from a large number of bias-aligned samples, the bias attributes of which have strong correlation with the target variable. Using the disentangled representation, we synthesize bias-conﬂicting samples that contain the diverse intrinsic attributes of bias-aligned samples by swapping their latent features. By utilizing these diversiﬁed bias-conﬂicting features during the training, our approach achieves superior classi-ﬁcation accuracy and debiasing results against the existing baselines on synthetic and real-world datasets. 