We can compress a rectiﬁer network while exactly preserving its underlying func-tionality with respect to a given input domain if some of its neurons are stable.However, current approaches to determine the stability of neurons with RectiﬁedLinear Unit (ReLU) activations require solving or ﬁnding a good approximation to multiple discrete optimization problems. In this work, we introduce an algorithm based on solving a single optimization problem to identify all stable neurons. Our approach is on median 183 times faster than the state-of-art method on CIFAR-10, which allows us to explore exact compression on deeper (5 × 100) and wider (2 × 800) networks within minutes. For classiﬁers trained under an amount of (cid:96)1 regularization that does not worsen accuracy, we can remove up to 56% of the connections on CIFAR-10 dataset. The code is available at the following link, https://github.com/yuxwind/ExactCompression. 