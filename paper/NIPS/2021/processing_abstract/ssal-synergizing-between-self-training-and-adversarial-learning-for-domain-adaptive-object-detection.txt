We study adapting trained object detectors to unseen domains manifesting signiﬁ-cant variations of object appearance, viewpoints and backgrounds. Most current methods align domains by either using image or instance-level feature alignment in an adversarial fashion. This often suffers due to the presence of unwanted background and as such lacks class-speciﬁc alignment. A common remedy to pro-mote class-level alignment is to use high conﬁdence predictions on the unlabelled domain as pseudo labels. These high conﬁdence predictions are often fallacious since the model is poorly calibrated under domain shift. In this paper, we propose to leverage model’s predictive uncertainty to strike the right balance between ad-versarial feature alignment and class-level alignment. Speciﬁcally, we measure predictive uncertainty on class assignments and the bounding box predictions.Model predictions with low uncertainty are used to generate pseudo-labels for self-supervision, whereas the ones with higher uncertainty are used to generate tiles for an adversarial feature alignment stage. This synergy between tiling around the uncertain object regions and generating pseudo-labels from highly certain object regions allows us to capture both the image and instance level context during the model adaptation stage. We perform extensive experiments covering various do-main shift scenarios. Our approach improves upon existing state-of-the-art methods with visible margins. 