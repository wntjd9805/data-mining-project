Compressive phase retrieval is a popular variant of the standard compressive sensing problem in which the measurements only contain magnitude information.In this paper, motivated by recent advances in deep generative models, we provide recovery guarantees with near-optimal sample complexity for phase retrieval with generative priors. We ﬁrst show that when using i.i.d. Gaussian measurements and an L-Lipschitz continuous generative model with bounded k-dimensional inputs, roughly O(k log L) samples sufﬁce to guarantee that any signal minimizing an amplitude-based empirical loss function is close to the true signal. Attaining this sample complexity with a practical algorithm remains a difﬁcult challenge, andﬁnding a good initialization for gradient-based methods has been observed to pose a major bottleneck. To partially address this, we further show that roughly O(k log L) samples ensure sufﬁcient closeness between the underlying signal and any globally optimal solution to an optimization problem designed for spectral initialization (though ﬁnding such a solution may still be challenging). We also adapt this result to sparse phase retrieval, and show that O(s log n) samples are sufﬁcient for a similar guarantee when the underlying signal is s-sparse and n-dimensional, matching an information-theoretic lower bound. While these guarantees do not directly correspond to a practical algorithm, we propose a practical spectral initialization method motivated by our ﬁndings, and experimentally observe performance gains over various existing spectral initialization methods for sparse phase retrieval. 