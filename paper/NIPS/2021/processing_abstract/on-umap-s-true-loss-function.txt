UMAP has supplanted t-SNE as state-of-the-art for visualizing high-dimensional datasets in many disciplines, but the reason for its success is not well understood.In this work, we investigate UMAP’s sampling based optimization scheme in detail.We derive UMAP’s true loss function in closed form and ﬁnd that it differs from the published one in a dataset size dependent way. As a consequence, we show that UMAP does not aim to reproduce its theoretically motivated high-dimensionalUMAP similarities. Instead, it tries to reproduce similarities that only encode the k nearest neighbor graph, thereby challenging the previous understanding ofUMAP’s effectiveness. Alternatively, we consider the implicit balancing of attrac-tion and repulsion due to the negative sampling to be key to UMAP’s success. We corroborate our theoretical ﬁndings on toy and single cell RNA sequencing data. 