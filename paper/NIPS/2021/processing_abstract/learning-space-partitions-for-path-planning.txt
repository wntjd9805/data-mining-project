Path planning, the problem of efﬁciently discovering high-reward trajectories, often requires optimizing a high-dimensional and multimodal reward function. Pop-ular approaches like CEM [37] and CMA-ES [16] greedily focus on promising regions of the search space and may get trapped in local maxima. DOO [31] andVOOT [22] balance exploration and exploitation, but use space partitioning strate-gies independent of the reward function to be optimized. Recently, LaMCTS [45] empirically learns to partition the search space in a reward-sensitive manner for black-box optimization. In this paper, we develop a novel formal regret analysis for when and why such an adaptive region partitioning scheme works. We also propose a new path planning method LaP3 which improves the function value estimation within each sub-region, and uses a latent representation of the search space. Empir-ically, LaP3 outperforms existing path planning methods in 2D navigation tasks, especially in the presence of difﬁcult-to-escape local optima, and shows beneﬁts when plugged into the planning components of model-based RL such as PETS [7].These gains transfer to highly multimodal real-world tasks, where we outperform strong baselines in compiler phase ordering by up to 39% on average across 9 tasks, and in molecular design by up to 0.4 on properties on a 0-1 scale. Code is available at https://github.com/yangkevin2/neurips2021-lap3. 