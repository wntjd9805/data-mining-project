We consider the problem of online classiﬁcation under a privacy constraint. In this setting a learner observes sequentially a stream of labelled examples (𝑥𝑡 , 𝑦𝑡 ), for 1 ≤ 𝑡 ≤ 𝑇, and returns at each iteration 𝑡 a hypothesis ℎ𝑡 which is used to predict the label of each new example 𝑥𝑡 . The learner’s performance is measured by her regret against a known hypothesis class H. We require that the algorithm satisﬁes the following privacy constraint: the sequence ℎ1, . . . , ℎ𝑇 of hypotheses output by the algorithm needs to be an ((cid:178), δ)-diﬀerentially private function of the whole input sequence (𝑥1, 𝑦1), . . . , (𝑥𝑇 , 𝑦𝑇 ). We provide the ﬁrst non-trivial regret bound for the realizable setting. Speciﬁcally, we show that if the class H has constant Littlestone dimension then, given an oblivious sequence of labelled examples, there is a private learner that makes in expectation at most 𝑂 (log 𝑇) mistakes – comparable to the optimal mistake bound in the non-private case, up to a logarithmic factor. Moreover, for general values of the Littlestone dimension 𝑑, the same mistake bound holds but with a doubly-exponential in 𝑑 factor. A recent line of work has demonstrated a strong connection between classes that are online learnable and those that are diﬀerentially-private learnable. Our results strengthen this connection and show that an online learning algorithm can in fact be directly privatized (in the realizable setting). We also discuss an adaptive setting and√ provide a sublinear regret bound of 𝑂 (𝑇). 