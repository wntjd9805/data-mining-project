We give an (ε, δ)-differentially private algorithm for the multi-armed bandit (MAB) problem in the shufﬂe model with a distribution-dependent regret of (cid:18)(cid:16)(cid:80)O a∈[k]:∆a>0 (cid:18)√ of O kT log T + k log T∆a√√ (cid:17) k+ log 1δ log Tε (cid:19) log 1δ log Tε (cid:19), and a distribution-independent regret, where T is the number of rounds, ∆a is the suboptimality gap of the arm a, and k is the total number of arms. Our upper bound almost matches the regret of the best known algorithms for the centralized model, and signiﬁcantly outperforms the best known algorithm in the local model. 