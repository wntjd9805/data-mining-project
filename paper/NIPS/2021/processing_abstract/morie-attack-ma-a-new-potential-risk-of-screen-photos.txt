Images, captured by a camera, play a critical role in training Deep Neural Net-works (DNNs). Usually, we assume the images acquired by cameras are consistent with the ones perceived by human eyes. However, due to the different physical mechanisms between human-vision and computer-vision systems, the ﬁnal per-ceived images could be very different in some cases, for example shooting on digital monitors. In this paper, we ﬁnd a special phenomenon in digital image processing, the moiré effect, that could cause unnoticed security threats to DNNs.Based on it, we propose a Moiré Attack (MA) that generates the physical-world moiré pattern adding to the images by mimicking the shooting process of digi-tal devices. Extensive experiments demonstrate that our proposed digital MoiréAttack (MA) is a perfect camouﬂage for attackers to tamper with DNNs with a high success rate (100.0% for untargeted and 97.0% for targeted attack with the noise budget (cid:15) = 4), high transferability rate across different models, and high robustness under various defenses. Furthermore, MA owns great stealthiness be-cause the moiré effect is unavoidable due to the camera’s inner physical structure, which therefore hardly attracts the awareness of humans. Our code is available at https://github.com/Dantong88/Moire_Attack. 