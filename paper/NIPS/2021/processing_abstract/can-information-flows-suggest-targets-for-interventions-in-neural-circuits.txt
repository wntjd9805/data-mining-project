Motivated by neuroscientiﬁc and clinical applications, we empirically examine whether observational measures of information ﬂow can suggest interventions. We do so by performing experiments on artiﬁcial neural networks in the context of fairness in machine learning, where the goal is to induce fairness in the system through interventions. Using our recently developed M -information ﬂow frame-work, we measure the ﬂow of information about the true label (responsible for accuracy, and hence desirable), and separately, the ﬂow of information about a protected attribute (responsible for bias, and hence undesirable) on the edges of a trained neural network. We then compare the ﬂow magnitudes against the effect of intervening on those edges by pruning. We show that pruning edges that carry larger information ﬂows about the protected attribute reduces bias at the output to a greater extent. This demonstrates that M -information ﬂow can meaningfully suggest targets for interventions, answering the title’s question in the afﬁrmative.We also evaluate bias-accuracy tradeoffs for different intervention strategies, to analyze how one might use estimates of desirable and undesirable informationﬂows (here, accuracy and bias ﬂows) to inform interventions that preserve the former while reducing the latter. 