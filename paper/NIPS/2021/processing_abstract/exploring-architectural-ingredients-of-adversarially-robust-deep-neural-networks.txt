Deep neural networks (DNNs) are known to be vulnerable to adversarial attacks. A range of defense methods have been proposed to train adversarially robust DNNs, among which adversarial training has demonstrated promising results. However, despite preliminary understandings developed for adversarial training, it is still not clear, from the architectural perspective, what conﬁgurations can lead to more robust DNNs. In this paper, we address this gap via a comprehensive investigation on the impact of network width and depth on the robustness of adversarially trainedDNNs. Speciﬁcally, we make the following key observations: 1) more parame-ters (higher model capacity) does not necessarily help adversarial robustness; 2) reducing capacity at the last stage (the last group of blocks) of the network can actually improve adversarial robustness; and 3) under the same parameter budget, there exists an optimal architectural conﬁguration for adversarial robustness. We also provide a theoretical analysis explaning why such network conﬁguration can help robustness. These architectural insights can help design adversarially robustDNNs. Code is available at https://github.com/HanxunH/RobustWRN. 