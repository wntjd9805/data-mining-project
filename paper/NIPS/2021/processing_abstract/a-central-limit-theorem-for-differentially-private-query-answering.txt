Perhaps the single most important use case for differential privacy is to privately answer numerical queries, which is usually achieved by adding noise to the answer vector. The central question is, therefore, to understand which noise distribution optimizes the privacy-accuracy trade-off, especially when the dimension of the answer vector is high. Accordingly, an extensive literature has been dedicated to the question and the upper and lower bounds have been successfully matched up to constant factors [BUV18, SU17]. In this paper, we take a novel approach to address this important optimality question. We ﬁrst demonstrate an intriguing central limit theorem phenomenon in the high-dimensional regime. More precisely, we prove that a mechanism is approximately Gaussian Differentially Private [DRS21] if the added noise satisﬁes certain conditions. In particular, densities proportional to e−(cid:107)x(cid:107)α p is the standard (cid:96)p-norm, satisﬁes the conditions. Taking this perspective, we make use of the Cramer–Rao inequality and show a “uncer-tainty principle”-style result: the product of privacy parameter and the (cid:96)2-loss of the mechanism is lower bounded by the dimension. Furthermore, the Gaussian mechanism achieves the constant-sharp optimal privacy-accuracy trade-off among all such noises. Our ﬁndings are corroborated by numerical experiments. p , where x (cid:107) (cid:107) 