The goal of this paper is to characterize Gaussian-Process optimization in the setting where the function domain is large relative to the number of admissible function evaluations, i.e., where it is impossible to ﬁnd the global optimum. We provide upper bounds on the suboptimality (Bayesian simple regret) of the so-lution found by optimization strategies that are closely related to the widely used expected improvement (EI) and upper conﬁdence bound (UCB) algorithms. These regret bounds illuminate the relationship between the number of evaluations, the domain size (i.e. cardinality of ﬁnite domains / Lipschitz constant of the covari-ance function in continuous domains), and the optimality of the retrieved function value.In particular, we show that even when the number of evaluations is far too small to ﬁnd the global optimum, we can ﬁnd nontrivial function values (e.g. values that achieve a certain ratio with the optimal value). 