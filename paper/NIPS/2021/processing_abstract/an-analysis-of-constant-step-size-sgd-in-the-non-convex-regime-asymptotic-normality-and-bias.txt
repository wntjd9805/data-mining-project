Structured non-convex learning problems, for which critical points have favorable statistical properties, arise frequently in statistical machine learning. Algorithmic convergence and statistical estimation rates are well-understood for such problems.However, quantifying the uncertainty associated with the underlying training al-gorithm is not well-studied in the non-convex setting. In order to address this short-coming, in this work, we establish an asymptotic normality result for the constant step size stochastic gradient descent (SGD) algorithm—a widely used algorithm in practice. Speciﬁcally, based on the relationship between SGD andMarkov Chains [1], we show that the average of SGD iterates is asymptotically nor-mally distributed around the expected value of their unique invariant distribution, as long as the non-convex and non-smooth objective function satisﬁes a dissipa-tivity property. We also characterize the bias between this expected value and the critical points of the objective function under various local regularity conditions.Together, the above two results could be leveraged to construct conﬁdence intervals for non-convex problems that are trained using the SGD algorithm. 