Recent research has shown that graph neural networks (GNNs) can learn policies for locomotion control that are as effective as a typical multi-layer perceptron (MLP), with superior transfer and multi-task performance [55, 20]. However, results have so far been limited to training on small agents, with the performance ofGNNs deteriorating rapidly as the number of sensors and actuators grows. A key motivation for the use of GNNs in the supervised learning setting is their applicabil-ity to large graphs, but this beneﬁt has not yet been realised for locomotion control.We show that poor scaling in GNNs is a result of increasingly unstable policy up-dates, caused by overﬁtting in parts of the network during training. To combat this, we introduce SNOWFLAKE, a GNN training method for high-dimensional continu-ous control that freezes parameters in selected parts of the network. SNOWFLAKE signiﬁcantly boosts the performance of GNNs for locomotion control on large agents, now matching the performance of MLPs while offering superior transfer properties. 