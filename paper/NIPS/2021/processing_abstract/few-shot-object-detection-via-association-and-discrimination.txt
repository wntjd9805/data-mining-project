Object detection has achieved substantial progress in the last decade. However, detecting novel classes with only few samples remains challenging, since deep learning under low data regime usually leads to a degraded feature space. Existing works employ a holistic ﬁne-tuning paradigm to tackle this problem, where the model is ﬁrst pre-trained on all base classes with abundant samples, and then it is used to carve the novel class feature space. Nonetheless, this paradigm is still imperfect. Durning ﬁne-tuning, a novel class may implicitly leverage the knowledge of multiple base classes to construct its feature space, which induces a scattered feature space, hence violating the inter-class separability. To over-come these obstacles, we propose a two-step ﬁne-tuning framework, Few-shot object detection via Association and DIscrimination (FADI), which builds up a discriminative feature space for each novel class with two integral steps. 1) In the association step, in contrast to implicitly leveraging multiple base classes, we construct a compact novel class feature space via explicitly imitating a speciﬁc base class feature space. Speciﬁcally, we associate each novel class with a base class according to their semantic similarity. After that, the feature space of a novel class can readily imitate the well-trained feature space of the associated base class. 2) In the discrimination step, to ensure the separability between the novel classes and associated base classes, we disentangle the classiﬁcation branches for base and novel classes. To further enlarge the inter-class separability between all classes, a set-specialized margin loss is imposed. Extensive experiments on standard PascalVOC and MS-COCO datasets demonstrate that FADI achieves new state-of-the-art performance, signiﬁcantly improving the baseline in any shot/split by +18.7. No-tably, the advantage of FADI is most announced on extremely few-shot scenarios (e.g. 1- and 3- shot). Code is available at: https://github.com/yhcao6/FADI 