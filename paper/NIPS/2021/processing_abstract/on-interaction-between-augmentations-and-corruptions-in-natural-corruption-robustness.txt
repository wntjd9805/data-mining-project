Invariance to a broad array of image corruptions, such as warping, noise, or color shifts, is an important aspect of building robust models in computer vision.Recently, several new data augmentations have been proposed that signiﬁcantly improve performance on ImageNet-C, a benchmark of such corruptions. However, there is still a lack of basic understanding on the relationship between data augmen-tations and test-time corruptions. To this end, we develop a feature space for image transforms, and then use a new measure in this space between augmentations and corruptions called the Minimal Sample Distance to demonstrate a strong correlation between similarity and performance. We then investigate recent data augmentations and observe a signiﬁcant degradation in corruption robustness when the test-time corruptions are sampled to be perceptually dissimilar from ImageNet-C in this fea-ture space. Our results suggest that test error can be improved by training on percep-tually similar augmentations, and data augmentations may not generalize well be-yond the existing benchmark. We hope our results and tools will allow for more ro-bust progress towards improving robustness to image corruptions. We provide code at https://github.com/facebookresearch/augmentation-corruption. 