Learning to execute algorithms is a fundamental problem that has been widely studied. Prior work [1] has shown that to enable systematic generalisation on graph algorithms it is critical to have access to the intermediate steps of the pro-gram/algorithm. In many reasoning tasks, where algorithmic-style reasoning is important, we only have access to the input and output examples. Thus, inspired by the success of pre-training on similar tasks or data in Natural Language Pro-cessing (NLP) and Computer Vision, we set out to study how we can transfer algorithmic reasoning knowledge. Speciﬁcally, we investigate how we can use algorithms for which we have access to the execution trace to learn to solve similar tasks for which we do not. We investigate two major classes of graph algorithms, parallel algorithms such as breadth-ﬁrst search and Bellman-Ford and sequential greedy algorithms such as Prim and Dijkstra. Due to the fundamental differences between algorithmic reasoning knowledge and feature extractors such as used inComputer Vision or NLP, we hypothesise that standard transfer techniques will not be sufﬁcient to achieve systematic generalisation. To investigate this empirically we create a dataset including 9 algorithms and 3 different graph types. We validate this empirically and show how instead multi-task learning can be used to achieve the transfer of algorithmic reasoning knowledge. 