Energy-based models (EBMs) offer ﬂexible distribution parametrization. How-ever, due to the intractable partition function, they are typically trained via con-trastive divergence for maximum likelihood estimation. In this paper, we propose pseudo-spherical contrastive divergence (PS-CD) to generalize maximum likeli-hood learning of EBMs. PS-CD is derived from the maximization of a family of strictly proper homogeneous scoring rules, which avoids the computation of the intractable partition function and provides a generalized family of learning objectives that include contrastive divergence as a special case. Moreover, PS-CD allows us to ﬂexibly choose various learning objectives to train EBMs without additional computational cost or variational minimax optimization. Theoretical analysis on the proposed method and extensive experiments on both synthetic data and commonly used image datasets demonstrate the effectiveness and modelingﬂexibility of PS-CD, as well as its robustness to data contamination, thus showing its superiority over maximum likelihood and f -EBMs. 