τ¯?´´K0.75¯δ ` dThis paper considers stochastic linear bandits with general nonlinear constraints.The objective is to maximize the expected cumulative reward over horizon T subject to a set of constraints in each round τ ď T . We propose a pessimistic-optimistic algorithm for this problem, which is efﬁcient in two aspects. First, the algorithm yields ˜O (pseudo) regret in round τ ď T, where K is the number of constraints, d is the dimension of the reward feature space, andδ is a Slater’s constant; and zero constraint violation in any round τ ą τ 1, whereτ 1 is independent of horizon T. Second, the algorithm is computationally efﬁcient.Our algorithm is based on the primal-dual approach in optimization and includes two components. The primal component is similar to unconstrained stochastic linear bandits (our algorithm uses the linear upper conﬁdence bound algorithm (LinUCB)). The computational complexity of the dual component depends on the number of constraints, but is independent of the sizes of the contextual space, the action space, and the feature space. Thus, the computational complexity of our algorithm is similar to LinUCB for unconstrained stochastic linear bandits. 