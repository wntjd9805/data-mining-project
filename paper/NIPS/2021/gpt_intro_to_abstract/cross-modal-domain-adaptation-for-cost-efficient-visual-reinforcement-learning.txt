Reinforcement learning (RL) has shown success in vision-based robotic control tasks, but training RL algorithms on real robots can be expensive and time-consuming. Simulators offer a cost-effective alternative, but policies trained in simulators often fail to generalize to the real world due to the "reality gap." Domain adaptation, which aligns representations from two domains, is a promising approach to bridge this gap. Previous works have focused on unsupervised visual domain adaptation, but we argue that the objective of learning a mapping function in this context is ill-posed. In this paper, we propose Cross-mOdal Domain Adaptation with Sequential structure (CODAS) to learn a mapping function from images in the target domain to states in the source domain, allowing policies trained on states to be directly deployed in the target domain. We formulate the adaptation problem as a variational inference problem and design a special residual model structure to enhance the training process. Our evaluations on various tasks demonstrate that CODAS outperforms existing methods in transferring policies to the target domain.