This paper introduces the concept of knowledge graph embedding (KGE) and its applications in various domains such as recommendation systems, question answering, and dialogue systems. The authors discuss different KGE models that aim to capture complex relation patterns in knowledge graphs, including symmetry, asymmetry, inversion, composition, and transitivity. While existing models can effectively capture some of these patterns, none of them are able to model transitivity effectively. In this paper, the authors propose a new model called Rot-Pro that combines projection and relational rotation to model transitivity and other relation patterns. Theoretical analysis and experimental results demonstrate the effectiveness of the Rot-Pro model in learning the transitivity pattern and outperforming other models on link prediction tasks in different datasets.