In recent years, deep learning has been successful in various fields due to its ability to process massive and high-dimensional data efficiently. However, training a deep learning model from scratch requires a large amount of labeled data and manual selection of hyperparameters. To address these issues, meta learning has gained attention as it allows models to learn how to learn by acquiring knowledge from multiple tasks. Meta learning typically involves formulating objective functions as a bi-level optimization problem, where the lower-level subproblem represents task adaptation and the upper-level subproblem aims to optimize meta parameters. While conventional meta learning methods focus on a single meta objective, real-world applications often involve multiple objectives. This paper introduces a unified gradient-based Multi-Objective Meta Learning (MOML) framework that formulates multiple objectives in meta learning as a Multi-Objective Bi-Level optimization Problem (MOBLP). The proposed framework is accompanied by a gradient-based optimization algorithm and theoretical proofs of its convergence properties. Several learning problems, such as few-shot learning, domain adaptation, multi-task learning, and Neural Architecture Search (NAS), are formulated and solved using the MOML framework, demonstrating its effectiveness and achieving state-of-the-art performance.