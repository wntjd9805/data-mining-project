We propose algorithms for learning Bayesian Networks (BNs) from data with the aim of keeping the state space size within a user-specified bound. By restricting the state space size, we can achieve fast probabilistic reasoning, resulting in fast-inference BNs. We compare our bounded state space (bss) algorithms to state-of-the-art bounded treewidth BN learning algorithms on real-world benchmark datasets. Our results demonstrate a clear advantage for the bss algorithms, showing better performance and higher reliability in terms of reasoning speed and data fitting. The challenges of extending BN-SLIM, a post-processing algorithm that uses MaxSAT, to bss learning are also discussed.