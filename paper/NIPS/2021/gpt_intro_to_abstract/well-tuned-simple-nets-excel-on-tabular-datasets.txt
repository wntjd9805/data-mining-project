This paper focuses on the application of deep learning techniques to tabular data, an area that has been understudied in the field. Traditional machine learning methods have dominated the domain of tabular data due to their superior performance, while deep learning has primarily been successful with raw data such as images and text. The existing literature presents mixed results on the effectiveness of deep learning for tabular data, with some claiming improved performance over traditional methods and others confirming the continued accuracy of traditional methods. This paper proposes that incorporating recent advances in deep learning regularization techniques can enhance the performance of neural networks on tabular data. The authors conducted extensive experiments on 40 datasets and found that well-regularized neural networks, including simple Multilayer Perceptrons, surpassed the current state-of-the-art models, including recent neural network architectures and Gradient-Boosted Decision Trees. The paper introduces a paradigm for selecting the optimal combination of regularization techniques and their hyperparameters through a joint search process. The results of this study have significant implications and open up new opportunities for deep learning applications in tabular datasets. The contributions of this paper include demonstrating the effectiveness of modern deep learning regularizers on tabular data, proposing a principled approach for selecting optimal regularization techniques, and showing that even simple neural networks can outperform traditional methods in this domain.