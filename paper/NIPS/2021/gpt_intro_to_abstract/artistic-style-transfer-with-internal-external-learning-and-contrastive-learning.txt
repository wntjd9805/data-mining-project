This paper introduces a novel approach to artistic style transfer, aiming to bridge the gap between real artworks and synthesized stylizations. The authors argue that existing methods often overlook the human-aware style information present in collections of human-created artworks. To address this, they propose an internal-external learning scheme that leverages the internal statistics of a single artwork and externally learns human-aware style information from a large-scale style dataset. Additionally, the paper addresses the neglect of stylization-to-stylization relations in existing methods and introduces contrastive losses to enforce these relations. Experimental results demonstrate the effectiveness and superiority of the proposed approach compared to state-of-the-art style transfer methods.