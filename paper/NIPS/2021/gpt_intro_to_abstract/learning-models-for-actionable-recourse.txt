Recently, there has been a growing interest in using machine learning for making important decisions in the legal and financial domains. However, it is crucial to explain the reasoning behind these decisions to ensure fairness and provide individuals with justifications. Counterfactual explanations, which suggest changes in features to obtain different predictions, can be used to provide actionable recourses for individuals negatively affected by the model outcomes. Existing approaches for computing recourses do not guarantee their existence, especially for nonlinear models. In this paper, we propose a novel algorithm that guarantees the existence of actionable recourses by building on adversarial training techniques. We demonstrate the effectiveness of our approach on real-world datasets, achieving improvements in recourse rates without sacrificing accuracy or the quality and robustness of the recourses.