Stochastic shortest path (SSP) is a reinforcement learning (RL) setting in which the agent aims to reach a goal state while minimizing its total expected cost. In this paper, we focus on the online learning problem in SSP, where both the transition dynamics and the cost function are initially unknown, and the agent interacts with the environment through multiple episodes. Our objective is to develop a learning algorithm that achieves low regret, approximating the optimal policy. We identify three desirable properties for such an algorithm: minimax optimality, parameter-free learning, and horizon-free bounds. Additionally, computational efficiency is a crucial consideration.