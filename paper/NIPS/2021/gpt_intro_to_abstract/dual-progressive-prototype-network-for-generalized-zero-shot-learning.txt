Deep learning methods in computer vision heavily rely on large amounts of manually-labeled data, limiting their applicability. To address this limitation, Generalized Zero-Shot Learning (GZSL) has emerged as a prominent area of research, aiming to recognize images from novel categories with only seen domain training data. In GZSL, category descriptions such as category attributes or word embeddings are introduced to associate two domain categories. In this paper, we propose a novel Dual Progressive Prototype Network (DPPN) that constructs two types of progressive prototypes for attributes and categories, respectively, in order to gradually improve cross-domain transferability and category discriminability of visual representations. Our approach dynamically adjusts attribute prototypes for each image, allowing for capturing vital visual differences across images. Additionally, DPPN aggregates attribute-related local features to preserve attribute-region correspondence. Experimental results demonstrate that DPPN outperforms existing methods in alleviating the domain shift problem in GZSL. Our contributions include the introduction of DPPN and its novel updating strategy for attribute prototypes, as well as the enhancement of category discriminability through progressive projection of category prototypes.