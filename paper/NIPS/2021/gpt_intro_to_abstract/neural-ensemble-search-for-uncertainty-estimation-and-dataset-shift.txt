This paper introduces the concept of Neural Ensemble Search (NES), an extension of Neural Architecture Search (NAS), for automatically constructing ensembles with varying base learner architectures. The goal is to find a set of diverse architectures that form a strong ensemble, overcoming challenges such as similarities between optimized base learner architectures and poor performing randomly selected architectures. The authors present two NES algorithms, NES-RS and NES-RE, and demonstrate their effectiveness in improving uncertainty estimation and robustness to dataset shift compared to state-of-the-art deep ensembles. The findings are validated over multiple datasets and architecture search spaces.