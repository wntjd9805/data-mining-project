Deep Neural Network (DNN) models have significantly increased in size and computational requirements, necessitating the study of parallel training techniques. This paper introduces Piper, an optimization algorithm for partitioning DNN layers across devices to maximize throughput. Piper considers data, tensor model, and pipeline model parallelism, as well as memory-saving optimizations. It supports general DAG model topologies and is efficient in both theory and practice. The evaluation demonstrates Piper's ability to find high-quality parallelization configurations and its advantages over prior work.