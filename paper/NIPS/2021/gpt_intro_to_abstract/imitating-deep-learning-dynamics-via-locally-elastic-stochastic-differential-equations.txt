Deep learning models have achieved significant success in various domains, such as computer vision and natural language processing. However, there is still much to learn about deep neural networks, as most advancements in architecture design and optimization are based on heuristics rather than theoretical understanding. This paper aims to quantitatively understand the impact of backpropagation in deep learning training, particularly how data from different classes become separable in their feature space. By analyzing the effects of a single update using stochastic gradient on network performance, the authors address this question from a phenomenological viewpoint. They propose a model that captures the interaction between training samples using stochastic differential equations (SDEs) to reflect the concept of local elasticity in neural networks. The main finding of the study reveals a phase transition phenomenon related to intra-class and inter-class impact, showing that linear separability of features is guaranteed when the intra-class effect is greater than the inter-class effect. The accuracy of the proposed model in simulating feature dynamics is demonstrated through experiments on synthetic and real datasets. The results provide insights into the training dynamics of neural networks, highlighting the crucial role of local elasticity.