Algorithms used in high-stakes decision making, such as loan approvals and employment decisions, have raised ethical concerns regarding their potential discriminatory bias. While previous efforts have focused on ensuring fairness at the time of decision making, there is a lack of consideration for the long-term impacts of these decisions. This paper aims to address this gap by exploring the long-term impact of actions in sequential decision making under uncertainty. The authors introduce impact functions that capture the dependency of biases on the action history, and propose a phased-learning algorithm that achieves optimal regret. Simulation results demonstrate the superiority of the proposed algorithm compared to existing methods. The study contributes to understanding the dynamics of biased decision making and provides insights for policy makers dealing with long-term consequences of algorithmic interventions.