This paper presents a re-imagining of neural architecture search (NAS) and automated machine learning (AutoML) by expanding the search space of operations. The authors propose a method that replaces the traditional discrete search space with a more expressive set of operations called Expressive Diagonalization (XD) operations. The XD operations include various types of convolutions, pooling, permutations, transposed convolutions, graph convolutions, and more. The authors demonstrate the effectiveness of XD-operations in solving partial differential equations, protein folding, and music modeling tasks, outperforming custom-designed operations and achieving lower error rates. The code to reproduce the results and the software to apply XD-operations are provided in the paper.