Graph Convolutional Networks (GCNs) have achieved significant success in various domains by applying deep learning techniques to graph-structured data. However, recent studies have revealed that GCNs are vulnerable to adversarial attacks, which raises concerns about their robustness in security and privacy applications. Most existing literature focuses on structural attacks, where adversarial edges are inserted, removed, or rewired to degrade the representation learning ability of GCNs. To enhance the robustness of GCNs against such attacks, this paper proposes GCN-LFR (Low-Frequency based Regularization), a general defense approach that leverages the spectral analysis of graph structures. The authors prove that low-frequency components in the graph spectrum are more robust to adversarial perturbations and propose a co-training paradigm that transfers the robustness from these components. Experimental results on benchmark datasets demonstrate that GCN-LFR outperforms state-of-the-art defenders and maintains performance on benign graphs, highlighting its broad applicability in deep graph learning.