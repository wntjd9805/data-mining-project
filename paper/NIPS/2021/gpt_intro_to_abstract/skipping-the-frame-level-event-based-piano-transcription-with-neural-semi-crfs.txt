Automatic Music Transcription (AMT) involves transcribing music recordings into music notation. This paper focuses on transcribing piano music into MIDI event sequences, where each event is specified by its onset, offset, and velocity. Previous approaches used neural networks at the frame-level to make predictions for note events, but required manual procedures to combine and extract note-level predictions. In this work, a direct approach to note-level transcription is proposed, scoring the likelihood of a time interval covering a musical event and using a specialized zeroth-order semi-Markov conditional random field (semi-CRF) for decoding. The proposed method achieves high accuracy on the MAESTRO dataset and can be applied to other similar tasks.