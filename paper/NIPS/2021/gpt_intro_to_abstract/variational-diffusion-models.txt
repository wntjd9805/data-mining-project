Likelihood-based generative modeling is a fundamental task in machine learning with various applications such as speech synthesis, translation, and compression. Autoregressive models have been the dominant approach due to their tractable likelihood and expressivity. However, diffusion models have shown promising results in image and audio generation but have yet to match autoregressive models on density estimation benchmarks. In this paper, we propose a flexible family of diffusion-based generative models that achieve state-of-the-art results on standard image density estimation benchmarks. We also improve the theoretical understanding of density modeling using diffusion models by analyzing their variational lower bound and deriving a simple expression based on the signal-to-noise ratio of the diffusion process. Additionally, we uncover new insights into the invariance and equivalence of diffusion models.