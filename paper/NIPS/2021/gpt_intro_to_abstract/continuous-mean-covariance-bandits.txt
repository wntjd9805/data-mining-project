The stochastic Multi-Armed Bandit (MAB) problem is a classic online learning model that deals with the exploration-exploitation trade-off in decision making. The Mean-Variance Bandits (MVB) model has gained attention for balancing rewards and performance variances but fails to consider correlation among multiple options. In this paper, we propose the Continuous Mean-Covariance Bandit (CMCB) model, which handles a continuous decision space and measures risk with option correlation. We introduce three feedback settings and provide optimal algorithms for each, along with lower bounds. Our work offers insights into risk management in decision making with correlated options.