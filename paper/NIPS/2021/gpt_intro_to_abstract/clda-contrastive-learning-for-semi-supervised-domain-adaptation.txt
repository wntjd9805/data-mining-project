Deep Convolutional networks have achieved impressive performance in computer vision tasks, but they suffer from the problem of generalizability across different datasets. Semi-Supervised Domain Adaptation (SSDA) has emerged as a solution, where a few labeled samples from the target domain are used to boost the performance of CNN models. Existing domain adaptation methods focus on aligning feature distributions without considering sample categories, leading to suboptimal results. In this paper, we propose a novel contrastive learning framework called CLDA, which includes Inter-Domain Contrastive Alignment to reduce discrepancy between class centroids and Instance Contrastive Alignment to reduce intra-domain discrepancy. Our approach achieves state-of-the-art results on multiple datasets.