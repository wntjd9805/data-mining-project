Neural networks deployed in real-world systems often encounter unknown samples that they have not been trained on, known as out-of-distribution (OOD) inputs. Identifying and handling these OOD inputs is crucial for safety-critical applications such as autonomous driving and healthcare. However, modern neural networks have been found to produce overconfident predictions on OOD inputs, making it difficult to distinguish between in-distribution (ID) and OOD data. In this paper, we propose a method called Rectified Activations (ReAct) for OOD detection, which attenuates the outsized activation of selected hidden units by rectifying the activations at a predetermined upper limit. This method significantly improves the separation between ID and OOD data, reducing the false positive rate from 55.72% to 20.38%. We provide empirical and theoretical insights into the mechanism behind ReAct and demonstrate its superior performance on various OOD detection benchmarks. Our contributions include introducing ReAct as a simple and effective approach, showcasing its generalizability to different network architectures and detection methods, achieving state-of-the-art performance on OOD detection tasks, and providing insights for future research in neural network mechanisms for OOD detection.