Mean estimation is a fundamental problem in statistics, optimization, and machine learning. However, privacy concerns prevent us from using the exact mean, leading to the problem of achieving the smallest error under a given privacy model. Differential privacy (DP) is a mathematical definition used to protect individual privacy and has become the standard in privacy-preserving data analysis. In this paper, we focus on the problem of differentially private mean estimation and aim to design a mechanism that achieves optimal error guarantees. We introduce the notion of instance optimality and propose a mechanism that works well not only on a given instance but also on its in-neighbors. We provide upper and lower bounds for the error of the mechanism and show that our proposed mechanism achieves near-optimal error guarantees in practical settings. We demonstrate the effectiveness of our mechanism through experimental results.