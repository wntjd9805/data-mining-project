Video Object Segmentation (VOS) is a crucial task in video understanding with various applications, such as augmented reality and self-driving cars. This paper focuses on semi-supervised VOS, aiming to track and segment objects throughout a video sequence using object masks provided in the first frame. Although deep learning-based VOS algorithms have shown promising results, they often struggle with multi-object scenarios, needing to match and combine single-object predictions. In contrast, this paper proposes an Associating Objects with Transformers (AOT) approach that associates and decodes multiple objects uniformly, offering greater efficiency. The authors introduce an identification mechanism to assign each target a unique identity and embed them in the same feature space, enabling the network to learn associations and correlations. Additionally, they design a Long Short-Term Transformer (LSTT) for hierarchical object matching and propagation, outperforming previous methods while maintaining efficiency. Experimental results on popular VOS benchmarks validate the effectiveness of AOT.