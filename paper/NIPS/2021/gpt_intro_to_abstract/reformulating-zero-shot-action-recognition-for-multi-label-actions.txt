Current image and video classification models perform well on previously seen classes but tend to fail when presented with novel classes. This requires retraining the system with additional samples, resulting in increased training time and computational resources. In this work, we focus on zero-shot action recognition (ZSAR) and propose a new approach called Pairwise Scoring ZSAR (PS-ZSAR). PS-ZSAR leverages semantic information to classify videos of unseen action categories. Unlike existing methods, PS-ZSAR avoids using a static text-based semantic space for class selection, as this can lead to incorrect classification boundaries. Instead, PS-ZSAR maps the visual and semantic representations of actions into a joint space, enabling accurate prediction of visually dissimilar actions. We evaluate PS-ZSAR on multiple video datasets and demonstrate its strong performance in both single-label and multi-label action recognition tasks. Additionally, we showcase its scalability in real-world scenarios through participation in the NIST ActEV challenge.