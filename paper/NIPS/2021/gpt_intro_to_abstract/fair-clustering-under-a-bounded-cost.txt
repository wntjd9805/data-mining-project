Machine learning algorithms are being increasingly used in domains that directly impact human lives, leading to the emergence of a fair machine learning community that develops algorithms satisfying fairness criteria. In this paper, we focus on group fairness, particularly in the context of clustering, which is a fundamental unsupervised learning problem. We explore the concept of fair clustering, where each point is assigned a color representing group membership, and the objective is to find a clustering that minimizes a given clustering objective while ensuring that each cluster has a specified proportion of colors. However, it is recognized that enforcing fairness constraints can negatively affect the clustering objective, leading to a degradation known as the price of fairness. We show that the price of fairness in fair clustering is unbounded, as illustrated in Figure 1, highlighting the potential trade-off between fairness and clustering quality. Furthermore, the legal notion of disparate impact does not require organizations to output fair clusters if they can justify an unfair solution due to business necessity. To address this, we propose fair clustering algorithms that operate under an exogenous threshold on the clustering objective, ensuring that the clustering cost does not exceed a pre-set upper bound. We formulate the problem mathematically and focus on different group fairness objectives, showing that they lead to NP-hard problems. We develop bi-criteria approximation algorithms that provide bounded violation of fairness constraints and bounded error compared to the optimal value for certain group fairness objectives. Additionally, we present an effective heuristic for the GROUP-LEXIMIN objective and analyze the inapproximability of other fairness objectives. Our algorithms are evaluated on various datasets, demonstrating good solutions with low fairness violations.