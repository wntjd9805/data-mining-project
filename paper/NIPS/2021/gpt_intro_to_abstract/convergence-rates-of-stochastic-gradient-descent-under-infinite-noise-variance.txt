We investigate the problem of unconstrained minimization using the stochastic gradient descent (SGD) algorithm, focusing on the case where the noise in the gradient is state dependent and has infinite variance. This scenario is relevant in modern statistical learning, where the population risk is minimized based on observed i.i.d. samples. While previous works have explored the convergence rates of SGD under finite noise variance, our study examines the behavior of SGD with diminishing step-sizes when the noise variance is infinite. We establish convergence rates towards the global minimum and identify a condition on the Hessian of the objective function. Additionally, we analyze the Polyak-Ruppert averaging of the SGD iterates and show that the limit distribution is a multivariate alpha-stable distribution. Our results demonstrate that SGD can converge to the global optimum even under heavy-tailed noise with infinite variance, without requiring modifications to the loss function or algorithm.