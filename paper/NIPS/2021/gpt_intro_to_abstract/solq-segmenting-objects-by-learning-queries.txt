Instance segmentation is a fundamental task in computer vision that involves locating instances of different categories and generating pixel-level masks for each instance. Current state-of-the-art methods follow a two-stage paradigm, where object detection is first performed and then masks are segmented within the detected boxes. However, these methods heavily rely on the detection branch, making it difficult to achieve better joint learning of multiple tasks. In this paper, we propose a novel end-to-end instance segmentation framework inspired by the end-to-end solution for object detection. Our method, called SOLQ, formulates instance segmentation as the joint learning of a unified query representation. We introduce a mask representation that can convert the spatial masks into embedding domain, allowing for more effective modeling of spatial information. Experimental results on the MS COCO dataset demonstrate that SOLQ outperforms existing methods in both mask and box AP, showcasing the effectiveness of our proposed approach.