This paper introduces the concept of A/B/n testing, a website optimization procedure that compares multiple versions of content to find the one with the highest conversion rate. The decision-making process for deploying alternative implementations involves factors such as cost, external data, and overall fit. However, the traditional A/B/n testing approach has limitations in terms of efficiency and the ability to differentiate small changes. To address these limitations, the paper proposes sequential testing policies that adaptively adjust sample allocation and can be stopped based on gathered data. The paper also addresses issues such as the presence of trends or inhomogeneity in data streams and the need for time-limited experiments. The proposed solution aims to identify all arms that are better than the control arm and provides useful tools for practical A/B/n testing.