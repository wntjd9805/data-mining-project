Dynamic visual reasoning is crucial for human intelligence, allowing us to explain and predict events in videos based on our intuitive physics knowledge. Previous approaches to artificial intelligence (AI) models with physical reasoning capabilities have either relied on black-box neural networks or graph neural networks (GNNs), both of which have limitations in terms of transparency, interpretability, and generalizability. To address these limitations, this paper proposes a new framework called Visual Reasoning with Differentiable Physics (VRDP), which combines a visual perception module, a concept learner, and a differentiable physics engine. VRDP achieves state-of-the-art performance on dynamic visual question-answering tasks, with high data efficiency and generalization capabilities.