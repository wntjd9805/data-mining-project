Semantic segmentation is a task that involves partitioning an image into different regions based on semantic categories. Most deep learning approaches for semantic segmentation use per-pixel classification, where each pixel is classified individually. However, mask classification is an alternative paradigm that predicts a set of binary masks associated with specific class predictions. In this paper, we propose a MaskFormer approach that converts any per-pixel classification model into a mask classification model using a Transformer decoder. Our experiments show that MaskFormer performs well on semantic segmentation and instance-level segmentation tasks, outperforming existing methods in terms of accuracy and efficiency. We also demonstrate its effectiveness on various datasets with different numbers of categories. Overall, MaskFormer provides a unified solution for both semantic and instance-level segmentation tasks.