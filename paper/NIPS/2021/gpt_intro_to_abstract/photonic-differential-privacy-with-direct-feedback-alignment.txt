The use of machine learning models trained on sensitive data has raised concerns about privacy. One approach to address this issue is differential privacy, which injects noise into the algorithm to prevent individual information inference. Another strategy is perturbed and quenched Stochastic Gradient Descent (SGD), where gradients are clipped, perturbed with noise, and used to update parameters. However, this approach decreases utility. In this paper, we propose a private-by-design learning algorithm inspired by Direct Feedback Alignment on Optical Processing Units (OPUs). The presence of noise in OPUs can be leveraged to control the privacy level, and we demonstrate the effectiveness of our algorithm using photonic hardware.