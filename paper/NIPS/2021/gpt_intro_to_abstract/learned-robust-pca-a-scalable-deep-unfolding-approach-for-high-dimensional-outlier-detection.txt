In this paper, we propose a scalable and learnable approach for high-dimensional robust principal component analysis (RPCA) problems. We address the challenges of high computational costs and the need for prior knowledge in existing approaches. Inspired by deep unfolded sparse coding, our approach parameterizes a classic RPCA algorithm and unfolds it as a feedforward neural network (FNN) with potentially infinite iterations. By learning the parameters of the FNN through backpropagation, we can achieve improved performance and arbitrary accuracy without the need for relearning. Our approach offers a highly efficient and easy-to-learn method for high-dimensional RPCA problems.