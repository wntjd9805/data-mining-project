We consider a time-varying nonlinear optimal control problem with state variables and control variables subject to certain constraints. This problem is related to dynamic programming and reinforcement learning. In applications such as energy and autonomous control, solving this problem in real time becomes a challenge due to its large or infinite horizon length. Model predictive control (MPC) is a feedback control technique commonly used for online optimization but is not widely used for nonlinear models due to computational complexity. Real-time iteration (RTI) schemes have been developed to reduce computation and enable RTI-based nonlinear MPC to be applied in fast dynamics. In this paper, we investigate the global convergence of RTI-based MPC and propose an adaptive scheme for stepsize selection using an augmented Lagrangian merit function. Our experiments show the superiority of the augmented Lagrangian over the penalized function, especially for time-varying problems. The algorithm also adaptively selects penalty parameters on the fly, and when the unit stepsize is accepted, the algorithm becomes the standard RTI-based MPC with existing local theories applying seamlessly. Our work complements the existing literature on RTI-based MPC by providing global convergence analysis.