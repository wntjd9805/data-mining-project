Episodic memory, also known as "mental time travel," has been proven useful in early stages of reinforcement learning (RL) and is supported by cognitive evidence. Episodic control (EC) uses this memory to control behavior and complements other control methods. However, existing EC methods suffer from issues such as vulnerability to noisy environments, sample inefficiency, and fixed combinations with parametric values. In this paper, we propose a novel model that integrates habitual, model-based, and episodic control in a single architecture to address these issues. We introduce Model-based Episodic Control (MBEC), which learns representations of trajectories and utilizes a memory-based planning algorithm for online value estimation. We also present a flexible CLS architecture that dynamically consolidates episodic and parametric values. Our contributions include a demonstration of MBEC's performance on various RL problems and analytical studies to validate our results.