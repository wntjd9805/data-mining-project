Deep neural networks (DNNs) have been widely deployed in real-world applications that require strict security. However, DNNs are susceptible to adversarial attacks, where even small perturbations to the input can cause incorrect predictions. Adversarial training, which involves augmenting the training set with adversarial samples, is commonly used to enhance DNNs' robustness. However, this method is time-consuming and can significantly increase training time. In this paper, we explore the possibility of finding robust subnetworks within randomly initialized networks without any training. We discover that such subnetworks, which we call Robust Scratch Tickets (RSTs), can achieve robust accuracy comparable to or even surpassing adversarially trained networks. We propose a general method to search for RSTs within randomly initialized networks and investigate their properties under different models, datasets, sparsity patterns, and attack methods. We also introduce the Random RST Switch (R2S), a defense technique that utilizes different RSTs for improved adversarial transferability. Our findings provide insights into DNN robustness and complement the lottery ticket hypothesis.