Today's most prominent methods for non-parametric, non-linear dimension reduction are t-Distributed Stochastic Neighbor Embedding (t-SNE) and Uniform Manifold Approximation and Projection for Dimension Reduction (UMAP). While UMAP is known for its excellent visualizations, the reason behind its success is not immediately clear. This paper aims to fill the gap in understanding UMAP's optimization method by analyzing it in detail and deriving its effective loss function. Surprisingly, the effective loss function differs significantly from UMAP's purported loss function, suggesting that UMAP approximates a binarized version of the high-dimensional similarities. These findings explain UMAP's tendency to produce crisp, over-contracted substructures and highlight the importance of considering artifacts in visualization methods. Additionally, the paper proposes an alternative explanation for UMAP's success, attributing it to the balancing of attractive and repulsive loss terms in the sampling-based optimization scheme.