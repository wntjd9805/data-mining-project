Inspired by the success of contrastive learning methods in the vision and language domains, recent advancements in graph learning have also adopted these methods to enhance the performance of various tasks. By creating two augmented views of a graph and maximizing the consistency between these views, contrastive learning enables graph representation learning without relying on expensive label information. Despite their effectiveness, existing graph contrastive learning models differ in augmented view design, encoding architecture, and contrastive objective. This paper aims to address the challenge of selecting the best components for contrastive learning on specific graph datasets. The authors propose an information-aware contrastive learning framework, called InfoGCL, based on the Information Bottleneck principle. They decouple the contrastive learning model into three modules: view augmentation, view encoding, and representation contrasting, and formulate optimization problems to find the optimal modules. The authors suggest principles for selecting the optimal modules, focusing on maximizing task-relevant information and minimizing mutual information between contrastive representations. They also explore the role of negative samples and show that they are not necessarily required for graph contrastive learning. The proposed InfoGCL method is evaluated on benchmark datasets, demonstrating competitive performance compared to state-of-the-art unsupervised methods for both node-level and graph-level tasks.