Recently, deep learning has demonstrated superior performance over traditional linear learners in many machine learning tasks. This has sparked theoretical investigation into the superiority of neural networks and the distinction between fixed feature representations and data-adaptive feature representations. In this paper, we extend this investigation and propose a new line of reasoning called "Local Signal Adaptivity." We focus specifically on the power of convolutional neural networks in image classification, compared to linear functions. We study a simple data distribution that captures the key property of natural image classification tasks and formally prove that CNNs can effectively locate the label-determining signal and ignore irrelevant background information. We also show a separation result between CNNs and their associated finite-width convolutional neural tangent kernels, proving that small CNNs can efficiently learn to find the signal while larger models are required for the kernels. Empirical justifications and experiments further support our theoretical results, indicating that the per-instance "signal finding within noisy backgrounds" ability of CNNs, referred to as "Local Signal Adaptivity," is a key component of the superiority of CNNs over fixed feature mappings.