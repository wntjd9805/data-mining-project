Self-localization and object localization are important tasks in navigation and surveillance systems, and have been extensively studied in the machine learning community. Existing localization methods achieve high precision using neural networks, but they are often specific to a particular modality and cannot be applied to other sensory systems. In this paper, we propose a modality-agnostic localization method that represents input samples in a low-dimensional manifold and infers correspondences between this manifold and a given topological map. By formulating the localization problem in terms of intrinsic space and incorporating optimal transportation, our approach provides a more generalizable solution that can be used with data from different modalities. We do not rely on modality-specific priors and instead focus on the correlation between the observer location and the measured signal. Our proposed method is applicable to a wide range of sensor modalities, as illustrated in Figure 1.