This paper investigates the relationship between neural network (NN) training dynamics and the complexity of the learned function. The authors propose the "Benevolent Training Hypothesis" (BTH), which suggests that NN designers may favor architectures that are easily trained, leading to better generalization. Evidence for the BTH is discussed, including the observation that training becomes more tedious for high frequency directions in the input space and that training slows down as images/labels become more corrupted. The paper focuses on quantifying NN complexity using the Lipschitz continuity of the network and examines the connection between training behavior and NN complexity close and far from the training data. The main findings include linking the trajectory of the 1st layer bias to the Lipschitz constant of the NN near the training data, as well as the impact of training on the Lipschitz constant in empty regions of the input space. The results provide insights into the complexity of neural networks and their generalization capabilities.