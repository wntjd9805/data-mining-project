In this paper, we address the question of whether current neural networks for video analysis and tracking are capable of tracking objects by their motion when appearance cues are uninformative. To investigate this, we introduce PathTracker, a synthetic challenge for object tracking without re-recognition. We compare the performance of leading models for video analysis, such as R3D and TimeS-formers, with human performance on the PathTracker challenge. Additionally, we propose a solution to PathTracker using a recurrent network inspired by primate neural circuitry involved in object tracking. This solution not only performs strongly correlated with humans on PathTracker, but also improves object tracking in natural videos. We release all PathTracker data, code, and human psychophysics to encourage further research in tracking without re-recognition.