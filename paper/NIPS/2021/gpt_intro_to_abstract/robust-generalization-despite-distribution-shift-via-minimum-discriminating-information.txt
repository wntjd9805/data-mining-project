Developing machine learning-based systems for real-world applications is challenging due to the mismatch between training and testing distributions. This issue, known as dataset shift, can significantly affect the performance of models. In this paper, we focus on the problem of tackling distribution shifts and introduce a new modeling framework based on the principle of minimum discriminating information. We propose a distributionally robust optimization (DRO) program to address this problem and derive generalization bounds for our model. We also present efficient algorithms for solving the optimization problems associated with distribution shifts. We demonstrate the effectiveness of our approach on two problem classes: training classifiers on biased data and off-policy evaluation for Markov decision processes. Our method outperforms existing approaches in both cases.