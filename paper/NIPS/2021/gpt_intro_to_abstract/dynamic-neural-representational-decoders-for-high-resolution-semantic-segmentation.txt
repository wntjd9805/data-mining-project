Semantic segmentation is a critical task in computer vision that involves classifying each pixel in an input image. Fully convolutional networks (FCNs) are commonly used for this task, consisting of an encoder and a decoder. While the encoder downsamples the image, the decoder is responsible for upsampling the output to the desired resolution. In this paper, we focus on improving the decoder and assume the use of any backbone networks as the encoder. We explore different approaches, such as bilinear upsampling and dilation convolutions, to address the challenge of low-resolution outputs. We also examine popular decoders used in semantic segmentation, such as the ones in DeepLabV3+ and RefineNet, and identify potential drawbacks. To overcome these limitations, we propose a novel decoder called dynamic neural representation decoder (NRD) that leverages neural networks to represent local label patches. Our method achieves improved accuracy and computational efficiency compared to existing approaches, making it a promising solution for semantic segmentation.