Monocular 3D reconstruction is a challenging task in computer vision due to the inherent ill-posed nature of the problem. Previous approaches have used correspondences and deep learning techniques to address this issue. However, current methods ignore the presence of local minima and make optimization harder by simultaneously solving multiple subtasks. In this paper, we propose a novel approach that solves a per-sample optimization problem to achieve accurate 3D reconstruction. We use differentiable optimization to recover the 3D vertex positions from 2D coordinates and optimize the rigid and non-rigid pose parameters. Our approach outperforms existing methods and does not rely on additional geometric priors. Experimental results demonstrate the effectiveness of our self-supervised losses in achieving high-quality 3D reconstruction.