The paper introduces a framework for fusing 3D Lidar and high-resolution color measurements in order to improve 3D perception for autonomous driving. The authors propose a Multi-modal Virtual Point detector (MVP) that generates dense 3D virtual points near target objects by mapping RGB measurements into the scene using depth measurements from the Lidar sensor. The MVP method addresses the density imbalance between close and faraway objects and can be added as a module to existing 2D or 3D detectors. Experimental results on the nuScenes dataset show that the MVP approach significantly improves object detection accuracy compared to a baseline method.