Question answering (QA) is a fundamental task in artificial intelligence (AI) that requires machines to answer questions given a context. However, QA models often over-exploit training bias, leading to a degradation in performance in out-of-distribution (OOD) test scenarios. In this paper, we propose a training paradigm called Introspective Distillation (IntroD) to blend the inductive bias of both in-distribution (ID) and OOD worlds fairly. We introduce two expert teacher models – ID-teacher and OOD-teacher – to capture the ID and OOD inductive bias, respectively. Our approach achieves strong performance in both ID and OOD evaluations, and experiments on visual QA and extractive QA datasets validate its effectiveness. We also show that the success of IntroD is due to causal introspection rather than simple ensemble methods.