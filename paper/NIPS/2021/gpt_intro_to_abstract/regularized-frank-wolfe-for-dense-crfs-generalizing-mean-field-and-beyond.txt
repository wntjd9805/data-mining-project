Fully-connected or dense conditional random fields (CRFs) have been a successful approach in semantic segmentation when combined with strong pixel-level classifiers like convolutional neural networks (CNNs). However, as CNNs have become stronger, the improvements brought by CRFs have decreased, leading to a decline in their popularity. In this paper, we propose a new class of algorithms called regularized Frank-Wolfe for inference and learning of CRFs. These algorithms optimize a nonconvex continuous relaxation of the CRF inference problem and show promising results. We also provide a tightness analysis for the resulting nonconvex relaxation. Additionally, we re-implement various existing first-order inference methods for comparison and find that CRFs can still achieve significant improvements over CNN models. Our best algorithm achieves a high mean intersection-over-union score on the PASCAL VOC test set, surpassing the performance of DeepLabv3+. We believe that these results could reignite interest in using dense CRFs for semantic segmentation tasks.