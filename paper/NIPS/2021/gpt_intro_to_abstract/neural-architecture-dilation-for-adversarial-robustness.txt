This paper introduces a novel approach, Neural Architecture Dilation for Adversarial Robustness (NADAR), that focuses on designing neural networks that can perform well in both standard and adversarial classification tasks. The authors propose a dilation architecture that aims to maximize robustness while minimizing the drop in accuracy. They also consider the computational cost of the network by applying a FLOPs-aware approach. The authors provide theoretical analysis and experimental results on benchmark datasets to demonstrate the effectiveness of their approach. This research contributes to a deeper understanding of the accuracy and robustness trade-off in neural network architectures.