In this paper, we introduce Convolutional Normalization (ConvNorm), a new normalization method designed specifically for Convolutional Neural Networks (ConvNets). We exploit the translation-invariance properties of convolutional operators to normalize each output channel for each layer of ConvNets. Unlike traditional normalization methods, ConvNorm is easy to implement and does not require hyperparameter tuning or heavy computation. Additionally, our method improves network robustness and training efficiency. We demonstrate these advantages through numerical experiments on standard image datasets.