Graph neural networks (GNNs) have been successful in processing structured inputs such as molecules or social networks. However, their performance drops significantly when their depth increases, limiting their ability to capture long-range dependencies in whole-graph classification and regression tasks. In this paper, we propose a novel approach called Graph Transformer (GraphTrans) that combines a standard GNN with a global Transformer subnetwork to learn both local and global relationships in a graph. We show that this approach improves GNN accuracy, particularly for large graph classification tasks. Additionally, we introduce a GNN readout module that aggregates all pairwise interactions into a single classification vector, achieving better performance than existing aggregation methods. Experimental results on various datasets demonstrate the effectiveness of our approach, with GraphTrans achieving state-of-the-art results on OpenGraphBenchmark and NCI biomolecular datasets.