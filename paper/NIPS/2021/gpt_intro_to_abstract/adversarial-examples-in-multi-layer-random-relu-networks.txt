The phenomenon of adversarial examples in deep networks has attracted significant interest in the field of computer science. Researchers have studied the reasons behind the extreme sensitivity of deep networks to small input perturbations and how to detect and avoid them. Previous studies have focused on specific network architectures, such as ReLU networks, and have proven the existence of adversarial examples in certain conditions. In this paper, we extend these findings and demonstrate that adversarial examples also arise in deep ReLU networks with random weights for a wide variety of network architectures. We show that the functions computed by these networks are very close to linear, resulting in the susceptibility to adversarial examples. Our results indicate the need for further investigation into the behavior of deep networks with random weights and the impact of network depth and width on the sensitivity to input perturbations.