Semi-supervised learning (SSL) has gained attention for its ability to leverage large amounts of unlabeled data, especially when labeled data is limited or difficult to obtain. Techniques such as consistency regularization and pseudo labeling have been widely used in modern SSL algorithms. However, popular SSL algorithms like FixMatch rely on a fixed threshold to compute the unsupervised loss, ignoring a significant amount of other unlabeled data. Additionally, these algorithms treat all classes equally without considering their varying learning difficulties. To address these issues, we propose Curriculum Pseudo Labeling (CPL), a curriculum learning strategy that dynamically adjusts thresholds for each class based on their learning status. This strategy, implemented in the improved algorithm FlexMatch, significantly enhances convergence speed and achieves state-of-the-art performance on SSL image classification benchmarks. Furthermore, we open-source TorchSSL, a PyTorch-based codebase for semi-supervised learning research, facilitating the study and customization of SSL algorithms.