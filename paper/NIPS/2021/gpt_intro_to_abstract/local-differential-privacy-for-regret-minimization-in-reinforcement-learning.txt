Reinforcement Learning (RL) algorithms have become widely used in various domains, including digital marketing, healthcare, and finance, where personalized services are desirable. However, concerns about privacy arise as these algorithms often require access to sensitive personal information. In this paper, we explore the impact of privacy-preserving measures, specifically Differential Privacy (DP) and Local Differential Privacy (LDP), on the learning problem in RL. We provide a regret lower bound for LDP and propose the first LDP algorithm for regret minimization in RL. Additionally, we present different privacy-preserving mechanisms compatible with LDP and evaluate their impact on the learning process through numerical simulations.