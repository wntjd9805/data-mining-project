In this paper, we revisit the analysis of the forward regression algorithm in the context of stochastic linear regression with sub-Gaussian noise. We compare the performance of the forward algorithm to the classical ridge regression strategy and investigate whether the conclusions from the adversarial bounded case hold in the stochastic setup. We demonstrate that the existing adversarial analysis is insufficient in capturing important phenomena, such as the concentration of the parameter estimate. We provide a refined analysis of the forward algorithm and show that it outperforms ridge regression in the unbounded sub-Gaussian linear regression scenario. We discuss the implications of this result in the practical application of stochastic linear bandits.