Decision trees and tree ensembles are commonly used in practical applications due to their simplicity, fast inference, and interpretability. However, traditional decision trees suffer from limitations such as exponential growth in size and inefficiency due to non-shared nodes. In this paper, we propose a novel model called Tree in Tree (TnT) that addresses these limitations by replacing the internal and leaf nodes with micro decision trees arranged in a Directed Acyclic Graph (DAG) structure. Our contributions include extending decision trees to decision graphs, developing a scalable algorithm for constructing large decision graphs, and demonstrating superior performance compared to existing decision trees/graphs. Additionally, our algorithm is capable of learning graph connections from scratch and provides a fully interpretable decision process. A Python implementation of TnT is available at the provided link.