This paper introduces the concept of causal bandits, a type of structured bandit problem where actions are interventions on variables of a causal graph. The authors highlight the real-world applications of causal bandits, such as healthcare, email campaigns, and genetic engineering. They discuss existing works on causal bandits that require significant prior knowledge of the causal graph, and propose the goal of developing causal bandit algorithms that do not rely on this prior knowledge and achieve stronger worst-case regret guarantees. The authors analyze different classes of causal graphs and present their contributions, including a novel algorithm called Central Node UCB (CN-UCB) for directed trees and causal forests, and generalizations for a wider range of graph classes. They also emphasize that exact causal graph recovery is not necessary for maximizing rewards in causal bandits.