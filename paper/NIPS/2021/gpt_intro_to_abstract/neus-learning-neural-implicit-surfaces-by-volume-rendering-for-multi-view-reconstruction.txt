Reconstructing surfaces from multi-view images is a fundamental problem in computer vision and computer graphics. Traditional approaches to 3D reconstruction have limitations when it comes to complex objects with non-Lambertian surfaces and thin structures. In recent years, neural implicit representations have emerged as a promising alternative due to their high reconstruction quality. These methods use differentiable surface rendering techniques to render 3D objects into images for training neural models. However, current surface rendering methods often fail to handle abrupt depth changes and can result in poor local minima during optimization. To address these limitations, we propose NeuS, a new neural rendering scheme that combines the accuracy of the signed distance function (SDF) representation with the robustness of volume rendering. Our approach leverages a novel volume rendering scheme to learn an implicit SDF representation, enabling accurate surface reconstruction even in the presence of abrupt depth changes. Experimental results demonstrate that NeuS outperforms state-of-the-art methods in terms of reconstruction quality, particularly for complex objects with occlusions and delicate structures.