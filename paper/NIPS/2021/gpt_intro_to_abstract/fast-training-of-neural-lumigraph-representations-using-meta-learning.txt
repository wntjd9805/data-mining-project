Learning 3D scene representations from 2D images is a crucial problem in machine learning, computer vision, and computer graphics. The ability to parameterize the scene and efficiently infer the parameters from observations is a key challenge in this field. Existing approaches, such as NeRF and coordinate-based networks, offer photorealistic quality but are slow to train and render. Other methods that use proxy geometry with surface feature aggregation are faster but limited in quality and runtime by traditional computer vision algorithms. In this paper, we propose a new framework that combines a surface-based neural rendering approach with meta learning to achieve fast training and rendering times. Our representation directly parameterizes an implicit surface, allowing real-time extraction and rendering. By combining shape representations and image features, we demonstrate the ability to train high-quality scene representations in minutes or tens of minutes and render them in real-time.