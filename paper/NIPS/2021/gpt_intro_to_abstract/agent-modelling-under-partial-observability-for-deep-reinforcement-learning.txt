This paper introduces Local Information Agent Modelling (LIAM), a method for effective agent modelling using only locally available information. The goal is to learn the relationship between the trajectory of the controlled agent and the trajectory of the modelled agent. LIAM employs an encoder-decoder agent modelling approach, where the encoder extracts informative features from the controlled agent's local observations and past actions, and the decoder replicates the observations and actions of the modelled agents. The learned representation is used to condition the policy of the controlled agent during the RL learning process. The effectiveness of LIAM is evaluated in three multi-agent environments, showing that it outperforms baseline methods and achieves comparable results to an ideal baseline with access to the modelled agent's trajectory. Detailed evaluations and comparisons of LIAM are also provided.