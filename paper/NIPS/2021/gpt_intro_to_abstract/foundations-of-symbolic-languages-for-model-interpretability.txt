This paper introduces the concept of interpretability in machine learning models and the importance of being able to answer questions about these models. The authors propose a logical language called FOIL, which allows users to express interpretability queries. They also discuss the computational cost of evaluating FOIL queries on decision trees and ordered binary decision diagrams. The paper concludes with the introduction of a user-friendly language and a prototype implementation that can be used to query decision trees and evaluate FOIL queries efficiently. The practical implementation is tested on synthetic and real data, demonstrating the usability of FOIL as a base for practical interpretability languages.