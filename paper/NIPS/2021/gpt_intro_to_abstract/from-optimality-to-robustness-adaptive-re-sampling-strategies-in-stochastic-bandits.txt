The K-armed stochastic bandit model is a decision-making problem where a learner selects actions and collects rewards. The objective is to maximize the expected sum of rewards by adapting the learner's strategy. This paper discusses existing strategies for bandit algorithms and their guarantees, as well as the motivations for alternative setups that require less knowledge on the distributions. The paper introduces the Dirichlet Sampling algorithm as a generalization of Non-Parametric Thompson Sampling, and presents regret guarantees for different families of distributions. A use-case in agriculture is also presented to demonstrate the effectiveness of Dirichlet Sampling.