Causal structure learning involves inferring a causal model from data, which is of interest to various academic disciplines. Directed acyclic graphs (DAGs) are commonly used to represent causal relationships, but their assumptions have been questioned. In this paper, we focus on learning the DAG of linear additive noise models (ANM). We discuss the importance of data scale and marginal variance in structure learning, as they can provide information about the data generating process. We also examine the performance of continuous structure learning algorithms and investigate the impact of data standardization on the recovery of the ground-truth DAG. Our findings demonstrate that the information carried by data scale, as measured by varsortability, plays a crucial role in achieving accurate causal structure identification. These results highlight the limitations of current benchmark methods and provide insights into the performance of structure learning algorithms in real-world scenarios.