Recent years have seen significant advancements in human pose estimation, with efforts focused on learning generic deep networks on large-scale human pose datasets. However, there is also a line of research aimed at personalizing and customizing human pose estimation for individual subjects. While it is possible to adapt the model to capture person-specific features using long videos or multiple photos, labeling large-scale data for just one person is expensive and impractical. In this paper, we propose a method called Test-Time Personalization, where we personalize human pose estimation with unlabeled video data during test time. We adopt the general paradigm of Test-Time Adaptation, where a generic model is first trained with diverse data and then fine-tuned to adapt to a specific instance during test time without human supervision. This approach allows the model to generalize to out-of-distribution data and preserve privacy during distributed training. Our method combines supervised and self-supervised keypoint estimation tasks using a Transformer model, enabling improved pose estimation by transforming self-supervised keypoints. The experiments conducted on multiple human pose estimation datasets demonstrate the effectiveness of our approach, with significant improvements over baselines observed. Additionally, our method's performance improves with the availability of more video frames for the same person during test time.