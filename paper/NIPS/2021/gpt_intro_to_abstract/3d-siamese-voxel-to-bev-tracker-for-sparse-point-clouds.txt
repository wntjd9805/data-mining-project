Object tracking is a critical task in computer vision, particularly in applications such as autonomous vehicles, mobile robotics, and augmented reality. While most previous efforts have focused on 2D object tracking using RGB data, recent attention has shifted towards 3D object tracking using sensors like LiDAR and Kinect. However, 3D object tracking on point clouds remains a challenging task due to their sparsity. This paper proposes a novel Siamese voxel-to-BEV (Bird's Eye View) tracker that aims to improve the tracking performance of 3D single object tracking, especially in sparse point clouds. The proposed framework incorporates shape-aware feature learning and voxel-to-BEV target localization to better distinguish the target from the background and accurately predict the target's center. Experimental results demonstrate that the proposed method achieves state-of-the-art performance on the KITTI dataset and shows good generalization ability on the nuScenes dataset.