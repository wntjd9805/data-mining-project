Graph convolution networks (GCN) and Graph neural networks (GNN) have emerged as powerful tools for representation learning in graph-structured data. These networks update node representations using graph convolution or message passing operators, enabling the capture of information from immediate and distant neighbors. However, the computational challenges posed by large-scale industrial datasets limit the effectiveness of these models. Sampling methods have been proposed to address this issue, but existing approaches lack guarantees on sampling variance reduction and do not adapt to the dynamics of embeddings. In this paper, we propose a novel reward function and algorithm called Thanos, which improves upon existing sampling methods by incorporating stability, reduced variance, and consideration of GNN training dynamics. Empirical results demonstrate the effectiveness of Thanos in terms of variance reduction and generalization performance.