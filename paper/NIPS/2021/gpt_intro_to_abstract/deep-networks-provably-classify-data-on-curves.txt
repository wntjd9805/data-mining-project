This paper introduces the problem of identifying low-dimensional structure in high-dimensional data in the fields of applied machine learning, engineering, and the sciences. The authors discuss the challenges of modeling probabilistic variability induced by the distribution of geometries and geometric variability associated with physical nuisances such as pose and illumination. They highlight the success of convolutional neural networks in image classification and propose studying how neural networks compute with data lying near a low-dimensional manifold as a step towards understanding their invariance to continuous transformations. Additionally, they examine the problem of classifying manifold-structured data and its applications in scientific and engineering domains. The paper presents the multiple manifold problem as a mathematical model and aims to determine how the structure of the data influences the resources required for generalization. The authors analyze the problem within the neural tangent kernel regime and provide a novel perspective on the role of network depth as a fitting resource in classification. They conclude by discussing the implications of their findings and the broader implications for understanding how neural networks compute with real data.