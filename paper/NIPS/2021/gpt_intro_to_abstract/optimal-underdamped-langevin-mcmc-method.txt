Sampling is a crucial research problem in statistics learning, with various applications in different areas such as Bayesian inference, multi-arm bandit optimization, and reinforcement learning. One of the key challenges in these applications is the sampling from a high-dimensional strongly-log-concave distribution. Recent advancements have proposed Markov chain Monte Carlo (MCMC) methods based on underdamped Langevin diffusion (ULD) to address this problem. These methods approximate the ULD process and enable the sampling from the target distribution with a certain level of accuracy. Several discretization methods have been proposed for approximating ULD, with each method having its own advantages and limitations. While the ULD-MCMC methods with full gradient oracle are well-understood, many real-world applications involve large-scale data and require stochastic gradient methods. In this paper, we focus on the optimal ULD-MCMC method with sum-decomposable potential and analyze its gradient complexity in terms of the dimension, component number, and accuracy. We propose a new full gradient ULD-MCMC method called AcceLerated ULD method (ALUM), which achieves the same asymptotic complexity as the existing RMM method but with a practical advantage of using less frequent gradient evaluations. Additionally, we introduce VR-ALUM methods that leverage unbiased variance reduction techniques and achieve improved gradient complexity compared to existing gradient-based MCMC approaches. We also provide an information-based lower bound on the worst-case error for estimating a ULD process and show that the VR-ALUM methods are optimal under the sum-decomposable setting.