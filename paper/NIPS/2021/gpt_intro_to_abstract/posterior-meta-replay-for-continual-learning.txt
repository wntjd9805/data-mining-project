In recent years, continual learning (CL) algorithms have been developed to address the limitations of training neural networks with independent and identically distributed (i.i.d.) samples. Most CL research focuses on learning a sequence of tasks without access to the overall joint distribution. Bayesian approaches have been used to find a combined posterior distribution via a recursive Bayesian update, but these methods have limitations and depend on factors like task ordering and similarity. In this paper, we propose an alternative Bayesian approach called posterior meta-replay, which learns task-specific posteriors without relying on the recursive update. We introduce probabilistic extensions of task-conditioned hyper-networks to achieve this and show that our approach outperforms prior-focused methods in task-agnostic inference settings. We also address challenges related to forgetting and task inference and demonstrate the scalability of our approach to modern architectures. Additionally, we improve existing Bayesian CL methods by introducing task-specific parameters and explicitly inferring the task.