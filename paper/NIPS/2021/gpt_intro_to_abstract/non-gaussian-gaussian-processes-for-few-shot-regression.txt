Gaussian Processes (GPs) are widely used probabilistic methods for modeling distributions over functions. They have been successfully applied in various applications, including multi-modal regression and time-series prediction. However, GPs have limitations when it comes to complex distributions or scenarios with few labeled samples. In this paper, we propose Non-Gaussian Gaussian Processes (NGGPs) to address these drawbacks. We leverage Continuous Normalizing Flows (CNF) to model arbitrary probability distributions and use an invertible ODE-based mapping to incorporate contextual information. We demonstrate the effectiveness of NGGPs in capturing complex structures and achieving state-of-the-art performance in few-shot learning scenarios through extensive benchmark testing.