Variational autoencoders (VAE) are powerful generative models that combine probabilistic modeling with neural networks. However, VAE often suffer from posterior collapse, where the latent variables become non-informative. This phenomenon is not specific to VAE and can occur in classical probabilistic models as well. Existing methods for avoiding posterior collapse adjust the inference procedure, but we propose a solution by making the latent variables identifiable. Our proposed latent-identifiable VAE resolves non-identifiability using Brenier maps and input-convex neural networks. We show that identifiable VAE mitigates posterior collapse without sacrificing fidelity to the data.