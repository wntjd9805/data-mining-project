As data sets grow in size and complexity, the challenges and opportunities for large-scale applications of online learning increase. The passive-aggressive learning approach has been successful for simple linear models, but extending it to nonlinear models, such as decision trees and neural networks, is more complex. This paper investigates a family of low-rank models for quadratic classification and shows how to derive passive-aggressive updates for these models by solving a quadratically constrained quadratic program. The paper's main contribution is extending the framework of passive-aggressive learning to a larger family of nonlinear models. The paper is organized as follows: a review of related work, formulation of the model and updates for passive-aggressive learning, experimental results, and concluding remarks with directions for future work.