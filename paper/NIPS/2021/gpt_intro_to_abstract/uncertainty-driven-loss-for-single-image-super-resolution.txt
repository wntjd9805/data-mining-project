Single image super-resolution (SISR) aims to reconstruct high-resolution (HR) images from degraded low-resolution (LR) images. Recent works in deep learning-based approaches have shown that deeper and more complex networks can improve SISR performance by enhancing the reconstruction of high-frequency details in images. However, the commonly used practice of using MSE or L1 loss treats every pixel equally, regardless of its importance in texture/edge regions or smooth areas. This paper proposes a new adaptive weighted loss for SISR that assigns higher weights to texture and edge areas during training, taking into account the uncertainty of these regions. By estimating the variance field underlying the HR image and incorporating it into the training process, the proposed approach achieves higher visual quality and improved objective performance. Experimental results demonstrate the effectiveness of the proposed uncertainty-driven loss compared to traditional loss functions.