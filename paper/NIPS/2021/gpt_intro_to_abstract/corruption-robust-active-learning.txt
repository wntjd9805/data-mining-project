Active learning algorithms aim to obtain the best hypothesis or classifier from a given hypothesis set while requesting as few labels as possible. This approach is particularly useful for applications where large datasets are needed but the cost of labeling is prohibitive. However, in the streaming setting, where labels may be potentially corrupted by an adversary, active learning becomes challenging as the learner has no knowledge of when or how many corruptions will occur. Existing active learning algorithms do not adequately handle label corruptions. In this paper, we propose a new algorithm that can achieve nearly the same label complexity as in the non-corrupted setting, matching the performance of existing algorithms, and requiring only a small number of additional labels in the general corruption case.