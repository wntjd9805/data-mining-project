Deployed machine learning systems often face the challenge of distribution shift, where the new data differs from the data the system was trained on. This can have severe consequences for systems like self-driving cars and financial trading algorithms. Online learning algorithms can mitigate these issues by updating the model on new, representative data. However, there is a tradeoff between adapting to new data and remembering previous training data. This paper proposes a Bayesian online learning framework that addresses non-stationary data distributions by inferring distribution shifts from the data and allowing the model to partially forget irrelevant information. The framework incorporates a discrete "change variable" that determines whether the new data is compatible with the previous distribution and uses beam search for change detection and Bayesian online learning. The proposed framework is tested on various real-world datasets with concept drift and demonstrates improved performance. The paper concludes by discussing related work, describing the methods, presenting experimental results, and drawing conclusions.