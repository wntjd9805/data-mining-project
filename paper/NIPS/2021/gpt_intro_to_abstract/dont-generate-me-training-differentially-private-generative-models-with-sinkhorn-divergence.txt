Modern machine learning algorithms have become increasingly reliant on personal data, raising concerns about privacy protection. Differential privacy offers a rigorous definition of privacy by quantifying the amount of information leaked by a user participating in data release. Generative models have emerged as a potential solution for sharing data while preserving privacy, as they can synthesize similar yet different data without repeated interactions with the data curator. However, it has been observed that generative models can reveal private information about their training data. This paper introduces DP-Sinkhorn, a method for training differentially private generative models using a semi-debiased Sinkhorn loss. DP-Sinkhorn is based on the framework of optimal transport and approximates the optimal transport distance using the Sinkhorn iteration method. It also proposes a novel technique to control the bias-variance trade-off in estimating gradients. The authors demonstrate state-of-the-art performance on image modeling benchmarks and generate high-quality images under strict differential privacy.