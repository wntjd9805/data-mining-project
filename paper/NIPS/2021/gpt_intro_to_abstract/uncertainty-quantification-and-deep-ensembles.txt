In this paper, we investigate the use of deep-ensembles, temperature scaling, and mixup data augmentation in the low-data regime of deep learning. We find that standard ensembling practices do not lead to better-calibrated models, but instead result in less confident predictions. We also observe that networks trained with mixup data augmentation are typically under-confident, and that the distributional shift induced by mixup affects the calibration properties of the trained neural networks. We suggest using temperature scaling in conjunction with deep-ensembling methods to mitigate under-confidence, and propose the Pool-Then-Calibrate strategy for post-processing deep-ensembles to significantly reduce Expected Calibration Error. Our findings provide insights into improving uncertainty quantification in deep learning models in low-data scenarios.