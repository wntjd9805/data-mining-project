Meta-learning, or learning to learn, aims to extract meta-knowledge from seen tasks in order to accelerate learning on unseen tasks. Many meta-learning algorithms operate on two levels: a base learner learns task-specific models in the inner loop, and a meta-learner learns the meta-parameter in the outer loop. However, existing meta-learning algorithms have limitations, such as requiring a large number of training samples or being infeasible for large models. This paper proposes a kernel-based algorithm that meta-learns a proximal regularizer for a nonlinear base learner, addressing these limitations. The algorithm is guaranteed to converge to a critical point of the meta-loss and has demonstrated superior performance on various benchmark regression and classification datasets.