This paper addresses the challenge of how meaningful communication can emerge in artificial agents without a common language. The authors observe that decentralized models of communication perform poorly, and propose a novel framework inspired by language learning in nature. They suggest grounding multi-agent communication by first learning representations of the world through autoencoding, and then interpreting grounded utterances. Experimental results demonstrate the effectiveness of this approach in improving communication and coordination in multi-agent settings. The authors highlight the importance of visual grounding in the problem of emergent communication.