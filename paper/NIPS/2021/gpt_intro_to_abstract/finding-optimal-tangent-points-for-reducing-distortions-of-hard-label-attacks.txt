Adversarial attacks on deep neural networks (DNNs) involve perturbing benign images to cause incorrect predictions. These attacks can be categorized as white-box or black-box attacks, depending on the information available about the target model. While white-box attacks have been extensively studied, black-box attacks are more practical as they do not require access to the target model's gradients. Transfer-based black-box attacks use a surrogate model to generate adversarial examples, while query-based attacks use feedback from the target model. However, query-based attacks face challenges in real-world scenarios with limited feedback and discontinuous objective functions. This paper proposes a geometric-based approach for minimizing distortions in black-box attacks. The approach discovers the optimal tangent point on a virtual hemisphere around the adversarial example, resulting in minimum distortion. Experimental results on CIFAR-10 and ImageNet datasets demonstrate the effectiveness of the proposed approach.