Image classification has been greatly improved by convolutional neural networks (CNNs), but their lack of adversarial robustness poses security concerns in high-stakes applications. Adversarial training (AT) has been successful in defending against adversarial attacks but is limited to supervised learning. Recent work has explored semi-supervised defenses, but there is a need for unsupervised defenses that improve model robustness without labeled data. This paper introduces ADVCL, a unified adversarial contrastive learning (CL) framework, and proposes generating pseudo-supervision stimulus based on clustering information for improved cross-task robustness transferability. Experimental results show that ADVCL achieves state-of-the-art robust accuracies using only standard linear finetuning, outperforming existing self-supervised methods.