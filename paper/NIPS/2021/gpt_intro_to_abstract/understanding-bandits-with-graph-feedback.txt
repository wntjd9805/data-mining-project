The multi-armed bandit problem in reinforcement learning involves a player facing a scenario where they need to choose between multiple options, each with potential losses. The player receives feedback after each round and aims to minimize regret, which is the difference between their cumulative losses and the cumulative losses of the best option. This paper focuses on the adversarial bandit problem, where losses are given in an adversarial fashion. The paper explores the impact of graph structures on regret and introduces parameters such as the fractional weak domination number and the k-packing independence number to improve bounds on regret. The paper also presents algorithms and lower bounds for different types of graphs. Overall, the paper makes progress in understanding how graph structure affects regret in the adversarial bandit problem.