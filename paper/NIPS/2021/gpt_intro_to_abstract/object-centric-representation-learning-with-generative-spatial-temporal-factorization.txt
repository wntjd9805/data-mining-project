In this paper, we propose a novel unsupervised framework called DyMON for multi-view object-centric representation learning in dynamic-scene settings. We address the challenge of temporal entanglement between scene structures and viewpoints by making weak assumptions about high frame rate observation sequences and significant differences in speeds between the observer and objects. This allows DyMON to learn the generative relationships between scenes and observations, and addresses the problem of scene spatial-temporal factorization. Experimental results demonstrate that DyMON is capable of training and performing object-oriented inference on multi-view-dynamic-scene data, recovering independent generative mechanisms, and enabling single-object manipulation in both space and time.