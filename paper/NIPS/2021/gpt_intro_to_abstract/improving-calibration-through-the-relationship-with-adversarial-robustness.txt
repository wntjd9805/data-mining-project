The robustness of machine learning algorithms and the calibration of their predictions are crucial factors in high-stakes applications. In this paper, we explore the relationship between adversarial robustness and calibration, finding that data points vulnerable to adversarial attacks are more likely to have poorly calibrated predictions. To address this issue, we propose a method called Adversarial Robustness based Adaptive Label Smoothing (AR-AdaLS) that adaptively smooths training labels based on the input's vulnerability to adversarial attacks. Experimental results on CIFAR-10, CIFAR-100, and ImageNet datasets demonstrate the effectiveness of AR-AdaLS in improving calibration and its ability to handle shifts in data distribution. Additionally, we introduce "AR-AdaLS of Ensemble" to combine AR-AdaLS with deep ensembles, further enhancing calibration performance. Our contributions include uncovering the correlation between adversarial robustness and calibration, proposing the AR-AdaLS algorithm, and conducting experimental analyses to validate its effectiveness.