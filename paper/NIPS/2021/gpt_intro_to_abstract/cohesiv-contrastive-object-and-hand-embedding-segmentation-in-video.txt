This paper addresses the challenge of segmenting hand and in-hand objects from a single image by learning from video data. While there has been progress in segmenting objects for specific categories, segmenting generic objects in contact remains challenging. The proposed approach utilizes a small amount of knowledge about humans to guide understanding of optical flow data. A network called COHESIV is implemented to segment the hand and interacting object based on RGB images and hand location inputs. Training and validation are conducted using video data from various datasets. The proposed method is compared to alternate approaches and demonstrates comparable performance to supervised bounding box methods while outperforming flow and saliency methods.