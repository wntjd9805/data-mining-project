In this paper, we propose a signal-agnostic approach called GEM (Generative Embedded Manifold) that learns and discovers a low-dimensional manifold in a variety of signals, including images, 3D shapes, audio, and cross-modal audiovisual signals. We address the limitations of existing generative models by utilizing neural fields to model signal distributions and hypernetworks to regress individual neural fields from a latent space. We formulate explicit learning objectives to ensure data coverage, local linearity, and global consistency, resulting in a model that captures the manifold of signals with minimal architecture modifications. We demonstrate the effectiveness of GEM in recovering the global structure of each signal domain, allowing for interpolation, completion, and generation of new samples.