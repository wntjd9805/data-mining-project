Unsupervised domain adaptation (UDA) has gained attention in recent years as a way to adapt models from a labelled source domain to an unlabelled target domain. While progress has been made in deep UDA methods for images, there is a lack of methods for videos. Existing approaches for video action recognition often overlook crucial temporal information and rely on complex adversarial learning. In this paper, we propose a simple yet effective approach called Contrast and Mix (CoMix) that leverages contrastive learning to adapt video action recognition models to target domains. We represent videos as graphs and use temporal contrastive self-supervised learning to align features between domains without requiring adversarial learning. We also incorporate synthetic videos that mix backgrounds from different domains to better capture shared action semantics. Additionally, we generate pseudo-labels for target samples and use a temporal supervised contrastive term to enhance discriminability in the latent space. Our approach is the first to successfully leverage contrastive learning for unsupervised video domain adaptation.