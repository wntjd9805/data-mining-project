This paper introduces the concept of domain generalization in machine learning, where a model is trained on multiple source domains to generalize well to unseen target domains. It highlights the challenge of domain generalization compared to domain adaptation, where the learner doesn't have access to target domain data. The paper focuses on learning an invariant representation across domains and addresses the limitations of existing methods. The proposed approach enforces the invariance of the representation network under domain density transformation functions, learned through generative adversarial networks (GANs). Extensive experiments demonstrate the effectiveness of the method on various datasets, with significant improvements over baselines. The contributions include providing observations and conditions for domain-invariant representation, proposing a theoretically grounded method, and evaluating its performance against state-of-the-art models.