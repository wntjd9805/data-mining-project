This paper introduces iterative amortized policy optimization, a technique that leverages the connection between amortized variational inference and policy optimization. The authors demonstrate the performance improvements of this technique over direct amortized policies, as well as more complex flow-based policies, using the MuJoCo environments. Additionally, they highlight the benefits of this amortization approach, including improved accuracy, the ability to provide multiple policy estimates, and generalization to new objectives.