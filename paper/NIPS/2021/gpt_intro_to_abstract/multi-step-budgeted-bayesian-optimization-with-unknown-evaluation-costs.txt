Bayesian optimization (BO) is a widely used algorithm for optimizing black-box functions. However, most BO algorithms do not consider the fact that the cost of evaluating the black-box function may vary across the optimization domain and is often unknown. This can lead to inefficient evaluations and poor performance. In this paper, we propose a principled approach to budgeted BO with unknown and potentially heterogeneous evaluation costs. We formulate the problem as a Markov decision process (MDP) and introduce a novel look-ahead acquisition function called Budgeted multi-step expected improvement (B-MS-EI). Our empirical evaluation demonstrates that B-MS-EI outperforms other acquisition functions in settings with heterogeneous costs.