Supervised machine learning for graph-structured data is widely used in various domains. Graph neural networks (GNNs) are a popular approach for graph classification and regression tasks. However, GNNs have limitations in terms of representation and generalization performance. In this paper, we explore the connection between graph theory and GNNs, specifically focusing on graph reconstruction. We introduce k-Reconstruction Neural Networks, a class of expressive GRL architectures that leverage k-reconstruction of graphs. We demonstrate that k-Reconstruction GNNs outperform traditional GNNs in terms of expressive power and performance. Theoretical analysis shows that k-Reconstruction GNNs can distinguish graph classes that traditional methods cannot, while empirical results demonstrate improved performance on both synthetic and real-world datasets. Overall, this work highlights the potential of incorporating graph reconstruction techniques in GNNs for enhanced expressive power and performance.