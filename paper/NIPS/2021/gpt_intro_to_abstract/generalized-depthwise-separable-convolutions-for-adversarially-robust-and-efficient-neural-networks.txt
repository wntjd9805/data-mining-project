Convolutional neural networks (CNNs) have emerged as the leading classification algorithm in machine learning, particularly for image classification tasks. However, their use in safety-critical Edge applications is limited due to their high computational costs and vulnerability to adversarial samples. Existing methods have focused on either model compression or robustness, but few have addressed the challenge of designing both efficient and robust CNNs. In this paper, we propose Generalized Depthwise-Separable (GDWS) convolutions, a universal post-training approximation of standard 2D convolutions that significantly improves the real hardware frames-per-second (FPS) of pre-trained networks without sacrificing robust accuracy. We demonstrate through experiments on CIFAR-10, SVHN, and ImageNet datasets that GDWS achieves higher robustness and FPS compared to existing complexity reduction techniques, without requiring additional training. Our work also showcases the versatility of GDWS in designing efficient and robust networks for union of norm-bounded perturbation models, a novel contribution in this field.