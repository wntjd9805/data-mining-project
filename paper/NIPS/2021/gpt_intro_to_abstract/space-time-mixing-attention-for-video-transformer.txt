This paper introduces a Video Transformer model for improving the accuracy of video recognition. The authors propose a solution to minimize the computational burden while exploiting temporal information in video streams. They compare their model to other approaches and demonstrate that it outperforms them in terms of efficiency and recognition accuracy on popular video recognition datasets. The proposed model achieves this by making approximations to full space-time attention and utilizing lightweight mechanisms for global temporal-only attention. The results show that the model effectively captures long-term dependencies and achieves high recognition accuracy.