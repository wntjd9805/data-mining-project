Animals play a crucial role in various fields such as zoology, farming, and ecology, but the progress in modeling animal pose and shape has been relatively slow due to the lack of labeled data. While some works have used synthetic data or 2D weak supervision to train models, these approaches have limitations in generating realistic images and capturing pose and shape variations. In this paper, we propose a coarse-to-fine approach for learning 3D animal pose and shape with only 2D weak supervision. We address the challenges of reconstructing the 3D mesh from a single RGB image by combining parametric and non-parametric representations. We also introduce an encoder-decoder structured GCN that utilizes both global and local features to capture overall structure and detailed shape information. Experimental results demonstrate that our approach achieves state-of-the-art performance on three animal datasets.