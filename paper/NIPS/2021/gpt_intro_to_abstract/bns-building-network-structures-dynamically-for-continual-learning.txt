Continual learning (CL) is the process of incrementally learning a sequence of tasks in a neural network, but it often faces the challenge of catastrophic forgetting (CF). This paper focuses on task continual learning (Task-CL) and explores techniques to prevent CF and enable knowledge transfer across tasks. Existing methods for CF prevention include regularization-based methods, replay-based methods, and structure-based methods. However, knowledge transfer has received relatively little attention in Task-CL algorithms. To address this, the paper proposes a reinforcement learning-based technique called Building Network Structures dynamically for CL (BNS) that simultaneously prevents CF and facilitates knowledge transfer. BNS consists of a neural structure search agent, a set of actions, and an environment that includes task data, a continual learner, a knowledge repository, and a replay buffer. Experimental results demonstrate that BNS outperforms existing Task-CL baselines in terms of accuracy and knowledge transfer across a variety of datasets.