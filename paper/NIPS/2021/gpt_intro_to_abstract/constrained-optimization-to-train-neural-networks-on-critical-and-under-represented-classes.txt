Deep Neural Networks (DNNs) excel in classification tasks with large and representative datasets, but encounter problems when faced with highly imbalanced class distributions. This issue is particularly problematic in critical applications like medical imaging, where misclassifying minority classes can have severe consequences. Existing methods for learning with imbalanced datasets do not prioritize accuracy for critical classes. To address this, we propose a novel constraint for training DNNs in binary classification, using Mann-Whitney statistics to maximize AUC while reducing false positives. We optimize this constrained problem using an Augmented Lagrangian method, incorporating AUC optimization into a principled framework. Evaluation on multiple datasets demonstrates the effectiveness of our method compared to baseline approaches.