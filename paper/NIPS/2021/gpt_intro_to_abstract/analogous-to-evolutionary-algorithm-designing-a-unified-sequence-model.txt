This paper introduces the concept of an Evolutionary Algorithm-based Transformer (EAT) inspired by the success of the Vision Transformer (TR). The authors explain the rationale behind the TR by drawing an analogy to the Evolutionary Algorithm, highlighting the similarities in training procedures and mathematical representations. They propose the EAT model, which incorporates a dynamic local population concept and a Task-related Head for improved flexibility in handling various tasks. Additionally, they introduce a Space-Filling Curve (SFC) module that allows for standardized input of multi-modal data. The authors conduct extensive experiments on classification and multi-modal tasks to demonstrate the effectiveness and flexibility of their approach.