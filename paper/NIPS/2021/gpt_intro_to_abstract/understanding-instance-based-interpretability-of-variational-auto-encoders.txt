Instance-based interpretation methods have gained popularity in supervised learning for explaining model predictions and have various applications. However, these methods are less understood in the context of unsupervised learning, particularly in generative models. In this paper, we investigate instance-based interpretations for unsupervised learning by leveraging influence functions. We analyze classical non-parametric and parametric methods and explore their application in variational auto-encoders (VAE), a deep generative model. We address the challenges of framing the counter-factual question and computing influence functions in VAE. We propose VAE-TracIn, a fast and efficient method that approximates influence functions without involving the Hessian matrix. We evaluate VAE-TracIn on real-world datasets and demonstrate its potential in various unsupervised learning tasks, such as data cleaning and model analysis. Our contributions include the formal framing of instance-based interpretations for unsupervised learning, examination of influence functions in classical methods, introduction of VAE-TracIn, and empirical evaluation with extensive analysis and visualization.