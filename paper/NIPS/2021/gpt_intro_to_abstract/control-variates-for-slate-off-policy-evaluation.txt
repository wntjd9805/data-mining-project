Online services often serve content in the form of a combinatorial, high-dimensional slate, with multiple values in each slot. Personalization of this content is typically done through machine learning and A/B testing, but testing and optimization become challenging when there are hundreds or thousands of eligible items per slot. In this paper, we explore the use of off-policy evaluation (OPE) as an alternative to A/B testing, using historical data to evaluate new candidate policies. We discuss the variance issues in handling a combinatorial action space and propose a control variates approach to further reduce this variance. Through empirical evidence, we demonstrate the superiority of our approach compared to existing estimators.