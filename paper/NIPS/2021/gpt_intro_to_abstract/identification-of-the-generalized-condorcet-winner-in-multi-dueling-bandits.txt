The standard multi-armed bandit (MAB) problem involves selecting one choice alternative from a set of options at each time step to maximize the observed reward. One variant of this problem is the dueling bandits scenario, where two arms compete in each time step and the winner is observed. The multi-dueling bandits setting extends this concept by allowing for the selection of a set of arms to compete against each other. This paper focuses on identifying the generalized Condorcet winner (GCW) in the multi-dueling bandits setting, which is an arm that outperforms all other arms in every query set containing both arms. The sample complexity of identifying the GCW is analyzed, with upper and lower bounds depending on various factors such as confidence level, number of alternatives, size of query sets, and unknown preference probabilities. The paper also discusses special cases and provides optimal solutions. Empirical comparisons are conducted, and detailed proofs are provided in the supplemental material.