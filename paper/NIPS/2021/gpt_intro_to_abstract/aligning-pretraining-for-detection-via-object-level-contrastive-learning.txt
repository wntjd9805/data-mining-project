Pretraining and finetuning of deep neural networks in computer vision have traditionally relied on large labeled datasets for initialization. However, self-supervised pretraining has emerged as a promising alternative by learning generic visual representations through pretext tasks. However, image-level pretraining may not be optimal for dense prediction tasks like object detection, prompting the need for object-level representations. In this paper, we present a self-supervised pretraining framework called Selective Object Contrastive learning (SoCo) that focuses on object detection. SoCo utilizes selective search to generate object proposals and treats each proposal as an independent instance, allowing for the learning of object-level visual representations. The framework also pretrains all network modules used in detectors, bridging the gap in network architecture between pretraining and finetuning. Experimental results demonstrate that SoCo achieves state-of-the-art transfer performance on the COCO dataset, outperforming supervised pretraining baselines.