The Stochastic Multi-armed Bandit (MAB) problem is a widely studied framework in decision-making under uncertainty. It involves sequentially choosing from a set of arms, each associated with an unknown reward distribution. The MAB problem has practical applications in various fields, such as online advertising and clinical trials, and has been extensively studied with the goals of regret minimization and best-arm identification. However, when the number of arms is large, storing all arms in memory becomes infeasible. This paper focuses on studying the MAB problem under streaming constraints, where only a fixed number of arms can be stored in memory at any given time. The authors investigate the trade-off between the size of the arm-memory and both expected regret and sample complexity. They establish lower bounds on the expected cumulative regret for single-pass algorithms and propose an (ε, δ)-PAC streaming algorithm for best-arm identification.