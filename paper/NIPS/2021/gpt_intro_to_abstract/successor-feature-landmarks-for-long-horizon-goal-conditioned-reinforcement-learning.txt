This paper introduces a framework called Successor Feature Landmarks (SFL) for tackling long-horizon goal-reaching reinforcement learning (RL) tasks in the context of self-driving cars. The framework leverages successor features (SF) to define a novel distance metric, Successor Feature Similarity (SFS), and uses it to build a landmark-based graph representation of the environment. SFL enables systematic exploration by planning paths towards landmarks at the frontier of the explored state space and executing them using a goal-conditioned policy. The paper evaluates SFL against current graph-based methods on MiniGrid and ViZDoom environments, demonstrating its superior performance, especially in cases where goals are far away and exploration is needed.