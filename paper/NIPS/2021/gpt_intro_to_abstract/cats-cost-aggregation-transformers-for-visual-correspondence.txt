Establishing dense correspondences across semantically similar images is important for various computer vision applications. Previous approaches have addressed the challenges of semantic correspondence by using deep convolutional neural networks (CNNs) to improve feature extraction and flow estimation. However, relying solely on matching similarity can result in challenges from repetitive patterns or background clutters. Recent methods have emphasized the importance of cost aggregation, but they either use hand-crafted techniques or have limitations in terms of learnability and robustness. In this work, we propose a novel cost aggregation network called CATs, which is based on the Transformer model. CATs effectively refines matching scores by considering global consensus and incorporating appearance embeddings and hierarchical features. Experimental results demonstrate the effectiveness of our method compared to previous approaches.