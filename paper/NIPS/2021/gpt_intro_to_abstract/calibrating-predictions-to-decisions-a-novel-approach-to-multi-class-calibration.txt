Machine learning predictions are often utilized by decision makers without insight into the design and training of the models, leading to concerns about the accuracy and trustworthiness of these predictions. In the context of healthcare applications, where accurate predictions are crucial, healthcare providers may worry that the model's training does not align with their own loss functions. To address this issue, distribution calibration has been proposed as a solution, but it requires extensive data and often focuses on relaxed variants of calibration. In this paper, we introduce a new notion of calibration called decision calibration, where predictions are indistinguishable from the true outcomes according to potential decision makers. We show that existing notions of calibration can be seen as special cases of decision calibration and develop an algorithm that achieves decision calibration for decision-makers choosing from a bounded set of actions. Our algorithm improves decision making and provides more accurate decision loss estimation. Empirical results on skin lesion classification and Imagenet datasets demonstrate the effectiveness of our approach.