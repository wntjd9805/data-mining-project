Designing experiments to maximize information gathering is a key challenge in science and engineering. Bayesian optimal experimental design (BOED) is a model-based framework that selects designs optimally by maximizing the expected information gained about the unknown quantity of interest. However, traditional BOED approaches require significant computation and do not lend themselves to quick and adaptive design selection. To address this, the Deep Adaptive Design (DAD) approach was proposed, which learns design policies to avoid costly computations at each iteration. However, DAD is limited to conditionally independent experiments and explicit likelihood models. In this paper, we introduce implicit Deep Adaptive Design (iDAD), which extends DAD to a more general class of models. iDAD utilizes likelihood-free lower bounds to learn adaptive design policy networks, enabling rapid adaptive experimentation with implicit models. We demonstrate the applicability of iDAD in various experimental design problems and show its superiority over existing baselines.