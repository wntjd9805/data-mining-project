Semi-supervised learning (SSL) utilizes unlabeled data to enhance a model's performance. However, the assumption that the label spaces of labeled and unlabeled data are the same is often violated in practice. This poses a challenge for SSL algorithms as outliers in the unlabeled data can negatively impact their performance. Open-set Semi-supervised Learning (OSSL) aims to address this issue by classifying known categories correctly while identifying samples of novel categories as outliers. Existing SSL methods do not work well for OSSL, necessitating the development of new approaches. In this paper, we propose a framework called OpenMatch that combines an outlier detector, a novel open-set soft-consistency loss, and the FixMatch technique to improve outlier detection in OSSL. Experimental results on various datasets demonstrate that OpenMatch achieves better performance in correctly classifying inliers and detecting outliers, even in the presence of unseen outliers in unlabeled training data. Our contributions include the introduction of a soft open-set consistency regularization (SOCR) and the development of the OpenMatch framework, which outperforms existing methods in OSSL.