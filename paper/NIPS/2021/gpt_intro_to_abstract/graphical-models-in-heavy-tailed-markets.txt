Graph learning frameworks in computer science often assume that the observed graph signals are Gaussian distributed. However, this assumption neglects scenarios where outliers or heavy-tailed distributions exist. This paper focuses on the problem of learning graph matrices with a Laplacian structure that follows a Student-t distribution. The authors propose a novel formulation for learning undirected weighted graphs and develop a numerical algorithm based on the alternating direction method of multipliers (ADMM). They also extend the framework to account for heavy-tails and k-component graphs, enabling a novel method for clustering financial time-series. Extensive practical results demonstrate the advantages of including heavy-tail assumptions in graph learning frameworks compared to Gaussian-based methods.