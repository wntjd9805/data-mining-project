Real-world classification datasets often encounter issues of label noise and class imbalance. Label noise arises from data generation limitations, such as sensor errors and mislabeling by crowdsourcing workers, leading to misleading training processes and degraded model performance. Class imbalance occurs when datasets are naturally long-tailed or biased due to imperfect data collection, resulting in poor classification performance for underrepresented classes. These two issues commonly coexist in real-world datasets. Previous methods have been proposed to address these issues, but they introduce hyper-parameters that complicate real-world deployment. Inspired by recent advances in meta-learning, some works propose leveraging a clean and unbiased meta set to tackle label noise and class imbalance. However, these methods do not fully utilize class-level information within each instance, potentially leading to the loss of valuable information. In this paper, we propose Generalized Data Weighting (GDW), which manipulates class-level gradients to better handle label noise and class imbalance. We introduce class-level weights, impose a zero-mean constraint, and develop a two-stage weight generation scheme embedded in bi-level optimization for efficient weight computation. Our proposed method achieves impressive performance improvement in various settings and contributes to better information utilization in classification tasks.