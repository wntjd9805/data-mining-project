This paper addresses the challenge of learning with limited supervision in deep neural networks. Specifically, the focus is on few-shot learning (FSL), where the goal is to quickly learn new tasks with only a small number of labeled data. Existing methods in FSL have focused on strengthening the backbone network, but still face the challenge of ambiguity due to limited support evidence. To overcome this challenge, the authors propose a novel approach that leverages out-of-distribution data as counter-examples to eliminate incorrect hypotheses. This approach is shown to improve the performance of various network architectures in different FSL settings.