This paper introduces the problem of estimating the performance of a new decision rule in sequential decision making problems, where collecting new data for evaluation may be expensive or dangerous. It explores the use of off-policy evaluation (OPE) methods, specifically trajectory-based importance sampling (IS) and stationary distribution importance sampling (SIS), to estimate the policy performance. However, these methods suffer from limitations such as variance exponential in horizon length and strong assumptions on parameters. The paper presents a new perspective on the bias-variance trade-off for OPE, showing the existence of a spectrum of estimators that bridges the unbiasedness of IS and the lower variance of SIS. It also extends this spectrum to doubly-robust and weighted versions of IS and SIS. The core idea involves splitting trajectories and using SIS and IS for different parts. The paper concludes with empirical case studies demonstrating the effectiveness of these new estimators.