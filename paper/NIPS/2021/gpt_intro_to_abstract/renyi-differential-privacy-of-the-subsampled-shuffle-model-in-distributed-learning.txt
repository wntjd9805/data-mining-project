In this paper, we explore the use of the shufﬂe privacy framework for distributed learning, where each client sends their private message to a secure shufﬂer that randomly permutes the messages before forwarding them to the server. We focus on analyzing the Rényi Differential Privacy (RDP) of subsampled mechanisms in the shufﬂe framework. Our main contributions include developing a novel bound for RDP applicable to any discrete ✏0-LDP mechanism, providing a lower bound for RDP, and analyzing the privacy-convergence trade-offs of the CLDP-SGD algorithm. Numerical experiments show that our approach achieves better privacy-utility performance compared to existing methods.