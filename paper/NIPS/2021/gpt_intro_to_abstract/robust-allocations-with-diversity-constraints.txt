Allocating heterogeneous divisible items among agents with different values has long been studied in economics, but it has gained importance in computer science and machine learning due to its applications in online advertising, datacenter resource allocation, and sharing economy platforms. Fairness is a desirable property in these allocations, with one appealing notion defining fair allocations as those that are both Pareto-optimal and envy-free. Another less restrictive notion is the Pigou-Dalton principle, which states that allocations should not transfer value from the rich to the poor. In this paper, we focus on another desirable facet of allocations - diversity. We consider diversity constraints where agents seek allocations that are diverse on certain attributes, such as race and gender. We analyze how adding these diversity constraints affects the outcome of the allocation and quantify the potential negative externality on other agents. We show that most welfarist allocation rules are not robust to diversity constraints, but the Nash Welfare objective achieves bounded negative externality. We also explore the impact of diversity constraints on an agent's own value and analyze different allocation rules using real-world data. Our main contribution is showing that the Nash Welfare objective is uniquely positioned to be robust, achieving no negative externality and monotonicity. However, we caution that allocation platforms must exercise care when allowing agents to express diversity constraints to avoid unfairness.