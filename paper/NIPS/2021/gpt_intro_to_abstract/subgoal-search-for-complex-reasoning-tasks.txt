This paper introduces the Subgoal Search (kSubS) method, which combines deep learning generative subgoal modeling with classical search algorithms to enable successful planning with subgoals. The authors demonstrate the effectiveness of this approach on complex reasoning tasks, including the puzzle games Sokoban and Rubik's Cube, as well as an inequality theorem proving benchmark. They achieve state-of-the-art results in the inequality theorem proving benchmark and competitive results in the other two tasks. The paper also presents implementations of the method, MCTS-kSubS and BF-kSubS, and discusses the role of the subgoal generator, the low-level policy, and the value function in the algorithm. The authors also highlight the advantages of using a transformer-based autoregressive model for subgoal generation and provide evidence of out-of-distribution generalization. Additionally, the paper hypothesizes that subgoal generation may help mitigate the negative impact of value function errors on planning. Overall, the contributions of the paper include the proposal of the Subgoal Search method, the demonstration of its effectiveness, and the provision of code and experiment settings for reproducibility.