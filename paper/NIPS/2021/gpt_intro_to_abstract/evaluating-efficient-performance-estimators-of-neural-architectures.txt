Neural architecture search (NAS) is a technique that automatically discovers architectures that perform better than hand-crafted ones for various applications. However, traditional NAS methods suffer from a heavy computational burden, and evaluating each candidate architecture is slow. To address this challenge, one-shot estimators (OSEs) and zero-shot estimators (ZSEs) have been proposed to accelerate the architecture evaluation process. In this paper, we conduct a comprehensive study on OSEs and ZSEs in different search spaces and reveal their biases, variances, and weaknesses. We also provide suggestions for future OSE applications and list open research problems and technical suggestions for improving ZSEs. Our work serves as a baseline for future research in architecture performance estimators.