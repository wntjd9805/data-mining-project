Meta-learning has emerged as a promising solution to address the challenge of acquiring large amounts of training data in machine learning. By leveraging the similarity between new and previously encountered tasks, meta-learning enables learners to quickly acquire new skills using data from related tasks. However, the theoretical understanding of meta-learning techniques has lagged behind empirical progress, particularly in terms of deriving generalization bounds. Existing methods either produce computationally challenging bounds or vacuous bounds. In this paper, we propose a novel approach that combines uniform stability and PAC-Bayes theory to derive generalization guarantees for gradient-based meta-learning. We also introduce a regularization scheme that minimizes the derived bound and demonstrate the effectiveness of our approach on various meta-learning problems. Our work contributes to improving the theoretical understanding and performance of meta-learning techniques.