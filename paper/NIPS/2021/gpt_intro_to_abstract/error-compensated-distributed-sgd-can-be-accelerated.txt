In this paper, we focus on communication compression as a technique for addressing the slow communication bottleneck in large-scale supervised machine learning problems. Communication compression involves applying a lossy compression transformation to the messages before communication, saving on communication time but introducing errors. We explore two families of compression operators: contraction compressors and unbiased compressors. We define and discuss examples of both types of compressors, highlighting their importance and trade-offs. The goal is to find a balance between compression and accuracy in order to optimize distributed systems for efficient machine learning.