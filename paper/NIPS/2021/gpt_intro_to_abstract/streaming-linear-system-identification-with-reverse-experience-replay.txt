This paper focuses on the problem of learning linear-time invariant (LTI) systems through the estimation of the matrix Aâˆ— from given samples. Most existing results in the literature have focused on the offline setting, where all samples are available in advance. However, this does not apply to the streaming setting, which is applicable in domains like reinforcement learning and large-scale forecasting. The goal of this paper is to design a stochastic gradient descent (SGD) style method that can work directly with a first-order gradient oracle and is applicable to various settings. The proposed method, called reverse experience replay, addresses temporal dependencies in data by replaying points in reverse order. The paper provides a detailed analysis of the proposed method and demonstrates its effectiveness through empirical validation.