Reinforcement Learning (RL) has shown success in simulated domains but faces challenges in real-world tasks. This paper focuses on real-world applications and proposes requirements such as multiple reward functions, stakeholder control of trade-offs, and an offline setting. The paper also aims to prevent unintended behavior and provide practical guarantees. To achieve these goals, the Seldonian framework is adopted. The paper presents contributions, formalizes the setting, extends Safe Policy Iteration algorithms, and tests the approach on synthetic and critical-care tasks. The accompanying codebase is available for reference.