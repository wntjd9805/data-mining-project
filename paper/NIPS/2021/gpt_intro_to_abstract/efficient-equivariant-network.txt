Convolutional neural networks (CNNs) have been successful in various vision tasks, thanks to their parameter sharing scheme that allows for translation equivariance. However, Group Equivariant CNNs (G-CNNs), which extend CNNs to exploit larger groups of symmetries, have drawbacks in terms of computational cost and the inability to adapt kernels to diverse feature patterns with respect to different spatial positions. Previous works have attempted to address these issues, but they either introduce extra parameters and complexity or suffer from quadratic memory and time complexity. Inspired by the observation that an equivariant linear layer is essentially a convolution-like operation, we propose a generalized framework for equivariant models, including G-CNNs and equivariant attention networks, and introduce a new equivariant layer called E4-layer. Our method addresses the computational complexities and reduces inter-channel redundancy in convolution filters, leading to efficient processing and improved performance with lower computational cost. Experimental results support the efficacy of our approach in various tasks.