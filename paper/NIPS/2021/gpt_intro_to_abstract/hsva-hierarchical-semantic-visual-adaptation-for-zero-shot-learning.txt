In this paper, we address the problem of zero-shot learning (ZSL) and propose a novel common space learning formulation called hierarchical semantic-visual adaptation (HSVA). We highlight the limitations of existing common space learning methods that only focus on distribution alignment and neglect the structure variation between the semantic and visual domains. Our proposed HSVA framework aligns the two domains through a combination of structure adaptation and distribution adaptation, resulting in a better common space that improves ZSL performance. We conduct extensive experiments on benchmark datasets and demonstrate that HSVA outperforms existing methods, achieving consistent improvement in both conventional and generalized ZSL settings. We also show the importance of considering structural variation and highlight the superiority of the common space learned by HSVA compared to other methods such as CADA-VAE.