Generative models in computer science aim to approximate the original data distribution as closely as possible by focusing on fidelity, diversity, and privacy. However, there is a growing concern about the bias present in machine learning models, which can unfairly discriminate and damage society's trust. This paper introduces the concept of synthetic data fairness and proposes a new approach, called DECAF, that leverages causal structure to generate fair synthetic data. DECAF utilizes a generative adversarial network (GAN) and removes bias at inference time through targeted edge removal. The paper highlights the contributions of DECAF, including its compatibility with different fairness definitions and its ability to maintain high downstream utility of generated data.