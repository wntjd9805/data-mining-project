Machine learning has revolutionized various domains, including face recognition, autonomous driving, and medical diagnoses. However, the reliance on large-scale training datasets containing sensitive information raises privacy concerns and makes data sharing difficult. One approach to address this challenge is the generation of synthetic datasets using generative models like generative adversarial networks (GAN). While GANs can generate synthetic records that closely resemble the original data, there is no theoretical guarantee of privacy protection. Differential privacy offers a rigorous privacy guarantee, but applying it to synthetic data generation is challenging. Two existing approaches, DP-GAN and PATE-GAN, combine differential privacy with synthetic data generation, but each has its limitations. To overcome these limitations, this paper proposes G-PATE, a new approach that combines a generative model with the PATE mechanism to train a differentially private data generator. G-PATE ensures differential privacy by focusing on the information flow from the discriminator to the generator. The paper presents a private gradient aggregation mechanism to reduce privacy consumption and increase scalability. Compared to existing approaches, G-PATE provides better utility and scalability, as demonstrated through experiments on credit and image datasets. To the best of the authors' knowledge, this is the first work to achieve high scalability and utility on high-dimensional face image datasets. The experimental results show significant improvements over existing baselines, including DP-GAN and PATE-GAN.