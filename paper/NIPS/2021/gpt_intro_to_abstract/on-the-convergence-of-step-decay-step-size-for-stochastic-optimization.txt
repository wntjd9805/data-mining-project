We address stochastic programming problems in machine learning applications, specifically focusing on the stochastic gradient descent (SGD) method for solving these problems. The SGD method uses a step decay step-size policy, which has been found to be effective in practice. However, the theoretical analysis of this step-size policy is still limited, and our goal is to provide convergence guarantees for SGD with the step decay step-size on non-convex, convex, and strongly convex optimization problems. We propose a non-uniform probability rule for selecting the output in the smooth non-convex setting and establish near-optimal convergence rates for SGD. We also provide error bounds for strongly convex problems and demonstrate the effectiveness of the step decay step-size in general convex cases.