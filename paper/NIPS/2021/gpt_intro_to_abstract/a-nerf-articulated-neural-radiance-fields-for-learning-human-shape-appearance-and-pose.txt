Generative models have advanced from recreating images to providing control and understanding of images through neural scene representations. However, learning 3D representations from 2D observations is a challenging task, especially for humans with diverse body shapes and non-rigid motion. This paper introduces Articulated Neural Radiance Fields (A-NeRF), which learns a user-specific neural 3D body model and skeleton pose from unlabelled videos. A-NeRF extends Neural Radiance Fields (NeRF) to work with single videos and articulated motion, alleviating the need for template models while maintaining accuracy. The paper describes the parameterization and rendering process of the MLP representation used in A-NeRF and highlights the novelty of learning a neural latent representation relative to an articulated skeleton. The contributions of this work enable the learning of a neural body model from monocular video, achieving a level of detail previously only attained with parametric surface models or multi-view approaches. The paper also discusses the applications and impact of this research, including motion capture, character animation, appearance and motion transfer, and the importance of ethical data usage in creating 3D models of people.