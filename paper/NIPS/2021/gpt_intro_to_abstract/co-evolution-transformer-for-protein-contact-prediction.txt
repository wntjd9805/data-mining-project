This paper introduces the Co-evolution Transformer (CoT), an attention-based architecture for protein contact prediction. The existing approaches for protein contact prediction, such as direct coupling analysis (DCA) and deep-learning based methods, have limitations in capturing high-order interactions among residues. To address these limitations, CoT incorporates residue co-evolution patterns derived from all homologous sequences into an attention function to learn residue representations. It also automatically weights residue representations from different homologs and selectively aggregates features to construct the co-evolution attention map. CoT significantly outperforms baseline methods on two benchmarks, CASP14 and CAMEO, achieving a 51.6% top-L long-range precision score for Free Modeling (FM) domains on CASP14, outperforming the winner group of CASP14 contact prediction challenge. The code for CoT is available at the provided GitHub repository.