Modern machine learning operates in an over-parameterized regime, where multiple parameter-sets can achieve low error on a given training set. This raises questions about the properties of the solution space and whether networks learn solutions that capture the underlying phenomena or simply artificial shortcuts. Similar variations exist in Neuroscience, where animals exhibit neural and behavioral variability when performing tasks. Trained Recurrent Neural Networks (RNNs) are used in Computational Neuroscience to explain brain dynamics, but their activity often differs from experimental recordings. In this paper, we explore how trained RNNs produce qualitatively different solutions for multiple tasks. We argue that it is important to chart the space of solutions that arise from training to effectively use artificial networks as models of neural circuits.