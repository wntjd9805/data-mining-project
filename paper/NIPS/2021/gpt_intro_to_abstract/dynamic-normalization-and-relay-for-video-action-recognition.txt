Human action recognition is a longstanding problem in video understanding, with recent research focusing on deep learning models for improved representation and generalization. However, learning efficient yet effective video representations remains challenging. In this paper, we propose a new approach called Dynamic Normalization and Relay (DNR) to enhance the spatial-temporal representation learning of CNNs for action recognition. DNR aims to predict accurate layer-wise normalization parameters in an input-dependent manner, addressing the limitation of small batch sizes and the noise introduced by Batch Normalization. We introduce two interdependent normalization relay modules, cross-temporal DNR and cross-layer DNR, to capture frame-level and clip-level feature dynamics, respectively. Experimental results on popular datasets demonstrate the effectiveness of DNR, showcasing significant accuracy improvements over baseline models.