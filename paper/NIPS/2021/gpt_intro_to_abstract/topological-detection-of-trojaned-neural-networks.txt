Recent years have seen significant advancements in deep neural networks (DNNs), but their complexity and lack of transparency make them vulnerable to various malicious attacks. This paper focuses on the Trojan attack, where the attacker injects Trojaned samples into the training dataset, resulting in a model that behaves normally on clean samples but consistently makes incorrect predictions on Trojaned samples. Traditional methods for identifying such attacks are not practical in a data-limited setting, so this paper proposes a topology-based Trojan detection algorithm. By analyzing the structural differences between clean and Trojaned networks using advanced tools from algebraic-topological foundations, the paper observes significant discrepancies and identifies highly salient loops connecting neurons in Trojaned models. The empirical findings are supported by a theoretical result, and experiments on synthetic and competition datasets show that the proposed method is highly effective in detecting Trojan attacks. The code for this research can be found at a provided GitHub link.