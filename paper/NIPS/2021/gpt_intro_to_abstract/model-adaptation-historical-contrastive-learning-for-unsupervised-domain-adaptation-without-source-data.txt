Deep neural networks have shown great success in computer vision tasks, but they often struggle to generalize to new domains. Unsupervised domain adaptation has been used to address this issue, but it requires access to the source-domain data, which raises concerns about data privacy and efficiency. In this work, we propose unsupervised model adaptation, which aims to adapt source-trained models to fit the target data distribution without accessing the source-domain data. We introduce historical contrastive learning, which includes historical contrastive instance discrimination and category discrimination, to address the challenges of unsupervised model adaptation without forgetting the source hypothesis. Our experiments demonstrate that our approach outperforms existing methods in various visual tasks and setups.