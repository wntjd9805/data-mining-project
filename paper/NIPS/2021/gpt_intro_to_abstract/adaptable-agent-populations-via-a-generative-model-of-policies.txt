This paper introduces a method called ADAP (Adaptable Agent Policies) that aims to learn a diverse policy space for reinforcement learning environments. The authors propose that learning more than one policy per environment can provide robustness and adaptability to environmental changes, as well as improve the multi-modality of agents in multi-agent environments. They integrate the goals of quality diversity into deep RL by simulating an entire population of agents using a generative model of policies. The paper presents experiments on Markov Soccer and Farmworld environments to demonstrate the effectiveness of their approach. The authors also provide qualitative results and additional experimental results on other environments. The paper discusses the method's model architecture, optimization techniques, and adaptation via optimization in the latent space of the generative model.