Matrix sensing is a widely studied topic in modern statistics, with applications in various fields such as image compression, collaborative filtering, and dimensionality reduction. The goal is to recover a rank-r matrix from a set of linear measurements. Traditional approaches involve explicit regularization or rank constraints to promote low-rankness, while more recent work focuses on implicit regularization. This paper investigates the implicit bias of discrete-time mirror descent in matrix sensing, both for rectangular and positive semidefinite matrices. The authors provide characterizations for the limiting point of the optimization algorithm, which minimize a quantity that interpolates between the nuclear norm and the Frobenius norm in the rectangular case, and a linear combination of the nuclear norm and the negative von Neumann entropy in the positive semidefinite case. The results offer new recovery guarantees for implicit regularization-based algorithms without explicitly enforcing low-rankness. Numerical simulations also suggest the behavior of gradient descent in relation to mirror descent.