The goal of graph-based semi-supervised learning (SSL) is to use relationships between data and a small set of labeled items to predict labels for the rest of the dataset. However, the bias in selecting which nodes to label can create distributional differences between the training and test sets, causing the SSL classifier to overfit to training data irregularities and perform poorly during inference. This problem becomes particularly pronounced when using Graph Neural Networks (GNNs) for semi-supervised learning, as the biased training labels can lead to the overfitting of spurious regularities. In this paper, we address this problem by proposing a framework called Shift-Robust GNN (SR-GNN) that adapts the biased sample of labeled nodes to conform to the distributional characteristics of an IID sample. We also explore two types of bias that occur in both deep and shallow versions of GNN models and demonstrate the effectiveness of SR-GNN in mitigating the effects of distributional shift in graph learning datasets.