Deep neural networks have demonstrated exceptional performance in various machine learning tasks, but they are susceptible to adversarial attacks. Adversarial attacks, particularly in black-box scenarios, are highly concerning due to their transferability. While previous work has achieved success with non-targeted attacks, targeted transferability remains challenging. This paper explores the overlooked potential of simple transferable attacks that require no additional training or data and demonstrates their strength compared to resource-intensive approaches. The superior performance of a simple logit loss is also highlighted. The effectiveness of simple transferable attacks is validated through extensive experiments in various transfer scenarios, including challenging and realistic ones. The results suggest that evaluation in only easy scenarios may provide misleading comparative results. The paper also showcases the generation of targeted Universal Adversarial Perturbations (UAPs) using the simple Logit attack in a data-free manner. The weaknesses of commonly adopted attack settings and transfer scenarios are analyzed, with the aim of inspiring more meaningful evaluations in targeted transferability.