Federated learning (FL) is a distributed machine learning paradigm where clients learn a shared prediction model while keeping their training data on local devices. FL focuses on the challenges of non-independent and identically distributed datasets, communication efficiency, and privacy. This paper extends FL to the multi-armed bandits (MAB) framework, motivated by applications such as personalized content recommendation and online education. The paper proposes a federated linear contextual bandits model and develops the Fed-PE algorithm for solving the problem. The algorithm achieves near-optimal regret performances and reduces communication costs while keeping personal information private. The paper also introduces the concept of collinearly-dependent policies and provides a tight minimax regret lower bound.