The paper focuses on bias in training data and explores the question of whether it is possible to certify the robustness of predictions under a given form and degree of bias. The authors propose programmable bias definitions to model nuanced biases in practical domains and target decision-tree learners to exactly certify their robustness. They present a language for bias modeling and a symbolic technique that performs decision-tree learning on a set of datasets defined by a bias model. The paper makes three contributions: formalizing the bias-robustness-certification problem, presenting the symbolic technique for certification, and evaluating the approach on various bias models and datasets. A running example is provided to illustrate the approach.