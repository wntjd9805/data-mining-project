Federated learning (FL) is a machine learning framework where a central server and multiple workers collaborate to train a model. Existing FL methods have focused on scenarios where workers have different sets of subjects with common features, known as horizontal FL (HFL). However, in many learning scenarios, workers handle data about the same subjects but with different sets of features, referred to as vertical FL (VFL). This setting is common in finance and healthcare applications, where data owners have different records of users but can establish a more accurate model by combining their features through FL. FL presents challenges in data heterogeneity and privacy, with recent studies examining how malicious workers can embed backdoors or replace the global model. However, little attention has been given to information leakage from public shared gradients and batch identities. In this paper, we propose an advanced data leakage attack called catastrophic data leakage in vertical federated learning (CAFE), which overcomes the limitations of existing attacks and provides theoretical guarantees on data recovery performance. We also develop a defense strategy to mitigate the data leakage attack and conduct experiments to validate the superior performance of CAFE compared to state-of-the-art methods.