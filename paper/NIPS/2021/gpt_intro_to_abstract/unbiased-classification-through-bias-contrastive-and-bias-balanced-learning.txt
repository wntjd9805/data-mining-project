Machine learning models have achieved high performance in tasks such as computer vision and natural language processing. However, concerns have been raised about the real-world performance of these models, particularly regarding biases in the training data. Biases can lead to societal side effects such as prejudice or racism. This paper proposes two debiasing approaches, the Bias-Contrastive (BiasCon) loss and the Bias-Balanced (BiasBal) loss, that can be applied when the bias label is available. The BiasCon loss utilizes contrastive learning to promote pulling samples with the same target class but different bias class closer in the feature space. The BiasBal loss optimizes the model to balance the target-bias correlation. Additionally, the Soft Bias-Contrastive (SoftCon) loss is proposed for cases where the bias label is unavailable, using the feature space of the bias-capturing model. Experimental results demonstrate that the proposed methods significantly improve debiasing performance across various datasets.