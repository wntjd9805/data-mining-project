Object pose estimation is a critical task in computer vision with applications in self-driving cars and augmented reality. Deep learning approaches have achieved high performance in 3D pose estimation, but they require large amounts of annotated data. Semi-supervised learning (SSL) can mitigate this issue by leveraging unlabeled data. While SSL has been widely explored in other computer vision tasks, limited attention has been given to SSL for 3D pose estimation. In this paper, we propose a semi-supervised learning framework for category-level 3D pose estimation from very few annotated examples and a collection of unlabeled images. We introduce a spatial matching approach that transfers the 3D pose annotation from labeled examples to unlabeled data. We also address the challenge of varying 3D pose and nuisance variations in shape, color, texture, context, and illumination. We utilize neural view synthesis and matching to transfer annotations and improve the 3D pose invariance in the feature extractor through contrastive loss. Our experiments demonstrate the effectiveness of our framework in leveraging unlabeled data and achieving robust 3D pose estimation, surpassing baseline methods, even in extreme few-shot settings and occlusion scenarios.