Generating realistic images has been a long-standing focus of research in the computer science community, particularly in the domain of image synthesis tasks involving persons or portraits. These tasks have various applications, such as advertising, games, and motion capture. However, most existing methods only handle well-aligned images of 'icon-view' foregrounds and struggle with the synthesis of 'non-iconic view' foregrounds, which involve person instances with arbitrary poses in cluttered scenes. Additionally, previous methods tend to distort the global semantics of the generated images, even when making subtle modifications to local regions. In this paper, we propose a novel image Local Autoregressive Transformer (iLAT) model for locally guided image synthesis. Our model effectively learns local discrete representations and achieves semantically consistent and visually realistic generation results. We also address issues such as slow inference speed and information leakage of local guidance through innovative techniques. Experimental results on pose-guided image generation and face editing tasks demonstrate the efficacy of our approach.