Machine learning involves discovering prediction rules from raw data, but not all of these rules are reliable due to biases in the training data. This paper aims to develop a toolkit that allows users to directly modify the prediction rules learned by a classifier, instead of relying on data modifications. The authors propose a method for editing a classifier's prediction rules without additional data collection, demonstrating its effectiveness in improving model performance in real-world scenarios. They also develop an automated pipeline for large-scale synthetic evaluation and show how the concept-transformation pipeline can be used to generate image counterfactuals for probing model behavior. Overall, the goal is to provide a more direct and targeted way of modifying a model's behavior by rewriting its prediction rules.