Sensitive data collection and analysis are on the rise, highlighting the importance of protecting individuals' private information. One effective approach to privacy preservation is differential privacy, which allows for quantifiable trade-offs between privacy and accuracy. Differential privacy has been widely adopted by organizations such as Google, Apple, and the U.S. Census Bureau. This paper focuses on differentially private query release, where the goal is to release approximate answers while maintaining differential privacy. Synthetic data generation, which involves creating privacy-preserving "fake" datasets, is explored as an approach to query release. Synthetic data methods have the advantage of being able to answer a larger collection of queries accurately, but they come with a computational cost. Despite the challenges, there has been a recent surge in research on practical algorithms for generating private synthetic data. This paper presents a unified algorithmic framework that captures these methods and introduces two new algorithms, GEM and PEP, which outperform existing methods in terms of accuracy and convergence. Additionally, the paper discusses the incorporation of public data into the synthetic data generation process and demonstrates the superiority of GEM over existing methods in utilizing public datasets effectively.