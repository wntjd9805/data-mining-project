This paper introduces an online temporal modeling algorithm called Long Short-term TRansformer (LSTR) for online action detection in video frames. Unlike offline methods, LSTR processes data causally up to the current time and can capture temporal relations in sequences up to 8 minutes long. LSTR effectively models long- and short-term temporal dependencies by storing the history directly and separating long- and short-term memories. The encoder-decoder architecture of LSTR compresses the long-term memory into a latent representation and performs self-attention and cross-attention operations on the short window of frames in the decoder. The paper validates LSTR on benchmark datasets and demonstrates its state-of-the-art performance in online action detection.