This paper explores the ethical and societal implications of automated decision-making in machine learning algorithms. Specifically, the focus is on the performance of these algorithms on marginalized groups and the potential legal consequences of disparate impact. The concept of fairness in decision-making is discussed, including notions such as demographic parity, equalized odds, and equality of opportunity. The paper formalizes the problem of fair classification as maximizing accuracy while satisfying a fairness constraint, and highlights the challenges and limitations of existing fair classification algorithms. The authors propose new fairness surrogates with promising theoretical properties and compare their performance on large-scale image and text classification tasks using deep neural network models. Overall, the results show the potential for improving fairness in machine learning algorithms, particularly in deep learning applications.