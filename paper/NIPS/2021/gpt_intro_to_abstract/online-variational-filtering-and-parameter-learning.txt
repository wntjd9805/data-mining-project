This paper introduces a novel variational approach for online filtering and parameter learning in Sequential State Models (SSMs). Many tasks in machine learning with time series data require online techniques, but performing inference in SSMs is challenging. Previous approaches for online variational inference have limitations in accurately approximating the posterior distribution of the latent states. The main contribution of this paper is a variational approach that bypasses these restrictions, by maximizing an Evidence Lower Bound (ELBO) in an online manner with a constant update cost. The approach incorporates a backward decomposition of the variational approximation of the states posterior and utilizes value functions satisfying Bellman-type recursions. The proposed method provides a principled solution for simultaneous state estimation and parameter learning in SSMs.