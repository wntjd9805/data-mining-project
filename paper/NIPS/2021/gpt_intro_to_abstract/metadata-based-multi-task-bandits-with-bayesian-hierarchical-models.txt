The introduction of this computer science paper discusses the multi-armed bandit (MAB) framework for sequential decision making problems. It highlights the exploration-exploitation trade-off and the increasing attention MAB has received in various applications. The paper focuses on the problem of efficient information sharing among a large number of related MAB tasks and explores the use of task metadata as a valuable source of information. The authors propose a hierarchical Bayesian framework and a Thompson sampling-based algorithm called MTTS to learn task relations and minimize cumulative regrets. The benefits of metadata-based information sharing are demonstrated through theoretical analysis and simulation experiments. The contributions of the paper include the formalization of the metadata-based multi-task MAB problem, the design of the MTTS algorithm, the derivation of regret bounds, and insight into performance under different conditions.