Deep learning has achieved remarkable success in various machine learning tasks, leading to growing interest in applying deep learning to scientific and engineering applications. Numerical solutions to partial differential equation (PDE) problems based on neural networks have become a key area of research in scientific machine learning, particularly for high-dimensional PDEs. Traditional numerical methods for PDEs suffer from exponential computational cost with increasing dimensionality, limiting their applicability. Neural networks, especially deep neural networks, offer a promising approach to overcome this curse of dimensionality by representing functions in high dimensions efficiently. This paper aims to explore the theoretical analysis of neural network-based methods for solving high-dimensional PDEs. The authors propose a functional-analytic approach and identify a suitable function class for neural network approximations. They demonstrate that solutions to a class of PDEs can be well approximated by functions in this class. The main theorem establishes that if the coefficients and the source term of the considered elliptic PDE are Barron functions, then the solution can be approximated by another Barron function with a controlled error. This approximation result shows that the solution can be represented by a two-layer neural network without suffering from the curse of dimensionality. The paper's contributions lie in providing a mathematical framework to analyze the approximation capabilities of neural networks for high-dimensional PDEs, which is crucial for advancing scientific machine learning in fields such as physics and control theory.