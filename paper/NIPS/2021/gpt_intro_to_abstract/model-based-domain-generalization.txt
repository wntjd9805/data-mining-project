Despite the success of modern machine learning methods in numerous applications, they can fail when presented with out-of-distribution (OOD) data. This failure mode is particularly problematic in safety-critical applications, leading to unsafe behavior. The domain generalization community has emerged to address these vulnerabilities, but existing algorithms have limitations. In this paper, we propose a new framework called Model-Based Domain Generalization (MBDG), which enforces invariance to transformations between domains. We rigorously re-formulate the domain generalization problem as a semi-infinite constrained optimization problem and prove its equivalence to the empirical parameterized dual problem. We introduce a primal-dual style algorithm that enforces invariance over unsupervised generative models and demonstrate its superior performance on various benchmarks.