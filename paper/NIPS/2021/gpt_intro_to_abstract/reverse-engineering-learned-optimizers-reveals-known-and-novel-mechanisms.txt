Optimization algorithms play a crucial role in modern machine learning, and advancements in optimization techniques have wide-ranging implications. One recent approach is meta-learning, which involves training an optimizer directly on a variety of tasks. These learned optimizers have shown superior performance compared to traditional optimizers in specific scenarios. However, there is limited understanding of how these learned optimizers operate and whether they exhibit novel behaviors not yet explored in optimization literature. In contrast, existing hand-designed optimizers, like momentum and Adam, are well-studied and analyzed based on established theoretical principles. This understanding allows for further improvements and analysis. Without similar comprehension of learned optimizers, it is arduous to analyze or synthesize their behavior. This paper introduces tools to isolate and comprehend the mechanisms used by nonlinear, high-dimensional learned optimizers. The study demonstrates that learned optimizers leverage both known techniques (such as momentum, gradient clipping, learning rate schedules) and novel methods for learning rate adaptation. The findings provide insights towards a scientific interpretation and understanding of learned algorithms. The code and trained weights of the studied learned optimizers are available at https://bit.ly/3eqgNrH.