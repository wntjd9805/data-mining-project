The introduction presents the concept of deep learning and the need for flexible models to achieve good performance on tasks like image classification. It discusses the limitations of kernel methods in providing this flexibility and introduces deep kernel processes as a solution. The paper explores the concept of deep Wishart processes (DWPs) and their advantages over feature-based models in capturing symmetries in the true posterior. However, previous research was unable to perform inference in DWPs due to the lack of a suitable approximate posterior distribution. The paper aims to address this issue by developing a flexible distribution for DWPs and comparing them with their equivalent deep Gaussian processes (DGPs). The contributions of the paper include a new family of distributions, an effective approximate posterior for DWPs, a doubly stochastic inducing-point inference scheme, and an empirical comparison with DGPs. The paper concludes by providing a reference implementation.