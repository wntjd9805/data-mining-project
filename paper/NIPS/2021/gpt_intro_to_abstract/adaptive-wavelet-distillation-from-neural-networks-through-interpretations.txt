Recent advancements in deep learning have significantly improved predictive performance, but the lack of interpretability in deep neural networks (DNNs) has limited their application in critical areas such as medicine, biology, and policy-making. In this paper, we propose a model distillation approach, called Adaptive Wavelet Distillation (AWD), which aims to construct interpretable models without sacrificing prediction performance. AWD utilizes attributions from a trained DNN to improve the learned wavelets, incorporating information about the input signals, target variable, and inductive biases present in the DNN. We present AWD's application in cosmology and cell biology, showing how it identifies relevant features in weak gravitational lensing convergence maps and improves prediction performance in molecular-partner prediction. The wavelet models generated by AWD provide concise explanations of model behavior using few parameters and compressed representations of the input. By addressing real-world problems, we hope to encourage further research and development of interpretable machine learning methods grounded in specific domains.