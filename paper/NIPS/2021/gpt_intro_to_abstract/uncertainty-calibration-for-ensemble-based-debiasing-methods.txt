In this paper, the authors address the issue of machine learning models struggling to generalize well in out-of-distribution settings, limiting their applicability to real-world scenarios. They focus on ensemble-based debiasing (EBD) methods, which have shown promising improvements on out-of-distribution performance. However, previous works have primarily focused on designing ensembling strategies without considering the importance of the bias-only model in the EBD process. The authors theoretically reveal that the quality of the predictive uncertainty estimation given by the bias-only model is crucial for the debiasing performance. They introduce a three-stage EBD framework, including bias modeling, model calibrating, and debiasing, to address the poor calibration issue of existing bias-only models. Experimental results on challenging datasets demonstrate the effectiveness of the proposed framework.