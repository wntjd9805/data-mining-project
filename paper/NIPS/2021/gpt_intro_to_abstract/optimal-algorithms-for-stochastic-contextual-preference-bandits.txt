Sequential decision-making problems with side information, known as contextual bandits, have been widely studied in machine learning. In this paper, we focus on the problem of regret minimization in a specific type of contextual bandit known as the structured contextual preference bandit. In this setting, the learner selects a subset of items from a large decision space and receives relative preference feedback about the top-ranked items in the selected subset. We propose two algorithms for the dueling bandit problem, where the learner can only compare pairs of items. We prove regret bounds for both algorithms and show their optimality in theoretical analysis. We also investigate the more general subsetwise preference feedback and discuss the limitations and potential benefits of this feedback model. Our theoretical findings are supported by empirical evaluations.