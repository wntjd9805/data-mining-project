The task of 3D scene understanding from a single RGB image is crucial for various applications in computer science, such as robotics, motion planning, and augmented reality. While there have been advancements in geometric reconstruction and object instance detection, the integration of 3D semantic reconstruction and instance reconstruction has been largely overlooked. In this paper, we propose the task of panoptic 3D scene reconstruction, which aims to predict surface geometry, semantic labels, and instance IDs for a scene from a single image. We present a new method that combines 2D convolutional features, depth estimates, and 2D instance segmentation to guide the lifting of features from 2D to 3D. We also introduce an instance propagation approach for effective object recognition. Our approach outperforms existing methods in terms of scene understanding and demonstrates the potential for holistic 3D perception.