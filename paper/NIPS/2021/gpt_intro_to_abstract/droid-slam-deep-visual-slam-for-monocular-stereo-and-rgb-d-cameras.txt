Simultaneous Localization and Mapping (SLAM) is an important problem in computer vision and robotics, with applications in autonomous vehicles. Traditional SLAM systems have used probabilistic and filtering approaches, as well as optimization-based formulations. However, these systems often suffer from failures and lack robustness. In this paper, we introduce DROID-SLAM, a new SLAM system based on deep learning. Our system achieves state-of-the-art performance, outperforming existing SLAM systems on various challenging benchmarks. It offers high accuracy, robustness, and generalization capabilities, and is trained using monocular input but can handle stereo or RGB-D input without retraining. The key innovation in DROID-SLAM is its differentiable recurrent optimization-inspired design, which combines the strengths of classical approaches and deep networks. We evaluate our system extensively on multiple datasets and sensor modalities, demonstrating its superior performance.