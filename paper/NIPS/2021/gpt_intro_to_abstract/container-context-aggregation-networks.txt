Convolutional neural networks (CNNs) and Transformers are widely used architectures in computer vision and natural language processing, respectively. Recently, there has been a push to explore alternative architectures, such as MLP-mixers, for image classification tasks. In this paper, we propose CONTAINER (CONText AggregatIon NEtwoRk), a general purpose building block that combines static and dynamic affinity matrices to process long range information while leveraging the inductive bias of local convolutions. We show that CONTAINER achieves state-of-the-art results on ImageNet and can be easily integrated into existing neural architectures. We also introduce a more efficient variant, CONTAINER-LIGHT, which is capable of processing high resolution inputs and improves performance in detection and instance segmentation tasks. Our findings demonstrate that a unified view of these architectures can lead to improved understanding and further advancements in the field.