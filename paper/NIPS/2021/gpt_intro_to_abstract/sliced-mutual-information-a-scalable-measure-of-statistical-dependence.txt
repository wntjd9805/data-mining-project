This paper introduces sliced mutual information (SMI) as a surrogate measure of informativeness in high-dimensional settings. SMI is defined as the average of mutual information terms between one-dimensional random projections. It inherits many properties of classic mutual information, such as nullification if variables are independent and a chain rule. SMI can be efficiently estimated and is well-suited for feature extraction tasks. The paper presents theoretical analysis and empirical evidence to support the effectiveness of SMI in high-dimensional data analysis. Unlike classic mutual information, SMI can grow as a result of deterministic transformations, making it a valuable metric in feature extraction.