Despite recent advancements in deep neural networks, dataset bias remains a challenge. Biased datasets often contain strong correlations between peripheral attributes and labels, causing models trained on these datasets to rely more on bias attributes rather than intrinsic attributes. This leads to the failure of generalizing on images without such correlations during the test phase. Previous approaches have focused on defining and debiasing specific bias types, limiting their capability in handling other bias types and requiring manual identification of the bias type. To address these limitations, we propose a feature augmentation approach using disentangled representation to diversify bias-conflicting samples. Our approach involves training two encoders to embed images into disentangled representations of intrinsic and bias attributes and randomly swapping latent vectors to create augmented bias-conflicting samples. Our experiments show the importance of diversity in debiasing and demonstrate the effectiveness of our approach in synthetic and real-world datasets, achieving state-of-the-art performance compared to existing baselines.