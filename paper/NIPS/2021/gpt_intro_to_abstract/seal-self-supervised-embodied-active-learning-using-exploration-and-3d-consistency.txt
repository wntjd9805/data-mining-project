This paper explores the question of whether the progress made in Internet computer vision can be leveraged to improve computer vision for embodied agents. The authors propose a framework called Self-supervised Embodied Active Learning (SEAL) which consists of two phases: Action and Perception. In the Action phase, an agent learns a self-supervised exploration policy to gather observations of objects with a confident viewpoint. In the Perception phase, the learned exploration policy is used to gather observations and labels in a self-supervised manner. The experiments show that the SEAL framework can improve object detection, instance segmentation, and embodied agent performance without the need for additional human annotations.