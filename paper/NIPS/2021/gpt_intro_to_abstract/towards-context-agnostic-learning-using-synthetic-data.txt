We present a study on learning to classify images of known objects in a contextual setting, using only a single synthetic example per object. We evaluate our methods on the tasks of traffic sign and handwritten character recognition. Our research explores the reliance of deep neural networks trained on real-world data on background signals, even when background information is unnecessary for classification. We propose a formal setting where the input space is divided into object and context spaces, aiming to learn a context-agnostic classifier. We introduce a risk bound and develop a technique for generating data to train deep neural networks. Our empirical validation shows that our methods achieve robust performance in classifying natural data with a context-agnostic approach. We also demonstrate the limitations of classifiers trained without our techniques. Further research is needed to understand the performance of deep learning systems in the context-agnostic setting when trained on natural data. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).