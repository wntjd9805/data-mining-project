Humans have the ability to memorize vast amounts of information over time, while classical planning methods assume full observability of the environment at every time step. However, this assumption is not realistic for many applications where observation is limited or occluded. Planning in Partially Observable Markov Decision Processes (POMDP) poses a challenge due to the need for suitable memory structures for decision making. Recurrent neural networks (RNNs) have been used to handle partial observability by maintaining latent states that are updated iteratively. However, this continuous updating causes past information to be quickly forgotten. To address this issue, Long-Short Term Memory networks (LSTM) and Gated Recurrent Units (GRU) incorporate internal gates to retain relevant information. Despite their improvements, these models still struggle to disentangle observable and unobservable information within the latent states. In this paper, we propose that many latent factors in the physical world remain constant over time, suggesting that memory updates may not be necessary at every time step. We introduce GateL0RD, a model that uses L0-regularized gates to encode piecewise constant latent state dynamics. Our experiments demonstrate that GateL0RD performs as well or better than existing RNN models in various partially-observable problems with piecewise constant dynamics. Furthermore, the model exhibits better generalization under distributional shifts and the latent states are easily interpretable by humans.