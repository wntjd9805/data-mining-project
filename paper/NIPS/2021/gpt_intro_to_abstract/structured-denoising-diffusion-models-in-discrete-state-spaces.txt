Generative modeling is an important aspect of machine learning, allowing us to generate high-dimensional data such as images, text, and speech waveforms. Several methods have been developed, each with their own strengths and weaknesses. Diffusion models have recently emerged as a promising alternative, achieving comparable sample quality to GANs and log-likelihoods similar to autoregressive models. These models use a parameterized Markov chain to reverse a predefined forward process, resulting in faster sampling and training stability. While most work has focused on continuous state spaces, this paper aims to improve and extend discrete diffusion models using structured categorical corruption processes. By embedding structure and domain knowledge into the transition matrices, the authors achieve significantly improved results for text and image generation. This work introduces new models, auxiliary loss, and noise schedules, outperforming non-autoregressive baselines and achieving strong results on various datasets.