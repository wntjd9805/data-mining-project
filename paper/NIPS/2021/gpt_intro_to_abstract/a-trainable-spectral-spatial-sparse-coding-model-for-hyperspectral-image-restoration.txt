Hyperspectral imaging (HSI) is a powerful technique that provides detailed information about a scene by capturing the electromagnetic spectrum on multiple bands. This offers advantages over traditional RGB imaging, such as the ability to identify specific materials based on high-dimensional information in a single pixel. However, working with hyperspectral data presents challenges, including complex degradations and a scarcity of ground-truth data. In this paper, we propose a fully interpretable machine learning model for HSI that combines deep learning principles with domain knowledge and physical rules. Our model uses a novel trainable spectral-spatial sparse coding approach with two layers, allowing for linear spectral unmixing per pixel and incorporating spatial relationships between pixels. By encoding prior knowledge directly into the model architecture, we achieve robust and efficient denoising results on benchmark datasets, surpassing both deep learning models and traditional baselines. Our work also highlights the importance of interpretable architectures and the ability to adapt to different noise levels, making our model suitable for blind denoising problems in hyperspectral imaging.