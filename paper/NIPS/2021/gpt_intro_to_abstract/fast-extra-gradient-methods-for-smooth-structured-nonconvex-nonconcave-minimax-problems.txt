Recently, nonconvex-nonconcave minimax problems have gained attention in the optimization and machine learning communities, especially in relation to generative adversarial networks and adversarial training. This paper focuses on a specific type of smooth structured nonconvex-nonconcave minimax problem and proposes an efficient first-order method for finding a stationary point. Previous research has explored extragradient-type methods for similar problems, but this paper introduces a novel approach called the fast extragradient method (FEG) that achieves a faster convergence rate. The paper also presents an adaptive variant of FEG that estimates problem parameters and a stochastic version called S-FEG, which uses stochastic noise to provide convergence analysis. The main contributions of this paper are the introduction of the FEG method with accelerated convergence, its faster rate compared to existing methods under the convex-concave setting, and the analysis of the adaptive and stochastic versions of FEG.