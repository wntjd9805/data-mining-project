In recent years, deep models for audio generation have made significant advancements in various applications. However, these models typically require large datasets for training, which can be challenging to collect in practical scenarios. In this paper, we explore the question of whether large amounts of training data are necessary for training a generative model. We present a generative adversarial network (GAN) based model called Catch-A-Waveform that can capture the essence of an audio source from as little as a few tens of seconds from a single training recording. This model does not require pre-training or external supervision. We demonstrate the effectiveness of our approach in generating diverse new audio samples and performing tasks such as bandwidth extension, inpainting, and denoising. Our work is inspired by generative models for visual data but addresses the unique challenges of audio signals.