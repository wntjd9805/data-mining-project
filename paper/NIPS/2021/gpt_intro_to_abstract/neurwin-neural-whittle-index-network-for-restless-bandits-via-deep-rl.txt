Many sequential decision problems in computer science can be modeled as multi-armed bandit problems, where each potential decision is represented as an arm. The goal is to maximize the expected long-term total discounted reward by choosing which arms to play and receive rewards from. The restless bandit problem is a particularly challenging case where the reward distribution of an arm depends on its state, which changes over time based on past actions. Traditional approaches to solve this problem have been limited to special instances. In this paper, we propose a machine learning approach called Neural Whittle Index Network (NeurWIN) that finds the Whittle indices for virtually all restless bandit problems. We leverage a mathematical property of the Whittle index to train NeurWIN using deep reinforcement learning. Experimental results demonstrate that NeurWIN significantly outperforms other reinforcement learning algorithms in various restless bandit problems. The paper concludes with a discussion of related literature, formal definitions, the training algorithm, and evaluation of NeurWIN's performance.