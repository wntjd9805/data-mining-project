In this paper, we question the necessity of massive training sets of real images in computer vision and instead investigate the use of procedural noise models to generate synthetic training data for a visual representation learner. We highlight the importance of naturalism and diversity in synthetic data and demonstrate that simple noise models can capture these properties. Our findings suggest that vision may be simpler than previously thought and that vision systems can be trained without relying on large datasets. This opens up possibilities for reducing costs and overcoming limitations associated with real data collection. While we do not advocate for the complete removal of datasets from computer vision, our work prompts a reimagining of what can be accomplished in their absence.