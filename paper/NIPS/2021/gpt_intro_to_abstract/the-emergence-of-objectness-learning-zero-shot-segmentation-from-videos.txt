Contrastive learning has emerged as a powerful method for obtaining high-level visual representations from images. However, it still has practical limitations such as the reliance on hand-crafted augmentations and the need for additional labeled data for fine-tuning. In this paper, we propose a solution to these limitations by developing object segmentation models automatically from unlabeled videos without any supervision. We leverage the dynamic nature of videos to capture complex object deformations and 3D viewpoint changes. By automatically segregating moving objects and their backgrounds in videos, we can discover object semantics from the foreground segmentations. We introduce a zero-shot object segmentation approach that is learned from unsupervised factorization of images into segments and their motions. Our model utilizes region segmentation and region flow estimation to enable mutual view synthesis and improve both segmentation and flow estimation. We demonstrate the effectiveness of our approach on multiple applications and show significant improvements over baselines.