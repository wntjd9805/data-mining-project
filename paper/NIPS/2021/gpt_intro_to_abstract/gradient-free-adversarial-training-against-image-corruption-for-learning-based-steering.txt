Autonomous driving requires reliable operation under various unpredictable conditions. This study focuses on "learning-based steering," which combines perception and control, crucial components for autonomous driving. External factors, such as weather conditions, along with internal factors can affect the quality of input data for learning algorithms. This paper aims to analyze and improve the sensitivity of neural network performance to image quality by simulating image degradations at training time. A systematic approach is proposed to measure image degradation severity and predict its impact on model performance. The method involves training on adversarially degraded images and fine-tuning on clean data. Experimental results show significant improvements in accuracy, especially on datasets with complex combinations of perturbations. The proposed algorithm outperforms other techniques in visual processing tasks and can be easily integrated with other frameworks. Additionally, a robustness evaluation standard is proposed under different scenarios, and code and datasets will be released for benchmarking autonomous driving under perturbations.