Algorithmic game theory and machine learning have made significant advancements in artificial intelligence, leading to the development of artificial agents that can defeat top human professionals in various recreational games. However, these agents often do not adapt to the actual capabilities of humans, resulting in a performance gap compared to agents that consider human behavior. In this paper, we address the problem of designing artificial agents that can effectively exploit unknown human opponents while playing against them repeatedly in an online fashion. We specifically focus on scenarios where the agent's strategy is subject to constraints to ensure the human's expected utility falls within certain thresholds. We also explore applications of our framework in ensuring human engagement during gameplay and in serious games for education. We study two-player sequential games, assume a fixed stochastic behavior for the human, and derive confidence regions for the human's strategy to formulate linear constraints on the agent's strategy. We propose the COX-UCB algorithm, which guarantees that these constraints are satisfied with high probability and exhibits sublinear regret. We provide empirical evaluations and demonstrate the tightness of our bounds.