This paper introduces the use of pretrained representations to enhance and stabilize the training of Generative Adversarial Networks (GANs) for image synthesis. While pretrained representations have been widely applied in computer vision and natural language processing, their application to unconditional noise-to-image synthesis with GANs has not yet been explored extensively. The naive application of pretrained features leads to suboptimal results, as the discriminator dominates the training process. To overcome these challenges, the paper proposes the use of feature pyramids for multi-scale feedback and random projections for leveraging deeper layers of the pretrained network. Extensive experiments on various datasets demonstrate state-of-the-art image synthesis with reduced training time, increasing data efficiency and eliminating the need for additional regularization. The project's code, models, and supplementary videos are available on the project page.