Machine learning models often struggle to generalize under distribution shifts, such as JPEG compression. Methods that learn invariant representations across domains using labeled training data and unlabeled test data simultaneously have been proposed. However, revisiting training data at test time can be impractical due to privacy concerns and other constraints. In this paper, we explore the concept of test-time training (TTT) through self-supervision as a solution. We analyze the limitations of TTT and propose a test-time feature alignment strategy using offline feature summarization and online moment matching. We also address the challenge of scaling the strategy to problems with a large number of classes. Theoretical analysis shows the potential of TTT, and we integrate contrastive representation learning into the framework. Experimental results demonstrate that our improved version of TTT, called TTT++, outperforms other recent methods on robustness benchmarks. Our findings suggest that leveraging additional information can enhance the effectiveness of test-time adaptation.