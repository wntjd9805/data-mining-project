Abstract
Deep Metric Learning (DML) aims to find representations suitable for zero-shot transfer to a priori unknown test distributions. However, common evaluation protocols only test a single, fixed data split in which train and test classes are assigned randomly. More realistic evaluations should consider a broad spectrum of distribution shifts with potentially varying degree and difficulty. In this work, we systematically construct train-test splits of increasing difficulty and present the ooDML benchmark to characterize generalization under out-of-distribution shifts in DML. ooDML is designed to probe the generalization performance on much more challenging, diverse train-to-test distribution shifts. Based on our new benchmark, we conduct a thorough empirical analysis of state-of-the-art DML methods. We find that while generalization tends to consistently degrade with difficulty, some methods are better at retaining performance as the distribution shift increases. Finally, we propose few-shot DML as an efficient way to consistently improve generalization in response to unknown test shifts presented in ooDML1. 1

Introduction
Image representations that generalize well are the foundation of numerous computer vision tasks, such as image and video retrieval [61, 71, 54, 38, 1], face (re-)identification [57, 34, 8] and image classification [65, 4, 19, 40, 37]. Ideally, these representations should not only capture data within the training distribution, but also transfer to new, out-of-distribution (OOD) data. However, in practice, achieving effective OOD generalization is more challenging than in-distribution [28, 12, 21, 49, 31, 55]. In the case of zero-shot generalization, where train and test classes are completely distinct, Deep
Metric Learning (DML) is used to learn metric representation spaces that capture and transfer visual similarity to unseen classes, constituting a priori unknown test distributions with unspecified shift.
To approximate such a setting, current DML benchmarks use single, predefined and fixed data splits of disjoint train and test classes, which are assigned arbitrarily [71, 8, 61, 24, 11, 33, 74, 51, 54, 42, 26, 64, 58]. This means that (i) generalization is only evaluated on a fixed problem difficulty, (ii) 1Code available here: https://github.com/CompVis/Characterizing_Generalization_in_DML
∗ Equal contribution, alphabetical order, † equal supervision, x now at University of Tuebingen. 35th Conference on Neural Information Processing Systems (NeurIPS 2021), virtual.
generalization difficulty is only implicitly defined by the arbitrary data split, (iii) the distribution shift is not measured and (iv) cannot be not changed. As a result, proposed models can overfit to these singular evaluation settings, which puts into question the true zero-shot generalization capabilities of proposed DML models.
In this work, we first construct a new benchmark ooDML to characterize generalization under out-of-distribution shifts in DML. We systematically build ooDML as a comprehensive benchmark for evaluating OOD generalization in changing zero-shot learning settings which covers a much larger variety of zero-shot transfer learning scenarios potentially encountered in practice. We systematically construct training and testing data splits of increasing difficulty as measured by their Frechet-Inception
Distance [23] and extensively evaluate the performance of current DML approaches.
Our experiments reveal that the standard evaluation splits are often close to i.i.d. evaluation settings.
In contrast, our novel benchmark continually evaluates models on significantly harder learning problems, providing a more complete perspective into OOD generalization in DML. Second, we perform a large-scale study of representative DML methods on ooDML, and study the actual benefit of underlying regularizations such as self-supervision [38], knowledge distillation [53], adversarial regularization [59] and specialized objective functions [71, 70, 8, 26, 54]. We find that conceptual differences between DML approaches play a more significant role as the distribution shift to the test split becomes harder.
Finally, we present a study on few-shot DML as a simple extension to achieve systematic and consistent OOD generalization. As the transfer learning problem becomes harder, even very little in-domain knowledge effectively helps to adjust learned metric representation spaces to novel test distributions. We publish our code and train-test splits on three established benchmark sets, CUB200-2011 [68], CARS196 [30] and Stanford Online Products (SOP) [43]. Similarly, we provide training and evaluation episodes for further research into few-shot DML. Overall, our contributions can be summarized as:
• Proposing the ooDML benchmark to create a set of more realistic train-test splits that evaluate
DML generalization capabilities under increasingly more difficult zero-shot learning tasks.
• Analyzing the current DML method landscape under ooDML to characterize benefits and drawbacks of different conceptual approaches to DML.
• Introducing and examining few-shot DML as a potential remedy for systematically improved
OOD generalization, especially when moving to larger train-test distribution shifts. 2