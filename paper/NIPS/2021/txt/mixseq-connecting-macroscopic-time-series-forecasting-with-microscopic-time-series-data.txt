Abstract
Time series forecasting is widely used in business intelligence, e.g., forecast stock market price, sales, and help the analysis of data trend. Most time series of interest are macroscopic time series that are aggregated from microscopic data. However, instead of directly modeling the macroscopic time series, rare literature studied the forecasting of macroscopic time series by leveraging data on the microscopic level.
In this paper, we assume that the microscopic time series follow some unknown mixture probabilistic distributions. We theoretically show that as we identify the ground truth latent mixture components, the estimation of time series from each component could be improved because of lower variance, thus beneﬁtting the estimation of macroscopic time series as well. Inspired by the power of Seq2seq and its variants on the modeling of time series data, we propose Mixture of Seq2seq (MixSeq), an end2end mixture model to cluster microscopic time series, where all the components come from a family of Seq2seq models parameterized by different parameters. Extensive experiments on both synthetic and real-world data show the superiority of our approach. 1

Introduction
Time series forecasting has proven to be important to help people manage resources and make decisions [20]. For example, probabilistic forecasting of product demand and supply in retails [9], or the forecasting of loans [1] in a ﬁnancial institution can help people do inventory or ﬁnancing planning to maximize the proﬁt. Most time series of interest are macroscopic time series, e.g., the sales of an online retail platform, the loans of a ﬁnancial institution, or the number of infections caused by some pandemic diseases in a state, that are comprised of microscopic time series, e.g., the sales of a merchant in the online retail, the loans from a customer given the ﬁnancial institution, or the number of infections in a certain region. That is, the observed macroscopic time series are just the aggregation or sum of microscopic time series.
∗Equal contribution.
†Corresponding author. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
Although various time series forecasting models, e.g., State Space Models (SSMs) [13], Autoregres-sive (AR) models [2], or deep neural networks [5], have been widely studied for decades, all of them study the modeling of time series without considering the connections between macroscopic time series of interest and the underlying time series on the microscopic level.
In this paper, we study the question whether the forecasting of macroscopic time series can be improved by leveraging the underlying microscopic time series, and the answer is yes. Basically, though accurately modeling each microscopic time series could be challenging due to large variations, we show that by carefully clustering microscopic time series into clusters, i.e., clustered time series, and using canonical approaches to model each of clusters, ﬁnally we can achieve promising results by simply summing over the forecasting results of each cluster.
To be more speciﬁc, ﬁrst, we assume that the microscopic time series are generated from a proba-bilistic mixture model [24] where there exist K components. The generation of each microscopic time series is by ﬁrst selecting a component z from {1, ..., K} with a prior p(z) (a Discrete distri-bution), then generating the microscopic observation from a probabilistic distribution p(x; Φz, z) parameterized by the corresponding component Φz. We show that as we can identify the ground truth components of the mixture, and the ground truth assignment of each microscopic observation, inde-pendent modeling of time series data from each component could be improved due to lower variance, and further beneﬁtting the estimation of macroscopic time series that are of interest. Second, inspired by recent successes of Seq2seq models [36, 10, 12] based on deep neural networks, e.g., variants of recurrent neural networks (RNNs) [16, 41, 22], convolutional neural networks (CNNs) [4, 15], and Transformers [19, 38], we propose Mixture of Seq2seq (MixSeq), a mixture model for time series, where the components come from a family of Seq2seq models parameterized by different parameters. Third, we conduct synthetic experiments to demonstrate the superiority of our approach, and extensive experiments on real-world data to show the power of our approach compared with canonical approaches.
Our contributions. We summarize our contributions in two-fold. (1) We show that by transforming the original macroscopic time series via clustering, the expected variance of each clustered time series could be optimized, thus improving the accuracy and robustness for the estimation of macroscopic time series. (2) We propose MixSeq which is an end2end mixture model with each component coming from a family of Seq2seq models. Our empirical results based on MixSeq show the superiority compared with canonical approaches. 2