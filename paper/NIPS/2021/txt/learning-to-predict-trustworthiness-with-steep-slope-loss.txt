Abstract
Understanding the trustworthiness of a prediction yielded by a classiﬁer is crit-ical for the safe and effective use of AI models. Prior efforts have been proven to be reliable on small-scale datasets. In this work, we study the problem of predicting trustworthiness on real-world large-scale datasets, where the task is more challenging due to high-dimensional features, diverse visual concepts, and a large number of samples. In such a setting, we observe that the trustworthi-ness predictors trained with prior-art loss functions, i.e., the cross entropy loss, focal loss, and true class probability conﬁdence loss, are prone to view both correct predictions and incorrect predictions to be trustworthy. The reasons are two-fold. Firstly, correct predictions are generally dominant over incorrect pre-dictions. Secondly, due to the data complexity, it is challenging to differentiate the incorrect predictions from the correct ones on real-world large-scale datasets.
To improve the generalizability of trustworthiness predictors, we propose a novel steep slope loss to separate the features w.r.t. correct predictions from the ones w.r.t. incorrect predictions by two slide-like curves that oppose each other. The proposed loss is evaluated with two representative deep learning models, i.e.,
Vision Transformer and ResNet, as trustworthiness predictors. We conduct com-prehensive experiments and analyses on ImageNet, which show that the proposed loss effectively improves the generalizability of trustworthiness predictors. The code and pre-trained trustworthiness predictors for reproducibility are available at https://github.com/luoyan407/predict_trustworthiness. 1

Introduction
Classiﬁcation is a ubiquitous learning problem that categorizes objects according to input features. It is widely used in a range of applications, such as robotics [1], environment exploration [2], medical diagnosis [3], etc. In spite of the successful development of deep learning methods in recent decades, high-performance classiﬁers would still have a chance to make mistakes due to the improvability of models and the complexity of real-world data [4, 5, 6, 7].
To assess whether the prediction yielded by a classiﬁer can be trusted or not, there are growing efforts towards learning to predict trustworthiness [8, 9]. These methods are evaluated on small-scale datasets, e.g., MNIST [10], where the data is relatively simple and existing classiﬁers have achieved high accuracy (> 99%). As a result, there are a dominant proportion of correct predictions and the trustworthiness predictors are prone to classify incorrect predictions as trustworthy predictions. The characteristics that the simple data is easy-to-classify aggravate the situation. To further understand the prowess of predicting trustworthiness, we study this problem on the real-world large-scale datasets, i.e., ImageNet [11]. This is a challenging theme for classiﬁcation in terms of boundary complexity, class ambiguity, and feature dimensionality [12]. As a result, failed predictions are inevitable. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
(a) (b)
Figure 1: Conceptual illustrations of trustworthiness prediction. (a) shows the process of predicting trustworthiness where the oracle is the trustworthiness predictor. The illustration in (b) shows that the task is challenging on ImageNet, where TCP’s conﬁdence loss [9] is used in this example.
The conﬁdence that is greater (lower) than the positive (negative) threshold would be classiﬁed as a trustworthy (untrustworthy) prediction. Usually, both the positive threshold and the negative threshold
# of classes in the case of TCP. are 0.5, but the negative threshold is 1
A general illustration of predicting trustworthiness [9, 13] is shown in Fig. 1a. The trustworthiness predictor [13] that is based on the maximum conﬁdence have been proven to be unreliable [8, 14, 15, 16]. Instead, Corbiere et al. [9] propose the true class probability (TCP) that uses the conﬁdence w.r.t. the ground-truth class to determine whether to trust the classiﬁer’s prediction or not. Nevertheless, the classiﬁcation conﬁdence is sensitive to the data. As shown in Fig. 1b, TCP predicts that all the incorrect predictions (0.9% in predictions) are trustworthy on MNIST [10] and predicts that all the incorrect predictions (∼16% in predictions) are trustworthy on ImageNet [11].
To comprehensively understand this problem, we follow the learning scheme used in [9] and use two state-of-the-art backbones, i.e., ViT [7] and ResNet [5], as the trustworthiness predictors. For simplicity, we call the “trustworthiness predictor" an oracle. We ﬁnd that the oracles trained with cross entropy loss [17], focal loss [18], and TCP conﬁdence loss [9] on ImageNet are prone to overﬁt the training samples, i.e., the true positive rate (TPR) is close to 100% while the true negative rate (TNR) is close to 0%. To improve the generalizability of oracles, we propose a novel loss function named the steep slope loss. The proposed steep slope loss consists of two slide-like curves that cross with each other and face in the opposite direction to separate the features w.r.t. trustworthy and untrustworthy predictions. It is tractable to control the slopes by indicating the heights of slides. In this way, the proposed loss is able to be ﬂexible and effective to push the features w.r.t. correct and incorrect predictions to the well-classiﬁed regions.
Predicting trustworthiness is similar to as well as different from conventional classiﬁcation tasks.
On one hand, predicting trustworthiness can be formulated as a binary classiﬁcation problem. On the other hand, task-speciﬁc semantics are different between the classiﬁcation task and predicting trustworthiness. The classes are referred to visual concepts, such as dog, cat, etc., in the classiﬁcation task, while the ones in predicting trustworthiness are abstract concepts. The trustworthiness could work on top of the classes in the classiﬁcation task. In other words, the classes in the classiﬁcation task are speciﬁc and closed-form, while trustworthiness is open-form and is related to the classes in the classiﬁcation task.
The contribution of this work can be summarized as follows.
• We study the problem of predicting trustworthiness with widely-used classiﬁers on ImageNet.
Speciﬁcally, we observe that a major challenge of this learning task is that the cross entropy loss, focal loss, and TCP loss are prone to overﬁt the training samples, where correct predictions are dominant over incorrect predictions.
• We propose the steep slope loss function that improves the generalizability of trustworthiness predictors. We conduct comprehensive experiments and analyses, such as performance on both small-scale and large-scale datasets, analysis of distributions separability, comparison to the class-balanced loss, etc., which verify the efﬁcacy of the proposed loss.
• To further explore the practicality of the proposed loss, we train the oracle on the ImageNet training set and evaluate it on two variants of ImageNet validation set, i.e., the stylized validation set and the adversarial validation set. The two variants’ domains are quite different 2
from the domain of the training set. We ﬁnd that the learned oracle is able to consistently differentiate the trustworthy predictions from the untrustworthy predictions. 2 Preliminaries
In this section, we ﬁrst recap how a deep learning model learns in the image classiﬁcation task. Then, we show how the task of predicting trustworthiness connects to the classiﬁcation task.
Supervised Learning for Classiﬁcation. In classiﬁcation tasks, given a training sample, i.e., image x ∈ Rm and corresponding ground-truth label y ∈ Y = {1, . . . , K}, we assume that samples are drawn i.i.d. from an underlying distribution. The goal of the learning task is to learn to ﬁnd a classiﬁer f (cls)(·; θ(cid:48)) with training samples for classiﬁcation. θ(cid:48) is the set of parameters of the classiﬁer. Let f (cls)
θ(cid:48) (·) = f (cls)(·; θ(cid:48)). The optimization problem is deﬁned as f ∗(cls)
θ(cid:48)
= arg min f (cls)
θ(cid:48)
ˆR(f (cls)
θ(cid:48)
, (cid:96)(cls), Dtr), (1) where f ∗(cls) and Dtr is the set of training samples.
θ(cid:48) is the learned classiﬁer, ˆR is the empirical risk, (cid:96)(cls) is a loss function for classiﬁcation,
Supervised Learning for Predicting Trustworthiness. In contrast to the learning task for classiﬁ-cation, which is usually a multi-class single-label classiﬁcation task [4, 5, 6, 7], learning to predict trustworthiness is a binary classiﬁcation problem, where the two classes are positive (i.e., trustworthy) or negative (i.e., untrustworthy). Similar to [9], given a pair (x, y) and a classiﬁer f (cls)
, we deﬁne the ground-truth label o for predicting trustworthiness as
θ(cid:48) o = (cid:40) if arg max f (cls) 1, 0, otherwise
θ(cid:48) (x) = y (2)
In other words, the classiﬁer correctly predicts the image’s label so the prediction is trustworthy in hindsight, otherwise the prediction is untrustworthy.
The learning task for predicting trustworthiness follows a similar learning framework in the clas-siﬁcation task. Let fθ(·) be an oracle (i.e., a trustworthiness predictor). A generic loss function (cid:96) : Rm × R → R≥0, where R≥0 is a non-negative space and m is the number of classes. Given training samples (x, y) ∈ Dtr, the optimization problem for predicting trustworthiness is deﬁned as f ∗
θ = arg min fθ 1
|Dtr|
|Dtr| (cid:88) i=1 (cid:96)(fθ(xi), oi), (3) where |Dtr| is the cardinality of Dtr.
Particularly, we consider two widely-used loss functions for classiﬁcation and the loss function used for training trustworthiness predictors as baselines. They are the cross entropy loss [17], focal loss
[18], and TCP conﬁdence loss [9]. Let p(o = 1|θ, x) = 1/(1 + exp(−z)) be the trustworthiness conﬁdence, where z ∈ R is the descriminative feature produced by the oracle, i.e., z = fθ(x). The three loss functions can be written as (cid:96)CE(fθ(x), o) = −o · log p(o = 1|θ, x) − (1 − o) · log(1 − p(o = 1|θ, x)), (cid:96)F ocal(fθ(x), o) = −o · (1 − p(o = 1|θ, x))γ log p(o = 1|θ, x)− (1 − o) · (p(o = 1|θ, x))γ log(1 − p(o = 1|θ, x)), (4) (5) (cid:96)T CP (fθ(x), y) = (fθ(x) − p(ˆy = y|θ(cid:48), x))2. (6)
In the focal loss, γ is a hyperparameter. In the TCP conﬁdence loss, ˆy is the predicted label and p(ˆy = y|θ(cid:48), x) is the classiﬁcation probability w.r.t. the ground-truth class.
Consequently, the learned oracle would yield z to generate the trustworthiness conﬁdence.
In the cases of (cid:96)CE and (cid:96)F ocal, the oracle considers a prediction is trustworthy if the corresponding trustworthiness conﬁdence is greater than the positive threshold 0.5, i.e., p(o = 1|θ, x) > 0.5. The predictions whose trustworthiness conﬁdences are equal to or lower than the negative threshold 0.5 are viewed to be untrustworthy. In the case of (cid:96)T CP , the positive threshold is also 0.5, but the negative threshold correlates to the number of classes in the classiﬁcation task. It is deﬁned as 1/K in [9]. 3
(a) (b)
Figure 2: Conceptual workﬂow of the proposed steep slope loss (a) and graph comparison between the proposed loss and the conventional losses (b). In (b), the cross entropy loss and focal loss are plotted in blue and black, respectively. The TCP conﬁdence loss is a square error and varies with the classiﬁcation conﬁdence. Therefore, it is not plotted here. 3 Methodology
In this section, we ﬁrst introduce the overall learning framework for predicting trustworthiness. Then, we narrow down to the proposed steep slope loss function. At last, we provide the generalization bound that is related to the proposed steep slope loss function. 3.1 Overall Design
Corbière et al. [9] provide a good learning scheme for predicting trustworthiness. Brieﬂy, it ﬁrst trains a classiﬁer with the training samples. Then, the classiﬁer is frozen and the conﬁdence network (i.e., trustworthiness predictor) is trained (or ﬁne-tuned) with the training samples. In general, we follows this learning scheme.
This work focuses on the trustworthiness on the predictions yielded by the publicly available pre-trained classiﬁers, i.e., ViT [7] and ResNet [5]. We use the pre-trained backbones as the backbones of the oracles for general purposes. In this sense, the set of the oracle’s parameters can be split into two parts, one is related to the backbone and the other one is related to the head, i.e., θ =
{θbackbone, θhead}. θbackbone is used to generated the intermediate feature xout and θhead = {w, b} are usually the weights of a linear function to generate the discriminative feature z = w(cid:62)xout + b.
With the classiﬁer, the oracle, a pre-deﬁned loss, and the training samples, we can optimize problem (3) to ﬁnd the optimal parameters for the oracle. 3.2 Steep Slope Loss
The conceptual workﬂow of the proposed steep slope loss is shown in Fig. 2a. The core idea is that we exploit the graph characteristics of the exponential function and the softsign function to establish two slides such that the features z w.r.t. the positive class ride down the positive slide to the right bottom and the features z w.r.t. the negative class ride down the negative slide to the left bottom. z is deﬁned as the signed distance to the hyperplane (i.e., oracle head). Given an image x, z = fθ(x) can be broken down into z = w(cid:62)xout + b (cid:107)w(cid:107)
, xout = fθbackbone (x). (7)
The signed distance to the hyperplane has a geometric interpretation: its sign indicates in which half-space xout is and its absolute value indicates how far xout is away from the hyperplane.
It is desired that the signed distance of xout with ground-truth label o = 1 (o = 0) tends towards
+∞ (−∞) as much as possible. To this end, we deﬁne the steep slope (SS) loss function as follows (cid:96)SS(fθ(x), o) = o · exp (cid:18) (cid:19) (cid:18) α+z 1 + |z|
− exp(−α+) (cid:124) (cid:123)(cid:122)
Positive slide (cid:19) (cid:125) (cid:18)
+(1 − o) · exp (cid:19) (cid:18) −α−z 1 + |z|
− exp(−α−) (cid:124) (cid:123)(cid:122)
Negative slide (8) (cid:19) (cid:125) where α+, α− ∈ R+ control the slope of the positive slide and the negative slide, respectively. If z w.r.t. the positive class is on the left-hand side of z = 0, minimizing the loss would push the point on the hill down to the bottom, i.e., the long tail region indicating the well-classiﬁed region. Similarly, z 4
w.r.t. the negative class would undergo a similar process. exp(−α+) and exp(−α−) are vertical shifts for the positive and negative slides such that (cid:96)ss has a minimum value 0. Note that the proposed steep slope loss is in the range [0, maximum{exp(α+) − exp(−α+), exp(α−) − exp(−α−)}], whereas the cross entropy loss and the focal loss are in the range [0, +∞). The proposed steep slope loss can work with the output of the linear function as well. This is because the signed distance and the output of the linear function have a proportional relationship with each other, i.e., w(cid:62)xout+b
∝ w(cid:62)xout + b. (cid:107)w(cid:107)
Essentially, as shown in Fig. 2b, the cross entropy loss, focal loss, and steep slope loss work in a similar manner to encourage z w.r.t. the positive class to move the right-hand side of the positive threshold 0 and encourage z w.r.t. the negative class to move the left-hand side of the negative threshold 0, which is analogous to the sliding motion. The proposed steep slope loss is more tractable to control the steepness of slopes than the cross entropy loss and focal loss. This leads to an effective learning to yield discriminative feature for predicting trustworthiness. 3.3 Generalization Bound
With the proposed steep slope loss, we are interested in the generalization bound of trustworthiness predictors. For simplicity, we simplify a trustworthiness predictor as f ∈ F, where F is a ﬁnite hy-pothesis set. The risk of predicting trustworthiness is deﬁned as R(f ) = E(x,y)∼P [(cid:96)SS(f (x), o)], where
P is the underlying joint distribution of (x, o). As P is inaccessible, a common practice is to use em-pirical risk minimization (ERM) to approximate the risk [19], i.e., ˆRD(f ) = 1 i=1 (cid:96)SS(f (xi), oi).
|D| (cid:80)|D|
The following theorem provides an insight into the correlation between the generalization bound and the loss function in the learning task for predicting trustworthiness.
Theorem 3.1. Denote maximum{exp(α+) − exp(−α+), exp(α−) − exp(−α−)} as (cid:96)max
[0, (cid:96)max following inequality holds for all f ∈ F:
SS . (cid:96)SS ∈
SS ]. Assume F is a ﬁnite hypothesis set, for any δ > 0, with probability at least 1 − δ, the
|R(f ) − ˆRD(f )| ≤ (cid:96)max
SS (cid:115) log |F| + log 2
δ 2|D|
The proof sketch is similar to the generalization bound provided in [20] and the detailed proof is provided in the appendix A.
A desired characteristic of the proposed steep slope loss is that it is in a certain range determined by
α+ and α−, as discussed in Section 3.2. This leads to the generalization bound shown in Theorem 3.1. The theorem implies that given a generic classiﬁer, as the number of training samples increases, the empirical risk would be close to the true risk with a certain probability. On the other hand, the cross entropy loss, focal loss, and TCP loss are not capped in a certain range. They do not ﬁt under
Hoeffding’s inequality to derive the generalization bounds. 4