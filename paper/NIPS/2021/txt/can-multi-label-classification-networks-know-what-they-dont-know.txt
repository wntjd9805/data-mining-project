Abstract
Estimating out-of-distribution (OOD) uncertainty is a major challenge for safely deploying machine learning models in the open-world environment. Improved methods for OOD detection in multi-class classiﬁcation have emerged, while OOD detection methods for multi-label classiﬁcation remain underexplored and use rudimentary techniques. We propose JointEnergy, a simple and effective method, which estimates the OOD indicator scores by aggregating label-wise energy scores from multiple labels. We show that JointEnergy can be mathematically interpreted from a joint likelihood perspective. Our results show consistent improvement over previous methods that are based on the maximum-valued scores, which fail to capture joint information from multiple labels. We demonstrate the effectiveness of our method on three common multi-label classiﬁcation benchmarks, including MS-COCO, PASCAL-VOC, and NUS-WIDE. We show that JointEnergy can reduce the FPR95 by up to 10.05% compared to the previous best baseline, establishing state-of-the-art performance. 1

Introduction
Despite many breakthroughs in machine learning, formidable obstacles obstruct its deployment in the real world, where a model can encounter unknown out-of-distribution (OOD) samples. The problem of OOD detection has gained signiﬁcant research attention lately [4, 18, 21, 25, 27, 28, 34, 30, 44].
OOD detection aims to identify test-time inputs that have no label intersection with training classes, thus should not be predicted by the model. Previous studies have primarily focused on detecting OOD examples in multi-class classiﬁcation, where each sample is assigned to a single label. Unfortunately, this can be unrealistic in many real-world applications where images often have multiple labels of interest. For example, in medical imaging, multiple abnormalities may be present in a medical scan [51].
Currently, a critical research gap exists in developing and evaluating OOD detection algorithms for multi-label classiﬁcation tasks that are more applicable to the real world. While one may expect solutions for multi-class setting should transfer to the multi-label setting, we show that this is far from the truth. The main challenges posed in multi-label setting stem from the need to estimate uncertainty by jointly leveraging the information across different labels, as opposed to relying on one
⇤Equal contribution. Work done while H.W was working at UW-Madison as an undergraduate researcher. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
In-Distribution f (x;θ) x
Out-of-Distribution
Plane
Car
Car
Bird
Cat
Deer
Dog
Horse
Frog
Ship
Truck
Max
Sum aggregating over many x
In-Distribution
Out-of-Distribution
Figure 1: Out-of-distribution detection for multi-label classiﬁcation networks. During inference time, input x is passed through classiﬁer f , and label-wise scores are computed for each label. OOD indicator scores are either the maximum-valued score (denoted by green outlines) or the sum of all scores. Taking the sum results in a larger difference in scores and more separation between in-distribution and OOD inputs (denoted by red lines), resulting in better OOD detection. Plots in the bottom right depict the probability densities of MaxLogit [15] versus JointEnergy (ours).
MaxLogit
JointEnergy  (ours)  dominant label. Our analysis reveals that simply using the largest model output (i.e., MaxLogit) can be limiting. As a simple illustration, we contrast in Figure 1 of estimating OOD uncertainty using joint vs. single label information. MaxLogit can only capture the difference between the dominant outputs for dog (in-distribution) and car (OOD), while positive information from another dominant label cat (in-distribution) is dismissed.
In this paper, we address the important problem of OOD uncertainty estimation in the multi-label classiﬁcation setting, and propose a simple and surprisingly effective method that jointly characterizes uncertainty from multiple labels. As a major advantage, our method circumvents the challenge to directly estimate the joint likelihood using generative models, which can be can computationally intractable to train and optimize, especially on multi-label datasets [17]. Formally, our proposed method, JointEnergy, derives a novel OOD score by combining label-wise energies over all labels.
Despite its simplicity, we show that the JointEnergy can be theoretically interpreted from a joint likelihood perspective. The joint likelihood allows separability between in-distribution vs. OOD data, since OOD data is expected to have lower joint likelihood (i.e., not associated with any of the labels).
In contrast, having multiple dominant labels is indicative of an in-distribution input, which is the key aspect that JointEnergy captures. As shown in Figure 1, JointEnergy effectively ampliﬁes the difference in scores between in-distribution and OOD inputs, compared to MaxLogit.
Extensive experiments show that JointEnergy outperforms existing methods on three common multi-label classiﬁcation tasks, establishing state-of-the-art performance. For example, on a DenseNet trained with MS-COCO [29], our method reduces the false positive rate (at 95% TPR) by 10.05% when evaluated against OOD data from ImageNet [9], compared to the best performing baselines.
Consistent performance improvement is observed on other multi-label tasks including PASCAL-VOC [11] and NUS-WIDE [6], as well as alternative network architecture.
Importantly, our analysis demonstrates a strong compatibility between the label-wise energy function and aggregation function, supported by both mathematical interpretation and empirical results. As an ablation, we explore the effectiveness of applying summation to popular OOD scoring functions [15, 16, 28, 27]. We ﬁnd that summing labels’ scores using previous methods is inferior to summing labels’ energies, emphasizing the need for JointEnergy. For example, simply summing over the logits across labels results in up to 51.93% degradation in FPR95 on MS-COCO. Our study therefore underlines the importance of properly choosing both the label-wise scoring function and the aggregation method.
Below we summarize our key results and contributions:
• We propose a novel method JointEnergy—addressing an important yet underexplored problem—OOD detection for multi-label classiﬁcation networks. Our method establishes 2
state-of-the-art performance, reducing the average FPR95 by up to 10.05%. We show theoretical interpretation, underpinning our method from a joint likelihood perspective.
• We conduct extensive ablations which reveals important insights for multi-label OOD uncertainty estimation under (1) different aggregation functions, (2) different label-wise
OOD scoring functions, and (3) the compatibility thereof.
• We curate three evaluation tasks in the multi-label setting from three real-world high-resolution image databases, which enables future research to evaluate OOD detection in a multi-label setting. Our code and dataset is released for reproducible research2. 2