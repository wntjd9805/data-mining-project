Abstract
We address the problem of sequential prediction with expert advice in a non-stationary environment with long-term memory guarantees in the sense of Bousquet and Warmuth [4]. We give a linear-time algorithm that improves on the best known regret bounds [27]. This algorithm incorporates a relative entropy projection step. This projection is advantageous over previous weight-sharing approaches in that weight updates may come with implicit costs as in for example portfolio optimization. We give an algorithm to compute this projection step in linear time, which may be of independent interest. 1

Introduction
We consider the classic problem of online prediction with expert advice [35] in a non-stationary environment. In this model nature sequentially generates outcomes which the learner attempts to predict. Before making each prediction, the learner listens to a set of n experts who each make their own predictions. The learner bases its prediction on the advice of the experts. After the prediction is made and the true outcome is revealed by nature, the accuracies of the learner’s prediction and the expert predictions are measured by a loss function. The learner receives information on all expert losses on each trial. We make no distributional assumptions about the outcomes generated, indeed nature may be assumed to be adversarial. The goal of the learner is to predict well relative to a predetermined comparison class of predictors, in this case the set of experts themselves. Unlike the standard regret model, where the learner’s performance is compared to the single best predictor in hindsight, our aim is for the learner to predict well relative to a sequence of comparison predictors.
That is, “switches” occur in the data sequence and different experts are assumed to predict well at different times.
In this work our focus is on the case when this sequence consists of a few unique predictors relative to the number of switches. Thus most switches return to a previously “good” expert, and a learner that can exploit this fact by “remembering” the past can adapt more quickly than a learner who has no memory and must re-learn the experts after every switch. The problem of switching with memory in online learning is part of a much broader and fundamental problem in machine learning: how a system can adapt to new information yet retain knowledge of the past. This is an area of research in many ﬁelds, including for example, catastrophic forgetting in artiﬁcial neural networks [11, 36].
In this paper we present an O(n)-time per trial projection-based algorithm for
Contributions. which we prove the best known regret bound for tracking experts with memory. Our projection-based algorithm is intimately related to a more traditional “weight-sharing” algorithm, which we show is a new method for Mixing Past Posteriors (MPP) [4]. We show that surprisingly this method 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
corresponds to the algorithm with the previous best known regret bound for this problem [27]. We also give an efﬁcient O(n)-time algorithm for computing exact relative entropy projection onto a simplex with non-uniform (lower) box constraints. Finally, we provide a guarantee which favors projection-based updates over weight-sharing updates when updating weights may incur costs.
The paper is organized as follows. We ﬁrst introduce the model and discuss related work, giving a detailed overview of the previous results on which we improve. In Section 3 we give our main results, a regret bound which holds for two algorithms, and an algorithm to compute relative entropy projection with non-uniform lower box constraints in linear time. In Section 4 we derive a new “geometric-decay” method for MPP, and show the correspondence to the current best known algorithm [27]. We give a few concluding remarks in Section 5. All proofs are contained in the appendices. 1.1 Preliminaries
We ﬁrst introduce notation. Let ∆n := {u ∈ [0, 1]n : (cid:107)u(cid:107)1 = 1} be the (n − 1)-dimensional probability simplex. Let ∆α n := {u ∈ [0, α]n : (cid:107)u(cid:107)1 = α} be a scaled simplex. Let 1 denote the vector (1, . . . , 1) and 0 denote the vector (0, . . . , 0). Let ei denote the ith standard basis vec-tor. We deﬁne D(u, w) := (cid:80)n to be the relative entropy between u and w. We denote component-wise multiplication as u (cid:12) w := (u1w1, . . . , unwn). For p ∈ [0, 1] we de-ﬁne H(p) := −p ln p − (1 − p) ln (1 − p) to be the binary entropy of p, using the convention that 0 ln 0 = 0. We deﬁne ri S to be the relative interior of the set S. For any positive integer n we deﬁne
[n] := {1, . . . , n}. We overload notation such that [pred] is equal to 1 if the predicate pred is true and 0 otherwise. For two vectors α and β we say α (cid:22) β iff αi ≤ βi for all i = 1, . . . , n. i=1 ui log ui wi 2