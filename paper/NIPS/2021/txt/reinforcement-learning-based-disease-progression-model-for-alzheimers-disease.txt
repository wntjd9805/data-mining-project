Abstract
We model Alzheimer’s disease (AD) progression by combining differential equa-tions (DEs) and reinforcement learning (RL) with domain knowledge. DEs provide relationships between some, but not all, factors relevant to AD. We assume that the missing relationships must satisfy general criteria about the working of the brain, for e.g., maximizing cognition while minimizing the cost of supporting cognition.
This allows us to extract the missing relationships by using RL to optimize an objective (reward) function that captures the above criteria. We use our model consisting of DEs (as a simulator) and the trained RL agent to predict individualized 10-year AD progression using baseline (year 0) features on synthetic and real data.
The model was comparable or better at predicting 10-year cognition trajectories than state-of-the-art learning-based models. Our interpretable model demonstrated, and provided insights into, "recovery/compensatory" processes that mitigate the effect of AD, even though those processes were not explicitly encoded in the model.
Our framework combines DEs with RL for modelling AD progression and has broad applicability for understanding other neurological disorders. 1

Introduction
Models that describe Alzheimer’s disease (AD) progression through time, i.e., the evolution of factors involved in the disease such as brain size, brain activity, pathology, and cognition (Fig. 1), are crucial for mitigating this highly prevalent disease [1, 2]. Such models can enhance our understanding of the disease processes and enable crucial applications like prediction of long-term cognition trajectories for early detection. Our goal is to develop a model to predict an individual’s future AD progression at 1-year intervals based on their baseline (year 0) data. We address this goal by combining differential equations that capture the relationships between some factors, and leveraging reinforcement learning to extract the missing relationships by optimizing a domain knowledge-based reward function.
Differential1 equation (DE) based models can describe disease progression by expressing domain knowledge as mathematical relationships between different factors [3, 4]. DE-based models have several advantages which make them attractive for disease progression modelling. The interpretability 1For simplicity, we use the term "differential equation" to denote algebraic and differential equations. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
of these models can enhance our understanding of disease processes [5, 6]. These models require limited data because the data is only used for parameter estimation. DE-based models’ mechanistic nature allows for intervention exploration [6]. However, these models provide an incomplete view of the disease because DEs describing relationships among some of the factors are unavailable [6].
We propose a framework for modeling AD progression that combines differential equations with rein-forcement learning (RL) to overcome the above limitation. We assume that the missing relationships are the solution of an optimization problem that can be formulated based on domain knowledge. In our model, this optimization problem’s objective function serves as the reward function for reinforcement learning. Therefore, by optimizing the reward, RL extracts the relationships among factors for which explicit DEs are unavailable. Thus, RL combined with the DEs describes the evolution of factors pertinent for modeling AD progression.
In our model, the available DEs define the simulator and the RL agent optimizes the domain-based reward function in the simulator. The parameters of the DEs are based on the available data. We overcome three main challenges for developing the proposed model. The first challenge is to identify the factors involved in each DE. We use domain knowledge to find existing causal relationships between different factors and differential equations relating them (when available).
Second, the DEs relating cognition, brain regions’ sizes, and brain activity are unknown (Fig. 1).
Since proposing novel DEs relating these factors requires significant scientific knowledge that is still in development, we address this challenge as follows. Multiple brain regions work together to produce cognition [7, 8]. We assume that the working of multiple brain regions is governed by an optimization problem that maximizes cognition while minimizing the cost of cognition [9]. We represent this optimization problem’s objective function in terms of cognition, brain size, and brain activity.
Finally, the above optimization problem needs to be solved for multiple time points for modeling disease progression with the solution at time t affecting the solution at time t
> t. Therefore, we use
RL to optimize the above objective (reward) function.
′
Our contributions are: 1. We developed an Alzheimer’s disease progression model based on domain knowledge that combines DEs and RL. To the best of our knowledge, this is the first attempt at using RL to develop a disease progression model. Our framework is generic and can be used with other DEs, or to provide a basis for modelling other neurological disorders. 2. We applied the model for predicting individualized long-term (10-year) future cognition trajectories using baseline (0th year) features on synthetic and real data.
On real data, our model reduced the prediction error by ∼ 10% than a state-of-the-art deep learning-based model [10] and produced more realistic trajectories than other benchmark models. Cognition trajectory prediction models are useful in a clinical setting to identify individuals at future risk of cognitive decline.
Figure 1: Causal relationships between variables based on domain knowledge. 3. Our interpretable model provided insight into how multiple brain regions together produce cogni-tion during AD. Specifically, we observed "recov-ery/compensatory" processes that mitigate the effect of AD on cognition [11], which could not be observed with state-of-the-art models. Recovery processes were not explicitly encoded into the model and were an outcome of the reward function’s form. Further investigation into the basis of recovery processes could guide the development of interventions. 2
Figure 2: Framework for modeling AD progression. (A) Relationship between brain size, brain activ-ity, information processing, and cognition (represented by solid and dashed edges). (B) Framework for AD progression that combines differential equations (DEs) with reinforcement learning (RL). 1.1