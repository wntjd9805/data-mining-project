Abstract
√
We consider speeding up stochastic gradient descent (SGD) by parallelizing it across multiple workers. We assume the same data set is shared among N workers, who can take SGD steps and coordinate with a central server. While it is possible to obtain a linear reduction in the variance by averaging all the stochastic gradients at every step, this requires a lot of communication between the workers and the server, which can dramatically reduce the gains from parallelism. The Local SGD method, proposed and analyzed in the earlier literature, suggests machines should make many local steps between such communications. While the initial analysis of Local SGD showed it needs Ω(
T ) communications for T local gradient steps in order for the error to scale proportionately to 1/(N T ), this has been successively improved in a string of papers, with the state of the art requiring
Ω (N ( poly(log T ))) communications. In this paper, we suggest a Local SGD scheme that communicates less overall by communicating less frequently as the number of iterations grows. Our analysis shows that this can achieve an error that scales as 1/(N T ) with a number of communications that is completely independent of T . In particular, we show that Ω(N ) communications are sufﬁcient. Empirical
N or N 3/4 evidence suggests this bound is close to tight as we further show that communications fail to achieve linear speed-up in simulations. Moreover, we show that under mild assumptions, the main of which is twice differentiability on any neighborhood of the optimal solution, one-shot averaging which only uses a single round of communication can also achieve the optimal convergence rate asymptotically.
√ 1

Introduction
Stochastic Gradient Descent (SGD) is a widely used algorithm to minimize convex functions f in which model parameters are updated iteratively as xt+1 = xt − ηtˆgt, where ˆgt is a stochastic gradient of f at the point xt and ηt is the learning rate. This algorithm can be naively parallelized by adding more workers independently to compute a gradient and then average 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
them at each step to reduce the variance in estimation of the true gradient ∇f (xt) (Dekel et al., 2012).
This method requires each worker to share their computed gradients with each other at every iteration.
We will refer to this method as "synchronized parallel SGD."
However, it is widely acknowledged that communication is a major bottleneck of this method for large scale optimization applications (McMahan et al., 2017; Koneˇcn`y et al., 2016; Lin et al., 2018b).
Often, mini-batch parallel SGD is suggested to address this issue by increasing the computation to communication ratio. Nonetheless, too large mini-batch size might degrade performance (Lin et al., 2018a). Along the same lines of increasing the computation over communication effort, local
SGD has been proposed to reduce communications (McMahan et al., 2017; Dieuleveut, Patel, 2019).
In this method, workers compute (stochastic) gradients and update their parameters locally, and communicate only once in a while to obtain the average of their parameters. Local SGD improves the communication efﬁciency not only by reducing the number of communication rounds, but also alleviates the synchronization delay caused by waiting for slow workers and evens out the variations in workers’ computing time (Wang, Joshi, 2018b).
On the other hand, since individual gradients of each worker are calculated at different points, this method introduces residual error as opposed to fully synchronized SGD. Therefore, there is a trade-off between having fewer communication rounds and introducing additional errors to the gradient estimates.
The idea of making local updates is not new and has been used in practice for a while (Mangasarian, 1995; Koneˇcn`y et al., 2016). However, until recently, there have been few successful efforts to analyze Local SGD theoretically and therefore it is not fully understood yet. Zhang et al. (2016) show that for quadratic functions, when the variance of the noise is higher far from the optimum, frequent averaging leads to faster convergence. The ﬁrst question we try to answer in this work is: how many communication rounds are needed for Local SGD to have the similar convergence rate of a synchronized parallel SGD while achieving performance that linearly improves in the number of workers?
Stich (2019) was among the ﬁrst who sought to answer this question for general strongly convex and smooth functions and showed that the communication rounds can be reduced up to a factor of
H = O((cid:112)T /N ), without affecting the asymptotic convergence rate (up to constant factors), where
T is the total number of iterations and N is number of parallel workers.
Focusing on smooth and possibly non-convex functions which satisfy a Polyak-Lojasiewicz condition,
Haddadpour et al. (2019) demonstrate that only R = Ω((T N )1/3) communication rounds are sufﬁcient to achieve asymptotic performance that scales proportionately to 1/N .
Recently, Khaled et al. (2020) and Stich, Karimireddy (2019) improve upon the previous works by showing linear speed-up for Local SGD with only Ω (N poly log (T )) communication rounds when data is identically distributed among workers and f is strongly convex. Their works also consider the cases when f is not necessarily strongly convex as well as the case of data being heterogeneously distributed among workers.
More recently, Yuan, Ma (2020) proposed a new accelerated method that requires only
Ω (cid:0)N 1/3 poly log (T )(cid:1) communication rounds for linear speed-up. While their results improve upon the earlier work, the communication requirements remain dependent on the total iterations T .
One-Shot Averaging (OSA), a method that takes an extreme approach to reducing communication, involves workers performing local updates until the very end when they average their parameters (Mcdonald et al., 2009; Zinkevich et al., 2010; Zhang et al., 2013c; Rosenblatt, Nadler, 2016;
Godichon-Baggioni, Saadane, 2020). This method can be seen as an extreme case of Local SGD with R = 1 and H = T local steps. Dieuleveut, Patel (2019); Godichon-Baggioni, Saadane (2020) provide an analysis of OSA and show that asymptotically, linear speed-up in the number of workers is achieved for a weighted average of iterates. However, both of these works make restrictive assumptions such as uniformly three-times continuously differentiability and bounded second and third derivatives or twice differentiability almost everywhere with bounded Hessian, respectively.
The second question we attempt to answer in this work, is whether these assumptions can be relaxed and OSA can achieve linear speed-up in more general scenarios.
In this work, we focus on smooth and strongly convex functions with a general noise model. Our contributions are three-fold: 2
Table 1: Comparison of Similar Works
Reference
Stich (2019)
Haddadpour et al. (2019)
Stich, Karimireddy (2019)
Woodworth et al. (2020)
Khaled et al. (2020)
Yuan, Ma (2020)
This Paper (cid:17) (cid:16)
O
O
˜O
µR2 (cid:17)b
µN T + κG2
µN T + κ2σ2
µN T R (cid:17)d
Convergence rate f (ˆxT ) − f ∗a (cid:16) ξ0
R3 + σ2 (cid:16) ξ0
R3 + κσ2 exp. decay + σ2
µN T exp. decay + σ2 (cid:16) κξ0
T 2 + κσ2 exp. decay + σ2 (cid:16) (1+cκ2 ln(T R−2))ξ0
κ−2T 2
µN T + κ2σ2
O
˜O
˜O
µT R
O (cid:16) (cid:16) (cid:17)
µN T + κσ2 log(9+T /κ)
µT R (cid:17)e
µN T + κ2σ2
µT R3
+ κσ2
Communication
Rounds R
√
Ω(
T N )
Ω((T N )1/3)
Ω(N ∗ poly(log T ))
Noise model uniform uniform with strong-growthc uniform with strong-growth
Ω(N ∗ poly(log T ))
Ω(N ∗ poly(log T )) uniform uniform
Ω(N 1/3 ∗ poly(log T )) uniform (cid:17)
µN T + κ2σ2
µT R (cid:17)f
Ω(N ) uniform with strong-growth a Depending on the work, ˆxT is either the last iterate or a weighted average of iterates up to T . b G is the uniform upper bound assumed for the l2 norm of gradients in the corresponding work. c This noise model is deﬁned in Assumption 5. d ˜O(.) ignores the poly-logarithmic and constant factors. e This is the bound for FedAC-II. FedAC-I requires R = Ω(N 1/2 ∗ poly(log T )). f c is the multiplicative factor in the noise model deﬁned in Assumption 5. 1. We propose a communication strategy which requires only R = Ω(N ) communication rounds to achieve performance that scales as 1/N in the number of workers. To the best of the authors’ knowledge, this is the only work to show that the number of communications can be taken to be completely independent of T . All previous papers required a number of communications which was at least N times a polynomial in log(T ), or had a stronger scaling with T . A comparison of our result to the available literature can be found in Table 1. 2. We show under mild additional assumptions, in particular twice differentiability on a neighborhood of the optimal point, OSA reaches linear speed-up asymptotically, i.e., with only one communication round we achieve the convergence rate of O(1/(N T )). 3. We simulate a simple example which is not twice differentiable at the optimum and observe that our bounds for part 1. are reasonably close to being tight. In particular, using 1 or
N or N 3/4 communications does not appear to result in a linear speed-up in the number of workers (while N communications does give a linear speed-up).
√
We notice that FedAC (Yuan, Ma, 2020) has a better dependence on the number of workers N , in expense of (poly logarithmic) dependence on T . With that in mind, we still believe our communication strategy is of independent interest, particularly in the framework of non-accelerated methods. We have performed extensive numerical experiments and comparisons between the two methods and highlighted the regimes where each method outperforms the other.
It is worth mentioning that although the the communication complexity by Woodworth et al. (2020) depends on T , their bound has a lower dependence on condition number κ. Hence, their results are stronger than ours only when κ = Ω(log T ).
The rest of this paper is organized as follows. In the following subsection we outline the related literature and ongoing works. In Section 2 we deﬁne the main problem and state our assumptions.
We present our theoretical ﬁndings in Section 3 followed by numerical experiments in Section 4 and conclusion remarks in Section 5. 1.1