Abstract
How related are the representations learned by neural language models, translation models, and language tagging tasks? We answer this question by adapting an encoder-decoder transfer learning method from computer vision to investigate the structure among 100 different feature spaces extracted from hidden represen-tations of various networks trained on language tasks. This method reveals a low-dimensional structure where language models and translation models smoothly interpolate between word embeddings, syntactic and semantic tasks, and future word embeddings. We call this low-dimensional structure a language represen-tation embedding because it encodes the relationships between representations needed to process language for a variety of NLP (natural language processing) tasks.
We ﬁnd that this representation embedding can predict how well each individual feature space maps to human brain responses to natural language stimuli recorded using fMRI. Additionally, we ﬁnd that the principal dimension of this structure can be used to create a metric which highlights the brain’s natural language processing hierarchy. This suggests that the embedding captures some part of the brain’s natural language representation structure. 1

Introduction
There are a multitude of common techniques for analytically representing the information contained in natural language. At the word level, language is often represented by word embeddings, which capture some aspects of word meaning using word co-occurrence statistics [8, 25]. Language representations that highlight speciﬁc linguistic properties, such as parts-of-speech [29] or sentence chunks [1], or that utilize well-known NLP models such as the intermediate layers of pretrained language models
[6, 10, 21, 27], are also frequently studied [12, 31]. In ﬁelds such as linguistics, natural language processing, and cognitive neuroscience, qualitative adjectives are often used to describe these language representations – e.g. “low-level” or “high-level” and “syntactic” or “semantic”. The use of these words belies an unstated hypothesis about the nature of the space of language representations – namely that this space is fundamentally low-dimensional, and therefore that the information from the representations in this space can be efﬁciently described using a few categorical descriptors. In this work, we attempt to directly map the low-dimensional space of language representations by generating “representation embeddings” using a method inspired by the work of Zamir et al. [44].
This method uses the transfer properties between representations to map their relationships.
The work described here has two main contributions. First, we used the representation embeddings to demonstrate the existence of low-dimensional structure within the space of language representations. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
We then used this structure to explore the relationships between – and gain deeper insight about – frequently used language representations. How do the intermediate layers of prominent language models relate to one another? How do the abstractions used by these layers evolve from low-level word embeddings of a context to a representation of the predicted next word for that context? Do different language models follow similar representation patterns? What are the differences between how unidirectional and bidirectional language models represent information? These are examples of the types of questions we can explore utilizing our representation embedding space. Second, we showed that this low-dimensional structure is reﬂected in brain responses predicted by these representation embeddings. In particular, we show that mapping the principal dimension of the representation embeddings onto the brain recovers, broadly, known language processing hierarchies.
We also show that the representation embeddings can be used to predict which representations map well to each area in the brain. 2