Abstract
The contrastive pre-training of a recognition model on a large dataset of unlabeled data often boosts the model’s performance on downstream tasks like image classiﬁ-cation. However, in domains such as medical imaging, collecting unlabeled data can be challenging and expensive. In this work, we consider the task of medical image segmentation and adapt contrastive learning with meta-label annotations to scenarios where no additional unlabeled data is available. Meta-labels, such as the location of a 2D slice in a 3D MRI scan, often come for free during the acquisition process. We use these meta-labels to pre-train the image encoder, as well as in a semi-supervised learning step that leverages a reduced set of annotated data. A self-paced learning strategy exploiting the weak annotations is proposed to further help the learning process and discriminate useful labels from noise. Results on ﬁve medical image segmentation datasets show that our approach: i) highly boosts the performance of a model trained on a few scans, ii) outperforms previous contrastive and semi-supervised approaches, and iii) reaches close to the performance of a model trained on the full data. 1

Introduction
Since the emergence of deep learning [26], there has been an active debate on the importance of pre-training neural networks. Precursor works [17] showed that pre-training a convolutional neural network with an unsupervised task (e.g., denoising autoencoders [49]) could lead to a better performance in the ﬁnal supervised task. As the amount of labeled training data increased, thanks to large datasets like ImageNet [13], it was however found that pre-training could actually hinder performance [38]. This makes sense in light of recent studies showing, for instance, that symmetries in large networks induce many equivalent local minima [16, 35, 47] in which a pre-trained model can get stuck. Recently, contrastive learning has renewed the interest in unsupervised pre-training
[37]. Several works [8, 10, 11, 20, 62] have found that pre-training a model with a contrastive loss can improve its performance on a subsequent supervised training task, often outperforming a network with supervised pre-training on ImageNet. While this has reopened the debate on the beneﬁt of pre-training, it offers little help for domains where data is scarce such as medical imaging. In medical imaging, not only are labels expensive since they come from highly-trained experts like radiologists, but images are also hard to obtain due to the need for costly equipment (e.g., MRI or CT scanner) and privacy regulations.
Over the last years, a breadth of semi-supervised learning approaches have been proposed for medical image segmentation, including methods based on attention [32], adversarial learning [60],
∗Corresponding author 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
2 temporal ensembling [12, 55], co-training [40, 63], data augmentation [6, 61] and transformation consistency [5]. The common principle of these approaches is to add an unsupervised regularization loss using unlabeled images, which is optimized jointly with a standard supervised loss on a limited set of labeled images. Despite reducing signiﬁcantly the amount of labeled data required for training, current semi-supervised learning methods still suffer from important drawbacks which impede their use in various applications. Thus, a large number of unlabeled images is often necessary to properly learn the regularization prior. As mentioned before, this may be impossible in medical imaging scenarios where data is hard to obtain. Moreover, these methods also need a sufﬁcient amount of labeled data, otherwise the learning may collapse [36].
In a recent work, Chaitanya et al. [7] showed that unsupervised pre-training can be useful to learn a segmentation task with very few samples, by leveraging the meta information of medical images (e.g., the position of a 2D image in the 3D volume). While achieving impressive accuracy with as few as two volumes, this work has signiﬁcant limitations. First, it relies on the strong assumption that the global or local representations of 2D images are similar if their locations within the volume or feature map are related. This assumption does not always hold in practice since volumes may not be well aligned, or due to the high variability of structures to segment. Second, it requires dividing the 2D images of a 3D volume in an arbitrary number of hard partitions that are contrasted, while the structure to segment typically varies gradually within the volume. Third, they do not exploit the full range of available meta data, for instance the patient ID or cycle phase of cardiac cine MRI, nor evaluate the beneﬁt of combining several types of meta information in pre-training. Last, their approach leverages meta data only in pre-training, however this information could further boost performance if used while learning the ﬁnal segmentation task, in a semi-supervised setting.
Our work addresses the limitations of current semi-supervised and self-supervised approaches for segmentation by proposing a novel self-paced contrastive learning method, which takes into account the noisiness of weak labels from meta data and exploits this data jointly with labeled images in a semi-supervised setting. The detailed contributions of this paper are as follows: – We propose, to our knowledge, the ﬁrst self-paced strategy for contrastive learning which dynami-cally adapts the importance of individual samples in the contrastive loss. This helps the model deal with noisy weak labels that arise, for instance, from misaligned images or splitting a 3D volume in arbitrary partitions. – We demonstrate the usefulness of a contrastive loss on meta-data for improving the performance of a ﬁnal task, not only in pre-training but also as an additional loss in semi-supervised training. – We show that combining multiple meta-labels in our self-paced contrastive learning framework can improve performance on the ﬁnal task, compared to using them independently. Our results also demonstrate the beneﬁt of combining contrastive learning with temporal ensembling to further boost performance.
We empirically validate our contributions on ﬁve well-known medical imaging datasets, and show the proposed approach to outperform the contrastive learning method of [7] as well as several state-of-the-art semi-supervised learning methods for segmentation [41, 43, 50, 58, 60]. In the results, our approach obtains a performance close to fully supervised training with very few training scans. 2