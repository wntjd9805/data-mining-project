Abstract
A recent line of research investigates how algorithms can be augmented with machine-learned predictions to overcome worst case lower bounds. This area has revealed interesting algorithmic insights into problems, with particular success in the design of competitive online algorithms. However, the question of improving algorithm running times with predictions has largely been unexplored.
We take a ﬁrst step in this direction by combining the idea of machine-learned predictions with the idea of “warm-starting" primal-dual algorithms. We consider one of the most important primitives in combinatorial optimization: weighted bipartite matching and its generalization to b-matching. We identify three key challenges when using learned dual variables in a primal-dual algorithm. First, predicted duals may be infeasible, so we give an algorithm that efﬁciently maps predicted infeasible duals to nearby feasible solutions. Second, once the duals are feasible, they may not be optimal, so we show that they can be used to quickly
ﬁnd an optimal solution. Finally, such predictions are useful only if they can be learned, so we show that the problem of learning duals for matching has low sample complexity. We validate our theoretical ﬁndings through experiments on both real and synthetic data. As a result we give a rigorous, practical, and empirically effective method to compute bipartite matchings. 1

Introduction
Classical algorithm analysis considers worst case performance of algorithms, capturing running times, approximation and competitive ratios, space complexities, and other notions of performance. Recently there has been a renewed interest in ﬁnding formal ways to go beyond worst case analysis [41], to better understand performance of algorithms observed in practice, and develop new methods tailored to typical inputs observed.
An emerging line of research dovetails this with progress in machine learning, and asks how algorithms can be augmented with machine-learned predictors to circumvent worst case lower bounds when the predictions are good, and approximately match them otherwise (see Mitzenmacher and Vassilvitskii
[36] for a survey). Naturally, a rich area of applications of this paradigm has been in online algorithms, where the additional information revealed by the predictions reduces the uncertainty about the future and can lead to better choices, and thus better competitive ratios. For instance, see the work by Lykouris and Vassilvitskii [33], Rohatgi [40], Jiang et al. [29] on caching; Antoniadis et al. [3], Dütting et al. [19] on the classic secretary problem; Purohit et al. [39], Lattanzi et al. [32] on scheduling; Purohit et al. [39], Anand et al. [2] on ski rental; and Bamas et al. [8] on set cover. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
However, the power of predictions is not limited to improving online algorithms. Indeed, the aim of the empirical paper that jump-started this area by Kraska et al. [31] was to improve running times for basic indexing problems. The main goal and contribution of this work is to show that at least in one important setting (weighted bipartite matching), we can give formal justiﬁcation for using machine learned predictions to improve running times: there are predictions which can provably be learned, and if these predictions are “good” then we have running times that outperform standard methods both in theory and empirically.
How can predictions help with running time? One intuitive approach, which has been used extensively in practice, is through the use of “warm-start” heuristics [46, 23, 22, 37], where instead of starting with a blank slate, the algorithm begins with some starting state (which we call a warm-start “solution” or “seed”) which hopefully allows for faster completion. While it is a common technique, there is a dearth of analysis understanding what constitutes a good warm-start, when such initializations are helpful, and how they can best be leveraged.
Thus we have a natural goal: put warm-start heuristics on ﬁrm theoretical footing by interpreting the warm-start solution as learned predictions. In this set up we are given a number of instances of the problem (the training set), and we can use them to compute a warm-start solution that will (hopefully) allow us to more quickly compute the optimal solution on future, test-time, instances. There are three challenges that we must address: (i) Feasibility. The learned prediction (warm-start solution) might not even be feasible for the speciﬁc instance we care about! For example, the learned solution may be matching an edge that does not exist in the graph at testing time. (ii) Optimization. If the warm-start solution is feasible and near-optimal then we want the algorithm to take advantage of it. In other words, we would like our running time to be a function of the quality of the learned solution. (iii) Learnability. It is easy to design predictions that are enormously helpful but which cannot actually be learned (e.g., the “prediction” is the optimal solution). We need to ensure that a typical solution learned from a few instances of the problem generalizes well to new examples, and thus offers potential speedups.
If we can overcome these three challenges, we will have an end-to-end framework for speeding up algorithms via learned predictions: use the solution to challenge (iii) to learn the predictions from historical data, use the solution to challenge (i) to quickly turn the prediction into something feasible for the particular problem instance while preserving near-optimality, and then use this as a warm-start seed in the solution to challenge (ii). 1.1 Our Contributions
We focus on one of the fundamental primitives of combinatorial optimization: computing bipartite matchings. For the bipartite minimum-weight perfect matching (MWPM) problem, as well as its extension to b-matching, we show that the above three challenges can be solved.
A key conceptual question is ﬁnding a speciﬁcation of the seed, and an algorithm to use it that satisﬁes the desiderata above. We have discussed warm-start “solutions”, so it is tempting to think that a good seed is a partial solution: a set of matched edges that can then be expanded to a optimal matching.
After all, this is the structure we maintain in most classical matching algorithms. Moreover, any such solution is feasible (one can simply set non-existing edges to have very high weight), eschewing the need for the feasibility step. At the same time, as has been observed previously in the context of online matchings [13, 45], this primal solution is brittle, and a minor modiﬁcation in the instance (e.g. an addition of a single edge) can completely change the set of optimal edges.
Instead, following the work of [13, 45], we look at the dual problem; that is, the dual to the natural linear program. We quantify the “quality” of a prediction ˆy by its (cid:96)1-distance from the true optimal dual y∗, i.e., by (cid:107)ˆy − y∗(cid:107)1. The smaller quantities correspond to better predictions. Since the dual is a packing problem we must contend with feasibility: we give a simple linear time algorithm that converts the prediction ˆy into a feasible dual while increasing the (cid:96)1 distance by a factor of at most 3.
Next, we run the Hungarian method starting with the resulting feasible dual. Here, we show that the running time is in proportional to the (cid:96)1 distance of the feasible dual to the optimal dual (Theorem 5).
Finally, we show via a pseudo-dimension argument that not many samples are needed before the 2
empirically optimal seed is a good approximation of the true optimum (Theorem 6), and that this empirical optimum can be computed efﬁciently. For the learning argument, we assume that matching instances are drawn from a ﬁxed but unknown distribution D.
Putting it all together gives us our main result.
Theorem 1 (Informal). There are three algorithms (feasibility, optimization, learning) with the following guarantees.
• Given a (possibly infeasible) dual ˆy from the learning algorithm, there exists an O(m + n) time algorithm that takes a problem instance c, and outputs a feasible dual ˆy(cid:48)(c) such that (cid:107)ˆy(cid:48)(c) − y∗(c)(cid:107)1 ≤ 3(cid:107)ˆy − y∗(c)(cid:107)1.
• The optimization algorithm takes as input feasible dual ˆy(cid:48)(c) and outputs a minimum weight perfect matching, and runs in time ˜O(m n · min{(cid:107)ˆy(cid:48)(c) − y∗(c)(cid:107)1, n}).
• After ˜O(C 2n3) samples from an unknown distribution D over problem instances, the learning algorithm produces duals ˆy so that Ec∼D [(cid:107)ˆy − y∗(c)(cid:107)1] is approximately minimum among all possible choices of ˆy, where C is the maximum edge cost and y∗(c) is an optimal dual for instance c.
√
√
Combining these gives a single algorithm that, with access to ˜O(C 2n3) problem instance samples from D, has expected running time on future instances from D of only ˜O(m n}), where
α = miny Ec∼D [(cid:107)y − y∗(c)(cid:107)1]. n min{α,
√
√
We emphasize that the Hungarian method with ˜O(mn) running time is the standard algorithm in practice. Although there are other theoretically faster exact algorithms for bipartite minimum-weight perfect matching [38, 21, 20, 18] that run in O(m n log(nC)), they are relatively com-plex (using various scaling techniques). Very recent breakthroughs give algorithms of run time
˜O((m + n1.5) log2(C)) for the minimum-weight perfect matching problem and several interesting extensions [43, 44]. However, the algorithms are highly complicated and their practical performance is yet to be demonstrated. In fact, we could not ﬁnd any implementation of the above algorithms, except for the Hungarian method, of which multiple implementations are readily available.
√
Note that our result shows that we can speed up the Hungarian method as long as the (cid:96)1-norm error of the learned dual, i.e., (cid:107)ˆy − y∗(c)(cid:107)1 is o( n). Further, as the projection step that converts the learned dual into a feasible dual takes only linear time, the overhead of our method is essentially negligible. Therefore, even if the prediction is of poor quality, our method has worst-case running time that is never worse than that of the Hungarian algorithm. Even our learning algorithm is simple, consisting of a straightforward empirical risk minimization algorithm (the analysis is more complex and involves bounding the “pseudo-dimension” of the loss functions).
√
We validate our theoretical results via experiments. For each dataset we ﬁrst feed a small number of samples (fewer than our theoretical bounds) to our learning algorithm. We then compare the running time of our algorithm to that of the classical Hungarian algorithm on new instances.
Details of these experiments can be found in Section 4. At a high level they show that our algorithm is signiﬁcantly faster in practice. Further, our experiment shows only very few samples are needed to achieve a notable speed-up. This conﬁrms the power of our approach, giving a theoretically rigorous yet also practical method for warm-start primal-dual algorithms. 1.2