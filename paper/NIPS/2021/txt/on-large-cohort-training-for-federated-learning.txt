Abstract
Federated learning methods typically learn a model by iteratively sampling updates from a population of clients. In this work, we explore how the number of clients sampled at each round (the cohort size) impacts the quality of the learned model and the training dynamics of federated learning algorithms. Our work poses three fundamental questions. First, what challenges arise when trying to scale federated learning to larger cohorts? Second, what parallels exist between cohort sizes in federated learning, and batch sizes in centralized learning? Last, how can we design federated learning methods that effectively utilize larger cohort sizes? We give partial answers to these questions based on extensive empirical evaluation. Our work highlights a number of challenges stemming from the use of larger cohorts.
While some of these (such as generalization issues and diminishing returns) are analogs of large-batch training challenges, others (including catastrophic training failures and fairness concerns) are unique to federated learning. 1

Introduction
Federated learning (FL) [52] considers learning a model from multiple clients without directly sharing training data, often under the orchestration of a central server. In this work we focus on cross-device FL, in which the aim is to learn across a large population of edge devices [27, Table 1].
A distinguishing characteristic of cross-device FL is partial participation of the client population:
Due to systems constraints such as network size, the server typically only communicates with a subset of the clients at a time1. For example, in the popular FedAvg algorithm [52], at each communication round the server broadcasts its current model to a subset of available clients (referred to as a cohort), who use the model to initialize local optimization and send their model updates back to the server.
Intuitively, larger cohort sizes have the potential to improve the convergence of FL algorithms. By sampling more clients per round, we can observe a more representative sample of the underlying population—possibly reducing the number of communication rounds needed to achieve a given accuracy. This intuition is reﬂected in many convergence analyses of FL methods [29, 31, 32, 62, 69], which generally show that asymptotic convergence rates improve as the cohort size increases.
Larger cohorts can also provide privacy beneﬁts. For example, when using the distributed differential privacy model [6, 11, 16, 65] in federated learning, noise is typically added to the updates sent from the clients to the server [54]. This helps preserve privacy but can also mar the utility of the learned model. By dividing the noise among more clients, larger cohorts may mitigate detrimental effects of noise. Moreover, since privacy tends to decrease as a function of the number of communication 1In contrast, cross-silo settings often have a small set of clients, most of which participate in each round [27]. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
rounds [1, 17], larger cohorts also have the potential to improve privacy in FL by reducing the number of rounds needed for convergence.
Motivated by the potential beneﬁts of large-cohort training, we systematically explore the impact of cohort size in realistic cross-device settings. Our results show that increasing the cohort size may not lead to signiﬁcant convergence improvements in practice, despite their theoretical beneﬁt [69].
Moreover, large-cohort training can introduce fundamental optimization and generalization issues.
Our results are reminiscent of work on large-batch training in centralized settings, where larger batches can stagnate convergence improvements [14, 19, 51, 70, 71], and even lead to generalization issues with deep neural networks [23, 30, 46–48, 50, 64]. While some of the challenges we identify with large-cohort training are parallel to issues that arise in large-batch centralized learning, others are unique to federated learning and have not been previously identiﬁed in the literature.
Contributions. In this work, we provide a novel examination of cohort sizes in federated learning.
We give a wide ranging empirical analysis spanning many popular federated algorithms and datasets (Section 2). Despite the many possible beneﬁts of large-cohort training, we ﬁnd that challenges exist in realizing these beneﬁts (Section 3). We show that these issues are caused in part by distinctive characteristics of federated training dynamics (Section 4). Using these insights, we provide partial solutions to the challenges we identify (Section 5), focusing on how to adapt techniques from large-batch training, and the limitations of such approaches. Our solutions are designed to serve as simple benchmarks for future work. We conclude by discussing limitations and open problems (Section 6).
Throughout, we attempt to uncover interesting theoretical questions, but remain ﬁrmly grounded in the practical realities of federated learning. 1.1