Abstract
This article proposes novel rules for false discovery rate control (FDRC) geared towards online anomaly detection in time series. Online FDRC rules allow to control the properties of a sequence of statistical tests. In the context of anomaly detection, the null hypothesis is that an observation is normal and the alterna-tive is that it is anomalous. FDRC rules allow users to target a lower bound on precision in unsupervised settings. The methods proposed in this article overcome short-comings of previous FDRC rules in the context of anomaly detection, in par-ticular ensuring that power remains high even when the alternative is exceedingly rare (typical in anomaly detection) and the test statistics are serially dependent (typical in time series). We show the soundness of these rules in both theory and experiments. 1

Introduction
Online anomaly detection is critical for many monitoring applications in health care, IT operations, manufacturing, or retail (e.g., [11, 4, 20]). In such settings, observations of one or several metrics of interest (naturally represented as time series) are sent sequentially to a detector. It is tasked with deciding whether a given observation is anomalous or not. Accordingly, anomaly detection in time-series data is a rich ﬁeld that has been surveyed in several articles [7, 6], Foorthuis [9] proposes a typology of anomalies, and Sadik and Gruenwald [21] discusses open research questions in the ﬁeld.
Arguably one of the most common approaches in addressing anomaly detection is via employing an unsupervised probabilistic anomaly scorer that assigns a probability to each point. This translates the problem of anomaly detection into one of online multiple hypotheses testing. Speciﬁcally, at each time step t, we observe a new data point zt and emit the null hypothesis Ht that zt is not anomalous. This hypothesis is tested with a p-value provided by the scorer and may be rejected (detection of an anomaly) if there is enough evidence against it.
As in any statistical testing problem, a decision threshold determines whether the null hypothesis is rejected or not. In the case of a single test, the most common convention is to report a discovery (a point is anomalous) if the associated p-value is smaller than some preselected threshold ↵. The effect is said to be statistically signiﬁcant at level ↵ and the probability to falsely declare the point anomalous is less than ↵. Importantly, in the case of multiple hypotheses tests, the threshold ↵ does not provide similar guarantees and the fraction of false positives may be arbitrarily close to 1. This particularly applies to anomaly detection because the proportion of alternative hypotheses tends to be very low. Hence, multiple hypotheses testing requires other mechanisms to set decision thresholds. In the case where all p-values are known in advance (ofﬂine setting), classical methods typically shrink the threshold ↵ conservatively [2, 3, 27].
In the setting of anomaly detection, a natural quantity to control is the false discovery rate (FDR) as introduced by [2], that is, the ratio of falsely labeled anomalies to total anomalies. Methods for
⇤Correspondence: quentin.rebjock@epfl.ch. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
sequential FDR control (FDRC) were pioneered by [10] who proposed the so-called ↵-investing strategy, which was later built upon and generalized [1, 15, 16, 18, 19, 30, 34, 16]. Online FDRC methods are appealing for anomaly detection problems as controlling the false discovery rate is equivalent to maximizing recall given a lower bound on precision. Consequently this allows to trade-off precision and recall even in the absence of labelled data, which is another commonality of anomaly detection. All online FDRC methods allocate some threshold at every time step, and reject the hypothesis based on it.
The main contribution of this article is the proposal of a novel method to overcome a common limitation of existing online FDRC methods that renders them unsuited for online anomaly detection tasks. When few rejections are made because the alternative hypothesis is extremely rare, as is the case in most anomaly detection problems, rejection thresholds of existing methods tend to zero.
This phenomenon is referred to as ↵-death in the literature [18] and prevents any future discoveries causing a loss of power. To circumvent this problem, we propose a method based on memory decay, revisiting [18], to ensure that rejection thresholds are lower-bounded by a non-zero value.
This guarantees that we have power even in the case where alternatives (anomalies) are rare. We demonstrate that this method allows us to control the decaying memory FDR [18], a version of the
FDR metric adapted to inﬁnite streams that progressively forgets past decisions. Our approach is fully general in the sense that it can enhance all of the most popular algorithms in the generalized
↵-investing class.
Our second contribution is the adaptation of the local dependency framework [34] to memory decay.
This allows to use our methods for practical applications where p-values are in general not indepen-dent. We evaluate experimentally the performances of the proposed algorithms and demonstrate that we can overcome the challenges occurring when alternative hypotheses are exceedingly rare.
This paper is structured as follows. Section 2 formalizes the problem of multiple hypotheses testing for anomaly detection and deﬁnes the false discovery rate. Section 3 reviews the main methods for online FDRC and illustrates their limitations. Section 4 details our contributions to prevent ↵-death.
Section 5 proposes an adjustment to make the algorithms robust to local dependency in the p-values.
Finally, Section 6 shows experimentally that our method preserves power while controlling the false discovery rate in anomaly detection settings. We conclude in Section 7. 2 Problem Formalization: Multiple hypotheses testing for anomaly detection
We formalize the problem statement of online anomaly detection via an unsupervised approach using probabilistic time series models. There is a rich and growing literature describing such probabilistic models (e.g., [5, 14, 24, 23, 26, 25, 8]) well suited for anomaly detection.
Deriving p-values. At each time step t, hypothesis Ht is tested based on a p-value that must be obtained from past observations only. The concept of anomaly is ambiguous and suffers from a subjective and imprecise deﬁnition [9]. We assume that anomalies are characterized by statistically rare events that deviate signiﬁcantly from expectations. For this reason, it is natural to address anomaly detection through probabilistic forecasting. A probabilistic forecast is an estimation of the probability distribution of zt given the past, that is Prob
, or equivalently its
} c.d.f. Ft. Under the null hypothesis (no anomaly), such a forecast should be a decent estimate of zt. From the forecast we can derive a p-value pt, which is the probability to observe an event in the tail of the distribution relative to zt under the assumption that Ht is null. Hence, a small value for pt is an indication that Ht must be rejected. We may derive two-sided p-values as pt = 2 min (Ft(zt), 1
Ft(zt)) using the predicted c.d.f. Ft for symmetric distributions. zt0 , t0 < t zt |
{
With this principle, we can infer a sequence of p-values 1t=1 iteratively as new observations are made available. Instead of two-sided p-values, other scenarios are conceivable as for certain usages, it may make sense to deﬁne anomalies as values either extremely high or low compared to the median. For example, in a scenario where we monitor the resources usage of a compute service, only large values should result in an alert. Accordingly, one-sided p-values can be derived to account for only one end of the distribution. More generally, p-values need only to be stochastically larger than the uniform distribution under the null hypothesis, that is: pt}
{
  if Ht is truly null then Prob pt 
{ u
} u for all u
[0, 1] . 2 (1) 2
With this deﬁnition of anomalies, we can decompose the problem of anomaly detection into two distinct sub-problems: (i) obtaining p-values in line with the application via a forecasting model and (ii) using a criterion on the p-values to accept/reject hypotheses. We will assume time series models to be given and focus on (ii), that is, the choice of decision thresholds.
False discovery rate control. As we reject hypotheses we want to make sure that we do not falsely report too many anomalies. If there was a single hypothesis we could reject it if the associated p-value is smaller than some threshold ↵: this ensures that the probability to report an anomaly when it is not is less than ↵. This is an immediate consequence of the deﬁnition of the p-value in
Equation (1). However, this procedure does not provide similar guarantees for a set of hypotheses in general and for sequentially dependent p-values as in the case of online anomaly detection in time series in particular. For this reason, in multiple hypotheses settings rejections are based on procedures controlling metrics pertaining to a set of tests.
One of these metrics is the family-wise error rate (FWER) [13], which is the probability to make at least one false discovery. The probability to reject a truly null hypothesis approaches 1 when the number of tests grows. This makes the FWER metric too conservative, leading to very few discoveries for long (possibly inﬁnite) streams of data.
The false discovery rate (FDR) is the more natural quantity to control in our setting. Procedures controlling the FDR aim at maximizing the number of true discoveries subject to an upper bound on the expected proportion of false discoveries. This is equivalent to maximizing recall subject to a user-deﬁned lower bound on precision. For a given set of hypotheses the FDR is formally deﬁned as the expected ratio of false positives to total discoveries: 0
FDR , E [FDP] , E
|H
|R| _ are the sets of truly null hypotheses and rejections respectively, and FDP is the
\R| 1

 
, 0 and where false discovery proportion of the samples.
R
H
This article is concerned with the problem of online FDR control where observations arrive se-quentially and we want to make a decision immediately on whether to classify the observation as anomalous or not. Alternative settings have been investigated in the literature. Rather than making a decision at every time step, Zrnic et al. [33] considers testing sequences of hypotheses by batches of variable length. This takes advantage of a partial ordering of the p-values at the cost of a delay in the decision, which is not desirable in online anomaly detection. Another option is to aggregate a series of p-values [17, 12] and perform FDR control consequently, either sequentially or based on multivariate [22] forecasts. Wang [31] propose to perform online anomaly detection by coupling a STL decomposition with a FDR method based on the distribution of z statistics or the residuals building on a method proposed by Sun and Cai [29]. 3