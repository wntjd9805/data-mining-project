Abstract
Many differentially private algorithms for answering database queries involve a step that reconstructs a discrete data distribution from noisy measurements. This provides consistent query answers and reduces error, but often requires space that grows exponentially with dimension. PRIVATE-PGM is a recent approach that uses graphical models to represent the data distribution, with complexity proportional to that of exact marginal inference in a graphical model with structure determined by the co-occurrence of variables in the noisy measurements. PRIVATE-PGM is highly scalable for sparse measurements, but may fail to run in high dimensions with dense measurements. We overcome the main scalability limitation of PRIVATE-PGM through a principled approach that relaxes consistency constraints in the estimation objective. Our new approach works with many existing private query answering algorithms and improves scalability or accuracy with no privacy cost. 1

Introduction
A central problem in the design of differentially private algorithms is answering sets of counting queries from a database. Many proposed algorithms follow the select-measure-reconstruct paradigm: they select a set of measurement queries, they privately measure them (using Gaussian or Laplace noise addition), and then they reconstruct the data or query answers from the noisy measurements.
When done in a principled manner, the reconstruct phase serves a number of critical functions: it combines the noisy evidence provided by the measurement queries, it allows new unmeasured queries to be answered (with no additional privacy cost), and it resolves inconsistencies in the noisy measurements to produce consistent estimates, which often have lower error. In this paper, we propose a novel, scalable, and general-purpose approach to the reconstruct step. With a principled approach to this problem, future research can focus on the challenging open problem of query selection.
Most existing general-purpose methods for reconstruction cannot scale to high-dimensional data, as they operate over a vectorized representation of the data, whose size is exponential in the dimension-ality [1–6]. Some special purpose methods exist that have better scalability, but are only applicable within a particular mechanism or in certain special cases [7–11, 5, 12–15]. A recently-proposed method, PRIVATE-PGM [16], offers the scalability of these special purpose methods and retains much of the generality of the general-purpose methods. PRIVATE-PGM can be used for the recon-struction phase whenever the measurements only depend on the data through its low-dimensional marginals. PRIVATE-PGM avoids the data vector representation in favor of a more compact graphical model representation, and was shown to dramatically improve the scalability of a number of popular mechanisms while also improving accuracy [16]. PRIVATE-PGM was used in the winning entry of the 2018 NIST differential privacy synthetic data contest [17, 18], as well as in both the ﬁrst and second-place entry of the follow-up 2020 NIST differential privacy temporal map contest [19, 20]. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
While PRIVATE-PGM is far more scalable than operating over a vector representation of the data, it is still limited. In particular, its required memory and runtime depend on the structure of the underlying graphical model, which in turn is determined by which marginals the mechanism depends on. When the mechanism depends on a modest number of carefully chosen marginals, PRIVATE-PGM is extremely efﬁcient. But, as the number of required marginals increases, the underlying graphical model becomes intractably large, and PRIVATE-PGM eventually fails to run. This is due to the inherent hardness of exact marginal inference in a graphical model.
In this paper, we overcome the scalability limitations of PRIVATE-PGM by proposing a natural relaxation of the estimation objective that enforces speciﬁed local consistency constraints among marginals, instead of global ones, and can be solved efﬁciently. Our technical contributions may be of broader interest. We develop an efﬁcient algorithm to solve a generic convex optimization problem over the local polytope of a graphical model, which uses a body of prior work on generalized belief propagation [21–31] and can scale to problems with millions of optimization variables. We also propose a variational approach to predict “out-of-model” marginals given estimated pseudo-marginals, which gives a completely variational formulation for both estimation and inference: the results are invariant to optimization details, including the approximate inference methods used as subroutines.
Our new approach, APPROX-PRIVATE-PGM (APPGM), offers many of the same beneﬁts as
PRIVATE-PGM, but can be deployed in far more settings, allowing effective reconstruction to be performed without imposing strict constraints on the selected measurements. We show that
APPGM permits efﬁcient reconstruction for HDMM [32], while also improving its accuracy, allows
MWEM [5] to scale to far more measurements, and improves the accuracy of FEM [33]. 2