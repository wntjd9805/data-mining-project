Abstract
This paper introduces deep synoptic Monte Carlo planning (DSMCP) for large imperfect information games. The algorithm constructs a belief state with an unweighted particle ﬁlter and plans via playouts that start at samples drawn from the belief state. The algorithm accounts for uncertainty by performing inference on
“synopses,” a novel stochastic abstraction of information states. DSMCP is the basis of the program Penumbra, which won the ofﬁcial 2020 reconnaissance blind chess competition versus 33 other programs. This paper also evaluates algorithm variants that incorporate caution, paranoia, and a novel bandit algorithm. Furthermore, it audits the synopsis features used in Penumbra with per-bit saliency statistics. 1

Introduction
Choosing a Nash equilibrium strategy is rational when the opponent is able to identify and exploit suboptimal behavior [Bowling and Veloso, 2001]. However, not all opponents are so responsive, and computing a Nash equilibrium is intractable for many games. This paper presents deep synoptic
Monte Carlo planning (DSMCP), an algorithm for large imperfect information games that seeks a best-response strategy rather than a Nash equilibrium strategy.
When opponents use ﬁxed policies, an imperfect information game may be viewed as a partially observable Markov decision process (POMDP) with the opponents as part of the environment.
DSMCP treats playing against speciﬁc opponents as related ofﬂine reinforcement learning (RL) problems and exploits predictability. Importantly, the structure of having opponents with imperfect information is preserved in order to account for their uncertainty.
DSMCP uses sampling to break the “curse of dimensionality” [Pineau et al., 2006] in three ways: sampling possible histories with a particle ﬁlter, sampling possible futures with upper conﬁdence bound tree search (UCT) [Kocsis and Szepesvári, 2006], and sampling possible world states within each information state uniformly. It represents information states with a generally-applicable stochas-tic abstraction technique that produces a “synopsis” from sampled world states. This paper assesses
DSMCP on reconnaissance blind chess (RBC), a large imperfect information chess variant. 2