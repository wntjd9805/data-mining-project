Abstract
Active learning sequentially selects the best instance for labeling by optimizing an acquisition function to enhance data/label efﬁciency. The selection can be either from a discrete instance set (pool-based scenario) or a continuous instance space (query synthesis scenario). In this work, we study both active learning scenarios for Gaussian Process Classiﬁcation (GPC). The existing active learning strategies that maximize the Estimated Error Reduction (EER) aim at reducing the classiﬁcation error after training with the new acquired instance in a one-step-look-ahead manner. The computation of EER-based acquisition functions is typically prohibitive as it requires retraining the GPC with every new query.
Moreover, as the EER is not smooth, it can not be combined with gradient-based optimization techniques to efﬁciently explore the continuous instance space for query synthesis. To overcome these critical limitations, we develop computationally efﬁcient algorithms for EER-based active learning with GPC. We derive the joint predictive distribution of label pairs as a one-dimensional integral, as a result of which the computation of the acquisition function avoids retraining the GPC for each query, remarkably reducing the computational overhead. We also derive the gradient chain rule to efﬁciently calculate the gradient of the acquisition function, which leads to the ﬁrst query synthesis active learning algorithm implementing
EER-based strategies. Our experiments clearly demonstrate the computational efﬁciency of the proposed algorithms. We also benchmark our algorithms on both synthetic and real-world datasets, which show superior performance in terms of sampling efﬁciency compared to the existing state-of-the-art algorithms. 1

Introduction
Compared to traditional passive learning with randomly sampled training instances, active learning aims at “optimally” querying instances for labeling to achieve label efﬁciency when training machine learning models, especially when labeling is difﬁcult or costly. There are two fundamental scenarios of active learning discussed in the literature: query synthesis and pool-based sampling [14]. In query synthesis, the leaner can request labels for any instance generated from a continuous feature space while pool-based sampling selects the instance from a ﬁnite set. Query synthesis is more challenging due to the inﬁnite search space and inherent higher label uncertainty. Recent research on query synthesis with deep generative models has shown promising potential [18, 11]. However, in 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
Figure 1: Phase diagram identiﬁcation by active learning with Gaussian Process Classiﬁcation (GPC). many science and engineering applications, acquiring the label for even one instance is prohibitively resource-demanding and therefore active learning with deep models may not be practical.
For example, one of critical materials science research questions is to identify phase transition
Identifying phase diagrams, where the phase transition response surface can be complex [8]. transitions can be formulated as ﬁnding the optimal classiﬁcation boundaries between different phases in the enormous materials design space. However, precisely knowing the phase of each design with the corresponding input features requires costly and time-consuming materials synthesis and proﬁling experiments or running complex simulation models. Furthermore, there may exist signiﬁcant uncertainty in acquired phase labels due to technical limitations. Hence, active learning for optimal Bayesian classiﬁers is a natural solution to help identify the phase diagram with as few as possible synthesized or simulated materials under such uncertainty and complexity. Gaussian
Process Classiﬁcation (GPC) as a popular and powerful Bayesian classiﬁer with the ﬂexibility of adopting different kernels [15], is suitable for solving this problem with appropriate active learning strategies. Fig.1 shows an example of phase identiﬁcation in a two-dimensional design space by active learning with GPC (Details in the Appendix). In the ﬁgure, the black solid line indicates the phase transition response surface, the crosses and dots indicate the queries of different phases, and the colorbar indicates the predictive distribution of GPC. From the ﬁgure we can see, the predictive distribution identiﬁes the phase transition boundary with a few samples guided by active learning using GPC surrogate models, which has signiﬁcant cost and time savings compared to the traditional trial-and-error phase diagram identiﬁcation paradigm in the current materials science practice.
Many active learning strategies have been proposed for GPC. For example, Bayesian Active Learning by Disagreement (BALD) selects the instance with the maximum mutual information between the observation and the derived uncertain model [5]. There also have been strategies targeting at reducing classiﬁcation error directly or indirectly. Estimated Error Reduction (EER) strategies optimize for the error reduction after training with the new queries [13, 10, 6]. We note here that EER-based active learning has been studied for both Gaussian Process Regression (GPR) and GPC [13, 6]. For GPR, the regression error can be represented by the posterior predictive variance with the analytical expression and the acquisition function is easy to calculate for efﬁcient active learning. In contrast, for GPC, there is no analytical expression for the posterior predictive. The model updates need approximate inference, such as Expectation Propagation (EP), an algorithm iteratively approximating the GPC posterior [7]. Moreover, the classiﬁcation error computation requires the new query labels; so the calculation of the corresponding EER-based acquisition function requires incrementally retraining the model for each possible query label to calculate the expected future error as the utility to guide active learning. The complexity of training GPC with EP approximation is O(n3), where n is the number of observed data. This has been the main hurdle to develop active learning for GPC models.
To reduce the calculation cost of EER, the paper [6] proposed to use a non-iterative but less accurate method Assumed Density Filtering (ADF) approximating the new posterior when calculating the acquisition functions. The paper [3] proposed a novel approximated error reduction (AER) criterion, in which the error reduction of a candidate is estimated based on the impact over its nearby instances.
The approximated estimation avoids re-inferring the labels of massive instances. These methods are relatively efﬁcient in computation. But besides EP approximation, they need additional approxima-tions in calculating acquisition functions so the acquisition functions are not precisely calculated, which may degrade the desired data efﬁciency. 2
In this paper, within the EER-based active learning framework for GPC, we develop computationally efﬁcient algorithms to compute EER to guide both query synthesis and pool-based active learning. In particular, we consider EER as the reduction of the Mean Objective Cost of Uncertainty (MOCU) [16] since the learning objective of GPC, in particular for identifying phase diagram, is to reduce the classiﬁcation error. By deriving the joint distribution of queries as a one-dimensional integral, we avoid retraining the GPC for each query when calculating the EER/MOCU-based acquisition function.
We further leverage a smooth approximation of MOCU, Soft MOCU (SMOCU) [17], to enable efﬁcient gradient computation of the SMOCU reduction by deriving the corresponding chain rule for efﬁcient query synthesis with GPC. To the best of our knowledge, this is the ﬁrst algorithm for query synthesis active learning based on EER strategies. We show in our experiments that our algorithms accelerate the computation of the acquisition functions. Compared with other existing algorithms, we demonstrate consistent data efﬁciency of our algorithms with both synthetic and real-world datasets. 2 Problem Setting and