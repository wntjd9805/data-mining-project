Abstract
In this paper, we model the subspace of convolutional ﬁlters with a neural ordinary differential equation (ODE) to enable gradual changes in generated images. Decom-posing convolutional ﬁlters over a set of ﬁlter atoms allows efﬁciently modeling and sampling from a subspace of high-dimensional ﬁlters. By further modeling
ﬁlters atoms with a neural ODE, we show both empirically and theoretically that such introduced continuity can be propagated to the generated images, and thus achieves gradually evolved image generation. We support the proposed framework of image generation with continuous ﬁlter atoms using various experiments, includ-ing image-to-image translation and image generation conditioned on continuous labels. Without auxiliary network components and heavy supervision, the proposed continuous ﬁlter atoms allow us to easily manipulate the gradual change of gen-erated images by controlling integration intervals of neural ordinary differential equation. This research sheds the light on using the subspace of network parameters to navigate the diverse appearance of image generation. 1

Introduction
Conditional image generation has been widely studied in recent years due to its numerous applications including image segmentation [12, 18], style transfer [57, 20], image inpainting [33, 52], image super-resolution [54, 44], image registration [1], and image synthesis [31]. Despite extensive research and applications in these ﬁelds, limited progress has been made on conditional image generation using continuous or closely spaced labels due to the difﬁculties pointed out in [8], e.g., the absence of real images for some labels. It is shown in [8] that the standard training with empirical risk minimization does not apply well to continuous labels. Moreover, it remains challenging to encourage the generation diversity, especially without heavy supervision, while maintaining output ﬁdelity.
Previously, generation diversity is mainly encouraged using explicit regularization terms to convey diversity with additional latent codes [26, 34]. However, explicit regularizations inevitably introduce additional hyperparameters, and sub-optimal hyperparameters can often cause either poor diversity or noticeable sacriﬁces in terms of generation quality and the correspondence to input conditions.
On the other hand, achieving generation diversity by modeling the deep network parameter space has attracted limited attention [47]. This direction is mainly challenged by the prohibitive cost on both modeling of and sampling from the very high-dimensional space of convolutional ﬁlters in modern image generative networks. Motivated by the observation that a convolutional ﬁlter can be well approximated by a linear combination of low-dimensional ﬁlter atoms, BasisGAN [47] shows in image generation that, the high-dimensional ﬁlter space in each layer can be well approximated by a low-dimensional ﬁlter subspace, which signiﬁcantly reduces the cost of both parameter modeling and sampling. In this way, each sampling of the modeled parameter subspace results in one deterministic transformation from the input condition to the desired target domain, and the diverse outputs are achieved by sampling multiple times. More importantly, it is empirically shown in [47] that without
⇤Equal contribution. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
any explicit regularizations, such parameter subspace modeling can work as a plug-and-play module to convert a deterministic conditional image generation network to produce diverse images with appealing stochasticity, without any auxiliary network components or regularization terms.
However, we observe that the ﬁlter subspace modeling in [47] suffers from several major limitations:
First, this method is sensitive to network conﬁgurations of the basis generator, as minor changes to the parameters can highly likely to trigger mode collapse in the parameter distribution, which results in a point estimation to the subspace of parameter and removes diversity in the output images.
Furthermore, BasisGAN is incapable of modeling a continuous space, so that gradual changes to the generated parameters cannot be obtained by simply interpolating the latent codes.
In this paper, we adopt a subspace view to convolutional ﬁlters by performing atom-coefﬁcients decomposition, as in [35, 47, 46, 48]. Then we further model the ﬁlter subspace using a neural ordinary differential equation (ODE), so that we are able to sample from this continuous subspace a series of ﬁlter atoms at arbitrarily ﬁne resolution. The low-dimensional ﬁlter subspace allows extremely efﬁcient learning and modeling using ODE. We show both empirically and theoretically that, continuous transition in the ﬁlter subspace can be propagated naturally to generated images, and thus produce visually appealing images with gradually varying appearance. More importantly, we show that the continuity introduced to the ﬁlter subspace and the induced generation smoothness allow continuous manipulation of generated appearance with only discrete samples as supervision, which is a task that is used to be considered intractable by training with standard empirical risk minimization [8]. These appealing properties of the proposed method enable various signiﬁcant applications through only standard training, without requiring any auxiliary network components, additional regularization terms, or heavy supervision.
We perform various experiments on conditional image generation, with conditions being in the form of images, labels, or both. We list here several example applications that are enabled by the proposed image generation using continuous ﬁlter atoms from an ODE atom generator:
• Continuous image synthesis that covers a wide range of gradually varying appearance with high ﬁdelity and accurate correspondence to the input condition.
• Sequential image synthesis with explicitly speciﬁed starting and ending points to allow
ﬂexible appearance manipulation without heavy supervision.
• Interpolation of generated image appearance at arbitrarily ﬁne resolution.
• An effective approach to generating images conditioned on continuous labels. 2