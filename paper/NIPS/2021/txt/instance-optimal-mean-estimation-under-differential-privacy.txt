Abstract
Mean estimation under differential privacy is a fundamental problem, but worst-case optimal mechanisms do not offer meaningful utility guarantees in practice when the global sensitivity is very large. Instead, various heuristics have been proposed to reduce the error on real-world data that do not resemble the worst-case instance. This paper takes a principled approach, yielding a mechanism that is instance-optimal in a strong sense. In addition to its theoretical optimality, the mechanism is also simple and practical, and adapts to a variety of data characteris-tics without the need of parameter tuning. It easily extends to the local and shufﬂe model as well. 1

Introduction
Mean estimation is one of the most fundamental problems in statistics, optimization, and machine learning. However, privacy concerns forbid us from using the exact mean in these applications, and the problem of how to achieve the smallest error under a given privacy model has received considerable attention in the literature. Differential privacy (DP) is a rigorous mathematical deﬁnition for protecting individual privacy and has emerged as the golden standard in privacy-preserving data analysis nowadays, which has been deployed by Apple [16], Google [22], and Microsoft [17].
Given a data set D := {xi}i∈[n] ⊂ U d, where U = [u], i.e., each coordinate of the input vector is an integer (real-valued coordinates can be handled by quantization; see remark 1), our goal is to obtain a differentially private estimation M (D) for the mean f (D) = 1 i=1 xi with small (cid:96)2
√ n error (cid:107)M (D) − f (D)(cid:107)2. Because f (·) has global (cid:96)2 sensitivity GSf = du/n, the standard DP mechanism just adds Gaussian noise scaled to GSf to each coordinate of f (D), which results in an (cid:96)2 error proportional to du/n. This simple mechanism is worst-case optimal [28], but it is certainly undesirable in practice, as people often conservatively use a large u (e.g., u = 232) but the actual dataset D may have much smaller coordinates. Instead, the clipped-mean estimator [1] (see Section 3.1 for details) has been widely used as an effective heuristic, but two questions remain unresolved: (1) how to choose the clipping threshold C; and (2) if it can yield any optimality guarantees. We answer these questions in a fairly strong sense in this paper. (cid:80)n 1.1
Instance Optimality
As worst-case optimality is theoretically trivial and practically meaningless for the mean estimation problem when the global sensitivity is too large, one may aim at instance optimality. More precisely, let M be the class of DP mechanisms and let
Rins(D) := inf
M (cid:48)∈M inf{ξ | Pr[(cid:107)M (cid:48)(D) − f (D)(cid:107)2 ≤ ξ] ≥ 2/3} 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
be the smallest error any M (cid:48) can achieve (with constant probability) on D, then the standard deﬁnition of instance optimality requires us to design an M such that
Pr[(cid:107)M (D) − f (D)(cid:107)2 ≤ c · Rins(D)] ≥ 2/3 (1) for every D, where c is called the optimality ratio. Unfortunately, for any D, one can design a trivial
M (cid:48)(·) ≡ f (D) that has 0 error on D (but fails miserably on other instances), so Rins(·) ≡ 0, which rules out instance-optimal DP mechanisms by a standard argument [21].
Since Rins(·) is unachievable, relaxed versions can be considered. The above trivial M (cid:48) exists because it is only required to work well on one instance D. Imposing higher requirements on M (cid:48) would yield relaxed notions of instance optimality. One natural requirement is that M (cid:48) should work well not just on D, but also on its neighbors, i.e., we raise the target error from Rins(D) to
Rnbr(D) := inf
M (cid:48)∈M sup
D(cid:48):dham(D,D(cid:48))≤1 inf{ξ | Pr[(cid:107)M (cid:48)(D(cid:48)) − f (D(cid:48))(cid:107)2 ≤ ξ] ≥ 2/3}.
Vahdan [35] observes that Rnbr(D) is exactly LSf (D), the local sensitivity of f at D, up to constant factors. However, LSf (·) may not be an appropriate target to shoot at, depending on what f is. For the MEDIAN problem, LSf (D) = 0 for certain D’s and no DP mechanisms can achieve this error du/n) for all D, so this relaxation turns
[33], while for mean estimation, LSf (D) = Θ(GSf ) = Θ( instance optimality into worst-case optimality.
The reason why the above relaxation is “too much” for the mean estimation problem is that D(cid:48) may change one vector of D arbitrarily, e.g., from (0, . . . , 0) to (u, . . . , u). We restrict this. More precisely, letting supp(D) denote the set of distinct vectors in D, we consider the target error
√
Rin-nbr(D) := inf
M (cid:48)∈M sup
D(cid:48):dham(D,D(cid:48))≤1,supp(D(cid:48))⊆supp(D) inf{ξ | Pr[(cid:107)M (cid:48)(D(cid:48))−f (D(cid:48))(cid:107)2 ≤ ξ] ≥ 2/3}, namely, we require M (cid:48) to work well only on D and its in-neighbors, in which a vector can only be changed to another one already existing in D. Correspondingly, an instance-optimal M (w.r.t. the in-neighborhood) is one such that (1) holds where Rins is replaced by Rin-nbr.
We make a few notes on this notion of instance optimality: (1) This optimality is only about the utility of the mechanism, not its privacy. We still require the mechanism to satisfy the DP requirement between any D, D(cid:48) such that dham(D, D(cid:48)) = 1, not necessarily one and its in-neighbors. (2) In general, a smaller neighborhood leads to a stronger notion of instance optimality. Thus, the optimality using in-neighbors is stronger than that using all neighbors, which is in turn stronger than worst-case optimality (i.e., D(cid:48) can be any instance), while the latter two are actually the same for the mean estimation problem. (3) For an instance-optimal M (by our notion), there still exist D, M (cid:48) such that M (cid:48) does better on D than M , but it is not possible for M (cid:48) to achieve a smaller error than the error of M on D over all in-neighbor of D. This is more meaningful than ranging over all neighbors of D, some of which (e.g., one with (u, . . . , u) as a datum) are unlikely to be the actual instances encountered in practice. 1.2 Our Results (cid:80)n
To design an M (D) for the mean function f (D) = 1 i=1 xi that achieves an error w.r.t. Rin-nbr(D) n for all D, we need an upper bound and a lower bound. For the lower bound, we show that Rin-nbr(D) =
Ω(w(D)/n), where w(D) := max1≤i<j≤n (cid:107)xi − xj(cid:107)2 is the diameter of D. Thus, from the upper bound side, it sufﬁces to show that the mechanism’s error is bounded by c · w(D)/n. This is achieved in two steps. First, we use the clipped-mean estimator, but ﬁnd the clipping threshold C that optimizes its bias-variance trade-off, which is a certain quantile of the norms of the vectors in D. However, we cannot use the optimal C directly, as it would violate DP. Thus, we use a simple binary search based algorithm that can ﬁnd any speciﬁc quantile privately with an optimal rank error. This results in a DP mechanism with error ˜O((cid:112)d/ρ)·r(D)/n, where r(D) := maxi (cid:107)xi(cid:107)2 and ρ is the privacy parameter (formal deﬁnition given in Section 2). To reduce the error from r(D) to w(D), in the second step, we rotate and shift D into a ˜D such that r( ˜D) = O(w(D)) w.h.p., and apply the clipped-mean estimator (with our privatized optimal clipping threshold) on ˜D, leading to an error of ˜O((cid:112)d/ρ) · w(D)/n for n = ˜Ω((cid:112)d/ρ). We also show that the optimality ratio c = ˜O((cid:112)d/ρ) is optimal, i.e., any mechanism
M (D) having error c · w(D)/n for all D must have c = ˜Ω((cid:112)d/ρ) for ρ < ˜O((cid:112)d/n). 2
α
√
α2 + d
Our mechanism has the following applications: (1) It can be applied directly to statistical mean estimation, where the vectors in D are i.i.d. samples from a certain distribution and one would like to estimate the mean of the distribution (in contrast, the version deﬁned above is referred to as empirical mean estimation). For concreteness, we show how this is done for the multivariate
Gaussian distributions N (µ, Σ). For the case Σ = I, our algorithm achieves an (cid:96)2 error of α using n = ˜O( d
ρ ) samples for α ≤ O(1), matching the optimal bound in the statistical setting [8].
For a non-identity, unknown Σ, the error is proportional to (cid:107)Σ1/2(cid:107)2 as in [8]. Our mechanism requires only crude a priori bounds on µ and Σ (i.e., the error depends on these bounds logarithmically), while [8] needs a constant-factor approximation of Σ, which can be obtained using n = ˜Ω(d3/2/
ρ) d-factor higher than the sample complexity of mean estimation. samples [26]. Note that this can be a
Fundamentally, estimating Σ is harder than estimating µ, and we bypass the former so as to retain the same sample complexity of the latter. In practice, estimating Σ ﬁrst would consume the privacy budget from the mean estimation problem itself. On the other hand, the beneﬁt of estimating Σ ﬁrst is that one can obtain an error guarantee under the Mahalanobis distance [26], which cannot be achieved by our method. (2) By simply changing the primitive operations, our mechanism easily extends to the local and shufﬂe model of differential privacy. In doing so, we also extend the one-dimensional summation/mean estimation protocol in the shufﬂe model [5] to high dimensions.
√
√
In addition to the theoretical optimality, our mechanism is also simple and practical. Most importantly, there is no (internal) parameter to tune. Yet, our experimental results demonstrate that our mechanism outperforms the state-of-the-art algorithm [8] with the best parameters tuned for each speciﬁc setting. 1.3