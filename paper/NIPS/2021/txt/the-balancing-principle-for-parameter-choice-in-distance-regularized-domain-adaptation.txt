Abstract
We address the unsolved algorithm design problem of choosing a justified regular-ization parameter in unsupervised domain adaptation. This problem is intriguing as no labels are available in the target domain. Our approach starts with the obser-vation that the widely-used method of minimizing the source error, penalized by a distance measure between source and target feature representations, shares charac-teristics with regularized ill-posed inverse problems. Regularization parameters in inverse problems are optimally chosen by the fundamental principle of balancing approximation and sampling errors. We use this principle to balance learning errors and domain distance in a target error bound. As a result, we obtain a theoretically justified rule for the choice of the regularization parameter. In contrast to the state of the art, our approach allows source and target distributions with disjoint supports.
An empirical comparative study on benchmark datasets underpins the performance of our approach. 1

Introduction
Domain adaptation uses the knowledge in a source domain to improve the performance of an algorithm on a related target domain [1]. In particular, domain adaptation tackles domain shifts in machine learning applications: Medical diagnostic systems should be adapted to new physical human variations; Industrial quality inspection systems should be accurate for new products; Self-driving cars should be able to adapt to new geographical environments and weather conditions. In this work, we focus on unsupervised domain adaptation where labels are only available in the source domain.
There are mainly two types of approaches for unsupervised domain adaptation: importance weight-ing [2, 3, 4, 5, 6, 7] and feature representation learning [8, 9, 10, 11, 12, 13]. In this work, we focus on feature representation learning which goes beyond classical importance weighting by allowing a target distribution with support outside of the source distribution. The core idea behind feature repre-sentation learning approaches is to map the data into a new feature space where the source and target 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
Figure 1: Unsupervised domain adaptation on Transformed Moons. Left: Target data (black dots) partially outside of the support of the source data (blue +, orange ×). The common assumption of bounded density ratio is violated in large regions. In contrast, all our assumptions are satisfied.
Our method identifies the best parameter of a domain adaptation algorithm [16] (green solid) which improves training on source data only (red dashed). Right: Regularization parameter (x-axis) which penalizes a distance [25] (purple) leading to models with different source error (blue) and target error (black). Importance weighted validation (IWV) shows the smallest error (red) for models without domain adaptation (αIWV = 0). In contrast, our approach identifies the optimal parameter (αBP = 1). data representations appear similar, and where enough information is preserved for prediction [14].
The similarity is often realized by regularization using distance measures between source and target representations [15, 16, 17, 18, 19, 20, 21]. However, the performance of such methods crucially depends on the choice of the regularization parameter which penalizes the distance. The problem we investigate in this work is to choose this parameter, which is sophisticated without any target labels.
While remarkable theoretical results have been achieved which quantify the generalization ability of domain adaptation models [8, 22, 19, 20, 21], the choice of the regularization parameter which is crucial for finding such models has not systematically been addressed. Even though some parameter choice strategies exist, they are either purely heuristically driven or very limited by their assump-tions [23]. Typical approaches are fixing the regularization parameters [12], minimizing the source error [16], balancing the source error and a distance [17], multiplying a fixed weighting parameter (e.g. 1 in [16]) by a heuristic schedule value that increases during training, or, (importance) weighting the input samples by the ratio between target and source density [3, 24, 23]. One common problem shared among all these approaches is that they all can fail if the density ratio is unbounded. Such unbounded density ratio is typical for many of the high dimensional problems considered in machine learning [19], e.g. see Figure 1. Besides the aforementioned issues, the lack of principled strategies for parameter choice causes misinterpretations in the ranking of domain adaptation methods which are traditionally compared by performance, while often relying on different parameter choice strategies.
In this work, we propose a principled method for choosing distance-penalizing parameters of feature representation learning approaches for unsupervised domain adaptation. Our approach starts with the observation that the distance-regularization setting of domain adaptation shares characteristics with regularized ill-posed inverse problems (see Table 1). In inverse problems, the regularization parameter can be optimally chosen by the fundamental balancing principle which optimizes an approximation-sample (bias-variance) trade-off [26, 27, 28]. We apply this principle for balancing domain distance and learning errors of target error bounds. In particular, we approach the problem of non-computable terms in the target error bound by a new algorithmic criterion for approximating the value of balance. We call our method the Balancing Principle for Domain Adaptation (BPDA).
The BPDA is general in the sense that it can be applied based on different target error bounds, e.g. on [8, 22, 19, 20, 21]. To the best of our knowledge, the BPDA is the first principled method for parameter choice in unsupervised domain adaptation that allows an unbounded ratio between target and source density. We provide a bound on the generalization error of the best model corresponding to the parameter chosen by the BPDA. Finally, we empirically investigate the behavior of the BPDA based on two target error bounds, different domain adaptation methods and benchmark datasets. Our 2
results show that the BPDA outperforms or is on par with the state of the art on the problem of choosing the regularization parameter, on several domain adaptation methods; applied on different datasets. 2 Summary of results
Notation Let X ⊂ Rn be an input space and Y be a discrete label space. Following the classical setting of unsupervised domain adaptation [25], we consider two datasets: A source dataset (x, y) = ((x1, lS(x1)), . . . , (xs, lS(xs))) ∈ (X × Y)s with inputs x1, . . . , xs independently drawn according to some source distribution (Borel probability measure) pS on X and labeled according to some labeling function1 lS : X → Y, and, an unlabeled target dataset x′ = (x′ t) ∈ X t with elements independently drawn according to some target distribution pT on X . Throughout this work, we focus on loss functions L : Y × Y → [0, ∞) which satisfy L(y, y) = 0. For example consider the 0-1 loss L(y1, y2) := 1[y1 ̸= y2], where 1[P ] is 1 iff the predicate P is true and 0 otherwise, and the quadratic loss function L(y1, y2) := |y1 − y2|2. We denote the source error by εS(f ) = εS(f, lS) with cross-error defined as εS(f, g) := Ex∼pS [L(f (x), g(x))] and its empirical sample estimate by (cid:98)εS(f ) = (cid:98)εS(f, lS) with (cid:98)εS(f, g) := (cid:80)s i=1 L(f (xi), g(xi)). We denote the analogously defined target error by εT (f ), target cross-error by εT (f, g) and its empirical sample estimate by (cid:98)εT (f ) with empirical cross-error (cid:98)εT (f, g). Throughout this work, we focus on target cross-errors εT (f, g) which satisfy the triangle inequality. 1, . . . , x′
Learning setup In this work, we focus on feature representation learning algorithms for domain adaptation. These approaches aim at finding two learning models: A representation mapping ϕ ∈
Φ ⊂ {ϕ : X → R} into some representation space R ⊂ Rm and a classifier g ∈ G ⊂ {g : R → Y}.
Loosely speaking, the aim is to find a mapping ϕ under which the source representations ϕ(x) := (ϕ(x1), . . . , ϕ(xs)) and the target representations ϕ(x′) := (ϕ(x′ t)) appear similar, and, at the same time, enough information is preserved for prediction [14] by g(x). A common approach to realize this aim is to solve the following objective function [19] g∈G,ϕ∈Φ (cid:98)εS(g ◦ ϕ) + α · d(ϕ(x), ϕ(x′)) min where d is a distance measure between source and target representations and α ∈ [0, ∞) is a parameter2. Good choices for d in Eq. (1) have been identified to be the Wasserstein distance [29, 30], the Maximum Mean Discrepancy [31, 32], moment distances [17, 33, 18, 34, 35, 36], adversarially learned distances [16, 37] and other measures of divergence [38, 39, 19, 20]. 1), . . . , ϕ(x′ (1)
Problem For some α ∈ [0, ∞), let gα ◦ ϕα denote the minimizer of Eq. (1). Given an increasing sequence of parameters α1, . . . , αw ∈ [0, ∞) with α1 = 0, the problem studied in this work is to choose the parameter α in the sequence α1, . . . , αw with the lowest target error εT (gα ◦ ϕα).
Approach Our approach consists in minimizing a target error bound which satisfies the form
εT (gα ◦ ϕα) ≤ D(α) + E(α) (2) where D(α) gives a notion of domain distance (cf. [25]) by quantifying a distance between source and target data representations and E(α) comprises different learning errors. We assume that
E(α) is bounded by some constant B > 0. The general form in Eq. (2) is satisfied by many error bounds [8, 22, 20, 21, 34] which all can be taken as a basis for our approach (more detailed examples are provided in Section 3 and Section 4). One problem that complicates the minimization of these error bounds is that all of them contain terms that are not computable due to the lack of target data.
That is, E(α) cannot be directly estimated. The BPDA overcomes this problem by a new criterion for estimating the value of balance between the normalized terms E(α) and D(α). The BPDA is detailed in Algorithm 1.
Properties of Algorithm 1 The BPDA has the following striking properties.
• The BPDA is a general procedure which can be instantiated by any error bound of the form in Eq. (2). See Section 4 and Section 5 for its application based on two different target error bounds [25, 20]. 1For simplicity, we use labeling functions instead of the more general concept of conditional distributions. 2For simplicity we omit further regularization of ϕ and g. 3
• In contrast to state-of-the-art methods, the BPDA does not assume a target labeling function lT that is equal to the source labeling function lS (covariate-shift assumption) and it does not assume that the ratio between target and source density is bounded (sample selection bias assumption). See the supplementary material for a discussion of covariate-shift violations.
• The learning model gαBP ◦ ϕαBP identified by the BPDA satisfies a generalization bound, see Section 4. If the learning errors term E(α) is non-decreasing, then the target error of gαBP ◦ ϕαBP is only a constant factor away from the minimum minα∈[0,∞) D(α) + E(α) of the instantiation bound in Eq. (2).
Algorithm 1: Balancing principle for domain adaptation (BPDA)
Input
:Increasing sequence of parameters α1, . . . , αw ∈ [0, ∞) with α1 = 0 and minimizers f1 := gα1 ◦ ϕα1 , . . . , fw := gαw ◦ ϕαw of Eq. (1).
:Parameter αBP solving the problem above.
Output
Initialization :S = {} for i = 1, . . . , w do
Compute empirical cross-error (cid:98)εT (fi, fj) and domain distance D(αj) for all j = 1, . . . , i − 1. if (cid:98)εT (fi, fj) ≤ D(αj)
S := S ∪ {αi} for all j = 1, . . . , i − 1 then 2 + 2B
D(0) (cid:16) (cid:17) end end return
:αBP := max S
Besides the properties above, the BPDA outperforms or is on par with the state of the art, on the problem of choosing the regularization parameter, on several domain adaptation methods; applied on different datasets, see Section 5.