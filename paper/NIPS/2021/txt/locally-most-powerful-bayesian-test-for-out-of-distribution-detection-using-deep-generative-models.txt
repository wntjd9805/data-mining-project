Abstract
Several out-of-distribution (OOD) detection scores have been recently proposed for deep generative models because the direct use of the likelihood threshold for OOD detection has been shown to be problematic. In this paper, we propose a new OOD score based on a Bayesian hypothesis test called the locally most powerful Bayesian test (LMPBT). The LMPBT is locally most powerful in that the alternative hypothesis (the representative parameter for the OOD sample) is speciﬁed to maximize the probability that the Bayes factor exceeds the evidence threshold in favor of the alternative hypothesis provided that the parameter speciﬁed under the alternative hypothesis is in the neighborhood of the parameter speciﬁed under the null hypothesis. That is, under this neighborhood parameter condition, the test with the proposed alternative hypothesis maximizes the probability of correct detection of OOD samples. We also propose numerical strategies for more efﬁcient and reliable computation of the LMPBT for practical application to deep generative models. Evaluations conducted of the OOD detection performance of the LMPBT on various benchmark datasets demonstrate its superior performance over existing OOD detection methods. 1

Introduction
In several real-world applications of deep learning models, detecting anomalous samples that signiﬁ-cantly deviate from the distribution of the training data, that is, out-of-distribution (OOD) samples, is crucial for reliable decision making, and various OOD detection methods have been studied in this regard. Deep generative models [9, 8, 17] have also been investigated for OOD detection as an intuitive strategy owing to their ability to evaluate the likelihood of a test sample. However, recent studies have shown that deep generative models can assign higher likelihoods to OOD samples than in-distribution samples [12], causing the direct use of raw likelihoods for OOD detection to be problematic.
To address this challenge, several OOD scores have been recently proposed for deep generative models and have exhibited effective OOD detection performance [15, 16, 18]. Ren et al. [15] proposed the use of the ratio of the likelihood obtained from a model trained using pure input data to that obtained from a background model trained using noise-perturbed input data as an OOD score. Xiao et al. [18] proposed a likelihood regret score that can be calculated as the difference between the likelihood obtained with the optimized parameters for a test sample and that approximated by the VAE. Serrà et al. [16] proposed a penalized log-likelihood with an input complexity as an OOD score, where the input complexity can be computed as the normalized size of the compressed input image.
In this paper, we propose a new OOD detection method that is optimal in some sense in the framework of a Bayesian hypothesis test—inspired by a uniformly most powerful Bayesian test [7] and a locally 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
most powerful test [14]. The Bayesian hypothesis test is based on the ratio of the posterior odds that the alternative hypothesis is true, given the observed data [3]. We formulate the OOD detection problem as a Bayesian test with the null hypothesis that a test sample is an in-distribution sample and the alternative hypothesis that the test sample is an OOD sample. Speciﬁcally, the null hypothesis is speciﬁed to represent the model trained on the in-distribution training set by the maximum likelihood estimation, as typically performed in previous studies. Against this speciﬁc null hypothesis, we propose to specify the alternative hypothesis to represent the model trained on the expanded training set with the test sample. Then, we show that the test with our proposed alternative hypothesis is locally most powerful in that the alternative hypothesis is speciﬁed so as to maximize the probability that the Bayes factor exceeds the evidence threshold in favor of the alternative hypothesis among all alternative hypotheses that have the model parameters in the neighborhood of the model parameter speciﬁed under the null hypothesis. That is, under this neighborhood parameter condition, the test with the proposed alternative hypothesis maximizes the probability of the correct detection of OOD samples. The proposed test is called the locally most powerful Bayesian test (LMPBT).
Because we specify the alternative hypothesis of the LMPBT for a test sample to represent the model trained on the expanded training set with that test sample, we need to re-train the model for each test sample. However, the computational cost of this retraining is signiﬁcant. To address this issue, we adopt the upweighting method [10]. Using this method, we analyze the inﬂuence of upweighting a test sample on the parameter change and estimate the new parameters without retraining.
However, computational issues are encountered when the upweighting method is directly applied in practice. First, the upweighting method involves the Hessian matrix, which is assumed to have all positive eigenvalues. However, the loss function of deep generative models is known to be nonconvex, and ﬁnding the global optimum is infeasible. Consequently, the Hessian can have negative eigenvalues. Second, the upweighting method requires the computation of the inverse of the Hessian matrix. However, deep generative models, which have numerous parameters, incur large costs for the calculation of the Hessian and its inverse.
To address these issues, we use a low-rank approximation [2, 20, 21, 13] of the Hessian. Consequently, we can ensure that the approximated Hessian has all positive eigenvalues and can signiﬁcantly reduce the computational cost for calculating the inverse of the Hessian. We evaluated the performance of the LMPBT using deep generative models on benchmark datasets and demonstrated a more effective
OOD detection performance than competing methods. In summary, the contributions of this study are as follows:
• We propose a new OOD detection method—the locally most powerful Bayesian test (LMPBT)— that maximizes the probability of correct detection of OOD samples under some conditions.
• We address the computational issues encountered when practically implementing the LMPBT for deep generative models.
• Evaluations conducted of the LMPBT using variational autoencoders (VAEs) [9] and Glows [8] on benchmark datasets demonstrate state-of-the-art performance for OOD detection (the code for the
LMPBT is available at https://github.com/keunseokim91/LMPBT). 2