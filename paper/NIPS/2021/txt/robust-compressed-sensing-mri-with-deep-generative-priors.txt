Abstract
The CSGM framework (Bora-Jalal-Price-Dimakis’17) has shown that deep gen-erative priors can be powerful tools for solving inverse problems. However, to date this framework has been empirically successful only on certain datasets (for example, human faces and MNIST digits), and it is known to perform poorly on out-of-distribution samples. In this paper, we present the ﬁrst successful application of the CSGM framework on clinical MRI data. We train a generative prior on brain scans from the fastMRI dataset, and show that posterior sampling via Langevin dynamics achieves high quality reconstructions. Furthermore, our experiments and theory show that posterior sampling is robust to changes in the ground-truth distribution and measurement process. Our code and models are available at: https://github.com/utcsilab/csgm-mri-langevin. 1

Introduction
Compressed sensing [23, 15] has enabled reductions to the number of measurements needed for successful reconstruction in a variety of imaging inverse problems. In particular, it has led to shorter scan times for magnetic resonance imaging (MRI) [62, 90], and most MRI vendors have released products leveraging this framework to accelerate clinical workﬂows. Despite their successes, sparsity-based methods are limited by the achievable acceleration rates, as the sparsity assumptions are either hand-crafted or are limited to simple learned sparse codes [72, 73].
More recently, deep learning techniques have been used as powerful data-driven reconstruction methods for inverse problems [49, 68]. There are two broad families of deep learning inversion techniques [68]: end-to-end supervised and distribution-learning approaches. End-to-end supervised techniques use a training set of measured images and deploy convolutional neural networks (CNNs) and other architectures to learn the inverse mapping from measurements to image. Network architec-tures that include both CNN blocks and the imaging forward model have grown in popularity, as they combine deep learning with the compressed sensing optimization framework, see e.g. [32, 3, 64].
End-to-end methods are trained for speciﬁc imaging anatomy and measurement models and show excellent performance in these tasks. However, reconstruction quality is known to suffer when applied out of distribution, and recently has been shown to severely degrade [4, 19] under certain types of natural measurement and anatomy perturbations.
In this paper we study deep learning inversion techniques based on distribution learning. These models are trained without reference to measurements, and so easily adapt to changes in the measurement
∗Ajil Jalal and Marius Arvinte contributed equally to this work. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
process. The most common family of such techniques, known also as Compressed Sensing with
Generative Models (CSGM) [13] uses pre-trained generative models as priors. Generative models are extremely powerful at representing image statistics and CSGM has been successfully applied to numerous inverse problems [13, 34] including non-linear phase retrieval [35], and improved with invertible models [6], sparsity based deviations [21], image adaptivity [42], and posterior sampling [79, 45]. These methods have only recently been applied to MRI and have not yet been shown to be competitive with supervised end-to-end methods. The very recent work [53] trains a
StyleGAN for magnitude-only DICOM images but requires the presence of side-information and studies Gaussian, real-valued measurements for reconstruction. The deviation from the true MRI measurement model and the use of magnitude images are known to be problematic when evaluating performance [77]. Another work [54] trained an Invertible Neural Network on complex-valued single-coil MR images and showed very good performance in comparison to sparsity and GAN priors.
Untrained and unamortized generators [37] have also been recently explored [19], showing promising results in some cases. Further, [17] studies the harder problem of learning a generative model for a class of images using only partial observations, as ﬁrst proposed in AmbientGAN [14].
In this paper we train the ﬁrst score-based generative model [80] for MR images. We show that we can faithfully represent MR images without any assumptions on the measurement system. As a consequence, we are able to reconstruct retrospectively under-sampled MRI data under a variety of realistic sampling schemes. We show that our reconstruction algorithm is competitive with end-to-end supervised training when the test-data are matched to the training data and that it is robust to various out-of-distribution shifts, while in some cases end-to-end methods signiﬁcantly degrade. 1.1 Contributions
• We successfully train a score-based deep generative model for complex-valued, T2-weighted brain
MR images without any assumptions on the measurement scheme. When applied to multi-coil
MRI reconstruction under the CSGM framework, we achieve competitive performance compared to end-to-end deep learning methods when the test-time data are sampled within distribution.
• We give evidence that posterior sampling should give high-quality reconstructions. First, we show that for any measurements (including the Fourier measurements in MRI) that posterior sampling with the correct prior is within constant factors of the optimal recovery method; second, even if the prior is wrong but gives α mass to the true distribution, we show that posterior sampling for
Gaussian measurements is nearly optimal with just an additive O(log(1/α)) loss.
• We empirically show that our approach is robust to test-time distribution shifts including different sampling patterns and imaging anatomy. The former is unsurprising given that our model was trained without knowledge of the measurement scheme. As a consequence, our approach provides a degree of ﬂexibility in choosing scan parameters – a common situation in routine clinical imaging. Perhaps surprisingly, the latter indicates that a specialized training set may offer sufﬁcient regularization for a larger class of images. In contrast, we empirically show that end-to-end methods do not always enjoy the same robustness guarantees, in some cases leading to severe degradation in reconstruction quality when applied out-of-distribution.
• Our method can be used to obtain multiple samples from the posterior by running Langevin dynamics with different random initializations. This allows us to get multiple reconstructions which can be used to obtain conﬁdence intervals for each reconstructed voxel and visualize our reconstruction uncertainty on a voxel-by-voxel resolution. Uncertainty quantiﬁcation can be incorporated into end-to-end methods, e.g., using variational auto-encoders [24], but this requires changes to the architecture. Our method does not require any modiﬁcation and multiple reconstruction samplers can be run in parallel.
Our main results are succinctly summarized in Figure 1: we achieve equivalent reconstruction performance using a reduced training set when evaluated in-distribution and are robust when evaluated out-of-distribution. 1.2