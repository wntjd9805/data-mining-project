Abstract
The development of data-dependent heuristics and representations for biological sequences that reﬂect their evolutionary distance is critical for large-scale biological research. However, popular machine learning approaches, based on continuous
Euclidean spaces, have struggled with the discrete combinatorial formulation of the edit distance that models evolution and the hierarchical relationship that charac-terises real-world datasets. We present Neural Distance Embeddings (NeuroSEED), a general framework to embed sequences in geometric vector spaces, and illustrate the effectiveness of the hyperbolic space that captures the hierarchical structure and provides an average 22% reduction in embedding RMSE against the best competing geometry. The capacity of the framework and the signiﬁcance of these improve-ments are then demonstrated devising supervised and unsupervised NeuroSEED approaches to multiple core tasks in bioinformatics. Benchmarked with common baselines, the proposed approaches display signiﬁcant accuracy and/or runtime improvements on real-world datasets. As an example for hierarchical clustering, the proposed pretrained and from-scratch methods match the quality of competing baselines with 30x and 15x runtime reduction, respectively. 1

Introduction
Over the course of evolution, biological sequences constantly mutate and a large part of biological research is based on the analysis of these mutations. Biologists have developed accurate statistical models to estimate the evolutionary distance between pairs of sequences based on their edit distance
D(s1, s2): the minimum number of (weighted) insertions, deletions or substitutions required to transform a string s1 into another string s2.
However, the computation of this edit distance kernel D with traditional methods is bound to a quadratic complexity and hardly parallelizable, making its computation a bottleneck in large scale analyses, such as microbiome studies [1, 2, 3]. Furthermore, the accurate computation of similarities among multiple sequences, at the foundation of critical tasks such as hierarchical clustering and multiple sequence alignment, is computationally intractable even for relatively small numbers of sequences. Problems that in other spaces are relatively simple become combinatorially hard in the space of sequences deﬁned by the edit distance. For example, ﬁnding the Steiner string, a classical problem in bioinformatics that can be thought of as computing the geometric median in the space of sequences, is NP-complete.
Classical algorithms and heuristics [4, 5, 6, 7] widely used in bioinformatics for these tasks are data-independent and, therefore, cannot exploit the low-dimensional manifold assumption that characterises real-world data [8, 9, 10]. Leveraging the available data to produce efﬁcient and data-∗Correspondence to gcorso@mit.edu 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
Figure 1: On the left, the key idea of NeuroSEED: learn an encoder function fθ that preserves distances between the sequence and vector space (D and d). The vector space can then be used to study the relationship between sequences and, potentially, decode new ones (see Section 7.2). On the right, an example of the hierarchical clustering produced on the Poincaré disk. The data was downloaded from UniProt [14] and consists of the P53 tumour protein from 20 different organisms. dependent heuristics and representations would greatly accelerate large-scale analyses that are critical to biological research.
While the number of available biological sequences has grown exponentially over the past decades, machine learning approaches to problems related to string matching [11, 12] have not been adopted widely in bioinformatics due to their limitation in accuracy and speed. In contrast to most tasks in computer vision and NLP, string matching problems are typically formalised as combinatorial optimisation problems. These discrete formulations do not ﬁt well with the current deep learning approaches. Moreover, representation learning methods based on Euclidean spaces struggle to capture the hierarchical structure that characterises real-world biological datasets due to evolution.
Finally, common self-supervised learning approaches, very successful in NLP, are less effective in the biological context where relations tend to be between sequences rather than between bases [13].
In this work, we present Neural Distance Embeddings (NeuroSEED), a general framework to produce representations for biological sequences where the distance in the embedding space is correlated with the evolutionary distance D between sequences. NeuroSEED provides fast approximations of the distance kernel D, low-dimensional representations for biological sequences, tractable analysis of the relationship between multiple sequences in the embedding geometry and a way to decode novel sequences.
Firstly, we reformulate several existing approaches into NeuroSEED highlighting their contributions and limitations. Then, we examine the task of embedding sequences to preserve the edit distance that is the basis of the framework. This analysis reveals the importance of data-dependent approaches and of using a geometry that matches the underlying data distribution well. The hyperbolic space is able to capture the implicit hierarchical structure given by biological evolution and provides an average 22% reduction in embedding RMSE against the best competing geometry.
We show the potential of the framework and its wide applicability by analysing two fundamental tasks in bioinformatics involving the relations between multiple sequences: hierarchical clustering and multiple sequence alignment. For both tasks, unsupervised approaches using NeuroSEED encoders are able to match the accuracy of common heuristics while being orders of magnitude faster. For hierarchical clustering, we also explore a method based on the continuous relaxation of Dasgupta’s cost in the hyperbolic space which provides a 15x runtime reduction at similar quality levels. Finally, for multiple sequence alignment, we devise an original approach based on variational autoencoders that matches the performance of competitive baselines while signiﬁcantly reducing the runtime complexity. 2
As a summary our contributions are: (i) We introduce NeuroSEED, a general framework to map sequences in geometric vector spaces, and reformulate existing approaches into it. (ii) We show how the hyperbolic space can bring signiﬁcant improvements to the data-dependent analysis of biological sequences. (iii) We propose several heuristic approaches to classical bioinformatics problems that can be constructed on top of NeuroSEED embeddings and provide signiﬁcant running time reduction against classical baselines. 2 Bioinformatics tasks
The ﬁeld of bioinformatics has developed a wide range of algorithms to tackle the classical problems that we explore. Here we present the tasks and brieﬂy mention their motivation and some of the baselines we test. More details are provided in Appendix B.
Edit distance approximation In this work, we always deal with the classical edit distance where the same weight is given to every string operation, but all the approaches developed can be applied to any distance function of choice (which is given as an oracle). For example, when using amino acid sequences, one of the different metric variants of the classical substitution matrices such as mPAM250 [15] would be a good choice. As baseline approximation heuristics, we take k-mer [5], which is the most commonly used alignment-free method and represents sequences by the frequency vector of subsequences of a certain length, and FFP [16], another alignment-free method which looks at the Jensen-Shannon divergence between distributions of k-mers.
Hierarchical clustering (HC) Discovering the intrinsic hierarchical structure given by evolutionary history is a critical step of many biological analyses. Hierarchical clustering (HC) consists of, given a pairwise distance function, deﬁning a tree with internal points corresponding to clusters and leaves to datapoints. Dasgupta’s cost [17] measures how well the tree generated respects the similarities between datapoints. As baselines we consider classical agglomerative clustering algorithms (Single
[18], Complete [19] and Average Linkage [6]) and the recent technique [20] that uses a continuous relaxation of Dasgupta’s cost in the hyperbolic space.
Multiple sequence alignment (MSA) Aligning three or more sequences is used for the identiﬁca-tion of active and binding sites as well as conserved protein structures, but ﬁnding its optimal solution is NP-complete. A related task to MSA is the approximation of the Steiner string which minimises the sum of the distances (consensus error) to the sequences in a set.
Datasets To evaluate the heuristics we chose three datasets containing different portions of the 16S rRNA gene, crucial in microbiome analysis [21], one of the most promising applications of our approach. The ﬁrst, Qiita [21], contains more than 6M sequences of up to 152 bp that cover the V4 hyper-variable region. The second, RT988 [11], has only 6.7k publicly available sequences of length up to 465 bp covering the V3-V4 regions. Both datasets were generated by Illumina
MiSeq [22] and contain sequences of approximately the same length. Qiita was collected from skin, saliva and faeces samples, while RT988 was from oral plaques. The third dataset is the Greengenes full-length 16S rRNA database [23], which contains more than 1M sequences of length between 1,111 to 2,368. Moreover, we used a dataset of synthetically generated sequences to test the importance of data-dependent approaches. A full description of the data splits for each of the tasks is provided in
Appendix B.4. 3 Neural Distance Embeddings
The underlying idea behind the NeuroSEED framework, represented in Figure 1, is to map sequences in a continuous space so that the distance between embedded points is correlated to the one be-tween sequences. Given a distribution of sequences and a distance function D between them, any
NeuroSEED approach is formed by four main components: an embedding geometry, an encoder model, a decoder model, and a loss function.
Embedding geometry The distance function d between the embedded points deﬁnes the geometry of the embedding space. While this factor has been mostly ignored by previous work [11, 24, 25, 26, 27], we show that it is critical for this geometry to reﬂect the relations between the sequences in the domain. In our experiments, we provide a comparison between Euclidean, Manhattan, cosine, squared Euclidean (referred to as Square) and hyperbolic distances (details in Appendix D). 3
Encoder model The encoder model fθ maps sequences to points in the embedding space. In this work we test a variety of models as encoder functions: linear layer, MLP, CNN, GRU [28] and transformer [29] with local and global attention. The details on how the models are adapted to the sequences are provided in Appendix C. Chen et al. [24] proposed CSM, an encoder architecture based on the convolution of subsequences. However, as also noted by Koide et al. [12], this model does not perform well when various layers are stacked and, due to the interdependence of cells in the dynamic programming routine, it cannot be efﬁciently parallelised on GPU.
Decoder model For some tasks it is also useful to decode sequences from the embedding space.
This idea, employed in Section 7.2 and novel among the works related to NeuroSEED, enables to apply the framework to a wider set of problems.
Loss function The simplest way to train a NeuroSEED encoder is to directly minimise the MSE between the sequences’ distance and its approximation as the distance between the embeddings:
L(θ, S) = (cid:88) s1,s2∈S (D(s1, s2) − α d(fθ(s1), fθ(s2)))2 (1) where α is a constant or learnable scalar. Depending on the application that the learned embeddings are used for, the MSE loss may be combined or substituted with other loss functions such as the triplet loss for closest string retrieval (Appendix F), the relaxation of Dasgupta’s cost for hierarchical clustering (Section 7.1) or the sequence reconstruction loss for multiple sequence alignment (Section 7.2).
There are at least ﬁve previous works [11, 24, 25, 26, 27] that have used approaches that can be described using the NeuroSEED framework. These methods, summarised in Table 1, show the potential of approaches based on the idea of NeuroSEED, but share two signiﬁcant limitations. The
ﬁrst is the lack of analysis of the geometry of the embedding space, which we show to be critical. The second is that the range of tasks is limited to edit distance approximation (EDA) and closest string retrieval (CSR). We highlight how this framework has the ﬂexibility to be adapted to signiﬁcantly more complex tasks involving relations between multiple sequences such as hierarchical clustering and multiple sequence alignment.
Table 1: Summary of the previous and the proposed NeuroSEED approaches. EDA stands for edit distance approximation and CSR for closest string retrievals. For our experiments, in the columns geometry and encoder we report those that performed best among the ones tested.
Method
Geometry
Encoder
Zheng et al. [11]
Chen et al. [24]
Zhang et al. [25]
Dai et al. [26]
Gomez et al. [27]
Jaccard
Cosine
Euclidean
Euclidean
Square
CNN
CSM
GRU
CNN
CNN
Section 5
Section 6
Section 7.1
Section 7.2
Appendix F
Hyperbolic
Hyperbolic
Hyperbolic
Cosine
CNN & transformer
CNN & transformer
Linear
Linear
Hyperbolic CNN & transformer
Decoder (cid:55) (cid:55) (cid:55) (cid:55) (cid:55) (cid:55) (cid:55) (cid:55) (cid:51) (cid:55)
Loss
Tasks
MSE
MSE
MAE + triplet
MAE + triplet
MSE
MSE
MSE
Relaxed Dasgupta
MSE + reconstr.
MSE & triplet
EDA
EDA
EDA & CSR
EDA & CSR
EDA & CSR
EDA
HC & MSA
HC
MSA
CSR 4