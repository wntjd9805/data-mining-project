Abstract
The interdependence between nodes in graphs is key to improve class predictions on nodes and utilized in approaches like Label Propagation (LP) or in Graph Neu-ral Networks (GNNs). Nonetheless, uncertainty estimation for non-independent node-level predictions is under-explored. In this work, we explore uncertainty quantiﬁcation for node classiﬁcation in three ways: (1) We derive three axioms explicitly characterizing the expected predictive uncertainty behavior in homophilic attributed graphs. (2) We propose a new model Graph Posterior Network (GPN) which explicitly performs Bayesian posterior updates for predictions on interde-pendent nodes. GPN provably obeys the proposed axioms. (3) We extensively evaluate GPN and a strong set of baselines on semi-supervised node classiﬁcation including detection of anomalous features, and detection of left-out classes. GPN outperforms existing approaches for uncertainty estimation in the experiments. 1

Introduction
Accurate and rigorous uncertainty estimation is key for reliable machine learning models in safety-critical domains [67]. It quantiﬁes the conﬁdence of machine learning models, thus allowing them to validate knowledgeable predictions or ﬂag predictions on unknown input domains. Uncertainty is commonly divided in aleatoric and epistemic uncertainty [28]. The aleatoric uncertainty accounts for irreducible uncertainty (e.g., due to inherent sensor noise). The epistemic uncertainty accounts for a lack of information for accurate prediction (e.g., test data signiﬁcantly different from training data).
Traditionally, machine learning models assume i.i.d. inputs, thus performing predictions based on input features only. For uncertainty estimation on i.i.d. inputs, a large class of deﬁnitions, models and evaluation methods have been introduced [28, 62, 3, 78, 50]. Further, uncertainty estimation has been successfully applied to different tasks e.g. out-of-distribution (OOD) or shift detection [78], active learning [75, 55], continual learning [4] or reinforcement learning [18].
In contrast, uncertainty estimation on interdependent nodes is more complex than on i.i.d. inputs and under-explored [3]. A node in an attributed graph is characterized by two types of information: its features and its neighborhood. While the feature information indicates the node position in the feature space – similarly to i.i.d. inputs –, the neighborhood information indicates the additional node position in the network space. To leverage the neighborhood information, recent graph neural networks (GNNs) successfully proposed to enrich and correct the possibly noisy information of the features of a single node by aggregating them with the features of its neighborhood [46, 92, 48]. It naturally leads to the distinction between predictions without network effects based exclusively on their own node feature representation, and predictions with network effects based on neighborhood
∗equal contribution 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
(a) AU w/o network (b) AU w/ network (c) EU w/o network (d) EU w/ network
Figure 1: Illustration of aleatoric uncertainty (AU) and epistemic uncertainty (EU) without and with network effects (i.e. i.i.d. inputs vs interdependent inputs). Nodes have the same features in all cases.
Network effects are visualized through edges between nodes which change the predicted distributions.
The aleatoric uncertainty is high if the categorical distribution ˆy(v)
Cat(p(v)) is ﬂat. The epistemic uncertainty is high if the Dirichlet distribution p(v)
Dir(α(v)) is spread out. We refer the reader to
Section 3.2 for formal deﬁnitions of those distributions.
∼
∼ aggregation. The aggregation step commonly assumes network homophily which states that nodes with similar properties tend to connect to each other more densely, thus violating the i.i.d. assumption between node features given their neighborhood.
The core motivation of our work is to transfer some of the existing uncertainty estimation deﬁnitions, models and evaluations from i.i.d. inputs to interdependent node inputs by leveraging both the feature and the neighborhood information. In particular, we aim at an accurate quantiﬁcation of the aleatoric and epistemic uncertainty without and with network effect under network homophily (see Fig. 1).
Our contribution. In this work, we consider uncertainty estimation on semi-supervised node classi-ﬁcation. First, we derive three axioms which materialize reasonable uncertainty for non-independent inputs. These axioms cover the traditional notions of aleatoric and epistemic uncertainty and distin-guish between the uncertainty with and without network effects. Second, we propose Graph Posterior
Network (GPN)2 for uncertainty estimation for node classiﬁcation and prove formally that it follows the axiom requirements contrary to popular GNNs. Third, we build an extensive evaluation setup for uncertainty estimation which relies on the assessment of uncertainty estimation quality of OOD de-tection and robustness against shifts of the attributed graph properties. Both OOD data and attributed graph shifts distinguish between attribute and structure anomalies. The theoretical properties of GPN manifest in these experiments where it outperforms all other baselines on uncertainty evaluation. 2