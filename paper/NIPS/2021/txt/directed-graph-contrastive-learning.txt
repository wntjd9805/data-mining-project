Abstract
Graph Contrastive Learning (GCL) has emerged to learn generalizable representa-tions from contrastive views. However, it is still in its infancy with two concerns: 1) changing the graph structure through data augmentation to generate contrastive views may mislead the message passing scheme, as such graph changing action de-prives the intrinsic graph structural information, especially the directional structure in directed graphs; 2) since GCL usually uses predeﬁned contrastive views with hand-picking parameters, it does not take full advantage of the contrastive informa-tion provided by data augmentation, resulting in incomplete structure information for models learning. In this paper, we design a directed graph data augmentation method called Laplacian perturbation and theoretically analyze how it provides contrastive information without changing the directed graph structure. Moreover, we present a directed graph contrastive learning framework, which dynamically learns from all possible contrastive views generated by Laplacian perturbation.
Then we train it using multi-task curriculum learning to progressively learn from multiple easy-to-difﬁcult contrastive views. We empirically show that our model can retain more structural features of directed graphs than other GCL models because of its ability to provide complete contrastive information. Experiments on various benchmarks reveal our dominance over the state-of-the-art approaches. 1

Introduction
There is a growing interest in learning from directed graphs using Graph Neural Networks (GNNs)
[17, 12, 18, 50] to tackle practical problems, such as time-series problems [1, 4, 49], ﬁne-grained trafﬁc prediction [29, 21] and recommendation system [35, 7, 40]. Current GNNs designed for learning from directed graphs [23, 43, 44] are trained end-to-end under supervision. This training scheme shows excellent performance by virtue of enough labeled data. Correspondingly, to make use of rich unlabeled data, several Graph Contrastive Learning (GCL) [39, 63, 69, 34, 13, 67] works are proposed based on GNNs and Contrastive Learning (CL) [5, 45, 14]. They utilize data augmentation methods to generate contrastive views from the original graphs, then force views generated from the same instance (node or graph) closer while views from different instances apart using InfoNCE-like
[28] objective function. However, current GCL methods encounter some issues in processing directed graphs, mainly in data augmentation method and contrastive learning framework.
Firstly, most data augmentation methods used in GCL [63, 69, 68] do not take the directed graph structure into account and may discard distinctive direction information. For example, the idea of dropping nodes/edges [68, 63, 52] is borrowed from random erasing used in images [66] , which overlooks the discrepancy of nodes and edges in different graph structures. Moreover, by grasping contrastive information through changing graph structure, part of the distinctive direction information, e.g., irreversible time-series relationships, will inevitably be lost. The message passing scheme will
∗Corresponding author 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
also be mislead, making it difﬁcult for GNN-based encoders to learn from directed graphs. There is a lack of data augmentation methods that are speciﬁcally designed for directed graphs to retain the original directed graph structure while providing enough contrastive information.
Besides, common contrastive learning frameworks are not optimized for directed graphs, they can only learn from a limited number of contrastive views [63, 69, 13]. However, due to the complex structure of directed graphs, it is insufﬁcient to use a small number of contrastive views to fully understand their structural characteristics [43]. Furthermore, since the contrastive views have to be determined before training, it becomes another problem to select the ideal views for the downstream task during pre-processing, about which we actually have no knowledge in advance [42, 59]. Hand-picking contrastive views also cause a decrease in generalization. Several works [41, 61] try to obtain more information by increasing the number of contrastive views. However, they still have to pre-deﬁne the views and trade off between the number of views and the training difﬁculty.
To address these two issues, we ﬁrst propose a directed graph data augmentation method called
Laplacian perturbation. Since the contrastive views are passed to the encoder in the form of
Laplacian matrix, a desirable data augmentation method is to perturb the Laplacian matrix without changing the directed graph structure. To achieve this, we adopt the approximate directed graph
Laplacian [43] where a teleport probability is introduced to control the degree of approximation.
Thus, by adding a perturbation term to this probability, we can simply augment the Laplacian matrix without altering the directed graph structure. As it is time-consuming to calculate the Laplacian matrix, we then speed it up using the power method [24]. In addition, from the theoretical analysis, we ﬁnd that the Laplacian perturbation is essentially a perturbation to the directed graph entropy.
The perturbation term essentially determines the magnitude of the entropy perturbation error, which affects the magnitude of the contrastive information.
To learn the complete structural characteristics of directed graphs, we design a directed graph contrastive learning framework to learn from contrastive views generated by Laplacian perturba-tion. First, we introduce a generalized dynamic-view contrastive objective which maximizes the sum of the mutual information between the representations of all contrastive views. This objective allows the contrastive views to change dynamically during training and motivates the encoder to learn a generalized representation from all views provided by data augmentation. However, this dynamic-view objective function is hard to optimize. Thus, we leverage the multi-task curriculum learning strategy [33, 36, 10, 26] to divide multiple contrastive views into sub-tasks with various difﬁculties and progressively learn from easy-to-difﬁcult sub-tasks. In this way, we can learn all views step-by-step to reach the ﬁnal objective. Moreover, learning from all contrastive views eliminates the need to adjust the data augmentation parameters anymore.
We empirically show that our Directed Graph Contrastive Learning (DiGCL) outperforms the competitive baselines in the settings of unsupervised and supervised learning. Systematic analysis is also carried out to analyze the performance of various augmentations on the mainstream benchmarks and the impact of different pacing functions on the performance of directed graph contrastive learning. 2 Directed Graph Data Augmentation
In this section, we ﬁrst design a directed graph data augmentation scheme named Laplacian perturba-tion. As it is time-consuming to calculate the Laplacian matrix, we then speed it up using the power method [24]. Finally, we analyze the proposed data augmentation scheme theoretically. 2.1 Directed Graph Laplacian and its Approximation
Formally, let a directed graph G = (V, E), its adjacency matrix can be denoted as A = {0, 1}n×n, where n = ∣V∣. The nodes are described by the feature matrix X ∈ Rn×c, with the number of features c per node. Intuitively, the data augmentation can be performed at the topological- and feature-level, operating on A and X, respectively [63, 69]. The distinctive attribute of directed graphs is the directionality of the edges, which leads us to focus on topological node-level data augmentation.
The augmented directed graph is fed to the GNN-based encoder in the form of Laplacian matrix to learn the representation. Since G may contain isolated nodes or could be formed into bipartite graph, it is not appropriate to trivially use directed graph Laplacian [6]. To relax this constraint, we use its 2
1 2 approximate form: the approximate directed graph Laplacian matrix [43], which is deﬁned as 1 2 1 2 (Π appr ˜PΠ
− 1 appr + Π 2
− 1 appr ˜PT Π 2 appr) ,
Lappr(G, α) = I − (1) where Πappr = 1
∣∣πappr∣∣ 1
Diag(πappr). The approximate eigenvector πappr is deﬁned as (1 − α)πappr ˜P + 1 (2) n where ˜P = ˜D−1 ˜A, ˜A = A + In×n denotes the transition matrix with added self-loops and the diagonal degree matrix ˜D(u, u) = ∑v∈V ˜A(u, v). Tong et al. [43] add self-loops to the original directed graph to ensure G to be aperiodic and redeﬁne the transition matrix based on personalized PageRank with the teleport probability α ∈ (0, 1) to guarantee the redeﬁned matrix to be irreducible. Note that we follow the [43] and set α = 0.1 in this paper. 11×n = πappr,
α 1 + α
According to Eq. (1), existing data augmentation methods [63, 69], e.g., node/edge dropping, sub-graph sampling, need to obtain the contrastive information by changing ˜P. Their use of sampling-based methods inevitably corrupts the directed graph structure and thus misleads the message passing in the GNN-based encoder. A desirable data augmentation method on Lappr is to perturb πappr reasonably without altering the directed graph structure ˜P1. 2.2 Directed Draph Data Augmentation with Laplacian Perturbation
From Eq. (2), it is easy to ﬁnd that the eigenvector πappr depends on the ˜P and α. In other words, we can shift the teleport probability α without changing the directed graph structure ˜P, thus altering the eigenvector πappr and ﬁnally perturbing the Laplacian matrix Lappr.
DEFINITION 1 Laplacian perturbation. Given a directed graph G = (V, E) and the teleport proba-bility α, we deﬁne the Laplacian perturbation opertation Φ(⋅) on the Lappr( ˜P, α) as
Φ∆α(G, α) = Lappr(G, α + ∆α), (3) where ∆α is a perturbation term that satisﬁes ∆α ⩾ 0 and α + ∆α ∈ (0, 1).
Through this operation, the directed graph structure and the sparsity of the Laplacian matrix are maintained, which means there is no training burden to the subsequent GNN-based encoder. However, using this operation for data augmentation is very time-consuming, since the time complexity of computing Eq. (2) is O (n2). To deal with it, we design an accelerating algorithm for computing this approximate eigenvector based on the power method [24].
We take advantage of the sparsity of the transition matrix ˜P to compute the approximate eigenvector
πappr and rewrite Eq. (2) to the form of discrete-time Markiv chain at time t as
πt+1 appr = (1 − α)πt appr
˜P + 1 n
α 1 + α 11×n. (4)
As stated in Tong et al. [43], πt the last term of Eq. (4) with (1 + α)πt appr1n×1 to appr has a special property that πt appr1n×1 = 1 1+α . We then multiply
πt+1 appr = (1 − α)πt appr
˜P + 1 n
α 1 + α
[(1 + α)πt appr1n×1]11×n = (1 − α)πt appr
˜P +
α n appr1n×n.
πt (5)
We can solve Eq. (5) iteratively using the power method [24]. Therefore, the complexity decreases to
O (nk), where k is the number of iteration times. Due to page limit, we do not discuss the number of iterations and convergence rate here. Please refer to [22] for more details. We take k = 100 and the tolerance as 1e−6 throughout. It can be seen easily that for large-scale graphs, our method can signiﬁcantly improve the speed and makes it possible to do Laplacian perturbation during the training, which is the basis for the framework proposed in Section 3. In addition, we compare the running time of our fast Laplacian perturbation with different data augmentation methods in Section 5.2. 1Note that adding self-loops to transform P into ˜P is a common trick [17, 56], and we ignore the effect of this operation on the directed graph structure. 3
Figure 1: Illustration of Laplacian perturbation. ξ is the auxiliary node deﬁned in [43] and the red dotted lines represent adding the self-loops. 2.3
Justiﬁcation of Laplacian Perturbation
Noticing the inherent connections between graph Laplacian and von Neumann entropy [62], we can use the proprieties of von Neumann entropy to analyze the Laplacian perturbation operation quantitatively. We start with deﬁning the von Neumann entropy of directed graphs.
DEFINITION 2 Directed graph von Neumann entropy. Given a directed graph G = (V, E), its von
Neumann entropy [62] based on the Lappr is deﬁned as
˜HVN(G, α) = 1 − 1 n
− 1 2n2
⎧⎪⎪
⎨
∑
⎪⎪⎩ (u,v)∈E ( 1 u dout dout v
+
πappr(u)
πappr(v)dout2 u
) − ∑ (u,v)∈ ˜E 1 u dout dout v
⎫⎪⎪
⎬
⎪⎪⎭
, (6) where ˜E = {(u, v) ∣ (u, v) ∈ E and (v, u) ∉ E}. din in- and out-degree of the node u. u = ∑v∈V A(v, u) and dout u = ∑v∈V A(u, v) are the
Since the Laplacian perturbation does not involve the nodes/edges and only changes the teleport probability connecting to the auxiliary node ξ as shown in Figure 1, the number of nodes n and the degrees of nodes du (edge distribution) will not change. Conversely, the approximate eigenvector
πappr has been changed. According to Eq. 6, the essence of this operation is a perturbation to the directed graph entropy. We further introduce the perturbation error to quantify this impact.
DEFINITION 3 Perturbation error. Given the perturbation term ∆α, we deﬁne the perturbation error of directed graph von Neumann entropy caused by Laplacian perturbation as ∆ ˜HVN(α, α +
∆α) = ˜HVN(G, α) − ˜HVN(G, α + ∆α).
THEOREM 1 Monotonicity of the perturbation error. The perturbation error ∆ ˜HVN increases monotonically with the Laplacian perturbation term ∆α.
THEOREM 2 Bounds on the perturbation error. Given a directed graph G = (V, E) and the teleport probability α, the inequality 0 < ∆ ˜HVN(α, α + ∆α) <
⎧⎪⎪
⎨
∑
⎪⎪⎩ (u,v)∈E holds. When the perturbation term ∆α = 0, ∆ ˜HVN = 0 and when ∆α → 1 − α, the perturbation error ∆ ˜HVN towards the upper bound.
πα appr(u) appr(v)dout2
πα 1 dout2 u 1 2n2
⎫⎪⎪
⎬
⎪⎪⎭ (7)
− (
) u
We show in THEOREM 1 that Laplacian perturbation can provide contrastive information in various magnitude for the encoder to learn the representations by changing ∆α. Meanwhile, since it does not need to alter the structure and the number of nodes n is generally high, the perturbation error will be in a very small range as shown in THEOREM 2. This can help the encoder to focus more on the directed graph structure rather than just learning from the errors. Proofs of THEOREM 1 and 2 are attached in the Supplementary Material. 3 Directed Graph Contrastive Learning
In this section, we introduce a new directed graph contrastive learning framework (DiGCL) with a more generalized objective, and then we present multi-task curriculum learning scheme to help
DiGCL progressively learn from multiple easy-to-difﬁcult contrastive views. The model illustration is in Figure 2 and the pseudo-code is given in the Supplementary Material. 4
Figure 2: Illustration of our DiGCL model using Laplacian perturbation. For a directed graph, we ﬁrst generate M different pairs of contrastive views by Laplacian perturbation. The different contrastive view pairs are then scored by a scoring function and mapped to different training paces by a pacing function. Finally, the arranged contrastive view pairs are input into a shared encoder to progressively learn the unsupervised graph representation with contrastive loss. 3.1 Learning with Dynamic-view Contrastive Objective
As we have deﬁned the directed graph data augmentation in Eq. (3), we follow the common graph contrastive learning (GCL) paradigm using our Laplacian perturbation.
Fixed-view Objective. GCL seeks to maximize the mutual information (MI) between the represen-tations of augmented graphs under different views [63, 69]. Based on it, we design a framework for directed graph contrastive learning, which contains three steps. (1) First, given a directed graph G = (V, E) and the teleport probability α, we generate two correlated views using for the G:
U∆α1 = Φ∆α1 (G, α) and V∆α2 = Φ∆α2(G, α) as a contrastive pair. This generation is through exe-cuting Laplacian perturbation Φ on the input G with the parameters ∆α1, ∆α2 separately. (2) Second, we take a GNN-based encoder f (⋅) to extract representation H∆α1 = f (U∆α1 ), H∆α2 = f (V∆α2) of two contrastive views. (3) Finally, the encoder is trained with the contrastive objective as max f
I (H∆α1; H∆α2 ) = max f
I (f (Φ∆α1 (G, α)); f (Φ∆α2(G, α))) , (8) where I(⋅) is the mutual information. This framework lets the encoder f (⋅) learn the representation of two different views U∆α1, V∆α2 while preserving as much MI as possible.
As shown in Eq. (8), the view generation is controlled by two perturbation terms ∆α1 and ∆α2, which may affect the objective function. The current GCLs manually select these parameters in advance, e.g., grid search, and ﬁx contrastive views during training. This parameter selection strategy could make the encoder obtained by Eq. (8) learn only the contrastive information in some particular views and lead to a reduced generalization of the model [59].
Dynamic-view Objective. To deal with it, we propose a more generalized objective to learn from dynamic changing contrastive views. We rewrite Eq. (8) as max f ∗
I (H∆α1; H∆α2) = max f ∗
E
∆α1,∆α2
I(f
∗(Φ∆α1(G, α)); f
∗(Φ∆α2(G, α))), (9) which requires the obtained optimal encoder f ∗ works well with ∀∆α1, ∆α2 ∈ [0, 1 − α) to learn a balanced and generalized representation. Note that InfoMin [42] designs a similar strategy that iteratively maximizes the MI in the worst views. In contrast, our objective maximizes the average
MI in all views because ﬁnding the worst views is related to the downstream task, about which we have zero prior knowledge. Besides, unlike other contrastive learning methods that also use multiple contrastive views [41, 13, 61], there is no ﬁxed number of views in our approach, and we do not preset the parameters to ﬁx the contrastive views but let them dynamically change during training.
However, maximizing Eq. (9) is not easy. Varying the perturbation term brings changes to the MI of views, which may result in large variance during the training process and unable to converge [42]. To increase the stability, we empirically make one of the views unperturbed in this paper, i.e., ∆α1 = 0.
We mark this view as U and design a multi-task training scheme to optimize proposed objective2. 3.2 Training using Multi-task Curriculum Learning
To tackle this problem, we propose a training scheme using curriculum learning, which utilizes prior knowledge about the difﬁculty of the learning tasks to learn from easy-to-difﬁcult contrastive views. 2The objective of ﬁxing a view is not exactly the same as the original one, and we ignore this trick’s impact. 5
Multi-task Curriculum Learning. Curriculum Learning facilitates the optimization on such a complex objective by scheduling the sub-objectives in a certain order [2, 33]. Inspired by it, we regard the process of training DiGCL as a multi-task problem [33, 36, 10, 11, 26, 20] and decompose it into M sub-tasks η1, . . . , ηM . Thus, the objective Eq. (9) can be rewritten as max f ∗ 1
M
M
∑ m=1
E
∆αm
I(f
∗(Lappr(G, α)); f
∗(Φ∆αm(G, α))), (10) where ∆αm ∈ {Θ1,...,M } is a uniform partition of Θ = [0, 1 − α) and the sub-task ηm is associated with the ∆αm. Then we consider sub-tasks that have less difﬁculty to learn in the optimization process as easy sub-tasks and vice versa as difﬁcult sub-tasks. We quantify this difﬁculty into difﬁculty score by means of a scoring function D(⋅). Based on it, we learn sub-tasks sequentially in a certain order decided by the pacing function P(⋅) to solve the main multi-task problem. Via information transmission by a shared encoder, the previously solved easy sub-tasks will assist in solving the next difﬁcult sub-tasks, while the latter can ﬁne-tune the encoder learned by the former.
Scoring Function. The scoring function D(⋅) measures how difﬁcult the sub-task ηm is, and can be any function D(⋅) ∶ {η1, . . . , ηM } → {d1, . . . , dM }, where d denotes the difﬁculty score. In each sub-task, there exists a pair of contrastive views as deﬁned in Eq. (10). We empirically assume that the difﬁculty dm of the sub-task ηm depend on how difﬁcult it is for the encoder f (⋅) to learn the contrastive information from this sub-task. Referring to DEFINITION 3, we can ﬁnd Laplacaian perturbation provides contrastive information to the encoder, and the perturbation term ∆α controls how much of this information is. Therefore, we can deﬁne the scoring function D(⋅) to calculate the difﬁculty dm of a sub-task ηm as dm = D(ηm) = 1 −
∆αm 1 − α
. (11)
The higher this score represents the smaller the perturbation error, the less contrastive information provided, and the less the encoder is able to distinguish the difference between the two views, resulting in a more difﬁcult sub-task. This idea coincides with the design of the discriminator in GAN [65, 9].
Pacing Function. The pacing function decides the learning sequence of sub-tasks and can be any function P(⋅) ∶ {1, . . . , L} → {d1, . . . , dM }, where L denotes all the learning iterations. We consider three function families [58]: logarithmic, exponential, and linear. Table in Figure 3(left) illustrates the pacing functions used in our experiments, which are parameterized by (da, db). Here da is the initial difﬁculty and db is the difﬁculty at the end of training, thus any pacing function with da = db is equivalent to ﬁxed view contrastive learning. We mark their corresponding perturbation terms as (∆αa, ∆αb). Considering the score in Eq. (11) is deﬁned in a continuous domain, we set the step size of the pacing function to 1, the ﬁnest-grained unit, i.e., L = M . This can help the model to switch between different training views in a more delicate way.
Name
Expression P(da,db)(l) log exp linear da + (db − da) (1 + 1/3 log ( l
L da + db−da (exp ( 3l e3−1
L da + (db − da) l
L
) − 1))
+ e−3))
Figure 3: (left) pacing function deﬁnitions for the three families of pacing functions used throughout; (right) the plot of pacing function curves from each family. l is the training epoch.
It is desired to ﬁnd the optimal solution over the entire deﬁnition domain of ∆α ∈ [0, 1 − α), we set the start point ∆αa = 0.9 − α (0.9 is used because the boundary value cannot be obtained) and ending point ∆αb = 0 in this paper, i.e., da = 1/9, db = 1. More analysis on the pacing functions can be seen in the Supplementary Material.
Contrastive loss. After discussing how to measure expectations in the objective, our attention shifts to maximizing the MI. Several works have investigated the lower bound of MI in contrastive learning, here we adopt InfoNCE [28]. For ith node ui in view U , the node-wise objective is deﬁned as (cid:96) (ui, vi) = − log
∑
U , zi exp (S (zi j=1 exp (S (zi
V∆αm ) /τ )
U , zj
V∆αm ) /τ ) n
, (12) 6
U is the projection of node feature that zi where vi is its corresponding positive node in view V∆αm and other nodes in view V∆αm is negative nodes of ui. zi
U ∈ ZU = g(HU ). A non-linear transformation g(⋅) named projection head maps augmented representations H to another lower dimension where the contrastive loss is calculated. S(⋅) denotes cosine similarity function and τ denotes the temperature parameter. The ﬁnal loss is computed across all positive node pairs in the views of one pace. Note that GRACE [68] proposes similar InfoNCE-like loss function. Different from it, we do not treat intra-view nodes (nodes in U except ui) as the negative samples since GNN-based encoder is already able to learn intra-graph structure well, we want to focus on inter-graph contrastive information. 4