Abstract
We consider the problem of learning mixtures of Gaussians under the constraint of approximate differential privacy. We prove that (cid:101)O(k2d log3/2(1/δ)/α2ε) samples are sufﬁcient to learn a mixture of k axis-aligned Gaussians in Rd to within total variation distance α while satisfying (ε, δ)-differential privacy. This is the ﬁrst re-sult for privately learning mixtures of unbounded axis-aligned (or even unbounded univariate) Gaussians. If the covariance matrices of each of the Gaussians is the identity matrix, we show that (cid:101)O(kd/α2 + kd log(1/δ)/αε) samples are sufﬁcient.
To prove our results, we design a new technique for privately learning mixture distributions. A class of distributions F is said to be list-decodable if there is an algorithm that, given “heavily corrupted” samples from f ∈ F, outputs a list of distributions one of which approximates f . We show that if F is privately list-decodable then we can learn mixtures of distributions in F. Finally, we show axis-aligned Gaussian distributions are privately list-decodable, thereby proving mixtures of such distributions are privately learnable. 1

Introduction
The fundamental problem of distribution learning concerns the design of algorithms (i.e., estimators) that, given samples generated from an unknown distribution f , output an “approximation” of f .
While distribution learning has a long history [54], studying it under privacy constraints is relatively new and unexplored.
In this paper, we work with a rigorous and practical notion of data privacy known as differential privacy [36]. Roughly speaking, differential privacy guarantees that no single data point can inﬂuence the output of an algorithm too much. Intuitively, this provides privacy by “hiding” the contribution of each individual. Differential privacy is the de facto standard for modern private analysis and has seen widespread impact in both industry and government [12, 22, 28, 29, 39].
In recent years, there has been a ﬂurry of activity in differentially private distribution learning and a number of techniques have been developed in the literature. In the pure differentially private setting,
Bun et al. [17] introduced a method to learn classes of distributions that admit a ﬁnite cover, i.e. when the class of distributions is well-approximated by a ﬁnite number of distributions. They show that this is an exact characterization of distributions which can be learned under pure differential privacy in the sense that a class of distributions is learnable under pure differential privacy if and only if the class 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
admits a ﬁnite cover [17, 41]. As a consequence of this result, they obtained pure differentially private algorithms for learning Gaussian distributions provided that the mean of the Gaussians are bounded and the covariance matrix of the Gaussians are spectrally bounded.1 Moreover, such restrictions on the Gaussians are necessary under the constraint of pure differential privacy.
One way to remove the requirement of having a ﬁnite cover is to relax to a weaker notion of privacy known as approximate differential privacy. With this notion, Bun et al. [17] introduced a method to learn a class of distributions that, instead of requiring a ﬁnite cover, requires a “locally small” cover, i.e. a cover where each distribution in the class is well-approximated by only a small number of elements within the cover. They prove that the class of Gaussians with arbitrary mean and a ﬁxed, known covariance matrix has a locally small cover which implies an approximate differentially private algorithm to learn this class of distributions. Later, Aden-Ali, Ashtiani, and Kamath [4] proved that the class of mean-zero Gaussians (with no assumptions on the covariance matrix) admits a locally small cover leading to an approximate differentially private method to learn the class of all Gaussians.
It is a straightforward observation that if a class of distributions admits a ﬁnite cover then the class of its mixtures also admits a ﬁnite cover. Combined with the aforementioned work of Bun et al., this implies a pure differentially private algorithm for learning mixtures of Gaussians with bounded mean and spectrally bounded covariance matrices. It is natural to wonder whether an analogous statement holds for locally small covers. In other words, if a class of distributions admits a locally small cover then does the class of mixtures also admit a locally small cover? If so, this would provide a fruitful direction to design differentially private algorithms for learning mixtures of arbitrary Gaussians.
Unfortunately, there are simple examples of classes of distributions that admit a locally small cover yet their mixture do not. This leaves open the question of designing private algorithms for many classes of distributions that are learnable in the non-private setting. One concrete open problem is for the class of mixtures of two arbitrary univariate Gaussian distributions. A more general problem is private learning of mixtures of k axis-aligned (or general) Gaussian distributions. 1.1 Main Results
We demonstrate that it is indeed possible to privately learn mixtures of unbounded univariate Gaus-sians. More generally, we give sample complexity upper bounds for learning mixtures of unbounded d-dimensional axis-aligned Gaussians. In the following theorem and the rest of the paper we use (cid:101)O to hide polylogarithmic factors, i.e. (cid:101)O(f (x)) means O(f (x) logc f (x)) for some c > 0.
Theorem 1.1 (Informal). The sample complexity of learning a mixture of k d-dimensional axis-aligned Gaussians to α-accuracy in total variation distance under (ε, δ)-differential privacy is (cid:101)O (cid:16) k2d log3/2(1/δ)
α2ε (cid:17)
.
The formal statement of this theorem can be found in Theorem 5.1. For technical reasons, we do require that δ ∈ (0, 1/n) for the above theorem to hold. This condition is quite standard in the differential privacy literature. Indeed, for useful privacy, δ should be “cryptographically small”, i.e.,
δ (cid:28) 1/n.
Even for the univariate case, our result is the ﬁrst sample complexity upper bound for learning mixture of Gaussians under differential privacy for which the variances are unknown and the parameters of the Gaussians may be unbounded. In the non-private setting, it is known that (cid:101)Θ(kd/α2) samples are necessary and sufﬁcient to learn a mixture of k axis-aligned Gaussian in Rd [6, 61]. In the private setting, the best known sample complexity lower bound is Ω(d/αε log(d)) under (ε, δ)-DP when
δ ≤ (cid:101)O( d/n) [46]. Obtaining improved upper or lower bounds in this setting remains an open question.
√
If the covariance matrix of each component of the mixture is the same and known or, without loss of generality, equal to the identity matrix, then we can improve the dependence on the parameters and obtain a result that is in line with the non-private setting. 1When we say that a matrix Σ is spectrally bounded, we mean that there are 0 < a1 ≤ a2 such that a1 · I (cid:22) Σ (cid:22) a2 · I. 2
Theorem 1.2 (Informal). The sample complexity of learning a mixture of k d-dimensional Gaussians with identity covariance matrix to α-accuracy in total variation distance under (ε, δ)-differential privacy is (cid:101)O (cid:16) kd
α2 + kd log(1/δ)
αε (cid:17)
.
We relegate the formal statement and the proof of this theorem to the supplementary materials (see
Appendix F). Note that the work of [53] implies an upper bound of O(k2d3 log2(1/δ)/α2ε2) for private learning of the same class albeit in the incomparable setting of parameter estimation.
Comparison with locally small covers. While the results in [4, 17] for learning Gaussian distribu-tions under approximate differential privacy do not yield ﬁnite-time algorithms, they do give strong information-theoretic upper bounds. This is achieved by showing that certain classes of Gaussians admit locally small covers. It is thus natural to ask if we can obtain sharper results by showing that mixtures of Gaussians also admit locally small covers. Unfortunately, the following simple example shows that not even mixtures of two univariate Gaussians admit locally small covers.
Proposition 1.3 (Informal version of Proposition B.6). Every cover for the class of mixtures of two univariate Gaussians is not locally small. 1.2 Techniques
To prove our result, we devise a novel technique which reduces the problem of privately learning mixture distributions to the problem of private list-decodable learning of distributions. The framework of list-decodable learning was introduced by Balcan, Blum, and Vempala [8] and Balcan, Röglin, and Teng [9] in the context of clustering but has since been studied extensively in the literature in a number of different contexts [7, 20, 21, 26, 27, 49, 55, 56]. The problem of list-decodable learning of distributions is as follows. There is a distribution f of interest that we are aiming to learn.
However, we do not receive samples from f ; rather we receive samples from a corrupted distribution g = (1 − γ)f + γh where γ ∈ (0, 1) and h is some arbitrary distribution. In our application, γ is close to 1, i.e. most of the samples are corrupted. The goal in list-decodable learning is to output a short list of distributions f1, . . . , fm with the requirement that f is close to at least one of the fi’s. The formal deﬁnition of list-decodable learning can be found in Deﬁnition 2.6. Informally, the reduction can be summarized by the following theorem which is formalized in Section 3.
Theorem 1.4 (Informal). If a class of distributions F is privately list-decodable then mixtures of distributions from F are privately learnable.
Roughly speaking, the reduction from learning mixtures of distribution to list-decodable learning works as follows. Suppose that there is an unknown distribution f which is a mixture of k distributions f1, . . . , fk. A list-decodable learner would then receive samples from f as input and output a short list of distributions (cid:98)F so that for every fi there is some element in (cid:98)F that is close to fi. In particular, some mixture of distributions from (cid:98)F must be close to the true distribution f . Since (cid:98)F is a small
ﬁnite set, the set of possible mixtures must also be relatively small. This last observation allows us to make use of private hypothesis selection which selects a good hypothesis from a small set of candidate hypotheses [4, 17]. In Section 3, we describe the aforementioned reduction in more detail.
We note that a similar connection between list-decodable learning and learning mixture distributions was also used by Diakonikolas et al. [26]. However, our reduction is focused on the private setting.
The reduction shows that to privately learn mixtures, it is sufﬁcient to design differentially private list-decodable learning algorithms that work for (corrupted versions of) the individual mixture compo-nents. To devise list-decodable learners for (corrupted) univariate Gaussian, we utilize “stability-based” histograms [15, 51] that satisfy approximate differential privacy.
To design a list-decodable learner for corrupted univariate Gaussians, we follow a three-step approach that is inspired by the seminal work of Karwa and Vadhan [50]. First, we use a histogram to output a list of variances one of which approximates the true variance of the Gaussian. As a second step, we would like to output a list of means which approximate the true mean of the Gaussian. This can be done using histograms provided that we roughly know the variance of the Gaussian. Since we have candidate variances from the ﬁrst step, we can use a sequence of histograms where the width of the bins of each of the histograms is determined by the candidate variances from the ﬁrst step. As a last step, using the candidate variances and means from the ﬁrst two steps, we are able to construct a small set of distributions one of which approximates the true Gaussian to within accuracy α. In the 3
axis-aligned Gaussians setting, we use our solution for the univariate case as a subroutine on each dimension separately. Now that we have a list-decodable learner for axis-aligned Gaussians, we use our reduction to obtain a private learning algorithm for learning mixtures of axis-aligned Gaussians.
Approaches based on constructing lists of candidate variances and means in order to learn an accurate mixture have been previously considered in the non-private setting [5, 6, 23, 61]. However, it does not seem possible to directly privatize the algorithms in this line of work since they construct these candidates directly from the samples, which is a clear violation of privacy. 1.3 Open Problems
The most basic open problem is to understand the exact sample complexity (up to constants) for learning mixtures of univariate Gaussians under approximate differential privacy.
Conjecture 1.5 (Informal). The sample complexity of learning a mixture of k univariate Gaussians to (cid:17)
. within total variation distance α with high probability under (ε, δ)-DP is Θ (cid:16) k
α2 + k
αε + log(1/δ)
ε
Another open question is whether it is possible to privately learn mixtures of (arbitrary) high-dimensional Gaussians. We conjecture that it is possible and with the following sample complexity.
Conjecture 1.6 (Informal). The sample complexity of learning a mixture of k d-dimensional
Gaussians to within total variation distance α with high probability under (ε, δ)-DP is
Θ (cid:16) kd2
α2 + kd2
αε + log(1/δ) (cid:17)
ε
. 1.4 Additional