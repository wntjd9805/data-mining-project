Abstract
Many sequential decision making problems are high-stakes and require off-policy evaluation (OPE) of a new policy using historical data collected using some other policy. One of the most common OPE techniques that provides unbiased estimates is trajectory based importance sampling (IS). However, due to the high variance of trajectory IS estimates, importance sampling methods based on state-action visitation distributions (SIS) have recently been adopted. Unfortunately, while SIS often provides lower variance estimates for long horizons, estimating the state-action distribution ratios can be challenging and lead to biased estimates. In this paper, we present a new perspective on this bias-variance trade-off and show the existence of a spectrum of estimators whose endpoints are SIS and IS. Additionally, we also establish a spectrum for doubly-robust and weighted version of these estimators. We provide empirical evidence that estimators in this spectrum can be used to trade-off between the bias and variance of IS and SIS and can achieve lower mean-squared error than both IS and SIS. 1

Introduction
Many sequential decision making problems, such as automated health-care, robotics, and online recommendations are high-stakes in terms of health, safety, or ﬁnance [Liao et al., 2020, Brown et al., 2020, Theocharous et al., 2020]. For such problems, collecting new data to evaluate the performance of a new decision rule, called an evaluation policy ⇡e, may be expensive or even dangerous if ⇡e results in undesired outcomes. Therefore, one of the most important challenges in such problems is the estimation of the performance J(⇡e) of the policy ⇡e before its deployment.
Many off-policy evaluation (OPE) methods enable estimation of J(⇡e) with historical data collected using an existing decision rule, called a behavior policy ⇡b. One popular OPE technique is trajectory-based importance sampling (IS) [Precup, 2000]. While this method is both non-parametric and provides unbiased estimates of J(⇡e), it suffers from the curse of horizon and can have variance exponential in the horizon length [Jiang and Li, 2016, Guo et al., 2017]. To mitigate this problem, recent methods use stationary distribution importance sampling (SIS) to adjust the stationary distri-bution of the Markov chain induced by the policies, instead of the individual trajectories [Liu et al., 2018, Gelada and Bellemare, 2019, Nachum and Dai, 2020]. This requires (parametric) estimation of the ratio between the stationary distribution induced by ⇡e and ⇡b. Unfortunately, estimating this ratio accurately can require unveriﬁably strong assumptions on the parameters [Jiang and Huang, 2020], and often requires solving non-trivial min-max saddle point optimization problems [Yang et al., 2020]. Consequently, if the parameterization is not rich enough, then it may not be possible to represent the distribution ratios accurately, and when using rich function approximators (such as neural networks) then the optimization procedure may get stuck in sub-optimal saddle points. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
In practice, these challenges can introduce error when estimating the distribution ratio, potentially leading to arbitrarily biased estimates of J(⇡e), even when an inﬁnite amount of data is available.
In this work, we present a new perspective on the bias-variance trade-off for OPE that bridges the unbiasedness of IS and the often lower variance of SIS. Particularly, we show that
• There exists a spectrum of OPE estimators whose end-points are IS and SIS, respectively.
• Estimators in this spectrum can have lower mean-squared error than both IS and SIS.
• This spectrum can also be established for doubly-robust and weighted version of IS and SIS.
In Sections 3 and 4 we show how trajectory-based and distribution-based methods can be combined.
The core idea establishing the existence of this spectrum relies upon ﬁrst splitting individual trajec-tories into two parts and then computing the probability of the ﬁrst part using SIS and IS for the latter. In Section 5, we introduce weighted and doubly-robust extensions of the spectrum. Finally, in
Section 6, we present empirical case studies to highlight the effectiveness of these new estimators. 2