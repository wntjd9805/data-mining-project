Abstract
We provide a ﬁrst-order oracle complexity lower bound for ﬁnding stationary points of min-max optimization problems where the objective function is smooth, nonconvex in the minimization variable, and strongly concave in the maximization variable. We establish a lower bound of Ω (cid:0)√
κ(cid:15)−2(cid:1) for deterministic oracles, where (cid:15) deﬁnes the level of approximate stationarity and κ is the condition number.
Our lower bound matches the best existing upper bound in the (cid:15) and κ dependence up to logarithmic factors. For stochastic oracles, we provide a lower bound of
Ω (cid:0)√
κ(cid:15)−2 + κ1/3(cid:15)−4(cid:1). It suggests that there is a gap between the best existing upper bound O(κ3(cid:15)−4) and our lower bound in the condition number dependence. 1

Introduction
In this paper, we study the oracle complexity lower bound of the following min-max optimization problem: min x∈X max y∈Y f (x; y), (1) where X ⊂ Rm and Y ⊂ Rn are nonempty closed convex sets. Such a problem arises in a wide range of applications, e.g., two-player zero-sum games [38], Generative Adversarial Networks [17], robust optimization [4], including defending adversarial attacks [18, 29].
The research in min-max problems (1) has a long history. If f is linear in both x and y, the problem is known as bilinear min-max optimization, for which von Neumann’s min-max theorem [38] guarantees the existence of a saddle point, a point (x∗, y∗) that satisﬁes strong duality (i.e. min-max equals max-min). Later, Sion [44] generalized the statement to convex-concave functions under certain regularity conditions, which led to the theory of KKT conditions. Aside from studying the existence of strong duality, Nemirovski [33], Nesterov [36] proposed algorithms that can ﬁnd approximate saddle points for convex-concave objectives with an O(1/(cid:15)) convergence rate. The rate was proven to be worst-case optimal even for min-max problems with a bilinear cross-term [41].
Going beyond the assumption of convex-concavity poses a big challenge. In general nonconvex-nonconcave min-max optimization problems, a saddle-point may not exist [22]. Deﬁning a notion of min-max points that is simultaneously nontrivial and tractable is still an open question. If one uses the 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
standard deﬁnition of saddle points as in the strong duality problems, then determining its existence is known to be NP-hard [9], and ﬁnding an approximate local saddle point is PPAD-complete [9].
Alternatively, a relaxed deﬁnition of min-max point known as Stackelberg equilibrium is guaranteed to exist [22], yet only local asymptotic convergence is known [22, 47].
Due to the lack of a well-formulated suboptimality measure for general nonconvex-nonconcave problems, recent research has considered problems with special structures. For example, Lin et al.
[26, 27] studied nonconvex-concave problems, Yang et al. [50] studied problems satisfying the
Polyak-Lojasiewicz inequality, Diakonikolas et al. [11] studied problems with weak Minty variational inequality solutions, Mangoubi and Vishnoi [30] considered an algorithm speciﬁc equilibrium.
Our work focuses on the analysis of gradient oracle complexity in the nonconvex-strongly-concave min-max setting. In the standard convex-concave setup, Lin et al. [27] designed a set of algorithms that achieve near-optimal gradient complexity for all the three variants of convex-concave min-max optimization. However, in the nonconvex-concave setting, it is unclear whether their algorithm is optimal given that no matching lower bound exists. In this work, our main contribution is as follows:
• We construct an explicit example on which no ﬁrst-order zero-respecting algorithm can
κ(cid:15)−2) oracle complexity for smooth nonconvex-strongly-concave
√ achieve less than Ω( problems, matching the ˜O(
√
κ(cid:15)−2) complexity in [27].
• We further extend our results to the stochastic(-oracle) setting, achieving the complexity
κ(cid:15)−2 + κ1/3(cid:15)−4). Compared against the results in [26], our result suggests lower bound Ω( that the dependency on the condition number may not be optimal.
√ 1.1