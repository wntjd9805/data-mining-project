Abstract
Graph Convolutional Networks (GCNs) are known to suffer from performance degradation as the number of layers increases, which is usually attributed to over-smoothing. Despite the apparent consensus, we observe that there exists a discrep-ancy between the theoretical understanding of over-smoothing and the practical capabilities of GCNs. Speciﬁcally, we argue that over-smoothing does not nec-essarily happen in practice, a deeper model is provably expressive, can converge to global optimum with linear convergence rate, and achieve very high training accuracy as long as properly trained. Despite being capable of achieving high training accuracy, empirical results show that the deeper models generalize poorly on the testing stage and existing theoretical understanding of such behavior remains elusive. To achieve better understanding, we carefully analyze the generalization capability of GCNs, and show that the training strategies to achieve high training accuracy signiﬁcantly deteriorate the generalization capability of GCNs. Motivated by these ﬁndings, we propose a decoupled structure for GCNs that detaches weight matrices from feature propagation to preserve the expressive power and ensure good generalization performance. We conduct empirical evaluations on various synthetic and real-world datasets to validate the correctness of our theory. 1

Introduction
In recent years, Graph Convolutional Networks (GCNs) have achieved state-of-the-art performance in dealing with graph-structured applications, including social networks [28, 21, 51, 12, 44], trafﬁc prediction [10, 45, 34, 31], knowledge graphs [52, 53, 43], drug reaction [14, 16] and recommendation system [2, 60]. Despite the success of GCNs, applying a shallow GCN model that only uses the information of a very limited neighborhood on a large sparse graph has shown to be not effective [23, 6, 20, 9, 46]. As a result, a deeper GCN model would be desirable to reach and aggregate information from farther neighbors. The inefﬁciency of shallow GCNs is exacerbated even further when the labeled nodes compared to graph size is negligible, as a shallow GCN cannot sufﬁciently propagate the label information to the entire graph with only a few available labels [35].
Although a deeper GCN is preferred to perceive more graph structure information, unlike traditional deep neural networks, it has been pointed out that deeper GCNs potentially suffer from over-smoothing [35, 41, 26, 4, 58], vanishing/exploding gradients [33], over-squashing [1], and training difﬁculties [62, 38], which signiﬁcantly affect the performance of GCNs as the depth increases.
Among these, the most widely accepted reason is “over-smoothing”, which is referred to as a phenomenon due to applying multiple graph convolutions such that all node embeddings converge to a single subspace (or vector) and leads to indistinguishable node representations.
The conventional wisdom is that adding to the number of layers causes over-smoothing, which impairs the expressiveness power of GCNs and consequently leads to a poor training accuracy. However, we observe that there exists a discrepancy between theoretical understanding of their inherent capabilities 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
Figure 1: Comparison of F1-score for GCN with different depth on Cora dataset, where deeper models can achieve high training accuracy, but complicate the training by requiring more iterations to converge and suffer from poor generalization. and practical performances. According to the deﬁnition of over-smoothing that the node representation becomes indistinguishable as GCNs goes deeper, the classiﬁer has difﬁculty assigning the correct label for each node if over-smoothing happens. As a result, the training accuracy is expected to be decreasing as the number of layers increases. However, as shown in Figure 1, GCNs are capable of achieving high training accuracy regardless of the number of layers. But, as it can be observed, deeper GCNs require more training iterations to reach a high training accuracy, and its generalization performance on evaluation set decreases as the number of layers increases. This observation suggests that the performance degradation is likely due to inappropriate training rather than the low expressive power caused by over-smoothing. Otherwise, a low expressiveness model cannot achieve almost perfect training accuracy simply by proper training tricks alone.1 Indeed, recent years signiﬁcant advances have been witnessed on tweaking the model architecture to overcome the training difﬁculties in deeper GCN models and achieve good generalization performance [38, 6, 33, 62].
Contributions. Motivated by aforementioned observation, i.e., still achieving high training accuracy when trained properly but poor generalization performance, we aim at answering two fundamental questions in this paper:
Q1: Does increasing depth really impair the expressiveness power of GCNs?
In Section 4, we argue that there exists a discrepancy between over-smoothing based theoretical results and the practical capabilities of deep GCN models, demonstrating that over-smoothing is not the key factor that leads to the performance degradation in deeper GCNs. In particular, we mathematically show that over-smoothing [41, 26, 35, 4] is mainly an artifact of theoretical analysis and simpliﬁcations made in analysis. Indeed, by characterizing the representational capacity of GCNs via Weisfeiler-Lehman (WL) graph isomorphism test [39, 55], we show that deeper GCN model is at least as expressive as the shallow GCN model, the deeper GCN models can distinguish nodes with a different neighborhood that the shallow GCN cannot distinguish, as long as the GCNs are properly trained. Besides, we theoretically show that more training iterations is sufﬁcient (but not necessary due to the assumptions made in our theoretical analysis) for a deeper model to achieve the same training error as the shallow ones, which further suggests the poor training error in deep GCN training is most likely due to inappropriate training.
Q2: If expressive, why then deep GCNs generalize poorly?
In Section 5, in order to understand the performance degradation phenomenon in deep GCNs during the evaluation phase, we give a novel generalization analysis on GCNs and its variants (e.g., ResGCN,
APPNP, and GCNII) under the semi-supervised setting for the node classiﬁcation task. We show that the generalization gap of GCNs is governed by the number of training iterations, largest node degree, the largest singular value of weight matrices, and the number of layers. In particular, our result suggests that a deeper GCN model requires more iterations of training and optimization tricks to converge (e.g., adding skip-connections), which leads to a poor generalization. More interestingly, our generalization analysis shows that most of the so-called methods to solve over-smoothing [47, 61, 6, 29] can greatly improve the generalization ability of the model, therefore results in a deeper model. 1The results in Figure 1 can be reproduced by removing both the dropout and weight decay operation. These two augmentations are designed to improve the generalization ability (i.e., validation/testing accuracy) of the model but might hurt the training accuracy, because of the randomness and also an extra regularization term on the model parameters which are introduced during training. A simple experiment using DGL can be found here. 2
The aforementioned ﬁndings naturally lead to the algorithmic contribution of this paper. In Section 6, we present a novel framework, Decoupled GCN (DGCN), that is capable of training deeper GCNs and can signiﬁcantly improve the generalization performance. The main idea is to isolate the expressive power from generalization ability by decoupling the weight parameters from feature propagation. In
Section 7, we conduct experiments on the synthetic and real-world datasets to validate the correctness of the theoretical analysis and the advantages of DGCN over baseline methods. 2