Abstract
There are two types of deep generative models: explicit and implicit. The former deﬁnes an explicit density form that allows likelihood inference; while the latter targets a ﬂexible transformation from random noise to generated samples. While the two classes of generative models have shown great power in many applications, both of them, when used alone, suffer from respective limitations and drawbacks.
To take full advantages of both models and enable mutual compensation, we propose a novel joint training framework that bridges an explicit (unnormalized) density estimator and an implicit sample generator via Stein discrepancy. We show that our method 1) induces novel mutual regularization via kernel Sobolev norm penalization and Moreau-Yosida regularization, and 2) stabilizes the training dynamics. Empirically, we demonstrate that proposed method can facilitate the density estimator to more accurately identify data modes and guide the generator to output higher-quality samples, comparing with training a single counterpart.
The new approach also shows promising results when the training samples are contaminated or limited. 1

Introduction
Deep generative model, as a powerful unsupervised framework for learning the distribution of high-dimensional multi-modal data, has been extensively studied in recent literature. Typically, there are two types of generative models: explicit and implicit. Explicit models deﬁne a density function of the distribution [35, 51, 42], while implicit models learn a mapping that generates samples by transforming an easy-to-sample random variable [15, 39, 2, 4].
Both models have their own power and limitations. The density form in explicit models endows them with convenience to characterize data distribution and infer the sample likelihood. However, the unknown normalizing constant often causes computational intractability. On the other hand, implicit models including generative adversarial networks (GANs) can directly generate vivid samples in various application domains including images, natural languages, graphs, etc. Nevertheless, one important challenge is to design a training algorithm that do not suffer from instability and mode collapse. In view of this, it is natural to build a uniﬁed framework that takes full advantages of the two models and encourages them to compensate for each other.
Intuitively, an explicit density estimator and a ﬂexible implicit sampler could help each other’s training given effective information sharing. On the one hand, the density estimation given by explicit
⇤Part of the work was done when the two authors were visiting The Chinese University of Hong Kong,
Shenzhen. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
models can be a good metric that measures quality of samples [6], and thus can be used for scoring generated samples given by implicit model or detecting outliers as well as noises in input true samples
[53]. On the other hand, the generated samples from implicit models could augment the dataset and help to alleviate mode collapse especially when true samples are insufﬁcient that would possibly make explicit model fail to capture an accurate distribution. We refer to Appendix A for a more comprehensive literature review.
Motivated by the discussions above, in this paper, we propose a joint learning framework that enables mutual calibration between explicit and implicit generative models. In our framework, an explicit model is used to estimate the unnormalized density; in the meantime, an implicit generator model is exploited to minimize certain statistical distance (such as the Wasserstein metric or Jensen-Shannon divergence) between the distributions of the true and the generated samples. On top of these two models, a Stein discrepancy, acting as a bridge between generated samples and estimated densities, is introduced to push the two models to achieve a consensus. Unlike ﬂow-based models [36, 26], our formulation does not impose invertibility constraints on the generative models and thus is ﬂexible in utilizing general neural network architectures. Our main contributions are as follows: i) Theoretically, we prove that our method allows the two generative models to impose novel mutual regularization on each other. Speciﬁcally, our formulation penalizes large kernel Sobolev norm of the critic in the implicit (WGAN) model, which ensures the critic not to change suddenly on the high-density regions and thus preventing the critic of the implicit model being too strong during training. In the mean time, our formulation also smooths the function given by the Stein discrepancy through Moreau-Yosida regularization, which encourages the explicit model to seek more modes in the data distribution and thus alleviates mode collapse. ii) In addition, we show that our joint training helps to stabilize the training dynamics. Compared with other common regularization approaches for GAN models that may shift original optimum, our method can facilitate convergence to unbiased model distribution. iii) We conduct comprehensive experiments to justify our theoretical ﬁndings and demonstrate that joint training can help two models achieve better performance. On the one hand, the energy model can detect complicated modes in data more accurately and distinguish out-of-distribution samples.
On the other hand, the implicit model can generate higher-quality samples. 2