Abstract
Estimating personalized treatment effects from high-dimensional observational data is essential in situations where experimental designs are infeasible, unethical, or expensive. Existing approaches rely on ﬁtting deep models on outcomes observed for treated and control populations. However, when measuring individual outcomes is costly, as is the case of a tumor biopsy, a sample-efﬁcient strategy for acquiring each result is required. Deep Bayesian active learning provides a framework for efﬁcient data acquisition by selecting points with high uncertainty. However, existing methods bias training data acquisition towards regions of non-overlapping support between the treated and control populations. These are not sample-efﬁcient because the treatment effect is not identiﬁable in such regions. We introduce causal, Bayesian acquisition functions grounded in information theory that bias data acquisition towards regions with overlapping support to maximize sample efﬁciency for learning personalized treatment effects. We demonstrate the performance of the proposed acquisition strategies on synthetic and semi-synthetic datasets IHDP and
CMNIST and their extensions, which aim to simulate common dataset biases and pathologies. 1

Introduction
How will a patient’s health be affected by taking a medication [37]? How will a user’s question be answered by a search recommendation [34]? We can gain insight into these questions by learning about personalized treatment effects. Estimating personalized treatment effects from observational data is essential when experimental designs are infeasible, unethical, or expensive. Observational data represent a population of individuals described by a set of pre-treatment covariates (age, blood pressure, socioeconomic status), an assigned treatment (medication, no medication), and a post-treatment outcome (severity of migraines). An ideal personalized treatment effect is the difference between the post-treatment outcome if the individual receives treatment and the post-treatment outcome if they do not receive treatment. However, it is impossible to observe both outcomes for an individual; therefore, the difference is estimated between populations instead. In the setting of binary treatments, data belong to either the treatment group (individuals that received the treatment) or the control group (individuals who did not). The personalized treatment effect is the expected difference
∗Equal contribution. Correspondence to {andrew.jesson, panagiotis.tigas}@cs.ox.ac.uk 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
in outcomes between treated and controlled individuals who share the same (or similar) measured covariates; as an illustration, see the difference between the solid lines in Fig. 1 (middle pane).
The use of pre-treatment covariates assembled from high-dimensional, heterogeneous measurements such as medical images and electronic health records is increasing [44]. Deep learning methods have been shown capable of learning personalized treatment effects from such data [42, 43, 21]. However, a problem in deep learning is data efﬁciency. While modern methods are capable of impressive performance, they need a signiﬁcant amount of labeled data. Acquiring labeled data can be expensive, requiring specialist knowledge or an invasive procedure to determine the outcome. Therefore, it is desirable to minimize the amount of labeled data needed to obtain a well-performing model. Active learning provides a principled framework to address this concern [8]. In active learning for treatment effects [10, 45, 39] a model is trained on available labeled data consisting of covariates, assigned treatments, and acquired outcomes. The model predictions decide the most informative examples from data comprised of only covariates and treatment indicators. Outcomes are acquired, e.g., by performing a biopsy for the selected patients, and the model is retrained and evaluated. This process repeats until either a satisfactory performance level is achieved or the labeling budget is exhausted.
At ﬁrst sight, this might seem simple; however, active learning induces biases that result in divergence between the distribution of the acquired training data and the distribution of the pool set data [13]. In the context of learning causal effects, such bias can have both positive and negative consequences.
For example, while random acquisition active learning results in an unbiased sample of the training data, we demonstrate how it can lead to over-allocation of resources to the mode of the data at the expense of learning about underrepresented data. Conversely, while biasing acquisitions toward lower density regions of the pool data can be desirable, it can also lead to outcome acquisition for data with unidentiﬁable treatment effects, which leads to uninformed, potentially harmful, personalized recommendations.
To see how training data bias can beneﬁt treatment effect estimation, consider one difference between experimental and observational data: the treatment assignment mechanism is unavailable for observa-tional data. In observational data, variables that af-fect treatment assignment (an untestable condition) may be unobserved. Moreover, the relative propor-tion of treated to controlled individuals varies across different sub-populations of the data. Fig. 1 illus-trates the latter point, where there are relatively equal proportions of treated and controlled examples for data in region 3. However, the proportions become less balanced as we move to either the left or the right. In extreme cases, say if a group described by some covariate values were systematically excluded from treatment, the treatment effect for that group cannot be known [38]. Fig. 1 illustrates this in re-gion 1, where only controlled examples reside, and in region 5, where only treated cases occur. In the language of causal inference, the necessity of seeing both treated and untreated examples for each sub-population corresponds to satisfying the overlap (or positivity) assumption (see 2.3). The data available in the pool set limits overlap when treatments cannot be assigned. In this setting, regions 2 and 4 of Fig. 1 are very interesting because while either the treated or control group are underrepresented, there may still be sufﬁcient coverage to estimate treatment effects. D’Amour and Franks [9] have described such regions as having weak overlap. Training data bias towards such regions can beneﬁt treatment effect estimation for underrepresented data by acquiring low-frequency data with sufﬁcient overlap.
Figure 1: Observational data. Top: data density of treatment (right) and control (left) groups. Middle: observed outcome re-sponse for treatment (circles) and control (x’s) groups. Bottom: data density for active learned training set after a number of acquisi-tion steps.
We hypothesize that the efﬁcient acquisition of unlabeled data for treatment effect estimation focuses on only exploring regions with sufﬁcient overlap, and uncertainty should be high for areas with non-overlapping support. The bottom pane of Fig. 1 imagines what a resulting training set distribution 2
could look like at an intermediate active learning step. It is not trivial to design such acquisition functions: naively applying active learning acquisition functions results in suboptimal and sample inefﬁcient acquisitions of training examples, as we show below. To this end, we develop epistemic uncertainty-aware methods for active learning of personalized treatment effects from high dimensional observational data. In contrast to previous work that uses only information gain as the acquisition objective, we propose ρBALD and µρBALD as “Causal BALD” objectives because they consider both the information gain and overlap between treated and control groups. We demonstrate the performance of the proposed acquisition strategies using synthetic and semi-synthetic datasets. 2