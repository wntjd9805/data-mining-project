Abstract
Convolutional networks are ubiquitous in deep learning. They are particularly useful for images, as they reduce the number of parameters, reduce training time, and increase accuracy. However, as a model of the brain they are seriously prob-lematic, since they require weight sharing – something real neurons simply cannot do. Consequently, while neurons in the brain can be locally connected (one of the features of convolutional networks), they cannot be convolutional. Locally connected but non-convolutional networks, however, signiﬁcantly underperform convolutional ones. This is troublesome for studies that use convolutional networks to explain activity in the visual system. Here we study plausible alternatives to weight sharing that aim at the same regularization principle, which is to make each neuron within a pool react similarly to identical inputs. The most natural way to do that is by showing the network multiple translations of the same image, akin to saccades in animal vision. However, this approach requires many translations, and doesn’t remove the performance gap. We propose instead to add lateral connectivity to a locally connected network, and allow learning via Hebbian plasticity. This re-quires the network to pause occasionally for a sleep-like phase of “weight sharing”.
This method enables locally connected networks to achieve nearly convolutional performance on ImageNet and improves their ﬁt to the ventral stream data, thus supporting convolutional networks as a model of the visual stream. 1

Introduction
Convolutional networks are a cornerstone of modern deep learning: they’re widely used in the visual domain [1, 2, 3], speech recognition [4], text classiﬁcation [5], and time series classiﬁcation [6].
They have also played an important role in enhancing our understanding of the visual stream [7].
Indeed, simple and complex cells in the visual cortex [8] inspired convolutional and pooling layers in deep networks [9] (with simple cells implemented with convolution and complex ones with pooling).
Moreover, the representations found in convolutional networks are similar to those in the visual stream [10, 11, 12, 13] (see [7] for an in-depth review).
Despite the success of convolutional networks at reproducing activity in the visual system, as a model of the visual system they are somewhat problematic. That’s because convolutional networks share weights, something biological networks, for which weight updates must be local, can’t do [14].
Locally connected networks avoid this problem by using the same receptive ﬁelds as convolutional networks (thus locally connected), but without weight sharing [15]. However, they pay a price locally connected networks are known to perform worse than their for biological plausibility: 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
convolutional counterparts on hard image classiﬁcation tasks [15, 16]. There is, therefore, a need for a mechanism to bridge the gap between biologically plausible locally connected networks and implausible convolutional ones.
Here, we consider two such mechanisms. One is to use extensive data augmentation (primarily image translations); the other is to introduce an auxiliary objective that allows some form of weight sharing, which is implemented by lateral connections; we call this approach dynamic weight sharing.
The ﬁrst approach, data augmentation, is simple, but we show that it suffers from two problems: it requires far more training data than is normally used, and even then it fails to close the performance gap between convolutional and locally connected networks. The second approach, dynamic weight sharing, implements a sleep-like phase in which neural dynamics facilitate weight sharing. This is done through lateral connections in each layer, which allows subgroups of neurons to share their activity. Through this lateral connectivity, each subgroup can ﬁrst equalize its weights via anti-Hebbian learning, and then generate an input pattern for the next layer that helps it to do the same thing. Dynamic weight sharing doesn’t achieve perfectly convolutional connectivity, because in each channel only subgroups of neurons share weights. However, it implements a similar inductive bias, and, as we show in experiments, it performs almost as well as convolutional networks, and also achieves better ﬁt to the ventral stream data, as measured by the Brain-Score [12, 17].
Our study suggests that convolutional networks may be biologically plausible, as they can be approximated in realistic networks simply by adding lateral connectivity and Hebbian learning. As convolutional networks and locally connected networks with dynamic weight sharing have similar performance, convolutional networks remain a good “model organism” for neuroscience. This is important, as they consume much less memory than locally connected networks, and run much faster. 2