Abstract
Autoregressive models and their sequential factorization of the data likelihood have recently demonstrated great potential for image representation and synthesis.
Nevertheless, they incorporate image context in a linear 1D order by attending only to previously synthesized image patches above or to the left. Not only is this unidirectional, sequential bias of attention unnatural for images as it disregards large parts of a scene until synthesis is almost complete. It also processes the entire image on a single scale, thus ignoring more global contextual information up to the gist of the entire scene. As a remedy we incorporate a coarse-to-ﬁne hierarchy of context by combining the autoregressive formulation with a multinomial diffusion process: Whereas a multistage diffusion process successively removes information to coarsen an image, we train a (short) Markov chain to invert this process. In each stage, the resulting autoregressive ImageBART model progressively incor-porates context from previous stages in a coarse-to-ﬁne manner. Experiments show greatly improved image modiﬁcation capabilities over autoregressive models while also providing high-ﬁdelity image generation, both of which are enabled through efﬁcient training in a compressed latent space. Speciﬁcally, our approach can take unrestricted, user-provided masks into account to perform local image editing. Thus, in contrast to pure autoregressive models, it can solve free-form image inpainting and, in the case of conditional models, local, text-guided image modiﬁcation without requiring mask-speciﬁc training. 1

Introduction
Spurred by the increasingly popular attention mechanism, a remarkably simple principle has driven progress in deep generative modeling over the past few years: Factorizing the likelihood of the data in an autoregressive (AR) fashion p(x) = (cid:89) i pθ(xi|x<i) (1) and subsequently learning the conditional transition probabilities with an expressive neural network such as a transformer [75]. The success of this approach is evident in domains as diverse as language modeling [7], music generation [16], neural machine translation [46, 76], and (conditional) image synthesis [54, 8]. However, especially for the latter task of image synthesis, which is also the focus of this work, the high dimensionality and redundancy present in the data challenges the direct applicability of this approach.
Missing Bidirectional Context Autoregressive models which represent images as a sequence from the top-left to the bottom-right have demonstrated impressive performance in sampling novel images and completing the lower half of a given image [8, 21]. However, the unidirectional, ﬁxed ordering
∗The ﬁrst three authors contributed equally to this work. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
of sequence elements not only imposes a perceptually unnatural bias to attention in images by only considering context information from left or above. It also limits practical applicability to image modiﬁcation: Imagine that you only have the lower half of an image and are looking for a completion of the upper half then these models fail at this minor variation of the completion task.
The importance of contextual information from both directions [36] has also been recognized in the context of language modeling [14, 45]. However, simply allowing bidirectional context as in [14] does not provide a valid factorization of the density function for a generative model. Furthermore, the sequential sampling strategy introduces a gap between training and inference, as training relies on so-called teacher-forcing [3] (where ground truth is provided for each step) and inference is performed on previously sampled tokens. This exposure bias can introduce signiﬁcant accumulations of errors during the generation process, affecting sample quality and coherence [57].
Global Context & Control via Multinomial Diffusion We propose a coarse-to-ﬁne approach that addresses the unidirectional bias of generative autoregressive models and their exposure bias as well as the lacking global context. We formulate learning the data density as a hierarchical problem. A coarser stage provides compressed contextual side information about the entire image for the autoregressive process on the next ﬁner stage. We utilize a diffusion process to gradually eliminate information and compress the data, yielding a hierarchy of increasingly abstract and compact representations.
The ﬁrst scale of this approach is a discrete representation learning task (cf. [74, 58, 16, 21, 78, 56]).
Subsequently, we further compress this learned representation via a ﬁxed, multinomial diffusion process [65, 30]. We then invert this process by training a Markov chain to recover the data from this hierarchy. Each Markovian transition is modeled autoregressively but it simultaneously attends to the preceding state in the hierarchy, which provides crucial global context to each individual autoregressive step. As each of this steps can also be interpreted as learning a denoising cloze task
[45], where missing tokens at the next ﬁner stage are “reﬁlled” with a bidirectional encoder and an autoregressive decoder, we dub our approach ImageBART.
Contributions of our work Our approach tackles high-ﬁdelity image synthesis with autoregressive models by learning to invert a ﬁxed multinomial diffusion process in a discrete space of compact image representations to successively introduce context. This reduces both the often encountered exposure bias of AR models and also enables locally controlled, user-interactive image editing.
Additionally, our model effectively handles a variety of conditional synthesis tasks and our introduced hierarchy corresponds to a successively compressed image representation. We observe that our model sample visually plausible images while still enabling a trade-off between reconstruction capability and compression rate. 2