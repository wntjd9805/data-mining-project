Abstract 3D pose transfer is one of the most challenging 3D generation tasks. It aims to transfer the pose of a source mesh to a target mesh and keep the identity (e.g., body shape) of the target mesh. Some previous works require key point annotations to build reliable correspondence between the source and target meshes, while other methods do not consider any shape correspondence between sources and targets, which leads to limited generation quality. In this work, we propose a correspondence-reﬁnement network to achieve the 3D pose transfer for both human and animal meshes. The correspondence between source and target meshes is ﬁrst established by solving an optimal transport problem. Then, we warp the source mesh according to the dense correspondence and obtain a coarse warped mesh.
The warped mesh will be better reﬁned with our proposed Elastic Instance Normal-ization, which is a conditional normalization layer and can help to generate high-quality meshes. Extensive experimental results show that the proposed architecture can effectively transfer the poses from source to target meshes and produce better results with satisﬁed visual performance than state-of-the-art methods. Our code and data are available at https://github.com/ChaoyueSong/3d-corenet.

Introduction 1 3D pose transfer has been drawing a lot of attention from the vision and graphics community. It has potential applications in 3D animated movies and games by generating new poses for existing shapes and animation sequences. 3D pose transfer is a learning-driven generation task which is similar to style transfer on 2D images. As shown in Figure 1, pose transfer takes two inputs, one is identity mesh that provides mesh identity (e.g., body shape), the other is pose mesh that provides the pose of mesh. It aims at transferring the pose of a source pose mesh to a target identity mesh and keeping the identity of the target identity mesh.
A fundamental problem for previous methods is to build reliable correspondence between source and target meshes. It can be very challenging when the source and target meshes have signiﬁcant differences. Most of the previous methods try to solve it with the help of user effort or other additional inputs, such as key point annotations [3, 34, 41], etc. Unfortunately, it is time-consuming to obtain such additional inputs that will limit the usage in practice. In [37], they proposed to implement pose transfer without correspondence learning. Their method is convenient but the performance will be degraded since they do not consider the correspondence between meshes. In this work, we propose a COrrespondence-REﬁnement Network (3D-CoreNet) to solve the pose transfer problem for both the human and animal meshes. Like [37], our method does not need key point annotations or other
∗Corresponding author 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
Figure 1: Pose transfer results generated by our 3D-CoreNet. In the ﬁrst two rows, the human identity and pose meshes are from SMPL [23], in the last two rows, the animal identity and pose meshes are from SMAL [46]. additional inputs. We learn the shape correspondence between identity and pose meshes ﬁrst, then we warp the pose mesh to a coarse warped output according to the correspondence. Finally, the warped mesh will be reﬁned to have a better visual performance. Our method does not require the two meshes to have the same number or order of vertices.
For the correspondence learning module, we treat the shape correspondence learning as an optimal transport problem to learn the correspondence between meshes. Our network takes vertex coordinates of identity and pose meshes as inputs. We extract deep features at each vertex using point cloud convolutions and compute a matching cost between the vertex sets with the extracted features. Our goal is to minimize the matching cost to get an optimal matching matrix. With the optimal matching matrix, we warp the pose mesh and obtain a coarse warped mesh. We then reﬁne the warped output with a set of elastic instance normalization residual blocks, the modulation parameters in the normalization layers are learned with our proposed Elastic Instance Normalization (ElaIN). In order to generate smoother meshes with more details, we introduce a channel-wise weight in ElaIN to adaptively blend feature statistics of original features and the learned parameters from external data, which help to keep the consistency and continuity of the original features.
Our contributions can be summarized as follows:
• We solve the 3D pose transfer problem with our proposed correspondence-reﬁnement network.
To the best of our knowledge, our method is the ﬁrst to learn the correspondence between different meshes and reﬁne the generated meshes jointly in the 3D pose transfer task.
• We learn the shape correspondence by solving an optimal transport problem without any key point annotations and generate high-quality ﬁnal meshes with our proposed elastic instance normalization in the reﬁnement module.
• Through extensive experiments, we demonstrate that our method outperforms state-of-the-art methods quantitatively and qualitatively on both human and animal meshes. 2
2