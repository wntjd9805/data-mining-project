Abstract
Multi-task learning aims to explore task relatedness to improve individual tasks, which is of particular signiﬁcance in the challenging scenario that only limited data is available for each task. To tackle this challenge, we propose variational multi-task learning (VMTL), a general probabilistic inference framework for learning multiple related tasks. We cast multi-task learning as a variational Bayesian inference problem, in which task relatedness is explored in a uniﬁed manner by specifying priors. To incorporate shared knowledge into each task, we design the prior of a task to be a learnable mixture of the variational posteriors of other related tasks, which is learned by the Gumbel-Softmax technique. In contrast to previous methods, our
VMTL can exploit task relatedness for both representations and classiﬁers in a principled way by jointly inferring their posteriors. This enables individual tasks to fully leverage inductive biases provided by related tasks, therefore improving the overall performance of all tasks. Experimental results demonstrate that the proposed VMTL is able to effectively tackle a variety of challenging multi-task learning settings with limited training data for both classiﬁcation and regression.
Our method consistently surpasses previous methods, including strong Bayesian approaches, and achieves state-of-the-art performance on ﬁve benchmark datasets. 1

Introduction
Multi-task learning [8] exploits knowledge shared among related tasks to improve their overall performance. This is especially signiﬁcant when only limited data is available for each task. The central goal in multi-task learning is to explore task relatedness to improve each individual task [2, 54], which is non-trivial since the underlying relationships among tasks can be complicated and highly nonlinear [52]. Early works deal with this by learning shared features, designing regularizers imposed on parameters [37, 24, 23, 21] or exploring priors over parameters [20, 3, 48, 53, 54]. Recently, multi-task deep neural networks have been developed, learning shared representations in the feature layers while keeping classiﬁer layers independent [33, 38, 55, 31]. Some methods [32, 25, 9, 14] learn a small number of related tasks based on one shared input. However, lots of training data is usually available. Few-shot learning [12] addresses multi-task learning with limited data, but usually relies on a large number of related tasks. Further, in general, most existing works explore either representations or classiﬁers for shared knowledge, leaving exploring them jointly an open problem.
In this work, we tackle the following challenging multi-task learning setting [33]: each task contains very limited training data and only a handful of related tasks are available to gain shared knowledge from. In addition, instead of sharing the same input, each of the multiple tasks has its own input space from a different domain and these tasks are related by sharing the same target space, e.g., the same class labels in classiﬁcation tasks. In this setting, it is difﬁcult to learn a proper model for each task independently without overﬁtting [33, 52]. It is therefore crucial to leverage the inductive bias [4] provided by related tasks learned simultaneously. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
To address this, we propose variational multi-task learning (VMTL), a novel variational Bayesian inference approach that can explore task relatedness in a uniﬁed way. Speciﬁcally, as shown in Fig. 1, we develop a probabilistic latent variable model by treating both the feature repre-sentation and the classiﬁer as latent variables. To explore task relatedness, we place condi-tional priors over the latent variables, which are dependent on data from other related tasks.
By doing so, multi-task learning is cast as the joint variational inference of feature representa-tions and classiﬁers for all tasks in a single uniﬁed framework. The probabilistic framework enables the model to better capture the uncertainty caused by limited data in each task [13].
To leverage the knowledge provided by related tasks, we propose to specify the priors of each task as a mixture of the variational posteriors of other tasks. In particular, the mixing weights are constructed with the Gumbel-Softmax tech-nique [22] and jointly learned with the probabilis-tic modeling parameters by back-propagation.
The obtained Gumbel-Softmax priors enable the model to effectively explore different correlation patterns among tasks and, more importantly, pro-vide a uniﬁed way to explore shared knowledge jointly for representations and classiﬁers. We val-idate the effectiveness of the proposed VMTL by extensive evaluation on ﬁve multi-task learning benchmarks with limited data for both classiﬁ-cation and regression. The results demonstrate the beneﬁt of variational Bayesian inference for modeling multi-task learning. VMTL consis-tently achieves state-of-the-art performance and surpasses previous methods on all tasks.
Fig. 1: A graphical illustration of the proposed model for multi-task learning. (xt,n, yt,n) is the n-th sample from task t. wt and zt,n are the intro-duced latent variables, i.e., a classiﬁer/regressor and representation, respectively, whose priors are conditioned on the data from other tasks, D1:T \t. 2 Methodology
Consider a set of T related tasks, each of which is a classiﬁcation or regression problem. Tasks in this paper share the same label space for classiﬁcation or the same target space for regression but have different distributions. Each task t has its own training data Dt = {xt,n, yt,n}Nt n=1, where Nt is the number of training samples. We consider the challenging setting where each task has limited labeled data, which makes it difﬁcult to learn a proper model for each task independently [33, 52].
In contrast to most previous works, we will explore the knowledge shared among tasks for learning both the classiﬁers/regressors and representations of each task. Note that in this section we derive our methodology mainly using terminologies related to classiﬁcation tasks, but it is also applicable to regression tasks. 2.1 Variational Multi-Task Learning
To better capture uncertainty caused by limited data, we explore multi-task learning in a probabilistic framework. We deﬁne the conditional predictive distribution: p(Yt|Xt, D1:T \t) with respect to the current task Dt: Yt = {yt,n}Nt n=1, where we use D1:T \t to denote the data from all tasks excluding Dt of task t. From a probabilistic perspective, jointly learning multiple tasks amounts to maximizing the conditional predictive log-likelihood as follows: n=1 and Xt = {xt,n}Nt 1
T
T (cid:88) t=1 log p(Yt|Xt, D1:T \t) = 1
T
T (cid:88)
Nt(cid:88) t=1 n=1 log p(yt,n|xt,n, D1:T \t). (1)
We condition the prediction for samples in each task on the data of other tasks, D1:T \t, to leverage the shared knowledge from related tasks.
The probabilistic multi-task learning formalism in (1) provides a general framework to explore task re-latedness by conditioning on other tasks. More importantly, it enables the model to incorporate shared knowledge from related tasks into the learning of both the classiﬁer and the feature representation in a uniﬁed way by specifying their priors. 2
We introduce the latent variables wt and zt,n to represent the classiﬁer and the latent representation of the sample xt,n, respectively. The joint distribution for the task t can be factorized as p(Yt, Zt, wt|Xt, D1:T \t) =
Nt(cid:89) n=1 p(yt,n|zt,n, wt)p(zt,n|xt,n, D1:T \t)p(wt|D1:T \t), (2) where we use Zt = {zt,n}Nt n=1 to collectively represent the set of latent representations of samples in task t. Here, we specify conditional priors dependent on other tasks to explore task relatedness. The probabilistic latent variables capture uncertainties at different levels: zt,n captures the uncertainty of each sample, while wt works at the categorical level. A graphical illustration of the probabilistic latent variable model is shown in Fig. 1.
Solving the model for multi-task learning involves inferring the true joint posterior p(Zt, wt|D1:T ) over all latent variables Zt and wt, which is generally intractable. We introduce a variational joint distribution q(Zt, wt|Dt) for the current task to approximate the true posterior. Also under the conditional independence assumption, the joint variational posterior distribution can be factorized with respect to classiﬁers and latent representations as follows: q(Zt, wt|Dt) = qθ(wt|Dt)
Nt(cid:89) n=1 qφ(zt,n|xt,n), (3) where qθ(wt|Dt) and qφ(zt,n|xt,n) are variational posterior distributions for classiﬁers and latent representations respectively, and θ and φ are the associated parameters. For computational feasibility, they are deﬁned as fully factorized Gaussians, as is common practice [28, 5].
To obtain a good approximation, the variational posterior should be close to the true posterior. This is usually achieved by minimizing the Kullback-Leibler (KL) divergence between them:
DKL (cid:2)q(Zt, wt|Dt)||p(Zt, wt|D1:T )(cid:3). (4)
By applying Bayes’ rule to the true posterior, we derive the evidence lower-bound (ELBO) with the probabilistic classiﬁer and representation for the conditional predictive log-likelihood in (1) : 1
T
T (cid:88) t=1 log p(Yt|Xt, D1:T \t) ≥ 1
T
T (cid:88) (cid:26) Nt(cid:88) t=1 n=1 (cid:110)
Ewt∼qθ
Ezt,n∼qφ[log p(yt,n|zt,n, wt)]
−DKL[qφ(zt,n|xt,n)||p(zt,n|xt,n, D1:T \t)] (cid:111)
− DKL (cid:27) (cid:2)qθ(wt|Dt)||p(wt|D1:T \t)(cid:3)
. (5)
The objective function provides a general probabilistic inference framework for multi-task learning.
As priors naturally serve as regularizations in Bayesian inference, they offer a uniﬁed way of sharing information across multiple tasks for improving both classiﬁers and representations. The detailed derivation is given in the supplementary materials.
In what follows, we will describe the speciﬁcation of the prior distributions over the classiﬁer and the representation, as well as their variational posterior distributions. 2.2 Learning Task Relatedness via Gumbel-Softmax Priors
The proposed variational multi-task inference framework enables related tasks to provide supportive information for the current task through the conditional priors of the latent variables. It offers a uniﬁed way to incorporate shared knowledge from related tasks into the inference of representations and classiﬁers for individual tasks.
Classiﬁers To leverage the shared knowledge, we propose to specify the prior of the classiﬁer for the current task using the variational posteriors over classiﬁers of other tasks: p(w(η) t
|D1:T \t) :=
αtiqθ(w(η−1) i
|Di), (cid:88) i(cid:54)=t (6) where η denotes the η-th iteration. In practice, to avoid entanglement among tasks, we deﬁne the prior of task t in the current iteration to be a combination of the variational posteriors [40] of the remaining 3
tasks from the last iteration. Particularly, our designed prior resembles the empirical Bayesian prior
[20, 3, 46, 44] in that the prior of each task is speciﬁed by the observed data of other tasks, which provides a principled way to explore the shared knowledge among multiple tasks.
During training, we aim to have each task learn more shared knowledge from its most relevant tasks, while maximally reducing the interference from irrelevant tasks. To this end, we adopt the
Gumbel-Softmax technique learn the mixing weights for all related tasks and deﬁne the mixing weights as follows:
αti = (cid:80) exp((log πti + gti)/τ ) i(cid:54)=t exp((log πti + gti)/τ ))
. (7)
Here αti is the mixing weight that indicates the relatedness between tasks t and i. πti is the learnable parameter in the Gumbel-Softmax formulation, which denotes the probability of two tasks transferring positive knowledge. gti is sampled from a Gumbel distribution, using inverse transform sampling by drawing u ∼ Uniform(0, 1) and computing g = − log(− log(u)). τ is the softmax temperature.
By using the Gumbel-Softmax technique, our model effectively handles possible negative transfer between tasks. The Gumbel-Softmax technique encourages the model to reduce the interference from the less relevant tasks by minimizing the corresponding mixing weights. The more negative the effects of interference between pairwise tasks are, the smaller the mixing weight is likely to be.
With respect to the inference of the variational posteriors, we deﬁne them as fully factorized Gaussians for each class independently: qθ(wt|Dt) =
C (cid:89) c=1 qθ(wt,c|Dt,c) =
C (cid:89) c=1
N (µt,c, diag(σ2 t,c)). (8) t,c can be directly learned with back-propagation [5]. where µt,c and σ2
As an alternative to direct inference, classiﬁers can also be inferred by the amortization technique [17], which will further reduce the computational cost. In particular, different classes share the inference network to generate the parameters of the speciﬁc classiﬁer. In practice, the inference network takes the mean of the feature representations in each class as input and returns the parameters µt,c and
σt,c for wt,c. The amortized classiﬁer inference enables the cost to be shared across classes, which reduces the overall cost. Therefore, it offers an effective way to handle scenarios with a large number of object classes and can still produce competitive performance, as shown in our experiments, even in the presence of the amortization gap [10].
Representations a sample xt,n as a mixture of distributions conditioned on the data of every other task, as follows: (cid:88)
In a similar way to (6), we specify the prior over the latent representation zt,n of p(z(η) t,n|xt,n, D1:T \t) :=
βtiqφ(z(η−1) t,n
|xt,n, Di). (9) i(cid:54)=t
Here, β is the mixing weight which is deﬁned in a similar way as in (7). The conditional distribution qφ(zt,n|xt,n, Di) on the right hand side of (9) indicates that we leverage the data Di from every other task i to help the model infer the latent representation of xt,n. The contribution of each other task is determined by the learnable mixing weight. In practice, the distribution qφ(zt,n|xt,n, Di) is inferred by an amortized network [15, 28]. To be more speciﬁc, the inference network takes an aggregated representation of xt,n and Di as input and returns the parameters of distribution qφ. The aggregated representation is formulated as (10) which is established by the cross attention mechanism [26]. The sample xt,n from the current task acts as a query, and Di,c plays the roles of the key and the value.
Di,c includes samples from the i-th task, which have the same label as xt,n. This is formulated as: f (xt,n, Di) = DotProduct(xt,n, Di,c, Di,c) := softmax( xt,nD(cid:62) i,c√ d
)Di,c, (10) where f is the aggregation function, and Di,c is a matrix, with each row containing a sample from class c of the i-th related task. d is the dimension of the input feature. Since we are dealing with supervised learning in this work, class labels of training samples are always available at training time.
The intuition here is to ﬁnd similar samples to help build the representation of the current sample.
The inference of the variational posterior qφ(zt,n|xt,n) over latent representations is also achieved using the amortization technique [15, 28]. The amortized inference network takes xt,n as input and returns the statistics of its probabilistic latent representation. 4
2.3 Empirical Objective Function
By integrating (6) and (9) into (5), we obtain the following empirical objective for variational multi-task learning with Gumbel-Softmax priors:
ˆLVMTL(θ, φ, α, β) =
+ DKL (cid:2)qφ(zt,n|xt,n)|| 1
T
T (cid:88) (cid:26) Nt(cid:88) (cid:110) 1
L (cid:88)
M (cid:88) t=1 (cid:88) n=1
M L
βtiqφ(zt,n|xt,n, Di)(cid:3)(cid:111) (cid:96)=1 m=1 i(cid:54)=t (cid:2) − log p(yt|z((cid:96)) t,n, w(m) t
)(cid:3)
+ DKL (cid:2)qθ(wt|Dt)||
αtiqθ(wi|Di)(cid:3) (cid:27)
, (cid:88) i(cid:54)=t t,n ∼ qφ(zt,n|xt,n) and w(m) (11) where z((cid:96)) t ∼ qθ(wt|Dt). To sample from the variational posteriors, we adopt the reparameterization trick [28]. L and M are the number of Monte Carlo samples for the variational posteriors of latent representations and classiﬁers, respectively. In practice, L and M are set to 10, which yields good performance while being computationally efﬁcient. We investigate the sensitivity of L and M in the supplementary materials. θ represents the statistical parameters associated with the classiﬁers or the inference parameters for the amortized classiﬁer; φ denotes parameters of the shared inference network for the latent representation.
We minimize this empirical objective function to optimize the model parameters jointly. The log-likelihood term is implemented as the cross-entropy loss.
In the practical implementation of the KL terms, we adopt the closed-form solution based on its upper bound as done in [35], i(cid:54)=t αtiq(wi)(cid:3) ≤ (cid:80) (cid:2)q(wt)||q(wi)(cid:3). Minimizing the KL terms e.g., DKL i(cid:54)=t αtiDKL encourages the model to leverage shared knowledge provided from related tasks at the instance level for representations and at the categorical level for classiﬁers. (cid:2)q(wt)|| (cid:80)
At test time, we obtain the prediction for a test sample xt by calculating the following probability using Monte Carlo sampling: p(yt|xt) ≈ 1
M L
L (cid:88)
M (cid:88) l=1 m=1 p(y|z(l) t
, w(m) t
), (12) where we draw samples from posteriors: z(l) t ∼ qφ(z|x) and wt (m) ∼ qθ(w|Dt). 3