Abstract
Deep Neural Networks (DNNs) are ubiquitous in today’s computer vision land-scape, despite involving considerable computational costs. The mainstream ap-proaches for runtime acceleration consist in pruning connections (unstructured pruning) or, better, ﬁlters (structured pruning), both often requiring data to re-train the model. In this paper, we present RED, a data-free structured, uniﬁed approach to tackle structured pruning. First, we propose a novel adaptive hashing of the scalar DNN weight distribution densities to increase the number of identical neurons represented by their weight vectors. Second, we prune the network by merging redundant neurons based on their relative similarities, as deﬁned by their distance. Third, we propose a novel uneven depthwise separation technique to further prune convolutional layers. We demonstrate through a large variety of benchmarks that RED largely outperforms other data-free pruning methods, often reaching performance similar to unconstrained, data-driven methods. 1

Introduction
Modern Deep Neural Networks (DNNs) have become the mainstream approach in machine learning in general and in computer vision in particular, with CNNs achieving outstanding performance on various tasks such as object classiﬁcation (He et al., 2016), detection (He et al., 2017) or segmentation (Chen et al., 2017). However, DNNs usually reach high requirements in terms of computational runtime. This prevents most state-of-the-art models to be deployed, most notably on edge devices. To address this shortcoming, a number of approaches for DNN compression have been proposed over the past few years. Architecture compression constitutes a convenient and popular way to address this runtime limitation, involving pruning as well as tensor decomposition techniques (Cheng et al., 2017).
It consists in either removing connections, i.e. an unstructured way or suppressing or reordering speciﬁc channels or ﬁlters i.e. a structured fashion. Although the former usually removes more weights than the latter (Park et al., 2020), unstructured compression has the drawback to produce sparse weight matrices, which require dedicated hardware or libraries (Han et al., 2016) for real-case runtime improvements. Furthermore, these methods can also be divided in data-driven vs. data-free methods. While data-free methods are far more convenient for privacy concerns, as some data may be conﬁdential (e.g. health data or military), they are still signiﬁcantly outperformed by data-driven methods. Hence, despite recent work (Kim et al., 2020; Tanaka et al., 2020), data-free architecture compression remains a challenging and promising domain with room for improvements. In this paper, we propose RED , a novel data-free structured compression framework. First, RED leverages a novel adaptive scalar hashing of the layer-wise weight distributions to introduce redundancies in
DNNs. In particular, we show that this hashing allows to introduce vector redundancies (i.e. neurons that perform the same operation) as well as tensor redundancies (i.e. low-rank ﬂattened convolution kernels). These redundancies can respectively be exploited by applying similarity-based neuron 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
merging, as well as a novel uneven depthwise separation of convolutional layers. To sum it up, our contributions are:
• An adaptive scalar weight hashing technique based on local extrema search of the weight distribution density, that introduces redundancies among neurons without signiﬁcantly altering the predictive function.
• A method for exploiting redundancies at the vector level with similarity-based neuron merging, and at the tensor level, with an uneven depthwise separation of convolutional layers that factors spatially redundant components.
• We introduce RED, a portable method for data-free structured DNN compression that signiﬁcantly outperforms state-of-the-art data-free methods and often rivals existing data-driven approaches. 2