Abstract
Scene classiﬁcation is a valuable classiﬁcation subtask and has its own characteris-tics which still needs more in-depth studies. Basically, scene characteristics are distributed over the whole image, which cause the need of “seeing” comprehensive and informative regions. Previous works mainly focus on region discovery and aggregation, while rarely involves the inherent properties of CNN along with its potential ability to satisfy the requirements of scene classiﬁcation. In this paper, we propose to understand scene images and the scene classiﬁcation CNN models in terms of the focus area. From this new perspective, we ﬁnd that large focus area is preferred in scene classiﬁcation CNN models as a consequence of learning scene characteristics. Meanwhile, the analysis about existing training schemes helps us to understand the effects of focus area, and also raises the question about optimal training method for scene classiﬁcation. Pursuing the better usage of scene characteristics, we propose a new learning scheme with a tailored loss in the goal of activating larger focus area on scene images. Since the supervision of the target regions to be enlarged is usually lacked, our alternative learning scheme is to erase already activated area, and allow the CNN models to activate more area during training. The proposed scheme is implemented by keeping the pairwise consistency between the output of the erased image and its original one. In partic-ular, a tailored loss is proposed to keep such pairwise consistency by leveraging category-relevance information. Experiments on Places365 show the signiﬁcant improvements of our method with various CNNs. Our method shows an inferior result on the object-centric dataset, ImageNet, which experimentally indicates that it captures the unique characteristics of scenes. 1

Introduction
Image classiﬁcation is one of the fundamental tasks of computer vision, and attracts a lot of attention as a popular task for facilitating the improvement of convolution neural network (CNN) [16, 23, 26, 11, 14]. As a valuable classiﬁcation subtask, scene classiﬁcation has its own characteristics which still needs further study. In comparison with objects, scenes are more complex and have many differences.
One of main differences is that the characteristics of scenes are basically distributed over the whole image, while those of objects are conﬁned within a clear boundary. This phenomenon inspires a core idea of scene classiﬁcation, “seeing” comprehensive and informative regions in the image.
Most scene classiﬁcation methods aim to extract unspeciﬁc [9, 25, 6] or speciﬁc regions [29, 33, 3], then aggregate them via statistical models [9, 6, 29] or relation modeling approaches [25, 3]. The main challenge is that the extraction and aggregation are partially independent from the main CNN backbone. It induces some issues as follows. 1) some sort of incompatibility caused by the separated 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
ways to extract and represent regions. 2) inevitable computational consumption from extra region extraction and aggregation processes. It is less studied to investigate the inherent properties of CNN and make them adaptive to the needs of scene classiﬁcation in a more organic and effective way.
In this paper, we explore a new way to understand scene images and the CNN models for scene classiﬁcation in terms of the focus area. It is deﬁned as the region consisting of pixels with large aggregated activation values in the feature maps. From this perspective, we obtain some observations that reveal the differences in the characteristics of CNNs between scene and object classiﬁcation, which also correlates well with the properties of these two kinds of images, i.e., scenes are more complex with richer objects. One of the interesting ﬁndings is that some properties of training scheme could drive the development of large focus area of the corresponding CNN model, which raises a question about how to optimize the training strategy by considering the scene characteristics.
In order to take advantages of the scene characteristics, we propose a new learning scheme with a tailored loss for scene classiﬁcation. Our goal is to inspire the CNN models to focus on more regions in the feature maps. However, the supervision of potentially useful regions is difﬁcult to be obtained. In alternative, we attempt to erase the already activated regions (from the images) and require the consistent outputs, thus, the CNN models themselves could expand the focus area with further optimizing. This is also motivated by our preliminary observations that a scene image can retain its semantic meaning even when some regions are masked. Speciﬁcally, the modiﬁed image is generated by partially erasing the input images with the guidance of model preference. The tailored loss is implemented as pairwise consistency of predictions, which can leverage the category-relevance information.
The principle behind our proposed method is the adversarial learning mechanism under the setting of pairwise consistency. Compared to the original image allows the unconﬁned exploration, the modiﬁed image is used for discovering additional parts which are previously ignored in the original branch. The consistency constraint with the shared parameters uniﬁes these two modes of region explorations, leveraging the underlying opposing operations to perform a more comprehensive and robust information extraction process. In addition, instance-level pairwise consistency shares the excellent quality of knowledge distillation, and yields the unchanged models with superior performances.
Experiments on one of the largest scene datasets, Places365 [38], demonstrate the effectiveness of the proposed method with various CNNs by showing the signiﬁcant performance improvements. Some statistical analyses about the focus area indicate that our proposed method can enhance the capability of exploring larger focus area in CNNs and ﬁt the characteristics of scene images. We also evaluate our method on ImageNet [15], and the inferior result can be the evidence to reveal the inner working mechanism that is speciﬁcally designed for scene images. 2