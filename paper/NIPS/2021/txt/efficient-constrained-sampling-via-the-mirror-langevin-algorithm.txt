Abstract
We propose a new discretization of the mirror-Langevin diffusion and give a crisp proof of its convergence. Our analysis uses relative convexity/smoothness and self-concordance, ideas which originated in convex optimization, together with a new result in optimal transport that generalizes the displacement convexity of the entropy. Unlike prior works, our result both (1) requires much weaker assumptions on the mirror map and the target distribution, and (2) has vanishing bias as the step size tends to zero. In particular, for the task of sampling from a log-concave distribution supported on a compact set, our theoretical results are signiﬁcantly better than the existing guarantees. 1

Introduction
We consider the following canonical sampling problem. Let V : Rd → R∪{∞} be a convex function and let π be the density on Rd which is proportional to exp(−V ). The task is to output a sample which is (approximately) distributed according to π, given query access to the gradients of V .
The sampling problem has attracted considerable attention recently within the machine learning and statistics communities. This renewed interest in sampling is spurred, on one hand, by a wide breadth of applications ranging from Bayesian inference [RC04, DM+19] and its use in inverse problems [DS17], to neural networks [GPAM+14, TR20]. On the other hand, there is a deep and fruitful connection between sampling and the ﬁeld of optimization, introduced in the seminal work [JKO98], which has resulted in the rapid development of sampling algorithms inspired by opti-mization methods such as: proximal/splitting methods [Ber18, Wib18, Wib19, SKL20], coordinate descent [DLLW21a, DLLW21b], mirror descent [HKRC18, CLGL+20, ZPFP20], Nesterov’s accel-erated gradient descent [CCBJ18, MCC+21, DRD20], and Newton methods [MWBG12, SBCR16,
CLGL+20, WL20].
To describe this connection, we recall the Langevin diffusion, which is the solution to the following stochastic differential equation (SDE): dXt = −∇V (Xt) dt +
√ 2 dBt. (LD)
Under standard assumptions on the potential V , the SDE is well-posed and it converges in distribution, as t → ∞, to its unique stationary distribution π. Thus, once suitably discretized, it yields a popular algorithm for the sampling problem. The Langevin diffusion is classically studied using techniques from Markov semigroup theory [see, e.g. BGL14, Pav14], but there is a more insightful perspective which views the diffusion (LD) through the lens of optimization [JKO98]. Speciﬁcally, if µt denotes the law of the process (LD) at time t, then the curve (µt)t≥0 is the gradient ﬂow of the KL divergence
DKL(· (cid:107) π) in the Wasserstein space of probability measures. This perspective has not only inspired 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
Figure 1: from [Bub15, Figure 4.1].
Illustration of the mirror Langevin algorithm (MLA). This illustration is adapted dom(φ(cid:63))
∇φ
∇φ(Xk)
−η∇V(X k)
Wt
∇φ(cid:63)
W0
Wη
∇φ(cid:63) dom(φ)
Xk mirror descent (MLA:1)
Xk+1/2 mirror diffusion (MLA:2)
Xk+1 new analyses of Langevin [CB18, Wib18, DMM19, VW19], but has also emboldened the possibility of bringing to bear the extensive toolkit of optimization onto the problem of sampling; see the references listed above.
However, the vanilla Langevin diffusion notably fails when the support of the target distribution π is not all of Rd. This task of constrained sampling, named in analogy to constrained optimization, arises in applications such as latent Dirichlet allocation [BNJ03], ordinal data models [JA06], survival time analysis [KM06], regularized regression [CEAM+12], and Bayesian matrix factorization [PBJ14].
Despite such a broad range of applications, the constrained sampling problem has proven to be challenging. In particular, most prior works have focused on domain-speciﬁc algorithms [GSL92,
PP14, LS16], and the ﬁrst general-purpose algorithms for this task are recent [BDMP17, BEL18].
In this work, we tackle the constrained sampling problem via the mirror-Langevin algorithm (MLA).
MLA is a discretization of the mirror-Langevin diffusion [HKRC18, ZPFP20], which is the sampling analogue of mirror descent. Namely, if φ : Rd → R ∪ {∞} is a mirror map, then the mirror-Langevin diffusion is the solution to the SDE
Xt = ∇φ(cid:63)(Yt), dYt = −∇V (Xt) dt + 2 [∇2φ(Xt)]1/2 dBt . (MLD)
√
Technical motivation. Recently, Zhang et al. [ZPFP20] analyze an Euler-Maruyama discretization of MLD; see (2.2) for details. The most curious aspect of their result is that their convergence guarantee has a bias term that does not vanish even when step size tends to zero and the number of iterations tends to inﬁnity. Moreover, they conjecture that this bias term is unavoidable. This is in contrast to known results for standard Langevin, which raises the main question of this paper:
Can a different discretization of MLD lead to a vanishing bias?
Our contributions. We propose a new discretization of the mirror-Langevin diffusion, given in (MLA) and illustrated in Figure 1. Our proposed discretization has the same cost as the standard
Euler-Maruyama discretization of MLD in terms of the number of queries to the gradient oracle for
V . We remark that our scheme for the case φ = (cid:107)·(cid:107)2/2 recovers the unadjusted Langevin algorithm.
The most important aspect of our result is that the bias of our algorithm vanishes as the step size tends to zero unlike the result by Zhang et al. [ZPFP20].
By adapting the analysis of Durmus et al. [DMM19], we provide a clean convergence analysis of our algorithm which theoretically validates our discretization scheme. Notably, our analysis only requires standard assumptions/deﬁnitions which are well-studied in optimization. In particular, we establish a stronger link between sampling and optimization without relying on technical assumptions of Zhang et al. [ZPFP20] (e.g. commutation conditions for Hessians; see (A5) therein).
Moreover, our analysis combines ideas from optimization with the calculus of optimal transport. In particular, we establish a new generalization of a celebrated fact, namely that the entropy functional is 2
displacement convex along Wasserstein geodesics, to the setting of Bregman divergences (Theorem 4).
This inequality has interesting consequences in its own right; as we discuss in Corollary 1, our result already implies the transport inequality of Cordero-Erausquin [CE17].
We provide convergence guarantees for the following classes of potentials: (1) convex and relatively smooth (Theorem 1); (2) strongly relatively convex and relatively smooth (Theorem 2); and (3) convex and Lipschitz (Theorem 3). Our results largely match state-of-the-art results for the discretization of the Langevin algorithm for unconstrained sampling. Our work paves the way for the practical deployment of mirror-Langevin methods for sampling applications, paralleling the successes of mirror descent in optimization [NY83, JN11, Bub15].
In Section 5, we demonstrate the strength of our convergence guarantees compared with the previous works [BDMP17, BEL18] in an application to Bayesian logistic regression; further applications are given in Appendix E. We also corroborate our theoretical ﬁndings with numerical experiments.
Other related works. Recently, a few works have proposed modiﬁcations of the Langevin algorithm for the task of constrained sampling. Bubeck et al. [BEL18] studied the projected Langevin algorithm (PLA), which simply projects each step of the Langevin algorithm onto dom(V ). A different approach was taken in Brosse et al. [BDMP17], which applies the Langevin algorithm to a smooth approximation of V given by the Moreau-Yosida envelope. The latter approach was later interpreted and further analyzed by Salim and Richtarik [SR20] using the primal-dual optimality framework from convex optimization.
A different line of work, more closely related to ours, uses a mirror map to change the geometry of the sampling problem [HKRC18, CLGL+20, ZPFP20]. In particular, the mirror-Langevin diffu-sion (MLD) was ﬁrst introduced in an earlier draft of [HKRC18], as well as in [ZPFP20]. The diffu-sion was further studied in [CLGL+20], which provided a simple convergence analysis in continuous time using the sampling analog of Polyak-Łojasiewicz inequalities [KNS16]. We also remark that the idea of changing the geometry via a mirror map also played an crucial role for the problem of sampling from the uniform distribution over a polytope [KN12, LV17, CDWY18, LV18, GN20, LLV20].
Lastly, our work follows the trend of applying ideas from optimization to the task of sampling.
Speciﬁcally, our analysis adopts the framework of relative convexity and smoothness, which was advocated as a more ﬂexible framework for optimization in [BBT17, LFN18]. 2 The mirror-Langevin algorithm 2.1