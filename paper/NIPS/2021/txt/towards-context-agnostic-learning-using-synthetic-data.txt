Abstract
We propose a novel setting for learning, where the input domain is the image of a map deﬁned on the product of two sets, one of which completely determines the labels. We derive a new risk bound for this setting that decomposes into a bias and an error term, and exhibits a surprisingly weak dependence on the true labels.
Inspired by these results, we present an algorithm aimed at minimizing the bias term by exploiting the ability to sample from each set independently. We apply our setting to visual classiﬁcation tasks, where our approach enables us to train classi-ﬁers on datasets that consist entirely of a single synthetic example of each class.
On several standard benchmarks for real-world image classiﬁcation, we achieve robust performance in the context-agnostic setting, with good generalization to real world domains, whereas training directly on real world data without our techniques yields classiﬁers that are brittle to perturbations of the background. 1

Introduction
We study the problem of learning to classifying images of known objects when placed in context, given only a single synthetic example of each object; our empirical evaluation considers the tasks of trafﬁc sign and handwritten character recognition.
Our methods also enable us to explore the extent to which deep neural networks trained using real-world data to perform image classiﬁcation can over-rely on signals from the backgrounds of images, even when no such information is necessary for classiﬁcation. Intuitively, even though contextual clues may be required in some settings, given an input that unambiguously contains the object of interest in the foreground, we expect a robust classiﬁer to be invariant to the rest of the image.
We present two main contributions. First, we introduce a formal setting for our study, where the input space is decomposed into object and context spaces, and the labels are independent of contexts when conditioned on the objects. We introduce the goal of learning a context-agnostic classiﬁer, i.e., a classiﬁer whose predictions are invariant under perturbations of the context. We derive a new risk bound for this setting that is tight up to a factor of two but also independent of the true labels, which holds so long as the classiﬁer outperforms random guessing.
Second, we present a new technique for automatically generating data to train a deep neural network for image classiﬁcation. The technique works by sampling independently from the object space, which contains the transformed views of the objects, and the context space, which is designed to include challenging backgrounds that make the resulting images difﬁcult to classify. The hypothesis is that training the network to accurately classify objects against these challenging backgrounds should produce a trained network that robustly generalizes to accurately classify objects against the range of backgrounds that it may encounter when deployed in more natural settings. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
We empirically validate our methods by training deep neural networks for a variety of real-world image classiﬁcation tasks using only a single synthetic example of each class, obtaining robust performance in the context-agnostic setting on natural data. Conversely, we ﬁnd that classiﬁers trained without our techniques using only natural data achieve negligible accuracy even under relatively benign perturbations that leave a well-deﬁned object in the foreground completely untouched. These results demonstrate the ability of our technique to train accurate and robust classiﬁers using only small amounts of high quality synthetic data, while also highlighting the need for future work in understanding the performance of deep learning systems in the context-agnostic setting when trained on natural data. 2