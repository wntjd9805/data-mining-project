Abstract
Optimization is a key component for training machine learning models and has
In this paper, we consider a particu-a strong impact on their generalization. lar optimization method—the stochastic gradient Langevin dynamics (SGLD) algorithm—and investigate the generalization of models trained by SGLD. We derive a new generalization bound by connecting SGLD with Gaussian channels found in information and communication theory. Our bound can be computed from the training data and incorporates the variance of gradients for quantifying a particular kind of “sharpness” of the loss landscape. We also consider a closely related algorithm with SGLD, namely differentially private SGD (DP-SGD). We prove that the generalization capability of DP-SGD can be ampliﬁed by iteration.
Speciﬁcally, our bound can be sharpened by including a time-decaying factor if the
DP-SGD algorithm outputs the last iterate while keeping other iterates hidden. This decay factor enables the contribution of early iterations to our bound to reduce with time and is established by strong data processing inequalities—a fundamental tool in information theory. We demonstrate our bound through numerical experiments, showing that it can predict the behavior of the true generalization gap. 1

Introduction
Modern deep neural networks (DNNs) are highly expressive: they can memorize an entire training dataset and still generalize well to unseen data (Zhang et al., 2016). This empirical observation is not captured by traditional generalization bounds found in statistical learning theory, which attribute the generalization ability to the use of a hypothesis class with constrained complexity (Vapnik and
Chervonenkis, 1971; Valiant, 1984). Recent studies demonstrate that different algorithmic choices and data distributions may yield DNNs with contrasting generalization behaviors (Hardt et al., 2016;
Neyshabur et al., 2017; Bartlett et al., 2017). In this paper, we study how one optimization method used for training DNNs, namely the stochastic gradient Langevin dynamics (SGLD) algorithm (Gelfand and Mitter, 1991; Welling and Teh, 2011), may inﬂuence their generalization.
The SGLD algorithm is used in different practical settings. For example, it has been implemented in open-source libraries (Facebook AI, 2020; Radebaugh and Erlingsson, 2019) for training models with differential privacy guarantees (Dwork et al., 2006; Song et al., 2013; Abadi et al., 2016). The additive noise in the SGLD algorithm can also mitigate overﬁtting for DNNs (Neelakantan et al., 2015). Recently, there is an increasing number of efforts (see e.g., Raginsky et al., 2017; Mou et al., 2018; Li et al., 2019; Pensia et al., 2018; Negrea et al., 2019) that investigate the generalization properties of the SGLD algorithm. It is within this body of work that the present paper is inscribed. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
Figure 1: Illustration of our generalization bound in Theorem 1. We use the SGLD algorithm to train 3-layer neural networks on MNIST when the training data have different label corruption level
α ∈ {0%, 25%, 50%, 75%}. Left: training accuracy. Middle: (empirical) generalization gap. Right: (empirical) generalization bound. As shown, the generalization gap is increasing with respect to α and our bound can capture this phenomenon. We defer detailed discussions to Section 5.
We derive a new generalization bound (Theorem 1) for the SGLD algorithm in Section 3. Our bound (see Figure 1 for an illustration) incorporates the variance of gradients, which can be estimated from the training data and captures a particular kind of “sharpness” of the loss landscape (Keskar et al., 2016). This variance term can also be predictive of the generalization gap as shown in a recent empirical study (Jiang et al., 2019). We consider a general setting in which the output from the SGLD algorithm can be any function of the iterates. This is crucial since many theoretical analyses (see e.g.,
Zhang et al., 2017; Jin et al., 2019) require the ﬁnal output to be the iterate that achieves the smallest value of the loss function or an average of the iterates, but not necessarily the last iterate. Finally, the numerical experiments in Section 5 suggest that our generalization bound is highly correlated with the true generalization gap.
We also investigate the DP-SGD algorithm in Section 4. In particular, we prove that if it is known a prior, that the algorithm outputs the last iterate rather than an arbitrary function of all iterates, then our bound can be further tightened by incorporating a time-decaying factor. Our analysis is motivated by a line of recent works (Feldman et al., 2018; Balle et al., 2019; Asoodeh et al., 2020) on privacy ampliﬁcation by iteration. Speciﬁcally, the original work by Feldman et al. (2018) provided two intertwined observations of the DP-SGD algorithm: (i) not releasing the intermediate steps can amplify the privacy guarantees and (ii) data points used in the early iterations get stronger privacy protection than those occurring late. In this paper, we establish two analogous results: (i) our generalization bound can be sharpened by incorporating a time-decaying factor if DP-SGD only outputs the last iterate (Theorem 2) and (ii) this decay factor enables the impact of early iterations on our bound to reduce with time (Lemma 4).
The proof techniques of this paper are based on fundamental tools from information theory. We ﬁrst use an information-theoretic framework, proposed by Russo and Zou (2016) and Xu and Raginsky (2017) and further tightened by Bu et al. (2020), for deriving an algorithmic generalization bound.
This framework relates the generalization gap with the mutual information I(W; Zi) between the output parameter W from the SGLD algorithm and each individual data point Zi. However, estimating the mutual information from data is often intractable. Given this major challenge, our key contribution is to connect the SGLD algorithm with a well-understood notion in data transmission, namely additive white Gaussian noise (AWGN) channels. This connection allows us to use properties of Gaussian channels for analyzing the mutual information. First, we upper bound I(W; Zi) using the variance of gradients by exploring the input-output mutual information of a Gaussian channel. This variance term can be estimated from the training data and is highly correlated with the true generalization gap.
Second, we incorporate a time-decaying factor into our bound. This factor is established by strong data processing inequalities (Dobrushin, 1956; Cohen et al., 1998) and has an intuitive interpretation: if a data point is used at an early iteration, its impact on the generalization gap reduces with time due to external Gaussian noise. The above two aspects correspond to Lemma 4 and Lemma 5 which, in turn, are the basis of our main results in Theorem 1 and Theorem 2.
The supplementary material of this paper includes: (i) omitted proofs of all theoretical results and (ii) supporting experimental results. 2