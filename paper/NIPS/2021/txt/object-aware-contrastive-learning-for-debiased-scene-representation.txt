Abstract
Contrastive self-supervised learning has shown impressive results in learning visual representations from unlabeled images by enforcing invariance against different data augmentations. However, the learned representations are often contextually biased to the spurious scene correlations of different objects or object and back-ground, which may harm their generalization on the downstream tasks. To tackle the issue, we develop a novel object-aware contrastive learning framework that
ﬁrst (a) localizes objects in a self-supervised manner and then (b) debias scene correlations via appropriate data augmentations considering the inferred object locations. For (a), we propose the contrastive class activation map (ContraCAM), which ﬁnds the most discriminative regions (e.g., objects) in the image compared to the other images using the contrastively trained models. We further improve the
ContraCAM to detect multiple objects and entire shapes via an iterative reﬁnement procedure. For (b), we introduce two data augmentations based on ContraCAM, object-aware random crop and background mixup, which reduce contextual and background biases during contrastive self-supervised learning, respectively. Our experiments demonstrate the effectiveness of our representation learning frame-work, particularly when trained under multi-object images or evaluated under the background (and distribution) shifted images.1 1

Introduction
Self-supervised learning of visual representations from unlabeled images is a fundamental task of machine learning, which establishes various applications including object recognition [1, 2], reinforcement learning [3, 4], out-of-distribution detection [5, 6], and multimodal learning [7, 8].
Recently, contrastive learning [1, 2, 9–15] has shown remarkable advances along this line. The idea is to learn invariant representations by attracting the different views (e.g., augmentations) of the same instance (i.e., positives) while contrasting different instances (i.e., negatives).2
Despite the success of contrastive learning on various downstream tasks [16], they still suffer from the generalization issue due to the unique features of the training datasets [17–19] or the choice of data augmentations [19–21]. In particular, the co-occurrence of different objects and background in randomly cropped patches (i.e., positives) leads the model to suffer from the scene bias. For example, Figure 1a presents two types of the scene bias: the positive pairs contain different objects (e.g., giraffe and zebra), and the patches contain adjacent object and background (e.g., zebra and safari). Speciﬁcally, the co-occurrence of different objects is called contextual bias [22], and that of object and background is called background bias [23]. Attracting the patches in contrastive learning
∗Equal contribution 1Code is available at https://github.com/alinlab/object-aware-contrastive. 2Some recent works (e.g., [14, 15]) attract the positives without contrasting the negatives. While we mainly focus on contrastive learning with negatives, our method is also applicable to the positive-only methods. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
(a) Scene bias in random crop (b) Performance drop (c) Biased prediction
Figure 1: Scene bias issue (a) and its negative effects on contrastive learning. (b) Linear evaluation
[24] of the original MoCov2 [1] and our debiased method, trained and evaluated on the COCO
[25] and Flowers [26] datasets, respectively, using the ResNet-50 architecture [27]. The vanilla
MoCov2 often loses its discriminative power as training goes as it entangles different objects, while the debiased model stably improves the classiﬁcation performance. (c) Prediction of MoCov2 on an image from the