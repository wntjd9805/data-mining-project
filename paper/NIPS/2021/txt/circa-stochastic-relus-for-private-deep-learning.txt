Abstract
The simultaneous rise of machine learning as a service and concerns over user pri-vacy have increasingly motivated the need for private inference (PI). While recent work demonstrates PI is possible using cryptographic primitives, the computational overheads render it impractical. State-of-art deep networks are inadequate in this context because the source of slowdown in PI stems from the ReLU operations whereas optimizations for plaintext inference focus on reducing FLOPs. In this paper we re-think ReLU computations and propose optimizations for PI tailored to properties of neural networks. Speciﬁcally, we reformulate ReLU as an ap-proximate sign test and introduce a novel truncation method for the sign test that signiﬁcantly reduces the cost per ReLU. These optimizations result in a speciﬁc type of stochastic ReLU. The key observation is that the stochastic fault behavior is well suited for the fault-tolerant properties of neural network inference. Thus, we provide signiﬁcant savings without impacting accuracy. We collectively call the optimizations Circa and demonstrate improvements of up to 4.7× storage and 3× runtime over baseline implementations; we further show that Circa can be used on top of recent PI optimizations to obtain 1.8× additional speedup. 1

Introduction
Today, Machine Learning as a Service (MLaaS) provides high-quality user experiences but comes at the cost of privacy—clients either share their personal data with the server or the server must disclose its model to the clients. Ideally, both the client and server would preserve the privacy of their inputs and model without sacriﬁcing quality. A recent and growing body of work has focused on designing and optimizing cryptographic protocols for private inference (PI). With PI, MLaaS computations are performed obliviously; without the server seeing the client’s data nor the client learning the server’s model. PI protocols are built using cryptographic primitives including homomorphic encryption (HE),
Secret Sharing (SS), and secure multiparty computation (MPC). The challenge is that all known protocols for PI incur impractically high overheads, rendering them unusable.
Existing PI frameworks [1, 2, 3] are based on hybrid protocols, where different cryptographic techniques are used to evaluate different network layers. Delphi [3], a leading solution based on
Gazelle [2], uses additive secret sharing for convolution and fully-connected layers. Secret sharing supports fast addition and multiplication by moving large parts of the computation to an ofﬂine phase [4]. Thus, convolutions can be computed at near plaintext speed. Non-linear functions, notably ReLU, cannot enjoy the same speedups. Most protocols (including Delphi, Gazelle, and
MiniONN [1]) use Yao’s Garbled Circuits (GC) [5] to process ReLUs. GCs allow two parties to collaboratively and privately compute arbitrary Boolean functions. At a high-level, GCs represent functions as encrypted two-input truth tables. This means that computing a function with GCs requires the function be decomposed into a circuit of binary gates that processes inputs in a bit-wise fashion. Thus, evaluating ReLUs privately is extremely expensive, to the point that PI inference runtime is dominated by ReLUs [3, 6]. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
Therefore, reducing ReLU cost is critical to realizing practical PI. There are two general approaches for minimizing the cost of ReLUs: designing new architectures that limit ReLU counts, and optimizing the cost per ReLU. Prior work has almost exclusively focused on minimizing ReLU counts. Work along this line includes replacing or approximating ReLUs with quadratics or polynomials (e.g.,
CryptoNets [7], Delphi [3], SAFENet [8]), designing new networks architectures to maximize accuracy per ReLU (e.g., CryptoNAS [6]), and more aggressive techniques that simply remove
ReLUs from the network (e.g., DeepReDuce [9]). Relatively little attention has been given to minimizing the cost of the ReLU operation itself.
In this paper we propose Circa1, a novel method to reduce ReLU cost based on a new stochastic
ReLU function. First, we refactor the ReLU as a sign computation followed by a multiplication, allowing us to push the multiplication from GC to SS, leaving only a sign computation in the GC.
Next, we approximate the sign computation to further reduce GC cost. This approximation is not free; it results in stochastic sign evaluation where the results are sometimes incorrect (we call incorrect computations faults to differentiate from inference error/accuracy). Finally, we show that stochastic sign can be optimized even further by truncating its inputs; truncation introduces new faults, but only for small positive or negative values.
Our key insight is that deep networks are highly resilient to stochastic ReLU fault behavior, which provides signiﬁcant opportunity for runtime beneﬁt. The stochastic ReLU introduces two types of faults. First, the sign of a ReLU can be incorrectly computed with probability proportional to the magnitude of the input (this probability is the ratio of the input magnitude over ﬁeld prime.) In practice we ﬁnd this rarely occurs as most ReLU inputs are very small (especially compared to the prime) and thus the impact on accuracy is negligible. Second, truncation can cause either small positive or small negative values to fault. Circa allows users to choose between these two probabilistic fault modes. In NegPass, small negative numbers experience a fault with some probability and are incorrectly passed through the ReLU. Alternatively, PosZero incorrectly resolves small positive inputs to zero. Empirically, we ﬁnd deep networks to be highly resilient against such faults, tolerating more than 10% fault rate without sacriﬁcing accuracy. Compared to Delphi, Circa-optimized networks run up to 3× times faster. We further show that Circa is orthogonal to the current best practice for ReLU count reduction [9]. When combined, we observe an additional 1.8× speedup. 2