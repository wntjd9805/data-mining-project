Abstract
Keyword search is a fundamental task to retrieve information that is the most relevant to the query keywords. Keyword search over graphs aims to ﬁnd subtrees or subgraphs containing all query keywords ranked according to some criteria.
Existing studies all assume that the graphs have complete information. However, real-world graphs may contain some missing information (such as edges or key-words), thus making the problem much more challenging. To solve the problem of keyword search over incomplete graphs, we propose a novel model named
KS-GNN based on the graph neural network and the auto-encoder. By considering the latent relationships and the frequency of different keywords, the proposed
KS-GNN aims to alleviate the effect of missing information and is able to learn low-dimensional representative node embeddings that preserve both graph structure and keyword features. Our model can effectively answer keyword search queries with linear time complexity over incomplete graphs. The experiments on four real-world datasets show that our model consistently achieves better performance than state-of-the-art baseline methods in graphs having missing information. 1

Introduction
Keyword search is an important research topic which allows users to provide query keywords and returns the most relevant results. The keyword search over graph data [1] usually retrieves top-k subtrees or subgraphs which contain all the query keywords ranked according to some criteria. For example, He et al. [2] propose a general scoring function considering both graph structure and content, and they aim to ﬁnd top-k nodes where each node can reach all query keywords, and the sum of its shortest path distances to these keywords is as small as possible. This ranking method is commonly used in later graph keyword search works [3, 4].
∗Corresponding author. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
All existing studies assume that the graph data is complete and has no missing information. How-ever, real-world graphs usually have some miss-ing edges [5] and missing attributes on some nodes [6]. This renders previous graph keyword search methods unable to ﬁnd exact answers when dealing with such incomplete graphs. Fig-ure 1 shows an example keyword search query over graphs. Given q={c, e, f }, on the left graph
G with no missing information, the best node is v4, since it contains keywords c and f , it can reach v5 containing e, and its sum of the short-est path distances to all query keywords is the smallest which is 1 (the shortest distances of v4 to c, e, and f are 0, 1, and 0). However, on the right graph G(cid:48) which has a missing edge and a node with missing attributes, the result becomes v1, v2 or v6, and the subtree consists of {v1, v2, v6}, with a total distance of 2.
Figure 1: Example of keyword search on incom-plete graphs
To handle the missing information, one simple idea is to ﬁrst utilize some state-of-the-art graph completion models (such as SAT [6]) to predict the missing information and then apply the existing algorithms (such as BLINKS [2]) to ﬁnd the answers from the graph with predicted keywords and edges. However, such a completed graph contains many noises and errors comparing with the original graph, and thus this method has poor performance as shown in our experimental study. To capture the latent information of the incomplete graphs, we propose to utilize the graph neural network (GNN) for graph keyword search. GNN has been widely applied in tasks such as link prediction [7, 8, 9], node classiﬁcation [10, 11], and node clustering [6, 12], but existing models cannot be directly applied to keyword search since they usually embed all the features (keywords) of a node into a single vector and they cannot obtain the representation for the individual query keywords.
We ﬁrstly design two naïve approaches based on GNN and dimension reduction. To achieve better performance, we propose a novel auto-encoder and GNN-based model using the message passing mechanism, called KS-GNN. The model mainly consists of three components: an encoder that transforms the original keyword information to low-dimensional embedding vectors; a decoder that aims to reconstruct the high-dimensional representation of keywords from the embedding; a message passing-based aggregation mechanism that preserves the shortest path information between keywords and the target node. Different from the existing graph keyword search works, we propose to leverage GNN to obtain representative node embedding that contains the keyword information, taking the latent graph structure, keyword distribution, and keyword frequency information into account.
Meantime, the proposed KS-GNN is able to encode the input query as a low-dimensional vector by its learned powerful encoder, and the results are obtained by computing the similarity between the query embedding and node embeddings. This also speeds up query processing time to linear complexity.
The main contributions of our approach are as follows:
• To our best knowledge, this is the ﬁrst work on keyword search in graphs with missing information.
• We propose an auto-encoder and GNN-based model KS-GNN to solve the problem effec-tively without having to know the complete information of the input graph.
• The experimental results on four real-world datasets show that our proposed model consis-tently outperforms several baseline methods. 2