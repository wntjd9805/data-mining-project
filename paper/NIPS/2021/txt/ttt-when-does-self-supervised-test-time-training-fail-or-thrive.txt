Abstract
Test-time training (TTT) through self-supervised learning (SSL) is an emerging paradigm to tackle distributional shifts. Despite encouraging results, it remains unclear when this approach thrives or fails. In this work, we ﬁrst provide an in-depth look at its limitations and show that TTT can possibly deteriorate, instead of improving, the test-time performance in the presence of severe distribution shifts.
To address this issue, we introduce a test-time feature alignment strategy utilizing ofﬂine feature summarization and online moment matching, which regularizes adaptation without revisiting training data. We further scale this strategy in the online setting through batch-queue decoupling to enable robust moment estimates even with limited batch size. Given aligned feature distributions, we then shed light on the strong potential of TTT by theoretically analyzing its performance post adaptation. This analysis motivates our use of more informative self-supervision in the form of contrastive learning for visual recognition problems. We empirically demonstrate that our modiﬁed version of test-time training, termed TTT++, outper-forms state-of-the-art methods by signiﬁcant margins on several benchmarks. Our result indicates that storing and exploiting extra information, in addition to model parameters, can be a promising direction towards robust test-time adaptation. Our code is available at https://github.com/vita-epfl/ttt-plus-plus. 1

Introduction
Machine learning models often struggle to generalize under distribution shifts. Even a perceptually mild shift between training and test data, e.g., JPEG compression, may cause severe prediction errors
[1]. One popular family of methods to address this challenge is to learn an invariant representation across domains by making use of labelled training data and unlabelled test data simultaneously [2–5].
However, revisiting training data at test time can be impractical due to increasing privacy concerns, inﬂating sizes of datasets as well as many other real-world constraints. This shortcoming prompts a more challenging yet appealing test-time adaptation paradigm: given a trained model, how can we adapt it from one domain to another on the ﬂy, without access to training data and human annotations?
One promising approach towards this goal is test-time training (TTT) through self-supervision [6].
The key idea of TTT is simple and straightforward: train the model on two tasks, namely a main task and a self-supervised learning (SSL) task, and update the model based only on the SSL task at test time. This technique implemented with self-supervised rotation prediction has shown encouraging results for improving the robustness of image classiﬁers under a variety of distributional shifts. Yet, its empirical performance is still inferior to other families of test-time algorithms [7, 8]. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
In this paper, we ﬁrst take an in-depth look at TTT with emphasis on its limitations. Our analysis starts with a basic question: can TTT always mitigate the effects of distributional shifts? Through an illustrative problem, we show that the TTT framework can lead to surprising failures, deteriorating the test accuracy rather than improving it. This problem is largely attributed to the unconstrained update from the SSL task that interfere with the main task. To address this issue, we introduce a test-time feature alignment strategy by means of ofﬂine feature summarization and online moment matching: once training completes, we compute the mean and covariance matrix of training features and store them as part of the model, referred to as ofﬂine feature summarization; at test time, we encourage the test feature distribution to be close to the training one by matching the moments estimated online with those pre-computed ofﬂine, a process referred to as online moment matching.
One practical challenge for online feature alignment lies in scaling the strategy to problems with a large number of classes, as obtaining a robust estimate of moments often requires at least a handful of samples per class. To mitigate this issue, we draw inspiration from recent literature [9] and decouple the sample size from the batch size for moment estimates. Speciﬁcally, we maintain a large dynamic queue of encoded features and progressively update it in a mini-batch manner. This modiﬁcation enables effective feature alignment even with limited batch size, greatly improving its viability in the online test-time setting.
Finally, we shed light on the strong potential of TTT through a theoretical analysis of the test accuracy after adaptation. In particular, we derive a lower bound of the test accuracy on the main task and show that it is expected to grow rapidly when the SSL task gets closer to the main task. These ﬁndings motivate our integration of contrastive representation learning [9–12], as a strong instance of SSL, into the TTT framework in visual recognition problems.
By combining the three proposed components, we devise an improved version of test-time training, termed TTT++. Experimental results show that TTT++ signiﬁcantly outperforms other recent methods by signiﬁcant margins on various robustness benchmarks. Our results suggest that exploiting extra information, including both task-speciﬁc information in the form of strong self-supervision and domain-speciﬁc information in the form of feature summarization, can be a promising direction to enhance the effectiveness of test-time adaptation. 2