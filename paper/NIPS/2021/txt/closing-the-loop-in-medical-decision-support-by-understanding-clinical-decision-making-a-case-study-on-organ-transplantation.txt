Abstract
Significant effort has been placed on developing decision support tools to improve patient care. However, drivers of real-world clinical decisions in complex medical scenarios are not yet well-understood, resulting in substantial gaps between these tools and practical applications. In light of this, we highlight that more attention on understanding clinical decision-making is required both to elucidate current clinical practices and to enable effective human-machine interactions. This is imperative in high-stakes scenarios with scarce available resources. Using organ transplan-tation as a case study, we formalize the desiderata of methods for understanding clinical decision-making. We show that most existing machine learning methods are insufficient to meet these requirements and propose iTransplant, a novel data-driven framework to learn the factors affecting decisions on organ offers in an instance-wise fashion directly from clinical data, as a possible solution. Through experiments on real-world liver transplantation data from OPTN, we demonstrate the use of iTransplant to: (1) discover which criteria are most important to clini-cians for organ offer acceptance; (2) identify patient-specific organ preferences of clinicians allowing automatic patient stratification; and (3) explore variations in transplantation practices between different transplant centers. Finally, we empha-size that the insights gained by iTransplant can be used to inform the development of future decision support tools. 1

Introduction
The decision that a patient and a clinician jointly make when a donor organ is offered for trans-plantation is critical and carries serious consequences. Even though the initial offer of a donor organ for a particular recipient is made on the basis of agreed criteria as to optimum allocation
∗Equal contribution 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
Figure 1: Closing the loop of medical decision support by understanding clinical decision-making.
Most existing clinical decision support tools offer generic advice or alerts to clinicians without specificity for the immediate decision about to be taken. In this paper, we highlight that iTransplant, by identifying drivers of that decision, will be able to feedback into future iterations of the decision support tool specific information about which factors impacted the decisions so that in future that specific information can be given to the decision maker or can be taken into account in designing future iterations of the decision support tool itself. within each transplant jurisdiction, there remains substantial variation in the rate at which organs are accepted. Clinical variation is a well-observed phenomenon, but may have profound consequences and unfavourably impact outcomes. Addressing clinical variation is therefore a major priority in many healthcare systems. Understanding the factors which are associated with variation in clinical decision-making is an important goal as it might be able to inform clinicians of biases which, if rectified, might result in improved clinical outcomes. With a case study on organ transplantation, we explore the potential of inverse decision-making approaches to shed light on such factors.
Organ transplantation
Transplantation is typically the last life-saving treatment available for patients with end-stage diseases that cause organ failures. However, due to the limited availability of donors, patients often have to wait years before transplantation [14, 23]. Regrettably, waitlists continue to grow despite increases in the number of donors and many patients die while waiting for an organ, with over 7,500 deaths each year in the United States alone [20]. The majority of these patients received at least one organ offer that was declined on their behalf [12], despite these organs often appearing to be suitable for transplantation and yielding good outcomes when eventually transplanted
[17]. It is therefore important to understand why donor organs subsequently successfully implanted have been declined for previous patients.
Clinicians’ decision-making is poorly understood When a donor organ becomes available, it is first offered to a patient on the waitlist on the basis of agreed offering criteria. Once an organ is offered, a clinician must choose whether to accept or decline the organ offer. Although significant effort has been placed into developing organ allocation algorithms [47, 28, 4], a donor offered to the first ranked patient in a waitlist is rejected up to 50% of the time [12, 43].
In real-world organ transplantation systems, the performance of organ allocation algorithms are significantly affected by clinicians’ assessments of organ offers. Even for good quality organs, the assigned organ offers could be turned down several times before they are finally accepted [45, 17].
The high ratio of declined organ offers is important as it may impact outcomes for that organ (e.g. due to prolonged cold ischemia time) and the patients involved (e.g. [12] shows that centers with higher acceptance rates experienced significantly lower adjusted estimated waitlist mortality of the highest-ranked patients).
Substantial variation in clinical practice Variation in clinical practice is an extensively studied phenomenon across medicine with significant impacts on organ transplantation [42, 2]. Striking discrepancies in organ offer acceptance rates have been observed for different transplant centers, even after accounting for organ quality and the severity of the recipient’s illness [12]. However, it has been impossible to disambiguate the causes of this variation, despite its importance for understanding current medical practices and ultimately improving organ allocation policy.
In this paper, we highlight that to address such challenges it is necessary for practical inverse decision-making approaches to provide interpretable and personalized insights into clinical decision-making.
Human interpretable policies
Interpretability and transparency are crucial for machine learning applications in medicine [39]. As a result, white-box models, such as logistic regression, are widely adopted in the medical literature (e.g. [33, 10]). Numerous studies have demonstrated 2
improved performance from using black-box models for medical applications [15], albeit at the cost of interpretability. The development of interpretable, yet highly performant, models for clinical decision-making is essential to bridge the gap to black-box models and further medical knowledge.
In addition, for such interpretations to be useful for understanding clinical decision-making, models must be counterfactually consistent (i.e. the counterfactual prediction must match the interpretation).
Precision medicine Precision, or personalized, medicine seeks to improve medical care by tailoring therapy to the needs of a particular patient [40]. However, in the organ transplantation setting, most existing methods only learn a global decision-making policy for all patients, which fails to address the discrepancies in clinicians’ policies for patients from different cohorts (see, e.g., [16, 5, 35]).
To both understand clinicians’ decision-making and improve precision medicine, models that learn personalized policies are necessary.
In this paper, we propose iTransplant (individualized TRANSparent Policy
Our contributions
Learning for orgAN Transplantation), a novel data-driven framework to learn interpretable organ offer acceptance policies directly from clinical data. Our method learns a patient-wise parametrization of the expert clinician policy that accounts for the differences between patients, a crucial but often overlooked factor in organ transplantation.
We achieve this by training a neural network-based policy selector to identify individualized policies for patients from different cohorts. These policies act on the space of known match criteria using a white-box function, ensuring interpretability with respect to the match criteria. Our method significantly outperforms existing interpretable models, with comparable accuracy to black-box approaches.
We conduct several investigative experiments with real-world liver transplantation data from the
Organ Procurement and Transplantation Network (OPTN), covering 190,525 organ offers. The results show that iTransplant can be used to probe clinical decision-making practices in a number of ways.
Our investigations allow us to: (1) identify important match criteria for organ offer acceptance; (2) discover patient-wise organ preferences of clinicians via automatic patient stratification in a latent representation space; and (3) examine the transplantation practice variations across transplant centers. 2 Problem Formulation
Notation We denote the feature space of all possible patients as X ⊆ Rd and the feature space of all possible organs available as O ⊆ Re. The organ offer that assigns organ O ∈ O to patient
X ∈ X is denoted with s = (X, O) and the associated decision of clinicians is denoted as a ∈ {0, 1}.
Here, the event of offer acceptance is denoted as {a = 1}, and {a = 0} means offer rejection.
The decision-making policy of clinicians (expert policy) is assumed to be a probability distribution
π∗(a|s) conditioned on the organ offer s.
Following the discussion on interpretability and precision medicine in Section 1, we propose three key desiderata of practical inverse decision-making approaches: 1) personalized policies, 2) interpretable insights of decisions, and 3) consistent interpretations under perturbation. First, let us introduce some concepts and assumptions related to the above requirements.
Criteria space Suppose there are l known match criteria related to decisions on organ offers, denoted by a set of functions C = {ci(s) : X × O → R, i = 1, 2, . . . , l}. Each criterion ci ∈ C takes patient and organ features as input and generates a match score as the assessment of organ offer s = (X, O). Based on l match criteria in C, we define a transform T : X × O → M ⊆ Rl that maps organ offers to a criteria space M. Given an organ offer s, its representation in space M can be calculated as T (s) := [m1(s), m2(s), . . . , ml(s)]′. In practice, the criteria space would usually be proposed by experts based on domain knowledge. Note, our method allows clinicians to explore criteria space M with different sets of criteria based on their own expertise.
In line with our desideratum for a personalized policy, we have Assumption 1 that bridges the criteria space M with the decision-making policy of clinicians on a per patient basis.
Assumption 1 (Partial monotonicity) There exists a vector v ∈ {−1, 1}l such that for any two organ offers s1 = (X1, O1), s2 = (X2, O2) satisfying the conditions of X1 = X2 and v ◦ T (s1) ⪰ v ◦ T (s2), where ◦ is the Hadamard product operator, we have π∗(a = 1|s1) ≥ π∗(a = 1|s2), where
π∗ is clinicians’ decision-making policy on organ offers. 3
Assumption 2 (Greedy decision policy) Noting that decisions on organ offers by clinicians will not necessarily affect the next organ offer assigned to their patients, we further assume that decisions of clinicians are consistent with a greedy policy, i.e., maximizing the immediate benefit R(s, a) of decision a on organ offer s with policy π∗(a|s) = arg maxa∈{0,1} R(s, a).
Related to the requirement for a personalized policy, clinicians may use different subsets of criteria in
M to evaluate potential outcomes of the offered organ for different cohorts of patients. For instance,
[5] reports that the difference in age of donor and recipient has diverse impacts on post-transplant mortality, and young recipients with elderly donors are most affected. Hence, a personalized reward structure is necessary to account for policy variations at the patient level, which leads to the following assumption:
Assumption 3 (Personalized rewards) Similar to existing literature on inverse decision-making (e.g., [49, 30]), we assume a linear structure of the reward function: R(s, a) = ⟨ρ∗ a(X), T (s)⟩, where ⟨·, ·⟩ is the inner product of two vectors in an Euclidean space, ρ∗ a(X) is the weight vector for different criteria in space M. Note that there exists a family of equivalence reward functions
R(s, a) = R(s, a) − Φ(s), where Φ(s) : X × O (cid:55)→ R can be arbitrary scalar functions of s (see, e.g., [29]), that are consistent with expert policy π∗. For the sake of convenience, we assume
R(s, a = 0) ≡ 0 and R(s, a = 1) = ⟨ρ∗(X), T (s)⟩. It is worth noting that ρ∗(X) is a function of patient features X and thus is able to represent the patient-specific rewards for clinicians.
To ensure that the decision policy is differentiable, we further adopt the maximum entropy assumption
[49] that π∗ follows a Boltzmann distribution: π∗(a|s) ∝ exp [R(s, a)], which is a soft version of the arg max operator. Note that expert policy π∗ is uniquely determined by the true reward parameter map ρ∗(X), in this paper, we seek to learn a representation ˆπ of expert policy π∗ with all three desiderata achieved by leveraging the notion of a transparent policy space introduced as follows.
Transparent policy space Following the Boltzmann distribution formulation of expert policy π∗, we can construct a transparent policy space Π as
Π = {Bernoulli(p) : p = 1 1 + exp [−⟨ρ, T (s)⟩]
, ρ ∈ Rl}, (1) where T (s) ∈ M. We call the vector ρ ∈ Rl a policy signature since it uniquely characterizes the behavior of the corresponding policy πρ in space Π. Due to the interpretability of criteria space M and the linear structure in equation (1), policies in space Π are human comprehensible by design and are considered transparent. Note that for the same patient feature vector X ∈ X , there exists a policy signature ρX = ρ∗(X) such that π∗(a|X, O) = πρX ∈ Π, ∀O ∈ O. Thereby, the expert policy π∗ can be represented with patient-wise projections in space Π.
Personalized policy projection Given demonstrations from expert policy π∗ and criteria space
M, our target is to find a patient-wise projection ˆπ(θ) of policy π∗ in the transparent policy space
Π such that the distance d(π∗, ˆπ(θ)) is minimized via minθ d(π∗, ˆπ(θ)), where ˆπ(θ) = πρ(X;θ) and ρ(X; θ) is a function of patient feature vector X with learnable parameter set θ. The dis-tance d(π∗, ˆπ(θ)) is defined as the accumulated Kullback–Leibler (KL) divergence d(π∗, ˆπ(θ)) :=
Es∼△(X ×O)[DKL(π∗∥ˆπ(θ))|s], where △(X × O) is the organ offer distribution. The requirement for consistency of ˆπ(θ) is addressed in Section 3. 3
Individualized Transparent Policy Learning
In this paper, we propose a data-driven framework, iTransplant, for learning patient-wise policies that match clinical practice. We utilize neural networks as general function approximators for the policy signature ρ(X; θ). The architecture of the proposed model is illustrated in Figure 2.
While the idea in [22] of mapping the input features into a concept space and performing prediction tasks using the concept space is in philosophy similar to our proposed method, the target of our method differs significantly from [22]. [22] aims to predict a set of human-specified concepts as an intermediate step, with each concept having a fixed (albeit learned) importance on the final prediction.
Contrastingly, iTransplant aims to predict individualized policies (equivalently a set of weights) over a set of clinician-specified criteria, but not the fixed values of such criteria. The distinct targets lead to significant differences in the problem formulation, methodology and analysis in our paper and in
[22]. 4
Figure 2: Network structure of the iTransplant framework.
In the proposed iTransplant framework, organ offers s = (X, O) are mapped to criteria space M via a transform T specified by domain experts. The transparent policies identified by iTransplant are all generated based the match criteria in space M. To achieve individualized policy identification, an auto-encoder structure is utilized to learn the latent representation Z ∈ Z of patient features
X. From Z, a specific policy signature ρ is generated by the policy selector network. Finally, the individualized policy πρ(a|s) is retrieved from the transparent policy space Π via the policy signature
ρ. This design ensures that the policies learned by iTransplant are innately individualized and human comprehensible. Detailed descriptions of the network structure and loss functions can be found in the
Appendix.
Policy guided patient stratification As shown in Figure 2, the policy selector network is built on top of a Mixture-of-Experts (MoE) layer [36], which contains a gating network and K expert networks. Based on the latent representation Z of a patient, the gating network will select k experts among the total K candidates and combine their outputs as the policy signature ρ. The MoE structure is applied to encourage the encoder network to group patients sharing the same decision policy in the latent space (see the Appendix for illustrations). The MoE layer in the policy selector network passes the gradient from the policy projection loss LP olicy back to the encoder network, enabling it to guide the encoder to map patients share the same policy as neighbours in the latent space Z. In this sense, in iTransplant, the representation learning of patient features in the latent space is guided by the learned policy, which allows the encoder network to learn the implicit stratification of patients from real-world transplantation data.
Individualized policy mapping Our main target is to find the patient-wise policy projec-tion ˆπ(θ) = πρ(X;θ) ∈ Π of expert policy π∗ such that the distance d(π∗, ˆπ(θ)) is min-imized. Note that the entropy of expert policy π∗ is a constant, we have d(π∗, ˆπ(θ)) =
−Es∼△(X ×O)[(cid:80) a∈{0,1} π∗(a|s) log(ˆπ(θ)(a|s))]+Constant, where the first term is the accumulated cross-entropy between π∗ and ˆπ(θ). Given demonstrations D = {(si, ai) : i = 1, 2, . . . , N } of expert policy π∗, the minimization of such accumulated KL-divergence can be achieved by minimizing the (cid:80)N following policy projection loss LP olicy = − 1
N
I(ai = a) log(ˆπ(θ)(ai|si)). a∈{0,1} (cid:80) i=1
Enforcing the consistency requirement Note that policies in space Π are innately consistent under perturbations to organ features. To meet the consistency requirement for inverse decision-making methods proposed in Section 2, a regularization term defined in equation (2) is enforced to improve consistency of policy projection in Π for patients with similar latent space representations.
LConsistency =
λ 2
Ex1,x2∼△(X ×X ) (cid:20) ∥ρ1 − ρ2∥2 2
∥z1 − z2∥2 2 (cid:21) (cid:12) (cid:12) x1, x2 (cid:12) (cid:12)
, (2) where △(X × X ) is the patient pair distribution over space X × X , ρ1, ρ2 and z1, z2 are policy signatures and latent representations for patients x1 and x2, respectively, λ > 0 is a hyperparameter. 4