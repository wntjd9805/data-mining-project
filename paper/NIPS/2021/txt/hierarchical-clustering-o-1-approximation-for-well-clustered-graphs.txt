Abstract
Hierarchical clustering studies a recursive partition of a data set into clusters of successively smaller size, and is a fundamental problem in data analysis. In this work we study the cost function for hierarchical clustering introduced by
Dasgupta [12], and present two polynomial-time approximation algorithms: Our
ﬁrst result is an O(1)-approximation algorithm for graphs of high conductance.
Our simple construction bypasses complicated recursive routines of ﬁnding sparse cuts known in the literature (e.g., [6, 11]). Our second and main result is an O(1)-approximation algorithm for a wide family of graphs that exhibit a well-deﬁned structure of clusters. This result generalises the previous state-of-the-art [10], which holds only for graphs generated from stochastic models. The signiﬁcance of our work is demonstrated by the empirical analysis on both synthetic and real-world data sets, on which our presented algorithm outperforms the previously proposed algorithm for graphs with a well-deﬁned cluster structure [10]. 1

Introduction
Hierarchical clustering (HC) studies a recursive partition of a data set into clusters of successively smaller size, via an effective binary tree representation. As a basic technique, hierarchical clustering has been employed as a standard package in data analysis, and has comprehensive applications in practice. While traditionally HC trees are constructed through bottom-up (agglomerative) heuristics, which lacked a clearly-deﬁned objective function, Dasgupta [12] has recently introduced a simple objective function to measure the quality of a particular hierarchical clustering and his work has inspired a number of research on this topic [3, 6, 7, 8, 10, 11, 20, 24]. Consequently, there has been a signiﬁcant interest in studying efﬁcient HC algorithms that not only work in practice, but also have proven theoretical guarantees with respect to Dasgupta’s cost function.
Our contribution.
In this work, we present two new approximation algorithms for constructing
HC trees that can be rigorously analysed with respect to Dasgupta’s cost function. For our ﬁrst result, we construct an HC tree of an input graph G entirely based on the degree sequence of V (G), and we show that the approximation guarantee of our constructed tree is with respect to the conductance of
G, which will be deﬁned formally in Section 2. The striking fact of this result is that, for any n-vertex graph G with m edges and conductance Ω(1) (a.k.a. expander graph), an O(1)-approximate HC tree of G can be very easily constructed in O(m + n log n) time, although obtaining such result for general graphs is impossible under the Small Set Expansion Hypothesis (SSEH) [6]. Our theorem is in line with a sequence of results for problems that are naturally linked to the Unique Games and
Small Set Expansion problems: it has been shown that such problems are much easier to solve once
∗The full version of the paper is available at https://arxiv.org/abs/2112.09055. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
the input instance exhibits the high conductance property [4, 5, 16, 18]. However, to the best of our knowledge, our result is the ﬁrst of this type for hierarchical clustering.
While our ﬁrst result presents an interesting theoretical fact, we further study whether we can extend this O(1)-approximate construction to a much wider family of graphs occurring in practice.
Speciﬁcally, we look at well-clustered graphs, i.e., the graphs in which vertices within each cluster are better connected than vertices between different clusters and the total number of clusters is constant.
This includes a wide range of graphs occurring in practice with a clear cluster-structure, and have been extensively studied over the past two decades (e.g., [13, 15, 23, 26]). As our second and main result, we present a polynomial-time O(1)-approximation algorithm that constructs an HC tree for a well-clustered graph. Given that the class of well-clustered graphs includes graphs with clusters of different sizes and asymmetrical internal structure, our result signiﬁcantly improves the previous state-of-the-art [10], which only holds for graphs generated from stochastic models. At the technical level, the design of our algorithm is based on the graph decomposition algorithm presented in [13], which is designed to ﬁnd a good partition of a well clustered graph. However, our analysis suggests that, in order to obtain an O(1)-approximation algorithm, directly applying their decomposition isn’t sufﬁcient for our purpose. To overcome this bottleneck, we reﬁne the output decomposition via a pruning technique, and carefully merge the reﬁned parts to construct our ﬁnal HC tree. In our point of view, our presented stronger graph decomposition procedure might have applications in other settings as well. To demonstrate the signiﬁcance of our work, we compare our algorithm against the previous state-of-the-art with similar approximation guarantee [10] and well-known linkage heuristics on both synthetic and real-world data sets. Although our algorithm’s performance is marginally better than
[10] for the graphs generated from the stochastic block models (SBM), the cost of our algorithm’s output is up to 50% lower than the one from [10] when the clusters of the input graph have different sizes and some cliques are embedded into a cluster.