Abstract
Optimization problems are ubiquitous in our societies and are present in almost every segment of the economy. Many of these optimization problems are NP-hard and computationally demanding, often requiring approximate solutions for large-scale instances. Machine learning frameworks that learn to approximate solutions to such hard optimization problems are a potentially promising avenue to address these diﬃculties, particularly when many closely related problem instances must be solved repeatedly. Supervised learning frameworks can train a model using the outputs of pre-solved instances. However, when the outputs are themselves approximations, when the optimization problem has symmetric solutions, and/or when the solver uses randomization, solutions to closely related instances may exhibit large diﬀerences and the learning task can become inherently more diﬃcult.
This paper demonstrates this critical challenge, connects the variation of the training data to the ability of a model to approximate it, and proposes a method for producing (exact or approximate) solutions to optimization problems that are more amenable to supervised learning tasks. The eﬀectiveness of the method is tested on hard non-linear nonconvex and discrete combinatorial problems. 1

Introduction
Constrained optimization (CO) is in daily use in our society, with applications ranging from supply chains and logistics, to electricity grids, organ exchanges, marketing campaigns, and manufacturing to name only a few. Two classes of hard optimization problems of particular interest in many ﬁelds are (1) combinatorial optimization problems and (2) nonlinear constrained problems. Combinato-rial optimization problems are characterized by discrete search spaces and have solutions that are combinatorial in nature, involving for instance, the selection of subsets or permutations, and the sequencing or scheduling of tasks. Nonlinear constrained problems may have continuous search spaces but are often characterized by highly nonlinear constraints, such as those arising in electrical power systems whose applications must capture physical laws such as Ohm’s law and Kirchhoﬀ’s law in addition to engineering operational constraints. Such CO problems are often NP-Hard and may be computationally challenging in practice, especially for large-scale instances.
While the AI and Operational Research communities have contributed fundamental advances in optimization in the last decades, the complexity of some problems often prevents them from being adopted in contexts where many instances must be solved over a long-term horizon (e.g., multi-year planning studies) or when solutions must be produced under time constraints. Fortunately, in many practical cases, including the scheduling and energy problems motivating this work, one is interested in solving many problem instances sharing similar patterns. Therefore, the application of deep learning methods to aid the solving of computationally challenging constrained optimization problems appears to be a natural approach and has gained traction in the nascent area at the intersection 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
between CO and ML [5, 19, 31]. In particular, supervised learning frameworks can train a model using pre-solved CO instances and their solutions. However, learning the underlying combinatorial structure of the problem or learning approximations of optimization problems with hard physical and engineering constraints may be an extremely diﬃcult task. While much of the recent research at the intersection of CO and ML has focused on learning good CO approximations in jointly training prediction and optimization models [3, 18, 22, 25, 32] and incorporating optimization algorithms into diﬀerentiable systems [1, 27, 34, 20], learning the combinatorial structure of CO problems remains an elusive task.
Beside the diﬃculty of handling hard constraints, which will almost always exhibit some viola-tions, two interesting challenges have emerged: the presence of multiple, often symmetric, solu-tions, and the learning of approximate solution methods. The ﬁrst challenge recognizes that an optimization problem may not have a unique solution. This challenge is illustrated in Figure 1, where the various y(i) represent optimal solutions to CO instances x(i) and C the feasible space. As a result, a com-binatorial number of possible datasets may be generated.
While equally valid as optimal solutions, some sets follow patterns which are more meaningful and recognizable. Sym-metry breaking is of course a major area of combinatorial optimization and may alleviate some of these issues. But diﬀerent instances may not break symmetries in the same fashion, thus creating datasets that are harder to learn.
The second challenge comes from realities in the application domain. Because of time constraints, the solution technique may return a sub-optimal solution. Moreover, modern com-binatorial optimization techniques often use randomization and large neighborhood search to produce high-quality solutions quickly. Although these are widely successful, diﬀerent runs for the same, or similar, instances may produce radically diﬀerent solutions. As a result, learning the solutions returned by these approximations may be inherently more diﬃcult. These eﬀects may be viewed as a source of noise that obscures the relationships between training data and their target outputs.
Although this does not raise issues for optimization systems, it creates challenging learning tasks.
Figure 1: Co-optimal datasets due to sym-metries.
This paper demonstrates these relations, connects the variation in the training data to the ability of a model to approximate it, and proposes a method for producing (exact or approximate) solutions to optimization problems that are more amenable to supervised learning tasks. More concretely, the paper makes the following contributions: 1. It shows that the existence of co-optimal or approximated solutions obtained by solving hard CO problems to construct training datasets challenges the learnability of the task. 2. To overcome this limitation, it introduces the problem of optimal dataset design, which is cast as a bilevel optimization problem. The optimal dataset design problem is motivated using theoretical insights on the approximation of functions by neural networks, relating the properties of a function describing a training dataset to the model capacity required to represent it. 3. It introduces a tractable algorithm for the generation of datasets that are amenable to learning, and empirical demonstration of marked improvements to the accuracy of trained models, as well as the ability to satisfy constraints at inference time. 4. Finally, it provides state-of-the-art accuracy results at vastly enhanced computational runtime on learning two challenging optimization problems: Job Shop Scheduling problems and Optimal
Power Flow problems for energy networks.
To the best of the authors’ knowledge, this work is the ﬁrst to highlight the issue of learnability in the face of co-optimal or approximate solutions obtained to generate training data for learning to approximate hard CO problems. The observations raised in this work may result in a broader impact as, in addition to approximating hard optimization problems, the optimal dataset generation strategy introduced in this paper may be useful to the line of work on integrating CO as diﬀerentiable layers for predictive and prescriptive analytics, as well as for physics constrained learning problems such as when approximating solutions to systems of partial diﬀerential equation. 2
2