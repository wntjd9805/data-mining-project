Abstract
Hamiltonian Monte Carlo (HMC) is a popular Markov Chain Monte Carlo (MCMC) algorithm to sample from an unnormalized probability distribution. A leapfrog integrator is commonly used to implement HMC in practice, but its per-formance can be sensitive to the choice of mass matrix used therein. We develop a gradient-based algorithm that allows for the adaptation of the mass matrix by encouraging the leapfrog integrator to have high acceptance rates while also ex-ploring all dimensions jointly. In contrast to previous work that adapt the hyper-parameters of HMC using some form of expected squared jumping distance, the adaptation strategy suggested here aims to increase sampling efﬁciency by maxi-mizing an approximation of the proposal entropy. We illustrate that using multiple gradients in the HMC proposal can be beneﬁcial compared to a single gradient-step in Metropolis-adjusted Langevin proposals. Empirical evidence suggests that the adaptation method can outperform different versions of HMC schemes by ad-justing the mass matrix to the geometry of the target distribution and by providing some control on the integration time. 1

Introduction
Consider the problem of sampling from a target density π on Rd of the form π(q) ∝ e−U (q), with a potential energy U : Rd → R being twice continuously differentiable. HMC methods [20, 46, 9] sample from a Boltzmann-Gibbs distribution µ(q, p) ∝ e−H(q,p) on the phase-space R2d based on the (separable) Hamiltonian function
H(q, p) = U (q) + K(p) with K(p) = 1 2 p(cid:62)M −1p.
The Hamiltonian represents the total energy that is split into a potential energy term U and a ki-netic energy K which we assume is Gaussian for some symmetric positive deﬁnite mass matrix M .
Suppose that (q(t), p(t))t∈R evolve according to the differential equations dq(t) dt
=
∂H(q(t), p(t))
∂p
= M −1p(t) and dp(t) dt
= −
∂H(q(t), p(t))
∂q
= −∇U (q(t)). (1)
Let (ϕt)t(cid:62)0 denote the ﬂow of the Hamiltonian system, that is for ﬁxed t, ϕt maps each (q, p) to the solution of (1) that takes value (q, p) at time t = 0. The exact HMC ﬂow ϕ preserves 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
volume and conserves the total energy i.e. H ◦ ϕt = H. Consequently, the Boltzmann-Gibbs distribution µ is invariant under the Hamiltonian ﬂow, that is µ(ϕt(E)) = µ(E) for any Borel set E ⊂ R2d. Furthermore, the ﬂow satisﬁes the generalized reversibility condition F ◦ ϕt =
ϕ−t ◦ F with the ﬂip operator F(q, p) = (q, −p). Put differently, the Hamiltonian dynamics go backward in time by negating the velocity.
If an analytical expression for the exact ﬂow were available, one could sample from µ using the invariant Markov chain that at state (q, p) ﬁrst draws a new velocity p(cid:48) ∼ N (0, M ) with the next state set to ϕT (q, p(cid:48)) for some integration time T > 0.
Such a velocity refreshment is necessary as the HMC dynamics preserve the energy and so cannot be ergodic. However, the Hamiltonian ﬂow cannot be computed exactly, except for very special potential functions. Numerical approximations to the exact solution of Hamiltonian’s equations are thus routinely used, most commonly the leapfrog method, also known as (velocity) Verlet integrator
[28, 10]. For a step size h > 0 and L steps, such an algorithm updates the previous state q0 and a new velocity p0 ∼ N (0, M ) by setting, for 0 (cid:54) (cid:96) (cid:54) L − 1, p(cid:96)+ 1 2
= p(cid:96) − h 2
∇U (q(cid:96)); q(cid:96)+1 = q(cid:96) + hM −1p(cid:96)+ 1 2
; p(cid:96)+1 = p(cid:96)+ 1 2
− h 2
∇U (q(cid:96)+1). (2)
This scheme can be motivated by splitting the Hamiltonian wherein the kick mappings in the ﬁrst and third step update only the momentum, while the drift mapping in the second step advances only the position q with constant speed. For T = Lh, the leapfrog integrator approximates ϕT (q0, p0) by (qL, pL) while also preserving some geometric properties of ϕ, namely volume preservation and generalized reversibility. The leapfrog method is a second-order integrator, making an O(h2) energy error H(qL, pL) − H(q0, p0). A µ-invariant Markov chain can be constructed using a Metropolis-Hastings acceptance step. More concretely, the proposed state (qL, pL) is accepted with the ac-ceptance rate a(q0, p0) = min{1, exp [− (H(qL, pL) − H(q0, p0))]}, while the next state is set to F(q0, p0) in case of rejection, although the velocity ﬂip is inconsequential for full refreshment strategies.
We want to explore here further the generalised speed measure introduced in [54] for adapting RWM or MALA that aim to achieve fast convergence by constructing proposals that (i) have a high average log-acceptance rate and (ii) have a high entropy. Whereas the entropy of the proposal in RWM or
MALA algorithms can be evaluated efﬁciently, the multi-step nature of the HMC trajectories makes this computation less tractable. The recent work in [41] consider the same adaptation objective by learning a normalising ﬂow that is inspired by a leapfrog proposal with a more tractable entropy by masking components in a leapfrog-style update via an afﬁne coupling layer as used for RealNVPs
[19]. [60] sets the integration time by maximizing the proposal entropy for the exact HMC ﬂow in
Gaussian targets, while choosing the mass matrix to be the inverse of the sample covariance matrix. 2