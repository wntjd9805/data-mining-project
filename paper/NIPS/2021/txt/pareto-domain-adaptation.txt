Abstract
Domain adaptation (DA) attempts to transfer the knowledge from a labeled source domain to an unlabeled target domain that follows different distribution from the source. To achieve this, DA methods include a source classiﬁcation objective LS to extract the source knowledge and a domain alignment objective LD to diminish the domain shift, ensuring knowledge transfer. Typically, former DA methods adopt some weight hyper-parameters to linearly combine the training objectives to form an overall objective L. However, the gradient directions of these objectives may conﬂict with each other due to domain shift. Under such circumstances, the linear optimization scheme might decrease the overall objective value at the expense of damaging one of the training objectives, leading to restricted solutions. In this paper, we rethink the optimization scheme for DA from a gradient-based perspec-tive. We propose a Pareto Domain Adaptation (ParetoDA) approach to control the overall optimization direction, aiming to cooperatively optimize all training objectives. Speciﬁcally, to reach a desirable solution on the target domain, we de-sign a surrogate loss mimicking target classiﬁcation. To improve target-prediction accuracy to support the mimicking, we propose a target-prediction reﬁning mecha-nism which exploits domain labels via Bayes’ theorem. On the other hand, since prior knowledge of weighting schemes for objectives is often unavailable to guide optimization to approach the optimal solution on the target domain, we propose a dynamic preference mechanism to dynamically guide our cooperative optimization by the gradient of the surrogate loss on a held-out unlabeled target dataset. Our theoretical analyses show that the held-out data can guide but will not be over-ﬁtted by the optimization. Extensive experiments on image classiﬁcation and semantic segmentation benchmarks demonstrate the effectiveness of ParetoDA. Our code is available at https://github.com/BIT-DA/ParetoDA. 1

Introduction
Domain adaptation (DA) is a well-established paradigm for learning a model on an unlabeled target domain with the assistance of a labeled related source domain, which has attracted a surge of interests in the machine learning community [34, 33, 13]. By bridging the domain gap on the premise of ensuring the performance of source classiﬁcation task, DA can adapt the model learned from the source domain to the target in the presence of data bias, which solves the dilemma of label scarcity in many real-world applications [55, 47, 11, 45, 3, 57]. Extensive DA approaches have been proposed in recent years, achieving great performances in many areas such as image classiﬁcation [11, 27, 56], semantic segmentation [49, 52, 16], and object detection [39, 43, 54].
∗ Equal contributions from both authors.
† Corresponding author. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
Most DA methods are devoted to aligning the distributions across domains by explicitly minimizing some discrepancy metrics [26, 28, 56] or adopting adversarial learning [11, 27, 41]. However, since the domain alignment objective also depends on the target domain that deviates from the source, the gradient direction of it may conﬂict with that of classiﬁcation objective on the source domain.
Thus, when the optimization proceeds to a certain stage, one objective will deteriorate if further improving the other one. Under this circumstance, no solution can reach the optimal of each objective at the same time. We can only obtain a set of so-called Pareto optimal solutions instead, where we cannot further decrease all objectives simultaneously [10]. All Pareto optimal solutions in loss space compose Pareto front as shown in Fig. 1.
Figure 1: Illustration of different optimization schemes. In each panel, the blue curve is the Pareto front where the region underneath is unaccessible. (a)-(b): Linear scheme that adopts weight hyper-parameters to unify the objectives. The green and purple dash lines represent different hyper-parameters. (c): Previous gradient-based scheme, which reaches Pareto optimal solutions with or without the guidance of preference vector. (d): Our ParetoDA that dynamically guides the optimization by the gradient of the target-classiﬁcation-mimicking loss on a held-out unlabeled target dataset, approaching the expected solution that minimizes the target classiﬁcation loss.
This dilemma obviously has been overlooked by most former DA methods, which generally adopt some empirical weight hyper-parameters to linearly combine the objectives, constructing an overall objective. This linear weighting scheme has two major concerns. First, as pointed out in [4], it can only obtain solutions on the convex part of the Pareto front of the objectives, while cannot reach the non-convex part, as shown in Fig. 1 (a)-(b). That is because it only considers reducing the overall objective value, which might damage some objectives during optimization (see the red up-arrow). Unfortunately, the Pareto fronts of DA methods are often non-convex, due to loss conﬂict caused by domain shift.
See examples shown in Fig. 2. Second, one could hardly reach the desired solution that performs best on target domain by tuning the weight hyper-parameters, since the obtained solution will deviate severely when the trade-offs slightly change (see the slopes of the dash lines in Fig. 1 (a)-(b) for reference).
The non-convex
Figure 2:
Pareto fronts of DANN [11] and CDAN [27] on task W→A (Ofﬁce-31).
To remedy these issues, we rethink the optimization scheme for DA from a gradient-based perspective.
By weighting objectives to control the overall optimization direction so that no objective deteriorates, one can reach a Pareto optimal solution on the Pareto front [1, 23, 30, 32]. Moreover, [30] precisely sets objective weights according to a preﬁxed preference vector (see Fig. 1 (c)). However, neither of them suits DA, because 1) in DA, the goal is to minimize the target classiﬁcation loss L∗
T , but neither LS or LD directly corresponds to this goal; 2) the target domain has no label to construct a classiﬁcation loss for the goal; 3) prior knowledge of weighting schemes for objectives is often unavailable to guide optimization to approach the optimal solution that minimizes L∗
T .
In this paper, we propose a Pareto Domain Adaptation (ParetoDA) approach, which cooperatively optimizes training objectives and is speciﬁcally designed for DA. Speciﬁcally, to minimize L∗
T , we design a target-classiﬁcation-mimicking (TCM) loss LT by the mutual information [17] leveraging the target predictions. In this loss, target predictions act as (soft) labels for themselves. Therefore, the accuracy of the predictions is important to support the mimicking. To reﬁne the predictions by maximally exploiting the information at hand, we propose a target prediction reﬁning mechanism which models the domain label as conditional information into the prediction probability by Bayes’ theorem. Intuitively, we ensembles a class-wise domain discriminator (trained with the domain labels) 2
as another classiﬁer—only when the class condition is correct, the discriminator can correctly predict the domain. On the other hand, to weight LT , LS and LD to guide the cooperative optimization towards minimizing L∗
T , we propose a dynamic preference mechanism to model the gradient of LT on a held-out unlabeled target dataset as the guidance. We evaluate the performance on the held-out data because 1) it suggests generalization performance, and 2) it is more stable and convincible than training data. One may be concerned that involving the gradient of the held-out data in training may eventually cause over-ﬁtting of the data. Fortunately, our theoretical analyses show that the held-out data can guide but will not be over-ﬁtted by the optimization of our method. Our contributions are:
• We rethink the optimization scheme in existing DA methods, which can only reach restricted solutions if the optimization objectives conﬂict with each other. And existing gradient-based strategies do not suit DA.
• We propose a Pareto Domain Adaptation method to obtain the desired Pareto optimal solution learned and dynamically guided (using the held-out unlabeled target data) by the designed surrogate objective function that mimics target classiﬁcation. To better support the mimicking, we also propose a target prediction reﬁning mechanism. As a general technique,
ParetoDA can be plugged into various DA methods and enhance their performance.
• We evaluate ParetoDA on two DA applications: image classiﬁcation and semantic segmenta-tion. Experimental results demonstrate the effectiveness of ParetoDA. 2