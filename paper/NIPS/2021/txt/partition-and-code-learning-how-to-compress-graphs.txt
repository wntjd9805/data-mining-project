Abstract
Can we use machine learning to compress graph data? The absence of ordering in graphs poses a signiﬁcant challenge to conventional compression algorithms, limiting their attainable gains as well as their ability to discover relevant patterns.
On the other hand, most graph compression approaches rely on domain-dependent handcrafted representations and cannot adapt to different underlying graph dis-tributions. This work aims to establish the necessary principles a lossless graph compression method should follow to approach the entropy storage lower bound.
Instead of making rigid assumptions about the graph distribution, we formulate the compressor as a probabilistic model that can be learned from data and generalise to unseen instances. Our “Partition and Code” framework entails three steps: ﬁrst, a partitioning algorithm decomposes the graph into subgraphs, then these are mapped to the elements of a small dictionary on which we learn a probability distribution, and ﬁnally, an entropy encoder translates the representation into bits. All the components (partitioning, dictionary and distribution) are parametric and can be trained with gradient descent. We theoretically compare the compression quality of several graph encodings and prove, under mild conditions, that PnC achieves compression gains that grow either linearly or quadratically with the number of vertices. Empirically, PnC yields signiﬁcant compression improvements on diverse real-world networks.1 1

Introduction
Lossless data compression has been one of the most fundamental and long-standing problems in computer science. It is by now well-understood that the intrinsic limits of compression are governed by the entropy of the underlying data distribution [1]. Crucially, these limits expose an intimate connection between compressibility and machine learning: the better one models the underlying data distribution (from limited observations) the more bits can be saved and vice-versa [2].
The compression of ordered data such as text, images, or video, underpins the modern technology from web protocols to video streaming. However, graph-structured data remain a notable exception.
As graph data are becoming more prevalent, it becomes increasingly important to invent practical ways to encode them parsimoniously.
There are three main challenges one faces when attempting to compress graphs:
∗This work was done while Giorgos Bouritsas was visiting Dr. Andreas Loukas at EPFL, Lausanne. 1The source code is publicly available at https://github.com/gbouritsas/PnC 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
C1. Dealing with graph isomorphism (GI). A key difﬁculty that distinguishes graphs from conven-tional data lies in the absence of an inherent ordering of the graph vertices. In order to be able to approach the storage lower bounds, isomorphic graphs should be encoded with the same codeword.
However, since the complexity of known algorithms for GI is super-polynomial on the number of vertices [3], a direct use of GI is impractical for graphs consisting of more than a few hundred vertices.
Indeed, an examination of the graph compression literature reveals that most progress has been made by optimising a vertex ordering and adapting methods originally invented for vectored data [4–6].
Unfortunately, naively encoding graphs as vectors results in a signiﬁcant loss in compression2.
C2. Evaluating the likelihood. An optimal encoder [1] requires one to accurately estimate and evaluate the probabilities of all the possible outcomes of the underlying domain. When dealing with high-dimensional data, this can be addressed by partitioning the data into parts to obtain a decomposition of the probability distribution: e.g., images can be compressed by modelling the distribution of pixels or patches [10–12], and text by focusing on characters or n-grams [13–19].
However, since graphs do not admit an efﬁciently computable canonical ordering, it is unclear what decomposition one should employ.
C3. Accounting for the description length of the learned model. The classical learning theory trade-off between model complexity and generalisation is of paramount concern for effective compression.
Though in typical deep learning applications one can aim to model the data distribution with an overparametrised neural network (NN) that generalises well, utilising such models to compress information is problematic: since decoding is impossible unless the decoder also receives the learned model (i.e., the NN parameters), overparametrised models are, by deﬁnition, suboptimal. This is a pertinent issue for likelihood-based neural approaches as overparametrisation is commonly argued to be a key component of why NNs can be trained [20–22].
The Partition and Code (PnC) framework. Our main contribution is PnC, a framework for learning compression algorithms suitable for encoding graphs sampled from an underlying distribution. In the heart of PnC lie two ideas: (a) Learn to break the problem into parts. Rather than predicting directly the likeli-hood, we aim to learn how to decompose graphs into non-overlapping subgraphs, see Fig. 1. (b) Identify and code recurring subgraphs when possible. We use a learned dictionary to code subgraphs that appear frequently, whereas rare subgraphs are encoded sep-arately. The dictionary is restricted to contain only a ﬁnite number of small recurring subgraphs. This biases the model towards interpretable and well gen-eralising solutions. Both the “partition” and “code” components of PnC are learned directly from the data, by optimising the total description length.
Figure 1: Illustration of the graph decom-position. The subgraph colours correspond to dictionary atoms a1, a2 and a3. Cuts are denoted in red.
Our framework provides a solution to the three challenges of graph compression. C1: By constraining the dictionary to only contain graphs of size up to a small constant, we can efﬁciently solve GI. C2:
Graph partitioning provides us with the desirable decomposition of the distribution. Using appropriate parametrised probabilistic models, we obtain a closed-form expression for the likelihood that can be later used by any close-to-optimal entropy coder [23–25]. C3: Since we use NNs to decompose the distribution (and not to predict the likelihood), we can rely on overparametrisation without having to relay the NN parameters to the decoder. Also, the complexity of our learned hypothesis (the dictionary) can be computed, and thus optimised, during training.
Theoretical results. Our analysis reveals that PnC can signiﬁcantly improve upon less sophisticated graph encoders and justiﬁes the usefulness of both the “Partition” and the “Code” component.
Speciﬁcally, we prove that under mild conditions on the underlying graph distribution, PnC requires in expectation Θ(n2) less bits than standard graph encodings, even if the latter are given access to an 2This follows by a simple counting argument: there are 2(n number for unlabelled graphs is asymptotically equal to 2(n probable, an encoding that does not consider isomorphism would sacriﬁce log n! bits [8, 9]. 2) labelled undirected graphs while the respective 2)/n! [7]. Thus, if all graphs of n vertices are equally 2
oracle that solves GI. Further, the dictionary induces additional savings of Θ(n) bits, with the gain being inversely proportional to the entropy of the distribution of the dictionary atoms. Thus, the more repetitive the patterns in the graph distribution are, the larger will be the compression beneﬁts of PnC.
Practical algorithms. We instantiate of our framework using the following algorithmic modules: (a) a low-parameter learnable estimate of the probability distribution, (b) learning to select the dictionary from a graph universe of ﬁnite size, and (c) learning to partition. The latter is a parametric randomised iterative algorithm, the probabilities of which are inferred from a Graph Neural Network (GNN) and optimised with reinforcement learning. Importantly, all algorithms can be jointly trained in order to minimise the total description length in a synergistic manner. We evaluate our framework on diverse real-world graph distributions and showcase compression gains with respect to both conventional and advanced baseline compressors, in observed and unseen data. 2