Abstract
Tuning hyperparameters is a crucial but arduous part of the machine learning pipeline. Hyperparameter optimization is even more challenging in federated learn-ing, where models are learned over a distributed network of heterogeneous devices; here, the need to keep data on device and perform local training makes it difﬁcult to efﬁciently train and evaluate conﬁgurations. In this work, we investigate the prob-lem of federated hyperparameter tuning. We ﬁrst identify key challenges and show how standard approaches may be adapted to form baselines for the federated setting.
Then, by making a novel connection to the neural architecture search technique of weight-sharing, we introduce a new method, FedEx, to accelerate federated hyperparameter tuning that is applicable to widely-used federated optimization methods such as FedAvg and recent variants. Theoretically, we show that a FedEx variant correctly tunes the on-device learning rate in the setting of online convex optimization across devices. Empirically, we show that FedEx can outperform natural baselines for federated hyperparameter tuning by several percentage points on the Shakespeare, FEMNIST, and CIFAR-10 benchmarks—obtaining higher accuracy using the same training budget. 1

Introduction
Federated learning (FL) is a popular distributed computational setting where training is performed locally or privately [30, 36] and where hyperparameter tuning has been identiﬁed as a critical problem [18]. Although general hyperparameter optimization has been the subject of intense study [3, 16, 26], several unique aspects of the federated setting make tuning hyperparameters especially challenging. However, to the best of our knowledge there has been no dedicated study on the speciﬁc challenges and solutions in federated hyperparameter tuning. In this work, we ﬁrst formalize the problem of hyperparameter optimization in FL, introducing the following three key challenges: 1. Federated validation data: In federated networks, as the validation data is split across devices, the entire dataset is not available at any one time; instead a central server is given access to some number of devices at each communication round, for one or at most a few runs of local training and validation. Thus, because the standard measure of complexity in FL is the number of communication rounds, computing validation metrics exactly dramatically increases the cost. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
Figure 1: FedEx can be applied to any local training-based FL method, e.g. FedAvg, by interleaving standard updates to model weights (computed by aggregating results of local training) with exponen-tiated gradient updates to hyperparameters (computed by aggregating results of local validation). 2. Extreme resource limitations: FL applications often involve training using devices with very limited computational and communication capabilities. Furthermore, many require the use of privacy techniques such as differential privacy that limit the number times user data can be accessed.
Thus we cannot depend on being able to run many different conﬁgurations to completion. 3. Evaluating personalization: Finally, even with non-federated data, applying common hyperpa-rameter optimization methods to standard personalized FL approaches (such as ﬁnetuning) can be costly because evaluation may require performing many additional training steps locally.
With these challenges1 in mind, we propose reasonable baselines for federated hyperparameter tuning by showing how to adapt standard non-federated algorithms. We further study the challenge of noisy validation signal due to federation, and show that simple state-estimation-based ﬁxes do not help.
Our formalization and analysis of this problem leads us to develop FedEx, a method that exploits a novel connection between hyperparameter tuning in FL and the weight-sharing technique widely used in neural architecture search (NAS) [4, 34, 40]. In particular, we observe that weight-sharing is a natural way of addressing the three challenges above for federated hyperparameter tuning, as it incorporates noisy validation signal, simultaneously tunes and trains the model, and evaluates personalization as part of training rather than as a costly separate step. Although standard weight-sharing only handles architectural hyperparameters such as the choice of layer or activation, and not critical settings such as those of local stochastic gradient descent (SGD), we develop a formulation that allows us to tune most of these as well via the relationship between local-training and ﬁne-tuning-based personalization. This make FedEx a general hyperparameter tuning algorithm applicable to many local training-based FL methods, e.g. FedAvg [36], FedProx [31], and SCAFFOLD [19].
In Section 4, we next conduct a theoretical study of FedEx in a simple setting: tuning the client step-size. Using the ARUBA framework for analyzing meta-learning [20], we show that a variant of FedEx correctly tunes the on-device step-size to minimize client-averaged regret by adapting to the intrinsic similarity between client data. We improve the convergence rate compared to some past meta-learning theory [20, 25] while not depending on knowing the (usually unknown) task-similarity.
Finally, in Section 5, we instantiate our baselines and FedEx to tune hyperparameters of FedAvg,
FedProx, and Reptile, evaluating on three standard FL benchmarks: Shakespeare, FEMNIST, and
CIFAR-10 [5, 36]. While our baselines already obtain performance similar to past hand-tuning,
FedEx further surpasses them in most settings examined, including by 2-3% on Shakespeare.