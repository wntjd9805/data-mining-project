Abstract
Silicon-photonics-based optical neural network (ONN) is a promising hardware platform that could represent a paradigm shift in efficient AI with its CMOS-compatibility, flexibility, ultra-low execution latency, and high energy efficiency.
In-situ training on the online programmable photonic chips is appealing but still en-counters challenging issues in on-chip implementability, scalability, and efficiency.
In this work, we propose a closed-loop ONN on-chip learning framework L2ight to enable scalable ONN mapping and efficient in-situ learning. L2ight adopts a three-stage learning flow that first calibrates the complicated photonic circuit states under challenging physical constraints, then performs photonic core mapping via combined analytical solving and zeroth-order optimization. A subspace learning procedure with multi-level sparsity is integrated into L2ight to enable in-situ gra-dient evaluation and fast adaptation, unleashing the power of optics for real on-chip intelligence. Extensive experiments demonstrate our proposed L2ight outperforms prior ONN training protocols with 3-order-of-magnitude higher scalability and over 30× better efficiency, when benchmarked on various models and learning tasks. This synergistic framework is the first scalable on-chip learning solution that pushes this emerging field from intractable to scalable and further to efficient for next-generation self-learnable photonic neural chips. From a co-design perspective,
L2ight also provides essential insights for hardware-restricted unitary subspace optimization and efficient sparse training. We open-source our framework at link. 1

Introduction
The escalating scales of deep learning models and datasets have brought increased demand for computing capacities in electronic processors. Stringent performance and efficiency constraints in practical applications raise a surging need to develop more efficient computing solutions. As a promising substitute for conventional electronics, optical neural networks (ONNs) have attracted extensive research interests owing to their sub-nanosecond latency and attojoule/multiply-accumulate operation (MAC) energy efficiency [42, 6, 51, 41, 54, 14, 15], shown in Figure 1(a).
However, robustness and trainability are still critical issues for photonic AI engines [58, 22, 60].
Due to the analog computing nature of ONNs, the photonic DNN model inevitably suffer from performance degradation or even complete malfunction [58, 60] with the existence of manufacturing errors, non-ideal device controls, and undesired circuit noises, shown in Figure 1(b). Though non-ideal effects can be simulated and considered during software training [58, 22] to improve noise tolerance, the variation simulation is physically inaccurate (especially with unknown process variations) and prohibitively expensive, shown in Figure 1(c). 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
Recently, on-device train-ing has become an appeal-ing trend towards adapt-able and self-learning
ONNs. However, training on photonic neural chips is non-trivial and much less explored than on con-ventional platforms. Prior work [57, 25, 21, 18] only demonstrated small proto-types, and their scalability and efficiency are rather limited. To push the limits of DNNs in optics, we propose an efficient three-stage learning framework
L2ight that consists of variation-agnostic identity calibration, alternate projection-based parallel mapping, and multi-level sparse subspace learning. The main contributions of this work are four-fold,
Figure 1: Comprehensive motivations. (a) Computational efficiency superior-ity of ONNs [42]. (b) Noise sensitivity of ONNs (Q: 8-bit quantization, CT: crosstalk, DV: device variation, PB: phase bias). (c) Runtime of noise-free matrix multiplication vs. w/ noise simulation (Q+CT+DV). (b) (a) (c)
• Scalability. For the first time, an ONN learning protocol can scale up to million-level parameters under practical circuit non-ideality, over 3-order-of-magnitude more scalable than prior arts.
• Efficiency. We explore multi-level sparsity in in-situ gradient evaluation to trim down unnecessary on-chip training energy and runtime cost.
• Learnability. By trading redundant representability, our restricted subspace optimization can provide ONNs with enough adaptability for on-device self-learning and task transfer.
• Robustness. Various practical device noises and process variations are considered in situ to facilitate noise-resilient photonic AI engines.
• To our best knowledge, this is the first framework that supports on-chip training on million-parameter ONNs, over 1000× more scalable and 30× more efficient than prior art. We open-source a PyTorch-centric [38] ONN library torchonn and release our on-chip training framework at link. 2