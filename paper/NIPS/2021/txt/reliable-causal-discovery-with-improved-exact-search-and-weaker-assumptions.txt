Abstract
Many of the causal discovery methods rely on the faithfulness assumption to guarantee asymptotic correctness. However, the assumption can be approximately violated in many ways, leading to sub-optimal solutions. Although there is a line of research in Bayesian network structure learning that focuses on weakening the assumption, such as exact search methods with well-deﬁned score functions, they do not scale well to large graphs. In this work, we introduce several strategies to improve the scalability of exact score-based methods in the linear Gaussian setting. In particular, we develop a super-structure estimation method based on the support of inverse covariance matrix which requires assumptions that are strictly weaker than faithfulness, and apply it to restrict the search space of exact search.
We also propose a local search strategy that performs exact search on the local clusters formed by each variable and its neighbors within two hops in the super-structure. Numerical experiments validate the efﬁcacy of the proposed procedure, and demonstrate that it scales up to hundreds of nodes with a high accuracy. 1

Introduction
Although it is often more reliable to discover causal relationships by making use of interventions or randomized experiments, they are practically challenging, expensive, or even prohibited owing to ethical considerations. Thus, causal discovery from observational data has received considerable attention in recent decades, and has been widely applied in different ﬁelds such as genetics [29].
One major class of causal discovery methods is the constraint-based methods, such as PC [40] and
FCI [43, 4], that leverage conditional independence tests to estimate the skeleton and then perform edge orientation. These methods are guaranteed to asymptotically return the true Markov equivalence class (MEC) under the Markov and faithfulness assumptions. Several modiﬁcations [30, 41] to these constraint-based methods have been developed to allow certain types of unfaithfulness, which, however, generally give rise to weaker claims and are not guaranteed to estimate the true MEC.
Another popular approach is the GES [3] algorithm that searches in the space of MECs greedily by maximizing a well-deﬁned score, such as the Bayesian information criterion (BIC) [36] score. It starts with an empty structure and consists of two phases: (1) adding edges until a local maximum is found, and (2) removing edges until a local maximum is reached. In spite of the greedy strategy, GES converges in the large sample limit to the true MEC under the Markov and faithfulness assumptions, similar to the aforementioned constraint-based methods.
Recently, NOTEARS [52] casts the Bayesian network structure learning task into a continuous constrained optimization problem with the least squares objective, using an algebraic characterization of directed acyclic graph (DAG). Subsequent work GOLEM [23] adopts a continuous unconstrained optimization formulation with a likelihood-based objective. For NOTEARS, it remains unclear 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
of the required assumptions for asymptotic correctness, whereas GOLEM adopts the generalized faithfulness assumption [9] to learn linear Gaussian DAGs, which could be converted to their MECs for causal interpretation [42]. These methods enable the application of numerical solvers and GPU acceleration, which thus are scalable to large graphs. However, they are only guaranteed to ﬁnd a local optimum of the optimization problem, and therefore the quality of the solution in practice may not be guaranteed, even in the asymptotic case.
Another line of research focuses on weakening the faithfulness assumption required for asymptotic correctness of the search results, since, given ﬁnite samples, approximate violations of faithfulness occur surprisingly often, especially when there is a large number of variables [46]. For instance, exact search methods ﬁnd the optimal Bayesian network based on a predeﬁned score function, such as dynamic programming (DP) [18, 24, 39, 38], A* [49, 48], and integer programming [1, 5]. The
DAGs estimated by these methods can be converted to their MECs for causal interpretation [42].
Note that the approaches based on sparsest permutation (SP) [32] and Boolean satisﬁability solver (SAT) [15, 16] can be viewed as instances of exact methods. Lu et al. [22] further demonstrated that these exact methods may produce correct results in cases where methods relying on faithfulness fail.
Due to the large search space of possible DAGs [2, 13], exact search methods are feasible only for small structures. Therefore, super-structure has been adopted to constrain the search space [27, 45], which is deﬁned to be an undirected graph that restricts the search to candidate DAGs whose skeleton is its subgraph. However, most of these methods rely on discovering the skeleton of the true DAG for use as a super-structure, utilizing estimation methods like MMPC [45], which require the faithfulness assumption to be asymptotically correct. Under approximate violations of faithfulness, these skeleton estimation methods may miss some edges owing to unfaithful conditional independencies in the data distribution; thus, further exact search procedures are guaranteed to miss those edges.
In this work, we introduce several strategies to improve the scalability of exact
Contributions. search in the linear Gaussian setting, giving rise to a more reliable causal discovery procedure. Our main contributions can be summarized as follows:
• We develop a super-structure estimation method based on the support of inverse covariance matrix of the data distribution, and show that it is asymptotically correct under assumptions strictly weaker than faithfulness (or, more speciﬁcally, than triangle-faithfulness). We combine this with exact search method like DP or A* to reduce search space.
• To further scale up exact search, we develop a local search strategy, called Local A*, on the local clusters formed by each variable and its neighbors within two hops in the super-structure.
• We demonstrate the efﬁcacy of our super-structure estimation method and local search strategy by conducting extensive experiments, and show that it scales up to hundreds of nodes with a high accuracy.
Paper organization. We review the common assumptions for causal discovery and the linear struc-tural equation model (SEM) in Section 2. In Section 3, we establish weaker variants of faithfulness and show how they could be used to learn a sound super-structure. We further formulate an improved exact search strategy in Section 4. The empirical studies in Section 5 validate our theoretical results and the efﬁcacy of the proposed procedure. We then conclude our work in Section 6. 2