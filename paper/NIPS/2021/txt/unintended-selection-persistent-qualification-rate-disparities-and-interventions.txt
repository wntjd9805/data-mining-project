Abstract
Realistically—and equitably—modeling the dynamics of group-level disparities in machine learning remains an open problem. In particular, we desire models that do not suppose inherent differences between artiﬁcial groups of people—but rather endogenize disparities by appeal to unequal initial conditions of insular subpopulations. In this paper, agents each have a real-valued feature X (e.g., credit score) informed by a “true” binary label Y representing qualiﬁcation (e.g., for a loan). Each agent alternately (1) receives a binary classiﬁcation label ˆY (e.g., loan approval) from a Bayes-optimal machine learning classiﬁer observing X and (2) may update their qualiﬁcation Y by imitating successful strategies (e.g., seek a raise) within an isolated group G of agents to which they belong. We consider the disparity of qualiﬁcation rates Pr(Y = 1) between different groups and how this disparity changes subject to a sequence of Bayes-optimal classiﬁers repeatedly retrained on the global population. We model the evolving qualiﬁcation rates of each subpopulation (group) using the replicator equation, which derives from a class of imitation processes. We show that differences in qualiﬁcation rates between subpopulations can persist indeﬁnitely for a set of non-trivial equilibrium states due to uniformed classiﬁer deployments, even when groups are identical in all aspects except initial qualiﬁcation densities. We next simulate the effects of commonly proposed fairness interventions on this dynamical system along with a new feedback control mechanism capable of permanently eliminating group-level qualiﬁcation rate disparities. We conclude by discussing the limitations of our model and ﬁndings and by outlining potential future work. 1

Introduction
Algorithmic prediction is increasingly used for socially consequential decisions and may determine individual access to information, education, employment, credit, housing, medical treatment, freedom from incarceration, or freedom from military targeting [1–5]. This situation raises technical challenges and ethical concerns, particularly regarding the dynamics of systemic inequalities and attendant harms to society [6–8]. Nonetheless, realistically—and equitably—modeling the dynamics of disparity in machine learning remains an open problem.
Research historically considered the fairness of algorithmic predictions in terms of statistical (in)consistencies [9] (e.g., across groups [10–16] or between similar individuals [10, 11]), pref-erence guarantees [17–19], or causal considerations [19, 20] but ignored the response of a population to new prediction policies. For instance, the proportions of potential loan applicants in each group that will seek higher wages, falsify income, or forego application might change if banks use new policies to approve or deny loans, possibly counteracting fair intent. We refer this class of fairness deﬁnitions as normative present fairness. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
Efforts to model such population response [21–31]and the autonomous dynamical systems arising from mutual recursion with myopically updating prediction policies [21–29] have intensiﬁed, but it has remained to plausibly explain persistent disparities under group-independent prediction policies— i.e., those that do not discriminate on the basis of group membership—without assuming a setting that is structurally imbalanced between groups. Our paper contributes to these efforts and considers the long-term consequences of machine learning on inter-group disparities when a sequence of classiﬁers induces dynamics within the rates of strategy adoption in each group. Upon adopting a dynamical framework, we note that yet another operationalization of fairness arises: the asymptotic equality of latent variables (i.e., those causally responsible for outcome disparities) between groups. This notion of long-term fairness need not be consistent with normative present fairness, which may actively combat it, highlighting a tension between ends and means for fairness considerations. 1.1 Our contributions
Herein, we describe an equitable model of population response: one which does not suppose inherent differences between groups of people but endogenizes disparities by appeal to unequal initial conditions, accounting for group-speciﬁc environmental conditions as dynamical variables. We reform our notion of “groups” (i.e., subpopulations) to appeal to natural boundaries of information exchange rather than artiﬁcially imposed classes of people. We thus offer a potentially more meaningful way to group individuals in discussions of fairness, asserting that, when considering such networks of peer exchange, “sensitive attributes” such as race, sex, color, etc. might not correspond to meaningful divisions of people, which depend on social context. Finally, we recognize fairness interventions as dynamical control policies that (un)intentionally select the future trajectories of a given system. We therefore allow ourselves to consider interventions that explicitly incorporate feedback from dynamical variables—rather than relying on ﬁxed, prescriptive modiﬁcations of predictor loss functions.
Our ﬁrst contribution is to propose a model of classiﬁer-induced group-level strategy adoption that is (1) equitable, i.e., free from structurally asymmetric assumptions as described above, (2) capable of explaining persistent disparities under Bayes-optimal, group-independent policies, and (3) derivable from plausible, localized information exchange between individuals. Speciﬁcally, we appeal to the replicator equation, an established model for evolutionary phenomena without mutation, to model how competing strategies for qualiﬁcation (which determine true machine learning labels
,
} affecting agent utilities) replicate within groups (i.e., isolated subpopulations that differ only in size and initial proportions of qualiﬁed individuals). We ground statements with a running example involving loan applications (elaborated upon in Section 2.2) for which qualiﬁcation (label Y = 1), interpreted as being in the public interest, implies future repayment of a loan for an applicant with feature proﬁle X. As we avoid assuming inherent differences between groups, we consider the label-conditioned feature distribution Pr(X
Y = y) as group-independent and deﬁne qualiﬁcation disparity in terms of differences in group qualiﬁcation rates Pr(Y = 1). We formulate our model in Section 2, emphasizing that only the proﬁle of strategies in each subpopulation is subject to evolution—narrowly qualiﬁed by the competition between strategies for replicative success—rather than the subpopulations themselves. The persistence of disparity is thus attributed to classiﬁer policy. 0, 1
{
|
Our second contribution, in Section 3, is a rigorous examination of the dynamical system formed by the replicator equation and an updating, group-independent, Bayes-optimal classiﬁer policy, including a characterization of its equilibrium states with linear stability analysis. We identify the set of stable interior states of the system as a stable hyperplane and show that any initial state with non-zero total qualiﬁcation disparity, deﬁned in Section 3, will continue to exhibit non-zero disparity asymptotically if the state attracts to the stable hyperplane (Theorem 10). In this sense, we claim that qualiﬁcation rate disparity persists indeﬁnitely for this setting.
Our ﬁnal contribution, in Section 4 is to consider a dynamics-aware fairness intervention based on feedback control that parametrically violates classiﬁer group-independence (and therefore, in our setting, equalized odds [12–14] and envy-freeness [17, 18]) to achieve long-term fairness. We use simulation to contrast this feedback control policy to a group-independent classiﬁer; a policy subject to demographic parity [10, 11]; and “laissez-faire”, group-speciﬁc policies. We conclude by discussing the limitations of our model and our ﬁndings and by outlining potential future work. 1.2