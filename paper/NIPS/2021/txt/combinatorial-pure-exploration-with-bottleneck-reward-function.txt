Abstract
In this paper, we study the Combinatorial Pure Exploration problem with the
Bottleneck reward function (CPE-B) under the ﬁxed-conﬁdence (FC) and ﬁxed-budget (FB) settings. In CPE-B, given a set of base arms and a collection of subsets of base arms (super arms) following a certain combinatorial constraint, a learner sequentially plays a base arm and observes its random reward, with the objective of ﬁnding the optimal super arm with the maximum bottleneck value, deﬁned as the minimum expected reward of the base arms contained in the super arm. CPE-B captures a variety of practical scenarios such as network routing in communication networks, and its unique challenges fall on how to utilize the bottleneck property to save samples and achieve the statistical optimality. None of the existing CPE studies (most of them assume linear rewards) can be adapted to solve such challenges, and thus we develop brand-new techniques to handle them. For the FC setting, we propose novel algorithms with optimal sample complexity for a broad family of instances and establish a matching lower bound to demonstrate the optimality (within a logarithmic factor). For the FB setting, we design an algorithm which achieves the state-of-the-art error probability guarantee and is the ﬁrst to run efﬁciently on ﬁxed-budget path instances, compared to existing CPE algorithms.
Our experimental results on the top-k, path and matching instances validate the empirical superiority of the proposed algorithms over their baselines. 1

Introduction
The Multi-Armed Bandit (MAB) problem [25, 30, 4, 2] is a classic model to solve the exploration-exploitation trade-off in online decision making. Pure exploration [3, 21, 7, 26] is an important variant of the MAB problem, which aims to identify the best arm under a given conﬁdence or a given sample budget. There are various works studying pure exploration, such as top-k arm identiﬁcation [17, 21, 7, 24], top-k arm under matriod constraints [9] and multi-bandit best arm identiﬁcation [18, 7].
The Combinatorial Pure Exploration (CPE) framework, ﬁrstly proposed by Chen et al. [11], encom-passes a rich class of pure exploration problems [3, 21, 9]. In CPE, there are a set of base arms, each associated with an unknown reward distribution. A subset of base arms is called a super arm, which follows a certain combinatorial structure. At each timestep, a learner plays a base arm and observes a random reward sampled from its distribution, with the objective to identify the optimal super arm 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
with the maximum expected reward. While Chen et al. [11] provide this general CPE framework, their algorithms and analytical techniques only work under the linear reward function and cannot be applied to other nonlinear reward cases.1
However, in many real-world scenarios, the expected reward function is not necessarily linear. One of the common and important cases is the bottleneck reward function, i.e., the expected reward of a super arm is the minimum expected reward of the base arms contained in it. For example, in communication networks [5], the transmission speed of a path is usually determined by the link with the lowest rate, and a learner samples the links in order to ﬁnd the optimal transmission path which maximizes its bottleneck link rate. In trafﬁc scheduling [31], a scheduling system collects the information of road segments in order to plan an efﬁcient route which optimizes its most congested (bottleneck) road segment. In neural architecture search [32], the overall efﬁciency of a network architecture is usually constrained by its worst module, and an agent samples the available modules with the objective to identify the best network architecture in combinatorial search space.
In this paper, we study the Combinatorial Pure Exploration with the Bottleneck reward function (CPE-B) which aims to identify the optimal super arm with the maximum bottleneck value by querying the base arm rewards, where the bottleneck value of a super arm is deﬁned as the minimum expected reward of its containing base arms. We consider two popular settings in pure exploration, i.e,
ﬁxed-conﬁdence (FC), where given conﬁdence parameter δ, the learner aims to identify the optimal super arm with probability 1 − δ and minimize the number of used samples (sample complexity), and
ﬁxed-budget (FB), where the learner needs to use a given sample budget to ﬁnd the optimal super arm and minimize the error probability.
Challenges of CPE-B. Compared to prior CPE works [11, 10, 20], our CPE-B aims at utilizing the bottleneck prop-erty to save samples and achieve the statistical optimality.
It faces with two unique challenges, i.e., how to (i) achieve the tight base-arm-gap dependent sample complexity and (ii) avoid the dependence on unnecessary base arms in the results, while running in polynomial time. We use a simple example in Figure 1 to illustrate our challenges.
In Figure 1, there are six edges (base arms) and three s-t paths (super arms), and the base arm reward w(ei), base arm gap ∆ei,ej and super arm gap ∆M∗,Msub are as shown in the ﬁgure. In order to identify the optimal path, all we need is to pull e1, e2, e4 to determine that e1 is worse than e2 and e4, and e3, e5, e6 are useless for revealing the sub-optimality of M1 and M2. In this case, the optimal sample complexity should be
) ln δ−1), which depends on the tight base arm gaps and only includes the critical
O(( base arms (e1, e2, e4). However, if one naively adapts existing CPE algorithms [11, 12, 16] to work with bottleneck reward function, an inferior sample complexity of O((cid:80) ln δ−1) is incurred, which depends on the loose super arm gaps and contains a summation over all base arms (including the unnecessary e3, e5, e6). Hence, our challenge falls on how to achieve such efﬁcient sampling in an online environment, where we do not know which are critical base arms e1, e2, e4 but want to gather just enough information to identify the optimal super arm. We remark that, none of existing CPE studies can be applied to solve the unique challenges of CPE-B, and thus we develop brand-new techniques to handle them and attain the optimal results (up to a logarithmic factor).
Figure 1: Illustrating example.
+ 1
∆2 ei,i∈[6]
M∗ ,Msub e4,e1 e2,e1
∆2
∆2 2 1
Contributions. For CPE-B in the FC setting, (i) we ﬁrst develop a novel algorithm BLUCB, which employs a bottleneck-adaptive sample strategy and achieves the tight base-arm-gap dependent sample complexity. (ii) We further propose an improved algorithm BLUCB-Parallel in high conﬁdence regime, which adopts an efﬁcient “bottleneck-searching” ofﬂine procedure and a novel “check-near-bottleneck” stopping condition. The sample complexity of BLUCB-Parallel drops the dependence on unnecessary base arms and achieves the optimality (within a logarithmic factor) under small enough δ. (iii) A matching sample complexity lower bound for the FC setting is also provided, which demonstrates the optimality of our algorithms. For the FB setting, (iv) we propose a novel algorithm
BSAR with a special acceptance scheme for the bottleneck identiﬁcation task. BSAR achieves the state-of-the-art error probability and is the ﬁrst to run efﬁciently on ﬁxed-budget path instances, 1The algorithmic designs and analytical tools (e.g., symmetric difference and exchange set) in [11] all rely on the linear property and cannot be applied to nonlinear reward cases, e.g, the bottleneck reward problem. 2
compared to existing CPE algorithms. All our proposed algorithms run in polynomial time.2 The experimental results demonstrate that our algorithms signiﬁcantly outperform the baselines. Due to space limit, we defer all the proofs to the supplementary material. 1.1