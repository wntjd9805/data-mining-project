Abstract
Federated learning (FL) is a challenging setting for optimization due to the het-erogeneity of the data across different clients which can cause a client drift phe-nomenon.
In fact, designing an algorithm for FL that is uniformly better than simple centralized training has been a major open problem thus far. In this work, we propose a general algorithmic framework, MIME, which i) mitigates client drift and ii) adapts an arbitrary centralized optimization algorithm such as mo-mentum and Adam to the cross-device federated learning setting. MIME uses a combination of control-variates and server-level optimizer state (e.g. momentum) at every client-update step to ensure that each local update mimics that of the cen-tralized method run on i.i.d. data. We prove a reduction result showing that MIME can translate the convergence of a generic algorithm in the centralized setting into convergence in the federated setting. Moreover, we show that, when combined with momentum-based variance reduction, MIME is provably faster than any cen-tralized method–the ﬁrst such result. We also perform a thorough experimental exploration of MIME’s performance on real world datasets (implemented here). 1

Introduction
Federated learning (FL) is an increasingly important large-scale learning framework where the train-ing data remains distributed over a large number of clients, which may be mobile phones or network sensors [38, 37, 43, 44, 28]. A server then orchestrates the clients to train a single model, here re-ferred to as a server model, without ever transmitting client data over the network, thereby providing some basic levels of data privacy and security.
Two important settings are distinguished in FL [28, Table 1]: the cross-device and the cross-silo settings. The cross-silo setting corresponds to a relatively small number of reliable clients, typically organizations, such as medical or ﬁnancial institutions. In contrast, in the cross-device federated learning setting, the number of clients may be extremely large and include, for example, all 3.5 bil-lion active android phones [25]. Thus, in that setting, we may never make even a single pass over
∗This work was also appears under the alternative title “Mime: Mimicking Centralized Stochastic Algo-rithms in Federated Learning” [31]. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
the entire clients’ data during training. The cross-device setting is further characterized by resource-poor clients communicating over a highly unreliable network. Together, the essential features of this setting give rise to unique challenges not present in the cross-silo setting. In this work, we are inter-ested in the more challenging cross-device setting, for which we will formalize and study stochastic optimization algorithms. Importantly, recent advances in FL optimization, such as SCAFFOLD [32] or FedDyn [1], are not anymore applicable since they are designed for the cross-silo setting.
The problem. The de facto standard algorithm for the cross-device setting is FEDAVG [43], which performs multiple SGD updates on the available clients before communicating to the server. While this approach can reduce the frequency of communication required, performing multiple steps on the same client can lead to ‘over-ﬁtting’ to its atypical local data, a phenomenon known as client drift
[32]. This in turn leads to slower convergence and can, somewhat counter-intuitively, require larger total communication [69]. Despite signiﬁcant attention received from the optimization community, the communication complexity of heterogeneous cross-device has not improved upon that of simple centralized methods, which take no local steps (aka SERVER-ONLY methods). Furthermore, algo-rithmic innovations such as momentum [59, 14], adaptivity [35, 75, 77], and clipping [71, 72, 76] are critical to the success of deep learning applications. The lack of a theoretical understanding of the impact of multiple client steps has also hindered adapting these techniques in a principled manner into the client updates, in order to replace the vanilla SGD update of FEDAVG.
To overcome such deﬁciencies, we propose a new framework, MIME, that mitigates client drift and can adapt an arbitrary centralized optimization algorithm, e.g. SGD with momentum or Adam, to the federated setting. In each local client update, MIME uses global optimizer state, e.g. momentum or adaptive learning rates, and an SVRG-style correction to mimic the updates of the centralized algorithm run on i.i.d. data. This optimizer state is computed only at the server level and kept ﬁxed throughout the local steps, thereby avoiding overﬁtting to the atypical local data of any single client.
Contributions. We summarize our main results below.
• MIME framework. We formalize the cross-device federated learning problem, and propose a new framework MIME that can adapt arbitrary centralized algorithms to this setting.
• Convergence result. We prove a result showing that MIME successfully reduces client drift.
We also prove that the convergence of any generic algorithm in the centralized setting translates convergence of its MIME version in the federated setting.
• Speed-up over centralized methods. By carefully tracking the bias introduced due to multiple local steps, we prove that MIME with momentum-based variance reduction (MVR) can beat a lower bound for centralized methods, thus breaking a fundamental barrier. This is the ﬁrst such result in FL, and also the ﬁrst general result showing asymptotic speed-up due to local steps.
• Empirical validation. We propose a simpler variant, MIMELITE, with an empirical perfor-mance similar to MIME. We report the results of thorough experimental analysis demonstrating that both MIME and MIMELITE indeed converge faster than FEDAVG.