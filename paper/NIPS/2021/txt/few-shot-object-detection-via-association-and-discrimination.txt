Abstract
Object detection has achieved substantial progress in the last decade. However, detecting novel classes with only few samples remains challenging, since deep learning under low data regime usually leads to a degraded feature space. Existing works employ a holistic ﬁne-tuning paradigm to tackle this problem, where the model is ﬁrst pre-trained on all base classes with abundant samples, and then it is used to carve the novel class feature space. Nonetheless, this paradigm is still imperfect. Durning ﬁne-tuning, a novel class may implicitly leverage the knowledge of multiple base classes to construct its feature space, which induces a scattered feature space, hence violating the inter-class separability. To over-come these obstacles, we propose a two-step ﬁne-tuning framework, Few-shot object detection via Association and DIscrimination (FADI), which builds up a discriminative feature space for each novel class with two integral steps. 1) In the association step, in contrast to implicitly leveraging multiple base classes, we construct a compact novel class feature space via explicitly imitating a speciﬁc base class feature space. Speciﬁcally, we associate each novel class with a base class according to their semantic similarity. After that, the feature space of a novel class can readily imitate the well-trained feature space of the associated base class. 2) In the discrimination step, to ensure the separability between the novel classes and associated base classes, we disentangle the classiﬁcation branches for base and novel classes. To further enlarge the inter-class separability between all classes, a set-specialized margin loss is imposed. Extensive experiments on standard Pascal
VOC and MS-COCO datasets demonstrate that FADI achieves new state-of-the-art performance, signiﬁcantly improving the baseline in any shot/split by +18.7. No-tably, the advantage of FADI is most announced on extremely few-shot scenarios (e.g. 1- and 3- shot). Code is available at: https://github.com/yhcao6/FADI 1

Introduction
Deep learning has achieved impressive performance on object detection [21, 11, 1] in recent years.
However, their strong performance heavily relies on a large amount of labeled training data, which limits the scalability and generalizability of the model in the data scarcity scenarios. In contrast, human visual systems can easily generalize to novel classes with only a few supervisions. Therefore, great interests have been invoked to explore few-shot object detection (FSOD), which aims at training a network from limited annotations of novel classes with the aid of sufﬁcient data of base classes. (cid:66)Corresponding author. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
(a) TFA (b) Association (c) Discrimination
Figure 1: Conceptually visualization of our FADI. (a) The conventional ﬁne-tuning paradigm, e.g., TFA [28], learns good decision boundaries during the pre-training stage to separate the decision space into several subspaces (rectangles) occupied by different base classes. In the ﬁne-tuning stage, a novel class (‘cow’) may exploit multiple similar base classes (‘sheep’ and ‘horse’) to construct the feature space of itself, which induces a scattered intra-class structure (the feature space of ‘cow’ across two base classes, ‘sheep’ and ‘horse’). FADI divides the ﬁne-tuning stage into two steps. (b) In the association step, to construct a compact intra-class structure, we associate each novel class with a well-learned base class based on their semantic similarity (‘cow’ is similar to ‘sheep’, ‘motor’ is similar to ‘bike’). The novel class readily learns to align its intra-class distribution to the associated base class. (c) In the discrimination step, to ensure the inter-class separability between novel classes and associated base classes, we disentangle the classiﬁcation branches for base and novel classes. A set-specialized margin loss is further imposed to enlarge the inter-class separability between all classes.
Various methods have since been proposed to tackle the problem of FSOD, including meta-learning [13, 35, 32], metric learning [14], and ﬁne-tuning [28, 31, 23]. Among them, ﬁne-tuning-based methods are one of the dominating paradigms for few-shot object detection. [28] introduces a simple two-stage ﬁne-tuning approach (TFA). MPSR [31] improves upon TFA [28] via alleviating the problem of scale variation. The recent state-of-the-art method FSCE [23] shows the classiﬁer is more error-prone than the regressor, and introduces the contrastive-aware object proposal encodings to facilitate the classiﬁcation of detected objects. All these works employ a holistic ﬁne-tuning paradigm, where the model is ﬁrst trained on all base classes with abundant samples, and then the pre-trained model is ﬁne-tuned on novel classes. Although it exhibits a considerable performance advantage compared with the earlier meta-learning methods, this ﬁne-tuning paradigm is still imperfect. To be speciﬁc, the current design of the ﬁne-tuning stage directly extracts the feature representation of a novel class from the network pre-trained on base classes. Therefore, a novel class may exploit the knowledge of multiple similar base classes to construct the feature space of itself. As a result, the feature space of a novel class will have an incompact intra-class structure that scatters across feature spaces of other classes, breaking the inter-class separability, hence leading to classiﬁcation confusion, as shown in Figure 1a.
To overcome these obstacles, we propose a two-step ﬁne-tuning framework, Few-shot object detection via Association and DIscrimination (FADI), which constructs a discriminable feature space for each novel class with two integral steps, association and discrimination. Speciﬁcally, in the association step, as shown in Figure 1b, to construct a compact intra-class structure, we associate each novel class with a well-trained base class based on their underlying semantic similarity. The novel class readily learns to align its feature space to the associated base class, thus naturally becomes separable from the remaining classes. In the discrimination step, as shown in Figure 1c, to ensure the separability between the novel classes and associated base classes, we disentangle the classiﬁcation branches for base and novel classes to reduce the ambiguity in the feature space induced by the association step. To further enlarge the inter-class separability between all classes, a set-specialized margin loss is applied. To this end, the ﬁne-tuning stage is divided into two dedicated steps, and together complement each other.
Extensive experimental results have validated the effectiveness of our approach. We gain signiﬁcant performance improvements on the Pascal VOC [7] and COCO [18] benchmarks, especially on the extremely few-shot scenario. Speciﬁcally, without bells and whistles, FADI improves the TFA [28] baseline by a signiﬁcant margin in any split and shot with up to +18.7 mAP, and push the envelope of the state-of-the-art performance by 2.5, 4.3, 2.8 and 5.6, 7.8, 1.6 for shot K = 1, 2, 3 on novel split-1 and split-3 of Pascal VOC dataset, respectively. 2
2