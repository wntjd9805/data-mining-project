Abstract
Partial label learning (PLL) is a typical weakly supervised learning problem, where each training example is associated with a set of candidate labels among which only one is true. Most existing PLL approaches assume that the incorrect labels in each training example are randomly picked as the candidate labels. However, this assumption is not realistic since the candidate labels are always instance-dependent. In this paper, we consider instance-dependent PLL and assume that each example is associated with a latent label distribution constituted by the real number of each label, representing the degree to each label describing the feature. The incorrect label with a high degree is more likely to be annotated as the candidate label. Therefore, the latent label distribution is the essential labeling information in partially labeled examples and worth being leveraged for predictive model training. Motivated by this consideration, we propose a novel
PLL method that recovers the label distribution as a label enhancement (LE) process and trains the predictive model iteratively in every epoch. Speciﬁcally, we assume the true posterior density of the latent label distribution takes on the variational approximate Dirichlet density parameterized by an inference model.
Then the evidence lower bound is deduced for optimizing the inference model and the label distributions generated from the variational posterior are utilized for training the predictive model. Experiments on benchmark and real-world datasets validate the effectiveness of the proposed method. Source code is available at https://github.com/palm-ml/valen. 1

Introduction
Partial label learning (PLL) deals with the problem where each training example is associated with a set of candidate labels, among which only one label is valid [7, 5, 37]. Due to the difﬁculty in collecting exactly labeled data in many real-world scenarios, PLL leverages inexact supervision instead of exact labels. The need to learn from the inexact supervision leads to a wide range of applications for PLL techniques, such as web mining [25], multimedia content analysis [38, 4], ecoinformatics [24, 31], etc.
To accomplish the task of learning from partial label data, many approaches have been proposed.
Identiﬁcation-based PLL approaches [17, 28, 24, 5, 37] regard the ground-truth label as a latent variable and try to identify it. Average-based approaches [15, 7, 40] treat all the candidate labels equally and average the modeling outputs as the prediction. For conﬁdence-based approaches
[8, 34, 42], the conﬁdence of each label is estimated instead of identifying the ground-truth label.
These approaches always adopt the randomly picked candidate labels to corrupt benchmark data into partially labeled version despite having no explicit generation process of candidate label sets.
To depict the instance-independent generation process of candidate label sets, Feng [9] proposes a statistical model and deduces a risk-consistent method and a classiﬁer-consistent method. Under the
∗Corresponding author 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
(a) Handwritten digits in MNIST [22] (b) Color image in CIFAR-10 [21]
Figure 1: The examples about the latent label distributions for partial label learning. The candidate labels are in the box and the red one is valid. same generation process, another classiﬁer-consistent risk estimator is proposed for deep model and stochastic optimizers [26].
The previous methods assume that the candidate labels are randomly sampled with the uniform generating procedure [26, 9], which is commonly adopted to corrupt benchmark datasets into partially labeled versions in their experiments. However, the candidate labels are always instance-dependent (feature-dependent) in practice as the incorrect labels related to the feature are more likely to be picked as candidate label set for each instance. These methods usually do not perform as well as expected due to the unrealistic assumption on the generating procedure of candidate label sets.
In this paper, we consider instance-dependent PLL and assume that each instance in PLL is associated with a latent label distribution [33, 35, 11] constituted by the real number of each label, representing the degree to each label describing the feature. Then, the incorrect label with a high degree in the latent label distribution is more likely to be annotated as the candidate label. For example, the candidate label set of the handwritten digits in Figure 1(a) contains “1”, “3” and “5”, where “1” and
“3” are not ground-truth but selected as candidate labels due to their high degrees in the latent label distribution of the instance. The object in Figure 1(b) is annotated with “bird” and “airplane” as the degrees of these two labels are much higher than others in the label distribution. The intrinsical ambiguity increases the difﬁculty of annotating, which leads to the result that annotators pick the candidate labels with high degrees in the latent label distribution of each instance instead of annotating the ground-truth label directly in PLL. Therefore, the latent label distribution is the essential labeling information in partially labeled examples and worth being leveraged for predictive model training.
Motivated by the above consideration, we deal with the PLL problem from two aspects. First, we enhance the labeling information by recovering the latent label distribution for each training example as a label enhancement process [33, 35]. Second, we run label enhancement and train the predictive model with recovered label distributions iteratively. The proposed method named VALEN, i.e.,
VAriational Label ENhancement for instance-dependent partial label learning, uses the candidate labels to initialize the predictive model in the warm-up training stage, then recovers the latent label distributions via inferring the variational posterior density parameterized by an inference model with the deduced evidence lower bound, and trains the predictive model with a risk estimator by leveraging the candidate labels as well as the label distributions. Our contributions can be summarized as follows:
• We for the ﬁrst time consider the instance-dependent PLL and assume that each partially labeled example is associated with a latent label distribution, which is the essential labeling information and worth being recovered for predictive model training.
• We infer the posterior density of the latent label distribution via taking on the approximate Dirichlet density parameterized by an inference model and deduce the evidence lower bound for optimization, in which the topological information and the features extracted from the predictive model are leveraged.
• We train predictive model with a proposed empirical risk estimator by leveraging the candidate labels as well as the label distributions. We iteratively recover the latent label distributions and train the predictive model in every epoch. After the network has been fully trained, the predictive model can perform predictions for future test examples alone.
Experiments on the corrupted benchmark datasets and real-world PLL datasets validate the effective-ness of the proposed method. 2
2 Proposed Method
First of all, we brieﬂy introduce some necessary notations. Let X = Rq be the q-dimensional instance space and Y = {y1, y2, ..., yc} be the label space with c class labels. Given the PLL training set
D = {(xi, Si)|1 ≤ i ≤ n} where xi denotes the q-dimensional instance and Si ⊆ Y denotes the candidate label set associated with xi. Note that Si contains the correct label of xi and the task of PLL is to induce a multi-class classiﬁer f : X (cid:55)→ Y from D. For each PLL training example
, . . . , lyc (xi, Si), we use the logical label vector li = [ly1
](cid:62) ∈ {0, 1}c to represent whether yj i i i = 1 if yj ∈ Si, otherwise lyj is the candidate label, i.e., lyj i = 0. The label distribution of xi is i ](cid:62) ∈ [0, 1]c where (cid:80)c denoted by di = [dy1 i = 1. Then L = [l1, l2, . . . , ln] and
D = [d1, d2, . . . , dn] represent the logical label matrix and label distribution matrix, respectively. i , . . . , dyc j=1 dyj i , dy2
, ly2 i 2.1 Overview
To deal with PLL problem, we iteratively recover the latent label distribution for each example x and train the predictive model by leveraging the recovered label distribution. We start with a warm-up period, in which we train the predictive model with the PLL minimal loss [26]. This allows us to attain a reasonable predictive model before it starts ﬁtting incorrect labels. After the warm-up period, the features extracted from the predictive model can help for recovering the latent label distribution.
Beneﬁted from the essential labeling information in the recovered label distribution, the performance of the predictive model could be further improved.
VALEN implements label enhancement and classiﬁer training iteratively in every epoch. In label enhancement, we assume the true posterior density of the latent label distribution takes on the variational approximate Dirichlet density parameterized by an inference model. Then the evidence lower bound is deduced for optimizing the inference model and the label distributions can be generated from the variational posterior. In classiﬁer training, the predictive model is trained by leveraging the recovered label distributions and candidate labels with an empirical risk estimator. After the models has been fully trained, the predictive model can perform prediction for future test instances alone. 2.2 Warm-up Training
The predictive model θ is trained on partially labeled examples by minimizing the following PLL minimal loss function [26]:
Lmin = min yj ∈Si (cid:96)(f (xi), eyj ), (1) n (cid:88) i=1 where (cid:96) is cross-entropy loss and eY = {eyj : yj ∈ Y} denotes the standard canonical vector in Rc, i.e., the j-element in eyj equals 1 and others equal 0. Similar to [26], the min operator in Eq. (1) is replaced by using the current predictions for slightly weighting on the possible labels in warm-up training. Then we could extract the feature φ of each x via using the predictive model. 2.3 Label Enhancement
We assume that the prior density p(d) is a Dirichlet with ˆα, i.e., p (d) = Dir (d | ˆα) where
ˆα = [ε, ε, . . . , ε](cid:62) is a c-dimensional vector with a minor value ε. Then we let the prior density p(D) be the product of each Dirichlet p(D) = n (cid:89) i=1
Dir(di| ˆα). (2)
We consider the topological information of the feature space, which is represented by the afﬁnity graph G = (V, E, A). Here, the feature vector φi of each example could be extracted from the predictive model θ in current epoch, V = {φi | 1 ≤ i ≤ n} corresponds to the vertex set consisting of feature vectors, E = {(φi, φj) | 1 ≤ i (cid:54)= j ≤ n} corresponds to the edge set, and a sparse adjacency matrix A = [aij]n×n can be obtained by aij = (cid:26) 1 0 if φi ∈ N (φj) otherwise
, (3) 3
where N (φj) is the set for k-nearest neighbors of φj and the diagonal elements of A are set to 1.
Let features matrix Φ = [φ1, φ2, . . . , φn], adjacency matrix A and logical labels L be observed matrix, VALEN aims to infer the posterior density p(D|L, Φ, A). As the computation of the exact posterior density p(D|L, Φ, A) is intractable, a ﬁxed-form density q(D|L, Φ, A) is employed to approximate the true posterior. We let the approximate posterior be the product of each Dirichlet i ](cid:62): parameterized by a vector αi = [α1 i , . . . , αc i , α2 qw(D | L, Φ, A) = n (cid:89) i=1
Dir (di|αi) . (4)
Here, the parameters ∆ = [α1, α2, . . . , αn] are outputs of the inference model parameterized by w, which is deﬁned as a two-layer GCN [20] by GCN(L, Φ, A) = ˜A ReLU
W1, with
Z = [Φ; L] and weight W0, W1. Here ˜A = ˆA− 1 matrix where ˆA is the degree matrix of A. 2 is the symmetrically normalized weight (cid:16) ˜AZW0 2 A ˆA− 1 (cid:17)
By following the Variational Bayes techniques, a lower bound on the marginal likelihood of the model is derived which ensures that qw(D|L, Φ, A) is as close as possible to p(D|L, Φ, A). For logical label matrix L, feature matrix Φ, and the corresponding A, the log marginal probability can be decomposed as follows 1: log p(L, Φ, A) = LELBO + KL[qw(D|L, Φ, A)||p(D|L, Φ, A)]. (5) where
LELBO = Eqw(D|L,Φ,A)[log p(L, Φ, A|D)] − KL[qw(D|L, Φ, A)||p(D)].
Due to the non-negative property of KL divergence, the ﬁrst term LELBO constitutes a lower bound of log p(L, Φ, A), which is often called as evidence lower bound (ELBO), i.e., log p(L, Φ, A) ≥
LELBO. (6)
According to Eq. (2) and Eq. (4) , the KL divergence in Eq. (6) can be analytically calculated as follows:
KL (qw(D|L, Φ, A)(cid:107)p(D)) = (cid:80)n
− log Γ (c · ε) + c log Γ (ε) + (cid:80)c (cid:18) (cid:16)(cid:80)c log Γ
αj i − ε (cid:17) (cid:16)
ψ i=1 (cid:16) j=1 j=1 αj i (cid:17) (cid:16)
αj i (cid:17)
− (cid:80)c j=1 log Γ
− ψ (cid:16)(cid:80)c j=1 αj i (cid:16)
αj i (cid:17)(cid:17) (cid:19) (cid:17)
. (7) where Γ(·) and ψ(·) are Gamma function and Digamma function, respectively.
As the ﬁrst part of Eq. (6) is intractable, we employ the implicit reparameterization trick [10] to approximate it by Monte Carlo (MC) estimation. Inspired by [20], we simply drop the dependence on Φ: p(L | A, D) = n (cid:89) p (li | A, D) , p(A | D) = i=1 n (cid:89) n (cid:89) i=1 j=1 p (aij | di, dj) , with p (aij = 1 | di, dj) = s (cid:0)d(cid:62) i dj (cid:1) . (8)
Here, s(·) is the logistic sigmoid function. We further assume that p (li|A, D) is a multi-In order to simplify the observation model, T(m) = variate Bernoulli with probabilities τi.
[τ (m)
] is computed from m-th sampling D(m) with a three-layer MLP parame-1 terized by η. Then the ﬁrst part of Eq. (6) can be tractable:
, . . . , τ (m)
, τ (m) 2 n
Eqw(D|L,Φ,A)[log pη(L, Φ, A|D)] = 1
M (cid:32)
M (cid:88) m=1 (cid:16) tr (I − L)(cid:62) log (cid:16)
I − T(m)(cid:17)(cid:17) (cid:16)
L(cid:62) log T(m)(cid:17)
+ tr
− (cid:107)A − S (cid:16)
D(m)D(m)(cid:62)(cid:17) 1More detailed calculations can be seen in Appendix A.1. 4 (9) (cid:33)
. (cid:107)2
F
Algorithm 1 VALEN Algorithm
Input: The PLL training set D = {(xi, Si)}n 1: Initialize the predictive model θ by warm-up training, the reference model w and observation i=1, epoch T and iteration I; model η; 2: Extract the features Φ from predictive model θ and calculate the adjacency matrix A; 3: for t = 1, . . . , T do 4: 5: 6: 7:
Obtain label distribution di for each example xi by Eq. (4);
Update θ, w and η by forward computation and back-propagation by fusing Eq. (12) and
Shufﬂe training set D = {(xi, Si)}n for k = 1, . . . , I do i=1 into I mini-batches;
Eq. (13); end for 8: 9: end for
Output: The predictive model θ.
Note that we can use only one MC sample in Eq. (9) during the training process as suggested in
[19, 35].
In addition, VALEN improves the label enhancement by employing the compatibility loss, which enforces that the recovered label distributions should not be completely different from the conﬁdence
ζ(xi) [9, 26] estimated by current prediction f (xi; θ):
Lo = − 1 n n (cid:88) c (cid:88) i=1 j=1
ζj(xi) log dyj i where
ζj(xi) = (cid:26) fj (xi; θ) / (cid:80) yk∈Si 0 fk (xi; θ) if yj ∈ Si otherwise
Now we can easily get the objective of label enhancement LLE as follows:
LLE = λLo − LELBO (10) (11) (12) where λ is a hyper-parameter. The label distribution matrix D is sampled from q(D|L, Φ, A), i.e., di ∼ Dir(αi). Note that the implicit reparameterization gradient [10] is employed, which avoids the inversion of the standardization function, which makes the gradients can be computed analytically in backward pass. 2.4 Classiﬁer Training
To train the predictive model, we minimize the following empirical risk estimator by levering the recovered label distributions: (cid:98)RV (f ) = n (cid:88)

 (cid:88) i=1 yj ∈Si 1 n dyj i (cid:80) yj ∈Si
 (cid:96)(f (xi), eyj )
 . dyj i (13)
Here we adopt the average value of di sampled by di ∼ Dir(αi). We can use any deep neural network as the predictive model, and then equip it with the VALEN framework to deal with PLL. Note that we could train the predictive model and update the label distributions in a principled end-to-end manner by fusing the objective Eq. (12) and Eq. (13). The algorithmic description of the VALEN is shown in Algorithm 1.
Let (cid:98)fV = minf ∈F (cid:98)RV (f ) be the empirical risk minimizer and f (cid:63) = minf ∈F RV (f ) be the optimal risk minimizer where RV (f ) is the risk estimator. Besides, we deﬁne the function space Hyj for the label yj ∈ Y as (cid:8)h : x (cid:55)→ fyj (x) | f ∈ F(cid:9). Let Rn (cid:1) be the expected Rademacher complexity
[2] of Hyj with sample size n, then we have the following theorem. (cid:0)Hyj
Theorem 1 Assume the loss function (cid:96)(f (x), eyj ) is L-Lipschitz with respect to f (x)(0 < L < ∞) for all yj ∈ Y and upper-bounded by M , i.e., M = supx∈X ,f ∈F ,yj ∈Y (cid:96)(f (x), eyj ). Then, for any 5
δ > 0, with probability at least 1 − δ, (cid:17) (cid:16) (cid:98)fV
R
− R (f (cid:63)) ≤ 4
√ 2L c (cid:88) j=1
Rn (cid:0)Hyj (cid:1) + M (cid:115) log 2
δ 2n
The proof of Theorem 1 is provided in Appendix A.2. Theorem 1 shows that the empirical risk (cid:1) → 0 for all minimizer fV converges to the optimal risk minimizer f (cid:63) as n → ∞ and Rn parametric models with a bounded norm. (cid:0)Hyj 3