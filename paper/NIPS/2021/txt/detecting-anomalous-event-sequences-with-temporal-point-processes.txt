Abstract
Automatically detecting anomalies in event data can provide substantial value in domains such as healthcare, DevOps, and information security. In this paper, we frame the problem of detecting anomalous continuous-time event sequences as out-of-distribution (OoD) detection for temporal point processes (TPPs). First, we show how this problem can be approached using goodness-of-ﬁt (GoF) tests. We then demonstrate the limitations of popular GoF statistics for TPPs and propose a new test that addresses these shortcomings. The proposed method can be combined with various TPP models, such as neural TPPs, and is easy to implement. In our experiments, we show that the proposed statistic excels at both traditional GoF testing, as well as at detecting anomalies in simulated and real-world data. 1

Introduction
Event data is abundant in the real world and is encountered in various important applications. For example, transactions in ﬁnancial systems, server logs, and user activity traces can all naturally be represented as discrete events in continuous time. Detecting anomalies in such data can provide immense industrial value. For example, abnormal entries in system logs may correspond to unnoticed server failures, atypical user activity in computer networks may correspond to intrusions, and irregular patterns in ﬁnancial systems may correspond to fraud or shifts in the market structure.
Manual inspection of such event data is usually infeasible due to its sheer volume. At the same time, hand-crafted rules quickly become obsolete due to software updates or changing trends (He et al., 2016). Ideally, we would like to have an adaptive system that can learn the normal behavior from the data, and automatically detect abnormal event sequences. Importantly, such a system should detect anomalies in a completely unsupervised way, as high-quality labels are usually hard to obtain.
Assuming “normal” data is available, we can formulate the problem of detecting anomalous event sequences as an instance of out-of-distribution (OoD) detection. Multiple recent works consider
OoD detection for image data based on deep generative models (Ren et al., 2019; Nalisnick et al., 2019; Wang et al., 2020). However, none of these papers consider continuous-time event data. Deep generative models for such variable-length event sequences are known as neural temporal point processes (TPPs) (Du et al., 2016). Still, the literature on neural TPPs mostly focuses on prediction tasks, and the problem of anomaly detection has not been adequately addressed by existing works (Shchur et al., 2021). We aim to ﬁll this gap in our paper.
∗Work done during an internship at Amazon Research.
Code and datasets: https://github.com/shchur/tpp-anomaly-detection 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
Our main contributions are the following: 1. Approach for anomaly detection for TPPs. We draw connections between OoD detection and
GoF testing for TPPs (Section 2). By combining this insight with neural TPPs, we propose an approach for anomaly detection that shows high accuracy on synthetic and real-world event data. 2. A new test statistic for TPPs. We highlight the limitations of popular GoF statistics for TPPs and propose the sum-of-squared-spacings statistic that addresses these shortcomings (Section 4).
The proposed statistic can be applied to both unmarked and marked TPPs. 2 Anomaly detection and goodness-of-ﬁt testing