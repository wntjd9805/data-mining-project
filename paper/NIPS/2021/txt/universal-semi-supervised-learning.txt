Abstract
Universal Semi-Supervised Learning (UniSSL) aims to solve the open-set problem where both the class distribution (i.e., class set) and feature distribution (i.e., feature domain) are different between labeled dataset and unlabeled dataset. Such a problem seriously hinders the realistic landing of classical SSL. Different from the existing SSL methods targeting at the open-set problem that only study one certain scenario of class distribution mismatch and ignore the feature distribution mismatch, we consider a more general case where a mismatch exists in both class and feature distribution. In this case, we propose a “Class-shAring data detection and Feature Adaptation” (CAFA) framework which requires no prior knowledge of the class relationship between the labeled dataset and unlabeled dataset. Particularly, CAFA utilizes a novel scoring strategy to detect the data in the shared class set. Then, it conducts domain adaptation to fully exploit the value of the detected class-sharing data for better semi-supervised consistency training.
Exhaustive experiments on several benchmark datasets show the effectiveness of our method in tackling open-set problems. 1

Introduction
A critical drawback of training a good neural network [25] is that it typically requires lots of labeled data, which is quite difﬁcult to satisfy due to the unaffordable monetary cost as well as the huge demand for human resources. A popular way to solve such a problem is Semi-Supervised Learning (SSL) [7] which can effectively leverage scarce labeled data and abundant unlabeled data to train an accurate classiﬁer. However, classical SSL [14, 15, 16, 17, 24, 39, 41, 49] relies on the closed-set assumption that the labeled and unlabeled data are drawn from the same class distribution and the same feature distribution. To be concrete, the class set of labeled data Cl is equal to that of unlabeled data Cu, and the marginal distribution pl(x) of the labeled data is identical to the unlabeled feature distribution pu(x), which is shown in Figure 1 (a). However, in practice, the datasets at hand could greatly violate the above assumption by having both class distribution mismatch and feature distribution mismatch, which is denoted as open-set1. In this situation, traditional closed-set SSL would suffer from severe performance degradation [31].
Recent works [4, 9, 19, 22, 29, 31, 45] have focused on dealing with the class distribution mismatch problem to extend SSL into the wild. For example, Guo et al. (2020) [19] considers the subset mismatch situation when the classes in labeled data are only a subset of the classes in unlabeled data, 1Note that there are some other works [4, 45] also named as “open-set SSL”. However, they all focus on the class distribution mismatch and do not deal with the feature distribution mismatch, so their setting is very different from ours. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
Figure 1: Problem illustration. (a) Closed-set SSL. (b) and (c) depict class distribution mismatch, where (b) describes subset mismatch; and (c) presents intersectional mismatch. (d) Feature distribution mismatch. In this ﬁgure, the dashed red box denotes feature distribution mismatch, and the solid green boxes mean the class distribution mismatch. i.e., Cl ⊂ Cu and Cu \ Cl (cid:54)= ∅ (Figure 1 (b)). It utilizes a meta learning scheme to down-weight the unlabeled data that do not belong to Cl. Chen et al. (2020) [9] deals with the intersectional mismatch problem where the labeled and unlabeled data both contain a shared class set but also hold a private class set, respectively, i.e., Cl ∩ Cu (cid:54)= ∅, Cl \ (Cu ∩ Cl) (cid:54)= ∅ and Cu \ (Cu ∩ Cl) (cid:54)= ∅ (Figure 1 (c)). It proposes a self-distillation method to ﬁlter out the probable unlabeled private data.
However, existing methods require prior knowledge of the relationship between Cl and Cu, which greatly limits their realistic application. When the class relationship is unknown, the potential private data from Dl and Du could both seriously mislead the learning process. Moreover, existing works only consider the class distribution mismatch and totally ignore the feature distribution mismatch problem. The latter problem is also quite common in practice, as when we try to collect a large amount of unlabeled data to aid the model training, the feature distribution of the newly obtained unlabeled data could be heavily inﬂuenced by when, where, and how we collect them. As a result, the potential feature distribution difference between labeled and unlabeled data could seriously harm the learning performance. Therefore, it is necessary to design a universal method to solve different scenarios of class distribution mismatch and meanwhile deal with the feature distribution mismatch.
In this paper, we propose a new framework dubbed “Class-shAring data detection and Feature
Adaptation (CAFA)” which is a Universal Semi-Supervised Learning (UniSSL) method for tackling different situations of open-set problem. Speciﬁcally, by considering that the labeled set and unlabeled set are drawn from different domains, we utilize a novel scoring mechanism to identify both the labeled and unlabeled data from the shared classes. The mechanism integrates two cues, namely domain similarity and label prediction shift, which are perfectly tailored for data detection in open-set
SSL. Then we employ domain adaptation [5, 6, 12, 40, 43, 47] to match the identiﬁed unlabeled data to the same feature distribution of the class-sharing labeled data. After feature adaptation, the value of original unlabeled data can be fully exploited for boosting the learning performance. Moreover, we conduct weighted SSL to take full advantage of the class-sharing data from the open dataset. To sum up, our main contributions are:
• We propose a universal framework that can solve different scenarios of open-set SSL without any prior class knowledge.
• Our method can fully exploit the value of unlabeled data by mitigating the feature distribution mismatch between labeled data and unlabeled data.
• Experiments show that our method outperforms all other baselines in different situations of open-set problems. 2 Universal Semi-Supervised Learning
In our open-set SSL setting, we are given a labeled set Dl = {(xi, yi)}l i=1 containing l instances xi i=1, and an unlabeled set Du = {xj}u labeled with {yi}l j=1 consisting of u unlabeled instances xj, where l (cid:28) u. The two datasets Dl and Du are drawn from two different feature distributions pl(xi) and pu(xj), respectively. We use Cl to denote the labeled class set which contains the classes of labeled data, and employ Cu to represent the unlabeled class set consisting of the classes of unlabeled 2
Figure 2: The pipeline of our Class-shAring data detection and Feature Adaptation (CAFA) approach. data. Note that in our setting, we do not know the exact relationship between Cl and Cu. Particularly, we use C = Cl ∩ Cu to denote the common class set shared by Dl and Du, and use C to denote the class sets private to labeled data and unlabeled data, respectively. The feature distributions are denoted as pl of labeled data with labels in C and C
Cl (xi), respectively, and the
C(xj) and pu
Cu (xj), feature distributions of unlabeled data that belong to C and C respectively.
Our goal is to effectively identify the class-sharing data from both Dl and Du, and then eliminate the feature distribution mismatch between the identiﬁed labeled and unlabeled data to help train an accurate semi-supervised model in classifying the test data to the classes-of-interests Cl. are denoted as pu
C(xi) and pl and C u u l l 2.1 The General Framework of CAFA
As shown in Figure 2, CAFA contains a feature extractor F , a classiﬁer C, an adversarial discriminator
D, and a non-adversarial discriminator D(cid:48). Given an input instance x, we use F to compute its feature representation z = F (x). Then we employ C to output the label prediction f using z. The non-adversarial discriminator D(cid:48) produces a domain similarity score wd, which quantiﬁes the similarity degree of an instance to one distribution. The adversarial discriminator D aims to adversarially adapt the feature distributions of labeled and unlabeled data to the common classes C.
The general framework of CAFA can be concisely formulated as: min
θF ,θC max
θD
Exi∼pl Lce(C(F (xi)), yi) (cid:124) (cid:125) (cid:123)(cid:122) supervised ﬁdelity term
− γExi∼pl,xj ∼pu wl · wu · Ladv(xi, xj; θF , θD) (cid:123)(cid:122) (cid:125) feature adaptation term (cid:124)
+ δExj ∼pu wu · Lssl(C(F (xj)), yj) (cid:125) (cid:123)(cid:122) class-sharing data exploration term (cid:124)
, (1) in which θF , θC, θD are the parameters of F , C, and D, respectively. In Eq. (1), the ﬁrst term is dubbed supervised ﬁdelity term which involves the standard cross-entropy loss Lce(·). The second term is dubbed feature adaptation term which introduces an adversarial learning loss Ladv to conduct feature adaptation on the class-sharing data from Dl and Du. Here the class-sharing data are detected through two scores wl and wu which will be detailed in Section 2.2. Through such a feature adaptation procedure, our CAFA approach can maximally exploit the unlabeled data and beneﬁt
SSL. The third term refers to class-sharing data exploration term which conducts semi-supervised training using a SSL loss Lssl(·) to make full use of class-sharing unlabeled data. Here the SSL loss can be any regularizer in existing methods such as consistency regularizer [24, 39] or manifold regularizer [1, 13, 44], and yj is a (cid:12) (cid:12)-dimensional vector denoting the generated pseudo learning target for each unlabeled datum xj, where the notation |·| indicates the size of the corresponding set.
The parameters γ and δ are non-negative coefﬁcients that trade off the above three terms. (cid:12)Cl(cid:12)
From the general CAFA framework presented above, we can see that the class-sharing data detection, feature adaptation, and semi-supervised training are essential to our approach, and they will be detailed in Sections 2.2, 2.3, 2.4, respectively. 3
Figure 3: Illustration of our domain similarity and label prediction shift. 2.2 Class-Sharing Data Detection l u
∪ C
Class-sharing data detection aims to correctly distinguish the training data belonging to C from those
. To achieve this goal, we hope to model two class-sharing scores wl(·) and wu(·) for in C labeled and unlabeled data, respectively, which should satisfy the following inequalities [43] wl(x) > E
E (2) x∼pl
C
Ex∼pu x∼pl
Cl wu(x) > Ex∼pu
C wl(x),
Cu wu(x).
The above inequities should hold in a large margin for better detection performance. Here we propose to utilize two cues, namely domain similarity wd and label prediction shift ws, to model wl and wu.
Domain Similarity has been employed to quantify whether an instance belongs to a speciﬁc domain by several methods [6, 43, 47]. They usually train a non-adversarial discriminator D(cid:48) to predict the data from pl as 0 and those from pu as 1 by minimizing a cross-entropy loss. The output value wd = D(cid:48)(F (x)) can be considered as the domain similarity of the input x. Particularly, the input x is likely to be sampled from pu if wd is large, and pl otherwise, formally
Cu wd(x), Ex∼pu wd(x) < Ex∼pu wd(x), E wd(x). x∼pl
C x∼pl (3)
E
C
Cl
Cu wd(x) ≈ Ex∼pu
However, such a training strategy lacks exploitation on the middle region between two feature distri-butions. Consequently, it is prone to overﬁt to the situation when E wd(x) ≈ 0 and Ex∼pu wd(x) ≈ 1, thus making the class-sharing data unrecognizable, as shown in the upper of Figure 3 (a). To solve this problem, we conduct Mixup [46] to strengthen the relationship between xi ∼ pl
C to yield discriminative domain similarities. Speciﬁcally, given two feature representations zi = F (xi) and zj = F (xj) of labeled datum xi and unlabeled datum xj, and their corresponding domain labels di = 0 and dj = 1, respectively, we can generate a mixed feature representation ˜zi,j and a mixed domain label ˜di,j as following
C and xj ∼ pu wd(x) ≈ E x∼pl
C x∼pl
Cl
C
˜zi,j = λzi + (1 − λ)zj,
˜di,j = 1 − λ, (4) in which λ is sampled from a Beta distribution Beta(α, α) where α is a hyper-parameter. Then we leverage the mixed feature representations with their domain labels by adding an extra binary cross-entropy term to our domain similarity loss Ldom, which is formulated as
Ldom = −Exi∼pl log(1 − D(cid:48)(F (xi))) − Exj ∼pu log D(cid:48)(F (xj))
+Exi∼pl,xj ∼pu [sim(zi, zj) · (−(1 − λ) log D(cid:48)(˜zi,j) − λ log(1 − D(cid:48)(˜zi,j)))] , (5) where sim(zi, zj) = z(cid:62) i zj (cid:107)zi(cid:107)(cid:107)zj (cid:107) denotes the cosine similarity between zi and zj. Based on a reasonable u assumption that zi and zj in C are closer to each other in the feature space than those in C
, such extra term weighted with cosine similarity can focus on interpolating the middle region between the two feature distributions pl
C, which helps preventing the aforementioned overﬁtting problem and making the domain similarity of class-sharing data closer to each other than the private data in C
, as shown in the lower panel of Figure 3 (a). Therefore, we can have
E
Cu wd(x). By combining Eq. (3), we have wd(x) < Ex∼pu u wd(x) and Ex∼pu l wd(x) < E wd(x) < Ex∼pu wd(x) < Ex∼pu wd(x) < E and C x∼pl
C
C and pu and C x∼pl (6)
E
Cl
C l
Cu wd(x). x∼pl
Cl x∼pl
C
C 4
The above inequality would yield a larger margin than traditional training strategy when equipped with the Mixup training. Thereby, our domain similarity can better detect the class-sharing data in the open-set situation. Nevertheless, the domain similarity alone is not sufﬁcient for class-sharing data detection. Therefore, we introduce label prediction shift to enhance the detection performance.
Label Prediction Shift indicates the inﬂuence imposed by adversarial perturbation on each in-stance, which can successfully differentiate the class-sharing data from private data, as shown in Figure 3 (b). Formally, given an input instance x, its label prediction can be denoted as
|Cl| f = (cid:2)f1(x), f2(x), · · · , f|Cl|(x)(cid:3)(cid:62) i=1 can be interpreted as the probability that x belongs to class i. Then we apply an adversarial perturbation on x to obtain the perturbed version of input instance x∗ = x − (cid:15)sign(−∇xLce(x, maxi∈{1,··· ,|Cl|} fi(x))), where (cid:15) controls the pertur-bation magnitude. As a result, the adversarial perturbation would decrease the maximum probability of the given input. Then, the label prediction shift can be computed as where {fi(x)} ws = max i∈Cl
As a result, the computed label prediction shift would satisfy the following inequality: fi(x) − max i∈Cl fi(x∗).
Ex∼pu
Cu ws(x) < Ex∼pu
C ws(x) < E x∼pl
C ws(x) < E x∼pl
Cl ws(x). (7) (8) l
C
Cl x∼pl x∼pl
C ws(x), E
Intuitively, the learning on scarce labeled data is strongly dependent on the supervised cross-entropy loss Lce, while the unlabeled data that are learned with consistency regularization are much more robust against perturbations [24, 30, 39], thus it is natural to have Ex∼pu ws(x) <
E ws(x). Moreover, the abundant unlabeled data have the effect of improving the model generalizability in SSL. In open-set situation, the model generalizability on the class set
C is greatly limited since there are only scarce labeled private data available, which makes such kind of data vulnerable against perturbations. On the contrary, the model learning on the classes in C is quite sufﬁcient when compared with C since there are both labeled and unlabeled data that can be leveraged. Hence, we have E ws(x). Additionally, the unlabeled private
Cu ws(x), Ex∼pu
Cl data in C do not belong to any known classes and completely lie out of any known distribution. As mentioned in [27], the adversarial perturbation would have less inﬂuence on their maximal label predictions than those data in Cl. Therefore, we can have Ex∼pu ws(x). Based on the above explanations, the inequality in Eq. (8) should hold.
To integrate the proposed two cues wd and ws based on Eqs. (6) and (8), we can compute wl and wu through
Cu ws(x) < Ex∼pu ws(x) < E x∼pl
C x∼pl u
C l wl(x) = wd(x) − ws(x), x ∈ Dl, wu(x) = ws(x) − wd(x), x ∈ Du.
Note that wd and ws are both normalized into interval [0, 1] before computation. Through Eq. (9), our class-sharing scores can perfectly satisfy Eq. (2), hence they are effective for detecting the class-sharing data from both Dl and Du. (9) 2.3 Feature Adaptation
C and pu
After detecting the class-sharing data in the above subsection, now we should eliminate the feature distribution mismatch between pl
C such that the value of unlabeled data can be properly extracted to aid the subsequent SSL. To this end, we treat the labeled data as target domain (i.e., di = 0, xi ∈ Dl) and the unlabeled data as the source domain (i.e., dj = 1, xj ∈ Du), and conduct adversarial domain adaptation [5, 6, 12, 40, 47] to achieve this goal. Particularly, we apply the class-sharing scores wl and wu to the adversarial learning loss Ladv, and train the adversarial discriminator
D to distinguish the labeled and unlabeled data. Meanwhile, the feature extractor F is trained to deceive D. The above adversarial process is formulated as the following min-max game:
Exi∼pl,xj ∼pu Ladv(xi, xj; θF , θD) = −Exi∼pl wl(xi) · log(1 − D(F (xi))) max
θF min
θD (10)
−Exj ∼pu wu(xj) · log D(F (xj)).
Thanks to the two class-sharing scores wl and wu, we can successfully mitigate the feature distribution mismatch between pl
Cu . As we will show later in the experiments, our feature adaptation can re-discover the value of unlabeled data and boost the SSL performance.
C without being inﬂuenced by the irrelevant distributions pl
Cl and pu
C and pu 5
2.4 Semi-Supervised Training
With the aforementioned class-sharing data detection and feature adaptation, we can take full ad-vantage of the open-set information by alleviating the negative impact from both class distribution mismatch and feature distribution mismatch. Then, we should aim at effectively exploring the class-sharing unlabeled data, meanwhile weakening the negative impact from private data. Particularly, the private data in C could mislead the unlabeled data transferring to the wrong classes, and the unlabeled private data in C could be erroneously incorporated into network training, causing further performance degradation. To solve this problem, we propose the following SSL training strategy: u l min
θF ,θC wu(x) · Lssl(C(F (x)), ˆy), (11) where wu(x) is employed to weaken the network learning on unlabeled private data, and ˆy indicates the calibrated pseudo target for each unlabeled datum to mitigate the misleading bias introduced by labeled private data. To calibrate the original biased pseudo target y, we propose to utilize a weighted softmax function. Particularly, we compute the average weight of wl with respect to each class c as wavg c = 1 l l (cid:88) i=1
I(yi = c) · wl(xi), c ∈ Cl. (12)
Based on Eq. (2), the computed weight wavg
Then we can calibrate the pseudo target y through c would be large if c is in C, and be small if c is in C l
.
[ˆy]c =
· exp [y]c wavg c (cid:80)|Cl| i=1 wavg i
· exp [y]i
, c ∈ Cl, (13) where the notation [·]c denotes the c-th entry of the input vector. Through such process, the entries of ˆy belonging to C would be suppressed, and those belonging to C would be enhanced, which successfully alleviates the bias from the original target y. l
To sum up, our general framework can be instantiated by substituting Eq. (10) and Eq. (11) into the feature adaptation term and class-sharing data exploration term in Eq. (1). Later experiments will show that our CAFA framework can effectively tackle different scenarios of the open-set problem without any prior knowledge of the class relationship and achieve encouraging performances. 3