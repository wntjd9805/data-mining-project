Abstract
Meaningful and simpliﬁed representations of neural activity can yield insights into how and what information is being processed within a neural circuit. However, without labels, ﬁnding representations that reveal the link between the brain and behavior can be challenging. Here, we introduce a novel unsupervised approach for learning disentangled representations of neural activity called Swap-VAE. Our approach combines a generative modeling framework with an instance-speciﬁc alignment loss that tries to maximize the representational similarity between trans-formed views of the input (brain state). These transformed (or augmented) views are created by dropping out neurons and jittering samples in time, which intu-itively should lead the network to a representation that maintains both temporal consistency and invariance to the speciﬁc neurons used to represent the neural state. Through evaluations on both synthetic data and neural recordings from hundreds of neurons in different primate brains, we show that it is possible to build representations that disentangle neural datasets along relevant latent dimensions linked to behavior. 1

Introduction
In the brain, the coordinated actions of groups of neurons are responsible for encoding sensory inputs and movements, as well as all processing and manipulation in between (1; 2; 3; 4; 5). Understanding what different populations of neurons are doing and how they work together to encode their inputs is a primary goal of neuroscience (6).
When successful, representations learned from populations of neurons can provide insights into how neural circuits work to encode their inputs and produce behavior, and allow for robust and stable decoding of these correlates. Over the last decade, a number of unsupervised learning approaches have been introduced to build representations of neural population activity without knowledge of speciﬁc labels or downstream decoding objectives (7; 8; 9; 10; 11; 12; 13). Such methods have provided exciting new insights into the stability of neural responses (14), individual differences (10), and remapping of neural responses through learning (15). However, without labels or additional inputs to guide the network, learning representations that allow different sources of variability to be distinguished is still a major challenge (16; 17).
∗Contact: rliu361@gatech.edu, evadyer@gatech.edu. Project page: https://nerdslab.github.io/SwapVAE/. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
Here, we develop a novel unsupervised approach for disentangling neural activity called Swap-VAE.
Our approach is loosely inspired by methods used in computer vision that aim to decompose images into their content and style (18; 19; 20; 21; 22): the representation of the content should give us the abstract “gist” of the image (what it is), and the style components are needed to create a realistic image (or, equivalently, they capture the variation in images with the same content). To map this idea onto the decomposition of brain states, we consider the execution of movements and their representation within the the brain (Figure 1, Right). The content in this case may be knowing where to go (target location) and the style would be the exact execution of the movement (the movement dynamic). We ask whether the neural representation of movement can be disentangled in a similar manner.
To identify the content within our neural recording, we use a self-supervised approach: we apply a variety of transformations to the input data (observed ﬁring rates) which we hypothesize to be content-preserving, and train the representation to be invariant to these manipulations. These transformed (or augmented) views are created by dropping out neurons and jittering samples in time, which intuitively should lead the network to a representation that maintains both temporal consistency and invariance to the speciﬁc neurons used to represent the neural state. In addition to this instance-speciﬁc alignment loss, we also encourage the network to reconstruct the original inputs using a regularized variational autoencoder (beta-VAE) (23; 24) that has access to both the content variables and another set of variables in the model that encodes the style. We show that through combining our proposed self-supervised alignment loss with a generative model, we can learn representations that disentangle latent factors underlying neural population activity.
We apply our method to synthetic data and publicly available non-human primate (NHP) reaching datasets from two different individuals (25). To quantify how effectively our method disentangles these datasets, we propose several general-purpose measures of representation quality, which char-acterize the extent to which variation in content and style is isolated by the two different spaces.
We show that by using our approach, we can effectively disentangle the behavior and dynamics of movement without any labels. Our model thus strikes a nice balance between view-invariant representation and generation.
Our speciﬁc contributions are as follows:
• In Section 3, we propose a generative method, Swap-VAE, that can both (i) learn a repre-sentation of neural activities that reveal meaningful and interpretable latent factors and (ii) generate realistic neural activities.
• To further encourage disentanglement, we introduce a novel latent space augmentation called BlockSwap (Section 3.3), where we swap the content variables between two views and ask the network to predict the original view from the content of a different view.
• In Section 3.4, we introduce metrics to quantify the disentanglement of our representations of behavior and apply them to neural datasets from different non-human primates (Section 4) to gain insights into the link between neural activity and behavior. 2