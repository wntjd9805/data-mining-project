Abstract
In this paper, we tackle the problem of novel visual category discovery, i.e., group-ing unlabelled images from new classes into different semantic partitions by lever-aging a labelled dataset that contains images from other different but relevant categories. This is a more realistic and challenging setting than conventional semi-supervised learning. We propose a two-branch learning framework for this problem, with one branch focusing on local part-level information and the other branch focusing on overall characteristics. To transfer knowledge from labelled data to unlabelled data, we propose using dual ranking statistics on both branches to generate pseudo labels for training on the unlabelled data. We further introduce a mutual knowledge distillation method to allow information exchange and encour-age agreement between the two branches for discovering new categories, allowing our model to enjoy the beneﬁts of global and local features. We comprehensively evaluate our method on public benchmarks for generic object classiﬁcation, as well as the more challenging benchmarks for ﬁne-grained visual recognition, achieving state-of-the-art performance. 1

Introduction
Superior performance on many problems has been achieved by recent machine learning models, especially the ones based on deep learning. While the success comes at the cost of large-scale human annotation, which is prohibitively expensive in practice. For example, modern convolutional neural networks (CNNs) can surpass human-level recognition performance on ImageNet after training with over one million labelled images [22]. On the one hand, it is not possible to annotate all possible classes in the real world, as there are way more classes than the 1, 000 classes in ImageNet and new classes keep growing over time. On the other hand, annotating speciﬁc data, such as the medical data, may require speciﬁc expertise, which renders the large-scale annotation extremely difﬁcult, if not impossible. Therefore, it is desired to enable the machine learning systems to deal with unlabelled data automatically.
Recently, the problem of novel category discovery was formalized in [20, 18], which aims at discovering new visual categories on unlabelled data by transferring knowledge from labelled data.
The labelled data is assumed to contain similar but different categories to those in the unlabelled data.
This problem is similar to semi-supervised learning in the sense that both labelled and unlabelled data are used to learn the model. While novel category discovery is much harder because semi-supervised learning assumes that every class contains labelled instances, while for novel category discovery there are no labels available for the new classes in the unlabelled data. This setting is also relevant to
∗ Corresponding author. 35th Conference on Neural Information Processing Systems (NeurIPS 2021)
unsupervised clustering. But differently, novel category discovery makes use of the labelled data to extract a speciﬁc class prior (i.e., the properties that delineate a class) for partitioning the unlabelled data, while the unsupervised clustering may produce multiple different but equally valid clustering results by adopting different properties (e.g., color, shape, pose, lighting, etc). In this paper, we introduce a simple and effective two-branch framework for novel category discovery, with one branch focusing on local part-level information and the other branch focusing on overall characteristics. Our contributions are as follows.
First, we propose to apply dual ranking statistics for transferring knowledge from the known classes in the labelled data to the unlabelled data, resulting in more robust pseudo label generation for learning on the unlabelled data. We maintain a dynamic object part dictionary and apply part-level ranking statistics on the similarity distribution of each instance over the dictionary to obtain pseudo labels, which are complementary to the pseudo labels obtained by simply examining the ranking statistics of global descriptors.
Second, we introduce a mutual knowledge distillation method to allow information exchange and encourage agreement between the local and global branches. The dual ranking statistics provide global and part-level information for learning in two branches separately. The mutual knowledge distillation further allows information exchange between the two branches and makes them beneﬁt from each other. Unlike conventional methods that distill between teacher and student models with known labels, our method distills between two branches of the same model without any manual annotations.
Third, we comprehensively evaluate our method on public benchmarks for generic object classi-ﬁcation, including CIFAR10, CIFAR100, and ImageNet, obtaining state-of-the-art results. Fur-thermore, we also validate our approach on the more challenging ﬁne-grained datasets CUB-200,
Stanford-Cars, and FGVC-Aircraft, in which the local details are more important to distinguish different classes. Our method outperforms existing methods by a substantial margin, thanks to the ability of our model to subtly exploit both local and global information. Our code can be found at https://github.com/DTennant/dual-rank-ncd. 2