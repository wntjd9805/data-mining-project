Abstract
Existing convolutional neural networks (CNNs) often use global average pooling (GAP) to aggregate feature maps into a single representation. However, GAP cannot well characterize complex distributive patterns of spatial features while such patterns play an important role in texture-oriented applications, e.g., material recognition and ground terrain classiﬁcation. In the context of texture representa-tion, this paper addressed the issue by proposing Fractal Encoding (FE), a feature encoding module grounded by multi-fractal geometry. Considering a CNN feature map as a union of level sets of points lying in the 2D space, FE characterizes their spatial layout via a local-global hierarchical fractal analysis which examines the multi-scale power behavior on each level set. This enables a CNN to encode the regularity on the spatial arrangement of image features, leading to a robust yet discriminative spectrum descriptor. In addition, FE has trainable parameters for data adaptivity and can be easily incorporated into existing CNNs for end-to-end training. We applied FE to ResNet-based texture classiﬁcation and retrieval, and demonstrated its effectiveness on several benchmark datasets. 1

Introduction
Ideal image descriptors for classiﬁcation are capable of characterizing both local features and global patterns of an image. Local features are about the local singularities or ﬁne details of an image, such as edges and corners. Global patterns are about the distributions and spatial layouts of local image features. While local features are critical for visual recognition, global image patterns also play an important role in many scenarios, such as material recognition [1], ground terrain classiﬁcation [2] and dynamics recognition [3].
Typical convolutional neural networks (CNNs) for image classiﬁcation connect convolutional layers with fully-connected (FC) layers. The FC layers encode the spatial layouts of feature maps and act as a classiﬁer. Such a structure fails to produce a robust global representation, as FC layers capture spatial layouts based on “absolute” locations and their outputs are not invariant to spatial transforms such as translation, rotation and scaling, that often occur in real scenarios.
To achieve the robustness to spatial transforms in CNN-based representation, many existing studies (e.g. [4, 5, 6]) apply global average pooling (GAP) to feature maps, which averages all entries in a feature channel so as to eliminate the dependency on spatial locations. However, the naive averaging operation totally disregards the spatial layout of a feature map. As a result, when dealing with images of complex distributive patterns, GAP cannot encode sufﬁciently discriminative information.
∗Corresponding author: Yuhui Quan 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
A robust yet discriminative global representation is particularly important for analyzing images of texture patterns [7], since for such images, spatial transforms are one main source of variations and distributive characteristics are the key clues during analysis. In the context of texture analysis and related applications, there have been some efforts [8, 9, 10, 11, 2, 12] on designing a more sophisti-cated global pooling module. Most of these works are about encoding the numerical distribution of features (e.g. soft histograms [8, 9, 12]) into a single representation. Nonetheless, they may still lose the details on the spatially distributive characteristics of features which are useful for texture analysis.
Aiming at characterizing the spatially distributive patterns in feature maps to form a robust yet discriminative texture representation, this paper proposed a statistical global feature encoding module called FE (Fractal Encoding), which is grounded by fractal geometry [13, 14].
Fractal geometry has been widely used for texture analysis and synthesis; see e.g. [15,
Motivations 16, 17, 18, 19, 20].
Its central concept is the fractal dimension that measures the distributive irregularity of a spatial point set. Many studies have shown that natural textures carry fractal dimension information [15, 16, 21]. Since a CNN is a spatial feature extractor, its generated feature maps may also encode fractal dimension information that reﬂects the regularity of texture patterns.
Inspired by this, FE describes the spatial layout of features in terms of spatially distributive regularity using fractal-dimension-based statistics in a hierarchical manner.
Fractal dimension is established based on the measurement at scale δ. For each δ, an object is measured in a way that ignores the irregularity of size less than δ. If the measurement is proportional to δ−β for some β and β is almost the same for small scales δ, we can compute its limit, which is called the fractal dimension. Let the n-dimensional Euclidean space Rn be covered by a mesh of n-dimensional hypercubes with diameter d. Given a point set E⊂Rn, its fractal dimension denoted by β(E) is deﬁned by [14]:
β(E) = lim d→0 log N (E, d)
− log d
, (1) where N (E, d) is the number of mesh hypercubes that intersect E.
It can be seen fractal dimension is about cross-scale examination in terms of power law. This makes it possible to encode additional discriminative information on spatial layouts that ignored by the simple number counting operations in a histogram. For simplicity, consider the fractal dimensions on binary images. The white/black pixels on a binary image can be viewed as a set of points on a 2D grid. See
Figure 1 for three numerical examples, where the fractal dimensions are different between the grid and the two bars, while the histograms of all the sample images in terms of black/white pixels are the same. If we view those sample images as speciﬁc feature patches, the fractal-dimension-based statistics from FE can well distinguish the spatial feature organization of those two types of textures.
In addition to discriminability, fractal dimension is theoretically invariant to spatial bi-Lipschitz transform [21, 20], a general transform that covers a wide range of often-seen image transformations.
Note that the inﬂuence of the spatial transforms of an image are likely to propagate to its feature maps. Then the FE driven by fractal dimensions can enjoy the robustness in this case. 1.80 1.62 1.62
Figure 1: Fractal dimensions (numbers in the second row) calculated by the scheme of [22] on a grid image and two bar images. The white pixels are viewed as a set of spatial points on a 2D grid. If we view the binary images as some texture features (e.g. feature patches from a CNN), then fractal dimensions can well distinguish the spatial distribution of the two types of texture features.
Main idea
The key part in FE is the fractal analysis pooling (FAP). For higher discriminability, FAP leverages multi-fractal geometry [23] to form multiple fractal-dimension-based statistical quantities.
This leads to a local-global hierarchical fractal analysis process. Concretely, FE looks at a feature map as an union of point sets. The point sets are the level sets under a local point-wise categorization function D(·). The FE calculates a single (global) fractal-dimension-based statistical quantity on 2
every level set: f ( (cid:98)D) = β(E (cid:98)D), where E (2)
Encouraged by the robustness of fractal dimension to spatial transforms and feature value scaling, we introduce the function D based on local fractal dimension [16] (also called Hölder exponent [14]) deﬁned as the power D(·) of U (B (x, r)) ∝ rD(x) for x ∈ E, where B (x, r) is a hypercube with center x and diameter 2r, and U is some measurement. It can be seen that the local fractal dimension has a similar form as the global one in (1): (cid:98)D = {x ∈ E : D(x) = (cid:98)D}.
D(x) = lim r→0 log U(B(x, r))
−log r
. (3)
In other words, D(x) characterizes the local power law around x under measurement U.
The above local-global hierarchical fractal analysis process involves some discrete operations (e.g. box counting) that are non-differentiable, which creates obstacles for back propagation and model training.
By appropriate design with soft relaxations, we implement FE using common operations of CNNs, so that it can be end-to-end trained on top of any standard CNN and deal with images of varying sizes.
In addition, FE is designed with trainable parameters which can be jointly learned with the backbone network for better adaptivity to data, as well as for automatically setting some hyper-parameters which may be difﬁcult to determine but critical to the performance in practice.
Since FAP and GAP capture distributive features from different aspects respectively, FE combines them with the bi-linear pooling (BLP) [24] to exploit their complementary capabilities. The resulting module is deployed to the ResNet for texture classiﬁcation and retrieval.
Contributions
This work contributes to deep learning and texture analysis in the following aspects.
Firstly, we propose a novel fractal-analysis-driven global feature encoding module which is capable of encoding the spatially distributive regularity of features on a feature map. Secondly, we build multi-fractal analysis into a standard CNN for boosting the power of deep-learning-based texture representation, which leads to state-of-the-art results in classiﬁcation and retrieval tasks. 2