Abstract
We propose a Safe Pontryagin Differentiable Programming (Safe PDP) methodol-ogy, which establishes a theoretical and algorithmic framework to solve a broad class of safety-critical learning and control tasks—problems that require the guaran-tee of safety constraint satisfaction at any stage of the learning and control progress.
In the spirit of interior-point methods, Safe PDP handles different types of system constraints on states and inputs by incorporating them into the cost or loss through barrier functions. We prove three fundamentals of the proposed Safe PDP: ﬁrst, both the solution and its gradient in the backward pass can be approximated by solving their more efﬁcient unconstrained counterparts; second, the approximation for both the solution and its gradient can be controlled for arbitrary accuracy by a barrier parameter; and third, importantly, all intermediate results throughout the approximation and optimization strictly respect the constraints, thus guaranteeing safety throughout the entire learning and control process. We demonstrate the ca-pabilities of Safe PDP in solving various safety-critical tasks, including safe policy optimization, safe motion planning, and learning MPCs from demonstrations, on different challenging systems such as 6-DoF maneuvering quadrotor and 6-DoF rocket powered landing. 1

Introduction
Safety is usually a priority in the deployment of a learning or control algorithm to real-world systems.
For a physical system (agent), safety is normally given in various constraints on system states and inputs, which must not be violated by the algorithm at any stage of the learning and control process, otherwise will cause irrevocable or unacceptable failure/damage. Those systems are referred to as safety-critical. The constraints in a safety-critical system can include the immediate ones, which are directly imposed on the system state and input at certain or all-time instances, and the long-term ones, which are deﬁned on the trajectory of system states and inputs over a long period.
Compared to the abundant results that focus on system optimality [1–3], systematic and principled treatments for safety-critical learning and control problems seem largely insufﬁcient, particularly in the following gaps (detailed in Section 1.1). First, existing safety strategies are either too conservative, which may restrict the task performance, or violation-tolerable, which only pursues the near-constraint guarantee and thus are not strictly constraint-respecting. Second, a systematic safety paradigm capable of handling different types of constraints, including system state and input (or mixed), immediate, or/and long-term constraints, is still lacked. Third, some existing safety strategies suffer from huge computational- and data- complexity, difﬁcult to be integrated into any differentiable programming frameworks to solve large-scale learning and continuous control tasks.
To address the above research gaps, this paper aims to develop a safe differentiable programming framework with the following key capabilities. First, the framework provides a systematic treatment for different types of constraints in a safety-critical problem; second, it attains provable safety- and accuracy- guarantees throughout the learning and control process; third, it is ﬂexible to perform safe learning of any unknown aspects of a constrained decision-making system, including policy, dynamics, state and input constraints, and control cost; ﬁnally, it can be integrated to any differentiable programming framework to efﬁciently solve large-scale safe learning and control tasks. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
1.1