Abstract
Feature-based dynamic pricing is an increasingly popular model of setting prices for highly differentiated products with applications in digital marketing, online sales, real estate and so on. The problem was formally studied as an online learning problem [Javanmard and Nazerzadeh, 2019] where a seller needs to propose prices on the fly for a sequence of T products based on their features x while having a small regret relative to the best —“omniscient”— pricing strategy she could have come up with in hindsight. We revisit this problem and provide two algorithms (EMLP and ONSP) for stochastic and adversarial feature settings, respectively, and prove the optimal O(d log T ) regret bounds for both. In comparison, the best and O(T 2/3) respectively, with existing results are O
λmin being the smallest eigenvalue of E[xxT ] that could be arbitrarily close to 0.
We also prove an Ω(
T ) information-theoretic lower bound for a slightly more general setting, which demonstrates that “knowing-the-demand-curve” leads to an exponential improvement in feature-based dynamic pricing. (cid:110) 1
λ2 log T, min (cid:111)(cid:17)
√
√ (cid:16)
T min 1

Introduction
The problem of pricing — to find a high-and-acceptable price — has been studied since Cournot
[1897]. In order to locate the optimal price that maximizes the revenue, a firm may adjust their prices of products frequently, which inspires the dynamic pricing problem. Existing works [Kleinberg and
Leighton, 2003, Broder and Rusmevichientong, 2012, Chen and Farias, 2013, Besbes and Zeevi, 2015] primarily focus on pricing a single product, which usually will not work well in another setting when thousands of new products are being listed every day with no prior experience in selling them.
Therefore, we seek methods that approach an acceptable-and-profitable price with only observations on this single product and some historical selling records of other products.
In this work, we consider a “feature-based dynamic pricing” problem, which was studied by Amin et al. [2014], Cohen et al. [2020], Javanmard and Nazerzadeh [2019]. In this problem setting, a sales session (product, customer and other environmental variables) is described by a feature vector, and the customer’s expected valuation is modeled as a linear function of this feature vector.
Feature-based dynamic pricing. For t = 1, 2, ..., T : 1. A feature vector xt ∈ Rd is revealed that describes a sales session (product, customer and context). 2. The customer valuates the product as wt = x⊤ 3. The seller proposes a price vt > 0 concurrently (according to xt and historical sales records). 4. The transaction is successful if vt ≤ wt, i.e., the seller gets a reward (payment) of rt = vt · 1(vt ≤ wt). t θ∗ + Nt.
Here T is unknown to the seller (and thus can go to infinity), xt’s can be either stochastic (e.g., each sales session is drawn i.i.d.) or adversarial (e.g., the sessions arrive in a strategic sequence),
θ∗ ∈ Rd is a fixed parameter for all time periods, Nt is a zero-mean noise, and 1t = 1(vt ≤ wt) is an indicator that equals 1 if vt ≤ wt and 0 otherwise. In this online-fashioned setting, we only see 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
Table 1: