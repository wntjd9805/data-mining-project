Abstract
In statistical learning and analysis from shared data, which is increasingly widely adopted in platforms such as federated learning and meta-learning, there are two major concerns: privacy and robustness. Each participating individual should be able to contribute without the fear of leaking one’s sensitive information. At the same time, the system should be robust in the presence of malicious participants inserting corrupted data. Recent algorithmic advances in learning from shared data focus on either one of these threats, leaving the system vulnerable to the other. We bridge this gap for the canonical problem of estimating the mean from i.i.d. samples. We introduce PRIME, which is the ﬁrst efﬁcient algorithm that achieves both privacy and robustness for a wide range of distributions. We further complement this result with a novel exponential time algorithm that improves the sample complexity of PRIME, achieving a near-optimal guarantee and matching a known lower bound for (non-robust) private mean estimation. This proves that there is no extra statistical cost to simultaneously guaranteeing privacy and robustness. 1

Introduction
When releasing database statistics on a collection of entries from individuals, we would ideally like to make it impossible to reverse-engineer each individual’s potentially sensitive information.
Privacy-preserving techniques add just enough randomness tailored to the statistical task to guarantee protection. At the same time, it is becoming increasingly common to apply such techniques to databases collected from multiple sources, not all of which can be trusted. Emerging data access frameworks, such as federated analyses across users’ devices or data silos [50], make it easier to temper with such collected datasets, leaving private statistical analyses vulnerable to a malicious corruption of a fraction of the data.
Differential privacy has emerged as a widely accepted de facto measure of privacy, which is now a standard in releasing the statistics of the U.S. Census data [2] statistics and also deployed in real-world commercial systems [74, 40, 41]. A statistical analysis is said to be differentially private (DP) if the likelihood of the (randomized) outcome does not change signiﬁcantly when a single arbitrary entry is added/removed (formally deﬁned in §1.2). This provides a strong privacy guarantee: even a powerful adversary who knows all the other entries in the database cannot conﬁdently identify whether a particular individual is participating in the database based on the outcome of the analysis.
This ensures plausible deniability, central to protecting an individual’s privacy.
In this paper, we focus on one of the most canonical problems in statistics: estimating the mean of a distribution from i.i.d. samples. For distributions with unbounded support, such as sub-Gaussian and heavy-tailed distributions, fundamental trade-offs between accuracy, sample size, and privacy have only recently been identiﬁed [58, 52, 54, 3] and efﬁcient private estimators proposed. However, these approaches are brittle when a fraction of the data is corrupted, posing a real threat, referred to as data poisoning attacks [19, 79]. In defense of such attacks, robust (but not necessarily private) statistics has emerged as a popular setting of recent algorithmic and mathematical breakthroughs [73, 30]. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
One might be misled into thinking that privacy ensures robustness since DP guarantees that a single outlier cannot change the estimation too much. This intuition is true only in a low dimension; each sample has to be an obvious outlier to signiﬁcantly change the mean. However, in a high dimension, each corrupted data point can look perfectly uncorrupted but still shift the mean signiﬁcant when colluding together (e.g., see Fig. 1). Focusing on the canonical problem of mean estimation, we introduce novel algorithms that achieve robustness and privacy simultaneously even when a fraction of data is corrupted arbitrarily. For such algorithms, there is a fundamental question of interest: do we need more samples to make private mean estimation also robust against adversarial corruption?
Sub-Gaussian distributions. If we can afford exponential run-time in the dimension, robustness can be achieved without extra cost in sample complexity. We introduce a novel estimator that (i) satisﬁes (ε, δ)-DP, (ii) achieves near-optimal robustness under α-fraction of corrupted data, achieving accuracy of O(α(cid:112)log(1/α)) nearly matching the fundamental lower bound of Ω(α) that holds even for a (non-private) robust mean estimation with inﬁnite samples, and (iii) achieves near-optimal sample complexity matching that of a fundamental lower bound for a (non-robust) private mean estimation as shown in Table 1.
Theorem 1 (Informal Theorem 7, exponential time). Algorithm 2 is (ε, δ)-DP. When α fraction of the data is arbitrarily corrupted from n samples from a d-dimensional sub-Gaussian distribution with mean µ and an identity sub-Gaussian parameter, if n = (cid:101)Ω(d/α2 + (d + d1/2 log(1/δ))/(αε)) then Algorithm 2 achieves (cid:107)ˆµ − µ(cid:107)2 = O(α(cid:112)log(1/α)) w.h.p.
We introduce PRIME (PRIvate and robust Mean Estimation) in §2.3 with details in Algorithm 9 in
Appendix E.1, to achieve computational efﬁciency. It requires a run-time of only (cid:101)O(d3 + nd2), but at the cost of requiring extra d1/2 factor larger number of samples. This cannot be improved upon with current techniques since efﬁcient robust estimators rely on the top PCA directions of the covariance matrix to detect outliers. [78] showed that (cid:101)Ω(d3/2) samples are necessary to compute PCA directions d). It remains an open question if this (cid:101)Ω(d3/2/(αε)) while preserving (ε, δ)-DP when (cid:107)xi(cid:107)2 = O( bottleneck is fundamental; no matching lower bound is currently known.
Theorem 2 (Informal Theorem 6, polynomial time). PRIME is (ε, δ)-DP and under the assumption of Thm.1, if n = (cid:101)Ω(d/α2 + (d3/2 log(1/δ))/(αε)), achieves (cid:107)ˆµ − µ(cid:107)2 = O(α(cid:112)log(1/α)) w.h.p.
√ (ε, δ)-DP [52]
α-corruption [36]
α-corruption and (ε, δ)-DP (this paper)
Upper bound (poly-time) Upper bound (exp-time) (cid:101)O( d (cid:101)O(cid:0) d
αε
α2 + d log1/2(1/δ) (cid:101)O( d
α2 )
α2 + d3/2 log(1/δ)
αε
[Theorem 6]
) (cid:1) (cid:101)O( d
αε )♣
α2 + d (cid:101)O( d
α2 )
α2 + d+d1/2 log(1/δ)
αε
[Theorem 7] (cid:101)O( d
)
Lower bound
α2 + d (cid:101)Ω( d
αε )♠
Ω( d
α2 )
α2 + d
[52]
αε )♠ (cid:101)Ω( d
Table 1: For estimating the mean µ ∈ Rd of a sub-Gaussian distribution with a known covariance, we list the sufﬁcient or necessary conditions on the sample sizes to achieve an error (cid:107)ˆµ − µ(cid:107)2 = (cid:101)O(α) under (ε, δ)-DP, corruption of an α-fraction of samples, and both. ♣ requires the distribution to be a
Gaussian [14] and ♠ requires δ ≤ d/n.
√
Heavy-tailed distributions. When samples are drawn from a distribution with a bounded covariance, parameters of Algorithm 2 can be modiﬁed to nearly match the optimal sample complexity of (non-robust) private mean estimation in Table 2. This algorithm also matches the fundamental limit on the accuracy of (non-private) robust estimation, which in this case is Ω(α1/2).
Theorem 3 (Informal Theorem 8, exponential time). From a distribution with mean µ ∈ Rd and covariance Σ (cid:22) I, n samples are drawn and α-fraction is corrupted. Algorithm 2 is (ε, δ)-DP and if n = (cid:101)Ω((d + d1/2 log(1/δ))/(αε) + d1/2 log3/2(1/δ)/ε) achieves (cid:107)ˆµ − µ(cid:107)2 = O(α1/2) w.h.p.
The proposed PRIME-HT for covariance bounded distributions achieve computational efﬁciency at the cost of an extra factor of d1/2 in sample size. This bottleneck is also due to DP PCA, and it remains open whether this gap can be closed by an efﬁcient estimator.
Theorem 4 (Informal Theorem 9, polynomial time). PRIME-HT is (ε, δ)-DP and if n = (cid:101)Ω((d3/2 log(1/δ))/(αε)) achieves (cid:107)ˆµ − µ(cid:107)2 = O(α1/2) w.h.p. under the assumptions of Thm. 3. 2
Upper bound (poly-time) Upper bound (exp-time) Lower bound (ε, δ)-DP [54]
α-corruption [36]
α-corruption and (ε, δ)-DP (this paper) (cid:101)O( d log1/2(1/δ)
αε (cid:101)O( d
α ) (cid:101)O(cid:0) d3/2 log(1/δ)
αε
[Theorem 9]
) (cid:1)
) (cid:101)O( d log1/2(1/δ)
αε (cid:101)O( d
α ) (cid:101)O( d+d1/2 log3/2(1/δ)
αε
[Theorem 8]
)
Ω( d
αε )
Ω( d
α )
Ω( d
αε ) ([54])
Table 2: For estimating the mean µ ∈ Rd of a covariance bounded distribution, we list the sufﬁcient or necessary conditions on the sample size to achieve an error (cid:107)ˆµ − µ(cid:107)2 = O(α1/2) under (ε, δ)-DP, corruption of an α-fraction of samples, and both. 1.1 Technical contributions
We introduce PRIME which simultaneously achieves (ε, δ)-DP and robustness against α-fraction of corruption. A major challenge in making a standard ﬁlter-based robust estimation algorithm (e.g.,
[30]) private is the high sensitivity of the ﬁltered set that we pass from one iteration to the next.
We propose a new framework which makes private only the statistics of the set, hence signiﬁcantly reducing the sensitivity. Our major innovation is a tight analysis of the end-to-end sensitivity of this multiple interactive accesses to the database. This is critical in achieving robustness while preserving privacy and is also of independent interest in making general iterative ﬁltering algorithms private.
√
The classical ﬁlter approach (see, e.g. [30]) needs to access the database O(d) times, which brings an extra O( d) factor in the sample complexity due to DP composition. In order to reduce the iteration complexity, following the approach in [36], we propose ﬁltering multiple directions simultaneously using a new score based on the matrix multiplicative weights (MMW). In order to privatize the MMW
ﬁlter, our major innovation is a novel adaptive ﬁltering algorithm DPTHRESHOLD(·) that outputs a single private threshold which guarantees sufﬁcient progress at every iteration. This brings the number of database accesses from O(d) to O((log d)2).
One downside of PRIME is that it requires an extra d1/2 factor in the sample complexity, compared to known lower bounds for (non-robust) DP mean estimation. To investigate whether this is also necessary, we propose a sample optimal exponential time robust mean estimation algorithm in §4 and prove that there is no extra statistical cost to jointly requiring privacy and robustness. Our major technical innovations is in using resilience property of the dataset to not only ﬁnd robust mean (which is the typical use case of resilience) but also bound sensitivity of that robust mean. 1.2 Preliminary on differential privacy (DP)
DP is a formal metric for measuring privacy leakage when a dataset is accessed with a query [37].
Deﬁnition 1.1. Given two datasets S = {xi}n i=1, we say S and S(cid:48) are neighboring if d(cid:52)(S, S(cid:48)) ≤ 1 where d(cid:52)(S, S(cid:48)) (cid:44) max{|S \ S(cid:48)|, |S(cid:48) \ S|}, which is denoted by S ∼ S(cid:48). For an output of a stochastic query q on a database, we say q satisﬁes (ε, δ)-differential privacy for some
ε > 0 and δ ∈ (0, 1) if P(q(S) ∈ A) ≤ eεP(q(S(cid:48)) ∈ A) + δ for all S ∼ S(cid:48) and all subset A. i=1 and S(cid:48) = {x(cid:48) i}n(cid:48)
Let z ∼ Lap(b) be a random vector with entries i.i.d. sampled from Laplace distribution with pdf (1/2b)e−|z|/b. Let z ∼ N (µ, Σ) denote a Gaussian random vector with mean µ and covariance Σ.
Deﬁnition 1.2. The sensitivity of a query f (S) ∈ Rk is deﬁned as ∆p = supS∼S(cid:48) (cid:107)f (S) − f (S(cid:48))(cid:107)p for a norm (cid:107)x(cid:107)p = ((cid:80) i∈[k] |xi|p)1/p. For p = 1, the Laplace mechanism outputs f (S) + Lap(∆1/ε) and achieves (ε, 0)-DP [37]. For p = 2, the Gaussian mechanism outputs f (S) + N (0, (∆2((cid:112)2 log(1.25/δ))/ε)2I) and achieves (ε, δ)-DP [38].
We use these output perturbation mechanisms along with the exponential mechanism [69] as building blocks. Appendix A provides detailed survey of privacy and robust estimation. 1.3 Problem formulation
We are given n samples from a sub-Gaussian distribution with a known covariance but unknown mean, and α fraction of the samples are corrupted by an adversary. Our goal is to estimate the 3
unknown mean. We follow the standard deﬁnition of adversary in [30], which can adaptively choose which samples to corrupt and arbitrarily replace them with any points.
Assumption 1. An uncorrupted dataset Sgood consists of n i.i.d. samples from a d-dimensional sub-Gaussian distribution with mean µ ∈ Rd and covariance E[xx(cid:62)] = Id, which is 1-sub-Gaussian, 2/2) for all v ∈ Rd. For some α ∈ (0, 1/2), we are given a corrupted i.e., E[exp(v(cid:62)x)] ≤ exp((cid:107)v(cid:107)2 dataset S = {xi ∈ Rd}n i=1 where an adversary adaptively inspects all the samples in Sgood, removes
αn of them, and replaces them with Sbad which are αn arbitrary points in Rd.
Similarly, we consider the same problem for heavy-tailed distributions with a bounded covariance.
We present the assumption and main results for covariance bounded distributions in Appendix B.
Notations. Let [n] = {1, 2, . . . , n}. For x ∈ Rd, we use (cid:107)x(cid:107)2 = ((cid:80) i∈[d](xi)2)1/2 to denote the
Euclidean norm. For X ∈ Rd×d, we use (cid:107)X(cid:107)2 = max(cid:107)v(cid:107)2=1 (cid:107)Xv(cid:107)2 to denote the spectral norm.
The d × d identity matrix is Id×d. Whenever it is clear from context, we use S to denote both a set of data points and also the set of indices of those data points. (cid:101)O and (cid:101)Ω hide poly-logarithmic factors in d, n, 1/α, and the failure probability.
Outline. We present PRIME for sub-Gaussian distribution in §2, and present theoretical analysis in
§3. We then introduce an exponential time algorithm with near optimal guarantee in §4. Due to space constraints, analogous results for heavy-tailed distributions are presented in Appendix B. 2 PRIME: efﬁcient algorithm for robust and DP mean estimation
In order to describe the proposed algorithm PRIME, we need to ﬁrst describe a standard (non-private) iterative ﬁltering algorithm for robust mean estimation. 2.1