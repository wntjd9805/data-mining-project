Abstract
Rule-based models, e.g., decision trees, are widely used in scenarios demanding high model interpretability for their transparent inner structures and good model expressivity. However, rule-based models are hard to optimize, especially on large data sets, due to their discrete parameters and structures. Ensemble methods and fuzzy/soft rules are commonly used to improve performance, but they sacriﬁce the model interpretability. To obtain both good scalability and interpretability, we propose a new classiﬁer, named Rule-based Representation Learner (RRL), that automatically learns interpretable non-fuzzy rules for data representation and classiﬁcation. To train the non-differentiable RRL effectively, we project it to a continuous space and propose a novel training method, called Gradient Grafting, that can directly optimize the discrete model using gradient descent. An improved design of logical activation functions is also devised to increase the scalability of
RRL and enable it to discretize the continuous features end-to-end. Exhaustive experiments on nine small and four large data sets show that RRL outperforms the competitive interpretable approaches and can be easily adjusted to obtain a trade-off between classiﬁcation accuracy and model complexity for different scenarios. Our code is available at: https://github.com/12wang3/rrl. 1

Introduction
Although Deep Neural Networks (DNNs) have achieved impressive results in various machine learning tasks (Goodfellow et al., 2016), rule-based models, beneﬁting from their transparent inner structures and good model expressivity, still play an important role in domains demanding high model interpretability, such as medicine, ﬁnance, and politics (Doshi-Velez and Kim, 2017). In practice, rule-based models can easily provide explanations for users to earn their trust and help protect their rights (Molnar, 2019; Lipton, 2016). By analyzing the learned rules, practitioners can understand the decision mechanism of models and use their knowledge to improve or debug the models (Chu et al., 2018). Moreover, even if post-hoc methods can provide interpretations for DNNs, the interpretations from rule-based models are more faithful and speciﬁc (Murdoch et al., 2019). However, conventional rule-based models are hard to optimize, especially on large data sets, due to their discrete parameters and structures, which limit their application scope. To take advantage of rule-based models in more scenarios, we urgently need to answer such a question: how to improve the scalability of rule-based models while keeping their interpretability?
∗Corresponding authors. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
Studies in recent years provide some solutions to improve conventional rule-based models in different aspects. Ensemble methods and soft/fuzzy rules are proposed to improve the performance and scalability of rule-based models but at the cost of model interpretability (Ke et al., 2017; Breiman, 2001; Irsoy et al., 2012). Bayesian frameworks are also leveraged to more reasonably restrict and adjust the structures of rule-based models (Letham et al., 2015; Wang et al., 2017; Yang et al., 2017).
However, due to the non-differentiable model structure, they have to use methods like MCMC or
Simulated Annealing, which could be time-consuming for large models. Another way to improve rule-based models is to let a high-performance but complex model (e.g., DNN) teach a rule-based model (Frosst and Hinton, 2017; Ribeiro et al., 2016). However, learning from a complex model requires soft rules, or the ﬁdelity of the student model is not guaranteed. The recent study Wang et al. (2020) tries to extract hierarchical rule sets from a tailored neural network. When the network is large, the extracted rules could behave quite differently from the neural network and become useless in most cases. Nevertheless, combined with binarized networks (Courbariaux et al., 2015), it inspires us that we can search for the discrete solutions of interpretable rule-based models in a continuous space leveraging effective optimization methods like gradient descent.
In this paper, we propose a novel rule-based model named Rule-based Representation Learner (RRL) (see Figure 1a). We summarize the key contributions as follows:
• To achieve good model transparency and expressivity, RRL is formulated as a hierarchical model, with layers supporting automatic feature discretization, rule-based representation learning in ﬂexible conjunctive and disjunctive normal forms, and rule importance evaluation.
• To facilitate training effectiveness, RRL exploits a novel gradient-based discrete model train-ing method, Gradient Grafting, that directly optimizes the discrete model and uses the gradient information at both continuous and discrete parametric points to accommodate more scenarios.
• To ensure data scalability, RRL utilizes improved logical activation functions to handle high-dimensional features. By further combining the improved logical activation functions with a tailored feature binarization layer, it realizes the continuous feature discretization end-to-end.
• We conduct experiments on nine small data sets and four large data sets to validate the advantages, i.e., good accuracy and interpretability, of our model over other representative classiﬁcation models. The beneﬁts of the model’s key components are also veriﬁed by the experiments. 2