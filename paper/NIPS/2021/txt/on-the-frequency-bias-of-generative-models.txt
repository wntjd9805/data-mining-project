Abstract
The key objective of Generative Adversarial Networks (GANs) is to generate new data with the same statistics as the provided training data. However, multiple recent works show that state-of-the-art architectures yet struggle to achieve this goal.
In particular, they report an elevated amount of high frequencies in the spectral statistics which makes it straightforward to distinguish real and generated images.
Explanations for this phenomenon are controversial: While most works attribute the artifacts to the generator, other works point to the discriminator. We take a sober look at those explanations and provide insights on what makes proposed measures against high-frequency artifacts effective. To achieve this, we ﬁrst independently assess the architectures of both the generator and discriminator and investigate if they exhibit a frequency bias that makes learning the distribution of high-frequency content particularly problematic. Based on these experiments, we make the following four observations: 1) Different upsampling operations bias the generator towards different spectral properties. 2) Checkerboard artifacts introduced by upsampling cannot explain the spectral discrepancies alone as the generator is able to compensate for these artifacts. 3) The discriminator does not struggle with detecting high frequencies per se but rather struggles with frequencies of low magnitude. 4) The downsampling operations in the discriminator can impair the quality of the training signal it provides. In light of these ﬁndings, we analyze proposed measures against high-frequency artifacts in state-of-the-art GAN training but ﬁnd that none of the existing approaches can fully resolve spectral artifacts yet.
Our results suggest that there is great potential in improving the discriminator and that this could be key to match the distribution of the training data more closely. 1

Introduction
In recent years, unconditional Generative Adversarial Networks (GANs) have achieved impressive photo-realism for image synthesis tasks. While this has hampered the identiﬁcation of generated images based on visual cues, multiple recent works show that it is straightforward to distinguish real and generated images based on their high-frequency content [7–9, 14, 22, 34, 38]. This has aroused considerable interest because it reveals a fundamental problem in state-of-the-art GANs:
Existing approaches evidently struggle to learn the correct data distribution. While GAN training is notoriously hard, learning the distribution of high-frequency content is particularly problematic [7– 9, 14, 22, 34, 38]. This indicates a systematic problem in existing approaches that could make training suboptimal. For example, if generating high-frequencies is difﬁcult for the generator but detecting them is straightforward for the discriminator this imbalance could impair the stability of the training. Conversely, if the discriminator struggles to detect high frequencies generating ﬁne details also becomes more difﬁcult which could impede convergence. Therefore, we argue that it is important to better understand the expressivity of both the generator and the discriminator. Indeed, numerous works suggest that the architecture of the generator can hamper the generation of high 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
(a) Ground truth (b) Reconstruction of a generator with bilin-ear upsampling using pixel-level supervision (c) Reconstruction guided by a discriminator with BlurPool downsampling
Figure 1: Spectral Properties of Generator and Discriminator. (a) We show a natural image and a high-pass ﬁltered version (ampliﬁed for clarity) to illustrate the networks’ behavior for both low and high magnitudes at high frequencies. (b) Our experiments reveal that bilinear upsampling biases the generator towards generating data with little high-frequency content, regardless of the magnitude. (c) The discriminator shows no such bias but provides better guidance for frequencies with high magnitude. The results further reveal artifacts due to downsampling that impair the training signal.
We include the training details for both experiments in the supplementary. frequencies [4, 7, 9, 10, 14, 20]. However, another line of works question the quality of the training signal provided by the discriminator [5, 10, 15]. But is there indeed a frequency bias that prevents learning high frequencies in existing GAN models?
This is a non-trivial question as GAN training involves two players where architectures for both the generator and discriminator, loss functions, as well as the dataset statistics can all affect the generated images. To narrow down potential factors, we ﬁrst develop isolated testbeds for both the generator and discriminator. Then, we extend our ﬁndings to state-of-the-art GANs on large-scale datasets.
Generator: The majority of works attribute the high-frequency artifacts to the upsampling operations in the generator [4, 7, 9, 25, 38]. Upsampling typically follows a pre-deﬁned scheme, e.g. bilinear or nearest neighbor interpolation, or zero insertion between pixels. While the latter introduces too many high frequencies, interpolation has been shown to reduce artifacts [4, 7]. But is interpolation always a good scheme for upsampling? Our experiments indicate that both bilinear and nearest neighbor upsampling bias the generator towards predicting little high-frequency content, see Fig. 1b.
While zero insertion can be more ﬂexible, it is prone to introducing checkerboard artifacts, i.e. too many high frequencies [4, 7, 25]. But why do the learnable ﬁlters in subsequent layers not learn to compensate for these artifacts? Depending on the training objective, checkerboard artifacts might be penalized only slightly. Our experiments evidence that when the loss function is sensitive to these artifacts the generator is indeed capable of compensating for them.
Discriminator: This leads us to question the quality of the training signal: Can the discriminator detect high frequencies and provide the necessary supervision? Chen et al. [5] argue that the discriminator cannot detect high-frequency information due to the downsampling operations. Our experiments corroborate that downsampling can introduce artifacts in the training signal. However, we also observe that the discriminator can indeed provide a meaningful training signal for the spectral statistics at high frequencies when their magnitude is large enough, e.g., Fig. 1c. Other works propose to train both the generator and discriminator in wavelet space [10] or add a discriminator on the spectrum of the images to reduce high-frequency artifacts [15]. Motivated by these approaches we ask: Is it enough to consider only the spatial domain? In agreement with these works, our results suggest that the discriminator can beneﬁt from (additional) input in frequency-based domains. Further, our testbed yields insights on which of these measures is most effective and reveals that the training signal from the discriminator might remain problematic.
Contributions: We take a sober look at explanations for high-frequency artifacts in generated images and unify the efforts that have been done so far. In particular, we develop isolated testbeds for both the generator and the discriminator which allows us to analyze what makes existing efforts effective.
The conclusions drawn by this paper shed new light on limitations of common design choices for both generator and discriminator: i) Bilinear and nearest neighbor upsampling bias the generator towards 2
predicting little high-frequency content. ii) Zero insertion is prone to producing checkerboard artifacts in the generated images. However, with a suitable loss function, the learnable ﬁlters of the generator can compensate for the artifacts. This indicates that the upsampling in the generator alone cannot explain the spectral discrepancies. iii) In general, the discriminator is able to detect high frequencies and provide supervision to learn the correct spectral statistics. However, while the exponential decay of the spectrum for natural images creates the impression of the discriminator being insensitive to high frequencies, it actually struggles with low magnitudes. iv) We ﬁnd that all commonly used downsampling operations in the discriminator can impair the quality of the training signal.
Lastly, we demonstrate that these ﬁndings extend to full GAN training. In agreement with [15], we ﬁnd that spectral discriminators can bring us one step closer to matching the spectral statistics.
Nonetheless, generated images remain straightforward to classify based on their spectral statistics only. While recent works on GANs largely focus on improving the generator, e.g., [16, 18, 19], our
ﬁndings suggest that the design of the discriminator plays an equally important role and deserves more attention in future work. We believe that our testbeds for both the generator and discriminator can be a useful tool for future investigations. We release our code and dataset at https://github.com/ autonomousvision/frequency_bias. 2 Preliminaries
GAN Training: A generative adversarial network consists of a generator and a discriminator that are trained jointly in a 2-player game. Given latent variables z ∼ pz, the generator synthesizes images while the discriminator tries to distinguish the synthesized images from real images I ∼ pD, sampled from data distribution pD. Let GΘ and DΦ denote a generator G and a discriminator D with parameters Θ and Φ, respectively. The parameters of the models are updated in alternating steps using a non-saturating GAN objective [11] which is often combined with R1-regularization to stabilize training [24]
V (Θ, Φ) = Ez∼pz [f (DΦ(GΘ(z)))] + EI∼pD f (−DΦ(I)) − λ(cid:107)∇DΦ(I)(cid:107)2(cid:105) (cid:104) (1) where f (t) = − log(1 + exp(−t)) and λ controls the strength of the regularizer.
Image Processing in the Frequency Domain: The discrete 2D Fourier transform maps a gray scale image I ∈ RH×W to the frequency domain:
ˆI[k, l] = 1
HW
H−1 (cid:88)
W −1 (cid:88) x=0 y=0 exp−2πi x·k
H exp−2πi y·l
W ·I[x, y] (2) for k = 0, . . . , H − 1 and l = 0, . . . , W − 1. The power spectral density is estimated by the squared magnitudes of the Fourier components S[k, l] = |ˆI[k, l]|2. Similar to [7, 8] we consider the reduced spectrum ˜S, i.e. the azimuthal average over the spectrum in normalized polar coordinates r ∈ [0, 1],
θ ∈ [0, 2π)
˜S(r) = 1 2π (cid:90) 2π 0
S(r, θ)dθ with r = (cid:115) k2 + l2 1 4 (H 2 + W 2) and θ = atan2(k, l) (3)
Since images are discretized in space, the maximum frequency is determined by the Nyquist fre-quency. For a square image, H = W , it is given by fnyq =
Spectral Classiﬁer: To detect generated images, Dzanic et al. [8] propose to classify real and gen-erated images based on their reduced spectrum. More speciﬁcally, they ﬁt a power-law function to the tail of each reduced spectrum for frequencies above a given threshold rc = 0.75 and train a binary classiﬁer on the ﬁt parameters of each spectrum. 2, i.e. for r = 1. k2 + l2 = H/
√
√ 3 Are high frequencies more difﬁcult to generate?
In this section, we investigate if there is a frequency bias in the generator that impedes the generation of high frequencies. Therefore, we ﬁrst consider the generator in an isolated setting assuming pixel-level supervision – otherwise, even with a perfect discriminator it would be impossible to generate a correct image. We extend our ﬁndings to the full GAN setting in Section 5. 3
There are two lines of argumentation in existing works: The ﬁrst investigates artifacts that arise from the upsampling operations in the generator [4, 7, 9]. These works analyze the spectral properties of the generator predictions at convergence. We extend this analysis from the perspective of a frequency bias to see if low frequencies are learned earlier during training. The second line of works argues for a frequency bias of the learnable ﬁlters [14, 20]. Motivated by their analysis we investigate if learnable ﬁlters are at all able to compensate for the artifacts introduced by upsampling.
Experimental Setting: To isolate the generator from the discriminator we consider a conditional re-construction task. In particular, we take 10 images from a dataset and pair them with 10 latent codes drawn from a normal distribution. Given a latent code, the generator is optimized to reconstruct the corresponding image with a pixel-wise L2-loss
LI = 1
HW
H−1 (cid:88)
W −1 (cid:88) x=0 y=0 (cid:107)GΘ(z)[x, y] − I[x, y](cid:107)2 2 (4)
√
√
We choose the generator from PGAN [16] because of its simple architecture comprising only con-volutions and upsampling operations. Further, when combined with R1-regularization it trains stably in a GAN setting [24], allowing us to use the same generator in Section 5. We reduce the number of channels for faster training because our primary focus is on the spectral properties. As upsampling operations, we investigate bilinear and nearest neighbor interpolation, zero insertion, and reshaping in the channel dimension [29]. We ensure that all networks have a similar number of parameters.
More details are provided in the supplementary.
Datasets: In natural images, the spectral density follows an exponential decay. To isolate the ef-fects of frequency range and magnitute, we create a Toyset of images with two Gaussian peaks
N (µ1, σ1), N (µ2, σ2) of equal magnitude in the spectrum, see Fig. 2a, 2b. Based on the Nyquist frequency fnyq = H/ 2fnyq and draw µ1 ∼ 2, we create samples using σ1 = σ2 = 1/
U(0.05fnyq, 0.15fnyq) and µ2 ∼ U(0.75fnyq, 0.85fnyq). Together with a uniformly distributed phase, we apply the inverse Fourier transform to create images. We further test our setting on natural images with a downsampled version of CelebA [21]. Both datasets have a resolution of 642 pixels.
Evaluation Metrics: On the spatial domain, we report PSNR on the RGB values and on the fre-quency domain we evaluate the reduced spectrum, see Eq. (3). To analyze frequency-dependent convergence we further visualize the evolution of the spectrum similar to [26]. Here, the x-axis denotes the (frequency) radius r in normalized polar coordinates and the y-axis denotes the training iterations. The color corresponds to the relative error of the average predicted reduced spectrum wrt. the ground truth, where positive and negative values indicate too many and too few predicted frequencies, respectively. We clip the colorbar at 1, i.e., when the relative error exceeds 100%.
Do generators exhibit a frequency bias? The spectral evolution in Fig. 2 shows different behavior for bilinear and nearest neighbor upsampling compared to zero insertion and reshaping. Particularly on the Toyset, a generator with bilinear or nearest neighbor upsampling learns the lower frequencies earlier in training than the high frequencies, see Fig. 2c and 2d. While the generator with bilinear upsampling struggles with high frequencies throughout training, for nearest neighbor upsampling it eventually ﬁts the high-frequency peak, suggesting that its bias towards little high-frequency content is not as strong. In contrast, a generator with zero insertion or reshaping learns both peaks approx-imately at equal speed but is prone to generating checkerboard artifacts as indicated by the large error at the highest frequency in Fig. 2e and 2f. Between the peaks of the toyset, where frequencies have small magnitudes, all methods struggle to match the statistics of the training data because the L2-loss penalizes errors at frequencies with low magnitude only slightly. This explains why for CelebA there is an overall trend towards learning lower frequencies earlier during training. The PSNR values in
Table 1 support these ﬁndings in the spatial domain. The lack of high frequencies for bilinear and nearest neighbor upsampling manifests in a low PSNR, particularly for the Toyset which contains many high frequencies by construction.
Can the generator learn to compensate for the artifacts? Since the L2-loss is less sensitive to frequencies with low magnitudes (see supplementary for a formal derivation), we now add an L2-loss on the logarithm of the reduced spectrum:
LS = 1
√
H/ 2
H/ 2−1
√ (cid:88) k=0 (cid:13) (cid:13) (cid:13)log (cid:16) ˜S (GΘ(z)) (cid:17)
[k] − log (cid:17) (cid:16) ˜S(I)
[k] (cid:13) 2 (cid:13) (cid:13) 2 (5)
The logarithm penalizes errors at low magnitudes more strongly and can therefore reduce the checker-board artifacts introduced by zero insertion and reshaping, see Fig. 3. Hence, given a suitable 4
Bilinear
+ LS
NN
+ LS
Zeros
+ LS
Reshape
+ LS
AvgPool BlurPool
+ SD
+ SD
Stride
MLP
+ SD
+SD
Toyset 21.1 20.9 30.7 30.7 38.6 38.0 38.6 36.5
CelebA 34.9 37.0 40.9 39.8 42.4 43.6 42.3 40.9
Toyset 16.3 19.2 23.3 15.6 23.3 24.1 26.2 46.5
CelebA 25.4 27.0 24.2 24.4 25.5 25.6 28.1 33.7
Table 1: PSNR for different upsampling opera-tions in the generator at resolution 642 pixels.
Table 2: PSNR for different downsampling opera-tions in the discriminator at resolution 642 pixels. t e s y o
T
A b e l e
C (a) GT Sample (b) GT Spectrum (c) Bilinear (d) NN (e) Zeros (f) Reshape
Figure 2: Spectrum Error Evolution for the Generator. We show one sample from the dataset in the ﬁrst column and the mean and standard deviation of the reduced spectra for all 10 samples in the second column for reference. For the Toyset the dashed lines mark the mean of the Gaussian peaks at 0.1fnyq and 0.8fnyq. Upsampling with bilinear or nearest neighbor interpolation biases the generator towards predicting little high-frequency content. Conversely, zero insertion and reshaping are prone to introducing checkerboard artifacts, indicated by the large errors at the highest frequency. The color corresponds to the relative error of the average predicted reduced spectrum wrt. the ground truth and is clipped at 1, i.e. when the relative error exceeds 100%. (a) Bilinear (b) NN (c) Zeros (d) Reshape
Figure 3: Reduced Spectrum for the Generator on the Toyset. We plot the mean and standard deviation of the reduced spectrum above 0.75fnyq. The peak at the highest frequencies from upsampling with zero insertion or reshaping is removed by an additional loss on the spectrum. objective, learnable ﬁlters can indeed compensate for high-frequency artifacts introduced by zero insertion and reshaping. Interestingly, bilinear upsampling does not beneﬁt as much from the spectral loss. This suggests that a strong bias towards little high-frequency content can be more difﬁcult to compensate for. As expected, the additional loss does not alter the evaluation in the spatial domain signiﬁcantly and yields similar PSNR values in Table 1.
Implications: Overall, these results lead us to conclude that different upsampling operations bias the generator towards different spectral properties. Nearest neighbor and particularly bilinear up-sampling introduce a bias towards ﬁtting functions with little high-frequency content. In Section 5, we will see that this can also be beneﬁcial when working with natural images as their spectral density follows an exponential decay. On the other hand, zero insertion and reshaping introduce a bias towards checkerboard artifacts. However, with a suitable loss function, the network ﬁlters can learn to compensate for these artifacts. Therefore, the upsampling in the generator alone cannot explain the spectral discrepancies. This suggests that the training signal provided by the discriminator might be suboptimal in the ﬁrst place. 5
t e s y o
T
A b e l e
C t e s y o
T
A b e l e
C (a) AvgPool (b) BlurPool (c) Stride (d) MLP (a) Stride (b) +SD (c) +F-Mining (d) +Wavelet
Figure 4: Spectrum Error Evolution for Dis-criminators with Different Downsampling
Operations. The downsampling operations do not signiﬁcantly bias the discriminator to-wards any frequency range. Instead, it gener-ally struggles with frequencies of low magni-tude. The color corresponds to the relative error of the average predicted reduced spectrum wrt. the ground truth and is clipped at 1, i.e. when the relative error exceeds 100%.
Figure 5: Spectrum Error Evolution for
Discriminators on Different Input Domains.
The spectral discriminator greatly improves the spectral statistics on both datasets while hard example mining in the frequency domain (F-mining) and wavelets alter results only slightly.
The color corresponds to the relative error of the average predicted reduced spectrum wrt. the ground truth and is clipped at 1, i.e. when the relative error exceeds 100%. 4 Can the discriminator provide a good training signal?
In this section, we investigate how good the training signal is that the discriminator can provide.
Only a few existing works consider the discriminator as a cause for the spectral discrepancies. Chen et al. [5] attribute the high-frequency artifacts to information loss in the downsampling operations. In particular, they analyze how high frequencies affect the output of the discriminator at convergence.
Instead, we consider how downsampling affects the training signal by assessing the input to the dis-criminator. Further, we analyze how the spectral statistics evolve during training to see if downsam-pling introduces a bias towards correcting low frequencies earlier than high frequencies. To reduce spectral discrepancies, Chen et al. [5] propose a regularizer based on the reduced spectrum to per-form hard example mining in the frequency domain, cf. Eq. (3). Similarly, Jung et al. [15] deﬁne an additional discriminator on the reduced spectrum. While spectral discrepancies are not the main fo-cus of their work, Gal et al. [10] also argue for "unfavorable loss functions" and propose to train both the generator and discriminator in wavelet space. In the second part of this section, we therefore aim to understand what makes (additional) inputs from other domains valuable and which of the proposed measures are most effective to correct the high-frequency artifacts.
Experimental Setting: Similar to the generator experiments in Section 3, we propose a conditional reconstruction task to assess the quality of the training signal independently of the generator architec-ture. More speciﬁcally, we train a class-conditional GAN with a single sample per class. To minimize the impact of the generator, we directly optimize the pixel values of the fake images. In practice, we pair 10 images with 10 labels as training data and optimize 10 learnable tensors conditioned on the la-bels. We optimize the learnable tensors and discriminator weights in an alternating fashion using the
GAN two-player game setting. Similar to Section 3, we use the PGAN discriminator [16] with a re-duced number of channels because our primary focus is on the spectral properties. As downsampling operations, we investigate strided convolution, average pooling, and blurring with subsequent average pooling [37]. We further train an MLP on the ﬂattened input image as a baseline without any downsam-pling operations. When adding a spectrum discriminator, we weigh both discriminator losses equally as in [15]. Note, that training a GAN on such few images is a non-trivial task that requires careful tuning to train stably. We ensured that this is the case for our results, see supplementary for details.
Datasets and Metrics: We use the same datasets and metrics as in Section 3 and evaluate them on the reconstructions guided by the gradients from the discriminator. This allows us to assess the quality of the training signal.
How does downsampling affect the training signal? Fig. 4 shows the evolution of the average spec-trum of the reconstructed images. On the Toyset, both the low- and high-frequency peaks are learned approximately at an equal pace. This suggests that the discriminator can indeed detect and correct the spectral statistics at high frequencies, regardless of the choice of downsampling operation. However, 6
(a) GT (b) MLP (c) AvgPool (d) BlurPool (e) Stride (f) Stride
+ SD (g) Stride
+ F-mining (h) Stride
+ Wavelet
Figure 6: Reconstruction Guided by the Discriminator. All discriminators with downsampling lead to signiﬁcant deviations from the ground truth. While F-mining and wavelets slightly improve the reconstruction, the spectral discriminator decreases image ﬁdelity. all approaches struggle to correct frequencies of low magnitude. For natural images, the power spectrum decays exponentially which creates the impression that the discriminator struggles with high frequencies, while it actually struggles with the low magnitude of the high-frequency content.
In image space, amongst the downsampling operations strided convolution achieves the best PSNR.
However, it is much lower than the values for the generator in Table 1 which reﬂects the harder task due to instance- instead of pixel-level supervision. Fig. 6 shows the learned tensors at the last training iteration. While the reconstruction from the MLP is reasonably good, the downsampling operations introduce artifacts in the training signal provided by the discriminator.
Is it enough to train in the spatial domain? In Fig. 5 we compare the spectrum evolution for an addi-tional spectral discriminator (SD) [15], hard example mining in the frequency domain (F-Mining) [5] and training in wavelet space (Wavelet) [10]. Since the spectral discriminator is directly applied to the reduced spectrum, it can guide the generator on the spectral statistics of the dataset and greatly reduces the error in Fig. 5b. Instead, F-mining and wavelets only slightly reduce the spectral discrepancies, e.g., on CelebA for frequencies between 0.5 − 0.75fnyq. While F-mining increases the weight of samples with poor spectral realness, it does not make the discriminator more sensitive to slight changes in im-age space. This is in agreement with the ﬁndings in [5]. Wavelets separate the input wrt. the frequency but not wrt. the magnitude which could explain why low magnitude artifacts remain difﬁcult to detect.
In the spatial domain, however, the reconstructions with the spectral discriminator in Fig. 6e and 6f reveal a caveat: While the spectrum is better aligned, the reconstruction with the additional spec-tral discriminator qualitatively becomes worse. As the spectrum computation and the azimuthal integration discard information, images with the same reduced spectra can look very different.
Consequently, penalizing the reduced spectrum might not be sufﬁcient for improving the training signal alone. This also reﬂects in the PSNR in Table 2 which, except for the MLP, remains largely unaffected by the spectral discriminator. In the supplementary, we verify that replacing the reduced spectrum with the full Fourier transform indeed improves the image ﬁdelity. However, as the spectral discriminator is an MLP, this does not trivially scale to real-world settings.
Implications: In contrast to existing hypotheses, our ﬁndings evidence that the discriminator gener-ally struggles with frequencies that have a low magnitude but that high frequencies are not per se more difﬁcult to detect. An additional discriminator on the reduced spectrum can greatly facilitate learning the spectral statistics of the data but might not improve the image ﬁdelity. Even in our simple testbed, none of the convolutional architectures with downsampling is able to provide artifact-free supervision.
This indicates that the discriminator might play a more important role in reducing high-frequency arti-facts than currently anticipated in the ﬁeld. While a simple spectral discriminator provides a good ﬁrst step, we conclude that more work in this area is required to solve the problem. We believe that one key is to reduce the downsampling artifacts, e.g., by exploring alternative downsampling operations or by considering approaches that allow for pixel-level supervision of the discriminator as in [30] or [28]. 5
Improving GANs
We now analyze the full GAN training, i.e., when generator and discriminator are two competing neural networks. First, we extend the discriminator analysis from Section 4 and verify if these results are also valid for full GAN training. Next, we investigate if the most effective discriminator is able to resolve high-frequency artifacts of the different upsampling strategies discussed in Section 3.
Lastly, we analyze its effect on StyleGAN2 [19], a state-of-the-art GAN model, which shows the characteristic peak at the highest frequencies in the reduced spectrum. 7
(a) Bilinear (b) NN (c) Zeros (d) Reshape
Figure 7: Reduced Spectrum for PGAN on FFHQ64. We plot the mean and standard deviation of the reduced spectrum above 0.75fnyq. The spectral discriminator prevents the high peak for zero insertion and reshaping but cannot fully correct the spectral discrepancies. Similar to Fig. 3, bilinear upsampling struggles to match the spectral statistics of the dataset.
Original Wavelet
Acc FID Acc FID Acc FID Acc FID
F-Mining
SD
Bilinear
Reshape
Acc FID Acc FID Acc FID Acc FID
Zeros
NN
FFHQ64 72 31.0 73 39.8 73 33.7 62 31.0
Cats128 88 106.1 74 122.5 77 119.3 62 114.6
FFHQ64 57 36.3 62 31.0 66 34.9 67 35.2
Cats128 62 138.2 62 114.6 77 128.8 70 129.7
Table 3: Spectral Classiﬁcation Accuracy and
FID for PGAN with discriminators on different input domains.
Table 4: Spectral Classiﬁcation Accuracy and
FID for PGAN using different upsampling strate-gies with spectral discriminator.
Experimental Setting: We start by combining the architectures from Section 3 and Section 4 to obtain PGAN [16] with a reduced number of channels, which we train from scratch with R1-regularization and without progressive growing [19, 24] until the discriminator has seen 15M images.
Next, we extend our analysis to StyleGAN2 on resolutions up to 10242 pixels. The StyleGAN2 generator uses bilinear upsampling which, according to our previous ﬁndings, should not cause the el-evated amount of high frequencies. Therefore, we ﬁnetune pre-trained models with the most effective discriminator following the training protocol from [17] until the discriminator has seen 2.5M images.
Datasets: We consider large-scale real-world datasets in this section. We train our version of PGAN on a downsampled version of FFHQ [18] at resolution 642 pixels and a downsampled version of 200k images from LSUN Cats [36] at resolution 1282 pixels. We ﬁnetune StyleGAN2 on LSUN
Cats (2562 pixels), AFHQ Dog [6] (5122 pixels) and FFHQ (10242 pixels). For AFHQ Dog, we use adaptive discriminator augmentation due to the small size of the dataset [17].
Evaluation Metrics: In the spatial domain, we report FID [12] on the full dataset and 50k gen-erated images. To measure spectral discrepancies we deploy the spectral classiﬁer described in
Section 2. We follow the proposal in [4] and replace the KNN classiﬁer with an SVM to ob-tain a stronger classiﬁer. We use 1000 real and fake images each and use 90% and 10% for training and evaluation, respectively. Here, a classiﬁcation accuracy of around 50% is ideal as this indicates a perfect generator because the classiﬁer is forced to make a random guess.
+SD
Original
Acc FID Acc FID 92 6.5 80 8.4
Cats256
AFHQ Dog 92 7.4 66 12.1 99 2.8 94 3.1
FFHQ
How do the isolated settings transfer to full GAN training?
We ablate PGAN with discriminators on different input domains in Table 3. In agreement with the ﬁndings from Section 4, the wavelet discriminator (Wavelet) and hard frequency mining (F-Mining) improve the spectral statistics only slightly. Hence, generated images can still be classiﬁed with high accuracy. The most effective method to learn the spectral statistics remains the additional spectral discriminator (SD) as indicated by the lower accuracy of the spectral classiﬁer on all datasets. Con-sistent with our observation on the testbed, the image quality in the spatial domain remains largely unaffected.
Recalling the implication of Section 3, that the generator can learn to compensate for high-frequencies artifacts given a suited training objective, we now investigate whether the spectral discriminator satis-ﬁes such a requirement for different upsampling operations in the generator. Consistent with our obser-vation on the generator testbed, Fig. 7 shows that the spectrum discriminator is also able to signiﬁcantly reduce the peak at the highest frequency for both zero insertion and reshaping upsampling. However, the magnitude at the highest frequencies remains slightly elevated because the generator only receives supervision through the discriminator (real vs. fake) instead of full ground truth spectra considered in
Table 5: Finetuning StyleGAN2 with an additional disciminator on the reduced spectrum. 8
the testbed. On the other hand, the bias towards little high-frequency content for bilinear and nearest neighbor upsampling aligns well with the spectral statistics of the datasets. This also reﬂects in Table 4 where images generated with zero insertion and reshaping are still detected with higher accuracy than images generated with bilinear and nearest neighbor upsampling. Considering both the spatial statis-tics and image ﬁdelity, we observe that upsampling with nearest neighbor yields the best performance.
Lastly, we evaluate the effect of the spectral discriminator when applied to StyleGAN2 on datasets with higher resolution, namely LSUN Cats (2562), AFHQ Dog (5122) and FFHQ (10242). The results in Table 5 show mixed results: On AFHQ Dog the spectral discriminator results in a strong improvement on the spectrum but also signiﬁcantly increases the FID. In contrast, on FFHQ the FID stays similar but the spectral discriminator also only slightly improves the spectral statistics and is not able to correct the peak at the highest frequency1. This suggests that in existing architectures there is a tradeoff between perceptual image quality and matching the spectral statistics of the data.
Implications: Our experiments show that both of our testbeds on the generator and the discriminator provide consistent observations which are aligned with those for full GAN training. Our ﬁndings suggest that the spectral discriminator can reduce the spectral discrepancies but the misalignment in the high frequencies is not fully addressed. We further observe that nearest neighbor upsam-pling together with an additional spectral discriminator is a good combination for natural images where high-frequency content is low. However, when applying existing measures to StyleGAN2, we observe that none of them can solve the spectral discrepancies completely. This suggests that the high-frequency artifacts in GANs are still an open problem that require further research. Our work takes an important step towards understanding the underlying mechanisms and sheds light on the effectiveness and limitations of existing approaches. 6 Other