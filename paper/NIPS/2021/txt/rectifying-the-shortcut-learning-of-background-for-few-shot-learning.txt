Abstract
The category gap between training and evaluation has been characterised as one of the main obstacles to the success of Few-Shot Learning (FSL). In this paper, we for the first time empirically identify image background, common in realistic images, as a shortcut knowledge helpful for in-class classification but ungeneralizable beyond training categories in FSL. A novel framework, COSOC, is designed to tackle this problem by extracting foreground objects in images at both training and evaluation without any extra supervision. Extensive experiments carried on inductive FSL tasks demonstrate the effectiveness of our approaches. 1

Introduction
Through observing a few samples at a glance, humans can accurately identify brand-new objects.
This advantage comes from years of experiences accumulated by the human vision system. Inspired by such learning capabilities, Few-Shot Learning (FSL) is developed to tackle the problem of learning from limited data [24, 53]. At training, FSL models absorb knowledge from a large-scale dataset; later at evaluation, the learned knowledge is leveraged to solve a series of downstream classification tasks, each of which contains very few support (training) images from brand-new categories.
The category gap between training and evaluation has been considered as one of the core issues in
FSL [10]. Intuitively, the prior knowledge of old categories learned at training may not be applicable to novel ones. [62] consider solving this problem from a causal perspective. Their backdoor adjustment method, however, adjusts the prior knowledge in a black-box manner and cannot tell which specific prior knowledge is harmful and should be suppressed.
In this paper, we identify image background as one specific harmful source knowledge for FSL.
Empirical studies in [56] suggest that there exists spurious correlations between background and category of images (e.g., birds usually stand on branches, and shells often lie on the beaches; see
Fig. 1), which serves as a shortcut knowledge for modern CNN-based vision systems to learn. It is further revealed that background knowledge has positive impact on the performance of in-class classification tasks. As illustrated in the simple example of Fig. 1, images from the same category are more likely to share similar background, making it possible for background knowledge to generalize from training to testing in common classification tasks. For FSL, however, the category gap produces brand-new foreground, background and their combinations at evaluation. The correlations learned at training thus may not be able to generalize and would probably mislead the predictions. We take
*Corresponding author
Code: https://github.com/Frankluox/FewShotCodeBase 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
Figure 1: An illustrative example that demonstrates why background information is useful for regular classification but harmful for few-shot learning. empirical investigations on the role of image foreground and background in FSL, revealing how image background drastically affects the learning and evaluation of FSL in a negative way.
Since the background is harmful, it would be good if we could force the model to concentrate on foreground objects at both training and evaluation, but this is not easy since we do not have any prior knowledge of the entity and position of the foreground objects in images. When humans are going to recognize foreground objects of images from the same class, they usually look for a shared local pattern that appears in the majority of images, and recognize patches with this pattern as foreground.
This inspires us to design a novel framework, COSOC, to extract foreground of images for both training and evaluation of FSL by seeking shared patterns among images. The approach does not depend on any additional fine-grained supervisions such as bounding boxes or pixel-level labelings.
The procedure of foreground extraction of images in the training set is implemented before training.
The corresponding algorithm, named Clustering-based Object Seeker (COS), first pre-trains a feature extractor on the training set using contrative learning, which has an outstanding performance, shown empirically in a later section, on the task of discriminating between ground-truth foreground objects.
The feature extractor then maps random crops of images—candidates of foreground objects—into a well-shaped feature space. This is followed by runing a clustering algorithm on all of the features of the same class, imitating the procedure of seeking shared local patterns inspired by human behavior.
Each cropped patch is then assigned a foreground score according to its distance to the nearest cluster centroid, for determining a sampling probability of that patch in the later formal training of FSL models. For evaluation, we develop Shared Object Concentrator (SOC), an algorithm that applies iterative feature matching within the support set, looking for one crop per image at one time that is most likely to be foreground. The sorted averaging features of obtained crops are further leveraged to match crops of query images so that foreground crops have higher matching scores. A weighted sum of matching scores are finally calculated as classification logits of each query sample. Compared to other potential foreground extracting algorithms such as saliency-based methods, our COS and SOC algorithms have additional capability of capturing shared, inter-image information, performing better in complicated, multi-object scenery. Our methods also have flexibility of dynamically assigning beliefs (probabilities) to all candidate foreground objects, relieving the risk of overconfidence.
Our contributions can be summarized as follows. i) By conducting empirical studies on the role of image foreground and background in FSL, we reveal that image background serves as a source of shortcut knowledge which harms the evaluation performance. ii) To solve this problem, we propose
COSOC, a framework combining COS and SOC, which can draw the model’s attention to image foreground at both training and evaluation. iii) Extensive experiments for non-transductive FSL tasks demonstrate the effectiveness of our method. 2