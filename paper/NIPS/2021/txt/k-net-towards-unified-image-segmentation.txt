Abstract
Semantic, instance, and panoptic segmentations have been addressed using different and specialized frameworks despite their underlying connections. This paper presents a uniﬁed, simple, and effective framework for these essentially similar tasks. The framework, named K-Net, segments both instances and semantic categories consistently by a group of learnable kernels, where each kernel is responsible for generating a mask for either a potential instance or a stuff class.
To remedy the difﬁculties of distinguishing various instances, we propose a kernel update strategy that enables each kernel dynamic and conditional on its meaningful group in the input image. K-Net can be trained in an end-to-end manner with bipartite matching, and its training and inference are naturally NMS-free and box-free. Without bells and whistles, K-Net surpasses all previous published state-of-the-art single-model results of panoptic segmentation on MS COCO test-dev split and semantic segmentation on ADE20K val split with 55.2% PQ and 54.3% mIoU, respectively. Its instance segmentation performance is also on par with
Cascade Mask R-CNN on MS COCO with 60%-90% faster inference speeds. Code and models will be released at https://github.com/ZwwWayne/K-Net/. 1

Introduction
Image segmentation aims at ﬁnding groups of coherent pixels [48]. There are different notions in groups, such as semantic categories (e.g., car, dog, cat) or instances (e.g., objects that coexist in the same image). Based on the different segmentation targets, the tasks are termed differently, i.e., semantic and instance segmentation, respectively. There are also pioneer attempts [19, 29, 50, 62] to joint the two segmentation tasks for more comprehensive scene understanding.
Grouping pixels according to semantic categories can be formulated as a dense classiﬁcation problem.
As shown in Fig. 1-(a), recent methods directly learn a set of convolutional kernels (namely semantic kernels in this paper) of pre-deﬁned categories and use them to classify pixels [40] or regions [22].
Such a framework is elegant and straightforward. However, extending this notion to instance segmentation is non-trivial given the varying number of instances across images. Consequently, instance segmentation is tackled by more complicated frameworks with additional steps such as object detection [22] or embedding generation [44]. These methods rely on extra components, which must guarantee the accuracy of extra components to a reasonable extent, or demand complex post-processing such as Non-Maximum Suppression (NMS) and pixel grouping. Recent approaches [34, 49, 55] generate kernels from dense feature grids and then select kernels for segmentation to simplify the frameworks. Nonetheless, since they build upon dense grids to enumerate and select kernels, these methods still rely on hand-crafted post-processing to eliminate masks or kernels of duplicated instances. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
Figure 1: Semantic segmentation (a), instance (b), and panoptic segmentation (c) tasks are uniﬁed by a common framework in this paper. In conventional semantic segmentation methods, each convolutional kernel corresponds to a semantic class. Our framework extends this notion to make each kernel corresponds to either a potential instance or a semantic class.
In this paper, we make the ﬁrst attempt to formulate a uniﬁed and effective framework to bridge the seemingly different image segmentation tasks (semantic, instance, and panoptic) through the notion of kernels. Our method is dubbed as K-Net (‘K’ stands for kernels). It begins with a set of convolutional kernels that are randomly initialized, and learns the kernels in accordance to the segmentation targets at hand, namely, semantic kernels for semantic categories and instance kernels for instance identities (Fig. 1-(b)). A simple combination of semantic kernels and instance kernels allows panoptic segmentation naturally (Fig. 1-(c)). In the forward pass, the kernels perform convolution on the image features to obtain the corresponding segmentation predictions.
The versatility and simplicity of K-Net are made possible through two designs. First, we formulate
K-Net so that it dynamically updates the kernels to make them conditional to their activations on the image. Such a content-aware mechanism is crucial to ensure that each kernel, especially an instance kernel, responds accurately to varying objects in an image. Through applying this adaptive kernel update strategy iteratively, K-Net signiﬁcantly improves the discriminative ability of the kernels and boosts the ﬁnal segmentation performance. It is noteworthy that this strategy universally applies to kernels for all the segmentation tasks.
Second, inspired by recent advances in object detection [4], we adopt the bipartite matching strat-egy [47] to assign learning targets for each kernel. This training approach is advantageous to conventional training strategies [37, 46] as it builds a one-to-one mapping between kernels and instances in an image. It thus resolves the problem of dealing with a varying number of instances in an image. In addition, it is purely mask-driven without involving boxes. Hence, K-Net is naturally
NMS-free and box-free, which is appealing to real-time applications.
To show the effectiveness of the proposed uniﬁed framework on different segmentation tasks, we conduct extensive experiments on COCO dataset [38] for panoptic and instance segmentation, and
ADE20K dataset [70] for semantic segmentation. Without bells and whistles, K-Net surpasses all previous state-of-the-art single-model results on panoptic (54.6% PQ) and semantic segmentation benchmarks (54.3% mIoU) and achieves competitive performance compared to the more expensive
Cascade Mask R-CNN [3]. We further analyze the learned kernels and ﬁnd that instance kernels incline to specialize on objects at speciﬁc locations of similar sizes. 2