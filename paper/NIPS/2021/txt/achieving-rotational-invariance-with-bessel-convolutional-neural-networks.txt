Abstract
For many applications in image analysis, learning models that are invariant to translations and rotations is paramount. This is the case, for example, in medical imaging where the objects of interest can appear at arbitrary positions, with arbitrary orientations. As of today, Convolutional Neural Networks (CNN) are one of the most powerful tools for image analysis. They achieve, thanks to convolutions, an invariance with respect to translations. In this work, we present a new type of convolutional layer that takes advantage of Bessel functions, well known in physics, to build Bessel-CNNs (B-CNNs) that are invariant to all the continuous set of possible rotation angles by design. 1

Introduction
Deep learning models, and more particularly Convolutional Neural Networks (CNNs), are known as being among the most powerful tools for image analysis. For this reason, they are still constantly upgraded in order to achieve better performance [1]. One of the main reasons why CNNs are so much used in computer vision lies in the fact that they achieve translation invariance thanks to convolutions.
Filters sweep the image locally and patterns can be recognized regardless of their absolute position in the image. However, some other important types of invariance are more difﬁcult to obtain. It is for example the case for the rotational invariance, which is relevant for many applications. One could for example consider medical imaging where tissues, cells, tumors or other objects of interest have a local, arbitrary, orientation in the images [2]. Another example is satellite imaging of ships, where both the global orientation of the satellite and the local orientation of a ship are arbitrary [3].
Multiple works proposed solutions in order to bring rotational invariance in CNNs. However, many of them (i) only make the model more robust to rotations without providing guarantees regarding the rotational invariance [4, 5, 6, 7, 8], (ii) only provide guarantees for a ﬁnite set of rotation angles [9, 10, 11, 12, 13, 14, 15] or (iii) only handle global rotational invariance, while a local one is sometimes more relevant [4, 5, 6]. In addition to that, and more similarly to the method proposed in this paper, other works present solutions to build CNNs that are rotational invariant for all rotation angles, while providing mathematical guarantees. One can for example cite [16, 17, 18]. Our work is in the continuity of those. We integrate a new kind of convolutional layer in CNNs to build
Bessel-Convolutional Neural Networks (B-CNNs). In B-CNNs, Bessel functions from physics are used to build a representation of the images that is more adapted to deal with rotations. We propose a new way to use this representation in order to compute feature maps in a rotational equivariant way (see Figure 1 for an example). This rotational equivariance can then lead to rotational invariance with a proper choice of architecture.
∗B. Frénay and A. Mayer are co-last authors. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
Figure 1: This ﬁgure illustrates the lack of rotational equivariance in standard CNNs (left), as opposed to the rotational equivariance of B-CNNs (right). For each triplet of images, the ﬁrst image is the input image, the second is the feature map obtained, and the last one is the feature map reoriented to make the comparison easier. It can be seen that the last images in the two left triplets for the standard
CNN are different. Hence, a different orientation of the input image produces a different feature map.
However, feature maps are identical except for a rotation for the B-CNN on the right.
Section 2 formally deﬁnes the problem of rotational invariance in CNNs and provides the necessary notations. Next, Section 3 presents the related works on bringing rotational invariance into CNNs. Our method, B-CNN, is then introduced in Section 4, along with some background on Bessel functions.
Experiments are described and discussed in Section 5. Finally, a more general discussion about some aspects of B-CNNs, as well as some future works, are presented in Section 6 before concluding the paper in Section 7. 2