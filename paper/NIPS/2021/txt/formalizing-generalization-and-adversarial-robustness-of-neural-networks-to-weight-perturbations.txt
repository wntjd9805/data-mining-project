Abstract
Studying the sensitivity of weight perturbation in neural networks and its impacts on model performance, including generalization and robustness, is an active re-search topic due to its implications on a wide range of machine learning tasks such as model compression, generalization gap assessment, and adversarial attacks. In this paper, we provide the ﬁrst integral study and analysis for feed-forward neural networks in terms of the robustness in pairwise class margin and its generalization behavior under weight perturbation. We further design a new theory-driven loss function for training generalizable and robust neural networks against weight per-turbations. Empirical experiments are conducted to validate our theoretical analysis.
Our results offer fundamental insights for characterizing the generalization and robustness of neural networks against weight perturbations. 1

Introduction
Neural network is currently the state-of-the-art machine learning model in a variety of tasks, including computer vision, natural language processing, and game-playing, to name a few. In particular, feed-forward neural networks consists of layers of trainable model weights and activation functions with the premise of learning informative data representations and the complex mapping between data samples and the associated labels. Albeit attaining superior performance, the need for studying the sensitivity of neural networks to weight perturbations is also intensifying owing to several practical motivations. For instance, in model compression, the robustness to weight quantization is crucial for designing energy-efﬁcient hardware accelerator [20] and for reducing memory storage while retaining model performance [9, 26]. The notion of weight perturbation sensitivity is also used as a property to reﬂect the generalization gap at local minima [10, 15]. In adversarial robustness and security, weight sensitivity can be leveraged as a vulnerability for fault injection and causing erroneous prediction
[11, 32]. However, while weight sensitivity plays an important role in many machine learning tasks and problem setups, theoretical characterization of its impacts on generalization and robustness of neural networks remains elusive.
This paper bridges this gap by developing a novel theoretical framework for understanding the generalization gap (through Rademacher complexity) and the robustness (through classiﬁcation margin) of neural networks against norm-bounded weight perturbations. Speciﬁcally, we consider 1Work partly done in TCFSH 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
the multi-class classiﬁcation problem setup and multi-layer feed-forward neural networks with non-negative monotonic activation functions. Our analysis offers fundamental insights into how weight perturbation affects the generalization gap and the pairwise class margin. To the best of our knowledge, this study is the ﬁrst work that provides a comprehensive theoretical characterization of the interplay between weight perturbation, robustness in classiﬁcation margin, and generalization gap.
Moreover, based on our analysis, we propose a theory-driven loss function for training generalizable and robust neural networks against norm-bounded weight perturbations. We validate its effectiveness via empirical experiments. Our main contributions are summarized as follows.
• We study the robustness (worst-case bound) of the pairwise class margin function against weight perturbations in neural networks, including the analysis of single-layer (Theorem 1), all-layer (Theorem 2), and selected-layer (Theorem 3) weight perturbations.
• We characterize the generalization behavior of robust surrogate loss for neural networks under weight perturbations (Section 3.4) through Rademacher complexity (Theorem 4).
• We propose a theory-driven loss design for training generalizable and robust neural networks (Section 3.5). The empirical results in Section 4 validate our theoretical analysis and demonstrate the effectiveness of improving generalization and robustness against weight perturbations. We also show that in our studied setting the associated generalization bounds are non-vacuous. 2