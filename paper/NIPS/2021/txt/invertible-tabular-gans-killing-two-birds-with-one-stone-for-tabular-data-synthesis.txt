Abstract
Tabular data synthesis has received wide attention in the literature. This is because available data is often limited, incomplete, or cannot be obtained easily, and data privacy is becoming increasingly important. In this work, we present a generalized
GAN framework for tabular synthesis, which combines the adversarial training of
GANs and the negative log-density regularization of invertible neural networks.
The proposed framework can be used for two distinctive objectives. First, we can further improve the synthesis quality, by decreasing the negative log-density of real records in the process of adversarial training. On the other hand, by increasing the negative log-density of real records, realistic fake records can be synthesized in a way that they are not too much close to real records and reduce the chance of potential information leakage. We conduct experiments with real-world datasets for classiﬁcation, regression, and privacy attacks. In general, the proposed method demonstrates the best synthesis quality (in terms of task-oriented evaluation metrics, e.g., F1) when decreasing the negative log-density during the adversarial training. If increasing the negative log-density, our experimental results show that the distance between real and fake records increases, enhancing robustness against privacy attacks. 1

Introduction
Generative models, such as generative adversarial networks (GANs) and variational autoencoders (VAEs), have proliferated over the past several years [24, 15, 31, 2, 18, 1, 16]. GANs are one of the most successful models among generative models, and tabular data synthesis is one of the many GAN applications [7, 4, 28, 27, 21, 38].
However, tabular data synthesis is challenging due to the following two problems: i) Tabular data frequently contains sensitive information. ii) It is required to share tabular data with people, some of whom are trustworthy while others are not. Therefore, generating fake records as similar as possible to real ones, which is commonly accepted to enhance the synthesis quality, is not always preferred in tabular data synthesis, e.g., sharing with unveriﬁed people [27, 5].
In [5], it was revealed that one can effectively extract privacy-related information from a pre-trained
GAN model if its log-densities are high enough. To this end, we propose a generalized framework, called invertible tabular GAN (IT-GAN), where we integrate the adversarial training of GANs and 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
(a) IT-GAN (b) IT-GAN(Q) (c) IT-GAN(L)
Figure 1: Synthesis examples with IT-GAN’s variations for Census, a binary classiﬁcation dataset.
We use t-SNE [37] to project each real/fake record onto a 2-dim space. (a) The synthesis only with the adversarial training shows a reasonable synthesis outcome. (b) The synthesis with the adversarial training and decreasing the negative log-density shows a better similarity between the distributions of the blue (real) and the red (fake) points than that of (a). (c) The synthesis with the adversarial training and increasing the negative log-density improves the privacy protection, i.e., it is not likely that the blue points are correctly inferred from the red points. Refer to Appendix B for additional ﬁgures. the negative log-density training of invertible neural networks. In our framework, we can improve1 or sacriﬁce the negative log-density during the adversarial training to trade off between synthesis quality and privacy protection (cf. Figure 1).
Our generator based on neural ordinary differential equations (NODEs [6]) is invertible and enables the proposed training concept. For NODEs, there exists an efﬁcient unbiased estimation technique of their Jacobian-determinants [6, 16]. By using the unbiased Hutchinson estimator, therefore, we can efﬁciently estimate the negative log-density. After that, this negative log-density can be used for the following two opposite objectives: i) decreasing the negative log-density to further increase the synthesis quality (cf. IT-GAN(Q) in Figure 1), or ii) increasing the negative log-density to synthesize realistic fake records that are not too much similar to real records (cf. IT-GAN(L) in Figure 1). In particular, the second objective to make the log-density worse after little sacriﬁcing the synthesis quality is closely related to the information leakage issue of tabular data.
However, this invertible generator has one limitation – the dimensionality of hidden layers cannot be changed. To overcome this limitation, we propose a joint architecture of an autoencoder (AE) and a
GAN. The motivation behind the proposed joint architecture is twofold: i) The role of the AE is to create a hidden representation space, on which the generator and the discriminator work. The hidden representation space has the same dimensionality as that of the latent input vector of the generator.
Therefore, the input and output sizes are the same in our generator, which meets the invariant dimensionality requirement of NODEs. ii) Separating the labor between the AE and the generator can improve the training process. In general, tabular data contains a large number of columns, which makes the synthesis more difﬁcult. In our joint architecture, the generator shares its task with the AE; it does not directly synthesize fake records but fake hidden representations. The decoder (recovery network) of the AE converts them into human-readable fake records. Therefore, our ﬁnal training consists of the GAN training, the AE training, and the negative log-density regularization.
We conduct experiments with 6 real-world tabular datasets and compare our method with 9 baseline methods. In many evaluation cases, our methods outperform all other baselines. Our contributions can be summarized as below: 1. We propose a general framework where we can trade-off between synthesis quality and information leakage. 2. To this end, we combine the adversarial training of GANs and the negative log-density training of invertible neural networks. 3. We conduct thorough experiments with 6 real-world tabular datasets and our methods outperform existing methods in almost all cases. 1It is well known that VAEs generate blurred samples but achieve a better log-density than GANs. Therefore, there exists a room to improve the log-density of fake samples by GANs. 2
2