Abstract
A central challenge in training classification models in the real-world federated system is learning with non-IID data. To cope with this, most of the existing works involve enforcing regularization in local optimization or improving the model aggregation scheme at the server. Other works also share public datasets or synthesized samples to supplement the training of under-represented classes or introduce a certain level of personalization. Though effective, they lack a deep understanding of how the data heterogeneity affects each layer of a deep classi-fication model. In this paper, we bridge this gap by performing an experimental analysis of the representations learned by different layers. Our observations are surprising: (1) there exists a greater bias in the classifier than other layers, and (2) the classification performance can be significantly improved by post-calibrating the classifier after federated training. Motivated by the above findings, we propose a novel and simple algorithm called Classifier Calibration with Virtual Representa-tions (CCVR), which adjusts the classifier using virtual representations sampled from an approximated gaussian mixture model. Experimental results demonstrate that CCVR achieves state-of-the-art performance on popular federated learning benchmarks including CIFAR-10, CIFAR-100, and CINIC-10. We hope that our simple yet effective method can shed some light on the future research of federated learning with non-IID data. 1

Introduction
The rapid advances in deep learning have benefited a lot from large datasets like [1]. However, in the real world, data may be distributed on numerous mobile devices and the Internet of Things (IoT), requiring decentralized training of deep networks. Driven by such realistic needs, federated learning [2, 3, 4] has become an emerging research topic where the model training is pushed to a large number of edge clients and the raw data never leave local devices.
A notorious trap in federated learning is training with non-IID data. Due to diverse user behaviors, large heterogeneity may be present in different clients’ local data, which has been found to result in unstable and slow convergence [5] and cause suboptimal or even detrimental model performance [6, 7].
There have been a plethora of works exploring promising solutions to federated learning on non-IID data. They can be roughly divided into four categories: 1) client drift mitigation [5, 8, 9, 10], which modifies the local objectives of the clients, so that the local model is consistent with the global model to a certain degree; 2) aggregation scheme [11, 12, 13, 14, 15], which improves the model fusion mechanism at the server; 3) data sharing [6, 16, 17, 18], which introduces public datasets or synthesized data to help construct a more balanced data distribution on the client or on the server;
∗corresponding author. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
4) personalized federated learning [19, 20, 21, 22], which aims to train personalized models for individual clients rather than a shared global model.
However, as suggested by [7], existing algorithms are still unable to achieve good performance on image datasets with deep learning models, and could be no better than vanilla FedAvg [2]. To identify the reasons behind this, we perform a thorough experimental investigation on each layer of a deep neural network. Specifically, we measure the Centered Kernel Alignment (CKA) [23] similarity between the representations from the same layer of different clients’ local models. The observation is thought-provoking: comparing different layers learned on different clients, the classifier has the lowest feature2 similarity across different local models.
Motivated by the above discovery, we dig deeper to study the variation of the weight of the classifier in federated optimization, and confirm that the classifier tends to be biased to certain classes. After identifying this devil, we conduct several empirical trials to debias the classifier via regularizing the classifier during training or calibrating classifier weights after training. We surprisingly find that post-calibration strategy is particularly useful — with only a small fraction of IID data, the classification accuracy is significantly improved. However, this approach cannot be directly deployed in practice since it infringes the privacy rule in federated learning.
Based on the above findings and considerations, we propose a novel and privacy-preserving approach called Classifier Calibration with Virtual Representations (CCVR) which rectifies the decision boundaries (the classifier) of the deep network after federated training. CCVR generates virtual representations based on an approximated Gaussian Mixture Model (GMM) in the feature space with the learned feature extractor. Experimental results show that CCVR achieves significant accuracy improvements over several popular federated learning algorithms, setting the new state-of-the-art on common federated learning benchmarks like CIFAR-10, CIFAR-100 and CINIC-10.
To summarize, our contributions are threefold: (1) We present the first systematic study on the hidden representations of different layers of neural networks (NN) trained with FedAvg on non-IID data and provide a new perspective of understanding federated learning with heterogeneous data. (2)
Our study reveals an intriguing fact that the primary reason for the performance degradation of NN trained on non-IID data is the classifier. (3) We propose CCVR (Classifier Calibration with Virtual
Representations) — a simple and universal classifier calibration algorithm for federated learning.
CCVR is built on top of the off-the-shelf feature extractor and requires no transmission of the representations of the original data, thus raising no additional privacy concern. Our empirical results show that CCVR brings considerable accuracy gains over vanilla federated learning approaches. 2