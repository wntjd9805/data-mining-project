Abstract
In the paper, we propose a class of efﬁcient mirror descent ascent methods to solve the nonsmooth nonconvex-strongly-concave minimax problems by using dynamic mirror functions, and introduce a convergence analysis framework to conduct rigorous theoretical analysis for our mirror descent ascent methods. For our stochastic algorithms, we ﬁrst prove that the mini-batch stochastic mirror descent ascent (SMDA) method obtains a gradient complexity of O(κ3(cid:15)−4) for
ﬁnding an (cid:15)-stationary point, where κ denotes the condition number. Further, we propose an accelerated stochastic mirror descent ascent (VR-SMDA) method based on the variance reduced technique. We prove that our VR-SMDA method achieves a lower gradient complexity of O(κ3(cid:15)−3). For our deterministic algorithm, we prove that our deterministic mirror descent ascent (MDA) achieves a lower gradient
κ(cid:15)−2) under mild conditions, which matches the best known complexity of O( complexity in solving smooth nonconvex-strongly-concave minimax optimization.
We conduct the experiments on fair classiﬁer and robust neural network training tasks to demonstrate the efﬁciency of our new algorithms.
√ 1

Introduction
Minimax optimization recently has attracted increased interest largely due to advance in many machine learning applications such as generative adversarial networks (GANs) [14, 41], robust neural networks training [32], fair learning [31], federated learning [10], and policy evaluation [43]. In the paper, we study the following nonsmooth nonconvex-strongly-concave minimax problem: min x∈X max y∈Y
F (x, y) = (cid:8)f (x, y) + g(x) − h(y)(cid:9), (1) where the function f (x, y) : X × Y → R is smooth and possibly nonconvex in x ∈ X and µ-strongly concave in y ∈ Y, and the functions g(x) and h(y) are convex and possibly nonsmooth. Here
X ⊆ Rd and Y ⊆ Rp are compact and convex constraint sets, or X = Rd and Y = Rp. In many machine learning problems, f (x, y) generally represents loss function and is a stochastic form, i.e., f (x, y) = Eξ[f (x, y; ξ)], where the random variable ξ follows an unknown data distribution. Here both g(x) and h(y) frequently denote the nonsmooth regularization terms such as g(x) = ν1(cid:107)x(cid:107)1 and h(y) = ν2(cid:107)y(cid:107)1 with ν1, ν2 > 0. In fact, the above problem (1) comes from many machine learning problems, such as fair classiﬁer, robust training, nonlinear temporal-difference learning in reinforcement learning [43] and robust federated learning [10].
When g(x) = 0 and h(y) = 0 in the problem (1), the classic gradient descent ascent (GDA) methods
[40, 27] can effectively solve this problem, which alternatively conducts a gradient descent update on the variable x and a gradient ascent update on the variable y at each iteration. At the same time, some stochastic GDA methods [40, 27, 30, 18, 46, 17] have been proposed to solve the stochastic minimax problem (1), where f (x, y) = Eξ[f (x, y; ξ)]. More recently, some works [2, 4, 8] focus on more general minimax problem (1), where both g(x) and h(y) are possibly nonsmooth. Meanwhile, 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
Table 1: Gradient complexity of the representative ﬁrst-order methods for obtaining an (cid:15)-stationary point of the nonsmooth nonconvex minimax problem (1). Note that these comparison methods don’t rely on some speciﬁc strong assumptions on the problem (1). Since the convergence properties of the deterministic proximal gradient descent ascent (PGDA) [8] build on the Kurdyka-Lojasiewicz (KL) geometry assumption, it be excluded. Here κ denotes condition number of objective function f (x, y) in variable y. Since HiBSA algorithm [29] does not provide explicit dependence on κ, we use p(κ).
Type
Algorithm Reference
Deterministic
Stochastic
HiBSA
MAPGDA
PAGDA
MDA
PASGDA
SMDA
VR-SMDA
[29]
[2]
[4]
Ours
[4]
Ours
Ours
Loop(s) Gradient Complexity
Single
Double
Single
Single
Single
Single
Double
O(p(κ)(cid:15)−2)
O(κ3/2(cid:15)−2)
O(κ2(cid:15)−2)
κ(cid:15)−2)
O(
O(κ3(cid:15)−4)
O(κ3(cid:15)−4)
O(κ3(cid:15)−3)
√ some (stochastic) proximal gradient descent ascent (PGDA) methods [2, 4, 8] have been presented to solve the problem (1). However, they still suffer from the large sample complexities for ﬁnding an stationary point of the minimax problem (1) without some speciﬁc strong assumptions such as KL geometry (Please see Table 1).
In this paper, thus, we propose a class of efﬁcient mirror descent ascent methods by using dynamic mirror function (i.e., Bregman function). Speciﬁcally, our methods perform an adaptive mirror descent update to variable x and an adaptive mirror ascent update to variable y alternatively at each iteration.
Our new algorithmic framework can generate many popular methods and their variants by adopting different mirror functions. For example, by adopting the mirror functions ψ(x) = 1 2 (cid:107)x(cid:107)2 and
φ(y) = 1 2 (cid:107)y(cid:107)2, our methods will include the classic (proximal) gradient descent ascent algorithms.
Our main contributions are summarized as follows: 1) We propose a class of novel mirror descent ascent methods to solve the minimax problem (1) by using dynamic mirror functions. Moreover, we provide a convergence analysis framework for our mirror descent ascent methods. 2) We present a faster deterministic adaptive mirror descent ascent (MDA) method, which reaches
κ(cid:15)−2) than the existing nonsmooth nonconvex minimax a lower gradient complexity of O( methods. Meanwhile, we propose a fast stochastic mirror descent ascent (SMDA) method, which requires O(κ3(cid:15)−4) stochastic gradient evaluations to obtain an (cid:15)-stationary point of the problem (1).
√ 3) We further propose an accelerated stochastic mirror descent ascent (VR-SMDA) method by using the variance reduced technique of SARAH/SNVRG/SPIDER [37, 51, 12, 44]. Moreover, we prove that our VR-SMDA reaches a lower gradient complexity of O(κ3(cid:15)−3).
In fact, when our methods solve the minimax problem (1) without nonsmooth regularization terms, i.e., g(x) = 0 and h(y) = 0, our theoretical results also can apply these minimax problems without nonsmooth regularization terms studied in [27, 28]. 2