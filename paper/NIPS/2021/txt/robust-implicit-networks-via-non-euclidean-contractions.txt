Abstract
Implicit neural networks, a.k.a., deep equilibrium networks, are a class of implicit-depth learning models where function evaluation is performed by solving a ﬁxed point equation. They generalize classic feedforward models and are equivalent to inﬁnite-depth weight-tied feedforward networks. While implicit models show improved accuracy and signiﬁcant reduction in memory consumption, they can suffer from ill-posedness and convergence instability.
This paper provides a new framework, which we call Non-Euclidean Monotone
Operator Network (NEMON), to design well-posed and robust implicit neural networks based upon contraction theory for the non-Euclidean norm (cid:96)
. Our framework includes (i) a novel condition for well-posedness based on one-sided
Lipschitz constants, (ii) an average iteration for computing ﬁxed-points, and (iii) explicit estimates on input-output Lipschitz constants. Additionally, we design a training problem with the well-posedness condition and the average iteration as constraints and, to achieve robust models, with the input-output Lipschitz constant as a regularizer. Our (cid:96) well-posedness condition leads to a larger polytopic training search space than existing conditions and our average iteration enjoys accelerated convergence. Finally, we evaluate our framework in image classiﬁcation through the MNIST and the CIFAR-10 datasets. Our numerical results demonstrate improved accuracy and robustness of the implicit models with smaller input-output Lipschitz bounds. Code is available at https://github. com/davydovalexander/Non-Euclidean_Mon_Op_Net.
∞
∞ 1

Introduction
Implicit neural networks are inﬁnite-depth learning models with layers deﬁned implicitly through a
ﬁxed-point equation. Examples of implicit neural networks include deep equilibrium models [Bai et al., 2019] and implicit deep learning models [El Ghaoui et al., 2021]. Implicit networks can be considered as generalizations of feedforward neural networks with input-injected weight tying, i.e., training parameters are transferable between layers. Indeed, in implicit networks, function evaluation is executed by solving a ﬁxed-point equation and backpropagation is implemented by computing gradients using implicit differentiation. Due to these unique features, implicit models enjoy more
ﬂexibility and improved memory efﬁciency compared to traditional neural networks. At the same time, implicit networks can suffer from instability in their training due to the nonlinear nature of their
ﬁxed-point equations and can show brittle input-output behaviors due to their model ﬂexibility.
∗These authors contributed equally. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
It is known that implicit neural networks require careful tuning and initialization to avoid ill-posed training procedures. Indeed, without additional assumptions, their ﬁxed-point equation may not have a unique solution and the numerical algorithms for ﬁnding their solutions might not converge. Several recent works in the literature have focused on studying well-posedness and convergence of the ﬁxed-point equations of implicit networks using frameworks such as monotone operator theory [Winston and Kolter, 2020], contraction theory [El Ghaoui et al., 2021], and a mixture of both [Revay et al., 2020]. Despite several insightful results, important questions about conditions for well-posedness of implicit networks and efﬁcient algorithms that converge to their solutions are still open.
One of the key features of implicit neural networks is their ﬂexibility, which might come at the cost of low input-output robustness. As ﬁrst noted in [Szegedy et al., 2014], the input-output behavior of deep neural networks can be vulnerable to perturbations; close enough input data can lead to completely different outputs. This lack of robustness can lead to unreliable performance of neural networks in safety-critical applications. Among several notions of robustness, the Lipschitz constant of a neural network is a coarse but rigorous measure which can be used to estimate input-output sensitivity of the network [Szegedy et al., 2014]. For this reason, there has been a growing interest in estimating the input-output Lipschitz constant of deep neural networks with respect to the (cid:96)2-norm [Fazlyab et al., 2019, Combettes and Pesquet, 2020]. However, it turns out that in some applications, the input-output Lipschitz constants with respect to non-Euclidean norms are more informative measures for studying robustness. One such application appears in the robustness analysis of neural networks with large-scale inputs under widely-distributed adversarial perturbations (examples of these adversarial perturbations can be found in [Szegedy et al., 2014]). For these examples, the input-output (cid:96)2-Lipschitz constant does not provide complete information about robustness of the network; a neural network with small input-output (cid:96)2-Lipschitz constant can be very sensitive to widespread entrywise--Lipschitz constant small perturbations of the input signal. On the other hand, the input-output (cid:96) provides a different metric which appears to be well-suited for the analysis of widespread distributed perturbations. Another application is the estimation of input signal conﬁdence intervals from output deviations, where the input-output (cid:96)
-Lipschitz constant of the network provides more scalable bounds than its (cid:96)2 counterpart.
∞
∞