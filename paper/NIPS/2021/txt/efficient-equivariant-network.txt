Abstract
Convolutional neural networks (CNNs) have dominated the ﬁeld of Computer Vi-sion and achieved great success due to their built-in translation equivariance. Group equivariant CNNs (G-CNNs) that incorporate more equivariance can signiﬁcantly improve the performance of conventional CNNs. However, G-CNNs are faced with two major challenges: spatial-agnostic problem and expensive computational cost. In this work, we propose a general framework of previous equivariant models, which includes G-CNNs and equivariant self-attention layers as special cases. Un-der this framework, we explicitly decompose the feature aggregation operation into a kernel generator and an encoder, and decouple the spatial and extra geometric dimensions in the computation. Therefore, our ﬁlters are essentially dynamic rather than being spatial-agnostic. We further show that our Equivariant model is parameter Efﬁcient and computational Efﬁcient by complexity analysis, and also data Efﬁcient by experiments, so we call our model E4-Net. Extensive experiments verify that our model can signiﬁcantly improve previous works with smaller model size. Especially, under the setting of training on 1/5 data of CIFAR10, our model improves G-CNNs by 5%+ accuracy, while using only 56% parameters and 68%
FLOPs. 1

Introduction
In the past few years, convolutional neural networks (CNNs) have been widely used and achieved superior results on multiple vision tasks, such as image classiﬁcation [31, 55, 51, 22], semantic segmentation [3], and object detection [44]. A compelling explanation of the good performance of
CNNs is that their built-in parameter sharing scheme brings in translation equivariance: shifting an image and then feeding it through a CNN layer is the same as feeding the original image and then shifting the resulted feature maps. In other words, the translation symmetry is preserved by each layer.
Motivated by this, Cohen and Welling [9] proposed Group Equivariant CNNs (G-CNNs), showing how convolutional networks can be generalized to exploit larger groups of symmetries. Following
G-CNNs, researchers have designed new neural networks that are equivariant to other transformations like rotations [9, 61, 24, 49] and scales [65, 53]. However, G-CNNs still have two main drawbacks: 1) In the implementation, G-CNNs would introduce extra dimensions to encode new transformations, such as rotations and scales, thus have a very high computational cost. 2) Although G-CNNs achieve group equivariance by sharing kernels, like vanilla CNNs, they lack the ability to adapt kernels to diverse feature patterns with respect to different spatial positions, namely, the spatial-agnostic problem [68, 39, 70, 71, 54, 67, 36].
∗Corresponding author. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
Some previous works focus on solving these two problems. Cheng et al. [4] proposed to decompose the convolutional ﬁlters over joint steerable bases to reduce model size. However, it is essentially
G-CNNs which still have the inherent spatial-agnostic problem. To incorporate dynamic ﬁlters, one solution is introducing attention mechanism into each convolution layer in G-CNNs without disturbing inherent equivariance [48, 45]. The cost is that they introduce extra parameters and increase the complexity of space and time. Another solution is to replace group convolution layers with stand-alone self-attention layers by designing a speciﬁc position embedding to ensure equivariance [47, 26].
However, the self-attention mechanism suffers from quadratic memory and time complexity, because it has to compute the attention score at each pair of inputs.
Actually, Cohen et al. [7], Kondor et al. [29] and Bekkers [1] revealed that an equivariant linear layer is essentially a convolution-like operation. Inspired by this, we further discover that a general feature-extraction layer, either linear or non-linear, being equivariant is equivalent to that the feature aggregation mechanism between each pair of inputs only depends on the relative positions of these two inputs. Based on this observation, we propose a generalized framework of previous equivariant models, which includes G-CNNs and equivariant attention networks as special cases. Under this generalized framework, we design a new equivariant layer to conquer the aforementioned difﬁculties.
Firstly, to avoid quadratic computational complexity, the feature aggregation operator is explicitly decomposed into a kernel generator and an encoder which takes one single feature as the input. Since our kernels are calculated based on input features, they are essentially dynamic rather than being spatial-agnostic. In addition, we decouple the feature aggregation mechanism across spatial and extra geometric dimensions to reduce the inter-channel redundancy in convolution ﬁlters [4] and further accelerate computation. Extensive experiments show that our method can process data very efﬁciently and perform signiﬁcantly better than previous works using lower computational cost. As our method is parameter Efﬁcient, computational Efﬁcient, data Efﬁcient and Equivariant, we name our new layer as E4-layer.
We summarize our main contributions as follows:
• We propose a generalized framework of previous equivariant models, which includes G-CNNs and attention-based equivariant models as special cases.
• Under the generalized framework, we explicitly decompose the feature aggregation operator into a kernel generator and an encoder, and further decouple the spatial and extra geometric dimensions to reduce computation.
• Extensive experiments verify that our method is also data efﬁcient and performs competi-tively with lower computational cost. 2