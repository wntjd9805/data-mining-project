Abstract
Graph Convolutional Networks (GCNs) are promising deep learning approaches in learning representations for graph-structured data. Despite the proliferation of such methods, it is well known that they are vulnerable to carefully crafted adversarial attacks on the graph structure.
In this paper, we ﬁrst conduct an adversarial vulnerability analysis based on matrix perturbation theory. We prove that the low-frequency components of the symmetric normalized Laplacian, which is usually used as the convolutional ﬁlter in GCNs, could be more robust against structural perturbations when their eigenvalues fall into a certain robust interval. Our results indicate that not all low-frequency components are robust to adversarial attacks and provide a deeper understanding of the relationship between graph spectrum and robustness of GCNs. Motivated by the theory, we present GCN-LFR3, a general robust co-training paradigm for GCN-based models, that encourages transferring the robustness of low-frequency components with an auxiliary neural network. To this end, GCN-LFR could enhance the robustness of various kinds of GCN-based models against poisoning structural attacks in a plug-and-play manner. Extensive experiments across ﬁve benchmark datasets and ﬁve GCN-based models also conﬁrm that GCN-LFR is resistant to the adversarial attacks without compromising on performance in the benign situation. 1

Introduction
Graph Convolutional Networks (GCNs) elaborate the expressive power of deep learning from grid-like data to graph-structured data and have achieved remarkable success in a wide variety of domains [7, 6, 13, 27, 22, 30, 1, 8, 42, 18, 31, 12, 41, 19]. Just like CNNs, modern GCNs could promisingly learn both the local and global structural patterns of graphs through designed convolutions. However, the vulnerability of GCNs against adversarial attacks has been revealed recently [70, 11, 9]. The lack of robustness arouses concerns on applying GCNs in a variety of
ﬁelds pertaining to security and privacy. Adversarial attacks on graphs aim to degrade the ability of representation learning of GCNs, and fool them to make wrong decisions by perturbing either node features or graph structures. Given the complexity of the underlying structural information and the ease of operation in practice [50], the majority of literature focuses on the adversarial attacks on structures by inserting/removing/rewiring adversarial edges, i.e., structural attacks. In other words,
∗Heng Chang is supported by 2020 Tencent Rhino-Bird Elite Training Program. Work done during Heng’s internship at Tencent AI Lab.
†Corresponding authors. 3Code available at https://github.com/SwiftieH/LFR. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
structural attacks on graphs during the training stage of GCNs with node features unchanged becomes a commonly considered setting by attackers [24]. Therefore, it is of emerging importance to enhance the robustness of GCNs against structural attacks, which is also the aim of this work.
For a better understanding of the structural attacks, it naturally leads to the question: Do the adversarial edges post equal inﬂuences on the graph spectrum? Here, graph spectrum plays a signiﬁcant role in Graph Signal Processing (GSP) [45, 39] and graph learning. Empirical observations from recent papers suggest the answer could be “no”. We can observe that the perturbations resulting from structural attacks express an implicit trend on the graph spectrum [14]. As the toy example shown in Figure 1, low-frequency components (far left) tend to be more robust in comparison with high-frequency ones (far right). Similarly, [29] observes that the low-pass ﬁlters seem to be more stable than high-pass ﬁlters when we randomly add/remove edges. These observations point to a promising direction for developing principled defense approaches based on the theoretical analysis of graph spectrum.
Contributions. To mitigate the vulnerability of GCNs against adversarial attacks, in this pa-per, we aim to bridge the gap between the spec-tral analysis and the robustness of GCNs under structural perturbations. Speciﬁcally, for the symmetric normalized Laplacian, which is com-monly chosen as the graph ﬁlter in GCNs, we prove that the low-frequency components could be more robust against both one-edge and multi-edge perturbations when their eigenvalues fall into a robust interval. Interestingly, this result reveals that not all low-frequency components are robust to adversarial attacks.
Figure 1: Observation. After adversarial attacks on the structure of graphs, the perturbations on the low-frequency components (far left) are smaller than that in the high-frequency ones (far right).
Considering the beneﬁt from robust interval in low frequencies, we further propose GCN-LFR (Low-Frequency based Regularization), a general robust co-training paradigm that can transfer the robustness from the eligible low-frequency components. GCN-LFR is a general defender that can work with any GCN-based model against various training-time attacks. In particular, GCN-LFR regularizes the training process of any given GCN with the robust information from an auxiliary regularization net MLFR , which injects a set of learnable parameters to imitate the robust interval for low-frequency components. Moreover, instead of jointly training two branches, we design an alternative training scheme to accelerate the training process. We observe that the alternative training scheme also beneﬁts the ﬁnal performance in practice.
In experiments, to demonstrate the ﬂexibility of GCN-LFR, we integrate GCN-LFR with ﬁve popular
GCN-based models and compare GCN-LFR with four state-of-the-art defenders across ﬁve benchmark datasets under a variety of settings, including one-edge targeted, multi-edge targeted, and non-targeted attacks. Extensive results demonstrate that GCN-LFR consistently outperforms the defending baselines under all settings. Remarkably, we also show that GCN-LFR successfully enhances the robustness of GCNs without deduction of performance on benign graphs. It further reveals the broad applicability and relevance of GCN-LFR in the area of deep graph learning. 2