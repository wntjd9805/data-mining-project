Abstract
Effectively modeling phenomena present in highly nonlinear dynamical systems whilst also accurately quantifying uncertainty is a challenging task, which often re-quires problem-speciﬁc techniques. We present a novel, domain-agnostic approach to tackling this problem, using compositions of physics-informed random features, derived from ordinary differential equations. The architecture of our model lever-ages recent advances in approximate inference for deep Gaussian processes, such as layer-wise weight-space approximations which allow us to incorporate random
Fourier features, and stochastic variational inference for approximate Bayesian inference. We provide evidence that our model is capable of capturing highly nonlinear behaviour in real-world multivariate time series data. In addition, we
ﬁnd that our approach achieves comparable performance to a number of other probabilistic models on benchmark regression tasks. 1

Introduction
Dynamical systems are ubiquitous across the natural sciences, with many physical and biological processes being driven on a fundamental level by differential equations. Inferring ordinary differential equation (ODE) parameters using observational data from such systems is an active area of research
[Meeds et al., 2019, Ghosh et al., 2021], however, in particularly complex systems it is often infeasible to characterise all of the individual processes present and the interactions between them. Rather than attempt to fully describe a complex system, latent force models (LFMs) [Alvarez et al., 2009] specify a simpliﬁed mechanistic model of the system which captures salient features of the dynamics present.
This leads to a model which is able to readily extrapolate beyond the training input space, thereby retaining one of the key advantages of mechanistic modeling over purely data-driven techniques.
Modeling nonlinear dynamical systems presents an additional challenge, and whilst nonlinear differential equations have been incorporated into LFMs [Ward et al., 2020], shallow models such as
LFMs are generally less capable than deep models of modeling the non-stationarities often present in nonlinear systems. Deep model architectures have greater representational power than shallow models as a result of their hierarchical structure, which typically consists of compositions of functions
[LeCun et al., 2015]. Deep probabilistic models such as deep Gaussian processes (DGPs) [Damianou and Lawrence, 2013] are able to leverage this representational power, with the additional advantage of being able to accurately quantify uncertainty.
In this paper, we aim to model nonlinear dynamics by constructing a DGP from compositions of physics-informed random Fourier features, with the motivation behind this approach being that many real-world systems are compositional hierarchies [LeCun et al., 2015]. Whilst a number of recent works have incorporated random Fourier features into deep models [Cutajar et al., 2017, Mehrkanoon and Suykens, 2018], the only work we are aware of which does so in the context of a physics-informed
DGP is that of Lorenzi and Filippone [2018]. The authors impose physical structure on a DGP with 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
(a) Deep Gaussian process (DGP) (b) Deep latent force model (DLFM)
Figure 1: A conceptual explanation of how our proposed DLFM differs from a DGP. At each
τ )u(τ )dτ , where G is the Green’s layer, we perform the operation x, G
}
) represents an exponentiated quadratic GP prior. For function corresponding to an ODE, and u(
· example, the second operation in the model shown above would take the form,
= f1 0 G(2)(f1 0 G((cid:96))(x f1, G
}
τ )u(τ )dτ .
=
− (2)
L
L ((cid:96))
{
{ (cid:82) x
− (cid:82) random features by constraining the function values within the model as a means of performing
ODE parameter inference. Rather than following the approach of Lorenzi and Filippone [2018] and placing constraints on function values whilst using an exponentiated quadratic (EQ) kernel, we instead integrate a physics-informed prior into the structure of the DGP by utilising a kernel based on an ODE.
Our main contribution in this paper is the introduction of a novel approach to incorporating physical structure into a deep probabilistic model, whilst providing a sound quantiﬁcation of uncertainty. We achieve this through derivation of physics-informed random Fourier features via the convolution of an EQ GP prior with the Green’s function associated with a ﬁrst order ODE. These features are then incorporated into each layer of a DGP, as shown in Figure 1. To ensure the scalability of our model to large datasets, stochastic variational inference is employed as a method for approximate Bayesian inference. We provide experimental evidence that our modeling framework is capable of capturing highly nonlinear dynamics effectively in both toy examples and real world data, whilst also being applicable to more general regression problems. 2