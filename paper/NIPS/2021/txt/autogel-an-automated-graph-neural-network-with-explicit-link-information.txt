Abstract
Recently, Graph Neural Networks (GNNs) have gained popularity in a variety of real-world scenarios. Despite the great success, the architecture design of
GNNs heavily relies on manual labor. Thus, automated graph neural network (AutoGNN) has attracted interest and attention from the research community, which makes signiﬁcant performance improvements in recent years. However, existing AutoGNN works mainly adopt an implicit way to model and leverage the link information in the graphs, which is not well regularized to the link prediction task on graphs, and limits the performance of AutoGNN for other graph tasks.
In this paper, we present a novel AutoGNN work that explicitly models the link information, abbreviated to AutoGEL. In such a way, AutoGEL can handle the link prediction task and improve the performance of AutoGNNs on the node classiﬁcation and graph classiﬁcation task. Speciﬁcally, AutoGEL proposes a novel search space containing various design dimensions at both intra-layer and inter-layer designs and adopts a more robust differentiable search algorithm to further improve efﬁciency and effectiveness. Experimental results on benchmark data sets demonstrate the superiority of AutoGEL on several tasks. 1

Introduction
}
V
· · · v1,
{
, vn} e(vi, vj) : vi, vj 2
{
As one of ubiquitous data structures, graph G(E, V ) contains the node-set V = and edge-set E =
, which can represent a lot of real-world data sets, such as social networks [Bu et al., 2018], physical systems [Sanchez-Gonzalez et al., 2018], protein-protein interaction networks [Yue et al., 2020]. In recent years, Graph Neural Networks (GNNs) have been introduced for various graph tasks and achieve unprecedented success, such as node classiﬁcation
[Kipf and Welling, 2016a, Hamilton et al., 2017], link prediction [Vashishth et al., 2019, Li et al., 2020], and graph classiﬁcation [Niepert et al., 2016, Zhang et al., 2018]. Generally, GNNs encode d ) that preserves similarity in the
G(V, E) into the d-dimensional vector space (e.g., V original graph. Despite the great success, those GNNs are restricted to speciﬁc instances within GNN design space [You et al., 2020]. Different graph tasks usually require different GNN architectures
[Gilmer et al., 2017]. For example, compared with the node classiﬁcation task, GNNs for graph classiﬁcation introduces an extra readout phase to obtain graph embeddings. However, architecture design for these GNNs remains a challenging problem due to the diversity of graph data sets. Given a graph task, a GNN architecture performs well on one data set does not necessarily imply that it is also suitable for other data sets [You et al., 2020].
R| 2
|⇥
V
Some pioneer works have been proposed to alleviate the above issue in GNN models. They introduce
Neural Architecture Search (NAS) [Elsken et al., 2019] approaches to automatically design suitable
⇤Corresponding author 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
GNN architecture for the given data set (i.e., AutoGNN) [Zhou et al., 2019, Gao et al., 2020,
Jiang and Balaprakash, 2020, Zhao et al., 2021]. Architectures identiﬁed by these AutoGNNs rival or surpass the best handcrafted GNN models, demonstrating the potential of AutoGNN towards better GNN architecture design. Unfortunately, the existing AutoGNNs are mainly designed for the node classiﬁcation and graph classiﬁcation task. Their designs do not include edge embeddings, i.e., modeling and organizing link information in an implicit way. First, it is difﬁcult for existing
AutoGNNs to handle another important graph task on the edge-level, link prediction (LP) task.
Second, lack of edge embedding makes them inexpressive to leverage the complex link information, such as direction information of edges and different edge types in multi-relational graphs. Especially, various edge types could impose different inﬂuence for encoding nodes into embeddings, which can further improve the model performance on the node-level and graph-level tasks. Therefore, a new
AutoGNN is desired to model link information explicitly on various data sets.
To bridge the aforementioned research gap, we propose AutoGEL, a novel AutoGNN framework with
Explicit Link information, which can handle the LP task and improve performance of AutoGNNs on other graph tasks. Speciﬁcally, AutoGEL explicitly learns the edge embedding in the message passing framework to model the complex link information, and introduces the several novel design dimensions into the GNN search space, enabling a more powerful GNN to be searched for any given graph data set. Moreover, AutoGEL adopts a robust differentiable search algorithm to guarantee the effectiveness of searched architectures and control the computational footprint. We summarize the contributions of this work as follows:
•
•
•
The design of existing AutoGNNs follows an implicit way to leverage and organize the link information, which cannot handle the LP task and limits the performance of AutoGNNs on other graph tasks. In this paper, we present a novel method called AutoGEL to solve these issues through explicitly modeling the link information in the graphs.
AutoGEL introduces several novel design dimensions into the GNN search space at both the intra-layer and inter-layer designs, so as to improve the task performance. Moreover, motivated by one robust NAS algorithm SNAS, AutoGEL upgrades the search algorithm adopted in existing
AutoGNNs to further guarantee the effectiveness of ﬁnal derived GNN.
The experimental results demonstrate that AutoGEL can achieve better performance than manually designed models in the LP task. Furthermore, AutoGEL shows excellent competitiveness with other AutoGNN works on the node and graph classiﬁcation tasks. 2