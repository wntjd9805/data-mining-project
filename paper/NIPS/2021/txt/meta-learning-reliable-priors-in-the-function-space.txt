Abstract
When data are scarce, meta-learning can improve a learner’s accuracy by harness-ing previous experience from related learning tasks. However, existing methods have unreliable uncertainty estimates which are often overconﬁdent. Addressing these shortcomings, we introduce a novel meta-learning framework, called
F-PACOH, that treats meta-learned priors as stochastic processes and performs meta-level regularization directly in the function space. This allows us to directly steer the probabilistic predictions of the meta-learner towards high epistemic uncer-tainty in regions of insufﬁcient meta-training data and, thus, obtain well-calibrated uncertainty estimates. Finally, we showcase how our approach can be integrated with sequential decision making, where reliable uncertainty quantiﬁcation is imper-ative. In our benchmark study on meta-learning for Bayesian Optimization (BO),
F-PACOH signiﬁcantly outperforms all other meta-learners and standard baselines. 1

Introduction
Learning new concepts and skills from a small number of examples as well as adapting them quickly in face of changing circumstances is a key aspect of human intelligence. Unfortunately, our machine learning algorithms lack such adaptive capabilities. Meta-Learning [1, 2] has emerged as a promising avenue towards enabling systems to learn much more efﬁciently by harnessing experience from previ-ous related learning tasks [3–8]. By meta-learning probabilistic prior beliefs, we not only make more accurate predictions when given a small amount of training data, but also improve the self-assessment machine learning algorithm in the form of epistemic uncertainty estimates [9–12]. Such uncertainty estimates are critical for sequential decision problems such as Bayesian optimization (BO) [13, 14] and reinforcement learning [15, 16] which require efﬁcient information gathering and exploration.
However, in most practical settings, there are only few tasks available for meta-training. Hence we face the risk of overﬁtting to these few tasks [17] and, consequently impairing the performance on unseen tasks. To prevent this, recent work has proposed various forms of regularization on the meta-level [18, 12, 8]. While these methods are effective in preventing meta-overﬁtting for the mean predictions, they fail to do so for the associated uncertainty estimates, manifested in gross overconﬁdence. Such overconﬁdence is highly detrimental for downstream sequential decision tasks that rely on calibrated uncertainty estimates [19, 20] to perform sufﬁcient exploration. For instance, if the global optimum of the true target function in BO lies outside the model’s 95 % conﬁdence bounds the acquisition algorithm may never query points close to the optimum and get stuck in sub-optimal solutions. We hypothesize that previous methods yield overconﬁdent predictions since they do not meta-regularize the predictive distribution directly. Instead, they perform meta-regularization in some latent space, for example the method parameters, which is non-trivially associated with the resulting predictive distribution and thus may not have the indented regularization effects. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
To overcome the issue of overconﬁdent predictions in meta-learning, we develop a novel approach that regularizes meta-learned priors directly in the function space. We build on the PAC-Bayesian PACOH framework [12] which uses a hyper-prior over the latent prior parameters for meta-regularization.
However, we propose to deﬁne the hyper-prior as stochastic process, characterized by its marginal distributions in the function space, and make the associated meta-learning problem tractable by using an approximation of the KL-divergence between stochastic processes [21]. The functional
KL allows us to directly steer the meta-learned prior towards high epistemic uncertainty in regions of insufﬁcient meta-training data and, thus, obtain reliable uncertainty estimates. When instantiating our functional meta-learning framework, referred to as F-PACOH, with Gaussian Processes (GPs), we obtain a simple algorithm that can be seamlessly integrated into sequential decision algorithms.
In our experiments, we showcase how F-PACOH can facilitate transfer and life-long learning in the context of BO, and unlike previous meta-learning methods, consistently yields well-calibrated uncertainty estimates. In our benchmark study on meta-learning for BO and hyper-parameter tuning,
F-PACOH signiﬁcantly outperforms all other meta-learners and standard baselines. Finally, we consider lifelong BO, where the meta-BO algorithm faces a sequence of BO tasks and needs build-up prior knowledge iteratively. In this challenging setting, F-PACOH is the only method that is able to signiﬁcantly improve its optimization performance as it gathers more experience. This paves the way for exciting new applications for meta-learning and transfer such as the recurring re-optimization and calibration of complex machines and systems under changing external conditions. 2