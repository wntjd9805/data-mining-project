Abstract
In this work, we consider the problem of sequence-to-sequence alignment for sig-nals containing outliers. Assuming the absence of outliers, the standard Dynamic
Time Warping (DTW) algorithm efﬁciently computes the optimal alignment be-tween two (generally) variable-length sequences. While DTW is robust to temporal shifts and dilations of the signal, it fails to align sequences in a meaningful way in the presence of outliers that can be arbitrarily interspersed in the sequences. To address this problem, we introduce Drop-DTW, a novel algorithm that aligns the common signal between the sequences while automatically dropping the outlier ele-ments from the matching. The entire procedure is implemented as a single dynamic program that is efﬁcient and fully differentiable. In our experiments, we show that
Drop-DTW is a robust similarity measure for sequence retrieval and demonstrate its effectiveness as a training loss on diverse applications. With Drop-DTW, we address temporal step localization on instructional videos, representation learn-ing from noisy videos, and cross-modal representation learning for audio-visual retrieval and localization. In all applications, we take a weakly- or unsupervised approach and demonstrate state-of-the-art results under these settings. 1

Introduction
The problem of sequence-to-sequence alignment is central to many computational applications. Align-ing two sequences (e.g., temporal signals) entails computing the optimal pairwise correspondence between the sequence elements while preserving their match orderings. For example, video [1] or audio [2] synchronization are important applications of sequence alignment in the same modality, while the alignment of video to audio [3] represents a cross-modal task. Dynamic Time Warping (DTW) [2] is a standard algorithm for recovering the optimal alignment between two variable length sequences. It efﬁciently solves the alignment problem by ﬁnding all correspondences between the two sequences, while being robust to temporal variations in the execution rate and shifts.
A major issue with DTW is that it enforces correspondences between all elements of both sequences and thus cannot properly handle sequences containing outliers. That is, given sequences with inter-spersed outliers, DTW enforces matches between the outliers and clean signal, which is prohibitive in many applications. A real-world example of sequences containing outliers is instructional videos.
These are long, untrimmed videos depicting a person performing a given activity (e.g., making a latte) following a pre-deﬁned set of ordered steps (e.g., a recipe). Typically, only a few frames in the video correspond to the instruction steps, while the rest of the video frames are unrelated to the main activity (e.g., the person talking); see Figure 1 for an illustration. In this case, matching the outlier frames to instruction steps will not yield a meaningful alignment. Moreover, the match score 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
Figure 1: Aligning instructional videos. Left: Both video sequences (top and bottom) depict the three main steps of “making latte”; however, there are unrelated video segments, i.e., outliers, inbetween the steps. DTW aligns all the frames with each other and creates false correspondences where outliers are matched to signal (red links). Right: In contrast, Drop-DTW ﬁnds the optimal alignment, while simultaneously dropping unrelated frames (crossed out), leaving only correct correspondences (green links). between such sequences, computed by DTW, will be negatively impacted by “false” correspondences and therefore cannot be used reliably for downstream tasks, e.g., retrieval or representation learning.
In this paper, we introduce Drop-DTW to address the problem of matching sequences that contain interspersed outliers as illustrated in Figure 1 (right) and compared to standard DTW (on the left).
While various improvements to DTW have been previously proposed (e.g., [1, 4–8]), Drop-DTW is the ﬁrst to augment DTW with the ability to ﬂexibly skip through irrelevant parts of the signal during alignment, while still allowing one-to-many matching. Rather than relying on a two-step greedy approach, where elements are ﬁrst dropped before aligning the remaining signal, Drop-DTW achieves this in a uniﬁed framework that solves for the optimal temporal alignment while jointly detecting outliers. Drop-DTW casts sequence alignment as an optimization problem with a novel component specifying the cost of dropping an element within the optimization process. It is efﬁciently realized using a dynamic program that naturally admits a differentiable approximation and can be efﬁciently used at training and inference time.
Contributions.
• We propose an extension of DTW that is able to identify and align the common signal between sequences, while simultaneously excluding interspersed outliers from the alignment.
• The proposed Drop-DTW formulation naturally admits a differentiable approximation and we therefore demonstrate its usage as a training loss function.
• We demonstrate the utility of Drop-DTW, for both training and inference for multi-step localization in instructional videos, using only ordered steps as weak supervision. We achieve state-of-the-art results on the CrossTask [9] dataset and are the ﬁrst to tackle the COIN [10] and YouCook2 [11] datasets, given only ordered steps (i.e., no framewise labels are used).
• We employ Drop-DTW as a loss function for weakly-supervised video representation learning on the PennAction dataset [12], modiﬁed to have interspersed outliers, and unsupervised audio-visual representation learning on the AVE dataset [13]. Compared to the baselines, Drop-DTW yields superior representations, as measured by its performance on various downstream tasks.
Our code is available at: https://github.com/SamsungLabs/Drop-DTW. 2