Abstract
To beneﬁt the learning of a new task, meta-learning has been proposed to transfer a well-generalized meta-model learned from various meta-training tasks. Existing meta-learning algorithms randomly sample meta-training tasks with a uniform probability, under the assumption that tasks are of equal importance. However, it is likely that tasks are detrimental with noise or imbalanced given a limited number of meta-training tasks. To prevent the meta-model from being corrupted by such detrimental tasks or dominated by tasks in the majority, in this paper, we propose an adaptive task scheduler (ATS) for the meta-training process. In
ATS, for the ﬁrst time, we design a neural scheduler to decide which meta-training tasks to use next by predicting the probability being sampled for each candidate task, and train the scheduler to optimize the generalization capacity of the meta-model to unseen tasks. We identify two meta-model-related factors as the input of the neural scheduler, which characterize the difﬁculty of a candidate task to the meta-model. Theoretically, we show that a scheduler taking the two factors into account improves the meta-training loss and also the optimization landscape.
Under the setting of meta-learning with noise and limited budgets, ATS improves the performance on both miniImageNet and a real-world drug discovery benchmark by up to 13% and 18%, respectively, compared to state-of-the-art task schedulers. 1

Introduction
Meta-learning has emerged in recent years as a popular paradigm to beneﬁt the learning of a new task in a sample-efﬁcient way, by meta-training a meta-model (e.g., initializations for model parameters) from a set of historical tasks (called meta-training tasks). To learn the meta-model during meta-training, the majority of existing meta-learning methods randomly sample meta-training tasks with a uniform probability. The assumption behind such uniform sampling is that all tasks are equally important, which is often not the case. First, some tasks could be noisy. For example, in our experiments on drug discovery, all compounds (i.e., examples) in some target proteins (i.e., tasks) are even labeled with the same bio-activity value due to improper measurement. Second, the number of meta-training tasks is likely limited, so that the distribution over different clusters of tasks is uneven.
There are 2, 523 target proteins in the binding family among all 4, 276 proteins for meta-training, but only 55 of them belong to the ADME family. To ﬁll the gap, we are motivated to equip the meta-learning framework with a task scheduler that determines which tasks should be used for meta-training in the current iteration.
Recently, a few studies have started to consider introducing a task scheduler into meta-learning, by adjusting the class selection strategy for construction of each few-shot classiﬁcation task [17, 19],
∗H. Yao and Y. Wang contribute equally; correspondence to: Y. Wei 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
directly using a self-paced regularizer [3], or ranking the candidate tasks based on the amount of information associated with them [11]. While the early success of these methods is a testament to the beneﬁts of introducing a task scheduler, developing a task scheduler that adapts to the progress of the meta-model remains an open challenge. Such a task scheduler could both take into account the complicated learning dynamics of a meta-learning algorithm better than existing manually deﬁned schedulers, and explicitly optimize the generalization capacity to avoid meta-overﬁtting [23, 30].
To address these limitations, in this paper, we propose an Adaptive Task Scheduler (ATS) for meta-learning. Instead of ﬁxing the scheduler throughout the meta-training process, we design a neural scheduler to predict the probability of each training task being sampled. Concretely, we adopt a bi-level optimization strategy to jointly optimize both the meta-model and the neural scheduler.
The meta-model is optimized with the sampled meta-training tasks by the neural scheduler, while the neural scheduler is learned to improve the generalization ability of the meta-model on a set of validation tasks. The neural scheduler considers two meta-model-related factors as its input: 1) the loss of the meta-model with respect to a task, and 2) the similarity between gradients of the meta-model with respect to the support and query sets of a task, which characterize task difﬁculty from the perspective of the outcome and the process of learning, respectively. On this account, the neural scheduler avoids the pathology of a poorly generalized meta-model that is corrupted by a limited budget of tasks or detrimental tasks (e.g., noisy tasks).
The main contribution of this paper is an adaptive task scheduler that guides the selection of meta-training tasks for a meta-learning framework. We identify two meta-model-related factors as building blocks of the task scheduler, and theoretically reveal that the scheduler considering these two factors improves the meta-training loss as well as the optimization landscape. Under different settings (i.e., meta-learning with noisy or a limited number of tasks), we empirically demonstrate the superiority of our proposed scheduler over state-of-the-art schedulers on both an image classiﬁcation benchmark (up to 13% improvement) and a real-world drug discovery dataset (up to 18% improvement). The proposed scheduler demonstrates great adaptability, tending to 1) sample non-noisy tasks with smaller losses if there are noisy tasks but 2) sample difﬁcult tasks with large losses when the budget is limited. 2