Abstract
The integration and transfer of information from multiple sources to multiple tar-gets is a core motive of neural systems. The emerging ﬁeld of partial information decomposition (PID) provides a novel information-theoretic lens into these mecha-nisms by identifying synergistic, redundant, and unique contributions to the mutual information between one and several variables. While many works have studied aspects of PID for Gaussian and discrete distributions, the case of general contin-uous distributions is still uncharted territory. In this work we present a method for estimating the unique information in continuous distributions, for the case of one versus two variables. Our method solves the associated optimization problem over the space of distributions with ﬁxed bivariate marginals by combining copula decompositions and techniques developed to optimize variational autoencoders.
We obtain excellent agreement with known analytic results for Gaussians, and illus-trate the power of our new approach in several brain-inspired neural models. Our method is capable of recovering the effective connectivity of a chaotic network of rate neurons, and uncovers a complex trade-off between redundancy, synergy and unique information in recurrent networks trained to solve a generalized XOR task. 1

Introduction and background
In neural systems, often multiple neurons are driven by one external event or stimulus; conversely multiple neural inputs can converge onto a single neuron. A natural question in both cases is how multiple variables hold information about the singleton variable. In their seminal work [1], Williams and Beer proposed an axiomatic extension of classic information theory to decompose the mutual information between multiple source variables and a single target variable in a meaningful way. For the case of two sources X1, X2, their partial information decomposition (PID) amounts to expressing the mutual information of X1, X2 with a target Y as a sum of four non-negative terms,
I(Y : (X1, X2)) = U (Y : X1\X2) + U (Y : X2\X1) + R(Y : (X1, X2)) + S(Y : (X1, X2)) , (1.1) corresponding to unique (U1, U2), redundant (R) and synergistic (S) contributions, respectively.
These terms should also obey the consistency equations
I(Y : X1) = R(Y : (X1, X2)) + U (Y : X1\X2) ,
I(Y : X2) = R(Y : (X1, X2)) + U (Y : X2\X1) . (1.2) (1.3)
The PID has proved useful in understanding information processing by distributed systems in a diverse array of ﬁelds including machine learning [2, 3], earth science [4] and cellular automata [5], 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
and particularly in neuroscience [6–10], where notions of synergy and redundancy, traditionally considered mutually exclusive and distinguished by the sign of
∆ = I(Y : (X1, X2)) − I(Y : X1) − I(Y : X2) ,
= S(Y : (X1, X2)) − R(Y : (X1, X2)) , (1.4) have long played a central role in the quest to understand how neural circuits integrate information from multiple sources [11–14]. The novelty of the PID framework here is in separating the measures of synergy and redundancy in (1.4).
The above abstract formulation of PID provides three equations for four unknowns, and only becomes operational once one of U1, U2, R, or S is deﬁned. This has been done in [15] via a deﬁnition of the unique information:
Deﬁnition 1 (BROJA [15]). Given three random variables (Y, X1, X2) with joint probability den-sity p(y, x1, x2), the unique information U1 of X1 with respect to Y is
U (Y : X1\X2) = min q∈Q
Iq(Y : X1|X2) , (cid:90)
= min q∈Q dydx1dx2 q(y, x1, x2) log (cid:18) q(y, x1|x2) q(y|x2)q(x1|x2) (cid:19)
, where
Q = {q(y, x1, x2) | q(y, xi) = p(y, xi), i = 1, 2} . (1.5) (1.6) (1.7)
In words, we minimize the conditional mutual information I(Y : X1|X2) over the space of density functions that preserve the marginal densities p(y, x1) and p(y, x2). The above deﬁnition implies, along with (1.2)-(1.3), that the unique and redundant information only depend on the marginals p(y, x1), p(y, x2), and that the synergy can only be estimated from the full p(y, x1, x2).
The original deﬁnition in [15] was limited to discrete random variables. Here, we show that the extension to continuous variables is well-deﬁned and can be practically estimated.
Motivation from decision theory [15]. Consider for simplicity discrete variables. A decision maker
DM1 can choose an action a from a ﬁnite set A, and receives a reward u(a, y) based on the selected action and the state y, which occurs with probability p(y). Notably, DM1 has no knowledge of y, but observes instead a random signal x1 sampled from p(x1|y). Choosing the action maximizing the expected reward for each x1, his maximal expected reward is (cid:88)
R1 = p(x1) max a|x1 (cid:88) p(y|x1)u(a, y) . (1.8) x1 y
DM1 is said to have no unique information about y w.r.t. another decision maker DM2 that observes x2 ∼ p(x2|y) – if R2 ≥ R1 for any set A, any distribution p(y), and any reward function u(a, y).
A celebrated theorem by Blackwell [16, 17] states that such a generic advantage by DM2 occurs iff there exist a stochastic matrix q(x1|x2) which satisﬁes p(x1|y) = (cid:88) x2 p(x2|y)q(x1|x2) . (1.9)
But this occurs precisely when the unique information (1.5) vanishes, since then there exists a joint distribution q(y, x1, x2) in Q for which y ⊥ x1|x2, which implies q(x1|x2, y) = q(x1|x2), and thus (1.9) holds. Similar results exist for continuous variables [18, 19]. Thus the unique information from Deﬁnition 1 quantiﬁes a departure from Blackwell’s relation (1.9).
In this work we present a deﬁnition and a method to estimate the BROJA unique information for generic continuous probability densities. Our approach is based on the observation that the constraints (1.7) can be satisﬁed with an appropriate copula parametrization, and makes use of techniques developed to optimize variational autoencoders. We only consider one-dimensional
Y, X1, X2 for simplicity, but the method can be naturally extended to higher dimensional cases. In
Section 2 we review related works, in Section 3 we present our method and Section 4 contains several illustrative examples. 2
2