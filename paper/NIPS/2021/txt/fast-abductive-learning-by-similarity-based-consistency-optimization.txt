Abstract
To utilize the raw inputs and symbolic knowledge simultaneously, some recent neuro-symbolic learning methods use abduction, i.e., abductive reasoning, to inte-grate sub-symbolic perception and logical inference. While the perception model, e.g., a neural network, outputs some facts that are inconsistent with the symbolic background knowledge base, abduction can help revise the incorrect perceived facts by minimizing the inconsistency between them and the background knowledge.
However, to enable effective abduction, previous approaches need an initialized per-ception model that discriminates the input raw instances. This limits the application of these methods, as the discrimination ability is usually acquired from a thorough pre-training when the raw inputs are difﬁcult to classify. In this paper, we propose a novel abduction strategy, which leverages the similarity between samples, rather than the output information by the perceptual neural network, to guide the search in abduction. Based on this principle, we further present ABductive Learning with
Similarity (ABLSim) and apply it to some difﬁcult neuro-symbolic learning tasks.
Experiments show that the efﬁciency of ABLSim is signiﬁcantly higher than the state-of-the-art neuro-symbolic methods, allowing it to achieve better performance with less labeled data and weaker domain knowledge. 1

Introduction
To address the limitations of current machine learning methods, the next generation of Artiﬁcial
Intelligence calls for the integration of data-driven machine learning and knowledge-driven reasoning such as logic inference [1]. Neuro-Symbolic Learning [8, 22] and Statistical Relational AI [23] are representative works in this direction. However, most of these approaches try to approximate logical calculus with differentiable functions using distributed representations in a neural network, and train the model in an end-to-end manner, which usually demand a large number of labeled data.
Abductive Learning (ABL) [5, 29] is a novel framework attaching machine learning models to a ﬁrst-order logical reasoning model while preserving the full expressive power of each side: The machine learning model learns to convert raw input data (e.g., images, text) into symbolic representations, and the logical model tries to reason about them. Because ABL allows full-featured logical reasoning, it can directly consult symbolic background knowledge bases and reduce the requirement for massive labeled data. The logical reasoning model adopts abductive reasoning [20], or abduction, to search for the labels of the unlabeled instances, which are used for updating the machine learning model.
Because abductive reasoning is non-deterministic, for each unlabeled instance there could be multiple abduced labels. To choose the best labels, one needs to minimize the inconsistency between the abduced labels and the symbolic background knowledge. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
Hence, a well-designed consistency measure improves the quality of the abduced labels and leads to a high-performance model. For example, some approaches take the consistency score as the size of the largest subset of unlabeled examples with abduced labels that are consistent with knowledge base, leading to a subset-selection problem that is difﬁcult to solve [5, 29]; some other works measure the conﬁdence of the predicted labels by the perceptual machine learning model, which could be unreliable when the model is under-trained [19, 4, 2].
According to its deﬁnition, abduction refers to the process of inferring speciﬁc facts that give the best explanation to observations based on background knowledge [20]. Hence, not only the symbolized information—the labels predicted by perception model and the symbolic background knowledge base, but also the observed raw representation of the inputs contribute to the goodness of abduced labels. For example, when babies start learning an unknown language, although they could not make sense of the acoustic syllables in a sentence, they can amazingly learn from a handful of examples and understand a few words by distinguishing different sound patterns (raw representation) as well as identifying frequently occurred syllable combinations (symbolic relations) [9].
Inspired by this phenomenon, we develop a similarity-based consistency measure for abduction, which takes the idea that samples in the same category are similar in feature space while samples of different classes are dissimilar. It can be regarded as the clustering initialization for the perception model [29], and then the metric for clustering in embedding space is improved when the model gets updated by the abduced labels during training. Applying this principle, we propose ABductive
Learning with Similarity (ABLSim), which adopts beam search to solve the optimization problem of ﬁnding the best abduced labels. We verify the effectiveness of ABLSim on four neuro-symbolic tasks. Compared with other methods, ABLSim can abduce higher quality labels for unlabeled data and accelerate the model training, bringing a signiﬁcantly better performance. Moreover, even when we increase the difﬁculty of abduction by removing some rules from the knowledge base, ABLSim still achieves comparable results as the other abduction-based neuro-symbolic learning methods with a full knowledge base. 2