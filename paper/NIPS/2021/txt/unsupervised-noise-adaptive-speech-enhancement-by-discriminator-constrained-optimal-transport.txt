Abstract
This paper presents a novel discriminator-constrained optimal transport network (DOTN) that performs unsupervised domain adaptation for speech enhancement (SE), which is an essential regression task in speech processing. The DOTN aims to estimate clean references of noisy speech in a target domain, by exploiting the knowledge available from the source domain. The domain shift between training and testing data has been reported to be an obstacle to learning problems in diverse
ﬁelds. Although rich literature exists on unsupervised domain adaptation for classi-ﬁcation, the methods proposed, especially in regressions, remain scarce and often depend on additional information regarding the input data. The proposed DOTN approach tactically fuses the optimal transport (OT) theory from mathematical analysis with generative adversarial frameworks, to help evaluate continuous labels in the target domain. The experimental results on two SE tasks demonstrate that by extending the classical OT formulation, our proposed DOTN outperforms previous adversarial domain adaptation frameworks in a purely unsupervised manner. 1

Introduction
The goal of speech enhancement (SE) is to convert low-quality speech signals to ones with improved quality and intelligibility. SE serves as an important regression task in the speech-processing ﬁeld and has been widely used for a pre-processor in speech-related applications, such as speech coding [1], automatic speech recognition (ASR) [2], speaker recognition [3], and assistive hearing devices [4, 5].
Recent advances in machine learning have made signiﬁcant progress to the SE technology. Generally, 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
learning-based SE approaches estimate a transformation to characterize the mapping function from noisy to clean speech signals in the training phase [6]. The estimated transformation converts noisy speech signals to generate clean-like signals in the testing phase. Various neural network models have been used to characterize noisy-to-clean transformations. Well-known examples of such models include fully connected neural network [7], deep denoising autoencoder [8], convolutional neural network [9], long-short-term memory [10], and Transformer [11]. To effectively handle diverse noisy conditions, we usually prepare a considerable amount of training data that cover various noise types to train SE models. However in real-application scenarios, the noise types in the testing data may not always be involved in the training set. Consequently, the noisy-to-clean transformation learned from the training data cannot be suitably applied to handle the testing noise, resulting in limited enhancement performance. This training-testing mismatch is generally called a domain mismatch issue for SE. An effective solution is required to perform domain adaptation to adjust the SE models with formulating a precise noisy-to-clean transformation that matches the testing conditions. Most existing domain adaptation methods rely on at least one of the following adaptation mechanisms: aligning domain-invariant features [12, 13, 14] and adversarial training, where a discriminator is introduced during training as a domain classiﬁer [15, 16, 17].
This study aims to solve the unsupervised domain adaptation problem for SE by introducing optimal transport (OT). In particular, we consider the circumstance where SE is tested on a target domain with completely unlabeled data, and only labeled data from the source domain is available for reference. Generally speaking, OT theory compares two (probability) distributions and considers all possible transportation plans in between to ﬁnd one with a minimal displacement cost. The concept of OT can be applied to minimize domain mismatch and consequently achieve unsupervised domain adaptation. Even with the mathematical characteristics offered by OT, obstacles to excellent
SE performance persist due to the complex structure possessed by human speech. To further overcome the obstacles, another concept from Generative Adversarial Network (GAN) is integrated to assist attaining sophisticated SE domain adaptation. Although an existing domain transition technique “domain adversarial training” and our proposal share similarity in names, the fundamental constructions are substantially different. A key element in our method lies in a discriminator utilized to examine speech output characteristics, instead of a domain classiﬁer. More precisely, the discriminator in our method was employed to govern the output speech quality by learning the probability distribution of the source labels. This novel approach was designed especially for the unsupervised SE domain adaptation to exhibit excellent performance, which was veriﬁed on the
VoiceBank and TIMIT datasets.
Contributions We proposed a novel method designed speciﬁcally for unsupervised domain adapta-tion in a regression setting. This area of study still has very limited results; moreover, the existing methods often require additional classiﬁcation of source domains or may not yet be supported by strong regression applications. Conversely, our approach does not require any additional input infor-mation other than the source samples, source labels, and target samples. Our approach was applied to two standardized SE tasks, namely VoiceBank-DEMAND and TIMIT, and achieved superior adapta-tion performance in terms of both Perceptual Evaluation of Speech Quality (PESQ) and Short-Time
Objective Intelligibility (STOI) scores. Furthermore, owing to the simple input requirements, we can easily investigate the effect of target sample complexity on our method by increasing the number of noise types allowed in the target domain, which has not been reported by previous literature to the best of our knowledge. 2