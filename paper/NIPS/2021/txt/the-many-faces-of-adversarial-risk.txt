Abstract
Adversarial risk quantiﬁes the performance of classiﬁers on adversarially perturbed data. Numerous deﬁnitions of adversarial risk—not all mathematically rigorous and differing subtly in the details—have appeared in the literature. In this paper, we re-visit these deﬁnitions, make them rigorous, and critically examine their similarities and differences. Our technical tools derive from optimal transport, robust statistics, functional analysis, and game theory. Our contributions include the following: generalizing Strassen’s theorem to the unbalanced optimal transport setting with ap-plications to adversarial classiﬁcation with unequal priors; showing an equivalence between adversarial robustness and robust hypothesis testing with ∞-Wasserstein uncertainty sets; proving the existence of a pure Nash equilibrium in the two-player game between the adversary and the algorithm; and characterizing adversarial risk by the minimum Bayes error between a pair of distributions belonging to the ∞-Wasserstein uncertainty sets. Our results generalize and deepen recently discovered connections between optimal transport and adversarial robustness and reveal new connections to Choquet capacities and game theory. 1

Introduction
Neural networks are known to be vulnerable to adversarial attacks, which are imperceptible per-turbations to input data that maximize loss [38, 15, 5]. Developing algorithms resistant to such attacks has received considerable attention in recent years [8, 28, 24, 20], motivated by safety-critical applications such as autonomous driving [18, 27], medical imaging [17, 23, 22] and law [21, 6].
A classiﬁcation algorithm with high accuracy (low risk) in the absence of an adversary may have poor accuracy (high risk) when an adversary is present. Thus, a modiﬁed notion known as adversarial risk is used to quantify the adversarial robustness of algorithms. Algorithms that minimize adversarial risk are deemed robust. Procedures for ﬁnding them have been effective in practice [24, 41, 28], spurring numerous theoretical investigations into adversarial risk and its minimizers.
There is no universally agreed upon deﬁnition of adversarial risk. Even the simplest setting of binary classiﬁcation in Rd with an (cid:96)2 adversary admits various deﬁnitions involving set expansions
[9, 16], transport maps [29], Markov kernels [31], and couplings [26]. These works broadly interpret adversarial risk as a measure of robustness to small perturbations, but their deﬁnitions differ in subtle details such as the class of adversaries and algorithms considered, budget constraints placed on the adversary, assumptions on the loss function, and the geometry of decision boundaries.
Optimal adversarial risk is most commonly deﬁned as the minimax risk under adversarial contam-ination [24, 33]. Other notable characterizations include an optimal transport cost between data generating distributions in [30, 2, 10, 11], the optimal value of a distributionally robust optimization problem [36, 35, 40], and the value of a two-player zero-sum game [26, 29, 3, 4].
The diversity of deﬁnitions for adversarial risk makes it challenging to compare approaches. Moreover, not all approaches are rigorous. For instance, the classes of adversarial strategies and classiﬁer 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
algorithms are often unclear, and issues of measurability are ignored. Although this may be harmless for applied research, it has led to incorrect proofs and insufﬁcient assumptions in some theoretical works; a mathematically rigorous foundation for adversarial risk is essential for future research.
In this paper, we examine various notions of adversarial risk for binary classiﬁcation in a non-parametric setting, where the decision boundary (or decision region) of a classiﬁer is an arbitrary subset of the input space. We present rigorous deﬁnitions of adversarial risk and identify conditions under which these deﬁnitions are equivalent. We consider the general setting of Polish spaces (complete, separable metric spaces), and present stronger results for the Euclidean space (Rd). Our contributions are as follows:
• We examine the deﬁnition of adversarial risk based on set expansions. For Polish spaces, we observe that adversarial risk is not Borel measurable, and hence, not well-deﬁned when the decision region is an arbitrary set. We show that the problem can be resolved by considering a Polish space equipped with the universal completion of the Borel σ-algebra and restricting the decision regions to Borel sets. For the Euclidean space with the Lebesgue σ-algebra, we show that adversarial risk is well-deﬁned for any Lebesgue measurable decision region.
Our key lemma (Lemma 4.3) shows that the Lebesgue σ-algebra is preferred over the
Borel σ-algebra because set expansions are Lebesgue measurable but not necessarily Borel measurable. These results are contained in Section 4.
• We show that the deﬁnition of adversarial risk using set expansions is identical to a notion of risk that appears in robust hypothesis testing with ∞-Wasserstein uncertainty sets. We prove this result in Polish spaces using the theory of measurable selections [1, 43]. In Rd, we are able to use the powerful theory of Choquet capacities [7] (in particular, Huber and
Strassen’s 2-alternating capacities [19]) to establish results of a similar nature. These results are contained in Section 5.
• We consider the binary classiﬁcation setup with unequal priors and show (under suitable assumptions) that the optimal adversarial risk from the above deﬁnitions is characterized by an unbalanced optimal transport cost between data-generating distributions. For both Polish spaces and Rd, the main tool we use is Theorem 6.1 in which we generalize a classical result of Strassen on excess-cost optimal transport [37, 42] from probability measures to
ﬁnite measures with possibly unequal mass. This generalizes results of [31, 2] on binary classiﬁcation, which were only for equal priors. These results are contained in Section 6.
• We consider the setup of a zero-sum game between the adversary and the algorithm. We show that the value of this game (adversarial risk) is equal to the minimum Bayes error between a pair of distributions belonging to the ∞-Wasserstein uncertainty sets centered around true data-generating distributions. We prove the existence of a pure Nash equilibrium in this game for Rd and for Polish spaces with a midpoint property. This extends/strengthens the results of [26, 29, 3] to non-parametric classiﬁers. These results are contained in Section 7.
The paper is organized as follows: In Section 2, we present preliminary deﬁnitions from optimal transport and metric space topology. In Section 3, we discuss various deﬁnitions of adversarial risk and present more related work. Sections 4, 5, 6 and 7 contain our main contributions summarized above. We conclude the paper in Section 8 and discuss future research directions.
We emphasize that rectifying measure theoretic issues with existing formulations of adversarial risk is one of our contributions, but not the main focus of our paper. We start our presentation with ﬁxing measurability and well-deﬁnedness (in Section 4) because otherwise we will not be able to rigorously present our main results in the subsequent sections, namely: relation to robust hypothesis testing and
Choquet capacities in section 5, generalizing the results of [2, 30] in section, 6 proving minimax theorems and existence of Nash equilibria and extending the results of [26, 3, 29] in section 7.
Notation: Throughout the paper, we use X to denote a Polish space (a complete, separable metric space) with metric d and Borel σ-algebra B(X ). For x ∈ X and r ≥ 0, let Br(x) denote the closed ball of radius r centered at x. We use P(X ) and M(X ) to denote the space of probability measures and ﬁnite measures deﬁned on the measure space (X , B(X )), respectively. Let B(X ) denote the universal completion of B(X ). Let P(X ) and M(X ) denote the space of probability measures and
ﬁnite measures deﬁned on the complete measure space (X , B(X )). For µ, ν ∈ M(X ), we say ν dominates µ if µ(A) ≤ ν(A) for all A ∈ B(X ) and write µ (cid:22) ν. When X is Rd, we use L(X ) to 2
denote the Lebesgue σ-algebra and λ to denote the d-dimensional Lebesgue measure. Note that
L(X ) = B(X ) for X = Rd. For a positive integer n, we use [n] to denote the ﬁnite set {1, . . . , n}. 2 Preliminaries 2.1 Metric Space Topology
We introduce three different notions of set expansions. For (cid:15) ≥ 0 and A ∈ B(X ), the (cid:15)-Minkowski expansion of A is given by A⊕(cid:15) := ∪a∈AB(cid:15)(a). The (cid:15)-closed expansion of A is deﬁned as A(cid:15) :=
{x ∈ X : d(x, A) ≤ (cid:15)}, where d(x, A) = inf a∈A d(x, a). The (cid:15)-open expansion of A is deﬁned as A(cid:15)) := {x ∈ X : d(x, A) < (cid:15)}. We use the notation A−(cid:15) to denote ((Ac)(cid:15))c. Similarly,
A(cid:9)(cid:15) := ((Ac)⊕(cid:15))c. For example, consider the set A = (0, 1] in the space (X , d) = (R, | · |) and (cid:15) > 0. Then A⊕(cid:15) = (−(cid:15), 1 + (cid:15)], A(cid:15) = [−(cid:15), 1 + (cid:15)] and A(cid:15)) = (−(cid:15), 1 + (cid:15)). For any A ∈ B(X ), A(cid:15) is closed and A(cid:15)) is open. Hence, A(cid:15), A(cid:15)) ∈ B(X ). Moreover, A(cid:15)) ⊆ A⊕(cid:15) ⊆ A(cid:15). However, A⊕(cid:15) may not be in B(X ) (see Appendix for an example). In general, the Minkowski sum of two Borel sets need not be Borel [13], and that of two Lebesgue measurable sets need not be Lebesgue measurable [34]. 2.2 Optimal Transport
Let µ, ν ∈ P(X ). A coupling between µ and ν is a joint probability measure π ∈ P(X 2) with marginals µ and ν. The set Π(µ, ν) ⊆ P(X 2) denotes the set of all couplings between µ and ν. The optimal transport cost between µ and ν under a cost function c : X × X → [0, ∞) is deﬁned as (cid:82)
X 2 c(x, x(cid:48))dπ(x, x(cid:48)). For a positive integer p, the p-Wasserstein distance
Tc(µ, ν) = inf π∈Π(µ,ν) p . The ∞-Wasserstein metric is deﬁned as between µ and ν is deﬁned as, Wp(µ, ν) = (Tdp (µ, ν))
W∞(µ, ν) = limp→∞ Wp(µ, ν). It can also be expressed in the following ways: 1
W∞(µ, ν) = inf
π∈Π(µ,ν) ess sup (x,x(cid:48))∼π d(x, x(cid:48)) = inf{δ > 0 : µ(A) ≤ ν(Aδ)∀A ∈ B(X )}. (1)
Given a µ ∈ P(X ) and a measurable function f : X → X , the push-forward of µ by f is deﬁned as a probability measure f(cid:93)µ ∈ P(X ) given by f(cid:93)µ = µ(f −1(A)) for all A ∈ B(X ). 3 Adversarial Risk: Deﬁnitions and