Abstract
Imagine trying to track one particular fruitﬂy in a swarm of hundreds. Higher biological visual systems have evolved to track moving objects by relying on both their appearance and their motion trajectories. We investigate if state-of-the-art spatiotemporal deep neural networks are capable of the same. For this, we introduce PathTracker, a synthetic visual challenge that asks human observers and machines to track a target object in the midst of identical-looking “distractor” objects. While humans effortlessly learn PathTracker and generalize to systematic variations in task design, deep networks struggle. To address this limitation, we identify and model circuit mechanisms in biological brains that are implicated in tracking objects based on motion cues. When instantiated as a recurrent network, our circuit model learns to solve PathTracker with a robust visual strategy that rivals human performance and explains a signiﬁcant proportion of their decision-making on the challenge. We also show that the success of this circuit model extends to object tracking in natural videos. Adding it to a transformer-based architecture for object tracking builds tolerance to visual nuisances that affect object appearance, establishing the new state of the art on the large-scale TrackingNet challenge.
Our work highlights the importance of understanding human vision to improve computer vision. 1

Introduction
Lettvin and colleagues [1] presciently noted, “The frog does not seem to see or, at any rate, is not concerned with the detail of stationary parts of the world around him. He will starve to death surrounded by food if it is not moving.” Object tracking is fundamental to survival, and higher biological visual systems have evolved the capacity for two distinct and complementary strategies to do it. Consider Figure 1: can you track the object labeled by the yellow arrow from left-to-right? The task is trivial when appearance cues, like color, make it possible to solve the temporal correspondence problem by “re-recognizing” the target in each frame (Fig. 1a). However, this strategy is not effective when objects cannot be discriminated by their appearance alone (Fig. 1b). In this case integration of object motion over time is necessary for tracking. Humans are capable of tracking objects by their motion when appearance is uninformative [2, 3], but it is unclear if the current generation of neural networks for video analysis and tracking can do the same. To address this question we introduce
PathTracker, a synthetic challenge for object tracking without re-recognition (Fig. 1c).
*†These authors contributed equally to this work. 1Carney Institute for Brain Science, Brown University, Providence, RI 2Northeastern University, Boston, MA 3DeepMind, London, UK 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
Leading models for video analysis rely on object classiﬁcation pre-training. This gives them access to rich semantic representations that have supported state-of-the-art performance on a host of tasks, from action recognition to object tracking [4–6]. As object classiﬁcation models have improved, so too have the video analysis models that depend on them. This trend in model development has made it unclear if video analysis models are effective at learning tasks when appearance cues are uninformative. The importance of diverse visual strategies has been highlighted by synthetic challenges like Pathﬁnder, a visual reasoning task that asks ob-servers to trace long paths embed-ded in a static cluttered display [7, 8].
Pathﬁnder tests object segmentation when appearance cues like category or shape are missing. While humans can easily solve it
[8], deep neural net-works struggle, including state-of-the-art vision transformers [7–9]. Impor-tantly, models that learn an appropri-ate visual strategy for Pathﬁnder also exhibit more efﬁcient learning and im-proved generalization on object seg-mentation in natural images [10, 11].
Our PathTracker challenge extends this line of work into video by pos-ing an object tracking problem where the target can be tracked by motion and spatiotemporal continuity, not cat-egory or appearance.
Figure 1: The appearance of objects makes them (a) easy or (b) hard to track. We introduce the PathTracker Challenge (c), which asks observers to track a particular green dot as it travels from the red-to-blue markers, testing object tracking when re-recognition is impossible.
Contributions. Humans effortlessly solve our novel PathTracker challenge. A variety of state-of-the-art models for object tracking and video analysis do not.
• We ﬁnd that neural architectures including R3D [12] and state-of-the-art transformer-based TimeS-formers [5] are strained by long PathTracker videos. Humans, on the other hand, are far more effective at solving these long PathTracker videos.
• We describe a solution to PathTracker: a recurrent network inspired by primate neural circuitry involved in object tracking, which renders decisions that are strongly correlated with humans.
• These same circuit mechanisms improve object tracking in natural videos through a motion-based strategy that builds tolerance to changes in target object appearance, resulting in the state-of-the-art score on TrackingNet [13].
• We release all PathTracker data, code, and human psychophysics at http://bit.ly/InTcircuit to spur interest in the challenge of tracking without re-recognition. 2