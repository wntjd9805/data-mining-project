Abstract
Private data analysis suffers a costly curse of dimensionality. However, the data often has an underlying low-dimensional structure. For example, when optimizing via gradient descent, the gradients often lie in or near a low-dimensional subspace.
If that low-dimensional structure can be identiﬁed, then we can avoid paying (in terms of privacy or accuracy) for the high ambient dimension.
We present differentially private algorithms that take input data sampled from a low-dimensional linear subspace (possibly with a small amount of error) and output that subspace (or an approximation to it). These algorithms can serve as a pre-processing step for other procedures. 1

Introduction
Differentially private algorithms generally have a poor dependence on the dimensionality of their input. That is, their error or sample complexity grows polynomially with the dimension. For example, for the simple task of estimating the mean of a distribution supported on [0, 1]d, we have
√ per-coordinate error Θ( d/n) to attain differential privacy, where n is the number of samples. In contrast, the non-private error is Θ((cid:112)log(d)/n).
This cost of dimensionality is inherent [BUV14, SU17, DSS+15]. Any method with lower error is susceptible to tracing attacks (a.k.a. membership inference attacks). However, these lower bounds only apply when the data distribution is “high-entropy.” This leaves open the posssibility that we can circumvent the curse of dimensionality when the data has an underlying low-dimensional structure.
Data often does possess an underlying low-dimensional structure. For example, the gradients that arise in deep learning tend to be close to a low-dimensional subspace [ACG+16, LXT+17, GARD18,
LFLY18, LGZ+20, ZWB20, FT20]. Low dimensionality can arise from meaningful relationships that are at least locally linear, such as income versus tax paid. It can also arise because we are looking at a function of data with relatively few attributes.
A long line of work [BLR08, HT10, HR10, Ull15, BBNS19, BCM+20, ZWB20, KRRT20, etc.] has shown how to exploit structure in the data to attain better privacy and accuracy. However, these approaches assume that this structure is known a priori or that it can be learned from non-private sources. This raises the question:
Can we learn low-dimensional structure from the data subject to differential pri-vacy?
We consider the simple setting where the data lies in Rd but is in, or very close to a linear subspace, of dimension k. We focus on the setting where k (cid:28) d and we develop algorithms whose sample 0The full version of this article is available online at https://arxiv.org/abs/2106.00001 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
complexity does not depend on the ambient dimension d; a polynomial dependence on the true dimension k is unavoidable.
Our algorithms identify the subspace in question or, if the data is perturbed slightly, an approximation to it. Identifying the subspace structure is interesting in its own right, but it also can be used as a pre-processing step for further analysis – by projecting to the low-dimensional subspace, we ensure subsequent data analysis steps do not need to deal with high-dimensional data. 1.1 Our Contributions: Privately Learning Subspaces – Exact Case
We ﬁrst consider the exact case, where the data X1, · · · , Xn ∈ Rd are assumed to lie in a k-dimensional subspace (rather than merely being near to it) – i.e., rank (A) = k, where A = (cid:80)n i ∈ Rd×d. In this case, we can also recover the subspace exactly. i XiX T
However, we must also make some non-degeneracy assumptions. We want to avoid a pathological input dataset such as the following. Suppose X1, · · · , Xk are linearly independent, but Xk =
Xk+1 = Xk+2 = · · · = Xn. While we can easily reveal the repeated data point, we cannot reveal anything about the other points due to the privacy constraint.
A natural non-degeneracy assumption would be to assume that the data points are in “general position” – that is, that there are no non-trivial linear dependencies among the data points. This means that every set of k data points spans the subspace or, equivalently, no subspace of dimension k − 1 contains more than k − 1 data points. This is a very natural assumption – if the data consists of n samples from a continuous distribution on the subspace, then this holds with probability 1. We relax this assumption slightly and assume that no subspace of dimension k − 1 contains more than (cid:96) data points.
We also assume that all points are non-zero. Note that we deﬁne subspaces to pass through the origin; our results can easily be extended to afﬁne subspaces.
Theorem 1.1 (Main Result – Exact Case). For all n, d, k, (cid:96) ∈ N and ε, δ > 0 satisfying n ≥ d satisfying the following.
O
Here S k
, there exists a randomized algorithm M : Rd×n → S k d denotes the set of all k-dimensional subspaces of Rd. (cid:96) + log(1/δ) (cid:16) (cid:17)
ε
• M is (ε, δ)-differentially private with respect to changing one column of its input.
• Let X = (X1, · · · , Xn) ∈ Rd×n. Suppose there exists a k-dimensional subspace S∗ ∈ S k d that contains all but (cid:96) of the points – i.e., |{i ∈ [n] : Xi ∈ S∗}| ≥ n − (cid:96). Further suppose that any (k − 1)-dimensional subspace contains at most (cid:96) points – i.e., for all S ∈ S k−1
, we have |{i ∈ [n] : Xi ∈ S}| ≤ (cid:96). Then P [M (X) = S∗] = 1. d
The parameter (cid:96) in Theorem 1.1 can be thought of as a robustness parameter. Ideally the data points are in general position, in which case (cid:96) = k − 1. If a few points are corrupted, then we increase (cid:96) accordingly; our algorithm can tolerate the corruption of a small constant fraction of the data points.
Theorem 1.1 is optimal in the sense that n ≥ Ω samples are required. (cid:96) + log(1/δ) (cid:16) (cid:17)
ε 1.2 Our Contributions: Privately Learning Subspaces – Approximate Case
Next we turn to the substantially more challenging approximate case, where the data X1, · · · , Xn ∈
Rd are assumed to be close to a k-dimensional subspace, but are not assumed to be contained within that subspace. Our algorithm for the exact case is robust to changing a few points, but very brittle if we change all the points by a little bit. Tiny perturbations of the data points (due to numerical errors or measurement imprecision) could push the point outside the subspace, which would cause the algorithm to fail. Thus it is important to for us to cover the approximate case and our algorithm for the approximate is entirely different from our algorithm for the exact case.
The approximate case requires us to precisely quantify how close the input data and our output are to the subspace and we also need to make quantitative non-degeneracy assumptions. It is easiest to formulate this via a distributional assumption. We will assume that the data comes from a Gaussian distribution where the covariance matrix has a certain eigenvalue gap. This is a strong assumption and we emphasize that this is only for ease of presentation; our algorithm works under weaker assumptions. Furthermore, we stress that the differential privacy guarantee is worst-case and does not depend on any distributional assumptions. 2
We assume that the data is drawn from a multivariate Gaussian N (0, Σ). Let λ1(Σ) ≥ λ2(Σ) ≥
· · · ≥ λd(Σ) be the eigenvalues of Σ ∈ Rd×d. We assume that there are k large eigenval-ues λ1(Σ), · · · , λk(Σ) – these represent the “signal” we want – and d − k small eigenvalues
λk+1(Σ), · · · , λd(Σ) – these are the “noise”. Our goal is to recover the subspace spanned by the eigenvectors corresponding to the k largest eigenvalues λ1(Σ), · · · , λk(Σ). Our assumption is that there is a large multiplicative gap between the large and small eigenvalues. Namely, we assume
λk+1(Σ)
λk(Σ) ≤ 1
Theorem 1.2 (Main Result – Approximate Case). For all n, d, k ∈ N and α, γ, ε, δ > 0 satisfying poly(d) . n ≥ Θ (cid:18)k log(1/δ)
ε
+ ln(1/δ) ln(ln(1/δ)/ε)
ε (cid:19) and γ2 ≤ Θ (cid:18)
εα2n d2k log(1/δ)
·min (cid:26)1 k
, 1 log(k log(1/δ)/ε) (cid:27)(cid:19)
, there exists an algorithm M : Rd×n → S k k-dimensional subspaces of Rd represented as projection matricies – i.e., S k
Π = ΠT , rank(Π) = k}. d satisfying the following. Here S k d is the set of all d = {Π ∈ Rd×d : Π2 =
• M is (ε, δ)-differentially private with respect to changing one column of its input.
• Let X1, · · · , Xn be independent samples from N (0, Σ). Let λ1(Σ) ≥ λ2(Σ) ≥ · · · ≥
λd(Σ) be the eigenvalues of Σ ∈ Rd×d. Suppose λk+1(Σ) ≤ γ2 · λk(Σ). Let Π ∈ S k d be the projection matrix onto the subspace spanned by the eigenvectors corresponding to the k largest eigenvalues of Σ. Then P [(cid:107)M (X) − Π(cid:107) ≤ α] ≥ 0.7.
The sample complexity of our algorithm n = O(k log(1/δ)/ε) is independent of the ambient dimension d; this is ideal. However, there is a polynomial dependence on d in γ, which controls the multiplicative eigenvalue gap. This multiplicative eigenvalue gap is a strong assumption, but it is also a necessary assumption if we want the sample complexity n to be independent of the dimension d. In fact, it is necessary even without the differential privacy constraint [CZ16]. That is, if we did not assume an eigenvalue gap that depends polynomially on the ambient dimension d, then it would be impossible to estimate the subspace with sample complexity n that is independent of the ambient dimension d even in the non-private setting.
Our algorithm is based on the subsample and aggregate framework [NRS07] and a differentially private histogram algorithm. These methods are generally quite robust and thus our algorithm is, too. For example, our algorithm can tolerate o(n/k) input points being corrupted arbitrarily. We also believe that our algorithm’s utility guarantee is robust to relaxing the Gaussianity assumption.
All that we require in the analysis is that the empirical covariance matrix of a few samples from the distribution is sufﬁciently close to its expectation Σ with high probability. 1.3