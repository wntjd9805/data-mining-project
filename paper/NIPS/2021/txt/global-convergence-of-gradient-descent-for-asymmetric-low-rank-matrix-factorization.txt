Abstract
We study the asymmetric low-rank factorization problem: min
U∈Rm×d,V∈Rn×d 1 2 (cid:107)UV(cid:62) − Σ(cid:107)2
F where Σ is a given matrix of size m×n and rank d. This is a canonical problem that admits two difﬁculties in optimization: 1) non-convexity and 2) non-smoothness (due to unbalancedness of U and V). This is also a prototype for more complex problems such as asymmetric matrix sensing and matrix completion. Despite being non-convex and non-smooth, it has been observed empirically that the randomly initialized gradient descent algorithm can solve this problem in polynomial time.
Existing theories to explain this phenomenon all require artiﬁcial modiﬁcations of the algorithm, such as adding noise in each iteration and adding a balancing regularizer to balance the U and V.
This paper presents the ﬁrst proof that shows randomly initialized gradient descent converges to a global minimum of the asymmetric low-rank factorization problem with a polynomial rate. For the proof, we develop 1) a new symmetrization technique to capture the magnitudes of the symmetry and asymmetry, and 2) a quantitative perturbation analysis to approximate matrix derivatives. We believe both are useful for other related non-convex problems. 1

Introduction
This paper studies the asymmetric low-rank matrix factorization problem: min
U∈Rm×d,V∈Rn×d f (U, V) := 1 2 (cid:107)UV(cid:62) − Σ(cid:107)2
F . (1) where Σ ∈ Rm×n is a given matrix of rank d. While solving this optimization problem is not hard (e.g., using power method), in this paper, we are interested in using randomly initialized gradient descent to solve this problem:
Ut+1 = Ut + η(Σ − UtV(cid:62)
Vt+1 = Vt + η(Σ − UtV(cid:62) t )Vt; t )(cid:62)Ut, (2) (3) 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
where η > 0 is the learning rate and U0, V0 are randomly initialized according to some distribution.
Empirically, gradient descent with a constant learning rate can efﬁciently solve this problem (see, e.g., Figure 1 in Du et al. [2018]). Somehow surprisingly, there is no global convergence proof of this generic algorithm, let alone convergence rate analysis. The main difﬁculties are 1) the problem is non-convex and 2) this problem is not smooth with respect to (U, V) because the magnitudes of them can be highly unbalanced.
To motivate the study of gradient descent for this optimization problem, we note that this is a prototypical optimization problem that illustrates the gap between practice and theory. In particular, the prediction function UV(cid:62) is homogeneous: if we multiply a factor by a scalar c and divide another factor by c, the prediction function remains the same. This homogeneity also exists in deep learning models. Therefore, progress made in understand (1) can further help us gain understanding on other non-convex problems, such as asymmetric matrix sensing, asymmetric matrix completion, and deep learning optimization. We refer readers to Du et al. [2018] for more discussions.
For Problem (1), Du et al. [2018] showed gradient ﬂow (gradient descent with the step size η → 0),
˙U = (cid:0)Σ − UV(cid:62)(cid:1) V and ˙V = (cid:0)Σ − UV(cid:62)(cid:1)(cid:62) converges to the global minimum but no rate was given. Here U : R → Rm×d, U = U(t) and
V : R → Rn×d, V = V(t) are an integral curve over manifold Rm×d × Rn×d, and ˙U := dU dt , (cid:0)U(cid:62)U − V(cid:62)V(cid:1) = 0.
˙V := dV
This invariance implies that if initially the difference between the magnitudes of U0 and V0 is small, then the difference remains small. This in turn guarantees the smoothness on the gradient ﬂow trajectory. Du et al. [2018] further uses a geometric result (all saddle points in the objective function are strict and all local minima are global minima [Ge et al., 2015, 2017b, 2016, Li et al., 2019b]), and then invokes the stable manifold theorem to show the global convergence of gradient ﬂow [Lee et al., 2016, Panageas and Piliouras, 2016]. dt . Key in their proof is an invariance maintained by gradient ﬂow: d
U, dt
However, to prove a polynomial convergence rate, the approach that solely relies on the geometry will fail because there exists a counter example [Du et al., 2017]. Furthermore, for gradient descent with η > 0, the key invariance no longer holds.1
Du et al. [2018] also studied gradient descent with decreasing step sizes ηt = O (cid:0)t−1/2(cid:1), and obtained an “approximate global optimality result": if the magnitude of the initialization is O (δ), then gradient descent converges to a δ-optimal solution, i.e., this result does not establish that gradient descent converges to a global minimum. And again, there was no convergence rate. Furthermore, their result crucially relies on ηt is of order O (cid:0)t−1/2(cid:1) to ensure the second order term does not diverge and thus does not apply to gradient descent with a constant learning rate.
Some previous works, e.g., Ge et al. [2015], Jin et al. [2017], modiﬁed the gradient descent algorithm to the perturbed gradient descent algorithm by adding an isotropic noise at each iteration, which can help escape strict saddle points and bypass the exponential lower bound in Du et al. [2017]. To deal with the non-smooth problem, they also added a balancing regularization term [Park et al., 2017, Tu et al., 2016, Ge et al., 2017a, Li et al., 2019b], 1
F to the objective function to ensure balancedness between U and V throughout the optimization process. With these two modiﬁcations, one can prove a polynomial convergence rate. However, experiments suggest that the isotropic noise and the balancing regularizer may be proof artifacts, because vanilla gradient descent applies to the original objective function (1) without any regularizer ﬁnds a global minimum efﬁciently. From a practical point of view, one does not want to add noise or additional regularization because it may require more hyper-parameter tuning. 8 (cid:107)U(cid:62)U − V(cid:62)V(cid:107)2
The only global quantitative analysis for randomly initialized gradient is by Du et al. [2018] who proved the global convergence rate for the case where Σ has rank 1, and U and V are two vectors. In this case, one can reduce the problem to the dynamics of 4 variables, which can be easily analyzed.
Unfortunately, it is very difﬁcult to generalize their analysis to the general rank setting. Recent work also studies this case with noise injected to the gradient update [Liu et al., 2021].
In this paper, we develop new techniques to overcome the technical difﬁculties and obtain the ﬁrst polynomial convergence of randomly initialized gradient descent for solving the asymmetric low-rank 1While the invariance can still hold approximately in some way, characterizing the approximation error is highly non-trivial, and this is one of our key technical contributions. 2
matrix factorization problem. Most importantly, our analysis is completely different from existing ones: we give a thorough characterization of the entire trajectory of gradient descent.
Before presenting our main results, we emphasize that the goal of this paper is not to provide new provably efﬁcient algorithms to solve Problem (1), but to provide a rigorous analysis of an intriguing and practically relevant phenomenon on gradient descent. This is of the same ﬂavor as the recent breakthrough on understanding Burer-Moneiro method for solving semideﬁnite programs [Cifuentes and Moitra, 2019]. 1.1 Main Results
Our main result is below.
Theorem 1.1. Suppose each entry of U0 and V0 are initialized using Gaussian distribution (cid:16) with mean 0 and variance ε2, where ε = ˜O
.2 Then there exists Ttotal(δ, η) =
√ (cid:16) σdε2 dσ3 1
O with high probability over the initialization, when t > Ttotal(δ, η),f (Ut, Vt) ≤ δ. such that for any δ > 0 and learning rate η = O
σd d3σ1(m+n)
, we have that
ε + 1
ησd (cid:16) 1
ησd ln σd
δ ln dσd (cid:17) (cid:17) (cid:17)
Here, σ1 and σd are the largest and the smallest singular values of Σ, respectively. Notably, in sharp contrast to the result in Du et al. [2018], which requires the initialization depends on δ, our initialization does not depend on the target accuracy. To our knowledge, this is the ﬁrst global convergence result for gradient descent in solving Problem (1). Furthermore, we give a polynomial rate. The ﬁrst term in Ttotal(δ, η) represents a warm-up phase and the second term represents the local linear convergence phase, which will be clear in the analysis sections. On the other hand, while we believe Ttotal(δ, η) is nearly tight, our requirement for η is loose. An interesting future direction is further relax this requirement.
Now by taking η → 0, we have the following corollary for gradient ﬂow. ln σd
Corollary 1.2. Given δ > 0, there exists T = O
δ probability over the initialization, for all t ≥ T , we have f (Ut, Vt) ≤ δ.3
ε + 1
σd ln dσd (cid:16) 1
σd (cid:17)
, such that with high
This is also the ﬁrst convergence rate result of randomly initialized gradient ﬂow for asymmetric matrix factorization. We note that our analysis on gradient ﬂow is nearly tight. To see this, consider the ordinary differential equation ˙at = (σd − a2 t )aT with initial point a0 > 0, then s = a2 has analytical solution st = σde2σd t
−1 . Hence, to achieve a δ optimal solution, i.e. |σd − a2| ≤ δ, we e2σd t+ σd a2 0 (cid:17) 1 (cid:17)
− 1. Hence T = Θ is necessary.
− 1
δ ≤ e2σdt + σd a2 0 need σd (cid:16) σd a2 0 (cid:16) 1
σd ln σd
δ
Remark 1.2. We note that the weights will also converge. In section 3.3, we will prove that U and V are always bounded, which implies the gradient norm is bounded in terms of the loss. Since the loss function converges linearly, we have that the gradient norm converges to 0 linearly. The convergence of U and V follows from that the trajectory of (Ut, Vt) forms a Cauchy sequence. 1.3 Additional