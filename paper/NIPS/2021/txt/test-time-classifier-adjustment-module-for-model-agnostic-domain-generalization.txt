Abstract
This paper presents a new algorithm for domain generalization (DG), test-time template adjuster (T3A), aiming to robustify a model to unknown distribution shift.
Unlike existing methods that focus on training phase, our method focuses test phase, i.e., correcting its prediction by itself during test time. Speciﬁcally, T3A adjusts a trained linear classiﬁer (the last layer of deep neural networks) with the following procedure: (1) compute a pseudo-prototype representation for each class using online unlabeled data augmented by the base classiﬁer trained in the source domains, (2) and then classify each sample based on its distance to the pseudo-prototypes. T3A is back-propagation-free and modiﬁes only the linear layer; therefore, the increase in computational cost during inference is negligible and avoids the catastrophic failure might caused by stochastic optimization. Despite its simplicity, T3A can leverage knowledge about the target domain by using off-the-shelf test-time data and improve performance. We tested our method on four domain generalization benchmarks, namely PACS, VLCS, OfﬁceHome, and TerraIncognita, along with various backbone networks including ResNet18,
ResNet50, Big Transfer (BiT), Vision Transformers (ViT), and MLP-Mixer. The results show T3A stably improves performance on unseen domains across choices of backbone networks, and outperforms existing domain generalization methods. 1

Introduction
Deep neural networks often fail to generalize to out-of-distribution samples. Accuracy suffers when the model performs under conditions different to those of training, such as variations in light [8], weather [51], object poses [2], textures [16], or object backgrounds [5]. Nevertheless, the model may be deployed to different conditions in practical situations; thus, some countermeasures are needed.
Over the past decade, various studies have focused on training a generalizable model to unseen domains given a dataset consisting of several source domains. This setting is usually denoted as domain generalization (DG) [6, 61]. Domain generalization operates under the assumption that one can improve robustness to domain shift by incorporating the structure common to multiple domains.
For example, domain-invariant feature learning constrains the representation to be invariant to domain shifts [14, 45, 29]. Other methods use meta-learning [19] to learn how to regularize the model to improve the robustness [28, 4, 31]. However, despite signiﬁcant work on this front, machine learning systems are still vulnerable to domain shifts even after using the above methods during training.
Notably, recent large-scale benchmarks [17] show that many approaches do not provide signiﬁcant improvement compared to simple supervised learning, i.e., empirical risk minimization (ERM), with a proper and practical experimental setup. It suggests that the setup in its current state may be too difﬁcult, and a different approach might be needed.
This paper proposes a method of using additional off-the-shelf data in the DG setup, the unsupervised data available at the test-time. Since no data about the target domain is available during training in 35th Conference on Neural Information Processing Systems (NeurIPS 2021), virtual.
a DG setup, the existing domain generalization algorithms focus on how to use labeled data from multiple-source domains. However, at test-time the model always has access to test data from the target domain. Although the available data is constrained to be (1) unlabeled and (2) only available online (models can not know all test cases in advance), this data provides clue about the target distribution that is not available during training. It is natural to ask the question: How can we use the off-the-shelf unlabeled data available at test-time to increase performance on the target domain?
It is worth emphasizing that our setting is different from the transductive setting [49, 22, 57] where all test cases are known in advance, even though we use test data for adjustment. When testing, the model is usually deployed in some environment, and must work well on various samples that will appear continuously. Similarly, the deployed model usually needs to make correct predictions at that moment; there is no point in going back in time and correcting the predictions. Therefore, it is desirable that adjustment and inference be performed at the same time, not ofﬂine after a large amount of data has been accumulated. Looking beyond domain generalization, some recent studies suggest optimizing the model during test time using objective function deﬁned only by unsupervised data (e.g, prediction entropy) [34, 52]. However, updating parameters using stochastic gradient descent (SGD) increases computational costs and harm inference throughput. In addition, data available at test time is limited, and stochastic optimization can lead to catastrophic failure.
To this end, we present test-time templates adjuster (T3A), which adjusts the linear classiﬁer (the last layer of deep neural networks) at test-time. T3A adjusts the weights of the linear classiﬁer as the following optimization-free procedure: (1) create a pseudo-prototype for each class using online unlabeled data and the classiﬁer trained in the source domains, (2) and then classify each sample based on its distance to the pseudo-prototype. This procedure makes the adjusted decision boundary avoid the high-data density region on the target domain and reduce the ambiguity (entropy) of predictions, which is known to be connected to classiﬁcation error [52]. Since T3A does not alter the training phase, it can be used together with existing DG algorithms. Moreover, it can be used together with any classiﬁcation model since it only adjusts the linear classiﬁer on top of the representations. Some readers may wonder how effective it is to modify only the linear classiﬁer while freezing the representation itself. Later in this paper (Section 3.2), we empirically demonstrate that this modiﬁcation is indeed beneﬁcial.
We evaluate our method on multiple standard domain generalization benchmarks, namely VLCS [12],
PACS [27], OfﬁceHome [50], and TerraIncognita [5]. We compare our method with (1) various DG algorithms reported in [17] and (2) Tent [52] that minimizes the prediction entropy at test time using
SGD. With the standard ResNet50 backbone [18], T3A improves ERM by 1.5 points on average accuracy over four dataset, and outperforms most existing DG algorithms. Furthermore, we evaluated our method with 10 different backbone networks, including residual networks (resnet18 and resnet50), big transfer (BiT-M-R50x3, BiT-M-R101x3, and BiT-M-R152x2 [24]), vision transformers (ViT-B16,
ViT-L16, Hybrid ViT [9], DeiT [48]), and MLP-Mixer (Mixer-L16) [47]. The results show that T3A gives a statistically signiﬁcant performance gain against ERM on all backbone networks. 2 Preliminary and