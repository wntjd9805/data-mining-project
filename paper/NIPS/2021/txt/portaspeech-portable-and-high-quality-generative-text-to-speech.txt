Abstract
Non-autoregressive text-to-speech (NAR-TTS) models such as FastSpeech 2 [24] and Glow-TTS [8] can synthesize high-quality speech from the given text in parallel.
After analyzing two kinds of generative NAR-TTS models (VAE and normalizing
ﬂow), we ﬁnd that: VAE is good at capturing the long-range semantics features (e.g., prosody) even with small model size but suffers from blurry and unnatural results; and normalizing ﬂow is good at reconstructing the frequency bin-wise details but performs poorly when the number of model parameters is limited. Inspired by these observations, to generate diverse speech with natural details and rich prosody using a lightweight architecture, we propose PortaSpeech, a portable and high-quality generative text-to-speech model. Speciﬁcally, 1) to model both the prosody and mel-spectrogram details accurately, we adopt a lightweight VAE with an enhanced prior followed by a ﬂow-based post-net with strong conditional inputs as the main architecture. 2) To further compress the model size and memory footprint, we introduce the grouped parameter sharing mechanism to the afﬁne coupling layers in the post-net. 3) To improve the expressiveness of synthesized speech and reduce the dependency on accurate ﬁne-grained alignment between text and speech, we propose a linguistic encoder with mixture alignment combining hard word-level alignment and soft phoneme-level alignment, which explicitly extracts word-level semantic information. Experimental results show that PortaSpeech outperforms other TTS models in both voice quality and prosody modeling in terms of subjective and objective evaluation metrics, and shows only a slight performance degradation when reducing the model parameters to 6.7M (about 4x model size and 3x runtime memory compression ratio compared with FastSpeech 2). Our extensive ablation studies demonstrate that each design in PortaSpeech is effective3. 1

Introduction
Recently, deep learning-based text-to-speech (TTS) has attracted a lot of attention in speech commu-nity [2, 15, 20, 22, 24, 25, 29, 35]. Among neural network-based TTS systems, some of them generate mel-spectrograms autoregressively from text [15, 22, 29, 35] and suffer from slow inference speed and robustness (word skipping and repeating) problems [25], while others [8, 12, 16, 19, 24, 25] generate mel-spectrograms in parallel with comparable quality using non-autoregressive architecture, called NAR-TTS, which enjoys fast inference and avoids robustness issues in the meanwhile. In general, modern TTS models aim to achieve the following goals:
• Fast: to reduce the cost of computational resources and apply the model to real-time applications, the inference speed of TTS model should be fast.
∗Equal contribution.
†Corresponding author 3Audio samples are available at https://portaspeech.github.io/. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
• Lightweight: to deploy the model to mobile or edge devices, the model size should be small and the runtime memory footprint should be low.
• High-quality: to improve the naturalness of synthesized speech, the model should capture the details (frequency bins between two adjacent harmonics, unvoiced frames and high-frequency parts) in natural speech.
• Expressive: to generate expressive and dynamic speech, the model should use powerful prosody modeling methods to accurately model the fundamental frequency and duration of speech.
• Diverse: to prevent the synthesized speech from being too dull and tedious when generating long speech, the model should be able to generate diverse speech samples with different intonations given one text input sequence.
To achieve the above goals, in this work, we propose PortaSpeech, a portable and high-quality gener-ative text-to-speech model, which generates mel-spectrograms with natural details and expressive prosody using a lightweight architecture. Speciﬁcally,
• Through some preliminary experiments (see Section 4.2), we ﬁnd that VAE is good at capturing the long-range semantics features (e.g., prosody), while normalizing ﬂow is good at reconstructing the frequency bin-wise details. Based on these observations, we adopt VAE with an enhanced prior followed by a ﬂow-based post-net as the main model architecture of PortaSpeech, which helps
PortaSpeech generate high-quality and expressive results. In addition, PortaSpeech can generate diverse speech by sampling latent variables from the prior of VAE and post-net.
• Through the experiments, we also ﬁnd that even when the model is very small, VAE is still good at capturing the prosody, making it possible for PortaSpeech to reduce its model size using a lightweight VAE. Besides, we introduce the grouped parameter sharing mechanism to the post-net to compress its model size. By doing these, PortaSpeech can be very lightweight and fast at a small performance cost.
• To model the prosody better and generate more expressive speech, we introduce a linguistic encoder with mixture alignment, which combines hard word-level alignment and soft phoneme-level alignment. Our proposed linguistic encoder also reduces the dependence on ﬁne-grained (phoneme-level) alignment and alleviates the burden of the speech-to-text aligner.
Experiments on the LJSpeech [7] dataset show that PortaSpeech outperforms other state-of-the-art
TTS models with comparable model parameters in voice quality and prosody in terms of both subjective and objective evaluation metrics. When compressing the model size, our PortaSpeech shows only a slight performance degradation but enjoys the beneﬁts of a much smaller number of model parameters (about 4x model size reduction) and lower memory footprints (about 3x memory reduction) compared with FastSpeech 2. The main contributions of this work are summarized as follows:
• We analyze the characteristics of VAE and normalizing ﬂow when applied to TTS and combines the advantages of VAE and normalizing ﬂow to generate mel-spectrograms with rich details and expressive prosody.
• We propose mixture alignment in the linguistic encoder, which improves the prosody and reduces the dependence on ﬁne-grained (phoneme-level) hard alignment.
• Using lightweight VAE and introducing the grouped parameter sharing mechanism to the post-net,
PortaSpeech can generate high-quality speech with a small number of model parameters and small runtime memory footprints. 2