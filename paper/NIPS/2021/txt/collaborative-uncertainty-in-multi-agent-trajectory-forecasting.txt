Abstract
Uncertainty modeling is critical in trajectory forecasting systems for both inter-pretation and safety reasons. To better predict the future trajectories of multiple agents, recent works have introduced interaction modules to capture interactions among agents. This approach leads to correlations among the predicted trajec-tories. However, the uncertainty brought by such correlations is neglected. To
ﬁll this gap, we propose a novel concept, collaborative uncertainty (CU), which models the uncertainty resulting from the interaction module. We build a gen-eral CU-based framework to make a prediction model learn the future trajectory and the corresponding uncertainty. The CU-based framework is integrated as a plugin module to current state-of-the-art (SOTA) systems and deployed in two special cases based on multivariate Gaussian and Laplace distributions. In each case, we conduct extensive experiments on two synthetic datasets and two public, large-scale benchmarks of trajectory forecasting. The results are promising: 1) The results of synthetic datasets show that CU-based framework allows the model to appropriately approximate the ground-truth distribution. 2) The results of trajectory forecasting benchmarks demonstrate that the CU-based framework steadily helps
SOTA systems improve their performances. Specially, the proposed CU-based framework helps VectorNet improve by 57 cm regarding Final Displacement Error on nuScenes dataset. 3) The visualization results of CU illustrate that the value of
CU is highly related to the amount of the interactive information among agents. 1

Introduction
A multi-agent trajectory forecasting system aims to predict future trajectories of multiple agents based on their observed trajectories and surroundings [1, 2]. Precise trajectory prediction provides essential information for decision making and safety in numerous intelligent systems, including autonomous vehicles [3, 4, 5, 6], drones [7], and industrial robotics [8, 9].
The rapid development of deep learning has enabled a number of deep-learning-based algorithms to handle multi-agent trajectory forecasting [3, 4, 5, 6, 10, 11, 12, 13, 14, 15]. These methods exhibit state-of-the-art performances, with some having been integrated into real-world systems. However, deep-learning-based forecasting is not always reliable or interpretable [16, 17, 18]. In circumstances when noises from the environment are overwhelmingly distracting, or when the situation has never been encountered before, a deep-learning-based algorithm could provide bafﬂing predictions, which might cause terrible tragedies. A fundamental challenge is to know when we could rely on those deep-learning-based forecasting algorithms. To tackle this problem, one solution is to report the uncertainty of each prediction. Finding ways to best conceptualize and measure the prediction uncertainty of deep-learning-based algorithms becomes an imperative, which motivates this work.
∗The corresponding author is Siheng Chen. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
Figure 1: Uncertainty modeling in multi-agent trajectory forecasting. (a) a typical pipeline of an encoder in multi-agent trajectory forecasting systems. (b) and (c) illustrate the decoder pipeline of previous methods and our method respectively. Previous methods output the predicted trajectory ˆY and individual uncertainty σi, and our method additionally outputs collaborative uncertainty σij.
There are two main types of uncertainty to model in deep-learning-based algorithms [19]: 1) aleatoric uncertainty, regarding information aside from statistic models, which data cannot explain; 2) epistemic uncertainty, the uncertainty inside a model, when the model lacks knowledge of the system/process being modeled (e.g., due to limited training data). As it is most effective to model aleatoric uncertainty in big data regimes such as those common to deep learning with image data [17], this work focuses on aleatoric uncertainty. In the following passage, we use the term “uncertainty” to represent aleatoric uncertainty. [16] uses the predictive variance to approximate uncertainty in the Bayesian deep learning model, which has been widely adapted in many works [20, 21, 22, 11] for uncertainty modeling in multi-agent trajectory forecasting. However, the predictive variance of a single agent alone may not sufﬁce to reﬂect the complete landscape of uncertainty, especially when agent-wise interaction is present. Recent works that attempt to exploit the interaction among agents have impressively boosted the prediction precision, which further highlights the need to better measure uncertainty in multi-agent trajectory forecasting. We seek to build a more sophisticated and robust measurement for capturing the previously neglected uncertainty brought by correlated predictions.
In this paper, we coin a concept individual uncertainty (IU) to describe the uncertainty that can be approximated by the predictive variance of a single agent. Relatively, we propose a new concept, collaborative uncertainty (CU) to estimate the uncertainty resulting from the usage of interaction modules in prediction models. We further introduce an original probabilistic CU-based framework to measure both individual and collaborative uncertainty in the multi-agent trajectory forecasting task.
We apply this framework to two special cases: multivariate Gaussian distribution and multivariate
Laplace distribution. In each case, our CU-based framework allows our model to simultaneously learn the mappings that are from input data to 1) accurate prediction, 2) individual uncertainty, and 3) collaborative uncertainty; see Figure 1 for model illustration. Extensive experiments demonstrate that CU modeling yields signiﬁcantly larger performance gains in prediction models equipped with interaction modules (See Figure 4), conﬁrming that CU is highly related to the existence of the interaction modeling procedure, and adding CU modeling beneﬁts accurate predictions.
The contributions of this work are summarized as follows:
● We propose, analyze, and visualize a novel concept, collaborative uncertainty (CU), to model the uncertainty brought by the interaction modules in multi-agent trajectory forecasting.
● We design a general CU-based framework to empower a prediction model to generate a proba-bilistic output, where the mean is the future trajectory and the covariance reﬂects the corresponding uncertainty. Under this framework, we show two special cases based on multivariate Gaussian and
Laplace distributions respectively.
● We conduct extensive experiments to validate the CU-empowered prediction model on both synthetic datasets and two large-scale real-world datasets. On self-generated synthetic datasets, we validate the proposed method is able to closely reconstruct the ground-truth distribution. On the public benchmarks, the CU-empowered prediction model consistently outperforms the corresponding one without CU. Specially, by leveraging the proposed CU, VectorNet improves by 57 cm regarding
Final Displacement Error (FDE) on nuScenes dataset! 2