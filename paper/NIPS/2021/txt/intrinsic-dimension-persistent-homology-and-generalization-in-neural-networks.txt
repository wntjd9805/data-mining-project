Abstract
Disobeying the classical wisdom of statistical learning theory, modern deep neural networks generalize well even though they typically contain millions of parameters.
Recently, it has been shown that the trajectories of iterative optimization algorithms can possess fractal structures, and their generalization error can be formally linked to the complexity of such fractals. This complexity is measured by the fractal’s intrinsic dimension, a quantity usually much smaller than the number of parameters in the network. Even though this perspective provides an explanation for why overparametrized networks would not overﬁt, computing the intrinsic dimension (e.g., for monitoring generalization during training) is a notoriously difﬁcult task, where existing methods typically fail even in moderate ambient dimensions. In this study, we consider this problem from the lens of topological data analysis (TDA) and develop a generic computational tool that is built on rigorous mathematical foundations. By making a novel connection between learning theory and TDA, we
ﬁrst illustrate that the generalization error can be equivalently bounded in terms of a notion called the ’persistent homology dimension’ (PHD), where, compared with prior work, our approach does not require any additional geometrical or statistical assumptions on the training dynamics. Then, by utilizing recently established theoretical results and TDA tools, we develop an efﬁcient algorithm to estimate
PHD in the scale of modern deep neural networks and further provide visualization tools to help understand generalization in deep learning. Our experiments show that the proposed approach can efﬁciently compute a network’s intrinsic dimension in a variety of settings, which is predictive of the generalization error. 1

Introduction
In recent years, deep neural networks (DNNs) have become the de facto machine learning tool and have revolutionized a variety of ﬁelds such as natural language processing [DCLT18], image perception [KSH12, RBH+21], geometry processing [QSMG17, ZBL+20] and 3D vision [DBI18,
GLW+21]. Despite their widespread use, little is known about their theoretical properties. Even now the top-performing DNNs are designed by trial-and-error, a pesky, burdensome process for the average practitioner [EMH+19]. Furthermore, even if a top-performing architecture is found, it is difﬁcult to provide performance guarantees on a large class of real-world datasets.
This lack of theoretical understanding has motivated a plethora of work focusing on explaining what, how, and why a neural network learns. To answer many of these questions, one naturally examines the generalization error, a measure quantifying the differing performance on train and 35th Conference on Neural Information Processing Systems (NeurIPS 2021)
test data since this provides signiﬁcant insights into whether the network is learning or simply memorizing [ZBH+21]. However, generalization in neural networks is particularly confusing as it refutes the classical proposals of statistical learning theory such as uniform bounds based on the
Rademacher complexity [BM02] and the Vapnik–Chervonenkis (VC) dimension [Vap68].
Instead, recent analyses have started focusing on the dynamics of deep neural networks. [NBMS17,
BO18, GJ16] provide analyses on the ﬁnal trained network, but these miss out on critical train-ing patterns. To remedy this, a recent study [SSDE20] connected generalization and the heavy tailed behavior of network trajectories–a phenomenon which had already been observed in prac-tice [SSG19, ¸SGN+19, SZTG20, GSZ21, CWZ+21, HM20, MM19]. [SSDE20] further showed that the generalization error can be linked to the fractal dimension of a parametric hypothesis class (which can then be taken as the optimization trajectories). Hence, the fractal dimension acts as a ‘capacity metric’ for generalization.
While [SSDE20] brought a new perspective to generalization, several shortcomings prevent ap-plication in everyday training. In particular, their construction requires several conditions which may be infeasible in practice: (i) topological regularity conditions on the hypothesis class for fast computation, (ii) a Feller process assumption on the training algorithm trajectory, and that (iii) the
Feller process exhibits a speciﬁc diffusive behavior near a minimum. Furthermore, the capacity metrics in [SSDE20] are not optimization friendly and therefore can’t be incorporated into training.
In this work, we address these shortcomings by exploiting the recently developed connections between fractal dimension and topological data analysis (TDA). First, by relating the box dimension [Sch09] and the recently proposed persistent homology (PH) dimension [Sch20], we relax the assumptions in [SSDE20] to develop a topological intrinsic dimension (ID) estimator. Then, using this estimator we develop a general tool for computing and visualizing generalization properties in deep learning.
Finally, by leveraging recently developed differentiable TDA tools [CHU17, CHN19], we employ our ID estimator to regularize training towards solutions that generalize better, even without having access to the test dataset.
Our experiments demonstrate that this new measure of intrinsic dimension correlates highly with generalization error, regardless of the choice of optimizer. Furthermore, as a proof of concept, we illustrate that our topological regularizer is able to improve the test accuracy and lower the generalization error. In particular, this improvement is most pronounced when the learning rate/batch size normally results in a poorer test accuracy.
Overall, our contributions are summarized as follows:
• We make a novel connection between statistical learning theory and TDA in order to develop a generic computational framework for the generalization error. We remove the topological regularity condition and the decomposable Feller assumption on training trajectories, which were required in
[SSDE20]. This leads to a more generic capacity metric.
• Using insights from our above methodology, we leverage the differentiable properties of persistent homology to regularize neural network training. Our ﬁndings also provide the ﬁrst steps towards theoretically justifying recent topological regularization methods [BGND+19, CNBW19].
• We provide extensive experiments to illustrate the theory, strength, and ﬂexibility of our framework.
We believe that the novel connections and the developed framework will open new theoretical and computational directions in the theory of deep learning. To foster further developments at the the intersection of persistent homology and statistical learning theory, we release our source code under: https://github.com/tolgabirdal/PHDimGeneralization. 2