Abstract
Linear mixed-effect models provide a natural baseline for estimating disease pro-gression using longitudinal data. They provide interpretable models at the cost of modeling assumptions on the progression proﬁles and their variability across subjects. A signiﬁcant improvement is to embed the data in a Riemannian manifold and learn patient-speciﬁc trajectories distributed around a central geodesic. A few interpretable parameters characterize subject trajectories at the cost of a prior choice of the metric, which determines the shape of the trajectories. We extend this approach by learning the metric from the data allowing more ﬂexibility while keeping the interpretability. Speciﬁcally, we learn the metric as the push-forward of the Euclidean metric by a diffeomorphism. This diffeomorphism is estimated iteratively as the composition of radial basis functions belonging to a reproducible kernel Hilbert space. The metric update allows us to improve the forecasting of imaging and clinical biomarkers in the Alzheimer’s Disease Neuroimaging Initia-tive (ADNI) cohort. Our results compare favorably to the 56 methods benchmarked in the TADPOLE challenge.
∗This work was partially supported by NIH R01AG027161 and R01EY032284.
†This research has also received funding from the program "Investissements d’avenir" ANR-10-IAIHU-06.
This work was also funded in part by the French government under management of Agence Nationale de la
Recherche as part of the "Investissements d’avenir" program, reference ANR-19-P3IA-0001 (PRAIRIE 3IA
Institute) and by ANR under the joint programme in neurodegenerative diseases (JPND) ANR-19-JPW2-000 (E-DADS).
‡Data used in preparation of this article were obtained from the Alzheimer’s Disease Neuroimaging
Initiative (ADNI) database (adni.loni.usc.edu). As such, the investigators within the ADNI contributed to the design and implementation of ADNI and/or provided data but did not participate in analysis or writ-ing of this report. A complete listing of ADNI investigators can be found at: http://adni.loni.usc.edu/wp-content/uploads/how_to_apply/ADNI_Acknowledgement_List.pdf 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
1

Introduction
Understanding the progression of diseases is essential to accurately monitor, diagnose and predict patients’ state of health. Disease progression modeling analyses longitudinal data to capture common and subject-speciﬁc progression patterns. Longitudinal data analysis has usually been addressed in the framework of parametric mixed-effects models [1]. The population parameters express the characteristics of the disease, and the individual parameters encode the speciﬁcities of each patient. It represents the diversity of pathology. The challenge is to construct models ﬂexible enough to learn the disease heterogeneity across the population and sufﬁciently interpretable to derive a practical conclusion.
To understand the trade-off between ﬂexibility and interpretability, we review these models through the prism of time and space variability of patients’ trajectories. We refer to time variability when all the patients follow the same trajectory but not at the same speed and not with the same onset and to space variability when each patient follows a different trajectory but with the same speed and the same onset. For instance, to observe the different stages of a disease, event-based models have been introduced [2], the timeline of disease progression is seen as a succession of stages followed by each patient but not in same order. Time variability is encoded into this subject-speciﬁc ordering.
Extension to mixture model includes space variability as a set of possible trajectories[3]. Increasing the number of stages and mixture components improves both the space and time granularity but it will result in a lack of interpretability of each stage.
To express more ﬁnely the space granularity, we can assume the patients’ observations follow a continuous parametric curve, the dataset providing discrete, noisy observations along this curve.
[4, 5, 6]. These curves can be deﬁned with mechanistic approaches using Ordinary Differential
Equations (ODE), the sources of variability (time and space) across patient being in the Cauchy conditions (t0 and X(t0)) and the common pattern of progression in the vector ﬁeld as derivative [4, 5].
This family of models is interesting to study the correlation between time and space variability [4], but it is a double-edge sword since these two factors cannot be analysed independently. Probabilistic approaches to represent parametric curves can solve this point. Gaussian Processes (GP) have been applied for disease progression successfully [7] to study correlation in the pathological progression while keeping time and space variability separated. Their semi-parametric paradigm allows for a signiﬁcant ﬂexibility by encoding the space-variability in the Gaussian kernel, but this last part is not easy to interpret. More generally in Bayesian models, it is difﬁcult to disentangle the different random effects to obtain meaningful parameters. To address this point, geometric approaches have proved to be efﬁcient for scalar biomarkers [6] and brain shapes [8].
One instance of this family of geometric models [6] assumes that each subject follows a curve on a Riemannian manifold which is a translation from a common geodesic (Disease Course
Mapping, DCM). The space variability is encoded in the translation and the time variability by a time reparametrization. Though the Riemannian formalism provides interesting tools for modeling trajectories, it is usually constrained to well-studied manifolds with simple geodesics such as sigmoid curves for biomarkers or straight lines for cortical atrophy. In order to increase the model ﬂexibility, some contributors propose to learn the metric by playing on the representation of trajectories [9].
They rely on a push-forward method to learn a metric with pseudo-diffeomorphic transformations
[10]. Observations’ trajectories are seen as transformations of straight lines evolving in a latent space learned by an auto-encoder. Though this semi-parametric representation enables multiple progression proﬁles, it is inappropriate for disentangling space and time variability.
Another method for trajectory learning is to use the theory of shape analysis and more especially the deformation of shapes in time. Authors commonly learn the deformation as a diffeo-morphism with a Reproducing Kernel Hilbert Space (RKHS), the kernel regularity encoding the smoothness of the deformation through time [8, 11]. We believe that this deformation method is an interesting alternative to the the auto-encoders to increase model ﬂexibility while keeping control on space and time variability.
In this work, following [9] but taking a step back, we propose a semi-parametric method using a RKHS to learn the Riemannian metric of DCM models. We thereby retain the possibility to learn the inter-variability of patient trajectories thanks to the mixed-effect framework, keeping the advantages of the geometric and Bayesian approach presented in [12]. First, we recall the structure of the mixed-effect model in section 2.1, then we present the method to learn the metrics step by 2
step in section 2.2. We validate the presented method on synthetic data in 3.1 and on a real dataset (ADNI,Tadpole) in 3.2 by comparing it with previous models on the task of predicting patient’s biomarker progression. Finally, we discuss limitations and possible future works in the discussion section 4. 1.1