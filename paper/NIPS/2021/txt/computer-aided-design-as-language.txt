Abstract
Computer-Aided Design (CAD) applications are used in manufacturing to model everything from coffee mugs to sports cars. These programs are complex and require years of training and experience to master. A component of all CAD models particularly difﬁcult to make are the highly structured 2D sketches that lie at the heart of every 3D construction. In this work, we propose a machine learning model capable of automatically generating such sketches. Through this, we pave the way for developing intelligent tools that would help engineers create better designs with less effort. The core of our method is a combination of a general-purpose language modeling technique alongside an off-the-shelf data serialization protocol. Additionally, we explore several extensions allowing us to gain ﬁner control over the generation process. We show that our approach has enough
ﬂexibility to accommodate the complexity of the domain and performs well for both unconditional synthesis and image-to-sketch translation. 1

Introduction coincident mirror
Computer-Aided Design (CAD) is used in the produc-tion of most manufactured objects: from cars to robots to stents to power plants. CAD has replaced pencil drawings with precise computer sketches, enabling un-paralleled precision, ﬂexibility, and speed. Despite these improvements the CAD engineer must still de-velop, relate and annotate all the minutiae of their de-signs with the same attention to detail as their drafting-table forebears. CAD productivity might be improved by the careful application of machine learning to auto-mate predictable design tasks and free the engineer to focus on the bigger picture. The ﬂexibility and power of deep learning is uniquely suited to the complexity of design.
Sketches are at the heart of mechanical CAD. They are the skeleton from which three dimensional forms are made. A sketch consists of various geometric entities (e.g., lines, arcs, splines and circles) related by speciﬁc constraints such as tangency, perpendicularity and sym-metry. Figure 1 illustrates how entities and constraints work in tandem to create well-deﬁned shapes. Geo-metric entities lie on a single plane and together form enclosed regions used by subsequent construction oper-ations such as lofts and extrusions to generate complex
∗Correspondence to: ganin@deepmind.com. orthogonal tangent
Figure 1: The anatomy of a CAD sketch.
Sketches are the main building block of ev-ery 3D construction. A sketch consists of entities (e.g., lines and arcs) and constraints (e.g., tangent and mirror). The dotted curve shows what happens if we drop some of the constraints — the design idea is lost. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
Interpreter states line.end.x line.end.y (0, 0.6, False)
Transformer [33] + Pointer Net [35]
. . .
. . . line.start.y: • line.end.x: 0.6
. . .
. . .
. . .
Tokens tangent
Figure 2: Interpreter-guided generation of a sketch. At each point in time, a Transformer [33] outputs a raw value which is fed into an interpreter that decides which ﬁeld of a Protocol Buffers
) its message this value corresponds to. Once the ﬁeld is populated the interpreter communicates ( decision back to the Transformer and transitions (
) to the next state. 3D geometry. Well-chosen sketch constraints are essential to properly convey design intent [2] and facilitate the sketch’s resilience to successive parameters modiﬁcations which is often understood as a measure of the quality of a design document [8]. The dotted curve in Figure 1 shows what happens when some of the constraints are dropped – the design idea is lost.
The complexities of sketch construction are analogous to those of natural language modeling. Select-ing the next constraint or entity in a sketch is like the generation of the next word in a sentence. In both contexts, the selection must function grammatically (form a consistent constraint system in the case of the sketch) and work towards some cohesive meaning (preserve design intent). Luckily, machine learning has proved highly successful in generating natural language — especially the Transformer
[33] trained on vast amounts of real-world data [26, 6]. It is therefore a promising choice for adapting to the task of sketch generation. This work is our take at this adaptation.
We make the following contributions: (1) We devise a method for describing structured objects using
Protocol Buffers [32] and demonstrate its ﬂexibility on the domain of natural CAD sketches. (2) We propose several techniques for capturing distributions of objects represented as serialized Protocol
Buffers. Our approach draws inspiration from recent advances in language modeling while focusing on eliminating data redundancy. (3) We collect a dataset of over 4.7M of carefully preprocessed parametric CAD sketches and use this dataset to validate the proposed generative models. To our knowledge, the experiments presented in this work signiﬁcantly surpass the scale of those reported in the literature both in terms of the amount of training data and the model capacity. 2