Abstract
The accuracy of simulation-based forecasting in chaotic systems is heavily de-pendent on high-quality estimates of the system state at the time the forecast is initialized. Data assimilation methods are used to infer these initial conditions by systematically combining noisy, incomplete observations and numerical models of system dynamics to produce effective estimation schemes. We introduce amortized assimilation, a framework for learning to assimilate in dynamical systems from sequences of noisy observations with no need for ground truth data. We motivate the framework by extending powerful results from self-supervised denoising to the dynamical systems setting through the use of differentiable simulation. Experimen-tal results across several benchmark systems highlight the improved effectiveness of our approach over widely-used data assimilation methods. 1

Introduction
Forecasting in the geosciences is an initial value problem of enormous practical signiﬁcance. In high value domains like numerical weather prediction [1], climate modeling [2], atmospheric chemistry
[3], seismology [4], and others [5–7], forecasts are produced by estimating the current state of the dynamical system of interest and integrating that state forward in time using numerical models based on the discretization of differential equations. These numerical models are derived from physical principles and possess desirable extrapolation and convergence properties. Yet despite the efﬁcacy of these models and the vast amount of compute power used in generating these forecasts, obtaining highly accurate predictions is non-trivial. Discretization introduces numerical errors and it is often too computationally expensive to directly simulate the system of interest at the resolution necessary to capture all relevant features.
Further complicating matters in geoscience applications is that many systems of interest are chaotic, meaning that small errors in the initial condition estimates can lead to signiﬁcant forecasting errors over relatively small time frame [8]. This can be problematic when the initial condition for a forecast is current state of the Earth, a large-scale actively evolving system that cannot be directly controlled.
Modern numerical weather prediction (NWP) models utilize hundreds of millions of state variables scattered over a three-dimensional discretization of the Earth’s atmosphere [9]. To perfectly initialize a simulation, one would need to know the true value of all of these state variables simultaneously.
This data is simply not available. In reality, what is available are noisy, partial measurements scattered non-uniformly in time and space.
The inverse problem of estimating the true state of a dynamical system from imperfect observations is the target of our work and of the broader ﬁeld known as data assimilation. Data assimilation techniques produce state estimates by systematically combining noisy observations with the numerical model [10, 9]. The data assimilation problem differs from other state estimation problems in that the numerical model acts both as an evolution equation and as a mechanism for transporting information from regions where observations are dense to regions where observations are sparse [11]. Thus for accurate estimates of the full system state, it is important to utilize both the model and observations. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
One recent trend in deep learning research has been the push to develop neural network models to replace expensive, oft repeated processes. This incurs a large upfront cost to train the network in exchange for a faster solution to subsequent iterations of the problem. These amortized methods were initially developed for statistical inference [12] but have also been used in the context of numerical simulation [13], and meta-learning [14]. Our work extends this approach to variational data assimilation [15].
In this work, we introduce a self-supervised framework for learning to assimilate which we call amortized assimilation. Here, we use the term self-supervised to indicate that our method learns to assimilate entirely from trajectories of noisy observations without the use of ground truth data during training. Our design incorporates the objective ﬂexibility of variational assimilation but amortizes the expense of solving the nonlinear optimization problem inherent to variational methods into the training of a neural network that then behaves as a sequential ﬁlter.
Our contributions are both theoretical and empirical. In Section 3.1, we introduce an amortized assimilation architecture based on the Ensemble Kalman Filter [16]. We then develop the theory of amortized assimilation in Section 3.2 by extending the powerful self-supervised denoising results of
Batson and Royer [17] to the dynamical systems setting through the use of differentiable simulation.
We then support this theory through a set of numerical experiments1 in Section 5, where we see that amortized assimilation methods match or outperform conventional approaches across several benchmark systems with especially strong performance at smaller ensemble sizes. 2 Preliminaries
Problem Setting
In this work, we consider a dy-namical system with state variable x(t) ∈ C ⊂ Rd where C is a compact subset of Rd and system dy-namics deﬁned by the differential equation: dx dt
= g(x(t)) (1) with g as a time-invariant, Lipschitz continuous map from Rd → Rd. The state is observed at a sequence of K discrete time points {τ0, τ1, . . . , τK} generating the time-series y0:K = {y0, y1, . . . , yK} where 0 ≤ k ≤ K is an index corresponding to the time point
τk. These observations are imperfect representations of the system states x0:K = {x0, x1, . . . xK} generated from observation operators of the form:
Figure 1: Observations are assumed to be generated from a Hidden Markov Model. yk = Hk(xk) + ηk (2) where Hk is an arbitrary potentially nonlinear function and ηk ∼ N (0, σ2 kI). This noise model is often referred to as a Hidden Markov Model (Figure 1). In the classical assimilation setting, the observation operators are assumed to be known a priori though our proposed method is capable of learning a subset of observation operators. For a problem like numerical weather prediction, these operators may represent measurements taken of certain atmospheric quantities at a particular measurement location.
Data assimilation is then the inverse problem of estimating the true trajectory x0:K from our noisy observations y0:K and our model of the system evolution: x(τk+1) = Mk:k+1(x(τk)) = x(τk) + (cid:90) τk+1
τk g(x(t)) dt. (3)
Sequential Filtering
In the absence of ground truth, it is practical to present data assimilation from a statistical perspective. In particular, the quantity of interest that we are concerned with in this paper is the ﬁltering distribution p(xk | y0:k). Efﬁcient algorithms for estimating the ﬁltering distribution 1Code available at https://github.com/mikemccabe210/amortizedassimilation. 2
Figure 2: Ensemble ﬁlters model the time-evolution of uncertainty under nonlinear dynamics by maintaining a set of samples from the state distribution and simulating their trajectories forward in time. Observations are then used to reﬁne these forecast estimates in what is called the analysis step. are derived from exploiting dependence relationships in the generative model to produce the two step cycle:
Forecast:
Analysis: p(xk | y0:k−1) = (cid:90)
Rd p(xk | xk−1) dxk−1 p(xk | y0:k) ∝ p(yk | xk)p(xk | y0:k−1) (4a) (4b)
When evaluating data assimilation methods, the objective function is often evaluated with respect to the “analysis” estimates as these act as these are the initial conditions used for the next forecast phase. In subsequent sections, we will use xf k to refer to forecast and analysis estimates of xk respectively. k and xa
In the case of linear dynamics with Gaussian uncertainties, the Kalman ﬁlter [18] provides both the forecast and analysis distributions exactly in closed form. However, the general case is signiﬁcantly more complicated. Under nonlinear dynamics, computing the forecast distribution requires the solution of the Fokker-Planck partial differential equation [19]. While ﬁnding an exact solution to these equations is computationally infeasible, one can produce what is called an ensemble estimate of the forecast distribution using Sequential Monte Carlo methods [20].
Ensemble ﬁlters (Figure 2) replace an exact representation of the uncertainty over states with an empirical approximation in the form of a small number of samples called particles or ensemble members. The forecast distribution can then be estimated by integrating the dynamics forward in time for each ensemble member independently. Allowing for full generality leads to particle ﬁlter approaches while enforcing Gaussian assumptions leads to the Ensemble Kalman ﬁlter (EnKF) [16].
The former is rarely used in data assimilation settings as particle ﬁlters can become degenerate in high dimensions [21] while the latter has been quite successful in practice. Like the classical Kalman
ﬁlter, the EnKF assumes that both the state distribution and observation likelihoods are Gaussian.
The latter is often reasonable, but the former is a rather strong assumption under nonlinear dynamics.
Ensemble methods possess an inherent trade-off in that larger ensembles more accurately model uncertainty, but each ensemble member requires independently integrating the dynamics forward in time which can be signiﬁcantly more expensive than the assimilation step itself. Bayesian ﬁlters rely on robust covariance estimates to maintain stability which can be difﬁcult to obtain when using a small ensemble. Heuristics such as covariance inﬂation [22] and localization [23] have been developed to improve stability at smaller ensemble sizes, but there remains value in developing methods that improve upon the accuracy of these approaches.
Variational Assimilation The alternative to sequential ﬁlters is variational assimilation. Variational assimilation methods, like 4D-Var [24], directly solve for the initial conditions of a system by ﬁnding the state x0 which minimizes the negative log posterior density through nonlinear optimization. This is expensive, but gradient-based optimization utilizing the adjoint of the numerical model avoids the persistent Gaussian state assumptions necessary for tractable Bayesian ﬁlters. Furthermore, these 3
Figure 3: The AmEnF replaces the analysis step of a conventional ensemble ﬁlter with a neural network trained using historical data. The model uses an augmented state which includes both standard inputs as well as recurrent memory. methods can be augmented by auxiliary objectives promoting concordance with physical properties like conservation laws. 3 Amortized Assimilation 3.1 Amortized Ensemble Filters
Our proposed approach attempts to combine the ﬂexibility of variational methods with the efﬁciency of sequential ﬁlters by training a neural network to act as an analysis update mechanism. Before diving into the theory, we present the general amortized assimilation framework from the perspective of a speciﬁc architecture which we call the Amortized Ensemble Filter (AmEnF). The AmEnF (Figure 3) replaces the EnKF analysis equations with a parameterized function in the form of a neural network whose weights are optimized for a speciﬁc dynamical system during training. By unrolling a ﬁxed number of assimilation cycles as ﬁrst proposed in Haarnoja et al. [25], the AmEnF can be trained efﬁciently using backpropagation through time [26]. The loss used for this training will be discussed in more detail in Section 3.2.
One advantage of decoupling from the statistical model in this way is that it allows us to incorporate more information into our analysis process. Like the EnKF, the analysis ensemble members are computed using the forecast values xf i,k for each ensemble member i ∈ [m] with m denoting the number of ensemble members, the ensemble covariance P f k , and the observations yk. However, we augment these features with the dynamics g(xf i,k) and coordinate-wise recurrent memory ci,k−1 resulting in the following update equations: xf i,k = Mk−1:k(xa i,k, P f zxi, zci = fL(xf i,k−1) k , yk, g(xf i,k), ci,k−1) k = Cov({xf
P f i,k}m i,k, P f k=1) k , yk, g(xf
λxi, λci = fN (xf i,k), ci,k−1) (5) i,k = λxi (cid:12) xf xa i,k + zxi ci,k = λci (cid:12) ci,k−1 + zci where fL and fN are neural networks with linear and sigmoid ﬁnal activations respectively. We implement these as a single network which is split only at the ﬁnal layer. We observed notable gains to training stability through the inclusion of this sigmoid-gated ﬁnal layer. For scalability, we do not use the full covariance matrix as an input to the model. Rather, we include local covariance entries as additional feature channels where each channel represents the covariance with the state value at a ﬁxed relative spatial position. For instance in a 1D system, the relative covariance channels may contain the variance at the given point and the covariances with the points to the left and right.
The inclusion of recurrent memory may seem out of place when the dynamics are assumed to be
Markovian. However, while the dynamics themselves are Markovian, the data assimilation process is not. The inclusion of memory allows the model to learn from the past without explicitly including previous states and observations. This is a signiﬁcant beneﬁt in practice. The other non-standard inclusion, the local dynamics, led to a small performance boost as well. As our method is not reliant on generative models of the inputs, additional features could be added trivially. 4
3.2 Self-Supervised Assimilation
The major obstacle to training an assimilation model is the lack of ground truth data. In this section, we derive theoretical motivation for the self-supervised training procedure that lies at the heart of amortized assimilation. Recent work in image denoising has shown that self-supervised methods are a promising alternative to denoising methods with explicit noise models. Lehtinen et al. [27] initially demonstrated the ability to denoise images without clean ground truth images by using multiple noise samples. Batson and Royer [17] expanded this idea to the more general J -invariance framework which exploits independence assumptions between noise in different partitions of the state vector to derive a valuable decomposition of the denoising loss. Techniques developed using this approach have exhibited comparable performance to explicitly supervised denoising across multiple applications [28–30]. In our work, we extend this approach to the dynamical systems setting using differentiable simulation. As we do not need the full generality of the J -invariance framework to derive our results, we begin by restricting Proposition 1 from Batson and Royer [17] to our setting.
Lemma 1 (Noise2Self – Restricted). Suppose concatenated noisy observation vector y = [yk; yk+1] is an unbiased estimator of concatenated state vector x = [xk; xk+1] and that the noise in yk is independent from the noise in yk+1. Now let z = f (y) = [zk; zk+1]. If f is a function such that zk+1 does not depend on the value of yk+1 then:
Ey(cid:107)f (y)k+1 − yk+1(cid:107)2= Ey[(cid:107)f (y)k+1 − xk+1(cid:107)2+(cid:107)yk+1 − xk+1(cid:107)2] (6)
While the proof of this lemma can be found in the supplementary materials (C.1), the main takeaway is that if we are able to deﬁne a search space for our denoising function such that all f in the space have the stated independence property, then the expected self-supervised denoising loss can be decomposed into the expected supervised loss and the noise variance. As the noise variance term is irreducible, this decomposition implies that minimizing the expected self-supervised loss is equivalent to minimizing the expected supervised loss.
Moving back over to data assimilation, our ultimate goal is to train a neural network to act as our denoising agent. Letting fθ denote a neural network parameterized by weights θ, we can formalize the objective that we’d actually like to minimize as the supervised analysis loss:
La(θ) = 1
K − 1
K−1 (cid:88) k=1 (cid:13) (cid:18) 1 (cid:13) (cid:13) m (cid:13) m (cid:88) i=1 fθ(xf i,k, P f k , yk, g(xf i,k), ci,k−1) (cid:19)
− xk (cid:13) 2 (cid:13) (cid:13) (cid:13)
. (7)
This supervised loss reﬂects that our goal is to produce the best initial condition estimates at the start of a forecast window. Unfortunately, xk is unknown so this objective cannot be used to train a denoising model. In the amortized assimilation framework, we instead minimize what we call the self-supervised forecast loss:
Lssf (θ) = 1
K − 1
K−1 (cid:88) k=1 (cid:13) (cid:18) 1 (cid:13) (cid:13) m (cid:13) m (cid:88) i=1
Hk+1(Mk:k+1 ◦ fθ(xf i,k, ·) (cid:19)
− yk+1 (cid:13) 2 (cid:13) (cid:13) (cid:13)
. (8)
The self-supervised approach (Figure 4) has the obvious advantage that it uses readily available noisy observations as the training target. However, we can also show that it is theoretically well-motivated under Lemma 1. Differentiable simulation acts as a bridge between our denoised estimate and future observations which are assumed to have independently sampled noise under the generative model described in Section 2. While Lemma 1 is stated in terms of one step ahead forecasting, similar to prior work [31], we observe signiﬁcantly improved performance by unrolling the procedure over multiple steps.
The power of this approach lies in the fact that the forecast objective can actually be used to bound the analysis objective so that minimizing the forecast objective is equivalent to minimmizing an upper bound on the analysis objective. To show this, apart from the previously speciﬁed generative model assumptions, we rely on two additional assumptions:
Assumption 1 (Uniqueness of Initial Value Problem (IVP) Solution). The autonomous system evolution equation x(cid:48)(t) = g(x(t)) is deterministic and L-Lipschitz continuous in x thus admitting a unique solution to the initial value problem under the Picard-Lindelöf theorem [32].
Assumption 2 (Unbiased Observation Operators). For all observation operators Hk, the observation yk is an unbiased estimator of some subset of xk, ie. if xS k is the restriction of xk to some subset of features S then E[yk | xS k ] = xS k . 5
Figure 4: The self-supervised training process is unrolled across multiple ﬁltering steps. Loss is evaluated between “pseudo-observations” and noisy observations obtained from the system.
We also deﬁne an additional loss, the supervised forecast loss Lf as the mean squared error between the forecast state and the true state. For the purposes of our analysis, we’ll assume that S is the full state such that E[yk | xk] = xk though this will not be the case in our numerical experiments. Our
ﬁrst result focuses on the case where the supervised loss is driven to zero.
Proposition 1 (Zero Loss Regime). Under the stated assumptions, let fθ denote a family of functions parameterized by θ for which min θ Lf (θ) = 0. For any θ which achieves this minimum, it is also true that La(θ) = 0 and that θ is in set of minimizers of Ey0:K [Lssf (θ)].
The proof can be found in the supplementary materials (C.2). This case provides important motivation by showing that if a perfect denoiser exists and is contained within our search space then it is also in the set of minimizers for our expected self-supervised objective. This does not necessarily mean that such a function will be discovered as the objective is non-convex and in practice, we’re minimizing the self-supervised loss over a ﬁnite sample rather than over the expectation of the noise distribution.
For the more general case, with sufﬁciently smooth dynamics, one might expect that over short time horizons, a function which minimizes the forecast loss should perform well for the analysis loss, this is not guaranteed and depends on the properties of the system under study. For our bound, we only consider the supervised losses as per the decomposition in Lemma 1, minimizing the expected self-supervised forecast loss is equivalent to minimizing the expected supervised forecast loss.
Proposition 2 (Non-zero Loss Regime). Under the previously stated assumptions, the supervised analysis loss can be bounded by the supervised forecast loss as: 1
K − 1
K−1 (cid:88) k=1 (cid:13) (cid:18) 1 (cid:13) (cid:13) m (cid:13) m (cid:88) i=1 (cid:19) fθ(·))
− xk (cid:13) (cid:13) (cid:13) (cid:13)
≤ eL(τk+1−τk)
K − 1
K−1 (cid:88) k=1 max i∈[m] (cid:13) (cid:13)
Mk:k+1 ◦ fθ(xf (cid:13) (cid:13) i,k, ·) − xk (cid:13) (cid:13) (cid:13) (cid:13) (9)
The proof (found in C.3) simply uses the Lipschitz coefﬁcient to bound the system Lyapunov exponents which govern the evolution of perturbations. While the tightness of the bound is system speciﬁc, large Lyapunov exponents can be offset by more frequent assimilation cycles. In Section 5, our numerical results suggest that training under this loss is effective in practice for a number of common test systems designed to simulate real-world phenomena. 3.3
Implementation Details
Avoiding Ensemble Collapse Ensemble-based uncertainty estimates are an elegant solution to the problem of computing the evolution of uncertainty under nonlinear dynamics, but without assumptions on the noise model, evaluating the analysis uncertainty is non-trivial. A well-known problem in deep learning-based uncertainty quantiﬁcation is feature collapse [33, 34], a phenomenon in which the hidden representations resulting from regions of the input space are pushed arbitrarily closely together by the neural network. In our ensemble-based uncertainty quantiﬁcation scheme, this poses an issue as ensemble members can quickly converge over a small number of assimilation steps resulting in ensemble collapse.
We address this by combining ensemble estimation with MC Dropout [35] which interprets a pass through a dropout-regularized neural network as a sample from a variational distribution over network weights. Thus, for standard usage of MC Dropout one can estimate uncertainty in the predictive 6
(a) Mean ensemble spread over as-similation cycles (b) Ensemble trajectories with ob-servation noise σ = 1.0 (c) Ensemble trajectories with obser-vation noise σ = 2.5
Figure 5: MC Dropout introduces an additional stochastic element that stabilizes the ensemble resulting in realistic relationships between the ensemble spread and system uncertainty. distribution by using multiple dropout passes to integrate out weight uncertainty. In our case, we further have to account for uncertainty over the input distribution which is represented by our forecast ensemble. We employ a relatively simple Monte Carlo scheme in which the forecast ensemble members are assimilated by a single pass through a dropout-regularized network with independent dropout masks giving us m samples from the predictive distribution as our analysis ensemble. While this is a crude approximation, we found it resulted in more consistent performance with less tuning compared to the sensitivity constraints found in recent uncertainty quantiﬁcation methods [33, 36, 37].
Incomplete Observations One important concern in data assimilation is handling a variety of observation operators as the full state will rarely be observed at one time point. We discuss two processes for addressing this in amortized ﬁlters. The ﬁrst, which is far more ﬂexible but less effective at exploiting prior knowledge, is to initialize an network with independent weights corresponding to each observation type. This can be used with any observation type, even ones with unknown relationships to the system state. These unknown observation operators can be trained by evaluating the loss at points with future, known observation operators and passing the gradient signal back in time through the differentiable simulation connecting the time points.
The second, which we implement in the AmEnF, is to use our knowledge of the spatial distribution of the observation operators to assign the observed values corresponding to certain locations as channels in the input representation. Coordinates which are not observed can be masked and an additional channel is appending indicating whether a particular coordinate was observed during the given assimilation cycle. This is depicted by the shading in the observation channels of Figure 3.
More details on the masking process can be found in the supplementary material. 4