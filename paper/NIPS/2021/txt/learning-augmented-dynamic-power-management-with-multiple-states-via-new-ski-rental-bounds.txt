Abstract
We study the online problem of minimizing power consumption in systems with multiple power-saving states. During idle periods of unknown lengths, an algorithm has to choose between power-saving states of different energy consumption and wake-up costs. We develop a learning-augmented online algorithm that makes decisions based on (potentially inaccurate) predicted lengths of the idle periods.
The algorithmâ€™s performance is near-optimal when predictions are accurate and degrades gracefully with increasing prediction error, with a worst-case guarantee almost identical to the optimal classical online algorithm for the problem. A key ingredient in our approach is a new algorithm for the online ski rental problem in the learning augmented setting with tight dependence on the prediction error. We support our theoretical ï¬ndings with experiments. 1

Introduction
Energy represents up to 70% of total operating costs of modern data centers [41] and is one of the major quality-of-service parameters in battery-operated devices. In order to ameliorate this, contemporary CPUs are equipped with sleep states to which the processor can transition during periods of inactivity. In particular, the ACPI-standard [25] speciï¬es that each processor should possess, along with the active state ğ¶0 that is used for processing tasks, at least one sleep state ğ¶1.
Modern processors generally possess more sleep states ğ¶2, . . . ; for example, current Intel CPUs implement at least 4 such ğ¶-states [19]. Apart from CPUs, such sleep states appear in many systems ranging from hard drives or mobile devices to the start-stop feature found in many cars, and are furthermore often employed when rightsizing data centers [2].
Intuitively, in a â€œdeeperâ€ sleep state, the set of switched-off components will be a superset of the corresponding set in a more shallow sleep state. This implies that the running cost for residing in that deeper state will be lower, but the wake-up cost to return to the active state ğ¶0 will be higher compared to a more shallow sleep state. In other words, there is a tradeoff between the running and the wake-up cost. During each idle period, a dynamic power management (DPM) strategy has to decide in which state the system resides at each point in time, without a-priori knowledge about the duration of the idle period. Optimally managing these sleep states is a challenging problem due to its online nature. On the one hand, transitioning the system to a too deep state could be highly suboptimal if the idle period ends shortly after. On the other hand, spending too much idle time in a shallow state would accumulate high running costs. The impact of DPM strategies in practice 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
has been studied for instance in data centers, where each machine may be put to a sleep mode if no request is expected. See the study of Lim et al. [34] on multi-tier data centers.
The special case of 2-state DPM systems, i.e., when there is only a single sleep state (besides the active state), is essentially equivalent to the ski rental problem, one of the most classical problems and of central importance in the area of online optimization [39; 26]. This problem is deï¬ned as follows: A person goes skiing for an unknown number of days. On every day of skiing, the person must decide whether to continue renting skis for one more day or to buy skis. Once skis are bought there will be no more cost on the following days, but the cost of buying is much higher than the cost of renting for a day. It is easy to see that this captures a single idle period of DPM with a single sleep state whose running cost is 0: The rental cost corresponds to the running cost of the active state and the cost of buying skis corresponds to the wake-up cost; transitioning to the sleep state corresponds to buying skis. Given this equivalence, the known 2-competitive deterministic algorithm and ğ‘’/(ğ‘’ âˆ’ 1) â‰ˆ 1.58-competitive randomized algorithm for ski rental carry over to 2-state DPM, and these competitive ratios are tight. In fact, it was shown by Irani et al. [28] and Lotker et al. [36] that the same competitive ratios carry over even to multi-state DPM. Ski rental, also known as rent-or-buy problem, is a fundamental problem appearing in many domains not restricted to computer hardware questions. For the AI community, this problem for example implicitly appears in expert learning with switching costs: paying the price to switch to a better expert allows to save expenses in the future.
Beyond these results for the classical online setting, [28] also gave a deterministic ğ‘’/(ğ‘’ âˆ’ 1)-competitive algorithm for the case in which the length of the idle periods is repeatedly drawn from a
ï¬xed, and known, probability distribution. When the probability distribution is ï¬xed but unknown they developed an algorithm that learns the distribution over time and showed that it performs well in practice. Although it is perhaps not always reasonable to assume a ï¬xed underlying probability distribution for the length of idle periods, real-life systems do often follow periodical patterns so that these lengths can indeed be frequently predicted with adequate accuracy, see Chung et al. [18] for a speciï¬c example. Nevertheless, it is not hard to see that blindly following such predictions can lead to arbitrarily bad performance when predictions are faulty. The ï¬eld of learning-augmented algorithms [38] is concerned with algorithms that incorporate predictions in a robust way.
In this work, we introduce multi-state DPM to the learning-augmented setting. Extending ideas of [28] and [36], we give a reduction from multi-state DPM to ski rental that is applicable to the learning-augmented setting. Although ski rental has been investigated through the learning-augmented algorithms lens before [40; 44], earlier work has focused on the optimal trade-off between consistency (i.e., the performance when predictions are accurate) and robustness (i.e., the worst-case performance). To apply our reduction from DPM to ski rental, we require more reï¬ned guarantees for learning-augmented ski rental. To this end we develop a new learning-augmented algorithm for ski rental that obtains the optimal trade-off between consistency and dependence on the prediction error. Our resulting algorithm for DPM achieves a competitive ratio arbitrarily close to 1 in case of perfect predictions and its performance degrades gracefully to a competitive ratio arbitrarily close to the optimal robustness of ğ‘’/(ğ‘’ âˆ’ 1) â‰ˆ 1.58 as the prediction error increases.
Potential negative societal impact. This is a work of theoretical nature and we are not aware of potential negative societal impact. That said, we cannot rule out future misuse of the contained theoretical knowledge. 1.1 Formal deï¬nitions
In the problem of dynamic power management (DPM), we are given ğ‘˜ + 1
Problem deï¬nition. power states denoted by 0, 1, . . . , ğ‘˜, with power consumptions ğ›¼0 > Â· Â· Â· > ğ›¼ğ‘˜ â‰¥ 0 and wake-up costs
ğ›½0 < Â· Â· Â· < ğ›½ğ‘˜ . For state 0, we have ğ›½0 = 0 and we call this the active state. The input is a series of idle periods of lengths â„“1, . . . , â„“ğ‘‡ received online, i.e., the algorithm does not know the length of the current period before it ends. During each period, the algorithm can transition to states with lower and lower power consumption, paying energy cost ğ‘¥ğ›¼ğ‘– for residing in state ğ‘– for time ğ‘¥. If ğ‘— is the state at the end of the idle period, then it has to pay the wake-up cost ğ›½ ğ‘— to transition back to the active state 0. The goal is to minimize the total cost.
In the learning-augmented setting, the algorithm receives at the beginning of the ğ‘–th idle period a prediction ğœğ‘– â‰¥ 0 for the value of â„“ğ‘– as additional input. We deï¬ne ğœ‚ğ‘– := ğ›¼0|ğœğ‘– âˆ’ â„“ğ‘– | to be the error of the ğ‘–th prediction, and ğœ‚ := (cid:205)ğ‘‡
ğ‘– ğœ‚ğ‘– to be the total prediction error. 2
(Continuous-time) ski rental is the special case of DPM with ğ‘˜ = 1, ğ›¼1 = 0 and a single idle period of some length â„“. In this case, we call ğ›¼ := ğ›¼0 the rental cost, ğ›½ := ğ›½1 the buying cost, and â„“ the length of the ski season. In learning-augmented ski rental, we write the single prediction as ğœ := ğœ1. (ğœŒ, ğœ‡) (ğœŒ, ğœ‡) (ğœŒ, ğœ‡)-competitiveness. Classical online algorithms are typically analyzed in terms of competitive ratio. A (randomized) algorithm A for an online minimization problem is said to be ğœŒ-competitive (or alternatively, obtain a competitive ratio of ğœŒ) if for any input instance, cost(A) â‰¤ ğœŒ Â· OPT + ğ‘, (1) where cost(A) and OPT denote the (expected) cost of A and the optimal cost of the instance and ğ‘ is a constant independent of the online part of the input (i.e., the lengths â„“ğ‘– in case of DPM). For the ski rental problem one requires ğ‘ = 0, since the trivial algorithm that buys at time 0 has constant cost ğ›½.
In the learning-augmented setting, for ğœŒ â‰¥ 1 and ğœ‡ â‰¥ 0, we say that A is (ğœŒ, ğœ‡)-competitive if cost(A) â‰¤ ğœŒ Â· OPT + ğœ‡ Â· ğœ‚ (2) for any instance, where ğœ‚ is the prediction error. This corresponds to a competitive ratio of ğœŒ + ğœ‡ ğœ‚
OPT (with ğ‘ = 0). While this could be unbounded as ğœ‚/ğ‘‚ğ‘ƒğ‘‡ â†’ âˆ, our DPM algorithm achieves a favorable competitive ratio even in this case (see Theorem 5, where we take the minimum over a range of pairs (ğœŒ, ğœ‡), including ğœ‡ = 0).
For a (ğœŒ, ğœ‡)-competitive algorithm, ğœŒ is also called the consistency (i.e., competitive ratio in case of perfect predictions) while ğœ‡ describes the dependence on the prediction error. 1.2 Our results
Our ï¬rst result is a (ğœŒ, ğœ‡)-competitive algorithm for ski rental that achieves the optimal ğœ‡ correspond-ing to the given ğœŒ. For ğœŒ âˆˆ [1, ğ‘’
ğ‘’âˆ’1 ], let (cid:27)
ğœ‡(ğœŒ) := max
, ğœŒ(1 âˆ’ ğ‘‡)ğ‘’âˆ’ğ‘‡ (cid:26) 1 âˆ’ ğœŒ ğ‘’âˆ’1
ğ‘’ ln 2 where ğ‘‡ âˆˆ [0, 1] is the solution to ğ‘‡ 2ğ‘’âˆ’ğ‘‡ = 1 âˆ’ 1
ğœŒ . Let ËœğœŒ â‰ˆ 1.16 be the value of ğœŒ for which both terms in the maximum yield the same value. The ï¬rst term dominates for ğœŒ > ËœğœŒ and the second term if ğœŒ < ËœğœŒ. Note that ğœ‡(1) = 1 and ğœ‡ (cid:0) ğ‘’
ğ‘’âˆ’1
Theorem 1. For any ğœŒ âˆˆ [1, ğ‘’
ğ‘’âˆ’1 ], there is a (ğœŒ, ğœ‡(ğœŒ))-competitive randomized algorithm for learning-augmented ski rental, i.e., given a prediction with error ğœ‚, its expected cost is at most
ğœŒ OPT +ğœ‡(ğœŒ) Â· ğœ‚. (cid:1) = 0. See Figure 1 (left) for an illustration. (3)
,
ğ‘’âˆ’1 already achieves the best possible value of ğœ‡ = 0.
Note that ğœŒ < 1 is impossible for any algorithm (due to the case ğœ‚ = 0) and ğœŒ > ğ‘’ since ğœŒ = ğ‘’
We also prove a lower bound showing that ğœ‡(ğœŒ) deï¬ned in (3) is the best possible.
Theorem 2. For any ğœŒ âˆˆ [1, ğ‘’ with some prediction error ğœ‚ such that the expected cost of A is at least ğœŒ OPT +ğœ‡(ğœŒ)ğœ‚.
ğ‘’âˆ’1 ] and any (randomized) algorithm A, there is a ski rental instance
ğ‘’âˆ’1 is uninteresting
However, for most values of the prediction ğœ it is possible to achieve a better ğœ‡ < ğœ‡(ğœŒ), and ğœ‡(ğœŒ) only captures the worst case over all possible predictions ğœ. The proof of Theorem 1 is sketched in Section 2. The complete proofs of Theorems 1 and 2 are provided in the full version [8] in the supplementary material.
In Section 3, we give a reduction from DPM to ski rental in the learning-augmented setting, provided that the ski rental algorithm satisï¬es a natural monotonicity property (deï¬ned formally in Section 3):
Lemma 3. If there is a monotone (ğœŒ, ğœ‡)-competitive ski rental algorithm, then there is a (ğœŒ, ğœ‡)-competitive algorithm for DPM.
Since our ski rental algorithm is monotone, this directly yields a (ğœŒ, ğœ‡(ğœŒ))-competitive algorithm for
DPM. From the special case (ğœŒ, ğœ‡) = (cid:0) ğ‘’
, 0(cid:1), this theorem directly implies the following result for
ğ‘’âˆ’1 classical DPM (without predictions), which was ï¬rst proved by Lotker et al. [36] for the equivalent multi-slope ski rental problem: 3
Figure 1: Illustration of ğœ‡(ğœŒ) and of the resulting competitive ratio in function of ğœ‚/OPT.
Corollary 4 ([36]). There is a ğ‘’ predictions).
ğ‘’âˆ’1 -competitive randomized online algorithm for DPM (without
Using techniques from online learning, in a way similar to [5], we show in Section 4 how to achieve
â€œalmostâ€ (ğœŒ, ğœ‡(ğœŒ))-competitiveness simultaneously for all ğœŒ:
Theorem 5. For any ğœ– > 0, there is a learning-augmented algorithm A for dynamic power manage-ment whose expected cost can be bounded as cost(A) â‰¤ (1 + ğœ–) min (cid:8)ğœŒ OPT +ğœ‡(ğœŒ) Â· ğœ‚ (cid:12)
ğ‘’âˆ’1 ](cid:9) + ğ‘‚ (cid:0) ğ›½ğ‘˜
The above theorem gives a competitive ratio arbitrarily close to min{ğœŒ + ğœ‡(ğœŒ) Â·
}, which is equal to 1 if ğœ‚ = 0 and never greater than ğ‘’
ğ‘’âˆ’1 . In particular, we achieve a performance that degrades gracefully from near-optimal consistency to near-optimal robustness as the error increases.1 See
Figure 1 (right) for an illustration.
ğœ– log 1
ğœ–
ğœ‚
OPT (cid:12) ğœŒ âˆˆ [1, ğ‘’ (cid:1).
In Section 5, we illustrate the performance of these algorithms by simulations on synthetic datasets, where the dependence on the prediction error can be observed as expected from theoretical results. 1.3