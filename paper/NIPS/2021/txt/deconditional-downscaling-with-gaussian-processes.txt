Abstract
Reﬁning low-resolution (LR) spatial ﬁelds with high-resolution (HR) information, often known as statistical downscaling, is challenging as the diversity of spatial datasets often prevents direct matching of observations. Yet, when LR samples are modeled as aggregate conditional means of HR samples with respect to a mediating variable that is globally observed, the recovery of the underlying ﬁne-grained
ﬁeld can be framed as taking an “inverse” of the conditional expectation, namely a deconditioning problem. In this work, we propose a Bayesian formulation of deconditioning which naturally recovers the initial reproducing kernel Hilbert space formulation from Hsu and Ramos [1]. We extend deconditioning to a downscaling setup and devise efﬁcient conditional mean embedding estimator for multiresolution data. By treating conditional expectations as inter-domain features of the underlying ﬁeld, a posterior for the latent ﬁeld can be established as a solution to the deconditioning problem. Furthermore, we show that this solution can be viewed as a two-staged vector-valued kernel ridge regressor and show that it has a minimax optimal convergence rate under mild assumptions. Lastly, we demonstrate its proﬁciency in a synthetic and a real-world atmospheric ﬁeld downscaling problem, showing substantial improvements over existing methods. 1

Introduction
Spatial observations often operate at limited resolution due to practical constraints. For example, remote sensing atmosphere products [2, 3, 4, 5] provide measurement of atmospheric properties such as cloud top temperatures and optical thickness, but only at a low resolution. Devising methods to reﬁne low-resolution (LR) variables for local-scale analysis thus plays a crucial part in our understanding of the anthropogenic impact on climate
When high-resolution (HR) observations of different covariates are available, details can be instilled into the LR ﬁeld for reﬁnement. This task is referred to as statistical downscaling or spatial disaggregation and models LR observations as the aggregation of an unobserved underlying HR ﬁeld.
For example, multispectral optical satellite imagery [6, 7] typically comes at higher resolution than atmospheric products and can be used to reﬁne the latter.
Statistical downscaling has been studied in various forms, notably giving it a probabilistic treatment [8, 9, 10, 11, 12, 13], in which Gaussian processes (GP) [14] are typically used in conjunction with a sparse variational formulation [15] to recover the underlying unobserved HR ﬁeld. Our approach follows this line of research where we do not observe data from the underlying HR groundtruth ﬁeld.
On the other hand, deep neural network (DNN) based approaches [16, 17, 18] study this problem from a different setting, where they often assume that both HR and LR matched observations are available for training. Then, their approaches follow a standard supervised learning setting in learning a mapping between different resolutions.
∗Indicates equal contribution
†Department of Statistics, Oxford, UK, OX1 3LB. <siu.chau@stats.ox.ac.uk, shahine.bouabid@stats.ox.ac.uk, dino.sejdinovic@stats.ox.ac.uk> 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
However, both lines of existing methods require access to bags of HR covariates that are paired with aggregated targets, which in practice might be infeasible. For example, the multitude of satellites in orbit not only collect snapshots of the atmosphere at different resolutions, but also from different places and at different times, such that these observations are not jointly observed. To overcome this limitation, we propose to consider a more ﬂexible mediated statistical downscaling setup that only requires indirect matching between LR and HR covariates through a mediating ﬁeld. We assume that this additional ﬁeld can be easily observed, and matched separately with both HR covariates and aggregate LR targets. We then use this third-party ﬁeld to mediate learning and downscale our unmatched data. In our motivating application, climate simulations [19, 20, 21] based on physical science can serve as a mediating ﬁeld since they provide a comprehensive spatiotemporal coverage of meteorological variables that can be matched to both LR and HR covariates.
Formally, let bx = {x(1), . . . , x(n)} ⊂ X be a general notation for bags of HR covariates, f : X → R the ﬁeld of interest we wish to recover and ˜z the LR aggregate observations from the ﬁeld f . We suppose that bx and ˜z are unmatched, but that there exists mediating covariates y, ˜y ∈ Y, such that (bx, y) are jointly observed and likewise for (˜y, ˜z) as illustrated in Figure 1. We assume the following aggregation observation model ˜z = EX [f (X)|Y = ˜y] + ε with some noise ε. Our goal in mediated statistical downscaling is then to estimate f given (bx, y) and (˜y, ˜z), which corresponds to the deconditioning problem introduced in [1].
Motivated by applications in likelihood-free inference and task-transfer regression, Hsu and Ramos [1] ﬁrst studied the decondi-tioning problem through the lens of reproducing kernel Hilbert space (RKHS) and introduced the framework of Deconditional
Mean Embeddings (DME) as its solution.
In this work, we ﬁrst propose a Bayesian formulation of decon-ditioning that results into a much simpler and elegant way to arrive to the DME-based estimator of Hsu and Ramos [1], using the conditional expectations of f . Motivated by our mediated statistical downscaling problem, we then extend deconditioning to a multi-resolution setup and bridge the gap between DMEs and existing probabilistic statistical downscaling methods [9].
By placing a GP prior on the sought ﬁeld f , we obtain a poste-rior distribution of the downscaled ﬁeld as a principled Bayesian solution to the downscaling task on indirectly matched data.
For scalability, we provide a tractable variational inference ap-proximation and an alternative approximation to the conditional mean operator (CMO) [22] to speed up computation for large multi-resolution datasets.
Figure 1: The LR response ˜z (blue) and the bag HR covariates bx (green) are unmatched. The down-scaling is mediated through bag-level LR covariates y and ˜y (or-ange).
From a theoretical stand point, we further develop the frame-work of DMEs by establishing it as a two-staged vector-valued regressor with a natural reconstruction loss that mirrors Grünewälder et al. [23]’s work on conditional mean embeddings. This perspective allows us to leverage distribution regression theory from [24, 25] and obtain convergence rate results for the deconditional mean operator (DMO) estimator. Under mild assumptions, we obtain conditions under which this rate is a minimax optimal in terms of statistical-computational efﬁciency.
Our contributions are summarized as follows:
• We propose a Bayesian formulation of the deconditioning problem of Hsu and Ramos [1].
We establish its posterior mean as a DME-based estimate and its posterior covariance as a gauge of the deconditioning quality.
• We extend deconditioning to a multi-resolution setup in the context of the mediated statistical downscaling problem and bridge the gap with existing probabilistic statistical downscaling methods. Computationally efﬁcient algorithms are devised.
• We demonstrate that the DMO estimate minimises a two-staged vector-valued regression and derive its convergence rate under mild assumptions, with conditions for minimax optimality. 2
• We benchmark our model against existing methods for statistical downscaling tasks in climate science, on both synthetic and real-world multi-resolution atmospheric ﬁelds data, and show improved performance. 2