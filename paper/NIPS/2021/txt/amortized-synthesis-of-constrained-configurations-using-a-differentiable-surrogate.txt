Abstract
In design, fabrication, and control problems, we are often faced with the task of synthesis, in which we must generate an object or conﬁguration that satisﬁes a set of constraints while maximizing one or more objective functions. The synthesis problem is typically characterized by a physical process in which many different realizations may achieve the goal. This many-to-one map presents challenges to the supervised learning of feed-forward synthesis, as the set of viable designs may have a complex structure. In addition, the non-differentiable nature of many physical simulations prevents efﬁcient direct optimization. We address both of these problems with a two-stage neural network architecture that we may consider to be an autoencoder. We ﬁrst learn the decoder: a differentiable surrogate that approximates the many-to-one physical realization process. We then learn the encoder, which maps from goal to design, while using the ﬁxed decoder to evaluate the quality of the realization. We evaluate the approach on two case studies: extruder path planning in additive manufacturing and constrained soft robot inverse kinematics. We compare our approach to direct optimization of the design using the learned surrogate, and to supervised learning of the synthesis problem. We
ﬁnd that our approach produces higher quality solutions than supervised learning, while being competitive in quality with direct optimization, at a greatly reduced computational cost.

Introduction 1
One of the ambitions of artiﬁcial intelligence is to automate problems in design, fabrication, and control that demand efﬁcient and accurate interfaces between machine learning algorithms and physical systems. Whether it is optimizing the topology of a mechanical structure or identifying the feasible paths for a manufacturing robot, we can often view these problems through the lens of synthesis. In a synthesis task, we seek conﬁgurations of a physical system that achieve certain desiderata while satisfying given constraints; i.e., we must optimize a physically-realizable design.
In this work, design refers to the parametric space over which we have control and in which, e.g., we optimize. A realization is the object that arises when the design is instantiated, while goal refers to its desired properties. For example, in fabrication, the design might be a set of assembly steps, the realization would be the resulting object, while the goal could be to match target dimensions while maximizing strength. Synthesis, then, refers to ﬁnding a design whose realization achieves the goal.
Synthesis problems are challenging for several reasons. The physical realization process may be costly and time-consuming, making evaluation of many designs difﬁcult. Moreover, the realization process—or even a simulation of it—is generally not differentiable, rendering efﬁcient gradient-based methods inapplicable. Finally, there may be a many-to-one map from the parametric space of feasible and equally-desirable designs to realizations; i.e., there may be multiple ways to achieve the goal.
Surrogate modeling is widely used to address the ﬁrst two challenges, though it can still be expensive because of the need for optimization, sampling, or search algorithms to ﬁnd a feasible design. More seriously, the third challenge—lack of uniqueness—creates difﬁculties for naïve supervised learning 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
Figure 1: (a) For a ﬁxed and large-enough starting speed, there exist exactly two angles such that the ball will hit the target, where the mean of these two angles is π/4. (b) Some 3D printers utilize ﬁbers to reinforce the thermoplastic print. (c) For such printers, ﬁber is laid out along an extruder path but deforms into a smoothed version due to the ﬁber’s high stiffness and low stretch. Our goal is to generate extruder paths that compensate for the smoothing, but multiple extruder paths can result in the same target shape, such as a square. (d) In soft robot inverse kinematics, we control the stretch ratios of both the left- and right-hand sides of a snake-like robot.
Our goal is to reach the target while avoiding an obstacle but, as is illustrated, the solution is not unique – two different designs are shown. approaches to synthesis. Speciﬁcally, consider generating many design/realization pairs, evaluating the constraints and objectives on the realizations, and attempting to learn a supervised map from goal back to design. When multiple designs lead to the same realization, or multiple realizations achieve the same goal, the supervised learner is penalized for producing designs that are valid but happen to not be the ones used to generate the data. Moreover, this approach may learn to produce an “average” design that is actually incorrect. Figure 1a shows a cartoon example: if the goal is to throw a ball to reach some target distance, there are two possible launch angles (designs) resulting in landing points (realizations) at the correct spot. Performing least-squares regression from distance to angle on the full set of distance/angle pairs, however, learns an average angle that does not satisfy the goal.
To address these challenges, we propose to use a two-stage neural network architecture that resembles an autoencoder. One stage (the decoder) acts as a differentiable surrogate capturing the many-to-one physical realization process. The other stage (the encoder) maps from a goal back to a design but, critically, it is trained end-to-end with a loss in the space of realizations that ﬂows back through the decoder. Thus the encoder—our central object of interest for synthesis—is not constrained to match a speciﬁc design in a training dataset, but instead is tasked with ﬁnding any design that meets the desiderata of the realized output. The result is a neural network that performs amortized synthesis: it is trained once, and at run time produces a design that is approximately optimal, using only a feed-forward architecture. Note that our method is not an autoencoder, as the design is not a lower-dimensional representation of the goal, and the encoder and the decoder are trained in separate stages.
Our method places a number of requirements on the synthesis problem. First, to train the surrogate, we need data pairs of designs and realizations. Commonly, this would require us to generate designs, in which a substantial amount of designs are viable, and simulate them on a simulator. Second, given our current setting, the physical realization process needs to be deterministic. Third, to train the encoder, the synthesis problem should have a clear objective function, or at least we can quantify the objective. Finally, given our current feed-forward setting, we consider synthesis problems that need only one valid design, although we may further extend our method by using a generative encoder.
In this work, we demonstrate this two-stage approach on a pair of speciﬁc design tasks. The ﬁrst case study is extruder path planning for a class of 3D printers (the Markforged Mark Two) that can reinforce polymer layers with discrete ﬁbers (Figure 1b). Since the ﬁbers are stiff, their shape is deformed after extrusion (Figure 1c, top row), and our task is to ﬁnd an extruder path that results in a given ﬁber shape. As shown in Figure 1c, this problem has the many-to-one nature described above: for a small error tolerance on ﬁber path, there exist inﬁnitely many extruder paths, which may even look very different. The second case study is constrained soft robot inverse kinematics.
In this work, we use a simulation of a snake-like soft robot as in Xue et al. [97], in which we can control the stretch ratios of each individual segment on both sides of the robot. The robot has to reach 2
a target while avoiding an obstacle, and the locations of both are input goals. As before, there may be multiple solutions for a given goal (i.e., locations of target and obstacle), as shown in Figure 1d.
For both case studies, we compare to two baseline algorithms. In direct-learning, a neural network for the synthesis problem (i.e., from goal to design) is trained in a supervised manner on a set of designs. Since this effectively averages designs in the training dataset, as argued above, our method outperforms it signiﬁcantly. The second baseline is direct-optimization, which uses a gradient-based method (BFGS) to optimize for each new design separately, given access to the trained differentiable surrogate for the realization process (decoder). Our method is competitive with this rough “performance upper bound” while using dramatically lower computational resources. 2