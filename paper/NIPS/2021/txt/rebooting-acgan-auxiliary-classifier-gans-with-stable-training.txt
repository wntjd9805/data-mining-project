Abstract
Conditional Generative Adversarial Networks (cGAN) generate realistic images by incorporating class information into GAN. While one of the most popular cGANs is an auxiliary classiﬁer GAN with softmax cross-entropy loss (ACGAN), it is widely known that training ACGAN is challenging as the number of classes in the dataset increases. ACGAN also tends to generate easily classiﬁable samples with a lack of diversity. In this paper, we introduce two cures for ACGAN. First, we identify that gradient exploding in the classiﬁer can cause an undesirable collapse in early train-ing, and projecting input vectors onto a unit hypersphere can resolve the problem.
Second, we propose the Data-to-Data Cross-Entropy loss (D2D-CE) to exploit relational information in the class-labeled dataset. On this foundation, we propose the Rebooted Auxiliary Classiﬁer Generative Adversarial Network (ReACGAN).
The experimental results show that ReACGAN achieves state-of-the-art generation results on CIFAR10, Tiny-ImageNet, CUB200, and ImageNet datasets. We also verify that ReACGAN beneﬁts from differentiable augmentations and that D2D-CE harmonizes with StyleGAN2 architecture. Model weights and a software package that provides implementations of representative cGANs and all experiments in our paper are available at https://github.com/POSTECH-CVLab/PyTorch-StudioGAN. 1

Introduction
Generative Adversarial Networks (GAN) [1] are known for the forefront approach to generating high-ﬁdelity images of diverse categories [2, 3, 4, 5, 6, 7, 8, 9]. Behind the sensational generation ability of GANs, there has been tremendous effort to develop adversarial objectives free from the vanishing gradient problem [10, 11, 12], regularizations for stabilizing adversarial training [11, 13, 14, 3, 15, 16, 17], and conditioning techniques to support the adversarial training using category information of the dataset [18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28]. Subsequently, the conditioning techniques have become the de facto standard for high-quality image generation. The models with the conditioning methods are called conditional Generative Adversarial Networks (cGAN), and cGANs can be divided into two groups depending on the discriminator’s conditioning way: classiﬁer-based
GANs [18, 20, 23, 25, 27] and projection-based GANs [19, 3, 4, 28].
The classiﬁer-based GANs facilitate an auxiliary classiﬁer to generate class-speciﬁc images by penalizing the generator if the synthesized images are not consistent with the conditioned labels.
ACGAN [18] has been one of the widely used classiﬁer-based GANs for its simple design and satisfactory generation performance. While ACGAN can exploit class information by pushing and pulling classiﬁer’s weights (proxies) against image embeddings [23], it is well known that
ACGAN training is prone to collapsing at the early stage of training as the number of classes increases [19, 23, 25, 27]. In addition, the generator of ACGAN tends to generate easily classiﬁable images at the cost of reduced diversity [18, 19, 27]. Projection-based GANs, on the other hand, have shown cutting-edge generation results on datasets with a large number of categories. SNGAN [3], 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
Figure 1: Schematics that depict how cGANs perform conditioning. The red color means positive samples/proxy, and the blue color indicates negative samples/proxies. Arrows represent push-pull forces based on the reference sample. The length of an arrow indicates the magnitude of the force.
SAGAN [29], and BigGAN [4] are representatives in this family and can generate realistic images on CIFAR10 [30] and ImageNet [31] datasets. However, projection-based GANs only consider a pairwise relationship between an image and its label proxy (data-to-class relationships). As the result, the projection-based GANs can miss an additional opportunity to consider relation information between data instances (data-to-data relationships) as discovered by [23].
In this paper, we analyze why ACGAN training becomes unstable as the number of classes increases and propose remedies for (1) the instability and (2) the relatively poor generation performance of ACGAN compared with the projection-based models. First, we begin by analytically deriving the gradient of the softmax cross-entropy loss used in ACGAN. By examining the exact values of analytic gradients, we discover that the unboundedness of input feature vectors and poor classiﬁcation performance in the early training stage can cause an undesirable gradient exploding problem. Second, with alleviating the instability, we propose the Rebooted Auxiliary Classiﬁer Generative Adversarial
Networks (ReACGAN) using the Data-to-Data Cross-Entropy loss (D2D-CE). ReACGAN projects image embeddings and proxies onto a unit hypersphere and computes similarities for data-to-data and data-to-class consideration. Additionally, we introduce two margin values for intra-class variations and inter-class separability. In this way, ReACGAN overcomes the training instability and can exploit additional supervisory signals by explicitly considering data-to-class and data-to-data relationships, and also by implicitly looking at class-to-class relationships in the same mini-batch.
To validate our model, we conduct image generation experiments on CIFAR10 [30], Tiny-ImageNet [32], CUB200 [33], and ImageNet [31] datasets. Through extensive experiments, we demonstrate that ReACGAN beats both the classiﬁer-based and projection-based GANs, improving over the state of the art by 2.5%, 15.8%, 5.1%, and 14.5% in terms of Fréchet Inception Dis-tance (FID) [34] on the four datasets, respectively. We also verify that ReACGAN beneﬁts from consistency regularization [16] and differentiable augmentations [9, 8] for limited data training.
Finally, we conﬁrm that D2D-CE harmonizes with the StyleGAN2 architecture [7]. 2