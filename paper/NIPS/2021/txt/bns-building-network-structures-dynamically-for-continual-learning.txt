Abstract
Continual learning (CL) of a sequence of tasks is often accompanied with the catastrophic forgetting (CF) problem. Existing research has achieved remarkable results in overcoming CF, especially for task continual learning. However, limited work has been done to achieve another important goal of CL, knowledge transfer.
In this paper, we propose a technique (called BNS) to do both. The novelty of
BNS is that it dynamically builds a network to learn each new task to overcome
CF and to transfer knowledge across tasks at the same time. Experimental results show that when the tasks are different (with little shared knowledge), BNS can already outperform the state-of-the-art baselines. When the tasks are similar and have shared knowledge, BNS outperforms the baselines substantially by a large margin due to its knowledge transfer capability. 1

Introduction
Continual learning (CL) incrementally learns a sequence of tasks in a neural network. Each task consists of a set of classes to be learned together. CL is often accompanied by the catastrophic forgetting (CF) problem [38]. Two main settings for CL have been extensively studied, namely, task continual learning (Task-CL) and class continual learning (Class-CL). Task-CL learns a classiﬁer for each task. In testing, the task id is provided for the test data so that the speciﬁc task model can be applied to assign a class to the test sample. Although Class-CL also learns a sequence of tasks, in testing the task id is not provided for each sample. Note that there is also a less known or studied
CL setting called domain continual learning (Domain-CL), in which all tasks (or domains) share the same set of classes [22] and no task id is provided in testing. This paper focuses on Task-CL.
A large amount of research has been done on overcoming CF [8]. The main existing techniques include the regularization-based methods [63, 11, 25, 18], replay-based methods [43, 18, 56] and structure-based methods [50, 61, 39]. Regularization-based methods are primarily designed to evaluate the importance of the parameters learned from old tasks, and then use some mechanisms to protect those important parameters so that the performance of old tasks will not be affected much in the process of learning new tasks. Replay-based methods use part of the data cached in the past or train a generator to generate some similar past data to help maintain the performance of the old tasks in learning new tasks. Structure-based methods allow the neural network to adaptively adjust the network structure during the learning process or to add a learning module that does not share in
∗Corresponding authors. The main part of the work was done when Bing Liu was at Peking University on leave of absence from University of Illinois at Chicago. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
the continual learning process. In the Task-CL setting, several techniques have overcome CF, e.g,
HAT [50] (see Section 4.3).
However, another major objective of CL, knowledge transfer across tasks [8, 21, 47], has received relatively little attention. An ideal Task-CL algorithm must do well on both (preventing CF and transferring knowledge). Being able to prevent CF alone is far from satisfactory. We will see in
Section 4.3 that the knowledge transfer ability of the current Task-CL algorithms is very weak. This paper proposes a technique based on reinforcement learning (RL) called BNS (Building Network
Structures dynamically for CL) to explicitly perform both CF prevention and knowledge transfer at the same time and automatically. When the tasks are different with little shared knowledge, BNS should prevent CF. When the tasks are similar with shared knowledge, BNS should transfer knowledge across tasks to achieve higher accuracy than without knowledge transfer.
BNS has three components: a neural structure search agent, a set of actions, and the environment.
The environment includes the current task data, a continual learner, a knowledge repository and a replay buffer. We propose to use the similarity of the new task and the old tasks as the state representation in the environment. This enables knowledge transfer as more similar tasks tend to have more shared knowledge to be transferred across tasks. For each new task, the agent uses the state to sample a sequence of actions to construct a new continual learner for the task, which includes building a new network structure and selecting the past knowledge (i.e., parameters) from the knowledge repository to initialize the parameters. The continual learner then learns the current task. After learning, a specially designed reward is computed based on the current task validation data and the saved data of old tasks in the replay buffer (to avoid CF and to transfer knowledge to the current task). The reward is used to guide the training of the agent through RL. Thus, BNS achieves both CF avoidance and knowledge transfer at the same time. The ﬁnal model learned by the continual learner not only performs the current new task well but also maintains the performance of the old tasks.
Experimental results on ﬁve datasets MNIST, CIFAR10, CIFAR-100, F-EMNIST and F-Celeba show that BNS markedly outperforms the existing state-of-the-art Task-CL baselines. For datasets (F-EMNIST and F-Celeba) with high task similarities, BNS can leverage knowledge transfer to improve the accuracy substantially compared to the baselines. Even for datasets (MNIST, CIFAR10, and CIFAR-100) with very different/dissimilar tasks, apart from overcoming CF, it can also improve the accuracy in most cases, which existing Task-CL baselines have difﬁculty to do. 2