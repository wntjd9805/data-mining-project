Abstract
Contrastive self-supervised learning has largely narrowed the gap to supervised pre-training on ImageNet. However, its success highly relies on the object-centric priors of ImageNet, i.e., different augmented views of the same image correspond to the same object. Such a heavily curated constraint becomes immediately infeasible when pre-trained on more complex scene images with many objects. To over-come this limitation, we introduce Object-level Representation Learning (ORL), a new self-supervised learning framework towards scene images. Our key insight is to leverage image-level self-supervised pre-training as the prior to discover object-level semantic correspondence, thus realizing object-level representation learning from scene images. Extensive experiments on COCO show that ORL signiﬁcantly improves the performance of self-supervised learning on scene images, even surpassing supervised ImageNet pre-training on several downstream tasks.
Furthermore, ORL improves the downstream performance when more unlabeled scene images are available, demonstrating its great potential of harnessing unla-beled data in the wild. We hope our approach can motivate future research on more general-purpose unsupervised representation learning from scene data.1 1

Introduction
Unsupervised visual representation learning aims at obtaining transferable features with abundant unlabeled data. Recent self-supervised learning (SSL) methods based on contrastive learning [60, 22, 37, 5, 19, 4, 7] have largely narrowed the gap and even surpassed the supervised counterpart on a number of downstream tasks [30, 49, 15, 47, 35, 23]. These methods build upon the instance discrimination task that maximizes the agreement between different data-augmented views of the same image. Despite their success, current SSL methods are primarily pre-trained on the unlabeled
ImageNet [8] dataset that contains iconic images with single object as shown in Figure 1(a). The underlying object-centric constraint of ImageNet makes it hard to be applied in real world scenarios where more complex scene images with multiple objects are available. Meanwhile, naïvely adopting the off-the-shelf contrastive learning methods on scene images introduces inconsistent learning signals since random crops of the same image may correspond to different objects as shown in
Figure 1(b). Indeed, it has been shown that current contrastive learning methods tend to struggle on more complex scene datasets [19, 50, 34, 58] like COCO [33] or Places365 [72]. Therefore, it is imperative to design an effective object-level representation learning paradigm as illustrated in
Figure 1(c) to harness massive unlabeled scene images in the wild. 1Project page: https://www.mmlab-ntu.com/project/orl/. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
Figure 1: (a) Current image-level contrastive learning methods heavily rely on the object-centric bias of ImageNet, i.e., different crops correspond to the same object. Prior works use either the different views of the same image [60, 22, 37, 5, 19, 7] (i.e., intra-image) or similar images [74, 63, 1, 11] (i.e., inter-image) to form positive pairs. (b) Directly adopting image-level contrastive learning methods on scene images can cause inconsistent learning signals since different crops may correspond to different objects. (c) Object-level contrastive learning can overcome the limitation in (b) by enforcing object-level consistency. (d) We ﬁnd that image-level contrastive learning encodes priors for region correspondence discovery across images, and high-response regions are usually objects or object parts (we show one discovered object-instance pair per image pair for clarity), which is useful for object-level representation learning.
In this work, we are interested in going beyond ImageNet to obtain better representations on non-iconic images. Apparently, it is challenging to learn representations from scene-level images since they are entangled with many concepts including structures, objects, backgrounds and relationships. It remains an open question how to take advantages of spatial information of multiple objects naturally residing in the scene images when no object annotations are available, let alone further deriving object-level correspondence to construct positive object-instance pairs.
To tackle these challenges, we introduce a novel object-level unsupervised representation learning framework tailored for scene images. Our framework is based on a key insight of the current contrastive learning methods: they can implicitly group different images with similar visual concepts together even though they are explicitly optimized to group different views of the same image.
This phenomenon reveals that image-level contrastive learning has already induced a latent space with rich visual concepts. Though the latent space usually entangles other scene concepts like structures, backgrounds and relationships, it will be useful for object discovery if appropriately deployed. Through computing the similarity of sampled regions between k-nearest-neighbor (KNN) images, we conclude two observations: 1) image-level contrastive learning encodes priors for region correspondence discovery across images; 2) high-response regions are usually objects or object parts.
Based on the observation above, we propose a multi-stage framework for unsupervised object-level representation learning. Speciﬁcally, we ﬁrst extract potential object-based regions in scene images using the unsupervised region proposal algorithms (e.g., selective search [56]). We then propose a region correspondence generation scheme to leverage the off-the-shelf image-level contrastive learning pre-trained model to discover corresponding object-instance pairs for the proposed regions in the embedding space. Finally, we use the obtained object-instance pairs to construct positive sample pairs for object-level representation learning. Figure 1(d) shows several cross-image object-instance pairs discovered by our framework on COCO dataset using the latent prior of BYOL [19], the state-of-the-art image-level contrastive learning method. The discovered inter-corresponding pairs substantially provide diverse intra-class variances at the object-instance level to aid object-level representation learning.
Overall, our main contributions are summarized as follows: 2
1) We observe that existing image-level contrastive learning methods have priors to discover object-level correspondence across images. We leverage this prior for the ﬁrst time for unsupervised cross-image object-level correspondence discovery. 2) With the obtained correspondence, we introduce a novel multi-stage self-supervised learning pipeline, termed as ORL, for object-level representation learning from scene images, going beyond object-centric ImageNet. 3) We contribute the ﬁrst study for object-level SSL. ORL substantially outperforms image-level contrastive learning approaches pre-trained on COCO dataset (∼118k images with labels discarded), setting a new state of the art on this challenging dataset that contains diverse scenes in the wild.
The COCO pre-trained ORL even surpasses supervised ImageNet pre-training on several considered downstream tasks. When SSL is conducted on a larger “COCO+” dataset (COCO train2017 set plus COCO unlabeled2017 set, ∼241k images in total), ORL further improves the performance, demonstrating its potential to beneﬁt from more unlabeled scene data. 2