Abstract
√
We develop algorithms for private stochastic convex optimization that adapt to the hardness of the speciﬁc function we wish to optimize. While previous work pro-vide worst-case bounds for arbitrary convex functions, it is often the case that the function at hand belongs to a smaller class that enjoys faster rates. Con-cretely, we show that for functions exhibiting κ-growth around the optimum, i.e., f (x) ≥ f (x(cid:63)) + λκ−1(cid:107)x − x(cid:63)(cid:107)κ 2 for κ > 1, our algorithms improve upon the
κ−1 . Crucially, they achieve standard these rates without knowledge of the growth constant κ of the function. Our al-gorithms build upon the inverse sensitivity mechanism, which adapts to instance difﬁculty [2], and recent localization techniques in private optimization [25]. We complement our algorithms with matching lower bounds for these function classes and demonstrate that our adaptive algorithm is simultaneously (minimax) optimal over all κ ≥ 1 + c whenever c = Θ(1). d/nε privacy rate to the faster ( d/nε)
√
κ 1

Introduction
Stochastic convex optimization (SCO) is a central problem in machine learning and statistics, where for a sample space S, parameter space X ⊂ Rd, and a collection of convex losses {F (·; s) : s ∈ S}, one wishes to solve minimize x∈X f (x) := ES∼P [F (x; S)] = (cid:90)
S
F (x; s)dP (s) (1) iid∼ P . While as formulated, the problem is by now fairly using an observed dataset S = Sn 1 well-understood [12, 38, 29, 10, 37], it is becoming clear that, because of considerations beyond pure statistical accuracy—memory or communication costs [45, 26, 13], fairness [23, 28], personal-ization or distributed learning [35]—problem (1) is simply insufﬁcient to address modern learning problems. To that end, researchers have revisited SCO under the additional constraint that the solu-tion preserves the privacy of the provided sample [22, 21, 1, 16, 19]. A waypoint is Bassily et al.
[7], who provide a private method with optimal convergence rates for the related empirical risk min-imization problem, with recent papers focus on SCO providing (worst-case) optimal rates in various settings: smooth convex functions [8, 25], non-smooth functions [9], non-Euclidean geometry [5, 4] and under more stringent privacy constraints [34].
Yet these works ground their analyses in worst-case scenarios and provide guarantees for the hardest instance of the class of problems they consider. Conversely, they argue that their algorithms are op-timal in a minimax sense: for any algorithm, there exists a hard instance on which the error achieved by the algorithm is equal to the upper bound. While valuable, these results are pessimistic—the exhibited hard instances are typically pathological—and fail to reﬂect achievable performance.
∗Equal contribution. Author order determined by coin toss. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
In this work, we consider the problem of adaptivity when solving (1) under privacy constraints.
Importantly, we wish to provide private algorithms that adapt to the hardness of the objective f . A loss function f may belong to multiple problem classes, each exhibiting different achievable rates, so a natural desideratum is to attain the error rate of the easiest sub-class. As a simple vignette, if one gets an arbitrary 1-Lipschitz convex loss function f , the worst-case guarantee of any ε-DP algorithm is Θ(1/ n + d/(nε)). However, if one learns that f exhibits some growth property—say f is 1-strongly convex—the regret guarantee improves to the faster Θ(1/n + (d/(nε))2) rate with the appropriate algorithm. It is thus important to provide algorithms that achieves the rates of the
“easiest” class to which the function belongs [32, 46, 18].
To that end, consider the nested classes of functions F κ for κ ∈ [1, ∞] such that, if f ∈ F κ then there exists λ > 0 such that for all x ∈ X ,
√ f (x) − inf x(cid:48)∈X f (x(cid:48)) ≥
λ
κ (cid:107)x − x(cid:63)(cid:107)κ 2 .
For example, strong convexity implies growth with parameter κ = 2. This growth assumption closely relates to uniform convexity [32] and the Polyak-Kurdyka-Łojasiewicz inequality [11], and we make these connections precise in Section 2. Intuitively, smaller κ makes the function much easier to optimize: the error around the optimal point grows quickly. Objectives with growth are widespread in machine learning applications: among others, the (cid:96)1-regularized hinge loss exhibits sharp growth (i.e. κ = 1) while (cid:96)1- or (cid:96)∞-constrained κ-norm regression —i.e. s = (a, b) ∈ Rd × R and F (x; s) = |b − (cid:104)a, x(cid:105)|κ—has κ-growth for any κ integer greater than 2 [43]. In this work, we provide private adaptive algorithms that adapt to the actual growth of the function at hand.
We begin our analysis by examining Asi and Duchi’s inverse sensitivity mechanism [2] on ERM as a motivation. While not a practical algorithm, it achieves instance-optimal rates for any one-dimensional function under mild assumptions, quantifying the best bound one could hope to achieve with an adaptive algorithm, and showing (in principle) that adaptive private algorithms can exist. We
ﬁrst show that for any function with κ-growth, the inverse sensitivity mechanism achieves privacy cost (d/(nε))κ/(κ−1); importantly, without knowledge of the function class F κ, that f belongs to.
This constitutes grounding and motivation for our work in three ways: (i) it validates our choice of sub-classes F κ as the privacy rate is effectively controlled by the value of κ, (ii) it exhibits the rate we wish to achieve with efﬁcient algorithms on F κ and (iii) it showcases that for easier functions, privacy costs shrink signiﬁcantly—to illustrate, for κ = 5/4 the privacy rate becomes (d/(nε))5.
We continue our treatment of problem (1) under growth in Section 4 and develop practical algo-rithms that achieve the rates of the inverse sensitivity mechanism. Moreover, for approximate (ε, δ)-d/(nε))κ/(κ−1). Our differential privacy, our algorithms improve the rates, achieving roughly ( algorithms hinge on a reduction to SCO: we show that by solving a sequence of increasingly con-strained SCO problems, one achieves the right rate whenever the function exhibits growth at the optimum. Importantly, our algorithm only requires a lower bound κ ≤ κ (where κ is the actual growth of f ).
√
We provide optimality guarantees for our algorithms in Section 5 and show that both the inverse sen-sitivity and the efﬁcient algorithms of Section 4 are simultaneously minimax optimal over all classes
F κ whenever κ = 1 + Θ(1) and d = 1 for ε-DP algorithms. Finally, we prove that in arbitrary dimension, for both pure- and approximate-DP constraints, our algorithms are also simultaneously optimal for all classes F κ with κ ≥ 2.
On the way, we provide results that may be of independent interest to the community. First, we develop optimal algorithms for SCO under pure differential privacy constraints, which, to the best of our knowledge, do not exist in the literature. Secondly, our algorithms and analysis provide high-probability bounds on the loss, whereas existing results only provide (weaker) bounds on the expected loss. Finally, we complete the results of Ramdas and Singh [40] on (non-private) optimiza-tion lower bounds for functions with κ-growth by providing information-theoretic lower bounds (in contrast to oracle-based lower bounds that rely on observing only gradient information) and captur-ing the optimal dependence on all problem parameters (namely d, L and λ). 1.1