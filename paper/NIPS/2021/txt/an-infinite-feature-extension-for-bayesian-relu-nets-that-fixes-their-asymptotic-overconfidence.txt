Abstract
A Bayesian treatment can mitigate overconﬁdence in ReLU nets around the training data. But far away from them, ReLU Bayesian neural networks (BNNs) can still underestimate uncertainty and thus be asymptotically overconﬁdent. This issue arises since the output variance of a BNN with ﬁnitely many features is quadratic in the distance from the data region. Meanwhile, Bayesian linear models with
ReLU features converge, in the inﬁnite-width limit, to a particular Gaussian process (GP) with a variance that grows cubically so that no asymptotic overconﬁdence can occur. While this may seem of mostly theoretical interest, in this work, we show that it can be used in practice to the beneﬁt of BNNs. We extend ﬁnite
ReLU BNNs with inﬁnite ReLU features via the GP and show that the resulting model is asymptotically maximally uncertain far away from the data while the
BNNs’ predictive power is unaffected near the data. Although the resulting model approximates a full GP posterior, thanks to its structure, it can be applied post-hoc to any pre-trained ReLU BNN at a low cost. 1

Introduction
Approximate Bayesian methods, which turn neural networks (NNs) into Bayesian neural networks (BNNs), can be used to address the overconﬁdence issue of NNs [1]. Speciﬁcally, Kristiadi et al. [2] recently showed for binary ReLU classiﬁcation networks that far away from the training data, i.e. when scaling any input with a scalar α > 0 and taking the limit α → ∞, the conﬁdence of (Gaussian-based)
BNNs is strictly less than one—“being Bayesian” can thus mitigate overconﬁdence. This result is encouraging vis-à-vis standard point-estimated networks, for which Hein et al. [3] showed earlier that the same asymptotic limit always yields arbitrarily high conﬁdence. Nevertheless, BNNs can still be asymptotically overconﬁdent, albeit less so than standard NNs, since the aforementioned uncertainty bound can be loose.
We identify that this issue arises because the variance over function outputs of a BNN is asymptotically quadratic, while the corresponding mean is asymptotically linear w.r.t. α. Intuitively, ﬁxing this issue requires adding an unbounded number of ReLU features with increasing distance from the training data, so that the output mean stays unchanged but the associated variance grows super-quadratically.
And indeed there is a particular Gaussian process (GP), arising from the cubic spline kernel [4], which has cubic variance growth and can be seen as a Bayesian linear model with countably inﬁnite
ReLU features. In the context of the analysis, the fact that standard ReLU BNNs only use ﬁnitely many features makes them “miss out” on some uncertainty that should be there. In this work, we
“add back” this missing uncertainty into ﬁnite ReLU BNNs by ﬁrst extending the cubic spline kernel 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
(a) K = 6 (b) K = 20 (c) K = 60 (d) K = ∞
Figure 1: The construction of a GP prior with the proposed “ReLU kernel”, as the limiting covariance of the output of a Bayesian linear model with K ReLU features (grey), arranged at regular intervals, oriented away from the origin. Red curves are function samples with the thick one being the mean, and the red shade their std. dev. With ﬁnite K (a-c), the variance grows quadratically, leading to the asymptotic overconﬁdence in ReLU BNNs. But, with K = ∞ (d), the variance grows cubically away from the origin. The fact that this kernel has zero mean and negligible variance near the origin enables us to easily combine this GP with standard ﬁnite pre-trained ReLU BNNs. to cover the whole input domain (Fig. 1) and then using the resulting GP to model residuals of
BNNs [5–7]. Conceptually, we extend ﬁnite BNNs into inﬁnite ones. The proposed kernel has two crucial properties: (i) It has negligible values around the origin, which we can assume without loss of generality to be the region where the data reside, and (ii) like the cubic spline kernel, its variance grows cubically in α. Using the ﬁrst property, we can approximately decompose the resulting a posteriori function output simply as a posteriori BNNs’ output plus a priori the GP’s output. This extension can therefore be applied to any pre-trained ReLU BNN in a post-hoc manner. And due to the second property, we can show that the extended BNNs are guaranteed to predict with uniform conﬁdence away from the data. This approach thus ﬁxes ReLU BNNs’ asymptotic overconﬁdence, without affecting the BNNs’ predictive mean. Finally, the method can be extended further while still preserving all these properties, by also modeling the representations of input points with the proposed GP. By doing so, the GP can adapt to the data well, and hence also improve the extended
ReLU BNNs’ non-asymptotic uncertainty.
A core contribution of this paper is the theoretical analysis: We show that our method (i) models the uncertainty that ReLU BNNs lack, thus (ii) ensuring that the surrounding output variance asymptotically grows cubically in the distance to the training data, and ultimately (iii) yields uniform asymptotic conﬁdence in the multi-class classiﬁcation setting. These results extend the prior analysis in so far as it is limited to the binary classiﬁcation case and does not guarantee the asymptotically maximum-entropy prediction. Furthermore, our approach is complementary to the method of Meinke and Hein [8], which attains maximum uncertainty far from the data for non-Bayesian NNs. We empirically conﬁrm the analysis and show effectiveness in the non-asymptotic regime. 2