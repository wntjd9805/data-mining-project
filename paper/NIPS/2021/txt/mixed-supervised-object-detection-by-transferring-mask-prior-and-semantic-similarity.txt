Abstract
Object detection has achieved promising success, but requires large-scale fully-annotated data, which is time-consuming and labor-extensive. Therefore, we consider object detection with mixed supervision, which learns novel object cat-egories using weak annotations with the help of full annotations of existing base object categories. Previous works using mixed supervision mainly learn the class-agnostic objectness from fully-annotated categories, which can be transferred to upgrade the weak annotations to pseudo full annotations for novel categories. In this paper, we further transfer mask prior and semantic similarity to bridge the gap between novel categories and base categories. Speciﬁcally, the ability of using mask prior to help detect objects is learned from base categories and transferred to novel categories. Moreover, the semantic similarity between objects learned from base categories is transferred to denoise the pseudo full annotations for novel categories. Experimental results on three benchmark datasets demonstrate the effectiveness of our method over existing methods. Codes are available at https://github.com/bcmi/TraMaS-Weak-Shot-Object-Detection. 1

Introduction
With the ubiquitous application of convolutional neural networks and the release of large-scale fully-annotated detection benchmark datasets (e.g., MS COCO [27], ILSVRC Detection [32], and
PASCAL VOC [10]), object detection has achieved signiﬁcant advances in recent years [14, 29, 41].
However, Fully Supervised Object Detection (FSOD) requires massive training images with precise bounding boxes and box-level category labels. Acquiring such full annotations is time-consuming and labor-intensive, which limits the application of FSOD in real-world scenarios. In contrast, weak annotations like image-level category labels are much easier to acquire (e.g., crawl from public websites). Thus, plenty of Weakly Supervised Object Detection (WSOD) methods [22, 30, 15] have been proposed to bridge the gap between full annotation and weak annotation. Due to the lack of box-level annotation, WSOD methods rely on unsupervised proposal generation strategy (e.g., Selective Search [43], Edge Boxes [48]) to extract region proposals. Based on the proposals,
[3, 38, 39] formulated WSOD task as Multiple Instance Learning (MIL) problem, which treats each image as a bag or multiple bags of proposals. With known image-level labels and unknown box-level labels, we can infer the box-level label of each proposal with an MIL classiﬁer. However, WSOD methods usually only localize the most discriminative region and confuse objects with co-occurring distractors, so the performance gap between FSOD and WSOD is still very large.
∗Equal contribution
†Corresponding author 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
It is worth noting that WSOD ignores the existence of fully-annotated object detection datasets.
By taking this into consideration, another learning paradigm using mixed supervision, i.e., full annotations for a set of categories and weak annotations for another set of categories, has been explored by [18, 45, 5, 26]. This learning paradigm has inconsistent names like mixed/cross-supervised object detection in previous literature [26, 5]. However, “mixed/cross-supervised" does not emphasize cross-category transfer and could be easily confused with “semi/omni-supervised".
Inspired by weak-shot learning [4], which transfers knowledge from fully-annotated base categories to weakly-annotated novel categories, we refer to this learning paradigm as Weak-SHot Object
Detection (WSHOD). Assuming the existence of an off-the-shelf dataset with fully-annotated base categories (precise bounding boxes and box-level labels), with the goal to detect the objects of novel categories, we can collect weakly-annotated data (only image-level labels) for novel categories.
Fully-annotated base categories and weakly-annotated novel categories have no overlap. We refer to the dataset with base (resp., novel) categories as source (resp., target) dataset, since our goal is utilizing base categories to help improve the detection performance on novel categories.
Under this paradigm, the key problem is what and how to transfer from fully-annotated base categories to weakly-annotated novel categories. Existing works [26, 45] still follow the typical framework of WSOD, that is, feeding proposals into an MIL classiﬁer. Due to the availability of box-level annotations of base categories, they train a CNN backbone with a region proposal network (RPN) to generate proposals. Since the objects of different categories share many common characteristics (e.g., closed contour), objectness is supposed to be transferrable across different categories. Therefore, the trained network could also generate proposals for novel categories, which will be sent to the MIL classiﬁer.
In this paper, beyond class-agnostic objectness, we consider another two targets to be transferred: mask prior and semantic similarity. Since both base categories and novel categories have image-level labels, we can obtain the coarse semantic masks (e.g., CAM [46]) for each image. We conjecture that the coarse semantic mask could provide strong guidance for detecting objects, so we attempt to integrate coarse semantic mask into our CNN backbone. In particular, we employ the image-level labels to train a classiﬁer to derive CAM [46], and append the derived CAM to the feature map in
CNN backbone. Because CAM provides the rough probability that each pixel belongs to a certain category, such mask prior information combined with the feature map could greatly enhance the ability to locate and identify candidate bounding boxes. By saying “transfer mask prior", we mean that the ability to detect objects based on mask prior and feature map can be transferred from base categories to novel categories, which will help detect the objects of novel categories.
Besides, following the iterative training strategy in [45], we progressively mine the pseudo bounding boxes of novel categories, during which the noisy bounding boxes are ﬁltered out. The pseudo bounding boxes with correct (resp., incorrect) pseudo labels assigned by the MIL classiﬁer are referred to as inliers (resp., outliers). We argue that semantic similarity, whether two bounding boxes belong to the same category or not, is class-agnostic. Then, we attempt to transfer semantic similarity from base categories to help identify the outliers of novel categories. Speciﬁcally, we train a similarity network based on the ground-truth bounding boxes of base categories to verify whether two bounding boxes belong to the same category. We divide the pseudo bounding boxes of novel categories into batches and the pseudo bounding boxes in each batch have the same pseudo label.
Within each batch, we apply the trained similarity network to all pairs of pseudo bounding boxes to compute their semantic similarities, and then average the similarities for each one. If one batch is dominated by inliers, an inlier should be close to most other pseudo bounding boxes and its average similarity should be high. Thus, we can use average similarity to distinguish outliers and inliers.
In summary, the transferred mask prior could help obtain better candidate bounding boxes, while the transferred semantic similarity could help discard the noisy pseudo bounding boxes. We conduct extensive experiments on three datasets. The results demonstrate that our proposed approach with transferred mask prior and semantic similarity can signiﬁcantly boost the performance of weak-shot object detection. Considering that the key of our method is Transferring Mask prior and Similarity, we dub our method as TraMaS. Our main contributions are as follows:
• We propose a novel approach named TraMaS for weak-shot object detection (WSHOD).
Besides class-agnostic objectness, we also propose to transfer mask prior and semantic similarity. 2
• We integrate CAM derivation into our network, which can help generate better candidate bounding boxes with mask prior.
• We employ a similarity network to learn semantic similarity, which can be used to ﬁlter out noisy pseudo bounding boxes.
• Our TraMaS method outperforms all state-of-the-art WSOD and WSHOD methods on three benchmark datasets. 2