Abstract
Ensemble-based debiasing methods have been shown effective in mitigating the reliance of classiﬁers on speciﬁc dataset bias, by exploiting the output of a bias-only model to adjust the learning target. In this paper, we focus on the bias-only model in these ensemble-based methods, which plays an important role but has not gained much attention in the existing literature. Theoretically, we prove that the debiasing performance can be damaged by inaccurate uncertainty estimations of the bias-only model. Empirically, we show that existing bias-only models fall short in producing accurate uncertainty estimations. Motivated by these ﬁndings, we propose to conduct calibration on the bias-only model, thus achieving a three-stage ensemble-based debiasing framework, including bias modeling, model calibrating, and debiasing. Experimental results on NLI and fact veriﬁcation tasks show that our proposed three-stage debiasing framework consistently outperforms the traditional two-stage one in out-of-distribution accuracy. 1

Introduction
Machine learning models have achieved remarkable performance on natural language understand-ing [10; 7; 28] and computer vision [16; 17]. However, observations have shown that these models have difﬁculties in generalizing well in out-of-distribution settings [30; 40; 2; 11], which limits their applications to real-world scenarios. A major cause of this failure is the reliance of the model on speciﬁc dataset bias [33]. For instance, McCoy et al. [23] have shown that sentence pairs with high word overlaps in MNLI are easy to be classiﬁed as the label ‘entailment’, even if they have different relations.
A growing body of literature recognizes debiasing as an important direction in machine learning and natural language processing [38; 3; 4; 34]. Within these works, ensemble-based debiasing (EBD) methods [15; 22; 8; 39; 5] have caused considerable interest within the community, as shown
∗Equal contribution.
†Work done while Yimeng Chen was interning at Institute for AI Industry Research, Tsinghua University.
‡Corresponding author. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
promising improvements on the out-of-distribution performance. EBD methods, e.g., PoE [8],
DRiFt [15], and Inverse-Reweight [39], usually adopt a two-stage framework. Firstly, a biased predictor is trained based on the bias features only, namely the bias-only model. Its output is then utilized to adjust the learning target of the main model by using different ensembling strategies.
Previous works are mainly limited to designing different ensembling strategies, without considering the bias-only model, which clearly plays an essential role in the whole process.
In this paper, we focus on investigating the bias-only model in the EBD methods. We theoretically reveal that the quality of the predictive uncertainty estimation given by the bias-only model is crucial for the debiasing performance of EBD methods. Speciﬁcally, we prove that the out-of-distribution accuracy of the debiased model is monotonically decreasing with the calibration error of the bias-only model when such error exceeds a threshold4. Moreover, by theoretically analyzing the decline of in-distribution performance caused by debiasing, we show the existence of the case when uncertainty calibration can also mitigate such a side-effect. Empirically, we show that bias-only models employed by existing methods on both natural language inference and fact veriﬁcation tasks fail to produce accurate uncertainty estimations. These ﬁndings indicate the critical role of the calibration property of current bias-only models for further improvement of EBD methods.
Motivated by the theoretical analysis and empirical study, we introduce an additional calibration stage into the previous EBD methods. In this stage, the bias-only model is calibrated with model-agnostic calibration methods to obtain more accurate predictive uncertainty estimation. Speciﬁcally, two typical calibration methods are used in this paper, i.e. temperature scaling [12] and Dirichlet calibration [19]. After that, the calibrated bias-only model is used to train the main model with off-the-shelf ensembling strategies. In this way, we extend the traditional two-stage EBD framework to a three-stage one, including bias Modeling, model Calibrating, and Debiasing, named MoCaD for short.
To demonstrate the effectiveness of our proposed framework, we conduct experiments on four challenging benchmarks for two NLU tasks, i.e. natural language inference and fact veriﬁcation.
Experimental results show that our framework signiﬁcantly improves the out-of-distribution perfor-mance, as compared with the traditional two-stage one. Moreover, our theoretical results are well veriﬁed by the empirical observations in real scenarios.
Our main contributions can be summarized as the following three folds.
• We explore, both theoretically and empirically, the effect of the bias-only model in the EBD methods. Consequently, a critical problem is revealed: existing bias-only models are poorly calibrated, which will hurt the debiasing performance.
• We propose a model-agnostic three-stage EBD framework to tackle the above problem.
• We conduct extensive experiments on four challenging datasets for two different tasks, and experimental results show the superiority of our proposed framework as against the traditional two-stage one. 2