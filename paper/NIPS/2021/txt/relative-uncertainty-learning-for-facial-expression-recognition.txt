Abstract
In facial expression recognition (FER), the uncertainties introduced by inher-ent noises like ambiguous facial expressions and inconsistent labels raise con-cerns about the credibility of recognition results. To quantify these uncertain-ties and achieve good performance under noisy data, we regard uncertainty as a relative concept and propose an innovative uncertainty learning method called Relative Uncertainty Learning (RUL). Rather than assuming Gaussian uncertainty distributions for all datasets, RUL builds an extra branch to learn uncertainty from the relative difficulty of samples by feature mixup. Specif-ically, we use uncertainties as weights to mix facial features and design an add-up loss to encourage uncertainty learning.
It is easy to implement and adds little or no extra computation overhead. Extensive experiments show that
RUL outperforms state-of-the-art FER uncertainty learning methods in both real-world and synthetic noisy FER datasets. Besides, RUL also works well on other datasets such as CIFAR and Tiny ImageNet. The code is available at https://github.com/zyh-uaiaaaa/Relative-Uncertainty-Learning. 1

Introduction
Although well-trained models can give high-confidence inferences directly, the inference results may actually be wrong and cause serious consequences [22]. Therefore, the concept of uncertainty is widely used in measuring how well the model trusts its inference results, which has become a research hotspot in trustworthy machine learning [3, 11, 10, 22, 26, 16]. It is expected that a reliable model assigns high level uncertainty to its erroneous predictions so that humans can intervene to avoid lots of disasters. As described by Kiureghian et al. [25], the uncertainties in machine learning can be split into aleatoric uncertainty and epistemic uncertainty, which are also called data uncertainty and model uncertainty. In this paper, we focus on quantifying data uncertainty as model uncertainty can be eliminated by introducing more training data. Concretely, data uncertainty in facial expression recognition (FER) is mainly caused by ambiguous facial expressions and the subjectiveness of annotators, which blocks the improvement of recognition performance [47].
Recent studies propose a variety of methods to solve the uncertainty learning problem in the face recognition field. PFE [37] introduces a new branch to learn the uncertainty of face recognition and recognizes faces by measuring the similarity between two Gaussian distributions. Chang et al. [4] further propose DUL to learn feature and uncertainty simultaneously in order to improve facial feature learning. When it comes to FER, SCN [47] uses a fully-connected layer to learn an importance weight for each image and suppresses uncertainties according to the learned weights. However, the strong learning ability of neural networks will deteriorate the uncertainty learning branch. One solution is adding regularization to force the model to learn uncertainty, which needs to be tuned carefully, otherwise, it would lead to underfitting. For example, SCN uses margin loss to keep the gap between certain and uncertain images, but choosing a suitable gap value is non-trivial. DUL assumes features 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
to follow a Gaussian distribution, but the real distribution of the dataset is not always following such an assumption. Therefore, it is still a challenge to learn uncertainty distributions of real datasets without deteriorating feature learning.
To address the problem, we perceive data uncertainty from a different point of view. We realize that data uncertainty – the difficulty to classify a sample correctly is actually a relative concept.
More specifically, the difficulty of classification is a person’s subjective feeling that comes from comparison. One can only know whether a sample is easy or not according to a reference. Inspired by this idea, we propose an innovative method called Relative Uncertainty Learning (RUL) to help deep learning models to learn uncertainty for each sample. Concretely, we build a new branch to model the uncertainties of input images and utilize the uncertainties as weights to mix two features of different labels. Through an add-up loss function, the model is encouraged to recognize two expressions simultaneously from the mixed features, which enables the model to learn uncertainty comparatively while minimizing the total loss. As discussed in Section 3.3, the uncertainty learning branch will assign large uncertainty values to uncertain facial expression images while small uncertainty values to certain images.
The main contributions of this work are as follows:
• We perceive uncertainty from a new perspective and propose an innovative uncertainty learning method to learn uncertainty from the relative difficulty of two samples.
• We get state-of-the-art performance in both real-world and synthetic noisy FER datasets.
• RUL does not need prior knowledge of the dataset uncertainty distribution and can be easily applied to different classification tasks with low computation cost. 2