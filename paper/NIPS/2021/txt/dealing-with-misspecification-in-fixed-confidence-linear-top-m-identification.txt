Abstract
We study the problem of the identiﬁcation of m arms with largest means under a
ﬁxed error rate δ (ﬁxed-conﬁdence Top-m identiﬁcation), for misspeciﬁed linear bandit models. This problem is motivated by practical applications, especially in medicine and recommendation systems, where linear models are popular due to their simplicity and the existence of efﬁcient algorithms, but in which data inevitably deviates from linearity. In this work, we ﬁrst derive a tractable lower bound on the sample complexity of any δ-correct algorithm for the general Top-m identiﬁcation problem. We show that knowing the scale of the deviation from linearity is necessary to exploit the structure of the problem. We then describe the
ﬁrst algorithm for this setting, which is both practical and adapts to the amount of misspeciﬁcation. We derive an upper bound to its sample complexity which conﬁrms this adaptivity and that matches the lower bound when δ → 0. Finally, we evaluate our algorithm on both synthetic and real-world data, showing competitive performance with respect to existing baselines. 1

Introduction
The multi-armed bandit (MAB) is a popular framework to model sequential decision making problems.
At each round t > 0, a learner chooses an arm kt among a ﬁnite set of K ∈ N possible options, and it receives a random reward X kt t ∈ R drawn from a distribution νkt with unknown mean µkt.
Among the many problem settings studied in this context, we focus on pure exploration, where the learner aims at maximizing the information gain for answering a given query about the arms [5]. In particular, we are interested in ﬁnding a subset of m ≥ 1 arms with largest expected reward, which is known as the Top-m identiﬁcation problem [22]. This generalizes the widely-studied best-arm (i.e.,
Top-1) identiﬁcation problem [16]. This problem has several important applications, including online recommendation and drug repurposing [31, 35]. Two objectives are typically studied. On the one hand, in the ﬁxed-budget setting [2], the learner is given a ﬁnite amount of samples and must return a subset of m best arms while minimizing the probability of error in identiﬁcation. On the other hand, in the ﬁxed-conﬁdence setting [16], the learner aims at minimizing the sample complexity for returning a subset of m best arms with a ﬁxed maximum error rate δ ∈ (0, 1), deﬁned as the number of samples collected before the algorithm stops. This paper focuses on the latter. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
In practice, information about the arms is typically available (e.g., the characteristics of an item in a recommendation system, or the inﬂuence of a drug on protein production in a clinical application).
This side information inﬂuence the expected rewards of the arms, thus adding structure (i.e., prior knowledge) to the problem. This is in contrast to the classic unstructured MAB setting, where the learner has no prior knowledge about the arms. Due to their simplicity and ﬂexibility, linear models have become the most popular to represent this structure. Formally, in the linear bandit setting [3], the mean reward µk of each arm k ∈ [K] := {1, 2, . . . , K} is assumed to be an inner product between known d-dimensional arm features φk ∈ Rd and an unknown parameter θ ∈ Rd.
This model has led to many provably-efﬁcient algorithms for both best-arm [38, 42, 17, 43, 13] and
Top-m identiﬁcation [24, 35]. Unfortunately, the strong guarantees provided by these algorithms hold only when the expected rewards are perfectly linear in the given features, a property that is often violated in real-world applications. In fact, when using linear models with real data, one inevitably faces the problem of misspeciﬁcation, i.e., the situation in which the data deviates from linearity.
A misspeciﬁed linear bandit model is often described as a linear bandit model with an additive term to encode deviation from linearity. Formally, the expected reward µk = φ(cid:62) k θ + ηk of each arm k ∈ [K] k θ and its misspeciﬁcation ηk ∈ R. Note the ﬂexibility can be decomposed into its linear part φ(cid:62) of this model: for (cid:107)η(cid:107) = 0, where η = [η1, η2, . . . , ηK](cid:62), the problem is perfectly linear and thus highly structured, as the mean rewards of different arms are related through the common parameter
θ; whereas when the misspeciﬁcation vector η is large in all components, the problem reduces to an unstructured one, since knowing the linear part alone provides almost no information about the expected rewards. Learning in this setting thus requires adapting to the scale of misspeciﬁcation, typically under the assumption that some information about the latter is known (e.g., an upper bound
ε to (cid:107)η(cid:107)). Due to its importance, this problem has recently gained increasing attention in the bandit community for regret minimization [20, 29, 18, 33, 39]. However it has not been addressed in the context of pure exploration. In this paper, we take a step towards bridging this gap by studying
ﬁxed-conﬁdence Top-m identiﬁcation in the context of misspeciﬁed linear bandits. Our detailed contributions are as follows.
Contributions. (1) We derive a tractable lower bound on the sample complexity of any δ-correct algorithm for the general Top-m identiﬁcation problem. (2) Leveraging this lower bound, we show that knowing an upper bound ε to (cid:107)η(cid:107) is necessary for adapting to the scale of misspeciﬁcation, in the sense that any δ-correct algorithm without such information cannot achieve a better sample complexity than that obtainable when no structure is available. (3) We design the ﬁrst algorithm for Top-m identiﬁcation in misspeciﬁed linear bandits. We derive an upper bound to its sample complexity that holds for any δ ∈ (0, 1) and that matches our lower bound for δ → 0. Notably, our analysis reveals a nice adaptation to the value of ε, recovering state-of-the-art dependences in the linear case (ε = 0), where the sample complexity scales polynomially in d and not in K, and in the unstructured case (ε large), where only polynomial terms in K appear. (4) We evaluate our algorithm on synthetic problems and real datasets from drug repurposing and recommendation system applications, while showing competitive performance with state-of-the-art methods.
√