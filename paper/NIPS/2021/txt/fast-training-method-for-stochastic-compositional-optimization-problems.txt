Abstract
The stochastic compositional optimization problem covers a wide range of machine learning models, such as sparse additive models and model-agnostic meta-learning.
Thus, it is necessary to develop efficient methods for its optimization. Existing methods for the stochastic compositional optimization problem only focus on the single machine scenario, which is far from satisfactory when data are distributed on different devices. To address this problem, we propose novel decentralized stochastic compositional gradient descent methods to efficiently train the large-scale stochastic compositional optimization problem. To the best of our knowledge, our work is the first one facilitating decentralized training for this kind of problem.
Furthermore, we provide the convergence analysis for our methods, which shows that the convergence rate of our methods can achieve linear speedup with respect to the number of devices. At last, we apply our decentralized training methods to the model-agnostic meta-learning problem, and the experimental results confirm the superior performance of our methods. 1

Introduction
The stochastic compositional optimization problem [20] plays an important role in the machine learning field, since it covers numerous applications, such as policy evaluation [19], sparse additive models [20], and model-agnostic meta-learning [6, 1]. Specifically, the stochastic compositional optimization problem is defined as follows: (cid:104) (cid:17)(cid:105) (cid:16)
Eζ f
Eξ[g(x; ξ)]; ζ
, min x∈Rd (1) where the outer-level function f (y) = Eζ[f (y; ζ)] : Rd′
→ R is a smooth and nonconvex function, the inner-level function g(x) = Eξ[g(x; ξ)] : Rd → Rd′ is a smooth function. It is obvious that the loss function consists of two stochastic functions f and g, making it different from the non-compositional problem.
The compositional structure in Eq. (1) leads to more challenges in optimization compared with the non-compositional problem, since the stochastic gradient of the loss function in Eq. (1) is not an unbiased estimation of the full gradient. Thus, efficient training of the stochastic compositional optimization problem has attracted increasing attention in recent years. For example, [20] proposed the stochastic compositional gradient descent (SCGD) method to deal with the two-level stochasticity in Eq. (1). But it has a worse convergence rate than the standard stochastic gradient descent method.
To improve it, a series of variance-reduced methods have been proposed. For example, [25] developed the composite randomized incremental gradient method based on the SAGA [4] technique. [27, 24] further improved the convergence rate based on the SPIDER [5] method. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
Although aforementioned methods have achieved much progress in optimizing Eq. (1), all of them only focus on the single-machine scenario. In fact, data are usually distributed on different devices in many real-world applications. It is necessary to study the distributed training method for the stochastic compositional optimization problem. In the past few years, numerous distributed training methods have been proposed, such as asynchronous stochastic gradient descent (SGD) [16], decentralized SGD
[13], local SGD [14]. But they are not applicable to the stochastic compositional problem. Especially, their convergence results do not hold for Eq. (1) because those distributed training methods require the stochastic gradient is an unbiased estimation of the full gradient. As far as we know, there are no existing works studying distributed training methods for Eq. (1) with theoretical guarantees.
To fill the aforementioned gap, we developed two novel decentralized training methods for the stochastic compositional optimization problem. In particular, we proposed a gossip-based decentral-ized stochastic compositional gradient descent (GP-SCGD) method and a gradient-tracking-based decentralized stochastic compositional gradient descent (GT-SCGD) method. With our methods, different devices can collaboratively optimize Eq. (1). However, establishing the convergence rate of our proposed methods is challenging. Existing convergence analysis techniques for decentralized
SGD are not applicable to our methods because the stochastic compositional gradient is different from the stochastic gradient. To address this challenge, we proposed new convergence analysis techniques for the decentralized SCGD method, where we show how to bound the gradient variance and the consensus error under the decentralized setting. In particular, both GP-SCGD and GT-SCGD can achieve the convergence rate O( 1
Kϵ2 ) to achieve ϵ-accuracy solution, where K is the number of devices. It indicates that our methods can achieve the linear speedup with respect to the number of devices, which is consistent with decentralized SGD. To the best of our knowledge, our work is the first one to establish the convergence rate of decentralized SCGD and achieving the linear speedup. Moreover, the sample complexity of our methods is O( 1
Kϵ3 ). It indicates that our methods can achieve a better sample complexity O( 1
ϵ3 ) than O( 1
ϵ4 ) of traditional SCGD [20] when K = 1, which further confirms the superiority of our methods. Finally, we applied our proposed methods to optimize the model-agnostic meta-learning problem. The empirical results confirm the effectiveness of our methods. In the following, we summarize the contributions of our work.
• We proposed two novel decentralized stochastic compositional gradient descent methods:
GP-SCGD and GT-SCGD. This is the first work studying the decentralized training method for stochastic compositional optimization problems.
• We established the convergence rate of our decentralized stochastic compositional gradient descent methods with novel theoretical analysis. This is the first work establishing the convergence rate for decentralized SCGD and showing the linear speedup with respect to the number of devices. In addition, our methods can achieve better sample complexities than traditional SCGD.
• The extensive empirical evaluation on the model-agnostic meta-learning task confirms the effectiveness of our proposed methods. 2