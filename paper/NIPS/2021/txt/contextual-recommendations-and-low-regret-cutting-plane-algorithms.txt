Abstract
We consider the following variant of contextual linear bandits motivated by routing applications in navigational engines and recommendation systems. We wish to learn a hidden d-dimensional value w∗. Every round, we are presented with a subset Xt ⊆ Rd of possible actions. If we choose (i.e. recommend to the user) action xt, we obtain utility (cid:104)xt, w∗(cid:105) but only learn the identity of the best action arg maxx∈Xt(cid:104)x, w∗(cid:105).
We design algorithms for this problem which achieve regret O(d log T ) and exp(O(d log d)). To accomplish this, we design novel cutting-plane algorithms with low “regret” – the total distance between the true point w∗ and the hyperplanes the separation oracle returns.
We also consider the variant where we are allowed to provide a list of several recommendations. In this variant, we give an algorithm with O(d2 log d) regret and list size poly(d). Finally, we construct nearly tight algorithms for a weaker variant of this problem where the learner only learns the identity of an action that is better than the recommendation. Our results rely on new algorithmic techniques in convex geometry (including a variant of Steiner’s formula for the centroid of a convex set) which may be of independent interest. 1

Introduction
Consider the following problem faced by a geographical query service (e.g. Google Maps). When a user searches for a path between two endpoints, the service must return one route out of a set of possible routes. Each route has a multidimensional set of features associated with it, such as (i) travel time, (ii) amount of trafﬁc, (iii) how many turns it has, (iv) total distance, etc. The service must recommend one route to the user, but doesn’t a priori know how the user values these features relative to one another. However, when the service recommends a route, the service can observe some feedback from the user: whether or not the user followed the recommended route (and if not, which route the user ended up taking). How can the service use this feedback to learn the user’s preferences over time?
Similar problems are faced by recommendation systems in general, where every round a user arrives accompanied by some contextual information (e.g. their current search query, recent activity, etc.), the system makes a recommendation to the user, and the system can observe the eventual action (e.g. the purchase of a speciﬁc item) by the user. These problems can be viewed as speciﬁc cases of a variant of linear contextual bandits that we term contextual recommendation.
In contextual recommendation, there is a hidden vector w∗ ∈ Rd (e.g. representing the values of the user for different features) that is unknown to the learner. Every round t (for T rounds), the learner is presented with an adversarially chosen (and potentially very large) set of possible actions Xt. Each 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
element xt of Xt is also an element of Rd (visible to the learner); playing action xt results in the learner receiving a reward of (cid:104)xt, w∗(cid:105). The learner wishes to incur low regret compared to the best possible strategy in hindsight – i.e. the learner wishes to minimize (1) where x∗ t = arg maxx∈Xt(cid:104)x, w∗(cid:105) is the best possible action at time t. In our geographical query example, this regret corresponds to the difference between the utility of a user that always blindly follows our recommendation and the utility of a user that always chooses the optimal route. t , w∗(cid:105) − (cid:104)xt, w∗(cid:105)) , t=1 ((cid:104)x∗
Reg = (cid:80)T
Thus far this agrees with the usual set-up for contextual linear bandits (see e.g. [4]). Where contextual recommendation differs from this is in the feedback available to the learner: whereas classically in contextual linear bandits the learner learns (a possibly noisy version of) the reward they receive each round, in contextual recommendation the learner instead learns the identity of the best arm x∗ t .
This altered feedback makes it difﬁcult to apply existing algorithms for linear contextual bandits. In particular, algorithms like LINUCB and LIN-Rel [1, 4] all require estimates of (cid:104)xt, w∗(cid:105) in order to learn w∗ over time, and our feedback prevents us from obtaining any such absolute estimates.
In this paper we design low-regret algorithms for this problem. We present two algorithms for this problem: one with regret O(d log T ) and one with regret exp(O(d log d)) (Theorems 4.1 and 4.2).
Note that both regret guarantees are independent of the number of offered actions |Xt| (the latter even being independent of the time horizon T ). Moreover both of these algorithms are efﬁciently implementable given an efﬁcient procedure for optimizing a linear function over the sets Xt. This condition holds e.g. in the example of recommending shortest paths that we discussed earlier.
In addition to this, we consider two natural extensions of contextual recommendation where the learner is allowed to recommend a bounded subset of actions instead of just a single action (as is often the case in practice). In the ﬁrst variant, which we call list contextual recommendation, each round the learner recommends a set of at most L (for some ﬁxed L) actions to the learner. The learner still observes the user’s best action each round, but the loss of the learner is now the difference between the utility of the best action for the user and the best action offered by the learner (capturing the difference in utility between a user playing an optimal action and a user that always chooses the best action the learner offers).
In list contextual recommendation, the learner has the power to cover multiple different user prefer-ences simultaneously (e.g. presenting the user with the best route for various different measures). We show how to use this power to construct an algorithm for the learner which offers poly(d) actions each round and obtain a total regret of poly(d).
In the second variant, we relax an assumption of both previous models: that the user will always choose their best possible action (and hence that we will observe their best possible action). To relax this assumption, we also consider the following weaker version of contextual recommendation we call local contextual recommendation.
In this problem, the learner again recommends a set of at most L actions to the learner (for some
L > 1)1. The user then chooses an action which is at least as good as the best action in our list, and we observe this action. In other words, we assume the learner at least looks at all the options we offer, so if they choose an external option, it must be better than any offered option (but not necessarily the global optimum). Our regret in this case is the difference between the total utility of a learner that always follows the best recommendation in our list and the total utility of a learner that always plays their optimal action2.
Let A = maxt |Xt| be a bound on the total number of actions offered in any round, and let γ =
A/(L − 1). We construct algorithms for local contextual recommendation with regret O(γd log T ) and γ · exp(O(d log d)). We further show that the ﬁrst bound is “nearly tight” (up to poly(d) factors) in some regimes; in particular, we demonstrate an instance where L = 2 and K = 2Ω(d) 1Unlike in the previous two variants, it is important in local contextual recommendation that L > 1; if L = 1 then the user can simply report the action the learner recommended and the learner receives no meaningful feedback. 2In fact, our algorithms all work for a slightly stronger notion of regret, where the benchmark is the utility of a learner that always follows the ﬁrst (i.e. a speciﬁcally chosen) recommendation on our list. With this notion of regret, contextual recommendation reduces to local contextual recommendation with L = max |Xt|. 2
where any algorithm must incur regret at least min(2Ω(d), Ω(T )). The results for local contextual recommendation are included in the Supplementary Material. 1.1 Low-regret cutting plane methods and contextual search
To design these low-regret algorithms, we reduce the problem of contextual recommendation to a geometric online learning problem (potentially of independent interest). We present two different (but equivalent) viewpoints on this problem: one motivated by designing separation-oracle-based algorithms for convex optimization, and the other by contextual search. 1.1.1 Separation oracles and cutting-plane methods
Separation oracle methods (or “cutting-plane methods”) are an incredibly well-studied class of algorithms for linear and convex optimization. For our purposes, it will be convenient to describe cutting-plane methods as follows.
Let B = {w ∈ Rd | (cid:107)w(cid:107) ≤ 1} be the unit ball in Rd. We are searching for a hidden point w∗ ∈ B.
Every round we can choose a point pt ∈ B and submit this point to a separation oracle. The separation oracle then returns a half-space separating pt from w∗; in particular, the oracle returns a direction vt such that (cid:104)w∗, vt(cid:105) ≥ (cid:104)pt, vt(cid:105).
Traditionally, cutting-plane algorithms have been developed to minimize the number of calls to the separation oracle until the oracle returns a hyperplane that passes within some distance δ of w∗. For example, the ellipsoid method (which always queries the center of the currently-maintained ellipse) has the guarantee that it makes at most O(d2 log 1/δ) oracle queries before ﬁnding such a hyperplane.
In our setting, instead of trying to minimize the number of separation oracle queries before ﬁnding a “close” hyperplane, we would like to minimize the total (over all T rounds) distance between the returned hyperplanes and the hidden point w∗. That is, we would like to minimize the expression
Reg(cid:48) = (cid:80)T t=1 ((cid:104)w∗, vt(cid:105) − (cid:104)pt, vt(cid:105)) . (2)
Due to the similarity between (2) and (1), we call this quantity the regret of a cutting-plane algorithm.
We show that, given any low-regret cutting-plane algorithm, there exists a low-regret algorithm for contextual recommendation.
Theorem 1.1 (Restatement of Theorem 3.1). Given a low-regret cutting-plane algorithm A with regret ρ, we can construct an O(ρ)-regret algorithm for contextual recommendation.
This poses a natural question: what regret bounds are possible for cutting-plane methods? One might expect guarantees on existing cutting-plane algorithms to transfer over to regret bounds, but interestingly, this does not appear to be the case. In particular, most existing cutting-plane methods and analysis suffers from the following drawback: even if the method is likely to ﬁnd a hyperplane within distance δ relatively quickly, there is no guarantee that subsequent calls to the oracle will return low-regret hyperplanes.
In this paper, we will show how to design low-regret cutting-plane methods. Although our ﬁnal algorithms will bear some resemblance to existing cutting-plane algorithms (e.g. some involve cutting through the center-of-gravity of some convex set), our analysis will instead build off more recent work on the problem of contextual search. 1.1.2 Contextual search
Contextual search is an online learning problem initially motivated by applications in pricing [6].
The basic form of contextual search can be described as follows. As with the previously mentioned problems, there is a hidden vector w∗ ∈ [0, 1]d that we wish to learn over time. Every round the adversary provides the learner with a vector vt (the “context”). In response, the learner must guess the value of (cid:104)vt, w∗(cid:105), submitting a guess yt. The learner then incurs a loss of |(cid:104)vt, w∗(cid:105) − yt| (the distance between their guess and the true value of the inner product), but only learns whether (cid:104)vt, w∗(cid:105) is larger or smaller than their guess.
The problem of designing low-regret cutting plane methods can be interpreted as a “context-free” variant of contextual search. In this variant, the learner is no longer provided the context vt at the beginning of each round, and instead of guessing the value of (cid:104)vt, w∗(cid:105), they are told to directly 3
submit a guess pt for the point w∗. The context vt is then revealed to them after they submit their guess, where they are then told whether (cid:104)pt, w∗(cid:105) is larger or smaller than (cid:104)vt, w∗(cid:105) and incur loss
|(cid:104)vt, w∗(cid:105)−(cid:104)pt, w∗(cid:105)|. Note that this directly corresponds to querying a separation oracle with the point pt, and the separation oracle returning either the halfspace vt (in the case that (cid:104)w∗, vt(cid:105) ≥ (cid:104)w∗, pt(cid:105)) or the halfspace −vt (in the case that (cid:104)w∗, vt(cid:105) ≤ (cid:104)w∗, pt(cid:105)).
One advantage of this formulation is that (unlike in standard analyses of cutting-plane methods) the total loss in contextual search directly matches the expression in (2) for the regret of a cutting-plane method. In fact, were there to already exist an algorithm for contextual search which operated in the above manner – guessing (cid:104)vt, w∗(cid:105) by ﬁrst approximating w∗ and then computing the inner product – we could just apply this algorithm verbatim and get a cutting-plane method with the same regret bound. Unfortunately, both the algorithms of [7] and [6] explicitly require knowledge of the direction vt.
This formulation also raises an interesting subtlety in the power of the separation oracle: speciﬁcally, whether the direction vt is ﬁxed (up to sign) ahead of time or is allowed to depend on the point p. Speciﬁcally, we consider two different classes of separation oracles. For (strong) separation oracles, the direction vt is allowed to freely depend on the point pt (as long as it is indeed true that (cid:104)w∗, vt(cid:105) ≥ (cid:104)pt, vt(cid:105)). For weak separation oracles, the adversary ﬁxes a direction ut at the beginning of the round, and then returns either vt = ut or vt = −ut (depending on the sign of (cid:104)w∗ − pt, ut(cid:105)).
The strong variant is most natural when comparing to standard separation oracle guarantees (and is necessary for the reduction in Theorem 1.1), but for many standalone applications (especially those motivated by contextual search) the weak variant sufﬁces. In addition, the same techniques we use to construct a cutting-plane algorithm for weak separation oracles will let us design low-regret algorithms for list contextual recommendation. 1.2 Our results and techniques
We design the following low-regret cutting-plane algorithms: 1. An exp(O(d log d))-regret cutting-plane algorithm for strong separation oracles. 2. An O(d log T )-regret cutting-plane algorithm for strong separation oracles. 3. An O(poly(d))-regret cutting-plane algorithm for weak separation oracles.
All three algorithms are efﬁciently implementable (in poly(d, T ) time). Through Theorem 1.1, points (1) and (2) immediately imply the algorithms with regret exp(O(d)) and O(d log T ) for contextual recommendation. Although we do not have a blackbox reduction from weak separation oracles to algorithms for list contextual recommendation, we show how to apply the same ideas in the algorithm in point (3) to construct an O(d2 log d)-regret algorithm for list contextual recommendation with
L = poly(d).
To understand how these algorithms work, it is useful to have a high-level understanding of the algorithm of [7] for contextual search. That algorithm relies on a multiscale potential function the authors call the Steiner potential. The Steiner potential at scale r is given by the expression
Vol(Kt + rB), where Kt (the “knowledge set”) is the current set of possibilities for the hidden point w∗, B is the unit ball, and addition denotes Minkowsi sum; in other words, this is the volume of the set of points within distance r of Kt. The authors show that by choosing their guess yt carefully, they can decrease the r-scale Steiner potential (for some r roughly proportional to the width of Kt in the current direction vt) by a constant factor. In particular, they show that this is achieved by choosing yt so to divide the expanded set Kt + rB exactly in half by volume. Since the Steiner potential at scale r is bounded below by Vol(rB), this allows the authors to bound the total number of mistakes at this scale. (A more detailed description of this algorithm is provided in Section 2.2).
In the separation oracle setting, we do not know vt ahead of time, and thus cannot implement this algorithm as written. For example, we cannot guarantee our hyperplane splits Kt + rB exactly in half. We partially work around this by using (approximate variants of) Grunbaum’s theorem, which guarantees that any hyperplane through the center-of-gravity of a convex set splits that convex set into two pieces of roughly comparable volume. In other words, everywhere where the contextual search algorithm divides the volume of Kt + rB in half, Grunbaum’s theorem implies we obtain comparable results by choosing any hyperplane passing through the center-of-gravity of Kt + rB. 4
Unfortunately, we still cannot quite implement this in the separation oracle setting, since the choice of r in the contextual search algorithm depends on the input vector vt. Nonetheless, by modifying the analysis of contextual search we can still get some guarantees via simple methods of this form. In particular we show that always querying the center-of-gravity of Kt (alternatively, the center of the
John ellipsoid of Kt) results in an exp(O(d log d))-regret cutting-plane algorithm, and that always querying the center of gravity of Kt + 1
T B results in an O(d log T )-regret cutting-plane algorithm.
Our cutting-plane algorithm for weak separation oracles requires a more nuanced understanding of the family of sets of the form Kt + rB. This family of sets has a number of surprising algebraic properties. One such property (famous in convex geometry and used extensively in earlier algorithms for contextual search) is Steiner’s formula, which states that for any convex K, Vol(K + rB) is actually a polynomial in r with nonnegative coefﬁcients. These coefﬁcients are called intrinsic volumes and capture various geometric measures of the set K (including the volume and surface area of K).
There exists a lesser-known analogue of Steiner’s formula for the center-of-gravity of K + rB, which states that each coordinate of cg(K + rB) is a rational function of degree at most d; in other words, the curve cg(K + rB) for r ∈ [0, ∞) is a rational curve. Moreover, this variant of Steiner’s formula states that each point cg(K + rB) can be written as a convex combination of d + 1 points contained within K known as the curvature centroids of K. Motivated by this, we call the curve
ρK(r) = cg(K + rB) the curvature path of K.
Since the curvature path ρK is both bounded in algebraic degree and bounded in space (having to lie within the convex hull of the curvature centers), we can bound the total length of the curvature path
ρK by a polynomial in d (since it is bounded in degree, each component function of ρK can switch from increasing to decreasing a bounded number of times). This means that we can discretize the curvature path to within precision ε while only using poly(d)/ε points on the path.
Our algorithms against weak separation oracles and for list contextual recommendation both make extensive use of such a discretization. For example, we show that in order to construct a low-regret algorithm against a weak separation oracle, it sufﬁces to discretize ρKt into O(d4) points and then query a random point; with probability at least O(d−4), we will closely enough approximate the point
ρ(r) = cg(K + rB) that our above analogue of contextual search would have queried. We show this results in poly(d) total regret3. A similar strategy works for list contextual recommendation: there we discretize the curvature path for the knowledge set Kt into poly(d) candidate values for w∗, and then submit as our set of actions the best response for each of these candidates.