Abstract
Numerous recent works show that overparameterization implicitly reduces variance for min-norm interpolators and max-margin classiﬁers. These ﬁndings suggest that ridge regularization has vanishing beneﬁts in high dimensions. We challenge this narrative by showing that, even in the absence of noise, avoiding interpolation through ridge regularization can signiﬁcantly improve generalization. We prove this phenomenon for the robust risk of both linear regression and classiﬁcation, and hence provide the ﬁrst theoretical result on robust overﬁtting. 1

Introduction
L
Conventional statistical wisdom cautions the user who trains a model by minimizing a loss (θ): if a global minimizer achieves zero or near-zero training loss (i.e., it interpolates), we run the risk of overﬁtting (i.e., high variance) and thus suboptimal prediction performance. Instead, regularization is commonly used to reduce the effect of noise and to obtain an estimator with better generalization.
Speciﬁcally, regularization limits model complexity and induces worse data ﬁt, for example via an explicit penalty term R(θ). The resulting penalized loss (θ) + λR(θ) explicitly imposes certain structural properties on the minimizer. This classical rationale, however, does seemingly not apply to overparameterized models: for example, large neural networks in practice exhibit good generalization performance on i.i.d. samples even if (θ) vanishes and label noise is present [36].
L
L
→
Since interpolators are not unique in the overparameterized regime, it is crucial to study the speciﬁc implicit biases of interpolating estimators. In particular, for common losses, a large body of recent work analyzes the properties of the solutions found via gradient descent at convergence (see e.g. [44, 12, 13, 22, 26, 27, 49, 31]). For example, for linear and logistic regression, it is well-known that gradient descent converges to the min-(cid:96)2-norm and max-(cid:96)2-margin solutions, respectively [22, 27, 2 32, 49]. These interpolating estimators also minimize the respective penalized loss 2 in (cid:107) the limit of λ
θ (θ) + λ (cid:107) 0 [44].
L
A plethora of recent papers explicitly study generalization properties on min-(cid:96)2-norm interpolators [15, 18, 23, 6, 33, 34, 35] and max-(cid:96)2-margin solutions [14, 34, 46], and show that the variance decreases as the overparameterization ratio increases beyond the interpolation threshold. While regularization with λ > 0 is commonly known to reduce the risk at the interpolation threshold [23, 37], many of these works are motivated by the second descent of the double descent phenomenon [7] which suggests that regularization becomes redundant with sufﬁcient overparameterization. Hence, previous papers focus on highly overparameterized settings where the optimal regularization parameter satisﬁes 0 [29, 54, 43], implying that for large d/n, explicit regularization with λ > 0 is redundant or
λopt even detrimental for generalization.
≤
∗Equal contribution. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
(a) Neural networks (b) Linear regression (c) Linear classiﬁcation
Figure 1: Avoiding interpolation can beneﬁt robustness even in the overparameterized (d n) regime and for noiseless training data. We plot the robust accuracy gain of (a) early-stopped neural networks compared to models at convergence, ﬁt on sanitized (binary 1-3) MNIST that arguably has minimal noise; and (cid:96)2 regularized estimators compared to interpolators with λ 0 for (b) linear regression with n = 103 and (c) robust logistic regression with n = 103. See Appendix B for experimental details and Sections 3 and 4 for the precise settings of (b) and (c).
→ (cid:29)
Taking a step back, this narrative originated from theoretical and experimental ﬁndings that consider the standard test risk with identically distributed training and test data. However, this measure cannot reﬂect the robust risk of models when the test data has a shifted distribution, is attacked by adversaries, or contains many samples from minority groups [19, 21, 40, 55]. In fact, mounting empirical evidence suggests that regularization is indeed helpful for robust generalization, even in highly overparameterized regimes where the beneﬁts for the standard risk are negligible [42]. This phenomenon is sometimes referred to as robust overﬁtting.
In the presence of noise, the following intuition holds true: since the robust risk ampliﬁes estimation errors, its variance is larger and hence regularization – such as early stopping – can be beneﬁcial for generalization [47]. However, we observe that even when estimating entirely noiseless signals, robust overﬁtting persists! We observe this phenomenon in experiments with shallow neural networks on sanitized image data depicted in Figure 1a and, in fact, even for linear models trained on high-dimensional synthetic noiseless data. In particular, Figures 1b,1c show that min-(cid:96)2-norm and robust 0), achieve a higher robust max-(cid:96)2-margin interpolators (minimizers of the training loss for λ risk than the corresponding regularized estimators that do not interpolate noiseless observations (minimizers for λ > 0).
→
To date, our observations in the noiseless case cannot be explained by prior work. On the contrary, they seem to contradict a simple intuition: if the min-(cid:96)2-norm and robust max-(cid:96)2-margin interpolators exhibit large risks as λ 0, the induced bias for a small (cid:96)2-norm is potentially suboptimal and a larger penalty weight λ > 0 should only degrade performance. In this paper, we provide possible explanations that debunk this intuition in the high-dimensional overparameterized regime. We prove for isotropic Gaussian covariates that a strictly positive regularization parameter λ systematically improves robust generalization for linear and robust logistic regression. Empirically, we show that early stopping and other factors that lead to a non-interpolating estimator achieve a similar effect.
Our results provide the ﬁrst rigorous explanation of robust overﬁtting even in the absence of noise.
→
In Section 2, we formally deﬁne the setting that we use throughout our analysis. We then ﬁrst present precise asymptotic expressions for the robust risk for linear regression in Section 3 that explicitly explain robust overﬁtting. Furthermore, in Section 4, we consider classiﬁcation with logistic regression and derive asymptotic results. 2 Risk minimization framework
In this section, we introduce the data generating process that we assume throughout our analysis, and deﬁne the standard and robust risks that we use as evaluation metrics. 2
2.1 Problem setting
∈
Rd to a target y
This paper considers the supervised learning problem of estimating a mapping from d-dimensional real-valued features x
=
∈ Y ⊆
D n i=1. We assume that the feature vectors xi are drawn i.i.d. from the marginal distribution P (xi, yi)
}
{
θ(cid:63), xi(cid:105) that we assume to be an isotropic Gaussian. We further focus on noiseless observations yi = (cid:104)
θ(cid:63), xi(cid:105) for regression tasks and yi = sgn(
) for classiﬁcation tasks, respectively. However, the main (cid:104) results are more general and apply to noisy observations as well. For regression, we assume additive
Gaussian noise with zero mean and σ2 variance, while for classiﬁcation we ﬂip a certain percentage of the training labels.
R given a training set of labeled samples
This paper studies the high-dimensional asymptotic regime where d/n
γ as both the dimensionality d and the number of samples n tend to inﬁnity. This high-dimensional setting is widely studied as it can often – as in our experiments – yield precise predictions for the risk of the estimator when both the input dimension and the data set size are large [9, 52]. It is also the predominant setting considered in previous theoretical works that discuss overparameterized linear models [2, 14, 15, 23, 25, 24, 50].
→ 2.2 Standard and robust risk
We now introduce the standard and robust evaluation metrics for regression and classiﬁcation. Given
R, we deﬁne the standard (population) risk of an estimator ˆθ as a pointwise test loss (cid:96)test : R (cid:17)
→
×
R (cid:16)
R(ˆθ) := EX
P(cid:96)test
∼
ˆθ, X (cid:104)
, (cid:105)
θ(cid:63), X (cid:104) (cid:105)
, (1) where the expectation is taken over the marginal feature distribution P. Note that for any data-dependent estimator ˆθ, this risk is ﬁxed if conditioned on the training data. Our asymptotic bounds hold almost surely over draws of the training set. As standard in the literature, we choose the square loss (cid:96)test(u, v) = (u
=sgn(v) for classiﬁcation. v)2 for regression and the 0-1 loss (cid:96)test(u, v) = 1 sgn(u)
−
The broad application of ML models in real-world decision-making processes increases requirements on their generalization abilities beyond i.i.d. test sets. For example, in the image domain, classiﬁers should be robust and output the same prediction for perturbations of an image that do not change the ground truth label (e.g., imperceptible (cid:96)p-perturbations [19]). In this case, we say the perturbations are consistent and the estimator that achieves zero robust population risk also has zero standard population risk. For linear models in particular, one way to enforce consistency is to restrict perturbations to the space orthogonal to the ground truth, as proposed in [41].
Motivated by the imperceptibility assumption and (cid:96)p-adversarial attacks widely studied in the image domain, we consider the adversarially robust risk of a parameter θ with respect to consistent (cid:96)p-perturbations
R(cid:15)(ˆθ) := EX (cid:96)test(
ˆθ, X + δ (cid:104)
, (cid:105)
θ(cid:63), X (cid:104) (cid:105)
) , (2)
∼
δ
P max p((cid:15))
∈U
Rd :
δ
Up((cid:15)) :=
δ
{ with the perturbation set (cid:107)
∈ (cid:107)p ≤
In many scientiﬁc applications, security against adversarial attacks may not be the dominating concern; one may instead require estimators to be robust against small distribution shifts. Earlier work [48] has pointed out that distribution shift robustness and adversarial robustness are equivalent for losses that are convex in the parameter θ. Similarly, in our setting, adversarial robustness against consistent (cid:96)p-perturbations implies distributional robustness against (cid:96)p-bounded mean shifts in the covariate distribution P (see Appendix A.3). (cid:105) (cid:15) and
θ(cid:63), δ (cid:104)
.
= 0
} 3 Min-(cid:96)2-norm interpolation in robust linear regression
In the context of regression, we illustrate overﬁtting of the robust risk in Equation (2) with the
U2((cid:15)). More precisely, we show that preventing min-(cid:96)2-norm set of consistent (cid:96)2-perturbations interpolation on noiseless samples via ridge regularization improves the robust risk. We refer the reader to Appendix C.1 for an intuitive explanation. Lastly, we note that due to the rotational invariance of the problem, our results hold for sparse and dense ground truths θ(cid:63) alike. 3 (cid:54)
3.1
Interpolating and regularized estimator
We study linear ridge regression estimates deﬁned as
ˆθλ = arg min
θ 1 n n (cid:88) i=0 (yi − (cid:104)
)2 + λ
θ, xi(cid:105)
θ (cid:107) 2 2. (cid:107) (3)
The min-(cid:96)2-norm interpolator is the limit of the linear ridge regression estimate with λ given by
→ 0 and is
ˆθ0 = arg min
θ
θ (cid:107) (cid:107)2 such that
θ, xi(cid:105) (cid:104)
= yi for all i. (4)
→
Note that the min-(cid:96)2-norm interpolator is also the estimator that gradient descent on the unregularized loss converges to, while ridge regression with λ > 0 corresponds to early-stopped estimators [1, 2].
Therefore, by proving that a ridge regularized estimator with λ > 0 signiﬁcantly outperforms the 0, we also show that early stopping beneﬁts robust generalization. min-(cid:96)2-norm interpolator with λ
Whenever the goal is to achieve a low robust risk, a popular alternative to using the standard linear regression estimate in Equations (3),(4) is to consider adversarially trained estimators [19, 25].
However, (cid:96)2-adversarial training in its usual form (i.e., with inconsistent perturbations) prevents regression estimators from interpolating, and hence, has a similar effect to (cid:96)2-regularization as we discuss in more detail in Appendix C.2. On the other hand, training with consistent perturbations as deﬁned in the robust risk is equivalent to full knowledge of the direction of θ(cid:63) and hence simply recovers the ground truth in the noiseless case. Since our goal is to reveal the shortcomings of interpolators compared to regularized estimators, we only analyze ridge estimators trained without perturbations. 3.2 Robust overﬁtting in noiseless linear regression
The following theorem provides a precise asymptotic expression of the robust risk under consistent (cid:96)2-perturbations for the ridge regression estimate in Equation (3). The proof extends techniques from previous works [23, 15] based on results from random matrix theory [3, 28] and can be found in
Appendix E. Without loss of generality, we can assume that (cid:107)
Theorem 3.1. Assuming the marginal input distribution P =
N mator ˆθλ for λ > 0 (deﬁned in (3)) with respect to consistent (cid:96)2-perturbations converges to (cid:107)2 = 1. (0, Id), the robust risk (2) of the esti-U2((cid:15)) asymptotically
θ(cid:63)
R(cid:15)(ˆθλ) (cid:114) a.s.
−→ Rλ + (cid:15)2 d/n
Pλ +
γ, 8(cid:15)2
π PλRλ =: where
R(cid:15),λ (5) and as d, n
→
∞
λ) + σ2γ(m(
Rλ = λ2m(cid:48)(
−→ Rλ.
−
The function m(z) is the Stieltjes transform of the Marchenko-Pastur law and is given by
→
−
λ)) is the asymptotic standard risk, i.e., R(ˆθλ)
Pλ =
Rλ −
λm(cid:48)( with
λ)
λ))2 a.s.
λ2(m(
−
−
− 1
γ z
√(1
γ z)2 4γz
−
−
− 0 and
. Further, the limit limλ m(z) = corresponds to the asymptotic standard ((cid:15) = 0) and robust risks ((cid:15) > 0) of the min-(cid:96)2-norm interpolator ˆθ0 (4). 0 R(cid:15),λ exists for all (cid:15)
− 2γz
≥
→
−
−
We plot the precise asymptotic risks of the ridge estimate with optimal regularization parameter λopt 0 in Figure 2. For the robust risk, we use (cid:15) = 0.4. We and of the min-(cid:96)2-norm interpolator for λ
→
ﬁrst observe in Figure 2a that ridge regularization reduces the robust risk even for d/n 1 well beyond the interpolation threshold – the regime where previous works show that the variance is negligible, and hence, regularization does not improve generalization. (cid:29) 2
Moreover, Figure 2b illustrates that the beneﬁcial effect of ridge regularization persists even for noiseless data. This supports our statement that regularization not only helps to reduce variance, but also reduces the part of the robust risk that is unaffected by noise in the overparameterized regime.
Furthermore, we show that experiments run with ﬁnite values of d and n (depicted by the markers in
γ. This
Figure 2) closely match the predictions obtained from Theorem 3.1 for d, n and d/n
→ ∞
→ 2Here we choose λ using the population risk oracle. In practice, one would resort to standard tools such as cross-validation techniques that also enjoy theoretical guarantees (see e.g. [38]). 4
(a) Noisy observations (b) Noiseless observations
Figure 2: Asymptotic theoretical predictions for d, n (curves) and experimental results with ﬁnite d and n = 103 (markers) for the robust ((cid:15) = 0.4) and standard risk of the min-(cid:96)2-norm interpolator (solid, interpolating) and the ridge regression estimate with optimal λ (dashed, regularized) for (a) noisy data with σ2 = 0.2 and (b) noiseless data. We observe that the gap between the robust risk of the interpolating and optimally regularized estimators persists even for noiseless observations.
→ ∞ indicates that the high-dimensional asymptotic regime does indeed correctly predict and characterize the high-dimensional non-asymptotic regime. Finally, even though Theorem 3.1 assumes isotropic
Gaussian covariates, we can extend it to more general covariance matrices following the same argument as in [23], based on results from random matrix theory [28]. 4 Max-(cid:96)2-margin interpolation in robust linear classiﬁcation
Unlike linear regression, adversarially trained binary logistic regression classiﬁers may still inter-polate the training data, resulting in robust max-(cid:96)2-margin interpolators as λ 0. Hence, in this section we train and evaluate classiﬁers with (cid:96) ((cid:15)), a standard choice in the experimental and theoretical classiﬁcation literature [19, 24, 42, 47], but also discuss (cid:96)2-perturbations in Appendix D.3 for completeness. Our theoretical results show that the robust max-(cid:96)2-margin interpolator with λ 0 has a worse robust risk than a regularized predictor with λ > 0.
-perturbation sets
U∞
→
∞
→ 4.1
Interpolating and regularized estimator
As discussed in Section 3, a common method to obtain robust estimators is to use adversarial training.
However, for linear regression, adversarial training either renders interpolating estimators infeasible, or requires oracle knowledge of the ground truth. In contrast, for linear classiﬁcation, interpolation is easier to achieve – it only requires the sign of to be the same as the label yi for all i. In xi, θ (cid:104) particular, when the data is sufﬁciently high dimensional, it is possible to ﬁnd an interpolator of the adversarially perturbed training set. (cid:105)
We study the robust ridge-regularized logistic regression estimator with penalty weight λ > 0,
ˆθλ := arg min
θ 1 n n (cid:88) i=1 max
∈U
∞((cid:15))
δ log(1 + e−(cid:104)
θ,xi+δ yi) + λ (cid:105)
θ (cid:107) 2 2. (cid:107) (6)
In the limit λ estimator from Equation (6) directionally aligns with the robust max-(cid:96)2-margin interpolator:3 0 the results in [44] imply that the robust ridge-regularized logistic regression
→
ˆθ0 := arg min
θ (cid:107)
θ (cid:107)2 such that min
δ
∞((cid:15))
∈U
θ, xi + δ yi(cid:104) (cid:105) ≥ 1 for all i. (7) 3While [44] only proves the result for (cid:15) = 0, it is straightforward to extend it to the general case where (cid:15) ≥ 0. 5
(a) Beneﬁt of ridge regularization (b) Beneﬁt of early stopping
Figure 3: Normalized robust margins and risks of empirical simulations using (cid:15) = 0.1 and d/n = 8, with respect to (a) increasing 1/λ and (b) gradient descent iterations when minimizing Equation (6) using λ = 0. Both ridge regularization and early stopping yield superior robust and standard risks.
Each experiment uses n = 103 and inconsistent (cid:96)
-perturbations for training. See Appendix B for more details.
∞
We say that the data is robustly separable if the robust max-(cid:96)2-margin interpolator exists.
The robust max-(cid:96)2-margin solution is an interpolating estimator of particular importance since it directionally aligns with the estimator found by gradient descent [31]. Since the robust accuracy (i.e., the robust risk deﬁned using the 0-1 loss) is independent of the norm of the estimator, we simply refer to the robust max-(cid:96)2-margin solution as the normalized vector
.
ˆθ0
ˆθ0 (cid:107) 2 (cid:107)
In this paper, we study two choices for the set of training perturbations ((cid:15)):
U∞ inconsistent perturbations consistent perturbations ((cid:15)) =
{
U∞
U∞
δ
∈ ((cid:15)) =
Rd :
{
δ
δ
∈
Rd : (cid:15), (cid:107) (cid:107)∞ ≤ (cid:107)∞ ≤
δ (cid:107)
δ, θ(cid:63) (cid:104) (cid:105) (cid:15)
}
= 0
} (8) (9)
Adversarial training with respect to inconsistent perturbations (8) is a popular choice in the literature to improve the robust risk (e.g. [19, 24]). However, perturbed samples may cross the true decision boundary, and hence, inconsistent perturbations effectively introduce noise during the training procedure. In particular, in the data model with noiseless observations that we introduce in Section 4.2, the ground truth function misclassiﬁes approximately 8% of the labels when perturbing the training data with inconsistent perturbations of size (cid:15) = 0.1.
As mentioned in the introduction, in this paper we are interested in verifying whether regularization can be beneﬁcial in high dimensions even in the absence of noise. Therefore, in the sequel we study the impact of both inconsistent (8) and consistent (9) perturbations on robust overﬁtting. 4.2 Robust overﬁtting in noiseless linear classiﬁcation
We now show empirically that regularization helps to improve the robust and standard risks when training with noiseless data and derive precise asymptotic predictions for both risks. Throughout xi, θ(cid:63)
. this subsection we assume deterministic, and hence, noiseless training labels, i.e., yi = sgn (cid:105) (cid:104)
Furthermore, as we discuss in Section 4.3, the inductive bias of the (cid:96)
-robust logistic loss encourages sparse solutions. Since we are primarily interested in learning ground truth functions that match the implicit bias of the estimator, we assume the sparse ground truth θ(cid:63) = (1, 0, . . . , 0)T .
∞
We ﬁrst show robust overﬁtting experimentally on noiseless data when training with inconsistent perturbations and subsequently demonstrate that overﬁtting persists even if the training procedure is completely noiseless (i.e., using consistent training perturbations). Finally, we provide theoretical evidence for our observations in the high-dimensional asymptotic limit. 6
∈U 1
θ
∞((cid:15))
Training with inconsistent adversarial perturbations Figure 3a illustrates the robust margin as well as the standard and robust risks of the estimator ˆθλ trained mini minδ using inconsistent adversarial perturbations on a synthetic data set with ﬁxed overparameterization ratio d/n = 8. We observe that decreasing the ridge coefﬁcient well beyond the point where the minimizer of the robust logistic loss (6) reaches 100% robust training accuracy (i.e., the robust margin becomes positive) substantially hurts generalization.
θ, xi + δ yi(cid:104) 2 (cid:107) (cid:105) (cid:107)
In addition to varying the ridge coefﬁcient λ, we notice that the same trends as for λ 0 also occur for the gradient descent optimization path as the number of iterations t goes to inﬁnity. Figure 3b indicates that, similarly to ridge regularization, early stopping also avoids the robust max-(cid:96)2-margin and yields an estimator with signiﬁcantly lower standard and solution that is obtained for t robust risks.
→ ∞
→
Training with consistent adversarial perturbations As discussed in Section 4.1, even for noiseless training data, inconsistent perturbations can induce noise during the training procedure. Hence, one could hypothesize that the noise induced by the inconsistent perturbations causes the overﬁtting observed in Figure 3. To contradict this hypothesis, we also study adversarial training with consistent perturbations. By deﬁnition, consistent perturbations do not cross the true decision boundary and hence leave the training data entirely noiseless.
Figure 4a shows that the adversarially trained estimators (6),(7) with consistent and inconsistent perturbations yield comparable robust risks. Moreover, robust overﬁtting occurs in both situations, as the risk is higher for the interpolating estimator λ 0 compared to an optimal λ > 0. Hence, our observations demonstrate that robust overﬁtting persists even if training with consistent perturbations in an entirely noiseless setting. This observation is counter intuitive since, according to classical wisdom, we would expect ridge regularization to only beneﬁt in noisy settings where the estimator suffers from a high variance.
→
→
γ as d, n
We now prove this phenomenon using the next theorem. In particular, similar to Theorem 3.1 for linear regression, we show that robust overﬁtting occurs in the high-dimensional asymptotic regime where d/n
. We state an informal version of the theorem in the main text and refer
→ ∞ to Appendix F for the precise statement. The proof is inspired by the works [24, 46] and uses the
Convex Gaussian Minimax Theorem (CGMT) [20, 51].
Theorem 4.1 (Informal). Assume that (cid:15) = (cid:15)0/√d for some constant (cid:15)0 and θ(cid:63) = (1, 0,
, 0)T .
Then, the robust and standard risks of the regularized estimator ˆθλ (6) (λ > 0) and of the robust max-(cid:96)2-margin interpolator (7) (λ
-perturbations converge in probability as d, n 0) with inconsistent (8) or consistent (9) adversarial (cid:96)
· · ·
→
∞
R(ˆθλ) 1
π
→ arccos (cid:19) (cid:18) ν(cid:63) (cid:107)
ν(cid:63) and R(cid:15)(ˆθλ)
, d/n
→
R(ˆθλ) +
γ to: 1 2 erf
→ ∞
→ (cid:19) (cid:18) (cid:15)0δ(cid:63)
√2ν(cid:63)
+ I (cid:19) (cid:18) (cid:15)0δ(cid:63)
ν(cid:63) ,
ν(cid:63) (cid:107)
ν(cid:63)
We denote by erf(.) the error function, (cid:90) t 0 1
√2π exp (cid:18)
− (cid:19) x2 2 (cid:32) erf (cid:112) (cid:33) dx, xu 2(1
− u2)
I(t, u) := (cid:113) and use the notation ν(cid:63) =
)2 + (ν(cid:63) (cid:107) optimization problem speciﬁed in Appendix F that depends on θ(cid:63), γ, (cid:15)0 and λ.
)2, where ν(cid:63)
⊥ (ν(cid:63)
⊥
, ν(cid:63) (cid:107)
, δ(cid:63) are the unique solution of a scalar
Since the theoretical expressions are hard to interpret, we visualize the asymptotic values of the standard and robust risks from Theorem 4.1 in Figure 4b by solving the scalar optimization problem speciﬁed in Appendix F. We observe that Theorem 4.1 indeed predicts the beneﬁts of regularization for robust logistic regression and that simulations using ﬁnite values of d and n follow the asymptotic trend. We describe the full empirical setup in Appendix B. 4.3
Intuitive explanation and discussion
Even though we explicitly derive the precise asymptotic expressions of the standard and robust risks in Theorem 4.1 that predict the beneﬁts of regularization for generalization, it is difﬁcult to extract intuitive explanations for this phenomenon directly from the proof. We conjecture that a non-zero 7
(a) Fixed (cid:15) = 0.1 for increasing d (b) Fixed n, d and asymptotic predictions
Figure 4: (a) Comparison of consistent and inconsistent (cid:96)
-perturbations for adversarial logistic regression with respect to the degree of overparameterization d/n, using (cid:15) = 0.1 for both training and evaluation. Note that both estimators behave very similarly, implying that the effect of inconsistency is negligible for small (cid:15). (b) Robust and standard risks of the robust max-(cid:96)2-margin interpolator 0) and robust ridge estimate (λ = 1) with consistent perturbations (9) using (cid:15) = 0.05 as a (λ function of the overparameterization ratio d/n for simulations (markers) and asymptotic theoretical predictions from Theorem 4.1 (lines). We note that, for small values of γ, solving the optimization problem that gives the theoretical predictions becomes numerically unstable. All simulations use n = 103 samples from our data model; see Appendix B for further experimental details.
→
∞
∞ ridge penalty induces a more sparse ˆθλ (i.e., with a smaller (cid:96)1/(cid:96)2-norm ratio) than the robust max-(cid:96)2-margin solution ˆθ0 and use simulations to support our claim. Since the (cid:96)
-adversarially robust risk penalizes dense solutions with large ratio of the (cid:96)1/(cid:96)2-norms (see Lemma A.2 in Appendix A.2), we expect more sparse estimators to have a lower robust risk. Indeed, Figure 5a shows that the (cid:96)1/(cid:96)2-norm ratio strongly correlates with the robust risk of the estimator.
We begin by noting that, due to Lagrangian duality, minimizing the ridge-penalized loss (6) corre-sponds to minimizing the unregularized loss constrained to the set of estimators θ with a bounded (cid:96)2-norm. This norm decreases as the ridge coefﬁcient λ increases. In what follows, we provide intuition on the effect of the ridge penalty λ on the sparsity of the estimator ˆθλ.
Large λ inducing a small (cid:96)2-norm We ﬁrst analyze the regularized estimator ˆθλ for large λ that constrains solutions to have small (cid:96)2-norm. We can therefore use Taylor’s theorem and the closed-form expression of adversarial perturbations (see Lemma A.2 in Appendix A.2) to approximate the unregularized robust loss from Equation (6) as follows: 1 n n (cid:88) i=1 log(1 + e−
θ,xi yi (cid:104) (cid:105)
+(cid:15) (cid:107)
Π⊥θ 1) (cid:107) 1 n n (cid:88) i=1
≈ xi, θ yi(cid:104)
Π
+ (cid:15) (cid:107)
⊥
θ (cid:107)1. (cid:105)
− (10) (cid:80)n
As a consequence, the minimizer ˆθλ should result in a large robust average margin solution, that is, a solution with large 1 (cid:107)1). Indeed, we observe this using simulations
Π n
⊥ for ﬁnite d, n in Figures 5b and 5c. In particular, the objective in Equation (10) leads to a trade-off between the sparsity of the estimator (via its convex surrogate, the (cid:96)1-norm) and an average of the
. We note that such estimators have been well studied in the literature sample-wise margins yi(cid:104) and are known to achieve good performance in recovering sparse ground truths [5, 17, 39]. (yi(cid:104) xi, θ xi, θ (cid:105) − i=1 1
θ (cid:107)
θ (cid:15) (cid:105) (cid:107) (cid:107) 2
Small λ inducing a large (cid:96)2-norm In contrast, a small ridge coefﬁcient λ leads to estimators
ˆθλ with large (cid:96)2-norms. In this case, the estimator approaches a large robust (minimum) margin (cid:107)1) which is maximized by the solution, i.e., a solution with large mini (yi(cid:104) robust max-(cid:96)2-margin interpolator (7). As a consequence, this leads to a trade-off between estimator 1 sparsity and the robust minimum margin mini
. Due to the high dimensionality of the
θ (cid:105) (cid:107) input data, the training samples xi are approximately orthogonal. Thus, to achieve a non-vanishing robust margin, estimators are forced to trade-off sparsity with all sample-wise margins instead of just
Π (cid:107) yi(cid:104) xi, θ xi, θ (cid:105) − 1
θ
θ
⊥ (cid:15) (cid:107) (cid:107) (cid:107) 2 2 8
(a) Sparsity of ˆθλ (b) Robust margin of ˆθλ (c) Robust margin decay of ˆθλ (cid:15)
θ xi, θ
Π (cid:107)
Figure 5: (a) The (cid:96)1-norm and the rescaled (by a factor of 10) robust risk of the estimator with respect to 1/λ. (b) The robust average margin contrasted to the robust margin as a function of 1/λ. The horizontal lines denote the corresponding values for θ(cid:63). (c) The ordered sample-wise robust margins (cid:107)1 when interpolating and regularizing. For larger λ, the robust (minimum) margin yi(cid:104) (cid:105) − decreases while the robust average margin (horizontal lines) increases. We normalize the estimators,
ˆθλ(cid:107)2 = 1, for all curves presented in the plots; see Appendix B for further experimental details. i.e., the average. We reveal this trade-off in Figures 5a and 5b where the increase in (cid:96)1/(cid:96)2-norm ratios corresponds to a decrease in the robust average margin and an increase in the robust margin. (cid:107)
⊥
Finally, we observe that the sparse ground truth is characterized by a large robust average margin (horizontal dotted line in Figure 5b) and a small (minimum) robust margin (horizontal dashed line). Therefore, we expect that the solution that is sparser and which satisﬁes the same properties for the robust margin as the ground truth θ(cid:63), will achieve lower robust and standard risks. Indeed, our ﬁndings indicate that the regularized estimator ˆθλ for large λ aligns better with θ(cid:63), compared to the solution obtained for a small λ, and hence justify the better performance of ridge-regularized predictors. 4.4 Beneﬁts of an unorthodox way to avoid the robust max-(cid:96)2-margin interpolator
In the previous subsections we focused on robustly separable data and studied the generalization performance of regularized estimators that do not maximize the robust margin. Another way to avoid the robust max-(cid:96)2-margin solution is to introduce enough label noise in the training data. We now show that, unexpectedly, this unorthodox way to avoid the robust max-margin solution can also yield an estimator with better robust generalization than the robust max-(cid:96)2-margin solution of the corresponding noiseless problem.
Speciﬁcally, in our experiments we introduce noise by ﬂipping the labels of a ﬁxed fraction of the training data. Figure 6 shows the robust and standard risks together with the training loss of the estimator ˆθλ from Equation (6) trained with consistent perturbations for λ 0 with varying fractions of ﬂipped labels. For low noise levels, the data is robustly separable and the training loss vanishes at convergence, yielding the robust max-(cid:96)2-margin solution in Equation (7). For high enough noise levels, the constraints in Equation (7) become infeasible and the training loss of the resulting estimator starts to increase. As discussed in Subsection 4.3, this estimator has a better implicit bias than the robust max-(cid:96)2-margin interpolator and hence achieves a lower robust risk.
Even though it is well known that introducing covariate noise can induce implicit regularization [8], our observations show that in contrast to common intuition, the robust risk also decreases when introducing wrong labels in the training loss. In parallel to our work, the paper [30] shows that training with corrupted labels can be beneﬁcial for the standard risk.
→
However, we emphasize here that we do not advocate in favor of artiﬁcial label noise as a means to obtain more robust classiﬁers. In particular, even if the data is not robustly separable, the estimator with optimal ridge parameter λopt in Figure 6 still always outperforms the unregularized solution. 9
× 103 and n = 103. We observe for unregularized estimators (λ
Figure 6: Training loss and robust risks with respect to increasing training label noise for (cid:15) = 0.1, 0) that, counterintuitively, d = 8 moderate amounts of label noise decrease the robust risk by avoiding the robust max-(cid:96)2-margin solution. While this might spuriously imply that injecting label noise increases robustness, estimators with optimal ridge parameter λopt still outperform their unregularized counterparts in terms of robust risk. Since the setting is noisy, we average the risks over ﬁve independent dataset draws and indicate standard deviations via error bars.
→
Finally, we remark that a similar effect can also be observed when training with inconsistent perturba-tions with large perturbation norm (cid:15). We refer to Appendix D.1 for further discussion. 5