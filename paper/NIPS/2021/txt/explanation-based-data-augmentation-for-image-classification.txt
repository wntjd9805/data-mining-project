Abstract
Existing works have generated explanations for deep neural network decisions to provide insights into model behavior. We observe that these explanations can also be used to identify concepts that caused misclassiﬁcations. This allows us to understand the possible limitations of the dataset used to train the model, particularly the under-represented regions in the dataset. This work proposes a framework that utilizes concept-based explanations to automatically augment the dataset with new images that can cover these under-represented regions to improve the model performance. The framework is able to use the explanations generated by both interpretable classiﬁers and post-hoc explanations from black-box classiﬁers.
Experiment results demonstrate that the proposed approach improves the accuracy of classiﬁers compared to state-of-the-art augmentation strategies. 1

Introduction
Machine learning models learn decision boundaries based on the training dataset. Ideally, a training dataset should provide sufﬁcient variations in each class so that the model can learn the correct decision boundaries. However, when there are under-represented regions in the training dataset, the model will learn sub-optimal decision boundaries, leading to misclassiﬁcation of data points [1, 2].
One way to address this problem is to augment the training dataset. A common data augmentation approach is to apply different transformations to the training samples [3] or to mix existing samples
[4, 5]. However, such data augmentations only explore the neighborhood of these samples and may not cover the under-represented regions. Another approach is to use annotations such as part landmarks to obtain images from image resources such as Flickr or Google [6]. This approach may introduce out-of-distribution images and degrade the classiﬁer performance.
Identifying the appropriate samples to add to the training dataset is crucial. Here, we propose to use model decision explanations to facilitate the search for samples from image repositories and augment the training dataset with samples from the under-represented regions to enable the model to learn the correct decision boundaries. Figure 1a shows the image of a juvenile Black Tern that has been misclassiﬁed as White Breasted Nuthatch. A closer examination of the training dataset reveals that it contains very few images of juvenile Black Terns (5 out of 30 images). These juvenile birds have white heads with black skullcap and black earmark, unlike the adult Black Terns [7] (see Figure 1b).
In fact, the juvenile Black Tern in Figure 1a is more similar to White Breasted Nuthatch as shown in
Figure 1c, leading to the misclassiﬁcation. Clearly, there is a need to augment the training data to include more images of juvenile Black Tern in order to learn the correct decision boundary between
Black Terns and White Breasted Nuthatch.
Methods to explain model decisions include pixel-level attributions [8, 9, 10], and high-level semantic concepts such as coarse-grained saliency maps [11, 12], interpretable basis decomposition [13], linguistic explanations [14, 15] and prototypes [16]. The work in [17] designs a Comprehensive 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
(a) Juvenile black tern. (b) Images of adult black tern. (c) Images of white breasted nuthatch.
Figure 1: Example of juvenile black tern that is misclassiﬁed as white breasted nuthatch.
Convolutional Neural Network called CCNN that explains the model decision in terms of word phrases, e.g., the bird in Figure 1a is classiﬁed as White Breasted Nuthatch due to the concepts ’white breast’, ’white belly’, ’long beak’.
This paper introduces a framework called BRACE (BetteR Accuracy from Concept-based Explana-tion), which utilizes concept-based explanations to identify candidate samples from image repositories for data augmentation. The key idea is to identify concepts that have led to misclassiﬁcations and augment the dataset with images that contain these concepts. We design a utility function that computes the degree of match between the visual features in an image and the set of concepts in the under-represented regions. The proposed approach enables us to select samples with high utility scores and increase the representativeness of the training dataset. Experiment results on multiple datasets demonstrate that BRACE outperforms state-of-the-art augmentation methods. 2