Abstract
Bounding box (bbox) regression is a fundamental task in computer vision. So far, the most commonly used loss functions for bbox regression are the Intersection over Union (IoU) loss and its variants. In this paper, we generalize existing IoU-based losses to a new family of power IoU losses that have a power IoU term and an additional power regularization term with a single power parameter α.
We call this new family of losses the α-IoU losses and analyze properties such as order preservingness and loss/gradient reweighting. Experiments on multiple object detection benchmarks and models demonstrate that α-IoU losses, 1) can surpass existing IoU-based losses by a noticeable performance margin; 2) offer detectors more ﬂexibility in achieving different levels of bbox regression accuracy by modulating α; and 3) are more robust to small datasets and noisy bboxes. 1

Introduction
Bounding box (bbox) regression localizes an object in an image/video by predicting a bbox for the object, which is fundamental to object detection, localization, and tracking. For example, the most advanced object detectors often consist of a bbox regression branch and a classiﬁcation branch with the bbox regression branch generating bboxes to localize objects for classiﬁcation. In this work, we explore more effective loss functions for bbox regression in the context of object detection.
Whilst early works in object detection use (cid:96)n-norm losses [11] for bbox regression, recent works directly adopt the localization performance metric, i.e., Intersection over Union (IoU), as the local-ization loss [28, 39]. Compared with (cid:96)n-norm losses, the IoU loss is invariant to bbox scales, thus helping train better detectors. However, the IoU loss suffers from the gradient vanishing problem when the predicted bboxes are not overlapping with the ground truth, which tends to slow down convergence and result in inaccurate detectors. This has motivated the design of several improved
IoU-based losses including Generalized IoU (GIoU), Distance-IoU (DIoU) and Complete IoU (CIoU).
GIoU introduces a penalty term into the IoU loss to alleviate the gradient vanishing problem [32], while DIoU and CIoU consider the central point distance and aspect ratio between predicted bboxes and their ground truth in penalty terms [43].
In this paper, we present a new family of IoU losses obtained by applying power transformations to existing IoU-based losses. We ﬁrst apply the Box-Cox transformation [2] to the IoU loss LIoU = 1 − IoU and generalize it to a power IoU loss: Lα-IoU = (1 − IoU α)/α, α > 0, denoted as α-IoU.
We further simplify α-IoU to Lα-IoU = 1 − IoU α for α (cid:57) 0 and extend it to a more general form 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
∗This research was done when Jiabo He interned with the DAMO Academy, Alibaba Group.
†Corresponding authors.
with an additional power regularization term (see equation (3)). This allows us to generalize existing
IoU-based losses, including GIoU, DIoU, and CIoU, to a new family of power IoU losses (see equation (4)) for more accurate bbox regression as well as object detection.
We show that, relative to LIoU, Lα-IoU with α > 1 up-weights both the loss and gradient of high IoU objects, leading to improved bbox regression accuracy. When 0 < α < 1, it down-weights high
IoU objects which we ﬁnd hurts regression accuracy. The power parameter α can serve as a knob to adapt α-IoU losses to meeting different levels of bbox regression accuracy (precision measured under different IoU thresholds), with α > 1 for high regression accuracy (i.e., high IoU thresholds) by focusing more on those high IoU objects. We also empirically show that α is not overly sensitive to different models or datasets, with α = 3 performing consistently well in most cases. The family of
α-IoU losses can be easily applied for improving state-of-the-art detectors under both clean and noisy bbox settings without introducing additional parameters to these models (making any modiﬁcations to training algorithms), nor increasing their training/inference time.
In summary, our main contributions are as follows:
• We propose a new family of power IoU losses called α-IoU for accurate bbox regression and object detection. α-IoU presents a uniﬁed power generalization of existing IoU-based losses.
• We analyze a set of properties of α-IoU, including order preservingness and loss/gradient reweight-ing, to show that a proper choice of α (i.e., α > 1) can help improve bbox regression accuracy by adaptively up-weighting the loss and gradient of high IoU objects.
• We empirically show, on multiple benchmark object detection datasets and models, that α-IoU losses can consistently outperform existing IoU-based losses and provide more robustness for small datasets and noisy bboxes. 2