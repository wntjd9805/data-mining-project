Abstract
Distributed learning paradigms such as federated learning often involve transmis-sion of model updates, or gradients, over a network, thereby avoiding transmission of private data. However, it is possible for sensitive information about the training data to be revealed from such gradients. Prior works have demonstrated that labels can be revealed analytically from the last layer of certain models (e.g., ResNet), or they can be reconstructed jointly with model inputs by using Gradients Match-ing [1] with additional knowledge about the current state of the model. In this work, we propose a method to discover the set of labels of training samples from only the gradient of the last layer and the id to label mapping. Our method is applicable to a wide variety of model architectures across multiple domains. We demonstrate the effectiveness of our method for model training in two domains - image clas-siﬁcation, and automatic speech recognition. Furthermore, we show that existing reconstruction techniques improve their efﬁcacy when used in conjunction with our method. Conversely, we demonstrate that gradient quantization and sparsiﬁcation can signiﬁcantly reduce the success of the attack. 1

Introduction
Distributed learning paradigms such as federated learning [2] offer a mechanism for mobile devices to collaboratively train deep learning models via transmission of model updates over the network, while ensuring sensitive training data remains resident, locally, on device. Recent works have demonstrated that information about training data can be revealed from a gradient, or a model update in general.
For instance, in the image classiﬁcation domain, the leaked information ranges from some property of the data like membership inference [3, 4], to pixel-wise accurate image reconstruction [1]. To reconstruct the samples given to a model, Zhu et al. [1] propose Deep Leakage from Gradients (DLG), or Gradients Matching (GM), a method that iteratively updates a dummy training sample to minimize the distance of its gradient to a target gradient sent from a client. This has been used to successfully reconstruct large images in a mini-batch [5, 6, 7]. The application of GM has also been demonstrated in other domains, such as language modeling [1] and automatic speech recognition [8].
As opposed to model inputs being continuous, training labels being discrete prevents common techniques like gradient descent from being trivially employed for reconstructing them. Instead, training labels can be reconstructed jointly with model inputs by optimizing for continuous "pseudo" labels (a probability distribution on labels) [1]. However, this method is not guaranteed to succeed,
∗Work performed while at Google. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
for instance, when the weight update is computed from a single sample. Zhao et al. [9] ﬁrst observe that a label of a single training image can be analytically derived from a gradient with 100% success rate. Their method, however, only applies to gradients computed from a single sample, and does not apply to gradients computed from a mini-batch, or aggregated from multiple training steps. Yin et al.
[7] and Wainakh et al. [10] extend this method to demonstrate that labels of samples in a mini-batch can be recovered. The method leads to high success rate on revealing labels of samples in the batch, but its applicability is restricted to classiﬁcation models using a non-negative activation function before the fully-connected layer.
While many works have focused on sample reconstruction, the knowledge of training labels has been shown to be necessary for high-quality reconstruction [7]. In sequence models (e.g., speech and language domains), revealing the labels itself can result in a signiﬁcant leak of privacy. Speech transcript leakage imposes a signiﬁcant threat to users’ privacy and can lead to the exposure of speaker identities [8]. Text-form data may include secrets such as passwords, social security numbers, or sensitive words that reveal the context of the conversation. However, in sequence models that output natural language, the number of labels (e.g., characters, wordpieces, or words) can be substantially larger than in image classiﬁcation models. For such large search spaces, the joint optimization approach adopted in [1] becomes ineffective.
In this work, we make the following contributions. 1. We propose a method to reveal the entire set of labels used in computing a weight update.
We refer to the method as Revealing Labels from Gradients (RLG). The method is applicable with any model that uses a softmax activation with cross-entropy loss, thus is applicable to a wide variety of deep learning architectures. We empirically demonstrate that RLG can be applied to a parameter update generated from a mini-batch (1-step, N -sample), or after several steps (K-step, 1-sample each), or even the most general case of K-step update of
N -sample at each step. 2. We discuss the effects of gradient quantization and sparsiﬁcation techniques, namely Sign-SGD and GradDrop, in the prevention of RLG. These methods have been used to reduce the communication cost in distributed training. We discover that they are also effective in mitigating RLG. 3. We further demonstrate that in sequence models, the knowledge about the set of labels can be used to fully reconstruct a sequence of labels in order, while GM has limited success. In addition to the parameter update, this requires the current state of the model.
We demonstrate our method on 1) an image classiﬁcation task and 2) an automatic speech recognition (ASR) task. For image classiﬁcation, we present our results on ResNet [11], which has often been the target of choice for attacks in previous works [5, 7], and EfﬁcientNet [12], the state-of-the-art architecture for image classiﬁcation. While the approach proposed in [7] works for the ResNet, only our proposed method works for EfﬁcientNet. For ASR, we demonstrate our method with the attention-based encoder-decoder architecture. We show that our method used in conjunction with GM can perform full transcript reconstruction, while none of prior works succeed. Our code is published at https://github.com/googleinterns/learning-bag-of-words. 2 Revealing Training Labels from Gradients 2.1