Abstract
Graph embedding maps a graph into a convenient vector-space represen-tation for graph analysis and machine learning applications. Many graph embedding methods hinge on a sampling of context nodes based on random walks. However, random walks can be a biased sampler due to the structural properties of graphs. Most notably, random walks are biased by the degree of each node, where a node is sampled proportionally to its degree. The implication of such biases has not been clear, particularly in the context of graph representation learning. Here, we investigate the impact of the random walks’ bias on graph embedding and propose residual2vec, a general graph embedding method that can debias various structural biases in graphs by using random graphs. We demonstrate that this debiasing not only improves link prediction and clustering performance but also allows us to explicitly model salient structural properties in graph embedding. 1

Introduction
On average, your friends tend to be more popular than you. This is a mathematical necessity known as the friendship paradox, which arises due to a sampling bias, i.e., popular people have many friends and thus are likely to be on your friend list [1]. Beyond being a fun trivia, the friendship paradox is a fundamental property of graphs: following an edge is a biased sampling that preferentially samples nodes based on nodes’ degree (i.e., the number of neighbors). The fact that random walk is used as the default sampling paradigm across many graph embedding methods raises important questions: what are the implications of this sampling bias in graph embedding? If it is undesirable, how can we debias it?
Graph embedding maps a graph into a dense vector representation, enabling a direct application of many machine learning algorithms to graph analysis [2]. A widely used framework is to turn a graph into a “sentence of nodes” and then feed the sentence to word2vec [3–6]. A crucial diﬀerence from word embedding is that, rather than using given 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
Figure 1: Random walks have a strong preference towards hubs. (A) A toy graph generated by a stochastic block model with a core-periphery structure, where core nodes have more neighbors than peripheral nodes [18]. (B) Random walkers preferentially visit nodes with many neighbors, generating a trajectory that overrepresents the core nodes. sentences, graph embedding methods generate synthetic “sentences” from a given graph.
In other words, the generation of synthetic “sentences” in graph is an implicit modeling decision [7], which most graph embedding methods take for granted. A common approach for generating sentences from a graph is based on random walks, which randomly traverse nodes by following edges. The friendship paradox comes into play when a walker follows an edge (e.g., friendship tie): it is more likely to visit a node with many neighbors (e.g., popular individual). As an example, consider a graph with a core-periphery structure, where core nodes have more neighbors than periphery (Fig. 1A). Although core nodes are the minority, they become the majority in the sentences generated by random walks (Fig. 1B). This is because core nodes have more neighbors than periphery and thus are likely to be a neighbor of other nodes, which is a manifestation of the friendship paradox. Then, how does the sampling bias aﬀect the embedding?
Previous approaches to mitigate the degree bias in embedding are based on modifying random walks or the post-transformation of the embedding [8–16]. Here we show that word2vec by itself has an implicit bias arising from the optimization algorithm—skip-gram negative sampling (SGNS)—which happens to negate the bias due to the friendship paradox. To leverage this debiasing feature further, we propose a more general framework, residual2vec, that can also compensate for other systematic biases in random walks. We show that residual2vec performs better than conventional embedding methods in link prediction and community detection tasks. Using a citation graph of 260k journals, we demonstrate that the biases from random walks overshadow the salient features of graphs. By removing the bias, residual2vec better captures the characteristics of journals such as the impact factor and journal subject. The python code of residual2vec is available at GitHub [17]. 2 Built-in debiasing feature of SGNS word2vec 2.1