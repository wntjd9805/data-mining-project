Abstract
This paper leverages machine-learned predictions to design competitive algorithms for online conversion problems with the goal of improving the competitive ratio when predictions are accurate (i.e., consistency), while also guaranteeing a worst-case competitive ratio regardless of the prediction quality (i.e., robustness). We unify the algorithmic design of both integral and fractional conversion problems, which are also known as the 1-max-search and one-way trading problems, into a class of online threshold-based algorithms (OTA). By incorporating predictions into design of OTA, we achieve the Pareto-optimal trade-off of consistency and robustness, i.e., no online algorithm can achieve a better consistency guarantee given for a robustness guarantee. We demonstrate the performance of OTA using numerical experiments on Bitcoin conversion. 1

Introductions
An online conversion problem aims to convert one asset to another through a sequence of exchanges at varying rates in order to maximize the terminal wealth in ﬁnancial markets. With limited information on possible future rates, the core challenge in an online conversion problem is how to balance the return from waiting for possible high rates with the risk that high rates never show up. A high proﬁle example of this risk is cryptocurrency markets, e.g., Bitcoin, where high ﬂuctuations up and down make it challenging to optimize exchanges. Two well-known classical online conversion problems are 1-max-search [7] and one-way trading [8], which can be considered as integral and fractional versions of the online conversion problem that trade the asset as a whole or fraction-by-fraction (e.g., trading stock in lot or shares). Beyond these two problems, a number of extensions and variants of online conversion problems have been studied with applications to lookback options [14], online portfolio selection [13], online bidding [5], and beyond.
Most typically, conversion problems are studied through the lens of competitive ratios and the goal is to design online algorithms that minimize the worst-case return ratio of the ofﬂine optimal to online algorithm decisions. For example, EI-Yaniv et al. [8] have shown that optimal online algorithms can be designed to achieve the minimal competitive ratios for both 1-max-search and one-way trading.
However, in real-world problems, predictions about future conversion rates are increasingly available and the algorithms developed in the literature are not designed to take advantage of such information.
The challenge for using such predictions is that, in one extreme, the additional information is an accurate prediction (advice) of future inputs. In this case, the algorithm can conﬁdently use the information to improve performance, e.g., [9]. However, most commonly, predictions have 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
no guarantees on their accuracy, and if an online algorithm relies on an inaccurate prediction the performance can be even worse than if it had ignored the prediction entirely.
This challenge is driving the emerging area of the learning-augmented online algorithm (LOA) design, which seeks to design online algorithms that can incorporate untrusted machine-learned predictions in a way that leads to near-optimal performance when predictions are accurate but maintains robust performance when predictions are inaccurate. To measure this trade-off, two metrics have emerged, introduced by [15] and [19]: consistency and robustness. Consistency is deﬁned as the competitive ratio when the prediction is accurate, i.e., CR(0), where CR(ε) is the competitive ratio when the prediction error is ε. In contrast, robustness is the worst competitive ratio over any prediction errors, i.e., maxε CR(ε). Thus, consistency and robustness provide a way to quantify the ability of an algorithm to exploit accurate predictions while ensuring robustness to poor predictions.
In recent years, a stream of literature has sought to design robust and consistent LOA for a variety of online problems, such as online caching [15], ski-rental [19], and others. The ultimate goal is to develop algorithms that are Pareto-optimal across robustness and consistency, in the sense that for any γ, the LOA achieves the minimal consistency guarantee among all online algorithms that are
γ-competitive. For the ski rental problem, recent works have derived Pareto-optimal algorithms, e.g.,
[4, 22], but in most cases the question of where the Pareto-boundary of LOA lies is yet to be answered.
In this paper, we focus on the design of LOA for online conversion problems and we seek to answer the following question: Is it possible to design a Pareto-optimal LOA for the online conversion problem?
Contributions. We show that the answer to the above question is “yes”, by designing an online threshold-based algorithm (OTA), and proving that it is Pareto-optimal. In particular, we introduce a class of OTA that uniﬁes the algorithmic design of both 1-max-search and one-way trading. We then incorporate predictions into OTA by parameterizing the threshold functions based on the predictions.
This approach yields bounded consistency and robustness (see Theorem 4.5 and Theorem 4.6).
Further, we derive lower bounds for robustness-consistency trade-offs and show that our learning-augmented OTA achieves those lower bounds, and is thus Pareto-optimal (see Theorem 5.1 and
Theorem 5.2). Finally, we demonstrate the improvement of the learning-augmented OTA over pure online algorithms using numerical experiments based on real-world data tracking Bitcoin prices.
The technical contributions of this paper are twofold. First, we provide a sufﬁcient condition for design and analysis of the learning-augmented OTA with a guaranteed generalized competitive ratio.
This competitive ratio is general in the sense that it not only can yield robustness and consistency guarantees, but can also potentially provide more ﬁne-grained performance guarantees beyond robustness and consistency. Second, we provide a novel way of deriving the lower bound on the robustness-consistency trade-off, which may be of use beyond online conversion problems. The key idea is to construct a function that can model all online algorithms under a special family of instances, and the lower bound can be derived from combining the robustness and consistency requirements on this function. This constructive approach to arriving at a lower bound is distinctive. 2