Abstract
Learning a sequence of tasks without access to i.i.d. observations is a widely studied form of continual learning (CL) that remains challenging. In principle, Bayesian learning directly applies to this setting, since recursive and one-off Bayesian up-dates yield the same result. In practice, however, recursive updating often leads to poor trade-off solutions across tasks because approximate inference is nec-essary for most models of interest. Here, we describe an alternative Bayesian approach where task-conditioned parameter distributions are continually inferred from data. We offer a practical deep learning implementation of our framework based on probabilistic task-conditioned hypernetworks, an approach we term poste-rior meta-replay. Experiments on standard benchmarks show that our probabilistic hypernetworks compress sequences of posterior parameter distributions with virtu-ally no forgetting. We obtain considerable performance gains compared to existing
Bayesian CL methods, and identify task inference as our major limiting factor.
This limitation has several causes that are independent of the considered sequential setting, opening up new avenues for progress in CL. 1

Introduction
In recent years, a variety of continual learning (CL) algorithms have been developed to overcome the need to train neural networks with an independent and identically distributed (i.i.d.) sample. Most
CL literature focuses on the particular scenario of continually learning a sequence of T tasks with datasets D(1), . . . , D(T ). Because only access to the current task is granted, successful training of a discriminative model that captures p(Y | X) has to occur without an i.i.d. training sample from the overall joint D(1:T ) i.i.d.∼ p(X)p(Y | X).
The advantages of a Bayesian approach for solving this problem are numerous and include the ability to drop all i.i.d. assumptions across and within tasks in a mathematically sound way, the ability to revisit tasks whenever new data becomes available, and access to principled uncertainty estimates capturing both data and parameter uncertainty. Up until now, Bayesian approaches to CL essentially focused on ﬁnding a combined posterior distribution via a recursive Bayesian update p(W | D(1:T )) ∝ p(W | D(1:T −1))p(D(T ) | W). Because the posterior of the previous task is used as prior for the next task, these approaches are also known as prior-focused [17]. In theory, the 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
above recursive update can always recover the posterior p(W | D(1:T )), independently of how the data is presented. However, because proper Bayesian inference is intractable, approximations are needed in practice, which lead to errors that are recursively ampliﬁed. As a result, whether solutions that are easily found in the i.i.d. setting can be obtained via the approximate recursive update strongly depends on factors such as task ordering, task similarity and the considered family of distributions.
These factors limit the effectiveness of the recursive update and have a detrimental effect on the performance of prior-focused methods, especially in task-agnostic CL settings.
To overcome these limitations, we propose an alternative Bayesian approach to CL that does not rely on the recursive update to learn distinct tasks and instead aims to learn task-speciﬁc pos-teriors (Fig. 1, refer to SM F.1 for a detailed discussion of the graphical model). In this view,
ﬁnding trade-off solutions across tasks is not re-quired, and knowledge transfer can be explicitly controlled for each task via the prior, which is no longer prescribed by the recursive update and can thus be set freely. By introducing probabilis-tic extensions of task-conditioned hypernetworks
[91], we show how task-speciﬁc posteriors can be learned with a single shared meta-model, an approach we term posterior meta-replay.
Figure 1: The proposed posterior meta-replay framework learns task-speciﬁc posteriors p(W |
D(t)) via a single shared meta-model, with task-speciﬁc point estimates (e.g., MAP) being a limit case. In this view, the modelled solution space is not limited to admissible solutions that lie in the overlap of all task-speciﬁc posteriors. By contrast, prior-focused methods learn a single posterior p(W | D(1:T )) recursively and thus require the existence of trade-off solutions between learned and future tasks in the currently modelled solution space. Shaded areas indicate high density regions.
This approach introduces two challenges: forget-ting at the level of the hypernetwork, and the need to know task identity to correctly condition the hypernetwork. We empirically show that forget-ting at the meta-level can be prevented by using a simple regularizer that replays parameters of previous posteriors. In task-agnostic inference settings, often referred to as class-incremental learning in the context of classiﬁcation benchmarks [88], the main hurdle therefore becomes task inference at test time. Here we focus on this task-agnostic setting, arguably the most challenging but also the most natural CL scenario, since the obtained models can be deployed just like those obtained via i.i.d. training (e.g., irrespective of the sequential training, the ﬁnal model will be a classiﬁer across all classes). In order to explicitly infer task identity from unseen inputs without resorting to generative models, we thoroughly study the use of principled uncertainty that naturally arises in Bayesian models. We show that results obtained in this task-agnostic setting with our approach constitute a leap in performance compared to prior-focused methods. Furthermore we show that limitations in task inference via predictive uncertainty are not related to our CL solution, but depend instead on the combination of approximate inference method, architecture, uncertainty measure and prior. Finally, we investigate how task inference can be further improved through several extensions.
We summarize our main contributions below:
• We describe a Bayesian CL framework where task-conditioned posterior parameter distributions are continually learned and compressed in a hypernetwork.
• In a series of synthetic and real-world CL benchmarks we show that our task-conditioned hyper-networks exhibit essentially no forgetting, both for explicitly parameterized and implicit posterior distributions, despite using the parameter budget of a single model.
• Compared to prior-focused methods, our approach leads to a leap in performance in task-agnostic inference while maintaining the theoretical beneﬁts of a Bayesian approach.
• Our approach scales to modern architectures such as ResNets, and remaining performance limita-tions are linked to uncertainty-based out-of-distribution detection but not to our CL solution.
• Finally, we show how prominent existing Bayesian CL methods such as elastic weight consolidation can be dramatically improved in task-agnostic settings by introducing a small set of task-speciﬁc parameters and explicitly inferring the task. 2
2