Abstract
Many tasks in deep learning involve optimizing over the inputs to a network to minimize or maximize some objective; examples include optimization over latent spaces in a generative model to match a target image, or adversarially perturbing an input to worsen classiﬁer performance. Performing such optimization, however, is traditionally quite costly, as it involves a complete forward and backward pass through the network for each gradient step. In a separate line of work, a recent thread of research has developed the deep equilibrium (DEQ) model, a class of models that foregoes traditional network depth and instead computes the output of a network by ﬁnding the ﬁxed point of a single nonlinear layer. In this paper, we show that there is a natural synergy between these two settings. Although, naively using
DEQs for these optimization problems is expensive (owing to the time needed to compute a ﬁxed point for each gradient step), we can leverage the fact that gradient-based optimization can itself be cast as a ﬁxed point iteration to substantially improve the overall speed. That is, we simultaneously both solve for the DEQ
ﬁxed point and optimize over network inputs, all within a single “augmented”
DEQ model that jointly encodes both the original network and the optimization process. Indeed, the procedure is fast enough that it allows us to efﬁciently train
DEQ models for tasks traditionally relying on an “inner” optimization loop. We demonstrate this strategy on various tasks such as training generative models while optimizing over latent codes, training models for inverse problems like denoising and inpainting, adversarial training and gradient based meta-learning. 1

Introduction
Many settings in deep learning involve optimization over the inputs to a network to minimize some desired loss. For example, for a “generator” network G : Z → X that maps from latent space Z to an observed space X , it may be desirable to ﬁnd a latent vector z ∈ Z that most closely produces some target output x ∈ X by solving the optimization problem (e.g. [10, 13]) minimize z∈Z (cid:107)x − Gθ(z)(cid:107)2 2. (1)
As another example, constructing adversarial examples for classiﬁers [28, 53] typically involves optimizating over a perturbation to a given input; i.e., given a classiﬁer network g : X → Y, task loss
∗Correspondence to: Swaminathan Gurumurthy <sgurumur@andrew.cmu.edu>
Code available at https://github.com/locuslab/JIIO-DEQ 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
(cid:96) : Y → R+, and a sample x ∈ X , we want to solve maximize (cid:107)δ(cid:107)≤(cid:15) (cid:96)(g(x + δ)). (2)
More generally, a wide range of inverse problems [10] and other auxiliary tasks [22, 3] in deep learning can also be formulated in such a manner.
Orthogonal to this line of work, a recent trend has focused on the use of an implicit layer within deep networks to avoid traditional depth. For instance, Bai et al. [5] introduced deep equilibrium models (DEQs) which instead treat the network as repeated applications of a single layer and compute the output of the network as a solution to an equilibrium-ﬁnding problem instead of simply specifying a sequence of non-linear layer operations. Bai et al. [5] and subsequent work [6] have shown that
DEQs can achieve results competitive with traditional deep networks for many realistic tasks.
In this work, we highlight the beneﬁt of using these implicit models in the context of input optimization routines. Speciﬁcally, because optimization over inputs itself is typically done via an iterative method (e.g., gradient descent), we can combine this optimization ﬁxed-point iteration with the forward
DEQ ﬁxed point iteration all within a single “augmented” DEQ model that simultaneously performs forward model inference as well as optimization over the inputs. This enables the models to more quickly perform both the inference and optimization procedures, and the resulting speedups further allow us to train networks that use such “bi-level” ﬁxed point passes. In addition, we also show a close connection between our proposed approach and the primal-dual methods for constrained optimization.
We illustrate our methods on 4 tasks that span across different domains and problems: 1) training
DEQ-based generative models while optimizing over latent codes; 2) training models for inverse problems such as denoising and inpainting; 3) adversarial training of implicit models; and 4) gradient-based meta-learning. We show that in all cases, performing this simultaneous optimization and forward inference accelerates the process over a more naive inner/outer optimization approach. For instance, using the combined approach leads to a 3.5-9x speedup for generative DEQ networks, a 3x speedup in adverarial training of DEQ networks and a 2.5-3x speedup for gradient based meta-learning. In total, we believe this work points to a variety of new potential applications for optimization with implicit models. 2