Abstract
Standard lossy image compression algorithms aim to preserve an image’s appear-ance, while minimizing the number of bits needed to transmit it. However, the amount of information actually needed by a user for downstream tasks – e.g., deciding which product to click on in a shopping website – is likely much lower.
To achieve this lower bitrate, we would ideally only transmit the visual features that drive user behavior, while discarding details irrelevant to the user’s decisions. We approach this problem by training a compression model through human-in-the-loop learning as the user performs tasks with the compressed images. The key insight is to train the model to produce a compressed image that induces the user to take the same action that they would have taken had they seen the original image. To approximate the loss function for this model, we train a discriminator that tries to distinguish whether a user’s action was taken in response to the compressed image or the original. We evaluate our method through experiments with human participants on four tasks: reading handwritten digits, verifying photos of faces, browsing an online shopping catalogue, and playing a car racing video game. The results show that our method learns to match the user’s actions with and without compression at lower bitrates than baseline methods, and adapts the compres-sion model to the user’s behavior: it preserves the digit number and randomizes handwriting style in the digit reading task, preserves hats and eyeglasses while randomizing faces in the photo veriﬁcation task, preserves the perceived price of an item while randomizing its color and background in the online shopping task, and preserves upcoming bends in the road in the car racing game. 1

Introduction
Modern web platforms serve billions of images every day, and typically rely on lossy compression algorithms to store and transmit this data efﬁciently. Recent work on machine learning methods for lossy image compression [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11] improves upon standard methods like JPEG
[12] by training neural networks to minimize the number of bits needed to generate high-ﬁdelity reconstructions. In this paper, we explore the idea of compressing images to even smaller sizes by intentionally allowing reconstructions to deviate drastically from the visual appearance of their originals, and instead optimizing reconstructions for the speciﬁc, downstream tasks that the user wants to perform with them, such as video conferencing, online gaming, or remotely operating space robots [13].
Original
Compressed  (for users with four different tasks) (a) (c) (b) (d)
Figure 1: Images compressed 2-4x smaller than JPEG retain information for tasks like shopping for cars in a perceived price range (a), surveying car colors (b), and checking photos for eyeglasses (c) or hats (d). 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
Encoder
Decoder
Distant road  discarded
Left bend preserved
User action
Steer left
Compression  loss
Original image
Compression model
Compressed image
= Discriminator: 
Steer left
Was the user shown the  original or a compressed  image?
Figure 2: Given the original image x, we would like to generate a compressed image ˆx such that the user’s action a upon seeing the compressed image is similar to what it would have been had the user seen the original image instead. In a 2D top-down car racing video game, our compression model learns that, in order to match the user’s steering with and without compression, it must preserve bends, but can discard the road farther ahead.
Our main observation in this work is that, instead of optimizing the compression model for a task-agnostic perceptual similarity objective function, we can instead optimize the compression model for functional similarity: producing compressed images that, when shown to the user, induce the user to take the same actions that they would have taken had they observed the original, uncompressed images.
We call this PragmatIc COmpression (PICO), inspired by prior work on pragmatics [14, 15, 16] that characterizes the meaning of a message through the behavior it induces in a listener. PICO adapts compression to user behavior, enabling the user to perform their individually-desired tasks with compressed images instead of the original images. For example, consider two users with distinct tasks: one ﬂying a quadcopter, and the other driving a ground robot. On a network with an extremely low bitrate, we would like the compressed video feed of the ground robot to preserve ground-level obstacles and terrain while discarding details about power lines and tree canopies, and the quadcopter feed to do the opposite.
To this end, we formulate compression as a human-in-the-loop learning problem, in which the compression model is represented as an encoder-decoder neural network that takes the original image as an input and outputs the compressed image. The user sees the compressed image, and takes an action to perform their desired task (see Figure 2). The main challenge in this work is designing a loss function for the compression model that evaluates the quality of the compressed image in the context of the original image and the user’s action. We do not assume knowledge of the user’s desired task, so we cannot directly evaluate the quality of the compressed image by evaluating the ﬁtness of the user’s action upon seeing the compressed image. We also do not assume access to ground-truth action labels for the original images in the streaming setting, so we cannot compare the user’s action upon seeing the compressed image to some ground-truth action.
Instead, we deﬁne the loss function through adversarial learning. For example, consider a user browsing an online shopping catalogue, observing photos and clicking on appealing items. To collect positive and negative examples of user behavior, we simply randomize whether a user sees the original or compressed version of an image while they are shopping, and record their actions. We then train a discriminator to predict the likelihood that a user’s action was taken in response to the original rather than a compressed image, and train the compression model to maximize this predicted likelihood.
Our primary contribution is the PICO algorithm for human-in-the-loop learning of data compression models. We validate PICO through three user studies on Amazon Mechanical Turk, in which we train and evaluate our compression models on data from human participants. In the ﬁrst study, we asked participants to read handwritten digits and identify the numbers – PICO learned to preserve the number and discard handwriting style (Figure 3). In the second study, we asked users to browse a car catalogue and select cars based on perceived price – PICO learned to preserve overall shape and sportiness while randomizing paint jobs and backgrounds (Figure 4). In the third study, we asked participants to verify photos of faces by checking if heads or eyes were covered – PICO learned to preserve hats and eyeglasses while randomizing faces (Figure 5). In all three studies, PICO obtained up to 2-4x lower bitrates than non-adaptive baseline methods. To show that PICO can be used in sequential decision-making problems, we also ran a user study with 12 participants who played a car racing video game – at a ﬁxed bitrate, PICO learned to preserve bends in the road substantially better than a non-adaptive baseline method, enabling users to drive more safely (Figure 6). 2
2