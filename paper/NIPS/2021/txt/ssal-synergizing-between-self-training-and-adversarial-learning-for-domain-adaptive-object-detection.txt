Abstract
We study adapting trained object detectors to unseen domains manifesting signiﬁ-cant variations of object appearance, viewpoints and backgrounds. Most current methods align domains by either using image or instance-level feature alignment in an adversarial fashion. This often suffers due to the presence of unwanted background and as such lacks class-speciﬁc alignment. A common remedy to pro-mote class-level alignment is to use high conﬁdence predictions on the unlabelled domain as pseudo labels. These high conﬁdence predictions are often fallacious since the model is poorly calibrated under domain shift. In this paper, we propose to leverage model’s predictive uncertainty to strike the right balance between ad-versarial feature alignment and class-level alignment. Speciﬁcally, we measure predictive uncertainty on class assignments and the bounding box predictions.
Model predictions with low uncertainty are used to generate pseudo-labels for self-supervision, whereas the ones with higher uncertainty are used to generate tiles for an adversarial feature alignment stage. This synergy between tiling around the uncertain object regions and generating pseudo-labels from highly certain object regions allows us to capture both the image and instance level context during the model adaptation stage. We perform extensive experiments covering various do-main shift scenarios. Our approach improves upon existing state-of-the-art methods with visible margins. 1

Introduction
Deep convolutional neural network based object detectors have shown promising results, through learning representative features from large annotated datasets [7, 32, 10]. However, like other supervised deep learning methods, object detection methods trained on the source domain do not generalize adequately to a new target domain. This problem, known as domain shift [49] could be exhibited by change in style, camera pose, or object size and orientation, or the number or location of objects in the scene, among other things. Often, collecting large annotated dataset for
ﬁne-tuning the model to the target domain is expensive, error prone and in many cases not possible.
Unsupervised Domain Adaptation (UDA) is a promising research direction towards solving this problem by transferring knowledge from a labelled source domain to an unlabelled target domain.
∗Corresponding author, Intelligent Machines Lab, Department of Computer Science, Information Tech-nology University of the Punjab, Lahore, Pakistan. Email: akhtar.munir@itu.edu.pk Project Page: http://im.itu.edu.pk/synergizing-domain-adaptation/ 35th Conference on Neural Information Processing Systems (NeurIPS 2021)
Many unsupervised domain adaptive detectors rely on adversarial adaptation or self-training tech-niques. Methods based on adversarial adaptation [4, 43, 15, 17, 54, 50, 3, 36], mostly rely on domain discriminator for aligning features at image or instance levels. However, due to the absence of labels in target domain they suffer from the challenges of how to pick samples for the adaptation. Selecting uniformly, one ends up missing on infrequent classes or instances. Most importantly adversarial alignment do not explicitly incorporates the class discriminative information, resulting in non-optimal alignment for classiﬁcation and object detection tasks [43, 4, 45]. A potential solution to this problem is self-training based adaptation, however, it faces the challenge of how to avoid noisy pseudo-labels.
Some methods choose high conﬁdence predictions as pseudo-labels [27, 19, 42], but the likely poor calibration of model under domain shift renders this solution inefﬁcient [38]. Further, in the case of object detection, prediction probability can not directly capture object localization inaccuracies.
We present a principled approach, dubbed as SSAL (Synergizing between Self-Training and Adversar-ial Learning for Domain Adaptive Object Detection), to achieve right balance between self-training and adversarial alignment for adaptive object detection via leveraging model’s predictive uncertainty.
To estimate predictive uncertainty of a detection, we propose taking into account variations in both the localization prediction and conﬁdence prediction across Monte-Carlo dropout inferences [8]. Certain detections are taken as pseudo-labels for self-training, while uncertain ones are used to extract tiles (regions in image) for adversarial feature alignment. This synergy between adversarial alignment via tiling around the uncertain object regions and self-training with pseudo-labels from certain object regions lets us include instance-level context for effective adversarial alignment and improve feature discriminability for class-speciﬁc alignment. Since we select pseudo-labels with low uncertainty and take relatively uncertain as potential, object-like regions with context (i.e. tiles) for adversarial alignment, we tend to reduce the effect of poor calibration under domain shift, thereby improving model’s generalization across domains.
Our key contributions include the following: (1) We introduce a new uncertainty-guided framework that strikes the right balance between self-training and adversarial feature alignment for adapting object detection methods. Both pseudo-labelling for self-training and tiling for adversarial alignment are impactful due to their simplicity, generality and ease of implementation. (2) We propose a method for estimating the object detection uncertainty via taking into account variations in both the localization prediction and conﬁdence prediction across Monte-Carlo dropout inferences. (3) We show that, selecting pseudo-labels with low uncertainty and using relatively uncertain regions for adversarial alignment, it is possible to address the poor calibration caused by domain shift, and hence improve model’s generalization across domains. (4) Unlike most of the previous methods, we build on computationally efﬁcient one-stage anchor-less object detectors and achieve state-of-the-art results with notable margins across various adaptation scenarios. 2