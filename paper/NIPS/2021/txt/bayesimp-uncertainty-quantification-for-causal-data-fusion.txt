Abstract
While causal models are becoming one of the mainstays of machine learning, the problem of uncertainty quantiﬁcation in causal inference remains challenging. In this paper, we study the causal data fusion problem, where datasets pertaining to multiple causal graphs are combined to estimate the average treatment effect of a target variable. As data arises from multiple sources and can vary in quality and quantity, principled uncertainty quantiﬁcation becomes essential. To that end, we introduce Bayesian Interventional Mean Processes, a framework which combines ideas from probabilistic integration and kernel mean embeddings to represent interventional distributions in the reproducing kernel Hilbert space, while taking into account the uncertainty within each causal graph. To demonstrate the utility of our uncertainty estimation, we apply our method to the Causal Bayesian
Optimisation task and show improvements over state-of-the-art methods. 1

Introduction
Causal inference has seen a signiﬁcant surge of research interest in areas such as healthcare [1], ecology [2], and optimisation [3]. However, data fusion, the problem of merging information from multiple data sources, has received limited attention in the context of causal modelling, yet presents signiﬁcant potential beneﬁts for practical situations [4, 5]. In this work, we consider a causal data fusion problem where two causal graphs are combined for the purposes of inference of a target variable (see Fig.1). In particular, our goal is to quantify the uncertainty under such a setup and determine the level of conﬁdence in our treatment effect estimates.
Figure 1: Example problem setup: Causal graphs collected in two separate medical studies i.e. [6] and [7]. (Left) D1 : Data describing the causal relationships between statin level and Prostate Speciﬁc
Antigen (PSA). (Right) D2 : Data from a prostate cancer study for patients about to receive a radical prostatectomy. Goal: Model EEE[Cancer Volume|do(Statin)] while also quantifying its uncertainty.
Let us consider the motivating example in Fig.1, where a medical practitioner is investigating how prostate cancer volume is affected by a statin drug dosage. We consider the case where the doctor 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
∗Denotes equal contribution with alphabetical ordering
only has access to two separate medical studies describing the quantities of interest. On one hand we have observational data, from one medical study D1 [1], describing the causal relationship between statin level and prostate speciﬁc antigen (PSA), and on the other hand we have observational data, from a second study D2 [7], that looked into the link between PSA level and prostate cancer volume.
The goal is to model the interventional effect between our target variable (cancer volume) and the treatment variable (statin). This problem setting is different from the standard observational scenario as it comes with the following challenges:
• Unmatched data: Our goal is to estimate E[cancer volume|do(statin)] but the observed cancer volume is not paired with statin dosage. Instead, they are related via a mediating variable PSA.
• Uncertainty quantiﬁcation: The two studies may be of different data quantity/quality.
Furthermore, a covariate shift in the mediating variable, i.e. a difference between its distributions in two datasets, may cause inaccurate extrapolation. Hence, we need to account for uncertainty in both datasets.
Formally, let X be the treatment (Statin), Y be the mediating variable (PSA) and T our target (cancer volume), and our aim is to estimate E[T |do(X)]. The problem of unmatched data in a similar context has been previously considered by [5] using a two-staged regression approach (X → Y and Y → T ).
However, uncertainty quantiﬁcation, despite being essential if our estimates of interventional effects will guide decision-making, has not been previously explored. In particular, it is crucial to quantify the uncertainty in both stages as this takes into account the lack of data in speciﬁc parts of the space.
Given that we are using different datasets for each stage, there are also two sources of epistemic uncertainties (due to lack of data) as well as two sources of aleatoric uncertainties (due to inherent randomness in Y and T ) [8] . It is thus natural to consider regression models based on Gaussian
Processes (GP) [9], as they are able to model both types of uncertainties. However, as GPs, or any other standard regression models, are designed to model conditional expectations only and will fail to capture the underlying distributions of interest (e.g. if there is multimodality in Y as discussed in [10]). This is undesirable since, as we will see, interventional effect estimation requires accurate estimates of distributions. While one could in principle resort to density estimation methods, this becomes challenging since we typically deal with a number of conditional/ interventional densities.
In this paper, we introduce the framework of Bayesian Interventional Mean Processes (BAYESIMP) to circumvent the challenges in the causal data fusion setting described above. BAYESIMP considers kernel mean embeddings [11] for representing distributions in a reproducing kernel Hilbert space (RKHS), in which the whole arsenal of kernel methods can be extended to probabilistic inference (e.g. kernel Bayes rule [12], hypothesis testing [13], distribution regression [14]). Speciﬁcally, BAYES-IMP uses kernel mean embeddings to represent the interventional distributions and to analytically marginalise out Y , hence accounting for aleatoric uncertainties. Further, BAYESIMP uses GPs to estimate the required kernel mean embeddings from data in a Bayesian manner, which allows to quantify the epistemic uncertainties when representing the interventional distributions. To illustrate the quality of our uncertainty estimates, we apply BAYESIMP to Causal Bayesian Optimisation [15], an efﬁcient heuristic to optimise objective functions of the form x∗ = arg minx∈X E[T |do(X) = x].
Our contributions are summarised below: 1. We propose a novel Bayesian Learning of Conditional Mean Embedding (BAYESCME) that allows us to estimate conditional mean embeddings in a Bayesian framework. 2. Using BAYESCME, we propose a novel Bayesian Interventional Mean Process (BAYESIMP) that allows us to model interventional effect across causal graphs without explicit density estimation, while obtaining uncertainty estimates for E[T |do(X) = x]. 3. We apply BAYESIMP to Causal Bayesian Optimisation, a problem introduced in [15] and show signiﬁcant improvements over existing state-of-the-art methods.
Note that [16] also considered a causal fusion problem but with a different objective. They focused on extrapolating experimental ﬁndings across treatment domains, i.e. inferring E[Y |do(X)] when only data from p(Y |do(S)) is observed, where S is some other treatment variable. In contrast, we focus on modelling combined causal graphs, with a strong emphasis on uncertainty quantiﬁcation.
While [17] considered mapping interventional distributions in the RKHS to model quantities such as E[T |do(X)], they only considered a frequentist approach, which does not account for epistemic uncertainties. 2
Notations. We denote X, Y, Z as random variables taking values in the non-empty sets X , Y and Z respectively. Let kx : X × X → R be positive deﬁnite kernels on X with an associated RKHS Hkx . The corresponding canonical feature map kx(x(cid:48), ·) is denoted as φx(x(cid:48)). Analogously for Y and Z.
In the simplest setting, we observe i.i.d samples D1 = i=1 from joint distribution PXY Z which we con-{xi, yi, zi}N catenate into vectors x := [x1, ..., xN ](cid:62). Similarly for y and z. For this work, X is referred as treatment variable, Y as mediating variable and Z as adjustment variables accounting for confound-ing effects. With an abuse of notation, features matrices are deﬁned by stacking feature maps along the columns, i.e Φx := [φx(x1), ..., φx(xN )]. We denote the Gram matrix as Kxx := Φ(cid:62) x Φx and the vector of evaluations kxx as [kx(x, x1), ..., kx(x, xN )]. We deﬁne Φy, Φz analogously for y and z.
Figure 2: A general two stage causal learning setup.
Lastly, we denote T = f (Y ) + (cid:15) as our target variable, which is modelled as some noisy evaluation of a function f : Y → T on Y while (cid:15) being some random noise. For our problem setup we observe j=1 from the joint PY T independent of D1. Again, a second dataset of i.i.d realisations D2 = {˜yj, tj}M we deﬁne ˜y := [˜y1, ..., ˜yM ](cid:62) and t := [t1, ..., tM ](cid:62) just like for D1. See Fig.2 for illustration. 2