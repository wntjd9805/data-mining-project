Abstract
We consider the problem of allocating divisible items among multiple agents, and consider the setting where any agent is allowed to introduce diversity constraints on the items they are allocated. We motivate this via settings where the items themselves correspond to user ad slots or task workers with attributes such as race and gender on which the principal seeks to achieve demographic parity. We consider the following question: When an agent expresses diversity constraints into an allocation rule, is the allocation of other agents hurt signiﬁcantly? If this happens, the cost of introducing such constraints is disproportionately borne by agents who do not beneﬁt from diversity. We codify this via two desiderata capturing robustness.
These are no negative externality – other agents are not hurt – and monotonicity – the agent enforcing the constraint does not see a large increase in value. We show in a formal sense that the Nash Welfare rule that maximizes product of agent values is uniquely positioned to be robust when diversity constraints are introduced, while almost all other natural allocation rules fail this criterion. We also show that the guarantees achieved by Nash Welfare are nearly optimal within a widely studied class of allocation rules. We ﬁnally perform an empirical simulation on real-world data that models ad allocations to show that this gap between Nash Welfare and other rules persists in the wild. 1

Introduction
Allocating heterogeneous divisible items (or resources) among agents with different values over these items is a central problem in economics, with literature dating back many decades [43, 9, 37, 44, 5].
These problems have gained importance in computer science and machine learning due to their applications in, among other things, large-scale online advertising [33, 7, 29, 6, 24, 8], resource allocation in datacenters [28] and sharing economy platforms.
Given their wide applicability, there has been a large body of work on elucidating desirable properties of such allocations. One desirable property is fairness or equity in the value the allocation provides to different agents. Though there is no universally agreed-upon notion of fairness, one appealing notion [44] deﬁnes fair allocations as those that are both Pareto-optimal on the value they provide to the agents as well as envy-free [43], meaning that no agent should derive more value from another agent’s allocation. A less restrictive notion is the so-called Pigou-Dalton principle [17, 35] or welfarism, which states that given any ﬁxed total value of the agents, an allocation should prefer distributing these values so that there is no potential transfer of value from an agent with larger value (the “rich”) to one with smaller value (the “poor”). This loosely translates to allocations that optimize 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
a (weakly) concave social welfare function over agents’ values. We call rules that optimize separable, symmetric, concave functions of agent values as welfarist allocation rules.1
Due to their simplicity of implementation and ease of understanding, most allocation rules im-plemented in practice are welfarist rules. Indeed, even when allocations are supported by prices, for instance in revenue-maximizing ad auctions, by Myerson’s celebrated transformation [36, 22] and its generalizations, these can be viewed as optimizing a linear “virtual welfare” function over allocations [10, 12]. Further, envy-freeness can also be implemented by the welfarist Nash Welfare rule [37, 21, 44] that optimizes the product of agents’ values, and which we will discuss extensively. 1.1 Allocations with Diversity
In this paper, we consider a different desirable facet of such allocations – diversity. The notion of fairness presented above attempts to spread value fairly across agents. Suppose, in addition, the items being allocated were also associated with individuals. For instance, consider the following scenario motivated by online advertising – the items are ad view slots in an advertising ecosystem, each item labeled with the attributes, such as race, age, gender, of the viewing individual on a social media site.
The agent represents an advertiser who has different preferences over the viewing individuals. The agent may not only seek an allocation of slots that maximizes its own value, but may also want these slots to not be all views by any particular race. In other words, the agent seeks an allocation that is also diverse on the attributes of the corresponding slots. Similarly, in a team formation platform, an agent seeking such a team may value diversity in attributes such as gender and race of the team members in addition to competence. Diversity has become an increasingly important consideration for eliminating bias in allocation platforms where the items map to humans. Allowing agents to specify some form of diversity constraints on allocations are one way for achieving this goal [45, 4, 11, 38].
The simplest diversity constraint we consider is the case where the agent wants items with different attributes (such as race and gender) in ﬁxed proportions, which models the diversity desiderata in the advertising and team formation settings considered above. We term these “proportionality constraints"; see Section 2.2 for a formal deﬁnition. More generally, such constraints capture complementarity in the allocation, where an agent can say “I want at least as much of this attribute as that attribute.” A different application for such constraints is in machine allocation in data centers, where a client could request machines in different geographic regions in certain proportions [41]. For simplicity, we call these constraints diversity constraints, though it should be kept in mind that they model complementarity in general and can easily arise in settings beyond achieving diversity.
In Section 2.2, we model diversity constraints imposed by agent i as simply a convex polytope Pi such that the empty allocation (cid:126)0 ∈ Pi. First, this means such constraints preserve feasibility of the allocation. More importantly, these constraints, including proportionality constraints considered above, can have both positive and negative coefﬁcients, and this leads to interesting and non-obvious behavior of welfarist allocation rules. This forms the focus of this paper.
Externality in Diverse Allocations. One natural solution to incorporating diversity is for the allocation platform to ask agents for their constraints and add them to the welfarist optimization problem. Indeed, recent work on large scale online allocation problems [18, 19, 24] shows that even in the presence of arbitrary convex constraints on the allocations that can run across time, the resulting problem can be viewed as online stochastic convex programming and admits efﬁcient approximation algorithms [3, 8]. Similarly, recent works on auctions with diversity constraints [12, 14, 26] also follow this route and simply add these constraints to an optimization procedure.
In this paper, our main focus is to understand how adding such constraints affects the outcome of the allocation. More precisely, for any welfarist allocation rule, when an agent imposes diversity constraints, this changes the allocation of not just this agent, but all other agents as well. Naturally, seeking a diverse allocation will incur a cost in terms of diminished total value of all the agents. This cost is, of course, counterbalanced by the beneﬁt of diversity to the agent seeking diversity (which does not explicitly appear in our model). Since the agent seeking diversity is the one beneﬁting from the constraints, it would be desirable from both the other agents’ and the platform’s perspective that this agent should be the one bearing the majority of this cost, while the values for other agents should 1We borrow this term from [39], though the concept itself is classic [32, 34] (See Section 2.1 for formal deﬁnitions.) 2
not be signiﬁcantly impacted. In other words, there should be little negative externality on other agents. We present this desideratum formally in Section 2.3.
It is not a priori clear whether the welfarist allocation rules are robust in the above sense and thus the extent to which imposing diversity constraints, even by one agent, may impact other agents. In fact, this lack of clarity may be a major reason for a platform to hesitate to implement functionality enabling agents to specify such diversity constraints, a signiﬁcant shortcoming for applications such as team selection and online advertising. Thus the focus of our work is on quantifying the potential negative externality and on developing recommendations for ﬁnding robust allocations. 1.2 Our Results
To start with, one could reasonably hope that welfarist allocation rules that attempt to ﬁnd equitable or fair allocations across agents would be naturally robust to the addition of diversity constraints, in the sense that to a good approximation, the negative externality to other agents’ values is bounded.
Our ﬁrst analytical result shows that the above intuition is false. In Section 3, we show that almost all welfarist allocation rules – regardless of how equitably or fairly they distribute value among agents – are not robust in the sense that the negative externality on other agents that stems from imposing even a single diversity constraint is unbounded (see Theorem 1.) On the positive side, we show that the Nash Welfare objective [37, 21], which optimizes the product of agents’ values, is the exception in that it achieves negative externality that is bounded above by an absolute constant factor even when a constant number of agents impose arbitrary diversity constraints. Further, this constant bound is nearly optimal for any number of agents enforcing such constraints since any allocation rule satisfying the Pigou-Dalton principle also suffers similar negative externality. (Theorems 2 and 3.)
We then consider how an agent’s imposing diversity constraints affects its own value. We deﬁne an allocation rule to be monotone if an agent’s imposing diversity constraints weakly reduces her own value, and is monotone to a constant factor if the value increases by at most a constant factor. In
Section 4, we show such monotonicity is correlated with how egalitarian the allocation rule is – the more egalitarian (or concave) a rule is, the closer to monotone it is (see Theorem 4.) Further, the
Nash Welfare allocation rule is monotone to an absolute constant factor.
In Section 5, we use real-world datasets to model ad allocation. For a budget-capped valuation function that is widely studied in this setting, we compare the negative externality induced by various allocation rules. In this setting, the social welfare maximizing rule models ﬁrst price auctions with budget constrained advertisers, and we empirically show that it indeed suffers large externality and non-monotonicity. However, the Nash Welfare rule suffers very small externality and is monotone, hence making a case for that our theoretical insights will apply in the wild as well.
We summarize the upper and lower bounds on the amount of negative externality and non-monotonicity for various allocation rules in Section 2.3. Taken together, our main contribution is therefore to show that the Nash Welfare objective is uniquely positioned among a large class of welfarist allocation rules to be robust, achieving both no negative externality and monotonicity to within small constant factors. Our results also suggest that care must be exercised by the allocation platform when allowing agents to express diversity or complementarity constraints. If these are di-rectly encoded into the optimization like in [12, 19, 24, 3, 6], they may create second-order unfairness where the resulting decease in value is borne by agents not directly beneﬁting from the diversity. 1.3