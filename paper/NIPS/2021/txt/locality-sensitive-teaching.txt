Abstract
The emergence of the Internet-of-Things (IoT) sheds light on applying the ma-chine teaching (MT) algorithms for online personalized education on home de-vices. This direction becomes more promising during the COVID-19 pandemic when in-person education becomes infeasible. However, as one of the most inﬂu-ential and practical MT paradigms, iterative machine teaching (IMT) is prohibited on IoT devices due to its inefﬁcient and unscalable algorithms. IMT is a paradigm where a teacher feeds examples iteratively and intelligently based on the learner’s status. In each iteration, current IMT algorithms greedily traverse the whole train-ing set to ﬁnd an example for the learner, which is computationally expensive in practice. We propose a novel teaching framework, Locality Sensitive Teaching (LST), based on locality sensitive sampling, to overcome these challenges. LST has provable near-constant time complexity, which is exponentially better than the existing baseline. With at most 425.12× speedups and 99.76% energy savings over IMT, LST is the ﬁrst algorithm that enables energy and time efﬁcient machine teaching on IoT devices. Owing to LST’s substantial efﬁciency and scalability, it is readily applicable in real-world education scenarios. 1

Introduction
During the COVID-19 pandemic, there is an increasing demand for learning at home. Computer-based personalized education (CBPE) [1, 2, 3] on Internet-of-Things (IoT) devices become essential as it improves the accessibility of students to the educational resources and reduces the potential privacy risks. Due to the popularity of Coursera, Duolingo, and EdX, online on-device educa-tion has become increasingly more important nowadays. To better understand and improve the
CBPE approaches in this context, we consider machine teaching (MT) [4] as a simpliﬁed yet helpful paradigm. Speciﬁcally, MT deﬁnes the problem where a machine teacher constructs a minimal set of examples that allows a student to learn a target concept repeatedly. However, MT on the IoT device is still prohibitive for two primary reasons: (1) MT technique does not allow real-time interaction between teachers and students. It is designed to work over a static set and cannot incorporate real-time student feedback, (2) MT can not support on-device training due to the expensive cost spent in constructing this minimal teaching set. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
Figure 1: A brief overview of the proposed LST algorithm. There are two stages: 1) during data preprocessing, the indices of data samples are stored in LSH hash tables. 2) during the teaching stage, in each iteration, the machine teacher uses the student’s information to query an example from hash tables. Then the machine teacher feeds the example to the student.
As a result, a more practical paradigm – iterative machine teaching (IMT) [5, 6] has been proposed to achieve state-of-the-art teaching performance. In IMT, the teacher interacts with the student in every iteration and aims to teach the target concept with a minimum number of iterations. Although IMT reduces both teaching set size and teaching iterations, it is still not efﬁcient enough. The time and energy required by IMT are prohibitively expensive on IoT devices. There are two primary reasons: (1) IMT is not designed for real-time teaching. Current IMT uses a deterministic greedy algorithm, which traverses the entire dataset to ﬁnd the optimal teaching example during each iteration. This linear time scan costs excessive time in real-world datasets, preventing more frequent interactions between machine teachers and students. (2) IMT has poor energy efﬁciency because the greedy scan requires scoring and ranking on the training examples. The energy budget of IoT devices such as integrated CPU-GPU System-on-Chips (SoCs) cannot afford this expensive energy consumption in real-world teaching. Clearly, there is a gap between IMT and its deployment on IoT devices.
Contemporary IMT literature focuses on developing and analyzing theories, models, or paradigms in teaching. Few studies are addressing the trade-offs between teachability and efﬁciency. Although some IMT algorithms manage their potential applications in crowd-sourcing [7, 8, 9], personal edu-cation [4], or online data poison [10, 11], they do not consider the edge computing and IoT settings and ignore the substantial potential impact behind it.
Our work proposes a time and energy-efﬁcient IMT algorithm, namely Locality Sensitive Teaching (LST), that enables machine teaching on IoT devices. A real-life teaching observation inspires LST: a human teacher teaches a target concept to the student efﬁciently based on his or her knowledge in mind rather than a brutal-force scan over all the course materials. Similarly, an efﬁcient IMT algorithm should provide optimal examples by looking up from a data structure rather than traversing the entire example set. Our LST algorithm effectively pre-indexes the teaching examples in hash tables. Then, given the student’s current state at each iteration, we regard it as a query and generate examples through efﬁcient sampling using the hash tables [12]. Moreover, we signiﬁcantly improve the time and energy efﬁciency by reducing the expensive linear scan into a lightweight lookup in hash tables. As a result, LST could be compatible with edge computing on IoT devices.
Our proposal, LST, comes with three key questions: (1) how to reformulate the IMT problem as a sampling problem that involves efﬁcient hash table data structures? (2) how to maintain the identical teachability of IMT when utilizing the efﬁcient hash table structures? (3) how to provide an efﬁcient
LST implementation on IoT devices that reduce energy and time consumption?
At a high level, we tackle these challenges as follows:
• We reformulate IMT as an adaptive inner product sampling problem. We partition the teaching materials into two parts: (1) query: current state of student and the optimal model possessed by the machine teacher, (2) data: teaching examples denoted as feature-label pairs. We apply an asymmetric transformation that projects both parts as vectors. Then, we argue that the original
IMT formula can be formulated as an adaptive inner product sampling. Given the query vector, the task is to sample data vectors with large inner products. Therefore, locality sensitive sampling can be introduced for efﬁcient teaching examples generation. 2
• We demonstrate, both theoretically and empirically, that LST preserves the teachability of IMT.
Theoretically, we prove the LST can achieve exponential teachability with high probability. Em-pirically, the experiments on real-world teaching indicate that LST matches or even exceed the teachability of original IMT.
• We provide a novel LST system design on integrated CPU-GPU SoC platforms that performs time and energy-efﬁcient teaching in real-world settings. We re-partition the locality sensitive sampling procedure into two parts: GPU-friendly random projection and CPU-friendly hash table lookups. Then, we exploit the beneﬁts of fast matrix multiplications on GPU and efﬁcient hash table lookups implemented on CPUs. Therefore, our LST system takes full advantage of the memory-constrained CPU-GPU SoCs.
Through extensive experiments in real-world teaching scenarios, we demonstrate that LST per-forms exponential teachability that matches or even exceeds IMT while achieving at most 425.12× speedups and 99.76% energy savings on IoT devices. On server-based evaluation, LST achieves more than 2000× speedups over IMT. 2