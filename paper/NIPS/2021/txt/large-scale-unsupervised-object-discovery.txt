Abstract
Existing approaches to unsupervised object discovery (UOD) do not scale up to large datasets without approximations that compromise their performance. We propose a novel formulation of UOD as a ranking problem, amenable to the arsenal of distributed methods available for eigenvalue problems and link analysis.
Through the use of self-supervised features, we also demonstrate the ﬁrst effective fully unsupervised pipeline for UOD. Extensive experiments on COCO [42] and
OpenImages [35] show that, in the single-object discovery setting where a single prominent object is sought in each image, the proposed LOD (Large-scale Object
Discovery) approach is on par with, or better than the state of the art for medium-scale datasets (up to 120K images), and over 37% better than the only other algorithms capable of scaling up to 1.7M images. In the multi-object discovery setting where multiple objects are sought in each image, the proposed LOD is over 14% better in average precision (AP) than all other methods for datasets ranging from 20K to 1.7M images. Using self-supervised features, we also show that the proposed method obtains state-of-the-art UOD performance on OpenImages1.
Figure 1: Sample UOD results obtained by LOD on the OpenImages dataset [35] which contains 1.7M images.
Ground-truth boxes are shown in yellow, and predictions are in red. Best viewed in color. 1

Introduction
This paper addresses the problem of identifying prominent objects in large image collections without manual annotations, a process known as unsupervised object discovery (UOD). Early approaches to
UOD focused mostly on ﬁnding clusters of images featuring objects of the same category [22, 58, 61, 62, 64, 69]. Some of them [58, 61, 62] also output object locations in images, but their evaluations are limited to small datasets with distinctive object classes. More recent techniques [8, 66, 67] focus on the discovery of image links and individual object locations within much more diverse image collections. They typically rely on combinatorial optimization to select objects, or rather, object bounding boxes, among thousands of candidate region proposals [46, 65, 67, 83] given similarity scores computed for pairs of proposals associated with different images. Although these techniques achieve promising results, their computational cost and inherently sequential nature limit the size of the dataset they can be applied to. Attempts to scale up the state-of-the-art approach [67] by reducing the search space size have revealed that this compromises its ability to discover multiple objects in 1Our code is publicly available at https://github.com/huyvvo/LOD. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
each image. Other approaches to UOD focus on learning image representations by decomposing images into objects [5, 12, 23, 43, 47]. These techniques do not scale up (yet) to large natural image collections, and focus mostly on small datasets containing simple shapes in constrained environments.
Table 1: Large-scale object discovery performance and comparison to the state of the art on COCO [42] (C120K), OpenImages [35] (Op1.7M) and their respective subsets C20K and Op50K, in three standard metrics.
Using VGG16 features [60], the proposed method LOD achieves top performance in both single and multi-object discovery, and scales better to 1.7M images in Op1.7M than the previous state of the art [67]. When running with self-supervised features (LOD + Self [18]), it yields the best results on Op1.7M, showing the ﬁrst effective fully unsupervised pipeline for UOD. See Sec. 4 for more details.
Single-object
CorLoc
Multi-object
Method
EB [83]
Wei [71]
Kim [32]
Vo [67]
Ours (LOD+Self [18])
Ours (LOD)
AP50
C20K C120K Op50K Op1.7M C20K C120K Op50K Op1.7M C20K C120K Op50K Op1.7M 28.8 38.2 35.1 48.5 41.1 48.5 1.41 0.73 0.96 1.62 1.29 1.98 1.43 0.74 0.96 1.6 1.37 2.0 4.91 2.44 3.93 5.03 4.90 6.64 5.49 1.86
-4.88 6.28 6.28 5.46 1.86 4.13 4.98 6.37 6.46 29.1 38.3 34.8 48.5 42.4 48.6 1.53 0.6 0.98 1.58 1.87 1.88 4.86 2.41 3.93 5.18 4.56 6.63 32.7 34.8 37.0 48.0 49.5 48.1 32.8 34.8
-47.8 49.4 47.7 1.53 0.6
-1.57 1.86 1.83
AP@[50:95]
It is natural to cast unsupervised object discovery (UOD) as the task of ﬁnding repetitive visual patterns in image collections. Recent approaches (e.g., [66, 67]) to UOD formulate it as a combinatorial optimization problem in a graph of images, selecting simultaneously image pairs that contain similar objects and region proposals that correspond to objects, with the corresponding computational limitations. The motivation behind our work is to formulate UOD as a simpler graph-theoretical problem with a more efﬁcient solution, where objects correspond to well-connected nodes in a graph whose nodes are region proposals (instead of images in [66, 67]), and edges are weighted by region similarity and objectness. In this scenario, ﬁnding object-proposal nodes is now a ranking problem where the goal is to rank the nodes based on how well they are connected in the graph. From another perspective, ranking is rather a natural modelization choice for UOD as in our context, discovering objects means ﬁnding the most object-like regions in a set of initial region proposals which naturally amounts to ranking them according to their “objectness”. As a result, a large array of methods available for eigenvalue problems and link analysis [48] can be applied to solve UOD on much larger datasets than previously possible (Fig. 1). We consider three variants of this approach: the ﬁrst one re-deﬁnes the UOD objective [66, 67] as an eigenvalue problem on the graph of region proposals, the second variant explores the applicability of PageRank [4, 48] for UOD, and the ﬁnal variant combines the other two into a hybrid algorithm, dubbed LOD (for large-scale object discovery), which uses the solution of the eigenvalue problem to personalize PageRank. LOD offers a fast, distributed solution to object discovery on very large datasets. We show in Sec. 4.1 and Table 1 that its performance is comparable or better than the state of the art in the single object discovery setting for datasets of up to 120K images, and over 37% better than the only algorithms we are aware of that can handle up to 1.7M images. In the multi-object discovery setting, LOD signiﬁcantly outperforms all existing techniques on datasets from 20K to 1.7M images. While LOD does not explicitly address discovering relationships between images (e.g., grouping images into classes), we demonstrate that categories can be discovered as a post-processing step (see Sec. 4.2). The best performing approaches to UOD so far all use supervised region proposals and/or features. We also demonstrate for the ﬁrst time in
Sec. 4.1 that self-supervised features can give good UOD performance. Our main contributions can be summarized as follows:
• We propose a new formulation of UOD as a ranking problem, allowing the application of parallel and distributed link analysis methods [4, 48].
• We scale UOD up to datasets 87 times larger than those considered in the previous state of the art [67]. Our novel LOD algorithm outperforms others on medium-size datasets by up to 32%.
• We propose to use self-supervised features for UOD and show that LOD, combined with these features, offers a viable UOD pipeline without any supervision whatsoever.
• We conduct extensive experiments on the COCO [42] and OpenImages [35] datasets to empirically validate our method. We also demonstrate applications of our approach to object category discovery and retrieval, outperforming other existing unsupervised baselines on both tasks by a large margin. 2
2 Problem statement and related work 2.1 Problem statement
Consider a collection of n images, each equipped with a set region proposals [66, 67]. For the sake of simplicity, we assume in this presentation that all images have exactly r region proposals. We wish to ﬁnd which ones of these correspond to objects, and link images that contain similar objects, without any information other than how similar pairs of proposals are. This problem is known as unsupervised object discovery (UOD) and can be formulated as an optimization problem [67] over a graph where images are represented as nodes. Let epq ∈ {0, 1} for p, q = 1, 2, . . . , n be a set of binary variables indicating if two images are connected in the graph, with epq = 1 when images p and q share similar visual content. Similarly, let xk p ∈ {0, 1} for p = 1, 2, . . . , n and k = 1, 2, . . . , r be indicator variables such that xk p = 1 when region proposal k of image p is an object-like region in image p that is similar to an object-like region in one of the neighbors of image p. Let also xp be (x1 p)T , x be the n × r matrix whose rows are xp for p = 1, 2, . . . , n and e be the binary adjacency matrix of the image graph. Then, the object discovery problem can be formulated as a combinatorial maximization problem: n (cid:88) p, . . . , xr r (cid:88) (cid:88) (cid:88) epqxT p Spqxq s.t. xk p ≤ ν and epq ≤ τ
∀ 1 ≤ p ≤ n, (C) max x,e p=1 q∈N (p) k=1 q(cid:54)=p where Spq ∈ Rr×r is a matrix whose entry Sk(cid:96) pq ≥ 0 measures the similarity between region k of image p and region (cid:96) of image q as well as the saliency of the respective regions, N (p) is a set of potential high-similarity neighbors of image p, and ν and τ are predeﬁned constants corresponding to the maximum number of objects in an image and the maximum number of its neighbors, respectively.
Previous approaches [66, 67] to UOD solve a convex relaxation of (C) in the dual domain and/or use block-coordinate ascent on its variables x and e. The similarity scores Sk(cid:96) pq are typically computed using the Probabilistic Hough Matching (PHM) algorithm from [8], which combines local appearance and global geometric consistency constraints to compare pairs of regions. A high PHM score between a pair of proposals is an indicator of whether the corresponding two proposals may correspond to a common foreground object. We follow this tradition and also use PHM scores (Sec. 4).
The objective of UOD as formulated in (C) is to ﬁnd both the objects (variables xk p) and the edges linking the images that contain them (variables epq). Its combinatorial nature makes it hard to scale up to large values of n and r. [67] uses a block-coordinate ascent algorithm to (C), updating variables x and e alternatively to optimize the objective. It attempts to scale up (C) with a drastic approximation, running on parts of the image collection to reduce r to only 50 before running on the entire dataset.
However, using signiﬁcantly reduced sets of region proposals hinders its ability to discover multiple objects (Table 1). Moreover, this algorithm is inherently sequential. According to [66], in each iteration of optimizing x, an index i is chosen and xi is updated while e and all xj with j (cid:54)= i are kept ﬁxed. The update of xi depends on the updated values of other xj if xj is updated before xi.
This is crucial to guarantee that the objective always increases. If all xi are updated in parallel, there is no guarantee that the objective would increase. Consequently, this process is not parallelizable, preventing the algorithm from scaling up to datasets with millions of images. We therefore drop the second objective of UOD, and rely only on a fully connected, weighted graph of proposals where edge weights encode proposals’ similarity (edge weights can be zeros, see Sec. 3). In turn, we can reformulate UOD as a ranking problem [4, 30, 34, 36, 51], amenable to the panoply of large-scale distributed tools available for eigenvalue problems and link analysis. We consider two different ranking formulations: the ﬁrst (Q) tackles a quadratic optimization problem, and the second (P) is based on the well-known PageRank algorithm [4, 48]. We combine these two approaches into a joint formulation (LOD) that gives the best results on large-scale datasets. See Sections 3 and 4 for details. 2.2