Abstract
Conventional supervised learning methods, especially deep ones, are found to be sensitive to out-of-distribution (OOD) examples, largely because the learned representation mixes the semantic factor with the variation factor due to their domain-speciﬁc correlation, while only the semantic factor causes the output. To address the problem, we propose a Causal Semantic Generative model (CSG) based on a causal reasoning so that the two factors are modeled separately, and develop methods for OOD prediction from a single training domain, which is common and challenging. The methods are based on the causal invariance principle, with a novel design in variational Bayes for both efﬁcient learning and easy prediction.
Theoretically, we prove that under certain conditions, CSG can identify the seman-tic factor by ﬁtting training data, and this semantic-identiﬁcation guarantees the boundedness of OOD generalization error and the success of adaptation. Empirical study shows improved OOD performance over prevailing baselines. 1

Introduction
Deep learning has initiated a new era of artiﬁcial intelligence where the potential of machine learning models is greatly unleashed. Despite the great success, these methods heavily rely on the assumption that data from training and test domains follow the same distribution (i.e., the IID assumption), while in practice the test domain is often out-of-distribution (OOD), meaning that the test data distribute differently from the training data. Popular models for predicting the output (or label, response, outcome) y from the input (or covariate) x have been found erroneous when confronted with a distribution change, even from an essentially irrelevant perturbation like a position shift or background change for images [91, 6, 102, 41, 2, 27]. These phenomena pose serious concerns on the robustness and trustworthiness of machine learning methods and severely impede them from risk-sensitive scenarios.
Looking into the problem, although deep learning models allow extracting abstract representation for prediction with their powerful approximation capacity, the representation may unconsciously mix up semantic factors s (e.g., shape of an object) and variation factors v (e.g., background, object position) due to a correlation between them (e.g., desks often appear in a workspace background and beds in bedrooms), so the model also relies on the variation factors v for prediction via this correlation. However, this correlation tends to be superﬁcial and spurious (e.g., a desk can also appear in a bedroom, but this does not make it a bed), and may change drastically in a new domain, making the effect from v misleading. So it is desired to learn a representation that identiﬁes s against v.
Formally, the essence of this goal is to leverage causal relations for prediction, since the fundamental distinction between s and v is that only s is the cause of y. Causal relations better reﬂect basic
∗Correspondence to: Chang Liu <changliu@microsoft.com>.
†Work done during an internship at Microsoft Research Asia. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
mechanisms of nature. They bring the merit to machine learning that they tend to be universal and invariant across domains [97, 87, 93, 77, 16, 96, 98], thus provide the most transferable and reliable information to unseen domains. This causal invariance has been shown to lead to proper domain adaptation [97, 123], lower adaptation cost and lighter catastrophic forgetting [87, 9, 56].
In this work, we propose a Causal Semantic Generative model (CSG) following a causal consideration to separately model the semantic (cause of prediction) and variation latent factors, and develop OOD prediction methods with theoretical guarantees on identiﬁability and the boundedness of OOD prediction error. Addressing the complaint that OOD prediction and causality methods often require multi-domain or intervention data, we focus on the most common and also challenging tasks where only one single training domain is available, including OOD generalization and domain adaptation, where in the latter, unsupervised test-domain data are additionally available for training. The methods and theory are based on the causal invariance principle, which suggests to share generative mechanisms across domains, while the latent factor distribution (i.e., the prior p(s, v)) changes. We argue that this causal invariance is more reliable than inference invariance in the other direction adopted by many existing methods [33, 101, 2, 66, 79]. For our method, we design novel and delicate reformulations of the ELBO objective so that we avoid the cost to build and learn two inference models. Theoretically, we prove that under certain conditions, CSG can identify the semantic factor on the single training domain, even in presence of an s-v correlation. We further prove the merits from this identiﬁcation: prediction error is bounded for OOD generalization, and for domain adaptation, the test-domain prior is identiﬁable which leads to an accurate prediction. To sum up our contributions,
• Up to our knowledge, we are the ﬁrst to show a theoretical guarantee (under appropriate conditions) to identify the latent cause of prediction (i.e., the semantic factor) on a single training domain, and also the ﬁrst to show the theoretical beneﬁts of this identiﬁcation for OOD prediction.
The results also contribute to generative representation learning for revealing what is learned.
• We develop effective methods for OOD generalization and domain adaptation, and achieve mostly better performance than prevailing methods on real-world image classiﬁcation tasks. 2