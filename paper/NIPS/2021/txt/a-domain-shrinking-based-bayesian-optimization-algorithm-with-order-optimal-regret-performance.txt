Abstract
We consider sequential optimization of an unknown function in a reproducing kernel Hilbert space. We propose a Gaussian process-based algorithm and establish its order-optimal regret performance (up to a poly-logarithmic factor). This is the
ﬁrst GP-based algorithm with an order-optimal regret guarantee. The proposed algorithm is rooted in the methodology of domain shrinking realized through a sequence of tree-based region pruning and reﬁning to concentrate queries in increasingly smaller high-performing regions of the function domain. The search for high-performing regions is localized and guided by an iterative estimation of the optimal function value to ensure both learning efﬁciency and computational efﬁciency. Compared with the prevailing GP-UCB family of algorithms, the proposed algorithm reduces computational complexity by a factor of O(T 2d−1) (where T is the time horizon and d the dimension of the function domain). 1

Introduction
Consider a black-box optimization problem with an unknown objective function f : X → R, where
X ⊂ Rd is a convex and compact set. The learner can access the function only through a noisy oracle, which, when queried with a point x ∈ X , returns a noisy function value at that point. The learning objective is to approach the maximizer x∗ of the function through a sequence of query points {xt}T chosen sequentially in time. The learning efﬁciency is measured by cumulative regret given by t=1
R(T ) =
T (cid:88) t=1
[f (x∗) − f (xt)] . (1)
This cumulative regret measure dictates the online nature of the problem: every query point during the learning process carries loss, not just the end point xT after learning concludes. The classical exploration-exploitation tradeoff in online learning hence ensues. 1.1 Gaussian Process Models
The above problem is ill-posed unless certain structure of the unknown objective function f is assumed to make learning x∗ feasible. One such structural assumption is the convexity of f , which leads to the class of stochastic convex optimization problems. Another class of black-box optimization problems that is gaining interest in recent years is kernel-based learning where f is assumed to live in a Reproducing Kernel Hilbert Space (RKHS) associated with a positive-deﬁnite kernel. An effective approach to kernel-based black-box optimization is Bayesian optimization that adopts a ﬁctitious prior on the unknown function f . In other words, while f is deterministic, it is viewed internally by 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
the learning algorithm as a realization of a random process over X . A natural choice is the Gaussian process (GP) with a Gaussian prior due to the conjugate property that signiﬁcantly simpliﬁes the analytical form of the posterior distribution at each newly obtained observation.
In a celebrated work, Srinivas et al. [1] proposed the GP-UCB algorithm that constructs a proxy of f using the upper conﬁdence bound (UCB) concept ﬁrst introduced in the classical multi-armed bandit problem [2, 3]. Speciﬁcally, at each time instant t, a UCB of f is constructed using the closed-form posterior mean and standard deviation of the GP model of f . The algorithm then sets the next query point to be the maximizer of the UCB. Several variations of GP-UCB, tailored for different settings (see Sec 1.3), have since been developed.
The GP-UCB family of algorithms generally enjoy good empirical performance in terms of regret.
The analytical guarantees of their regret performance, however, leave considerable gaps to the existing lower bound [4]. More signiﬁcantly, the state-of-the-art regret bound of GP-UCB does not guarantee a sublinear order in T for certain kernels, hence a lack of guaranteed convergence to f (x∗) [4, 5].
Another difﬁculty with the GP-UCB family of algorithms is their computational complexity, which can be prohibitive as the dimension d and/or the horizon length T grows. The computational complexity has two main sources: (i) the inversion of the covariance matrix in updating the posterior
GP distribution, which has an O(t3) complexity with t samples; (ii) the maximization of the UCB proxy over the entire domain X at each time instant. In particular, due to the multi-modality of the UCB score, its maximization is often carried out using a grid search with an increasingly ﬁner discretization of the entire domain. Speciﬁcally, due to analytical requirements, the discretization is typically assumed to grow in the order of O(t2d) [1, 6], resulting in an overall computational complexity of O(T 2d+3).
Several studies exist that tackle the ﬁrst source of high complexity of GP-UCB, using sparse matrix approximation techniques to reduce the complexity in the inversion of the covariance matrix (see, e.g., [7, 8]). The second source, which is the dominating factor, has not been effectively addressed. 1.2 Main results
The goal of this work is to develop a GP-based Bayesian optimization algorithm with a regret guarantee that closes the gap to the lower bound. Furthermore, we tackle the second source of the complexity to ensure both learning efﬁciency and computational efﬁciency.
Referred to as GP-ThreDS (Thresholded Domain Shrinking), the proposed algorithm is rooted in the methodology of domain shrinking: it continuously prunes sub-performing regions of the domain
X and zooms into increasingly smaller high-performing regions of X as time goes. The purpose of the domain shrinking is twofold. First, it ensures high learning efﬁciency by focusing queries on regions of X with function values approaching f (x∗). Second, it achieves computational efﬁciency by avoiding a global maximization of the proxy function over the entire domain X .
Our speciﬁc approach to domain shrinking is built upon a sequence of localized searches on a growing binary tree that forms successively reﬁned partitions of X . Starting from the root of the tree that represents the entire domain, the search progresses down the tree by adaptively pruning nodes that do not contain the maximizer with high probability, consequently zooming into increasingly smaller high-performing regions of X as the search deepens. Another progressive thread in this sequence of localized searches is the criterion for pruning the tree. Each localized search aims to identify nodes at a certain depth of the tree that contain points with function values exceeding a given threshold. The threshold is updated iteratively to approach the maximum function value f (x∗). More succinctly, the proposed algorithm is a sequence of localized searches in the domain of the function guided by an iterative search in the range of the function.
The above domain shrinking approach via localized search is the primary contributing factor to improved performance in terms of both regret guarantee and computational complexity. In particular, the rate of domain shrinking is controlled to ensure not only the concentration of query points in high-performing regions, but also a constant-sized discretization at all times when estimating the function values. This constant-sized discretization allows a tighter regret analysis and results in a regret upper bound for GP-ThreDS that matches with the lower bound (up to a poly-logarithmic factor). We show that the regret of GP-ThreDS is O(
T γT ) (up to a poly-logarithmic factor), where γT denotes the maximum information gain after T steps and is representative of the effective dimension of the
√ 2
√
T ) regret bound [e.g., see, 6, Theorem 3]. The O( problem [9, 10]. In the case of Matérn and Squared Exponential (SE) kernels where the lower bounds on regret are known, on substituting the improved bounds on γT from [11], our results match the lower bounds and close the gap reported in [4, 12]. In comparison, the state-of-the-art analysis of
GP-UCB yields an O(γT
γT ) gap between the regret guarantees of GP-UCB and the proposed GP-ThreDS is signiﬁcant: it can grow polynomially in T (e.g. in the case of Matérn kernel).
Computation-wise, the constant-sized discretization contrasts sharply with the growing (at rate O(t2d) with time t) discretization required by the GP-UCB family of algorithms. Another factor contributing to the reduced complexity is the relaxed search criterion that aims to determine only the existence of threshold-exceeding points, in contrast to ﬁnding a global maximizer as in the GP-UCB family of algorithms. As a result, GP-ThreDS reduces the computational complexity from O(T 2d+3) as required by GP-UCB family of algorithms to O(T 4).
√ 1.3