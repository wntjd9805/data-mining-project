Abstract
We present a variational method for online state estimation and parameter learning in state-space models (SSMs), a ubiquitous class of latent variable models for sequential data. As per standard batch variational techniques, we use stochastic gradients to simultaneously optimize a lower bound on the log evidence with respect to both model parameters and a variational approximation of the states’ posterior distribution. However, unlike existing approaches, our method is able to operate in an entirely online manner, such that historic observations do not require revisitation after being incorporated and the cost of updates at each time step remains constant, despite the growing dimensionality of the joint posterior distribution of the states. This is achieved by utilizing backward decompositions of this joint posterior distribution and of its variational approximation, combined with Bellman-type recursions for the evidence lower bound and its gradients.
We demonstrate the performance of this methodology across several examples, including high-dimensional SSMs and sequential Variational Auto-Encoders. 1

Introduction
Many tasks in machine learning with time series data—such as video prediction [16, 27], speech enhancement [35] or robot localization [9, 18, 28]—often need to be performed online. Online techniques are also necessary in contexts as diverse as target tracking [4], weather prediction [13] and ﬁnancial forecasting [42]. A popular class of models for these sequential data are SSMs which, when combined with neural network ideas, can also be used to deﬁne powerful sequential Variational
Auto-Encoders (VAEs); see e.g. [8, 15, 16, 30]. However, performing inference in SSMs is a challenging problem and approximate inference techniques for such models remain an active research area.
Formally, an SSM is described by a latent Markov process and an observation process. Even if the model parameters are assumed known, online inference of the states of the latent process is a complex problem known as ﬁltering. Standard approximations such as the extended Kalman Filter (KF), ensemble KF, and unscented KF can be used, but only provide an ad hoc Gaussian approximation to the ﬁlter [13, 17, 37]. More generally, assumed density ﬁltering techniques [3, 7, 32] can provide other simple parametric family approximations. These approximate ﬁltering methods can be used, in turn, to develop online parameter learning procedures by either augmenting the state with the static parameters or using gradient-based approaches. However, such approaches are notoriously unreliable
[19]. Particle Filtering (PF) methods, on the other hand, provide a more principled approach for online state and parameter estimation with theoretical guarantees [11, 12, 19, 41], but the variance of
PF estimates typically scales exponentially with the state dimension [6].
Although they typically do not return consistent estimates, variational techniques provide an attractive alternative for simultaneous state estimation and parameter learning which scales better to high-dimensional latent states than PF, and are not restricted to simple parametric approximations. Many
∗Equal contribution 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
such methods have been proposed for SSMs over recent years, e.g. [2, 10, 20, 22, 23, 29, 33, 36].
However, they have generally been developed for batch inference where one maximizes the Evidence
Lower Bound (ELBO) for a ﬁxed dataset. As such, they are ill-suited for online learning as, whenever a new observation is collected, one would need to update the entire joint variational states distribution whose dimension increases over time. Though a small number of online variational approaches have been developed [30, 38, 45], these rely on signiﬁcant restrictions of the variational family, leading to approximations that cannot faithfully approximate the posterior distribution of the latent states.
The main contribution of this paper is a novel variational approach to perform online ﬁltering and parameter learning for SSMs which bypasses those restrictions. As per standard batch variational inference, we simultaneously maximize an ELBO with respect to both model parameters and a variational approximation of the joint state posterior. However, our method operates in an entirely online manner and the cost of updates at each time step remains constant. Key to our approach is a backward decomposition of the variational approximation of the states posterior, combined with a representation of the ELBO and its gradients as expectations of value functions satisfying
Bellman-type recursions akin to those appearing in Reinforcement Learning (RL) [39]. 2