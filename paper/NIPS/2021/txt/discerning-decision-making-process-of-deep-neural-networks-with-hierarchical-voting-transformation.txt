Abstract
Neural network based deep learning techniques have shown great success for numerous applications. While it is expected to understand their intrinsic decision-making processes, these deep neural networks often work in a black-box way. To this end, in this paper, we aim to discern the decision-making processes of neural networks through a hierarchical voting strategy by developing an explainable deep learning model, namely Voting Transformation-based Explainable Neural Net-work (VOTEN). Speciﬁcally, instead of relying on massive feature combinations,
VOTEN creatively models expressive single-valued voting functions between ex-plicitly modeled latent concepts to achieve high ﬁtting ability. Along this line, we
ﬁrst theoretically analyze the major components of VOTEN and prove the relation-ship and advantages of VOTEN compared with Multi-Layer Perceptron (MLP), the basic structure of deep neural networks. Moreover, we design efﬁcient algorithms to improve the model usability by explicitly showing the decision processes of
VOTEN. Finally, extensive experiments on multiple real-world datasets clearly validate the performances and explainability of VOTEN. 1

Introduction
Neural network based deep learning techniques have attracted great attention from both academia and industry in the past decade. Compared with classic machine learning models, deep neural networks have much higher expressiveness and adaptability for complicated data input, and thus have made tremendous success in various application domains, such as Computational Vision [29, 56], Natural
Language Processing [54, 20], and Recommender Systems [32, 24]. Nevertheless, since deep neural networks usually have complicated connections of hidden units, a long-standing challenge is how to decipher what’s inside the black box of models for understanding their intrinsic decision-making processes. Indeed, in many real-world scenarios, such as business analysis [33, 57, 49] and human resource management [50, 44, 46, 44], the lack of model explainability makes people less likely to be convinced when the decision-making process of the model is not understandable. This prevents a broader application of deep neural networks.
While many research efforts have been made in developing explainable deep learning models [45, 10], most of existing works focus on post-hoc explanation [5, 18], i.e., designing metrics to measure the feature relevance/contribution to the outputs of a trained model. Although these methods have
*Corresponding authors.
†This work was accomplished when Ying Sun was an intern in Baidu supervised by Hengshu Zhu. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
Figure 1: Structure overview of VOTEN. made progress on ﬁnding important features, the decision-making process of deep learning models is still not available for users. For example, users often need to guess the reason why a prediction is made from the relevant features instead of understanding the decision-making process. Indeed, understanding the intrinsic decision-making process of deep neural networks is a non-trivial task.
A major reason is that deep neural networks usually involve massive feature combinations to gain expressiveness on ﬁtting complicated functions. During this process, the effect of features and hidden units may be largely coupled with each other. This indicates that the decision logic of models is inherently buried in the massive feature combinations. Meanwhile, it is difﬁcult for human to understand the intrinsic modeling process of deep learning in a natural manner. Therefore, a key point on improving the explainability of deep neural networks is to decouple the feature combinations and make the modeling process consistent with human decision process. In this way, the model will have an explicit decision-making process and become human-understandable.
To this end, in this paper, we propose an explainable deep learning model, namely Voting
Transformation-based Explainable Neural Network (VOTEN). Speciﬁcally, VOTEN assumes the transformation from the input to the output to be a hierarchical voting process. During this process, lower-level concepts vote for higher-level concepts layer-by-layer in an expressive but explainable way. Instead of relying on massive feature combinations, VOTEN creatively models expressive single-valued voting functions between explicitly modeled hidden concepts to gain expressiveness on
ﬁtting complicated functions. This process is explainable for its consistency with human decision-making process. We ﬁrst theoretically analyze the major components of VOTEN and prove the relationship and advantages of VOTEN compared with Multi-Layer Perceptron (MLP), which is the basic structure of deep neural networks. The results show that MLP can be derived from VOTEN by using the inexpressive voting functions. Accordingly, we further analyze the effect of inherent votings and design efﬁcient algorithms for pruning and explaining VOTEN. Finally, we evaluated VOTEN on multiple real-world datasets with comprehensive experiments. The experimental results demonstrate that VOTEN generally promotes powerful and explainable deep learning. Speciﬁcally, VOTEN (1) signiﬁcantly raises prediction performance; (2) exponentially decreases feature combinations; and (3) supports efﬁcient pruning and effective feature analysis. Meanwhile, we also visualize the intrinsic decision-making process of VOTEN through case studies, which show VOTEN is explainable and can discover meaningful latent concepts. 2 VOTEN
In this section, we introduce the technical details of VOTEN. 2.1 Structure
When dealing with complicated information, we usually aggregate them step-by-step to form compli-cated inference. Although deep neural networks also extract abstract features layer-by-layer, they are still difﬁcult to be explained. A major difference is that we can induce explicit concepts, which makes us able to explain our inference in a straightforward way.
For example, we can predict that “This student may get high GPA because he/she works very hard”.
If the more explicit explanation is needed, we can further explain that “I observed that he/she stay long in the library”. In this process, with the observation that “stay long in the library”, we ﬁrst 2
infer “hard-working”, then infer “high GPA”. Moreover, when trying to make more comprehensive inference, we may get more observations for existing concepts (e.g., “little missing of classes” may also imply “hard-working”), or induce more concepts (e.g., “learning-efﬁciency”). This kind of process is straightforward and conforms with our way of understanding. However, deep neural networks cannot model concepts in an explicit way. Instead, concept information are embedded in massive hidden units. As we cannot understand these induced concepts, neural networks are like uniﬁed, inseparable complicated functions, even though they are actually performing information aggregation. Along this line, we believe a natural way to understand how a model decides the output is to make the intrinsic concepts explicit for human.
Therefore, we propose VOTEN, whose structure overview is shown in Figure 1. VOTEN hierar-chically models a small number of explicit concepts. During inference, the higher-level concepts will be induced via information aggregation from the lower-level concepts. To achieve meaningful information aggregation, VOTEN focuses on quantifying relationship between individual concepts of different levels. For better understanding, in VOTEN, observations and concepts can be regarded as voters. Based on their own value, each voter independently votes for the higher-level concepts.
The votes are aggregated to get the value estimation of each higher-level concept. These concepts will further vote for the next level. In the training process, the model learns to builds intermediate concepts and their quantitative voting functions.
Formally, for a VOTEN model with D levels of concepts, we use Cd d-th layer, where C0 of concepts as a voting layer. In the d-th voting layer, each concept Cd concept Cd+1 votes with a single-valued nonlinear function f d average of the votes and estimates the value of Cd+1 i to denote the i-th concept in the i denotes an input feature. We refer to transformations between adjacent levels i votes for each higher-level i as the input and i,j : R → R. Then, a counting layer gets weighted j with an independent voting channel V d i,j takes the value of Cd i,j. V d as j xd+1 j = nd(cid:88) k=1 k,jf d ad k,j(xd k) s.t. ∀d, j, nd(cid:88) k=1 ad k,j = 1, (1) where nd denotes the number of concepts in the d-th layer, xd k,j denotes the weight of V d i,j. The concepts of the last layer is regarded as the decision score, which generates the model output with o = F V OT EN (xD). In particular, to assure the ability of the voting functions on effective concept transformation, VOTEN models each voting function with a voting network.
The voting network can be designed in complicated ways without inﬂuencing model explainability, as long as the function is still single-valued. For example, we can adopt weight-sharing structures to reduce model complexity. k denotes the value of Cd k, ad 2.2 Why is VOTEN more explainable than MLP?
In this part, we theoretically discuss VOTEN’s advantages over MLP. Speciﬁcally, we claim that voting expressiveness is the core proposition of VOTEN that raises explainability.
Theorem 1 MLP can be derived from a subset of degenerated VOTEN models whose voting functions in the form of f d i,j, where σ is a predeﬁned activation function, the scalars wd i ) + bd i ) = wd i,j ∈ R are trainable parameters. i,jσ(xd i,j(xd i,j, bd
Proof. Please refer to Appendix A.
From this point of view, MLP also conforms to human inference. However, MLP is still difﬁcult to explain. Indeed, we can more easily understand an inference process with (1) fewer concepts, (2) shorter concept transformations, and (3) fewer reasoning patterns. Under VOTEN schema, we show how inexpressive voting channels make MLP disobey these three traits.
Corollary 1 In MLP, votings from the same concept are linearly correlated.
This means individual voters in MLP are weak in distinguishing different concepts in the next level.
Therefore, MLP relies on highly complicated feature combinations of a large number of deeply tiled voters to achieve high ﬁtting ability. During this process, necessary intermediate information is inherently modeled through combinatorial effects of hidden concepts with inexplicit meanings.
Indeed, previous works have proved that human-understandable concepts are inherently mounted in the hidden units of neural network models [28]. 3
Corollary 2 In MLP, the hypothesis space for voting distribution is limited to scaling and shifting an input distribution.
This means that MLP voters cannot always induce complicated concepts that have different distri-bution from their value. As a result, the input needs to go through a long path of transformations between similar concepts until it contributes to the output. Moreover, the deeply tiled massive concepts make each input feature has massive paths to the output, which brings a large number of possible decision-making patterns of the model. In addition, the effect of votings can easily couple and cancel each other out in the downstream calculations. As a result, separately analyzing the role of individual concepts or decision paths becomes meaningless.
Different from MLP, VOTEN has far more expressive voting functions. It directly models nonlinear transformations between essential intermediate concepts without relying on massive feature combina-tions and naive transformations. As a result, VOTEN’s decision-making process is explicit with only a small number of meaningful concepts, thus is explainable. 2.3 Explaining the effect of votings
In VOTEN, individual voting channels play explicit roles in inﬂuencing the model decision. In this i : Rn0 → R to represent the part, we analyze the effect of votings. First, we use a concept function gd transformation from model inputs x0 ∈ Rn0 to Cd
Deﬁnition 1 In VOTEN, we refer to two concept functions g and g(cid:48) as equivalent iff. there exists an invertible function Φ, so that ∀x0 ∈ Rn0, Φ(g(x0)) = g(cid:48)(x0).
Since Φ is invertible, the outputs of two equivalent concept functions have one-to-one correspondence over all the possible inputs. Then, they can effect equally in the decision-making process.
Theorem 2 In VOTEN, if replacing a concept function with an equivalent form, there exists a way to replace its voting functions so that all the downstream concept functions stay unchanged.
Proof. Please refer to Appendix A. i , which decides the meaning of the concept.
To analyze how voting channels effect on concept functions, we can reformulate Equation 1 as j = gd+1 xd+1 j (x0) = nd(cid:88) i,j(f d ad i,j(gd i (x0)) − Ex[f d i,j(gd i (x))]) + bd+1 j
, (2) where Ex[f d i,j(gd independent bias. In particular, i=1 i (x))] denotes the expectation of f d i,j over all the instances, bd+1 j is a sample-bd+1 j = nd(cid:88) i=1 ad i,j
Ex[f d i,j(gd i (x))] = Ex[gd+1 j (x)]. (3) j i,j(gd i,j(gd i (x0)) − hd i,j to denote Ex[f d i,j reveals the effect of V d i (x))]. Notably, by adding an arbitrary bias to gd+1
For simplicity, we use hd
, we obtain an equivalence of the original concept. According to Theorem 2, we can construct a model with exactly the same expression (i.e., equivalent concepts and the same predictions) as the previous one. This implies that VOTEN may converge to models with differed internal bias but exactly the same decision-making process, indicating VOTEN explanation should be independent of concept bias. According to Equation 2 and 3, voting channels’ average only inﬂuence concept bias while the voting deviation f d i,j for the decision. This can be intuitively explained as each voter can vote with different basic scores and only the deviation from the basic score reﬂects their judgement for a speciﬁc instance. Similarly, from the global view, we reformulate i,j(x0) + bd+1 the concept function as xd+1
Notably, K d i,j(·) generates a distribution with mean 0 and variance 1 over all the instances. Therefore, i,j and σd ad i,j jointly decide the overall effect of votings. Speciﬁcally, the counting layer explicitly adjusts ad i,j so that reliable voters have stronger inﬂuences. Meanwhile, the voter implicitly adjusts
σd i,j. When the concept is less related to the target concept and cannot support proper votes, they decrease σd i,j and tend to always vote the basic score to avoid disturbing the model. Otherwise, they increase σd i,j and vote conﬁdently to lead the model to correct estimation. i (x0))−hd
σd j = (cid:80)
, where K d i,j(x0) = i,jK d i,jσd i,j (gd f d i ad i,j i,j j
.
Based on the above analysis, we can easily design algorithms to ease both VOTEN local and global explanation, such as recognizing decision paths and quantifying the concept/feature relevance to the prediction, which can be found in Appendix B and Appendix C. 4
Table 1: Model Performance. We conducted 10 independent runs on each dataset and show the average ± standard deviation of AUC and AP. In particular, for multi-classiﬁcations, we estimated the macro average of each metric. We also did signiﬁcance test, where * and ** denote signiﬁcantly (i.e., p-value ≤ 0.05) and very signiﬁcantly (i.e., p-value ≤ 0.01) worse than VOTEN.
AUC 0.9396∗∗
PR
±
±
PR
±
±
PR
±
±
PR
±
±
PR
±
±
PR
±
AUC 0.6762∗∗
AUC 0.5134∗∗
DT [43] 0.2557∗∗ 0.0007 0.0096 0.0177∗∗ 0.0001 0.0014 0.8119∗∗ 0.0010 0.0005 0.2514∗∗ 0.0022 0.0018 0.6408∗∗ 0.0002 0.0002 0.0081∗∗ 0.0001
AUC 0.7250∗∗
AUC 0.6705∗∗
AUC 0.4999∗∗
± 0.0002
RF [48] 0.4624∗∗ 0.0010 0.9007∗∗ 0.0006 0.0349∗∗ 0.0011 0.6566∗∗ 0.0052 0.9763∗∗ 0.0003 0.9979∗∗ 0.0001 0.6348∗∗ 0.0014 0.9388∗∗ 0.0005 0.8505∗∗ 0.0001 0.8429∗∗ 0.0001 0.0085∗∗ 0.0001 0.5139∗∗ 0.0009
LGB [27] MLP [22] NAM [7] VOTEN 0.4817∗∗ 0.5007 0.0041 0.0007 0.9209∗∗ 0.9237 0.0001 0.0005 0.0525∗ 0.0550 0.0001 0.0017 0.7305∗ 0.7322 0.0003 0.0016 0.9753∗∗ 0.9783 0.0013 0.0003 0.9965∗∗ 0.9983 0.0001 0.0001 0.6522 0.6972 0.0019 0.0001 0.9508 0.9566 0.0002 0.0001 0.8590∗∗ 0.8612 0.0001 0.0005 0.8459∗∗ 0.8481 0.0005 0.0001 0.0120 0.0120 0.0001 0.0001 0.5975 0.6026 0.0021 0.0001 0.4412∗∗ 0.0014 0.9031∗∗ 0.0014 0.0485∗∗ 0.0014 0.7102∗∗ 0.0082 0.7000∗∗ 0.0008 0.9497∗∗ 0.0001 0.6567∗∗ 0.0043 0.9506∗∗ 0.0006 0.7897∗∗ 0.0003 0.7751∗∗ 0.0001 0.0108∗∗ 0.0001 0.5742∗∗ 0.0018 0.4870∗∗ 0.0040 0.9199∗∗ 0.0008 0.0516∗∗ 0.0014 0.7250∗∗ 0.0017 0.9662∗∗ 0.0018 0.9965∗∗ 0.0002 0.6215∗∗ 0.0030 0.9454∗∗ 0.0004 0.8297∗∗ 0.0007 0.8157∗∗ 0.0007 0.0113∗∗ 0.0001 0.5917∗∗ 0.0005
MR
RP
CT
CI
HG
AS 2.4 VOTEN supports effective model pruning
In VOTEN, concepts are estimated by averaging the votes. This means we can delete a voting channel while keeping the physical meaning of the target concept unchanged. This supports effective link pruning. Speciﬁcally, since only the voting deviation from the average decides the effect, we can assume the absent channel votes the basic score regardless of the input. Formally, the value of Cd+1 is estimated as ˆxd+1 i,j ∈ {0, 1} indicates if V d i ) − hd i,j is not absent. Furthermore, since only involving a small number of voting channels, we can achieve network pruning on VOTEN by exhaustively exploring how the performance will get inﬂuenced if some voting channels are absent, which is infeasible for MLP. In MLP, we usually prune unimportant hidden units to reduce model complexity. However, usually not all the voting channels from an important concept are necessary. In VOTEN, these unnecessary concept transformations can be further eliminated to not only reduce model complexity but also raises the explainability of the model.
In Appendix D, we give an efﬁcient VOTEN pruning algorithm with a lazy updating strategy. j = (cid:80)nd i,j) + bd+1
, where I d i=1 I d i,j(f d i,j(xd i,jad j j 3 Experiment
To evaluate the effectiveness and explainability of VOTEN for seizing comprehensive decision-making patterns. We conducted experiments1 with 6 large public datasets, including Context-aware
Multi-Modal Transportation Recommendation (MR) [2, 58], IJCAI-18 Search Conversion Rate
Prediction (RP) [3], Forest Cover Type Prediction (CT) [12], Census-Income Prediction (CI) [38],
Allstate Claim Prediction (AS) [1], and Higgs boson dataset (HG) [11]. The detailed descriptions of experimental setup can be found in Appendix E. 3.1 Performance Evaluation: Can VOTEN achieve higher performance than MLP?
We used two widely adopted metrics for imbalanced classiﬁcation performance evaluation, including
Area Under ROC Curve (AUC) [14] and average precision (AP) [19], whose higher value means 1Our code is available at https://github.com/sunyinggilly/VOTEN 5
higher performance. In Table 1, we compare the performance of VOTEN with several baselines, including Decision Tree (DT) [43], Random Forest (RF) [48], LightGBM (LGB) [27], MLP [22], and Neural Additive Model (NAM) [7] (see Appendix E.2 for detail). For each dataset, we have carefully tuned the parameters of the baselines to achieve their best performance. Especially, detailed analysis on MLP parameters can be found in Appendix E.3. It can be observed that, while deep neural networks are powerful when incorporated with purposely designed modules or prior knowledge for speciﬁc tasks, its standard form (i.e., MLP) without task-speciﬁc structures may perform worse than
LightGBM, which have also been shown by many previous studies [47, 8, 4]. Indeed, LightGBM is believed to be powerful in handling structured data and often appears as the major model of the top solutions in data-mining competitions [58, 35]. In contrast, VOTEN, also in its standard form, signiﬁcantly outperforms MLP for all these tasks and comparable with LightGBM. Indeed, on many datasets, it outperforms LightGBM if complicated feature engineering is not performed. This shows the effectiveness of VOTEN in terms of handling real-world problems. Indeed, VOTEN is more suitable for handling data-mining tasks since it has more reasonable decision-making process. It should be noticed that, similar to MLP, VOTEN is a standard and generic model that can be easily expanded to task-speciﬁc networks to raise model performance (for example, we can replace MLP with VOTEN in DeepFM [24]). While this paper focuses on the generic performance of standard
VOTEN, it shows the possibility of building more powerful deep learning solutions for a wide range of applications. 3.2 Explanation Complexity: Is the decision-making process of VOTEN recognizable?
RP
MR
Data
#P/F
#C/L
Depth
Model
Table 2: Explanation complexity. “#C/L” counts hid-den concepts in each layer. “#P/F” counts possible decision paths from each feature.
In Table 2, we compare the explanation com-plexity of MLP and VOTEN. As we have dis-cussed in Section 2.2, we use the number of feature combinations, the length of decision paths, and the number of possible decision-making patterns to show the explanation com-plexity of a model. In particular, we trained two VOTEN models with different settings for each dataset. Speciﬁcally, “VOTEN−” is com-parable to the best performance of MLP, with the least feature combinations. “VOTEN” is the one with the best performance. It can be observed that VOTEN greatly reduces feature combinations and decision paths. For exam-ple, on the MR dataset, MLP needs 7 voting layers that each contain 128 concepts. This brings an exponentially large number of long decision paths. In contrast, VOTEN achieves comparable performance with 16 hidden con-cepts in total. Then, each feature only has 16 possible paths with a length of 2 to reach the output. This signiﬁcantly eases the understanding of the decision-making process. For some datasets, VOTEN with no intermediate concepts (i.e., features directly vote for the prediction) can achieve comparable performance to MLP. Moreover, even when reaching its best performance, VOTEN still has a much smaller explanation complexity than MLP. It should be noticed that we have listed the maximum possible number of decision paths for convincing illustration. In practice, we can easily distinguish a fewer number of important decision paths, which will be shown in the following experiments.
Performance
AP
AUC 0.920 0.487 0.922 0.497 0.924 0.501 0.725 0.052 0.732 0.055 0.732 0.055 0.996 0.966 0.997 0.969 0.998 0.978 0.945 0.622 0.950 0.652 0.951 0.652 0.816 0.830 0.816 0.831 0.848 0.862 0.592 0.011 0.594 0.012 0.598 0.012
MLP
VOTEN−
VOTEN
MLP
VOTEN−
VOTEN
MLP
VOTEN−
VOTEN
MLP
VOTEN−
VOTEN
MLP
VOTEN−
VOTEN
MLP
VOTEN−
VOTEN 249 16 256 1,728 1 64 249 1,024 4,096 1,024 1 16 224 8 4,096 224 16 4,096 128 16 16 12 0 8 128 32 64 32 0 4 64 8 64 64 16 64 7 1 2 3 0 2 7 2 2 2 0 2 4 1 2 4 1 2
HG
AS
CT
CI 3.3 Case Study: How to explain a VOTEN model?
We show how to explain a VOTEN model with an example in the MR dataset. Speciﬁcally, we
ﬁrst analyze the global decision-making process and discover the meaning of concepts by observing voting functions on important decision paths. Then, we locally explain how the inputs of an instance hierarchically vote the ﬁnal prediction.
Task Description. The task is to recommend the transport mode for online map app users, given a user and an Origin-Destination (OD) pair. The features mainly contain user portraits and an ordered list of recommended plans of the map app. Each plan consists of transport mode, time, distance, and price. We deleted the ﬁrst recommended plan’s mode information since it is too strongly correlated 6
Figure 2: Case study of VOTEN global decision-making process in MR dataset. We show the important paths from inputs to one output, where wide lines indicate important voting channels.
The concept LxHy indicates the y-th concept in the x-th layer. We visualize the important voting functions for each concept along the paths relevant to L2H7, where blue lines show the function while green lines show the average vote. with the label (many users choose the ﬁrst recommendation as default). In this way, we can better observe how the model incorporates complicated information for meaningful decisions.
Global Decision-Making Process. We focus on the decision-making process for the class “Subway”.
First, we discover the important transformations from observations to the prediction with our decision path recognition algorithm. The results are shown in Figure 2. Next, we analyze the meaning of concepts from the bottom to the top. L1H8 gets larger when modes of more recommended plans are “Subway”, which we regard as “OD pair with ﬂexible subway-based plans”. L1H12 decreases with higher prices and lower distances, which we regard as “OD pair’s distance-cost performance”.
L1H14 observes if the OD pair is distant but still available with inexpensive and fast transportation.
Besides, it also observes if modes of public transportation ever appear in the plan list. Therefore, we regard L1H14 as “distant OD pair with convenient and economical public transportation”. L1H15 is sensitive to a time-consuming top-1 plan. It also observes the other plans’ modes and prices to estimate if trading money for efﬁciency is infeasible. Therefore, we regard L1H15 as “no choice but a time-consuming transportation”. In the second layer, L2H7 is estimated based on L1H8,
L1H12, L1H14, and L1H15. It gets higher if many subway-based plans available (higher L1H8), transportation with balanced distance-cost is recommended (has a peak for L1H12), distant OD pair but still has convenient public transportation (higher L1H14), or costly time-saving transportation is infeasible (higher L1H15). Comprehensively considering these reasons, it implies “OD pair suitable for subway transportation, which votes for the score of “Subway” with a monotonic transformation.
Along the other path, L1H4 is a concept “OD pair with inexpensive transportation”. Then, L2H5 is also about the price since it is mainly based on L1H4. It should be noticed that its estimation may still be enhanced by other lower-level concepts when dealing with speciﬁc instances, although they are less important from the global view. Finally, L2H5 and L2H7 vote nonlinearly to the score so that the model can make accurate quantitative predictions. With the above analysis, we can qualitatively understand the logic of VOTEN on recommending “Subway”. Actually, the decision-making process is quantitatively more complicated and can handle more special cases. In practice, domain experts can thoroughly analyze the shape and gradients of the voting functions to get more insights into the concepts. This may help researchers to ﬁnd new concepts and develop new theories, especially in
ﬁelds such as psychology and management, where scientists work on ﬁnding mechanisms linking observations to outcomes. Extra visualizations on global decision path and voting functions can be found in Appendix F and Appendix G.
Local Decision-Making Process. Then, we analyze the decision paths for speciﬁc instances. In
Figure 3, we visualize the most important paths for a sample with a high score for “Subway”, which are ﬁltered with a small threshold in our local decision path recognition algorithm. Based on the global analysis, we can easily tell how the observations gradually transformed to higher-level concepts. Speciﬁcally, for L1H12, the vote from price is ﬁltered out, showing the OD pair’s price is normal over the dataset. However, it ﬁnds the OD pair to be distant, which contributes to a relatively larger distance-cost performance than average, given the normal price. This indicates the plan to be relatively more economical. L2H7 observes the value of L1H12, and ﬁnds that the OD pair can 7
Figure 3: Case study of VOTEN local decision-making process in MR dataset, where wider and darker lines indicate stronger inﬂuence (negatively in blue and positively in red). The bottom left shows ﬁltered paths when we gradually bring up the thresholds. We also show the important voting functions, where the green lines show the average and red points show vote for the current instance. (a) MR (b) CT
Figure 4: Heatmap for the propogation-based relevance in VOTEN. The x-axis represents features and the y-axis represents the instance-output pairs, where #I_O indicates the feature relevance of the I-th instance to class O. Red means positive relevance while blue means negative relevance. choose transportation whose distance-cost performance more balanced than average cases (reaches the peak of voting). In this case, L2H7 votes high for subway, which is an economical and balanced transportation mode. On the other decision path, L1H8 thinks “Subway” may not be suitable since subway-based plans seldom appear in the list, thus votes negatively for L2H7. But L1H12 makes a very conﬁdent judgment based on the balance of distance-price performance, which dominates L2H7 and makes the model predict correctly. Interestingly, we ﬁnd one of the most important strategies in this task is to guess the transportation mode most recommended by the app (the information that we hide in prior), which is reasonable. On the one hand, the app’s recommender system trained with abundant information can naturally achieve high performance. On the other hand, many users will click the ﬁrst recommendation as default. In addition to this strategy, the model will use more important decision paths to achieve more accurate predictions. As we gradually increase the threshold, more decision-making patterns appeared. Extra visualizations on local explanation of other datasets can be found in Appendix H. 3.4 Relevance Analysis: Can VOTEN help quantify feature relevance?
Propagation-Based Relevance. Motivated by relevance propagation [10], we propose an algorithm (see Appendix D) to quantify the relevance of features and concepts, based on the important decision paths. The short decision paths of VOTEN decreases error accumulation during the propagation and enables more accurate relevance estimation. In Figure 4, we visualize the propagation-based feature relevance with heatmaps. Obviously, features from #69 to #86 are generally important in the MR dataset, among which the ﬁrst several features (information about the top-1 plan in the list) are the most relevant. Furthermore, the relevant features vary for different samples in terms of different classes, which indicates VOTEN to predict in multiple patterns. For example, Figure 4(b) shows that
VOTEN assigns high score to class 2 for sample 4 and sample 5 with different reasons. Speciﬁcally, feature #3 and #53 contribute positively for sample 5 while negatively for sample 4. Instead, #50 is more positively relevant for sample 4. Extra visualizations can be found in Appendix I.
Single-Sighted Prediction Strength. We can also estimate the feature relevance from the view of model performance when the prediction is supported by a single voter in some layer. Speciﬁcally, 8
Table 3: Features with top-5 single-sighted prediction strength for class 0 and class 1 of MR dataset in VOTEN. “Input” indicates the AUC of ranking the samples according to the feature’s value.
Model
Top-1
VOTEN 0.675 0.596
Input
Top-2 0.653 0.533
Class 0
Top-3 0.647 0.572
Top-4 0.606 0.600
Top-5 0.592 0.586
Top-1 0.747 0.535
Top-2 0.632 0.527
Class 1
Top-3 0.625 0.534
Top-4 0.587 0.555
Top-5 0.566 0.525 (a) MR (Class 0) (b) RP
Figure 5: Single-sighted prediction strength in VOTEN. We also show the AUC of linearly ranking the samples as comparisons. Darker color means higher AUC. we disable the other voters in a similar way as we do in model pruning. Table 3 shows 5 MR features achieving the highest AUC when conducting single-sighted prediction for class 0 and class 1 in VOTEN. As a comparison, we also show the AUC of directly ranking with the feature, which reveals the feature’s linear correlation with the prediction. In particular, since there can be negative correlations, we evaluate AUC for the rank in increasing and decreasing order, and use the larger one as the performance. Moreover, Figure 5 shows the results on all the features. It can be observed that, even if approximated into single-sighted, VOTEN signiﬁcantly raises AUC, showing VOTEN to recognize important features and strengthen their effectiveness with nonlinear transformations. Especially, while feature #85 originally seems not correlated with the output,
VOTEN ﬁnds it in practice nonlinearly very relevant to the output. This proves the effectiveness of VOTEN on quantifying the inherent nonlinear relationships between the observations and the prediction. Interestingly, VOTEN weakens the effect of some features (e.g., feature #3 for RP) to prevent them from disturbing the prediction. Extra visualizations can be found in Appendix J. 3.5 Pruning Experiment
We conducted pruning experiments on
VOTEN for MR and CT datasets with our pruning algorithm. As we gradually deleted voting channels, we monitored the change of AUC during this process, which are shown in Figure 6. For MR, AUC is still near 0.924 after pruning nearly half of the voting channels. For CT, AUC is still near 0.998 after pruning a quarter of the channels. Interestingly, proper prun-ing may slightly raise model performance, which is reasonable as a simple model has less chance of over-ﬁtting. In practice, op-erations like ﬁne-tuning can be adopted to further raise the performance of the pruned VOTEN model. Then, the model can be further compressed without affecting the prediction much. These results prove VOTEN to support effective pruning, which is helpful. We can use complicated information for training and prune the model to decrease the complexity for storage, calculation and explanation.
Figure 6: VOTEN pruning experiments. The x-axis shows the ratio of pruned channels while the y-axis shows AUC. The green line shows MLP’s performance. (a) MR (b) CT 4