Abstract
One major problem in black-box adversarial attacks is the high query complexity in the hard-label attack setting, where only the top-1 predicted label is available. In this paper, we propose a novel geometric-based approach called Tangent Attack (TA), which identiﬁes an optimal tangent point of a virtual hemisphere located on the decision boundary to reduce the distortion of the attack. Assuming the decision boundary is locally ﬂat, we theoretically prove that the minimum (cid:96)2 distortion can be obtained by reaching the decision boundary along the tangent line passing through such tangent point in each iteration. To improve the robustness of our method, we further propose a generalized method which replaces the hemisphere with a semi-ellipsoid to adapt to curved decision boundaries. Our approach is free of pre-training. Extensive experiments conducted on the ImageNet and CIFAR-10 datasets demonstrate that our approach can consume only a small number of queries to achieve the low-magnitude distortion. The implementation source code is released online at https://github.com/machanic/TangentAttack. 1

Introduction
Adversarial attacks cause deep neural networks (DNNs) to make incorrect predictions by slightly perturbing benign images during the test time. They can be divided into two main categories on the basis of the amount of information exposed by the target model, namely white-box and black-box attacks. Many white-box attacks [6, 29, 32] have been proposed, and they can compute the gradients w.r.t. the target model’s input images to generate adversarial examples with the ﬁrst-order optimization techniques. In contrast, black-box attacks are more practical because they craft adversarial examples without requiring the target model’s gradients.
Over the past years, the community has made considerable efforts in developing black-box attacks, and the proposed methods can be divided into transfer- and query-based attacks. Transfer-based attacks [25, 37, 38] generate adversarial examples by using a white-box attack method against a surrogate model to fool the target model. Although there is no need to query the target model in these attacks, the attack success rate can not be guaranteed, especially in the case of targeted attacks.
To achieve satisfactory attack success rates, the query-based attacks use elaborate queries to obtain the feedback of the target model for crafting adversarial examples. In the score-based setting, the query-based attacks [2, 12, 22, 28] estimate approximate gradients by querying the predicted scores of the target model at multiple points. However, in most real-world scenarios, the score-based setting
∗Corresponding author. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
non-adversarial region
HSJA point g tangent point k adversarial region xt xg xt−1 non-adversarial region
H original image x
Figure 1: Simpliﬁed two-dimensional illustration of our motivation. H is the decision boundary, and xt−1 is the current adversarial example mapped onto the decision boundary at the (t − 1)-th iteration.
HSJA updates xt−1 along the gradient direction to reach g and then maps it to H at xg along the line through x and g. However, the optimal update should be the tangent point k because it can be mapped onto H at xt that has the shortest distance to the original image x. is not applicable because the public service returns only the top-1 predicted label (i.e., the hard label) rather than the predicted score. In this case, since the feedback information is limited and the objective function is discontinuous, the attack requires solving a high-dimensional combinatorial optimization problem, which is often challenging.
To reformulate the attack as a real-valued continuous optimization problem, OPT [10], Sign-OPT [11], and RayS [8] focus on minimizing an objective function g(θ), which is deﬁned as the distance from the original image to the nearest adversarial example along the direction θ. However, when attacking complex models, it may be difﬁcult to ﬁnd a suitable direction θ along which adversarial examples exist.
Boundary Attack (BA) [4], HopSkipJumpAttack (HSJA) [7], QEBA [24], qFool [26], and Policy
Driven Attack (PDA) [40] eliminate the search of the direction θ. Instead, they start from a large adversarial perturbation and then reduce its distortion while staying in the adversarial region. Because the output labels of the target model ﬂip only near the decision boundary, these attacks restrict their explorations to the regions near the decision boundary. However, they do not thoroughly investigate the geometric properties of the decision boundary to accelerate the attack. For example, PDA uses a reinforcement learning framework to train a policy network to predict search directions, which are not geometrically optimal. In addition, the prediction accuracy of the policy network decreases signiﬁcantly in the later stages of the iterations, resulting in worse performance of these iterations.
HSJA and qFool simply use the gradient u estimated at the decision boundary as the direction of each update, while ignoring a geometrically critical issue, i.e., u is not the optimal direction to be followed (Fig. 1). We could explore better search directions at each attack iteration.
To ﬁnd the optimal search direction for minimizing the distortions of attack, we propose a new geometric-based approach whose motivation is illustrated in Fig. 1. We construct a virtual semicircle
B centered at xt−1 to indicate all possible locations that xt−1 can reach along different directions, and the radius of B limits the range of updates for successful attacks. It is easy to observe that moving along the tangent line can reach the nearest location of the decision boundary to the original image x, thereby producing the adversarial example with the minimum distortion. In real attack scenarios, the image data reside in a high-dimensional space, and the semicircle becomes a hemisphere. In this case, the beneﬁt of using tangent points still exists, and we provide the detailed description and the formal proof in Section 3 and appendix.
To summarize, the main contributions of this study are as follows. 1. We cast the problem of minimizing the distortion in hard-label attacks into a geometric problem.
We discover that the minimum distortion can be obtained by searching the optimal tangent point of a virtual hemisphere around the adversarial example at each iteration. 2. We propose a novel geometric-based method to obtain a closed-form solution of the optimal tangent point. We provide an intuitive explanation of our approach, as well as a formal proof of its correctness. 3. To improve robustness, we further propose a generalized method that replaces the hemisphere with a semi-ellipsoid to adapt to the target models with curved decision boundaries. 4. Extensive experiments conducted on the CIFAR-10 [23] and ImageNet [14] datasets demonstrate the effectiveness of our approach. 2
2