Abstract
Progress in machine learning (ML) stems from a combination of data availability, computational resources, and an appropriate encoding of inductive biases. Useful biases often exploit symmetries in the prediction problem, such as convolutional networks relying on translation equivariance. Automatically discovering these useful symmetries holds the potential to greatly improve the performance of ML systems, but still remains a challenge.
In this work, we focus on sequential prediction problems and take inspiration from Noether’s theorem to reduce the problem of ﬁnding inductive biases to meta-learning useful conserved quantities.
We propose Noether Networks: a new type of architecture where a meta-learned conservation loss is optimized inside the prediction function. We show, theoretically and experimentally, that Noether Networks improve prediction quality, providing a general framework for discovering inductive biases in sequential problems. 1

Introduction
The clever use of inductive biases to exploit symmetries has been at the heart of many landmark achievements in machine learning, such as translation invariance in CNN image classiﬁcation [35], permutation invariance in Graph Neural Networks [52] for drug design [57], or roto-translational equivariance in SE3-transformers [25] for protein structure prediction [33]. However, for data distributions of interest, there may be exploitable symmetries that are either unknown or difﬁcult to describe with code. Progress has been made in automatically discovering symmetries for ﬁnite groups [74], but meta-learning and exploiting general continuous symmetries has presented a major challenge. In part, this is because symmetries describe the effect of counterfactuals about perturbations to the data, which are not directly observable.
In this work, we propose to exploit symmetries in sequential prediction problems indirectly. We take inspiration from Noether’s theorem [44], which loosely states the following:
For every continuous symmetry property of a dynamical system, there is a corresponding quantity whose value is conserved in time.
For example, consider a system of planets interacting via gravity: this system is translation invariant in all three cardinal directions (i.e. translating the entire system in the x,y, or z axis conserves the laws of motion). Noether’s theorem asserts there must be a conserved quantity for each of these symmetries; in this case, linear momentum. Similarly, the system has a time-invariance (i.e. the laws of motion are the same today as they will be tomorrow). In this case, the corresponding conserved quantity is the total energy of the system.
∗Equal contribution. Our code is publicly available at https://lis.csail.mit.edu/noether. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
...
...
Figure 1: Noether Networks enforce conservation laws, meta-learned by gφ, in sequential predictions made by fθ, which is tailored to the input x0 to produce ﬁnal predictions ˆx1:T . Imposing these meta-learned inductive biases improves video prediction quality with objects sliding down a ramp.
Inspired by this equivalence, we propose that approximate conservation laws are a powerful paradigm for meta-learning useful inductive biases in sequential prediction problems. Whereas symmetries are difﬁcult to discover because they are global properties linked to counterfactuals about unobserved perturbations of the data, conserved quantities can be directly observed in the true data. This provides an immediate signal for machine learning algorithms to exploit.
Our approach involves meta-learning a parametric conservation loss function which is useful to the prediction task. We leverage the tailoring framework [4], which proposes to encode inductive biases by ﬁne-tuning neural networks with hand-designed unsupervised losses inside the prediction function.
Whereas traditional auxiliary losses are added to the task loss during training, tailoring losses are optimized inside the prediction function both during training and testing, customizing the model to each individual query. In doing so, we ensure there is no generalization gap for the conservation loss. We propose to meta-learn the self-supervised loss function and parameterize it in the form
T 2. This conservation form of a conservation loss; i.e. t=1 | encodes a meta-inductive bias (inductive bias over inductive biases) which narrows the search space
� exponentially (in T ) and simpliﬁes the parameterization. Figure 1 demonstrates the Noether Network pipeline for a video prediction task. (x0, ˜x1:T ; gφ) = gφ(x0) gφ(˜xt)
−
L
|
The main contribution of this paper is the Noether Network, an architecture class and algorithm that can automatically learn its own inductive biases in the form of meta-learned conservation loss func-tions. We theoretically characterize the advantages of such conservation laws as effective regularizers that constrain the learning to lower-dimensional output manifolds, lowering the generalization gap.
Empirically, we ﬁrst ﬁnd that, when the meta-learned conservation loss takes the form of a synthesized program, Noether Networks recover known conservation laws from raw physical data. Second, we
ﬁnd that Noether Networks can learn conservation losses on raw videos, modestly improving the generalization of a video prediction model, especially on longer-term predictions. 2 Theoretical Advantages of Enforcing Conservation Laws
In this section, we demonstrate principled advantages of enforcing conservation laws of the form gφ(fθ(x)) = gφ(x) by considering a special case where preimages under gφ form afﬁne subspaces.
{
= gφ(x) : x
Let input x and target y be x, y
Rd, and let the Noether embedding be gφ : Rd
∈
P
∈ the form fθ(x) = x + vθ for vθ ∈
Rm x + Az : z
×
{ denote by C the smallest upper bound on the loss value as where
Θ, of
] = d is the dimensionality of the preimages of gφ. We
C (for all x, y and θ).
. We consider a restricted class of models, parameterized by θ
}
Rd such that for all x, the preimage of gφ is g−
→ P
∈ gφ(x) m. Here, m (fθ(x), y) 1
φ [
Rd
Rd
, A
≤
∈
∈
}
}
{
L
≤ 2
Deﬁne ψ(v) = Ex,y[
ζ
L (f (x, v), y)] 1 n
− n i=1 L
≥
=
V
{
Rd : θ 0 is the smallest real number such that, for all v and v� in vθ ∈
Θ �
∈ n 1 n
. Finally, we deﬁne R = supθ
G(θ) = Ex,y[ (fθ(x), y)]
Θ
}
�
∈
−
L (f (xi, v), yi), with Lipschitz constant ζ. Therefore,
ψ(v�)
�2, where
V vθ�2, and the generalization gap by
ψ(v)
| ≤ v�
−
−
� v
ζ
|
, (fθ(xi), yi).
L i=1
�
Theorem 1 shows that enforcing conservation laws of gφ(fθ(x)) = gφ(x) is advantageous when the dimension of the preimages under gφ is less than the dimension of x; that is, when m < d.
Theorem 1. Let ρ
∈ examples ((xi, yi))n i=1, the following holds for all θ
N+. Then, for any δ > 0, with probability at least 1
δ over an iid draw of n
Θ:
−
ξ ln(max(√ξ, 1)) + ξ ln(2R(ζ 1
−
G(θ)
C 2n where ξ = m if gφ(fθ(x)) = gφ(x) for any x
�
≤
∈ 1/ρ)√n) + ln(1/δ)
�
+
ξ 1
}�
Θ, and ξ = d otherwise.
≥
{
ζ 2/ρ n
. (1)
Rd and θ
∈
∈
The proof is presented in Appendix A. In Theorem 1, when we enforce the conservation laws, d is replaced by m, the dimension of the preimage. We now discuss various cases for the values of m:
Rd
• (Case of m = d) Let us consider an extreme scenario where the function gφ maps all x to one single point. In this scenario, the dimensionality of preimages under gφ is maximized as m = d. Accordingly, the bounds with and without enforcing the conservation laws become the same. Indeed, in this scenario, the conservation laws of gφ(fθ(x)) = gφ(x) give
Rd, even without imposing them. us no information, because they always hold for all x
• (Case of m = 0) Let us consider another extreme scenario where the function gφ is invertible.
In this scenario, the dimensionality of preimages under gφ is zero as m = 0. Thus, imposing the condition of gφ(fθ(x)) = gφ(x) makes the bound in Theorem 1 to be very small. Indeed, in this scenario, the condition of gφ(fθ(x)) = gφ(x) implies that fθ(x) = x: i.e., x is not moving, and thus it is easy to generalize.
∈
∈
• (Case of 0 < m < d) From the above two cases, we can see that the beneﬁt of enforcing conservation laws comes from more practical cases in-between these, with 0 < m < d.
In Theorem 1, the function gφ can differ from the true function g∗φ underlying the system. This is because we analyze a standard generalization gap: i.e., the difference between the expected loss and the training loss. The cost of not using the true g∗φ is captured in the training loss; i.e., the training loss can be large with the function gφ that differs signiﬁcantly from the true g∗φ. Even in this case, the generalization gap can be small. For example, in the case of m = 0, the generalization bound is small, whereas the training loss will be large unless xt+1 = xt. Therefore, our analysis gives us the insight on the trade-off between the training loss and the dimensionality of preimages under gφ. 3 Noether Networks
Leveraging tailoring to encode inductive biases. We perform a prediction-time optimization to encourage outputs to follow conservation laws using the tailoring framework [4]. Tailoring encodes inductive biases in the form of unsupervised losses optimized inside the prediction function. In doing so, tailoring ﬁne-tunes the model to each query to ensure that it minimizes the unsupervised loss for that query. For example, we may optimize for energy conservation in a physics prediction problem.
In meta-tailoring, we train the model to do well on the task loss after the tailoring step has ﬁne-tuned its parameters. In contrast to auxiliary losses, which would optimise the conservation loss only for the training points, tailoring allows us to ensure conservation at test time. Since we aim to build in the conservation in the architecture, we want to ensure it is also satisﬁed for unseen test samples. Another advantage of tailoring losses is that they are easier to meta-learn. Auxiliary losses are pooled over all examples and training epochs and their effect is only known at validation/test time. We would need to use implicit gradients [39, 47] to know their eventual effect on the ﬁnal weights at the end of training.
With tailoring, we can directly measure the effect of the meta-learned update on the same sample.
A limitation of tailoring framework is that the tailoring loss must be user-speciﬁed. This is acceptable in domains where the desired inductive bias is both known and easily encoded, but problematic in general — we address this issue with Noether Networks. Our approach can be seen as a generalization of tailoring where the unsupervised loss is meta-learned and takes the form of a conservation loss. 3
Noether Networks: discovering useful conservation laws. We build on the paradigm of conser-vation laws; i.e. quantities that are conserved over time. This has the following two challenges: 1. Real data often has noise, breaking any exact conservation law. Moreover, many conser-vation laws are only approximately satisﬁed given only partial information of the system.
For example, conservation of energy is not fully satisﬁed in real dissipative systems and estimating conservation of mass from pixels is bound to be inexact in the case of occlusions. 2. Optimizing for conservation alone can lead to trivial quantities, such as predicting a constant value gφ(x) = C independent of x.
We search for useful conservation laws, whose (approximate) enforcing brings us closer to the true data manifold for the current sequence. Note that a useful conserved quantity doesn’t need to be exactly conserved in the training data to improve prediction performance. We only need its conservation to be informative of the data manifold. This allows us to discover conservation laws even in imperfect, noisy environments. Conversely, tailoring with a trivial conserved quantity cannot improve the ﬁnal predictions (see App. B for a detailed explanation). Finally, viewing conserved quantities as useful inductive biases aligns well with their use, since we often care about biases only insofar as they help improve task performance.
The search for such useful conserved quantities can take many forms. In this work, we focus on two: ﬁrst, in the beginning of section 4.1, we use a combination of program synthesis and gradient descent to generate a large, but ﬁnite, number of candidate parametric formulas for physical system prediction. We then try meta-tailoring with each formula on the training set and pick the conservation formula with the best loss. Formulas can be a useful, interpretable description in scientiﬁc domains given the appropriate state-space. However, for general descriptions from raw data, we would like to describe the loss with a neural network, as we describe in the next section.
Meta-learning a neural loss function. We propose Noether Networks, an architecture class for
˜xt+1 and a meta-learned tailoring sequential prediction that consists of a base predictor fθ : ˜xt �→
Rk. This embedding takes loss, parameterized as the conservation of a neural embedding gφ : ˜xt �→ raw predictions as input (such as images in the case of video prediction). The conservation form induces a meta-inductive bias over potential learned tailoring losses. The Noether loss is formulated as
LNoether(x0, ˜x1:T ; gφ) =
T
| t=1
� gφ(x0) gφ (˜xt) 2
|
≈
−
T t=1
� gφ(˜xt 1)
−
|
− gφ (˜xt) 2
| (2) (a) (b)
−
�
�
�
�
�� 1) are the model’s predictions, and ˜x0 � x0. where x0 is the ground-truth input, the ˜xt = fθ(˜xt
��
Expressions 2(a) and 2(b) are equivalent if we fully enforce the conservation law, but they differ if conservation is not fully enforced. When not fully conserving, 2(a) propagates information from ground truth more directly to the prediction, but 2(b) may be a useful approximation which better handles imperfectly conserved quantities, where the quantity should be Lipschitz but not exactly constant. In both cases, if we tailor θ with a single gradient step; the gradient update takes the form (3) 1). We can now backpropagate from
We compute ﬁnal predictions as ˆxt = fθ(x0;φ)(ˆxt
Ltask(x1:T , ˆx1:T ) back to φ, which will be optimized so that the unsupervised adaptation θ
�→
θ(x0; φ) helps lower
Ltask.The optimization requires second-order gradients to express how φ affects
Ltask through θ(x0; φ). This is similar to MAML [23], as well as works on meta-learning loss func-tions for few-shot learning [5] and group distribution shift [71]. Algorithm 1 provides pseudo-code.
λin∇θLNoether(x0, ˜x1:T (θ); gφ).
θ(x0; φ) = θ
−
−
For deep learning frameworks that allow per-example weights, such as JAX [9], the loop over sequences in Alg. 1 can be efﬁciently parallelized. To parallelize it for other frameworks we use the
CNGRAD algorithm [4], which adapts only the Conditional Normalization (CN) layers in the inner loop. Similar to BN layers, CN only performs element-wise afﬁne transformations: y = x
γ + β, which can be efﬁciently parallelized in most deep learning frameworks even with per-example γ, β.
�
Finally, even though we use the two-layer optimization typical of meta-learning, we are still in the classical single-task single-distribution setting. Noether Networks learn to impose their own inductive biases via a learned loss and to leverage it via an adaptation of its parameters θ. This is useful as we often do not have access to meta-partitions that distinguish data between distributions or tasks. 4
Algorithm 1 Prediction and training procedures for Noether Networks with neural conservation loss
Given: predictive model class f ; embedding model class g; prediction horizon T ; training dist.
LNoether
Dtrain; batch size N ; learning rates λin, λout, λemb; task loss
Ltask; Noether loss 1: procedure PREDICTSEQUENCE(x0; θ, φ) 2: 3: 4: 5: 6:
˜x0, ˆx0 ← x0, x0
˜xt ← 1) t
}
∀
−
θ(x0; φ)
θ
λin∇θLNoether(x0, ˜x1:T ; gφ)
←
− 1, . . . , T fθ(x0;φ)(ˆxt
ˆxt ← return ˆx1:T
∈ { 1) 1, . . . , T fθ(˜xt
∈ {
∀
}
− t randomly initialized weights randomly initialized weights
←
←
φ
θ while not done do 7: procedure TRAIN 8: 9: 10: 11: 12: 13: 0:T , . . . , x(N )
Sample batch x(0) 0:T ∼ Dtrain
N do n for 0
PREDICTSEQUENCE(x(n) n=0 Ltask(ˆx(n) n=0 Ltask(ˆx(n)
≤
≤
ˆx(n) 1:T ←
φ
φ
−
←
θ
θ
−
← return φ, θ
λemb∇φ
λout∇θ
N
�
N
� 0 ; θ, φ) 14: 15: 16:
� Initial predictions
� Inner step with Noether loss
� Final prediction with tailored weights
� Initialize weights for Noether embedding g
� Initialize weights for predictive model f 1:T , x(n) 1:T ) � Outer step with task loss for embedding 1:T , x(n)
� Outer step for predictive model 1:T ) 4 Experiments
Our experiments are designed to answer the following questions: 1. Can Noether Networks recover known conservation laws in scientiﬁc data? 2. Are Noether Networks useful for settings with controlled dynamics? 3. Can Noether Networks parameterize useful conserved quantities from raw pixel information? 4. How does the degree of conservation affect performance on the prediction task? 4.1 Experimental domains
To answer the above questions, we consider a number of different experimental domains, which we overview in this subsection, before moving on to the evaluation and results.
·
Spring and pendulum from state coordinates. Greydanus et al. [28] propose the setting of an ideal spring and ideal pendulum, which will allow us to understand the behavior of Noether Networks for scientiﬁc data where we know a useful conserved quantity: the energy. They also provide data from a real pendulum from [53]. In contrast to the ideal setups, here the data is noisy and the
Hamiltonian is only approximately conserved, as the system is dissipative. For the two pendulum,
R2 contains its angle q and momentum p. Given the parameters in [28] the energy input x = (p, q) cos q being a simpler equivalent. For the spring, input
= 3(1 is
− 2 (q2 + p2).
R2 contains the displacement q and momentum p and the energy is x = (p, q)
Thus, q2 + 1.0
= 1 p2 is a conserved quantity, where the coefﬁcient 1.0 has appropriate units.
∈ cos q) + p2, with p2
H
H
−
∈ 3
·
We build on their vanilla MLP baseline and discover conservation laws that, when used for meta-tailoring, improve predictions. Since the baseline predicts d dt (xt) rather than xt+1, we apply the loss
LNoether (xt, xt + fθ(xt)Δt). to a ﬁnite-difference approximation, i.e.
�
Domain speciﬁc language for scientiﬁc formulas. To search over Hamiltonians, we program a simple domain speciﬁc language (DSL) for physical formulas. Since formulas in the DSL have physical meaning, each sub-formula carries its own associated physical units and is checked for validity. This allows us to signiﬁcantly prune the exponential space, as done in AI-Feynman [63].
The vocabulary of the DSL is the following: Input(i): returns the i-th input, Operation: one of
+,
, Parameter(u): trainable scalar with units [u]. xt, xt + dx
LNoether dt Δt
=
�
,
{
−
, /, sin, cos, x2
·
} 5
Table 1: Recovering for the ideal pendulum.
Table 2: Recovering for the ideal spring.
Method
Vanilla MLP
Noether Nets
True
H
[oracle]
H
Description
N/A 2.99 cos(q)
RMSE 0.0563 0.0423 3.00 cos(q) 0.0422 p2 p2
−
−
Method
Vanilla MLP
Noether Nets
True
H
[oracle]
H
Description
N/A q2 + 1.002 p2 q2 + 1.000 p2
RMSE
.0174
.0165
.0166
Figure 2: Noether Networks can recover the energy of a real pendulum, even though it is not fully conserved. This is because they only look for quantities whose conservation helps improve pre-dictions. Moreover, by only softly en-couraging conservation, it better encodes imperfect conservations.
In settings such as robotics we may be interested in action-Pixel pendulum with controls. conditioned video prediction [45]: predicting future frames given previous frames and an agent’s actions. We recorded videos of episodes in OpenAI Gym’s pendulum swing up environment, using a scripted policy. Each model receives four history frames and a sequence of 26 policy actions starting from the current timestep, and must predict 26 future frames. As this is a visually simple environment we limit the training dataset to 5 episodes of 200 frames each, holding out 195 episodes for testing.
Video prediction with real-world data. To characterize the beneﬁts provided by Noether Net-works in a real-world video prediction setting, we evaluate the effect of adding a Noether conservation loss to the stochastic video generation (SVG) model [18] on the ramp scenario of the Physics 101 dataset [69]. The dataset contains videos of various real-world objects sliding down an incline and colliding with a second object. Each model is conditioned on the ﬁrst two frames and must predict the subsequent 20 frames. To increase difﬁculty, we restrict our data to the 20-degree incline. 4.2 Evaluation
Can Noether Networks recover known conservation laws in scientiﬁc data? We ﬁrst generate all valid formulas up to depth 7, removing operations between incompatible physical units and formu-las equivalent up to commutativity. We obtain 41,460 and 72,372 candidate conserved formulas for the pendulum and spring, respectively, which need not have units of energy. These formulas are purely symbolic, with some trainable parameters still to be deﬁned. We thus optimize their parameters via gra-dient descent to have low variance within sequences of true data. We then do the same for random se-quences; if conservation is two orders of magnitude smaller for the true data, we accept it as an approx-imate conservation. This measure is similar to others used before [38], but is not sufﬁcient when the data is noisy, the minimisation is sub-optimal, or there are numerical issues. As a result, we obtain 210 and 219 candidates for approximately conserved quantities for the pendulum and spring, respectively.
Finally, for each potentially conserved quantity, we try it as meta-tailoring loss: starting from the pre-trained vanilla MLP, we ﬁne-tune it for 100 epochs using meta-tailoring, with one inner step and a range of inner learning rates 10k for k
. We then evaluate the ﬁne-tuned
} model on long-term predictions, keeping the expression with the best MSE loss in the training data.
We observe that this process correctly singles out equations of the same form as the true Hamiltonian
, with almost the exact parameters. Using these as losses reaches equivalent performance with that 2.5, . . . , 1
∈ {−
− 3,
H of the oracle, which uses the true formula (see Tables 1 and 2).
Finally, we run the same process for a real pendulum [53], where energy is not conserved. We use largely the same pipeline as for the ideal pendulum, the differences are explained in Appendix C.
Noether Networks discover p2
− 2.4 cos(q) described in [28]. This Noether Network improves the baseline by more than one order of magnitude, matches the performance of hand-coding the conservation loss, and improves over Hamil-tonian Neural Networks, which fully impose conservation of energy. Results can be seen in ﬁgure 2. 2.39 cos(q), close to the (potentially sub-optimal)
= p2
H
− 6
Figure 3: In controlled pendulum environment, the Noether Network has lower mean squared error (left) and slightly better structural similar-ity (right). Metrics are computed and plotted by prediction timestep, where timestep 0 is a given history frame. Note that simply training SVG for more steps does not increase performance.
Figure 4: The Noether Network outperforms the baseline by a small margin in all four metrics in real-world video prediction, showing they can meta-learn useful conserved quantities from raw pixel data.
Are Noether Networks useful in settings with controlled dynamics? For the controlled pendulum experiments, we begin with an SVG model but modify it to (1) remove the prior sampling component since the environment is deterministic and (2) concatenate each action to the corresponding frame encoder output and feed the result to the LSTM. After training the SVG model for 50 epochs and ﬁxing its weights, we run Algorithm 1 for 20 epochs to learn an embedding network for conserving useful quantities. We found that Noether Networks perform better in this setting by directly adapting the latent LSTM activations against the conservation loss, rather than adapting any network parameters. Since Noether Networks take additional training steps starting from a pre-trained
SVG model, we also continued training the SVG model for 20 further epochs, which we call “SVG (more steps).” Figure 3 shows the results of each method on held out sequences. Noether Networks improve the overall mean squared error (MSE) and structural similarity (SSIM) over the base SVG.
Can Noether Networks parameterize useful conserved quantities from raw pixel information?
We train on only 311 training sequences, which makes generalization difﬁcult. In this setting, the base
SVG model struggles with overﬁtting — novel test objects often morph into objects seen at train-time, and the object in motion often morphs with the target object (as shown in ﬁgure 1). Our Noether
Network uses the inner loss formulation of Equation 2(b), where gφ is a two-layer CNN receiving two consecutive frames followed by a fully-connected projection layer producing 64-dimensional embed-dings. We meta-tailor the embedding and the base model for 400 epochs. As seen in ﬁgure 4, taking a single inner tailoring step improves performance slightly over the baseline SVG model with respect to all four considered metrics: learned perceptual image patch similarity (LPIPS) [72], mean squared error (MSE), peak signal-to-noise ratio (PSNR), and structural similarity (SSIM). As the prediction horizon increases, the Noether Network performs comparatively better, likely because conservations encourage the model to retain aspects of the ground-truth input. These results provide some evidence that Noether Networks are capable of learning useful inductive biases from raw video data.
To investigate whether the Noether embeddings learn relevant features, we use Gradient-weighted
Class Activation Mapping (Grad-CAM) [54] to compute importance maps for sequences in the test set.
Since the Noether embedding has 64 dimensions, we perform principal component analysis (PCA) before Grad-CAM to reduce the dimensionality of the embedding, and to sort dimensions by the percentage of variance they explain in the test set frames. Interestingly, we ﬁnd that the ﬁrst PCA dimension captures 83.6% of the variance, and the ﬁrst four dimensions capture 99.9% of the variance.
Figure 5 shows Grad-CAM localization maps for two example test-set sequences, (a) depicts an orange torus and (b) shows a blue brick, where warmer colors (red) indicate high importance and cooler colors (blue) indicate low importance. Our interpretations of Grad-CAM localization maps are consistent across examples, see Appendix F for additional ones. The ﬁrst dimension, which explains the vast majority of the variance, primarily focuses on the sliding object in both examples. It also attends to the object on the table, and to the edge of the ramp. The attention to the objects suggests that the Noether
Network learns to conserve quantities related to the objects’ pixels and their motion (since it takes 7
(a) Orange object (b) Blue object n o z i r o h n o i t c i d e r
P
−
←
Embedding dimension (after PCA)
−→
Embedding dimension (after PCA)
−→
Figure 5: Grad-CAM localization maps show that the Noether embeddings attend to relevant frame regions for two example sequences. Heatmaps for the ﬁrst six dimensions of the embedding (in the
PCA basis, sorted by decreasing amount of variance explained) are shown for three time steps. two consecutive frames). We hypothesize that the attention to the table edge encodes information about the orientation of the sequence, since half of the training sequences are randomly
ﬂipped horizontally. While some the dimensions focus nearly uniformly on the entire frame, the fourth dimension focuses on the orange sliding object in (a), and the human hand and table in (b). In all the test set examples, whenever the human hand is in the frame, it is attended to by this dimension. We hypothesize that it learns to conserve the hand in sequences where it is present, and possibly picks up on similarly-colored pixels as well.
Finally, the sixth dimension seems to track blue sliding objects.
How does the degree of conservation affect performance?
All of the results presented in this work were achieved by Noether
Networks trained and evaluated with a single inner step. To char-acterize how the degree to which the conservations are imposed affects video prediction performance, we optimize the inner (Noether) loss for many inner steps and measure the outer (task) loss, as shown in ﬁgure 6. Here, the inner loss is optimized by
Adam for 500 steps, as opposed to the single step of SGD during 4). During the training (both settings use a learning rate of 10− optimization, the outer loss improves for roughly 150 inner steps, which suggests that the approximate conservations learned by the
Noether Network generalize to more exact conservation settings. 5