Abstract
This paper studies a new variant of the stochastic multi-armed bandits problem where auxiliary information about the arm rewards is available in the form of control variates. In many applications like queuing and wireless networks, the arm rewards are functions of some exogenous variables. The mean values of these variables are known a priori from historical data and can be used as control variates. Leveraging the theory of control variates, we obtain mean estimates with smaller variance and tighter conﬁdence bounds. We develop an upper conﬁdence bound based algorithm named UCB-CV and characterize the regret bounds in terms of the correlation between rewards and control variates when they follow a multivariate normal distribution. We also extend UCB-CV to other distributions using resampling methods like Jackkniﬁng and Splitting. Experiments on synthetic problem instances validate performance guarantees of the proposed algorithms. 1

Introduction
Stochastic Multi-Armed Bandits (MAB) setting has been extensively used to study decision making under uncertainty (Thompson, 1933; Bubeck et al., 2012; Lattimore and Szepesvári, 2020). In the classical setting, it is assumed that the arm rewards are independent of each other. After playing an arm, the learner observers independent and identically distributed reward samples. The exploration versus exploitation trade-off is a fundamental problem in the bandits setting, and a learner can accumulate more rewards if it is balanced well. A better balance can be achieved if the learner can estimate arm’s mean rewards with tighter conﬁdence bounds (Auer et al., 2002; Auer and Ortner, 2010; Garivier and Cappé, 2011) and smaller variance (Audibert et al., 2009b; Mukherjee et al., 2018). Any available side or auxiliary information can aid in building tighter conﬁdence bounds. In this paper, we study the improvement in the performance that can be achieved when side information is available in the form of control variates.
Any observable input that is correlated with the random variable of interest can be a Control
Variate (CV). When the mean of the CV is known, it becomes useful to reduce the variance of the mean estimator of the random variable. CV method is a popular variance reduction technique to improve the estimates’ precision without altering the simulation runs or an increase in the number of samples (Lavenberg et al., 1982). Many stochastic simulations involve inputs generated using known distributions. These inputs can be potential CVs as output could be correlated with them. It has motivated the development of rich theory to analyze the quality of the estimators resulting from
CVs (Lavenberg and Welch, 1981; Lavenberg et al., 1982; Nelson, 1990). We adopt these techniques to study the stochastic multi-armed bandits problem when CVs are available for the arms.
In many real-life applications, exogenous variables inﬂuence arms’ rewards and act as CVs. For example, consider a job aggregating platform that assigns jobs to one of the servers/workers in each slot. The jobs are of variable size, and the time to serve them depends on their size and other 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
unknown extraneous factors. The platform observes the size of each job and knows their mean value from historical data. The random job sizes correlate with service times and can be used as a CV to estimate each server’s mean service time. Another example is a wireless system where a transmitter can transmit packets on a channel in each slot. Successful transmission of the packets (quality) depends on random quantities like fading, interference, and channel noise on the selected channel.
The transmitter can observe the fading value using pilot signals in each round and know their mean value from past observations. These fading values on a channel can be used as a CV to estimate the channel’s quality.
The performance of a MAB algorithm depends on how good is the conﬁdence interval of its mean reward estimators (Auer et al., 2002; Auer and Ortner, 2010; Garivier and Cappé, 2011). The tightness of these intervals depends on the variance of the estimators (Audibert et al., 2009b; Mukherjee et al., 2018). Naturally, estimators with smaller variance for the same number of samples result in better performance. Thus CVs can be leveraged to improve the performance of bandits algorithms with smaller conﬁdence intervals. The reduction depends on how strongly the reward samples and associated CVs are correlated.
Linear methods are widely used for variance reduction using CVs where the new samples are generated taking the weighted sum of reward samples and centered CV samples. Then these new samples are used for the estimation of the mean rewards. The choice of the weight that results in maximum variance reduction depends on the variance of CV and its correlation with reward samples.
In practice, both of these quantities are unknown and need to be estimated from the observed samples.
However, using the estimated weight makes the new samples highly correlated and makes the analysis of conﬁdence intervals challenging.
For multivariate normal distributions, tight conﬁdence intervals can be constructed that hold with high probability for the mean reward estimators resulting from the linear control variates. Using these results, we develop a MAB algorithm that exploits CVs to improve the regret performance. For general distributions, we discuss resampling methods that result in unbiased estimators with better conﬁdence intervals. Speciﬁcally, our contributions are as follows:
• For the case where rewards and CVs are normally distributed, we develop an algorithm named Upper Conﬁdence Bounds with Control Variates (UCB-CV) that uses the estimators based on the linear control variates.
• In Section 4, we show that the regret of UCB-CV is smaller by a factor (1 − ρ2) compared to the existing algorithms when the rewards and CV have a multivariate normal distribution, where ρ is the correlation coefﬁcient of the reward and control variates.
• In Section 5, we discuss how to adapt UCB-CV for the general distributions using estimators and associated conﬁdence intervals based on jackkniﬁng, splitting, and batching methods.
• We validate the performance of UCB-CV on synthetically generated data in Section 6. 1.1