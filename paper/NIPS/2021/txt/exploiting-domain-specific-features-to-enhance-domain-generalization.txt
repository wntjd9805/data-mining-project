Abstract
Domain Generalization (DG) aims to train a model, from multiple observed source domains, in order to perform well on unseen target domains. To obtain the gen-eralization capability, prior DG approaches have focused on extracting domain-invariant information across sources to generalize on target domains, while useful domain-speciﬁc information which strongly correlates with labels in individual domains and the generalization to target domains is usually ignored. In this paper, we propose meta-Domain Speciﬁc-Domain Invariant (mDSDI) - a novel theoreti-cally sound framework that extends beyond the invariance view to further capture the usefulness of domain-speciﬁc information. Our key insight is to disentangle features in the latent space while jointly learning both domain-invariant and domain-speciﬁc features in a uniﬁed framework. The domain-speciﬁc representation is optimized through the meta-learning framework to adapt from source domains, targeting a robust generalization on unseen domains. We empirically show that mDSDI provides competitive results with state-of-the-art techniques in DG. A further ablation study with our generated dataset, Background-Colored-MNIST, conﬁrms the hypothesis that domain-speciﬁc is essential, leading to better results when compared with only using domain-invariant. 1

Introduction and