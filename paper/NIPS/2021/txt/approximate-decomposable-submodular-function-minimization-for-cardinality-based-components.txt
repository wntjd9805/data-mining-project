Abstract
Minimizing a sum of simple submodular functions of limited support is a spe-cial case of general submodular function minimization that has seen numerous applications in machine learning. We develop fast techniques for instances where components in the sum are cardinality-based, meaning they depend only on the size of the input set. This variant is one of the most widely applied in practice, encompassing, e.g., common energy functions arising in image segmentation and recent generalized hypergraph cut functions. We develop the ﬁrst approximation algorithms for this problem, where the approximations can be quickly computed via reduction to a sparse graph cut problem, with graph sparsity controlled by the desired approximation factor. Our method relies on a new connection between sparse graph reduction techniques and piecewise linear approximations to concave functions. Our sparse reduction technique leads to signiﬁcant improvements in theoretical runtimes, as well as substantial practical gains in problems ranging from benchmark image segmentation tasks to hypergraph clustering problems. 1

Introduction
Given a ground set V , a function f : 2V → R is submodular if for every A, B ⊆ V it satisﬁes f (A) + f (B) ≥ f (A ∩ B) + f (A ∪ B). Submodular functions are ubiquitous in combinatorial optimization and machine learning, arising, e.g., in image segmentation [22], hypergraph clustering [30], data subset selection [44], document summarization [31], and dense subgraph discovery [43]. Algorithms for minimizing submodular functions are well studied. Strongly-polynomial time algorithms for general submodular minimization exist [36, 17, 18], but their runtimes are impractical in most cases.
The past decade has witnessed several advances in faster algorithms for decomposable submodular function minimization (DSFM), i.e., minimizing a sum of simpler submodular functions [9, 24, 39, 29, 35, 10, 21, 19]. This problem is deﬁned by identifying a set E ⊆ 2V of subsets of the ground set.
The goal is then to solve minimizeS⊆V f (S) = (cid:80) e∈E fe(S ∩ e), (1) where for each e ∈ E, fe is a submodular function supported on a subset e ⊆ V . Functions of this form often arise as energy functions in computer vision [22, 23, 13], and generalized cut functions for hypergraph clustering and learning [12, 28, 30, 32, 41, 42], among other applications.
This paper focuses on cardinality-based DSFM (Card-DSFM), where every component fe in the sum is a concave cardinality function, i.e., fe(A) = ge(|A|) for some concave function ge. A single concave cardinality function is effectively a function of one variable and is trivial to minimize.
However, set functions obtained via sums of these functions are much more complex and have broad modeling power, making this one of the most widely studied and applied variants since the earliest
∗This research was performed while the author was a postdoctoral associate at Cornell University. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
work on DSFM [24, 39]. In terms of theory, previous research has addressed specialized runtimes and solution techniques [24, 39, 22, 41]. In practice, cardinality-based decomposable submodular functions frequently arise as higher-order energy functions in computer vision [22] and set cover functions [39]. The most widely used generalized hypergraph cut functions are also cardinality based [30, 32, 41, 42, 1]. Even previous research on algorithms for the more general DSFM problem tends to focus on cardinality-based examples in experimental results [9, 39, 19, 29].
We present the ﬁrst approximation algorithms for Card-DSFM, using a purely combinatorial ap-proach that relies on approximately reducing (1) to a sparse graph cut problem. The fact that concave cardinality functions are representable by graph cuts has previously been noted in different contexts [22, 39, 41]—this can be accomplished by combining simple graph gadgets, whose cut properties together model the function. However, previous techniques are limited in that they (i) focus only on exact reduction techniques, (ii) do not consider the density of the resulting graph, and (iii) do not address any questions regarding the optimality of such a reduction. Here we develop new approximate reduction methods leading to a sparse graph, which we show is optimally sparse in terms of the standard gadget reduction strategy. We show that representing a concave cardinality function with a sparse graph is equivalent to approximating a concave function with a piecewise linear curve, where the number of linear pieces determines the sparsity of the reduced graph. We develop a new algorithm for the resulting piecewise linear approximation problem, and prove new bounds on the number of edges needed to model different concave functions that arise in practice. Combining our reduction strategy with state of the art algorithms for maximum ﬂow [15, 26, 40, 14] leads to fast runtime guarantees for ﬁnding approximate solutions to Card-DSFM. Our algorithm is also easy to implement and achieves substantial practical improvements on benchmark image segmentation experiments [19, 9, 29] and algorithms for hypergraph clustering [42]. 2