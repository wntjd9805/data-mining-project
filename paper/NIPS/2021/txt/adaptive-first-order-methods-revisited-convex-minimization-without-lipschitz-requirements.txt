Abstract
We propose a new family of adaptive first-order methods for a class of convex mini-mization problems that may fail to be Lipschitz continuous or smooth. Specifically, motivated by a recent flurry of activity on non-Lipschitz (NoLips) optimization, we consider problems that are continuous or smooth relative to a reference Bregman function – as opposed to a global, ambient norm (Euclidean or otherwise). These conditions encompass a wide range of problems with singular objectives that can-not be treated with standard first-order methods for Lipschitz continuous/smooth problems – such as Fisher markets, Poisson tomography problems, D-optimal design, and the like. In this setting, the application of existing order-optimal adap-tive methods – like UNIXGRAD or ACCELEGRAD – is not possible, especially in the presence of randomness and uncertainty. The proposed method – which we call adaptive mirror descent (ADAMIR) – aims to close this gap by concurrently achieving min-max optimal rates in problems that are relatively continuous or smooth, including stochastic ones. 1

Introduction
Owing to their wide applicability and flexibility, first-order methods continue to occupy the forefront of research in learning theory and continuous optimization. Their analysis typically revolves around two basic regularity conditions for the problem at hand: (i) Lipschitz continuity of the problem’s objective, and / or (ii) Lipschitz continuity of its gradient (also referred to as Lipschitz smoothness).
Depending on which of these conditions holds, the lower bounds for first-order methods with perfect
T ) and Θ(1/T 2) after T gradient queries, and they are achieved by gradient gradient input are Θ(1/ descent and Nesterov’s fast gradient algorithm respectively [36, 37, 48]. By contrast, if the optimizer only has access to stochastic gradients (as is often the case in machine learning and distributed
√ control), the corresponding lower bound is Θ(1/
T ) for both classes [14, 34, 37].
√
This disparity in convergence rates has led to a surge of interest in adaptive methods that can seamlessly interpolate between these different regimes. Two state-of-the-art methods of this type are the ACCELEGRAD and UNIXGRAD algorithms of Levy et al. [26] and Kavis et al. [24]: both
T ) value convergence rate in non-smooth problems, an algorithms concurrently achieve an O(1/
O(1/T 2) rate in smooth problems, and an O(1/
T ) average rate if run with bounded, unbiased stochastic gradients (the smoothness does not affect the rate in this case). In this regard, UNIXGRAD and ACCELEGRAD both achieve a “best of all worlds” guarantee which makes them ideal as off-the-shelf solutions for applications where the problem class is not known in advance – e.g., as in online traffic routing, game theory, etc.
√
√
At the same time, there have been considerable efforts in the literature to account for problems that do not adhere to these Lipschitz regularity requirements – such as Fisher markets, quantum tomography,
D-design, Poisson deconvolution / inverse problems, and many other examples [7, 10, 11, 28, 29, 45].
The reason that the Lipschitz framework fails in this case is that, even when the problem’s domain 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
is bounded, the objective function exhibits singularities at the boundary, so it cannot be Lipschitz continuous or smooth. As a result, no matter how small we pick the step-size of a standard gradient method (adaptive or otherwise), the existence of domains with singular gradients can – and typically does – lead to catastrophic oscillations (especially in the stochastic case).
A first breakthrough in this area was provided by Birnbaum et al. [10] and, independently, Bauschke et al. [7] and Lu et al. [29], who considered a “Lipschitz-like” gradient continuity condition for problems with singularities.1 At around the same time, Lu [28] and Teboulle [45] introduced a
“relative continuity” condition which plays the same role for Lipschitz continuity. Collectively, instead of using a global norm as a metric, these conditions employ a Bregman divergence as a measure of distance, and they replace gradient descent with mirror descent [14, 34].
In these extended problem classes, non-adaptive mirror descent methods achieve an O(1/
T ) value convergence rate in relatively continuous problems [2, 28], an O(1/T ) rate in relatively smooth problems [7, 10], and an O(1/
T ) average rate if run with stochastic gradients in relatively continuous problems [2, 28]. Importantly, the O(1/T ) rate for relatively smooth problems does not match the O(1/T 2) rate for standard Lipschitz smooth problems: in fact, even though [20] proposed a tentative path towards faster convergence in certain non-Lipschitz problems, Dragomir et al.
[17] recently established an Ω(1/T ) lower bound for problems that are relatively-but-not-Lipschitz smooth.
√
√
Our contributions. Our aim in this paper is to provide an adaptive, parameter-agnostic method that simultaneously achieves order-optimal rates in the above “non-Lipschitz” framework. By design, the proposed method – which we call adaptive mirror descent (ADAMIR) – has the following desirable properties:
√ 1. When run with perfect gradients, the trajectory of queried points converges, and the method’s
T ) and O(1/T ) for rate of convergence in terms of function values interpolates between O(1/ relatively continuous and relatively smooth problems respectively.
√ 2. When run with stochastic gradients, the method attains an O(1/
T ) average rate of convergence. 3. The method applies to both constrained and unconstrained problems, without requiring a finite
Bregman diameter or knowledge of a compact domain containing a solution.
The only thing we assume known in the above is the reference Bregman function with respect to which the problem’s objective is relatively continuous/smooth; other than that, we assume no prior information on the problem’s regularity class / modulus and/or the oracle model being accessed (deterministic or stochastic).2 The enabling apparatus for these properties is an adaptive step-size policy in the spirit of [6, 18, 30]. However, a major difference – and technical difficulty – is that the relevant definitions cannot be stated in terms of global norms, because the variation of non-Lipschitz function explodes at the boundary of the problem’s domain (put differently, gradients may be unbounded even over bounded domains). For this reason, our policy relies on the aggregation of a suitable sequence of “Bregman residuals” that stabilizes seamlessly when approaching a smooth solution, thus enabling the method to achieve faster convergence rates.