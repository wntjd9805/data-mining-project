Abstract
Can we leverage high-resolution information without the unsustainable quadratic complexity to input scale? We propose Traversal Network (TNet), a novel multi-scale hard-attention architecture, which traverses image scale-space in a top-down fashion, visiting only the most informative image regions along the way. TNet offers an adjustable trade-off between accuracy and complexity, by changing the number of attended image locations. We compare our model against hard-attention baselines on ImageNet, achieving higher accuracy with less resources (FLOPs, pro-cessing time and memory). We further test our model on fMoW dataset, where we process satellite images of size up to 896×896 px, getting up to 2.5x faster process-ing compared to baselines operating on the same resolution, while achieving higher accuracy as well. TNet is modular, meaning that most classiﬁcation models could be adopted as its backbone for feature extraction, making the reported performance gains orthogonal to beneﬁts offered by existing optimized deep models. Finally, hard-attention guarantees a degree of interpretability to our model’s predictions, without any extra cost beyond inference. 1

Introduction
In image classiﬁcation, deep neural networks (DNNs) are typically designed and optimized for a speciﬁc input resolution, e.g. 224 × 224 px. Using modern DNNs on images of higher resolution (as happens e.g., in satellite or medical imaging) is a non-trivial problem due to the subtlety of scaling model architectures [57], and rapid increase in computational and memory requirements.
A linear increase in the spatial dimensions of the input, results in a quadratic increase in computational complexity and memory, and can easily lead to resource bottlenecks. This can be mitigated with careful engineering, e.g., streaming [46] or gradient checkpointing [42]. However, such solutions are content-agnostic, and don’t take advantage of the fact that discriminative information may be sparse and distributed across various image scales, deeming processing of the whole input unnecessary.
Our goal is to leverage high-resolution information, while dispensing with the unsustainable quadratic complexity to input scale. To this end, we propose Traversal Network (TNet), a multi-scale hard-attention architecture, which traverses image scale-space in a top-down fashion, visiting only the most informative image regions along the way. TNet is recursive, and can be applied to inputs of virtually any resolution; an outline of its processing ﬂow is presented in Fig. 1 (a). Our method draws its intuition from the way humans use saccades to explore the visual world.
TNet offers an adjustable trade-off between accuracy and complexity, by changing the number of attended image regions. This way, complexity increases linearly with the number of attended locations, irrespective of the input resolution. Also, hard-attention explicitly reveals the image regions that our model values the most, providing a certain degree of interpretability (Fig. 1 (c)). Importantly, interpretability comes without any extra cost beyond inference, in contrast to popular attribution methods, which require at least an additional backward pass [53], or numerous forward passes [1]. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
Figure 1: (a) Multi-scale processing in TNet. Starting at level 1, features are selectively extracted from image regions at various scales (red cubes), and then, they are combined to create the ﬁnal image representation used for classiﬁcation (blue cube). (b) Experimental results on ImageNet [13] with baselines based on [18]. Numeric annotations correspond to the number of attended locations.
Our model offers a better trade-off between accuracy and complexity (FLOPs). (c) Examples of attention policy (top 3 locations) learned on ImageNet.
Attention may also reduce data acquisition cost [60], by allowing only a fraction of the high-resolution content to be acquired.
TNet is trained end-to-end by employing a modiﬁed version of REINFORCE rule [68], while using only classiﬁcation labels. Our architecture is modular, and most classiﬁcation models could be adopted as its backbone for feature extraction. This way, we can directly take advantage of various performance beneﬁts offered by existing optimized deep models.
Hard-attention is the mechanism that allows TNet to dispense with quadratic complexity to input scale, and as a result, we evaluate our model against strong hard-attention baselines on ImageNet [18].
A summary of our results is depicted in Fig. 1 (b), where we see that TNet offers a better trade-off between accuracy and complexity measured in FLOPs (similar behavior is observed with actual timings and memory). We extend our experiments to fMoW dataset, which consists of high-resolution satellite images [12]. We process images up to 896 × 896 px, getting up to 2.5x faster processing compared to baselines operating on the same resolution, while achieving higher accuracy as well.
We ﬁnd improvements in accuracy surprising, because TNet is processing only part of the input, in contrast to fully convolutional baselines. We primarily attribute this behavior to a novel regularization method, which encourages classiﬁcation based on individual attended locations. We verify its efﬁcacy through an ablation study. 2