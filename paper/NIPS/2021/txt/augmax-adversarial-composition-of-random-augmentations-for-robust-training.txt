Abstract
Data augmentation is a simple yet effective way to improve the robustness of deep neural networks (DNNs). Diversity and hardness are two complementary dimen-sions of data augmentation to achieve robustness. For example, AugMix explores random compositions of a diverse set of augmentations to enhance broader cov-erage, while adversarial training generates adversarially hard samples to spot the weakness. Motivated by this, we propose a data augmentation framework, termed
AugMax, to unify the two aspects of diversity and hardness. AugMax ﬁrst randomly samples multiple augmentation operators and then learns an adversarial mixture of the selected operators. Being a stronger form of data augmentation, AugMax leads to a signiﬁcantly augmented input distribution which makes model training more challenging. To solve this problem, we further design a disentangled normalization module, termed DuBIN (Dual-Batch-and-Instance Normalization), that disentan-gles the instance-wise feature heterogeneity arising from AugMax. Experiments show that AugMax-DuBIN leads to signiﬁcantly improved out-of-distribution robustness, outperforming prior arts by 3.03%, 3.49%, 1.82% and 0.71% on
CIFAR10-C, CIFAR100-C, Tiny ImageNet-C and ImageNet-C. Codes and pre-trained models are available: https://github.com/VITA-Group/AugMax. 1

Introduction
Out-of-distribution (OOD) samples present a challenge when deploying AI models in the real world.
Examples include natural corruptions (e.g., due to camera blurs or noise, snow, rain, or fog in image data), sensory perturbations (e.g., sensor transient error, electromagnetic interference) and domain shifts (e.g., summer → winter). However, deep networks are often trained on limited amounts of data which may not cover sufﬁcient scenarios. As a result, they are vulnerable to unforeseen distributional changes despite achieving high performance on standard benchmarks [1–3]. This jeopardizes their trustworthiness as well as safe deployment in real-world environments. Thus it is critical to develop techniques that improve robustness even when training with relatively clean datasets.
Several techniques have been proposed to consolidate the robustness against unforeseen corruptions, including robust data augmentation [5, 3, 8, 6], Lipschitz continuity [9–11], stability training [12], pre-training [13–16], and robust network structures [17–19], to name a few. Among these techniques, data augmentation is of particular interest due to its empirical effectiveness, ease of implementation, low computational overhead, and plug-and-play nature.
∗Work partially done during an internship at NVIDIA. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
(a) Standard (b) AugMix (Diversity) (c) PGD Attack (Hardness) (d) AugMax (Ours) (Diversity & Hardness)
Figure 1: The effects of diversity and hardness in data augmentations. We visualize features of augmented images fed to the network during training. The features are from the penultimate layer of a ResNeXt29 trained on CIFAR10 training data using only standard data augmentation (random
ﬂipping and translation) following [4]. For visualization, we randomly selected 300 ﬁxed images from 3 ﬁxed classes (denoted by different colors) to which we apply different augmentation methods: (a) standard augmentation (random ﬂipping and translation); (b) AugMix [5]; (c) PGD Attack [6, 7]; (d) AugMax (ours). In order to achieve good model robustness, the augmented training data should both be diverse and also contain enough hard cases. As can be seen, PGD Attack generates hard cases (which the network cannot separate) but are not diverse enough (they are all clustered together) while
AugMix creates diverse but not hard samples (they are well separated). By contrast, our approach (AugMax) achieves a uniﬁcation between hard and diverse samples.
There are mainly two categories of data augmentation approaches:
The ﬁrst category aims to increase diversity of the training data by composing multiple random transformations [20–22, 5, 3]. While standard data augmentation methods (e.g., random ﬂipping and translation) lead to poor robustness [5], more aggressive combinations of multiple augmentations have shown promise. One such successful example is AugMix [5], which stochastically samples from diverse augmentation operations and randomly mixing them to produce highly diverse augmented images. AugMix can increase the sample diversity coverage compared to standard augmentations, as shown in Figure 1 (a) and (b).
The second category aims to boost the hardness of the training data by sampling from the worst-case augmentations that tries to fool the model into misclassifying the samples. A common technique to achieve this goal is adversarial perturbation [6, 23, 8]. Training over such worst-case samples allows a model to actively ﬁx its generalization weaknesses [24] and empirically improves its robustness against corruptions [25, 26, 7]. Due to the extra complexity to generate adversarial perturbations, the improved robustness usually comes at the cost of largely increased training time compared with non-adversarial methods [6, 27]. An example falling into this category is the PGD attack [6], as is shown in Figure 1 (c).
Previous work has focused on leveraging one of these category to improve robustness. In this paper, we unify both approaches in a single framework. In particular, we show that diversity and hardness are complementary and that a uniﬁcation between the two is necessary to achieve robustness. We propose a new strategy to achieve this uniﬁcation and successfully increase robustness.
Summary of contributions:
• We propose AugMax, a novel augmentation framework which achieves robustness through a uniﬁcation between diversity and hardness, by searching for the worst-case mixing strategy.
• Being a stronger form of data augmentation, AugMax leads to a signiﬁcantly augmented and more heterogeneous input distribution, which also makes model training more challenging. To solve this problem, we design a new normalization strategy, termed DuBIN, to disentangle the instance-wise feature heterogeneity of AugMax samples.
• We show that combination of AugMax and DuBIN (AugMax-DuBIN) achieves state-of-the-art robustness against corruptions and improves robustness against other common distribution shifts.
AugMax achieves a good uniﬁcation between sample diversity and hard corner-case generation during data augmentation. AugMax is built on top of the AugMix framework [5] which mixes multiple data augmentation operators in a multi-branch and layered pipeline. However, different from AugMix where augmentation operators and mixing weights are both randomly sampled, operators are ﬁrst 2
Figure 2: AugMax overview. Black and red arrows represent forward paths and back-propagation paths to generate AugMax images, respectively. In contrast to AugMax, where the mixing parameters m and w are adversarially learned, AugMix randomly samples m and w from predeﬁned distributions (and thus no backpropergation on m and w). randomly sampled, followed by adversarially trained mixture of the selected operators in Augmax.
This simple change from AugMix to AugMax results in considerable difference in their feature distributions. From the visualizations (in Figure 1), AugMax generates more adversarially “hard samples", while still keeping a good amount of diversity compared to AugMix and PGD Attack.
Searching for adversarial mixing strategies in AugMax is slightly more expensive since it involves adversarial mixing. To make this efﬁcient, we adopt an efﬁcient adversarial training strategy [28]. As a result, AugMax adds only a reasonable amount of extra complexity compared to non-adversarial training methods, while improving robustness signiﬁcantly. For example, AugMax training time is only ∼ 1.5 times that of AugMix on ImageNet (see Table 7). Moreover, Augmax is signiﬁcantly more efﬁcient than traditional adversarial training which has ∼ 10 times training time overhead compared with AugMix.
Being a stronger form of data augmentation with adversarial sample generation, AugMax leads to a signiﬁcantly augmented input distribution which makes model training more challenging. This naturally motivates us to propose a novel and ﬁner-grained normalization scheme termed Dual-Batch-and-Instance Normalization (DuBIN). As illustrated in Figure 3, DuBIN adds an additional instance normalization (IN) in parallel to the traditional Dual Batch Normalization (DuBN) [7, 29] used in adversarial training, in order to better model and disentangle the instance-wise feature heterogeneity arising from AugMax. We show that adding the instance normalization is an important knob to promote the capability of AugMax in boosting model robustness.
Our framework, AugMax-DuBIN, is illustrated in Figure 2. AugMax-DuBIN trains on clean images and achieves state-of-the-art robustness on natural corruption benchmarks [1], and also improves model robustness against other common distribution shifts [30, 2]. In particular, our method surpasses state-of-the-art method on CIFAR10-C, CIFAR100-C, Tiny ImageNet-C and ImageNet-C by 3.03%, 3.49%, 1.82% and 0.71% respectively. 2