Abstract
Despite enormous successful applications of graph neural networks (GNNs), theo-retical understanding of their generalization ability, especially for node-level tasks where data are not independent and identically-distributed (IID), has been sparse.
The theoretical investigation of the generalization performance is beneﬁcial for understanding fundamental issues (such as fairness) of GNN models and designing better learning methods. In this paper, we present a novel PAC-Bayesian analysis for GNNs under a non-IID semi-supervised learning setup. Moreover, we analyze the generalization performances on different subgroups of unlabeled nodes, which allows us to further study an accuracy-(dis)parity-style (un)fairness of GNNs from a theoretical perspective. Under reasonable assumptions, we demonstrate that the distance between a test subgroup and the training set can be a key factor affecting the GNN performance on that subgroup, which calls special attention to the training node selection for fair learning. Experiments across multiple GNN models and datasets support our theoretical results4. 1

Introduction
Graph Neural Networks (GNNs) [13, 35, 20] are a family of machine learning models that can be used to model non-Euclidean data as well as inter-related samples in a ﬂexible way. In recent years, there have been enormous successful applications of GNNs in various areas, such as drug discovery [18], computer vision [29], transportation forecasting [49], recommender systems [48], etc. Depending on the type of prediction target, the application tasks can be roughly categorized into node-level, edge-level, subgraph-level, and graph-level tasks [46].
In contrast to the marked empirical success, theoretical understanding of the generalization ability of GNNs has been rather limited. Among the existing literature, some studies [9, 11, 25] focus on the analysis of graph-level tasks where each sample is an entire graph and the samples of graphs are
IID. A very limited number of studies [36, 42] explore GNN generalization for node-level tasks but they assume the nodes (and their associated neighborhoods) are IID samples, which does not align with the commonly seen graph-based semi-supervised learning setups. Baranwal et al. [3] investigate
GNN generalization without IID assumptions but under a speciﬁc data generating mechanism.
In this work, our ﬁrst contribution is to provide a novel PAC-Bayesian analysis for the generalization ability of GNNs on node-level tasks with non-IID assumptions. In particular, we assume the node features are ﬁxed and the node labels are independently sampled from distributions conditioned on the node features. We also assume the training set and the test set can be chosen as arbitrary subsets of nodes on the graph. We ﬁrst prove two general PAC-Bayesian generalization bounds (Theorem 1
∗School of Information, University of Michigan, Ann Arbor, Michigan, USA
†Equal contribution.
‡Department of EECS, University of Michigan, Ann Arbor, Michigan, USA 4Code available at https://github.com/TheaperDeng/GNN-Generalization-Fairness. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
and Theorem 2) under this non-IID setup. Subsequently, we derive a generalization bound for GNN (Theorem 3) in terms of characteristics of the GNN models and the node features.
Notably, the generalization bound for GNN is inﬂuenced by the distance between the test nodes and the training nodes in terms of their aggregated node features. This suggests that, given a ﬁxed training set, test nodes that are “far away” from all the training nodes may suffer from larger generalization errors. Based on this analysis, our second contribution is the discovering of a type of unfairness that arises from theoretically predictable accuracy disparity across some subgroups of test nodes.
We further conduct a empirical study that investigates the prediction accuracy of four popular GNN models on different subgroups of test nodes. The results on multiple benchmark datasets indicate that there is indeed a signiﬁcant disparity in test accuracy among these subgroups.
We summarize the contributions of this work as follows: (1) We establish a novel PAC-Bayesian analysis for graph-based semi-supervised learning with non-IID assumptions. (2) Under this setup, we derive a generalization bound for GNNs that can be applied to an arbitrary subgroup of test nodes. (3) As an implication of the generalization bound, we predict that there would be an unfairness of GNN predictions that arises from accuracy disparity across subgroups of test nodes. (4) We empirically verify the existence of accuracy disparity of popular GNN models on multiple benchmark datasets, as predicted by our theoretical analysis. 2