Abstract
Existing methods for unsupervised domain adaptation often rely on minimizing some statistical distance between the source and target samples in the latent space.
To avoid the sampling variability, class imbalance, and data-privacy concerns that often plague these methods, we instead provide a memory and computation-efﬁcient probabilistic framework to extract class prototypes and align the target features with them. We demonstrate the general applicability of our method on a wide range of scenarios, including single-source, multi-source, class-imbalance, and source-private domain adaptation. Requiring no additional model parameters and having a moderate increase in computation over the source model alone, the proposed method achieves competitive performance with state-of-the-art methods. 1

Introduction
In many real-world applications, such as healthcare and autonomous driving, data labeling can be expensive and time-consuming. To make predictions on a new unlabeled dataset, one may naively use an existing supervised model trained on a large labeled dataset. However, even subtle changes in the data-collection conditions, such as lighting or background for natural images, can cause a model’s performance to degrade drastically [1]. This shift in the input data distribution is referred to in the literature as covariate shift [2]. By leveraging the labeled samples from the source domain and unlabeled samples from the target domain, unsupervised domain adaptation aims to overcome this issue, making the learned model generalize well in the target domain [3].
Ben-David et al. [4, 5] provide an H-divergence based theoretical upper bound on the target error.
Ganin [6] popularizes learning an invariant representation between the source and target domains to minimize this divergence. Numerous prior methods [7–12] follow this trend, focusing on using the source and target samples for feature alignment in the latent space. While this approach can reduce the discrepancy between domains, directly using the source and target samples for feature alignment has the following problems. First, several commonly used methods that can be used to quantify the difference between two empirical distributions, such as maximum mean discrepancy (MMD) [13] and Wasserstein distance [14, 15], are sensitive to outlier samples in a mini-batch when used to match the source and target marginal distributions [16, 17]. We attribute this problem to the sampling variability of both the source and target samples. Second, while we typically assume that the two domains share the same label space, we cannot guarantee that the samples drawn from the source and target domains will cover the same set of classes in each mini-batch. Especially, if the label proportions shift between domains, learning domain invariant representation might not lead to improvements over using the source data alone to train the model [18]. If we pull the support of
∗ Equal contribution. Corresponding to: mingyuan.zhou@mccombs.utexas.edu
PyTorch code is available at https://github.com/korawat-tanwisuth/Proto_DA 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
Figure 1: This ﬁgure exhibits a diagram of Prototype-oriented Conditional Transport (PCT). Unlike existing methods that align the target and source features, our method aligns the target features with class prototypes.
The gray arrow indicates that the gradients of the prototypes do not back-propagate through the transport loss. the source and target feature representations from different classes closer together, the classiﬁer will be more likely to misclassify those examples. Finally, aligning the target features to source features means that we need access to both the source and target data simultaneously. In applications such as personal healthcare, we may not have access to the source data directly during the adaptation stage; instead, we may only be given access to the target data and the model trained on the source data.
We propose an algorithm that constructs class prototypes to represent the source domain samples in the latent space. Using the prototypes instead of source features avoids the previously mentioned problems: 1) sampling variability in the source domain, 2) instance class-mismatching in a mini-batch, and 3) source-data privacy concerns. As we expect the classiﬁer to make better predictions on the target data in regions where the source density is sufﬁciently high [19], it is natural to consider encouraging the feature encoder to map the target data close to these prototypes. Motivated by the cluster assumption [20] (decision boundaries should not cross high-density regions of the data), we provide a method to transport the target features to these class prototypes and vice versa. We further extend our bi-directional transport to address the potential shift in label proportions, a common problem that has been studied [21–25] but that has been often overlooked in prior works [6, 7, 26].
Compared to existing methods, the proposed one has several appealing aspects. First, it does not rely on adversarial training to achieve competitive performance, making the algorithm robust and converge much faster. Moreover, learnable prototypes not only avoid expensive computation but also bypass the need to directly access the source data. This attribute makes our algorithm applicable to the settings where preserving the source data privacy is a major concern. Unlike clustering-based approaches that typically require multiple forward passes before an update, our algorithm processes data in mini-batches for each update and is trained in an end-to-end manner.
We highlight the main contributions of the paper as follows: 1) We utilize the linear classiﬁer’s weights as class prototypes and propose a general probabilistic framework to align the target features to these prototypes. 2) We introduce the minimization of the expected cost of a probabilistic bi-directional transport for feature alignment, and illustrate its superior performance over related methods. 3) We test the proposed method under multiple challenging yet practical settings: single-source, multi-source, class-imbalance, and source-private domain adaptation. In comparison to state-of-the-art algorithms, the proposed prototype-oriented method achieves highly competitive performance in domain adaptation, while requiring no additional model parameters and only having a moderate increase in computation over the source model alone. 2 Prototype-oriented conditional transport
In this section, we propose Prototype-oriented Conditional Transport (PCT), a holistic method for domain adaption consisting of three parts: learning class prototypes, aligning the target features with learned prototypes using a probabilistic bi-directional transport framework of Zheng and Zhou 2
Figure 2: Visualization of different methods on a synthetic dataset, where darker points marked with “·” and lighter points marked with “×” denote the source and target samples, respectively, and the red and green colors denote two different classes. For each method, the left plot shows the data space whereas the right plot exhibits the output of the feature encoder in the latent space. Letters A and B correspond to the two class prototypes in the latent space. When there is clear class imbalance, DANN, a representative algorithm whose strategy is to match the marginal feature distributions between the source and target, fails to adapt to the target domain.
[27], and estimating the target class proportions. Our method does not introduce additional model parameters for aligning domain features, and the model can be learned in an end-to-end manner. We provide a motivating example of the application of our method on a synthetic dataset in Figure 2.
In domain adaptation, we are given a labeled dataset from the source domain, {(xs i=1 ∼ Ds, and an unlabeled dataset from the target domain, {xt t . We focus on the closed-category domain adaptation and assume that the source and target domains share the same label space, i.e., ys i , yt j ∈ {1, 2, . . . , K}, where K denotes the number of classes. The goal of domain adaptation is to learn a model with low risk on the target samples. The model typically consists of a feature encoder,
Fθ : X → Rdf , parameterized by θ, and a linear classiﬁcation layer Cµ : Rdf → RK, parameterized by µ. In prior works [6, 7, 26], the feature encoder is a pre-trained neural network, and the classiﬁer is a randomly initialized linear layer. To simplify the following notation, we denote f s i = Fθ(xs i ) and f t j, respectively. j) as the feature representations of the source data xs i and target data xt j = Fθ(xt j=1 ∼ Dx i )}ns j}nt i , ys 2.1 Learning class prototypes
Most existing works [6, 7, 26] focus on aligning the source and target features in a latent space. By contrast, we propose to characterize the features of each class with a class prototype and align the target features with these class prototypes instead of the source features. This approach has several advantages. First, the feature alignment between two domains would be more robust to outliers in the source domain as we avoid using the source samples directly. Second, we do not need to worry about the missing classes in the sampled mini-batch in the source domain like we do when we align the features of source and target samples. Prototypes ensure that every class is represented for each training update. Last but not least, using the inferred prototypes instead of source features allows adapting to the target domain even without accessing the source data during the adaptation stage, which is an appealing trait when preserving the source data privacy is a concern (see Table 6).
Previous methods [28–31, 12, 32] construct each class prototype as the average latent feature for that class extracted by the feature encoder, which is computationally expensive due to the forward passing of a large number of training samples. We propose to construct class prototypes in the same latent space but with learnable parameters: [µ1, µ2, . . . , µK] ∈ Rdf ×K, where the dimension of each prototype, df , is the same as the hidden dimension after the feature encoder Fθ. This strategy has been successfully applied by Saito et al. [33] in a semi-supervised learning setting. We learn each class prototype in a way that encourages the prototype to be close to the source samples associated with that class in the feature space. In particular, given the prototypes and source samples xs i with features f s i , we use the cross-entropy loss to learn the prototypes: i and labels ys
Lcls = E(xs i ,ys i )∼Ds (cid:104)(cid:80)K k=1 − log ps ik1{ys i =k} (cid:105)
, ps ik := exp(µT k f s k(cid:48)=1 exp(µT i +bk) k(cid:48) f s (cid:80)K i +bk(cid:48) )
, (1) where bk is a bias term and ps ik is the predictive probability for xs i to be classiﬁed to class k. We note that this way of learning the class prototypes is closely connected to learning the standard linear classiﬁcation layer Cµ on source-only data with the cross-entropy loss. The neural network weights in the classiﬁcation layer can be interpreted as the class prototypes. Therefore, compared with source-only approaches, constructing prototypes in this way introduce no additional parameters. As we show in Figure 4a, our method requires much fewer parameters than other domain-adaptation methods.
Moreover, it requires much less computation than other prototype-based methods by avoiding the need to average the latent features for each class. 3
2.2 Bi-directional prototype-oriented conditional transport
In this section, we will discuss how we encourage the feature encoder to align the target data with class prototypes. Our approach is motivated by the cluster assumption, which has been widely adopted in both semi-supervised learning [20, 34, 35] and domain-adaptation literature [36, 37, 31, 38].
The cluster assumption states that the input data distribution consists of separated clusters and that instances belonging to the same cluster tend to have the same class labels. This means that the decision boundaries should not cross data high-density regions. To achieve this goal, we minimize the expected pairwise cost between the target features and prototypes with respect to two differently constructed joint distributions. By minimizing the expected costs under these two different joint distributions, the target feature will be close to the prototypes, far from the decision boundaries. 2.2.1 Moving from target domain to class prototypes
To deﬁne the expected cost of moving from the target domain to the class prototypes, we ﬁrst use the chain rule to factorize the joint distribution of the class prototype µk and target feature f t j j), where drawing from the target feature distribution p(f t as p(f t j) can be realized by t to obtain f t selecting a random target sample xt j). The conditional distribution, representing the probability of moving from target feature f t j to class prototype µk, is deﬁned as j)πθ(µk | f t j = Fθ(xt j ∼ Dx
πθ(µk | f t j) = p(µk) exp(µT k f t j ) k(cid:48) f t k(cid:48)=1 p(µk(cid:48) ) exp(µT j ) (cid:80)K
, k ∈ {1, . . . , K}, (2) k f t where, through the lens of Bayes’ rule, p(µk) is the discrete prior distribution over the K classes for the target domain, and exp(µT j) plays the role of an unnormalized likelihood term, measuring the similarity between class prototypes and target features. Intuitively, the target features are more likely to be moved to the prototypes which correspond to dominant classes in the target domain or which are closer to the target features (or both). Note that in practice we often do not have access to the target class distribution p(µk). We can use a uniform prior distribution for p(µk). However, this could be sub-optimal, especially when classes are seriously imbalanced in the target domain. To address this issue, we propose a way to estimate {p(µk)}K
We now deﬁne the expected cost of moving the target features to class prototypes as: k=1 in Section 2.3.
Lt→µ = Ext j ∼Dx t
Eµk∼πθ (µk | f t j ) (cid:2)c(µk, f t j)(cid:3) = Ext j ∼Dx t (cid:20) (cid:80)K k=1 c(µk, f t j) p(µk) exp(µT k f t j ) k(cid:48) f t k(cid:48)=1 p(µk(cid:48) ) exp(µT j ) (cid:80)K (cid:21)
, (3) where c(·, ·), a point-to-point moving cost, is deﬁned with the cosine dissimilarity as c(µk, f t j) = 1 −
µT k f t j
||µk||2||f t j ||2
. (4)
We also consider other point-to-point costs and present the results in Section 4.2. With Eq. (3), it is straightforward to obtain an unbiased estimation of Lt→µ with a mini-batch from target domain Dx t .
In this target-to-prototype direction, we are assigning each target sample to the prototypes according to their similarities and the class distribution. Intuitively, minimizing this expected moving cost encourages each target feature to get closer to neighboring class prototypes, reducing the violation of the cluster assumption. If we think of each prototype as the mode of the distribution of source features for a class, this loss encourages a mode-seeking behavior [27]. Still, this loss alone might lead to sub-optimal alignment. The feature encoder can map most of the target data to only a few prototypes. We connect this loss to entropy minimization to elucidate this point.
Connection with entropy minimization. The expected cost of moving from the target domain to prototypes can be viewed as a generalization of entropy minimization [20], an effective regularization
If the point-to-point moving cost is in many prior domain-adaptation works [39, 33, 40, 17]. k f t exp(µT j ) deﬁned as c(µk, f t j ) and the conditional probability is k(cid:48) f t k(cid:48)=1 exp(µT
πθ(µk | f t j ) (with a uniform prior), then the expected moving cost (cid:3), which is equivalent to minimizing the entropy on becomes: Lt→µ = −Ext jk log pt jk the target samples. Entropy minimization alone also has a mode-seeking behavior and has the same tendency to drop some modes (class prototypes). In other words, one trivial solution is to assign the same one-hot encoding to all the target samples [41, 42]. j) = − log pt jk = − log exp(µT k f t j ) k(cid:48)=1 exp(µT k(cid:48) f t (cid:2) (cid:80)K k=1 pt j) = pt jk = j ∼Dx t (cid:80)K (cid:80)K 4
2.2.2 Moving from class prototypes to target domain
To ensure that each prototype has some target features located close by and avoid dropping class prototypes, we propose to add a cost of the opposite direction [27], i.e., moving from the prototypes j=1, of target samples of size M , denoting ˆp(f t) = to target features. Given a mini-batch, {xt (cid:80)M as the empirical distribution of the target features in this mini-batch, the probabilities of j}M 1
M δf t j j=1 moving from a prototype µk to the M target features is deﬁned as a conditional distribution:
πθ(f t j | µk) =
ˆp(f t j(cid:48)=1 ˆp(f t j ) exp(µT k f t j ) k f t j(cid:48) ) exp(µT j(cid:48) ) (cid:80)M
= exp(µT k f t j ) k f t j(cid:48)=1 exp(µT j(cid:48) ) (cid:80)M
, f t j ∈ {f t 1, . . . , f t
M }. (5)
As opposed to the probabilities of moving a target feature to different class prototypes πθ(µk | f t j),
πθ(f t j | µk) normalizes the probabilities across the M target samples for each prototype, which ensures that each prototype will be assigned to some target features. Then, the expected cost of moving along this prototype-to-target direction is deﬁned as:
Lµ→t = E
{xt j }M j=1∼Dx t
= E
{xt j }M j=1∼Dx t
Eµk∼p(µk)Ef t (cid:20) j ∼πθ (f t k=1 p(µk) (cid:80)M (cid:80)K (cid:2)c(µk, f t j | µk) j=1 c(µk, f t j) (cid:80)M j)(cid:3) exp(µT k f t j ) k f t j(cid:48)=1 exp(µT j(cid:48) ) (cid:21)
, (6) which can be estimated by drawing a mini-batch of M target samples.
Finally, combining the classiﬁcation loss in Eq. (1), target-to-prototype moving cost in Eq. (3), and prototype-to-target moving cost in Eq. (6), our loss is expressed as
Lcls + Lt→µ + Lµ→t. (7)
Note that we treat µ as ﬁxed in both Lt→µ and Lµ→t. This strategy allows us to apply our method in the source-data-private setting where we only have access to the source model. We also ﬁnd empirically that this leads to more stable training. 2.3 Learning class proportions in the target domain
We propose to infer the class proportions {p(µk)}K k=1 in the target domain by maximizing the log-likelihood of the unlabeled target data while ﬁxing the class prototypes µ. Directly optimizing the marginal likelihood is intractable, so we use the EM algorithm [43–45] to derive the following iterative updates (see the derivation in Appendix B). We ﬁrst initialize with a uniform prior: p(µk)0 = 1
K , and obtain new estimates at each update step l (starting from 0): p(µk)l+1 = 1
M (cid:80)M j=1 πl
θ(µk | f t j), where πl
θ(µk | f t j) = p(µk)l exp(µT k f t j ) k(cid:48) f t k(cid:48)=1 p(µk(cid:48) )l exp(µT j ) (cid:80)K
. (8)
Intuitively, the average predicted probabilities over the target examples for each class are used to estimate the target proportions, with p(µk)l+1 shown above providing an estimate based on a single mini-batch of M target samples. To estimate it based on the full dataset, we iteratively update it with p(µk)l+1 ← (1 − βl)p(µk)l + βlp(µk)l+1, where we follow the decaying schedule of the learning rate of the other parameters to set βl = β0(1 + γl)−α, in which γ = 0.0002, α = 0.75. The inintial value β0 is a hyper-parameter that can be set as either 0 to indicate a uniform prior, or a small value, such as 0.001, to allow the class proportions to be inferred from the data. 3