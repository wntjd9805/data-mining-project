Abstract
We analyze the complexity of learning directed acyclic graphical models from observational data in general settings without speciﬁc distributional assumptions.
Our approach is information-theoretic and uses a local Markov boundary search procedure in order to recursively construct ancestral sets in the underlying graph-ical model. Perhaps surprisingly, we show that for certain graph ensembles, a simple forward greedy search algorithm (i.e. without a backward pruning phase) sufﬁces to learn the Markov boundary of each node. This substantially improves the sample complexity, which we show is at most polynomial in the number of nodes. This is then applied to learn the entire graph under a novel identiﬁability condition that generalizes existing conditions from the literature. As a matter of independent interest, we establish ﬁnite-sample guarantees for the problem of recovering Markov boundaries from data. Moreover, we apply our results to the special case of polytrees, for which the assumptions simplify, and provide explicit conditions under which polytrees are identiﬁable and learnable in polynomial time.
We further illustrate the performance of the algorithm, which is easy to implement, in a simulation study. Our approach is general, works for discrete or continuous distributions without distributional assumptions, and as such sheds light on the minimal assumptions required to efﬁciently learn the structure of directed graphical models from data. 1

Introduction
Learning the structure of a distribution in the form of a graphical model is a classical problem in statistical machine learning, whose roots date back to early problems in structural equations and covariance selection [12, 45, 46]. Graphical models such as Markov networks and Bayesian networks impose structure in the form of an undirected graph (UG, in the case of Markov networks) or a directed acyclic graph (DAG, in the case of Bayesian networks). This structure is useful for variety of tasks ranging from querying and sampling to inference of conditional independence and causal relationships, depending on the type of graph used. In practice, of course, this structure is rarely known and we must rely on structure learning to ﬁrst infer the graphical structure. The most basic version of this problems asks, given n samples from some distribution P that is represented by a graphical model G = (V, E), whether or not it is possible to reconstruct G.
In this paper, we study the structure learning problem for Bayesian networks (BNs). Our main contribution is a ﬁne-grained analysis of a polynomial time and sample complexity algorithm for learning the structure of BNs with potentially unbounded maximum in-degree and without faithfulness.
In particular, in our analysis we attempt to expose the underlying probabilistic assumptions that are important for these algorithms to work, drawing connections with existing work on local search algorithms and the conditional independence properties of P . 35th Conference on Neural Information Processing Systems (NeurIPS 2021), virtual.
1.1 Contributions
One of the goals of the current work is to better understand the minimal assumptions needed to identify and learn the structure of a DAG from data. Although this is a well-studied problem, existing theoretical work (see Section 1.2) relies on assumptions that, as we show, are not really necessary. In particular, our results emphasize generic probabilistic structure (conditional independence, Markov boundaries, positivity, etc.) as opposed to parametric or algebraic structure (linearity, additivity, etc.), and hence provide a more concrete understanding of the subtle necessary conditions for the success of this approach.
With this goal in mind, we study two fundamental aspects of the structure learning problem: Identiﬁa-bility and Markov boundary search. On the one hand, we provide a weaker condition for identiﬁability compared to previous work, and on the other, we exhibit families of DAGs for which forward greedy search sufﬁces to provably recover the parental sets of each node. More speciﬁcally, our contributions can be divided into several parts: 1. Identiﬁability (Theorem 3.1). We prove a new identiﬁability result on DAG learning.
Roughly speaking, this condition requires that the entropy conditioned on an ancestral set
H(Xk | A) of each node in G is dominated by one of its ancestors. An appealing feature of this assumption is that it applies to general distributions without parametric or structural assumptions, and generalizes existing ones based on second moments to a condition on the local entropies in the model. We also discuss in depth various relaxations of this and other conditions (Appendix C). 2. Local Markov boundary search (Algorithm 2, Proposition 4.1). We prove ﬁnite-sample guar-antees for a Markov boundary learning algorithm that is closely related to the incremental association Markov blanket (IAMB) algorithm, proposed in Tsamardinos et al. [42]. These results also shed light on the assumptions needed to successfully learn Markov boundaries in general settings; in particular, we do not require faithfulness, which is often assumed. 3. Structure learning (Algorithm 1, Theorem 5.1). We propose an algorithm which runs in
O(d3r log d) time and O(d2r log3 d) sample complexity, to learn an identiﬁable DAG G from samples. Here, d is the dimension and r ≤ d is the depth of the DAG G, deﬁned in
Section 2. 4. Learning polytrees (Theorem 5.2). As an additional application of independent interest, we apply our results to the problem of learning polytrees [10, 37]. 5. Generalizations and extensions (Appendix C). In the supplement, we have included an extensive discussion of our assumptions with many examples and generalizations to illustrate the main ideas. For example, this appendix includes relaxations of the positivity assumption on P , the main identiﬁability condition (Condition 1), the PPS condition (Condition 2), and extensions to general, non-binary distributions. We also discuss examples of the conditions and a comparison to the commonly assumed faithfulness condition.
Finally, despite a long history of related work on Markov blanket learning algorithms [e.g. 1, 34, 40], to the best of our knowledge there has been limited theoretical work on the ﬁnite-sample properties of IAMB and related algorithms. It is our hope that the present work will serve to partially ﬁll in this gap. 1.2