Abstract
Annealed importance sampling (AIS) and related algorithms are highly effective tools for marginal likelihood estimation, but are not fully differentiable due to the use of Metropolis-Hastings correction steps. Differentiability is a desirable property as it would admit the possibility of optimizing marginal likelihood as an objective using gradient-based methods. To this end, we propose Differentiable AIS (DAIS), a variant of AIS which ensures differentiability by abandoning the Metropolis-Hastings corrections. As a further advantage, DAIS allows for mini-batch gradients.
We provide a detailed convergence analysis for Bayesian linear regression which goes beyond previous analyses by explicitly accounting for the sampler not having reached equilibrium. Using this analysis, we prove that DAIS is consistent in the full-batch setting and provide a sublinear convergence rate. Furthermore, motivated by the problem of learning from large-scale datasets, we study a stochastic variant of DAIS that uses mini-batch gradients. Surprisingly, stochastic DAIS can be arbitrarily bad due to a fundamental incompatibility between the goals of last-iterate convergence to the posterior and elimination of the accumulated stochastic error.
This is in stark contrast with other settings such as gradient-based optimization and
Langevin dynamics, where the effect of gradient noise can be washed out by taking smaller steps. This indicates that annealing-based marginal likelihood estimation with stochastic gradients may require new ideas. 1

Introduction
Marginal likelihood (ML), sometimes called evidence, is a central quantity in Bayesian learning as it measures how well a model can describe a particular dataset. It is commonly used to select hyperparameters for Gaussian processes [Rasmussen, 2003], where either closed-form solutions or accurate, tractable approximations are available. However, it is more often the case that computing
ML is computationally intractable, as it involves summation or integration over high-dimensional model parameters or latent variables. In this case, one must resort to numerical methods or other approximations [Kass and Raftery, 1995]. In the context of model comparison (e.g., evaluating gener-ative models [Wu et al., 2016, Huang et al., 2020]), annealed importance sampling (AIS) [Neal, 2001] is one of the most popular and effective algorithms. Notably, AIS is closely related to other generic
ML estimators that yield accurate estimation [Grosse et al., 2015], including Sequential Monte Carlo (SMC) [Doucet et al., 2001] and nested sampling [Skilling et al., 2006]. Under some assumptions,
AIS is able to produce accurate estimates of marginal likelihood given enough computation time (it converges to the true ML value quickly by adding more intermediate distributions).
AIS alternates between Markov chain Monte Carlo (MCMC) transitions and importance sampling updates, where the MCMC step typically involves a non-differentiable Metropolis-Hastings (MH) correction. Unfortunately, the non-differentiability precludes gradient-based optimization of the sampler and complicates theoretical analysis. To deal with this, we marry AIS with Hamiltonian 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
Monte Carlo (HMC) [Neal, 2011] and derive an unbiased yet differentiable ML estimator named differentiable AIS (DAIS) by removing the MH correction step, which further unlocks the possibility of mini-batch computation. Moreover, DAIS can be made memory efÔ¨Åcient by caching noise and simulating Hamiltonian dynamics in reverse [Maclaurin et al., 2015]. We analyze the convergence of
DAIS in the setting of Bayesian linear regression. Our analysis goes beyond prior analyses of AIS in that we account for the sampler not having reached equilibrium. In the full-batch setting, we show that DAIS retains the consistency guarantee of AIS (despite the lack of MH steps) and has a sublinear convergence rate.
Furthermore, motivated by the problem of learning from large-scale datasets, we study a stochastic variant of our algorithm that uses gradients estimated from a subset of the dataset. Given the success of stochastic optimization [Robbins and Monro, 1951, Bottou and Bousquet, 2011] and stochastic gradient MCMC algorithms [Welling and Teh, 2011, Chen et al., 2014], one may presume that stochastic gradient DAIS would perform well. Surprisingly, the stochastic version of DAIS can be arbitrarily bad. In particular, we show that the log ML estimates of DAIS with stochastic gradients are inconsistent due to a fundamental incompatibility between the goals of last-iterate convergence to the posterior and elimination of the accumulated stochastic error. This is in stark contrast with other settings such as gradient-based optimization and Langevin dynamics, where the gradient noise can be washed out by taking smaller steps. This indicates that annealing-based ML estimation with minibatch gradients may require new ideas.
We validate our theoretical analysis with simulations. We also demonstrate empirically that DAIS can be applied to variational autoencoders (VAEs) [Kingma and Welling, 2013, Rezende et al., 2014] for a tighter evidence lower bound, which in turn leads to improved performance compared to the vanilla
VAE. We also compare to importance weighted autoencoders (IWAE) [Burda et al., 2016]. While
IWAE is more effective with a low compute budget, we show that DAIS eventually outperforms
IWAE as compute increases. Finally, like AIS, DAIS can be used to evaluate generative models. We show that it performs on par with AIS despite the removal of the MH correction step and outperforms the IWAE bound by a large margin. 2