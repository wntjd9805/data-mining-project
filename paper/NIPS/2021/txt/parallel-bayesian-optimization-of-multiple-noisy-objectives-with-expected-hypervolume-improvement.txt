Abstract
Optimizing multiple competing black-box objectives is a challenging problem in many ﬁelds, including science, engineering, and machine learning. Multi-objective
Bayesian optimization (MOBO) is a sample-efﬁcient approach for identifying the optimal trade-offs between the objectives. However, many existing methods perform poorly when the observations are corrupted by noise. We propose a novel acquisition function, NEHVI, that overcomes this important practical limitation by applying a Bayesian treatment to the popular expected hypervolume improvement (EHVI) criterion and integrating over this uncertainty in the Pareto frontier. We argue that, even in the noiseless setting, generating multiple candidates in parallel is an incarnation of EHVI with uncertainty in the Pareto frontier and therefore can be addressed using the same underlying technique. Through this lens, we derive a natural parallel variant, qNEHVI, that reduces computational complexity of parallel EHVI from exponential to polynomial with respect to the batch size. qNEHVI is one-step Bayes-optimal for hypervolume maximization in both noisy and noiseless environments, and we show that it can be optimized effectively with gradient-based methods via sample average approximation. Empirically, we demonstrate not only that qNEHVI is substantially more robust to observation noise than existing MOBO approaches, but also that it achieves state-of-the-art optimization performance and competitive wall-times in large-batch environments. 1

Introduction
Black-box optimization problems that involve multiple competing noisy objectives are ubiquitous in science and engineering. For example, a real-time communications service may be interested in tuning the parameters of a control policy to adapt video quality in real time in order to maximize video quality and minimize latency [10, 17]. In robotics, scientists may seek to design hardware components that maximize locomotive speed and minimize energy expended [8, 38]. In agriculture, development agencies may seek to balance crop yield and environmental impact [28]. For such multi-objective optimization (MOO) problems, there typically is no single solution that is best with respect to all objectives. Rather, the goal is to identify the Pareto frontier: a set of optimal trade-offs such that improving one objective means deteriorating another. In many cases, the objectives are expensive to evaluate. For instance, randomized trials used in agriculture and the internet industry may take weeks or months to conduct and incur opportunity costs, and manufacturing and testing hardware is both costly and time-consuming. Therefore, it is imperative to be able to identify good trade-offs with as few objective evaluations as possible.
Bayesian optimization (BO), a method for efﬁcient global black-box optimization, is often used to tackle such problems. BO employs a probabilistic surrogate model in conjunction with an acquisition function to navigate the trade-off between exploration (evaluating designs with high uncertainty) and exploitation (evaluating designs that are believed to be optimal). Although a signiﬁcant number of works have explored multi-objective Bayesian optimization (MOBO), most available methods 35th Conference on Neural Information Processing Systems (NeurIPS 2021)
[3, 39, 51, 60] do not take into account the fact that, in practice, observations are often subject to noise. For example, results of an A/B test are highly variable due to heterogeneity in the underlying user population and other factors. Agricultural trials are affected by the stochastic nature of plant growth and environmental factors such as soil composition or wind currents. In robotics, devices are subject to manufacturing tolerances, and observations of quantities such as locomotive speed and efﬁciency may be corrupted by measurement error from noisy sensors and environmental factors such as temperature or surface friction. While previous work has shown that a principled treatment of noisy observations can signiﬁcantly improve optimization performance in the single-objective case
[24, 37], this issue is understudied in the multi-objective setting. Furthermore, many applications in which evaluations take a long time require evaluating large batches of candidates in parallel in order to achieve reasonable throughput. For example, when ﬁrms optimize systems via A/B tests, it may take several weeks to test any particular conﬁguration. Because of this, large batches of candidate policies are tested simultaneously [36]. In biochemistry and materials design, dozens of tests can be conducted parallel on a single microplate [63]. Even in sophisticated high throughput chemistry settings, these batches may take several hours or days to set up and evaluate [42]. Most existing
MOBO methods, however, are either designed for purely sequential optimization [3, 51] or do not scale well to large batch sizes [11].
Contributions: In this work, we propose a novel MOBO algorithm, based on expected hypervolume improvement (EHVI), that scales to highly parallel evaluations of noisy objectives. Our approach is made possible by a general-purpose, differentiable, cached box decomposition (CBD) implementation that dramatically speeds up critical computations needed to account for uncertainty introduced by noisy observations and generate new candidate points for highly parallel batch or asynchronous evaluation. In particular, our CBD-based approach solves the fundamental problem of scaling parallel
EHVI-based methods to large batch sizes, reducing time and space complexity from exponential to polynomial. Our proposed algorithm, noisy expected hypervolume improvement (NEHVI), is the one-step Bayes-optimal policy for hypervolume improvement and provides state-of-the-art performance across a variety of benchmarks. To our knowledge, our work provides the most extensive evaluation of noisy parallel MOBO to date. A high-quality implementation of qNEHVI, as well as many of the baselines considered here, will be made available as open-source software upon publication. 2 Preliminaries
Our goal is to ﬁnd the set of optimal designs x over a bounded set X ⊂ Rd that maximize one or more objectives f (x) ∈ RM , with no known analytical expression nor gradient information of f .
Multi-Objective Optimization (MOO) aims to identify the set of Pareto optimal objective trade-offs. We say a solution f (x) = (cid:2)f (1)(x), ..., f (M )(x)(cid:3) dominates another solution f (x) (cid:31) f (x(cid:48)) if f (m)(x) ≥ f (m)(x(cid:48)) for m = 1, ..., M and ∃ m ∈ {1, ..., M } s.t. f (m)(x) > f (m)(x(cid:48)). We deﬁne the Pareto frontier as P ∗ = {f (x) : x ∈ X , (cid:64) x(cid:48) ∈ X s.t. f (x(cid:48)) (cid:31) f (x)}, and denote the set of
Pareto optimal designs as X ∗ = {x : f (x) ∈ P ∗}. Since the Pareto frontier (PF) is often an inﬁnite set of points, MOO algorithms usually aim to identify a ﬁnite approximate PF P. A natural measure of the quality of a PF is the hypervolume of the region of objective space that is dominated by the PF and bounded from below by a reference point. Provided with the approximate PF, the decision-maker can select a particular Pareto optimal trade-off according to their preferences.
Bayesian Optimization (BO) is a sample-efﬁcient optimization method that leverages a probabilistic surrogate model to make principled decisions to balance exploration and exploitation [19, 50].
Typically, the surrogate is a Gaussian Process (GP), a ﬂexible, non-parametric model known for its well-calibrated predictive uncertainty [47]. To decide which points to evaluate next, BO employs an acquisition function α(·) that speciﬁes the value of evaluating a set of new points x based on the surrogate’s predictive distribution at . While evaluating the true black-box function f is time-consuming or costly, evaluating the surrogate is cheap and relatively fast; therefore, numerical optimization can be used to ﬁnd the maximizer of the acquisition function x∗ = arg maxx∈X α(x) to evaluate next on the black-box function. BO sequentially selects new points to evaluate and updates the model to incorporate the new observations.
Evolutionary algorithms (EAs) such as NSGA-II [12] are a popular choice for solving MOO problems (see Zitzler et al. [67] for a review of various other approaches). However, EAs generally suffer from high sample complexity, rendering them infeasible for optimizing expensive-to-evaluate black-box 2
functions. Multi-objective Bayesian optimization (MOBO), which combines a Bayesian surrogate with an acquisition function designed for MOO, provides a much more sample-efﬁcient alternative. 3