Abstract
The goal of self-supervised visual representation learning is to learn strong, trans-ferable image representations, with the majority of research focusing on object or scene level. On the other hand, representation learning at part level has received signiﬁcantly less attention. In this paper, we propose an unsupervised approach to object part discovery and segmentation and make three contributions. First, we construct a proxy task through a set of objectives that encourages the model to learn a meaningful decomposition of the image into its parts. Secondly, prior work argues for reconstructing or clustering pre-computed features as a proxy to parts; we show empirically that this alone is unlikely to ﬁnd meaningful parts; mainly because of their low resolution and the tendency of classiﬁcation networks to spatially smear out information. We suggest that image reconstruction at the level of pixels can alleviate this problem, acting as a complementary cue. Lastly, we show that the stan-dard evaluation based on keypoint regression does not correlate well with segmen-tation quality and thus introduce different metrics, NMI and ARI, that better char-acterize the decomposition of objects into parts. Our method yields semantic parts which are consistent across ﬁne-grained but visually distinct categories, outperform-ing the state of the art on three benchmark datasets. Code is available at the project page: https://www.robots.ox.ac.uk/~vgg/research/unsup-parts/. 1

Introduction
Humans perceive the world as a collection of distinct objects. When we interact with an object, we naturally perceive the different parts it consists of. In visual scene understanding, parts provide intermediate representations that are more invariant to changes in object pose, orientation, camera view or lighting than the objects themselves. They are useful in analyzing objects for higher level tasks, such as ﬁne-grained recognition, manipulation etc. However, supervised learning of parts requires manual annotations, which are slow, expensive and infeasible to collect for the almost unlimited variety of objects in the real world. Thus, unsupervised part discovery and segmentation has recently gained the interest of the community. We thus consider the problem of automatically discovering the parts of visual object classes: given a collection of images of a certain object category (e.g., birds) and corresponding object masks, we want to learn to decompose an object into a collection of repeatable and informative parts.
It is important to deﬁne and understand the nature of parts before we begin describing approaches to part discovery. While there is no universally accepted formal deﬁnition for what constitutes a “part”, the nature of objects and object parts is accepted as different. For example, for Gibson [26], an object is “detachable”, i.e. something that, at least conceptually, can be picked up and moved to a different place irrespective of the rest of the scene. Parts, in contrast, are constituent elements of an object, and 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
cannot be removed without breaking the object, i.e. they are essential to the object and occur across most instances of the same object category.
Unsupervised part discovery requires suitable inductive principles and the choice of these principles deﬁnes the nature of the parts that will be discovered. Parts could, for example, be deﬁned based on motion following the principle of common fate in Gestalt psychology (i.e. what moves together belongs together) [66, 73], or they could be deﬁned based on visual appearance or function. Here, we are interested in semantic parts across different instances of an object category (e.g., birds, cars, etc.) and combine three simple learning principles as “part proxy”: (a) consistency to transformation (equivariance), (b) visual consistency (or self-similarity), and (c) distinctiveness among different parts.
Prior work has suggested that useful cues for part discovery can be obtained from pre-trained neural networks [2, 28]. These networks can in fact be used as a dense feature extractors and the feature responses can be clustered or otherwise decomposed to identify parts [14, 37]. In particular, [37] learn part prototypes, and make the latter orthogonal to avoid parts collapsing into a single one.
In this paper, we revisit and improve such concepts. We make the following contributions. First, we show that contrastive learning can be employed as an effective tool to decompose objects into diverse and yet consistent parts. In particular, we seek parts whose feature responses are homogeneous within the same or different occurrences of the same part type, while at the same time being distinctive for different types of parts. A second contribution is to discuss whether clustering pre-trained features is indeed sufﬁcient for part discovery. To this end, we show that simply clustering dense features sometimes captures obviously self-similar structures, such as image edges, rather than meaningful parts (Section 3.2). This is somewhat intrinsic to using pre-trained feed-forward local features, as these can only analyze a ﬁxed image neighborhood and thus pick up the pattern which is most obvious within their aperture. As a complementary cue, we thus suggest to look at the visual consistency of parts. The idea is that most parts are visually homogeneous, sharing a color or texture. A generative model of the part appearance may thus be able to detect part membership at the level of individual pixels. We show, in particular, that even very simple models that assume color consistency are complementary and beneﬁcial when added to feature-based grouping.
Finally, we consider the problem of assessing automated part discovery. An issue is the relative scarcity of data labelled with part segmentation. Another one, technically more challenging, is the fact that parts that are discovered without supervision may not necessarily correspond to the parts that a human annotator would assign to an image. This makes the use of manual part annotations for evaluation tricky. Prior work in the area has thus assessed the discovered parts via proxy tasks, such as learning keypoint predictors, using supervision. The idea is that, if parts are consistent, they should be good predictors of other geometric primitives. Unfortunately, as we show empirically, transferring parts to keypoints is unlikely to provide a meaningful metric for the quality of the part segments. We show, for instance, that knowledge of a single keypoint provides a better predictor of other keypoints than any of the previous unsupervised models.
To address this issue, we propose a new evaluation protocol. We still use keypoints as they are readily available, or ground-truth part segmentation when possible; however, instead of learning to regress such ground truth annotations, we simply measure the co-occurrence statistics of the predicted parts and these annotations using Normalized Mutual Information and Adjusted Rand Index. The latter require the learned parts to be geometrically consistent and distinctive regardless of whether they are in one-to-one correspondence with manually provided labels and results in a more meaningful measure for this task.
Empirically, we demonstrate that these improvements lead to stronger automated part discovery than prior work on standard benchmarks. 2