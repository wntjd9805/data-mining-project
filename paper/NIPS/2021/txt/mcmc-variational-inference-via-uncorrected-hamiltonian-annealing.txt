Abstract
Given an unnormalized target distribution we want to obtain approximate samples from it and a tight lower bound on its (log) normalization constant log Z. Annealed
Importance Sampling (AIS) with Hamiltonian MCMC is a powerful method that can be used to do this. Its main drawback is that it uses non-differentiable transition kernels, which makes tuning its many parameters hard. We propose a framework to use an AIS-like procedure with Uncorrected Hamiltonian MCMC, called Uncor-rected Hamiltonian Annealing. Our method leads to tight and differentiable lower bounds on log Z. We show empirically that our method yields better performances than other competing approaches, and that the ability to tune its parameters using reparameterization gradients may lead to large performance improvements. 1

Introduction
Variational Inference (VI) [4, 41, 45] is a method to do approximate inference on a target distribution p(z) = ¯p(z)/Z that is only known up to the normalization constant Z. The basic insights are, ﬁrst, that the evidence lower bound (ELBO) Eq(z)[log ¯p(z) − log q(z)] lower-bounds log Z and, second, that maximizing the ELBO is equivalent to minimizing the KL-divergence from q to p. The simplest
VI method chooses a parameterized family for q and optimizes its parameters to maximize the ELBO.
A recent direction involves combining VI with Markov chain Monte Carlo (MCMC) [34, 43]. These methods can be seen as an instance of the auxiliary VI framework [2] – they create an augmented variational distribution that represents all intermediate random variables generated during the MCMC procedure. An augmented target distribution that attempts to capture the inverse MCMC dynamics is optimized jointly with this variational distribution. However, it has been observed that capturing inverse dynamics is challenging [43, §5.4] (further discussion in Section 4).
Annealed Importance Sampling (AIS) [22, 27] is a powerful technique used to build augmented distri-butions without the need of learning inverse dynamics. While it was originally proposed to estimate expectations using importance sampling, it can be easily used to build lower bounds on normalization constants of intractable densities [18, 44]. AIS creates a sequence of densities that bridge from a tractable initial approximation q to the target ¯p. Then, the augmented variational distribution is given by a sequence of MCMC kernels targeting each bridging density, while the augmented target uses the reversals of those kernels. It turns out that the ratio of these augmented distributions can be computed using only evaluations of the bridging densities. Combining Hamiltonian MCMC kernels with AIS has been observed to produce strong lower bounds [35, 44].
However, these bounds are sensitive to numerous parameters, such as the initial distribution, bridging schedule, and parameters of the MCMC kernels. It would be desirable to optimize these parameters 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
to tighten the bound. Unfortunately, the presence of Metropolis-Hastings acceptance steps means that the the ﬁnal estimator is non-differentiable, and thus reparameterization gradients cannot be used.
In this work, we propose Uncorrected Hamiltonian Annealing (UHA), a differentiable alternative to Hamiltonian AIS. We deﬁne an augmented variational distribution using Hamiltonian MCMC kernels, but dropping the accept-reject steps. This is motivated by the fact that Hamiltonian dynamics sometimes have high acceptance rates. Since these uncorrected MCMC kernels do not exactly hold the bridging densities invariant, an augmented target distribution cannot be deﬁned in terms of reversals. Instead, we deﬁne our augmented target by deriving an algorithm for the exact reversal of the original (corrected) MCMC kernel and dropping the accept-reject step. Surprisingly, this yields a very simple expression for the resulting lower bound.
We use reparameterization gradients to tune various parameters involved in the lower bound produced by UHA, including the initial approximation q, parameters of the uncorrected MCMC kernel, and the bridging densities. Experimentally, tuning all these leads to large gains. For example, in several inference tasks we observe that tuning UHA with K = 64 bridging densities gives better results than traditional Hamiltonian AIS with K = 512.
Finally, we use UHA to train VAEs [24, 31]. In this case we observe that using UHA leads to higher ELBOs. In addition, we observe that increasing the number of bridging densities with UHA consistently leads to better results, and that for a large enough number of bridging densities the variational gap (difference between ELBO and true log-likelihood) becomes small, and models with higher log-likelihood are obtained. 2 Preliminaries
Variational inference and augmentation. Suppose that p(z) = 1
¯p is unnormalized and Z = (cid:82) ¯p(z)dz is the corresponding normalizer, and let
Z ¯p(z) is some target density, where
ELBO(q(z), ¯p(z)) = E q(z) log
¯p(z) q(z) (1) be the "ELBO operator". Variational inference (VI) is based on the fact that for any q(z) we have [4] log Z = ELBO(q(z), ¯p(z)) + KL(q(z)(cid:107)p(z)). (2)
In VI, the parameters of q are tuned to maximize the "evidence lower bound" (ELBO). Since the
KL-divergence is non-negative, this is always a lower bound on log Z. Also, maximizing the ELBO is equivalent to minimizing the KL-divergence from q to p.
To get tighter bounds and better approximations recent work has made use of augmented distributions
[2, 21]. Let z1:M = (z1, · · · , zM ) and suppose that ¯p(z1:M ) = ¯p(zM )p(z1:M −1|zM ) augments the original target density while preserving its normalization constant. Then, for any q(z1:M ) we have log Z = ELBO(q(z1:M ), ¯p(z1:M )) + KL(q(z1:M )(cid:107)p(z1:M )). (3)
The ﬁrst term is called the "augmented" ELBO and again lower bounds log Z. By the chain rule of
KL-divergence [12], the KL-divergence from q to p over z1:M upper-bounds the KL-divergence over zM . This justiﬁes using the marginal of q over zM to approximate the original target distribution.
Annealed Importance Sampling. A successful approach for creating augmented distributions is
Annealed Importance Sampling (AIS) [27]. It creates an augmented proposal distribution q by applying a sequence of transition densities Tm(zm+1|zm), and an augmented target by deﬁning transition densities Um(zm|zm+1). This gives the augmented densities q(z1:M ) = q(z1)
M −1 (cid:89) m=1
Tm(zm+1|zm) and
¯p(z1:M ) = ¯p(zM )
M −1 (cid:89) m=1
Um(zm|zm+1). (4)
Naively, the ratio of these densities is
¯p(z1:M ) q(z1:M )
=
¯p(zM ) q(z1)
Um(zm|zm+1)
Tm(zm+1|zm)
.
M −1 (cid:89) m=1 2 (5)
To deﬁne the transitions Tm and Um, AIS creates a sequence of unnormalized densities ¯π1, . . . , ¯πM −1 that “bridge” from a starting distribution q to the target ¯p, meaning that ¯π1 is close to q and ¯πM −1 is close to ¯p. Then, for each intermediate distribution, Tm(zm+1|zm) is chosen to be a Markov kernel that holds πm invariant, and Um to be the reversal of Tm with respect to πm, deﬁned as
Um(zm|zm+1) = T (zm+1|zm)
πm(zm)
πm(zm+1)
.
This choice produces a simpliﬁcation so that eq. 5 becomes
¯p(z1:M ) q(z1:M )
=
¯p(zM ) q(z1)
M −1 (cid:89) m=1
¯πm(zm)
¯πm(zm+1)
. (6) (7)
This can be easily evaluated without needing to evaluate the transition densities. The ratio from eq. 7 can be used to get an expression for the lower bound ELBO(q(z1:M ), ¯p(z1:M )). Research has shown that the AIS augmentation may lead to extremely tight lower bounds [18, 17, 35, 44].
Hamiltonian Dynamics. Many MCMC methods used to sample from p(z) are based on Hamiltonian dynamics [3, 8, 29, 42]. The idea is to create an augmented distribution p(z, ρ) = p(z)S(ρ), where
S(ρ) is a distribution over a momentum variable ρ (e.g. a Multivariate Gaussian). Then, one can deﬁne numerical integration schemes where z and ρ evolve while nearly holding p(z, ρ) constant. When corrected by a Metropolis-Hastings acceptance step, this can be made to exactly hold p(z, ρ) invariant.
This is alternated with a scheme that resamples the momentum ρ while holding S(ρ) invariant. When
Hamiltonian dynamics work well, z can quickly move around, suppressing random-walk behavior.
There are a variety of different Hamiltonian MCMC methods, corresponding to different integration schemes, momentum distributions, and ways of resampling the momentum. For instance, HMC and
Langevin dynamics use the leapfrog integrator, a Gaussian for the momentum variables and a full resampling of the momentum variables at each step [29, 42]. On the other hand, if the momentum variables are only partially resampled, the under-damped variants of HMC and Langevin dynamics are recovered [29]. It was observed that partial resampling may lead to improved perfomance [9].
It is easy to integrate Hamiltonian dynamics into AIS. First, deﬁne an augmented target ¯p(z, ρ) =
¯p(z)S(ρ) and an augmented starting distribution q(z, ρ) = q(z)S(ρ). Then, create a series of augmented densities ¯π1(z, ρ), . . . , ¯πM −1(z, ρ) bridging the two as ¯πm(z, ρ) = ¯πm(z)S(ρ). Finally, deﬁne the forward transition Tm(zm+1, ρm+1|zm, ρm) to be an iteration of a Hamiltonian MCMC method that leaves πm(z, ρ) invariant. We will describe a single transition Tm as a sequence of three steps: (1) resample the momentum; (2) simulate Hamiltonian dynamics and apply an accept-reject step; and (3) negate the momentum. The precise process that deﬁnes the transition is shown in Alg. 1.
Note that this algorithm is quite general, and compatible with HMC, Langevin dynamics and their underdamped variants (by selecting an appropriate integrator and resampling method).
Algorithm 1 Corrected Tm(zm+1, ρm+1|zm, ρm) m from some s(ρ(cid:48) 1. Sample ρ(cid:48) 2. Simulate Hamiltonian dynamics as (z(cid:48)(cid:48) m|ρm) that leaves S(ρ) invariant. Set z(cid:48) m) ← Tm(z(cid:48)
Calculate an acceptance probability α = min (1, ¯πm(z(cid:48)(cid:48) m , ρ(cid:48)(cid:48)(cid:48)
With probability α, set (z(cid:48)(cid:48)(cid:48) m). m)/¯πm(z(cid:48) m, ρ(cid:48) m, ρ(cid:48)(cid:48) m) ← (z(cid:48)(cid:48) m, ρ(cid:48)(cid:48) m, ρ(cid:48)(cid:48) m ← zm. m, ρ(cid:48) m)). m) ← (z(cid:48) m , ρ(cid:48)(cid:48)(cid:48) m, ρ(cid:48) m). m). Otherwise, set (z(cid:48)(cid:48)(cid:48) m). m , −ρ(cid:48)(cid:48)(cid:48) 3. Reverse the momentum as (zm+1, ρm+1) ← (z(cid:48)(cid:48)(cid:48) return (zm+1, ρm+1)
Representing Tm this way makes it easy to show it holds the density πm(z, ρ) invariant. The overall strategy is to show that each of the steps 1-3 holds πm invariant, and so does the composition of them [29, §3.2]. For steps 1 and 3 this is trivial, provided that S(ρ) = S(−ρ). For step 2, we require that the simulation Tm has unit Jacobian and satisﬁes T −1 m = Tm. Then, Tm can be interpreted as a symmetric Metropolis-Hastings proposal, meaning the Metroplis-Hastings acceptance probability α is as given. A typical choice for Tm that satisﬁes these requirements is the leapfrog integrator with a momentum reversal at the end. (This reversal then gets "un-reversed" in step 3 for accepted moves.)
Since Tm holds πm invariant, we can deﬁne Um as the reversal of Tm wrt πm. Then, eq. 7 becomes
¯p(z1:M , ρ1:M ) q(z1:M , ρ1:M )
=
¯p(zM , ρM ) q(z1, ρ1)
M −1 (cid:89) m=1
¯πm(zm, ρm)
¯πm(zm+1, ρm+1)
. (8) 3
Using this ratio we get an expression for the lower bound ELBO(q(z1:M , ρ1:M ), ¯p(z1:M , ρ1:M )) obtained with Hamiltonian AIS. While this method has been observed to yield strong lower bounds on log Z [35, 44] (see also Section 5.2), its performance depends on many parameters: initial distribution q(z), momentum distribution S, momentum resampling scheme, simulator Tm, and bridging densities.
We would like to tune these parameters by maximizing the ELBO using reparameterization-based estimators. However, due to the accept-reject step required by the Hamiltonian MCMC transition, the resulting bound is not differentiable, and thus reparameterization gradients are not available. 3 Uncorrected Hamiltonian Annealing
The contribution of this paper is the development of uncorrected Hamiltonian Annealing (UHA).
This method is similar to Hamiltonian AIS (eq. 8), but yields a differentiable lower bound. The main idea is simple. For any transitions Tm and Um, by the same logic as in eq. 5, we can deﬁne the ratio
¯p(z1:M , ρ1:M ) q(z1:M , ρ1:M )
=
¯p(zM , ρM ) q(z1, ρ1)
M −1 (cid:89) m=1
Um(zm, ρm|zm+1, ρm+1)
Tm(zm+1, ρm+1|zm, ρm)
. (9)
Hamiltonian AIS deﬁnes Tm as a Hamiltonian MCMC kernel that holds πm invariant, and Um as the reversal of Tm with respect to πm. While this leads to a nice simpliﬁcation, there is no requirement that these choices be made. We can use any transitions as long as the ratio Um/Tm is tractable.
We propose to use the "uncorrected" versions of the transitions Tm and Um used by Hamiltonian
AIS, obtained by dropping the accept-reject steps. To get an expression for the uncorrected Um we ﬁrst derive the reversal Um used by Hamiltonian AIS (Alg. 2). These uncorrected transitions are no longer reversible with respect to the bridging densities πm(z, ρ), and thus we cannot use the simpliﬁcation used by AIS to get eq. 8. Despite this, we show that the ratio Um/Tm for the uncorrected transitions can still be easily computed (Thm. 2). This produces a differentiable estimator, meaning the parameters can be tuned by stochastic gradient methods designed to maximize the ELBO.
We start by deriving the process that deﬁnes the transition Um used by Hamiltonian AIS. This is shown in Alg. 2. It can be observed that Um follows the same three steps of Tm (resample momentum,
Hamiltonian simulation with accept-reject, momentum negation), but in reverse order. m , ρ(cid:48)(cid:48)(cid:48)
Algorithm 2 Corrected Um(zm, ρm|zm+1, ρm+1) m) ← (zm+1, −ρm+1). 1. Set (z(cid:48)(cid:48)(cid:48) 2. Simulate Hamiltonian dynamics as (z(cid:48)(cid:48) m) ← Tm(z(cid:48)(cid:48)(cid:48)
Calculate an acceptance probability α = min (1, ¯πm(z(cid:48)(cid:48) m, ρ(cid:48)
With probability α, set (z(cid:48) 3. Sample ρm from srev(ρm|ρ(cid:48) return (zm, ρm) m, ρ(cid:48)(cid:48) m), the reversal of s(ρ(cid:48) m) ← (z(cid:48)(cid:48) m, ρ(cid:48)(cid:48) m). Otherwise, set (z(cid:48) m , ρ(cid:48)(cid:48)(cid:48) m, ρ(cid:48)(cid:48) m). m)/¯πm(z(cid:48)(cid:48)(cid:48) m, ρ(cid:48) m , ρ(cid:48)(cid:48)(cid:48) m)). m) ← (z(cid:48)(cid:48)(cid:48) m|ρm) with respect to S(ρm). Set zm ← z(cid:48) m , ρ(cid:48)(cid:48)(cid:48) m). m.
Lemma 1. The corrected Um (Alg. 2) is the reversal of the corrected Tm (Alg. 1) with respect to πm. (Proof Sketch). First, we claim the general result that if T1, T2 and T3 have reversals U1, U2 and U3, respectively, then the composition T = T1 ◦ T2 ◦ T3 has reversal U = U3 ◦ U2 ◦ U1 (all reversals with respect to same density π). Then, we apply this to the corrected Tm and Um: Tm is the composition of three steps that hold πm invariant. Thus, its reversal Um is given by the composition of the reversals of those steps, applied in reversed order. A full proof is in Appendix F.
We now deﬁne the "uncorrected" transitions used by UHA, shown in Algs. 3 and 4. These are just the transitions used by Hamiltonian AIS but without the accept-reject steps. (If Hamiltonian dynamics are simulated exactly, the acceptance rate is one and the uncorrected and corrected transitions are equivalent.) We emphasize that, for the "uncorrected" transitions, Tm does not exactly hold πm invariant and Um is not the reversal of Tm. Thus, their ratio does not give a simple expression in terms of ¯πm as in eq. 8. Nevertheless, the following result shows that their ratio has a simple form.
Theorem 2. Let Tm and Um be the uncorrected transitions deﬁned in Algs. 3 and 4, and let the dynamics simulator Tm(z, ρ) be volume preserving and self inverting. Then,
Um(zm, ρm|zm+1, ρm+1)
Tm(zm+1, ρm+1|zm, ρm)
=
S(ρm)
S(ρ(cid:48) m)
, (10) 4
Algorithm 3 Uncorrected Tm(zm+1, ρm+1|zm, ρm) 1. Sample ρ(cid:48) m from some s(ρ(cid:48) 2. Simulate Hamiltonian dynamics as (z(cid:48)(cid:48) 3. Reverse the momentum as (zm+1, ρm+1) ← (z(cid:48)(cid:48) return (zm+1, ρm+1) m|ρm) that leaves S(ρ) invariant. Set z(cid:48) m) ← Tm(z(cid:48) m, −ρ(cid:48)(cid:48) m, ρ(cid:48) m). m, ρ(cid:48)(cid:48) m). m ← zm. m, ρ(cid:48)(cid:48)
Algorithm 4 Uncorrected Um(zm, ρm|zm+1, ρm+1) m) ← (zm+1, −ρm+1). 1. Set (z(cid:48)(cid:48) 2. Simulate Hamiltonian dynamics as (z(cid:48) 3. Sample ρm from srev(ρm|ρ(cid:48) return (zm, ρm) m, ρ(cid:48) m), the reversal of s(ρ(cid:48) m) ← Tm(z(cid:48)(cid:48) m, ρ(cid:48)(cid:48) m). m|ρm) with respect to S(ρm). Set zm ← z(cid:48) m. where ρ(cid:48) m is the second component of Tm(zm+1, −ρm+1). (That is, ρ(cid:48) m from Algs. 3 and 4.) (Proof Sketch.) We consider variants of Algs. 3 and 4 in which each time z is assigned we add
Gaussian noise with some variance aI. We then derive the densities for Tm and Um using the rule for transformation of densities under invertible mappings, using that Tm is self-inverting and volume preserving. Taking the ratio gives eq. 10. Since this is true for arbitrary a, we take the stated result as the limit as a → 0. A full proof is in Appendix G.
As an immediately corollary of eq. 9 and Theorem 2 we get that for UHA
¯p(z1:M , ρ1:M ) q(z1:M , ρ1:M )
=
¯p(zM ) q(z1)
M −1 (cid:89) m=1
S(ρm+1)
S(ρ(cid:48) m)
. (11)
This ratio can be used to get an expression for the lower bound ELBO(q(z1:M , ρ1:M ), ¯p(z1:M , ρ1:M )) obtained with UHA. As mentioned in Section 2, the parameters of the augmented distributions are tuned to maximize the ELBO, equivalent to minimizing the KL-divergence from q to ¯p. While computing this ELBO exactly is typically intractable, an unbiased estimate can be obtained using a sample from q(z1:M , ρ1:M ) as shown in Alg. 5. If sampling is done using reparameterization, then unbiased reparameterization gradients may be used together with stochastic optimization algorithms to optimize the lower bound. In contrast, the variational lower bound obtained with Hamiltonian AIS (see Alg. 6 in Appendix A) does not allow the computation of unbiased reparameterization gradients.
Algorithm 5 Generating the (differentiable) uncorrected Hamiltonian annealing variational bound.
Sample z1 ∼ q and ρ1 ∼ S.
Initialize estimator as L ← − log q(z1). for m = 1, 2, · · · , M − 1 do
Run uncorrected Tm (Alg. 3) on input (zm, ρm), storing ρ(cid:48)
Update estimator as L ← L + log (S(ρm+1)/S(ρ(cid:48) m)). m and the output (zm+1, ρm+1).
Update estimator as L ← L + log ¯p(zM ). return R 3.1 Algorithm Details
Simulation of dynamics. We use the leapfrog operator with step-size (cid:15) to simulate Hamiltonian dynamics. This has unit Jacobian and satisﬁes Tm = T −1 m (if the momentum is negated after the simulation), which are the properties required for eq. 11 to be correct (see Theorem 2).
Momentum distribution and resampling. We set the momentum distribution S(ρ) = N (ρ|0, Σ) to be a Gaussian with mean zero and covariance Σ. The resampling distribution s(ρ(cid:48)|ρ) must hold this distribution invariant. As is common we use s(ρ(cid:48)|ρ) = N (ρ(cid:48)|ηρ, (1 − η2)Σ), where η ∈ [0, 1) is the damping coefﬁcient. If η = 0, the momentum is completely replaced with a new sample from S in each iteration (used by HMC and Langevin dynamics [29, 42]). For larger η, the momentum becomes correlated between iterations, which may help suppress random walk behavior and encourage faster mixing [9] (used by the underdamped variants of HMC and Langevin dynamics [29]).
Bridging densities. We set ¯πm(z, ρ) = q(z, ρ)1−βm ¯p(z, ρ)βm, where βm ∈ [0, 1] and βm < βm+1. 5
Computing gradients. We set the initial distribution q(z1) to be a Gaussian, and perform all sampling operations in Alg. 5 using reparameterization [24, 31, 39]. Thus, the whole procedure is differentiable and reparameterization-based gradients may be used to tune parameters by maximizing the ELBO. These parameters include the initial distribution q(z1), the covariance Σ of the momentum distribution, the step-size (cid:15) of the integrator, the damping coefﬁcient η of the momentum resampling distribution, and the parameters of the bridging densities (including β), among others. As observed in Section 5.2.1 tuning all of these parameters may lead to considerable performance improvements. 4