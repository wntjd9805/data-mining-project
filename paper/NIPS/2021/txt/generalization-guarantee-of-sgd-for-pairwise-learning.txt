Abstract
Recently, there is a growing interest in studying pairwise learning since it includes many important machine learning tasks as speciﬁc examples, e.g., metric learning,
AUC maximization and ranking. While stochastic gradient descent (SGD) is an efﬁcient method, there is a lacking study on its generalization behavior for pairwise learning. In this paper, we present a systematic study on the generalization analysis of SGD for pairwise learning to understand the balance between generalization and optimization. We develop a novel high-probability generalization bound for uniformly-stable algorithms to incorporate the variance information for better generalization, based on which we establish the ﬁrst nonsmooth learning algorithm to achieve almost optimal high-probability and dimension-independent excess risk bounds with O(n) gradient computations. We consider both convex and nonconvex pairwise learning problems. Our stability analysis for convex problems shows how the interpolation can help generalization. We establish a uniform convergence of gradients, and apply it to derive the ﬁrst excess risk bounds on population gradients for nonconvex pairwise learning. Finally, we extend our stability analysis to pairwise learning with gradient-dominated problems. 1

Introduction
Many machine learning problems can be formulated as learning with pairwise loss functions, where the performance of the associated models needs to be quantiﬁed on a pair of training examples.
Representative problems include AUC maximization [14, 25, 42, 63, 66], metric learning [8, 31], ranking [1, 13] and learning with minimum error entropy loss functions [29]. For example, in supervised metric learning we wish to ﬁnd a distance function between pairs of examples so that examples within the same class are relatively close while examples from different classes are far apart from each other. In ranking, we aim to ﬁnd a function to predict the ordering of examples. This motivates the recent growing interest in a unifying study of these problems, under the framework of pairwise learning [29, 32, 40, 58].
Stochastic gradient descent (SGD) is a workhorse for machine learning due to its cheap computation complexity, simplicity and efﬁciency [7, 20, 49, 53, 62, 65]. SGD iteratively updates the model based on stochastic gradients computed on one or several randomly selected training examples, which can achieve sample-size independent iteration complexity for a prescribed optimization accuracy.
This is especially attractive for pairwise learning as the objective function involves O(n2) terms for problems with n training examples. An important problem on SGD is to understand its generalization performance, i.e., how the models trained by SGD would behave on testing examples. While there are some interesting work on the generalization analysis of SGD for pointwise learning [9, 10, 28, 36, 39], there is much less work on SGD for pairwise learning. A notable difference between pairwise learning 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
and pointwise learning is that the objective function in pairwise learning involves O(n2) dependent terms, which introduces a difﬁculty in handling this dependency. For example, one needs to decouple this dependency to apply concentration inequalities established for independent data. Furthermore, for algorithmic stability analysis, a perturbation of the training dataset by a single example can change
O(n) terms in the objective function, which is more challenging than stability analysis of pointwise learning. To our best knowledge, the only work on generalization analysis of SGD for pairwise learning are [40, 55, 59]. However, their analysis requires restrictive assumptions on convexity, smoothness and Lipschitz continuity of loss functions. Furthermore, they fail to incorporate the interpolation (low noise) assumption into their generalization guarantee.
In this paper, we initialize a systematic generalization analysis of SGD for pairwise learning under general assumptions. Our contributions are listed as follows. 1. We develop a novel high-probability generalization bound for uniformly-stable algorithms, which incorporates the variance information to improve the learning performance. We apply this result to n) (up to a log factor) for an develop the ﬁrst dimension-independent high-probability bound O(1/ algorithm with O(n) gradient computations to solve nonsmooth learning problems.
√ 2. We study the stability and generalization guarantee of SGD for pairwise learning with convex loss functions, covering both smooth and nonsmooth problems. Our analysis suggests an early-stopping n) and O(1/(nσ)) for convex strategy for getting excess population risk bounds of the order O(1/ and σ-strongly convex problems, respectively. Under an interpolation or a low noise assumption, we improve our excess risk bounds to O(1/n) by exploiting the smoothness assumption.
√ 3. We provide the ﬁrst generalization analysis of SGD for pairwise learning with nonconvex loss functions. We establish a uniform convergence of empirical gradients to population gradients by showing its connection to Rademacher chaos complexities. We then apply this uniform convergence to develop high-probability generalization guarantees for general nonconvex pairwise learning. Under a gradient dominance assumption, our stability analysis gives dimension-independent bounds.
The paper is organized as follows. We survey the related work in Section 2 and give the problem formulation in Section 3. We study convex and nonconvex pairwise learning in Section 4 and Section 5, respectively. Conclusion is given in Section 6. In the appendix, we present all the proofs, speciﬁc examples of pairwise learning and preliminary experimental results. 2