Abstract
We study Byzantine collaborative learning, where n nodes seek to collectively learn from each others’ local data. The data distribution may vary from one node to another. No node is trusted, and f < n nodes can behave arbitrarily. We prove that collaborative learning is equivalent to a new form of agreement, which we call averaging agreement. In this problem, nodes start each with an initial vector and seek to approximately agree on a common vector, which is close to the average of honest nodes’ initial vectors. We present two asynchronous solutions to averaging agreement, each we prove optimal according to some dimension. The ﬁrst, based on the minimum-diameter averaging, requires n ≥ 6f +1, but achieves asymptotically the best-possible averaging constant up to a multiplicative constant. The second, based on reliable broadcast and coordinate-wise trimmed mean, achieves optimal
Byzantine resilience, i.e., n ≥ 3f + 1. Each of these algorithms induces an optimal
Byzantine collaborative learning protocol. In particular, our equivalence yields new impossibility theorems on what any collaborative learning algorithm can achieve in adversarial and heterogeneous environments. 1

Introduction
The distributed nature of data, the prohibitive cost of data transfers and the privacy concerns all call for collaborative machine learning. The idea consists for each machine to keep its data locally and to
“simply” exchange with other machines what it learned so far. If all machines correctly communicate and execute the algorithms assigned to them, collaborative learning is rather easy. It can be achieved through the standard workhorse optimization algorithm: stochastic gradient descent (SGD) [37], which can be effectively distributed through averaging [26].
∗Authors are listed alphabetically. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
But in a practical distributed setting, hardware components may crash, software can be buggy, communications can be slowed down, data can be corrupted and machines can be hacked. Besides, large-scale machine learning systems are trained on user-generated data, which may be crafted maliciously. For example, recommendation algorithms have such a large inﬂuence on social medias that there are huge incentives from industries and governments to fabricate data that bias the learning
In the parlance of algorithms and increase the visibility of some contents over others [6, 33]. distributed computing, “nodes" can be Byzantine [28], i.e., they can behave arbitrarily maliciously, to confuse the system. Given that machine learning (ML) is now used in many critical applications (e.g., driving, medication, content moderation), its ability to tolerate Byzantine behavior is of paramount importance.
In this paper, we precisely deﬁne and address, for the ﬁrst time, the problem of collaborative learning in a fully decentralized, Byzantine, heterogeneous and asynchronous environment with non-convex loss functions. We consider n nodes, which may be machines or different accounts on a social media.
Each node has its own local data, drawn from data distributions that may greatly vary across nodes.
The nodes seek to collectively learn from each other, without however exchanging their data. None of the nodes is trusted, and any f < n nodes can be Byzantine.
Contributions. We ﬁrst precisely formulate the collaborative learning problem. Then, we give our main contribution: an equivalence between collaborative learning and a new more abstract problem we call averaging agreement. More precisely, we provide two reductions: from collaborative learning to averaging agreement and from averaging agreement to collaborative learning. We prove that both reductions essentially preserve the correctness guarantees on the output. The former reduction is the most challenging one to design and to prove correct. First, to update nodes’ models, we use averaging agreement to aggregate nodes’ stochastic gradients. Then, to avoid model drift, we regularly “contract” the nodes’ models using averaging agreement. To prove correctness, we bound the diameter of honest nodes’ models, and we analyze the effective gradient [12]. We then carefully select a halting iteration, for which correctness can be guaranteed.
Our tight reduction allows to derive both impossibility results and optimal algorithms for collaborative learning by studying the “simpler” averaging agreement problem. We prove lower bounds on the correctness and Byzantine resilience that any averaging agreement algorithm can achieve, which implies the same lower bounds for collaborative learning. We then propose two optimal algorithms for averaging agreement. Our ﬁrst algorithm is asymptotically optimal with respect to correctness, up to a multiplicative constant, when nearly all nodes are honest. Our second algorithm achieves optimal
Byzantine resilience. Each of these algorithms induces an optimal collaborative learning protocol.
While our algorithms apply in a very general setting, they can easily be tweaked for more speciﬁc settings with additional assumptions, such as the presence of a trusted parameter server [30], the assumption of homogeneous (i.e. i.i.d.) local data or synchrony (Section 3.3 and Section 6).
We implemented and evaluated our algorithms in a distributed environment with 3 ResNet models [24].
More speciﬁcally, we present their throughput overhead when compared to a non–robust collaborative learning approach with both i.i.d. and non–i.i.d. data (i.e. we highlight the cost of heterogeneity).
Essentially, we show that our ﬁrst algorithm is more lightweight with a slowdown of at most 1.7X in the i.i.d. case and almost the triple in the non–i.i.d. case. Our second algorithm adds slightly more than an order of magnitude overhead: here the non-i.i.d. slowdown is twice the i.i.d. one.