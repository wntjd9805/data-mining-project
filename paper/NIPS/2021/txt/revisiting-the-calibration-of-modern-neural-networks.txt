Abstract
Accurate estimation of predictive uncertainty (model calibration) is essential for the safe application of neural networks. Many instances of miscalibration in modern neural networks have been reported, suggesting a trend that newer, more accurate models produce poorly calibrated predictions. Here, we revisit this question for recent state-of-the-art image classiﬁcation models. We systematically relate model calibration and accuracy, and ﬁnd that the most recent models, notably those not using convolutions, are among the best calibrated. Trends observed in prior model generations, such as decay of calibration with distribution shift or model size, are less pronounced in recent architectures. We also show that model size and amount of pretraining do not fully explain these differences, suggesting that architecture is a major determinant of calibration properties. 1

Introduction
Neural networks, especially vision models, are increasingly used in safety-critical applications such as autonomous driving (Bojarski et al., 2016), medical diagnosis (Esteva et al., 2017; Jiang et al., 2012), and meteorological forecasting (Sønderby et al., 2020). For such applications, it is essential that model predictions are not just accurate, but also well calibrated. Model calibration refers to the accuracy with which the scores provided by the model reﬂect its predictive uncertainty. For example, in a medical application, we would like to defer images for which the model makes low-conﬁdence predictions to a physician for review (Kompa et al., 2021). Skipping human review due to conﬁdent, but incorrect, predictions, could have disastrous consequences.
While intense research and engineering effort has focused on improving the predictive accuracy of models, less attention has been given to model calibration. In fact, over the last few years, there have been many reports that calibration of modern neural networks can be surprisingly poor, despite the advances in accuracy (e.g. Guo et al. 2017; Lakshminarayanan et al. 2017; Malinin & Gales 2018;
Thulasidasan et al. 2019; Hendrycks et al. 2020b; Ovadia et al. 2019; Wenzel et al. 2020; Havasi et al. 2021; Rahaman & Thiery 2020; Leathart & Polaczuk 2020). Some works suggest a trend for larger, more accurate models to be worse calibrated (Guo et al., 2017).
These concerns are more relevant than ever, since the architecture size, amount of training data, and computing power used by state-of-the-art models continue to increase. At the same time, rapid advances in model architecture (Tolstikhin et al., 2021; Dosovitskiy et al., 2021) and training approaches (Chen et al., 2020; Mahajan et al., 2018; Radford et al., 2021) raise the question whether past results on calibration, largely obtained on standard convolutional architectures, extend to current state-of-the-art models. Since model advances are quickly translated to real-world, safety-critical applications (e.g. Mustafa et al. 2021), there is an urgent need to re-assess the calibration properties of current state-of-the-art models. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
Contributions. To address this need, we provide a systematic comparison of recent image classiﬁ-cation models, relating their accuracy, calibration, and design features. We ﬁnd that: 1. The best current models, including the non-convolutional MLP-Mixer (Tolstikhin et al., 2021) and Vision Transformers (Dosovitskiy et al., 2021), are well calibrated compared to past models and their performance is more robust to distribution shift. 2. In-distribution calibration slightly deteriorates with increasing model size, but this is out-weighed by a simultaneous improvement in accuracy. 3. Under distribution shift, calibration improves with model size, reversing the trend seen in-distribution. 4. Accuracy and calibration are correlated under distribution shift, such that optimizing for accuracy may also beneﬁt calibration. 5. Model size, pretraining duration, and pretraining dataset size cannot fully explain differences in calibration properties between model families.
Our results suggest that further improvements in model accuracy will continue to beneﬁt calibration.
They also hint at architecture as an important determinant of model calibration. We provide code and a large dataset of calibration measurements, comprising 180 distinct models from 16 families, each evaluated on 79 ImageNet-scale datasets and 28 metric variants.1 2