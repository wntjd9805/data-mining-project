Abstract
Attention mechanism has shown great performance and efﬁciency in a lot of deep learning models, in which relative position encoding plays a crucial role.
However, when introducing attention to manifolds, there is no canonical local coordinate system to parameterize neighborhoods. To address this issue, we propose an equivariant transformer to make our model agnostic to the orientation of local coordinate systems (i.e., gauge equivariant), which employs multi-head self-attention to jointly incorporate both position-based and content-based information.
To enhance expressive ability, we adopt regular ﬁeld of cyclic groups as feature
ﬁelds in intermediate layers, and propose a novel method to parallel transport the feature vectors in these ﬁelds. In addition, we project the position vector of each point onto its local coordinate system to disentangle the orientation of the coordinate system in ambient space (i.e., global coordinate system), achieving rotation invariance. To the best of our knowledge, we are the ﬁrst to introduce gauge equivariance to self-attention, thus name our model Gauge Equivariant
Transformer (GET), which can be efﬁciently implemented on triangle meshes.
Extensive experiments show that GET achieves state-of-the-art performance on two common recognition tasks. 1

Introduction
Recently, Transformer has dominated the area of Natural Language Processing [48]. Its key advantage over previous methods is its ability to attend to the most relevant part in a given context. This is largely attributed to its self-attention operator, which computes the similarity between representations of words in sequences in the form of attention scores. Because of the superiority, researchers start to apply Transformer to other learning areas, including Computer Vision [26, 53, 16, 59] and Graphs
[49].
In this work, we aim at applying Transformer to manifolds. Unlike regular data, such as images, where each neighbor owns a clearly quantiﬁed relative position to its center in a canonical coordinate system, irregular data do not have a uniquely deﬁned local coordinate system for the neighbors, resulting in the problem of orientation ambiguity, which directly obstructs the Transformer to numerically intake the relative position information.
Several works have been proposed to deal with the rotation ambiguity problem, in which a promising way is to exploit gauge equivariance. While most of them are not rotation invariant to global
∗Work was done during an internship at JD Explore Academy.
∗Equal contribution. Sorted by tossing the coin.
†Corresponding author. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
coordinate system, all of them are established on convolution, i.e., equal attention to neighboring points and neglect to content-based information. So it is desirable to propose a gauge equivariant transformer with the support of rotation invariance.
In this paper, we propose Gauge Equivariant Transformer, named GET for short, which employs multi-head self-attention to simultaneously utilize position-based and content-based information, and is both gauge equivariant and rotation invariant. To achieve rotation invariance, we ﬁrst project xyz coordinates in a global coordinate system onto a local coordinate frame, and then design equivariant transformers to overcome the orientation ambiguity problem of local coordinate systems. We adopt the regular ﬁeld proposed in [13] as feature ﬁelds of intermediate layers, since the representation of regular ﬁeld commutes with element-wise activation functions. After that, we propose a novel method to accommodate parallel transport of feature vectors in regular ﬁeld with any rotation angles. Since we adopt regular ﬁelds in intermediate layers, we make a relaxation such that they are equivariant only for gauge transformations of angles that are multiples of 2π/N . Exact equivariance can be guaranteed for gauge transformations at multiples of 2π/N , and an equivariance error bound can be obtained for all other angles. In experiments, our model shows better performance and greater parameter efﬁciency than all baseline methods. Our contributions can be summarized as follows:
• We propose GET, which incorporates attention and achieves both gauge equivariance and rotation invariance with superior expressive power. GET is mathematically proven to be exactly equivariant on angles that are multiples of 2π/N (N ∈ N∗), and an equivariance error bound is derived for other angles to guarantee the overall approximate equivariance property.
• We carefully design the model input to ensure that it is irrelevant to the global coordinate system, only depending on the choice of gauge. Our model achieves rotation invariance with the assistance of gauge equivariance.
• We propose a novel method to parallel transport the feature vectors in the regular ﬁeld by extending the representation of a cyclic group to any angle rotation group. Compared to previous methods using truncation or interpolation, our extension can preserve more geometric information.
• We elevate the model performance by designing a new approach which incorporates Taylor expansion in solving the equivariance constraint, which has a better approximation ability in local neighborhoods.
• We conﬁrm the superiority of our model via extensive experiments. Our model outperforms the HSN model on the SHREC dataset by 3.1% accuracy, and outperforms the MeshCNN model on the Human Body Segmentation dataset by 0.3% accuracy with much fewer parameters, presenting state-of-the-art performance. 2