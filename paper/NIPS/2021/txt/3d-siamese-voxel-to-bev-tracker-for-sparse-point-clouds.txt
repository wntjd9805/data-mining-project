Abstract 3D object tracking in point clouds is still a challenging problem due to the sparsity of LiDAR points in dynamic environments. In this work, we propose a Siamese voxel-to-BEV tracker, which can signiﬁcantly improve the tracking performance in sparse 3D point clouds. Speciﬁcally, it consists of a Siamese shape-aware feature learning network and a voxel-to-BEV target localization network. The Siamese shape-aware feature learning network can capture 3D shape information of the object to learn the discriminative features of the object so that the potential target from the background in sparse point clouds can be identiﬁed. To this end, we
ﬁrst perform template feature embedding to embed the template’s feature into the potential target and then generate a dense 3D shape to characterize the shape information of the potential target. For localizing the tracked target, the voxel-to-BEV target localization network regresses the target’s 2D center and the z-axis center from the dense bird’s eye view (BEV) feature map in an anchor-free manner.
Concretely, we compress the voxelized point cloud along z-axis through max pooling to obtain a dense BEV feature map, where the regression of the 2D center and the z-axis center can be performed more effectively. Extensive evaluation on the KITTI and nuScenes datasets shows that our method signiﬁcantly outperforms the current state-of-the-art methods by a large margin. Code is available at https:
//github.com/fpthink/V2B. 1

Introduction
Object tracking is an essential task in computer vision and has been widely in various applications, such as autonomous vehicle, mobile robotics, and augmented reality. In the past few years, many efforts [33, 2, 12, 64] have been made on 2D object tracking from RGB data. Recently, with the development of 3D sensor such as LiDAR and Kinect, 3D object tracking [37, 72, 53, 28, 42] has attracted more attention. Lately, some pioneering works [22, 18, 52] have focused on point cloud based 3D object tracking. However, due to the sparsity of 3D point clouds, 3D object tracking on point clouds is still a challenging task.
Few works are dedicated to 3D single object tracking (SOT) with only point clouds. As a pioneer,
SC3D [21] is the ﬁrst 3D Siamese tracker that performs matching between the template and candidate 3D target proposals generated by Kalman ﬁltering [22]. Furthermore, a shape completion network is used to enhance shape information of candidate proposals in sparse point clouds, thereby improving the accuracy of matching. However, SC3D cannot perform the end-to-end training, and consumes
†Equal Contributions, ∗Corresponding authors.
Le Hui, Lingpeng Wang, Mingmei Cheng, Jin Xie, and Jian Yang are with PCA Lab, Key Lab of Intelligent
Perception and Systems for High-Dimensional Information of Ministry of Education, and Jiangsu Key Lab of
Image and Video Understanding for Social Security, School of Computer Science and Engineering, Nanjing
University of Science and Technology, China. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
much time when matching exhaustive candidate proposals. Towards these concerns, Qi et al. [52] proposed an end-to-end framework termed P2B, which ﬁrst localizes potential target centers in the search area via Hough voting [48], and then aggregates vote clusters to generate target proposals.
Nonetheless, when facing sparse scenes, P2B may not be able to track the object accurately, or even lose the tracked object. On the one hand, it adopts random sampling to generate initial seed points, which further exacerbates the sparsity of point clouds. On the other hand, it is difﬁcult to generate high-quality target proposals on sparse 3D point clouds. Although SC3D has enhanced shape information of candidate proposals, the low-quality candidate proposals obtained from sparse point clouds still degrade tacking performance.
As shown in Fig. 1, we count the number of points on KITTI’s cars.
It can be found that 51% of cars have less than 100 points, and only 7% of cars have more than 2500 points. When facing sparse point clouds, it is difﬁcult to distinguish the target from the background due to the sparsity of point clouds. Therefore, how to improve the tracking performance in sparse scenes should be considered. Our intuition consists of two folds.
First, enhancing shape information of target will provide discriminative information to distinguish the target from the background, especially in sparse point clouds. Second, due to the sparsity of the point cloud, it is difﬁcult to regress the target center in 3D space.
We hence consider compressing the sparse 3D space into a dense 2D space, and perform center regression in the dense 2D space to improve tracking performance.
Figure 1: Statistics of the number of points on KITTI’s cars. Cars are colored in red.
In this paper, we propose a novel Siamese voxel-to-BEV (V2B) tracker, which aims to improve the tracking performance of 3D single object tracking, especially in sparse point clouds. We illustrate our framework in Fig. 2. We ﬁrst feed the template and search area into the Siamese network to extract point features, respectively. Then, we employ the global and local template feature embedding to strengthen the correlation between the template and search area so that the potential target in the search area can be effectively localized. After that, we introduce a shape-aware feature learning module to learn the dense geometric features of the potential target, where the complete and dense point clouds of the target are generated. Thus, the geometric structures of the potential target can be captured better so that the potential target can be effectively distinguished from the background in the search area. Finally, we develop a voxel-to-BEV target localization network to localize the target in the search area. In order to avoid using the low-quality proposals on sparse point clouds for target center prediction, we directly regress the 3D center of the target with the highest response in the dense bird’s eye view (BEV) feature map, where the dense BEV feature map is generated by voxelizing the learned dense geometric features and performing max-pooling along the z axis. Thus, with the constructed dense BEV feature map, for sparse point clouds, our method can more accurately localize the target center without any proposal.
In summary, we propose a novel Siamese voxel-to-BEV tracker, which can signiﬁcantly improve tracking performance, especially in sparse point clouds. We develop a Siamese shape-aware feature learning network that can introduce shape information to enhance the discrimination of the potential target in the search area. We develop a voxel-to-BEV target localization network, which can accurately detect the 3D target’s center in the dense BEV space compared to sparse 3D space. Extensive results show that our method has achieved new state-of-the-art results on the KITTI dataset [20], and has a good generalization ability on the nuScenes [6] dataset. 2