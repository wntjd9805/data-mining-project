Abstract
Large sparse linear systems of equations are ubiquitous in science and engineering, such as those arising from discretizations of partial differential equations. Alge-braic multigrid (AMG) methods are one of the most common methods of solving such linear systems, with an extensive body of underlying mathematical theory. A system of linear equations deﬁnes a graph on the set of unknowns and each level of a multigrid solver requires the selection of an appropriate coarse graph along with restriction and interpolation operators that map to and from the coarse represen-tation. The efﬁciency of the multigrid solver depends critically on this selection and many selection methods have been developed over the years. Recently, it has been demonstrated that it is possible to directly learn the AMG interpolation and restriction operators, given a coarse graph selection. In this paper, we consider the complementary problem of learning to coarsen graphs for a multigrid solver, a necessary step in developing fully learnable AMG methods. We propose a method using a reinforcement learning (RL) agent based on graph neural networks (GNNs), which can learn to perform graph coarsening on small planar training graphs and then be applied to unstructured large planar graphs, assuming bounded node degree.
We demonstrate that this method can produce better coarse graphs than existing algorithms, even as the graph size increases and other properties of the graph are varied. We also propose an efﬁcient inference procedure for performing graph coarsening that results in linear time complexity in graph size. 1

Introduction
Algebraic multigrid (AMG) [1, 2, 3] is a widely used method for approximating the solution to large, sparse linear systems, particularly those arising from elliptic boundary value problems. AMG has proven to be effective for a variety of problems, including partial differential equations (PDEs), image and video processing [4, 5], and sparse Markov chains [6]. The focus of this work is on developing reinforcement learning agents to construct optimal AMG methods for improved efﬁciency and robustness. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
AMG algorithms aim to solve a sparse linear system of the form
Ax = b (1) by successively constructing coarser representations of the problem. Constructing an AMG method is effectively a graph coarsening problem, to deﬁne a coarse representation of Acxc = bc, and an interpolation problem, to deﬁne the transfer of solutions between the coarse and original (or ﬁne) representation of the problem.
AMG has strong theoretical support for model problems [2, 7, 8], but it is important to recognize that the classical algorithm for AMG relies heavily on heuristics. Thus, there is a persistent need to both improve the general theoretical foundations of AMG [9, 10, 11, 12] and to improve its efﬁciency, including by leveraging recent advances in machine learning. There are two main heuristics used within AMG, namely selecting the coarse nodes for a given matrix (or graph) and construction of the interpolation operator between coarse and ﬁne graphs. Recently, there have been studies on developing machine learning techniques to construct the interpolation operator [13, 14]. However, these methods require prior knowledge of the ﬁne-coarse partitioning and the interpolation sparsity pattern. Hence, developing a learnable coarse-grid selection method is a necessary step in the development of fully learnable AMG algorithms. While much heuristic work has been done on the graph coarsening problem in this context (e.g., [15, 16]), optimal partitioning into coarse and ﬁne nodes is known to be NP hard [17]. Nevertheless, the ML-based coarsening scheme that we propose yields a strictly better coarsening for a class of AMG solvers on planar grids compared to previous algorithms. We expand on this notion in Appendix D, where we note the limitations of comparing directly to the observed convergence of AMG algorithms based only on heuristics.
As we review in Section 3.1, the graph of A in (1) can be partitioned into coarse and ﬁne (a.k.a. ﬁne-only) nodes; this has previously been presented as an optimization problem [17] and accompanied with a greedy algorithm for approximating the solution. However, for computational feasibility, this approach is rather simple and is known to break down in some cases [18]. An alternative is to use combinatorial optimization approaches such as simulated annealing [18]. While this produces good coarsenings, it is infeasibly expensive for large graphs. In this study, we develop a reinforcement learning method to achieve scalable (linear order in graph size) and high-quality
ﬁne-coarse partitioning, focusing on discretizations of the 2D Poisson equation,
∆φ = f,
− (2) where ∆ is the Laplace operator and f (x, y) and φ(x, y) are real-valued functions.
To the best of our knowledge, this work is the ﬁrst to approach AMG coarsening using machine learning. Based on the optimization formulation of the coarsening problem introduced in [17] and outlined in more detail in Appendix D, we train a dueling double-DQN agent with topology adaptive convolution layers (TAGCN) [19] to yield a more efﬁcient coarsening, as compared to previous studies. This optimization problem is tightly coupled, so that selecting one node to be in the coarse problem affects the eligibility of its neighbouring nodes for selection. Therefore, the process of coarsening is temporal in nature, and we model it as an RL problem, as discussed in Section 4. By using the optimization framework [17] as our starting point, we are able to prove that our RL method produces a convergent multigrid solver, and by combining evaluation with a graph decomposition algorithm [20, 21] we are able to coarsen efﬁciently.
The main contribution of this paper is to propose an RL method to train a grid-coarsening agent for the 2D Poisson problem which: (1) can coarsen arbitrary unstructured planar grids, including those much larger than the training grids, assuming bounded node degree, (2) can coarsen a grid with computational expense that is linear in the grid size (Theorem 2), (3) is guaranteed to produce a convergent multigrid method (Theorem 3), and (4) produces superior coarse grids to existing heuristic methods (Section 5). 2