Abstract
Recent advances in self-supervised learning have dramatically improved the state of the art on a wide variety of tasks. However, research in language model pre-training has mostly focused on natural languages, and it is unclear whether models like BERT and its variants provide the best pre-training when applied to other modalities, such as source code. In this paper, we introduce a new pre-training objective, DOBF, that leverages the structural aspect of programming languages and pre-trains a model to recover the original version of obfuscated source code.
We show that models pre-trained with DOBF signiﬁcantly outperform existing approaches on multiple downstream tasks, providing relative improvements of up to 12.2% in unsupervised code translation, and 5.3% in natural language code search. Incidentally, we found that our pre-trained model is able to deobfuscate fully obfuscated source ﬁles, and to suggest descriptive variable names. 1

Introduction
Model pre-training with self-supervised methods such as BERT Devlin et al. [2018], RoBERTa Liu et al. [2019], XLM Lample and Conneau [2019] or XLNet Yang et al. [2019], has become ubiquitous in Natural Language Processing (NLP), and led to signiﬁcant improvements in many tasks. These approaches are based on the Masked Language Modeling (MLM) objective, which consists in randomly masking words from an input text, and training a model to recover the original input.
In the original approach proposed by Devlin et al. [2018], a fraction of selected masked words is replaced by masked tokens, another is replaced by random words, and another remains unchanged.
Since then, a myriad of studies have proposed to modify the MLM objective, either by masking contiguous spans of text Song et al. [2019], Joshi et al. [2020], masking named entities and phrases
Sun et al. [2019], sampling masked words according to their frequencies Lample and Conneau [2019], replacing words with plausible alternatives Clark et al. [2020], etc. Overall, most of these pre-training objectives boil down to denoising auto-encoding tasks with different methods to add noise to the input, using arbitrary noise functions. In our case, we are interested in pre-training deep learning models for programming languages. As in natural language, pre-training was shown to be effective for source code Feng et al. [2020], Roziere et al. [2020]. However, these studies both rely on the original MLM objective proposed by Devlin et al. [2018], which was initially designed for natural languages and does not leverage the particular structure of source code. We argue that this objective
⇤Equal contribution. The order was determined randomly. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
is actually suboptimal in the context of programming languages, and propose a new objective based on deobfuscation of identiﬁer names in source code.
Code obfuscation consists in modifying source code in order to make it harder for humans to understand, or smaller while keeping its behaviour unchanged. In some ancient interpreted languages, name minimization could also reduce the memory usage of the program. Today, it is used to protect intellectual property by preventing people from understanding and modifying the code, to prevent malware detection, and to compress programs (e.g. Javascript code) to reduce network payload sizes.
Moreover, C compilers discard variable names, and current rule-based and neural-based decompilers generate obfuscated C code with uninformative variable names Fu et al. [2019]. Obfuscators typically apply several transformations to the code. While some operations can be reversed (e.g. dead code injection), the obfuscation of identiﬁer names—renaming every variable, method and class with uninformative names—is irreversible and has a substantial impact on code comprehension Gellenbeck and Cook [1991], Takang et al. [1996], Lawrie et al. [2006].
By analyzing the overall structure of an obfuscated ﬁle, an experienced programmer can always, with time, understand the meaning of the obfuscated code. For instance, in the obfuscated example in
Figure 1, one can recognize the function and guess that it implements a breadth-ﬁrst search algorithm.
We also expect neural networks, that excel in pattern recognition, to perform well on this task. We propose to pre-train a model to revert the obfuscation function, by training a sequence-to-sequence (seq2seq) model to convert obfuscated functions, where names of functions and variables have been replaced by uninformative names, back to their original forms. Suggesting proper variable and function names is a difﬁcult task that requires to understand what the program does. In the context of source code, it is a more sensible, but also a more difﬁcult task than MLM. Indeed, we observe (c.f. Figure 1) that predicting the content of randomly masked tokens is usually quite simple, as it often boils down to making syntax related predictions (e.g. predicting that was has been masked out is a parenthesis, a semi-column, etc.). These simple predictions actually provide little training signal to the model. In practice, MLM also masks out variable names, but if a given variable appears multiple times in a function, it will be easy for the model to simply copy its name from one of the other occurrences. Our model does not have this issue, as all occurrences of masked variables are replaced by the same VAR_i special tokens.
In this paper, we make the following contributions:
• We present DOBF, a new pre-training objective based on deobfuscation, and show its effectiveness on multiple programming languages.
• We show that DOBF signiﬁcantly outperform MLM (e.g. BERT) on multiple tasks such as code search, code summarization or unsupervised code translation. We show that pre-training methods based on DOBF outperform all existing pre-training methods on all the considered tasks.
• We show that, by design, models pre-trained with DOBF have interesting applications and can be used to understand functions with uninformative identiﬁer names. Besides, the model is able to successfully deobfuscate fully obfuscated source ﬁles.
Our method improves other machine learning methods for programming languages. Automatic deob-fuscation and identiﬁer name proposal can also make code more accessible, and facilitate innovation and malware detection. Conversely, automatic deobfuscation could facilitate theft of proprietary code, therefore hindering the distribution of software and reducing investments in innovative softwares.
Socially undesirable uses of our work (e.g. intellectual property theft) are targetable legally, while desirable ones (e.g. malware detection, IDE tools) can be seen as primarily technical problems.
Therefore, we believe that the impact of our work will be mostly positive. 2