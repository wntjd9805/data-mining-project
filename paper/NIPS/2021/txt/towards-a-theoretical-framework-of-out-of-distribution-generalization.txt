Abstract
Generalization to out-of-distribution (OOD) data is one of the central problems in modern machine learning. Recently, there is a surge of attempts to propose algorithms that mainly build upon the idea of extracting invariant features. Al-though intuitively reasonable, theoretical understanding of what kind of invariance can guarantee OOD generalization is still limited, and generalization to arbitrary out-of-distribution is clearly impossible. In this work, we take the ﬁrst step towards rigorous and quantitative deﬁnitions of 1) what is OOD; and 2) what does it mean by saying an OOD problem is learnable. We also introduce a new concept of expan-sion function, which characterizes to what extent the variance is ampliﬁed in the test domains over the training domains, and therefore give a quantitative meaning of invariant features. Based on these, we prove OOD generalization error bounds.
It turns out that OOD generalization largely depends on the expansion function.
As recently pointed out by [21], any OOD learning algorithm without a model selection module is incomplete. Our theory naturally induces a model selection criterion. Extensive experiments on benchmark OOD datasets demonstrate that our model selection criterion has a signiﬁcant advantage over baselines. 1

Introduction
One of the most fundamental assumptions of classic supervised learning is the “i.i.d. assumption”, which states that the training and the test data are independent and identically distributed. However, this assumption can be easily violated in a reality [8, 10, 11, 17, 38, 48, 56] where the test data usually have a different distribution than the training data. This motivates the research on the out-of-distribution (OOD) generalization, or domain generalization problem, which assumes access only to data drawn from a set Eavail of available domains during training, and the goal is to generalize to a larger domain set Eall including unseen domains.
To generalize to OOD data, most existing algorithms attempt to learn features that are invariant to a certain extent across training domains in the hope that such invariance also holds in unseen domains.
For example, distributional matching-based methods [20, 35, 55] seek to learn features that have the same distribution across different domains; IRM [5] and its variants [1, 32, 33] learn feature representations such that the optimal linear classiﬁer on top of the representation matches across domains. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
Though the idea of learning invariant features is intuitively reasonable, there is only limited theoretical understanding of what kind of invariance can guarantee OOD generalization. Clearly, generalization to an arbitrary out-of-distribution domain is impossible and in practice, the features can hardly be absolutely invariant from Eavail to Eall unless all the domains are identical. So it is necessary to
ﬁrst formulate what OOD data can be generalized to, or, what is the relation between the available training domain set Eavail and the entire domain set Eall. Meanwhile, to what extent the invariance of features on Eavail can be preserved in Eall should be rigorously characterized.
In this paper, we take the ﬁrst step towards a general OOD framework by quantitatively formalizing the relationship between Eavail and Eall in terms of the distributions of features and provide OOD generalization guarantees based on our quantiﬁcation of the difﬁculty of OOD generalization problem.
Speciﬁcally, we ﬁrst rigorously formulate the intuition of invariant features used in previous works by introducing the “variation” and “informativeness” (Deﬁnition 3.1 and 3.2) of each feature. Our theoretical insight can then be informally stated as: for learnable OOD problems, if a feature is informative for the classiﬁcation task as well as invariant over Eavail, then it is still invariant over
Eall. In other words, invariance of informative features in Eavail can be preserved in Eall. We further introduce a class of functions, dubbed expansion function (Deﬁnition 3.3), to quantitatively characterize to what extent the variance of features on Eavail is ampliﬁed on Eall.
Based on our formulation, we derive theoretical guarantees on the OOD generalization error, i.e., the gap of largest error between the domain in Eavail and domain in Eall. Speciﬁcally, we prove the upper and lower bound of OOD generalization error in terms of the expansion function and the variation of learned features over Eavail. Our results theoretically conﬁrm that 1) the expansion function can reﬂect the difﬁculty of OOD generalization problem, i.e., problems with more rapidly increasing expansion functions are harder and have worse generalization guarantees; 2) the generalization error gap can tend to zero when the variation of learned features tend to zero, so minimizing the variation in Eavail can reduce the generalization error.
As pointed out by Gulrajani and Lopez-Paz [21], any OOD algorithm without a speciﬁed model selection criterion is not complete. Since Eall is unseen, hyper-parameters can only be chosen according to Eavail. Previous selection methods mainly focus on validation accuracy over Eavail, which is only a biased metric of OOD performance. On the contrary, a promising model selection method should instead be predictive of OOD performance. Inspired by our bounds, we propose a model selection method to select models with high validation accuracy and low variation, which corresponds to the upper bound of OOD error. The introduction of a model’s variation relieves the problem of classic selection methods, in which models that overﬁt Eavail tend to be selected.
Experimental results show that our method can outperform baselines and select models with higher
OOD accuracy.
Contributions. We summarize our major contributions here:
• We introduce a quantitative and rigorous formulation of OOD generalization problem that charac-terizes the relation of invariance over the training domain set Eavail and test domain set Eall. The core quantity in our characterization, the expansion function, determines the difﬁculty of an OOD generalization problem.
• We prove novel OOD generalization error bounds based on our formulation. The upper and lower bounds together indicate that the expansion function well characterizes the OOD generalization ability of features with different levels of variation.
• We design a model selection criterion that is inspired by our generalization bounds. Our criterion takes both the performance on training domains and the variation of models into consideration and is predictive of OOD performance according to our bounds. Experimental results demonstrate our selection criterion can choose models with higher OOD accuracy.
The rest of the paper is organized as follows: Section 2 is our preliminary. In Section 3, we give our theoretical formulation. Section 4 gives our generalization bound. We propose our model selection method in Section 5. In Section 6 we conduct experiments on expansion function and model selection.
We review more related works in Section 7 and conclude our work in Section 8. 2
2 Preliminary
Throughout the paper, we consider a multi-class classiﬁcation task X → Y = {1, . . . , K}.1 Let Eall be the domain set we want to generalize to, and Eavail ⊆ Eall be the available domain set, i.e., all domains we have during the training procedure. We denote (X e, Y e) to be the input-label pair drawn from the data distribution of domain e. The OOD generalization goal is to ﬁnd a classiﬁer f ∗ that minimizes the worst-domain loss on Eall: f ∗ = argmin f ∈F
L(Eall, f ), L(E, f ) (cid:44) max e∈E
E(cid:2)(cid:96)(cid:0)f (X e), Y e(cid:1)(cid:3) (1) where F : X → RK is the the hypothetical space and (cid:96)(·, ·) is a loss function. Similar to previous works [5, 16, 27, 33], we assume that f can be decomposed into g ◦ h, where g ∈ G : Rd → RK is the top classiﬁer and h : X → Rd is a d-dimensional feature extractor, i.e., h(x) = (φ1(x), φ2(x), . . . , φd(x))(cid:62), φi ∈ Φ.
Here Φ is the set of scalar feature maps which map X to R and d is ﬁxed. We will call each φ ∈ Φ a feature for simplicity. Given a domain e, we denote the d-dimensional random vector h(X e) as he, one-dimensional feature φ(X e) as φe, and the conditional distribution of he, φe given Y e = y as
P(he|y), P(φe|y). For simplicity, we assume the data distribution is balanced in every domain, i.e.,
P (Y e = y) = 1
K , ∀y ∈ Y, e ∈ Eall. Our framework can be easily extended to the case where the balanced assumption is removed, with an additional term corresponding to the imbalance adding to the generalization bounds. 3 Framework of OOD Generalization Problem
The main challenge of formalizing the OOD generalization problem is to mathematically describe the connection between Eavail and Eall and how generalization depends on this relation. Towards this goal, we introduce several quantities to characterize the relation of feature distributions over different domains and bridge Eavail and Eall by expansion function (Deﬁnition 3.3) over the quantities we have introduced. Our framework is motivated by the understanding that, in an OOD generalization task, certain “property” of “good” features in Eavail should be “preserved” in Eall (the reason is described in Section 1). In Section 3.1, we will go into details on what we mean by “property” (variation,
Deﬁnition 3.1), “good” (informativeness, Deﬁnition 3.2), and “preserved” (measured by expansion function). In Section 6.2, we further illustrate the key concepts in our framework by a real-world
OOD problem. 3.1 Formalizing OOD Problem by Quantifying Feature Distribution
We ﬁrst introduce the concepts “variation" and “informativeness" of a feature φ. The ﬁrst one is what we expect to be preserved in Eall and the second one characterizes what features will be considered.
Speciﬁcally, let ρ(P, Q) be a symmetric “distance” of two distributions. Note that ρ can have many choices, like L2 Distance, Total Variation and symmetric KL-divergence, etc. The variation and informativeness are deﬁned as follows:
Deﬁnition 3.1 (Variation). The variation of feature φ(·) across a domain set E is
Vρ(φ, E) = max y∈Y sup e,e(cid:48)∈E
ρ(cid:0)P(φe|y), P(φe(cid:48)
|y)(cid:1). (2)
A feature φ(·) is ε-invariant across E, if ε ≥ V(φ, E) (We omit the subscript ρ in case of no ambiguity).
Deﬁnition 3.2 (Informativeness). The informativeness of feature φ(·) across a domain set E is
Iρ(φ, E) = 1
K(K − 1) min e∈E (cid:88) y(cid:54)=y(cid:48) y,y(cid:48)∈Y
ρ(cid:0)P(φe|y), P(φe|y(cid:48))(cid:1). (3)
A feature φ(·) is δ-informative across E, if δ ≤ I(φ, E). 1Note that our framework can be generalized to other kinds of problems easily. 3
The variation V(φ, E) measures the stability of φ(·) over the domains in E and the informativeness
I(φ, E) captures the ability of φ(·) to distinguish different labels. We would like to highlight that the variation and informativeness are deﬁned on each one-dimensional feature φ(·). Unlike previous distance between distributions deﬁned in d-dimensional space, our deﬁnitions are more reasonable and practical, since it can be easily calculated and analyzed.
We are now ready to introduce the core quantity for connecting Eavail and Eall. Our motivation, as elaborated in the introduction section, is that, if a feature is informative for the classiﬁcation task and invariant over Eavail, then to enable OOD generalization from Eavail to Eall, it should be still invariant over Eall. So the relation between V(φ, Eavail) and V(φ, Eall) of an informative feature captures the feasibility and difﬁculty of OOD generalization. To quantitatively measure this relation, we deﬁne the following function class:
Deﬁnition 3.3 (Expansion Function). We say a function s : R+ ∪ {0} → R+ ∪ {0, +∞} is an expansion function, iff the following properties hold: 1) s(·) is monotonically increasing and s(x) ≥ x, ∀x ≥ 0; 2) limx→0+ s(x) = s(0) = 0.
This function class gives a full characterization of how the variation between Eavail and Eall is related. Based on this function class, we can introduce our formulation of the learnability of OOD generalization as follows:
Deﬁnition 3.4 (Learnability). Let Φ be the feature space and ρ be a distribution distance. We say an OOD generalization problem from Eavail to Eall is learnable if there exists an expansion function s(·) and δ ≥ 0, such that: for all φ ∈ Φ satisfying Iρ(φ, Eavail) ≥ δ, we have s(Vρ(φ, Eavail)) ≥
Vρ(φ, Eall). If such s(·) and δ exist, we further call this problem (s(·), δ)-learnable. If an OOD generalization problem is not learnable, we call it unlearnable.
To understand the intuition and rationality of our formulation, several discussions are in order.
Properties of the expansion function.
In Deﬁnition 3.3, we highlight two properties of the ex-pansion function. The ﬁrst property comes naturally from the monotonicity properties of variation: any ε1-invariant feature is also ε2-invariant for ε2 ≥ ε1; and V(φ, E1) ≤ V(φ, E2) for any E1 ⊆ E2.
The monotonicity also implies that larger Eall will induce larger s(·)2 and it is also harder to be generalized to. From this view, we can see that the scale of s(·) can reﬂect the difﬁculty of OOD generalization. The second property is more crucial since it formulates the intuition that if an informa-tive feature is almost invariant in Eavail, it should remain invariant in Eall. Without this assumption,
OOD generalization can never be guaranteed because we cannot predict whether an invariant and informative feature in Eavail will vary severely in unseen Eall.
Necessity of informativeness. We include a seemingly redundant quantity informativeness in the deﬁnition of learnability. However, this term is necessary because only informative features are responsible for the performance of classiﬁcation. Non-informative but invariant features over Eavail may only capture some noise that is irrelevant to the classiﬁcation problem, and we shall not expect the noise to be invariant over Eall. Moreover, we show in Figure 1 that in practice, many invariant but useless features in Eavail vary a lot in Eall, and adding the constraint of informativeness makes the expansion function reasonable. In addition, there are multiple choices of (s(·), δ) to make an OOD generalization problem learnable: larger δ will ﬁlter out more features, and so s(·) can be smaller (ﬂatter). This multiplicity will result in a trade-off between s(·) and δ, which will be discussed in
Section 6.2.
Two extreme cases: i.i.d. & unlearnable. To better understand the concept of learnability, we consider two extreme cases. (1) The ﬁrst example is when all data from different e ∈ Eall are identically distributed, i.e., the classic supervised learning setting. This problem is (s(·), 0)-learnable with s(x) = x, implying no extra difﬁculty in OOD generalization. (2) As an example of unlearnable, consider the following case (modiﬁed from Colored MNIST [5]): For e ∈ Eavail, images with label 0 always has a red background while images with label 1 has a blue background. For e ∈ Eall \ Eavail, this relationship is entirely inverse. Since data from different e ∈ Eavail are identically distributed but different from other e ∈ Eall, no expansion function can make it learnable, i.e., it is OOD-unlearnable. 2When we talk about the scale of s(·), e.g. it is larger / smaller, we mean the comparison of two expansion function, rather than the comparison along a function. 4
The unlearnability of this case also coincides with our intuition: Without prior knowledge, it is not clear from merely the training data, whether the task is to distinguish digit 0 from 1, or to distinguish color red from blue. As a result, generalization to Eall cannot be guaranteed. 4 Generalization Bound
In this section, we consider an OOD generalization problem from Eavail to Eall, and our goal is to analyze the OOD generalization error of classiﬁer f = g ◦ h deﬁned by err(f ) = L(Eall, f ) − L(Eavail, f ), where we assume the loss function l(·, ·) is bounded by [0, C]. We prove two upper bounds (4.1, 4.2) as well as a lower bound (4.3) for err(f ) based on our formulation. Our bounds together provide a complete characterization of the difﬁculty of OOD generalization. Since we expect that an invariant classiﬁer can generalize to unseen domains, we hope to bound err(f ) in terms of the certain variation of f . To this end, we deﬁne the variation and informativeness of f in terms of its features, i.e.,
V sup(h, Eavail) (cid:44)
I inf(h, Eavail) (cid:44) sup
β∈S d−1 inf
β∈S d−1
V(β(cid:62)h, Eavail),
I(β(cid:62)h, Eavail), where (β(cid:62)h)(x) = β(cid:62)h(x) is a feature and S d−1 = {β ∈ Rd : (cid:107)β(cid:107)2 = 1} is the unit (d − 1)-sphere.
Necessity of using supremum over linear combination. One seemingly plausible deﬁnition of the variation of a classiﬁer f can be the supremum over all V(φi, Eavail), i ∈ [d]. However, as is shown in Appendix 1, it is possible that two high-dimensional joint distributions have close marginal distribution in each dimension, while they do not overlap. In other words, there exist cases where
V(φi, Eall) = 0, ∀i ∈ [d] but after applying the top model g over φi’s, the distribution varies a lot in
Eavail. Our deﬁnition comes from the simple idea that the class of top model G is at least a linear space, so we should at least consider the variation of every (normalized) linear combination of h(·).
With this, we can guarantee the joint distribution distance is still small.
Theorem 4.1 (Main Theorem). Suppose we have learned a classiﬁer f (x) = g(h(x)) such that
∀e ∈ Eall and ∀y ∈ Y, phe|Y e(h|y) ∈ L2(Rd). Denote the characteristic function of random variable he|Y e as ˆphe|Y e (t|y) = E[exp{i(cid:104)t, he(cid:105)}|Y e = y]. Assume the hypothetical space F satisﬁes the following regularity conditions that ∃α, M1, M2 > 0, ∀f ∈ F, ∀e ∈ Eall, y ∈ Y, (cid:90) h∈Rd phe|Y e (h|y)|h|αdh ≤ M1 and (cid:90) t∈Rd
|ˆphe|Y e (t|y)||t|αdt ≤ M2.
If (Eavail, Eall) is (cid:0)s(·), I inf(h, Eavail)(cid:1)-learnable under Φ with Total Variation ρ3, then we have err(f ) ≤ O (cid:16) s(cid:0)V sup
ρ (h, Eavail)(cid:1) α2 (α+d)2 (cid:17)
. (4) (5)
Here ρ is total variation distance, and O(·) depends on d, C, α, M1, M2.
The above theorem holds for a general classiﬁer learned by any algorithms. Due to its generality, we need to introduce some technical regularity conditions on the density function. The assumption (4) assume the decay rate of density and its characteristic function, which is common in the literature, e.g. [14]. This theorem demonstrates that, the generalization error can be bounded by a function of the variation of h, and it converges to 0 as the variation approaches to 0. Under some special but typical case where the top model g is linear, we can further show that even without the regularity conditions in Theorem 4.1, we have a much better (linear) convergence rate.
Theorem 4.2 (Linear Top Model). Consider any loss satisfying (cid:96)(ˆy, y) = (cid:80)K any classiﬁer with linear top model g, i.e., k=1 (cid:96)0(ˆyk, yk).4 For f (x) = Ah(x) + b with A ∈ RK×d, b ∈ RK, 3For two distribution P, Q with probability density function p, q, ρ(P, Q) = 1 2 4This decomposition is a technical assumption to make the proof more convenient. Truncated square loss or x |p(x) − q(x)|dx. (cid:82)
Truncated absolute loss satisfy this assumption. 5
if (Eavail, Eall) is (cid:0)s(·), I inf(h, Eavail)(cid:1)-learnable under Φ with Total Variation ρ, then we have err(f ) ≤ O (cid:16) s(cid:0)V sup(h, Eavail)(cid:1)(cid:17)
. (6)
Here O(·) depends only on d and C.
Discussion. Theorem 4.1 shows that, for any model, the generalization gap depends largely on the model’s variation captured by V sup(h, Eavail). The result is irrelevant to the algorithm and provides a guarantee for the generalization gap from Eavail to Eall, so long as the learned model f is invariant, i.e. V sup(h, Eavail) is small. When s(·) is ﬁxed, a model with smaller V sup(h, Eavail) results in a smaller gap, which matches our understanding that invariant features in Eavail are somehow invariant in Eall. When V sup(h, Eavail) is ﬁxed, more difﬁcult generalization will generate a larger expansion function, which leads to a larger gap. For the Gaussian class with bounded mean and variance, α (cid:29) d and the convergent rate is almost linear.
However, without any constraint to g, the convergent rate might be small. Theorem 4.2 then offers a generalization bound with a linear convergent rate under mild assumptions when g is linear, which is common in reality. It relaxes the concentration assumption (Formula 4) and asks only for the integrability of the density. The convergent rate is identical to the convergent rate of the expansion function, showing that s(·) captures the generalization quite well.
Proof Sketch of Theorem 4.1. The proof of the main result, Theorem 4.1, is decomposed into the following steps. First, we transform err(f ) into the Total Variation of joint distributions of features in different domains (Step 1). To bound the Total Variation, it is sufﬁcient to bound the distance of the corresponding Fourier transform, and further, it is equivalent to bound the Radon transform of joint distributions (Step 2). Eventually, we show that V sup(β(cid:62)h, Eavail) can be used to bound the Radon transform, which ﬁnishes the proof (Step 3).
Step 1. The OOD generalization error can be bounded as: err(f ) ≤ sup (e,e(cid:48))∈(Eavail,Eall)
C
K (cid:90) (cid:88) y∈Y h∈Rd (cid:12)phe|Y e (h|y) − phe(cid:48) |Y e(cid:48) (h|y))(cid:12) (cid:12) (cid:12)dh.
Step 2. According to the assumption (4), the dominant term in (7) is (cid:90)
|h|≤r1 (cid:12) (cid:12) (cid:12) (cid:90)
|t|≤r2 e−i(cid:104)h,t(cid:105)(cid:0)ˆphe|Y e (t|y) − ˆphe(cid:48) |Y e(cid:48) (t|y))(cid:1)dt (cid:12) (cid:12) (cid:12)dt, (7) (8) where r1 and r2 are well-selected scalars that depend on s(cid:0)V sup
Theorem [31, 42] and the Fourier Inversion Formula, (8) is bounded above by
ρ (h, Eavail)(cid:1). By the Projection
O(rd 1rd 2) × (cid:90) u∈R (cid:12) (cid:12)Re(cid:48)(β, u) − Re(β, u)(cid:12) (cid:12)du, (9) where Re(β, u) is the Radon transform of phe|Y e (t|y).
ρ (h, Eavail)(cid:1)(cid:1). We ﬁnish
Step 3. The right-hand side of Formula 8 can be bounded by O(cid:0)rd the proof by selecting appropriate r1 and r2 to balance the rate of the dominant term and other minor terms. For more details, please see Appendix 2 for the complete proofs. 2s(cid:0)V sup 1rd
Now we turn to the lower bound of err(f ).
Theorem 4.3 (Lower Bound). Consider 0-1 loss: (cid:96)(ˆy, y) = I(ˆy (cid:54)= y). For any δ > 0 and any expansion function satisfying 1) s(cid:48)
∈ (1, +∞); 2) exists k > 1, t > 0, s.t. kx ≤ s(x) < +∞, x ∈ [0, t], there exists a constant C0 and an OOD generalization problem (Eavail, Eall) that is (s(·), δ)-learnable under linear feature space Φ w.r.t symmetric KL-divergence
ρ, s.t. ∀ε ∈ [0, t 2 ], the optimal classiﬁer f satisfying V sup(h, Eavail) = ε will have the OOD generalization error lower bounded by
+(0) (cid:44) limx→0+ s(x)−s(0) x err(f ) ≥ C0 · s(V sup(h, Eavail)). (10)
Theorem 4.3 shows that err(f ) of optimal classiﬁer f is lower bounded by its variation. Here
“optimal” means the classiﬁer that minimize L(f, Eavail). Altogether, the above three theorems 6
offer a bidirectional control of OOD generalization error, showing that our formulation can offer a
ﬁne-grained description of most OOD generalization problem in a theoretical way. To pursue a good
OOD performance, OOD algorithm should focus on improving predictive performance on Eavail and controlling the variation V sup(h, Eavail) simultaneously. Note that this bound starts from population error, and we call for future works to combine our generalization bound and traditional bound from data samples to population error, giving a more complete characterization of the problem. 5 Variation as a Factor of Model Selection Criterion
As is pointed out in [21], model selection has a signiﬁcant effect on domain generalization, and any OOD algorithm without a model selection criterion is not complete. [21] trained more than 45,900 models with different algorithms, and results show that when traditional selection methods are applied, none of OOD algorithms can outperform ERM [58] by a signiﬁcant margin. This result is not strange, since traditional selection methods focus mainly on (validation) accuracy, which is biased in OOD generalization [21, 63]. A very typical example is Colored MNIST [5], where the image is colored according to the label, but the relationship varies across domains. As explained in
[5], ERM principle will only capture this spurious feature (color) and performs badly in Eall. Since
ERM is exactly minimizing loss in Eavail, any model selection method using validation accuracy alone is likely to choose ERM rather than any other OOD algorithm [63]. Thus no algorithm will have a signiﬁcant improvement compared to ERM.
A natural question arises: what else can we use, in addition to accuracy? Theorem 4.1 points out that, learning feature with small variation across Eavail is important for decreasing OOD generalization error. Once a model f achieves a small V sup(h, Eavail), then err(f ) will be small. If the validation accuracy is also high, we shall know that the OOD accuracy will remain high. To this end, we propose our heuristic selection criterion (Algorithm 1). Instead of considering validation accuracy alone, we combine it with feature variation and select the model with high validation accuracy as well as low variation.
Algorithm 1: Model Selection
Input: available dataset Xavail = (Xtrain, Xval), candidate models set M, var_acc_rate r0. for f = g ◦ h in M do for i in [d] do
ˆVi ← maxy∈Y,X e(cid:54)=X e(cid:48) ∈Xavail
Total Variation(P(φe i |y), P(φe(cid:48) i |y)); (cid:46)Use GPU KDE end
Vf ← meani∈[d]
Accf ← compute validation accuracy of f using Xval
ˆVi end
Return argmaxf ∈M(Accf − r0Vf )
We brieﬂy explain Algorithm 1 here. For each candidate model, we calculate its variation using the average of each feature’s variation, i.e., 1 i∈[d] V(φi, Xavail). When deriving the bounds, we use d
V sup instead of their average because we need to consider the worst case, i.e., the worst top model. In practice, we ﬁnd out that the average of V(φi, Xavail) is enough to improve selection. (cid:80)
Our criterion of model selection is
Accf − r0Vf , (11) i.e., we select a model with high validation accuracy and low variation simultaneously. Here r0 is a hyper-parameter representing the concrete relationship between err(f ) and Vf . Although we have already used one hyper-parameter to help select multiple hyper-parameter combinations, it is natural to ask whether we can further get rid of the selection of r0. Since r0 represents the relationship between variation and accuracy, which is actually determined by the unknown expansion function, explicitly calculating r0 is not possible. However, we can empirically estimate r0 using
, where ˆM ⊂ M is the model with not bad validation accuracy. We do not use r0 = the whole set M because some OOD algorithms will perform extremely bad when the penalty is
Stdf ∈ ˆMAccf
Stdf ∈ ˆMVf 7
huge, and these models will inﬂuence our estimation of the ratio. Since high validation means large informativeness in learned features, the use of ˆM is an implicit application of informative assumption.
As shown in Section 6.1, our method can select models with higher OOD accuracy in various OOD datasets. We also explain in Appendix 3 why our method can outperform the traditional method in
Color MNIST, where the dataset is hand-make and simple enough to calculate the expansion function. 6 Experiments
In this section, we conduct experiments to compare our model selection criterion (Section 5) with the baseline method5 [21]. Since both the variation and informativeness in Deﬁnition 3.1 are based on one-dimensional features, we can directly estimate these quantities feature-by-feature and design model selection method based on them. To verify the existence of the expansion function and to see what it’s like in a real-world dataset, we plot nearly 2 million features trained in a common-used
OOD dataset and compute their variation and informativeness. We then draw the expansion function for this problem. 6.1 Experiments on Model Selection
In this section, we conduct experiments to compare the performance of models selected by our method and by validation accuracy. We train models on different datasets, different Eavail, and select models according to a different selection criteria. We then compare the OOD accuracy of selected models.
Settings We train our model on three benchmark OOD datasets (PACS [34], OfﬁceHome [59],
VLCS [57]) and consider all possible selections of (Eavail, Eall) . We choose ResNet–50 as our network architecture. We use ERM [58] and four common-used OOD algorithms (CORAL [55],
Inter-domain Mixup [62], Group DRO [51], and IRM [5]). For each environment setup, we train 200 models using different algorithms, penalties, learning rates, and epoch. After training, we employ different selection methods and compare the OOD accuracy of the selected models. As stated in
Section 5, we use the standard deviation of V and validation accuracy in ˆM to estimate r0, where
ˆM = {f ∈ M : Accf ≥ max ˆf Acc ˆf − 0.1}. Note that calculating V(φi, Xavail) takes calculus many times, so we design a parallel GPU kernel density estimation to speed up the whole process a hundred times and manage to ﬁnish one model in seconds. For more details about the experiments, see Appendix 4.
Table 1: Model Selection Result. “Env” denotes the unseen domain during training. “Val” denotes the OOD accuracy of model selected by validation accuracy.
PACS
OfﬁceHome
VLCS
Env
Val
Ours
Env
Val
Ours
Env
Val
Ours
S
C
C
A
A avg acc inc
-P 85.20% 80.42% 96.17% 77.86% 84.91% 88.72% 81.74% 96.83% 79.00% 86.57% 1.66%↑ acc inc
-P 61.85% 55.56% 74.72% 76.25% 67.09% 65.76% 55.07% 75.20% 76.31% 68.09% 1.00%↑ acc inc
-L 97.46% 64.83% 69.50%6 97.81% 66.98% 69.50% 70.97% 76.32% 0.63%↑ 70.97% 75.69% avg avg
V
C
R
S
Result We summarize our experimental results in Table 1. For each environment setup, we select the best model according to Algorithm 1 and validation accuracy. The results show that on all datasets, our selection criterion signiﬁcantly outperforms the validation accuracy in average OOD accuracy.
For a more detailed comparison, our method improves the OOD accuracy in most of the 12 setups.
Our experiments demonstrate that our criterion can help select models with higher OOD accuracy. 5Our experiments is conducted in DomainBed: https://github.com/facebookresearch/DomainBed. 6Notice that some OOD accuracy are the same in the two methods since the same model is selected. This happens when the unseen domain is close to Eavail so that the validation accuracy metric is close to ours. 8
6.2 Learnability of Real-World OOD Problem
Figure 1: The expansion function of the OOD generalization problem on Ofﬁce-Home. The x-axis stands for V(φ, Eavail) and the y-axis for V(φ, Eall). There are approximately 2 million points in each image, with each point representing a feature, and its color represents its informativeness. The solid red line stands for the expansion function under the corresponding δ. When δ increases, the expansion function decreases. When δ = 0, no expansion function can make it learnable.
One may wonder if the expansion function really exists and what it will look like for a real-world
OOD generalization task. In this section, we consider the OOD dataset Ofﬁce-Home [59]. We explicitly plot millions of features’ Vρ(φ, Eavail) and Vρ(φ, Eall) with Total Variation ρ to see what the expansion function is like in this task. We take the architecture as ResNet-50 [23], and we trained thousands of models with more than ﬁve algorithms, obtaining about 2 million features. The results are in Figure 1.
Existence of s(·). When δ = 0, some non-informative features are nearly 0-invariant across Eavail but are varying across Eall, so no expansion function can make this task learnable, i.e., this task is
NOT (s(·), 0) for any expansion function. But as δ increases, only informative features are left, and now we can ﬁnd appropriate s(·) to make it learnable. We can clearly realize from the ﬁgure that s(·) do exist when δ ≥ 0.15.
Trade-off between s(·) and δ. The second phenomenon is that the slope of s(·) decreases as δ increases, showing a trade-off between s(·) and δ. Although this trade-off comes naturally from the deﬁnition of learnability, it has a deep meaning. As is shown in Section 4, err(f ) is bounded by O(s(ε)) where ε is the variation of the model. To make the bound tighter, a natural idea is to choose a ﬂatter s(·). However, a ﬂatter s(·) corresponds to a larger δ. Typically, learning a model to meet this higher informativeness requirement is more difﬁcult, and it is possible that the algorithm achieves this by capturing more domain-speciﬁc features, which will therefore increase the variation of the model, ε. As a result, we are not sure whether s(ε) will increase or decrease. We believe this is also the essence of model selection: i.e., to trade-off between the variation and informativeness of a model, which is done in Formula 11. 7 More