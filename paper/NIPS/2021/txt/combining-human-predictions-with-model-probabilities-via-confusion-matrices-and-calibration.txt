Abstract
An increasingly common use case for machine learning models is augmenting the abilities of human decision makers. For classiﬁcation tasks where neither the human nor model are perfectly accurate, a key step in obtaining high performance is combining their individual predictions in a manner that leverages their relative strengths. In this work, we develop a set of algorithms that combine the probabilistic output of a model with the class-level output of a human. We show theoretically that the accuracy of our combination model is driven not only by the individual human and model accuracies, but also by the model’s conﬁdence. Empirical results on image classiﬁcation with CIFAR-10 and a subset of ImageNet demonstrate that such human-model combinations consistently have higher accuracies than the model or human alone, and that the parameters of the combination method can be estimated effectively with as few as ten labeled datapoints. 1

Introduction
One of the main goals of machine learning is to develop algorithms that can operate robustly in an autonomous fashion without human supervision. However, there are many applications where hybrid human-machine approaches are likely to be a preferred mode of operation for a variety of different reasons, such as improving trust between humans and machines, and allowing for a human or a model to take over in situations where the one or the other lacks expertise [Kamar, 2016, Vaughan, 2018, Kleinberg et al., 2017, Riedl, 2019, Trouille et al., 2019, Johnson and Vera, 2019, Zahedi and
Kambhampati, 2021].
The performance beneﬁts of combining multiple predictors, rather than relying on a single predictor, have been clearly demonstrated in past work in several ﬁelds. For example, in machine learning there is a rich vein of research over the past few decades on combining models using a variety of different estimation and algorithmic approaches [Kittler et al., 1998, Dietterich, 2000, Kuncheva, 2014, Sagi and Rokach, 2018]. This existing line of work emphasizes that combinations of models that have diversity in how they make predictions can systematically outperform a single model. In parallel, in the behavioral science literature, there has been extensive prior work studying combinations of human opinions where, again, diverse combinations tend to outperform any single individual [Hong and Page, 2004, Lamberson and Page, 2012].
This naturally leads to questions about hybrid combinations of human and machine predictions, rather than just combining one type or the other. For example, one motivation for hybrid combinations is empirical evidence that human and machine classiﬁers do not make the same types of errors for problems such as image classiﬁcation [Geirhos et al., 2020, Rosenfeld et al., 2018, Serre, 2019], i.e., they are diverse in their predictions. These ideas have begun to have impact in real-world applications, where hybrid human-machine teams have been found to be effective in areas such as crowdsourcing
[Kamar et al., 2012], citizen science [Beck et al., 2018], speech transcription [Gaur et al., 2015], 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
Figure 1: Left: Combining a human’s label and a classiﬁer’s probabilities for an ImageNet-16H
[Steyvers et al., 2022] image (true label: bear). Right: Human-machine combinations (purple) achieve lower error rates on average than the human or classiﬁer alone (ResNet-164 on CIFAR-10H, VGG-19 on ImageNet-16H). face identiﬁcation [Phillips et al., 2018], and clinical radiology [Bien et al., 2018, Patel et al., 2019,
Rajpurkar et al., 2020].
In this paper, we focus on a simple yet realistic instantiation of the general problem of hybrid combinations of human and machine predictions. In particular, we consider a K-way classiﬁcation task such as image classiﬁcation, with a single human making categorical classiﬁcation decisions (i.e. predicting only a label) and a single classiﬁcation model predicting a distribution over labels. While humans can provide conﬁdence estimates with their label predictions, calibrated self-assessment of conﬁdence can be difﬁcult [Keren, 1991, Kahneman and Tversky, 1996, Klayman et al., 1999] as well as time-consuming.
A key question in this context is whether the non-probabilistic information from a human predictor can be effectively combined with the probabilistic information from a machine learning model. We answer this question in the afﬁrmative and show both theoretically and empirically how relatively simple probabilistic combination techniques can robustly outperform each of a human and machine on their own. In particular we show that a human can augment their predictions with those of a classiﬁcation model, improving classiﬁcation accuracy and producing calibrated predictions, even when the model is less accurate than the human. Similarly, from the model’s perspective, accuracy can often be signiﬁcantly improved by augmenting it’s class probabilities with a human’s labels, while improving calibration performance, even when the human is less accurate than the model.
Figure 1 shows an example using our proposed methodology for an image from the ImageNet-16H dataset [Steyvers et al., 2022]. The human incorrectly predicts the label dog. The classiﬁcation model (a deep network) predicts the correct label bear with a probability of 0.86 (uncalibrated) and 0.78 (calibrated). The combined prediction is for bear with a conﬁdence of 0.74, with dog having a higher conﬁdence given the human’s prediction. The histograms on the right show the overall average reduction in error rate on test images: even though the classiﬁers are on average less accurate (6.10%, 11.1% error) than the human (4.62%, 9.99% error), the resulting combinations have lower error rates than either (2.85%, 6.62% error).
The primary contributions of our work are as follows:
• We propose and investigate a general framework for combining predictions using instance-level conﬁdence from a model and class-level information from a human. The methods we propose are straightforward to implement in practice and label-efﬁcient.1
• We empirically validate our approach on the CIFAR-10H [Peterson et al., 2019] and ImageNet-16H
[Steyvers et al., 2022] image classiﬁcation datasets and show that human-machine combinations in this context are systematically more accurate and better calibrated than either alone.
• We develop a theoretical understanding, for this framework, of the key tradeoffs related to cali-bration and accuracy for both the individual human and model, introducing the notion of model and human conﬁdence ratios. We illustrate how these factors affect the combination, showing for 1Code for our estimation methods and experiments is available at: https://github.com/GavinKerrigan/conf_matrix_and_calibration. 2
example how two models with the same accuracy but with different calibration properties can have different performance when combined with human predictions.
The paper begins in Section 2 by introducing notation and deriving our combination method. Section 3 discusses related work and in Section 4 we propose a number of different estimation methods.
Section 5 describes our experimental results with two image classiﬁcation datasets, with individual human labelers, individual models, and combinations. Complementing the experimental results in Section 6 we develop theoretical results that characterize combination performance. Section 7 discusses the potential societal impact and limitations of the work, and Section 8 concludes the paper. 2 Combining Human Labels and Model Probabilities
Notation. We consider a K-ary classiﬁcation problem, where the goal is to predict a label y ∈ Y = {1, . . . , K} from features x ∈ X . The random variable (x, y) follows an unknown dis-tribution with support X × Y. We assume access to an individual human labeler represented by the function h : X → Y, where h(x) ∈ Y is the label predicted by the human. In addition, we have access to a trained machine classiﬁer m : X → RK, where m(x) ∈ RK is the normalized probability vector output by the classiﬁer. Both the human and classiﬁer are assumed to be noisy labelers relative to the ground truth y. The true labels could be determined, for example, by expert labelers or additional information not contained in x.
Combining Predictions. Given an input x ∈ X , our goal is to predict a true label conditioned on the predictions h(x) and m(x). The key challenge in combining human and classiﬁer predictions is simultaneously leveraging both the class-level outputs from the human and the predictive distributions output by the classiﬁer. Although we focus on the particular case where h is a human and m is a classiﬁer, our setup could be applied more generally to combinations of a non-probabilistic labeler (whose output is categorical) and a probabilistic labeler (whose output is a distribution over classes).
There are a variety of functional forms that could be used to combine the predictions. We pursue a probabilistic approach, where the conditional distribution over labels that we seek can be factored via
Bayes’ rule as p(cid:0)y|h(x), m(x)(cid:1) ∝ p(cid:0)h(x)|y, m(x)(cid:1)p(cid:0)y|m(x)(cid:1).
In this work, we pursue a conditional independence (CI) approach where the human labels h(x) and the probabilistic predictions m(x) are assumed to be conditionally independent given y. Under this assumption, the quantity of interest factors as (1) p(cid:0)y|h(x), m(x)(cid:1) ∝ p(cid:0)h(x)|y(cid:1)p(cid:0)y|m(x)(cid:1). (2)
In the above, the term p(h(x)|y) can be interpreted as calibrated probabilities at the class level. We parameterize the term p(h(x)|y) by the confusion matrix for the labeler h, which we denote by ϕ with entries ϕij = p(h(x) = i|y = j). The second term p(y|m(x)) can be interpreted as calibrated probabilities at the instance level. However, the probabilistic output of the classiﬁer m(x) may differ from p(y|m(x)). For example, modern neural networks tend to be overconﬁdent in their predictions
[Guo et al., 2017]. To remedy this, post-hoc calibration maps m(x) to well-calibrated probabilities via a learned calibration map with parameters θ. We note that there are many possible choices for such a post-hoc calibration map [Guo et al., 2017, Zhang et al., 2020, Kull et al., 2019, Patel et al., 2021], but our method is agnostic to this choice. In this work, we use mθ(x) to denote the output of the classiﬁer after applying such a calibration map. The second term in Equation (2) is then parameterized by the calibrated classiﬁer probabilities mθ(x).
Altogether, our method expresses the predicted probability for class j, given that the human predicts class i and the model produces a class probability vector m(x) as: p(cid:0)y = j|h(x) = i, m(x)(cid:1) =
ϕijmθ j (x) k=1 ϕikmθ (cid:80)K k(x)
. (3)
The CI assumption above is common (both implicitly and explicitly) in prior work on combining predictions, such as additive classiﬁer ensembles [Kuncheva, 2014, Sagi and Rokach, 2018] and (log-)linear opinion pools [Genest and Zidek, 1986, Jacobs, 1995]. As our primary motivation is to develop a relatively simple and robust methodology for combining human and model predictions, the 3
additional functional or parametric assumptions (and parameters) required to specify a joint model for p(h(x), m(x)|y) are beyond the scope of the work in this paper. In addition, although the CI assumption is unlikely to hold exactly, prior work [Kuncheva, 2006] notes that a CI model can be an optimal discriminant even when the CI assumption is violated. As further motivation, for the two datasets we use in this paper, CIFAR-10H and ImageNet-16H, the conditional dependence of the predictions h(x) by the human and m(x) by the model appears to be relatively weak (see Appendix
A for details). 3