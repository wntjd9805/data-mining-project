Abstract
Domain adaptive semantic segmentation aims to transfer knowledge learned from labeled source domain to unlabeled target domain. To narrow down the domain gap and ease adaptation difﬁculty, some recent methods translate source images to target-like images (latent domains), which are used as supplement or substitute to the original source data. Nevertheless, these methods neglect to explicitly model the relationship of knowledge transferring across different domains. Alternatively, in this work we break through the standard “source-target” one pair adaptation framework and construct multiple adaptation pairs (e.g. “source-latent” and “latent-target”). The purpose is to use the meta-knowledge (how to adapt) learned from one pair as guidance to assist the adaptation of another pair under a meta-learning framework. Furthermore, we extend our method to a more practical setting of open compound domain adaptation (a.k.a multiple-target domain adaptation), where the target is a compound of multiple domains without domain labels. In this setting, we embed an additional pair of “latent-latent” to reduce the domain gap between the source and different latent domains, allowing the model to adapt well on multiple target domains simultaneously. When evaluated on standard benchmarks, our method is superior to the state-of-the-art methods in both the single target and multiple-target domain adaptation settings. 1

Introduction
Semantic segmentation is a popular task in computer vision, which assigns pixel-wise semantic labels for given images. It has been widely utilized to facilitate downstream applications such as video surveillance and autonomous driving. Recent progress on image semantic segmentation has been driven by deep neural networks trained on a large amount of labeled data, which are yet expensive to obtain. An alternative way is to generate synthetic images with pixel-level ground truth readily available in an effortless way [1, 2]. However, the model purely trained on synthetic datasets usually performs rather poor on real data. To address this issue, domain adaptation methods are used to reduce the domain shift and learn domain-invariant representations by minimizing distribution discrepancy between source and target domains [3, 4]. Following the advances of generative adversarial nets (GANs) [5], adversarial learning has been used to align representations of different domains in an adversarial manner [6, 7, 8, 9]. Recent studies introduce an additional intermediate domain, i.e. latent domain, to narrow down the huge domain gap between source and target domains [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]. This is achieved by image-to-image
∗The corresponding author is Shanshan Zhang. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
(a) (b)
Figure 1: Comparison of different domain adaptation frameworks for semantic segmentation. (a)
Previous frameworks built one domain adaptation pair that directly adapts a model from source domain and latent domain to target domain. In contrast, (b) we construct two domain adaptation pairs.
The purpose is to use the meta-knowledge learned from one pair as guidance to assist the adaptation of another pair under a meta-learning framework. translation technique, which generates augmented images that share the same contents as well as ground truth labels with the source domain and similar style to the target domain.
Previous works use the latent domain as supplement or substitute to the original source domain to ease the adaptation difﬁculty, following the traditional one-pair domain adaptation framework, as shown in Fig. 1(a). In contrast, in this paper we construct two domain adaptation pairs: “source→latent” and
“latent→target”. The purpose is to use the meta-knowledge learned from one pair of “source→latent” as guidance to assist the adaptation of another pair of “latent→target”, as shown in Fig. 1(b).
Speciﬁcally, we use a meta-learning framework to learn the meta-knowledge, which reveals that a model starting from which initial condition can adapt well on the adaptation pair of “source→latent”.
Meta-learning (a.k.a. learning to learn) has re-surged recently due to its efﬁcacy for few-shot deep learning. In our paper, we only borrow the idea of bi-level optimization, to achieve an initialization that is good for both domain adaptation and segmentation. Please note for latent-target adaptation, since we do not have segmentation labels on target, we cannot optimize for the segmentation task.
Thus, an initialization that is only good for domain adaptation is not sufﬁcient; it is necessary to obtain an initialization that is good for both domain adaptation and segmentation. On the other hand, this initialization can be well transferred from source-latent to latent-target as it does not overﬁt to the domain adaptation or segmentation tasks on the latent domain thanks to the property of bi-level optimization. Recently, a couple of works have also successfully applied meta-learning to domain adaptation. The most related work to ours is [22], which requires multiple source domains or a proportion of labeled target data. In contrast, our proposed method makes use of a generated latent domain, and thus is more ﬂexible in practice.
Most existing domain adaptation methods only aim at adapting a model to a single target domain, without considering a more practical scenario where the target consists of multiple data distributions.
To investigate a more realistic setting for domain adaptation, we further study the problem of open compound domain adaptation (a.k.a multiple-target domain adaptation) [23]. In this setting, the target is a union of multiple domains without domain labels. To address this challenge, we extend our proposed method from single-target to multi-target domain adaptation. Speciﬁcally, we embed an additional domain pair of “latent→latent” to algin arbitrary two latent domains in the meta-training phase, which better learn the meta-knowledge of adaptation across different domains. In the meta-testing phase, the learned meta-parameters are used to initialize model parameters, promoting our model to adapt well on multiple target domains simultaneously.
In summary, the contribution of our work is three folds. (1) We propose a meta-learning framework compatible for both single-target and multi-target domain adaptation settings. To the best of our knowledge, this is the ﬁrst work that adopts meta-learning framework to handle domain adaptive semantic segmentation. (2) We ﬁrst generate additional images as a latent domain via style transfer from source to target domains. This latent domain is then used to construct domain pairs for meta-learning, which transfers meta-knowledge of adaptation across different domains. (3) Our approach achieves state-of-the-art performance on several challenging benchmark datasets. Also, we provide comprehensive model analyses for the proposed method. 2
Figure 2: Training procedure of our meta-learning framework for single-target domain adaptation. In the meta-training phase, we construct a domain pair of “source→latent” to learn the meta-knowledge via bi-level optimization. The meta-knowledge reveals a model starting from which initial condition adapts well from labeled domain to a new unlabeled domain. In the meta-testing phase, we use the learned meta-knowledge as guidance to assist the adaptation of “latent→target”. 2