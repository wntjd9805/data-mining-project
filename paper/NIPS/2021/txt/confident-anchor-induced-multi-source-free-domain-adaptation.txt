Abstract
Unsupervised domain adaptation has attracted appealing academic attentions by transferring knowledge from labeled source domain to unlabeled target domain.
However, most existing methods assume the source data are drawn from a single domain, which cannot be successfully applied to explore complementarily trans-ferable knowledge from multiple source domains with large distribution discrep-ancies. Moreover, they require access to source data during training, which are inefﬁcient and unpractical due to privacy preservation and memory storage. To address these challenges, we develop a novel Conﬁdent-Anchor-induced multi-source-free Domain Adaptation (CAiDA) model, which is a pioneer exploration of knowledge adaptation from multiple source domains to the unlabeled target domain without any source data, but with only pre-trained source models. Specif-ically, a source-speciﬁc transferable perception module is proposed to automati-cally quantify the contributions of the complementary knowledge transferred from multi-source domains to the target domain. To generate pseudo labels for the target domain without access to the source data, we develop a conﬁdent-anchor-induced pseudo label generator by constructing a conﬁdent anchor group and as-signing each unconﬁdent target sample with a semantic-nearest conﬁdent anchor.
Furthermore, a class-relationship-aware consistency loss is proposed to preserve consistent inter-class relationships by aligning soft confusion matrices across do-mains. Theoretical analysis answers why multi-source domains are better than a single source domain, and establishes a novel learning bound to show the effec-tiveness of exploiting multi-source domains. Experiments on several representa-tive datasets illustrate the superiority of our proposed CAiDA model. The code is available at https://github.com/Learning-group123/CAiDA. 1

Introduction
Unsupervised Domain Adaptation (UDA) [22, 59, 63] captures transferable knowledge from labeled data in a source domain to classify unlabeled data in a target domain. UDA has achieved remarkable successes in many applications, e.g., object detection [23], medical diagnose [9, 12], sentiment anal-ysis [34], etc. Generally, most of existing methods employ adversarial learning [17] to encourage the learned source and target features to be indistinguishable from each other [10, 15], or minimize the distribution discrepancy across domains by matching the statistical moments of distributions [41]. (cid:3)Equal contributions yCorresponding author 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
However, the above-mentioned methods have a strong assumption that the source data are merely drawn from a single domain. Unfortunately, the source data are often collected under different deployed environments (i.e., multiple source domains with large distribution discrepancies) in real-world applications, which makes them difﬁcult to explore complementarily transferable knowledge from the multi-source domains for target prediction. To achieve this, Multi-Source Domain Adap-tation (MSDA) [32, 34, 61] is proposed to match the features across domains and then quantify the contributions of source domains [2, 41, 60]. Additionally, [29, 58] aim to weight the source contribu-tions by normalizing the distance similarities between source and target domains.
Unfortunately, recent MSDA methods [29, 34, 41, 44] require massive labeled source data when adapting source domains to the target domain. This could make them inefﬁcient and unpractical in real-world applications with sensitive information (e.g., medical diagnosis [12] and recommendation system [24]), due to privacy preservation issues, storage and security concerns [50, 51]. To this end, a new challenging and practical problem named Multi-Source-Free Domain Adaptation (MSFDA) is researched, which explores transferable knowledge from multiple source domains to target domain with only pre-trained source models and without access to any source data. The trivial solutions for tackling MSFDA via using existing single-source-free domain adaptation methods [25, 30, 33, 57] are to adapt each source model individually and simply take an average prediction of source models.
However, they cannot explore the contributions of the complementary information transferred from different source domains, due to the lack of source data. Therefore, tackling the MSFDA problem is a challenging but rarely-researched task.
To address the MSFDA problem, we develop a novel Conﬁdent-Anchor-induced multi-source-free
Domain Adaptation (CAiDA) model, which is a pioneer exploration to capture transferable infor-mation from multiple source models to promote target prediction without access to source data.
Speciﬁcally, a source-speciﬁc transferable perception module is designed to calibrate the contribu-tions of the transferability from multiple source domains. We develop a conﬁdent-anchor-induced pseudo label generator to mine pseudo labels for the unlabeled target data, by incorporating with the quantiﬁed source transferability contributions. We construct a conﬁdent anchor group to assign each target sample with a semantic-nearest conﬁdent anchor, and perform feature augmentation be-tween them to generate conﬁdent target pseudo label. A class-relationship-aware consistency loss is proposed to ensure the semantic consistency of underlying inter-class relationships across domains via the alignment of soft confusion matrices. Furthermore, based on some mild assumptions, the-oretical analysis guarantees that multiple source models could help generate more reliable pseudo labels. Our theoretical analysis also provides a novel learning bound for MSFDA, which reveals that multiple source models help achieve a tighter generalization error bound for the target domain. We verify the effectiveness of our proposed model via comparison experiments on benchmark datasets.
The main contributions of our work are summarized as follows: (cid:15) We develop a novel Conﬁdent-Anchor-induced multi-source-free Domain Adaptation (CAiDA) model to explore transferable knowledge from multiple source domains to assist target prediction with pre-trained source models and without access to source data. To our best knowledge, this paper is a pioneer exploration of multi-source-free domain adaptation in the ﬁeld of transfer learning. (cid:15) We propose a novel MSFDA theory, which shows that multiple source models could improve the possibility of obtaining more reliable pseudo labels under some mild assumptions. Our theoretical analysis also provides a novel generalization bound for MSFDA to show the effect of multiple source models. This novel bound implies a positive answer to the solvability of MSFDA problem. (cid:15) A source-speciﬁc transferable perception module and a class-relationship-aware consistency loss are designed to quantify the contributions of the transferability of multiple source domains and ensure the semantic consistency of underlying inter-class relationships across domains, respectively. (cid:15) Based on the conﬁdent pseudo labeling strategy in theoretical analysis, a conﬁdent-anchor-induced pseudo label generator is proposed to generate pseudo labels for the target domain by establishing a conﬁdent anchor group and assigning each target sample with a semantic-nearest conﬁdent anchor. 2