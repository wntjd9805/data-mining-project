Abstract
We propose several schemes for upper bounding the optimal value of the con-strained most probable explanation (CMPE) problem. Given a set of discrete random variables, two probabilistic graphical models deﬁned over them and a real number q, this problem involves ﬁnding an assignment of values to all the variables such that the probability of the assignment is maximized according to the ﬁrst model and is bounded by q w.r.t. the second model. In prior work, it was shown that
CMPE is a unifying problem with several applications and special cases including the nearest assignment problem, the decision preserving most probable explanation task and robust estimation. It was also shown that CMPE is NP-hard even on tractable models such as bounded treewidth networks and is hard for integer linear programming methods because it includes a dense global constraint. The main idea in our approach is to simplify the problem via Lagrange relaxation and decom-position to yield either a knapsack problem or the unconstrained most probable explanation (MPE) problem, and then solving the two problems, respectively using specialized knapsack algorithms and mini-buckets based upper bounding schemes.
We evaluate our proposed scheme along several dimensions including quality of the bounds and computation time required on various benchmark graphical models and how it can be used to ﬁnd heuristic, near-optimal feasible solutions in an example application pertaining to robust estimation and adversarial attacks on classiﬁers. 1

Introduction
We develop upper bounding algorithms for the constrained most probable explanation (CMPE) task
[32], a recently deﬁned unifying (discrete) optimization task over probabilistic graphical models (PGMs) [9, 20, 25] or log-linear models. At a high level, the CMPE task adds a global capacity constraint to the classic optimization problem in PGMs called most probable explanation (MPE).
Given a set of log-potentials F, namely a log-linear model, the MPE task seeks to ﬁnd an assignment of values to all variables (i.e., an explanation) such that the sum over the projection of the assignment on the log-potentials is maximized, namely it has the maximum probability. The CMPE task adds a global constraint to MPE using a possibly different set of log-potentials G and a real number q.
Speciﬁcally, it seeks to ﬁnd the most probable assignment w.r.t. F under the constraint that the sum over the projection of the assignment on the log-potentials in G is smaller than or equal to q.
Our interest in CMPE stems from the fact that several tasks in Explainable AI [16] can be reduced to
CMPE. For example, the nearest assignment problem [31] and the decision preserving explanation problem [7, 32] are instances of CMPE; the former seeks to ﬁnd an assignment whose probability is as close as possible to a given assignment, namely, its nearest neighbor while the latter seeks to ﬁnd the most probable extension of a given partial assignment according to a generative model such that the same (classiﬁcation) decision is made according to a discriminative model. Other applications of
CMPE include various queries in robust estimation [10] and detecting adversarial attacks. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
In terms of computational complexity, Rouhani et al. [31, 32] showed that CMPE is much harder than MPE. In particular, via a reduction from the multi-choice knapsack problem (MCKP) [19],
Rouhani et al. showed that while MPE is linear time on graphical models having empty primal graphs, CMPE is NP-hard. However, despite these worst-case results, the good news is that MCKP is an instance of easy NP-hard problems [19] and can be well-approximated using advanced methods from the knapsack problems literature. The MCKP reduction also yields a graph-based technique for approximating CMPE. The key idea is to condition on variables, namely remove them from the primal graph G until no more than k nodes remain in each connected component. The removed nodes form a k-separator [3] and each assignment to them yields an MCKP. When the k-separator is bounded, this method yields a fully polynomial time approximation scheme (FPTAS). When the k-separator is not bounded, Rouhani et al. propose to perform local search yielding an anytime algorithm.
While the algorithms described above yield a lower bound, no non-trivial upper bounding algorithms are available for CMPE. Such algorithms serve two important purposes [24]: (1) generating heuristic near-optimal solutions; and (2) pruning the search space of branch and bound methods and thus improving their efﬁciency. In principle, CMPE can be encoded as a mixed integer linear program (MILP) and solved using MILP solvers such as Gurobi [17] and SCIP [1, 2]. However, CMPE and other related tasks such as MPE and MCKP are particularly difﬁcult for MILP solvers because the global constraint in CMPE simultaneously restricts all the variables while MILP solvers are adept at handling sparse constraints. This motivates the development of specialized methods for CMPE.
In this paper, we propose two approaches for efﬁciently computing qualitative upper bounds for the
CMPE task. These approaches relax either the objective or the constraint or both. Our ﬁrst approach is based on Lagrangian relaxation (cf. [35]) and relaxes the global constraint using a Lagrange multiplier λ ≥ 0 to yield an (unconstrained) MPE task. Given a value for λ, an upper bound on the
MPE task yields an upper bound on CMPE. We propose to solve the MPE task using either exact or upper bounding approaches described in literature such as mini-bucket elimination [11], dual decomposition [14] and join graph based cost shifting schemes [18] and further tighten the upper bound by searching for the best possible value for λ, namely a value that minimizes the upper bound on MPE. Our second approach is based on Lagrangian decomposition. The key idea is to decompose the problem by duplicating variables [6] via equality constraints and then relaxing the latter using
Lagrange multipliers such that the resulting problem reduces to MCKP. Solving the MCKP for a given assignment of values to the multipliers yields an upper bound on CMPE. We propose to further improve the bound by searching for the best possible value assignment to the multipliers via an iterative algorithm.
Empirically, we investigate the quality and computational efﬁciency of our proposed bounding techniques on a variety of CMPE tasks formulated on cutset networks [30] and graphical models used in the UAI competitions [13, 15]. We also explore a novel application of CMPE: making classiﬁers (expressed as log-linear models) change their decision by minimally changing the test example. We found that when there is a relatively small limit on the amount of storage space an algorithm can use, our approach based on Lagrange decomposition via MCKP yields the best upper bounds. However, it also requires signiﬁcantly longer to converge. Conversely, when the space limit is relatively large, the approach based on Lagrangian relaxation that utilizes MPE solvers is superior. 2 Notation and