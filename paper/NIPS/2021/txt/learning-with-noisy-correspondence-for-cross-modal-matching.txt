Abstract
Cross-modal matching, which aims to establish the correspondence between two different modalities, is fundamental to a variety of tasks such as cross-modal retrieval and vision-and-language understanding. Although a huge number of cross-modal matching methods have been proposed and achieved remarkable progress in recent years, almost all of these methods implicitly assume that the multimodal training data are correctly aligned. In practice, however, such an assumption is extremely expensive even impossible to satisfy. Based on this observation, we reveal and study a latent and challenging direction in cross-modal matching, named noisy correspondence, which could be regarded as a new paradigm of noisy labels. Different from the traditional noisy labels which mainly refer to the errors in category labels, our noisy correspondence refers to the mismatch paired samples. To solve this new problem, we propose a novel method for learning with noisy correspondence, named Noisy Correspondence Rectiﬁer (NCR). In brief,
NCR divides the data into clean and noisy partitions based on the memorization effect of neural networks and then rectiﬁes the correspondence via an adaptive prediction model in a co-teaching manner. To verify the effectiveness of our method, we conduct experiments by using the image-text matching as a showcase.
Extensive experiments on Flickr30K, MS-COCO, and Conceptual Captions verify the effectiveness of our method. The code could be accessed from www.pengxi. me. 1

Introduction
As one of the most fundamental techniques in multimodal learning, cross-modal matching aims to bridge different modalities. In recent years, some cross-modal matching methods [19, 11, 7, 26] have been proposed based on Deep Neural Networks (DNNs), which achieved remarkable progress in a
∗Some parts of the work was done while Zhenyu Huang was an internship at Baidu Inc.
†Corresponding author. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
variety of applications, such as clustering [29, 24], image/video captioning [1, 44, 22], cross-modal retrieval [40, 19, 13], and visual question answering [9].
In general, most existing cross-modal matching methods embed different modalities into a common space wherein the similarity of positive cross-modal pairs is maximized and that of the negative ones is minimized. Although these methods have achieved promising results, their success depends on an implicit data assumption, i.e., the training data are correctly aligned across modalities. For example, in the vision-and-language tasks, the text needs to accurately describe the image content, and vice versa. In practice, however, it is extremely expensive and time-consuming to annotate or collect such data pairs. Especially, considering the data collected from the Internet [35, 14], it is inevitable to collect some mismatched pairs which are wrongly treated as the matched ones. To the best of our knowledge, such a special noisy label (correspondence) problem has been ignored so far, which will remarkably degrade the performance of matching methods as shown in our experiments.
Figure 1: Noisy labels vs. Noisy Correspondence. We denote the noisy samples with red lines and clean samples with green lines. The traditional noisy labels mainly refer to the errors in category labels, while the noisy correspondence refers to the alignment errors in paired data. For the noisy correspondence in cross-modal matching, the true positive pair correctly guides the cross-modal matching, while the false positive pair causes incorrect supervision for training.
Based on the above observation, we reveal a new paradigm for the noisy labels, named noisy correspondence. Different from the traditional noisy labels, the noisy correspondence refers to the alignment errors in paired data rather than the errors in category annotations (see Fig. 1). To the best of our knowledge, there is no effort has been devoted to study this new problem and the closest paradigm might be the partially view-aligned problem (PVP) [12, 41]. However, PVP is remarkably different from noisy correspondence, and the latter is more practical than the former. To be speciﬁc, PVP focuses on that the cross-modal alignment is totally unavailable, whereas the noisy correspondence focuses on that some correspondences are incorrect. In addition, PVP assumes that some correctly aligned data are available for training, whereas our noisy correspondence assumes that the clean and noisy data are mixed.
To solve the noisy correspondence problem in cross-modal matching, we propose a novel method, named Noisy Correspondence Rectiﬁer (NCR). Our method is based on the memorization effect of DNNs observed in [3, 39], i.e., DNNs tend to learn the simple patterns before ﬁtting noisy samples. Motivated by this empirical observation, NCR divides the data into two relative accurate data partitions, i.e., “noisy” and “clean” subsets, based on their loss difference. After that, NCR employs an adaptive prediction function for label rectifying so that the false positives and the true positives could be identiﬁed from the “clean” and the “noisy” subsets, respectively. Furthermore, we propose a novel triplet loss for robust cross-modal matching by recasting the rectiﬁed labels as the soft margin.
The main contributions and novelties of this paper could be summarized as below. i) We reveal a new problem in cross-modal analysis, which is also a new paradigm for noisy labels, termed noisy correspondence. Different from the traditional noisy labels, the noisy correspondence refers to the alignment errors in paired data instead of the errors in category annotations. To the best of our knowledge, this work could be the ﬁrst study on this problem. ii) To solve the noisy correspondence problem, we propose a novel method for learning with noisy correspondence, named Noisy Corre-spondence Rectiﬁer (NCR). One major novelty of NCR is that the rectiﬁed label is elegantly recasted as the soft margin of a triplet loss so that the robust cross-modal matching could be achieved. iii)
To verify the effectiveness of our method, we conduct experiments on the image-text matching task.
Extensive experiments on three challenging datasets verify the effectiveness of our method in the synthesized and real noises. 2
2