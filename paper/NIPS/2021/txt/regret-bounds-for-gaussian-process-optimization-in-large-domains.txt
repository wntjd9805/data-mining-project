Abstract
The goal of this paper is to characterize Gaussian-Process optimization in the setting where the function domain is large relative to the number of admissible function evaluations, i.e., where it is impossible to ﬁnd the global optimum. We provide upper bounds on the suboptimality (Bayesian simple regret) of the so-lution found by optimization strategies that are closely related to the widely used expected improvement (EI) and upper conﬁdence bound (UCB) algorithms. These regret bounds illuminate the relationship between the number of evaluations, the domain size (i.e. cardinality of ﬁnite domains / Lipschitz constant of the covari-ance function in continuous domains), and the optimality of the retrieved function value.
In particular, we show that even when the number of evaluations is far too small to ﬁnd the global optimum, we can ﬁnd nontrivial function values (e.g. values that achieve a certain ratio with the optimal value). 1

Introduction
In practice, nonconvex, gradient-free optimization problems arise frequently, for instance when tuning the parameters of an algorithm or optimizing the controller of a physical system (see e.g.
Shahriari et al. [2016]) for more concrete examples). Different versions of this problem have been addressed e.g. in the multi-armed-bandit and the Bayesian-optimization literature (which we review below). However, the situation where the number of admissible function evaluations is too small to identify the global optimum has so far received little attention, despite arising frequently in practice.
For instance, when optimizing the hyper-parameters of a machine-learning method or the controller-parameters of a physical system, it is typically impossible to explore the domain exhaustively. We take ﬁrst steps towards a better understanding of this setting through a theoretical analysis based on the adaptive-submodularity framework by Golovin and Krause [2011]. It is not the purpose of the present paper to propose a novel algorithm with better performance (we modify the EI and UCB strategies merely to facilitate the proof), but rather to gain an understanding of how GP-optimization performs in the aforementioned setting, as a function of the number of evaluations and the domain size.
As is done typically, we model the uncertainty about the underlying function as a Gaussian Process (GP). The question is how close we can get to the global optimum with T function evaluations, where T is small relative to the domain of the function (i.e., it is impossible to identify the global optimum with high conﬁdence with only T evaluations). As a performance measure, we use the
Bayesian simple regret, i.e., the expected difference between the optimal function value and the value attained by the algorithm. For the discrete case with domain size N , we derive a problem-independent regret bound (i.e., it only depends on T, N and is worst-case in terms of the GP prior) for two optimization algorithms that are closely related to the well-known expected improvement (EI, Jones et al. [1998]) and the upper conﬁdence bound (UCB, Auer et al. [2002], Srinivas et al.
∗manuel.wuthrich@pm.me 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
[2010]) methods. In contrast to related work, our bounds are non-vacuous even when we can only explore a small fraction of the function. We extend this result to continuous domains and show that the resulting bound scales better with the size of the function domain (equivalently, the Lipschitz constant of the covariance function) than related work (Gr¨unew¨alder et al. [2010]). 1.1