Abstract
Bayesian optimization (BO) is a sample-efﬁcient approach to optimizing costly-to-evaluate black-box functions. Most BO methods ignore how evaluation costs may vary over the optimization domain. However, these costs can be highly heteroge-neous and are often unknown in advance. This occurs in many practical settings, such as hyperparameter tuning of machine learning algorithms or physics-based simulation optimization. Moreover, those few existing methods that acknowledge cost heterogeneity do not naturally accommodate a budget constraint on the total evaluation cost. This combination of unknown costs and a budget constraint intro-duces a new dimension to the exploration-exploitation trade-off, where learning about the cost incurs a cost itself. Existing methods do not reason about the various trade-offs of this problem in a principled way, leading often to poor performance.
We formalize this claim by proving that the expected improvement and the expected improvement per unit of cost, arguably the two most widely used acquisition func-tions in practice, can be arbitrarily inferior with respect to the optimal non-myopic policy. To overcome the shortcomings of existing approaches, we propose the budgeted multi-step expected improvement, a non-myopic acquisition function that generalizes classical expected improvement to the setting of heterogeneous and unknown evaluation costs. Finally, we show that our acquisition function outperforms existing methods in a variety of synthetic and real problems. 1

Introduction
Bayesian optimization (BO) (Shahriari et al., 2016; Frazier, 2018) is a family of algorithms for opti-mizing black-box functions that performs well when the number of evaluations is limited (Snoek et al., 2012; Calandra et al., 2016; Grifﬁths and Hernández-Lobato, 2020). However, most BO algorithms ignore the fact that the cost of evaluating the black-box objective function may vary substantially across the optimization domain and is often unknown. Problems with this feature arise commonly in practice. For instance, in the context of hyperparameter optimization of machine learning algorithms (Swersky et al., 2013; Wu et al., 2020), certain values of hyperparameters such as the learning rate may yield longer training times. Similarly, in materials design and robotics, simulation experiments can take longer for certain parameter conﬁgurations (Field, 1999). Figure 1 illustrates heterogeneity in evaluation costs from benchmark problems used in this paper, which can vary by an order of magni-tude. Failing to account for these heterogeneous evaluation costs can lead to evaluating an expensive point when another less expensive one would provide equal beneﬁt towards ﬁnding the optimum. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
Figure 1: Evaluation times of the latent Dirichlet allocation, random forest, and energy-aware robot pushing benchmark problems (described later in Section 5.1).
We consider budgeted BO of a black-box objective function, whose evaluation costs are unknown and possibly heterogeneous across the domain. The goal is to ﬁnd a point with the largest possible objective value by querying the objective function at a sequence of adaptively chosen points, where the total evaluation cost is subject to a budget constraint (this cost only affects evaluation, and not a point’s quality upon implementation).
While some existing approaches do address heterogeneous evaluation costs, all do so heuristically, e.g. by maximizing a traditional cost-agnostic acquisition function divided by the cost of evaluation (Snoek et al., 2012; Poloczek et al., 2017; Wu et al., 2020; Lee et al., 2020b), or by rolling out a heuristic base policy (Lee et al., 2021). Importantly, most of these approaches accommodate neither budget constraints nor uncertainty about the cost function as part of the exploration-exploitation trade-off. As we argue theoretically and demonstrate through experiments, this can lead to poor performance. A notable exception is the concurrent work of Lee et al. (2021), which introduces a budget-aware non-myopic acquisition function based on rollout of a heuristic base policy. This work appeared while the present paper was under review.
Main Contributions. Motivated by the above shortcomings in existing work, we provide a principled approach to budgeted BO with unknown and potentially heterogeneous evaluation costs. Our main contributions are:
• We propose a Markov decision process (MDP) formulation of the budgeted BO problem with unknown and heterogeneous evaluation costs. Our formulation allows for a random time horizon (i.e., the last time before the budget is depleted), going beyond the ﬁxed-horizon MDPs formulated in existing work on non-myopic BO.
• Budgeted multi-step expected improvement (B-MS-EI), a novel look-ahead acquisition function that generalizes classical expected improvement to the budgeted cost-heterogeneous setting.
B-MS-EI can be seen as a principled approximation of the optimal policy of our MDP.
• We prove that expected improvement (EI) and its cost-normalized variant, two popular existing approaches, can be arbitrarily inferior with respect to the optimal non-myopic policy.
• An empirical evaluation on a number of synthetic and real-world experiments demonstrates that
B-MS-EI performs favorably with respect to other acquisition functions that are widely-used in settings with heterogeneous costs.
The remainder of this work is organized as follows: In Section 2, we review related work. Our problem setup is formalized in Section 3. In Section 4, we introduce B-MS-EI and discuss its efﬁcient maximization via one-shot multi-step Monte Carlo trees. Numerical experiments are presented in
Section 5. Finally, we discuss directions of future work and conclude in Section 6. 2