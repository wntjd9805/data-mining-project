Abstract
Federated Learning is an emerging direction in distributed machine learning that en-ables jointly training a model without sharing the data. Since the data is distributed across many edge devices through wireless / long-distance connections, federated learning suffers from inevitable high communication latency. However, the latency issues are undermined in the current literature [15] and existing approaches such as FedAvg [27] become less efﬁcient when the latency increases. To overcome the problem, we propose Delayed Gradient Averaging (DGA), which delays the averaging step to improve efﬁciency and allows local computation in parallel to communication. We theoretically prove that DGA attains a similar convergence rate as FedAvg, and empirically show that our algorithm can tolerate high network latency without compromising accuracy. Speciﬁcally, we benchmark the training speed on various vision (CIFAR, ImageNet) and language tasks (Shakespeare), with both IID and non-IID partitions, and show DGA can bring 2.55
⇥ speedup. Moreover, we built a 16-node Raspberry Pi cluster and show that DGA can consistently speed up real-world federated learning applications. to 4.07
⇥ 1

Introduction
Federated Learning [18, 27] has gained growing attention as it enables multi-clients distributed training without exposing the data from private users. During the training, only the model updates are exchanged between clients and servers, thus private training data never leave local devices, enhancing privacy. Many successful applications such as next-word prediction [10], voice recognition [38], and health care applications [50] have been derived under the framework.
A signiﬁcant difference between federated scenarios and typical in-center distributed settings [6, 8] is the networking condition. Unlike high-end in-cluster network infrastructures where high bandwidth (100 1ms) network is available, edge devices are usually connected through wireless and long-distance connection, thus the bandwidth and latency are strictly limited.
This dwarfs the performance of federated systems and slows the development of related applications.
Gbps) and low latency (
⇠

While the bandwidth constraints have been efﬁciently addressed by gradient compression [25], low-rank updates [18] and quantization techniques [43], the issue related to network latency is rarely studied in the recent literature [12, 15]. However, high network latency is inevitable in federated settings because of (1) wireless connections and (2) long-distance transmission (Figure. 1.(b)). On the one hand, the high-density urban ofﬁce and home environments create a lot of contention, as dozens of devices compete for the same radio frequency. On the other hand, the multi-geographic located data entails a minimum latency cost: even with the speed of light, it requires hundreds of milliseconds to send a packet across the world. In either case, the high latency is a hard barrier introduced by physical limits thus inevitable. If not handled speciﬁcally, such communication lag, in the magnitude of hundreds of milliseconds, or even seconds, will signiﬁcantly degrade the scalability of the learning algorithm as shown in the Figure. 1. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
Within a Rack  (<1us)
Same Data Center  (~ 1ms)
Wireless Connection  (~ 20ms)
Across the World  (> 100ms)
Latency:1us 100ms 1.00 1ms 500ms 10ms 1s 0.75 0.50 0.25 0.00 3.5x↓  5.8x ↓ t u p h g u o r h
T (a) Conventional Settings (b) Federated Settings (c) Speed Comparison
Figure 1: Left, Middle: The training settings of conventional distributed training v.s. federated learning are very different. Right: High latency cost greatly degrades the FedAvg’s [27] performance, proposing a severe challenge to scale up the training system. The latency statistics is referenced from
Verizon [46] and speedtest [42].
Within a Rack
<1us
In this paper, we propose Delayed Gradient Aggregation (DGA) to address the latency bottleneck.
The key idea is to delay the gradient averaging to a future iteration thus the communication can be pipelined with computation. By accepting stale average gradients for model updates, DGA allows the communication to execute in parallel with the computation, thus scalable even under extreme latency. We prove that our DGA shares the same convergence as FedAvg and provide extensive experiments on image and language tasks in both i.i.d. and non-i.i.d settings. We demonstrate that (a) Conventional Distributed Settings (i) DGA speeds up FedAvg by a factor 2.6 over various datasets; (ii) no accuracy drop to 4.1 under extreme communication lag (e.g., > 1 second). We further set up a Raspberry Pi cluster to simulate the real-world scenario and demonstrate that DGA is robust against network stragglers. Our 10ms contributions can be summarized as follows:
Within a Data Center
~ 1ms
Wireless Connection
~ 20ms
Across the World
> 100ms (b) Federated Distributed Settings 500ms 100ms
⇥
⇥ 1ms 1us 1.00 16x4 = 64 cards, batch size 32-2 latency(ms)
Scalability speed 1us 1ms 10ms 100ms 500ms 1s 1.00 0.99 0.94 0.70 0.29 0.17 504 501 352 472 145 87 501 503 472 447 399 145 87 39 352 234 5 10 20 50 100 200 500 1000 2000 5000 p u d e e p
S 0.75
• We propose DGA, a novel distributed optimization method to tolerate the communication latency for federated learning. To our best knowledge, our algorithm is the ﬁrst work that can achieve scalable federated training under high latency (>1s). 98x worse 4x worse 0.50 0.25 0.00
• We theoretically justify the convergence of DGA. We show that under reasonable delay interval, it shares the same convergence rate as FedAvg [51]. We also discuss its extension with momentum update to better suit modern federated optimizations.
• We empirically evaluate the accuracy on diverse datasets and benchmark the speed on different latency setups. Under an extremely high latency, DGA can show impressive improvement over previous algorithms while preserving similar performance on both i.i.d and non-i.i.d partitions.
• We build up a Raspberry Pi cluster of 16 devices to evaluate our algorithm in a real-world setting.
Even with unpredictable packet loss and latency ﬂuctuation, DGA still shows consistent speedup. 10ms 100ms 500ms 1ms 1us 2 Delayed Gradient Averaging (~1ms) 
Within a Data Center  (<1us) 
Within a Rack 1.00 0.75 (a) Conventional Distributed Settings 2.1 Problem Setting, Preliminaries and