Abstract
Deep learning provides a new avenue for image restoration, which demands a deli-cate balance between ﬁne-grained details and high-level contextualized information during recovering the latent clear image. In practice, however, existing methods empirically construct encapsulated end-to-end mapping networks without deep-ening into the rationality, and neglect the intrinsic prior knowledge of restoration task. To solve the above problems, inspired by Taylor’s Approximations, we unfold
Taylor’s Formula to construct a novel framework for image restoration. We ﬁnd the main part and the derivative part of Taylor’s Approximations take the same effect as the two competing goals of high-level contextualized information and spatial details of image restoration respectively. Speciﬁcally, our framework consists of two steps, correspondingly responsible for the mapping and derivative functions.
The former ﬁrst learns the high-level contextualized information and the later com-bines it with the degraded input to progressively recover local high-order spatial details. Our proposed framework is orthogonal to existing methods and thus can be easily integrated with them for further improvement, and extensive experiments demonstrate the effectiveness and scalability of our proposed framework. Code will be publicly available upon acceptance. 1

Introduction
Image restoration has long been an important task in computer vision, which demands a delicate bal-ance between spatial ﬁne-grained details and high-level contextualized information while recovering a latent clear image from a given degraded observation. It is a highly ill-posed issue as there exists inﬁnite feasible results for single degraded image. Representative image restoration tasks include image deraining, image deblurring.
Much research efforts have been devoted to solve the single image restoration problem, which can be categorized into two groups: traditional optimization methods [16, 36] and deep learning based methods. In detail, various natural images priors have been developed in traditional image restoration methods to regularize the solution space of the latent clear image, e.g., low-rank prior [36, 42], dark channel prior [31, 32, 54], graph-based prior [28, 2], total variation regularization [5, 8, 1] and sparse image priors [29, 56]. However, these priors are difﬁcult to design and the methods are difﬁcult to optimize, limiting their practical usage.
Convolutional neural networks (CNNs) have been applied in numerous high-level computer vision problems and obtained promising improvement in image restoration tasks over traditional meth-ods [52, 63, 15, 26, 45, 25, 7, 66, 67, 10, 37]. However, most existing CNN-based image restoration methods empirically construct encapsulated end-to-end mapping networks without deepening into the rationality, and neglect the intrinsic properties of the degradation process. Speciﬁcally, it makes
∗Corresponding Author. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
these methods unable to balance effectively the two competing goals of spatial ﬁne-grained de-tails and high-level contextualized information while recovering images from the degraded inputs, limiting the model performance. Moreover, existing forward-pass mapping methods lack of sufﬁ-cient interpretability, making it hard to analyze the effect of each module and preventing further improvement.
To solve the aforementioned problems, in this paper, we ﬁrst revisit the connection between Taylor’s
Approximation and image restoration task, and propose to unfold Taylor’s Formula as blueprints to construct a novel framework that enforces each process part to coincide with the intrinsic properties of image restoration task. We ﬁgure out that the main part and derivative part of Taylor’s Approximation take the same effect as the above two competing goals of image restoration respectively. In this way, our approach deviates from existing methods that optimally balance the above goals in the overall recovery process and independent from the degradation process. Speciﬁcally, we break down the overall recovery process into two manageable steps, corresponding to two speciﬁc operation steps that are responsible for the mapping and derivative functions respectively. The former ﬁrst learns the high-level contextualized information and the later combines it with the degraded input to progressively recover local high-order spatial details. Moreover, our proposed framework is orthogonal to existing methods and thus can be easily integrated with them for further performance gain. The conducted extensive experiments demonstrate the effectiveness and scalability of our proposed framework over two popular image restoration tasks, image deraining and image deblurring.
The contributions of this paper can be summarized as follows: 1) We introduce a new perspective for designing image restoration framework by unfolding the Taylor’s Formula. To the best of our knowledge, this is the ﬁrst effort to solve image restoration task inspired by Taylor’s Approximations. 2) In contrast to existing methods that optimally balance the competing goals of high-level contextualized information and local high-order spatial details of image restoration re-spectively in the overall recovery process, we break down it into two manageable steps, corresponding to two speciﬁc steps that are responsible for the mapping and derivative functions respectively. 3) Our proposed framework (i.e., Deep Taylor’s Approximations Framework) is orthogonal to existing CNN-based methods and these methods can be easily integrated with our framework directly for further improvement. Extensive experiments conducted on standard benchmarks demonstrate the effectiveness of the framework. 2