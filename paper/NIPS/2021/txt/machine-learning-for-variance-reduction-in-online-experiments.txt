Abstract
We consider the problem of variance reduction in randomized controlled trials, through the use of covariates correlated with the outcome but independent of the treatment. We propose a machine learning regression-adjusted treatment effect estimator, which we call MLRATE. MLRATE uses machine learning predictors of the outcome to reduce estimator variance. It employs cross-ﬁtting to avoid over-ﬁtting biases, and we prove consistency and asymptotic normality under general conditions. MLRATE is robust to poor predictions from the machine learning step: if the predictions are uncorrelated with the outcomes, the estimator performs asymptotically no worse than the standard difference-in-means estimator, while if predictions are highly correlated with outcomes, the efﬁciency gains are large.
In A/A tests, for a set of 48 outcome metrics commonly monitored in Facebook experiments the estimator has over 70% lower variance than the simple difference-in-means estimator, and about 19% lower variance than the common univariate procedure which adjusts only for pre-experiment values of the outcome. 1

Introduction
While sample sizes are typically larger for online experiments than traditional ﬁeld experiments, the desired minimum detectable effect sizes may be small, and the outcome variables of interest may be heavy-tailed. Even with quite large samples, statistical power may be low. Variance reduction methods play a key role in these settings, allowing for precise inferences with less data [12, 32, 38]. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
One common technique involves "adjusting" the simple difference-in-means estimator to account for covariate imbalances between the test and control groups [12, 22], with the magnitude of the adjustment depending on both the magnitude of those imbalances, and the correlation between the covariates and the outcome of interest. If covariates are highly correlated with the outcome, then the treatment effect estimator’s variance will decrease substantially.
Performing this adjustment procedure with the pre-experiment values of the outcome variable itself as the covariate can greatly reduce conﬁdence interval (CI) width, if the outcome exhibits high autocorrelation. A natural question is how to adjust for multiple covariates, which may have a complicated nonlinear relationship with the outcome variable. Using many covariates in a machine learning (ML) model, it may be possible to develop a proxy highly correlated with the outcome variable and hence generate further variance reduction gains. This raises both statistical and scalability issues, however, as it is unclear how traditional justiﬁcations for linear regression adjustment with a
ﬁxed number of covariates translate to the case of general, potentially very complex ML methods, and it may not be scalable to generate new predictions every time an experiment’s results are queried.
This paper makes three contributions. First, we propose an easy-to-implement and practical estimator which can take full advantage of ML methods to perform regression adjustment across a potentially large number of covariates, and derive its asymptotic properties. We name the procedure MLRATE, for “machine learning regression-adjusted treatment effect estimator”. MLRATE uses cross-ﬁtting (e.g. [3, 9, 25]), which simpliﬁes the asymptotic analysis and guarantees that the “naive” CIs which do not correct for the ML estimation step are asymptotically valid. We also ensure robustness of the estimator to poor quality predictions from the ML stage, by including those ML predictions as a covariate in a subsequent linear regression step. Our approach is agnostic or model-free in two key respects—we do not assume that the ML model converges to the truth, and in common with [22], in the subsequent linear regression step we do not assume that the true conditional mean is linear. Second, we demonstrate that the method works well for online experiments in practice.
Across a variety of metrics, the estimator reduces variance in A/A tests by around 19% on average relative to regression adjustment for pre-experiment outcomes only. Some metrics see variance reduction of 50% or more. Variance reduction of this magnitude can amount to the difference between experimentation being infeasibly noisy and being practically useful. Third, we sketch how the computational considerations involved in implementing MLRATE at scale can be surmounted. 2 Outcome prediction for variance reduction 2.1 Setup & motivation
The data consist of a vector of covariates X, an outcome variable Y , and a binary treatment indicator
T . The treatment is assigned randomly and independently of the covariates. For observations i = 1, 2, . . . , N , the vector (Yi, Xi, Ti) is drawn iid from a distribution P . To motivate our main estimator and illustrate some of the central ideas, ﬁrst consider a “difference-in-difference”-style estimator, where we train an ML model g(X) predicting Y from X, and then compute the difference between the test and control group averages of Y − g(X). If we treat the estimated ML model g as non-random and ignore its dependence on the sample, the resulting estimator has the same expectation as the usual difference-in-means estimator where we compute the difference between the test and control group averages of Y . This is because g(X) and T are independent, and hence
E[Y − g(X) | T = 1] − E[Y − g(X) | T = 0] = E[Y | T = 1] − E[Y | T = 0]. Furthermore, if g(X) is a good predictor of Y , then V ar(Y ) will exceed V ar(Y − g(X)), and the difference-in-difference estimator based on averages of Y − g(X) will be lower variance than the difference-in-means estimator based on averages of Y .
MLRATE differs in two main respects from the heuristic argument above. First, instead of directly subtracting the ML predictions g(X) from the outcome Y , we include them as a regressor in a subsequent linear regression step. This guarantees robustness of the estimator to poor, even asymptotically inconsistent predictions: regardless of how bad the outcome predictions from the
ML step are, MLRATE has an asymptotic variance no larger than the difference-in-means estimator.
Second, we use cross-ﬁtting to estimate the predictive models, so that the predictions for every observation are generated by a model trained only on other observations. This allows us to control the randomness in the ML function ignored in the argument above. We derive the asymptotic distribution of this regression-adjusted estimator, and show that the usual, “naive” CIs for the average treatment 2
effect (ATE), which ignore the randomness generated by estimating the predictive models, are in fact asymptotically valid. Thus asymptotically the ML step can only increase precision, and introduces no extra complications in computing CIs. 2.2