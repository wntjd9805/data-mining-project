Abstract
Many real-world problems are compositional – solving them requires completing interdependent sub-tasks, either in series or in parallel, that can be represented as a dependency graph. Deep reinforcement learning (RL) agents often struggle to learn such complex tasks due to the long time horizons and sparse rewards. To address this problem, we present Compositional Design of Environments (CoDE), which trains a Generator agent to automatically build a series of compositional tasks tailored to the RL agent’s current skill level. This automatic curriculum not only enables the agent to learn more complex tasks than it could have otherwise, but also selects tasks where the agent’s performance is weak, enhancing its robustness and ability to generalize zero-shot to unseen tasks at test-time. We analyze why current environment generation techniques are insufﬁcient for the problem of generating compositional tasks, and propose a new algorithm that addresses these issues. Our results assess learning and generalization across multiple compositional tasks, including the real-world problem of learning to navigate and interact with web pages. We learn to generate environments composed of multiple pages or rooms, and train RL agents capable of completing wide-range of complex tasks in those environments. We contribute two new benchmark frameworks for generating compositional tasks, compositional MiniGrid and gMiniWoB for web navigation.
CoDE yields 4x higher success rate than the strongest baseline, and demonstrates strong performance of real websites learned on 3500 primitive tasks.

Introduction 1
Consider purchasing an airline ticket, logging in to a website, or buying movie tickets. These tasks can be completed by mastering a small set of basic manipulation skills (primitives), such as entering an appropriate text in a ﬁll-in ﬁeld, or selecting a date, and combining them in different ways to form complex, compositional tasks [42]. Humans can easily generalize between compositional tasks – purchase a ticket on an airline or ﬁll out a form that they have not seen before, even when the task carries over several pages – but training autonomous agents to do this is far from straightforward.
Yet, unlocking generalization across related tasks would pave the way towards autonomous agents that can automatically handle the details of completing wide variety of real-world user requests such as, “Buy me a plane ticket to Los Angeles leaving on Friday”. The complexity and diversity of real environments make this a formidable challenge, especially due to the exponentially exploding action space and sparse rewards.
Generalizing across compositional tasks is challenging for several reasons, including the tractability of training [42]. Many compositional tasks require planning over an excessively long horizon while providing only sparse rewards, making it difﬁcult for RL agents to learn. Presenting easy tasks 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
(a) Iter=100 (b) Iter=12000 (c) Iter=24000 (d) Web Nav. Test (e) cMiniGrid Test
Figure 1: Environments examples. Generated Web pages become more complicated over the course of training (a-c), unseen test “Login” website (d) and "Task List" minigrid (e) environments. More in Appendix A.13. until the agent learns can be a solution, but it is not clear how to construct such a curriculum for complex compositional tasks [20]. Manually designing a pre-deﬁned curriculum is tedious, and intractable. Domain randomization (DR) [41; 17] does not tailor the difﬁculty of the task to the ability of the agent. Automatically generating tasks tailored to the agent’s learning progress is a promising approach, but as we will show, current approaches (e.g. [8]) suffer from fundamental limitations in the context of generating compositional tasks.
We present a new automatic curriculum generation algorithm, Compositional Design of Environments (CoDE), which jointly trains a Generator and a population of Learner agents. The generator is trained with a novel multi-objective reward function. Its ﬁrst objective is to maximize the regret between the agents in the population and the best-performing agent, stabilizing regret estimation and making it less vulnerable to becoming stuck in local minima. Second, the generator is trained to adjust the task difﬁculty to match the learners’ proﬁciency using an explicit difﬁculty incentive designed for use with compositional tasks. In this way, the generator builds more challenging environments when the learners are performing well, and reduces the difﬁculty when the learners are struggling. We demonstrate that this difﬁculty incentive addresses degenerative edge cases present in prior work.
By automatically searching for tasks on which the learners are performing poorly, the generator makes the learners more robust, enabling them to generalize to unseen tasks at test time. This ability is necessary for many real-world tasks, such as web navigation. Prior work on web navigation relied on collecting demonstration data from a series of training websites [36; 21], or training a separate policy for every single website [17]. These techniques cannot scale to a production-quality system, because they would require re-training the agents every time an airline company updated its site. In contrast, we show that CoDE produces robust agents with general form-ﬁlling and navigation skills that can be applied zero-shot to novel tasks at test time.
Another challenge in learning compositional tasks is that the existing benchmarks do not match real-life complexities. For example, real websites are orders of magnitude more complex than existing benchmarks [36; 21]. To address this problem, we introduce two new benchmark tasks for compositional task generation, which we are releasing in open-source. The ﬁrst provides a way to automatically generate Minigrid [6] navigation tasks which include subtasks such as locating a key to open a door. The second, generative MiniWoB (gMiniWob), focuses on web navigation and manipulation (form-ﬁlling) tasks and enables a generator to construct increasingly complex form-ﬁlling websites, spanning multiple pages, out of common design primitives such as navigation bars, product carousels, item decks, and item carts (Figure 1). The evaluation environments in gMiniWoB are orders of magnitude more complex than MiniWoB, the prior web navigation benchmark [36].
This paper makes the following contributions. First, we formally introduce compositional tasks by drawing a connection to the Petri Nets graph formalism, and showing its relationship to POMDPs. We then analyze why prior techniques for automatically generating a curriculum of tasks are insufﬁcient for compositional tasks, and propose a new algorithm, CoDE that addresses these weaknesses. We build two new automatic task generation environments spanning simple navigation tasks and web navigation, and release both in open-source. We demonstrate strong empirical results across both domains. In the context of web navigation, we show that CoDE generates a curriculum of increasingly challenging websites. Resulting agents successfully generalize to complex, unseen sites at test time, and without additional training solve wide range of form-ﬁlling tasks from ﬂight purchases to 90% success rate, 4x improvement login in. CoDE agents solve the most difﬁcult tasks with
⇡ 2
(a) Primitives (b) Example 1 (c) Example 2
Figure 2: Examples of compositional task primitives (a) and two different compositional tasks composed using the same primitives (b-c). Note, passive primitives (in grey) that do not lead to the task progression and serve as a distraction for the agent. Difﬁculty budget for the generator is based on the number of primitives used. over the strongest baseline. Lastly, we demonstrate that the method scales up to real websites.
The implementation of CoDE and gMiniWoB framework are available in open source at https:
//github.com/google-research/google-research/tree/master/compositional_rl. 2