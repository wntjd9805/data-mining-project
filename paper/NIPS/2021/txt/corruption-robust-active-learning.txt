Abstract
We conduct theoretical studies on streaming-based active learning for binary classi-ﬁcation under unknown adversarial label corruptions. In this setting, every time before the learner observes a sample, the adversary decides whether to corrupt the label or not. First, we show that, in a benign corruption setting (which includes the misspeciﬁcation setting as a special case), with a slight enlargement on the hypoth-esis elimination threshold, the classical RobustCAL framework can (surprisingly) achieve nearly the same label complexity guarantee as in the non-corrupted setting.
However, this algorithm can fail in the general corruption setting. To resolve this drawback, we propose a new algorithm which is provably correct without any assumptions on the presence of corruptions. Furthermore, this algorithm enjoys the minimax label complexity in the non-corrupted setting (which is achieved by
RobustCAL) and only requires ˜O(Ctotal) additional labels in the corrupted setting to achieve O(ε + Ctotal n ), where ε is the target accuracy, Ctotal is the total number of corruptions and n is the total number of unlabeled samples. 1

Introduction
An active learning algorithm for binary classiﬁcation aims to obtain the best hypothesis (classiﬁer) from some given hypothesis set while requesting as few labels as possible. Under some favorable conditions, active learning algorithms can require exponentially fewer labels then passive, random sampling [Hanneke, 2014]. Active learning is ideally suited for applications where large datasets are required for accurate inference, but the cost of paying human annotators to label a dataset is prohibitively large [Joshi et al., 2009, Yang et al., 2015, Beluch et al., 2018]. A bit more formally, for an example space X (such as a set of images) and label space {0, 1} (like whether the image contains a human-made object or not), let H be a hypothesis class such that for each h ∈ H, we have h : X → {0, 1}. After a certain number of labels are requested, the learner will output a target hypothesis hout ∈ H. In this paper, we consider the streaming setting where at each time t nature reveals xt ∼ DX and an active learning algorithm must make the real-time decision on whether to request the corresponding label yt or not. Such a streaming setting of active learning is frequently encountered in online environments such as learning a spam ﬁlter or fraud detection (i.e., mark as spam/fraudulent and do not request the label, or send to inbox/expert to obtain a label).
This paper is interested in a setting when the requested label yt is potentially corrupted by an adversary. That is, when requesting the label for some example xt ∈ X , if uncorrupted the learner will receive a label drawn according to the “true” conditional label distribution, but if corrupted, the learner will receive a label drawn from an arbitrary distribution decided by an adversary. This setting is challenging because the learner has no a priori knowledge of when or how many corruptions will occur. And if the learner is collecting data adaptively, he may easily be misled into becoming conﬁdent in an incorrect belief, collect data based on that belief, and never recover to output an accurate classiﬁer even if the adversary eventually stops serving corrupted labels later. This greatly contrasts with the passive setting (when all labels are observed) where as long as the number of 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
corrupts grows sub-linearly over time, the effect of the corruptions will fade and the empirical risk minimizer will converge to an accurate classiﬁer with respect to the uncorrupted labels.
The source of corruptions can come from automatic labeling, non-expert labeling, and, mostly severely, adaptive data poisoning adversaries. Particularly, with the rise of crowdsourcing, it is increasingly feasible for such malicious labelers to enter the system (Miller et al. [2014], Awasthi et al. [2014]). There have been many prior works that consider robust ofﬂine training using corrupted labels (i.e., the passive setting) [Hendrycks et al., 2018, Yu et al., 2019]. Correspondingly, related corruption settings have also been considered in online learning [Gupta et al., 2019, Zimmert and
Seldin, 2019, Wei et al., 2020] and reinforcement learning [Lykouris et al., 2020, Chen et al., 2021a,
Wei et al., 2021]. However, there is a striking lack of such literature in the active learning area.
Existing disagreement-based active learning algorithms nearly achieve the minimax label complexity for a given target accuracy when labels are trusted [Hanneke, 2014], but they fail to deal with the case where the labels are potentially corrupted.
Our contributions:
In this paper, we study active learning in the agnostic, streaming setting where an unknown number of labels are potentially corrupted by an adversary. We begin with the performance of existing baseline algorithms.
• Firstly, we analyze the performance of empirical risk minimization (ERM) for the passive
-optimal hypothesis
ε2 , where R∗ is the risk of best hypothesis. This result serves as a setting where all labels are observed, which will output an as long as n (cid:39) 1 benchmark for the following active learning results (Section 3).
ε + R∗Ctotal (cid:15) + R∗ (cid:16) (cid:17) n
If we assume that the disagreement coefﬁcient, a quantity that characterizes the sample complexity of active learning algorithms [Hanneke, 2014], is some constant, then we obtain the following results for active learning.
• Secondly, we analyze the performance of a standard active learning algorithm called Robust-CAL [Balcan et al., 2009, Dasgupta et al., 2007, Hanneke, 2014] under a benign assumption on the corruptions (misspeciﬁcation model is a special case under that assumption).We show that, by slightly enlarging the hypothesis elimintion threshold, this algorithm can achieve almost the same label complexity as in the non-corrupted setting. That is, the algorithm will output an O(ε + R∗Ctotal
ε with at most (cid:101)O (R∗n + log(n)) number of labels (Section 4).
)-optimal hypothesis as long as n (cid:39) R∗
ε2 + 1 n
• Finally and most importantly, in the general corruption case without any assumptions on how corruptions allocated, we propose a new algorithm that matches RobustCAL in the non-corrupted case and only requires (cid:101)O(Ctotal) additional labels in the corrupted setting.
That is, the algorithm will output an (cid:0)ε + Ctotal (cid:1)-optimal hypothesis as long as n (cid:39) 1
ε2 with (cid:1) number of labels. Besides, this algorithm also enjoys at most (cid:101)O (cid:0)(R∗)2n + log(n) + Ctotal an improved bound under a benign assumption on the corruptions. That is, the algorithm will (cid:1)
-optimal hypothesis with at most (cid:101)O (cid:0)(R∗)2n + log(n) + R∗Ctotal output an number of labels (Section 5)
ε + R∗Ctotal (cid:17) (cid:16) n n
Note that Ctotal can be regarded as a ﬁxed budget or can be increasing with incoming samples. In the latter case, Ctotal in the second and third result can be different since they may require different n.
Detailed comparison between these two results will be discussed in corresponding sections.