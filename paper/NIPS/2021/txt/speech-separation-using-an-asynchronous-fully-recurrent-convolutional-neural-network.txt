Abstract
Recent advances in the design of neural network architectures, in particular those specialized in modeling sequences, have provided signiﬁcant improvements in speech separation performance. In this work, we propose to use a bio-inspired architecture called Fully Recurrent Convolutional Neural Network (FRCNN) to solve the separation task. This model contains bottom-up, top-down and lateral connections to fuse information processed at various time-scales represented by stages. In contrast to the traditional approach updating stages in parallel, we propose to ﬁrst update the stages one by one in the bottom-up direction, then fuse information from adjacent stages simultaneously and ﬁnally fuse information from all stages to the bottom stage together. Experiments showed that this asynchronous updating scheme achieved signiﬁcantly better results with much fewer parameters than the traditional synchronous updating scheme. In addition, the proposed model achieved good balance between speech separation accuracy and computational efﬁciency as compared to other state-of-the-art models on three benchmark datasets. 1

Introduction
Speech separation aims to extract individual speeches from a mixture of speeches of multiple speakers. It is an important preprocessing step for speech recognition in noisy environment. Recent development of speech separation methods at the waveform level has aroused researchers’ interest
[21, 22, 20], avoiding the traditional representation of STFT amplitude and phase used in so-called time-frequency (TF) domain methods [7, 11]. Among these so-called time-domain methods, some presented mechanisms fuse information processed at various time scales, called multi-scale fusion (MSF) methods, such as in FurcaNeXt [40] or SuDoRM-RF [33], and yield impressive results on the speech separation task. In this work we aim to explore if there exist even better MSF methods.
Evidence from observations of sensory systems of mammals show them to utilize MSF in their processing. For instance, the visual system includes multiple processing stages (from lower functional areas such as the lateral geniculate nucleus to higher functional areas such as the inferior temporal cortex), which process different scales of information [1]: the higher the stage, the coarser the scale. See Figure 1a for illustration. Similar mechanisms and areas have also been identiﬁed and located in the auditory system [1]. More importantly, physiological and anatomical studies have revealed abundant recurrent synaptic connections within the same stage (also called lateral
∗Corresponding author. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
Figure 1: The structure of FRCNN and typical updating schemes. The number of stages S = 4. (a) The structure of the FRCNN. Every node denotes a stage, corresponding to a group of neurons in a functional area in the sensory pathway (e.g., the inferior colliculus in the auditory pathway). Red, blue and orange arrows denote bottom-up, top-down and lateral connections, respectively. Both bottom-up and top-down connections can be made between adjacent stages and non-adjacent stages. (b) Synchronous updating scheme in one block [19]. (c) The proposed asynchronous updating scheme in one block. The dashed box in each subﬁgure indicates the basic building block for constructing a complete RNN (see Figure 4). (d) Multi-scale information fusion for an example stage receiving three types of inputs. connections) and bottom-up/top-down synaptic connections between stages [3]. The intra-stage and inter-stage connections bring different scales of sensory information together and each stage performs information fusion. These connections fuse different scales of information more completely, and may lead to better results than existing MSF methods.
However, Figure 1a merely reﬂects a purely static structure in the brain and does not show the dynamics of the sensory system. In biological systems, given a stimulus, the neurons along a sensory hierarchy do not ﬁre simultaneously like shown in Figure 1b. For example, it was reported that the neural response initialized at a retinotopic position in anesthetized rat V1 propagated uniformly in all directions with a velocity of 50–70 mm/s, slowed down at the V1/V2 area border, after a short interval, spread in V2, then reﬂected back in V1 [38]. In general, “the speed of an action potential varies among neurons in a range from about 2 to 200 miles per hour”[24]. The time at which a neuron starts to ﬁre depends on a variety of factors including the neuron type, the stage at the sensory pathway, the number of the dendrites connected to it and the morphology of the neural ﬁbers. This precludes the possibility of faithfully replicating the sensory system to obtain an excellent artiﬁcial neural network (ANN). Nevertheless, the history of ANN development indicates that getting inspiration from the brain is enough to make great progress if task-speciﬁc techniques are combined. Inspired by the discovery of simple cells and complex cells in cat visual cortex [9, 10], a hierarchical model Neocognitron [6] was proposed and later developed into convolutional neural networks [15] by applying the backpropagation algorithm. We investigate empirically if there exists an asynchronous updating scheme for the structure shown in Figure 1a that provides improvement for speech separation performance.
As the model has bottom-up, top-down and lateral connections as shown in Figure 1a, we call the model a fully recurrent convolutional neural network (FRCNN). This name emphasizes the presence of both lateral and top-down recurrent connections in the model, distinguishing the model from an existing model [17] named recurrent convolutional neural network (RCNN) that has lateral recurrent connections only. The model with the synchronous updating scheme (Figure 1b) is called the synchronous FRCNN or S-FRCNN, which was studied for visual recognition [19]. We aim to propose an asynchronous FRCNN or A-FRCNN for speech separation. We notice that SuDoRM-RF
[33] also has the three types of connections and we start from its framework to study different updating schemes of FRCNN.
The architecture of our proposed A-FRCNN is illustrated in Figure 1c. The information ﬁrst passes through stages one by one in the bottom-up direction, then fuses between adjacent stages in parallel, and ﬁnally fuses together with skip connections to the bottom stage. In the S-FRCNN, the information transmission from the bottom stage to any upper stage then back to the bottom stage is too fast: one step upward and one step downward (Figure 1b). In contrast, in the A-FRCNN, the information starting from the bottom stage goes through more processing steps before it goes back to the bottom stage, which is advantageous for comprehensive MSF. Increasing the depth of a model is one of the keys for the success of deep learning. We will show the merit of A-FRCNN compared to S-FRCNN in experiments. 2
2