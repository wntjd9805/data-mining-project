Abstract
We investigate a low-rank model of quadratic classiﬁcation inspired by previous work on factorization machines, polynomial networks, and capsule-based architec-tures for visual object recognition. The model is parameterized by a pair of afﬁne transformations, and it classiﬁes examples by comparing the magnitudes of vectors that these transformations produce. The model is also over-parameterized in the sense that different pairs of afﬁne transformations can describe classiﬁers with the same decision boundary and conﬁdence scores. We show that such pairs arise from discrete and continuous symmetries of the model’s parameter space: in particular, the latter deﬁne symmetry groups of rotations and Lorentz transformations, and we use these group structures to devise appropriately invariant procedures for model alignment and averaging. We also leverage the form of the model’s decision boundary to derive simple margin-based updates for online learning. Here we explore a strategy of passive-aggressive learning: for each example, we compute the minimum change in parameters that is required to predict its correct label with high conﬁdence. We derive these updates by solving a quadratically constrained quadratic program (QCQP); interestingly, this QCQP is nonconvex but tractable, and it can be solved efﬁciently by elementary methods. We highlight the concep-tual and practical contributions of this approach. Conceptually, we show that it extends the paradigm of passive-aggressive learning to a larger family of nonlinear models for classiﬁcation. Practically, we show that these models perform well on large-scale problems in online learning. 1

Introduction
As data sets grow in size and complexity, they create new opportunities—and challenges—for large-scale applications of online learning [1]. These challenges have been extensively studied and, for the most part, elegantly resolved for the simplest linear models of classiﬁcation [2]. For such models, one particularly elegant approach is that of passive-aggressive learning [3]. In this framework, a model is only updated when it fails to classify an example correctly with high conﬁdence. When an update is triggered, however, the model is changed by whatever minimum amount is required to achieve this goal. This approach neatly dispenses with the need to choose or adapt learning rates.
Given the appeal of such updates, it is of natural interest to extend this approach to a larger family of nonlinear models. Proceeding from the linear model, this can be done most straightforwardly by the use of kernel methods [4–6]. But kernel methods do not scale effortlessly to the regime of online learning that we envision in this paper—where the examples are arriving in a streaming fashion from an essentially unlimited source [7, 8]. It is possible to adopt a budgeted approach [9–14] 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
for kernel-based passive-aggressive updates [15–17], conserving memory at the expense of model capacity, but this approach necessarily entails further complexities.
Without the kernel trick, we must face the crux of the problem. Passive-aggressive updates hinge on the ability to perform a fundamental calculation: when an update is triggered, we must compute the minimum change in model parameters that is required to ﬁx the classiﬁer’s decision boundary.
This is a relatively simple calculation for linear models (with hyperplane decision boundaries), but an enormously complex one for (say) decision trees, ensemble methods, and neural nets with threshold or ReLU activation functions. The question is whether this is true for all nonlinear models.
This paper investigates a family of low-rank models for quadratic classiﬁcation inspired by previous work on factorization machines [18, 19], polynomial networks [20, 21], and capsule-based archi-tectures for visual object recognition [22, 23]. For models in this family, we show how to derive passive-aggressive updates by solving a quadratically constrained quadratic program (QCQP). The
QCQP is nonconvex but tractable: it reduces to an elementary minimization over a bounded interval.
In this way, we are able to extend the framework of passive-aggressive learning to a larger family of nonlinear models. This is the paper’s main contribution.
The organization of this paper is as follows. In section 2, we review the main lines of work that motivated this study. In section 3, we formulate our model, elucidate its symmetries, and derive the updates for passive-aggressive learning. In section 4, we provide experimental results on a data set with 100M training examples. Finally, in section 5, we conclude and suggest some directions for future work. 2