Abstract
We study the problem of training certiﬁably robust models against adversarial examples. Certiﬁable training minimizes an upper bound on the worst-case loss over the allowed perturbation, and thus the tightness of the upper bound is an important factor in building certiﬁably robust models. However, many studies have shown that Interval Bound Propagation (IBP) training uses much looser bounds but outperforms other models that use tighter bounds. We identify another key factor that inﬂuences the performance of certiﬁable training: smoothness of the loss landscape. We ﬁnd signiﬁcant differences in the loss landscapes across many linear relaxation-based methods, and that the current state-of-the-arts method often has a landscape with favorable optimization properties. Moreover, to test the claim, we design a new certiﬁable training method with the desired properties. With the tightness and the smoothness, the proposed method achieves a decent performance under a wide range of perturbations, while others with only one of the two factors can perform well only for a speciﬁc range of perturbations. Our code is available at https://github.com/sungyoon-lee/LossLandscapeMatters. 1

Introduction
Despite the success of deep learning in many applications, the existence of adversarial example, an imperceptibly modiﬁed input that is designed to fool the neural network [34, 4], hinders the application of deep learning to safety-critical domains. There has been increasing interest in building a model that is robust to adversarial attacks [14, 26, 23, 47, 43, 16, 41]. However, most defense methods evaluate their robustness with adversarial accuracy against predeﬁned attacks. Thus, these defenses can be broken by new attacks [1, 6, 37, 8, 9].
To this end, many training methods have been proposed to build a certiﬁably robust model that can be guaranteed to be robust to adversarial perturbations [17, 28, 39, 11, 24, 15, 46, 2, 19]. They develop an upper bound on the worst-case loss over valid adversarial perturbations and minimize it to train a certiﬁably robust model. These certiﬁable training methods can be mainly categorized into two types: linear relaxation-based methods and bound propagation methods. Linear relaxation-based methods use relatively tighter bounds, but are slow, hard to scale to large models, and memory-inefﬁcient [39, 40, 11]. On the other hand, bound propagation methods, represented by Interval
Bound Propagation (IBP), are fast and scalable due to the use of simple but much looser bounds
[24, 15]. One would expect that training with tighter bounds would lead to better performance, but
IBP outperforms linear relaxation-based methods, especially when the perturbation is large, despite using much looser bounds. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
These observations on the performance of certiﬁable training methods raise the following questions:
Why does certiﬁable training with tighter bounds not result in a better performance?
What other factors may inﬂuence the performance of certiﬁable training?
In this paper, we provide empirical and theoretical analysis to answer these questions. First, we demonstrate that IBP [15] has a more favorable (smooth) loss landscape than other linear relaxation-based methods, and thus it often leads to better performance even with much looser bounds. To account for this difference, we present a uniﬁed view of IBP and linear relaxation-based methods and
ﬁnd that the relaxed gradient approximation (which will be deﬁned in Deﬁnition 1) of each method plays a crucial role in its optimization behavior. Based on the analysis of the loss landscape and the optimization behavior, we propose a new certiﬁable training method that has a favorable loss landscape with tighter bounds. As a result, the proposed method can achieve a decent performance under a wide range of perturbations. We summarize the contributions of this study as follows:
• We provide empirical and theoretical analysis of the loss landscape of certiﬁable training methods and ﬁnd that smoothness of the loss landscape is important for building certiﬁably robust models, in addition to the tightness of the upper bound.
• We ﬁnd that the relaxed gradient approximation of a certiﬁable training method plays a major role in shaping the loss landscape, determining its optimization behavior.
• To verify our claims, we propose a certiﬁable training method with tighter bounds and a favorable loss landscape. With the two key factors, the proposed method can achieve a decent performance under a wide range of perturbations, while others with only one of the two can perform well only for a speciﬁc range of the adversarial perturbations. 2