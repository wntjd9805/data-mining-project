Abstract
In this paper, we propose a transformer-based procedure for the efﬁcient registration of non-rigid 3D point clouds. The proposed approach is data-driven and adopts for the ﬁrst time the transformer architecture in the registration task. Our method is general and applies to different settings. Given a ﬁxed template with some desired properties (e.g. skinning weights or other animation cues), we can register raw acquired data to it, thereby transferring all the template properties to the input geometry. Alternatively, given a pair of shapes, our method can register the ﬁrst onto the second (or vice-versa), obtaining a high-quality dense correspondence between the two. In both contexts, the quality of our results enables us to target real applications such as texture transfer and shape interpolation. Furthermore, we also show that including an estimation of the underlying density of the surface eases the learning process. By exploiting the potential of this architecture, we can train our model requiring only a sparse set of ground truth correspondences (10 ∼ 20% of the total points). The proposed model and the analysis that we perform pave the way for future exploration of transformer-based architectures for registration and matching applications. Qualitative and quantitative evaluations demonstrate that our pipeline outperforms state-of-the-art methods for deformable and unordered 3D data registration on different datasets and scenarios. 1

Introduction
Recent technological advancements of 3D acquisition pipelines have produced an abundance of available data. The direct consequence is the non-standardization of the acquisition process. Such technological democratization brings along a disparate amount of different representations, dis-cretization, and arbitrary resolution. Given so, the request to align such data has become urgent.
Furthermore, data-driven statistical approaches require aligned data to relate feature changes across the population, inferring underlying patterns.
The Computer Vision community has devoted an extraordinary effort in the last decades to address 3D objects analysis. A common way to approach this problem is to align the geometry of one 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
source S target T output
Figure 1: Some results in real application targeted by our method. In the ﬁrst row, three examples of texture transfer on human shape pairs. In the second and third row, two examples of interpolation between intra-class and inter-class shapes from ShapeNet (one for each row). known shape to an incoming one. Such methodology is referred to as registration. Many different axiomatic pipelines have been proposed that address different kind of objects and domains. While many methods rely on the assumption that the shapes used in the registration task differ just by a rigid transformation, the non-rigid domain is far more complex and interesting. This category pertains organic objects (e.g., humans, animals, internal organs), which are particularly interesting as well.
Non-rigid registration aims to align two geometries that may differ by bending and stretching of the geometry, which may also signiﬁcantly modify its metric. This problem is even more complicated if the geometry representation is given just by a sparse point cloud.
However, an emerging ﬁeld merges data with classical algorithmic problems, exploiting such statistics as regularization. Among the different learning approaches, recently, the use of the Attention mechanism has become signiﬁcantly popular in NLP domain, being later transferred to Computer
Vision applications. Such architecture is called Transformers, and they represent one of the most signiﬁcant groundbreaking methodological advancement since the introduction of CNNs.
In this work, we aim to let non-rigid registration meet the transformers. Intuitively, we aim to use the transformer as a geometrical translator between two non-rigid point clouds. As the ﬁrst element, we modiﬁed the attention mechanism, proposing to make it aware of the underlying density of the geometry. Hence, we apply such a mechanism in an autoencoder–like architecture, which takes a template point cloud as input and aims to modify its geometry to ﬁt the target point cloud.
The proposed method achieves better results than several state-of-the-art competitors in the shape matching task. We show results on humans case, but also inter-class objects. In this second case, our method is trained in an unsupervised manner, showing the power of our attention mechanism to infer the underlying geometry. Also, thanks to the attention mechanism, we are able to interpret what the network considers relevant for the registration. Finally, we can target texture transfer and shape interpolation showing applicability in real tasks as demonstrated in 1.
Our contributions could be summarized as follows: (a) We propose the ﬁrst transformer for non-rigid registration task, showing the advantages of translation paradigm; (b) We modiﬁed the attention mechanism to make it aware of the point cloud density and of the underlying geometry of a shape; (c) We signiﬁcantly improve the state-of-the-art performances on different datasets and challenging scenarios.
All code and data is publicly available 1. 1https://github.com/GiovanniTRA/transmatching 2
2