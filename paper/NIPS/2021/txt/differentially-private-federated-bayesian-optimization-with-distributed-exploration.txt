Abstract
Bayesian optimization (BO) has recently been extended to the federated learning (FL) setting by the federated Thompson sampling (FTS) algorithm, which has promising applications such as federated hyperparameter tuning. However, FTS is not equipped with a rigorous privacy guarantee which is an important consideration in FL. Recent works have incorporated differential privacy (DP) into the training of deep neural networks through a general framework for adding DP to iterative algorithms. Following this general DP framework, our work here integrates DP into
FTS to preserve user-level privacy. We also leverage the ability of this general DP framework to handle different parameter vectors, as well as the technique of local modeling for BO, to further improve the utility of our algorithm through distributed exploration (DE). The resulting differentially private FTS with DE (DP-FTS-DE) algorithm is endowed with theoretical guarantees for both the privacy and utility and is amenable to interesting theoretical insights about the privacy-utility trade-off.
We also use real-world experiments to show that DP-FTS-DE achieves high utility (competitive performance) with a strong privacy guarantee (small privacy loss) and induces a trade-off between privacy and utility. 1

Introduction
Bayesian optimization (BO) has become popular for optimizing expensive-to-evaluate black-box functions, such as tuning the hyperparameters of deep neural networks (DNNs) [56]. Motivated by the growing computational capability of edge devices and concerns over sharing the raw data, BO has recently been extended to the federated learning (FL) setting [46] to derive the setting of federated
BO (FBO) [12]. The FBO setting allows multiple agents with potentially heterogeneous objective functions to collaborate in black-box optimization tasks without requiring them to share their raw data. For example, mobile phone users can use FBO to collaborate in optimizing the hyperparameters of their DNN models used in a smart keyboard application without sharing their sensitive raw data.
Hospitals can use FBO to collaborate with each other when selecting the patients to perform a medical test [67] without sharing the sensitive patient information. An important consideration in FL has been a rigorous protection of the privacy of the users/agents, i.e., how to guarantee that by participating in a FL system, an agent would not reveal sensitive information about itself [29]. Furthermore, incorporating rigorous privacy preservation into BO has recently attracted increasing attention due to its importance to real-world BO applications [33, 36, 48, 71]. However, the state-of-the-art algorithm in the FBO setting, federated Thompson sampling (FTS) [12], is not equipped with privacy guarantee and thus lacks rigorous protection of the sensitive agent information.
Differential privacy (DP) [20] provides a rigorous privacy guarantee for data release and has become the state-of-the-art method for designing privacy-preserving ML algorithms [28]. Recently, DP has been applied to the iterative training of DNNs using stochastic gradient descent (DP-SGD) [1] 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
and the FL algorithm of federated averaging (DP-FedAvg) [47], which have achieved competitive performances (utility) with a strong privacy guarantee. Notably, these methods have followed a general framework for adding DP to generic iterative algorithms [45] (referred to as the general DP framework hereafter), which applies a subsampled Gaussian mechanism (Sec. 2) in every iteration.
For an iterative algorithm (e.g., FedAvg) applied to a database with multiple records (e.g., data from multiple users), the general DP framework [45] can hide the participation of any single record in the algorithm in a principled way. For example, DP-FedAvg [47] guarantees (with high probability) that an adversary, even with arbitrary side information, cannot infer whether the data from a particular user has been used by the algorithm, hence preserving user-level privacy. Unfortunately, FTS [12] is not amenable to a straightforward integration of the general DP framework [45] (Sec. 3.1). So, we modify FTS to be compatible with the general DP framework and hence introduce the DP-FTS algorithm to preserve user-level privacy in the FBO setting. In addition to the theoretical challenge of accounting for the impact of the integration of DP in our theoretical analysis, we have to ensure that
DP-FTS preserves the practical performance advantage (utility) of FTS. To this end, we leverage the ability of the general DP framework to handle different parameter vectors [45], as well as the method of local modeling for BO, to further improve the practical performance (utility) of DP-FTS.
Note that FTS, as well as DP-FTS, is able to achieve better performance (utility) than standard TS by accelerating exploration using the information from the other agents (aggregated by the central server) [12]. That is, an agent using FTS/DP-FTS beneﬁts from needing to perform less exploration in the early stages. To improve the utility of DP-FTS even more, we further accelerate exploration in the early stages using our proposed distributed exploration technique which is a combination of local modeling for BO and the ability of the general DP framework to handle different parameter vectors. Speciﬁcally, we divide the entire search space into smaller local sub-regions and let every agent explore only one local sub-region at initialization. As a result, compared with the entire search space, every agent can explore the local sub-region more effectively because its Gaussian process (GP) surrogate (i.e., the surrogate used by BO to model the objective function) can model the objective function more accurately in a smaller local sub-region [21]. Subsequently, in every
BO iteration, the central server aggregates the information (vector) for every sub-region separately:
For a sub-region, the aggregation (i.e., weighted average) gives more emphasis (i.e., weights) to the information (vectors) from those agents who are assigned to explore this particular sub-region.
Interestingly, this technique can be seamlessly integrated into the general DP framework due to its ability to process different parameter vectors (i.e., one vector for every sub-region) while still preserving the interpretation as a single subsampled Gaussian mechanism [45] (Sec. 3.3).1 As a result, the information aggregated by the central server can help the agents explore every sub-region (hence the entire search space) more effectively in the early stages and thus signiﬁcantly improve the practical convergence (utility), as demonstrated in our experiments (Sec. 5). We refer to the resulting DP-FTS algorithm with distributed exploration (DE) as DP-FTS-DE. Note that DP-FTS is a special case of DP-FTS-DE with only one sub-region (i.e., entire search space). So, we will refer to
DP-FTS-DE as our main algorithm in the rest of this paper.
In this paper, we introduce the differentially private FTS with DE (DP-FTS-DE) algorithm (Sec. 3), the ﬁrst algorithm with a rigorous guarantee on the user-level privacy in the FBO setting. DP-FTS-DE guarantees that an adversary cannot infer whether an agent has participated in the algorithm, hence assuring every agent that its participation will not reveal its sensitive information.2 We provide theoretical guarantees for both the privacy and utility of DP-FTS-DE, which combine to yield a number of elegant theoretical insights about the privacy-utility trade-off (Sec. 4). Next, we empirically demonstrate that DP-FTS-DE delivers an effective performance with a strong privacy guarantee and induces a favorable trade-off between privacy and utility in real-world applications (Sec. 5). 2