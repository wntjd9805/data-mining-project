Abstract
We derive a novel information-theoretic analysis of the generalization property of meta-learning algorithms. Concretely, our analysis proposes a generic under-standing of both the conventional learning-to-learn framework [1] and the modern model-agnostic meta learning (MAML) algorithms [2]. Moreover, we provide a data-dependent generalization bound for a stochastic variant of MAML, which is non-vacuous for deep few-shot learning. As compared to previous bounds that depend on the square norm of gradients, empirical validations on both simulated data and a well-known few-shot benchmark show that the proposed bound is orders of magnitude tighter in most situations. 1

Introduction
Learning a task with limited samples is crucial for real-world machine learning applications, where proper prior knowledge is a key component for a successful transfer. Meta-Learning [3] or learning-to-learn (LTL) aims to extract such information through previous training tasks, which has recently re-emerged as an important topic.
Modern approaches based on MAML [2] have gained tremendous success by exploiting the capabili-ties of deep neural networks [4–9]. However, many theoretical questions still remain elusive. For instance, in the most popular methods for few-shot learning [10], the task-speciﬁc parameters and meta-parameter are updated in support (also called meta-train) and query (also called meta-validation) set, respectively. However, the majority of existing theoretical results such as [1, 11–14] do not pro-vide a formal understanding of such popular practice. Moreover, modern meta-learning approaches have incorporated over-parameterized deep neural networks, where conducting the theoretical analysis becomes even more challenging.
In this paper, we introduce a novel theoretical understanding of the generalization property of meta-learning through an information-theoretical perspective [15]. Compared with previous theoretical results, the highlights of our contributions are as follows:
Uniﬁed Approach We analyze two popular scenarios. 1) The conventional LTL [11], where the meta-parameters and task-speciﬁc parameters are updated within the same data set (referred as joint training). 2) The modern MAML-based approaches where the meta-parameters and task speciﬁc parameters are updated on distinct data sets (referred as alternate training), and for which the existing theoretical analysis is rare.
Flexible Bounds The proposed meta-generalization error bounds are highly ﬂexible: they are algorithm-dependant, data-dependant, and are valid for non-convex loss functions. 1) Speciﬁcally, the generalization error bound for joint-training (Theorem 5.1) is controlled by the mutual information
∗Department of Computer Science and Software Engineering, <qi.chen.1@ulaval.ca>
†Department of Electrical Engineering and Computer Engineering, <changjian.shui.1@ulaval.ca>
‡Department of Computer Science and Software Engineering, <mario.marchand@ift.ulaval.ca> 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
between the output of the randomized algorithm and the whole data set. It can cover the typical results of [12, 1], which can be interpreted with an environment-level and a task-level error. In addition, it reveals the beneﬁt of meta learning compared to single task learning. 2) Moreover, the generalization error bound for alternate-training (Theorem 5.2) is characterized by the conditional mutual information between the output of the randomized algorithm and the meta-validation dataset, conditioned on the meta-train dataset. Intuitively, when the outputs of a meta learning algorithm w.r.t. different input data-sets are similar (i.e. the algorithm is stable w.r.t. the data), the meta-generalization error bound will be small. This theoretical result is coherent with the recently-proposed Chaser loss in Bayes MAML [16].
Non-vacuous bounds for gradient-based few-shot learning Conventional gradient-based meta-learning theories heavily rely on the assumption of a Lipschitz loss. However, [17] pointed out that this Lipschitz constant for simple neural networks can be extremely large. Thus, conventional gradient-based upper bounds are often vacuous for deep few-shot scenarios. In contrast, we propose a tighter data-depend bound that depends on the expected gradient-incoherence rather than the gradient norm (the approximation of the Lipschitz constant) [18] for the Meta-SGLD algorithm, which is a stochastic variant of MAML that uses the Stochastic Gradient Langevin Dynamics (SGLD) [19].
We ﬁnally validate our theory in few-shot learning scenarios and obtain orders of magnitude tighter bounds in most situations, compared to conventional gradient-based bounds. 2