Abstract
Modelers use automatic differentiation (AD) of computation graphs to imple-ment complex deep learning models without deﬁning gradient computations.
Stochastic AD extends AD to stochastic computation graphs with sampling steps, which arise when modelers handle the intractable expectations common in re-inforcement learning and variational inference. However, current methods for stochastic AD are limited: They are either only applicable to continuous ran-dom variables and differentiable functions, or can only use simple but high vari-ance score-function estimators. To overcome these limitations, we introduce
Storchastic, a new framework for AD of stochastic computation graphs. Stor-chastic allows the modeler to choose from a wide variety of gradient estimation methods at each sampling step, to optimally reduce the variance of the gradi-ent estimates. Furthermore, Storchastic is provably unbiased for estimation of any-order gradients, and generalizes variance reduction techniques to any-order derivative estimates. Finally, we implement Storchastic as a PyTorch library at github.com/HEmile/storchastic. 1

Introduction
One of the driving forces behind deep learning is automatic differentiation (AD) libraries of complex computation graphs. Deep learning modelers are relieved by accessible AD of the need to implement complex derivation expressions of the computation graph. However, modelers are currently limited in settings where the modeler uses intractable expectations over random variables [37, 8]. Two common examples are reinforcement learning methods using policy gradient optimization [49, 29, 36] and latent variable models, especially when inferred using amortized variational inference [34, 20, 41, 43]. Typically, modelers estimate these expectations using Monte Carlo methods, that is, sampling, and resort to gradient estimation techniques [37] to differentiate through the expectation.
A popular approach for stochastic AD is reparameterization [20], which is both unbiased and has low variance, but is limited to continuous random variables and differentiable functions. The other popular approach [49, 45, 13] analyzes the computation graph and then uses the score function estimator to create a surrogate loss that provides gradient estimates when differentiated. While this approach is more general as it can also be applied to discrete random variables and non-differentiable functions, naive applications of the score function will have high variance, which leads to unstable and slow convergence. Furthermore, this approach is often implemented incorrectly [13], which can introduce bias in gradients.
We therefore develop a new framework called Storchastic to support deep learning modelers. They can use Storchastic to focus on deﬁning stochastic deep learning models without having to worry about complex gradient estimation implementations. Storchastic extends DiCE [13] to other gradi-ent estimation techniques than basic applications of the score function. It deﬁnes a surrogate loss by decomposing gradient estimation methods into four components: The proposal distribution, weight-35th Conference on Neural Information Processing Systems (NeurIPS 2021).
Figure 1: An illustration of the (parallelized) Storchastic loss computation. a. Assign the stochastic nodes of the input stochastic computation graph (SCG) into two topologically sorted partitions. b.
Evaluate the SCG. We ﬁrst sample the set of values X1 from the proposal distribution. For each of the samples xi ∈ X1, we then sample a set of samples X2. The rows in the ﬁgure indicate different samples in X1, while the columns indicate samples in X2. The different samples are used to evaluate the cost function f |X1| · |X2| times. c. Compute the weighting function, control variate and gradient function for all samples. d. Using those components and the cost function evaluation, compute the storchastic surrogate loss, mimicking Algorithm 1. (cid:12) refers to element-wise multiplication, ⊕ to element-wise summation and (cid:80) for summing the entries of a matrix. ing function, gradient function and control variate. We can use this decomposition to get insight into how gradient estimators differ, and use them to further reduce variance by adapting components of different gradient estimators.
Our main contribution is a framework with a formalization and a proof that, if the components sat-isfy certain conditions, performing n-th order differentiation on the Storchastic surrogate loss gives unbiased estimates of the n-th order derivative of the stochastic computation graph. We show these conditions hold for a wide variety of gradient estimation methods for ﬁrst order differentiation. For many score function-based methods like RELAX [16], MAPO [28] and the unordered set estimator
[25], the conditions also hold for any-order differentiation. In Storchastic, we only have to prove these conditions locally. This means that modelers are free to choose the gradient estimation method that best suits each sampling step, while guaranteeing that the gradient remains unbiased. Storchas-tic is the ﬁrst stochastic AD framework to incorporate the measure-valued derivative [40, 18, 37] and
SPSA [46, 2], and the ﬁrst to guarantee variance reduction of any-order derivative estimates through control variates.
In short, our contributions are the following: 1. We introduce Storchastic, a new framework for general stochastic AD that uses four gradi-ent estimation components, in Section 3.1-3.3. 2. We prove Theorem 1, which provides conditions under which Storchastic gives unbiased any-order derivative estimates in Section 3.4. To this end, we introduce a mathematical formalization of forward-mode evaluation in AD libraries in Section 2.4. 3. We derive a technique for extending variance reduction using control variates to any-order derivative estimation in Section 3.5. 4. We implement Storchastic as an open source library for PyTorch, Section 3.7. 2
Figure 2: A Stochastic Computation Graph representing the computation of the losses of an VAE with a discrete latent space. 2