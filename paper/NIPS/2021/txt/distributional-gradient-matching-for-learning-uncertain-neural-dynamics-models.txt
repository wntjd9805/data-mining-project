Abstract
Differential equations in general and neural ODEs in particular are an essential technique in continuous-time system identification. While many deterministic learning algorithms have been designed based on numerical integration via the adjoint method, many downstream tasks such as active learning, exploration in reinforcement learning, robust control, or filtering require accurate estimates of predictive uncertainties. In this work, we propose a novel approach towards estimating epistemically uncertain neural ODEs, avoiding the numerical integration bottleneck. Instead of modeling uncertainty in the ODE parameters, we directly model uncertainties in the state space. Our algorithm – distributional gradient matching (DGM) – jointly trains a smoother and a dynamics model and matches their gradients via minimizing a Wasserstein loss. Our experiments show that, compared to traditional approximate inference methods based on numerical integration, our approach is faster to train, faster at predicting previously unseen trajectories, and in the context of neural ODEs, significantly more accurate.

Introduction 1
For continuous-time system identification and control, ordinary differential equations form an essential class of models, deployed in ap-plications ranging from robotics (Spong et al., 2006) to biology (Jones et al., 2009). Here, it is assumed that the evolution of a system is de-scribed by the evolution of continuous state vari-ables, whose time-derivative is given by a set of parametrized equations. Often, these equations are derived from first principles, e.g., rigid body dynamics (Wittenburg, 2013), mass action ki-netics (Ingalls, 2013), or Hamiltonian dynamics (Greydanus et al., 2019), or chosen for computa-tional convenience (e.g., linear systems (Ljung, 1998)) or parametrized to facilitate system iden-tification (Brunton et al., 2016).
Such construction methods lead to intriguing properties, including guarantees on physical realizability (Wensing et al., 2017), favorable convergence properties (Ortega et al., 2018), or a structure suitable for downstream tasks such as control design (Ortega et al., 2002). However, such models often capture the system dynamics only approximately, leading to a potentially significant discrepancy between the model and reality (Ljung, 1999). Moreover, when expert knowledge is not available, or precise parameter values are cumbersome to obtain, system identification from raw time series data becomes
Figure 1: Illustration of DGM: Learning a joint smoother (first vs second row) across trajectories enables sharing observational data. Dynamics reg-ularization (first vs second column) substantially improves prediction accuracy of joint smoother.
∗Equal Contribution. Correspondence to trevenl@ethz.ch, wenkph@ethz.ch. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
Smoother: (t, x0)
GPφ (cid:55)−−−→ pS(x(t)), pS( ˙x(t))
Dynamics: x(t)
N Nψ (cid:55)−−−→ pD( ˙x(t)) max
ψ,φ log pS(XS) − λ · W2 2(pS( ˙XS), pD( ˙XD))
Figure 2: High-level depiction of DGM. necessary. In this case, one may seek more expressive nonparametric models instead (Rackauckas et al., 2020; Pillonetto et al., 2014). If the model is completely replaced by a neural network, the resulting model is called neural ODE (Chen et al., 2018). Despite their large number of parameters, as demonstrated by Chen et al. (2018); Kidger et al. (2020); Zhuang et al. (2020, 2021), deterministic neural ODEs can be efficiently trained, enabling accurate deterministic trajectory predictions. For many practical applications however, accurate uncertainty estimates are essential, as they guide downstream tasks like reinforcement learning (Deisenroth and Rasmussen, 2011; Schulman et al., 2015), safety guarantees (Berkenkamp et al., 2017), robust control design (Hjalmarsson, 2005), planning under uncertainty (LaValle, 2006), probabilistic forecasting in meteorology (Fanfarillo et al., 2021), or active learning / experimental design (Srinivas et al., 2010). A common way of obtaining such uncertainties is via a Bayesian framework. However, as observed by Dandekar et al. (2021),
Bayesian training of neural ODEs in a dynamics setting remains largely unexplored. They demonstrate that initial variational-based inference schemes for Bayesian neural ODEs suffer from several serious drawbacks and thus propose sampling-based alternatives. However, as surfaced by our experiments in
Section 4, sampling-based approaches still exhibit serious challenges. These pertain both to robustness (even if highly informed priors are supplied), and reliance on frequent numerical integration of large neural networks, which poses severe computational challenges for many downstream tasks like sampling-based planning (Karaman and Frazzoli, 2011) or uncertainty propagation in prediction.
Contributions
In this work, we propose a novel approach for uncertainty quantification in nonlinear dynamical systems (cf. Figure 1). Crucially, our approach avoids explicit costly and non-robust numerical integration, by employing a probabilistic smoother of the observational data, whose representation we learn jointly across multiple trajectories. To capture dynamics, we regularize our smoother with a dynamics model. Latter captures epistemic uncertainty in the gradients of the ODE, which we match with the smoother’s gradients by minimizing a Wasserstein loss, hence we call our approach Distributional Gradient Matching (DGM). In summary, our main contributions are:
• We develop DGM, an approach2 for capturing epistemic uncertainty about nonlinear dy-namical systems by jointly training a smoother and a neural dynamics model;
• We provide a computationally efficient and statistically accurate mechanism for prediction, by focusing directly on the posterior / predictive state distribution.
• We experimentally demonstrate the effectiveness of our approach on learning challenging, chaotic dynamical systems, and generalizing to new unseen inital conditions.
High-level overview A high-level depiction of our algorithm is shown in Figure 2. In principle,
DGM jointly learns a smoother (S) and a dynamics model (D). The smoother model, chosen to be a Gaussian process, maps an initial condition x0 and a time t to the state distribution pS(x(t)) and state derivatives distribution pS( ˙x(t)) reached at that time. The dynamics model, chosen to be a neural network, represents an ODE that maps states x(t) to the derivative distribution pD( ˙x(t)).
Both models are evaluated at some training times and all its output distributions collected in the
˙XS and ˙XD. The parameters of these models are then jointly trained using a random variables XS,
Wasserstein-distance-based objective directly on the level of distributions. For more details on every one of these components, we refer to Section 3. There, we introduce all components individually and then present how they interplay. Section 3 builds on known concepts from the literature, which we 2Code is available at: https://github.com/lenarttreven/dgm 2
summarize in Section 2. Finally, in Section 4, we present the empirical study of the DGM algorithm, where we benchmark it against the state-of-the-art, uncertainty aware dynamics models. 2