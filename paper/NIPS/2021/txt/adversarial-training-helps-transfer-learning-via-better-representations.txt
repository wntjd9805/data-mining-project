Abstract
Transfer learning aims to leverage models pre-trained on source data to efﬁciently adapt to target setting, where only limited data are available for model ﬁne-tuning.
Recent works empirically demonstrate that adversarial training in the source data can improve the ability of models to transfer to new domains. However, why this happens is not known.
In this paper, we provide a theoretical model to rigorously analyze how adversarial training helps transfer learning. We show that adversarial training in the source data generates provably better representations, so ﬁne-tuning on top of this representation leads to a more accurate predictor of the target data. We further demonstrate both theoretically and empirically that semi-supervised learning in the source data can also improve transfer learning by similarly improving the representation. Moreover, performing adversarial training on top of semi-supervised learning can further improve transferability, suggesting that the two approaches have complementary beneﬁts on representations. We support our theories with experiments on popular data sets and deep learning architectures. 1

Introduction
Transfer learning is a popular methodology to obtain well-performing machine learning models in settings where high-quality labeled data is scarce [20, 48]. The general idea of transfer learning to take a pre-trained model from a source domain—where labeled data is abundant—and adapt it to a new target domain. Because the target data distribution often differs from the source setting, standard transfer learning ﬁne-tunes the model using a small-amount of labeled data from the target domain.
In many applications, the ﬁne-tuning is performed only on the last few layers of the network if the amount of target data is limited or if the one only has access to a representation (i.e. intermediate layers) produced by the model instead of the full model.
Transfer learning has demonstrated substantial empirical success and there is an exciting literature investigating different approaches to making transfer learning more effective [26, 27]. Recent experiments empirically demonstrated an intriguing phenomenon that models that are trained using adversarial-robust optimization on the source data transfer better to target data compared to non-adversarially trained models. We illustrate this phenomenon in Figure 1, which replicates the ﬁndings
⇤Equal contribution. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).  
in [46]. Here two models are trained on the full ImageNet and 10% of ImageNet using different levels of adversarial training—✏ is the l2 magnitude of the adversarial attack. Following [46], we
ﬁne-tuned the last layer of the models using data from CIFAR-10 and plot the ﬁnal accuracy on the target CIFAR-10. Adversarial training ("> 0) signiﬁcantly improves the transfer performance compared to model without adversarial training (" = 0). Additional experiments demonstrating this effect are provided in [46, 55], however it is still an open question how adversarial training in source helps transfer learning.
As our ﬁrst contribution, we initialize the study of how adversarial training helps ﬁxed-feature transfer learning from a theoretical perspective. Our analysis shows how that adversarial training on the source learns a better repre-sentation such that ﬁne-tuning on this representation leads to better performance on the target. Interestingly, we show that the robust representation can help transfer learning even when the source performance declines due to adver-sarial training. To the best of our knowledge, this is the
ﬁrst rigorous analysis of the effect of adversarial training on transfer learning.
As our second contribution, we extend our analysis to show that semi-supervised learning using pseudo-labeling can similarly lead to better representations for transfer learning. We support our theory with empirical experi-ments. Moreover our experiments demonstrate for the ﬁrst time that performing adversarial training on top of pseudo-labeling in the source can further boost transfer learning performance. This suggests that the two data augmenta-tion techniques of adversarial training and pseudo-labeling have complementary beneﬁts on learned representations.
Figure 1: Transfer accuracy improves with adversarial training on source task.
We plot target task (CIFAR-10) accuracy across different levels of `2-adversarial training on the source task (ImageNet).
The value of " corresponds to the size of the adversarial attack; i.e., " = 0 in-dicates no adversarial training. The two curves correspond to training the source model using all of ImageNet and a 10% subsample of ImageNet.
As a third technical contribution, we generalize the tech-niques in prior papers for analyzing transfer learning in regressions to classiﬁcation settings, where adversarial training and pseudo-labeling are more commonly used. Together, our results provide a useful and tractable framework to understand factors that improve transfer learning.