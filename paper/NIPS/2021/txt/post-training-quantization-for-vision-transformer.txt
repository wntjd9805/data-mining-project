Abstract
Recently, transformer has achieved remarkable performance on a variety of com-puter vision applications. Compared with mainstream convolutional neural net-works, vision transformers are often of sophisticated architectures for extracting powerful feature representations, which are more difﬁcult to be developed on mo-bile devices. In this paper, we present an effective post-training quantization algo-rithm for reducing the memory storage and computational costs of vision transform-ers. Basically, the quantization task can be regarded as ﬁnding the optimal low-bit quantization intervals for weights and inputs, respectively. To preserve the function-ality of the attention mechanism, we introduce a ranking loss into the conventional quantization objective that aims to keep the relative order of the self-attention re-sults after quantization. Moreover, we thoroughly analyze the relationship between quantization loss of different layers and the feature diversity, and explore a mixed-precision quantization scheme by exploiting the nuclear norm of each attention map and output feature. The effectiveness of the proposed method is veriﬁed on several benchmark models and datasets, which outperforms the state-of-the-art post-training quantization algorithms. For instance, we can obtain an 81.29% top-1 accu-racy using DeiT-B model on ImageNet dataset with about 8-bit quantization. Code will be available at https://gitee.com/mindspore/models/tree/master/research/cv/VT-PTQ. 1

Introduction
Following the applications in Natural Language Processing (NLP) tasks, transformer-based models have shown great power in various Computer Vision (CV) tasks, such as image classiﬁcation [11, 26], object detection [4, 39] and image super-resolution [5]. Pre-trained with large-scale data, these models usually have hundreds of millions of parameters. For instance, there are 307M parameters and 64G FLOPs in the ViT-L model, which is both memory and computation expensive during inference. This brings great challenges for these models to run on resource-constrained devices like mobile phones and intelligent cars. Besides, the real-time computer vision applications that integrate transformer-based models have to meet low latency requirements to achieve a high quality customer experience. Therefore, the model compression technology of transformer-based models is urgently needed for deployment in industrial environments.
Among various compression methods like pruning [16, 29, 19] and weight decomposition [37], quantization method [9, 38, 7, 27, 14, 32] compresses a neural network by using lower bit-width for weight values without changing the model architecture, which is particularly useful for carefully-designed network architectures like transformers. Quantizing both weights and inputs can speed up inference by tuning ﬂoating-point operations into integer or bit operations. There have been some
∗Corresponding author 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
training-aware quantization approaches for transformer-based models in NLP (e.g., BERT [17]) [34, 23, 35, 22]. However, these methods are not designed for computer vision tasks and usually need additional training or ﬁne-tuning. Furthermore, in some scenarios, the entire training data is not available to optimize the quantization model and the training costs for edge devices are intolerable.
Post-training quantization [24] is a kind of efﬁcient model compression technique, which can directly quantize neural network models without ﬁne-tuning. Most of the existing post-training quantization methods are designed for convolutional neural networks [3, 21, 30] or recurrent neural networks [36].
These methods do not take the character of vision transformer into consideration (e.g., the attention mechanism do not exist in CNNs), which are not perfectly suitable for quantizing vision transformer.
However, vision transformers are showing stronger performance in a large variety of computer vision tasks. Thus, we are motivated to explore the post-training quantization for them to reduce the costs on memory and computation.
In this paper, we study the post-training quantization method for vision transformer models with mixed-precision for higher compression and speed-up ratios. The quantized process in the transformer is formulated as an optimization problem for ﬁnding the optimal quantization intervals. Specially, our goal is to maximize the similarity between the full-precision and quantized outputs in vision transformers. To better preserve the functionality of the attention mechanism, we thoroughly analyze the difference between attention layers and conventional layers such as MLP. Then, a ranking loss is introduced to keep the relative order of attention values. Furthermore, we propose to determine the bit-widths of each layer according to the feature diversity, i,e,, the nuclear norm calculated by the attention map and output features. We alternatively search the quantization intervals of weights and inputs in all layers to obtain the best quantization results. In addition, bias correction is introduced to diminish the cumulative quantization error. Experimental results on several benchmarks demonstrate the effectiveness of our algorithm for achieving better performance over the state-of-art post-training quantization approaches. 2