Abstract
In reinforcement learning, pre-trained low-level skills have the potential to greatly facilitate exploration. However, prior knowledge of the downstream task is required to strike the right balance between generality (ﬁne-grained control) and speciﬁcity (faster learning) in skill design. In previous work on continuous control, the sensi-tivity of methods to this trade-off has not been addressed explicitly, as locomotion provides a suitable prior for navigation tasks, which have been of foremost interest.
In this work, we analyze this trade-off for low-level policy pre-training with a new benchmark suite of diverse, sparse-reward tasks for bipedal robots. We alleviate the need for prior knowledge by proposing a hierarchical skill learning framework that acquires skills of varying complexity in an unsupervised manner. For utilization on downstream tasks, we present a three-layered hierarchical learning algorithm to automatically trade off between general and speciﬁc skills as required by the respec-tive task. In our experiments, we show that our approach performs this trade-off effectively and achieves better results than current state-of-the-art methods for end-to-end hierarchical reinforcement learning and unsupervised skill discovery. Code and videos are available at https://facebookresearch.github.io/hsd3. 1

Introduction
A promising direction for improving the sample efﬁciency of reinforcement learning agents in com-plex environments is to pre-train low-level skills that are then used to structure the exploration in downstream tasks [23, 19, 27, 13, 30]. This has been studied in particular for the control of (simulated) robots, where there is a natural hierarchical decomposition of the downstream tasks into low-level con-trol of the robot’s actuators with a skill policy, and a high-level control signal that speciﬁes a direction or target robot conﬁguration with coarser temporal resolution. The large body of work on unsuper-vised skill or option discovery in hierarchical reinforcement learning (HRL) for continuous control relies, explicitly or implicitly, on prior knowledge that low-level skills should control the center of mass of the robot [26, 17, 13, 43, 6]. This nicely ﬁts a wide range of benchmark tasks that are variants of navigation problems, but the beneﬁt of such hierarchical setups outside this problem class is unclear.
The prior knowledge embedded in a pre-trained skill deﬁnes a speciﬁc trade-off between sample efﬁciency and generality. Skills that severely constrain the high-level action space to elicit speciﬁc behavior (e.g., translation of the center of mass) are likely to provide the largest gains in sample efﬁ-ciency, but are unlikely to be useful on a diverse set of downstream tasks. Conversely, low-level skills that expose many degrees of freedom are more widely applicable but less useful for guiding explo-ration. There is, thus, no single universally superior pre-trained skill. Depending on the downstream task, different skills might also be useful to efﬁciently explore in different parts of the environment.
In this paper, we aim to acquire skills that are useful for a variety of tasks while still providing strong exploration beneﬁts. We propose to pre-train a hierarchy of skills of increasing complexity which can subsequently be composed with a high-level policy. In the context of simulated robots, each skill consists of controlling a part of the robot conﬁguration over a short time horizon, such 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
as the position of the left foot of a humanoid, or the orientation of its torso. Skills of increasing complexity are constructed by jointly controlling larger portions of the conﬁguration. These skills are modelled with a shared policy and pre-trained in an environment without rewards and containing the robot only. Subsequently, skills are used in downstream tasks within a three-level hierarchical policy: the highest level selects the skill (which speciﬁes a goal space), the second level the target conﬁguration within that skill (the goal), and the pre-trained skill performs the low-level control to reach the goal. Compared to standard approaches involving a single static pre-trained skill [13, 43], our approach offers increased ﬂexibility for structuring exploration and ofﬂoads the issue of selecting prior knowledge from pre-training to downstream task learning. As a result, our skills can be acquired once per robot and applied to many different tasks.
We perform an experimental analysis of our hierarchical pre-training on a new set of challenging sparse-reward tasks with simulated bipedal robots. Our experiments show that each task is most efﬁciently explored by a distinct set of low-level skills, conﬁrming that even on natural tasks, where locomotion is of primal importance, there is no overall single best pre-trained skill. We further show that dynamic selection of goal spaces with a three-level hierarchy performs equally or better than a generic skill on all tasks, and can further improve over the best single skills per task.
The main contributions of our work are summarized as follows:
• We propose a novel unsupervised pre-training approach that produces a hierarchy of skills based on control of variable feature sets.
• We demonstrate how to automatically select between different skills of varying complexity with a three-level hierarchical policy that selects skills, goals, and native actions.
• We introduce a benchmark suite of sparse-reward tasks that allows for consistent and thorough evaluation of motor skills and HRL methods beyond traditional navigation settings.
• We study the implications of prior knowledge in skills experimentally and showcase the efﬁcacy of our hierarchical skill framework on the proposed benchmark tasks, achieving superior results compared to existing skill discovery and HRL approaches [13, 33, 53]. 2