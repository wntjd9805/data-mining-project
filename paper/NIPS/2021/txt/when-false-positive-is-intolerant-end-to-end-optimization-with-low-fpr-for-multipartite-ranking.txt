Abstract
Multipartite ranking is a basic task in machine learning, where the Area Under the receiver operating characteristics Curve (AUC) is generally applied as the evaluation metric. Despite that AUC reﬂects the overall performance of the model, it is inconsistent with the expected performance in some application scenarios, where only a low False Positive Rate (FPR) is meaningful. To leverage high perfor-mance under low FPRs, we consider an alternative metric for multipartite ranking evaluating the True Positive Rate (TPR) at a given FPR, denoted as TPR@FPR.
Unfortunately, the key challenge of direct TPR@FPR optimization is two-fold: a) the original objective function is not differentiable, making gradient backpropaga-tion impossible; b) the loss function could not be written as a sum of independent instance-wise terms, making mini-batch based optimization infeasible. To address these issues, we propose a novel framework on top of the deep learning frame-work named Cross-Batch Approximation for Multipartite Ranking (CBA-MR). In face of a), we propose a differentiable surrogate optimization problem where the instances having a short-time effect on FPR are rendered with different weights based on the random walk hypothesis. To tackle b), we propose a fast ranking estimation method, where the full-batch loss evaluation is replaced by a delayed update scheme with the help of an embedding cache. Finally, experimental results on four real-world benchmarks are provided to demonstrate the effectiveness of the proposed method. 1

Introduction
The multipartite ranking is a multi-class extension of bipartite ranking, aiming to sort a dataset with multiple discrete labels in proper order. Different from general multi-class classiﬁcation, the categories in multipartite ranking are arranged according to a certain attribute. In the past decade, multipartite ranking is studied in a variety of application scenarios in the ﬁeld of computer vision, including age estimation[33], monocular depth estimation [12] and aesthetic visual analysis [32], etc.
Previous literature [13, 29, 35, 37, 38] uses Area Under the ROC Curve (AUC) as the evaluation metric for multipartite ranking. Intuitively, Hanley & McNeil [18] prove that AUC measures the probability expectation that positive instances are sorted higher than negative instances. This metric
∗Corresponding authors. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
is less sensitive to class imbalance than other metrics like accuracy [41]. Beside AUC, other common used metrics include accuracy and mean square error (MSE) (see Sec. 2).
However, do these metrics always reﬂect the model performance in different scenarios properly?
This problem has more signiﬁcance under False Positive Rate (FPR) sensitive application scenarios, i.e., predictions leading to high false positive rates are intolerant. In these cases, the metrics mentioned above cannot properly measure the desired performance, especially when the expected FPR is low.
One example of such scenarios is medical diagnosis [24, 25]. Considering diseased cases as negatives, more patients are missed if FPR is higher. Another example of churn in the telecommunications industry is provided by Mozer et al.[31].
Based on the above consideration, our interest is to optimize the True Positive Rate (TPR) at a ﬁxed
False Positive Rate (FPR) for multipartite ranking, denoted as TPR@FPR. For practical reasons described above, the chosen FPR is in general small. Despite the practical advantages, it is infeasible to optimize such a metric in an end-to-end manner. To be concrete, the main challenges are as follows: (C1) TPR@FPR is a constrained combinatorial optimization problem, where the gradients of the objective function are not directly available even when proper surrogate losses are utilized. (C2) The loss function could not be expressed as a sum of independent instance-wise terms, making the stochastic optimization unavailable.
To solve these problems, we propose a novel method named Cross-Batch Approximation for Mul-tipartite Ranking (CBA-MR). In a nutshell, the main contributions of this paper are summarized as follows:
•
•
•
We consider a new evaluation metric TPR@FPR for multipartite ranking in FPR sensitive scenarios. This metric focuses on model performance with a low FPR, which is consistent with practical requirements.
To optimize the TPR@FPR metric, we propose Cross-Batch Approximation for Multipartite
Ranking. The main idea is to relax the tricky hard constraint on FPR as a probability-based loss function. Speciﬁcally, we propose a random-walk model to measure the possibility that a negative instance will affect short-term FPR value. On top of this model, we propose a differentiable loss function that automatically focuses on hard negative instances.
Motivated by the slow feature drift phenomenon, we introduce a nonparametric cross-batch cache module to approximate the ranking of negative examples rapidly. An upper bound of the approximation error is provided to exhibit the feasibility of approximation. 2