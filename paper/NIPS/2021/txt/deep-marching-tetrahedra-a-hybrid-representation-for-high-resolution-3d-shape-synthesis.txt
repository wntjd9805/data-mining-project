Abstract
We introduce DMTET, a deep 3D conditional generative model that can synthesize high-resolution 3D shapes using simple user guides such as coarse voxels. It marries the merits of implicit and explicit 3D representations by leveraging a novel hybrid 3D representation. Compared to the current implicit approaches, which are trained to regress the signed distance values, DMTET directly optimizes for the reconstructed surface, which enables us to synthesize ﬁner geometric details with fewer artifacts. Unlike deep 3D generative models that directly generate explicit representations such as meshes, our model can synthesize shapes with arbitrary topology. The core of DMTET includes a deformable tetrahedral grid that encodes a discretized signed distance function and a differentiable marching tetrahedra layer that converts the implicit signed distance representation to the explicit surface mesh representation. This combination allows joint optimization of the surface geometry and topology as well as generation of the hierarchy of subdivisions using reconstruction and adversarial losses deﬁned explicitly on the surface mesh. Our approach signiﬁcantly outperforms existing work on conditional shape synthesis from coarse voxel inputs, trained on a dataset of complex 3D animal shapes. Project page: https://nv-tlabs.github.io/DMTet/. 1

Introduction
Fields such as simulation, architecture, gaming, and ﬁlm rely on high-quality 3D content with rich geometric details and complex topology. However, creating such content requires tremendous expert human effort. It takes a signiﬁcant amount of development time to create each individual 3D asset. In contrast, creating rough 3D shapes with simple building blocks like voxels has been widely adopted.
For example, Minecraft has been used by hundreds of millions of users for creating 3D content. Most of them are non-experts. Developing A.I. tools that enable regular people to upscale coarse, voxelized objects into high resolution, beautiful 3D shapes would bring us one step closer to democratizing high-quality 3D content creation. Similar tools can be envisioned for turning 3D scans of objects recorded by modern phones into high-quality forms. Our work aspires to create such capabilities.
A powerful 3D representation is a critical component of a learning-based 3D content creation framework. A good 3D representation for high-quality reconstruction and synthesis should capture local geometric details and represent objects with arbitrary topology while also being memory and computationally efﬁcient for fast inference in interactive applications.
Recently, neural implicit representations [8, 39, 42, 51], which use a neural network to implicitly represent a shape via a signed distance ﬁeld (SDF) or an occupancy ﬁeld (OF), have emerged as an effective 3D representation. Neural implicits have the beneﬁt of representing complex geometry 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
and topology, not limited to a predeﬁned resolution. The success of these methods has been shown in shape compression [49, 13, 51], single-image shape generation [47, 60, 48], and point cloud reconstruction [57]. However, most of the current implicit approaches are trained by regressing to
SDF or OF values and cannot utilize an explicit supervision on the target surface, which imposes useful constraints for training. To mitigate this issue, several works [45, 31] proposed to utilize iso-surfacing techniques such as the Marching Cubes (MC) algorithm to extract a surface mesh from the implicit representation, which, however, is computationally expensive.
In this work, we introduce DMTET, a deep 3D conditional generative model for high-resolution 3D shape synthesis from user guides in the form of coarse voxels. In the heart of DMTET is a new differentiable shape representation that marries implicit and explicit 3D representations. In contrast to deep implicit approaches optimized for predicting sign distance (or occupancy) values, our model employs additional supervision on the surface, which empirically renders higher quality shapes with
ﬁner geometric details. Compared to methods that learn to directly generate explicit representations, such as meshes [54], by committing to a preset topology, our DMTET can produce shapes with arbitrary topology. Speciﬁcally, DMTET predicts the underlying surface parameterized by an implicit function encoded via a deformable tetrahedral grid. The underlying surface is converted into an explicit mesh with a Marching Tetrahedra (MT) algorithm, which we show is differentiable and more performant than the Marching Cubes. DMTET maintains efﬁciency by learning to adapt the grid resolution by deforming and selectively subdividing tetrahedra. This has the effect of spending computation only on the relevant regions in space. We achieve further gains in the overall quality of the output shape with learned surface subdivision. Our DMTET is end-to-end differentiable, allowing the network to jointly optimize the geometry and topology of the surface, as well as the hierarchy of subdivisions using a loss function deﬁned explicitly on the surface mesh.
We demonstrate our DMTET on two challenging tasks: 3D shape synthesis from coarse voxel inputs and point cloud 3D reconstruction. We outperform existing state-of-the-art methods by a signiﬁcant margin while being 10 times faster than alternative implicit representation-based methods at inference time. In summary, we make the following technical contributions: 1. We show that using Marching Tetrahedra (MT) as a differentiable iso-surfacing layer allows topological change for the underlying shape represented by a implicit ﬁeld, in contrast to the analysis in prior works [31, 45]. 2. We incorporate MT in a DL framework and introduce DMTET, a hybrid representation that combines implicit and explicit surface representations. We demonstrate that the additional supervision (e.g. chamfer distance, adversarial loss) deﬁned directly on the extracted surface from implicit ﬁeld improves the shape synthesis quality. 3. We introduce a coarse-to-ﬁne optimization strategy that scales DMTET to high resolution during training. We thus achieves better reconstruction quality than state-of-the-art methods on challenging 3D shape synthesis tasks, while requiring a lower computation cost. 2