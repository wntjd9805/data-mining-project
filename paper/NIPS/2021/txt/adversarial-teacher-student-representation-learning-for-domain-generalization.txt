Abstract
Domain generalization (DG) aims to transfer the learning task from a single or multiple source domains to unseen target domains. To extract and leverage the information which exhibits sufﬁcient generalization ability, we propose a simple yet effective approach of Adversarial Teacher-Student Representation Learning, with the goal of deriving the domain generalizable representations via generating and exploring out-of-source data distributions. Our proposed framework advances
Teacher-Student learning in an adversarial learning manner, which alternates be-tween knowledge-distillation based representation learning and novel-domain data augmentation. The former progressively updates the teacher network for deriving domain-generalizable representations, while the latter synthesizes data out-of-source yet plausible distributions. Extensive image classiﬁcation experiments on benchmark datasets in multiple and single source DG settings conﬁrm that, our model exhibits sufﬁcient generalization ability and performs favorably against state-of-the-art DG methods. 1

Introduction
Deep neural networks have achieved promising performance on a wide variety of tasks. However, these networks assume the training and testing samples fall in the same data distribution. Such a strong assumption would limit the applicability of the learned models in real-world scenarios (e.g., cross-city autonomous driving or multi-cite medical imaging task), in which training and testing data are typically observed under different conditions. In other words, the generalizability of the model at unseen target domains might be poor due to unexpected domain shifts. To tackle the domain discrepancy, domain generalization (DG) has been proposed and drawn increasing attention recently.
The aim of DG is to train models using data observed from single or multiple source domains, while expecting that the model would be generalized to unseen target domains. Most existing
DG approaches focus on deriving domain-invariant features [1] among multiple source domains or adopting meta-learning techniques [2, 3, 4, 5], which would simulate domain shifts during the meta-training stage. However, the features derived by the above methods are generally guaranteed to be invariant to the seen source domains, not the generalizability of the learned representation to describe unseen domain data. To overcome the limitation, [6, 7, 8, 9] turn to leverage data generation techniques for diversifying the source distributions, and thus avoid overﬁtting on source domains yet improve the generalization ability of models. Speciﬁcally, several works [6, 7, 8] choose to generate novel-domain images by either perturbing the style of source data to confuse the domain classiﬁer [6, 7], or transporting the source data to novel styles via optimal transport based objective [8].
[9] adopts Mixup [10] to interpolate the feature statistics between samples from different domains.
While the above methods perform well, designing an objective for generating samples with DG guarantees remains a challenging and open problem. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
Recently, self-supervised pre-training manifests the potential to derive generalizable representa-tion, which serves as a promising start point for downstream tasks (e.g., image segmentation or object detection). In domain generalization, a number of self-supervision techniques have been introduced [11, 12, 13] to improve network transferability by discovering the intrinsic properties within images. For instance, [11, 12, 13] adopt jigsaw puzzles as the pretext task, which predicts the relative positions of image patches to constrain the semantic feature learning in a multi-task training fashion. Recently, contrastive learning approaches [14, 15, 16, 17, 18] have been proposed and widely applied, which establish the representation learning from multiple views of an image to extract the task-relevant information and discard task-irrelevant noise. However, the concept of such multiview learning [19, 18] is simply realized by hand-crafted image transformations (e.g.,
RandomResizedCrop, Color Jittering, or Gaussian Blur). The effectiveness of these hand-crafted image transformations for beneﬁting the generalization to unseen distributions is still not guaranteed.
In this paper, we propose a unique Adversarial Teacher-Student Representation Learning framework for tackling domain generalized visual classiﬁcation. Based on the recent success of contrastive learning, we advance the concept of multi-view learning into DG regime for augmenting source instances to out-of-source styles and diversifying training distributions. To be more precise, with the goal of learning representations which are robust to unseen domain shift, we propose to jointly perform Domain Generalized Representation Learning and Novel Domain Augmentation in an adversarial learning manner. Based on Teacher-Student learning schemes [20, 16, 21], our framework utilizes original images as inputs to the teacher network and takes stylized augmentations as input to the student network. To ensure both learning stages produce domain generalized representation, we adopt the Teacher-Student co-training scheme, which progressively reﬁnes Teacher by the distilled knowledge learned from Student by observing augmented novel-domain data, enabling Teacher to be generalizable to data with out-of-source distributions. On the other hand, Adversarial Novel Domain
Augmentation aims at augmenting unseen domain data using source-domain training instances. The objective is to maximize the discrepancy between the input and augmented data, derived from the teacher and student modules, respectively. In order to have such augmented data exhibit sufﬁcient domain differences, the above discrepancy will be calculated using features derived from data across different source domains. By iteratively training the above two stages in an adversarial learning fashion, the resulting model (Teacher) would be able to derive domain generalizable representations.
The contributions of this paper are highlighted as below:
• Different from existing meta-learning based approaches, we propose a teacher-student adversarial learning scheme for addressing domain generalization classiﬁcation problems.
• In the stage of Domain Generalized Representation Learning, the student network observes augmented novel-domain data and distills the information to update the teacher network, allowing derivation of domain generalizable representation.
• In the stage of Novel Domain Augmentation, the generator aims at producing unseen yet plausible domain data, which maximizes the discrepancy between augmented and existing domains while the semantic information is preserved.
• Evaluations on several benchmark datasets in multiple and single source domain settings verify that our method performs favorably against existing DG approaches and exhibits sufﬁcient domain generalization capability. 2