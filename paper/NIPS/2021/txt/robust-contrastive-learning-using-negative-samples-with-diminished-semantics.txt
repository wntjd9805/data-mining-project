Abstract
Unsupervised learning has recently made exceptional progress because of the devel-opment of more effective contrastive learning methods. However, CNNs are prone to depend on low-level features that humans deem non-semantic. This dependency has been conjectured to induce a lack of robustness to image perturbations or domain shift. In this paper, we show that by generating carefully designed negative samples, contrastive learning can learn more robust representations with less de-pendence on such features. Contrastive learning utilizes positive pairs that preserve semantic information while perturbing superﬁcial features in the training images.
Similarly, we propose to generate negative samples in a reversed way, where only the superﬂuous instead of the semantic features are preserved. We develop two methods, texture-based and patch-based augmentations, to generate negative sam-ples. These samples achieve better generalization, especially under out-of-domain settings. We also analyze our method and the generated texture-based samples, showing that texture features are indispensable in classifying particular ImageNet classes and especially ﬁner classes. We also show that model bias favors texture and shape features differently under different test settings. Our code, trained models, and ImageNet-Texture dataset can be found at https://github.com/
SongweiGe/Contrastive-Learning-with-Non-Semantic-Negatives. 1

Introduction
Recent studies on self-supervised learning have shown great success in learning visual representations without human annotations. The gap between unsupervised and supervised learning has been progres-sively closed by contrastive learning [53, 48, 7, 18, 49, 6, 16, 56]. In the meantime, CNNs trained in the supervised setting are known to learn correlations between labels and superﬂuous features such as local patches [4, 3], texture [14], high-frequency components [51], and even artiﬁcially added features [26], which has raised concerns about deploying these models in a real scenario [30, 15].
CNNs trained by contrastive learning methods are no exception [23]. In this paper, we propose to construct negative samples that only preserve non-semantic features. We show that using contrastive learning methods trained with these negative samples can mitigate these concerns.
Contrastive learning methods exploit carefully designed augmentations to construct positive pairs and pull their representations together. These augmentations are crucial to contrastive learning [7, 6].
A common assumption behind these augmentations is to preserve the semantics of the input images while perturbing other superﬁcial signals. This inspires us to generate negative samples and inject additional implicit biases on the visual features learned by the models. Speciﬁcally, we utilize 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
Figure 1: We propose to construct negative samples (NS) from input images for contrastive learning with augmentations that only preserve non-semantic information such as texture and local features. augmentations that diminish the semantic features while keeping the undesired features such as texture. By pushing apart the representations of such negative samples and input images, the models are expected to rely more on the semantics of the images and less on superﬁcial features.
Inspired by the non-semantic features, we propose two methods to craft negative samples. The ﬁrst method relies on texture synthesis tools from classic approaches [12, 52]. It generates realistic texture images based on two patches extracted from input images, as shown in Figure 1(d). For each image in ImageNet, we generate its texture version and form a dataset which we call ImageNet-Texture.
The second method constructs non-semantic images by tiling randomly sampled patches of different sizes from the input image, as shown in Figure 1(e). Comparing the non-semantic negative samples with two semantic positive samples in Figure 1(b) and Figure 1(c), the dog from the input image is still recognizable in the positive samples but hard to understand from negative samples. Instead, local statistics such as the fur and color of the dog are preserved in the negative samples.
The generated non-semantic samples can be readily used with existing contrastive learning methods that distinguish positive pairs from negative pairs such as MoCo [18] and SimCLR [7]. Despite their simplicity, we show that these non-semantic negative samples are actually harder than the standard negative samples used by these methods, which are inefﬁcient at leveraging hard negatives [13, 31].
Further, our negative pairs can also be used by contrastive learning methods that do not explicitly use negative samples, such as BYOL [16]. We evaluate our methods with two contrastive learning methods, MoCo [18, 8] and BYOL [16], on three datasets, ImageNet-100, ImageNet-1K and STL-10. When using our proposed augmentations to generate negative samples and minimize their representation similarity to the input images, we notice a consistent improvement on the generalization performance over backbone methods [8, 16] and previous negative example generation strategies
[31, 43], especially under out-of-distribution (OOD) settings.
We conduct a systematic analysis of how the shape-texture trade-off inﬂuences model performance based on the proposed ImageNet-Texture dataset. We control the penalty on similarities between the non-semantic negative examples and the query samples. This impacts the trade-off between using shape and texture features. We ﬁnd that the relative importance of texture and shape features varies across different datasets. For example, shape bias beneﬁts ImageNet-Sketch [50] more than the original ImageNet validation set. On the other hand, texture bias beneﬁts ﬁner-grained classiﬁcation more, such as dog breed classiﬁcation included in ImageNet. These results complement previous evidence showing the effectiveness of shape features in classifying 16 coarse classes [14]. Such preference for one feature over the other is also observed intra-dataset: the texture is more important for some classes such as dishrag and plaque. These observations make us question the relationship between shape and texture features as the implicitly necessary bias of CNNs and advocate for an adaptive combination of both when deploying the model in real scenarios. In summary:
• We propose texture-based and patch-based augmentations to generate negative samples from input images, and show that these negative samples improve the generalization of contrastive learning.
• We introduce the ImageNet-Texture dataset, which contains texture versions of ImageNet images generated by texture synthesis tools.
• We provide ﬁne-grained analysis on the shape-texture trade-off of CNNs, and show different scenarios when one is preferred over the other. 2
2 Negative Samples with Diminished Semantics
CNNs are apt to learn low level features such as texture under supervised settings [3, 14, 51]; this has been recently witnessed under the contrastive learning setting as well [23]. To mitigate this problem, we propose two methods, texture-based and patch-based augmentations, to generate negative samples for contrastive learning. Texture-based augmentation generates realistic images based on texture synthesis and patch-based augmentation exploits more comprehensive local features by sampling patches from input images. By penalizing learned similarities between the representations of images and their non-semantic counterparts, the model is encouraged to rely less on the undesired features and focus more on the semantics. In practice, we ﬁnd the two negative samples play similar roles and the patch-based method works slightly better. In this section, we start with an overview of contrastive learning and show how non-semantic negatives are used in these frameworks. Then we elaborate on the two approaches to generate negative samples with diminished semantics. 2.1 Contrastive learning with non-semantic negatives
Given an encoder network f and an image x, we denote the output of the network as z = f (x). We use zi and zp to denote the representations of the query sample xi and a positive sample xp generated from the same input image with augmentations that preserve semantics. For contrastive learning methods like MoCo [18] and SimCLR [7], zn denotes the representation of the standard negative sample xn extracted from the memory bank (MoCo) or other images in the current batch (SimCLR). zns is the representation of the proposed negative sample xns which contains particular non-semantic features of the input image with the semantic part weakened. We extend the noise-contrastive estimation (NCE) loss as below:
LNCE = − log (cid:88) i∈I exp (cid:0)zT i zp/τ (cid:1) + exp (cid:0)αzT exp (cid:0)zT i zp/τ (cid:1) i zns/τ (cid:1) + (cid:80) n∈N exp (cid:0)zT i zn/τ (cid:1) , (1) where τ is a temperature parameter and α is an additional scaling parameter for non-semantic negatives. A larger α implies a stronger penalty on the similarity between the representations of the query image and its non-semantic version. In Appendix B.1 we discuss other possible ways to apply
α.
Methods like BYOL [16] do not explicitly rely on negative samples. Nevertheless, BYOL adapts the loss to maximize the agreement of positive pairs. Therefore, we explicitly use the non-semantic negative sample with their loss to minimize its similarity to the query sample:
LBYOL = (cid:107)zi − zp(cid:107) − α(cid:107)zi − zns(cid:107) = 2 − 2α − 2zT i zp + 2αzT i zns. (2)
We overload α to be the parameter that controls the penalty on the similarity between the representa-tions of input image and its non-semantic version under BYOL, with similar intention as MoCo and
SimCLR above. To minimize either LNCE or LBYOL, the encoder must learn features from xi that are not contained in xns but shared with xp. 2.2 Texture-based negative sample generation
We use texture synthesis tools to generate negative samples. Texture synthesis aims to generate realistic images that preserve as much local structure as possible from an example image [19, 11, 42].
For instance, as shown in Figure 1(d), the texture of the input dog image preserves the fur and colors of the dog. Notably, in previous discussion of robustness [3, 50], such local structure has often been recognized as highly correlated with the labels yet superﬂuous to generalization. For example, under large domain shift due to lighting, motion, and even modality, the texture is more apt to change than the semantic features, such as the shape. Furthermore, CNNs trained on ImageNet are more likely to classify images based on the texture features rather than the shape features which are instead preferred by humans due to their transferability [14]. To encourage the model to rely more on the shape features, we propose a two-step method to generate the texture image of input images as the negative samples for contrastive learning.
To be speciﬁc, we ﬁrst sample two patches from given images as the input to the texture synthesis algorithms. One patch is extracted from the center of the image. This patch is expected to reﬂect the texture of the object according to the implicit bias contained in the ImageNet dataset that most 3
of the objects are center-oriented in the images [2]. The other patch is extracted from a random location to reﬂect other possible textures of the image (e.g. background, peripheral region of the object). In this work, we extract patches with size 96 × 96 when image size allows, otherwise 48 × 48 patches are extracted. Second, we adopt off-the-shelf texture synthesis algorithms [12, 52, 1] to generate texture images based on the two patches. These non-parametric algorithms iteratively sample pixels from given patches that share a similar neighborhood with the current pixel. Speciﬁcally, we use the open-source software built on these methods [12, 52, 1] with multi-threaded CPU support implemented in Rust 1. For each sample in the ImageNet dataset, we generate one 224 × 224 texture image to construct a dataset that has the same training and validation size as the ImageNet dataset.
We call this dataset ImageNet-Texture. More examples can be found in Appendix A.1. 2.3 Patch-based negative sample generation
To simulate the local information contained in the images [4, 3], we propose an efﬁcient patch-based method to generate non-semantic images. Given an image and a patch size d, we sample patches of size d from ((cid:100) 224 d (cid:101))2 non-overlapping random locations that lie entirely in the image. The patches are then tiled and cropped into 224 × 224 as negative samples. Compared with the texture-based method, this generation process takes negligible time, therefore it can be implemented as part of the data loading process in parallel with training. By doing so, each training sample can be paired with different negative samples generated from different patches every time it is used, compared with the two ﬁxed patches selected when generating texture images.
Different from the texture-based method that generates realistic images, the patch-based method generates images with artiﬁcial lines as shown in Figure 1e. One might be concerned with possible degenerate solution where the model outputs a low similarity whenever it detects the repeated sharp changes in the horizontal or vertical directions, which could be done with a single layer of convolution.
However, interestingly, we ﬁnd that the model does not ﬁnd such a simple solution in practice. This is also noticed in a previous study where the image and its copy with a patch cut out are non-trivially distinguished by the model [34]. To mitigate this potential issue, we randomly sample patch size d from a prior distribution instead of using a ﬁxed d in practice, which allows the model to look at texture at different scales. 2.4 How hard are the texture-based and patch-based negative samples?
Constrastive learning methods are known to struggle with ﬁnding hard negative samples [13, 31] and researchers have proposed several ways to better leverage hard negatives [31, 43]. An intermediate question is how hard are our proposed negative samples compared with those standard negative samples used in previous constrastive learning methods [7, 18], i.e. random training samples. (a) Positive Sample (b) Standard NS (c) Texture-based NS (d) Patch-based NS
Figure 2: The histogram of cosine similarity between the representations of query sample and its paired samples, namely positive sample and standard, texture-based, and patch-based negative samples (NS), using MoCo-v2 model trained on the ImageNet-1K dataset for 200 epochs.
We use the ofﬁcial MoCo-v2 model pretrained on the ImageNet-1K dataset for 200 epochs to calculate the cosine similarities between different kinds of pairs across the ImageNet training set. We plot the histogram of these similarities in Figure 2. As shown in the Figures 2a and 2b, most positive pairs and negative pairs have similarity close to 1 and 0 respectively. Speciﬁcally, the average similarities across the training samples are 0.94257 and 0.00018 for positive and negative pairs. As shown in 1https://github.com/EmbarkStudios/texture-synthesis 4
the Figures 2d and 2c, the distributions of patch-based and texture-based negative samples are very different from those of standard negative samples; their similarity distributions have heavy tails in the positive region. Speciﬁcally, the distribution of patch-based and texture-based negative samples have average similarity 0.29503 and 0.35248 across the dataset, which shows that they remain difﬁcult after training with standard negative examples. 3 Experiments
In this section, we evaluate the two kinds of non-semantic negative samples with two contrastive learning methods, MoCo and BYOL, on the ImageNet dataset. We also experiment using its subset, the ImageNet-100 dataset [48, 31], which allows us to perform more comprehensive experiments.
We report accuracy on out-of-domain (OOD) datasets including the ImageNet-C(orruption) [22],
ImageNet-S(ketch) [50], Stylized-ImageNet [14], and ImageNet-R(endition)[21] datasets as an evaluation of the model’s robustness to domain shifts. ImageNet-C and Stylized-ImageNet contain images transformed from the images in the ImageNet validation set with common corruption and transferred style. ImageNet-S and ImageNet-R are collected independently from the ImageNet dataset and share all or a subset of the classes in the ImageNet dataset with a focus on sketch and other rendering modalities. We show that with our proposed non-semantic negatives, contrastive learning generalizes better under domain shifts. For patch-based negatives, it also improves the performance on the in-domain dataset. 3.1
ImageNet-100
ImageNet
ImageNet-C ImageNet-S
Stylized-ImageNet
ImageNet-R
MoCo-v2 - k = 16384
+ Texture-based - α = 2
+ Patch-based - α = 2
+ Patch-based - α = 3
MoCo-v2 - k = 8192
+ Patch-based - α = 2
MoCo-v2*
+ IFM [44] - (cid:15) = 0.05
+ IFM [44] - (cid:15) = 0.1
+ IFM [44] - (cid:15) = 0.2
+ Patch-based - α = 2
BYOL
+ Patch-based - α = 0.05
InsDis [53]
CMC [48]
InfoMin [49]
Supervised 77.88±0.28 77.76±0.17 79.35±0.12 75.58±0.52 77.73±0.38 79.54±0.32 80.00±0.14 80.86 81.22 81.02 81.49±0.11 78.76±0.28 78.81±0.33 68.52 79.34 82.74 86.26 43.08±0.27 43.58±0.33 45.13±0.35 44.45±0.15 43.22±0.39 45.48±0.20 45.15±0.42 47.36 47.46 47.19 47.48±0.20 44.43±0.35 44.60±0.21 28.93 39.28 48.87 49.17 28.24±0.58 29.11±0.39 31.76±0.88 34.03±0.58 28.45±0.36 33.36±0.45 30.38±0.30 31.35 31.87 31.55 34.20±0.40 35.84±0.38 36.76±0.51 16.67 24.04 38.43 34.95 16.20±0.55 16.59±0.17 17.37±0.19 18.60±0.26 16.83±0.12 17.81±0.32 16.68±0.39 18.18 18.42 18.68 17.95±0.41 15.01±0.19 15.52±0.22 9.86 13.88 18.14 21.20 32.92±0.12 33.36±0.15 34.78±0.15 36.89±0.11 33.19±0.44 36.31±0.37 30.38±0.30 36.79 37.23 37.14 38.45±0.19 39.53±0.51 41.16±0.39 19.60 32.68 40.68 39.76
Table 1: Top-1 accuracy on the ImageNet-100 dataset and its OOD variants. We consider the supervised baseline as well as several self-supervised baselines including MoCo-v2, BYOL, InsDis,
CMC, and InfoMIN. For our main comparison using MoCo-v2 and BYOL, we also report the standard deviation of 3 runs. For MoCo models, k represents the size of the memory bank. We use * to denote the experiments that use the training setting in a concurrent work IFM [44].
We follow the hyperparameters used in [31] to train MoCo-v2 on the ImageNet-100 dataset with a memory bank size k = 16384 or a halved memory bank size. We also conduct experiments following the hyperparameters in a concurrent study [44] except that we keep k = 16384 for our method.
For patch-based augmentation parameters, we use patch size sampled from a uniform distribution d ∼ U(16, 72). The parameter α is indicated behind each model name. We discuss the impact of
α in detail in the next section. More ablations on the patch-based augmentations can be found in
Appendix C.3. For ImageNet-C, we report the average accuracy across 5 levels of corruption severity.
We repeat the experiments, including both the pretraining and linear evaluation, for 3 runs and report the mean and standard deviation in Table 1. As shown in the table, when following the 5
previous memory bank size, using both patch-based and texture-based negatives improve the OOD generalizations. Speciﬁcally, patch-based augmentation increases the accuracy on ImageNet-S by 5.79% and ImageNet-R by 5.97% when α = 3. When α = 2, it also increases the in-domain accuracy by 1.47% and accuracy on ImageNet-C by 2.05%. The similar trend shared by standard
ImageNet and ImageNet-C with different α can be attributed to the resemblance of the images in the two dataset, especially those corrupted images with a lower level of severity. We show the performance of the model with α = 3 is actually better on the highest corruption level as shown in
Appendix C.2. The improvement achieved using texture-based negatives is less, probably because the information contained in the texture image is restricted due to the limited access to the two
ﬁxed patches. When the memory bank is halved to be 8, 192, the baseline MoCo model has slightly worse performance, decreasing from 77.88 to 77.73. But with patch-based hard negative samples, the MoCo-v2 model instead achieved the best accuracy 79.54 on the ImageNet-100 validation set,
IamgeNet-C and IamgeNet-R. We discuss this more in a later section. (a) Positive Sample (b) Standard NS (c) Texture-based NS (d) Patch-based NS
Figure 3: Histogram of cosine similarity between the representations of query sample and its paired positive sample, standard, texture-based, and patch-based negative samples (NS), using models trained without (blue) and with patch-based negative samples (red: α = 2, green: α = 3).
Similar to Figure 2, in Figure 3 we visualize the distribution of the cosine similarity between the query sample and both semantic and non-semantic samples calculated based on the models trained with and without patch-based negative samples. The shift of the distribution towards the origin in Figure 3d meets the expectation that our method reduces the similarity of input images and patch-based negative samples. Speciﬁcally, the average similarity decreases from 0.4040 to 0.3252 to 0.1593 when α increases from 0, namely no patched-based negatives, to 2 to 3. Interestingly, we notice in Figure 3c that the similarity to texture-based negative samples also decreases, and the average similarity decreases from 0.4114 to 0.3541 to 0.1896, although we did not explicitly penalize it. This demonstrates the resemblance of patch-based negative samples to texture-based negative samples. Given the better performance achieved with patch-based negative samples, for the rest of the experiments, we mainly focus on the patch-based methods. But we still conduct our analysis on the texture-based samples. We also ﬁnd a marginal decrease in the positive similarity (−0.0068) and negative similarity (−0.0008) when α = 2 and a substantial decrease in the positive similarity (−0.0737) and increase in the negative similarity (0.0036) when α = 3. A similar ﬁgure for texture-based negative samples can be found in the Appendix in Figure 12. 3.2
ImageNet-1K
ImageNet
ImageNet-C ImageNet-S
Stylized-ImageNet
ImageNet-R
MoCo-v2 [8]
+ MoCHi [31]
+ Patch-base NS - α = 2 67.60 67.56 67.92 87.7 88.7 87.6 17.47 16.32 18.58 5.55 5.94 6.34 27.81 25.71 28.95
Table 2: Top-1 accuracy on the ImageNet-1K dataset and its sketch, stylized, rendition variants, and mCE on the ImageNet-C dataset.
We follow the ofﬁcial hyperparameters [8] to train MoCo-v2 with our patch-based negative samples on the ImageNet-1K dataset. For the parameter α and patch size d, we follow the same conﬁguration used on the ImageNet-100 dataset. We compare our results against the MoCo-v2 baseline [8] and the hard negative mixing algorithm, MoCHi [31]. Due to limited computational resources, we report the metrics evaluated with the ofﬁcial model without repeated runs. The results are shown in Table 2. 6
More results can be found in Appendix C.6. Note that for ImageNet-C, we show the mCE metric [22], for which smaller is better. For the other datasets, we show the top-1 accuracy. 3.3 Extension to other non-semantic features
Model
Top-1 Accuracy
MoCo-v2 [8]
+ Patch-based NS
Non-semantic features are sometimes referred to as
“shortcuts” in the contrastive learning literature [6, 7]. Models that leverage such features often exhibit unfavorable generalization to downstream tasks. For example, without color jittering, SimCLR [9] tends to utilize color histograms to reduce the training loss.
In this section, we show that models trained with non-semantic negatives are coerced to avoid the shortcuts shared between query images and their non-semantic counterparts. In the example of the color shortcut, we note that the expected color distribution of our patch-based negatives is identical to that of the query images, and the actual distribution of samples is close. We conduct experiments with MoCo-v2 on the ImageNet-100 dataset while removing the color jittering from the augmentations. The accuracy of models with and without patch-based negatives are reported in Table 3. We found that patch-based negatives contribute signiﬁcant effectiveness in preventing the models from learning such a color distribution shortcut.
Table 3: Test accuracy of MoCo-v2 on the
ImageNet-100 dataset after removing color jittering and adding patch-based negatives. 70.44 76.42 3.4 Memory bank size
Contrastive learning methods based on negative samples suffer from ineffective excavation of hard negatives [13, 31] and resort to large batch sizes [7] or memory bank [18]. In this section, we study whether our proposed negative samples can mitigate this problem on the STL-10 and ImageNet-100 datasets. We keep the hyperparameters intact and vary the memory bank size. We report the accuracy of the MoCo-v2 baseline with and without patch-based negative samples on STL-10 dataset in Table 4.
We also compare with [43] which exploits hard negatives through reweighting. We found that with proper hyperparameters the MoCo-v2 baseline already beats the reweighting results with SimCLR.
SimCLR [7]
+ Debiased [10]
+ Hard [43]
MoCo-v2 [8]
+ Patch-based NS 80.16 84.90§ 87.42§ 88.00 89.36
Table 4: Top-1 accuracy on the STL-10 dataset.
§ denotes results visually extracted from Figure 2 in [43].
Figure 4: Top-1 accuracy on the STL-10 dataset with different memory bank sizes.
Figure 5: Top-1 accuracy on the
ImageNet-100 dataset with differ-ent memory bank sizes.
As shown in Figures 4 and 5, using patch-based non-semantic negatives consistently improves the
MoCo baseline when the number of standard negatives varies. When slightly decreasing the memory bank size on the STL-10 dataset as shown in Figure 4 and ImageNet-100 in Table 1, the performance with patch-based negatives increases. This is probably because, according to Eq. 1 and analysis in
Appendix B.1, a smaller memory bank size causes a larger contribution of non-semantic negatives to the loss, and consequently a larger regularization. To further demystify this observation, we conduct experiments with evenly sampled memory bank sizes between 4096 and 16384 and report the average and standard deviation across 3 runs in Figure 5. We conﬁrm a consistent recession of baseline accuracy when decreasing memory back sizes [18, 43]. However, the steady improvement led by the non-semantic negatives effectively mitigates the problem - the decrease caused by a smaller memory bank is less substantial and using patch-based negatives always beats the baseline. 7
4 Discussion 4.1 Controlling the shape-texture trade-off with α
There has been a growing interest in understanding the cause and impact of the trade-off between shape and texture bias of CNNs [14, 23, 35, 27]. CNNs trained on ImageNet are known to be over-reliant on the texture features [14]. Contrastive learning with our non-semantic negatives serve as not only an effective method to reduce such reliance, but a natural tool to study such a trade-off. (a) Shape-bias (b) Shape-texture accuracy (c) Sketch-clean accuracy (d) Coarse-ﬁner accuracy
Figure 6: Larger α monotonically increases the model bias to shape features over texture features.
Model performance is impacted by such a trade-off differently under different settings. In all scenarios, slightly calibrated shape bias improves model performance. The test settings represented in the red lines gain more from the increased shape bias than the settings represented in the green lines.
We train MoCo-v2 models with different α from 1 to 5 on the ImageNet-100 dataset. As shown in Figure 6a, we ﬁnd that α effectively controls the trade-off on the model bias to the shape and texture features. α = 0 is used to denote the baseline method. Speciﬁcally, a larger α in the loss function 1 leads to a larger penalty on the similarity between the representations of query samples and non-semantic samples, consequently a larger shape bias. We follow [14] to calculate shape bias on the stimuli images with conﬂicted shape and texture clues generated by style transfer. We show the corresponding accuracy on the shape and texture labels in Figure 6b.
As shown in Figure 6b, when α increases the texture accuracy on the stimuli dataset monotonically decreases while the shape accuracy monotonically increases. To further study how the trade-off between shape and texture bias impacts the model performance, we ﬁrst compare the accuracy on the
ImageNet validation dataset and ImageNet-Sketch dataset [50] when α varies in Figure 6c. We ﬁnd that on both datasets, slightly increased shape bias over baseline (α = 2) improves performances.
Interestingly, the accuracy peak on the ImageNet-Sketch appears at α = 3 while the peak appears at α = 2 on the ImageNet validation dataset. In addition, for even larger α the accuracy on the
ImageNet-Sketch dataset still outperforms the baseline while the standard accuracy gets hurt. This shows that different downstream tasks may beneﬁt differently from differently shape-biased models.
We plot the histograms of similarities calculated by the models trained with different α in Appendix
Figure 13. We ﬁnd that large α makes the original pretext task challenging - the model cannot effectively pull together the representations of positive pairs. Speciﬁcally, when α increases from 1 to 5, the average similarity of the positive pairs decrease from 0.9267 to 0.7541. This demonstrates that it is hard for the model to learn representations that are completely independent of the texture features contained in the non-semantic images. 4.2 Rethinking the shape-texture trade-off through class-based analysis
The initial discussion on the shape-texture trade-off shows that humans rely more on the shape features while CNNs rely more on texture features and increasing shape bias can improve accuracy and robustness [14]. However, similar to [40, 23], we notice that increasing shape bias does not always improve the generalization and robustness of the models. To better understand this phenomenon, we provide two observations based on the analysis of the ImageNet-Texture dataset and our method to explain why a texture-biased model is helpful with classiﬁcation on the ImageNet dataset.
First, we ﬁnd that an increasing shape bias often leads to more errors among the ﬁne-grained classes.
The initial discussion of the shape-bias [14] only pays attention to the selected 16 coarse classes.
We thus compare the ﬁner and coarse class accuracy on the dog images of ImageNet dataset as in
Figure 6d. For coarse class accuracy, the predictions are counted to be correct whenever the image is 8
Figure 7: A ResNet-50 model trained on the ImageNet dataset achieves decent accuracy when only texture features are available on some classes. A normal image and its texture version are displayed for some of these classes. The caption indicates the class ID, name, and accuracy on texture images. classiﬁed as a dog class, no matter which dog class is predicted, while for the ﬁner class accuracy, only those predictions of target dog classes are counted to be correct. We notice that the ﬁner class accuracy drops more signiﬁcantly when shape bias increases as opposed to the coarse class accuracy.
For example, when α = 3, the ﬁner class accuracy drops from 72.9 to 67.6 while the coarse class accuracy slightly decreases from 97.8 to 97.7. Therefore, for datasets with numerous ﬁne-grained classes like ImageNet, a texture-biased model is more helpful for a higher accuracy, which conﬁrms the previous conjecture [54] . Second, in Appendix Figure 9, we show a scatter plot of texture accuracy vs. standard accuracy of different model architectures and a histogram of accuracy on individual ImageNet-Texture classes. We identify several classes where using only texture features is sufﬁcient to achieve a high classiﬁcation accuracy. These classes are all missing in the previous study [14]. As shown in Figure 7 and Appendix Figure 10, texture serves as a more important clue than the shape for these classes. 5