Abstract
Cryptic crosswords, the dominant crossword variety in the UK, are a promising target for advancing NLP systems that seek to process semantically complex, highly compositional language. Cryptic clues read like ﬂuent natural language but are adversarially composed of two parts: a deﬁnition and a wordplay cipher requiring character-level manipulations. Expert humans use creative intelligence to solve cryptics, ﬂexibly combining linguistic, world, and domain knowledge. In this paper, we make two main contributions. First, we present a dataset of cryptic clues as a challenging new benchmark for NLP systems that seek to process compositional language in more creative, human-like ways. After showing that three non-neural approaches and T5, a state-of-the-art neural language model, do not achieve good performance, we make our second main contribution: a novel curriculum approach, in which the model is ﬁrst ﬁne-tuned on related tasks such as unscrambling words.
We also introduce a challenging data split, examine the meta-linguistic capabilities of subword-tokenized models, and investigate model systematicity by perturbing the wordplay part of clues, showing that T5 exhibits behavior partially consistent with human solving strategies. Although our curricular approach considerably improves on the T5 baseline, our best-performing model still fails to generalize to the extent that humans can. Thus, cryptic crosswords remain an unsolved challenge for NLP systems and a potential source of future innovation. 1

Introduction
Modern computational models have made great progress at handling a variety of natural language tasks that require interpreting rich syntactic and semantic structures [6; 30; 25; 32]. However, in NLP
[2; 26; 3] as in other areas of AI [22], machines still lag humans on tasks that require ﬂexible problem solving, rapid learning of unseen tasks, and generalization to new domains. Just as complex games mastered by human experts, such as chess, Go, and video games, have proved a fertile ground for developing more ﬂexible AI [36; 35; 27], we propose that creative language games are a rich area for developing more ﬂexible NLP models. In particular, we argue that linguistic tasks involving meta-linguistic reasoning pose an important and signiﬁcant challenge for state-of-the-art computational language systems.
One such domain is cryptic crossword puzzles. Cryptics are the most popular style of crossword in the United Kingdom and appear in major newspapers like The Times and The Guardian. Cryptic clues have two parts: a deﬁnition and a wordplay cipher that, when placed adjacent to each other, read like ﬂuent natural language. For example, consider this NLP-centric cryptic crossword clue:
“But everything’s really trivial, initially, for a transformer model (4)” with answer “BERT”. “(4)” is the enumeration and speciﬁes the number of letters in the answer. Solvers must identify which 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
Table 1: Examples of ﬁve common clue types in cryptic crosswords, all demonstrating clues for the answer: BERT. Indicators, where they occur, are italicized. The wordplay substrate appears in bold.
Typographical emphasis added to aid reader, only; actual clues have no such indication.
Clue type
Clue example
Explanation for this example
Anagram: An anagram clue requires scrambling some set of clue letters to produce the answer.
Initialism: An initialism requires tak-ing the ﬁrst letters of a phrase
Confused, Bret makes a language model (4)
But everything’s really trivial, initially, for a language model (4)
Hidden: The answer occurs within a larger phrase.
Language model somber text (4) in
Charade: For a charade clue, each part of the answer is clued sequentially.
A language model ex-ist? Right time! (4)
Double deﬁnition: In a double deﬁni-tion clue, two synonyms or phrases ap-pear next to each other, each of which can refer to the answer.
Model Sesame Street character (4)
Confused indicates that we should
“confuse” (anagram) the letters of
“Bret” to get BERT. initially indicates taking the ﬁrst let-ters of “But everything’s really triv-ial”. in indicates that a word is hidden in-side a phrase. Extract the word BERT from the phrase “somber text.”
“exist” becomes “BE” since “exist” and “be” are synonyms. A standard abbreviation for “right” is “R.” A standard crossword abbreviation for
“time” is “T.” This clue type does not have an indicator.
Bert is a valid answer for “Sesame
Street character”, and it is also a model. Double deﬁnitions do not have indicators. part of the clue is deﬁnition and which is wordplay. The deﬁnition should be a semantically valid description of the answer word: “a transformer model” can mean “BERT”. The wordplay part is the remainder of the clue: “But everything’s really trivial, initially”. The word initially in this context is used as an indicator, which tells the solver to take the initial letter of each of the preceding words (but everything’s really trivial) to produce “BERT”. Because both the wordplay and the deﬁnition give the same 4-letter word (which is what the enumeration, “(4)”, calls for), we can be conﬁdent that “BERT” is the correct answer.
The clue just discussed is an example of the initialism clue type, which is one of roughly 15 major clue types. Other types can require anagramming words, ﬁnding words hidden in longer phrases, performing synonym substitutions, substituting a word for a soundalike (e.g., “hiring” for “high ring”), or composing a number of these manipulations. See Table 1 for examples of several other clue types with answer “BERT” and Appendix A for examples of actual clues from the dataset. As with American-style clues, cryptics require world knowledge and linguistic ﬂexibility to match the deﬁnition, but also considerable attention to meta-linguistic concepts to solve the wordplay. In this paper we study the language task of solving individual cryptic clues, rather than full puzzles since, unlike American-style crosswords, cryptics generally have unique answers and so are less reliant on grid constraints in order to achieve a complete solution.
While cryptics pose a challenge to novice solvers unfamiliar with their structure, experts ﬂexibly combine world, domain-speciﬁc, and linguistic knowledge to solve novel clues. Experts know the rules that govern cryptic clues, but they also reason about them ﬂexibly and apply them to solve novel clues. In the psychology literature, it has been claimed that cryptics depend on domain-general intelligence and are an ideal domain for studying the “aha moment” in humans [11; 10] because experts can solve them with high accuracy (but rarely at ﬁrst glance), they can be easily generated, and they require drawing on a diverse range of cognitive abilities. Therefore, we believe that cryptic crosswords are an excellent domain for developing computational language systems that “learn and think like humans” [22], posing an interesting and important challenge for modern machine learning. 2
Our main contributions are, ﬁrst, a cleaned dataset of cryptic crosswords clues from theguardian.com, consisting of 142,380 clues from 5,518 puzzles over 21 years;1 and second, a novel curriculum learning approach, in which the model is ﬁrst ﬁne-tuned on related, synthetic tasks (e.g., an augmented word descrambling task) before tackling actual cryptic clues. This method meaningfully improves on a standard T5 seq-to-seq approach and on the best model of Efrat et al.
[7]—concurrent work that presents a similar dataset and similar neural baseline using T5.
In this paper, we aim not only to present a dataset and propose a novel solution but also to characterize the problem and motivate its importance. To that end, we elucidate the task with three non-neural baselines and ﬁne-tune T5 [31], a Transformer-based [38] encoder-decoder, as a neural baseline.
Since the character-level wordplay inherent to cryptics might be challenging to language models with subword tokenization (T5 uses SentencePiece [21]), we study whether T5 has or can acquire meta-linguistic knowledge. In Section 6.1 we examine whether T5 learns meta-features of the task related to answer length. In Section 6.3 we use a descrambling task to assess whether T5 understands the character composition of words and whether the model can make use of linguistic and meta-linguistic information simultaneously. Our results show, perhaps surprisingly, that the subword-tokenized T5 model is quite robust to character-level challenges. Moreover, the descrambling task may serve as a useful benchmark task in guiding the development of new approaches on the cryptics task.
Given the compositional nature of cryptic clues, we investigate the extent to which the model generalizes under increasingly difﬁcult data splits. In Section 6.2 we introduce a new form of disjoint data split to address T5’s robustness to inﬂection: a word-initial disjoint split that segments clue– answer pairs based on the ﬁrst two letters of the answer. In Section 6.4 we examine the systematicity of the model’s answer generation by perturbing the wordplay portion of anagram clues, showing that its behavior is partially consistent with human solving strategies.
Although our novel curricular approach considerably improves performance on this task, fully solving cryptics remains a challenge for modern machine learning, with expert humans still outperforming machines. Therefore, we hope that our dataset will serve as a challenging benchmark for future work. 2