Abstract
Supervised Pix2Pix and unsupervised Cycle-consistency are two modes that dom-inate the ﬁeld of medical image-to-image translation. However, neither modes are ideal. The Pix2Pix mode has excellent performance. But it requires paired and well pixel-wise aligned images, which may not always be achievable due to respiratory motion or anatomy change between times that paired images are acquired. The Cycle-consistency mode is less stringent with training data and works well on unpaired or misaligned images. But its performance may not be optimal. In order to break the dilemma of the existing modes, we propose a new unsupervised mode called RegGAN for medical image-to-image translation. It is based on the theory of "loss-correction". In RegGAN, the misaligned target images are considered as noisy labels˘aand the generator is trained with an addi-tional registration network to ﬁt the misaligned noise distribution adaptively. The goal is to search for the common optimal solution to both image-to-image transla-tion and registration tasks. We incorporated RegGAN into a few state-of-the-art image-to-image translation methods and demonstrated that RegGAN could be eas-ily combined with these methods to improve their performances. Such as a simple
CycleGAN in our mode surpasses latest NICEGAN even though using less net-work parameters. Based on our results, RegGAN outperformed both Pix2Pix on aligned data and Cycle-consistency on misaligned or unpaired data. RegGAN is insensitive to noises which makes it a better choice for a wide range of scenarios, especially for medical image-to-image translation tasks in which well pixel-wise aligned data are not available. Code and data used in this study can be found at https://github.com/Kid-Liet/Reg-GAN. 1

Introduction
Generative adversarial networks (GANs)[1] is a framework that simultaneously trains a generator G and a discriminator D through an adversarial process. The generator is used to translate the distribu-∗Equal contribution.
†Corresponding author. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
tion of source domain images X to the distribution of target domain images Y . The discriminator is used to determine if the target domain images are likely from the generator or from the real data. min
G max
D
LAdv (G, D) = Ey [log (D (y))] + Ex [log (1 − D (G (x)))] (1)
Supervised Pix2Pix[2] and unsupervised Cycle-consistency[3] are the two commonly used modes in GANs. Pix2Pix updates the generator (G : X → Y ) by minimizing pixel-level L1 loss between the source image x and the target image y. Therefore, it requires well aligned paired images, where each pixel has a corresponding label.
LL1 (G) = Ex,y [∥y − G (x) ∥1] min
G (2)
Well aligned paired images, however, are not always available in real-world scenarios. To address the challenges caused by misaligned images, Cycle-consistency was developed which was based on the assumption that the generator G from the source domain X to the target domain Y (G : X → Y ) was the reverse of the generator F from Y to X (F : Y → X). Compared to the Pix2Pix mode, the
Cycle-consistency mode works better on misaligned or unpaired images. min
G min
F
LCyc (G, F ) = Ex [∥F (G (x)) − x∥1] + Ey [∥G (F (y)) − y∥1] (3)
The Cycle-consistency mode, however, has its limitations. In the ﬁeld of medical image-to-image translation, it requires not only the style translation between image domains, but also the translation between speciﬁc pair of images. The optimal solution should be unique. For example, the translated images should maintain the anatomical features of the original images as much as possible. It is known that the Cycle-consistency mode may produce multiple solutions[4, 5], meaning that the training process may be relatively perturbing and the results may not be accurate. The pix2pix mode is not ideal either. Even though it has a unique solution, it is difﬁcult to satisfy the requirement asking for well aligned paired images. With misaligned images, the errors are propagated through the Pix2Pix mode which may result in unreasonable displacements on the ﬁnal translated images.
As of today, there is no image-to-image translation mode that can outperform both the Pix2Pix mode on aligned data and the Cycle-consistency mode on misaligned or unpaired data. Inspired by[6–10], we consider the misaligned target images as noisy labels, which means that the existing problem is regarded as supervised learning with noisy labels. So we introduce a new image-to-image translation mode called RegGAN. Figure 1 provides a comparison of the three modes: Pix2Pix,
Cycle-consistency and RegGAN. To facilitate reading, we summarize our contributions as follows.
• We demonstrate the feasibility of RegGAN from the theoretical perspective of "loss-correction". Speciﬁcally, we train the generator using an additional registration network to ﬁt the misaligned noise distribution adaptively, with the goal to search for the common optimal solution for both image-to-image translation and registration tasks.
• RegGAN eliminates the requirement for well aligned paired images and searches unique solution in training process. Based on our results, RegGAN outperformed both Pix2Pix on aligned data and Cycle-consistency˘aon misaligned or unpaired data.
• RegGAN can be integrated into other methods without changing the original network archi-tecture. Compared to Cycle-consistency with two generators and discriminators, RegGAN can provide better performance using less network parameters. 2