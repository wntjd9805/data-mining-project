Abstract
Existing rotated object detectors are mostly inherited from the horizontal detection paradigm, as the latter has evolved into a well-developed area. However, these detectors are difﬁcult to perform prominently in high-precision detection due to the limitation of current regression loss design, especially for objects with large aspect ratios. Taking the perspective that horizontal detection is a special case for rotated object detection, in this paper, we are motivated to change the design of rotation regression loss from induction paradigm to deduction methodology, in terms of the relation between rotation and horizontal detection. We show that one essential challenge is how to modulate the coupled parameters in the rotation regression loss, as such the estimated parameters can inﬂuence to each other during the dynamic joint optimization, in an adaptive and synergetic way. Speciﬁcally, we ﬁrst convert the rotated bounding box into a 2-D Gaussian distribution, and then calculate the
Kullback-Leibler Divergence (KLD) between the Gaussian distributions as the regression loss. By analyzing the gradient of each parameter, we show that KLD (and its derivatives) can dynamically adjust the parameter gradients according to the characteristics of the object. For instance, it will adjust the importance (gradient weight) of the angle parameter according to the aspect ratio. This mechanism can be vital for high-precision detection as a slight angle error would cause a serious accuracy drop for large aspect ratios objects. More importantly, we have proved that KLD is scale invariant. We further show that the KLD loss can be degenerated into the popular ln-norm loss for horizontal detection. Experimental results on seven datasets using different detectors show its consistent superiority, and codes are available at https://github.com/yangxue0827/RotationDetection. 1

Introduction
As a fundamental building block for visual analysis across aerial images, scene text etc., rotated object detection has recently been developed rapidly [1, 2, 3, 4, 5, 6], which beneﬁt themselves from the well-established horizontal detection approaches [7, 8, 9, 10, 11]. Speciﬁcally, many works
[12, 13, 14, 15] build themselves upon the previously established horizontal detection pipeline from an inductive perspective, as shown in Figure 1(a). However, these detectors are often unable to cope with challenging scenes well due to the limitations of current regression loss, such as large aspect ratio objects, dense scenes, etc., resulting in obvious disadvantages in high-precision detection.
∗Part of the work was done during an internship at Huawei Inc.
†Correspondence author is Junchi Yan. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
(a) Previous methods follow the induction paradigm (b) Our proposed method adopts a deduction methodol-from special horizontal to general rotated detection. ogy from general rotated to special horizontal detection.
Figure 1: Methodological road-map difference between horizontal detection (special case) and rotation detection (general case) in the previous methods [1, 12, 13, 14, 15] and the proposed method.
In this paper, we take a step back, and aim to develop (from a deductive perspective) a uniﬁed regression framework for rotation detection and its special case: horizontal detection. In fact, our new framework enjoys a coherent property that it can be degenerated into the current commonly used regression loss (e.g. ln-norm) in special cases (horizontal detection), as shown in Figure 1(b).
For a devising a rotation regression loss for high-precision rotation detection, one important observa-tion is that the importance of different parameters to different types of objects can vary. For example, the angle parameter (θ) and the center point parameter (x, y) are important for large aspect ratio objects and small objects, respectively. In another word, it is conjectured that regression loss should be self-modulated during the learning process and calls for more dynamic optimization strategy.
Inspired by the above ideas, we ﬁrst convert the rotated bounding box B(x, y, h, w, θ) into a 2-D
Gaussian distribution N (µ, Σ). As a standard distance metric, we then use the Kullback-Leibler
Divergence (KLD) [16] to calculate the distribution distance between the predicted bounding box and ground truth as the regression loss. We compare KLD with Smooth L1 loss [7] and another distance metric, Gaussian Wasserstein Distance (GWD) [5, 17], and ﬁnd that KLD has a more complete parameter optimization mechanism. In particular, by analyzing the gradient of the parameters during learning, we show that the optimization of one parameter will be affected by other parameters (as the gradient weight). It means that the model will adaptively adjust the optimization strategy given a speciﬁc conﬁguration of an object for detection, as shown can lead to excellent performance in high-precision detection. In addition, KLD is proven scale invariant, which is an important property that Smooth L1 loss and GWD do not possess. As the horizontal bounding box is a special case of the rotated bounding box, we show that KLD can also be degenerated into the ln-norm loss as commonly used in existing horizontal detection pipeline. The highlights of this paper are four-folds: 1) Differing from the dominant existing practices that build rotation detectors heavily upon the horizontal detectors, we develop new rotation detection loss from scratch and show that it is coherent with existing horizontal detection protocol in its degenerated case for horizontal detection. 2) To achieve a more principled measurement between the prediction and ground truth, instead of computing the difference for each physically-meaningful parameter related to the bounding box which are in different scales and units, we innovatively convert the regression loss of rotation detection into the KLD of two 2-D Gaussian distributions, leading to a clean and coherent regression loss. 3) Through the gradient analysis of each parameter in KLD, we further ﬁnd that the self-modulated optimization mechanism of KLD greatly promotes the improvement of high-precision detection, which verify the advantage of our loss design. More importantly, we have theoretically shown (in appendix) that KLD is scale invariant for detection, which is crucial for the rotation cases. 4) Extensive experimental results on seven public datasets and two popular detectors show the effectiveness of our approach, which achieves new state-of-the-art performance for rotation detection.
The source codes [18] are made public available. 2