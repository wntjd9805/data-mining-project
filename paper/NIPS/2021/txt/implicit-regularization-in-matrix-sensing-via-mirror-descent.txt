Abstract
We study discrete-time mirror descent applied to the unregularized empirical risk in matrix sensing. In both the general case of rectangular matrices and the particular case of positive semideﬁnite matrices, a simple potential-based analysis in terms of the Bregman divergence allows us to establish convergence of mirror descent—with different choices of the mirror maps—to a matrix that, among all global minimizers of the empirical risk, minimizes a quantity explicitly related to the nuclear norm, the
Frobenius norm, and the von Neumann entropy. In both cases, this characterization implies that mirror descent, a ﬁrst-order algorithm minimizing the unregularized empirical risk, recovers low-rank matrices under the same set of assumptions that are sufﬁcient to guarantee recovery for nuclear-norm minimization. When the sensing matrices are symmetric and commute, we show that gradient descent with full-rank factorized parametrization is a ﬁrst-order approximation to mirror descent, in which case we obtain an explicit characterization of the implicit bias of gradient
ﬂow as a by-product. 1

Introduction
Matrix sensing represents a paradigm in modern statistics [8, 26, 27], with applications ranging from image compression [2] to collaborative ﬁltering [18] and dimensionality reduction [34], for instance.
The goal is to recover a rank-r matrix X(cid:63) ∈ Rn×n(cid:48) from a set of linear measurements yi = (cid:104)Ai, X(cid:63)(cid:105), i = 1, . . . , m, where the sensing matrices Ai ∈ Rn×n(cid:48) are observed. This formulation includes the problem of matrix completion, where a subset of the entries of the matrix X(cid:63) is observed.
Most of the literature on matrix sensing is based on some form of explicit regularization or rank constraint to encourage or enforce low-rankness of the estimated matrix. A popular approach is based on minimizing the nuclear norm or on using explicit regularization techniques based on the nuclear norm, e.g. [5, 15, 17, 23, 26, 27, 30]. Another popular approach is based on non-convex optimization and the low-rank factorization X = UV(cid:62) with matrices U ∈ Rn×r, V ∈ Rn(cid:48)×r, where the factorization itself enforces the low-rankness of X, e.g. [7, 8, 16, 21, 22, 29, 31, 39].
The literature on implicit regularization for matrix sensing is more recent and less well developed.
When X(cid:63) is assumed to be a positive semideﬁnite matrix, it was ﬁrst empirically observed in [14] that mininizing the unregularized empirical risk using vanilla gradient descent with parametrization
X = UU(cid:62) and random full-rank initialization close to zero yields a low nuclear norm solution, even when U ∈ Rn×n, i.e. when no constraint on the rank of X is enforced. It was later proved that, with this parametrization, gradient descent minimizes the nuclear norm under the assumption that the sensing matrices Ai’s commute [14], or when the sensing matrices satisfy a restricted isometry property [19]. Gradient descent with low-rank initialization within a speciﬁc “capture neighborhood” has been studied in [9], which ensures that the iterates of the algorithm stay low-rank. When X(cid:63) is a general rectangular matrix, implicit regularization in matrix sensing has been studied through 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
the lenses of deep matrix factorization in [3, 12, 20, 25], and empirical and theoretical evidence is provided which suggests that a notion of rank-minimization is involved in the implicit bias of gradient descent. However, these works do not establish an explicit characterization of the limiting point of the optimization algorithm, e.g. in the form of a quantity that is minimized among all minimizers of the empirical risk. In the special case of full-observation matrix sensing, gradient ﬂow has been shown to learn solutions with gradually increasing rank [11].
Most theoretical results on implicit regularization in matrix sensing consider the continuous-time dynamics (i.e. gradient ﬂow), e.g. [3, 9, 12, 14, 20, 25], or assume an inﬁnitesimally small initial-ization, e.g. [14, 20]. Notable exceptions are [11], which makes a commutativity assumption on the data matrices in discrete time, and [19], which assumes a restricted isometry property that leads to a suboptimal sample complexity when the sensing matrices belong to a general class of random matrices [27]. In the context of linear neural networks, the dependence of the implicit bias of gradient descent on the initialization has been studied in [4, 24, 35, 38]. For instance, linear diagonal networks with shared weights were considered in [35], where it was shown that gradient descent minimizes a quantity which corresponds to the (cid:96)1-norm in the limit α → 0 and to the (weighted) (cid:96)2-norm in the limit α → ∞, where α denotes the initialization size. This result was later generalized in [38] using a tensor formulation, which allows for architectures including linear diagonal networks and linear full-length convolutional networks. However, these results focus on vector-based notions of norm-like functions that do not capture matrix-based quantities typically of interest in matrix sensing. 1.1 Our contributions
We study the implicit bias of discrete-time mirror descent in matrix sensing in both the general case of rectangular matrices and the particular case of positive semideﬁnite matrices. Under the only assumption on the sensing matrices Ai’s that there exists a matrix achieving zero training error, we characterize the limiting point as the matrix that minimizes a quantity which interpolates between the nuclear norm and Frobenius norm, parametrized by the mirror map parameter, in the rectangular case; and which is a linear combination of the nuclear norm and the negative von Neumann entropy, parametrized by the initialization size, in the positive semideﬁnite case. Compared to results on implicit regularization for gradient descent, our framework for mirror descent is simple, and the same analysis yields results for both the case of general rectangular and positive semideﬁnite matrices.
In the general case of rectangular matrices, we show that mirror descent, initialized at zero and equipped with the spectral hypentropy mirror map [10] parametrized by β > 0, among all global minimizers of the empirical risk, converges to a matrix that minimizes a quantity interpolating between the nuclear norm in the limit β → 0 and the Frobenius norm in the limit β → ∞. As a consequence, our result implies that, for β → 0, mirror descent can recover a rank-r matrix X(cid:63) under the same set of assumptions that is sufﬁcient for nuclear norm minimization to be successful, namely when the sensing matrices Ai’s satisfy the restricted isometry property with restricted isometry constant smaller than some absolute constant [27], or if X(cid:63) satisﬁes an incoherence condition and r(n + n(cid:48)) (modulo constants and logarithmic term) random entries of X(cid:63) are observed [26]. To the best of our knowledge, this is the ﬁrst recovery guarantee for an implicit regularization-based algorithm that does not explicitly enforce low-rankness in general rectangular matrix sensing.
In the particular case of positive semideﬁnite matrices, we can alternatively consider the spectral entropy mirror map and show that mirror descent, initialized at αI for any α > 0, converges to a positive semideﬁnite matrix that minimizes a linear combination of the nuclear norm and the negative von Neumann entropy, where the relative weights are controlled by the initialization size
α. While the limit α → 0 corresponds to minimizing the nuclear norm as in the case of rectangular matrices, the limit α → ∞ corresponds to maximizing the nuclear norm. This also translates into guaranteed recovery of a low-rank matrix X(cid:63) for α → 0 under the same assumptions that are sufﬁcient for nuclear norm minimization [26, 27]. A comparable result for gradient descent with full-rank factorized parametrization has been established in [19] under a stronger assumption on the restricted isometry constant, which is assumed to be smaller than a quantity depending on both the rank and the condition number of the matrix X(cid:63) and translates into a sub-optimal sample complexity.
We establish our results using a potential-based analysis for mirror descent in terms of the Bregman divergence, which provides an alternative proof technique to characterize the limiting point of mirror descent compared to the analysis based on KKT optimality conditions used in [13]. As a by-product, our proof of Theorem 1 yields an alternative proof of Theorem 1 in [13]. The advantage of our 2
approach is that convergence of mirror descent does not need to be assumed a-priori and can instead be established using convexity of the empirical risk. The analysis in terms of the Bregman divergence is not limited to convex settings and has been applied to non-convex problems, e.g. [36, 37, 40], and hence can be of more general interest to investigate the phenomenon of implicit bias.
In the case of square matrices, we show, assuming that the sensing matrices Ai’s are symmetric and commute, that gradient descent with full-rank parametrization X = UU(cid:62) − VV(cid:62), U, V ∈ Rn×n, is a ﬁrst-order approximation to mirror descent equipped with the spectral hypentropy, where the initialization size corresponds to the mirror map parameter β. A similar connection between mirror descent and reparametrized gradient descent has been established in the vector-case [1, 10, 33, 36].
Similarly, we show that gradient descent with full-rank parametrization X = UU(cid:62), U ∈ Rn×n, is a ﬁrst-order approximation to mirror descent equipped with the spectral entropy when the sensing matrices are symmetric and commute, thus recovering a generalization of Theorem 1 in [14] which holds for any positive initialization size α > 0 (rather than in the limit α → 0).
We present numerical simulations which suggest that, in some regimes, our results on the dependence on the initialization size α for mirror descent might be indicative for the behavior of gradient descent, even when the sensing matrices Ai’s do not commute. More precisely, the ﬁnal estimates of gradient descent and mirror descent closely track each other when the number of measurements is sufﬁciently large for nuclear norm minimization to recover a planted low-rank matrix, while gradient descent seems to put more emphasis on lowering the effective rank [28] at the expense of a higher nuclear norm when fewer measurements are available, which supports the empirical observations in [3, 20]. 2