Abstract
In recent years, substantial research on the methods for learning Hamiltonian equations has been conducted. Although these approaches are very promising, the commonly used representation of the Hamilton equation uses the generalized momenta, which are generally unknown. Therefore, the training data must be represented in this unknown coordinate system, and this causes difﬁculty in ap-plying the model to real data. Meanwhile, Hamiltonian equations also have a coordinate-free expression that is expressed by using the symplectic 2-form. In this paper, we propose a model that learns the symplectic form from data using neural networks, thereby providing a method for learning Hamiltonian equations from data represented in general coordinate systems, which are not limited to the generalized coordinates and the generalized momenta. Consequently, the proposed method is capable not only of modeling the target equations of both Hamiltonian and Lagrangian formalisms but also of extracting unknown Hamiltonian structures hidden in the data. For example, many polynomial ordinary differential equations such as the Lotka–Volterra equation are known to admit non-trivial Hamiltonian structures, and our numerical experiments show that such structures can certainly be learned from data. Technically, each symplectic 2-form is associated with a skew-symmetric matrix, but not all skew-symmetric matrices deﬁne a symplectic 2-form. In the proposed method, using the fact that symplectic 2-forms are derived as the exterior derivative of certain differential 1-forms, we model the differential 1-form by neural networks, thereby improving the efﬁciency of learning. 1

Introduction
In recent years, the applications of deep learning to learn the fundamental equations of classical mechanics have been actively studied. Analytical mechanics, which is a theory of classical mechanics, is classiﬁed into Lagrangian mechanics and Hamiltonian mechanics [1, 3, 18]. The equations of motion of Lagrangian mechanics are called the Euler–Lagrange equation, for which several neural network models were proposed [7, 17]. In Lagrangian mechanics, the equations are described using the state variables and the time derivatives of them. This feature of Lagrangian mechanics makes it easy to prepare the data necessary for learning. On the other hand, Hamiltonian mechanics can describe more general equations which are not covered by Lagrangian mechanics. In the previous 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
Figure 1: Overview of the proposed method. Generally, the analytical representation of generalized momenta is unknown, so the data cannot be presented in a canonical coordinate system. The proposed method learns the Hamilton equation from data represented in an arbitrary coordinate system by learning the symplectic 2-form as well as the energy function. In particular, to ensure that the learned symplectic 2-form is closed, our method learns the differential 1-form that derives the symplectic 2-form. A universal approximation theorem is also provided. models for Hamiltonian equations, the equation (cid:19) (cid:18)q p d dt (cid:18) O I
−I O
= (cid:33) (cid:19) (cid:32) ∂H
∂q
∂H
∂p (1) is typically assumed, where q is the state variable, and p is a variable called the generalized momentum.
It is known that Hamiltonian equations can be written in this form by using these variables; more precisely, any Hamiltonian equation can be locally written as (1) by using a special coordinate system called the Darboux coordinate system [20]. However, this coordinate system depends on the generally unknown Hamiltonian (the energy function), and it is usually not possible to prepare data in this coordinate system.
On the other hand, Hamiltonian equations also have a coordinate-free representation using the symplectic 2-form [20]. In this paper, we propose a method to learn the symplectic 2-form from data by using neural networks, thereby introducing a method to learn the Hamilton equation from data represented in general coordinate systems, not restricted to the generalized momentum. As explained below, general 2-forms are corresponding to skew symmetric matrices. Hence, a naive way to learn the symplectic 2-form is learning a skew symmetric matrix; however, actually, the equation learned in this way may not be Hamiltonian because not all skew symmetric matrices are corresponding to symplectic 2-forms. In the proposed method, instead of learning the 2-form directly, a 1-form that derives the symplectic 2-form is learned (see Figure 1).
Because the proposed model can be applied to data in any coordinate system, it can be employed for extracting the unknown underlying Hamiltonian structure behind the data that are expected to have such a structure. For example, many polynomial ordinary differential equations are known to have a Hamiltonian structure, but it is not easy to ﬁnd the structure analytically. The proposed method extracts the hidden structure in such cases from data. If the Hamiltonian structure can be found, it is possible to make predictions while preserving the energy conservation law. In addition to the energy, other hidden conserved quantities can be also extracted.
Main contributions of this paper include:
Symplectic geometric approach to learning symplectic 2-forms. The symplectic 2-form required to describe the Hamilton equation corresponds to a skew-symmetric matrix, but conversely, not all skew-symmetric matrices correspond to a symplectic 2-form. In this paper, we propose an efﬁcient model by learning the symplectic 1-form that derives the symplectic 2-form with neural networks.
Learning the Hamilton equation from data in arbitrary coordinate systems. By using the coordinate-free representation of the Hamilton equation, it is possible to learn the Hamilton equation from data represented in a general coordinate system, not restricted to the Darboux coordinate system.
In this way, the proposed method can determine whether the given data can be explained by the hidden theory of classical mechanics or not. A universal approximation theorem is also provided. 2
Table 1: Comparison with other studies.
HNN [11] LNN [7]
Skew Matrix
Learning (Sec. 3)
Neural Symplectic
Form (proposed)
In the known Darboux coordinate
In general coordinates on cotangent bundles
On general symplectic manifolds yes yes yes yes yes yes
Only symplectic forms
N/A
N/A yes yes yes yes 2