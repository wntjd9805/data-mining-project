Abstract
The generalization of representations learned via contrastive learning depends crucially on what features of the data are extracted. However, we observe that the contrastive loss does not always sufﬁciently guide which features are extracted, a behavior that can negatively impact the performance on downstream tasks via
“shortcuts”, i.e., by inadvertently suppressing important predictive features. We
ﬁnd that feature extraction is inﬂuenced by the difﬁculty of the so-called instance discrimination task (i.e., the task of discriminating pairs of similar points from pairs of dissimilar ones). Although harder pairs improve the representation of some features, the improvement comes at the cost of suppressing previously well represented features. In response, we propose implicit feature modiﬁcation (IFM), a method for altering positive and negative samples in order to guide contrastive models towards capturing a wider variety of predictive features. Empirically, we observe that IFM reduces feature suppression, and as a result improves performance on vision and medical imaging tasks. The code is available at: https://github. com/joshr17/IFM. 1

Introduction
Representations trained with contrastive learning are adept at solving various vision tasks including classiﬁcation, object detection, instance segmentation, and more [5, 15, 44]. In contrastive learning, encoders are trained to discriminate pairs of positive (similar) inputs from a selection of negative (dissimilar) pairs. This task is called instance discrimination: It is often framed using the InfoNCE loss [14, 33], whose minimization forces encoders to extract input features that are sufﬁcient to discriminate similar and dissimilar pairs.
However, learning features that are discriminative during training does not guarantee a model will generalize. Many studies ﬁnd inductive biases in supervised learning toward simple “shortcut” features and decision rules [16, 21, 32] which result in unpredictable model behavior under perturbations
[22, 43] and failure outside the training distribution [2, 37]. Simplicity bias has various potential sources [11] including training methods [8, 29, 41] and architecture design [10, 17]. Bias towards shortcut decision rules also hampers transferability in contrastive learning [4], where it is in addition inﬂuenced by the instance discrimination task. These difﬁculties lead us to ask: can the contrastive instance discrimination task itself be modiﬁed to avoid learning shortcut solutions?
We approach this question by studying the relation between contrastive instance discrimination and feature learning. First, we theoretically explain why optimizing the InfoNCE loss alone does not guarantee avoidance of shortcut solutions that suppress (i.e., discard) certain input features [4, 11].
Second, despite this negative result, we show that it is still possible to trade off representation of
Correspondence to Joshua Robinson (joshrob@mit.edu). 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
features sunny  dog  moving 
Ideal: diﬀerent because   sunny vs shady    dog vs cat  moving vs still discriminative features
Shortcut: diﬀerent because   sunny vs shady    features shady  cat  still 
Figure 1: An ideal encoder would discriminate between instances using multiple distinguishing features instead of ﬁnding simple shortcuts that suppress features. We show that InfoNCE-trained encoders can suppress features (Sec. 2.2). However, making instance discrimination harder during training can trade off representation of different features (Sec. 2.3). To avoid the need for trade-offs we propose implicit feature modiﬁcation (Sec. 3), which reduces suppression in general, and improves generalization (Sec. 4). one feature for another using simple methods for adjusting the difﬁculty of instance discrimination.
However, these methods have an important drawback: improved learning of one feature often comes at the cost of harming another. That is, feature suppression is still prevalent. In response, we propose implicit feature modiﬁcation, a technique that encourages encoders to discriminate instances using multiple input features. Our method introduces no computational overhead, reduces feature suppression (without trade-offs), and improves generalization on various downstream tasks.
Contributions. In summary, this paper makes the following main contributions: 1. It analyzes feature suppression in contrastive learning, and explains why feature suppression can occur when optimizing the InfoNCE loss. 2. It studies the relation between instance discrimination tasks and feature learning; concretely, adjustments to instance discrimination difﬁculty leads to different features being learned. 3. It proposes implicit feature modiﬁcation, a simple and efﬁcient method that reduces the tendency to use feature suppressing shortcut solutions and improves generalization. 1.1