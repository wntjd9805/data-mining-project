Abstract
Why do many modern neural-network-based graph generative models fail to repro-duce typical real-world network characteristics, such as high triangle density? In this work we study the limitations of edge independent random graph models, in which each edge is added to the graph independently with some probability. Such models include both the classic Erdös-Rényi and stochastic block models, as well as modern generative models such as NetGAN, variational graph autoencoders, and CELL. We prove that subject to a bounded overlap condition, which ensures that the model does not simply memorize a single graph, edge independent models are inherently limited in their ability to generate graphs with high triangle and other subgraph densities. Notably, such high densities are known to appear in real-world social networks and other graphs. We complement our negative results with a simple generative model that balances overlap and accuracy, performing comparably to more complex models in reconstructing many graph statistics. 1

Introduction
Our work centers on edge independent graph models, in which each edge (i, j) is added to the graph independently with some probability Pij ∈ [0, 1]. Formally,
Definition 1 (Edge Independent Graph Model). For any symmetric matrix P ∈ [0, 1]n×n let G(P ) be the distribution over undirected unweighted graphs where G ∼ G(P ) contains edge (i, j) inde-pendently, with probability Pij. I.e., p(G) = (cid:81) (i,j)∈E(G) Pij · (cid:81) (i,j) /∈E(G)(1 − Pij).
Edge independent models encompass many classic random graph models. This includes the Erdös-Rényi model, where for all i ̸= j, Pij = p for some fixed p ∈ [0, 1] [10]. It also includes the stochastic block model where Pij = p if two nodes are in the same community and Pij = q if two nodes are in different communities for some fixed p, q ∈ [0, 1] with q < p [29]. Other examples include e.g., the Chung-Lu configuration model [5], stochastic Kronecker graphs [17].
Recently, significant attention has focused on graph generative models, which seek to learn a distribution over graphs that share similar properties to a given training graph, or set of graphs. Many algorithms parameterize this distribution as an edge independent model or closely related distribution.
E.g., NetGAN and the closely related CELL model both produce P ∈ [0, 1]n×n and then sample edges independently without replacement with probabilities proportional to its entries, ensuring that at least one edge is sampled adjacent to each node [3, 23]. Variational Graph Autoencoders (VGAE),
GraphVAE, Graphite, and MolGAN are also all based on edge independent models [16, 28, 8, 13].
Given their popularity in both classical and modern graph generative models, it is natural to ask: 35th Conference on Neural Information Processing Systems (NeurIPS 2021), virtual.
How suited are edge independent models to modeling real-world networks. Are they able to capture features such as power-law degree distributions, small-world properties, and high clustering coefficients (triangle densities)? 1.1 Impossibility Results for Edge Independent Models
In this work we focus on the ability of edge independent models to generate graphs with high triangle, or other small subgraph densities. High triangle density (equivalently, a high clustering coefficient) is a well-known hallmark of real-work networks [31, 25, 9] and has been the focus of recent work exploring the power and limitations of edge-independent graph models [27, 4].
It is clear that edge independent models can generate triangle dense graphs. In particular, P ∈
[0, 1]n×n in Def. 1 can be set to the binary adjacency matrix of any undirected graph, and G(P ) will generate that graph with probability 1, no matter how triangle dense it is. However, this would not be a particularly interesting generative model – ideally G(P ) should generate a wide range of graphs. To capture this intuitive notion, we define the overlap of an edge-independent model, which is closely related to the overlap stopping criterion for training used in training graph generative models [3, 23].
Definition 2 (Expected Overlap). For symmetric P ∈ [0, 1]n×n let V (P ) def= EG∼G(P )|E(G)| and
Ov(P ) def=
EG1,G2∼G(P )|E(G1) ∩ E(G2)|
V (P )
.
That is, for any P ∈ [0, 1]n×n, Ov(P ) ∈ [0, 1] is the ratio of the expected number of edges shared by two graphs drawn independently from G(P ) to the expected number of edges in a graph drawn from G(P ). In one extreme, when P is a binary adjacency matrix, Ov(P ) = 1, and our generative model has simply memorized a single graph. In the other, if Pij = p for all i ̸= j (i.e., G(P ) is
Erdös-Rényi), Ov(P ) = p. This is the minimum possible overlap when V (P ) = p · (cid:0)n (cid:1). 2
Our main result is that for any edge independent model with bounded overlap, G ∼ G(P ) cannot have too many triangles in expectation. In particular:
Theorem 1 (Main Result – Expected Triangles). For a graph G, let ∆(G) denote the number of triangles in G. Consider symmetric P ∈ [0, 1]n×n.
EG∼G(P ) [∆(G)] ≤
· Ov(P )3/2 · V (P )3/2.
√ 2 3
As an example, consider the setting where the distribution generates sparse graphs, with V (P ) =
Θ(n). Theorem 1 shows that whenever Ov(P ) = o(1/n1/3), EG∼G(P )∆(G) = o(n) – i.e. the graph is very triangle sparse with the number of triangles sublinear in the number of nodes. This verifies that an Erdös-Rényi graph cannot achieve simultaneously linear number of edges (i.e., Ov(P ) = O(1/n)
) and super-linear number of triangles (i.e., Ov(P ) = Ω(1/n1/3)) under our proposed lens of viewing generative models.
We extend Theorem 1 to give similar bounds for the density of squares and other k-cycles (Thm. 4), as well as for the global clustering coefficient (Thm. 6). In all cases we show that our bounds are tight – e.g., in the triangle case, there is indeed an edge independent model with EG∼G(P ) [∆(G)] =
Θ (cid:0)Ov(P )3/2 · V (P )3/2(cid:1), matching the lower bound in Theorem 1. 1.2 Empirical Findings
Our theoretical results help explain why, despite performing well in a variety of other metrics, edge independent graph generative models have been reported to generate graphs with many fewer triangles and squares on average than the real-world graphs that they are trained on. Rendsburg et al. [23] test a suite of these models, including their own CELL model and the related NetGAN model [3]. Of all these models, when trained on the CORA-ML graph with 2,802 triangles and 14,268 squares, none is able to generate graphs with more than 1,461 triangles and 6,880 squares on average. Similar gaps are observed for a number of other graphs. Rendsburg et al. also report that the triangle count increases as their notion of overlap (closely related to Def. 2) increases. Theorem 1 demonstrates that this underestimation of triangle count, and its connection to overlap is inherent to all edge independent models, no matter how refined a method used to learn the underlying probability matrix P . 2
While our theoretical results bound the performance of any edge independent model, there may still be variation in how specific models trade-off overlap and realistic graph generation. To better understand this trade-off, we introduce two simple models with easily tunable overlap as baselines. One is based on reproducing the degree sequence of the original graph; the other, which is even simpler, is based on reproducing the volume. In both models, P is a weighted average of the input graph adjacency matrix and a probability matrix of minimal complexity which matches either the input degrees or the volume. In the latter case, to match just the volume, we simply use an Erdös-Rényi graph. In the former case, to match the degree sequence, we introduce our own model, the odds product model; this model is similar to the Chung-Lu configuration model [5], but, unlike Chung-Lu, is able to match degree sequences of real-world graphs with high maximum degree. We find that these simple baselines are often competitive with more complex models like CELL in terms of matching key graph statistics, like triangle count and clustering coefficient, at similar levels of overlap. 1.3