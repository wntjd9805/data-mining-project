Abstract
Stochastic model-based methods have received increasing attention lately due to their appealing robustness to the stepsize selection and provable efﬁciency guarantee. We make two important extensions for improving model-based methods on stochastic weakly convex optimization. First, we propose new minibatch model-based methods by involving a set of samples to approximate the model function in each iteration. For the ﬁrst time, we show that stochastic algorithms achieve linear speedup over the batch size even for non-smooth and non-convex (particularly, weakly convex) problems. To this end, we develop a novel sensitivity analysis of the proximal mapping involved in each algorithm iteration. Our analysis appears to be of independent interests in more general settings. Second, motivated by the success of momentum stochastic gradient descent, we propose a new stochastic extrapolated model-based method, greatly extending the classic Polyak momentum technique to a wider class of stochastic algorithms for weakly convex optimization.
The rate of convergence to some natural stationarity condition is established over a fairly ﬂexible range of extrapolation terms.
While mainly focusing on weakly convex optimization, we also extend our work to convex optimization. We apply the minibatch and extrapolated model-based methods to stochastic convex optimization, for which we provide a new complexity bound and promising linear speedup in batch size. Moreover, an accelerated model-based method based on Nesterov’s momentum is presented, for which we establish an optimal complexity bound for reaching optimality. 1

Introduction
In this paper, we are interested in the following stochastic optimization problem: min x ∈ X f (x) = Eξ∼Ξ (cid:2)f (x, ξ)(cid:3) (1) where f (·, ξ) stands for the loss function, sample ξ follows certain distribution Ξ, and X is a closed convex set. We assume that f (·, ξ) is weakly convex, namely, the sum of f (x, ξ) and a quadratic function λ 2 (cid:107)x(cid:107)2 is convex (λ > 0). This type of non-smooth non-convex functions can be found in a variety of machine learning applications, such as phase retrieval, robust PCA and low rank decomposition [8]. To solve problem (1), we consider the stochastic model-based method (SMOD,
[14, 9, 1]), which comprises a large class of stochastic algorithms (including stochastic (sub)gradient descent, proximal point, among others). Recent work [14, 9] show that SMOD exhibits promising convergence property: both asymptotic convergence and rates of convergence to certain stationarity 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
measure have been established for the SMOD family. In addition, empirical results [9, 15] indicate that
SMOD exhibits remarkable robustness to hyper-parameter tuning and often outperforms SGD.
Despite much recent progress, our understanding of model-based methods for weakly convex opti-mization is still quite limited. Particularly, it is still unknown whether SMOD is competitive against modern SGD used in practice. We highlight some important remaining questions. First, despite the appealing robustness and stable convergence, the SMOD family is sequential in nature. It is unclear whether minibatching, which is immensely used in training learning models, can improve the perfor-mance of SMOD when the problem is non-smooth. Particularly, the current best complexity bound
O( L2
ε4 ) from [9], which is regardless of batch size, is unsatisfactory. Were this bound tight, a sequen-tial algorithm (using one sample per iteration) would be optimal: it offers the highest processing speed per iteration as well as the best iteration complexity. Therefore, it is crucial to know whether minibatching can improve the complexity bound of the SMOD family or the current bound is tight.
Second, in modern applications, momentum technique has been playing a vital role in large-scale non-convex optimization (see [31, 28]). In spite of its effectiveness, to the best of our knowledge, momentum technique has been provably efﬁcient only in 1) unconstrained smooth optimization
[23, 10, 19] and 2) non-smooth optimization with a simple constraint [25], which constitute only a portion of the interesting applications. From the practical aspect, it is peculiarly desirable to know whether momentum technique is applicable beyond in SGD and whether it can beneﬁt the SMOD algorithm family in the non-smooth and non-convex setting.
Contributions. Our work is motivated by the aforementioned challenge to make SMOD more practi-cally efﬁcient. We summarize the contributions as follows. First, we extend SMOD to the minibatch setting and develop sharper rates of convergence to stationarity. Leveraging the tool of algorithm stability ([6, 27, 20]), we provide a nearly complete recipe on when minibatching would be helpful even in presence of non-smoothness. Our theory implies that stochastic proximal point and stochastic prox-linear are inherently parallelizable: both algorithms achieve linear speedup over the minibatch size. To the best of our knowledge, this is the ﬁrst time that these minibatch stochastic algorithms are proven to exhibit such an acceleration even for non-smooth and non-convex (particularly, weakly convex) optimization. Moreover, our theory recovers the complexity of minibatch (proximal) SGD in [9], showing that (proximal) SGD enjoys the same linear speedup by minibatching for smooth composite problems with non-smooth regularizers or with constrained domain.
Second, we present new extrapolated model-based methods by incorporating a Polyak-type mo-mentum term. We develop a uniﬁed Lyapunov analysis to show that a worst-case complexity of
O(1/ε4) holds for all momentum SMOD algorithms. To the best of our knowledge, these are the ﬁrst complexity results of momentum stochastic prox-linear and stochastic proximal point for non-smooth non-convex optimization. Since our analysis offers complexity guarantees for momentum SGD and its proximal variant, our work appears to be more general than a recent study [25], which only proves the convergence of momentum projected SGD. Proximal SGD is more advantageous in composite optimization, where the non-smooth term is often involved via its proximal operator rather than the subgradient. For example, in the Lasso problem, it is often favorable to invoke the proximal operator of (cid:96)1 function (Soft-Thresholding) to enhance solution sparsity. We summarize the complexity results in Table 1.
Third, we develop new convergence results of SMOD for convex optimization, showing that minibatch extrapolated SMOD achieves a promising linear speedup over the batch size under some mild condition.
Speciﬁcally, to obtain some ε-optimal solution, our proposed method exhibits an O(1/ε + 1/(mε2)) complexity bound in the worst case. Moreover, we develop a new minibatch SMOD based on Nesterov’s momentum, achieving the O(1/ε1/2 + 1/(mε2)) optimal complexity bound. Note that a similar complexity result, explicitly relying on the smoothness assumption, has been shown in a recent study [7]. Compared to this work, our analysis makes weaker assumptions, showing that smoothness is not a must-have for many model-based algorithms, such as SPL and SPP, to get sharper complexity bound.
Other related work. For smooth and composite optimization, it is well known that SGD can be linearly accelerated by minibatching (c.f. [11, 18, 29]). Minibatch model-based methods have been studied primarily in the convex setting. Asi et al. [2] investigates the speedups of minibatch stochastic model-based methods in the convex smooth, restricted strongly convex and convex interpolation settings, respectively. Since their assumptions differ from ours, the technique does not readily apply to the non-convex setting. Chadha et al. [7] studies the accelerated minibatch model-based methods 2
Table 1: Complexity of SMOD to reach E (cid:107)∇1/ρf (cid:107) ≤ ε (M: minibatch; E: Extrapolation, m: batch size)
Algorithms
M + SGD
M + Prox. SGD
M + SPL/SPP
E + SGD
E + Prox. SGD
E + SPL/SPP
M + E + SGD
M + E + Prox. SGD
M + E + SPL/SPP
Ours
O(1/ε4)
Problem f : non-smooth
Current Best
O(1/ε4)[9] f = (cid:96) + ω; (cid:96):smooth O(1/(mε4) + 1/ε2)[9] O(1/(mε4) + 1/ε2)
O(1/(mε4) + 1/ε2)
O(1/ε4)[9]
O(1/ε4)
O(1/ε4)[25]
O(1/ε4)
—
O(1/ε4)
—
O(1/ε4)
O(1/ε4)[25]
O(1/(mε4) + 1/ε2)
—
O(1/(mε4) + 1/ε2)
— f : non-smooth f : non-smooth f = (cid:96) + ω; (cid:96):smooth f : non-smooth f : non-smooth f = (cid:96) + ω; (cid:96):smooth f : non-smooth for convex smooth and convex interpolated problems. The interpolation setting, where the model can perfectly ﬁt the data, is not considered in our paper. Algorithm stability [6, 27]—an important technique for analyzing the generalization performance of stochastic algorithms [20, 3], is the key tool to obtain some of our convergence results. In contrast to the traditional work, our paper employs the stability argument to obtain sharper optimization convergence rates (with respect to the batch size). See Section 3. As noted by an anonymous reviewer, a similar idea of using stability analysis was proposed by Wang et al. [30], albeit with a different motivation from distributed stochastic optimization. Robustness and fast convergence of model-based methods have been shown on various statistical learning problems [8, 15, 1, 4, 16, 5]. Drusvyatskiy and Paquette [13] give a complete complexity analysis of the accelerated proximal-linear methods for deterministic optimization. Zhang and Xiao [32] further improve the convergence rates of prox-linear methods on certain ﬁnite-sum and stochastic problems by using variance-reduction. Momentum and accelerated methods for convex stochastic optimization can be referred from [24, 26]. The study [10, 23, 31] develop the convergence rate of stochastic momentum method for smooth non-convex optimization. 2