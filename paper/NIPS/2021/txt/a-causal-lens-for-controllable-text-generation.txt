Abstract
Controllable text generation concerns two fundamental tasks of wide applications, namely generating text of given attributes (i.e., attribute-conditional generation), and minimally editing existing text to possess desired attributes (i.e., text attribute transfer). Extensive prior work has largely studied the two problems separately, and developed different conditional models which, however, are prone to producing biased text (e.g., various gender stereotypes). This paper proposes to formulate controllable text generation from a principled causal perspective which models the two tasks with a uniﬁed framework. A direct advantage of the causal formulation is the use of rich causality tools to mitigate generation biases and improve control.
We treat the two tasks as interventional and counterfactual causal inference based on a structural causal model, respectively. We then apply the framework to the challenging practical setting where confounding factors (that induce spurious correlations) are observable only on a small fraction of data. Experiments show signiﬁcant superiority of the causal approach over previous conditional models for improved control accuracy and reduced bias. 1

Introduction
Controllable text generation aims at producing ﬂuent language with control over various attributes, ranging from sentiment, topic, politeness, to gender, persona, and so forth [60, 22]. The problem lies at the heart of many NLP applications such as emotional chatbot, news article writing, language detoxiﬁcation, etc. Of particular interest in this increasingly signiﬁcant area are two settings for control, namely (1) attribute-conditional generation [14, 30] which generates sentences that entail a given attribute, and (2) text attribute transfer [64, 26] which rewrites a given sentence to possess a desired attribute while preserving all other original characteristics (Figure 1). The goal is to learn the control in each setting with (attribute, text) training pairs1.
The two settings have usually been considered as separate tasks and each led to various solutions, respectively. Let x denote a sentence and a an attribute. Previous attribute-conditional generation work typically concerns the conditional distribution p(x|a) [14, 30, 33]. Despite the success of simulating observed real text, the conditional distribution is known to be susceptible to capture spurious correlations or biases in the data [48, 84]. For example, when generating biographical text given a gender attribute, the conditional model tends to generate text related to speciﬁc occupations such as nurse and yoga teacher for female, and architect and attorney for male [57, 69] (Figure 1).
The learned biases could impair the model generalization to new domains, and make negative social impact in downstream applications. A few very recent attempts have been made to mitigate the biases in the model with various machine learning techniques. Yet those methods are often speciﬁc to a particular attribute (e.g., gender) [68, 86], or rely on access to additional resources, such as fully observed confounding labels or a priori debiased classiﬁers [23, 40, 67], which can be costly to obtain in real applications. Furthermore, it is unclear how the diverse methods designed for 1Thus, for text attribute transfer (a.k.a., text style transfer), there is no direct supervision data, i.e., (original text, attribute, target text) triples. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
attribute-conditional generation could also be applied to debias text attribute transfer that has been formulated with distinct training objectives.
This paper studies controllable text generation from a principled causal perspective, that of-fers a unifying formulation of the two central tasks, and enables mitigation of spurious correla-tions with well-established causality techniques.
A growing number of recent work has used causality with machine learning [62] for disen-tangled representation [54, 78], model explana-tion [6, 13], and robust prediction [61, 24, 83].
Yet most approaches have focused on the vi-sion domain, taking advantage of image spatial structures, and thus are not directly applicable to text with abstract attributes (such as sentiment).
Though previous research on text modeling has also studied related concepts such as counterfac-tuals, it either handles only correlation instead of causation [58, 39, 76, 23, 86, 46], or focuses on different applications such as data augmenta-tion [85, 28, 82] and classiﬁcation [13, 29]. We discuss more related work in §4.
Figure 1: The causal ladder [56] and the formulations of controllable generation tasks corresponding to different rungs of the ladder.
We develop the ﬁrst uniﬁed causal framework for text generation under control. In particular, we devise a structural causal model (SCM) [56] that describes the causal relationships between different variables, where the text x is outcome and the attribute a to control (e.g., sentiment) is treatment. The SCM further accounts for spurious correlations with confounders (e.g., category) with latent variables. The resulting SCM enables us to formulate the two control tasks as performing causal inference at different rungs of the causal ladder
[56] (Figure 1), respectively. Speciﬁcally, (1) for attribute-conditional generation, we go beyond the association-based conditional p(x|a) and propose to instead use p(x|do(a)), corresponding to the intervention rung. The do-operation effectively eliminates the effect of confounders on the control, leading to unbiased text outputs; (2) for text attribute transfer, the task naturally maps to counterfactual prediction on the SCM, which answers the question “what the text would have been if the attribute had been different” through the standard causal inference procedure [56, 55]. The unifying perspective also allows us to draw from existing successful techniques and train the SCM for accurate control and confounder balancing [27, 41, 22].
Previous causal work typically assumes access to confounding labels or relevant proxy information for the entire observed data [43, 44, 48]. In many real applications, however, it is prohibitively expensive or impossible to measure all the confounding factors for unbiased training. For example, it is often not affordable to annotate massively the confounding labels for the entire (attribute, text) corpus. We thus consider a more practical yet challenging scenario where we observe confounding information for only a small subset (e.g., 1% − 5%) of samples [15]. We experiment on difﬁcult datasets where the target attributes and confounding factors have strong correlations. Results show the causal approach substantially improves over conventional conditional models with enhanced control accuracy and reduced bias, on both attribute-conditional generation and attribute transfer. 2