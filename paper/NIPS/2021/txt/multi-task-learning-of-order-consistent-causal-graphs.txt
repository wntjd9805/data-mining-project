Abstract
We consider the problem of discovering K related Gaussian directed acyclic graphs (DAGs), where the involved graph structures share a consistent causal order and sparse unions of supports. Under the multi-task learning setting, we propose a l1/l2-regularized maximum likelihood estimator (MLE) for learning K linear structural equation models. We theoretically show that the joint estimator, by leveraging data across related tasks, can achieve a better sample complexity for recovering the causal order (or topological order) than separate estimations. Moreover, the joint estimator is able to recover non-identiﬁable DAGs, by estimating them together with some identiﬁable DAGs. Lastly, our analysis also shows the consistency of union support recovery of the structures. To allow practical implementation, we design a continuous optimization problem whose optimizer is the same as the joint estimator and can be approximated efﬁciently by an iterative algorithm. We validate the theoretical analysis and the effectiveness of the joint estimator in experiments. 1

Introduction
Estimating causal effects among a set of random variables is of fundamental importance in many disciplines such as genomics, epidemiology, health care and ﬁnance [1, 2, 3, 4, 5, 6]. Therefore, designing and understanding methods for causal discovery is of great interests in machine learning.
Causal discovery from ﬁnite observable data is often formulated as a directed acyclic graph (DAG) estimation problem in graphical models. A major class of DAG estimation methods are score-based, which search over the space of all DAGs for the best scoring one. However, DAG estimation remains a very challenging problem from both the computational and statistical aspects [7]. On the one hand, the number of possible DAG structures grows super-exponentially in the number of random variables, whereas the number of observational sample size is normally small. On the other hand, some DAGs are non-identiﬁable from observational data even with inﬁnitely many samples.
Fortunately, very often multiple related DAG structures need to be estimated from data, which allows us to leverage their similarity to improve the estimator. For instance, in bioinformatics, gene expression levels are often measured over patients with different subtypes [8, 9] or under various experimental conditions [10]. In neuroinformatics, fMRI signals are often recorded for multiple subjects for studying the brain connectivity network [11, 12]. In these scenarios, multiple datasets will be collected, and their associated DAGs are likely to share similar characteristics. Intuitively, it may be beneﬁcial to estimate these DAGs jointly.
∗Work done partially during the visit at MBZUAI (Mohamed bin Zayed University of Artiﬁcial Intelligence) 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
In this paper, we focus on the analysis of the multi-task DAG estimation problem where the DAG structures can be related by a consistent causal order and a (partially) shared sparsity pattern, but allowed to have different connection strengths and edges, and differently distributed variables. In this setting, we propose a joint estimator for recovering multiple DAGs based on a group norm regularization. We prove that the joint l1/l2-penalized maximum likelihood estimator (MLE) can recover the causal order better than individual estimators.
Intuitively, it is not surprising that joint estimation is beneﬁcial. However, our results provide a quantitative characterization on the improvement in sample complexity and the conditions under which such improvement can hold. We show that:
• For identiﬁable DAGs, if the shared sparsity pattern (union support) size s is of order O(1) in K where K is the number of tasks (DAGs), then the effective sample size for order recovery will be nK where n is the sample size in each problem. Furthermore, as long as s is of order o(
K) in K, the joint estimator with group norm regularization leads to an improvement in sample complexity.
• A non-identiﬁable DAG cannot be distinguished by single-task estimators even with indeﬁnitely many observational data. However, non-identiﬁable DAGs can be recovered by our joint estimator if they are estimated together with other identiﬁable DAGs.
√
Apart from the theoretical guarantee, we design an efﬁcient algorithm for approximating the joint estimator through a formulation of the combinatorial search problem to a continuous programming.
This continuous formulation contains a novel design of a learnable masking matrix, which plays an important role in ensuring the acyclicity and shared order for estimations in all tasks. An interesting aspect of our design is that we can learn the masking matrix by differentiable search over a continuous space, but the optimum must be contained in a discrete space of cardinality p! (reads p factorial, where p is the number of random variables).
We conduct a set of synthetic experiments to demonstrates the effectiveness of the algorithm and validates the theoretical results. Furthermore, we apply our algorithm to more realistic single-cell expression RNA sequencing data generated by SERGIO [13] based on real gene regulatory networks.
The remainder of the paper is organized as follows. In Section 2, we introduce the linear structural equation model (SEM) interpretation of Gaussian DAGs and its properties. Section 3 is devoted to the statement of our main results, with some discussion on their consequences and implications. In Sec-tion 4, we present the efﬁcient algorithm for approximating the joint estimator. Section 5 summarizes related theoretical and practical works. Experimental validations are provided in Section 6. 2