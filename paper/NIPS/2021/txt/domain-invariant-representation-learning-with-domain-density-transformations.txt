Abstract
Domain generalization refers to the problem where we aim to train a model on data from a set of source domains so that the model can generalize to unseen target domains. Naively training a model on the aggregate set of data (pooled from all source domains) has been shown to perform suboptimally, since the information learned by that model might be domain-speciﬁc and generalize imperfectly to target domains. To tackle this problem, a predominant domain generalization approach is to learn some domain-invariant information for the prediction task, aiming at a good generalization across domains. In this paper, we propose a theoretically grounded method to learn a domain-invariant representation by enforcing the representation network to be invariant under all transformation functions among domains. We next introduce the use of generative adversarial networks to learn such domain transformations in a possible implementation of our method in practice.
We demonstrate the effectiveness of our method on several widely used datasets for the domain generalization problem, on all of which we achieve competitive results with state-of-the-art models. 1

Introduction
Domain generalization refers to the machine learning scenario where the model is trained on multiple source domains so that it is expected to generalize well to unseen target domains. The key difference between domain generalization [25, 37, 18] and domain adaptation [49, 48, 14, 45] is that, in domain generalization, the learner does not have access to data of the target domain, making the problem much more challenging. One of the most common domain generalization approaches is to learn an invariant representation across domains, aiming at a good generalization performance on target domains. For instance, in the representation learning framework, the prediction function y = f (x), where x is data and y is a label, is obtained as a composition y = h ◦ g(x) of a deep representation network z = g(x), where z is a learned representation of data x, and a smaller classiﬁer y = h(z), predicting label y given representation z, both of which are shared across domains. With this framework, we can aim to learn an “invariant” representation z across the source domains with the “hope” of a better generalization to the target domain.
Most existing “domain-invariance”-based methods in domain generalization focus on the marginal distribution alignment [37, 1, 44, 43, 32], which are still prone to distributional shifts when the conditional data distribution is not stable. In particular, the marginal alignment refers to making the 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
Figure 1: An example of two domains. For each domain, x is uniformly distributed on the outer circle (radius 2 for domain 1 and radius 3 for domain 2), with the color indicating class label y. After the transformation z = x/||x||2, the marginal of z is aligned (uniformly distributed on the unit circle for both domains), but the conditional p(y|z) is not aligned. Thus, using this representation for predicting y would not generalize well across domains. representation distribution p(z) to be the same across domains. This is essential since if p(z) for the target domain is different from that of source domains, the classiﬁcation network h(z) would face out-of-distribution data at test time. Conditional alignment refers to aligning the conditional distribution of the label given the representation p(y|z) to expect that the classiﬁcation network (trained on the source domains) would give accurate predictions at test time. The formal deﬁnitions of these two types of alignment are discussed in Section 3.
In Figure 1 we illustrate an example where the representation z satisﬁes the marginal alignment but not the conditional alignment. Speciﬁcally, x is distributed uniformly on the circle with radius 2 (and centered at the origin) for domain 1 and distributed uniformly on the circle with radius 3 (centered at the origin) for domain 2. The representation z deﬁned by the mapping z = g(x) = x/||x||2 will align the marginal distribution p(z), i.e., z is now distributed uniformly on the unit circle for both domains. However, the conditional distribution p(y|z) is not aligned between the two domains (y is represented by color), which means using this representation for classiﬁcation is suboptimal, and in this extreme case would lead to 0% accuracy in the target domain 2. This is an extreme case of misalignment but it does illustrate the importance of the conditional alignment. Therefore, we need to align both the marginal and the conditional distributions for a domain-invariant representation.
Recently, there have been several attempts [33, 34, 50] to align the joint distribution of the repre-sentation and the label p(y, z) in a domain generalization problem by aligning the distribution of z across domains for each class, i.e., p(z|y) (given that the label distribution p(y) is unchanged across domains). However, the key drawbacks of these methods are that they either do not scale well with the number of classes or have limited performance in real-world computer vision datasets (see Section 5).
In this paper, we focus on learning a domain-invariant representation that aligns both the marginal and the conditional distributions in domain generalization problems. We present theoretical results re-garding the necessary and sufﬁcient conditions for the existence of a domain-invariant representation; and subsequently propose a method to learn such representations by enforcing the invariance of the representation network under domain density transformation functions. A simple intuition for our approach is that if we enforce the representation to be invariant under the transformations among the source domains, the representation will become more robust under other domain transformations.
Furthermore, we introduce an implementation of our method in practice, in which the domain transformation functions are learned through the training process of generative adversarial networks (GANs) [20, 12]. We conduct extensive experiments on several widely used datasets and observe a signiﬁcant improvement over relevant baselines. We also compare our methods against other state-of-the-art models and show that our method achieves competitive results.
Our contribution in this work is threefold:
• We revisit the domain invariant representation learning problem and shed some light by providing several observations: a necessary and sufﬁcient condition for the existence of a 2
domain-invariant representation and a connection between domain-independent representa-tion and a marginally-aligned representation.
• We propose a theoretically grounded method for learning a domain-invariant representation based on domain density transformation functions. We also demonstrate that we can learn the domain transformation functions by GANs in order to implement our approach in practice.
• We empirically show the effectiveness of our method by performing experiments on widely used domain generalization datasets (e.g., Rotated MNIST, VLCS and PACS) and compare our method with relevant baselines (especially CIDG [33], CIDDG [34] and DGER [50]). 2