Abstract
Most existing methods for conditional average treatment effect estimation are designed to estimate the effect of a single cause — only one variable can be intervened on at one time. However, many applications involve simultaneous intervention on multiple variables, which leads to multi-cause treatment effect problems. The multi-cause problem is challenging because one needs to overcome the confounding bias for a large number of treatment groups, each with a different cause combination. The combinatorial nature of the problem also leads to severe data scarcity — we only observe one factual outcome out of many potential out-comes. In this work, we propose Single-cause Perturbation (SCP), a novel two-step procedure to estimate the multi-cause treatment effect. SCP starts by augmenting the observational dataset with the estimated potential outcomes under single-cause interventions. It then performs covariate adjustment on the augmented dataset to obtain the estimator. SCP is agnostic to the exact choice of algorithm in either step.
We show formally that the procedure is valid under standard assumptions in causal inference. We demonstrate the performance gain of SCP on extensive synthetic and semi-synthetic experiments. 1

Introduction
Estimating treatment effects from observational data is a central problem in causal inference and has many applications such as precision medicine [11]. In this work, we focus on estimating conditional average treatment effects (CATE) to reﬂect the heterogeneity within a population [1]. The vast majority of the CATE estimation methods consider the single-cause setting, where only one variable can be intervened on, e.g. the decision to give (or not to give) a particular drug. However, in many applications it is necessary to intervene on multiple variables simultaneously to achieve the desired outcome (the multi-cause setting). For example, multiple drugs are needed to treat patients with comorbid chronic diseases or systemic diseases such as cancer [21]. However, ﬁnding the best drug combination for each patient is very challenging and the current clinical practice is clearly sub-optimal [30]; studies have shown that nearly 50% of the elderly population in developed countries take one or more drugs that are not medically necessary [39]. Similar examples are abundant in the medical literature and beyond (Appendix A.5), which calls for a new methodology to estimate the combined effect of multiple causes (drugs), a challenge we undertake in this work.
We make a distinction between the terminology cause and treatment. We refer to a cause as an atomic variable that can be intervened on, and a treatment as a conﬁguration of all causes. Therefore, if the problem involves K causes and each cause is a binary variable, there will be 2K possible treatments.
The key objective of causal inference is to overcome the confounding bias in treatment assignment.
This is challenging in the multi-cause setting because a large number of treatment groups need to be 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
Figure 1: (A) Illustration of the data scarcity challenge. A1: K = 3 causes and A2: the single-cause setting.
Each row contains one observation. Three green cells in each row will be ﬁlled in by SCP’s ﬁrst step to form the augmented dataset. (B) Interventions on an illustrative DAG. B1: observational data (no intervention), B2: intervening on both causes, B3: intervening on A1 only. In B3, the intervention on A1 generates an effect on the outcome and the cause A2. The covariate X is greyed out for visual clarity. balanced. (In contrast, one only needs to balance two treatment groups in the single-cause setting.)
Furthermore, the combinatorial treatment also leads to data scarcity — we can only observe the outcome under the treatment that was given (factual outcome), but not the potential outcomes (PO) under all other treatments (2K − 1 in total, as illustrated in Figure 1 A). As the number of causes increases, the fraction of observed outcomes decreases exponentially, which challenges the reliable estimation of CATE.
In fact, many
Most single-cause methods consider only two treatments (treated or untreated). popular architectures and regularization methods aimed to overcome confounding do not scale computationally to large treatment spaces [57, 73, 58, 38]. As a remedy, one may make additional assumptions on the data generating process (DGP), for instance, assuming a linear model generates the outcome [29] or a low-dimensional latent variable generates the treatment [75]. However, such assumptions may limit the scope of application.
In this work, we take a different direction: instead of making additional assumptions on the functional form or latent variable structure, we exploit the connection between a single-cause intervention and a multi-cause intervention (Figure 1 B1-3). We establish that, under standard assumptions in causal inference, the single and multi-cause potential outcomes are equal in expectation under appropriate conditioning.
Based on this ﬁnding, we propose single-cause perturbation (SCP), a novel two-step procedure to estimate CATE in the multi-cause setting. In the ﬁrst step, SCP generates K additional datasets by predicting the potential outcomes resulting from perturbing each of the K causes to their opposite value. It then performs covariate adjustment on the combined dataset. By deliberately perturbing the causes, the treatment assignment in the augmented dataset would be more balanced than the observational data, thereby reducing the confounding bias. SCP is agnostic to the exact choice of algorithm in either step and the user can choose the algorithms based on the application.
Contributions. We present SCP, a two-step multi-cause CATE estimator that leverages the connection between single and multi-cause interventions. SCP overcomes confounding bias by using single-cause
CATE estimators to augment the observational data with the estimated potential outcomes. Compared with existing works, SCP does not make assumptions about the distributional or functional form of the DGP, making it suitable for complex problems in healthcare. We demonstrate and analyze the performance gain of SCP via extensive experiments. 2 Problem formulation and notations
In this work, we focus on the CATE estimation problem with K binary causes.1 Let the causes
A = (A1, . . . , AK) be a multi-dimensional random variable with sample space Ω = {0, 1}K, where
Ak is the kth cause. Let A−k ∈ Ω−k = {0, 1}K−1 be the collection of all but the kth cause. Let
X ∈ RD and Y ∈ R be the covariates and observed outcomes respectively. The causal relationship 1SCP also applies to multi-level categorical causes, i.e. Ak ∈ {0, 1, . . . , L}, L ∈ N+ and multi-dimensional outcomes, i.e. Y ∈ RM . Here, we use the current setting for illustration. 2
Figure 2: Illustrative causal graphs. (A) Intervention on all causes A. (B) Intervention on the single cause Ak.
The other causes are partitioned into descendants A↓
−k. Purple edges: confounding to treatment assignment. Brown edges: effects on the (combined) outcomes. Some less important edges are greyed out for visual clarity.
−k and non-descendants A↑ between these variables is illustrated in Figure 2 A, which is a direct generalization of the single cause setting [56]. We have access to an observational dataset D0 = {xi, yi, ai}i∈[N0] with N0 independent samples from the random variables deﬁned above. Throughout the text we use capital letters for random variables and lower case letters for ﬁxed constants. We use boldface for vectors or multi-dimensional random variables. When the context is clear, we will simplify the conditional expressions, e.g. P(Y |X) := P(Y |X = x). 2.1 Multi-cause intervention
We formulate the CATE estimation problem using the potential outcome (PO) framework [56].2
Let Y (a) ∈ R denote the potential outcome in a world where the treatment a ∈ Ω was given. We would like to estimate the CATE between any two treatments given the covariates i.e. τ (a, a(cid:48), x) =
E[Y (a) − Y (a(cid:48))|X = x], ∀a, a(cid:48) ∈ Ω, x ∈ RD. We can estimate CATE by estimating all potential outcomes E[Y (a)|X], ∀a ∈ Ω.
The following three assumptions have been proposed to identify the multi-cause PO [56, 24]. (1)
Consistency : ∀a ∈ Ω if A = a, Y (a) = Y . (2) Weak unconfoundedness: Y (a) ⊥⊥ A | X, ∀a ∈ Ω. (3) Overlap: P(A = a|X) > 0, ∀a ∈ Ω, if P(X) > 0. The assumptions stated above allow the expectation of multi-cause PO to be estimated from observational data: ∀a ∈ Ω, ∀x ∈ RD:
E[Y (a)|X = x] = E[Y |X = x, A = a] (1) 2.2 Single-cause intervention
Here we consider the intervention on a single-cause, e.g. adding a new drug A1 to the existing medications. Such intervention may affect the outcome and the other causes. For example, the inclusion of drug A1 may promote the usage of another drug A2 because A2 can mitigate the side effects of A1 [48].
We denote Y (ak) ∈ R as the potential outcome where the cause Ak is set to be ak. We refer to Y (ak) as the single-cause PO. Note that the single-cause PO Y (ak) is different from the multi-cause PO
Y (a) because the latter refers to a potential world where all causes are intervened on. We sometimes denote the multi-cause PO as Y (a) := Y (ak, a−k).
We assume that, based on domain knowledge, we can partition the rest of the causes A−k into
Ak’s causal descendants A↓
−k as illustrated in Figure 2 B [45]. We denote A−k(ak), A↓
−k(ak) and A↑
−k(ak) as their potential outcomes respectively. By deﬁnition, the non-descendants should be unaffected by the intervention:
−k and its non-descendants A↑
A↑
−k(0) = A↑
−k(1) = A↑
−k. (2)
As shown in Figure 2 B, it is convenient to aggregate all the variables affected by Ak into a combined outcome Y(cid:48) k, and aggregate all the variables confounding Ak as a combined confounder X(cid:48) k:
Y(cid:48) k := (Y, A↓
−k); Y(cid:48) k(ak) := (Y (ak), A↓
−k(ak)); X(cid:48) k := (X, A↑
−k) (3) 2In Appendix A.4, we present an alternative formalism using do-operation [46]. We show that the same SCP algorithm can be derived using either formalism. 3
Table 1: Summary of the data augmentation task in SCP’s ﬁrst step.
Equation
Eq. 2
Eq. 4
Eq. 4
A↑
A↓
Target
−k(a(cid:48) k)
−k(a(cid:48) k)
Y (a(cid:48) k)
Input Covariates
-X(cid:48) k k, A↓
−k
X(cid:48)
Estimated Value a↑ k) = a↑
−k(a(cid:48) k) ∼ P(A↓ a↓
−k(a(cid:48) k) = E(Y |X(cid:48) y(a(cid:48)
−k|X(cid:48) k, A↓
−k k, Ak)
−k, Ak)
Algorithm
-DR-CFR
DR-CFR k(ak), we make the standard assumptions using Ak, Y(cid:48) k, and X(cid:48)
To identify the combined PO Y(cid:48) k: (4) Single-cause Consistency : ∀k ≤ K, ∀a ∈ {0, 1} if Ak = ak, Y(cid:48) k. (5) Single-cause
Unconfoundedness: Y(cid:48) k, ∀ak ∈ {0, 1}, ∀k ≤ K. The multi-cause overlap (Section 2.1) implies single-cause overlap, but the multi-cause consistency and unconfoundedness do not imply the single-cause counterparts (Appendix A.3). Appendix A.1 Proposition 2 shows that, under these assumptions, we can identify Y(cid:48) k(ak) from observational data as: ∀k ≤ K, ∀ak ∈ {0, 1}, k(ak) ⊥⊥ Ak | X(cid:48) k(ak) = Y(cid:48)
P(Y(cid:48) k(ak)|X(cid:48) k) = P(A↓
−k|X(cid:48) k, Ak = ak) · P(Y |X(cid:48) k, A↓
−k, Ak = ak). (4)
Discussion on partitioning the causes. We can always partition the causes into descendants and non-decadents as long as the structure between the causes follows a DAG (hence no cycles). In practice, such structural knowledge is often available, e.g. we can use the clinical guidelines to identify the drugs whose prescription will be inﬂuenced by the usage of another drug. Note that we do not need to specify the causal graph of all individual variables (e.g. the link between two covariates Xi, Xj). However, when the full causal graph is available, we can adapt SCP to make use of the additional structural knowledge as discussed in Appendix A.6. On the other hand, we show empirically that SCP is not sensitive to misspeciﬁed partitioning (Section 5.1). Appendix A.3 contains an extended discussion on all our assumptions. 3 Single Cause Perturbation 3.1 The algorithm
In this section, we introduce our proposed method – single cause perturbation (SCP). Given an observational dataset D0 with N0 data points: D0 = {xi, yi, ai}i∈[N0], SCP proceeds in two steps: it ﬁrst ﬁts a set of models that can predict the effects of changing a single cause, and uses them to create K additional data sets Dk = {xi, ˜yk i=1, for k ∈ [K], each corresponding to the potential scenario of perturbing a single cause. It then ﬁts a ﬁnal model on this enlarged dataset, which is used to estimate the multi-cause CATE. The pseudocode is detailed in Appendix A.7 Algorithm 1. i }N0 i , ˜ak
Training single-cause models. Based on Equation 4, we will train two separate models to estimate the combined PO Y(cid:48)
−k(ak) and one for Y (ak). Note that for CATE estimation, we only need to estimate the expectation E(Y |X(cid:48)
−k, Ak) rather than the full probability distribution.
The models are trained on the observational data D0. We can use any single-cause CATE estimator for this purpose since only one cause is intervened on. k(ak): one for A↓ k, A↓
We choose to use the state of the art single-cause CATE estimator, Disentangled Representations for
Counterfactual Regression algorithm (DR-CFR) [22]. DR-CFR achieves higher estimation accuracy by learning to distinguish between true confounders, adjustment variables and instruments contained in X(cid:48) k. We provide a self-contained description of DR-CFR in Appendix A.8. k)|X(cid:48)
Data augmentation. As illustrated in Table 1, once the single-cause models are ﬁtted, sampling perturbed data points from observations (x, y, a) ∈ D0 involves three steps: (1) obtain a↑
−k(a(cid:48) k) directly from the observations, (2) sample a↓ k), and (3) obtain y(a(cid:48)
−k(a(cid:48) k) :=
E(Y (a(cid:48) k = 1 − ak corresponds to perturbing the cause Ak (recall that ak ∈ {0, 1}). Note that in step two we sample the new causes a↓
−k(a(cid:48) k) from the distribution in order to keep them as binary variables. To generate a new data point (x, ˜yk, ˜ak), we deﬁne ˜yk := y(a(cid:48) k) i , ˜ak and ˜ak := (a(cid:48) i=1 as the perturbed data for Ak. We combine all perturbed datasets Dk, k ∈ [K] and the original dataset D0 to create the augmented training data k)). Denote Dk = {xi, ˜yk k)). Here a(cid:48) k) ∼ P(A↓ k, A−k(a(cid:48) k, a−k(a(cid:48)
−k(a(cid:48) k)|X(cid:48) i }N0 4
DT r = {Dk}k∈[0,K]. For each unique x, DT r contains K + 1 different treatments a, ˜ak, . . . , ˜aK and their corresponding outcomes.
Covariate adjustment on augmented data. We can estimate CATE by learning the conditional expectation in Equation 1 using the augmented data DT r. We use a standard feed-forward neural network, fθ : RD × Ω → R with trainable weights θ. 3.2 Validity of SCP: linking single and multi-cause PO
One may wonder why the augmented data points (single-cause POs) would help estimate the multi-intervention on a single cause versus cause PO: they correspond to different interventions, i.e. intervention on all causes simultaneously. Proposition 1 shows that given our assumptions the single and multi-cause POs are equal in expectation under appropriate conditioning – therefore, (imputed) single cause POs can be used for multi-cause estimation. The proof is shown in A.1.
Proposition 1 (Equivalence of the single and multi-cause PO’s conditional expectation). Under the sequential ignorability assumption [53], ∀k ≤ K,
E(Y (ak, a−k)|X) = E(Y (ak)|X, A−k(ak) = a−k). (5)
Note that the Y (ak) and A−k(ak) on the right hand side (RHS) is precisely what we estimated and added to the augmented dataset Dk in the ﬁrst step. Thus if we train a supervised learning model on Dk to estimate the RHS, the trained model can also estimate the multi-cause PO on the
LHS. Moreover, since the relationship in Equation 5 holds for all k, we can pool all the augmented datasets into one training dataset DT r, which is K + 1 times the size of the observational data i.e.
|DT r| = (K + 1)|D0|. The increased sample size mitigates the data scarcity issue and allows the estimator to generalize better.
Proposition 1 also highlights the necessity of estimating A−k(ak) in addition to Y (ak) in the ﬁrst step. This is because Equation 5 is conditioned on A−k(ak) rather than the observed cause A−k.
Note that A−k(ak) = A−k, ∀ak ∈ {0, 1} only when Ak has no descendants. 3.3 SCP creates a more balanced dataset via data augmentation
In addition to increased sample size, there is also a less obvious (but equally important) reason why SCP would achieve performance gain: the augmented data tend to be more balanced than the observational data. This is because SCP perturbs every single cause of all the observations. For instance, by combining D0 and D1, the empirical distribution ˆP(A1|X = xi) = 0.5, ∀xi ∈ D0.
Balancing is important because prior research has shown that CATE estimators trained on a balanced dataset tend to generalize better [57]. In fact, many existing causal inference methods employ balancing techniques to improve performance (see Section 4). In Section 5.1, we demonstrate experimentally that SCP consistently improves the balancing of the observational dataset. 3.4 Trade off between sample size, balancing, and ﬁrst step error
SCP’s data augmentation increases sample size and improves balancing, both of which are beneﬁcial to CATE estimation. However, there is a caveat: the augmented dataset will also carry the ﬁnite-sample estimation error made in the ﬁrst step. There is a risk that this additional source of noise will reduce or even cancel out the beneﬁts of data augmentation.
In the simulation study in Section 5.1 we investigate this empirically, and observe that SCP’s actual error in the ﬁrst step is usually much smaller than the error required to offset the beneﬁts of data augmentation. We conjecture that this is because SCP only perturbs one cause at a time. The effect of such a localized perturbation can be efﬁciently estimated by the existing methods tailored for the single-cause setting.
One can envision an alternative way where we bundle together any two (or even more) causes Aj and
Ak and perturb both of them simultaneously. This will further increase the sample size and improve the balancing, but the ﬁrst step error will also increase because the effect of a joint perturbation is harder to estimate. After all, if we were able to do this well, there is no need for data augmentation in the ﬁrst place. 5
Table 2: Comparison with the related works. The ATE methods are listed for completeness.
Method
Ref
Estimand
Balancing method
Sample size
SCP
Cov. Adjustment
VSR
Deconfounder
Weighting
Matching
G computation
This work
[32]
[75]
[72]
[34]
[37]
[54]
CATE
CATE
CATE
CATE
ATE
ATE
ATE
Data augmentation
None
Weighting
None
Weighting
Matching
Marginalization
↑↑
=
=
=
=
↓↓
NA
E(Y(cid:48) k)|X(cid:48))
Intermediate estimand k(a(cid:48)
P(Y|X, A)
P(A|Z), P(Z|X)
P(Y|Z, A)
P(A|X)
P(A|X)
P(Y|X, A)
A complete theoretical analysis of the trade off is challenging because all three interacting factors contribute to the overall estimation error. Moreover, an important feature of SCP is that it does not make any assumption about the DGP (functional form or error distribution). However, such assumptions are usually necessary to establish statistical efﬁciency bounds [44]. For these reasons, we will defer the theoretical analysis of the trade off to future works. 4