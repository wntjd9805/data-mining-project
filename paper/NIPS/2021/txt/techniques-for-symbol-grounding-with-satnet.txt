Abstract
Many experts argue that the future of artiﬁcial intelligence is limited by the ﬁeld’s ability to integrate symbolic logical reasoning into deep learning architectures. The recently proposed differentiable MAXSAT solver, SATNet, was a breakthrough in its capacity to integrate with a traditional neural network and solve visual reasoning problems. For instance, it can learn the rules of Sudoku purely from image examples. Despite its success, SATNet was shown to succumb to a key challenge in neurosymbolic systems known as the Symbol Grounding Problem: the inability to map visual inputs to symbolic variables without explicit supervision (“label leakage”). In this work, we present a self-supervised pre-training pipeline that enables SATNet to overcome this limitation, thus broadening the class of problems that SATNet architectures can solve to include datasets where no intermediary labels are available at all. We demonstrate that our method allows SATNet to attain full accuracy even with a harder problem setup that prevents any label leakage. We additionally introduce a proofreading method that further improves the performance of SATNet architectures, beating the state-of-the-art on Visual Sudoku. 1

Introduction
Recent years have seen signiﬁcant advancements in deep learning, providing breakthroughs in image, video, and audio processing [1]. Despite its success, deep learning has many known limitations, such as low interpretability, vulnerability to adversarial attacks, and difﬁculty in solving problems requiring hard logical constraints [2–5]. To overcome these limitations, experts have described the need to migrate from purely deep learning-based systems to neurosymbolic artiﬁcial intelligence systems, which integrate neural networks with logical reasoning [6]. In this work we focus on improving a promising development in this ﬁeld: the award-winning architecture known as SATNet [7].
SATNet is a differentiable MAXSAT solver based on a low-rank semideﬁnite relaxation approach.
It can be integrated into traditional Deep Neural Networks (DNNs) to solve composite learning problems that require both logical reasoning and visual understanding. One such problem is Visual
Sudoku, where the model must learn the rules of a Sudoku puzzle purely from visual examples. When trained end-to-end, SATNet is able to achieve 63.2% total board accuracy in this task while traditional
DNN architectures are unable to exceed 0% [7]. This was regarded as a signiﬁcant breakthrough for neurosymbolic architectures. However, it was recently noted that SATNet training relies upon
“leakage” of labels through the logical constraint layer to the DNN used to classify digits [8].
This leakage essentially means that SATNet is learning in two supervised stages, where it ﬁrst trains its digit classiﬁcation component under direct supervision, and only then trains its SAT layer to learn the logical constraints delineating Sudoku. When the leakage is removed, SATNet’s ability to solve Visual Sudoku drops to 0% [8]. This is signiﬁcant, because taken independently, these two sub-problems are signiﬁcantly easier. Digit classiﬁcation is considered a solved problem, and while
SAT constraint mining is more difﬁcult, it could be argued that the differentiable aspect is no longer beneﬁcial if the system needs supervision on its inputs to learn regardless. For instance, there exist other SAT constraint miners that are not differentiable but outperform SATNet [9]. Overall, the issue 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
of being unable to learn to solve composite visual reasoning problems end-to-end is referred to as the Symbol Grounding Problem, and is considered one of the fundamental prerequisites for artiﬁcial intelligence to perform practical logical reasoning [8, 10].
Figure 1: The SATNet architecture used to solve Visual Sudoku. The red line shows the label leakage issue, which when removed, results in the Symbol Grounding Problem.
We observe a key challenge of symbol grounding is the large gap between the compositional nature of logical reasoning and the end-to-end gradient-based nature of neural networks. The former helps to reduce a sophisticated reasoning system into simple, independent modules, each of which can be designed manually or learned, while the latter encourages fusing all components together and using gradients as a universal means for learning. Many recent approaches aim to bridge this gap by relaxing logical constraint solving through numerical optimisations [11–14]. Although such end-to-end gradient-based optimisation is appealing, it can fail to address seemingly simple tasks like Visual
Sudoku. The success of SATNet is in fact due to inadvertent supervision of intermediate modules. We argue that compositionality does not have to be the opposite of the end-to-end learning design. The latter is particularly preferable because it eliminates the need for supervision of intermediate modules, which is often required by a compositional design. If compositionality can be trained using self-supervision (i.e. without manual effort), compositionality would then be at least equally preferable.
This is the approach that we take in the present work, synergistically combining compositionality with end-to-end learning without any explicit intermediate supervision. We envision our methodology forming a new paradigm for tackling neurosymbolic learning.
We describe a self-supervised pre-training method that can be used to bootstrap SATNet in order to overcome the Symbol Grounding Problem. Our methodology enables us to tackle a class of what we call Ungrounded MAXSAT problems, where label data are available only for the output variables of the MAXSAT problem. In the Visual Sudoku case, this formulation manifests itself as a dataset where, as before, inputs consist of images of digits describing the input cells of a Sudoku board. The labels of the dataset, however, consist of numerical representations only for the board cells that were not given as inputs. This means that there is no way of identifying what digit each input image refers to except by learning the rules of the Sudoku puzzle in parallel to predict the non-input values. We refer to this problem as Ungrounded Visual Sudoku. We show that our method improves the state of the art on this problem from 0% to 64.8%, achieving similar performance on Ungrounded Visual
Sudoku as SATNet with label leakage does in the grounded version of the same problem. In short, our main contributions are the following: 1. We describe a self-supervised clustering and distillation process for training a visual classiﬁer within a SATNet architecture. 2. We introduce a Symbol Grounding Loss that makes it possible to train logical constraint layers on an ungrounded symbol representation. 3. We show empirically that our methodology allows SATNet to achieve full performance on ungrounded Visual Sudoku (where label leakage is impossible), a task where previous state-of-the-art was 0%. 4. We introduce a Proofreader that improves the performance of any SATNet system (grounded or ungrounded), achieving state-of-the-art performance on Visual Sudoku. 2
2