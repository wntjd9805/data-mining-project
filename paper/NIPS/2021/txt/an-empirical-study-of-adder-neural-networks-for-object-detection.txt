Abstract
Adder neural networks (AdderNets) have shown impressive performance on image classiﬁcation with only addition operations, which are more energy efﬁcient than traditional convolutional neural networks built with multiplications. Compared with classiﬁcation, there is a strong demand on reducing the energy consumption of modern object detectors via AdderNets for real-world applications such as autonomous driving and face detection. In this paper, we present an empirical study of AdderNets for object detection. We ﬁrst reveal that the batch normalization statistics in the pre-trained adder backbone should not be frozen, since the relatively large feature variance of AdderNets. Moreover, we insert more shortcut connections in the neck part and design a new feature fusion architecture for avoiding the sparse features of adder layers. We present extensive ablation studies to explore several design choices of adder detectors. Comparisons with state-of-the-arts are conducted on COCO and PASCAL VOC benchmarks. Speciﬁcally, the proposed Adder FCOS achieves a 37.8% AP on the COCO val set, demonstrating comparable performance to that of the convolutional counterpart with an about 1.4× energy reduction. 1

Introduction
Object detection is a foundational problem in computer vision and has attracted tremendous interests from both academic and industrial communities for decades [21]. It has a wide range of applications for various areas, e.g., video surveillance, autonomous driving and robotic vision. Deep neural networks have indeed dominated the research of object detection in recent years since the pioneering work of R-CNN [12]. The performance of object detectors has been considerably improved by various designs of architecture, loss function etc. However, most modern accurate object detectors require massive computation, making them quite challenging in resource-constraint applications, e.g., mobile phones and embedded devices.
Various approaches have been proposed to compress and accelerate convolutional neural networks (CNNs) for classiﬁcation tasks, including channel pruning [24, 14, 26, 38], low-bit quantization [50, 25] and lightweight network design [33, 27]. These methods reduce the number of parameters or inference latency while maintaining the accuracy to the maximum extent. Such model compression methods have also been explored in a variety of down-stream tasks, such as semantic segmentation [7] and image super resolution [44] etc.
There have been a few methods aiming at fast and efﬁcient object detectors. One family of solutions is using new architecture design [23, 31, 29, 41]. For example, YOLO series [30, 31] have achieved good trade-off between running speed and accuracy via a novel one-stage detection framework.
Another family of solutions is to use common model compression methods for accelerating object
∗Corresponding author. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
detectors, e.g., knowledge distillation [4, 42] and pruning [1]. Moreover, some recent works utilize neural architecture search (NAS) approach for searching better architectures for different components of object detectors [3, 13, 11]. Although these methods mentioned above show strong performance while improving the efﬁciency, they are mainly built with traditional convolutional neural networks, which contain massive inefﬁcient multiplications.
Recently, Chen et al. [5] proposed the adder neural networks (AdderNets) to re-place traditional convolutional ﬁlters with adder ﬁlters. Since addition is more en-ergy efﬁcient than multiplication [36, 47],
AdderNets shed light on the design of efﬁ-cient neural networks and have the poten-tial of much fewer chip areas and less en-ergy consumption. AdderNets have shown impressive performance in large scale im-age classiﬁcation [45] via a kernel-based progressive distillation method, and also successfully been applied for other applica-tions like image super resolution. Song et al. [34] proposed to utilize self shortcuts and learnable power activations to build super resolution networks via adder ﬁlters.
Figure 1: Comparisons of mAP on COCO val2017 and energy costs for different object detectors.
Existing variants of AdderNets mainly deal with either image classiﬁcation [5, 45, 9] or super-resolution tasks [34]. It is not clear yet how will the AdderNets perform for object detection, which often has sophisticated framework design and various objectives. This much more challenging com-puter vision task therefore brings in new challenges and opportunities for the research on AdderNets.
So how to build accurate and efﬁcient object detectors via AdderNets? The straightforward idea is to directly replace the original convolutional ﬁlters by adder ﬁlters. However, this naive adder detector cannot be easily trained as classiﬁcation networks. At ﬁrst, most modern detectors tend to pre-train the backbone on the ImageNet and then ﬁne-tune the whole model on the target dataset, but this straightforward ﬁne-tuning might worsen adder detectors, because of the sensitivity of adder ﬁlter.
Moreover, the performance-proven neural architectures were all developed for convolution based detectors, and whether they are still applicable for the adder detectors is unclear.
In this paper, we propose a series of strategies to reform efﬁcient object detectors with adder ﬁlters.
In contrast with the frozen batch normalization widely exploited during ﬁne-tuning of the detector, we empirically observe an opposite conclusion that adder detectors are better to unlock the statistics of batch normalization in pre-trained adder backbone for a performance improvement. Extensive ablation studies are conducted to explore the properties of batch normalization layers and the impact of batch size. In addition, a new feature fusion network with more residual connections and a better fusion module is explored to compensate for sparse adder features. Experimental results are reported on PASCAL VOC and COCO benchmarks, and the results are carefully analyzed and discussed. In particular, the proposed Adder FCOS achieves a 37.8% mAP on COCO val set, which is comparable with state-of-the-art object detectors, while saving much energy consumption as shown in Figure 1.
In summary, we present an extensive empirical study for how to build object detectors via adder neural networks. We believe that the discussions and analysis in this paper will be beneﬁcial for the research of efﬁcient object detection and adder neural networks. 2