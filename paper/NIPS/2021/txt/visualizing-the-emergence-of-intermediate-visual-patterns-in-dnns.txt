Abstract
This paper proposes a method to visualize the discrimination power of intermediate-layer visual patterns encoded by a DNN. Speciﬁcally, we visualize (1) how the
DNN gradually learns regional visual patterns in each intermediate layer during the training process, and (2) the effects of the DNN using non-discriminative patterns in low layers to construct disciminative patterns in middle/high layers through the forward propagation. Based on our visualization method, we can quantify knowledge points (i.e. the number of discriminative visual patterns) learned by the DNN to evaluate the representation capacity of the DNN. Furthermore, this method also provides new insights into signal-processing behaviors of existing deep-learning techniques, such as adversarial attacks and knowledge distillation. 1

Introduction
Deep neural networks (DNNs) have achieved superior performance in various tasks, but the black-box nature of DNNs makes it difﬁcult for people to understand its internal behavior. Visualization methods are usually considered as the most direct way to understand the DNN. Recently, several attempts have been made to visualize the DNN from different aspects, e.g. illustrating the visual appearance that maximizes the prediction score of a given category [50, 66, 35], inverting intermediate-layer features to network inputs [12], extracting receptive ﬁelds of neural activations [73], estimating saliency/importance/attribution maps [74, 45, 75, 32], visualizing the sample distribution, such as
PCA [38], t-SNE [54], etc.
In spite of above explanations of the DNN, there is still a large gap between visual explanations of the patterns in the DNN and the theoretical analysis of the DNN’s discrimination power. In other words, visualization results usually cannot reﬂect the discrimination power of features in the DNN.
Therefore, instead of simply visualizing the entire sample, we divide intermediate-layer features into feature components, each of which represents a speciﬁc image region. We visualize the discrimination power of these feature components, and we consider discriminative feature components as knowledge points learned by the DNN. Based on above methods, we can diagnose the feature representation of a pre-trained DNN from the following perspectives.
• We visualize the emergence of intermediate visual patterns in a temporal-spatial manner and evaluate their discrimination power. (1) We visualize how the discrimination power of each individual visual
∗Corresponding author. This work was done under the supervison of Dr. Quanshi Zhang. He is with the
John Hopcroft Center and the MoE Key Lab of Artiﬁcial Intelligence, AI Institute, at the Shanghai Jiao Tong
University, China. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
Figure 1: Diagrammatic sketch for the emergence of visual patterns encoded by the DNN in a temporal-spatial manner. The visualization result enables people to analyze the quantity and quality of intermediate features. pattern increases during the learning process. (2) We illustrate effects of using non-discriminative patterns in low layers to gradually construct discriminative patterns in high layers during the forward propagation. As Figure 1 shows, the regional feature of the cat head emerges as a discriminative pattern for the cat category, while wall features are non-discriminative.
• Based on the the visualization result, we can further measure the quantity and quality of intermediate patterns encoded by a DNN. In Figure 1, we count knowledge points encoded in a DNN as regional patterns with strong discrimination power, and further evaluate whether each knowledge point is reliable for classiﬁcation. This provides a new perspective to analyze the DNN.
A distinct contribution of this study is to bridge the empirical visualization and the quantitative analysis of a DNN’s discrimination power. In comparison, Kim et al. [23] used concept activation vectors to model the relationship between visual features and manually annotated semantic concepts.
Cheng et al. [7] quantiﬁed the number of visual concepts encoded by the DNN. However, these two methods cannot reﬂect the discrimination power of regional visual concepts. On the other hand, some researchers derived mathematical bounds on the representational power of a DNN [68, 13] under certain assumptions of the network architecture. To this end, we believe that bridging regional patterns and a DNN’s discrimination power is a more convincing and more intuitive way to reveal the internal behavior of a DNN than mathematical bounds under certain assumptions.
Besides, our method provides insightful understanding towards existing deep-learning techniques, such as adversarial attacks and knowledge distillation. (1) For adversarial attacks, we discover that adversarial attacks mainly affect unreliable regional features in high layers of the DNN. The visualization result also enables us to categorize attacking behaviors of all image regions into four types. (2) For knowledge distillation, we discover that the student DNN usually encodes less reliable knowledge points, compared with the teacher DNN. Although knowledge distillation is able to force the student DNN to mimic features of a speciﬁc layer in the teacher DNN, there is still a big difference of features in other layers between the student DNN and the teacher DNN.
Contributions of this paper can be summarized as follows. (1) We propose a method to visualize the discrimination power of intermediate-layer features in the DNN, and illustrate the emergence of intermediate visual patterns in a temporal-spatial manner. (2) Based on the visualization result, we quantify knowledge points encoded by a DNN. (3) The proposed method also provides new insights into existing deep-learning techniques, such as the adversarial attack and the knowledge distillation. 2