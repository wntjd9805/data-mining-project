Abstract
Hyperspectral imaging offers new perspectives for diverse applications, ranging from the monitoring of the environment using airborne or satellite remote sensing, precision farming, food safety, planetary exploration, or astrophysics. Unfortu-nately, the spectral diversity of information comes at the expense of various sources of degradation, and the lack of accurate ground-truth “clean” hyperspectral signals acquired on the spot makes restoration tasks challenging. In particular, training deep neural networks for restoration is difﬁcult, in contrast to traditional RGB imaging problems where deep models tend to shine. In this paper, we advocate instead for a hybrid approach based on sparse coding principles that retains the in-terpretability of classical techniques encoding domain knowledge with handcrafted image priors, while allowing to train model parameters end-to-end without massive amounts of data. We show on various denoising benchmarks that our method is computationally efﬁcient and signiﬁcantly outperforms the state of the art. 1 1

Introduction
Hyperspectral imaging (HSI) enables measurements of the electromagnetic spectrum of a scene on multiple bands (typically about a hundred or more), which offers many perspectives over traditional color RGB imaging. For instance, the high-dimensional information present in a single pixel is sometimes sufﬁcient to identify the signature of a particular material, which is of course infeasible in the RGB domain. Not surprisingly, hyperspectral imaging is then of utmost importance and has a huge number of scientiﬁc and technological applications such as remote sensing [8, 22, 46], quality evaluation of food products [16, 19, 35], medical imaging [2, 18, 37], agriculture and forestry
[1, 36, 40], microscopy imaging in biology [25, 56], or exoplanet detection in astronomy [24].
Information contained in hyperspectral signals is much richer than in RGB images, but the price to pay is the need to deal with complex degradations that may arise from multiple sources, including sparse noise with speciﬁc patterns (stripes), in addition to photon and thermal noise [29, 51]. As a consequence, HSI denoising is a crucial pre-processing step to enhance the image quality before using data in downstream tasks such as semantic segmentation or spectral unmixing [30]. A second issue is the lack of large-scale collection of ground-truth high-quality signals and the large diversity of sensor types, which makes it particularly challenging to train machine learning models for restoration such as convolutional neural networks. To deal with the scarcity of ground-truth data, most successful approaches typically encode strong prior knowledge about data within the model architecture, which may be low-rank representations of input patches [17, 23, 53, 60, 70], sparse coding [13, 21, 23], or image self-similarities [39, 49, 71], which have proven to be very powerful in the RGB domain [9].
∗Equal contribution 1Code is available at https://github.com/inria-thoth/T3SC. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
In this paper, we propose a fully interpretable machine learning model for hyperspectral images that may be seen as a hybrid approach between deep learning techniques, where parameters can be learned end to end with supervised data, and classical methods that essentially rely on image priors.
Since designing an appropriate image prior by hand is very hard, our goal is to beneﬁt from deep learning principles (here, differentiable programming [6]) while encoding domain knowledge and physical rules about hyperspectral data directly into the model architecture, which we believe is a key to develop robust approaches that do not require massive amounts of training data.
More precisely, we introduce a novel trainable spectral-spatial sparse coding model with two layers, which performs the following operations: (i) The ﬁrst layer decomposes the spectrum measured at each pixel as a sparse linear combination of a few elements from a learned dictionary, thus performing a form of linear spectral unmixing per pixel, where dictionary elements can be seen as basis elements for spectral responses of materials present in the scene. (ii) The second layer builds upon the output of the ﬁrst one, which is represented as a two-dimensional feature map, and sparsely encodes patches on a dictionary in order to take into account spatial relationships between pixels within small receptive ﬁelds. To further reduce the number of parameters to learn and leverage classical prior knowledge about spectral signals [60], we also assume that the dictionary elements admit a low-rank structure—that is, dictionary elements are near separable in the space and spectrum domains, as detailed later. Even though dictionary learning has been originally introduced for unsupervised learning [42, 47], we adopt an unrolled optimization procedure inspired by the
LISTA algorithm [26], which has been very successful in imaging problems for training sparse coding models from supervised data [33, 34, 55, 63].
Our motivation for adopting a two-layer model is to provide a shared architecture for different HSI sensors, which often involve a different number of bands with different spectral responses. Our solution consists of learning sensor-speciﬁc dictionaries for the ﬁrst layer, while the dictionary of second layer is shared across modalities. This allows training simultaneously on several HSI signals, the ﬁrst layer mapping input data to a common space, before processing data by the second layer.
We experimentally evaluate our HSI model on standard denoising benchmarks, showing a signiﬁcant improvement over the state of the art (including deep learning models and more traditional baselines), while being computationally very efﬁcient at test time. Perhaps more important than pure quantitative results, we believe that our work also draws interesting conclusions for machine learning. First, by encoding prior knowledge within the model architecture directly, we obtain models achieving excellent results with a relatively small number of parameters to learn, a conclusion also shared by [33, 34] for RGB imaging; nevertheless, the effect is stronger in our work due to the scarcity of training data for HSI denoising and the difﬁculty to train deep learning models for this task. Second, we also show that interpretable architectures are useful: our model architecture can adapt to different noise levels per band and modify the encoding function at test time in a principled manner, making it well suited for solving blind denoising problems that are crucial for processing hyperspectral signals. 2