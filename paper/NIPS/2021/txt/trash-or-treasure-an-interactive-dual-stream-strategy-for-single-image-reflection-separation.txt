Abstract
Single image reﬂection separation (SIRS), as a representative blind source sepa-ration task, aims to recover two layers, i.e., transmission and reﬂection, from one mixed observation, which is challenging due to the highly ill-posed nature. Exist-ing deep learning based solutions typically restore the target layers individually, or with some concerns at the end of the output, barely taking into account the interaction across the two streams/branches. In order to utilize information more efﬁciently, this work presents a general yet simple interactive strategy, namely your trash is my treasure (YTMT), for constructing dual-stream decomposition networks. To be speciﬁc, we explicitly enforce the two streams to communicate with each other block-wisely. Inspired by the additive property between the two components, the interactive path can be easily built via transferring, instead of discarding, deactivated information by the ReLU rectiﬁer from one stream to the other. Both ablation studies and experimental results on widely-used SIRS datasets are conducted to demonstrate the efﬁcacy of YTMT, and reveal its superiority over other state-of-the-art alternatives. The implementation is quite simple and our code is publicly available at https://github.com/mingcv/YTMT-Strategy. 1

Introduction
Blind source separation, a long-standing problem in signal processing, aims to recover multiple intrinsic components from their mixture, the difﬁculty of which comes from its ill-posedness, i.e., without extra information, there is an inﬁnite number of feasible decompositions. Particularly in computer vision, image reﬂection separation (IRS) is a representative scenario that often occurs when taking pictures through a transparent medium such as glass. In such cases, the captured images will contain both the scene transmitted through the medium (transmission) and reﬂection. On the one hand, reﬂections are annoying for high-quality imaging, and may interfere with the performance of most, if not all, of classic and contemporary vision oriented algorithms such as object detection and segmentation. On the other hand, one may also want to see what happens in the reﬂection. Hence, developing effective transmission-reﬂection decomposition techniques is desired.
Formally, the captured superimposed image I can be typically modeled as a linear combination of a transmission layer T and a reﬂection R, i.e. I = T + R.1 Over last decades, a large number of schemes have been devised to solve the decomposition problem. Various statistical priors and regularizers have been proposed to mitigate the ill-posed dilemma, while diverse deep networks have been recently built for the sake of performance improvement, please see Sec. 2 for details. However,
∗Corresponding Author 1Many problems follow the same additive model, such as denoising (I = B + N , where B and N denote clean image and noise, respectively), and intrinsic image decomposition (log I = log A + log S, where A and
S stand for albedo and shading, respectively.) The proposed strategy can be potentially applied to all these tasks, but due to page limit, we concentrate on the task of SIRS to verify primary claims in this paper. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
in the literature, the additive property, say I = T + R, has been hardly investigated, except for acting as a reconstruction constraint.
Let us consider that, for any estimation pair ˆT and ˆR satisfying the additive property, there always exists an error/residual Q subject to I = ˆT + ˆR = (T + Q) + (R − Q). Once Q is somehow obtained, the only thing needed to do is subtracting it from ˆT , and adding it into ˆR instead of simply discarding.
Under the circumstances, no information is trash, only misplaced. To be symmetric, we rewrite Q as Q := QT − QR, yielding T = ˆT − QT + QR and R = ˆR − QR + QT . In other words, the two targets including ˆT and ˆR can gain from each other by exchanging, rather than discarding, their respective “trash” factors QT and QR. Driven by the above fact, a question naturally arises: Can such an interaction/exchange be applied to intermediate deep features of dual-stream networks?
Contributions. This paper answers the above question by designing a general interactive dual-stream/branch strategy, namely your trash is my treasure (YTMT). An obstacle to realizing YTMT was how to determine exchanging information. Intuitively, activation functions are competent for the job, which are developed to select (activate) a part of features from inputs. In this work, we adopt the ReLU that is arguably the most representative and widely-used activation manner, while others could be also qualiﬁed like [4, 24, 12, 2]. Please notice that, instead of simply discarding the deactivated features (trash) of the one stream, we alternatively deliver them to the other stream as compensation (treasure). By doing so, there are two main merits: 1) the information losing and dead
ReLU problems can be consequently mitigated, and 2) the decreasing speed in training error can be signiﬁcantly accelerated. The implementation is quite simple and ﬂexible. We provide two optional
YTMT blocks as examples and apply them on both plain and UNet architectures to verify the primary claims. Both ablation studies and experimental results on widely-used SIRS datasets are conducted to demonstrate the efﬁcacy of YTMT, and reveal its superiority over other state-of-the-art alternatives. 2