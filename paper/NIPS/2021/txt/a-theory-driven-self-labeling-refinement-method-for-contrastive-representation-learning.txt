Abstract
For an image query, unsupervised contrastive learning labels crops of the same image as positives, and other image crops as negatives. Although intuitive, such a native label assignment strategy cannot reveal the underlying semantic similarity between a query and its positives and negatives, and impairs performance, since some negatives are semantically similar to the query or even share the same semantic class as the query.
In this work, we ﬁrst prove that for contrastive learning, inaccurate label assignment heavily impairs its generalization for semantic instance discrimination, while accurate labels beneﬁt its generalization. Inspired by this theory, we propose a novel self-labeling reﬁnement approach for contrastive learning. It improves the label quality via two complementary modules: (i) self-labeling reﬁnery (SLR) to generate accurate labels and (ii) momentum mixup (MM) to enhance similarity between query and its positive. SLR uses a positive of a query to estimate semantic similarity between a query and its positive and negatives, and combines estimated similarity with vanilla label assignment in contrastive learning to iteratively generate more accurate and informative soft labels. We theoretically show that our SLR can exactly recover the true semantic labels of label-corrupted data, and supervises networks to achieve zero prediction error on classiﬁcation tasks. MM randomly combines queries and positives to increase semantic similarity between the generated virtual queries and their positives so as to improves label accuracy. Experimental results on CIFAR10, ImageNet, VOC and COCO show the effectiveness of our method. 1

Introduction
Self-supervised learning (SSL) is an effective approach to learn features without manual annotations, with great success witnessed to many downstream tasks, e.g. image classiﬁcation and object detec-tion [1–7]. The methodology of SSL is to construct a pretext task that can obtain data labels via well designing the task itself, and then build a network to learn from these tasks. For instance, by constructing jigsaw puzzle [8], spatial arrangement identiﬁcation [9], orientation [10], or chromatic channels [11] as a pretext task, SSL learns high-qualiﬁed features from the pretext task that can well transfer to downstream tasks. As it gets rid of the manual annotation requirement in supervised deep learning, SSL has been widely attracted increasing researching interests [1, 12].
As a leading approach in SSL, contrastive learning [1, 4, 13–17] constructs a novel instance discrimi-nation pretext task to train a network so that the representations of different crops (augmentations) of the same instance are close, while representations of different instances are far from each other.
Speciﬁcally, for an image crop query, it randomly augments the same image to obtain a positive, and view other image crops as negatives. Then it constructs a one-hot label over the positive and negatives to pull the query together with its positive and push the query away its negatives in the feature space. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
Motivation. But the one-hot labels in contrastive learning are indeed inaccurate and uninformative because of the following two reasons. Firstly, for a query, it could be semantically similar or even more similar to some negatives than its positives. Indeed, some negatives even belong to the same semantic class as the query [18–20]. It holds in practice, as (i) to achieve good performance, one often uses sufﬁcient negatives that are much more than the semantic class number, e.g. tens of thousands of negatives for ImageNet [21] in MoCo [1], unavoidably leading to the issue on negatives; (ii) even for the same image, especially for an image containing different objects which occurs in ImageNet, random augmentations, e.g. crop, provide crops with (slightly) different semantic information, and thus some of the huge negatives could be more similar to query. Secondly, samples from different classes also have some similarity which is not characterized in the one-hot labels. For example, given a query cat, it is often more similar to a dog than a car though both dog and car are negatives.
Learning from those similarity among samples is also important and can improve the performance.
This point is also supported by knowledge distillation or self-training approaches [22, 23], where a teacher model or a currently-training model is used to predict semantic similarity of a sample on different classes for further supervising model training, achieving better performance. Therefore, the one-hot label cannot well reveal the semantic similarity between query and its positives and
“negatives", and cannot guarantee the semantically similar samples to close each other, leading to performance degradation.
Contributions. In this work, we alleviate the above label issue, and derive some new results and alternatives for contrastive learning. Particularly, we theoretically show that inaccurate labels impair the performance of contrastive learning. Then we propose a self-labeling reﬁnement method to obtain more accurate labels for contrastive learning. Our main contributions are highlighted below. n (cid:80)n i }n i=1(cid:107)yi −y∗ i=1 with estimated labels {yi}n i=1, the better generalization of MoCo for instance discrimination.
Our ﬁrst contribution is proving that the generalization error of MoCo for instance discrimination linearly depends on the discrepancy between the estimated labels (e.g. one-hot labels) in MoCo and the true labels that really reﬂect semantical similarity between a query and its positives and negatives.
Formally, given n training queries D= {xi}n i=1 (e.g. one-hot labels in
MoCo) and ground truth labels {y∗ i=1 on their corresponding positives and negatives, the general-ization error of MoCo for instance discrimination is lower bounded by O(cid:0)ED[(cid:107)y −y∗(cid:107)2](cid:1) where i (cid:107)2, and is upper bounded by O(cid:0)(cid:112)ln(|F|)/n +ED [(cid:107)y −y∗(cid:107)2] (cid:1),
ED[(cid:107)y −y∗(cid:107)2] = 1 where |F| is the covering number of the network hypotheses in MoCo. It means that the more accurate of the estimated labels {yi}n
Inspired by our theory, we propose a Self-lAbeliNg rEﬁnement (SANE) method which iteratively employs the network and data themselves to generate more accurate and informative soft labels for contrastive learning. SANE has two complementary modules: (i) Self-Labeling Reﬁnery (SLR) to explicitly generate accurate labels, and (ii) Momentum Mixup (MM) to increase similarity between query and its positive and implicitly improve label accuracy. Given a query, SLR uses its one positive to estimate semantic similarity between the query and its keys (i.e. its positive and negatives) by computing their feature similarity, since a query and its positive come from the same image and should have close similarity on the same keys. Then SLR linearly combines the estimated similarity of a query with its vanilla one-hot label in contrastive learning to iteratively generate more accurate and informative soft labels. Our strategy is that at the early training stage, one-hot label has heavy combination weight to provide relatively accurate labels; along with more training, the estimated similarity becomes more accurate and informative, and its combination weight becomes larger as it explores useful underlying semantic information between the query and its keys that is missing in the one-hot labels. Besides, we prove that when the semantic labels in the instance discrimination task are corrupted, our SLR can exactly recover the true semantic labels of training data, and networks trained with our SLR can exactly predict the true semantic labels of test samples. i=1 as x(cid:48) i = θxi + (1−θ)(cid:101)xk and estimate their labels as y(cid:48)
Moreover, we introduce MM for contrastive learning to further reduce the possible label noise and also increase augmentation diversity. Speciﬁcally, we randomly combines queries {xi}n i=1 and their positives {(cid:101)xi}n i = θ ¯yi + (1−θ) ¯yk, where indexes i and k are randomly selected, ¯yi is the label of both xi and (cid:101)xi estimated by our label reﬁnery, and θ ∈ (0, 1) is a random variable. In this way, the component (cid:101)xk in the virtual query x(cid:48) i directly increases the similarity between the query x(cid:48) i and the positive key (cid:101)xk. So the label weight (1 − θ) of i on positive key (cid:101)xi to bring x(cid:48) label y(cid:48) i really contains the semantic information of (cid:101)xk. Meanwhile, the possible noise at the remaining positions of label y(cid:48) i is scaled by θ and becomes smaller. In this way, MM also improves the label quality. i and (cid:101)xk together is relatively accurate, as x(cid:48) 2
Other