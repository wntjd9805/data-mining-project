Abstract
Robustness against adversarial attacks has recently been at the forefront of algo-rithmic design for machine learning tasks. In the adversarial streaming model, an adversary gives an algorithm a sequence of adaptively chosen updates u1, . . . , un as a data stream. The goal of the algorithm is to compute or approximate some predetermined function for every preﬁx of the adversarial stream, but the adversary may generate future updates based on previous outputs of the algorithm. In par-ticular, the adversary may gradually learn the random bits internally used by an algorithm to manipulate dependencies in the input. This is especially problematic as many important problems in the streaming model require randomized algorithms, as they are known to not admit any deterministic algorithms that use sublinear space. In this paper, we introduce adversarially robust streaming algorithms for central machine learning and algorithmic tasks, such as regression and cluster-ing, as well as their more general counterparts, subspace embedding, low-rank approximation, and coreset construction. For regression and other numerical linear algebra related tasks, we consider the row arrival streaming model. Our results are based on a simple, but powerful, observation that many importance sampling-based algorithms give rise to adversarial robustness which is in contrast to sketching based algorithms, which are very prevalent in the streaming literature but suffer from adversarial attacks. In addition, we show that the well-known merge and reduce paradigm in streaming is adversarially robust. Since the merge and reduce paradigm allows coreset constructions in the streaming setting, we thus obtain robust algorithms for k-means, k-median, k-center, Bregman clustering, projective clustering, principal component analysis (PCA) and non-negative matrix factoriza-tion. To the best of our knowledge, these are the ﬁrst adversarially robust results for these problems yet require no new algorithmic implementations. Finally, we empirically conﬁrm the robustness of our algorithms on various adversarial attacks and demonstrate that by contrast, some common existing algorithms are not robust. 1

Introduction
Robustness against adversarial attacks have recently been at the forefront of algorithmic design for machine learning tasks [GSS15, CW17, AEIK18, MMS+18, TSE+19]. We extend this line of work by studying adversarially robust streaming algorithms.
In the streaming model, data points are generated one at a time in a stream and the goal is to compute some meaningful function of the input points while using a limited amount of memory, typically 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
sublinear in the total size of the input. The streaming model is applicable in many algorithmic and ML related tasks where the size of the data far exceeds the available storage. Applications of the streaming model include monitoring IP trafﬁc ﬂow, analyzing web search queries [LMV+16], processing large scientiﬁc data, feature selection in machine learning [HZZ21, GRB+19, WYWD10], and estimating word statistics in natural language processing [GDC12] to name a few. Streaming algorithms have also been implemented in popular data processing libraries such as Apache Spark which have implementations for streaming tasks such as clustering and linear regression [ZXW+16a].
In the adversarial streaming model [MBN+17, BMSC17, AMYZ19, BY20, BJWY20, HKM+20,
WZ20, ABD+21, KMNS21], an adversary gives an algorithm a sequence of adaptively chosen updates u1, . . . , un as a data stream. The goal of the algorithm is to compute or approximate some predetermined function for every preﬁx of the adversarial stream, but the adversary may generate future updates based on previous outputs of the algorithm. In particular, the adversary may gradually learn the random bits internally used by an algorithm to manipulate dependencies in the input. This is especially problematic as many important problems in the streaming model require randomized algorithms, as they are known to not admit any deterministic algorithms that use sublinear space.
Studying when adversarially robust streaming algorithms are possible is an important problem in lieu of recent interest in adversarial attacks in ML with applications to adaptive data analysis.
Formally, we deﬁne the model as a two-player game between a streaming algorithm StreamAlg and a source Adversary of adaptive and adversarial input to StreamAlg. At the beginning of the game, a
ﬁxed query Q is determined and asks for a ﬁxed function for the underlying dataset implicitly deﬁned by the stream. The game then proceeds in rounds, and in the t-th round, (1) Adversary computes an update ut ∈ [n] for the stream, which depends on all previous stream updates and all previous outputs from StreamAlg. (2) StreamAlg uses ut to update its data structures Dt, acquires a fresh batch Rt of random bits, and outputs a response At to the query Q. (3) Adversary observes and records the response At.
The goal of Adversary is to induce StreamAlg to make an incorrect response At to the query Q at some time t ∈ [m] throughout the stream.