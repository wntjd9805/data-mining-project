Abstract
Graph Neural Networks are perfectly suited to capture latent interactions between various entities in the spatio-temporal domain (e.g. videos). However, when an explicit structure is not available, it is not obvious what atomic elements should be represented as nodes. Current works generally use pre-trained object detectors or ﬁxed, predeﬁned regions to extract graph nodes. Improving upon this, our proposed model learns nodes that dynamically attach to well-delimited salient regions, which are relevant for a higher-level task, without using any object-level supervision. Constructing these localized, adaptive nodes gives our model inductive bias towards object-centric representations and we show that it discovers regions that are well correlated with objects in the video. In extensive ablation studies and experiments on two challenging datasets, we show superior performance to previous graph neural networks models for video classiﬁcation. 1

Introduction
Spatio-temporal data, and videos, in particular, are characterised by an abundance of events that require complex reasoning to be understood. In such data, entities or classes exist at multiple scales and in different contexts in space and time, starting from lower-level physical objects, which are well localized in space and moving towards higher-level concepts which deﬁne complex interactions. We need a representation that captures such spatio-temporal interactions at different level of granularity, depending on the current scene and the requirements of the task. Classical convolutional nets address spatio-temporal processing in a simple and rigid manner, determined only by ﬁxed local receptive
ﬁelds [1]. Alternatively, space-time graph neural nets [2, 3] offer a more powerful and ﬂexible approach modeling complex short and long-range interactions between visual entities.
In this paper, we propose a novel method to enhance vision Graph Neural Networks (GNNs) by an additional capability, missing from any other previous works. That is, to have nodes that are constructed for spatial reasoning and can adapt to the current input. Prior works are limited to having either nodes attached to semantic attention maps [4] or attached to ﬁxed locations such as grids [5, 3, 6]. Moreover, unlike works that require external object detectors [7] our method relies on a learnable mechanism to adapt to the current input.
∗Equal contribution. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
We propose a method that learns to discover salient regions, well-delimited in space and time, that are useful for modeling interactions between various entities. Such entities could be single objects, parts or groups of objects that perform together a simple action. Each node learns to associate by itself to such salient regions, thus the message passing between nodes is able to model object interactions more effectively. For humans, representing objects is a core knowledge system [8] and to emphasize them in our model, we predict salient regions [9] that give a strong inductive bias towards modeling them.
Our method, Dynamic Salient Regions Graph Neural Network (DyReg-GNN) improves the relational processing of videos by learning to discover salient regions that are relevant for the current scene and task. Note that the model learns to predict regions only from the weak supervision given by the high-level video classiﬁcation loss, without supervision at the region level. Our experiments convincingly show that the regions discovered are well correlated with the objects present in the video, conﬁrming the intuition that action recognition should be strongly related to salient region discovery. The capacity to discover such regions makes DyReg-GNN an excellent candidate model for tackling tasks requiring spatio-temporal reasoning.
Our main contributions are summarised as follow: 1. We propose a novel method to augment spatio-temporal GNNs by an additional capability: that of learning to create localized nodes suited for spatial reasoning, that adapt to the input. 2. The salient regions discovery enhance the relational processing for high-level video clas-siﬁcation tasks: creating GNN nodes from predicted regions obtains superior performance compared to both using pre-trained object detectors or ﬁxed regions 3. Our model leads to unsupervised salient regions discovery, a novelty in the realm of
GNNs: it predicts such regions in videos, with only weak supervision at the video class level.
We show that regions discovered are well correlated with actual physical object instances. 2