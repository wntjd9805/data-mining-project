Abstract
The neural attention mechanism has been incorporated into deep neural networks to achieve state-of-the-art performance in various domains. Most such models use multi-head self-attention which is appealing for the ability to attend to informa-tion from different perspectives. This paper introduces alignment attention that explicitly encourages self-attention to match the distributions of the key and query within each head. The resulting alignment attention networks can be optimized as an unsupervised regularization in the existing attention framework. It is simple to convert any models with self-attention, including pre-trained ones, to the proposed alignment attention. On a variety of language understanding tasks, we show the effectiveness of our method in accuracy, uncertainty estimation, generalization across domains, and robustness to adversarial attacks. We further demonstrate the general applicability of our approach on graph attention and visual question answering, showing the great potential of incorporating our alignment method into various attention-related tasks. 1

Introduction
Attention-based mechanisms aggregate features with learnable weights to introduce useful inductive biases for sequence models [1, 2]. Since the introduction of the self-attention based Transformer [3], attention has become the foundation for many state-of-the-art models. Exploiting its computational efﬁciency and scalability, it has been used to train unprecedented large models on big datasets [4].
Large attention-based models have been demonstrating their ability to learn good representations in an unsupervised manner and beneﬁt downstream analysis, with tremendous success in various natural language processing (NLP) [4–9], compute vision [10, 11], and multi-modal learning tasks [12, 13].
Attention networks, including multi-head attention, are being effectively utilized to capture the correlations between each pair of input tokens through individual or multiple attention functions.
More speciﬁcally, in a self-attention layer with H heads, assuming that the output of the previous layer consists of n tokens, each of which is represented as a feature vector of dimension dmodel = d · H, then each token feature vector will be transformed by a dmodel × d query projection matrix into a query feature vector, by a dmodel × d key projection matrix into a key feature vector, and by a dmodel × d value projection matrix into a value feature vector. The inner products of the ith query feature vector with all n key feature vectors are then fed through a softmax function to deﬁne the relative weights of the n keys to that query, which are used to aggregate the n value vectors into the vector representation of the ith word token in a head.
Although such networks are simple to optimize and intuitive to understand, how the key and query projection matrices should differ from each other has not been well-studied and understood. It is thus
The code is available at https://github.com/szhang42/alignment_attention 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
unclear whether they would result in well-controlled interactions between the keys and queries. In particular, ignoring the dependence between the n token feature vectors, we can view the output of the previous layer as an empirical distribution supported on n points in Rdmodel . In each head, this empirical distribution is transformed by the query and key projection matrices into a query empirical distribution and a key empirical distribution, respectively, each supported on n points at the same feature space in Rd. Since at each head two different projections matrices are used to project the input, the distributions of key and query will be different. Intuitively, if these two distributions are clearly misaligned with each other, then the query and key of a token, whose input feature resides in a region with lower probabilities, may have increased risk of being pushed further away from each other in the shared projection space.
This paper proposes alignment attention, which regularizes the query and key projection matrices at each self-attention layer, by matching the empirical distributions of the query and key feature vectors.
We focus on within-head alignment between empirical distributions and present three different options for distribution matching. In our framework, alignment attention, built as an unsupervised approach to match the query and key distributions, is trained jointly to maximize a combination of data likelihood and distribution agreement. This efﬁcient architecture design enables us to easily add alignment loss to convert existing self-attention networks, including pre-trained ones, into alignment attention.
Meanwhile, it naturally shares parameters and computation with the self-attention networks, allowing an end-to-end training.
With a generic architecture, alignment attention can convert any existing soft attention models, including pre-trained ones, while maintaining the inherent advantages of conventional attention, such as efﬁciency and being simple to optimize. The proposed method boosts the performance while remaining efﬁcient in memory and computation cost. Our experiments show that the proposed alignment attention method outperforms state-of-the-art self-attentions in a wide variety of settings, including natural language understanding tasks, graph attention network, and visual question answer-ing, in terms of accuracy and uncertainty estimation. We further demonstrate that alignment attention achieves strong performance in domain generalization and adversarial robustness. 2 Alignment attention
We introduce a general recipe for alignment attention: (a) build the alignment to match the key and query distributions within each head, (b) develop efﬁcient distribution matching methods, and (c) leverage existing attention structure and optimize the model in an end-to-end manner. The resulting architecture can be efﬁciently learned with existing self-attention networks. 2.1 Attention modules
Attention uses keys and queries to obtain soft attention weights W , which are then used to aggregate the values to obtain the output features. Consider n key-value pairs with a key matrix K ∈ Rn×dk , a value matrix V ∈ Rn×dv , and m queries Q ∈ Rm×dk , where in general the dimensions of queries and keys are equal. The scaled product between key and query [3] is: Φ = fdot(Q, K) = QK T / dk ∈
Rm×n. Alternative choices include dot-product [3, 4] and additive attention [14–16]. Attention weights W is deﬁned as the softmax output of Φ: W = softmax(Φ), where Wi,j = (cid:80)n represents the importance of the jth key to the ith query learned by the neural networks. exp(Φi,j ) j(cid:48)=1 exp(Φi,j(cid:48) )
√
The multi-head attention, ﬁrst proposed in Transformer [3], projects the queries, keys, and values into
H subspaces with H different learnable linear projections. These projections are performed in parallel and then concatenated into a single latent representation. At the lth self-attention layer, we can obtain attention weight W l,h = softmax(f (Ql,h, K l,h)), where Ql,h = QlM l,h
K , and
V l,h = V lM l,h
V for h = 1, ..., H, with M denoting the parametric matrices to learn. The attention results from all heads are then concatenated into the layer output as Ol = [W l,1V l,1, ..., W l,H V l,H ].
Q , K l,h = K lM l,h 2.2 Alignment attention
Self-attention allows the model to attend to the information from each representation subspace at each position [17]. To encourage different attention heads to indeed capture distinct features, most previous studies focus on the disagreement regularization to explicitly encourage the diversity 2
Figure 1: T-SNE visualizations of (a) soft attention and (b) alignment attention with bidirectional conditional transport. In (a) and (b), we visualize the both key distribution and the query distribution. The blue dots and orange diamonds represent the features from the key distribution and these from the query distribution, respectively. We show attention heatmaps of a VQA data in (c) and (d). It includes overall attention of seven examples’ matrix embedding by summing up the attention weight vectors, with darker color denoting higher attention probability. among attention heads [17]. By contrast, our focus is on exploiting how to make the key and query distributions better interact with each other in the latent space. We propose agreement matching to encourage the distributions of key and query over different tokens to be consistent within each head. Given a source input x and its output y, a neural attention model is trained to maximize the conditional probability of y given x over a training corpus. We introduce distribution alignment, an auxiliary regularization term in order to encourage the alignment between the learned key and query distributions. Considering a supervised learning problem with training data D := {xi, yi}N i=1, the likelihood parameterized by θ is denoted by pθ(yi | xi). For notational convenience, below we drop the data index i. The whole model is differentiable to directly maximize the likelihood. Formally, the training objective with alignment attention is expressed as:
L(x, y) = log pθ(y | x) (cid:125) (cid:124) (cid:123)(cid:122) likelihood
,
+λ ∗ LAlign(Q, K) (cid:125) (cid:123)(cid:122) alignment (cid:124) (1) where λ is the alignment weight [18–21]. The auxiliary regularization term LAlign guides the distribution matching between key (K) and query (Q).
The proposed alignment provides a sample-and-head-dependent matching between the key and query.
Assuming Q and K have the same batch size and number of heads; Q is of dimension [B, H, n, dq], where B represents the batch size, H the number of heads, n the number of queries, and dq the hidden dimension within a head; and K is of dimension [B, H, m, dk]. Focused on the self-attention networks, we assume n = m = w and dq = dk = d in our alignment attention. We use Q, K to calculate the point-to-point difference from the query to key for each head at each sample, resulting in a tensor with dimension [B, H, w, w]. At each of the B samples of the minibatch and each of the H heads, the training objective is to minimize the expected difference between the empirical distributions of query and key, both of which are supported on a set of w query/key features in Rd (see Figure 2). This ﬂexible alignment method could be conveniently deployed into a single-head or multi-head attention mechanism.
With the alignment attention, the resulting key and query distributions should be close to each other (see t-SNE plots [22, 23]in Figure 1). We also visualize the attention weight from both soft and alignment attentions in Figure 1. It is clear that while many semantically and sentimentally important words and their combinations, such as “where, they, sitting,” “color, ribbon,” “what, time, picture,”
“boxes, room,” “where, bicycles, chained,” “bus, gaudy,” and “animals, visible,” are overlooked by vanilla soft attention, they are appropriately highlighted by the proposed alignment attention. 2.3 Alignment methods
To align the key and query distributions, we need a method that can quantify the difference between two distributions given their empirical samples. Under this requirement, we consider three different distribution matching methods, including the discriminator-based adversarial training [24], which is directly related to the Jensen–Shannon (JS) divergence [25], the Wasserstein distance in its primal form, which can be deﬁned by solving an optimal transport problem [26, 27], and bi-directional conditional transport [28], which is developed by exploiting both the chain rule and Bayes’ rule to quantify the difference between two probability distributions. 3
Figure 2: On the left, we visualize the alignment attention. The ellipse represents query and the rectangle represents the key. On the right, a demonstration of the difference and similarity between vanilla soft attention and our alignment attention. Alignment attention (in green) shares the same architecture as soft attention before obtaining key, query, and value. Then alignment attention adds the alignment structure to perform distribution matching, where GRL represents the gradient reversal layer. 2.3.1 Adversarial training-based alignment
Adversarial training, the key part to enable GANs [24], has been successfully exploited to minimize the distributional discrepancy [29, 30]. Under a minimax two-player framework, the discriminator D is trained to distinguish the distributions of key and query, while both the query and key projection matrices, MQ and MK, are treated as the generator G and trained to confuse D. Here we consider a discriminator D that is shared across the H heads for alignment. Denote the empirical distributions of query and key as pQ and pK, respectively. For a sample of w tokens and at one of the H heads, we have pQ = (cid:80)w 1 w δkj , where qi and ki are projected from the ith token’s input feature via the query and key projection matrices at that head, respectively. Thus the alignment loss is the sum over H different head-dependent loss, each of which on a sample can be expressed as (we drop the head index for notational simplicity) w δqi and pK = (cid:80)w j=1 i=1 1 min
G max
D
LAlign−GAN(Q, K) := Eq∼pQ[log D(q)] + Ek∼pK [log(1 − D(k))]. (2)
In summary, the discriminator is trained to maximize the alignment loss, and the generator, i.e., the query and key projection matrices, is trained to minimize the alignment loss, so that the key and query distributions are learned adversarially to align with each other.
Discriminator-based modules. We leverage the highway architecture [31] to construct the dis-criminator. With a feature map X ∈ {Q, K}, the highway network ﬁrst computes a transform gate
τ , as τ = σ (Φτ (X)) , where Φτ is a fully-connected layer and σ is the sigmoid activation function.
Then, the output of the highway network is, IX = τ (cid:12) ReLU(Φh(X)) + (1 − τ ) (cid:12) X, where Φh is another linear layer followed by ReLU activation and (cid:12) denotes the element-wise multiplication. We further apply a two-layer MLP to obtain the classiﬁer probability, D(X) = σ(Φ2 (FNL (Φ1 (IX ))))), where Φ1 and Φ2 are fully-connected layers connected by FNL, a leaky ReLU activation function.
To optimize the discriminator-based modules, instead of alternately updating the adversaries, like in
GAN [24], we use the gradient-reversal layer [32] to jointly optimize all the components. 2.3.2 Optimal transport-based alignment
An alternative to the adversarial training-based alignment is to consider optimal transport (OT) [26], which has been widely used for distribution matching. In OT, the transport plan Π(pQ, pK) is the set of all possible joint distributions of query and key, whose marginals over the query and key are pK and pQ, respectively. We deﬁne the OT-based alignment cost as
LAlign−OT(Q, K) = min
π∈Π(pQ,pK )
Eq,k∼π [c(q, k)] , (3) where c(·, ·) is the transport cost between two points. For discrete pQ and pK, ﬁning the optimal transport plan often involves solving a computationally expensive linear programming problem. It is also known in the literature that OT is sensitive to the outliers in pQ and pK due to the two marginal constraints [33]. To reduce the computation burden, we consider an entropy-regularized OT, which allows the OT problem to be solved iteratively using the Sinkhorn iterations [34]. 4
Optimal transport-based modules. We use the Sinkhorn algorithm [34, 35] to estimate the trans-j=1(c(qi, kj)·π(qi, kj)−(cid:15)π(qi, kj) log π(qi, kj)), where port plan, deﬁned as π(cid:15) = argmin (cid:80)w (cid:15) = 0.01. The OT-alignment cost now becomes LAlign−OT = (cid:80)w j=1(c(qi, kj) · π(cid:15)(qi, kj)). (cid:80)w (cid:80)w i=1 i=1
π 2.3.3 Bidirectional conditional transport-based alignment 1 i=1 w δqi and pK = (cid:80)w
Instead of requiring π ∈ Π(pQ, pK) as in OT, we follow Zheng and Zhou [28] to consider probabilistic bidirectional conditional transport (CT), which exploits both the chain rule and Bayes’ theorem to constrain the joint π with both pQ = (cid:80)w 1 w δkj in two different ways. First, we consider a query-to-key CT that deﬁne π as π(qi, kj) = pQ(qi)πK(kj | qi), where πK(kj | qi) pK (kj ) exp(τφ(kj )T τφ(qi)) is a conditional distribution deﬁned as πK(kj | qi) = j(cid:48)=1 pK (kj(cid:48) ) exp(τφ(kj(cid:48) )T τφ(qi)) and τφ(·) is a neural network based transformation parameterized by φ. Second, we consider a key-to-query pQ(qi) exp(τφ(kj )T τφ(qi))
CT that deﬁnes π(qi, kj) = pK(kj)πQ(qi | kj), where πQ(qi | kj) = i(cid:48)=1 pQ(qi(cid:48) ) exp(τφ(kj )T τφ(qi(cid:48) )) .
Third, we deﬁne a point-to-point cost as cη(q, k) = 1 − τη(k)T τη(q)
, where τη(·) is a neural network based “critic” function whose parameter η will be adversarially learned. Combing them together leads to the bidirectional CT-based alignment loss as
||τη(k)||2||τη(q)||2 j=1 (cid:80)w (cid:80)w
LAlign−CT(Q, K) = 1 2
Eq∼pQ, k∼πK (· | q)[cη(q, k)] + 1 2
Ek∼pK , q∼πQ(· | k)[cη(q, k)]. (4)
Compared to OT, bidirectional CT is able to efﬁciently model the alignment with less computation.
The structure of alignment attention with transport-based methods is presented in Fig. 2.
CT-based modules. The critic τη(·) is structured similarly as the discriminator in Section 2.3.1. It projects the input data onto a vector space instead of outputting logits for binary classiﬁcation. For
τφ(·), we use a two-layer MLP network. We optimize the query and key projection matrices and φ to minimize LAlign−CT(Q, K) in (4), and optimize η to maximize it. The gradient-reversal layer [32] is also used to optimize the critic adversarially. 3