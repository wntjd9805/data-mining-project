Abstract
Greedy algorithms have long been a workhorse for learning graphical models, and more broadly for learning statistical models with sparse structure. In the context of learning directed acyclic graphs, greedy algorithms are popular despite their worst-case exponential runtime. In practice, however, they are very efﬁcient. We provide new insight into this phenomenon by studying a general greedy score-based algorithm for learning DAGs. Unlike edge-greedy algorithms such as the popular GES and hill-climbing algorithms, our approach is vertex-greedy and requires at most a polynomial number of score evaluations. We then show how recent polynomial-time algorithms for learning DAG models are a special case of this algorithm, thereby illustrating how these order-based algorithms can be rigorously interpreted as score-based algorithms. This observation suggests new score functions and optimality conditions based on the duality between Bregman divergences and exponential families, which we explore in detail. Explicit sample and computational complexity bounds are derived. Finally, we provide extensive experiments suggesting that this algorithm indeed optimizes the score in a variety of settings. 1

Introduction
Learning the structure of a graphical model from data is a notoriously difﬁcult combinatorial problem with numerous applications in machine learning, artiﬁcial intelligence, and causal inference as well as scientiﬁc disciplines such as genetics, medicine, and physics. Owing to its combinatorial structure, greedy algorithms have proved popular and efﬁcient in practice. For undirected graphical models (e.g. Ising, Gaussian) in particular, strong statistical and computational guarantees exist for a variety of greedy algorithms [27, 28]. These algorithms are based on the now well-known forward-backward greedy algorithm [29, 57], which has been applied to a range of problems beyond graphical models including regression [57], multi-task learning [52], and atomic norm regularization [44].
Historically, the use of the basic forward-backward greedy scheme for learning directed acyclic graphical (DAG) models predates some of this work, dating back to the classical greedy equivalence search [GES, 13] algorithm. Since its introduction, GES has become a gold-standard for learning
DAGs, and is known to be asymptotically consistent under certain assumptions such as faithfulness and score consistency [13, 34]. Both of these assumptions are known to hold for certain parametric families [21], however, extending GES to distribution-free settings has proven difﬁcult. Furthermore, 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
although GES is in practice extremely efﬁcient and has been scaled up to large problem sizes [43], it lacks polynomial-time guarantees. An important problem in this direction is the development of provably polynomial-time, consistent algorithms for DAG learning in general settings.
In this paper, we revisit greedy algorithms for learning DAGs with an eye towards these issues. We propose a greedy algorithm for this problem—distinct from GES—and study its computational and statistical properties. In particular, it requires at most a polynomial number of score evaluations and provably recovers the correct DAG for properly chosen score functions. Furthermore, we illustrate its intimate relationship with existing order-based algorithms, providing a link between these existing approaches and classical score-based approaches. Along the way, we will see how the analysis itself suggests a family of score functions based on the Bregman information [5], which are well-deﬁned without speciﬁc distributional assumptions.
Contributions At a high-level, our goal is to understand what kind of ﬁnite-sample and complexity guarantees can be provided for greedy score-based algorithms in general settings. In doing so, we aim to provide deeper insight into the relationships between existing algorithms. Our main contributions can thus be outlined as follows:
• A generic greedy forward-backward scheme for optimizing score functions deﬁned over
DAGs. Unlike existing edge-greedy algorithms that greedily add or remove edges, our algorithm is vertex-greedy, i.e. it greedily adds vertices in a topological sort.
• We show how several existing order-based algorithms from the literature are special cases of this algorithm, for properly deﬁned score functions. Thus, we bring these approaches back under the umbrella of score-based algorithms.
• We introduce a new family of score functions derived from the Bregman information, and analyze the sample and computational complexity of our greedy algorithm for this family of scores.
• We explore the optimization landscape of the resulting score functions, and provide evidence that not only does our algorithm provably recover the true DAG, it does so by globally optimizing a score function.
The last claim is intriguing: It suggests that it is possible to globally optimize certain Bayesian network scores in polynomial-time. In other words, despite the well-known fact that global optimization of
Bayesian networks scoring functions is NP-hard [12, 14], there may be natural assumptions under which these hardness results can be circumvented. This is precisely the case, for example, for undirected graphs: In general, learning Markov random ﬁelds is NP-hard [50], but special cases such as Gaussian graphical models [6, 33] and Ising models [8, 31, 55] can be learned efﬁciently.
Nonetheless, we emphasize that these results on global optimization of the score are merely empirical, and a proof of this fact beyond the linear case remains out of reach.
Previous work The literature on BNSL is vast, so we focus this review on related work involving score-based and greedy algorithms. For a broad overview of BNSL algorithms, see the recent survey
[24] or the textbooks [42, 49]. The current work is closely related to and inspired by generic greedy algorithms such as [27–29, 44, 52, 57]. Existing greedy algorithms for score-based learning include
GES [13], hill climbing [11, 51], and A* search [56]. In contrast to these greedy algorithms are global algorithms that are guaranteed to ﬁnd a global optimum such as integer programming [16, 17] and dynamic programming [36, 46, 47]. Another family of order-based algorithms dating back to
[51] centers around the idea of order search—i.e. ﬁrst searching for a topological sort—from which the DAG structure is easily deduced; see also [3, 4, 9, 45, 54]. Recently, a series of order-based algorithms have led to signiﬁcant breakthroughs, most notable of which are ﬁnite-sample and strong polynomial-time guarantees [10, 19, 22, 23, 38]. It will turn out that many of these algorithms are special cases of the greedy algorithm we propose; we revisit this interesting topic in Section 3.1. 2