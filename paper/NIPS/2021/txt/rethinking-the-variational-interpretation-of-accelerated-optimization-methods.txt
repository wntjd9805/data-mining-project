Abstract
The continuous-time model of Nesterov’s momentum provides a thought-provoking perspective for understanding the nature of the acceleration phenomenon in convex optimization. One of the main ideas in this line of research comes from the ﬁeld of classical mechanics and proposes to link Nesterov’s trajectory to the solution of a set of Euler-Lagrange equations relative to the so-called Bregman Lagrangian.
In the last years, this approach led to the discovery of many new (stochastic) accelerated algorithms and provided a solid theoretical foundation for the design of structure-preserving accelerated methods. In this work, we revisit this idea and provide an in-depth analysis of the action relative to the Bregman Lagrangian from the point of view of calculus of variations. Our main ﬁnding is that, while
Nesterov’s method is a stationary point for the action, it is often not a minimizer but instead a saddle point for this functional in the space of differentiable curves.
This ﬁnding challenges the main intuition behind the variational interpretation of
Nesterov’s method and provides additional insights into the intriguing geometry of accelerated paths. 1

Introduction
This paper focuses on the problem of unconstrained convex optimization, i.e. to ﬁnd x∗ ∈ arg min f (x), x∈Rd (P) for some lower bounded convex L-smooth2 loss f ∈ C1(Rd, R).
Nesterov’s acceleration. Nemirovskii and Yudin (1983) showed that no gradient-based optimizer can converge to a solution of (P) faster than O(k−2), where k is the number of gradient evaluations3.
While Gradient Descent (GD) converges like O(k−1), the optimal rate O(k−2) is achieved by the celebrated Accelerated Gradient Descent (AGD) method, proposed by Nesterov (1983): xk+1 = yk − η∇f (yk) , with yk = xk + k − 1 k + 2 (xk − xk−1). (AGD)
The intuition behind Nesterov’s method and the fundamental reason behind acceleration is, to this day, an active area of research (Allen-Zhu and Orecchia, 2014; Defazio, 2019; Ahn, 2020).
ODE models. Towards understanding the acceleration mechanism, Su et al. (2016) made an interesting observation: the convergence rate gap between GD and AGD is retained in the continuous-time limits (as the step-size η vanishes):
˙X + ∇f (X) = 0 (GD-ODE),
¨X +
˙X + ∇f (X) = 0 (AGD-ODE) 3 t
∗Equal Contribution. 2A differentiable function f : Rd → R is said to be β-smooth if it has β-Lipschitz gradients. 3This lower bound holds just for k < d hence it is only interesting in the high-dimensional setting. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
where ˙X := dX/dt denotes the time derivative (velocity) and ¨X := d2X/dt2 the acceleration.
Namely, we have that GD-ODE converges like O(t−1) and AGD-ODE like O(t−2), where t > 0 is the time variable. This seminal paper gave researchers a new tool to understand the nature of accelerated optimizers through Bessel Functions (Su et al., 2016), and led to the design of many novel fast and interpretable algorithms outside the Euclidean setting (Wibisono et al., 2016; Wilson et al., 2019), in the stochastic setting (Krichene et al., 2015; Xu et al., 2018) and also in the manifold setting (Alimisis et al., 2020; Duruisseaux and Leok, 2021).
Nesterov as solution to Euler-Lagrange equations. recovered from Euler-Lagrange equations, starting from the time-dependent Lagrangian
It is easy to see that AGD-ODE can be
L(X,
˙X, t) = t3 (cid:107) ˙X(cid:107)2 − f (X) (cid:19)
. (cid:18) 1 2
Indeed, the Euler-Lagrange equation (cid:18) ∂
∂ ˙X d dt (cid:19)
˙X, t)
L(X,
=
∂
∂X
L(X,
˙X, t) (1) (2) reduces in this case to t3 ¨X + 3t2 ˙X + t3∇f (X) = 0, which is equivalent to AGD-ODE (assuming t > 0). In a recent inﬂuential paper, Wibisono et al. (2016) generalized the derivation above to non-Euclidean spaces, where the degree of separation between points x and y is measured by means of the Bregman Divergence (Bregman, 1967) Dψ(x, y) = ψ(y) − ψ(x) − (cid:104)∇ψ(x), y − x(cid:105), where
ψ : Rd → R is a strictly convex and continuously differentiable function (see e.g. Chapter 1.3.2 in Amari (2016)). Namely, they introduced the so-called Bregman Lagrangian:
Lα,β,γ(X,
˙X, t) = eα(t)+γ(t) (cid:16) (cid:17)
Dψ(X + e−α(t)V, X) − eβ(t)f (X)
, (3) where α, β, γ are continuously differentiable functions of time. The Euler-Lagrange equations imply
¨X + (eα(t) − ˙α(t)) ˙X + e2α(t)+β(t) (cid:104)
∇2ψ(X + e−α(t) ˙X) (cid:105)−1
∇f (X) = 0. (4) 2 (cid:107)x(cid:107)2 2 (cid:107)x − y(cid:107)2 2, we get back to the Euclidean metric Dψ(x, y) = 1
The main result of Wibisono et al. (2016) is that, under the ideal-scaling conditions ˙β(t) ≤ eα(t) and ˙γ(t) = eα(t), any solution to Eq. (4) converges to a solution of (P) at the rate O(e−β(t)). Under the choice ψ(x) = 1 2. Moreover, choosing α(t) = log(2/t), β(t) = γ(t) = 2 log(t), we recover the original Lagrangian in Eq. (1) and O(e−β(t)) = O(t−2), as derived in Su et al. (2016).
Impact of the variational formulation. The variational formulation in Wibisono et al. (2016) has had a considerable impact on the recent developments in the theory of accelerated methods. Indeed, this approach can be used to design and analyze new accelerated algorithms. For instance, Xu et al. (2018) used the Lagrangian mechanics formalism to derive a novel simpliﬁed variant of accelerated stochastic mirror descent. Similarly, França et al. (2021), Muehlebach and Jordan (2021) used the dual Hamiltonian formalism to study the link between symplectic integration of dissipative
ODEs and acceleration. Due to its rising importance in the ﬁeld of optimization, the topic was also presented by Prof. M. I. Jordan as a plenary lecture at the International Congress of Mathematicians in 2018 (Jordan, 2018), centered around the question “what is the optimal way to optimize?”.
Imprecise implications of the variational formulation. While the Lagrangian formalism has been inspiring and successful for algorithm design and analysis, its precise implications for the geometry and the path of accelerated solutions have not been examined in a mathematically rigorous way (to the best of our knowledge). In Jordan (2018) it is hinted that, since Nesterov’s method solves the Euler-Lagrange equations, it minimizes the action functional (cid:82) t2
Lα,β,γ(Y, ˙Y , t)dt over the t1 space of curves by the minimum action principle of classical mechanics (Arnol’d, 2013). This claim4 is inaccurate. Indeed, the term minimum action principle is misleading5: solving Euler-Lagrange 4Paragraph before Eq. (9) in Jordan (2018): “[...] we use standard calculus of variations to obtain a differential equation whose solution is the path that optimizes the time-integrated Bregman Lagrangian”. 5From Section 36.2 in Gelfand and Fomin (2000): “The principle of least action is widely used [...]. However, in a certain sense the principle is not quite true [...]. We shall henceforth replace the principle of least action by the principle of stationary action. In other words, the actual trajectory of a given mechanical system will not be required to minimize the action but only to cause its ﬁrst variation to vanish.” 2
Figure 1: Optimization of f (x) = x2/2 using AGD-ODE. Peturbations (vanishing at extrema) are added to the
AGD-ODE solution: depending on the perturbation kind (i.e. direction in space of curves), the local behavior is either a max or a min. Hence, Nesterov’s path can be a saddle point for the action (formally shown in Sec. 3.1). only makes the action stationary (necessary condition: vanishing ﬁrst-order derivative), but does not guarantee minimality — this only holds in physics for very special cases6, which do not include even simple mechanical systems like the pendulum (proof in Section 36.2 of Gelfand and Fomin (2000)). Indeed, from a theoretical perspective, the claim requires computing the second variation along Nesterov’s path. Quite surprisingly, even though many papers are dedicated to the variational formulation (Wibisono et al., 2016; Jordan, 2018; Casgrain, 2019; Duruisseaux and Leok, 2021), to the best of our knowledge there is no work which provides an in-depth rigorous study of the action relative to Bregman Lagrangian and that characterizes minimality of Nesterov in the space of curves.
Our contributions.
Intrigued by the non-trivial open question of minimality of Nesterov’s path and by the enigmatic geometry of accelerated ﬂows, in this paper, we examine the properties of accelerated gradient methods from the perspective of calculus of variations. 1.
In Sec. 3 we study the minimality of classical Nesterov’s ODE (damping 3/t) proposed by Su et al. (2016) on multidimensional quadratic losses. By using Jacobi’s theory for the second variation (summarized in Sec. 2), we ﬁnd that Nesterov’s path is optimal only if the integration interval [t1, t2] is small enough. In contrast, if t2 − t1 > (cid:112)40/β (β is Lipschitz constant for the gradient), Nesterov’s path is actually a saddle point for the action (see Fig. 1).
In Sec. 4 we extend the analysis to the µ-strongly convex setting and thus consider a constant damping α. We show that, for extremely overdamped Nesterov ﬂows (α ≥ 2
β), i.e for highly
µ), Nesterov’s path is always suboptimal parameter tuning (acceleration holds only for α ≈ 2
√ a minimizer for the action. In contrast, we show that for α < 2
β (acceleration setting), if t2 − t1 > 2π/ 4β − α, Nesterov’s path is again a saddle point for the action.
In Sec. 5 we discuss the implications of our results for the theory of accelerated methods and propose a few interesting directions for future research. 2. 3.
√
√
√
We start by recalling some deﬁnitions and results from calculus of variations, which we adapt from classical textbooks (Landau and Lifshitz, 1976; Arnol’d, 2013; Gelfand and Fomin, 2000). 2