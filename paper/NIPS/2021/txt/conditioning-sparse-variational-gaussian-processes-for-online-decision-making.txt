Abstract
O
With a principled representation of uncertainty and closed form posterior updates,
Gaussian processes (GPs) are a natural choice for online decision making. However, (n2) computations for n training
Gaussian processes typically require at least points, limiting their general applicability. Stochastic variational Gaussian pro-cesses (SVGPs) can provide scalable inference for a dataset of ﬁxed size, but are difﬁcult to efﬁciently condition on new data. We propose online variational conditioning (OVC), a procedure for efﬁciently conditioning SVGPs in an online setting that does not require re-training through the evidence lower bound with the addition of new data. OVC enables the pairing of SVGPs with advanced look-ahead acquisition functions for black-box optimization, even with non-Gaussian likelihoods. We show OVC provides compelling performance in a range of applica-tions including active learning of malaria incidence, and reinforcement learning on
MuJoCo simulated robotic control tasks. 1

Introduction
Intelligent systems should be able to quickly and efﬁciently adapt to new data, adjusting their prior beliefs in response to the most recent events. These characteristics are desirable whether the system in question is controlling the actuators of a robot, tuning the power output of a laser, or monitoring the changing preferences of users on an online platform. What these applications share in common is a constant stream of new information. In this paper, we are interested in efﬁcient conditioning, meaning that we wish to efﬁciently update a posterior distribution after receiving new data.
The ability of Gaussian process (GP) regression models to condition on new data in closed form has made them a popular choice for Bayesian optimization (BO), active learning, and control [24]. All of these settings share similar characteristics: there is an “outer loop”, where new data is acquired from the real world (e.g. an expensive simulator), interleaved with an “inner loop”, which chooses where to collect data. In BO, for example, the “inner loop” is the optimization of an acquisition function evaluated using a surrogate model of the true objective. Simple acquisition functions, e.g. expected improvement (EI), consider only the current state of the surrogate, while more sophisticated acquisition functions “look ahead” to consider the effect of hypothetical observations on future surrogate states. One such acquisition function, batch knowledge gradient (qKG), deﬁnes the one-step
Bayes-optimal data batch as the batch that maximizes the expected surrogate maximum after the batch has been acquired [2, 84]. Advanced acquisition functions like qKG require the surrogate to have both efﬁcient posterior sampling and efﬁcient conditioning on new data.
GP regression has two major limitations that have prevented its large scale deployment for online decision-making. First, the computational and memory consumption of exact GPs grows at least quadratically with the amount of data [25, 65], generally limiting their usage to BO problems with fewer than 1, 000 function evaluations [24, 2, 79]. Second, they are limited to applications that have continuous real-valued responses, enabling modelling with solely a Gaussian likelihood. Stochastic 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
(a) Exact GP (b) SVGP + OVC (c) SVGP + OVC volatility model
Figure 1: An exact GP updates its predictive distribution after conditioning on new data points (a, moving from top row to bottom row). With OVC, we can condition SVGPs on both Gaussian responses (b) and non-Gaussian models (c) such as the Gaussian copula volatility model [82]. variational Gaussian processes (SVGPs) [33] have constant computational and memory footprints and are applicable to non-Gaussian likelihoods, but they sacriﬁce closed form expressions for updated posteriors on receiving new data. The SVGP posterior is optimized through the evidence lower bound (ELBO). In the online setting, training with the ELBO has two primary difﬁculties: the need to specify a ﬁxed number of observations to properly scale the ELBO gradient [8] and the need to adjust the inducing points without looking at past data [3, 9]. Thus, we are presented with a choice between the simplicity and analytic tractability of exact GPs and the scalability and ﬂexibility of SVGPs.
In this work, we develop Online Variational Conditioning (OVC) to allow SVGPs to be conditioned on-the-ﬂy, as shown in Figure 1. In the top row of each subplot, we ﬁt the data points shown in red, shifting to another batch of data points in the bottom row. We use an exact GP in Figure 1a, with exact conditioning shown in the bottom panel. The SVGP emulates the exact GP very well before seeing the new data and again after conditioning on the new data by using OVC (Figure 1b). In Figure 1c, we consider a non-Gaussian data model (a Gaussian copula volatility model [82]), where we cannot use exact GPs; the SVGP is still able to update its posterior over the latent volatility in response to new data without “forgetting” old observations. OVC is inspired by a new, simple rederivation of streaming sparse GPs (O-SGPR), originally proposed by Bui et al. [9]. OVC makes SVGPs truly compelling models for online decision-making, augmenting their existing strengths with efﬁcient, closed-form conditioning on new data points. In short, our contributions are:
• The development of OVC, a novel method to condition SVGPs on new data without re-optimizing the variational posterior through an evidence lower bound.
• OVC provides both stable inducing point initialization for SVGPs while enabling the inducing points and variational parameters to update in response to the new data.
• Enabling the effective application of SVGPs, through OVC, in look-ahead acquisitions in
BO for black-box optimization, controlling dynamical systems, and active learning.
Please see Appendix A for discussion of the limitations and broader impacts of our work. Our code is available at https://github.com/wjmaddox/online_vargp. 2 Preliminaries and