Abstract
Recent advances in computationally efﬁcient non-myopic Bayesian optimization offer improved query efﬁciency over traditional myopic methods like expected improvement, with only a modest increase in computational cost. These advances have been largely limited to unconstrained BO methods with only a few exceptions which require heavy computation. For instance, one existing multi-step lookahead constrained BO method [1] relies on computationally expensive unreliable brute-force derivative-free optimization of a Monte Carlo rollout acquisition function.
Methods that use the reparameterization trick for more efﬁcient derivative-based optimization of non-myopic acquisition functions in the unconstrained setting, like sample average approximation and inﬁnitesimal perturbation analysis, do not extend: constraints introduce discontinuities in the sampled acquisition function surface. Moreover, we argue here that being non-myopic is even more important in constrained problems because fear of violating constraints pushes myopic methods away from sampling the boundary between feasible and infeasible regions, slowing the discovery of optimal solutions with tight constraints. In this paper, we propose a computationally efﬁcient two-step lookahead constrained Bayesian optimization acquisition function (2-OPT-C) supporting both sequential and batch settings.
To enable fast acquisition function optimization, we develop a novel likelihood-ratio-based unbiased estimator of the gradient of the two-step optimal acquisition function that does not use the reparameterization trick. In numerical experiments, 2-OPT-C typically improves query efﬁciency by 2x or more over previous methods, and in some cases by 10x or more. 1

Introduction
We consider constrained optimization of a continuous black-box function f under continuous black-box constraints gi, minx∈A f (x) subject to gi(x) ≤ 0, i = 1, . . . , I, within the compact design space
A ⊆ Rd. We suppose both f (x) and gi(x) are derivative-free, time-consuming-to-evaluate and also noise-free. Such problems arise, for example, in tuning hyperparameters of machine learning models subject to runtime or fairness constraints and policy optimization in reinforcement learning with safety constraints. For instance, neural networks deployed on mobile phones must be accurate but may also have limited computation available while needing to respond to users in real time, creating a constraint on how long the model takes to predict at test time [2]. Another example, from [3], is predicting recidivism risk in the criminal justice system with a fairness constraint ensuring that false positive rates are equal across racial and ethnic groups. Other applications arise in drug discovery [4] and aircraft design [5].
Bayesian optimization (BO) has proven successful at solving black-box optimization problems with expensive objectives [6, 7], including constrained problems of the form above. BO methods for constrained problems include constrained expected improvement (EIC as in [8], rediscovered 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
by [9]), constrained BO with stepwise uncertainty reduction [10], predictive entropy search with unknown constraints [11], Alternating Direction Method of Multipliers Bayesian optimization [12], constrained BO with max-value entropy search [13], and augmented Lagrangian techniques that convert constrained problems into a sequence of unconstrained ones [14]. It also includes methods designed speciﬁcally for equality and mixed constraints [15], for batch observations [16] and for problems with high dimensions [17].
All of these existing methods, however, for constrained Bayesian optimization (CBO), are myopic, in the sense that they only consider the immediate improvement in solution quality resulting from a function evaluation and ignore later improvements in solution quality enabled by this evaluation. (Notable exceptions are [1, 18], discussed below.) This greedy behavior may hinder an algorithm’s ability to ﬁnd good solutions efﬁciently. While a recent ﬂurry of activity is addressing this issue for unconstrained problems [19, 20, 21, 22, 23], and the performance improvements provided by these non-myopic algorithms for unconstrained BO suggest that non-myopic BO is promising for constraints as well, substantial non-myopic development has not reached the constrained setting.
Moreover, we argue in detail below that being non-myopic provides even more value in constrained settings than it does in unconstrained ones. To ﬁnd a global optimum under constraints quickly, an algorithm beneﬁts by efﬁciently learning the boundary between the feasible region where the constraint is satisﬁed and the infeasible region where it is not. This is facilitated by sampling points likely to be close to this boundary. Myopic methods, however, such as EIC, undervalue sampling such points because they have a substantial probability of being infeasible and because infeasible points do not directly improve solution quality. Non-myopic methods, on the other hand, understand that learning about the boundary’s location will provide future beneﬁts, allowing them to value this information more appropriately. Localizing the boundary efﬁciently is especially important when the global optimum lies on this boundary, as it often does in constrained optimization when the objective (e.g., the quality of a product) is negatively correlated with a constraint (e.g., the cost required to produce it). We illustrate this via a simple example in §3 and our numerical experiments in §6, which show several-fold improvement over the state-of-the-art in some problems.
One existing non-myopic constrained BO method [1] ﬁrst formulates CBO as a dynamic program (DP). However, this DP is intractable. To mitigate the issue, rollout, an approximate DP technique, is used. Nevertheless, this approach requires an extremely large amount of computation to approximate the multi-step lookahead policy well, especially in problems with more than a few dimensions, in part because it relies on computationally expensive derivative-free optimization , and because its acquisition function is computed via Monte Carlo, further increasing the computation required. This limits its applicability.
The constrained multi-information source BO method recently proposed by [18] is also non-myopic.
It focuses on the multi-information source setting and assumes that the objective and constraint are evaluated in a decoupled fashion. In contrast, our applications of interest often compute the objective and constraints simultaneously. For example, when tuning ML hyperparameters to maximize accuracy subject to a model execution time constraint, the marginal cost of evaluating accuracy is negligible once we evaluate model execution time and incur the training cost. Thus, a method that evaluates the objective and constraints in a decoupled way discards information in such settings.
Our Contributions. We provide a novel non-myopic computationally efﬁcient method for batch
CBO. It substantially outperforms myopic CBO methods. In relation to [1] it requires substantially less computation to decide where to sample. Its query efﬁciency is substantially better in relatively higher-dimensional problems and is at least as good in lower-dimensional ones.
The key to our approach is a new method for optimizing stochastic acquisition functions, leveraging the likelihood ratio method [24]. Standard efﬁcient approaches to optimizing stochastic non-myopic acquisition functions, such as inﬁnitesimal perturbation analysis (IPA) [25] or the one-shot method
[26] (also called sample average approximation or SAA), rely on a sampled acquisition function surface created using the reparameterization trick. In CBO, however, this surface is discontinuous, preventing the efﬁcient use of these methods. Our novel approach is potentially generalizable to other settings where such discontinuities prevent the use of IPA and one-shot optimization.
Our work builds on the unconstrained two-step optimal method [21], overcoming substantial com-putational difﬁculties created by constraints’ inherent discontinuities. These difﬁculties require abandoning the IPA approach used in [21] and instead developing a new likelihood-ratio-based 2
approach. The likelihood ratio method that we use here to estimate the gradient of the acquisition function relies on a change of measure of the same type used within importance sampling. [21] coincidentally also uses importance sampling, but in a fundamentally different way: as a variance reduction technique, and not for gradient estimation. 2