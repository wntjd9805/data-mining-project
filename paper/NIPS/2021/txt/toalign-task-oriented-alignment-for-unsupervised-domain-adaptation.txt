Abstract 
Unsupervised domain adaptive classifcation intends to improve the classifcation  performance on unlabeled target domain. To alleviate the adverse effect of domain  shift, many approaches align the source and target domains in the feature space. 
However, a feature is usually taken as a whole for alignment without explicitly  making domain alignment proactively serve the classifcation task, leading to sub-optimal solution. In this paper, we propose an effective Task-oriented Alignment  (ToAlign) for unsupervised domain adaptation (UDA). We study what features  should be aligned across domains and propose to make the domain alignment  proactively serve classifcation by performing feature decomposition and alignment  under the guidance of the prior knowledge induced from the classifcation task  itself.  Particularly, we explicitly decompose a feature in the source domain into  a task-related/discriminative feature that should be aligned, and a task-irrelevant  feature that should be avoided/ignored, based on the classifcation meta-knowledge. 
Extensive experimental results on various benchmarks (e.g., Offce-Home, Visda-2017, and DomainNet) under different domain adaptation settings demonstrate the  effectiveness of ToAlign which helps achieve the state-of-the-art performance. The  code is publicly available at https://github.com/microsoft/UDA.  1

Introduction 
Convolutional Neural Networks (CNNs) have made extraordinary progress in various computer vision  tasks, with image classifcation as a most representative one. The trained models generally perform  well on the testing data which shares similar data distribution to that of the training data. However, in  many practical scenarios, drastic performance degradation is observed when applying such trained  models to new domains with domain shift [57], where the data distributions between the training and  testing domains are different. Fine-tuning on labeled target data is a direct solution but is costly due  to the requirement of target sample annotations. In contrast, unsupervised domain adaptation (UDA)  requires only the labeled source data and unlabeled target data to enhance the model’s performance  on the target domain, which has attracted increasing interest in both academia [3, 2, 72, 58, 25, 31]  and industry [63, 27]. 
There has been a large spectrum of UDA methods.  Supported by the theoretical analysis [3], the  overwhelming majority of methods tend to align the distributions of source and target domains. 
A line of works [6, 67, 43, 54, 55] explicitly align the distributions based on domain discrepancy  measurements, e.g., Maximum Mean Discrepancy (MMD) [6].  Another line of alignment-based 
UDAs borrow ideas from Generative Adversarial Networks [19] and use domain adversarial training 
∗This work was done when Guoqiang Wei was an intern at MSRA. 
†Corresponding author.  35th Conference on Neural Information Processing Systems (NeurIPS 2021). 
Figure 1: Illustration of adversarial learning based (a) Baseline and (b) our proposed ToAlign. 
D and C denote domain discriminator and image classifer respectively. (a) Baseline (e.g., DANN 
[18]) directly aligns the target feature f t  with the holistic source feature f s . Domain alignment and  image classifcation tasks are optimized in parallel.  (b) Our proposed ToAlign makes the domain  alignment proactively serve the classifcation task, where target feature f t  is aligned with source  task-discriminative "positive" feature f s  which is obtained under the guidance of meta-knowledge  induced from the classifcation task.  p denotes Hadamard product.  to learn domain-aligned/invariant features, which dominate in the top performance methods. In the  seminal work Domain Adversarial Neural Network (DANN) [17, 18], a domain discriminator is  trained to distinguish the target features from source features while a feature extractor (generator) is  trained to generate domain-invariant features to fool this discriminator. Following DANN, a plethora  of variants have been proposed [58, 40, 51, 11, 50, 61, 38, 41, 14, 10, 64]. 
It is noteworthy that the goal of alignment in UDA is to alleviate the adverse effect of domain shift to  improve the classifcation performance on unlabeled target data. Even though impressive progress has  been made, there is a common intrinsic limitation, i.e., alignment is still not deliberately designed  to dedicatedly/proactively serve the fnal image classifcation task.  In many previous UDAs, as  shown in Figure 1 (a), the alignment task is in parallel with the ultimate classifcation task.  The  assumption is that learning domain-invariant features (via alignment) reduces the domain gap and thus  makes the image classifer trained on source readily applicable to target [3]. However, with alignment  treated as a parallel task, there is a lack of mechanism to make it explicitly assist classifcation, where  the alignment may contaminate the discriminative features for classifcation [28]. Previous works  (e.g., CDAN [40]) exploit class information (e.g., predicted class probability) as a condition to the  discriminator. MADA [42] implements class-level domain alignment by applying one discriminator  per class.  Their purpose is to provide additional helpful information to the discriminator [40] or  perform class-level alignment [42], but they are still short of explicitly making alignment assist  classifcation. 
Some works move a step forward and investigate what features the networks should align for better  adaptation. [62, 32] focus on transferable local regions, which are selected based on the uncertainty  or entropy of the domain discriminator, for alignment. However, such self-induced feature selection  is still not specifc to the optimization of classifcation task; instead, it is based on the alignment task  itself. There is no guarantee that alignment positively serves the classifcation task. Hsu et al. [23]  carry out object centerness-aware alignment by aligning the center part of the objects to exclude the  background distraction/noise for domain adaptive object detection. However, the feature in object  center position could be task-irrelevant and thus is not suited for alignment. Moreover, regarding such  centerness feature as alignment objective is somewhat ad-hoc, which is still not designed directly  from the perspective of assisting classifcation. 
We pinpoint that the selection of "right" features to achieve task-oriented alignment is important. For  classifcation, the essence is to train the network to extract class-discriminative feature. Similarly, for 
UDA classifcation, it is also desired to assure strong discrimination of the target domain features  without class label supervision. Thus, we intend to align target features to the task-discriminative  source features while ignoring the task-irrelevant ones. Note that for the feature of a source sample, it  contains both task/classifcation-discriminative and task-irrelevant information, because the network  is in general not able to suppress non-discriminative feature responses (e.g., responses unrelated to  2  
Figure 2: Conceptual comparison between (a) previous alignment and (b) our proposed task-oriented  alignment.  {f t} and {f s} denote the sets of target features and source features, respectively.  (a) 
Previous methods take each source feature as a holistic one for alignment with target features. (b) We  decompose each source feature f s  into a task-discriminative positive feature f s  and a task-irrelevant  negative feature f s  and make the target features to be aligned with the positive source features {f s} p  while avoiding aligning with the negative source features {f s}.n  p  n image class or those related to other tasks such as alignment) perfectly [52, 9]. Aligning target features  with task-irrelevant source features would prevent alignment from serving classifcation and lead to  poor adaptation.  Intuitively, for example, image style that is a non-causal factor for classifcation  can be considered as task-irrelevant information and the bias towards such factor in alignment may  hurt the classifcation task. We demonstrate this by conducting experiments where only the source  task-irrelevant features are utilized to align with target i.e., the scheme Baseline+TiAlign in Figure  3. The performance of Baseline+TiAlign (in purple) on target test set drops drastically compared to  the source-only method which dose not incorporate any alignment technique. This corroborates that  aligning with task-irrelevant features is even harmful to the classifcation on target domain. 
Motivated by this, in this paper, we propose an effective UDA method named Task-oriented Alignment  (ToAlign) to make the domain alignment explicitly serve classifcation. We achieve this by performing  feature alignment guided by the meta-knowledge induced from the classifcation task to make the  target features align with task-discriminative source features (i.e., "positive" features), to avoid the  interference from task-irrelevant features (i.e., "negative" features). Figure 2 conceptually illustrates  the comparison between our proposed alignment and previous one.  Particularly, as illustrated in 
Figure 1 (b), to obtain the suitable feature from a source sample for alignment with target samples,  we leverage the classifcation task to guide the extraction/distillation of task-related/discriminative  s , from original feature f s .  Correspondingly, for the domain alignment task, we enforce  feature fp aligning target features with the source positive features by domain adversarial training to achieve  task-oriented alignment. In this way, the domain alignment will better assist the classifcation task. 
We summarize our main contributions as follows: 
•  We pinpoint that the selection of "right" features to achieve task-orientated alignment is important  for adaptation. 
•  We propose an effective UDA approach named ToAlign which enables the alignment to explic-itly serve classifcation.  We decompose a source feature into a task-relevant/discriminative one  and a task-irrelevant one under the guidance of classifcation-meta knowledge for performing  classifcation-oriented alignment, which explicitly guides the network what features should be  aligned. 
Extensive experimental results demonstrate the effectiveness of ToAlign. ToAlign is generic and can  be applied to different adversarial learning based UDAs to enhance their adaption capability, which  helps achieve the state-of-the-art performance with a negligible increase in training complexity and  no increase in inference complexity.  2