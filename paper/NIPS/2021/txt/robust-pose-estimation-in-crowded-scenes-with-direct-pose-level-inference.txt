Abstract
Multi-person pose estimation in crowded scenes is challenging because overlapping and occlusions make it difﬁcult to detect person bounding boxes and infer pose cues from individual keypoints. To address those issues, this paper proposes a direct pose-level inference strategy that is free of bounding box detection and key-point grouping. Instead of inferring individual keypoints, the Pose-level Inference
Network (PINet) directly infers the complete pose cues for a person from his/her visible body parts. PINet ﬁrst applies the Part-based Pose Generation (PPG) to infer multiple coarse poses for each person from his/her body parts. Those coarse poses are reﬁned by the Pose Reﬁnement module through incorporating pose priors, and ﬁnally are fused in the Pose Fusion module. PINet relies on discriminative body parts to differentiate overlapped persons, and applies visual body cues to infer the global pose cues. Experiments on several crowded scenes pose estimation benchmarks demonstrate the superiority of PINet. For instance, it achieves 59.8%
AP on the OCHuman dataset, outperforming the recent works by a large margin†. 1

Introduction
Multi-Person Pose Estimation (MPPE) performs both detection and pose keypoint localization for all persons appearing in an image. Due to its importance in human activity understanding, human-object interaction, human parsing, et al., MPPE has attracted increasing attention in recent years. Current
MPPE research can be summarized into two categories according to their pipelines, i.e. i) top-down methods [5, 18, 29, 25], which detect person bounding boxes and perform pose estimation for each bounding box, and ii) bottom-up methods [1, 20, 13, 17, 9, 7] that ﬁrst detect body keypoints, then assign them into corresponding persons. A more detailed review will be presented in Sec. 2.
The above two lines of research have signiﬁcantly boosted the performance of MPPE. However, performing MPPE is still challenging in crowded scenarios, where occlusions and person overlapping commonly occur. It is difﬁcult to detect accurate bounding boxes due to overlapped persons. The commonly used Non-maximum Suppression (NMS) in detection frameworks also tends to suppress dense bounding boxes, leading to many undetected persons. Those issues degrade the accuracy of top-down methods. Person overlapping and occlusions lead to invisible keypoints, making it difﬁcult for bottom-up methods to infer accurate pose cues from individual keypoints. As shown in many works, applying existing MPPE methods in crowded scenes gets inferior performance [10, 22].
As illustated in Fig. 1 (a) and (b), existing works generally suffer from difﬁculties of person detection and keypoint grouping in crowded scenarios. This paper targets to perform MPPE with a new pipeline, which is free of bounding box detection and keypoint grouping. We regard the human pose as an inference objective, and directly infer the complete pose cues, i.e., locations of all body keypoints, for a person from his/her visible body parts. In other words, we rely on discriminative visible body
†Code is available at: https://github.com/kennethwdk/PINet 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
Figure 1: (a) Top-down methods suffer from the difﬁculty of detecting overlapped person in red bounding box; (b) Bottom-up methods are sensitive to keypoint occlusions in red circles, thus can not infer accurate pose cues; (c) The proposed DPLI infers initial pose cues from body parts, e.g., three parts in the ﬁgure. Initial part cues are reﬁned and fused to get the pose cues for the occluded person. parts, e.g., heads, to differentiate overlapped persons. We apply visible part cues and contexts to infer the global pose, including both visible and invisible keypoints. As this pipeline directly infers complete pose cues, we name it as the Direct Pose-Level Inference (DPLI). This idea is also inspired by works that infer invisible cues according to visible ones [24, 22, 30]. For instance, PRNet [24] detects occluded persons according to visible body parts and person bounding box ratio prior.
We implement DPLI with the Pose-level Inference Network (PINet) that progressively infers the occluded person pose from coarse to ﬁne. Due to the lack of visible part annotations, we divide each person into several parts according to settings in Fig. 3 to acquire and exploit visible parts. The
Part-based Pose Generation (PPG) generates initial pose cues from each part. The subsequent Pose
Reﬁnement model employs a dynamic graph convolution to leverage contexts and pose structure prior for the pose reﬁnement. Finally, PINet uses Pose Fusion model to identify pose cues belonging to the same person, and fuse them as the ﬁnal pose estimation.
We test our method on crowded scenes pose estimation benckmarks including OCHuman and
CrowdPose. Experiments results show that, our PINet achieves superior performance compared with recent works. For instance, we achieve 59.8% AP on OCHuman, outperforming the recent
OPEC-Net [22] and DEKR [4] by 30.7% and 7.8%. On CrowdPose, PINet achieves 62.2% AP on the hard test set mostly composed of crowded scenes. On this challenging test set, PINet outperforms the recent DEKR [4] by 4.7% in AP.
Some recent works also detect occluded keypoints from visible ones for pose estimation. OPEC-Net [22] detects occluded keypoints by applying a Graph Convolution Network (GCN) [32] on visible keypoints and contexts. However, OPEC-Net falls into the top-down category because it requires bounding boxes to discriminate persons, thus suffers from the difﬁculty of person detection. To the best of our knowledge, this is an original contribution on the Direct Pose-Level Inference (DPLI) for pose estimation in crowded scenarios, which differs from the previous top-down and bottom-up pipelines. The superior performance shown by extensive experiments validates the effectiveness of our proposed PINet and illustrates potentials of the DPLI pipeline. 2