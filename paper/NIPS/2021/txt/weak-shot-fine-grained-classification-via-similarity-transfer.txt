Abstract
Recognizing ﬁne-grained categories remains a challenging task, due to the sub-tle distinctions among different subordinate categories, which results in the need of abundant annotated samples. To alleviate the data-hungry problem, we con-sider the problem of learning novel categories from web data with the support of a clean set of base categories, which is referred to as weak-shot learning. In this setting, we propose a method called SimTrans to transfer pairwise seman-tic similarity from base categories to novel categories. Speciﬁcally, we ﬁrstly train a similarity net on clean data, and then leverage the transferred similarity to denoise web training data using two simple yet effective strategies. In addi-tion, we apply adversarial loss on similarity net to enhance the transferability of similarity. Comprehensive experiments demonstrate the effectiveness of our weak-shot setting and our SimTrans method. Datasets and codes are available at https://github.com/bcmi/SimTrans-Weak-Shot-Classiﬁcation. 1

Introduction
Deep learning methods have made a signiﬁcant advance on extensive computer vision tasks. A large part of this advance has come from the available large-scale labeled datasets. For ﬁne-grained classiﬁcation, it is more necessary but more expensive to collect large-scale datasets. On the one hand, the subtle differences among ﬁne-grained categories dramatically boost the demand for abun-dant samples. On the other hand, professional knowledge is usually required to annotate images for enormous subcategories belonging to one category. As a consequence, ﬁne-grained classiﬁcation is critically limited by the scarcity of well-labeled training images.
In practice, we often have a set of base categories with sufﬁcient well-labeled data, and the problem is how to learn novel categories with less expense, in which base categories and novel categories have no overlap. Such problem motivates zero-shot learning [19], few-shot learning [6], as well as our setting. To bridge the gap between base (resp., seen) categories and novel (resp., unseen) categories, zero-shot learning requires category-level semantic representation (e.g., word vector [27] or human annotated attributes [19]) for all categories, while few-shot learning requires a few clean examples (e.g., 5, 10) for novel categories. Despite the great success of zero-shot learning and few-shot learning, they have the following drawbacks: 1) Annotating attributes or a few clean samples require expert knowledge, which is not always available; 2) Word vector is free, but much weaker than human annotated attributes [1]. Fortunately, large-scale images are freely available from public websites by using category names as queries, which is a promising data source to complement the learning of novel ﬁne-grained categories without any manual annotation.
∗Corresponding author 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
Figure 1: Comparison among zero-shot learning, few-shot learning, and weak-shot learning. Dif-ferent colors indicate different categories.
Figure 2: We transfer the similarity learnt from base training set to enhance the main classiﬁer learnt on novel training set. The boxes in differ-ent colors denote different categories. The num-bers above the arrows indicate similarities.
Considering the drawbacks of zero/few-shot learning and the accessibility of free web data, we in-tend to learn novel categories by virtue of web data with the support of a clean set of base categories, which is referred to as weak-shot learning as illustrated in Figure 1. Formally, given a set of novel
ﬁne-grained categories which are not associated with any clean training images, we collect web im-ages for novel categories as weak-labeled images and meanwhile leverage the clean images from base ﬁne-grained categories. We refer to the clean (resp., web) image set from base (resp., novel) categories as base (resp., novel) training set. Weak-shot learning is a useful and important setting.
By taking car model classiﬁcation as an example, we already have the dataset CompCars [52] with well-labeled images from base ﬁne-grained categories, but we often need to recognize other ﬁne-grained categories beyond this scope, because there are a huge number of car models and new car models are also continuously emerging. In this case, we could apply our setting to recognize novel
ﬁne-grained categories by collecting the web images for these categories. The closest related work to ours is [31], but they further assumed the reliability of word vectors [27] and the availability of unlabeled test images in the training stage.
In weak-shot setting, the key issue of novel training set is label noise, which will signiﬁcantly de-grade the performance of learnt classiﬁer [31, 34]. We explore using base training set to denoise novel training set, although they have disjoint category sets. As illustrated in Figure 2, our proposed framework employs the pairwise semantic similarity to bridge the gap between base categories and novel categories. The pairwise similarity which denotes whether two images belong to the same cat-egory is category-agnostic, so it is highly transferable across category sets even if they are disjoint.
Meanwhile, the pairwise similarity can be easily learnt from limited data, indicating that a small set of already annotated images could help learn extensive novel categories (see Section 5.3). Analo-gously, some methods [3] for few-shot learning transferred similarity from base categories to novel categories, which is directly used for classiﬁcation. In contrast, we transfer the pairwise similarity to alleviate the label noise issue of web data. For learning from web data, some works [38, 11] also attempted to denoise by similarity. Nevertheless, their similarities are derived from noisy samples, and likely to be corrupted due to noise overﬁtting [17].
Speciﬁcally, our framework consists of two training phases. Firstly, we train a similarity net (Sim-Net) [54] on base training set, which takes in two images and outputs the semantic similarity. Sec-ondly, we apply the trained SimNet to obtain the semantic similarities among web images. In this way, the similarity is transferred from base categories to novel categories. Based on the transferred similarities, we design two simple yet effective methods to assist in learning the main classiﬁer on novel training set. 1) Sample weighting (i.e., assign small weights to the images dissimilar to others) reduces the impact of outliers (web images with incorrect labels) and thus alleviates the problem of noise overﬁtting. 2) Graph regularization (i.e., pull close the features of semantically similar samples [60]) prevents the feature space from being disturbed by noisy labels. In addition, we pro-pose to apply adversarial loss [9] on SimNet to make it indistinguishable for base categories and novel categories, so that the transferability of similarity is enhanced. Since the key of our method is similarity transfer, we name our method SimTrans. We conduct extensive experiments on three ﬁne-grained datasets to demonstrate that the pairwise similarity is highly transferable and dramatically 2
beneﬁts learning from web data, even when the category sets are disjoint. Although the focus of this paper is ﬁne-grained classiﬁcation, we also explore the effectiveness of our setting and method on a coarse-grained dataset ImageNet [5]. We summarize our contributions as
• We propose to use transferred similarity to denoise web training data in weak-shot classiﬁ-cation task, which has never been explored before.
• We propose two simple yet effective methods using transferred similarity to tackle label noise: sample weighting and graph regularization.
• One minor contribution is applying adversarial loss to similarity net to enhance the trans-ferability of similarity.
• Extensive experiments on four datasets demonstrate the practicality of our weak-shot set-ting and the effectiveness of our SimTrans method. 2