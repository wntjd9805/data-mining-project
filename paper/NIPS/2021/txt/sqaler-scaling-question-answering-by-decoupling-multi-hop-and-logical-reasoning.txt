Abstract
State-of-the-art approaches to reasoning and question answering over knowledge graphs (KGs) usually scale with the number of edges and can only be applied effectively on small instance-dependent subgraphs. In this paper, we address this issue by showing that multi-hop and more complex logical reasoning can be accom-plished separately without losing expressive power. Motivated by this insight, we propose an approach to multi-hop reasoning that scales linearly with the number of relation types in the graph, which is usually significantly smaller than the number of edges or nodes. This produces a set of candidate solutions that can be prov-ably refined to recover the solution to the original problem. Our experiments on knowledge-based question answering show that our approach solves the multi-hop
MetaQA dataset, achieves a new state-of-the-art on the more challenging WebQues-tionsSP, is orders of magnitude more scalable than competitive approaches, and can achieve compositional generalization out of the training distribution. 1

Introduction
Reasoning, namely the ability to infer conclusions and draw predictions based on existing knowledge, is a hallmark of human intelligence. Infusing the same ability into machine learning models has been a major challenge [34, 29] and has historically required complex systems made of several hand-crafted or learned components [47, 19]. Recently, the paradigm has shifted to deep learning approaches [43, 42], where neural networks are used to reason over structured knowledge or a text corpus. In this work, we assume that the source of knowledge is a structured knowledge graph (KG) and we tackle the problem of knowledge-based question answering (KBQA), namely finding answers to natural language queries involving multi-hop and logical reasoning over the KG.
Answering queries over a knowledge graph involves many challenges, among which scalability is a major issue. Real-world KGs often contain millions of nodes and even a 2-hop neighborhood of the entities mentioned in the query may comprise tens of thousands of nodes. Many state-of-the-art approaches [41, 42, 39] address the challenge of scalability by building small query-dependent subgraphs. To this end, they usually use simple heuristics [41] or, in some cases, iterative procedures based on learned classifiers [42]. This preprocessing step is usually needed because each forward pass in end-to-end neural networks for KBQA scales at least linearly with the number of edges in the subgraph. Training neural networks involves repeated evaluation, which renders even a linear complexity impractical for graphs of more than a few tens thousands of nodes.
In order to address this issue, we introduce a novel approach called SQALER (Scaling Question
Answering by Leveraging Edge Relations). The method first learns a model that generates a set of candidate answers (entities in the KG) by multi-hop reasoning: the candidate solutions are obtained by starting from the set of entities mentioned in the question and seeking those that provide an answer by chained relational following operations. We refer to this module as the relation-level model. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
We show that this multi-hop reasoning step can be done efficiently and provably generates a set of candidates including all the actual answers to the original question. SQALER then uses a second-stage edge-level model that recovers the real answers by performing logical reasoning on a subgraph in the vicinity of the candidate solutions. A visual summary of our approach is depicted in Figure 1.
The main contributions and takeaway messages of this work are the following: 1. KBQA can be addressed by first performing multi-hop reasoning on the KG and then refining the result with more sophisticated logical reasoning without losing expressive power (we will elaborate this claim in more details in Section 2.3). 2. Multi-hop reasoning can be accomplished efficiently with a method that scales linearly with the number of relation types in the KG, which are usually significantly fewer than the number of facts or entities.
In the remainder of the paper, we first provide an extensive overview of our approach and a theoretical analysis of the expressive power and the computational complexity of SQALER. Our experimental results show that SQALER achieves better reasoning performance than state-of-the-art approaches, generalizes compositionally out of the training distribution, and scales to the size of real-world knowledge graphs with millions of entities. 2 Scaling KBQA with relation and edge-level reasoning
This section provides a detailed description of our approach. We start by defining the problem formally and giving an intuitive overview of SQALER. Then, we discuss the approach in more details and we analyze its computational complexity and expressive power r−→ Vj if Vj = {vj ∈ V | vi
Problem statement. We denote a knowledge graph as G = (V, R, E), where v ∈ V represents an entity or node in G, r ∈ R is a relation type, and we write v r−→ v′ to denote an edge in E labeled with relation type r ∈ R between two entities v, v′ ∈ V. We extend the same notation to sets of nodes r−→ vj, vi ∈ Vi}. Given a knowledge graph G = (V, R, E) by writing Vi and a natural language question Q, expressed as a sequence of tokens Q = (q1, q2, . . . , q|Q|), in knowledge-based question answering the objective is to identify a set of nodes AQ ⊆ V representing the correct answers to Q. Following previous work [41, 42, 43], we assume that the set of entities mentioned in the question VQ ⊆ V is given. These nodes are also called the anchor nodes of the question and in practice are commonly obtained using an entity-linking module.
Overview. KBQA can be cast as an entity seeking problem on G by translating Q into a set of nodes
VQ ⊆ V (the starting points of the search) and seeking for nodes that provide an answer [41, 42, 43].
Attempting to find AQ directly on G is prohibitive in practice, as even the most efficient graph-based neural networks generally scale at least linearly with the number of edges. Our approach mitigates this issue by breaking the problem in two subproblems. (a) We first utilize a relation-level model ϕ to obtain a set of candidate answers ˜AQ, such that
AQ ⊆ ˜AQ. We refer to ϕ as “relation-level” because, as we will see, it operates on the coalesced graph, a simplified representation of G, where edges of the same relation type are coalesced. The coalesced graph is constructed before training and incurs a one-time linear cost. By exploiting it during training, the relation-level model scales with the number of (distinct) relation types in the KG, which are usually significantly fewer than the number of edges or entities. (b) The candidate answers are then refined using an edge-level model ψ applied on a subgraph G( ˜AQ) of the original knowledge graph in the vicinity of ˜AQ. We should note that the refining step is not always necessary. Indeed, we found that a relation-level model is sufficient to perfectly solve tasks like multi-hop question answering [50]. Figure 1 shows an overview of our approach. 2.1 Relational coalescing for efficient knowledge seeking
Our approach relies on a relation-level model ϕ that operates as a knowledge seeker in G. The model identifies a node v as a candidate v ∈ ˜AQ based on the sequence of relations that connect it with VQ. 2
Figure 1: Overview of our approach. A relation-level model operates on a coalesced representation of the original KG to generate a set of candidate answers ˜AQ. This approximate solution is then refined by an edge-level model applied on a subgraph of the original KG.
This can be achieved by using a neural network ϕ to predict how likely it is that the correct answer is reached from VQ by following a sequence of relations R.
Reachability. To define how our method works, it will help to formalize the concept of reachability.
Let R = (r1, . . . , r|R|) be a sequence of relations. We say that “v is R-reachable from VQ” if there exists a path P = (v1, . . . , v|R|, v) in G such that: ri−→ vi+1 v1 ∈ VQ and vi i = 1, . . . , |R|. for every
That is, we can reach v by starting from a node in VQ and following a sequence of edges with relation types R. We also denote by reachG(VQ, R) the set of nodes that are R-reachable from VQ: reachG(VQ, R) = {v ∈ V | v is R-reachable from VQ}.
Relational coalescing. Given a knowledge graph G, a question Q, and a set of entity mentions
VQ, we consider a representation of the graph ˜GQ = ( ˜VQ, ˜RQ, ˜EQ), which allows us to efficiently compute sets of nodes that are reachable from VQ. We refer to this representation as the question-dependent coalesced KG, because edges with the same relation type are coalesced, as shown in Figure 1. The nodes of ˜GQ are sets of nodes of G that are reachable from VQ by following any possible r−→ Vj if Vj is the set of sequence of relations originating from VQ. The graph ˜GQ has an edge Vi nodes that are reachable from Vi by following relation r. For convenience, we include a relation type self ∈ ˜RQ to denote self loops. We refer the reader to Appendix A for a formal definition of ˜GQ.
The coalesced graph can be precomputed once as a preprocessing step for each question Q and incurs a one-time linear cost. In practice, however, we do not need to compute and store all the nodes in ˜GQ but only edge labels. This makes learning efficient because each forward/backward pass scales with the number of relation types and does not depend on the number of nodes or edges in the KG.
Knowledge seeking in ˜GQ. The coalesced graph allows us to provide approximate answers to input questions in an efficient manner. Specifically, we seek k ≥ 1 sequences of relations R⋆ i , such that:
AQ ⊆ ˜AQ = k (cid:91) i=1 reachG(VQ, R⋆ i ).
We can achieve this by using a model ϕ that only considers relation sequences originating from VQ.
The model predicts the likelihood ϕ : ˜EQ → [0, 1] of following a certain edge in a relation sequence from VQ to ˜AQ. Then, given R = (r1, . . . , r|R|) and a node in the coalesced graph VQ, we can compute the likelihood of R by multiplying the likelihood of all edges traversed by R in ˜GQ:
P(R | Q, ˜GQ, VQ) ∝
|R| (cid:89) i=1
ϕ(reachG(VQ, R1→i−1), ri, reachG(VQ, R1→i) | Q), 3
where R1→i = (r1, . . . , ri) is the subsequence of R up to the i-th relation. We generate ˜AQ by i | Q, ˜GQ, VQ). This can selecting the top k relation sequences R⋆ be done by an efficient search algorithm, such as beam search starting from VQ. Then, we compute
˜AQ as the union of all target nodes of the selected relation sequences. More details about the knowledge-seeking algorithm are provided in Appendix B. i with maximum likelihood P(R⋆ 2.2 Refining the solution on the original KG
In certain cases, like multi-hop question answering [50], the set of candidate answers ˜AQ may already be a reasonable estimate of AQ. We will substantiate this claim experimentally in Section 4. In general, however, we recover AQ by using an edge-level model ψ applied on a subgraph G( ˜AQ) of
G. Specifically, we construct G( ˜AQ) as the subgraph induced by the set of nodes V( ˜AQ), which includes all nodes visited when following the top-k relation sequences along with their neighbors (see
Figure 1 for an example). Any existing method for KBQA can be used to instantiate ψ by running it on G( ˜AQ) rather than G. We opted to use a Graph Convolutional Network (GCN) conditioned on the input question with the same architecture as in [41]. The edge-level model is constrained to predict an answer among the candidates generated by the relation-level model. 2.3 Analysis of scalability and expressive power
This section provides a scalability analysis of our approach and shows that the relation-level model scales linearly with the number of relation types in the graph. Then, we analyse the expressive power of SQALER and we show the class of supported logical queries.
Computational complexity. As mentioned, we do not evaluate the likelihood ϕ for all edges in
˜GQ, but we generate the most likely relation sequences using a knowledge-seeking procedure based on the beam search algorithm. At any given time step, only the β most likely relation sequences are retained and further explored at the next iteration. Hence, the time complexity required by our max( ˜GQ)), where τmax is the maximum allowed number of decoding time algorithm is O(τmax · β · d+ max( ˜GQ) is bounded by the number steps and d+ of relations in the graph, whereas τmax and β are constant parameters of the algorithm and are usually small. This gives a time complexity of: max( ˜GQ) is the maximum outdegree of ˜GQ. Note that d+
Hence, the knowledge-seeking algorithm scales linearly with the number of relations in the KG. The space complexity is also O(τmax · β · |R|). A more detailed analysis is provided in Appendix B.
O(τmax · β · |R|) = O(|R|).
Expressive power. Given a natural language question Q, we can represent the inferential chain needed to obtain AQ from VQ as a logical query Q on G. As an example, the question in Figure 2, “Who starred in films directed by George Lucas?”, can be represented by the logical query:
Q[V?] = V?.∃V : Directed(George_Lucas, V) ∧ Starred(V, V?). We denote with V? the target variable of the query and we say that v ∈ V satisfies Q if Q[v] = True. A query Q is an existential positive first-order (EPFO) query if it involves the existential quantification (∃), conjunction (∧), and disjunction (∨) [12] of literals corresponding to relations in the KG. Each literal is of the form r(V, V′), where V is either a node in VQ or an existentially quantified bound variable, and V′ is either an existentially quantified bound variable or the target variable. A literal r(V, V′) is satisfied if V r−→ V′, for r ∈ R. Any EPFO query can be represented in disjunctive normal form (DNF)
[15], namely as a disjunction of conjunctions. Note that, we do not consider queries with universal quantification (∀), as we assume that in real-world KGs no entity connects to all the others. Then, the following proposition holds for any knowledge graph and EPFO query.
Proposition 1. Let G = (V, R, E) be a knowledge graph and VQ ⊆ V denote a set of entities in G.
Let Q be a valid existential positive first-order query on G and let n∨ be the number of disjunction operators in the disjunctive normal form of Q. Then, there exist k ≤ n∨ + 1 sequences of relations
R⋆ i ∈ R∗ such that:
AQ ⊆ k (cid:91) i=1 reachG(VQ, R⋆ i ), 4
Figure 2: Architecture of the SQALER relation-level model. A question encoder is used to obtain a representation of tokens in the input natural language question. Then a graph-guided decoder is applied to obtain the likelihood of output relation sequences. The decoder is constrained to only attend to valid relations according to the structure of the coalesced KG. where AQ = {v ∈ V | Q[v] = True} is the denotation set of Q, namely the entities satisfying Q.
This shows that sampling n∨ + 1 sequences of relations allows generating a set of candidate answers
˜AQ that does not miss any of the real answers AQ. Then, assuming that the edge-level model ψ can recover AQ from ˜AQ, our approach can be used to answer any EPFO query on G. More details about the expressive power of SQALER and the proof of Proposition 1 are provided in Appendix C. 3 Architecture of the relation-level model
For the relation-level model ϕ, we propose an auto-encoder, where the the decoder is constrained to follow sequences of relations in the coalesced representation ˜GQ. We train the network with weak supervision, assuming that a sequence of relations is correct if it reaches a set of candidate answers
˜AQ that is the smallest reachable superset of the AQ. We found it useful to pretrain the model in order to infuse knowledge from the KG. In this case, we train the model to predict a path in the KG, given the representations of the source and target nodes. More details about training strategies are given in Appendix D.
The architecture of the model (see Figure 2) includes three main components: a question encoder, a relation encoder and a graph-guided decoder. We explain each one below.
Question encoder. The encoder receives as input a natural language question, which comprises a sequence of tokens Q = (q1, q2, . . . , q|Q|). The question is encoded using a pre-trained BERT
[18] model and processed with the same positional encoding technique used in [44]. The resulting embeddings are then fed into nl = 3 transformer encoder layers [44]. This results in a matrix
Q ∈ R|Q|+1×dmodel , where the first row vector is an overall representation of the whole query Q (derived from the embedding of the [CLS] token introduced by BERT) and each remaining row represents the final dmodel-dimensional encoding of a token in the input question.
Relation encoder. The relation encoder produces a representation r ∈ Rdmodel for each relation type r ∈ R. We decided to encode relations based on their surface form, with the same pre-trained
BERT model used in the question encoder. In this case, only the embedding of the [CLS] token is used in order to get the final representation r of each relation type r ∈ R. At inference time, or in 5
case the BERT model is not fine-tuned, the embeddings of the relations can be precomputed as a preprocessing step to improve the efficiency of the approach.
Graph-guided decoder. The decoder’s job is to predict a sequence of relations leading from VQ to
˜AQ in ˜GQ. At any time step t, it receives as input a sequence of relations Rt = (self, r1, . . . , rt−1) and predicts the next relation rt (self is used as a special token to denote the start of decoding). Note that the input sequence uniquely determines a node Vt in the graph ˜GQ, namely the node reachable from VQ by following Rt. The decoder thus selects rt by choosing amongst the outgoing edges
˜Et of Vt. We use the same number of layers nl both for the question encoder and the decoder. Let t−1]⊤ ∈ Rt×dmodel denote the hidden state of the l-th layer of the decoder preceding 0, . . . , xl
Xl time step t. Note that X0 t is the representation of the sequence Rt, obtained by using the relation encoder described above and the same positional encoding technique used in the question encoder.
For each decoder layer, we perform self-attention over the target sequence Xl t = [xl t by computing: t = Attention(xl
¯xl t, Xl t, Xl t), where Attention is a function that performs multi-head scaled dot-product attention [44] with skip connections and layer normalization [4]. The above step allows each relation in the decoded sequence to attend to all the others predicted up to time step t. We then let the result attend to the question as:
¯xQ,l t = Attention(¯xl t, Q, Q).
This is done in order to update the current state of the decoder based on the input question. Next, let Rt ∈ R| ˜Et|×dmodel denote the encoding of the relations labeling all edges in ˜Et. We constrain the decoded sequence to follow the structure of the graph by attending only to valid relations as follows: t = Attention(¯xQ,l
¯xR,l t
, Rt, Rt).
We get the hidden state of the next layer xl+1 by processing the result with a feed forward network.
The model outputs a categorical distribution ϕ(e | Q) ∈ [0, 1] over the edges e ∈ ˜Et, by applying a softmax function as follows: t
ϕ(Vi r−→ Vj | Q) = exp(r⊤xnl t ) exp(r′⊤xnl t ) r′
−→V ′ j ∈ ˜Et
, (cid:80)
V ′ i where xnl t of relations r and r′ respectively. is the output of the final layer of the decoder, whereas r and r′ denote the representations 4 Experiments
This section presents an evaluation of our approach with respect to both reasoning performance and scalability. We first show that SQALER reaches state-of-the-art results on popular KBQA benchmarks and can generalize compositionally out of the training distribution. Then, we demonstrate the scalability of our approach on KGs with millions of nodes. We refer the reader to Appendix E for more details about the experiments. 4.1 Experimental setup
Datasets. We evaluate the reasoning performance of our approach on MetaQA [50] and WebQues-tionsSP [49]. MetaQA includes multi-hop questions over the WikiMovies KB [35] and we consider both 2-hop (MetaQA 2) and 3-hop (MetaQA 3) queries. WebQuestionsSP (WebQSP) comprises more complex questions answerable over a subset of Freebase [21, 7], a large KG with millions of entities. We further assess the compositional generalization ability of SQALER on the Compositional
Freebase Questions (CFQ) dataset [28]. Each question in CFQ is obtained by composing primitive elements (atoms). Whereas the training and test distribution of atoms are similar, the test set contains different compounds, namely new ways of composing these atoms. CFQ comprises three dataset splits (MCD1, MCD2, and MCD3), with maximal compound divergence (MCD) between the training and test distributions. We refer the reader to Appendix E.1 for an extensive description of the datasets. 6
In our experiments on MetaQA and WebQuestionsSP, we assess the per-Evaluation protocol. formance of three variants of our approach: (a) a version that only makes use of the relation-level model without the refinement step (SQALER – Unrefined), (b) a model that utilizes a key-value memory network to identify the correct answers from the candidates (SQALER – KV-MemNN), and (c) a model that uses a GNN architecture for the refinement step (SQALER – GNN), as explained in
Section 2.2. Following previous work [41, 42, 43, 39], we evaluate the models based on the Hits@1 metric. On the CFQ dataset, we evaluate the accuracy of the refined model with the GNN based on whether it predicts exactly the same answers given by the corresponding SPARQL query. 4.2 Main results
KBQA Performance. Table 1 summarizes the results of our experiments on the two benchmark datasets. For the two multi-hop MetaQA datasets, we achieve state-of-the-art performance by only using the relation-level model of SQALER. As shown in Table 1, SQALER outperforms all the baselines on MetaQA 3, demonstrating the ability of our approach to perform multi-hop reasoning over a KG. For the more complex questions in the WebQuestionsSP dataset, the unrefined SQALER model achieves better performance than all but one (EmQL) of the baselines. To achieve such performance, however, EmQL creates a custom set of logical operations tailored towards the specifics of the target KG and the kind of questions in the dataset, while our approach is agnostic with respect to such details. Combining the relation and edge-level models improves the performance on WebQSP.
In particular, SQALER – GNN outperforms all considered baselines on the three datasets.
Table 1: Hits@1 on MetaQA and WebQuestionsSP
MetaQA 2 MetaQA 3 WebQSP
KV-MemNN [35]
GRAFT-Net [41]
ReifKB + mask [10]
PullNet [42]
EmbedKGQA [39]
EmQL [43]
SQALER – Unrefined
SQALER – KV-MemNN
SQALER – GNN 82.7 94.8 95.4 99.9 98.8 98.6 99.9 99.9 99.9 48.9 77.7 79.7 91.4 94.8 99.1 99.9 99.9 99.9 46.7 70.3 52.7 69.7 66.6 75.5 70.6 72.1 76.1
Compositional generalization.
In order to evaluate the compositional generalization ability of
SQALER, we performed additional experiments on the CFQ dataset. Table 2 shows the accuracy on the three MCD splits and the mean accuracy (MCD-mean) in comparison to the other methods in the leaderboard. Note that the other approaches address a semantic parsing task and require additional supervision, as they are trained to predict the target query. On the other hand, we aim to predict directly the set of answers to the input question. The experiment shows that SQALER is able to achieve compositional generalization with an accuracy comparable to the state-of-the-art model on
CFQ for semantic parsing.
Subgraph extraction. We analyzed the candidate solutions produced by the relation-level model in order to evaluate the suitability of our approach to building small question subgraphs that are likely to contain the answers to a natural language question. For this purpose, we computed the precision and recall of the set of candidate answers with varying number of relation sequences sampled by the relation-level model. Figure 3 shows the top relation sequences predicted by the relation-level model on two questions from the test set of WebQuestionsSP. The precision and recall curves are shown in Figure 4. As expected, on MetaQA the recall is high for all values of k, because selecting the most likely sequence of relations is sufficient to solve the multi-hop question answering task. On
WebQuestionsSP, only 3 sequences of relations are sufficient to obtain a recall of 0.91, and we can improve it to 0.95 by generating still small subgraphs consisting of only 10 sequences of relations. 7
Table 2: Accuracy and 95% confidence interval on the CFQ dataset
MCD1
MCD2
MCD3
MCD-mean
LSTM + Attention [28, 27, 5]
Transformer [28, 44]
Universal Transformer [28, 17]
Evolved Transformer [20, 40]
T5-11B [36, 20]
T5-11B-mod [20, 22]
HPD [23]
SQALER – GNN 0.289 ± 0.018 0.349 ± 0.011 0.374 ± 0.022 0.424 ± 0.010 0.614 ± 0.048 0.616 ± 0.124 0.720 ± 0.075 0.734 ± 0.039 0.050 ± 0.008 0.082 ± 0.003 0.081 ± 0.016 0.093 ± 0.008 0.301 ± 0.022 0.313 ± 0.128 0.661 ± 0.064 0.653 ± 0.040 0.108 ± 0.006 0.106 ± 0.011 0.113 ± 0.003 0.108 ± 0.002 0.312 ± 0.057 0.333 ± 0.023 0.639 ± 0.057 0.627 ± 0.045 0.149 ± 0.011 0.179 ± 0.009 0.189 ± 0.014 0.208 ± 0.007 0.409 ± 0.043 0.421 ± 0.091 0.673 ± 0.041 0.671 ± 0.041
Figure 3: Attention weights given by the relation-level model to the edges of the coalesced graph for two questions in WebQuestionsSP. Thicker and darker edges represent higher attention weights. 4.3 Efficiency and scalability
We analyze the efficiency of our approach on synthetic KBs (as in [9, 10]) and then compare the scalability of different preprocessing methods on the KGs of MetaQA and WebQuestiontsSP. First, we perform experiments on KBs where the relational coalescing has no effect: the outdegree of each node is equal to the number of relation types and all edges originating from a node have different relation labels. We perform two experiments on such KBs. In the first one (Figure 5a), the number of relation types is fixed to |R| = 10 and the number of entities varies from |V| = 102 to |V| = 106. In the second task (Figure 5b), the number of entities is fixed to |V| = 5000 and the number of relations varies from |R| = 1 to |R| = 103. The single answer node is always two-hops away from the entities mentioned in the question. We compare SQALER (unrefined) against a GNN-based approach (GRAFT-Net [41]) and a key-value memory network (KV-MemNN [35]). The approaches are evaluated based on the queries per second at inference time with a mini-batch size of 1. The results show that increasing the number of entities has negligible impact on the performance of SQALER, whereas GRAFT-Net and the key-value memory network are limited to graphs with less than 10k nodes. This shows that, in large KGs like Freebase, the baselines would not be able to handle even a 2-hop neighborhood of the entities mentioned in the question (we refer the reader to Appendix E.5 for more details). Finally, from the results in Figure 5b, we see that the throughput of our approach decreases with the number of relation types. However, in practice, we can leverage the GPU to score the edges of the graph in parallel. This is why we observe only a minor drop in performance when the number of relation types grows from |R| = 1 to |R| = 100.
In order to assess the scalability of the proposed relational coalescing operation, we further compare commonly used preprocessing methods on the KG of WebQuestionsSP. We evaluate the time required to extract complete 2-hop neighborhoods of the entities mentioned in the question and the time to perform Personalized Page Rank (PPR) on such graphs. The results are shown in Figure 5c. Note that, at inference time, we can perform the coalescing only on the portion of the graph explored by the model, which makes SQALER much more efficient. At training time, the preprocessing is comparable to the 2-hop neighborhood extraction. Finally, Figure 5d shows the performance of the models with the respective preprocessing step at inference time on synthetic KBs with growing number of edges. 8
Figure 4: Precision and recall of the top k sequences of relations on MetaQA 2 (left), MetaQA 3 (center) and WebQSP (right) (a) (b) (c) (d)
Figure 5: Inference time in queries/sec on synthetic KBs with increasing number of entities (a) and relation types (b). Time required by different preprocessing steps on the KG of WebQuestionsSP and
MetaQA (c). Complete inference and preprocessing time on synthetic KBs with increasing number of edges (d). We set the queries/sec to 0 when the model runs out-of-memory (OOM). 4.4
Incomplete knowledge graphs
In order to evaluate the capability of our approach to cope with missing information in the knowledge graph, we performed two additional experiments. In the first experiment, we evaluated our approach (the SQALER – GNN variant) on WebQuestionsSP using incomplete knowledge graphs with only 50% of the original edges (50% KG). Then, following previous work [41, 42], we tried to mitigate the missing information using additional sources of external knowledge. In particular, for each question, we used the same text documents extracted from Wikipedia as done by Sun et al. [41] (50% KG + Text). In this experiment, the relation-level model is unaware of the additional source of knowledge, but the information from the text documents is infused into the edge-level GNN with the same strategy used in GRAFT-Net [41] (note that this makes the edge-level GNN-based model essentially equivalent to the full version of GRAFT-Net, with both KG and text support). We compare our approach against GRAFT-Net and PullNet, namely the two baselines designed for open-domain question answering with incomplete KGs and text documents.
The results of the experiments are reported in Table 3. We observe that, despite not being designed for incomplete KGs, SQALER outperforms the baselines on both experimental settings. This is not surprising, as GRAFT-Net relies on a simple heuristic process to construct question subgraphs and
PullNet is constrained to follow the structure of the incomplete graph, because its iterative retrieval process can only expand nodes that are reachable from the set of anchor entities. This means that, in principle, any node retrieved by PullNet’s iterative process can also be reached by SQALER’s relation-level model. Similarly to the baselines, we note only a minor gain in performance when using the text documents as an additional source of information.
Table 3: Hits@1 on WebQuestionsSP with incomplete KGs (50% of the edges) and additional text
GRAFT-Net [41]
PullNet [42]
SQALER – GNN 50% KG 50% KG + Text 49.9 51.9 55.2 48.2 50.3 53.5 9
5