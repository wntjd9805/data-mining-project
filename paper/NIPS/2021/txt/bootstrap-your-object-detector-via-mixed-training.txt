Abstract
We introduce MixTraining, a new training paradigm for object detection that can improve the performance of existing detectors for free. MixTraining enhances data augmentation by utilizing augmentations of different strengths while excluding the strong augmentations of certain training samples that may be detrimental to training. In addition, it addresses localization noise and missing labels in human annotations by incorporating pseudo boxes that can compensate for these errors.
Both of these MixTraining capabilities are made possible through bootstrapping on the detector, which can be used to predict the difﬁculty of training on a strong augmentation, as well as to generate reliable pseudo boxes thanks to the robustness of neural networks to labeling error. MixTraining is found to bring consistent improvements across various detectors on the COCO dataset. In particular, the performance of Faster R-CNN [24] with a ResNet-50 [13] backbone is improved from 41.7 mAP to 44.0 mAP, and the accuracy of Cascade-RCNN [1] with a
Swin-Small [22] backbone is raised from 50.9 mAP to 52.8 mAP. 1

Introduction
Object detection is a fundamental task of computer vision. Its goal is to locate the bounding boxes of objects in an image as well as to classify them. Due to the complexity and diversity of the real world, this problem remains challenging despite the considerable attention it attracts. Most previous works focus on developing better detection frameworks [24, 34, 5, 2, 21, 23, 16] or stronger network architectures [18, 1, 14, 28, 12, 14]. In addition, there are some that study data augmentation strategies [10, 6, 4], label assignment [39, 17], or training losses [19, 25]. In general, the existing works follow a standard training paradigm where the network takes training images that are augmented by a single data augmentation strategy and the human-annotated bounding boxes are simply used as the training targets. We refer to this approach as SiTraining. Few works explore alternative training methods, which have been based on distillation [3, 32, 40] or dynamic adjustment of label assignment criteria and regression loss [35].
In this work, we expand the power of an augmentation strategy and the utility of human-annotated boxes through a new training paradigm for object detection. We observe that suitable magnitudes of an augmentation can vary from image to image, where a strong augmentation of certain images will enrich the training data, but may degrade the data when applied to other images, such as by altering the object appearance to become less compatible with the object class. Based on this, we present a mixed augmentation strategy that utilizes both strong and normal augmentations in a manner that takes advantage of strong augmentations only on images where they are expected to be helpful.
∗Equal contribution. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
Figure 1: The illustration of our training paradigm MixTraining. It integrates mixed augmentation and mixed training targets. In the bottom two branches, normally augmented images and strongly augmented images are passed to the detectors for training. In the top branch, an EMA detector is used to generate pseudo boxes and predict the foreground scores of the training targets. Only targets with a score higher than 0.9 will be used for training strongly augmented images.
We additionally note that human annotation of bounding boxes is often noisy or incomplete, which can be harmful to training. To alleviate this issue, we introduce the use of mixed training targets, composed of both human-annotated ground-truths and pseudo boxes that are intended to compensate for annotation errors.
The pseudo boxes are determined by bootstrapping on the detector. Because of the robustness of neural networks to label noise, the online detector can produce pseudo boxes that capture object locations missed or inaccurately localized by human labelers. We therefore utilize these pseudo boxes in conjunction with the human-annotated boxes to improve detection. Furthermore, the online detector can predict whether a strong augmentation of a training image would help training. This is accomplished by using the online detector to compute the foreground score of a training target. A high score indicates that the target can be easily trained on, while those with a low score are discarded from training.
Our training paradigm, called Mix-Training, integrates the mixed aug-mentation and mixed training targets as illustrated in Figure 1.
In the bottom two branches, normally aug-mented and strongly augmented im-ages are passed to the detector for training. In the top branch, an expo-nential moving average (EMA) model of the online detector is used to gen-erate pseudo boxes and to predict the foreground scores of the training tar-gets. Only for training targets with a high score will their strong augmenta-tions be included for training. As the detector progresses through training, the mixed augmentation and mixed training targets become increasingly better via bootstrapping.
Figure 2: Illustration of annotation noise in COCO2017. (left) The red box is an inaccurate annotation, and the correct localization is the green box. (right) Red boxes are original annotations, and the green box is the missing label.
MixTraining is a general training framework for object detection that can enhance existing object detectors without introducing extra computation or model parameters at inference time. Our experi-ments show that MixTraining can appreciably improve the performance of leading object detectors such as Faster R-CNN [24] with a ResNet-50 [13] backbone (from 41.7 mAP to 44.0 mAP) and
Cascade R-CNN [1] with the recently proposed Swin-Transformer [22] backbone (from 50.9 mAP to 52.8 mAP). 2
2