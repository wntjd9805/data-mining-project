Abstraction for Efﬁcient Point Cloud Representation Learning
Guocheng Qian
Hasan Abed Al Kader Hammoud
Guohao Li
Ali Thabet
Bernard Ghanem
King Abdullah University of Science and Technology (KAUST)
{guocheng.qian, hasanabedalkader.hammoud, bernard.ghanem}@kaust.edu.sa https://github.com/guochengqian/ASSANet
Abstract
Access to 3D point cloud representations has been widely facilitated by LiDAR sensors embedded in various mobile devices. This has led to an emerging need for fast and accurate point cloud processing techniques. In this paper, we revisit and dive deeper into PointNet++, one of the most inﬂuential yet under-explored networks, and develop faster and more accurate variants of the model. We ﬁrst present a novel Separable Set Abstraction (SA) module that disentangles the vanilla SA module used in PointNet++ into two separate learning stages: (1) learning channel correlation and (2) learning spatial correlation. The Separable SA module is signiﬁcantly faster than the vanilla version, yet it achieves comparable performance. We then introduce a new Anisotropic Reduction function into our
Separable SA module and propose an Anisotropic Separable SA (ASSA) module that substantially increases the network’s accuracy. We later replace the vanilla
SA modules in PointNet++ with the proposed ASSA module, and denote the modiﬁed network as ASSANet. Extensive experiments on point cloud classiﬁcation, semantic segmentation, and part segmentation show that ASSANet outperforms
PointNet++ and other methods, achieving much higher accuracy and faster speeds.
In particular, ASSANet outperforms PointNet++ by 7.4 mIoU on S3DIS Area 5, while maintaining 1.6× faster inference speed on a single NVIDIA 2080Ti GPU.
Our scaled ASSANet variant achieves 66.8 mIoU and outperforms KPConv, while being more than 54× faster. 1

Introduction
Among the various 3D object representations, point clouds have been surging in popularity, becoming one of the most fundamental 3D representations. This popularity stems from the increased availability of 3D sensors, like LiDAR, which produce point clouds as their raw output. The growing presence of point cloud data has been accompanied by the development of many 3D deep learning methods
[28, 41, 19, 38, 22]. Even though these methods achieve impressive performance, they are generally computationally expensive (Figure 1). With the integration of LiDAR sensors into hardware-limited devices, such as mobile devices and AR headsets, interest in efﬁcient models for point cloud processing has grown signiﬁcantly. Given the limited computational power of mobile devices and embedded systems, the design of mobile-friendly point cloud-based algorithms should not only focus on providing good accuracy, but also on maintaining high computational efﬁciency.
When processing point cloud data, one can always opt to convert the data into representations that are more accessible to deep learning frameworks. Popular options are multi-view methods [34, 5, 42] and voxel-based methods [6, 47]. Converting to these representations generally requires additional 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
Figure 1: Tradeoffs between accuracy (mIoU on S3DIS Area-5) and inference speed (in-stances/second). Speed is reported as the mean value of 200 runs on a single GTX 2080Ti GPU.
The proposed ASSANet scaled with different widths and depths shown in outperform the state-of-the-art methods in with better accuracies and faster speeds. Refer to Section 5.2 for details. computation and memory, and can lead to geometric information loss [23]. It is therefore more desirable to operate directly on point clouds. To that extent, we are currently witnessing a surge in point-based methods [27, 28, 41, 19, 38, 22]. The ﬁrst of such methods was introduced by Qi et al. through the seminal PointNet [27] architecture. PointNet operates directly on point clouds, without the need for an intermediate representation. Despite its efﬁciency, PointNet merely learns per-point features individually and discards local information, which restrains its performance. As a variant of
PointNet, PointNet++ [28] presents a novel Set Abstraction module that sub-samples the point cloud, groups the neighborhood, extracts local information via a set of multi-layer perceptrons (MLPs), and then aggregates the local information by a reduction layer (i.e. pooling). Figure 1 shows how
PointNet++ outperforms the pioneering PointNet [27] by a large margin. PointNet++ also obtains better accuracy than the graph-based method DeepGCN [19], and does so with a 100× speed gain.
PointNet++ provided a good balance between accuracy and efﬁciency, and was therefore widely utilized in various tasks like normal estimation [8], segmentation [26, 14], and object detection [32].
After PointNet++, graph-based [33, 39, 41, 19], pseudo-grid based [37, 20, 25, 38] and adaptive weight-based [40, 21, 7, 44], became the state-of-the-art in point cloud tasks. As shown in Figure 1, nearly all of these methods improve performance at the cost of speed. In this work, we focus on designing point cloud networks that are both fast and accurate. Inspired by its success, both in terms of the accuracy-speed balance and its wide adoption, we take a deep dive into PointNet++. We conduct extensive analysis of its architectural design (Section 3.1) and latency decomposition (Figure 2). Interestingly, we demonstrate that both its efﬁciency and accuracy can be improved sharply by minimal modiﬁcations to the architecture. These modiﬁcations lead to a new architecture design that is faster and more accurate than currently available point methods (shown in in Figure 1).
Contributions. (1) We demonstrate that the MLPs performed on the neighborhood features in the Set Abstraction (SA) module of PointNet++ reduce the inference speed. We introduce a new separable SA module that processes on point features directly allowing for a signiﬁcant improvement in inference speed. (2) We discover that all operations for processing neighbors in the SA module are isotropic which limits the performance (accuracy wise). We present a novel Anisotropic Reduction layer that treats each neighbor differently. We then insert Anisotropic Reduction into our Separable
SA and propose the Anisotropic Separable Set Abstraction (ASSA) module that greatly increases accuracy. (3) We present ASSANet by replace the vanilla SA in PointNet++ with the proposed ASSA.
ASSANet shows a much higher accuracy and a faster speed compared to PointNet++ and previous methods on various tasks (point cloud classiﬁcation, semantic segmentation, and part segmentation).
We further study two regimes for up-scaling ASSANet. As shown in Figure 1, our scaled ASSANet outperforms the previous state-of-the-art with a much faster inference speed. In particular, scaled
ASSANet achieves better accuracy than the graph-based method DeepGCN [19] with an increase in speed of 294×, the pseudo grid-based method KPConv [38] (54× faster), the adaptive weight-based method PosPool*(S) [22] (9× faster), and the efﬁcient 3D method PVCNN [23] (2× faster). 2