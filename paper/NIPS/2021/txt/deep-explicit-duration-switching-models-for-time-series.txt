Abstract
Many complex time series can be effectively subdivided into distinct regimes that exhibit persistent dynamics. Discovering the switching behavior and the statistical patterns in these regimes is important for understanding the underlying dynam-ical system. We propose the Recurrent Explicit Duration Switching Dynamical
System (RED-SDS), a ﬂexible model that is capable of identifying both state-and time-dependent switching dynamics. State-dependent switching is enabled by a recurrent state-to-switch connection and an explicit duration count variable is used to improve the time-dependent switching behavior. We demonstrate how to perform efﬁcient inference using a hybrid algorithm that approximates the posterior of the continuous states via an inference network and performs exact inference for the discrete switches and counts. The model is trained by maximizing a Monte
Carlo lower bound of the marginal log-likelihood that can be computed efﬁciently as a byproduct of the inference routine. Empirical results on multiple datasets demonstrate that RED-SDS achieves considerable improvement in time series segmentation and competitive forecasting performance against the state of the art. 1

Introduction
Time series forecasting plays a key role in informing industrial and business decisions [17, 24, 8], while segmentation is useful for understanding biological and physical systems [40, 45, 34]. State
Space Models (SSMs) [16] are a powerful tool for such tasks—especially when combined with neural networks [42, 12, 13]—since they provide a principled framework for time series modeling.
One of the most popular SSMs is the Linear Dynamical System (LDS) [5, 43], which models the dynamics of the data using a continuous latent variable, called state, that evolves with Markovian linear transitions. The assumptions of LDS allow for exact inference of the states [27]; however, they are too restrictive for real-world systems that often exhibit piecewise linear or non-linear hidden dynamics with a ﬁnite number of operating modes or regimes. For example, the power consumption of a city may follow different hidden dynamics during weekdays and weekends. Such data are better explained by a Switching Dynamical System (SDS) [1, 21], an SSM with an additional set of latent variables called switches that deﬁne the operating mode active at the current timestep.
Switching events can be classiﬁed into time-dependent or state-dependent [33]. Historically, emphasis was placed on the former, which occurs after a certain amount of time has elapsed in a given regime.
While in a vanilla SDS switch durations follow a geometric distribution, more complex long-term
∗Equal contribution.
†Work done during an internship at Amazon Research. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
temporal patterns can be captured using explicit duration models [40, 9]. As a recent alternative to time-dependency, recurrent state-to-switch connections [35] have been proposed that capture state-dependent switching, i.e., a change that occurs when the state variable enters a region that is governed by a different regime. For added ﬂexibility, these models can be used in conjunction with transition/emission distributions parameterized by neural networks [25, 19, 13, 30]. Recent works, e.g., [13, 30], proposed hybrid inference algorithms that exploit the graphical model structure to perform approximate inference for some latent variables and conditionally exact inference for others.
Despite these advances in repre-sentation and inference, model-ing complex real-world temporal phenomena remains challenging.
For example, state-of-the-art state-dependent models (e.g., [13]) lack the capacity to adequately capture time-dependent switching. Empir-ically, we ﬁnd this hampers their ability to learn parsimonious seg-mentations when faced with com-plex patterns and long-term depen-dencies (see Fig. 1 for an example).
Conversely, time-dependent switching models are “open-loop” and unable to model state-conditional behavioral transitions that are common in many systems, e.g., in autonomous or multi-agent sys-tems [35]. Intuitively, the suitability of the switching model largely depends on the underlying data-generating process; city power consumption may be better modeled via time-dependent switch-ing, whilst the motion of a ball bouncing between two walls is driven by its state. Indeed, complex real-world processes likely involve both types of switching behavior.
Figure 1: Segments (colored bars at the bottom) inferred by a baseline with no Explicit Duration (ED) modeling vs. our RED-SDS for a time series from the dancing bees dataset (top). The baseline struggles to learn long-term temporal patterns, particularly during the “waggle” phase of the bee dance.
Motivated by this gap, we propose the Recurrent Explicit Duration Switching Dynamical System (RED-SDS) that captures both state-dependent and time-dependent switching. RED-SDS combines the recurrent state-to-switch connection with explicit duration models for switches. Notably, RED-SDS allows the incorporation of inductive biases via the hyperparameters of the duration models to better identify long-term temporal patterns. However, this combination also complicates inference, especially when using neural networks to model the underlying probability distributions. To address this technical challenge, we propose a hybrid algorithm that (i) uses an inference network for the continuous latent variables (states) and (ii) performs efﬁcient exact inference for the discrete latent variables (switches and counts) using a forward-backward routine similar to Hidden Semi-Markov
Models [48, 9]. The model is trained by maximizing a Monte Carlo lower bound of the marginal log-likelihood that can be efﬁciently computed by the inference routine.
We evaluated RED-SDS on two important tasks: segmentation and forecasting. Empirical results on segmentation show that RED-SDS is able to identify both state- and time-dependent switching patterns, considerably outperforming benchmark models. For example, Fig. 1 shows that RED-SDS addresses the oversegmentation that occurs with an existing strong baseline [13]. For forecasting, we illustrate the competitive performance of RED-SDS with an extensive evaluation against state-of-the-art models on multiple benchmark datasets. Further, we show how our model is able to simplify the forecasting problem by breaking the time series into different meaningful regimes without any imposed structure. As such, we manage to learn appropriate duration models for each regime and extrapolate the learned patterns into the forecast horizon consistently.
In summary, the key contributions of this paper are:
• RED-SDS, a novel non-linear state space model which combines the recurrent state-to-switch connection with explicit duration models to ﬂexibly model switch durations;
• an efﬁcient hybrid inference and learning algorithm that combines approximate inference for states with conditionally exact inference for switches and counts;
• a thorough evaluation on a number of benchmark datasets for time series segmentation and forecasting, demonstrating that RED-SDS can learn meaningful duration models, identify both state- and time-dependent switching patterns and extrapolate the learned patterns consistently into the future. 2
2