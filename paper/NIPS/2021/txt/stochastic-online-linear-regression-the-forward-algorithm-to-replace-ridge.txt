Abstract
We consider the problem of online linear regression in the stochastic setting. We derive high probability regret bounds for online ridge regression and the forward algorithm. This enables us to compare online regression algorithms more accurately and eliminate assumptions of bounded observations and predictions. Our study advocates for the use of the forward algorithm in lieu of ridge due to its enhanced bounds and robustness to the regularization parameter. Moreover, we explain how to integrate it in algorithms involving linear function approximation to remove a boundedness assumption without deteriorating theoretical bounds. We showcase this modiﬁcation in linear bandit settings where it yields improved regret bounds.
Last, we provide numerical experiments to illustrate our results and endorse our intuitions. 1

Introduction and preliminaries
The forward regression algorithm, popularized in [24, 3], shows competitive performance bounds in the challenging setup of online regression with adversarial bounded observations. We revisit the analysis of this strategy in the practically relevant alternative situation of stochastic linear regression with sub-Gaussian noise, hence possibly unbounded observations. When compared to the classical ridge regression strategy - its natural competitor - the existing analysis in the adversarial bounded case suggests the forward algorithm has higher performances. It is then natural to ask whether this conclusion holds for the stochastic setup. However, we show that in the stochastic setup, the existing adversarial analysis does not seem sufﬁcient to draw conclusions, as it does not capture some important phenomena, such as the concentration of the parameter estimate around the regression parameter. It may further lead the practitioner to use an improper tuning of the regularization parameter. In order to overcome these issues, we revisit the analysis of the forward algorithm in the case of unbounded sub-Gaussian linear regression and provide a high probability regret bound on the performance of the forward and ridge regression strategies. Owing to this reﬁned analysis, we show that the forward algorithm is superior in this scenario as well, but for different reasons than what is suggested by the adversarial analysis. We discuss the implications of this result in a practical application: stochastic linear bandits, both from theoretical and experimental perspectives.
Setup: In the classical setting of online regression with the square loss, an environment initially chooses a sequence of feature vectors {xt}t ∈ Rd together with corresponding observations {yt}t ∈ 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
R. Then, at each decision step t, the learner receives feature vector xt and must output a prediction
ˆyt ∈ R. Afterwards, the environment reveals the true label yt and iteration t + 1 begins. In this article, we focus on the case when the data generating process is a stochastic linear model:
∃θ∗ ∈ Rd such that ∀t ∈ N∗ : yt = x(cid:62) t θ∗ + (cid:15)t, t θA where {(cid:15)t}t is a noise sequence. At iteration t, strategy A computes a parameter θA t−1 to predict
ˆyA t = x(cid:62) t−1. In the sequel, we omit the subscript A when the algorithm is clear from context. The def= (cid:96)(x(cid:62) t θt−1, yt) = (ˆyt − yt)2, the learner then updates its learner’s prediction incurs the loss: (cid:96)A t t=1 (cid:96)A prediction θt−1 to θt and so on. The total cumulative loss at horizon T is denoted LA t .
We also let (cid:96)t(θ) = (cid:96)(x(cid:62) t=1 (cid:96)t(θ)) be the instantaneous (resp. cumulative) loss incurred by predicting θ at time t (resp. ∀t = 1, . . . , T ). Online regression algorithms are evaluated using different regret deﬁnitions, in the form of a relative cumulative loss to a batch loss;
The quantity of interest in this paper is: t θ, yt) (resp. LT (θ) = (cid:80)T
T = (cid:80)T
RA
T = LA
T − min
θ
LT (θ). (1)
From the perspective of online learning theory, online regression algorithms are usually designed for an adversarial setting, assuming an arbitrary bounded response variable |yt| ≤ Y at each time step.
While the mere existence of algorithms with tight guarantees in this general setting is remarkable, a practitioner may also consider alternative settings, in which analysis for the adversarial setup may be overly conservative. For illustration, we focus on the practical setting of bounded parameter (cid:107)θ∗(cid:107)2 ≤ S and i.i.d zero-mean σ-sub-Gaussian noise sequences:
∀t ≥ 1, γ ∈ R : E [exp(γ(cid:15))] ≤ exp(σ2γ2/2).
We emphasize that while previous results in literature are valid for the adversarial bounded setting, we will still shed new light on the performance of these strategies in a stochastic unbounded setup, which is neither more general nor more restrictive than the adversarial one, and discuss their implications for the practitioner. Let us recall the two popular online regression algorithms considered.
Online ridge regression [Algorithm 1]: This folklore algorithm is deﬁned in the online setting as the greedy version of batch ridge regression:
θr t ∈ arg min
θ
Lt(θ) + λ||θ||2 2, (2) where λ is a parameter and λ||θ||2 2 is a regularization used to penalize model complexity.
Algorithm 1: Online ridge regression
Given θ0 ∈ Rd for t = 1, . . . , T do observe xt ∈ Rd and predict ˆyt = x(cid:62) observe yt and incur loss (cid:96)t ∈ R update parameter: θr t ∈ arg minθ Lt(θ) + λ||θ||2 2 t θr t−1 ∈ R end
A solution to the quadratic optimization problem of Eq. 2 is given in closed form, by θr where Gt(λ) = λI + (cid:80)t when λ is clear from context. t = Gt(λ)−1bt, q=1 xqyq. We may further denote Gt instead of Gt(λ) q and bt = (cid:80)t q=1 xqx(cid:62)
The forward algorithm [Algorithm 2]: A subtle change to the ridge regression takes advantage of the next feature xt+1 to better adapt to the next loss:
θf t ∈ arg min
θ
Lt(θ) + (x(cid:62) t+1θ)2 + λ||θ||2 2. (3) 2
Algorithm 2: The forward algorithm
Given θ0 ∈ Rd for t = 1, . . . , T do observe xt ∈ Rd update parameter: θf predict ˆyt = x(cid:62) t θf observe yt and incur loss (cid:96)t ∈ R t−1 ∈ R end t−1 ∈ arg minθ Lt−1(θ) + (x(cid:62) t θ)2 + λ||θ||2 2
Equivalently, the update step can be written: θf t+1bt, where Gt is still deﬁned same as before.
Intuitively, the term (x(cid:62) t+1θ)2 in Eq. 3 is a “predictive loss”, a penalty on the parameter θ in the direction of the new feature vector xt+1. This approach can be linked to transductive methods for regression [8, 22]. [22] describe two algorithms for linear prediction in supervised settings, and leverage the knowledge of the next test point to improve the prediction accuracy. However, these algorithms have signiﬁcant computational complexities and are not adapted to online settings. t = G−1