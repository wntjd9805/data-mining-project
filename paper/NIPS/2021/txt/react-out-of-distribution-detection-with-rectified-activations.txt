Abstract
Out-of-distribution (OOD) detection has received much attention lately due to its practical importance in enhancing the safe deployment of neural networks. One of the primary challenges is that models often produce highly conﬁdent predictions on OOD data, which undermines the driving principle in OOD detection that the model should only be conﬁdent about in-distribution samples. In this work, we propose ReAct—a simple and effective technique for reducing model overcon-ﬁdence on OOD data. Our method is motivated by novel analysis on internal activations of neural networks, which displays highly distinctive signature patterns for OOD distributions. Our method can generalize effectively to different network architectures and different OOD detection scores. We empirically demonstrate that
ReAct achieves competitive detection performance on a comprehensive suite of benchmark datasets, and give theoretical explication for our method’s efﬁcacy. On the ImageNet benchmark, ReAct reduces the false positive rate (FPR95) by 25.05% compared to the previous best method1. 1

Introduction
Neural networks deployed in real-world systems often encounter out-of-distribution (OOD) inputs— unknown samples that the network has not been exposed to during training. Identifying and handling these OOD inputs can be paramount in safety-critical applications such as autonomous driving [9] and health care. For example, an autonomous vehicle may fail to recognize objects on the road that do not appear in its object detection model’s training set, potentially leading to a crash. This can be prevented if the system identiﬁes the unrecognized object as OOD and warns the driver in advance.
A driving idea behind OOD detection is that the model should be much more uncertain about samples outside of its training distribution. However, Nguyen et al. [38] revealed that modern neural networks can produce overconﬁdent predictions on OOD inputs. This phenomenon renders the separation of in-distribution (ID) and OOD data a non-trivial task. Indeed, much of the prior work on OOD detection focused on deﬁning more suitable measures of OOD uncertainty [17, 19, 28, 29, 31, 33].
Despite the improvement, it is arguable that continued research progress in OOD detection requires insights into the fundamental cause and mitigation of model overconﬁdence on OOD data.
In this paper, we start by revealing an important observation that OOD data can trigger unit activation patterns that are signiﬁcantly different from ID data. Figure 1(b) shows the distribution of activations 1Code is available at: https://github.com/deeplearning-wisc/react.git 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
Before Rectiﬁcation
FPR95: 55.72%
OOD
ID
After Rectiﬁcation
FPR95: 20.38% y c n e u q e r
F n o i t a v i t c
A t i n
U 1 0 1 0 y c n e u q e r
F
OOD Scores (a)
Unit Indices  (b)
OOD Scores (c)
Figure 1: Plots showing (a) the distribution of ID (ImageNet [7]) and OOD (iNaturalist [16]) uncertainty scores before truncation, (b) the distribution of per-unit activations in the penultimate layer for ID and OOD data, and (c) the distribution of OOD uncertainty scores [33] after rectiﬁcation. Applying ReAct drastically improves the separation of ID and OOD data. See text for details. in the penultimate layer of ResNet-50 trained on ImageNet [7]. Each point on the horizontal axis corresponds to a single unit. The mean and standard deviation are shown by the solid line and shaded area, respectively. The mean activation for ID data (blue) is well-behaved with a near-constant mean and standard deviation. In contrast, for OOD data (gray), the mean activation has signiﬁcantly larger variations across units and is biased towards having sharp positive values (i.e., positively skewed). As a result, such high unit activation can undesirably manifest in model output, producing overconﬁdent predictions on OOD data. A similar distributional property holds for other OOD datasets as well.
The above observation naturally inspires a simple yet surprisingly effective method—Rectiﬁed
Activations (dubbed ReAct) for OOD detection. In particular, the outsized activation of a few selected hidden units can be attenuated by rectifying the activations at an upper limit c > 0. Conveniently, this can be done on a pre-trained model without any modiﬁcation to training. The dashed horizontal line in Figure 1(b) shows the cutoff point c, and its effect on the OOD uncertainty score is shown in
Figure 1(c). After rectiﬁcation, the output distributions for ID and OOD data become much more well-separated and the false positive rate (FPR) is signiﬁcantly reduced from 55.72% to 20.38%.
Importantly, this truncation largely preserves the activation for in-distribution data, and therefore ensures the classiﬁcation accuracy on the original task is largely comparable.
We provide both empirical and theoretical insights, characterizing and explaining the mechanism by which ReAct improves OOD detection. We perform extensive evaluations and establish state-of-the-art performance on a suite of common OOD detection benchmarks, including CIFAR-10 and
CIFAR-100, as well as a large-scale ImageNet dataset [7]. ReAct outperforms the best baseline by a large margin, reducing the average FPR95 by up to 25.05%. We further analyze our method theoretically and show that ReAct is more beneﬁcial when OOD activations are more chaotic (i.e., having a larger variance) and positively skewed compared to ID activations, a behavior that is typical of many OOD datasets (cf. Figure 1). In summary, our key results and contributions are: 1. We introduce ReAct —a simple and effective post hoc OOD detection approach that utilizes activation truncation. We show that ReAct can generalize effectively to different network architectures and works with different OOD detection methods including MSP [15],
ODIN [31], and energy score [33]. 2. We extensively evaluate ReAct on a suite of OOD detection tasks and establish a state-of-the-art performance among post hoc methods. Compared to the previous best method,
ReAct achieves an FPR95 reduction of 25.05% on a large-scale ImageNet benchmark. 3. We provide both empirical ablation and theoretical analysis, revealing important insights that abnormally high activations on OOD data can harm their detection and how ReAct effectively mitigates this issue. We hope that our insights inspire future research to further examine the internal mechanisms of neural networks for OOD detection. Code and dataset will be released for reproducible research. 2  
2