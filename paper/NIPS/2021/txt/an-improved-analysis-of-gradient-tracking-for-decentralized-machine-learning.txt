Abstract
We consider decentralized machine learning over a network where the training data is distributed across n agents, each of which can compute stochastic model updates on their local data. The agent’s common goal is to ﬁnd a model that minimizes the average of all local loss functions. While gradient tracking (GT) algorithms can overcome a key challenge, namely accounting for differences between workers’ local data distributions, the known convergence rates for GT algorithms are not optimal with respect to their dependence on the mixing parameter p (related to the spectral gap of the connectivity matrix).
We provide a tighter analysis of the GT method in the stochastic strongly convex, convex and non-convex settings. We improve the dependency on p from O(p−2) to O(p−1c−1) in the noiseless case and from O(p−3/2) to O(p−1/2c−1) in the general stochastic case, where c ≥ p is related to the negative eigenvalues of the connectivity matrix (and is a constant in most practical applications). This improve-ment was possible due to a new proof technique which could be of independent interest. 1

Introduction
Methods that train machine learning models on decentralized data offer many advantages over traditional centralized approaches in core aspects such as data ownership, privacy, fault tolerance and scalability [12, 33]. Many current efforts in this direction come under the banner of federated learning [17, 29, 28, 12], where a central entity orchestrates the training and collects aggregate updates from the participating devices. Fully decentralized methods, that do not rely on a central coordinator and that communicate only with neighbors in an arbitrary communication topology, are still in their infancy [24, 18].
The work of Lian et al. [24] on decentralized stochastic gradient descent (D-SGD) has spurred the research on decentralized training methods for machine learning models. This lead to improved theoretical analyses [16] and to improved practical schemes, such as support for time-varying topologies [32, 3, 16] and methods with communication compression [45, 51, 15, 47]. One of the most challenging aspect when training over decentralized data is data-heterogeneity, i.e. training data that is in a non-IID fashion distributed over the devices (for instance in data-center training) or generated in non-IID fashion on client devices [21, 13, 22, 23]. For example, the D-SGD method has been shown to be affected by the heterogenity [16].
In contrast, certain methods can mitigate the impact of heterogeneous data in decentralized optimiza-tion. For instance the gradient tracking (GT) methods developed by Lorenzo and Scutari [26] and
Nedi´c et al. [34], or the later D2 method by Tang et al. [46] which is designed for communication typologies that remain ﬁxed and do not change over time.
∗Current afﬁliation: CISPA Helmholtz Center for Information Security. 35th Conference on Neural Information Processing Systems (NeurIPS 2021).
Table 1: Important advances for Gradient Tracking in the strongly convex case. Our analysis improves upon all prior rates for both with and without the stochastic noise in terms of the graph parameter p.
Reference rate of convergence to (cid:15)-accuracy (cid:19)
Nedi´c et al. [34]
O
Alghunaim et al. [1] O
Qu and Li [40]
Pu and Nedi´c [39] this work
O
˜O
˜O
ε (cid:18) L3
µ3p2 log 1 (cid:18) L log 1
ε +
µ (cid:18) L2
µ2p2 log 1
ε
√
σ2
µnε
√ (cid:32)
+
µ (cid:19) 1 p2 log 1 (cid:19)
ε (cid:33) a
C1√
ε
+
ε
Lσ
√ pp (cid:32)
σ2
µnε
√ (cid:33)
L
µpc
+
ε log 1
ε
Lσ
√ pc
+
√
µ considered stochastic noise (cid:55) (cid:55) (cid:55) (cid:88) (cid:88) aC1 is a constant that is independent of ε, but can depend on other parameters, such as σ, µ, L, p
It is well known that GT methods do not depend on the heterogeneity of the data and that they converge linearly on distributed strongly convex problem instances without stochastic noise [26, 34].
However, when we apply these methods in the context of machine learning, we need to understand how they are affected by stochastic noise and how they behave on non-convex tasks.
In this paper, we develop a new, and improved, analysis of the gradient tracking algorithm with a novel proof technique. Along with the parallel contribution [55] that developed a tighter analysis of the D2 algorithm, we now have a more accurate understanding of in which setting GT works well and in which ones it does not, and our results allow for a more detailed comparison between the D-SGD,
GT and D2 methods (see Section 5 below).
Our analysis improves over all existing results that analyze the GT algorithm. Speciﬁcally, we prove a weaker dependence on the connectivity of the network (spectral gap) which is commonly incorporated into the convergence rates via the standard parameter p. For example, in the strongly convex setting (cid:1)(cid:1) where σ2 is with stochastic noise we prove that GT converges at the rate ˜O(cid:0) σ2 an upper bound on the variance of the stochastic noise, and c ≥ p a new parameter (often a constant). (cid:1)(cid:1),
By comparing this result with the previously best known upper bound, ˜O(cid:0) σ2
ε by Pu and Nedi´c [39], we see that our upper bound improves the last two terms by a factor of c p ≥ 1 and that the ﬁrst term matches with known lower bounds [37]. The D2 algorithm [46] only converges under the assumption that c is a constant2 and the recent upper bound from [55] coincides with our worst case complexity for GT on all topologies where D2 can be applied. We provide additional comparison of GT convergence rates in the Tables 1 and 2. p · (cid:0) σ√ c · (cid:0) σ√ p log 1 p log 1 nε + 1 pε + 1 nε + 1 pε + 1
ε
Contributions. Our main contributions can be summarized as:
• We prove better complexity estimates for the GT algorithm than known before with a new proof technique (which might be of independent interest).
• In the non-asymptotic regime (of importance in practice), the convergence rate depends on the network topology. By deﬁning new graph parameters, we can give a tighter description of this dependency, explaining why the worst case behavior is rarely observed in practice (see Section 5.1).
We verify this dependence in numerical experiments.
• We show that in the presence of stochastic noise, the leading term in the convergence rate of GT is optimal—we are the ﬁrst to derive this in the non-convex setting—and matching the unimprovable rate of all-reduce mini-batch SGD. 2