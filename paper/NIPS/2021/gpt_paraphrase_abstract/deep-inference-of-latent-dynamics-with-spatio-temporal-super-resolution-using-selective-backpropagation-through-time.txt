Neural interfaces have advanced to the point where they can access the activity of millions of neurons in the brain. However, there is often a trade-off between spatial sampling and temporal frequency due to bandwidth limitations. In this study, we present a method called selective backpropagation through time (SBTT) that can achieve spatio-temporal super-resolution in neuronal time series by leveraging relationships among neurons and latent low-dimensional population dynamics. SBTT allows the learning of deep generative models of latent dynamics from data where the observed variables change at each time step. These models can then fill in missing samples by combining observations with learned latent dynamics. We applied SBTT to sequential autoencoders and found that it significantly improves the characterization of neural population dynamics in electrophysiological and calcium imaging data. In electrophysiology, SBTT accurately infers neuronal population dynamics with lower interface bandwidths, leading to significant power savings for implanted neu-roelectronic interfaces. In two-photon calcium imaging, SBTT uncovers high-frequency temporal structure underlying neural population activity, outperforming current state-of-the-art methods. We also discovered that performance can be further enhanced by using limited, high-bandwidth sampling to pretrain dynamics models and then adapting them with SBTT for sparsely-sampled data. This research has been presented at the 35th Conference on Neural Information Processing Systems (NeurIPS 2021).