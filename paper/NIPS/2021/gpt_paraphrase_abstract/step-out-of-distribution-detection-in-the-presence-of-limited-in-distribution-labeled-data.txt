Many current semi-supervised learning (SSL) studies assume that unlabeled and test data come from the same distribution as labeled data. However, in real-world scenarios, it is important to have SSL algorithms that can not only classify samples from the same distribution as labeled data but also detect samples from unknown distributions. This paper focuses on semi-supervised out-of-distribution (OOD) detection, which faces two main challenges: a lack of labeled and in-distribution data, and the possibility of unseen OOD samples during training. Existing efforts in this area are limited. The proposed approach, called STEP, addresses these challenges by introducing a new technique called Structure-Keep Unzipping, which learns a new representation space that separates OOD samples effectively. An efficient optimization algorithm is used to solve the objective. Extensive experiments on various OOD detection benchmarks demonstrate that STEP significantly outperforms other methods and achieves remarkable detection performance.