A new strategy called Adaptive Pseudo Augmentation (APA) is introduced in this paper to address the challenge of training generative adversarial networks (GANs) with limited data. GANs usually require a large amount of data to synthesize high-quality images, but limited data leads to discriminator overfitting, which hinders the convergence of the generator. APA overcomes this issue by using the generator itself to augment the real data distribution with generated images, deceiving the discriminator in an adaptive manner. This approach is different from existing methods that rely on data augmentations or model regularization. Experimental results demonstrate that APA significantly improves synthesis quality in low-data scenarios. The paper also provides theoretical analysis to validate the convergence and effectiveness of APA. Notably, APA is a simple and effective strategy that can be seamlessly incorporated into powerful contemporary GANs like StyleGAN2, without imposing significant computational costs. The code for implementing APA is available at https://github.com/EndlessSora/DeceiveD.