This paper aims to bridge the gap between the latest theoretical advancements in matrix completion using the nuclear norm and its equivalent in inductive matrix completion. Firstly, in the distribution-free scenario, we establish sample complexity bounds that improve upon the previously best rate of rd2 to d3{2? r logpdq, where d represents the dimension of the side information and r denotes the rank. Secondly, we introduce the (smoothed) adjusted trace-norm minimization strategy, which serves as an inductive counterpart to the weighted trace norm. We demonstrate that this strategy guarantees a rate of Opdr logpdqq under arbitrary sampling. Previously, a similar rate was only achieved under uniform sampling and for exact recovery in the inductive case. Both of our findings align with the current state of the art in standard matrix completion, where they are known to be nearly optimal. Experimental results validate the superiority of our strategy over standard inductive matrix completion on synthetic datasets and real-world problems. These findings establish our strategy as a crucial tool in the matrix completion field, especially when using side information.