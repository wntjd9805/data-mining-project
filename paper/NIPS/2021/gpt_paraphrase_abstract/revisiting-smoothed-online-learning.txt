In this study, we focus on smoothed online learning, where the learner faces both a hitting cost and a switching cost. Our goal is to evaluate the competitive ratio and dynamic regret with switching cost. To limit the competitive ratio, we propose a method that balances the two costs through an optimization problem. Surprisingly, we discover that minimizing the hitting cost alone is highly competitive for λ-quadratic growth functions, outperforming previous results significantly. Additionally, when the hitting cost is both convex and λ-quadratic growth, we can reduce the competitive ratio to 1 + 2√ by minimizing the weighted sum of the λ hitting cost and the switching cost. To determine the dynamic regret with switching cost, we modify the Ader algorithm to incorporate the switching cost. Our modified algorithm, Smoothed Ader, achieves an optimal O((pT)(1 + PT)) bound for dynamic regret with switching cost. If the hitting cost is accessible at the start of each round, we obtain a similar guarantee without the bounded gradient condition and prove the optimality with a lower bound of Ω((pT)(1 + PT)).