The complexity of learning directed acyclic graphical models from observational data is analyzed without specific distributional assumptions. An information-theoretic approach is used, employing a local Markov boundary search procedure to construct ancestral sets in the graphical model. Surprisingly, it is shown that for certain graph ensembles, a simple forward greedy search algorithm is sufficient to learn the Markov boundary of each node without a backward pruning phase. This significantly improves the sample complexity, which is polynomial in the number of nodes. A novel identifiability condition is introduced to learn the entire graph. Finite-sample guarantees are established for recovering Markov boundaries from data. The algorithm is applied to the special case of polytrees, providing explicit conditions for their identifiability and learnability in polynomial time. The algorithm's performance is demonstrated in a simulation study. This general approach works for discrete or continuous distributions without distributional assumptions, revealing the minimal assumptions needed to efficiently learn the structure of directed graphical models from data.