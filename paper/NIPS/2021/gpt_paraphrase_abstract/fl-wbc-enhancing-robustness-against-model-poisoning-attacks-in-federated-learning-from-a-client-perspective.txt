Federated learning (FL) is a widely used distributed learning framework that trains a global model by communicating between a central server and edge devices. However, recent studies have shown that FL is susceptible to model poisoning attacks. Existing server-based defense methods have been proposed to mitigate these attacks, but our empirical findings reveal that these methods fail to ensure the robustness of FL under strong attacks. We also observe that once the global model is contaminated, the impact of the attacks persists in subsequent rounds even without further attacks. To address this, we propose a client-based defense called White Blood Cell for Federated Learning (FL-WBC). FL-WBC identifies the parameter space where the attack effect lingers and perturbs that space during local training. We provide certified guarantees of robustness against model poisoning attacks and convergence to FedAvg after implementing FL-WBC. Through experiments on FasionMNIST and CIFAR10 datasets, we demonstrate that our method effectively mitigates the impact of model poisoning attacks on the global model within 5 communication rounds, with minimal accuracy loss in both IID and non-IID settings. Our defense approach complements existing server-based robust aggregation methods and enhances the robustness of FL against strong attacks. The code for FL-WBC is available at https://github.com/jeremy313/FL-WBC.