Decomposing a scene into its shape, reﬂectance, and illumination is a core problem in computer vision and graphics. While neural approaches like NeRF have achieved impressive results in view synthesis, they lack explicit decomposition and solely focus on radiance. NeRD, an extension of NeRF, can perform decomposition but struggles to recover detailed illumination accurately, limiting realism. To address this, we propose a novel reﬂectance decomposition network that estimates shape, BRDF, and per-image illumination using a set of object images captured under varying illumination. Our key innovation is Neural-PIL, an illumination integration network that replaces a computationally expensive illumination integral operation with a simple network query. Additionally, we employ deep low-dimensional priors on BRDF and illumination representations through smooth manifold auto-encoders. Our decompositions yield significantly improved BRDF and light estimates, enabling more accurate novel view-synthesis and relighting compared to previous methods.