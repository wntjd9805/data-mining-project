Social media platforms have the power to influence users' choices and beliefs through content filtering. Many people are calling for regulations on these filtering algorithms, but designing and enforcing such regulations is challenging. This study aims to address three questions: how can an audit be designed to enforce regulations? Does the audit negatively impact platform performance? And how does the audit affect the content that platforms choose to filter? The study proposes a method for auditors to test compliance with regulations using only black-box access to the filtering algorithm. It also finds that regulations may not significantly hinder platform performance under certain conditions and that content diversity can help align the interests of platforms and regulators.