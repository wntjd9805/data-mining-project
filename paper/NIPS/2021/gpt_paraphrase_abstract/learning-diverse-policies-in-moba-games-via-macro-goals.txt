Researchers have made progress in building AI systems for MOBA games using deep reinforcement learning. However, these systems lack policy diversity. This paper introduces a new framework called MGG that learns diverse policies in MOBA games. MGG abstracts strategies as macro-goals and trains a Meta-Controller to predict these goals. To enhance policy diversity, MGG samples macro-goals from the Meta-Controller prediction and guides the training process accordingly. Experimental results on Honor of Kings show that MGG can execute diverse policies and outperform existing methods across various heroes.