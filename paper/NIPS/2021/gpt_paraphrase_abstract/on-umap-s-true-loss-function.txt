UMAP has become the preferred method for visualizing high-dimensional datasets, surpassing t-SNE in various fields. However, the reasons behind its success are not well known. This study aims to explore UMAP's optimization scheme based on sampling. By deriving UMAP's true loss function, we discovered that it differs from the published one in a way that depends on the dataset size. Consequently, UMAP does not aim to replicate its theoretically motivated high-dimensional similarities. Instead, it focuses on reproducing similarities that only encode the k nearest neighbor graph. This challenges the previous understanding of UMAP's effectiveness. On the other hand, we propose that the implicit balance between attraction and repulsion, achieved through negative sampling, is crucial to UMAP's success. Our theoretical findings are supported by experiments conducted on toy and single cell RNA sequencing data.