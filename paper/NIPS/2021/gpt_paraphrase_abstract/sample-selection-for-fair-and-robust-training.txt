This study addresses the importance of fairness and robustness in Trustworthy AI and proposes a new algorithm for achieving both. Fairness involves creating an unbiased model, while robustness involves learning from corrupted data. It is known that focusing on one aspect may negatively impact the other. The researchers propose a sample selection-based algorithm that addresses both fairness and robustness. They formulate a combinatorial optimization problem to select unbiased samples in the presence of data corruption. Since solving this problem is extremely difficult, they propose a greedy algorithm that is efficient and effective. Experimental results demonstrate that their algorithm achieves better fairness and robustness compared to existing techniques, both on synthetic and real datasets. Importantly, their algorithm only requires modifying the sampling step in batch selection and does not require changes to the training algorithm or additional clean data.