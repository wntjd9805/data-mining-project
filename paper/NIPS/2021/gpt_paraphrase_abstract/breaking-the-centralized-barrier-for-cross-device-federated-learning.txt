Federated learning (FL) presents challenges in optimization due to the heterogeneity of data across different clients, which leads to client drift. Developing an algorithm for FL that surpasses simple centralized training has been an unresolved problem. To address this, we propose a versatile algorithmic framework called MIME. MIME addresses client drift and adapts any centralized optimization algorithm (e.g., momentum, Adam) to the cross-device federated learning setting. It achieves this by utilizing control-variates and server-level optimizer state (e.g., momentum) at each client-update step, ensuring that local updates resemble those of the centralized method on independent and identically distributed (i.i.d.) data. Our research proves that MIME can transform the convergence of a generic algorithm in the centralized setting into convergence in the federated setting. Additionally, by combining MIME with momentum-based variance reduction, we demonstrate that it is faster than any centralized method, which is a first-of-its-kind result. We conduct comprehensive experiments on real-world datasets to evaluate MIME's performance.