Fonts can be represented in either a vector format or rasterized as fixed resolution images. However, the non-standard representation of vector fonts hinders the use of new network architectures for neural representations. On the other hand, rasterized fonts lose data fidelity when encoded through networks, particularly in representing font-specific details like edges and corners. To address this, we introduce multi-implicits, which represent fonts as a set of learned implicit functions that preserve font features without losing important characteristics. While obtaining ground truth multi-channel signals for supervision is challenging, we propose a method to train this representation with local supervision. Our neural architecture effectively discovers globally consistent multi-implicits for font families. Through extensive evaluation, we demonstrate the advantages of our proposed representation for tasks such as reconstruction, interpolation, synthesis, and glyph completion. The representation also allows for synthesizing a whole font family in the target style using a single characteristic font.