Unsupervised domain adaptation has gained significant attention for adapting models from labeled source domains to unlabeled target domains. While numerous techniques have been developed for image domain adaptation, unsupervised adaptation in videos remains largely unexplored. This paper introduces CoMix, a novel contrastive learning framework for unsupervised video domain adaptation. Unlike existing methods that rely on adversarial learning, CoMix utilizes temporal contrastive learning to bridge the domain gap. It maximizes the similarity between encoded representations of an unlabeled video at different speeds and minimizes the similarity between different videos played at different speeds. Additionally, CoMix incorporates background mixing to extend the temporal contrastive loss, allowing for more positive samples per anchor and leveraging action semantics shared across domains. The framework also integrates a supervised contrastive learning objective using target pseudo-labels to enhance the discriminability of the latent space. Extensive experiments on benchmark datasets demonstrate the superior performance of CoMix compared to state-of-the-art methods. Further details can be found on the project page: https://cvir.github.io/projects/comix.