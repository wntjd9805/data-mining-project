Reasoning about the three-dimensional (3D) structure of scenes based on their two-dimensional (2D) image projections is a fundamental problem in computer vision. To address this problem, researchers typically search for models that best explain the observed image data. However, this inverse problem is challenging due to the dependence of images on both the properties of the scenes and the image formation process. To effectively optimize the explanation of images, it is crucial to design differentiable functions for the projection of 3D scenes into images, which is known as differentiable rendering.Previous approaches to differentiable rendering have relied on replacing non-differentiable operations with smooth approximations, which can impact the accuracy of 3D estimation. In this paper, we propose a more general approach by investigating differentiable renderers from the perspective of randomized optimization and perturbed optimizers. Specifically, we establish a connection between well-known differentiable renderer formulations and randomly smoothed optimizers, and introduce differentiable perturbed renderers. We also introduce a variance reduction mechanism to address the computational burden of perturbed optimizers and develop an adaptive scheme to automatically adjust the smoothing parameters of the rendering process.We apply our method to the task of 3D scene reconstruction and evaluate its performance on 6D pose estimation and 3D mesh reconstruction. Our results demonstrate the advantages of perturbed renderers, as they provide informative gradients that serve as strong supervisory signals. Compared to the state-of-the-art alternatives that use smooth gradient approximations, our perturbed renderers yield more accurate solutions.