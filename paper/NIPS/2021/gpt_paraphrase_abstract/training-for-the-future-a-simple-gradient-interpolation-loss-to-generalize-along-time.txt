Machine learning models deployed in real world applications often face a drift between the training and test data distributions due to gradual changes over time. To address this, models are periodically re-trained on new data to ensure they can generalize to future data. Previous methods for enhancing temporal generalization, such as continuous transportation of past data and adversarial learning, have limitations such as poor scalability, training instability, and reliance on unlabeled future data. In response to these limitations, we propose a simple method that incorporates time-sensitive parameters and regularizes temporal complexity using a GradientInterpolation (GI) loss. GI allows the decision boundary to evolve over time while preventing overfitting to limited training snapshots. Our method outperforms both complex generative and adversarial approaches, as well as simpler gradient regularization methods, when tested on multiple real-world datasets.