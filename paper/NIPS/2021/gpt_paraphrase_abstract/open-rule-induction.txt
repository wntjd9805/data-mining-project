Rule induction systems have desirable properties such as ease of understanding, inferring new knowledge, and communicating with other inference systems. However, previous systems were limited to finding rules within a knowledge base (KB) and could not generalize to more complex real-world rules. To address this limitation, recent advancements propose language model (LM)-based rule generation to enhance the expressive power of rules. This paper revisits the differences between KB-based rule induction and LM-based rule generation, highlighting that KB-based methods discover data commonalities while LM-based methods "learn rules from rules," resulting in constrained patterns. To overcome this, the paper introduces the open rule induction problem, which aims to induce open rules utilizing the knowledge in LMs. The Orion system is then proposed to automatically mine open rules from LMs without the need for annotated rules. Extensive experiments demonstrate the quality and quantity of the inducted open rules. Surprisingly, these automatically inducted rules outperform manually annotated rules when applied in downstream tasks like relation extraction.