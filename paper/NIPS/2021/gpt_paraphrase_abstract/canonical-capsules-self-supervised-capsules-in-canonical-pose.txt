We introduce a novel capsule architecture for 3D point clouds that is self-supervised. Our approach involves using permutation-equivariant attention to compute capsule decompositions of objects, and training the model with pairs of randomly rotated objects. The main idea is to aggregate attention masks into semantic keypoints, which are used to supervise a decomposition that satisfies the properties of capsule invariance and equivariance. This allows us to train a neural network without the need for classification labels or manually-aligned training datasets. By learning an object-centric representation in a self-supervised manner, our method surpasses the current state-of-the-art in 3D point cloud reconstruction, canonicalization, and unsupervised classification.