The focus of this study is on intrinsic motivation in artificial agents, aiming to determine a suitable general-purpose objective for these agents. The research explores the idea of minimizing entropy of the agent's state visitation, using a latent state-space model, as a compact and versatile learning objective. This objective encourages the agent to gather information and gain control over its environment, reducing uncertainty and unpredictability. The study implements a deep reinforcement learning agent with a deep variational Bayes filter and finds that the agent successfully learns to discover, represent, and control dynamic objects in partially-observed environments using visual observations, without the need for external rewards.