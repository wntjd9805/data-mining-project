We have developed a framework for comparing data manifolds, specifically for evaluating deep generative models. Our framework uses a tool called Cross-Barcode(P,Q) to track spatial discrepancies in multiscale topology between the concentrated distributions on the manifolds. With this tool, we introduce the Manifold Topology Divergence score (MTop-Divergence) and apply it to assess the performance of deep generative models in various domains and datasets. We show that the MTop-Divergence accurately detects different types of model issues such as mode-dropping, intra-mode collapse, mode invention, and image disturbance. Our algorithm scales well with the increase in dimension of the high-dimensional space and can be applied universally to datasets of different sizes and dimensions, including those used to train recent GANs in the visual domain. This method is domain agnostic and does not rely on pre-trained networks.