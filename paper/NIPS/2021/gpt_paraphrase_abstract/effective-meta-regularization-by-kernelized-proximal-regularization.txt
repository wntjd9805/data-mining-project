Meta-learning is a technique that speeds up the learning of new tasks using a small number of samples. Recent methods using deep kernels have achieved excellent performance. However, the regularizers in these methods cannot be learned. This paper introduces an algorithm called MetaProx that learns a proximal regularizer for the base learner. We prove the convergence of MetaProx theoretically and show through experiments that it offers advantages over existing algorithms.