Deep state-space models (DSSMs) are used to predict temporal patterns in sequence data by learning the underlying dynamics. However, maximizing the evidence lower bound during training does not guarantee that the model actually learns these dynamics. To address this issue, we propose a constrained optimization framework for training DSSMs. In this framework, we introduce the extended Kalman VAE (EKVAE), which combines amortized variational inference with classic Bayesian filtering/smoothing to more accurately model dynamics compared to RNN-based DSSMs. Our experiments demonstrate that the constrained optimization framework significantly improves system identification and prediction accuracy, surpassing the performance of previous models. The EKVAE not only achieves remarkable results in identifying dynamical systems but also successfully learns state-space representations that separate static and dynamic features.