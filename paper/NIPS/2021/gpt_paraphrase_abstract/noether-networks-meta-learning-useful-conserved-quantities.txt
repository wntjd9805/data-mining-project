Advancements in machine learning (ML) are driven by data availability, computational resources, and the effective incorporation of inductive biases. These biases often leverage symmetries in prediction problems, such as how convolutional networks rely on translation equivariance. Automatically identifying these valuable symmetries has the potential to significantly enhance the performance of ML systems, but remains a challenging task. This study focuses on sequential prediction problems and draws inspiration from Noether's theorem to simplify the search for inductive biases by utilizing meta-learning of conserved quantities. Introducing Noether Networks, a novel architecture where a meta-learned conservation loss is optimized within the prediction function, we demonstrate through theoretical analysis and experiments that these networks enhance prediction accuracy. This framework provides a general approach for discovering inductive biases in sequential problems.