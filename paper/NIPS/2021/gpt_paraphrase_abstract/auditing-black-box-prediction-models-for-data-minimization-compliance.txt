This paper focuses on auditing black-box prediction models to ensure compliance with the GDPR's data minimization principle. The principle requires that prediction models only use the minimum necessary information for their tasks. To address the challenge of the black-box setting, the authors propose checking the necessity of each input feature by assigning a constant value to it across all predictions and measuring how much the model outcomes change. They introduce a metric for data minimization based on model instability under simple imputations and extend its applicability to a distributional setting using a Bayesian approach. The paper also addresses the auditing problem with a constraint on the number of queries to the prediction system. The authors formulate this problem as a multi-armed bandit framework and propose efficient algorithms using novel exploration strategies. Experimental results demonstrate the superiority of their auditing algorithms compared to simpler benchmarks.