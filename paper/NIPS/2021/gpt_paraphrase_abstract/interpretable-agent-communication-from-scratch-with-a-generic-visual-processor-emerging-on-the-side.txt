Deep networks are being used as autonomous agents, and it is important to understand how they can communicate with each other. In this study, we trained two deep nets from scratch to communicate with each other and identify objects without supervision. We found that the nets were able to successfully communicate about object classes they hadn't seen during training. Additionally, the visual representations generated during our training process were comparable in quality to those produced by a recent self-supervised learning model when used as generic visual features. These findings demonstrate that emergent deep net communication is viable in realistic scenarios and highlight a connection between this field and self-supervised visual learning.