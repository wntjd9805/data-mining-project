This study explores the challenge of evaluating off-policy from batched contextual bandit data with multidimensional actions, also known as slates. This problem is commonly found in recommender systems and user-interface optimization. The pseudoinverse (PI) estimator, proposed by Swaminathan et al. (2017), assumes that the conditional mean rewards are additive in actions. In this research, we consider a broader range of unbiased estimators that incorporate control variates. This class includes the PI estimator and its self-normalized variant. By optimizing over this class, we develop new estimators that offer improved risk guarantees compared to both the PI and self-normalized PI estimators. Experimental results using real-world recommender data and synthetic data validate these enhancements.