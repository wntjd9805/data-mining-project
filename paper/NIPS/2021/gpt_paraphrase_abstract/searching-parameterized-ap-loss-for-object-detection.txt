Loss functions are crucial for training deep-network-based object detectors. The widely used Average Precision (AP) metric evaluates object detection performance by considering both localization and classification tasks. However, since AP is non-differentiable, traditional object detectors use separate differentiable losses for these tasks, which can lead to performance degradation. Previous approaches manually design surrogate losses for AP, which is time-consuming and may not be optimal. In this study, we propose the Parameterized AP Loss, which replaces the non-differentiable components of AP with parameterized functions. This allows for a variety of AP approximations within a unified formula. We employ an automatic parameter search algorithm to find the optimal parameters. Our experiments on the COCO benchmark using three different object detectors (RetinaNet, Faster R-CNN, and Deformable DETR) show that the Parameterized AP Loss consistently outperforms existing handcrafted losses. We will release the code for further use.