This paper presents a practical online method for solving a specific type of optimization problem called distributionally robust optimization (DRO) with non-convex objectives. DRO is commonly used in machine learning to enhance the robustness of neural networks. Most existing methods for solving DRO rely on stochastic primal-dual methods, but these methods have limitations. They require manipulating high-dimensional dual variables, which is time-consuming, and they are not suitable for online learning scenarios where data arrives sequentially. To overcome these issues, the authors propose a new approach that incorporates a KL divergence regularization on the dual variables. This transforms the original min-max problem into a compositional minimization problem, allowing the development of practical duality-free online stochastic methods that do not require large mini-batches. The authors establish the state-of-the-art complexities of their proposed methods, both with and without a Polyak-≈Åojasiewicz (PL) condition of the objective. The effectiveness of the proposed method is demonstrated through empirical studies on large-scale deep learning tasks. The results show that the method can accelerate training by more than 2 times compared to baseline methods and save significant training time on a large dataset of approximately 265K images. Additionally, the superiority of DRO over Empirical Risk Minimization (ERM) is confirmed for imbalanced datasets. The proposed method also has potential applications in solving other types of stochastic compositional problems with state-of-the-art complexities.