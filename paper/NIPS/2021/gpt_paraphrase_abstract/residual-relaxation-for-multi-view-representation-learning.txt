This paper focuses on the impact of data augmentation on multi-view methods, which learn representations by aligning multiple views of the same image. The authors observe that certain augmentations, such as image rotation, can be detrimental to multi-view methods because they introduce a significant semantic shift that is difficult to align. To address this issue, the authors propose a new approach called Pretext-aware Residual Relaxation (Prelax) that allows for a flexible alignment objective by incorporating an adaptive residual vector between different views and leveraging pretext-aware learning to encode the semantic shift. Experimental results demonstrate that Prelax not only enhances the performance of multi-view methods with existing augmentations but also benefits from stronger augmentations like rotation.