Sampling-based methods, particularly Bayesian inference, are widely used in machine learning to handle uncertainty. However, as these techniques become more prevalent in everyday life, it is crucial to ensure that machine learning systems adhere to various trustworthy-related constraints such as fairness, safety, and interpretability. Unfortunately, there is a lack of practical and efficient algorithms for enforcing these constraints in probabilistic inference, specifically for sampling from intractable distributions subject to general nonlinear constraints. To address this issue, we propose a new family of constrained sampling algorithms that extend the existing Langevin Dynamics (LD) and Stein Variational Gradient Descent (SVGD) methods. These algorithms incorporate a moment constraint specified by a general nonlinear function. By leveraging the gradient flow structure of LD and SVGD, we develop two types of algorithms for handling constraints: a primal-dual gradient approach and a constraint controlled gradient descent approach. We analyze the continuous-time mean-field limit of these algorithms and demonstrate that they have a convergence rate of O(1/t) under mild conditions. Additionally, the LD variant exhibits linear convergence if a log Sobolev-like inequality holds. We conduct various numerical experiments to showcase the efficiency of our algorithms in trustworthy settings.