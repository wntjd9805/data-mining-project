Reinforcement learning agents often struggle to remember past events and integrate information across multiple timesteps or after being distracted. To address this issue, we propose a new memory architecture called Hierarchical Chunk Attention Memory (HCAM). HCAM divides the past into chunks and uses high-level and detailed attention mechanisms to recall relevant information. With HCAM, agents can remember past events in detail without attending to all intervening events. Our experiments demonstrate that agents with HCAM outperform agents with other memory architectures in tasks requiring long-term recall, retention, and reasoning. They excel in finding hidden objects, navigating efficiently in new environments, and learning and retaining new object names. HCAM enables agents to extrapolate to longer task sequences and maintain knowledge across episodes. It improves sample efficiency, generalization, and solves tasks that previously required specialized architectures. Our work contributes to the development of agents that can effectively learn and adapt in complex and dynamic environments.