Mutual information (MI) is a widely used measure of statistical dependence in various fields. However, estimating MI in high-dimensional settings is challenging due to the curse of dimensionality. To address this issue, this paper introduces sliced MI (SMI) as an alternative measure of dependence. SMI is computed by averaging MI values between one-dimensional random projections. Despite its simplicity, SMI retains many of the desirable properties of MI while offering efficient computation and estimation from samples. Unlike MI, SMI can increase due to deterministic transformations, making it valuable for feature extraction by optimizing it over raw data processing functions. Numerical experiments on independence testing and feature extraction confirm that SMI has the potential to outperform classic MI in high-dimensional inference tasks.