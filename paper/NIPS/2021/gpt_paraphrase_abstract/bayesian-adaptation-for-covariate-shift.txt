Deep neural networks often struggle to make accurate predictions with reliable uncertainty estimates when faced with distribution shift at test time. One way to address this issue is by improving the robustness of the networks. However, an alternative approach is to directly adapt the networks to unlabeled inputs from the specific distribution shift encountered at test time. This presents a challenging question regarding the relationship between unlabeled data and model parameters in the standard Bayesian model for supervised learning. In this paper, we propose a Bayesian model that establishes a well-defined connection between unlabeled inputs under distributional shift and model parameters. We demonstrate how approximate inference in this model can be achieved through a simple regularized entropy minimization procedure during test time. We assess the effectiveness of our method on various distribution shifts in image classification, such as image corruptions, natural distribution shifts, and domain adaptation settings. Our results indicate that our approach enhances both accuracy and uncertainty estimation.