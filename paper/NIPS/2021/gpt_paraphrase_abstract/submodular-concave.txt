First-order optimization methods have been shown to effectively converge to the maximum objective value of concave functions and provide reliable approximation guarantees for continuous submodular functions. This study introduces the maximization of functions represented by F(x) = G(x) + C(x) over a solvable convex body P, where G is a smooth DR-submodular function and C is a smooth concave function. This class of functions expands upon concave and continuous DR-submodular functions, for which no theoretical guarantees exist. The study presents a collection of Frank-Wolfe style algorithms that offer approximation guarantees of 1 - 1/e, 1/e, or 1/2 depending on the characteristics of the objective function (monotone or not, non-negative or not) and the properties of set P (downward closed or not). These algorithms are utilized to create a framework that smoothly transitions between selecting diverse elements from a given set or choosing clustered elements based on a suitable concave function. The algorithms are further applied to various functions within the DR-submodular + concave class in both constrained and unconstrained scenarios, demonstrating consistent outperformance compared to natural baselines.