Graph neural networks (GNN) have become popular for analyzing graph and relational data. However, as industrial datasets grow larger, the computation required for information sharing between GNN layers becomes impractical. Current sampling methods to approximate full-graph training have limitations, such as high variances and lack of theoretical guarantees. To address these issues, we propose a new approach that treats GNN neighbor sampling as a multi-armed bandit problem. We design a reward function that introduces bias to reduce variance and prevent unstable payouts. Unlike previous bandit-GNN approaches, our method achieves near-optimal regret and considers the training dynamics of GNN with stochastic gradient descent. This leads to lower variance estimates and competitive or better test accuracy on various benchmarks.