We introduce To The Point (TTP), a technique for generating 3D objects from a single image using weak supervision to learn 2D to 3D correspondences. Our approach involves recovering a 3D shape by first determining the 2D positions corresponding to the 3D template vertices, and then jointly estimating a rigid camera transformation and non-rigid template deformation that best explain the 2D positions via the 3D shape projection. By leveraging 3D-2D correspondences, we replace CNN-based regression with a simpler per-sample optimization problem, resulting in significantly more accurate 3D reconstructions. We treat this optimization as a differentiable layer and train the entire system end-to-end. Our method demonstrates consistent quantitative improvements across various categories and showcases qualitative results with diverse shape, pose, and texture predictions. For more information, please visit our project website: https://fkokkinos.github.io/to_the_point/.