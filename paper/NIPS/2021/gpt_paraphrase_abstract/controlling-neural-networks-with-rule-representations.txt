We propose a unique training method called DEEPCTRL that combines rules with deep learning, allowing for control over the strength of the rules during inference. DEEPCTRL incorporates a rule encoder and a rule-based objective into the model, enabling a shared representation for decision making. This method can be applied to any type of rule defined for input and output data, and it is compatible with various data types and model architectures. The key feature of DEEPCTRL is that it does not require retraining to adjust the rule strength; instead, users can adjust it during inference to achieve the desired balance between accuracy and rule verification. We demonstrate the effectiveness of DEEPCTRL in domains where incorporating rules is crucial, such as Physics, Retail, and Healthcare. DEEPCTRL enhances the trust and reliability of trained models by significantly increasing their rule verification ratio and also improving accuracy in downstream tasks. Furthermore, DEEPCTRL enables new applications, including hypothesis testing of rules on data samples and unsupervised adaptation based on shared rules across datasets.