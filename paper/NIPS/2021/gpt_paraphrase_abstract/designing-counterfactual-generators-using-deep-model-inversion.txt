Explanation techniques for understanding black-box models by synthesizing small, interpretable changes in images have gained popularity. These synthesized explanations, known as counterfactuals, need to be both interpretable and realistic. This paper focuses on generating counterfactual explanations using a deep inversion approach, without access to the training data. Existing deep inversion methods are inadequate for producing meaningful counterfactuals, so a new method called DISC (Deep Inversion for Synthesizing Counterfactuals) is proposed. DISC improves upon deep inversion by using stronger image priors, incorporating a novel manifold consistency objective, and adopting a progressive optimization strategy. The counterfactuals generated by DISC not only provide visually meaningful explanations but also effectively learn classifier decision boundaries and remain robust to unknown test-time corruptions.