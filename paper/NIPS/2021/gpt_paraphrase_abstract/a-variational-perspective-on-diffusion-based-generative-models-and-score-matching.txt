Discrete-time generative models and score matching methods have shown promise in modeling high-dimensional image data. Recently, Song et al. (2021) demonstrated that diffusion processes can be reversed by learning the score function, which represents the gradient of the log-density of the perturbed data. They proposed using the learned score function in an inverse formula to define a generative diffusion process. Although this approach has been empirically successful, it lacks a theoretical foundation. In this study, we directly address the continuous-time generative diffusion and develop a variational framework for likelihood estimation. This framework encompasses continuous-time normalizing flows as a special case and can be viewed as an infinitely deep variational autoencoder. We demonstrate that minimizing the score-matching loss is equivalent to maximizing a lower bound of the likelihood of the plug-in reverse stochastic differential equation proposed by Song et al. (2021), thereby bridging the theoretical gap.