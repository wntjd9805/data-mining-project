This study examines a learning problem involving dependent data. The objective is to predict the next state based on a trajectory of length n from a stationary Markov chain with k states. Previous research has shown that for k = 2, the optimal prediction risk is Θ(log log n) in Kullback-Leibler divergence. However, this study demonstrates that for 3 ≤ k ≤ O(n), the optimal prediction risk is Θ(k^2 log^2 n) using techniques from universal compression. These slower rates can be attributed to the memory in the data, as the spectral gap of the Markov chain can be arbitrarily small. To measure the memory effect, the study explores irreducible reversible chains with a predetermined spectral gap. Besides characterizing the optimal prediction risk for two states, the study reveals that, as long as the spectral gap is not excessively small, the prediction risk in the Markov model is O(k^2 n), which matches that of an iid model with the same number of parameters.