Deep ensembles are highly effective in large-scale image classification tasks, but their computational and memory costs limit their practicality. While some recent approaches aim to reduce these costs by distilling an ensemble model into a single model, there is still a performance gap between the two. To address this issue, we propose a simple method to narrow this gap by ensuring that the distilled model absorbs as much diversity from the ensemble as possible. Our experiments demonstrate that the standard distillation procedure fails to effectively transfer this diversity, particularly for complex models with near-zero training error. To overcome this, we introduce a perturbation strategy for distillation that identifies inputs where ensemble members' outputs disagree, thereby revealing diversity. Our empirical results confirm that a model distilled with these perturbed samples exhibits enhanced diversity and improved performance.