Deep learning systems often struggle with forgetting previous knowledge when learning new skills continuously. This paper focuses on two challenges, representation bias and classifier bias, in class-incremental learning. To address these biases, the paper presents a novel approach that utilizes explicit class augmentation (classAug) and implicit semantic augmentation (semanAug). The representation bias is tackled by learning diverse and transferable representations. The paper explores feature representations in incremental learning using spectral analysis and introduces classAug, a technique that exposes the model to more classes during training to facilitate transferable representations. To overcome the classifier bias, semanAug generates numerous instances of old classes in the deep feature space, maintaining the decision boundary of previously learned classes. This approach achieves comparable performance to representative data replay methods without storing old samples.