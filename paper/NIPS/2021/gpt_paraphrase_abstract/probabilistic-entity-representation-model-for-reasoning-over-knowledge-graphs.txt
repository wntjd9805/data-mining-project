Logical reasoning over Knowledge Graphs (KGs) is a crucial technique for efficient querying of large and incomplete databases. Existing methods utilize spatial geometries like boxes to learn query representations, but these geometries have strict boundaries that lead to ambiguity in the results. Moreover, previous approaches for handling unions lack closure and cannot be chained. To address these issues, we propose a Probabilistic Entity Representation Model (PERM) that encodes entities as Multivariate Gaussian densities, capturing both their semantic position and smooth decision boundaries. We also define closed logical operations of projection, intersection, and union that can be aggregated using an end-to-end objective function. Our experiments on public benchmark KG datasets demonstrate that PERM outperforms state-of-the-art methods on standard evaluation metrics. Additionally, we evaluate PERM's effectiveness in a COVID-19 drug-repurposing case study and show improved F1 scores compared to current methods. Finally, we provide a low-dimensional visualization of the Gaussian representations to illustrate the query answering process of PERM. Only the abstraction of the answer format is outputted.