Normalizing flows are generative models that use an invertible transformation to estimate the density of a complex target distribution from a simple base distribution. However, they struggle to model data that exists on an unknown low-dimensional manifold, which is common in real-world domains like image data. Previous solutions to this problem have introduced complications that undermine the exact density estimation capability of normalizing flows. In this study, we propose Conformal Embedding Flows as a framework to address this limitation and enable the learning of manifolds with tractable densities. We argue that combining a standard flow with a trainable conformal embedding offers the most natural approach for modeling manifold-supported data. We introduce a set of conformal building blocks and conduct experiments using synthetic and real-world data to demonstrate that flows can effectively model manifold-supported distributions without sacrificing tractable likelihoods.