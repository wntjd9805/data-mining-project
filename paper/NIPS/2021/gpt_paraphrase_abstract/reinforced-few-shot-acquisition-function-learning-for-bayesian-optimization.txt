This paper addresses the challenge of designing an acquisition function (AF) that performs well across different types of black-box functions in Bayesian optimization (BO). The authors propose a Bayesian variant of a deep Q-network (DQN) as a surrogate AF, which learns a distribution of Q-networks through the Kullback-Leibler regularization framework. This distribution provides the necessary uncertainty for sampling in BO and mitigates overfitting. In addition, a demo policy induced by an existing AF is used as the prior for the Bayesian DQN to improve training stability. The authors also leverage the meta-loss of Bayesian model-agnostic meta-learning on a meta-level to complement their few-shot AF learning approach. The proposed method, called FSAF, is general-purpose and independent of the input domain's dimension and cardinality. Experimental results demonstrate that FSAF achieves comparable or better regrets than state-of-the-art benchmarks on various synthetic and real-world test functions.