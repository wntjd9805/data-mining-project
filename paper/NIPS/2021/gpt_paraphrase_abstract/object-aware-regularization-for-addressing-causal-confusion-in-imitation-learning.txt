This paper introduces a technique called Object-aware REgularizatiOn (OREO) to address the causal confusion problem in behavioral cloning. OREO aims to prevent the policy from relying on correlated but undesired effects of expert actions by encouraging uniform attention to all semantic objects. The approach involves extracting semantic objects using vector-quantized variational autoencoder and randomly dropping units that share the same discrete code. Experimental results demonstrate that OREO significantly improves the performance of behavioral cloning compared to other regularization and causality-based methods in various Atari environments and a self-driving CARLA environment. It even outperforms inverse reinforcement learning methods trained with substantial environment interaction.