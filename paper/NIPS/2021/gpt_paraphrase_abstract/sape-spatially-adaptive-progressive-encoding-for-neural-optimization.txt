We introduce a technique called spatially adaptive progressive encoding (SAPE) for improving the ability of multilayer-perceptron (MLP) networks to learn functions with high-frequency components and wide frequency bands. SAPE gradually reveals signal components with increasing frequencies over time and space, without affecting training stability or requiring domain-specific preprocessing. This frequency exposure is controlled by a feedback loop that allows changes to propagate at different rates across local spatial portions of the signal space. We demonstrate the effectiveness of SAPE in various domains and applications, such as regression of low dimensional signals and images, representation learning of occupancy networks, and mesh transfer between 3D shapes.