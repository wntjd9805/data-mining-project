We introduce a self-supervised learning framework for category-level object pose estimation. Our method estimates the 6D poses of unseen objects without relying on CAD models or ground-truth pose annotations. By disentangling shape and pose through an invariant shape reconstruction module and an equivariant pose estimation module, our method achieves accurate category-level pose estimation comparable to fully supervised methods. We demonstrate the effectiveness of our approach through extensive experiments on both complete and partial depth point clouds. The project page with code and visualizations can be accessed at dragonlong.github.io/equi-pose.