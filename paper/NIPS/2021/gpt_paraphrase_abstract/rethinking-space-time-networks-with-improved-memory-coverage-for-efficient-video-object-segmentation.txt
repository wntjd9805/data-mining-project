This paper introduces a novel method for modeling space-time correspondences in video object segmentation. Unlike existing approaches, the proposed method establishes correspondences between frames without re-encoding mask features for each object, resulting in a highly efficient and robust framework. By using correspondences, the features from previous frames are aggregated to infer the nodes in the current frame. The aggregation process is treated as a voting problem, but existing methods using inner-product affinity tend to favor a small subset of memory nodes, regardless of the query. To address this issue, the paper suggests using negative squared Euclidean distance to compute affinities instead. The experimental results demonstrate that this approach allows every memory node to contribute, leading to improved memory efficiency and inference accuracy. The combination of correspondence networks and diversified voting achieves state-of-the-art results on DAVIS and YouTubeVOS datasets, while running significantly faster at 20+FPS for multiple objects.