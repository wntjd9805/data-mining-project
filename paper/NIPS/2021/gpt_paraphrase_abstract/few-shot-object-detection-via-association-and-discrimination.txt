In recent years, object detection has made significant advancements. However, detecting new classes with limited samples remains difficult, as deep learning with low data often leads to degraded features. Existing approaches use a holistic fine-tuning method, where the model is pre-trained on base classes with abundant samples and then used for novel classes. However, this approach has limitations. During fine-tuning, a novel class may rely on multiple base classes, resulting in a scattered feature space that undermines inter-class separability. To address these challenges, we propose a two-step fine-tuning framework called FADI (Few-shot object detection via Association and Discrimination). In the first step, we construct a compact feature space for each novel class by explicitly imitating a specific base class feature space, based on their semantic similarity. In the second step, we disentangle the classification branches for base and novel classes to ensure separability, and a set-specialized margin loss is applied to enhance inter-class separability. Experimental results on standard datasets demonstrate that FADI achieves state-of-the-art performance, particularly in extremely few-shot scenarios. The code for FADI is available at the provided GitHub link.