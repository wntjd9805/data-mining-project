Many machine learning tasks today require models to perform well on extreme cases or outliers in the dataset. This issue has been extensively researched in fields such as algorithmic fairness, class imbalance, and risk-sensitive decision making. One popular approach to improve the model's performance on these extreme cases is to minimize the Conditional Value at Risk (CVaR) loss, which calculates the average risk over the tail of the loss. However, in classification tasks where models are evaluated using the 0/1 loss, we demonstrate that if the classifiers are deterministic, then minimizing the average 0/1 loss also minimizes the CVaR 0/1 loss. This suggests that minimizing the CVaR loss is not beneficial without additional assumptions. To overcome this limitation, we propose minimizing the CVaR loss using randomized classifiers, where the minimizers of the average 0/1 loss and the CVaR 0/1 loss differ. This approach leads to improved performance on extreme cases. To learn such randomized classifiers, we introduce the Boosted CVaR Classification framework, inspired by the relationship between CVaR and a classical boosting algorithm called LPBoost. Within this framework, we develop an algorithm called Î±-AdaLPBoost. We evaluate our proposed algorithm on four benchmark datasets and demonstrate that it achieves higher performance on extreme cases compared to deterministic model training methods.