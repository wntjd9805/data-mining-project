We introduce SegFormer, a powerful yet efficient semantic segmentation framework that combines Transformers with lightweight MLP decoders. SegFormer has two notable features: 1) It utilizes a hierarchically structured Transformer encoder that produces multiscale features without the need for positional encoding, eliminating the performance drop caused by positional code interpolation when testing at different resolutions. 2) SegFormer simplifies the decoder by employing an MLP decoder that aggregates information from various layers, enabling the integration of local and global attention for effective representations. This simple and lightweight design proves to be crucial for efficient segmentation using Transformers. We have scaled our approach to create a range of models, from SegFormer-B0 to SegFormer-B5, which outperform previous methods in terms of performance and efficiency. For instance, SegFormer-B4 achieves 50.3% mIoU on ADE20K with only 64M parameters, making it 5 times smaller and 2.2% better than the previous state-of-the-art. Our top-performing model, SegFormer-B5, achieves an 84.0% mIoU on the Cityscapes validation set and demonstrates excellent zero-shot robustness on Cityscapes-C. The code for SegFormer can be found at: github.com/NVlabs/SegFormer.