Graph Neural Networks (GNNs) are highly suitable for capturing hidden relationships between different entities in the spatio-temporal domain, such as videos. However, when an explicit structure is absent, determining the atomic elements to be represented as nodes becomes non-trivial. Existing approaches often rely on pre-trained object detectors or fixed regions for node extraction. In contrast, our proposed model overcomes this limitation by learning nodes that dynamically attach to distinct and relevant regions, crucial for higher-level tasks, without the need for object-level supervision. By constructing these adaptive nodes, our model exhibits a preference towards object-centric representations and effectively identifies regions strongly correlated with objects in videos. Through extensive testing on two challenging datasets and conducting thorough ablation studies, we demonstrate that our model outperforms previous GNN models for video classification.