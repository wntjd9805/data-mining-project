This manuscript explores Kernel Ridge Regression (KRR) in the context of Gaussian design. Previous studies have reported exponents for the decay of the excess generalization error of KRR, assuming power-law decay of eigenvalues of the features co-variance. However, these decays were observed in different setups, such as the noiseless case with constant regularization and the noisy optimally regularized case. The intermediate settings have not been thoroughly investigated. This paper aims to unify and expand on this previous research by providing a comprehensive characterization of all regimes and excess error decay rates, considering the interplay of noise and regularization. The study reveals a transition in the noisy setting, where the exponent values shift from the noiseless case to the noisy case as the sample complexity increases. Real data sets also demonstrate this crossover phenomenon.