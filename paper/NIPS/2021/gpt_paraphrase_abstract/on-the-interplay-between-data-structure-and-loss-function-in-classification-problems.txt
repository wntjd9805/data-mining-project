The ability of heavily overparametrized machine learning models to generalize well is a central puzzle in the field. While previous studies have focused on isotropic inputs, this work considers a model with structured data, allowing for the manipulation of low-dimensional structures and their alignment with the target function. Using statistical physics methods, the authors derive a precise expression for the train and test error of random feature models trained on this structured data, applicable to any convex loss function. The study reveals that the impact of data structure on the double descent curve is greater for logistic loss compared to mean-squared loss, with the performance gap widening for easier tasks. Numerical experiments on MNIST and CIFAR10 datasets support these findings.