We propose a method to convert speech signals into a fixed-size representation that minimizes cosine loss using the LASER text embedding space. Our approach allows sentences to be close in this embedding space regardless of language or modality. By employing a similarity metric in this multimodal embedding space, we mine audio data in German, French, Spanish, and English from Librivox and align it with billions of sentences from Common Crawl. This process results in over twenty thousand hours of aligned speech translations. We evaluate the mined speech/text corpora by training neural speech translation systems for various language pairs. The addition of the mined data significantly improves the BLEU score on the CoVoST2 and MUST-C test sets compared to a competitive baseline. Furthermore, our approach enables direct speech-to-speech mining without transcription or translation, yielding over one thousand three hundred hours of aligned speech in French, German, Spanish, and English. This speech corpus has the potential to enhance research in speech-to-speech translation, which currently lacks sufficient end-to-end training data. All the mined multimodal corpora will be freely available.