Recent deep learning models have achieved impressive prediction results, but they often lack interpretability and computational efficiency. Interpretability is important in fields like science and medicine, where models need careful examination or interpretation is the primary goal. Additionally, interpretable models are concise and computationally efficient. This study presents adaptive wavelet distillation (AWD), a method that distills information from a trained neural network into a wavelet transform. AWD penalizes feature attributions of a neural network in the wavelet domain to learn an effective multi-resolution wavelet transform. The resulting model is highly predictive, concise, computationally efficient, and easy to interpret due to its multi-scale structure. Through collaboration with domain experts, AWD is shown to address challenges in cosmological parameter inference and molecular-partner prediction. In both cases, AWD produces a scientifically interpretable and concise model with better predictive performance than state-of-the-art neural networks. Furthermore, AWD identifies predictive features that are scientifically meaningful in their respective domains. The code and models are available on Github.