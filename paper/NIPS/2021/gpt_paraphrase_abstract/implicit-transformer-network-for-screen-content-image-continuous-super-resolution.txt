The widespread use of screen sharing, remote collaboration, and online education has led to a huge increase in screen content. In order to accommodate limited bandwidth, high-resolution screen content images (SCIs) are often downscaled and compressed. However, there is a growing demand for super-resolution (SR) of low-resolution (LR) SCIs to enhance detail observation on high-resolution displays. Existing image super-resolution (SR) methods designed for natural images do not work well for SCIs due to their different characteristics and the need for browsing at arbitrary scales. To address this, we propose a novel Implicit Transformer Super-Resolution Network (ITSRN) specifically for SCIs. Our approach uses an implicit transformer to infer pixel values at query coordinates from image features at key coordinates, and an implicit position encoding scheme to aggregate neighboring pixel values. We create benchmark datasets for LR and HR SCI pairs and conduct extensive experiments, which demonstrate that our ITSRN significantly outperforms other SR methods for both compressed and uncompressed SCIs.