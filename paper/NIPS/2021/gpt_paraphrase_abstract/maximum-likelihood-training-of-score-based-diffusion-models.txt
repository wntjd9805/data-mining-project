Score-based diffusion models are trained using a weighted combination of score matching losses to synthesize samples by reversing a stochastic process. While the log-likelihood of these models can be computed through a connection to continuous normalizing flows, it is not directly optimized by the score matching losses. However, we demonstrate that a specific weighting scheme of the objective can serve as an upper bound for the negative log-likelihood, allowing for approximate maximum likelihood training of score-based diffusion models. Through empirical observations, we find that maximum likelihood training consistently improves the likelihood of these models across various datasets, stochastic processes, and model architectures. Our best models achieve negative log-likelihoods comparable to state-of-the-art autoregressive models on CIFAR-10 and ImageNet 32x32 without any data augmentation, with values of 2.83 and 3.76 bits/dim, respectively.