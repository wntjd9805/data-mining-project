Simulated directed acyclic graph (DAG) models can unintentionally exhibit properties that affect structure learning algorithms. In this study, we demonstrate that the marginal variance increases along the causal order for additive noise models. We introduce a measure called varsortability to assess the agreement between the order of increasing marginal variance and the causal order. It is found that certain continuous structure learning algorithms perform well due to high varsortability, which can be matched by a simple baseline method. However, this performance may not extend to real-world data, where varsortability may be moderate or dependent on measurement scales. Even after standardization, these algorithms fail to identify the true DAG or its Markov equivalence class. Nevertheless, we discover that data generating processes with high varsortability leave a distinct covariance pattern that can be exploited. These findings challenge the significance of generic benchmarks with independently drawn parameters. The code for this study can be accessed at https://github.com/Scriddie/Varsortability.