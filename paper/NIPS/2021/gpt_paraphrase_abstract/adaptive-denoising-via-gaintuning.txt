Deep convolutional neural networks (CNNs) used for image denoising are usually trained on large datasets, achieving state-of-the-art performance. However, they struggle to generalize to data outside the training distribution. Recent studies have demonstrated the possibility of training denoisers on a single noisy image, adapting to its features. Nevertheless, the limited training information limits their performance. To address this issue, we propose "GainTuning", a methodology that allows pre-trained CNN models to be selectively adjusted for individual test images. GainTuning optimizes a single scaling parameter (the "Gain") for each channel in the CNN's convolutional layers to prevent overfitting. Our experiments show that GainTuning enhances the performance of state-of-the-art CNNs on standard image-denoising benchmarks, improving denoising results for almost every image in a held-out test set. Notably, GainTuning performs even better on test images that systematically differ from the training data, whether in noise level or image type. We demonstrate the potential of adaptive GainTuning in a scientific application involving transmission-electron-microscope images, using a CNN pre-trained on synthetic data. Compared to existing methodologies, GainTuning faithfully reconstructs the structure of catalytic nanoparticles from these low signal-to-noise ratio data.