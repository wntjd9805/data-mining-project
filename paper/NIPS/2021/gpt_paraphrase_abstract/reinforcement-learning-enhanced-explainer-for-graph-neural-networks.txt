Graph neural networks (GNNs) have recently emerged as revolutionary technologies for machine learning tasks on graphs. GNNs incorporate the graph structure with node representation using the message passing scheme, which makes interpretation challenging. A GNN explainer aims to identify the most influential subgraph to interpret the prediction of an instance. Existing methods solve this problem using continuous relaxation or search-based heuristics, but they have issues like violation of message passing and hand-crafted heuristics, resulting in poor interpretability. To address these issues, we propose RG-Explainer, an RL-enhanced GNN explainer. It consists of three main components: starting point selection, iterative graph generation, and learning stopping criteria. RG-Explainer constructs a connected explanatory subgraph by sequentially adding nodes from the boundary of the current graph, aligning with the message passing scheme. Additionally, we design an effective seed locator for selecting the starting point and learn stopping criteria for generating better explanations. Extensive experiments on synthetic and real datasets demonstrate that RG-Explainer outperforms state-of-the-art GNN explainers. Furthermore, RG-Explainer exhibits better generalization ability in the inductive setting.