We investigate the problem of asymmetric low-rank factorization, where the goal is to minimize a certain objective function involving matrices U and V. This problem is challenging due to its non-convex and non-smooth nature, as well as the imbalance between U and V. It serves as a prototype for more complex problems like asymmetric matrix sensing and matrix completion. Empirical observations have shown that the randomly initialized gradient descent algorithm can solve this problem efficiently. However, existing theories explaining this phenomenon require artificial modifications to the algorithm. In this paper, we provide the first proof that demonstrates the convergence of randomly initialized gradient descent to a global minimum of the asymmetric low-rank factorization problem with a polynomial rate. To achieve this, we introduce a new symmetrization technique to quantify the symmetries and asymmetries, and a quantitative perturbation analysis to approximate matrix derivatives. These techniques have potential applications in other non-convex problems.