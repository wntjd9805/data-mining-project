This study addresses the problem of path planning, which involves finding efficient trajectories with high rewards. Traditional approaches such as CEM and CMA-ES focus on promising areas of the search space but can get stuck in local maxima. Other methods like DOO and VOOT balance exploration and exploitation but use space partitioning strategies that are independent of the reward function. LaMCTS, on the other hand, learns to partition the search space in a reward-sensitive manner. In this paper, the authors develop a new regret analysis to understand the effectiveness of adaptive region partitioning. They also propose a new path planning method called LaP3, which improves function value estimation within sub-regions and utilizes a latent representation of the search space. Empirical results show that LaP3 outperforms existing methods in 2D navigation tasks and yields benefits when applied to model-based reinforcement learning. It also demonstrates superior performance in real-world tasks, such as compiler phase ordering and molecular design. The code for LaP3 is available at the provided GitHub link.