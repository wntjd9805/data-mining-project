We present a novel approach using deep reinforcement learning (RL) to improve the performance of integer programming (IP) through large neighborhood search (LNS). Our RL policy functions as a destroy operator, selecting a subset of variables at each step, while an IP solver acts as the repair operator. However, the vast number of variable subsets poses a challenge for conventional RL algorithms. To overcome this, we represent subsets by factorizing them into binary decisions for each variable and train a neural network using a customized actor-critic algorithm. We evaluate our method on four representative IP problems and demonstrate that it outperforms SCIP and other LNS baselines in terms of solution quality and runtime. Furthermore, our approach maintains its advantages even when applied to larger problems. Additional experiments with Gurobi, a leading commercial solver, also show that our method surpasses its performance within the same time constraints.