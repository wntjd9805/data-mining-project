The study of grounded language learning in machines has been extensively explored, but the learning of spatio-temporal linguistic concepts remains largely unexplored. This research introduces a new task in spatio-temporal language grounding, focusing on understanding descriptions of behavioral traces. A truth function is trained to predict if a description matches a given history of observations, involving time-extended predicates and spatio-temporal references. Different models, including multimodal Transformer architectures, are trained to explore architectural biases. The models are tested on generalization to randomly held-out sentences and grammar primitives. It is found that maintaining object identity in attention computation is crucial for overall generalization performance, while summarizing object traces in a single token has little impact. This research opens new possibilities for language-guided autonomous embodied agents. The code, pretrained models, and datasets are made available under an open-source license to encourage future work in this area.