Many modern machine learning applications have complex design goals, such as minimizing worst-case error, meeting specific precision or recall targets, or enforcing group-fairness constraints. To optimize these non-decomposable objectives, popular techniques break down the problem into a series of cost-sensitive learning tasks. However, when training over-parameterized models, the standard approach of re-weighting the loss to incorporate label costs can lead to unsatisfactory results. To address this issue, we propose new cost-sensitive losses that build upon the concept of logit adjustment and can handle more general cost matrices. These losses are calibrated and can be further enhanced by using distilled labels from a teacher model. Through experiments on benchmark image datasets, we demonstrate the effectiveness of our approach in training ResNet models with common robust and constrained optimization objectives.