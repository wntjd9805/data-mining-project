Deep neural networks are vulnerable to security threats, such as the Trojan attack, where attackers manipulate the model's behavior through Trojaned training samples. By applying neuroscientific principles, we identify subtle yet crucial structural differences in Trojaned models using topological tools. These tools enable us to model high-order dependencies, compare networks, and locate structural abnormalities. Notably, Trojaned models exhibit shortcuts from shallow to deep layers. Building on these findings, we propose a robust detection strategy for Trojaned models, outperforming standard baselines on various benchmarks.