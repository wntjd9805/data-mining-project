We present a new type of implicit neural models called Multiple Shooting Layers (MSLs). These models utilize parallelizable root-finding algorithms to solve initial value problems, effectively replacing Neural ODEs. MSLs offer improved efficiency in terms of the number of function evaluations and inference time. We analyze the different solution methods for MSLs from both theoretical and computational perspectives. We demonstrate the effectiveness of MSLs in long-term optimal control of ODEs and PDEs, as well as in generating sequences using latent models. Additionally, we explore the speed improvements achieved by applying MSL inference in Neural CDEs for time series classification of medical data.