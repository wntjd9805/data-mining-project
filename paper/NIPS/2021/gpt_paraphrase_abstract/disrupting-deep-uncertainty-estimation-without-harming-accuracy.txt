Deep neural networks (DNNs) have become highly effective predictors and are widely used for various tasks. However, it is important to have reliable uncertainty estimation of their predictions for deployment in risk-sensitive applications. This paper introduces a novel and straightforward attack that impacts the network's ability to estimate uncertainty, without causing incorrect predictions. As a result, the DNN becomes more confident in its incorrect predictions than its correct ones, without reducing its overall accuracy. Two versions of the attack are presented: one for a black-box scenario (where the attacker has no knowledge of the target network) and another for a white-box scenario. The attack only needs to be of very small magnitude to significantly damage uncertainty estimation, with larger magnitudes rendering uncertainty estimations completely unusable. The attack successfully targets three popular uncertainty estimation methods: vanilla softmax score, DeepEnsembles, and MC-Dropout. Additionally, an attack is demonstrated on SelectiveNet, a selective classification architecture. The proposed attack is tested on contemporary architectures like MobileNetV2 and EfficientNetB0, all trained on ImageNet classification.