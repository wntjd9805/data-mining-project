Adversarial attacks pose a significant threat to deep neural networks (DNNs). Various defense methods have been proposed, with adversarial training showing promising results. However, the impact of network architecture on the robustness of adversarially trained DNNs is not well understood. This paper addresses this gap by investigating the influence of network width and depth on robustness. The key findings are: 1) having more parameters does not necessarily improve robustness; 2) reducing capacity in the last stage of the network can enhance robustness; and 3) there exists an optimal architectural configuration for robustness under the same parameter budget. The paper also offers a theoretical analysis to explain why such network configurations aid robustness. These insights can guide the design of adversarially robust DNNs. The code for this research can be accessed at https://github.com/HanxunH/RobustWRN.