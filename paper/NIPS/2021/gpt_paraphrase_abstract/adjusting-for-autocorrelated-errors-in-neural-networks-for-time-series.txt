The growing field of research on neural networks for modeling time series data has often assumed that errors across time steps are uncorrelated. However, this assumption is often inaccurate due to the temporal nature of the data, leading to inaccurate maximum likelihood estimations. To address this issue, we propose a method that learns the autocorrelation coefficient alongside the model parameters. Our experiments on time series forecasting demonstrate the effectiveness of our approach, as it consistently improves performance across a range of real-world datasets and state-of-the-art models. We also provide empirical critical values to assess the severity of autocorrelated errors and analyze various aspects of our method to highlight its advantages. Furthermore, we validate that our method is not limited to forecasting alone by considering other time series tasks.