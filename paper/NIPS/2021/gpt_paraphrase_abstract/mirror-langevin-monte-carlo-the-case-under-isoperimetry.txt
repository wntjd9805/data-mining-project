Motivated by the relationship between sampling and optimization, we investigate a mirror descent version of Langevin dynamics. We analyze three discretization methods and establish convergence rates, considering functional inequalities like Log-Sobolev in the relevant metric. Our findings demonstrate a complex connection between the underlying geometry and the target distribution. They suggest that caution is necessary to ensure the discretized algorithm achieves negligible bias with decreasing stepsize when sampling from potentials under less stringent smoothness/convexity conditions.