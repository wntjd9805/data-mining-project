Most deep learning algorithms currently rely on error backpropagation, which is considered biologically implausible. An alternative approach involves training artificial neural networks by treating each unit as a reinforcement learning agent, forming a team of agents. This allows all units to be trained using the REINFORCE algorithm, which aligns with observed forms of synaptic plasticity. However, REINFORCE suffers from high variance and slow learning, making it impractical for training deep networks. To address this, we introduce a novel algorithm called MAP propagation that significantly reduces variance while maintaining the local nature of the learning rule. Experimental results show that MAP propagation can solve reinforcement learning tasks at a similar speed to backpropagation in actor-critic networks. Our work enables the wider use of agent teams in deep reinforcement learning.