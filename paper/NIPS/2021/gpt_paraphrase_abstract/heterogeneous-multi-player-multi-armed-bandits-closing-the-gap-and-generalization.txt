Despite recent progress in decentralized multi-player multi-armed bandits (MP-MAB) problems, the regret gap in the heterogeneous MP-MAB setting remains unresolved. This paper introduces BEACON, a solution that addresses this gap through improvements in implicit communication and efficient exploration. The proposed adaptive differential communication (ADC) design enhances communication efficiency, while a batched exploration scheme incorporates the combinatorial upper confidence bound (CUCB) principle. Additionally, BEACON extends to solve a new MP-MAB problem with a nonlinear system reward function and proves logarithmic regret. This work bridges the disjointed areas of combinatorial MAB (CMAB) and MP-MAB, suggesting a valuable connection for further investigation.