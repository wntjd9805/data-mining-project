We propose a novel approach called multi-label active learning (ML-AL) to address the challenges of data annotation in multi-label classification (MLC). MLC allows for complex label dependencies but requires labor-intensive annotation due to correlated and potentially large label spaces. Our approach combines a Gaussian Process-Bayesian Bernoulli Mixture model (GP-B2M) to accurately quantify a data sample's contribution to the label space and select informative samples for annotation. The GP-B2M model encodes label correlations using a Bayesian Bernoulli mixture of label clusters and integrates a predictive Gaussian Process to handle sparse labels. We develop a variational inference algorithm to efficiently infer the model's posterior. The model also provides a predictive distribution that includes label predictions and their correlations. We design a sampling function that captures both feature uncertainty and label covariance for effective data sampling. Experimental results on real-world multi-label datasets demonstrate the superior performance of our proposed model in active learning.