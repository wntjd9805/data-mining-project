Deep models trained using maximum likelihood have been successful in survival analysis. However, practitioners often evaluate these models using different criteria, such as binary classification losses like Brier score (BS) and Bernoulli log likelihood (BLL) at specific time points. Models trained with maximum likelihood may not perform well on these criteria since maximum likelihood does not directly optimize them. To address this issue, we propose a method called Inverse-Weighted Survival Games. In these games, the objectives for each model are constructed using re-weighted estimates that involve the other model, with the latter being fixed during training. We demonstrate that when the loss is appropriate, these games always converge to the true failure and censoring distributions. This means that once reached, the models in the game accurately represent these distributions. We provide an example where this convergence is unique. We validate the effectiveness of these games on simulations and apply them to real-world cancer and critically-ill patient data to optimize the BS criterion.