We address the issue of online classification with a privacy constraint. In this scenario, a learner observes a sequence of labeled examples and returns a hypothesis at each iteration that predicts the label of new examples. The learner's performance is measured by regret against a known hypothesis class H. We require that the algorithm satisfies a privacy constraint by ensuring that the sequence of hypotheses it outputs is differentially private with respect to the entire input sequence. We present the first regret bound for the realizable setting, showing that a private learner can make a limited number of mistakes comparable to the non-private case. The bound varies depending on the Littlestone dimension of the class H. We also highlight the connection between online learnable classes and differentially private learnable classes, reinforcing the possibility of directly privatizing an online learning algorithm. We discuss an adaptive setting and provide a sublinear regret bound.