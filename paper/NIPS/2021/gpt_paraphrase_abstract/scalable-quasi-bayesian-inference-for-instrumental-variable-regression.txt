In recent years, there has been increased interest in using flexible machine learning models for instrumental variable regression. However, there is still a lack of methodology for quantifying uncertainty in these models. In this study, we introduce a scalable quasi-Bayesian approach for instrumental variable regression, based on kernelized IV models. Unlike Bayesian approaches, our method does not require additional assumptions about the data generation process and provides a scalable approximate inference algorithm with comparable time cost to point estimation methods. Our algorithm can also be extended to work with neural network models. We analyze the theoretical properties of our proposed quasi-posterior and demonstrate its competitive performance through empirical evaluation.