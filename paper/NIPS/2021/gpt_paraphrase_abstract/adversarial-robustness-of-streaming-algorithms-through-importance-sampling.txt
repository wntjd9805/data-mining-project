Recent algorithmic design for machine learning tasks has focused on achieving robustness against adversarial attacks. In the adversarial streaming model, an adversary presents a data stream of adaptively chosen updates to an algorithm. The objective of the algorithm is to compute or approximate a predetermined function for every prefix of the adversarial stream. However, the adversary can generate future updates based on the previous outputs of the algorithm, potentially learning the random bits used by the algorithm to manipulate input dependencies. This poses a challenge for problems in the streaming model that require randomized algorithms, as deterministic algorithms with sublinear space usage are not feasible. This paper introduces adversarially robust streaming algorithms for central machine learning and algorithmic tasks, including regression, clustering, subspace embedding, low-rank approximation, and coreset construction. For regression and numerical linear algebra tasks, the row arrival streaming model is considered. The results are based on the observation that many importance sampling-based algorithms exhibit adversarial robustness, in contrast to sketching-based algorithms commonly used in the streaming literature, which are susceptible to adversarial attacks. The paper also demonstrates that the merge and reduce paradigm in streaming is adversarially robust. This enables the construction of robust algorithms for various clustering problems, including k-means, k-median, k-center, Bregman clustering, projective clustering, principal component analysis (PCA), and non-negative matrix factorization, without requiring new algorithmic implementations. The robustness of these algorithms is empirically validated against various adversarial attacks, highlighting their superiority over existing algorithms that lack robustness.