We propose a new method called NeRV that represents videos using neural networks instead of traditional frame sequences. NeRV takes the frame index as input and outputs the corresponding RGB image. This approach simplifies video-related tasks and improves efficiency compared to pixel-wise representations. Video encoding in NeRV involves fitting a neural network to video frames, and decoding is a straightforward feedforward operation. NeRV achieves faster encoding and decoding speeds and better video quality. Additionally, NeRV can be used for video compression and video denoising tasks. We provide the source code and pre-trained model for NeRV at https://github.com/haochen-rye/NeRV.git.