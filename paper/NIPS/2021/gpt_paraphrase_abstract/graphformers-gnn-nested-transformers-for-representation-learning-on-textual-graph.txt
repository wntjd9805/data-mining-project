This study focuses on representation learning for textual graphs, aiming to generate low-dimensional embeddings for nodes based on their individual textual features and neighborhood information. Previous approaches relied on a cascaded model architecture, where language models encoded node features independently and graph neural networks aggregated the embeddings. However, this architecture limited the modeling of textual features. To address this limitation, the authors propose GraphFormers, which combines layerwise graph neural network components with transformer blocks of language models. This architecture allows for the fusion of text encoding and graph aggregation, enabling accurate comprehension of each node's semantic from a global perspective. Additionally, a progressive learning strategy is introduced, where the model is trained on manipulated data and original data successively to enhance its ability to integrate graph information. The proposed GraphFormers outperform state-of-the-art baselines on three large-scale benchmark datasets while maintaining comparable running efficiency. The source code for GraphFormers is available at https://github.com/microsoft/GraphFormers.