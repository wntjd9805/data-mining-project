Recent studies have focused on training artificial agents to communicate effectively with each other through referential games. However, this approach often results in successful but incomprehensible communication. The issue lies in the game objective, which revolves around communicating about a single object in a shared visual context. This narrow focus leads to overfitting and fails to encourage the development of language skills beyond concrete reference. In contrast, human language encompasses a diverse range of abstract ideas. To address this limitation, we propose games that necessitate communication of generalizations over sets of objects representing abstract visual concepts. Additionally, these games can incorporate separate contexts for each agent. Our findings indicate that these modified games significantly enhance the systematicity and interpretability of the learned languages, as determined by various metrics in the literature. Furthermore, we introduce a technique for identifying logical operations embedded in the emergent languages by learning an approximate compositional reconstruction of the language.