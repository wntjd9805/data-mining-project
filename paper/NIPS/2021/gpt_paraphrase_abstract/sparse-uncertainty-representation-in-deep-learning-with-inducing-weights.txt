Bayesian Neural Networks and deep ensembles are two popular methods for quantifying uncertainty in deep learning. However, these approaches face challenges in scaling due to memory inefficiency, as they require storing multiple parameters compared to deterministic models. To overcome this, we propose a method that incorporates a small inducing weight matrix to reduce the dimensionality of uncertainty quantification. We also extend Matheron's conditional Gaussian sampling rule to enable faster weight sampling, allowing our inference method to maintain reasonable runtime compared to ensembles. Importantly, our approach achieves competitive performance in prediction and uncertainty estimation tasks with fully connected neural networks and ResNets, while reducing the parameter size to less than 24.3% of a single neural network.