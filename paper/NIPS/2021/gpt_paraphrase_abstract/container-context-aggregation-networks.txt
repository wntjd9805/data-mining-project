Convolutional neural networks (CNNs) are widely used in computer vision, while Transformers have gained popularity in natural language processing and are now being adopted in computer vision as well. Recent research has shown that a simple MLP-based solution can produce effective visual representations without the need for traditional convolutional or Transformer components. We propose a unified approach called CONTAINER (CONText AggregatIon NEtwoRk), which is a general-purpose building block for aggregating spatial context in neural networks. The CONTAINER architecture achieves high accuracy on ImageNet and can be used in object detection and instance segmentation networks, outperforming other methods with comparable computational requirements. Our method also shows promising results in self-supervised learning. Code for our approach is available at https://github.com/allenai/container.