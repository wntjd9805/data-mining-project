Adversarial imitation learning is a popular method in continuous control imitation. Various modifications have been proposed to improve policy performance and algorithm sample complexity. However, these choices are rarely tested together in rigorous empirical studies, making it challenging to determine their significance. To address this, we conduct a comprehensive study involving more than 50 choices within a generic adversarial imitation learning framework. Our study includes a large-scale analysis with over 500,000 trained agents using both synthetic and human-generated demonstrations. We examine the outcomes and emphasize the unexpected discoveries.