The lookahead algorithm is a method used to train neural networks by updating its fast weights multiple times before updating its slow weights. This algorithm has been found to significantly improve test performance compared to traditional optimization methods. However, there is currently no theoretical understanding of why lookahead performs better. In this study, we address this issue by analyzing the excess risk error, which measures test performance. We prove that when using stochastic gradient descent as the inner-loop optimizer, lookahead achieves smaller excess risk error compared to traditional methods on both convex and nonconvex problems. Additionally, we discover that incorporating a stagewise optimization strategy, which gradually decreases the learning rate, further improves lookahead's performance on convex problems. Finally, we introduce a new algorithm called stagewise locally-regularized lookahead (SLRLA), which combines the vanilla objective with a local regularizer to achieve optimization and generalization improvements over conventional lookahead. Experimental results on CIFAR10/100 and ImageNet datasets confirm the advantages of SLRLA. The code for SLRLA can be found at https://github.com/sail-sg/SLRLA-optimizer.