The stochastic multi-arm bandit problem has been extensively studied with certain assumptions on the arm's distribution. However, these assumptions may not always be precisely accessible to practitioners, raising concerns about the robustness of bandit algorithms to model misspecification. In this study, a generic Dirichlet Sampling (DS) algorithm is examined, which involves pairwise comparisons of empirical indices computed through re-sampling of arms' observations and a data-dependent exploration bonus. It is demonstrated that various versions of this strategy achieve optimal regret guarantees for bounded distributions and logarithmic regret for semi-bounded distributions with a mild quantile condition. Additionally, a simple tuning can ensure robustness to a wide range of unbounded distributions, albeit with slightly worse than logarithmic asymptotic regret. Numerical experiments are conducted using synthetic agriculture data to showcase the effectiveness of the DS algorithm in a decision-making problem.