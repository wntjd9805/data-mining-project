This paper addresses the domain shift problem in Generalized Zero-Shot Learning (GZSL) by improving the transferability and discriminability of visual representations. The proposed Dual Progressive Prototype Network (DPPN) constructs attribute and category prototypes to capture prototypical visual patterns. DPPN alternately searches attribute-related local regions and updates attribute prototypes to achieve accurate attribute-region correspondence, enhancing attribute localization ability. Additionally, DPPN projects category prototypes into multiple spaces to improve category discriminability. Both attribute and category prototypes are learned collaboratively in a unified framework, resulting in transferable and distinctive visual representations. Experimental results on four benchmarks demonstrate that DPPN effectively mitigates the domain shift problem in GZSL.