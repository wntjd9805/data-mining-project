Bayesian deep learning has theoretical benefits and practical advantages such as improved uncertainty quantification and model selection. The Laplace approximation (LA) is a simple but less popular method for approximating the intractable posteriors of deep neural networks. This is because it is perceived as expensive, difficult to implement, and yielding inferior results. However, this work challenges these misconceptions by (i) discussing different variants of LA that are cost-effective, (ii) introducing "laplace," a user-friendly software library for PyTorch that provides access to various versions of LA, and (iii) conducting extensive experiments to demonstrate that LA performs competitively and is computationally efficient compared to popular alternatives. The aim is to encourage wider adoption of LA in practical deep learning, even in domains where Bayesian approaches are currently not commonly used.