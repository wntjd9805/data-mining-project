Recent advancements in 3D shape reconstruction have primarily relied on static datasets with limited sensory data. This approach neglects the importance of active object exploration, which involves both vision and touch. The goal of active touch sensing for 3D reconstruction is to select tactile readings that enhance shape reconstruction accuracy. However, the lack of frameworks for shape exploration has hindered the development of deep learning-based active touch models. This paper addresses this issue by introducing a system that includes a haptic simulator, a mesh-based 3D shape reconstruction model, and data-driven solutions using either tactile or visuotactile signals. This framework allows for the development of fully data-driven solutions for active touch, improving object understanding. Experimental results demonstrate the superiority of our models compared to natural baselines in the task of 3D shape understanding. We provide our framework as a tool to encourage further research in this area.