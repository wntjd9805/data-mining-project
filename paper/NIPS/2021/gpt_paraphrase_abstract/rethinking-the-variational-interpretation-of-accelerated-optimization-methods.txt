The continuous-time model of Nesterov's momentum offers an interesting perspective on understanding the acceleration phenomenon in convex optimization. This perspective suggests a connection between Nesterov's trajectory and a set of Euler-Lagrange equations related to the Bregman Lagrangian. This approach has led to the development of new accelerated algorithms and has provided a strong theoretical basis for designing structure-preserving accelerated methods. In this study, we further explore this idea and conduct a detailed analysis of the action associated with the Bregman Lagrangian using calculus of variations. Our main finding is that while Nesterov's method is a stationary point for the action, it is often not a minimizer but instead a saddle point in the space of differentiable curves. This discovery challenges the prevailing understanding of Nesterov's method as a variational interpretation and offers additional insights into the geometric properties of accelerated paths.