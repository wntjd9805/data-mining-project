This study explores the utilization of self-driving simulators for perception tasks in autonomous driving. While simulators can generate large amounts of labeled data, there is a domain gap between synthetic and real data. The researchers propose a method to minimize this gap by using neural-invariant representations and strategically sampling data from the simulator. Their approach is applicable to any network architecture and simulator choice. They demonstrate their method on a vehicle segmentation task using multi-sensor data and evaluate it on a real-world dataset. The study also identifies the types of variations that affect perception networks trained with simulators and how their domain adaptation technique can compensate for them.