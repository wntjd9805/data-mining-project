We propose a dynamic token sparsiÔ¨Åcation framework for vision transformers. Our framework progressively and dynamically prunes redundant tokens based on input, improving image recognition accuracy. We use a lightweight prediction module to estimate the importance of each token and add it to different layers for hierarchical token pruning. To optimize the module, we introduce an attention masking strategy to differentiably prune tokens. This framework reduces FLOPs by 31% to 37% and improves throughput by over 40%, with less than a 0.5% drop in accuracy. Our DynamicViT models achieve competitive complexity/accuracy trade-offs compared to CNNs and vision transformers on ImageNet. Code is available at https://github.com/raoyongming/DynamicViT.