We present APT, a novel unsupervised pre-training approach for reinforcement learning. APT actively explores reward-free environments to learn behaviors and representations. The key innovation is maximizing non-parametric entropy in an abstract representation space, enabling scalability in high-dimensional observation environments. We evaluate APT by introducing task-specific rewards after a long unsupervised pre-training phase. APT achieves human-level performance on 12 Atari games and competes well with fully supervised RL algorithms. It outperforms baselines in terms of asymptotic performance and data efficiency on DMControl suite, significantly improving performance on challenging tasks.