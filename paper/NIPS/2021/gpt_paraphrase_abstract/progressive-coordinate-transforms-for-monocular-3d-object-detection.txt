This abstract discusses the importance of recognizing and locating objects in a 3D space for an AI agent's perception of its surroundings. While progress has been made using LiDAR point clouds, it is challenging to achieve 3D object detection with only a monocular image. Existing approaches either use heavy networks to fuse RGB and depth information or are ineffective in processing pseudo-LiDAR points. The limitations are attributed to inaccurate object localization. To address this, the authors propose a lightweight approach called Progressive Coordinate Transforms (PCT), which improves coordinate representations through a localization boosting mechanism and a confidence-aware loss. They also utilize semantic image representation to compensate for patch proposals. The PCT approach achieves superior results on monocular 3D detection benchmarks like KITTI and Waymo Open Dataset, and it can be applied to other coordinate-based 3D detection frameworks. The code for PCT is available at the provided GitHub link.