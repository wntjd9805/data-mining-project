Unsupervised contrastive learning, which labels image crops as positives and negatives, suffers from inaccurate label assignment. This issue hampers the generalization of contrastive learning for semantic instance discrimination. To address this, we introduce a novel self-labeling reﬁnement approach that enhances label quality through two modules: self-labeling reﬁnery (SLR) and momentum mixup (MM). SLR estimates the semantic similarity between a query and its positive and negatives, generating more accurate and informative soft labels. Theoretical analysis proves the ability of SLR to recover true semantic labels and achieve zero prediction error. MM combines queries and positives to increase semantic similarity, improving label accuracy. Experimental results on various datasets demonstrate the effectiveness of our method.