The federated Thompson sampling (FTS) algorithm has extended Bayesian optimization (BO) to federated learning (FL), with potential applications in hyperparameter tuning. However, FTS lacks a robust privacy guarantee, an important consideration in FL. To address this, we integrate differential privacy (DP) into FTS to protect user-level privacy. Additionally, we utilize a general DP framework for iterative algorithms to accommodate different parameter vectors and implement local modeling for BO, enhancing the algorithm's utility through distributed exploration (DE). The resulting algorithm, called differentially private FTS with DE (DP-FTS-DE), offers theoretical guarantees for both privacy and utility and provides insights into the privacy-utility trade-off. Real-world experiments demonstrate that DP-FTS-DE achieves high utility while maintaining a strong privacy guarantee, striking a balance between privacy and utility.