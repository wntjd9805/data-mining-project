Contrastive self-supervised learning has made significant progress in narrowing the gap to supervised pre-training on ImageNet. However, its success heavily depends on the object-centric priors of ImageNet, where different augmented views of the same image correspond to the same object. This constraint becomes impractical when dealing with more complex scene images containing multiple objects. To address this limitation, we propose Object-level Representation Learning (ORL), a new framework for self-supervised learning on scene images. Our approach leverages image-level self-supervised pre-training as a prior to discover object-level semantic correspondence, enabling effective object-level representation learning from scene images. Experimental results on COCO demonstrate that ORL significantly enhances the performance of self-supervised learning on scene images, even surpassing supervised ImageNet pre-training on certain downstream tasks. Additionally, ORL demonstrates improved downstream performance when more unlabeled scene images are available, showcasing its potential in harnessing unlabeled data in real-world scenarios. We hope that our approach will inspire future research on unsupervised representation learning from scene data.