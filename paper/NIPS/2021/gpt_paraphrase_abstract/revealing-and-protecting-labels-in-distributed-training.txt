Distributed learning methods like federated learning aim to transmit model updates over a network to protect private data. However, it has been shown that sensitive information about the training data can still be exposed through these updates. Previous studies have demonstrated that labels can be analytically revealed from the last layer of certain models or reconstructed together with model inputs using Gradients Matching and additional knowledge about the model's state. In this research, we propose a technique to identify the labels of training samples solely from the gradient of the last layer and the mapping of IDs to labels. Our approach is applicable to various model architectures in different domains. We validate the effectiveness of our method in image classification and automatic speech recognition for model training. Additionally, we find that existing reconstruction techniques improve their success when used alongside our method. Conversely, we show that gradient quantization and sparsification can significantly reduce the effectiveness of this attack.