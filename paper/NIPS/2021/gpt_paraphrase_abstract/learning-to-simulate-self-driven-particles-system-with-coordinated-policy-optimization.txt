Self-Driven Particles (SDP) are multi-agent systems found in everyday life, like flocks of birds and traffic flows. Designing controllers for SDP systems manually is time-consuming and the resulting behaviors are often unrealistic and not generalizable. Reinforcement learning offers an attractive solution for automating controller development in SDP. However, existing multi-agent reinforcement learning (MARL) methods define agents as teammates or enemies, which does not capture the essence of SDP where agents can switch between cooperative and competitive roles. To address this, we propose a novel MARL method called Coordinated Policy Optimization (CoPO), which incorporates social psychology principles to learn neural controllers for SDP. Our experiments demonstrate that CoPO outperforms MARL baselines in various metrics. The trained vehicles exhibit diverse and complex social behaviors, improving performance and safety as a whole. Demo video and source code are available at: https://decisionforce.github.io/CoPO/.