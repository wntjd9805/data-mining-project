This paper introduces a novel method for efficiently registering non-rigid 3D point clouds using a transformer-based approach. Unlike previous methods, our approach is data-driven and utilizes the transformer architecture for the first time in the registration task. Our method is versatile and can be applied in various scenarios. It can register raw acquired data to a fixed template, transferring all the template properties to the input geometry. It can also register one shape onto another, creating a high-quality dense correspondence between the two. Our results are of high quality, making it suitable for real applications like texture transfer and shape interpolation. Additionally, we demonstrate that incorporating an estimation of the surface density aids in the learning process. By leveraging the potential of this architecture, our model can be trained with only a sparse set of ground truth correspondences. Our proposed model and analysis open up possibilities for future exploration of transformer-based architectures in registration and matching applications. Through qualitative and quantitative evaluations, we show that our pipeline outperforms state-of-the-art methods for registering deformable and unordered 3D data in different datasets and scenarios.