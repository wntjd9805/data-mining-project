Continual learning (CL) is crucial for long-term autonomous reinforcement learning agents, as it allows them to continuously build on previous knowledge. However, finding the right balance between capacity constraints, avoiding catastrophic forgetting, and positive transfer on new tasks is challenging. Currently, there is an excessive focus on catastrophic forgetting in the community. To address these issues, we propose prioritizing forward transfer and introduce Continual World, a benchmark of diverse robotic tasks based on Meta-World. We evaluate existing CL methods and identify their limitations, highlighting unique algorithmic challenges in RL. Our benchmark offers a computationally inexpensive challenge to improve understanding of current and future solutions. More information, including open-source code, can be found at https://sites.google.com/view/continualworld.