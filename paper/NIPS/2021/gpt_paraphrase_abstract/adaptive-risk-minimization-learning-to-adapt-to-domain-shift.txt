Most machine learning algorithms assume that the training and test data come from the same distribution, but this is often not the case in practical applications. Machine learning systems are frequently tested under different conditions, such as changes in temporal correlations or atypical users. In this study, we focus on the problem of domain generalization, where the training data is divided into domains and there may be multiple shifts in the test data. Previous methods aimed to learn a single model or feature space that performs well on all domains, but we propose a new approach called adaptive risk minimization (ARM). ARM optimizes models to adapt to shifts by learning from unlabeled test points. Compared to previous methods, ARM provides a 1-4% increase in test accuracy on various image classification problems with domain shift.