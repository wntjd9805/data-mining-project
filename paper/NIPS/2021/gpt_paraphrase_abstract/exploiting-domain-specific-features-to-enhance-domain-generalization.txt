Domain Generalization (DG) is a technique used to train a model that can perform well on new, unseen domains by learning from multiple observed source domains. Previous approaches to DG have focused on extracting domain-invariant information across sources to generalize on target domains, but have often ignored domain-specific information that is strongly correlated with labels in individual domains and generalization to target domains. In this paper, we propose a new framework called meta-Domain SpeciÔ¨Åc-Domain Invariant (mDSDI) that goes beyond the traditional invariance view and considers the usefulness of domain-specific information. Our approach disentangles features in the latent space and simultaneously learns both domain-invariant and domain-specific features in a unified framework. We optimize the domain-specific representation through a meta-learning framework that adapts from source domains, aiming for robust generalization on unseen domains. Empirical results demonstrate that mDSDI achieves competitive performance compared to state-of-the-art DG techniques. Additionally, an ablation study conducted on our generated dataset, Background-Colored-MNIST, confirms the importance of domain-specific information, as it leads to better results compared to using only domain-invariant information.