Probability discrepancy measure is a crucial component in various machine learning models, including weakly supervised learning and generative modeling. However, existing measures often overlook the fact that distributions are not the final output of learning but rather the input for a downstream predictor. Therefore, it is essential to adjust the probability discrepancy measure to align with the end tasks. To address this, we propose a novel bi-level optimization approach that compares the two distributions not uniformly against the entire hypothesis space but only in relation to the optimal predictor for the downstream task. By applying this approach to margin disparity discrepancy and contrastive domain discrepancy, we observe significant performance improvements in unsupervised domain adaptation. Additionally, our method offers a more principled training process.