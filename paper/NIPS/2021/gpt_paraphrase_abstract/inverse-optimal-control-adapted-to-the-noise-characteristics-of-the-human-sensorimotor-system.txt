Computational level explanations of human sensorimotor behavior often rely on optimal feedback control with signal-dependent noise. However, these explanations typically require assuming a cost function for a task and comparing observed and predicted trajectories to evaluate the optimality of human behavior. In this study, we introduce a new approach called inverse optimal control with signal-dependent noise, which allows us to infer the cost function from observed behavior. We formulate the problem as a partially observable Markov decision process and differentiate between the agent's and experimenter's inference problems. We develop a probabilistic formulation for the evolution of states and belief states, as well as an approximation for the propagation equation in the linear-quadratic Gaussian problem with signal-dependent noise. We also extend the model to account for the experimenter's partial observability of state variables. We validate our approach using synthetic data and apply it to experimental data, demonstrating its feasibility. By recovering the implicit costs and benefits in human sequential sensorimotor behavior, our approach reconciles normative and descriptive approaches within a computational framework.