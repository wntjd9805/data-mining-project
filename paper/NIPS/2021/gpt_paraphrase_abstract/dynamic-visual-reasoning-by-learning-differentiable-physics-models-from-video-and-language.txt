This study introduces a unified framework called Visual Reasoning with Differentiable Physics (VRDP) that combines visual perception, concept learning, and a differentiable physics engine to learn visual concepts and infer physics models from videos and language. The visual perception module analyzes video frames, identifying object-centric trajectories and representing them as latent scene representations. The concept learner grounds visual concepts based on language, providing prior knowledge for the physics engine. The differentiable physics engine, implemented as a differentiable rigid-body simulator, performs physical simulations based on the grounded concepts to infer physical properties like mass, restitution, and velocity. These learned concepts and physical models can explain observed phenomena and predict future and counterfactual scenarios. Integrating differentiable physics improves dynamics prediction accuracy, achieving state-of-the-art performance on synthetic and real-world benchmarks while maintaining transparency and interpretability. VRDP is also data-efficient, capable of optimizing physical parameters from a small number of videos or even a single video. Additionally, with inferred physical parameters, VRDP can quickly learn new concepts from a few examples.