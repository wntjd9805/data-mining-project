We present a principled technique for optimizing the precision-recall curve area (AUPRC) in deep learning, which is a more suitable metric for imbalanced datasets than the commonly used AUROC. While AUROC has been extensively studied, stochastic optimization of AUPRC has received little attention. Our method is based on maximizing the averaged precision (AP), an unbiased estimator of AUPRC. We formulate the objective as a sum of coupled compositional functions with inner functions dependent on random variables. We propose efficient stochastic algorithms called SOAP, which have provable convergence guarantees under mild conditions. Experimental results on image and graph datasets show that our approach outperforms previous methods in terms of AUPRC for imbalanced problems. This is the first attempt to optimize AUPRC with provable convergence, and our SOAP algorithm is available in the libAUC library at https://libauc.org/.