We propose a new learning setting where a map image is used to determine labels. We introduce a risk bound that separates into bias and error terms, with the bias term being significantly influenced by true labels. Based on these findings, we present an algorithm that minimizes the bias term by independently sampling from each set. This approach is applied to visual classification tasks, allowing classifiers to be trained on datasets consisting of just one synthetic example per class. In real-world image classification benchmarks, our method shows robust performance and generalization to different domains. In contrast, classifiers trained on real-world data without our techniques are sensitive to background perturbations.