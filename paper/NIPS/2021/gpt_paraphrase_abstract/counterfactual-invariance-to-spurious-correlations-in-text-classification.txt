The concept of "spurious correlation" refers to the dependence of a model on irrelevant aspects of input data. In machine learning, these correlations can be identified by observing changes in model predictions when irrelevant data is altered. This paper explores the use of causal inference techniques to stress test models for spurious correlations. The authors introduce the concept of "counterfactual invariance" as a measure of whether changing irrelevant input data should affect model predictions. They also examine the relationship between counterfactual invariance and model performance outside of the training domain. The authors propose practical methods for learning counterfactual invariant predictors, even without access to counterfactual examples. They find that the nature and implications of counterfactual invariance are dependent on the underlying causal structure of the data. Different causal structures require different regularization schemes to achieve counterfactual invariance. Additionally, counterfactual invariance has different implications for domain shift depending on the causal structure. This theory is supported by empirical results in text classification.