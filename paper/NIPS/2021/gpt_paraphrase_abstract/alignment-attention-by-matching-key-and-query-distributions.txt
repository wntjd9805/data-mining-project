The neural attention mechanism has been widely used in deep neural networks to achieve impressive performance in different domains. Most existing models employ multi-head self-attention, which allows for attending to information from various perspectives. In this study, we introduce alignment attention, which specifically encourages self-attention to align the distributions of the key and query within each head. By incorporating alignment attention into existing attention frameworks, we can optimize the resulting networks through unsupervised regularization. Our approach is easily applicable to any models using self-attention, even pre-trained ones. Through experiments on language understanding tasks, we demonstrate the effectiveness of our method in terms of accuracy, uncertainty estimation, domain generalization, and resilience against adversarial attacks. Additionally, we showcase the versatility of our approach by applying it to graph attention and visual question answering, highlighting its potential for enhancing various attention-related tasks.