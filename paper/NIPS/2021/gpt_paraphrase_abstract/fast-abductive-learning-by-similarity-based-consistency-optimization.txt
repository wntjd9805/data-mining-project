Recent neuro-symbolic learning methods integrate sub-symbolic perception and logical inference by using abduction, which is abductive reasoning. Abduction helps correct perceived facts that are inconsistent with the background knowledge base by minimizing the inconsistency between them. However, previous approaches require an initialized perception model that discriminates input raw instances, limiting their application when the raw inputs are difficult to classify. This paper proposes a new abduction strategy, ABductive Learning with Similarity (ABLSim), which uses the similarity between samples instead of the output information from the perceptual neural network to guide the search in abduction. ABLSim is applied to difficult neuro-symbolic learning tasks and experiments show that it is significantly more efficient than the state-of-the-art methods, achieving better performance with less labeled data and weaker domain knowledge.