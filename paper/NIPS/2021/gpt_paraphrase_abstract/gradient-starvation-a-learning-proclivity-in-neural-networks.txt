We have discovered and defined a key phenomenon in neural networks called "Gradient Starvation." This occurs when the network only captures a limited set of relevant features for a given task, ignoring other predictive features that could be useful. We provide a theoretical explanation for why this happens, using concepts from Dynamical Systems theory. Our research shows that this feature imbalance is expected under certain statistical conditions in the training data. To address this issue, we propose a new regularization method that improves accuracy and robustness by decoupling the learning dynamics of different features. We validate our findings through experiments on both simple and real-world datasets, demonstrating improved generalization in out-of-distribution scenarios.