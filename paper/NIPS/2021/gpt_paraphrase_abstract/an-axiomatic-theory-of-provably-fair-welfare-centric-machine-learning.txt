We propose an alternative approach to fair machine learning (ML) that addresses a challenge in welfare-based fair ML. We introduce the concept of malfare, which measures overall societal harm, and justify it using cardinal welfare axioms. We redefine fair ML as malfare minimization and show that it is not equivalent to maximizing welfare by defining utility as negative loss. We introduce fair-PAC learning, which is an algorithm that learns an ε-δ malfare-optimal model with bounded sample complexity. We demonstrate conditions under which standard PAC-learners can be converted to fair-PAC learners, providing statistical and computational efficiency guarantees for well-studied ML models. Fair-PAC learning democratizes fair ML by offering concrete training algorithms with rigorous generalization guarantees.