The synthesis problem in design, fabrication, and control often requires generating an object or configuration that meets constraints and maximizes objective functions. This task is challenging due to the many possible realizations and the non-differentiable nature of physical simulations. To address these challenges, we propose a two-stage neural network architecture that acts as an autoencoder. We first learn a decoder that approximates the many-to-one physical realization process, and then learn an encoder that maps from goal to design. Our approach outperforms supervised learning and is comparable to direct optimization in terms of solution quality, while significantly reducing computational cost.