We examine the problem of online linear regression in a stochastic setting. By analyzing online ridge regression and the forward algorithm, we establish regret bounds with high probability. This allows for a more accurate comparison of online regression algorithms and eliminates the need for assumptions about bounded observations and predictions. Our research supports the use of the forward algorithm instead of ridge regression due to its improved bounds and resilience to the regularization parameter. Additionally, we demonstrate how to incorporate the forward algorithm into algorithms involving linear function approximation, eliminating the need for boundedness assumptions without compromising theoretical bounds. We apply this modification to linear bandit settings, resulting in enhanced regret bounds. Finally, we conduct numerical experiments to validate our findings and support our intuitions.