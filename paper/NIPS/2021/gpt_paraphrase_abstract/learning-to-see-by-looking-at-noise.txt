Current vision systems are typically trained on large datasets, which come with various drawbacks such as high costs for curation, potential human biases, and concerns regarding privacy and usage rights. To address these issues, there has been growing interest in exploring alternative and more affordable data sources, such as unlabeled images. This research takes a step further by questioning the necessity of using real image datasets altogether and instead proposes learning from procedural noise processes. Multiple image generation models that generate images from simple random processes are examined, and these images are utilized as training data for a visual representation learner with a contrastive loss. The study investigates statistical image models, randomly initialized deep generative models, and procedural graphics models. The results indicate that while the noise should capture certain structural properties of real data, satisfactory performance can still be achieved even with processes that are far from realistic. Furthermore, the research emphasizes the importance of diversity in the training data for the acquisition of effective representations.