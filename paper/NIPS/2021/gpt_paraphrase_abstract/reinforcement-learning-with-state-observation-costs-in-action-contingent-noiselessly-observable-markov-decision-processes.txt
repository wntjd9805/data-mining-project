This study focuses on solving real-world problems that involve making optimal decisions in uncertain situations while considering the costs associated with obtaining information about the environment. The researchers develop and analyze algorithms for reinforcement learning in Action-Contingent Noiselessly Observable MDPs (ACNO-MDPs), a specific type of POMDPs. ACNO-MDPs are commonly found in domains like healthcare, where the value of information gained from medical tests must be balanced with the costs of conducting those tests. The researchers propose a Probably Approximately Correct (PAC) RL algorithm for tabular ACNO-MDPs that offers tighter bounds compared to generic POMDP-RL algorithms. For continuous-state ACNO-MDPs, they introduce a new method of incorporating observation information, which enables faster learning compared to other POMDP-RL algorithms in various simulated environments.