As predictive models are implemented in real-world scenarios, they face the challenge of dealing with strategic behavior. Current research on strategic classification approaches this issue as a Stackelberg game, where the decision-maker takes the lead by deploying a model and the strategic agents respond accordingly. However, this approach places the learning burden solely on the decision-maker and assumes that the agents' responses are immediate. In this study, we argue that the order of play in strategic classification is determined by how quickly the decision-maker and agents adapt to each other's actions. By allowing both players to learn over time, we demonstrate that if the decision-maker updates faster than the agents, the order of play can be reversed. Surprisingly, this role reversal can be advantageous for both the decision-maker and the strategic agents in typical learning settings. Furthermore, we show that when the decision-maker has the flexibility to choose their update frequency, they can induce learning dynamics that converge to Stackelberg equilibria with either order of play.