The performance of deep neural networks improves as the model size increases, which contradicts traditional views on overfitting and generalization. The double descent phenomenon suggests that test error decreases again when the model is sufficiently overparameterized. In this study, we examine the learning dynamics of the least squares scenario as a function of model size. We establish an excess risk bound for the gradient descent solution of the least squares objective, which is influenced by the smallest non-zero eigenvalue of the sample covariance matrix of the input features. Our analysis decouples the effect of optimization and generalization error, showing that double descent in noiseless regression is solely explained by optimization-related quantities. This differs from previous studies that focused on the Moore-Penrose pseudoinverse solution. We provide an alternative perspective that sheds light on the cause of the double descent phenomenon in the least squares setting. Additionally, we empirically investigate whether our predictions hold for neural networks by examining the spectrum of the sample covariance of features at intermediary hidden layers.