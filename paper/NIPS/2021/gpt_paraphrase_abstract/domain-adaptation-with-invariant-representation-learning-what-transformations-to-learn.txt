Unsupervised domain adaptation is a widely-used transfer learning approach in various real-world applications. Recent domain adaptation methods utilize deep neural networks to map input features to a latent representation with the same distribution across domains. However, this approach is not sufficient for optimal classification representation, and usually requires strong assumptions to find conditionally invariant representations. We explain why mapping the input features fixed across domains may not be suitable for domain adaptation when the source and target data supports overlap. To address this issue, we propose an efficient technique that incorporates domain-specific information along with the input features to find the optimal mapping from input to latent representation. Our model considers the minimal changes in causal mechanisms across domains, ensuring that the latent representation preserves valuable information about the target variable. We validate the effectiveness of our method through experiments on synthetic and real-world data. The code for our approach is available at the following GitHub repository: https://github.com/DMIRLAB-Group/DSAN.