Deep Spiking Neural Networks (SNNs) pose challenges for gradient-based methods due to their binary activation and complex dynamics. This study aims to train deep SNNs using residual learning, inspired by the success of ResNet in deep learning. Previous approaches, like SpikingResNet, failed to implement residual learning effectively. To address this, the spike-element-wise (SEW) ResNet is proposed, which can easily implement identity mapping and overcome gradient problems. The SEW ResNet is evaluated on different datasets and outperforms other directly trained SNNs in terms of accuracy and time-steps. Additionally, it is found that SEW ResNet achieves better performance with the addition of more layers, offering a simple method to train deep SNNs. Notably, this is the first successful attempt to directly train deep SNNs with over 100 layers. The code for SEW ResNet is available at https://github.com/fangwei123456/Spike-Element-Wise-ResNet.