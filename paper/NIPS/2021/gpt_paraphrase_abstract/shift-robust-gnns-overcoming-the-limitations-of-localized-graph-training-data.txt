There has been a recent increase in interest in developing Graph Neural Networks (GNNs) for semi-supervised learning tasks. However, previous research has assumed that the labeled nodes used for training are selected uniformly at random, which is not realistic in many real-world scenarios where data labeling is expensive and biased. This assumption leads to poor generalization of GNNs and overfitting to irrelevant patterns in the training data. To address this issue, we propose a method called Shift-Robust GNN (SR-GNN) that takes into account the distributional differences between biased training data and the actual distribution of the graph. Through various experiments on common GNN benchmark datasets, we demonstrate that SR-GNN outperforms other GNN models in terms of accuracy, reducing the negative effects introduced by biased training data by approximately 40%. On the largest dataset considered, ogb-arxiv, we achieve a 2% absolute improvement over the baseline and mitigate 30% of the negative effects caused by training data bias.