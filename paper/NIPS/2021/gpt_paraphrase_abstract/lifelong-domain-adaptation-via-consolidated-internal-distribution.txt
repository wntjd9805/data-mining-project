We have developed an algorithm to tackle the issue of unsupervised domain adaptation (UDA) in continual learning (CL) scenarios. Our algorithm aims to continually update a model in order to learn from distributional shifts in sequentially arriving tasks using unlabeled data, while also retaining knowledge about previously learned tasks. While existing UDA algorithms can address domain shift, they require simultaneous access to datasets from both the source and target domains. On the other hand, existing CL methods can handle tasks with labeled data. Our solution involves consolidating the learned internal distribution to improve model generalization on new domains, and leveraging experience replay to overcome catastrophic forgetting.