Word meaning can change over time due to societal changes, so it is important to consider time in word representation for certain tasks. Existing approaches train embeddings separately for each time-stamped corpus and align them using various methods. However, word meaning can change both in the short term and over long periods, suggesting a continuous process. A recent approach called 'Diff-Time' uses neural networks to model semantic evolution over time. This paper extends that approach by learning explicit functions over time for each word. The proposed 'Word2Fun' approach reduces the space complexity and can approximate any function modeling word evolution with a small error. The effectiveness of the approach is demonstrated through tasks like word clustering, temporal analogy, and semantic change detection. Code for the approach is available at the provided GitHub link.