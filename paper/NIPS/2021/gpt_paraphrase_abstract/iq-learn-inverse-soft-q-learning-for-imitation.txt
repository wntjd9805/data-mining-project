Imitation learning (IL) can be difficult in complex environments with high dimensions. Existing methods that incorporate dynamics information are challenging to train due to their adversarial optimization process. We propose a dynamics-aware IL method called IQ-Learn that learns a single Q-function to represent both reward and policy, avoiding adversarial training. Our method achieves state-of-the-art results in offline and online IL settings, outperforming existing methods in terms of required environment interactions and scalability in high-dimensional spaces. IQ-Learn shows promise for inverse reinforcement learning (IRL) as well, as the implicitly learned rewards correlate positively with ground-truth rewards.