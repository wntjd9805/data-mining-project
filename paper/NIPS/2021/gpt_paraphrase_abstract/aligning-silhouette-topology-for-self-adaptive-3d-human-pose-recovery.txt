Most existing techniques for 3D human pose estimation rely on articulation-centric 2D/3D pose supervision, which is inconvenient to acquire in real target domains. However, we observe that standard foreground silhouette estimation techniques on static camera feeds are not affected by domain-shifts. Based on this observation, we propose a novel target adaptation framework that uses only silhouette supervision to adapt a source-trained model-based regressor. Since an isolated silhouette loss is not sufficient for reliable pose-specific gradients without additional cues, we introduce a topology-centric loss that works in tandem with the silhouette loss. To achieve this, we develop convolution-friendly spatial transformations to separate the topological-skeleton representation from the raw silhouette. This enables the design of a Chamfer-inspired spatial topological-alignment loss using distance field computation, which avoids any hindrance in spatial-to-pointset mapping. Experimental results demonstrate the superiority of our approach over prior methods in adapting a source trained model to diverse unlabeled target domains, including in-the-wild datasets, low-resolution image domains, and adversarially perturbed image domains.