Rule-based models, such as decision trees, are commonly used when model interpretability is important. However, optimizing these models can be challenging, especially with large datasets, due to their discrete parameters and structures. Ensemble methods and fuzzy/soft rules are often used to improve performance, but this sacrifices interpretability. To address this, we propose a new classifier called Rule-based Representation Learner (RRL) that automatically learns interpretable non-fuzzy rules for data representation and classification. To effectively train the non-differentiable RRL, we project it to a continuous space and introduce a novel training method called Gradient Grafting, which optimizes the discrete model using gradient descent. We also improve the design of logical activation functions to enhance the scalability of RRL and enable it to discretize continuous features end-to-end. Extensive experiments on small and large datasets demonstrate that RRL outperforms other interpretable approaches and can be easily adjusted to balance classification accuracy and model complexity for different scenarios. Our code is available at: https://github.com/12wang3/rrl.