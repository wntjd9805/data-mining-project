Federated learning is a popular approach for training machine learning models across different domains. This method is also applicable to graph-level tasks, where graphs can be seen as special data samples stored in separate local systems. Collaborative training of graph neural networks (GNNs) can be beneficial for multiple local systems with small sets of graphs. To support this idea, we analyze real-world graphs from various domains and find that they share significant graph properties compared to random graphs. However, we also discover that different sets of graphs, even within the same domain or dataset, exhibit non-IID characteristics in terms of graph structures and node features. To address this issue, we propose a framework called graph clustered federated learning (GCFL), which identifies clusters of local systems based on GNN gradients. This approach reduces heterogeneity among the graphs in each cluster. Additionally, we observe that GNN gradients are highly fluctuating in GCFL, which affects clustering quality. To overcome this, we introduce a gradient sequence-based clustering mechanism called GCFL+, which utilizes dynamic time warping. Our extensive experiments and analysis demonstrate the effectiveness of both proposed frameworks.