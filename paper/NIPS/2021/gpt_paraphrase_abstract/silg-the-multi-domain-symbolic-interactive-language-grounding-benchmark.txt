Current research in language grounding focuses on studying single environments. This abstract proposes the development of a multi-environment Symbolic Interactive Language Grounding benchmark (SILG) that unifies various grounded language learning environments. SILG consists of grid-world environments that require generalization to new dynamics, entities, and partially observed worlds, as well as symbolic counterparts of visual worlds that involve interpreting complex scenes using rich natural language. These environments present diverse challenges in terms of observation space, action space, language specification, and plan complexity. The abstract also introduces a shared model architecture for reinforcement learning on these environments and evaluates recent advancements such as egocentric local convolution, recurrent state-tracking, entity-centric attention, and pretrained language models using SILG. The shared architecture achieves similar performance to environment-specific architectures, but it is observed that many recent modeling advancements do not yield significant improvements on environments other than the ones they were designed for. This emphasizes the necessity of a multi-environment benchmark. The best models still fall short of human performance on SILG, indicating room for future research. The authors hope that SILG will facilitate the discovery of new methodologies for language grounding that can effectively generalize across diverse environments and their associated challenges.