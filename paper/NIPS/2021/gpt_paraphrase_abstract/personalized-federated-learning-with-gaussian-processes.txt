Federated learning is a technique that aims to train a global model on client devices without extensive communication. Personalized federated learning (PFL) expands on this concept by accounting for data differences between clients and learning personalized models. Learning effectively across clients is challenging due to unique and limited data. This study introduces pFedGP, a PFL solution based on Gaussian processes (GPs) with deep kernel learning. GPs are effective in low data scenarios but face challenges in PFL. To address this, a shared kernel function is learned using a neural network, with a personal GP classifier for each client. Two novel methods are also introduced to improve generalization and reduce computational cost. PAC-Bayes generalization bound is derived and empirical results show significant improvements in accuracy compared to baseline methods, with up to 21% gain.