We present Invertible Dense Networks (i-DenseNets), an enhanced version of Residual Flows that is more efficient in terms of parameters. Our approach focuses on analyzing the Lipschitz continuity of the concatenation in DenseNets, ensuring the network's invertibility by meeting the Lipschitz constant. Additionally, we propose a learnable weighted concatenation that not only enhances model performance but also highlights the importance of the concatenated weighted representation. We also introduce the Concatenated LipSwish activation function, which maintains the Lipschitz condition and improves performance. Our i-DenseNet architecture surpasses Residual Flow and other flow-based models in density estimation, measured in bits per dimension, while using the same parameter budget. Furthermore, our model outperforms Residual Flows when trained as a hybrid model that functions as both a generative and discriminative model.