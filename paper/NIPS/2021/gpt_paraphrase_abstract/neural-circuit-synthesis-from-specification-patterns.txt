We explore the use of hierarchical Transformers to directly generate hardware circuits from high-level logical specifications in linear-time temporal logic (LTL). The LTL synthesis problem is a well-known challenge with an annual competition to track algorithm improvements. While machine learning approaches have potential in this area, they lack sufficient training data. To address this, we propose a method to generate additional training data by creating pairs of specifications and corresponding circuits. To ensure the synthetic data is close to human-written specifications, we mine common patterns from specifications used in the synthesis competitions. Our experiments demonstrate that hierarchical Transformers trained on this synthetic data successfully solve a significant portion of synthesis competition problems and even perform well on out-of-distribution examples from a recent case study.