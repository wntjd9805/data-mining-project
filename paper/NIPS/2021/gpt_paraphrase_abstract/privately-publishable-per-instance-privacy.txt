We explore the sharing of personalized privacy losses incurred through objective perturbation using per-instance differential privacy (pDP). While standard differential privacy (DP) provides a worst-case bound, it often overestimates the privacy loss for a specific individual relative to a fixed dataset. The pDP framework offers a more detailed analysis of privacy guarantees for a target individual, but the per-instance privacy loss itself can be influenced by sensitive data. In this study, we examine the per-instance privacy loss when releasing a private empirical risk minimizer learned through objective perturbation. We propose a set of methods to accurately and privately disclose the pDP losses with minimal additional privacy risk.