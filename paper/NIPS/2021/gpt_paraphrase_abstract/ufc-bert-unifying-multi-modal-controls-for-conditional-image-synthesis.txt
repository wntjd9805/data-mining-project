This paper presents UFC-BERT, a two-stage architecture for conditional image synthesis that unifies multiple multi-modal control signals. Unlike previous approaches, UFC-BERT uses non-autoregressive generation in the second stage to improve the consistency, speed, and preservation of specified image blocks in the synthesized image. The authors also propose a progressive algorithm that iteratively enhances the non-autoregressively generated image using two estimators for control compliance and image fidelity. Experimental results on clothing and facial datasets demonstrate that UFC-BERT can generate high-fidelity images that adhere to flexible multi-modal controls.