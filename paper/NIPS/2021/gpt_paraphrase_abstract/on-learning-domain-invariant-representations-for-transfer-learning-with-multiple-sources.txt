Domain adaptation (DA) has been extensively studied, focusing on learning domain-invariant representations and understanding the trade-offs involved. However, the complexity of multiple source domain adaptation and domain generalization (DG) settings has not received the same level of attention. These settings involve multiple source domains and the potential unavailability of the target domain during training. This paper introduces new upper-bounds for the target general loss and proposes two types of domain-invariant representations. The advantages, disadvantages, and trade-offs of learning each representation are thoroughly examined. Experimental analysis is conducted to investigate the trade-offs of these representations, providing practical insights on their usage and exploring additional properties of the developed theory.