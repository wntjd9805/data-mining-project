We present Deformable Butterﬂy (DeBut), a novel linear transformation that extends conventional butterﬂy matrices and can be adjusted for different input-output dimensions. DeBut retains the hierarchical structure of traditional butterﬂies, allowing for network compression when incorporated into neural networks. By replacing standard fully connected and convolutional layers with DeBut, we achieve a more uniform network with favorable properties such as reduced weight and inference complexity, while maintaining accuracy. The flexibility of DeBut also offers opportunities for analytical and practical exploration of the complexity-accuracy tradeoff. The code and Appendix can be accessed at: https://github.com/ruilin0212/DeBut.