We present DMTET, a deep 3D conditional generative model that can create detailed 3D shapes using simple user instructions like coarse voxels. Our model combines the advantages of implicit and explicit 3D representations by utilizing a new hybrid 3D representation. Unlike existing implicit approaches that regress signed distance values, DMTET directly optimizes for the reconstructed surface, resulting in finer geometric details and fewer artifacts. Unlike other deep 3D generative models that generate explicit representations like meshes, our model can generate shapes with any topology. DMTET consists of a deformable tetrahedral grid that encodes a discretized signed distance function and a differentiable marching tetrahedra layer that converts the implicit representation to an explicit surface mesh. This combination enables joint optimization of surface geometry, topology, and subdivision hierarchy using reconstruction and adversarial losses defined on the surface mesh. Our approach outperforms current methods for synthesizing shapes from coarse voxel inputs, as demonstrated on a dataset of complex 3D animal shapes. For more information, please visit our project page: https://nv-tlabs.github.io/DMTet/.