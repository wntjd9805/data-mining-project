We propose Traversal Network (TNet), a new hard-attention architecture called that allows us to utilize high-resolution information without the computational burden associated with input scale. TNet operates in a top-down manner, navigating through image scale-space and focusing only on the most informative regions. By adjusting the number of attended image locations, TNet provides a flexible balance between accuracy and complexity. In comparison to hard-attention baselines, our model achieves higher accuracy on ImageNet while utilizing fewer resources such as FLOPs, processing time, and memory. We also evaluate TNet on the fMoW dataset, processing satellite images up to 896Ã—896 px in size. Our model achieves up to 2.5 times faster processing than baselines operating at the same resolution, while maintaining superior accuracy. TNet is modular, allowing it to be used with various classification models for feature extraction, resulting in additional performance gains. Furthermore, our hard-attention approach provides interpretability to the model's predictions without incurring any extra cost during inference.