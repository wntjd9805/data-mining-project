Significant advancements have been made in recent years regarding the development of neural networks that adhere to the fundamental symmetries and coordinate freedoms of physical laws. Various frameworks utilize irreducible representations, high-order tensor objects, or symmetry-enforcing constraints. While different physical laws follow different combinations of fundamental symmetries, a considerable portion, if not all, of classical physics is equivariant to translation, rotation, reflection (parity), boost (relativity), and permutations. This study demonstrates that it is straightforward to parameterize universally approximating polynomial functions that maintain equivariance under these symmetries, as well as under the Euclidean, Lorentz, and Poincar√© groups, across any dimensionality. The key insight is that nonlinear O(d)-equivariant (and related-group-equivariant) functions can be universally expressed using a concise set of scalars, such as scalar products and scalar contractions of scalar, vector, and tensor inputs. Numerical examples are provided to support the theory, illustrating that the scalar-based approach is simple, efficient, and scalable.