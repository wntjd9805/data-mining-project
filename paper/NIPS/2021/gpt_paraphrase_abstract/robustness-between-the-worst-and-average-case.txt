Many recent studies in machine learning have focused on assessing the robustness of classifiers at test time, specifically how well they perform on perturbed examples in addition to the original training domain. Previous research has mainly examined two extremes of robustness: robustness to random perturbations and robustness to the worst-case perturbations. This paper argues that a continuum between these extremes offers an important additional measure of robustness. The authors propose that each extreme can be characterized by a q-norm over the perturbation space, with q=1 representing robustness to random perturbations and q=âˆž representing robustness to adversarial perturbations. The main technical contribution of this paper is a method to efficiently estimate the value of these norms by treating them as the partition function of a specific distribution and using path sampling with Markov Chain Monte Carlo (MCMC) methods. The authors demonstrate that their approach provides more accurate estimates of the "intermediate-q" robustness of various classifiers compared to simple random sampling. This highlights a tradeoff between classifiers that optimize different metrics. The code for reproducing the experiments is available at https://github.com/locuslab/intermediate_robustness.