Understanding the training process of deep learning models is essential for comprehending their effectiveness. This study investigates how data from different classes gradually become distinguishable in their feature spaces during neural network training with stochastic gradient descent. By employing a set of stochastic differential equations (SDEs), we model the evolution of features throughout the training process. Each SDE represents a training sample and includes a drift term that reflects the impact of backpropagation on all samples' features. Our key finding reveals a significant phase transition phenomenon concerning the intra-class impact. If the SDEs exhibit local elasticity, meaning the impact is more pronounced on samples from the same class as the input, the features of the training data become linearly separable, resulting in vanishing training loss. Conversely, if the features lack separability, regardless of the training duration, the impact is not locally elastic. Additionally, our SDE analysis demonstrates the emergence of a neural collapse, a simple geometric structure, when local elasticity is present. Overall, our findings emphasize the crucial role of local elasticity in the training dynamics of neural networks. We validate our theoretical analysis through experiments conducted on a synthesized dataset of geometric shapes and CIFAR-10.