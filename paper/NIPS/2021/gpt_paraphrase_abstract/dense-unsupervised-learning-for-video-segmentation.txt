We introduce a new method for unsupervised learning in video object segmentation (VOS) that allows for the direct learning of dense feature representations using a fully convolutional approach. Our method uses uniform grid sampling to extract anchors and trains the model to distinguish between them at both inter- and intra-video levels. However, training the model using a simple approach leads to a suboptimal solution. To address this, we propose a regularization scheme that takes into account the equivariance property of the segmentation task to similarity transformations. Our training objective is efficient and quickly converges. Despite using less training data and compute power, our approach achieves higher segmentation accuracy than previous methods on established VOS benchmarks.