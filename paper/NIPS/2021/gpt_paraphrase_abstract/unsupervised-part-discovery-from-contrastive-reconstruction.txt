This study focuses on self-supervised visual representation learning, which aims to develop strong and transferable image representations. While most research in this area has concentrated on object or scene-level representation learning, there has been limited attention given to learning representations at the part level. The authors propose an unsupervised approach for discovering and segmenting object parts, making three main contributions. Firstly, they create a proxy task with multiple objectives to encourage the model to learn a meaningful decomposition of the image into its parts. Secondly, they demonstrate that previous approaches, which rely on reconstructing or clustering pre-computed features, are unlikely to find meaningful parts due to low resolution and the tendency of classification networks to smudge out spatial information. The authors propose using image reconstruction at the pixel level as a complementary cue to address this issue. Finally, they introduce new evaluation metrics, NMI and ARI, to better assess the quality of object part decomposition, as the commonly used keypoint regression evaluation does not correlate well with segmentation quality. The proposed method outperforms existing approaches on three benchmark datasets, producing consistent semantic parts across visually distinct categories. The code for this study is available on the project page: https://www.robots.ox.ac.uk/~vgg/research/unsup-parts/.