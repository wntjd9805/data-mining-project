Inferring the 3D locations and shapes of multiple objects from a single 2D image has been a long-standing goal in computer vision. Existing methods either predict one of these properties or focus on a single object. The main challenge is to learn an effective image representation for 3D detection and reconstruction. In this study, we propose learning a regular grid of 3D voxel features aligned with the 3D scene space using a 3D feature lifting operator. With these voxel features, our novel CenterNet-3D detection head formulates 3D detection as keypoint detection in 3D space. We also introduce an efficient coarse-to-fine reconstruction module, including voxelization and a new local PCA-SDF shape representation, enabling detailed reconstruction and faster inference than previous methods. By incorporating supervision from both 3D detection and reconstruction, our approach preserves geometry and context in the 3D voxel features, benefiting both tasks. We demonstrate the effectiveness of our approach in single and multiple object scenarios. The code is available at http://cvlab.cse.msu.edu/project-mdr.html.