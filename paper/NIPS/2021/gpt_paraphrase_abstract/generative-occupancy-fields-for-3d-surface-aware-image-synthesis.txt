The emergence of generative radiance fields has greatly advanced the development of 3D-aware image synthesis. While radiance fields make training generative models easier due to their rendering process, they result in diffuse object surfaces. On the other hand, occupancy representations can ensure deterministic surfaces, but using them directly in generative models leads to convergence issues. To address this, we propose Generative Occupancy Fields (GOF), a novel model that combines the benefits of both radiance fields and occupancy representations. GOF incorporates a transition from cumulative rendering to rendering with surface points as the learned surface becomes more accurate. This transition is achieved by gradually reducing the sampling region in the rendering process. Experimental results demonstrate that GOF can generate high-quality images with 3D consistency while learning compact and smooth object surfaces. Our code is available at https://github.com/SheldonTsui/GOF_NeurIPS2021.