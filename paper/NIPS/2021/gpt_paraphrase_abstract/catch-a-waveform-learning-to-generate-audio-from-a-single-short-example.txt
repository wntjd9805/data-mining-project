We demonstrate that it is possible to capture the essence of an audio source using just a few tens of seconds from a single training signal. Our GAN-based generative model can be trained on a short audio signal from any domain without the need for pre-training or external supervision. Once trained, the model can generate random samples of arbitrary duration that maintain semantic similarity to the training waveform while introducing new compositions. This opens up various applications such as generating new jazz improvisations or rap variations based on a single example, modifying famous songs, filling in missing parts, enhancing speech signals, and improving old recordings. Our model achieves state-of-the-art results with as little as 20 seconds of training audio, despite having no prior knowledge about audio signals in general.