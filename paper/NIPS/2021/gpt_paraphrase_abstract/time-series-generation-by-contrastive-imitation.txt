We investigate the challenge of learning a generative model for time-series data. In this sequential setting, the generator must capture both the conditional dynamics of stepwise transitions and the joint distribution of multi-step trajectories. Autoregressive models trained through maximum likelihood estimation can learn explicit transition distributions but suffer from compounding error during rollouts. Adversarial models based on GAN training alleviate exposure bias but have implicit and difficult-to-assess transitions. To address these limitations, we propose a generative framework that combines the strengths of both approaches. We optimize a local transition policy that looks forward to mitigate compounding error and use a global energy model trained through contrastive estimation to provide reinforcement signals. During training, the components are learned cooperatively to avoid instabilities. During inference, the learned policy serves as the generator for iterative sampling, and the learned energy serves as a measure of sample quality. This approach focuses on imitating sequential behavior in time-series data and demonstrates theoretical correctness and algorithmic consistency. Empirical evaluations on real-world datasets show that our approach generates predictively useful samples at the level of existing benchmarks.