This study addresses the issue of data bias in question answering (QA) models. While existing debiasing methods have achieved good generalizability for out-of-distribution (OOD) scenarios, they often sacrifice performance for in-distribution (ID) scenarios and require prior knowledge of the test distribution. To overcome these limitations, the authors propose a novel debiasing method called Introspective Distillation (IntroD). IntroD blends the inductive bias of both OOD and ID scenarios by examining whether a training sample fits into the factual ID world or the counterfactual OOD world. Experimental results on visual QA datasets and a reading comprehension dataset show that IntroD maintains competitive OOD performance compared to other debiasing methods, while also improving or maintaining ID performance compared to non-debiasing methods.