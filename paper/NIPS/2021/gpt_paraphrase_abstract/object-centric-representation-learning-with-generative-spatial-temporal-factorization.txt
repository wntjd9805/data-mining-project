Learning about the structure and abstraction of complex scenes requires understanding objects within the scene. However, current approaches for unsupervised learning of object-centric representations have limitations. They either assume a stationary observer or a static scene, which leads to spatial ambiguities or incorrect inferences from dynamic scenes. To overcome these limitations, we introduce DyMON, a method that expands multi-view object-centric representation learning to dynamic scenes. By training DyMON on multi-view-dynamic-scene data, we demonstrate its ability to learn to separate observer motions and scene object dynamics, allowing for the creation of spatial representations of scene objects that can be queried across time and space. Furthermore, the factorized scene representations enable independent querying of a single object by space and time.