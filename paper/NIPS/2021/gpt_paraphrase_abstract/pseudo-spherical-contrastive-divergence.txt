Energy-based models (EBMs) are often trained using contrastive divergence due to the intractability of the partition function. This paper introduces a new approach called pseudo-spherical contrastive divergence (PS-CD) for learning EBMs. PS-CD is derived from the maximization of a family of scoring rules, which eliminates the need to compute the partition function and offers a range of learning objectives that include contrastive divergence. PS-CD also allows for flexible selection of learning objectives without added computational cost or variational minimax optimization. The proposed method is theoretically analyzed and experimentally validated on synthetic data and image datasets, demonstrating its effectiveness, modeling flexibility, and robustness to data contamination. PS-CD outperforms maximum likelihood and f-EBMs.