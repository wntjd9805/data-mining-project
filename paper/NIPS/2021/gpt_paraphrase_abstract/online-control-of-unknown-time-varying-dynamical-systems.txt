This study focuses on the online control of time-varying linear systems with unknown dynamics. The researchers find that this scenario is more challenging than dealing with either unknown time-invariant or known time-varying dynamics. They provide algorithmic upper bounds in cases where sublinear regret is possible. The study examines regret bounds for different classes of policies and highlights that these classes are not equivalent for time-varying systems, unlike for LTI systems. The researchers prove a lower bound that shows no algorithm can achieve sublinear regret for certain classes unless the system variability scales sublinearly in the horizon. They also demonstrate that offline planning for linear feedback policies is NP-hard, indicating the difficulty of the online learning problem. On a positive note, they propose an efficient algorithm that achieves sublinear regret against Disturbance Response policies, considering the system variability term. This algorithm even demonstrates sublinear adaptive regret bounds, which is a stronger metric for time-varying systems. The researchers suggest possible extensions to Disturbance Action policies and partial observation and present an inefficient algorithm for regret against linear state feedback policies.