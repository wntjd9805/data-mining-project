Our paper focuses on the problem of invariance under symmetry in machine learning. Specifically, we examine equivariant neural networks that produce homomorphic transformations of outputs when inputs are transformed. Steerable CNNs are commonly used for this purpose. However, these representations face a challenge when it comes to nonlinear layers, as they break equivariance and limit architectural choices. To address this, we employ harmonic distortion analysis to understand the impact of nonlinearities on Fourier representations of SO(2). We introduce a novel FFT-based algorithm that allows us to compute representations of nonlinearly transformed activations while maintaining band-limitation. This algorithm ensures exact equivariance for polynomial nonlinearities and provides approximate solutions with adjustable accuracy for general functions. We apply our approach to construct a fully E(3)-equivariant network for sampled 3D surface data. Through experiments with 2D and 3D data, we achieve results that surpass the state-of-the-art in terms of accuracy while enabling continuous symmetry and exact equivariance.