This research focuses on personalization in supervised learning while maintaining user-level differential privacy. The study aims to determine if users can collectively learn a shared structure and improve their individual tasks while protecting the privacy of their data. The question is addressed using joint, user-level differential privacy, ensuring the control of leaked information about each user's entire dataset. The study proposes algorithms that leverage popular non-private approaches like the Almost-No-Inner-Loop (ANIL) method, while providing strong privacy guarantees. When the problems involve linear regression with users' regression vectors in a common, unknown low-dimensional subspace, the algorithms demonstrate efficient performance with optimal estimation error guarantees. Additionally, an information-theoretic upper bound is established using an exponential mechanism-based algorithm.