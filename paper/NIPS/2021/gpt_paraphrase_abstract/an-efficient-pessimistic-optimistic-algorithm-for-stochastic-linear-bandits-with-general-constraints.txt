This paper discusses the problem of maximizing expected cumulative reward over a given time horizon in stochastic linear bandits with nonlinear constraints. The proposed algorithm for this problem achieves efficient results in two aspects. Firstly, it yields approximately optimal regret in each round and ensures zero constraint violation in all rounds. Secondly, the algorithm is computationally efficient due to its similarity to unconstrained stochastic linear bandits. The algorithm is based on the primal-dual approach, with the primal component using the linear upper confidence bound algorithm and the computational complexity of the dual component being independent of the sizes of various spaces.