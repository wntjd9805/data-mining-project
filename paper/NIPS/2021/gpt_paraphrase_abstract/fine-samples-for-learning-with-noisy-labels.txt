Modern deep neural networks (DNNs) struggle when dealing with datasets that have noisy (incorrect) class labels. There are two main types of techniques for handling noisy labels: developing noise-robust functions and using noise-cleansing methods to detect and filter out the noisy data. Noise-cleansing methods have recently emerged as the most effective algorithms for learning with noisy labels. However, these methods often rely on heuristics rather than a solid theoretical foundation, and they require a robust classifier to predict the noisy data based on loss values. In this paper, we propose a new approach for detecting and filtering label noise. Unlike existing methods, our approach focuses on the dynamics of each data point's latent representation and measures the alignment between the latent distribution and each representation using eigen decomposition of the data gram matrix. Our framework, called Filtering Noisy Instances via their Eigenvectors (FINE), offers a robust detector using simple methods that do not rely on derivatives and come with theoretical guarantees. Within our framework, we present three applications of FINE: a sample-selection approach, a semi-supervised learning (SSL) approach, and collaboration with noise-robust loss functions. Experimental results demonstrate that our proposed methods consistently outperform corresponding baselines for all three applications on various benchmark datasets.