This study focuses on selective classification in the online learning model, where a predictor has the option to abstain from classifying an instance. This can represent a decision to allocate more resources to that particular instance. The setting considers two important factors: the data may not be fully realizable, making abstention a valid long-term action, and feedback is only received when the learner abstains, indicating that reliable labels are only available with resource-intensive processing. The goal is to develop strategies that minimize mistakes while abstaining as little as possible compared to the best possible error-free classifier. The study proposes versioning-based schemes that achieve T µ mistakes and approximately T^(1-µ) excess abstention against adaptive adversaries, for any µ ∈ (0, 1]. The tight dependence of these results on T is demonstrated, and experiments on realistic datasets are provided.