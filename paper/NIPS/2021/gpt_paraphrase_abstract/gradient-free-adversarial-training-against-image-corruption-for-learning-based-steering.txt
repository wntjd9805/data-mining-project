We present a straightforward yet powerful framework for enhancing the resilience of learning algorithms to image corruptions in autonomous driving. These corruptions can arise from internal sources such as sensor noise and hardware abnormalities, as well as external factors like lighting, weather, visibility, and environmental effects. By utilizing sensitivity analysis and FID-based parameterization, we propose a novel algorithm that leverages basis perturbations to enhance the overall performance of self-driving cars in tasks such as autonomous steering, classification, and detection. Our model not only improves performance on the original dataset, but also achieves significant performance gains on datasets with multiple and unseen perturbations, with improvements of up to 87% and 77% respectively. A comparison with other state-of-the-art techniques verifies the effectiveness of our approach in bolstering the robustness of neural network training for learning-based steering and image processing tasks.