Different types of non-trivial spaces, such as graphs, texts, and images, are being used to embed structured data. While product spaces have been suggested as a solution, finding the best configuration for these spaces is time-consuming and limits practicality. To address this, we propose an overlapping space where subsets of coordinates can be shared between different space types. This reduces the number of coordinates needed to store objects and eliminates the need for configuration search. We also introduce an optimization algorithm that automatically learns the optimal configuration. Experimental results show that overlapping spaces outperform competitors in graph embedding tasks. In addition, we compare all spaces in an information retrieval setup and find that the proposed overlapping space consistently achieves optimal results without configuration tuning. This reduces training time, making it valuable for large-scale applications.