This study focuses on reconstructing a causal graphical model when there are latent variables present. The main objective is to recover the causal structure of the latent variables while allowing for general, potentially nonlinear dependencies. In practical scenarios, the dependence between raw observations is less important compared to the dependence between high-level latent features. The study introduces conditions under which both the latent representations and the underlying latent causal model can be identified using a mixture oracle. These findings establish a connection between the problem of learning the order of a mixture model and learning the bipartite structure between observables and unobservables. The proof is constructive and leads to various algorithms for explicitly reconstructing the full graphical model. The study also discusses efficient algorithms and presents experimental results demonstrating the effectiveness of the algorithms.