Kernel selection is crucial for Gaussian Process (GP) models as it influences the performance and prior support of functions. This study introduces KITT, a novel approach that uses a transformer-based architecture to quickly generate kernel recommendations for high-dimensional GP regression models. KITT can generate recommendations in less than 0.1 seconds, significantly faster than traditional kernel search algorithms. The model is trained using synthetic data from known kernels and can handle datasets of any dimension due to the self-attention mechanism. Experimental results show that KITT selects kernels that perform well across various regression benchmarks.