Language GANs face challenges in optimization due to the discrete nature of words. Unlike continuous tasks, language GANs do not have the benefit of gradient flows from discriminators to generators, resulting in unstable learning. However, we propose a solution by having the discriminator and generator networks cooperate in producing output sequences during training. These cooperative outputs not only provide better rewards for training but also improve the accuracy and stability of the discriminator. Our SelfGAN framework, based on this cooperative principle, outperforms Teacher Forcing and achieves state-of-the-art results in Summarization and Question Generation tasks.