Contrastive self-supervised learning has achieved impressive results in learning visual representations from unlabeled images by ensuring invariance across different data augmentations. However, these learned representations often exhibit contextual bias towards spurious correlations between objects and backgrounds, which limits their generalization capabilities for downstream tasks. To address this issue, we propose a novel object-aware contrastive learning framework. Firstly, we localize objects in a self-supervised manner using a technique called contrastive class activation map (ContraCAM), which identifies the most discriminative regions in an image compared to other images. We enhance ContraCAM to detect multiple objects and entire shapes through an iterative refinement process. Secondly, we introduce two data augmentations based on ContraCAM - object-aware random crop and background mixup. These augmentations help reduce contextual and background biases during contrastive self-supervised learning. Our experimental results demonstrate the effectiveness of our framework, especially when trained using multi-object images or evaluated under background (and distribution) shifted images.