The methodology of model stitching, initially introduced by Lenc and Vedaldi in 2015, is revisited and extended in this study. Model stitching involves connecting the bottom layers of one trained and frozen model (Model A) to the top layers of another model (Model B), with a trainable layer in between. This approach is argued to be a powerful tool for studying the internal representations of neural networks, as it can reveal aspects of representations that other measures like centered kernel alignment (CKA) cannot capture. Through extensive experiments, the authors use model stitching to provide quantitative evidence for intuitive statements such as the similarity of representations learned by "good networks" of the same architecture but trained in different ways (e.g., supervised vs. self-supervised learning). Additionally, the study demonstrates that representations learned with more data, larger width, or longer training time can be integrated into weaker models to improve their performance. Furthermore, the experiments uncover a new structural property of stochastic gradient descent (SGD) called "stitching connectivity," which is similar to mode-connectivity, indicating that different minima reached by SGD can be stitched together with minimal impact on accuracy.