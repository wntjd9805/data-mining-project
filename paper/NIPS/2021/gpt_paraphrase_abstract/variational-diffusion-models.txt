Diffusion-based generative models have been successful in synthesizing impressive images but their effectiveness as likelihood-based models has been questioned. However, we confirm that diffusion-based generative models can achieve state-of-the-art likelihoods on image density estimation benchmarks. Unlike other models, our method allows for efficient optimization of the noise schedule along with the rest of the model. We simplify the variational lower bound (VLB) expression by relating it to the signal-to-noise ratio of the diffused data, which enhances our theoretical understanding of this model class. Through this insight, we establish an equivalence between various models proposed in the literature. Furthermore, we demonstrate that the continuous-time VLB is unaffected by the noise schedule except at its endpoints, enabling us to optimize the noise schedule to minimize the variance of the VLB estimator, resulting in faster optimization. By combining these advancements with architectural improvements, we achieve state-of-the-art likelihoods on image density estimation benchmarks. Our models outperform autoregressive models that have dominated these benchmarks for a long time, with significantly faster optimization. Additionally, we explore the use of our model in a bits-back compression scheme and achieve compression rates close to the theoretical optimum for lossless compression.