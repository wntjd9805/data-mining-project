This study focuses on the potential security threats to Deep Neural Networks (DNNs) caused by the moiré effect in digital image processing. The researchers introduce the concept of a Moiré Attack (MA) which involves adding a physical-world moiré pattern to images to tamper with DNNs. The experiments conducted demonstrate that the MA is highly successful in manipulating DNNs, with a 100% success rate for untargeted attacks and a 97% success rate for targeted attacks. The attack is also found to be transferable across different models and robust against various defenses. The researchers highlight the stealthiness of the MA as the moiré effect is inherent in the camera's physical structure and goes unnoticed by humans. The code for the MA is made available for public access.