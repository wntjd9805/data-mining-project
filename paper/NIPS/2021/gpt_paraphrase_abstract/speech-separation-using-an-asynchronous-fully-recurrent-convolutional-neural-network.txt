Advancements in neural network architectures, particularly in sequence modeling, have greatly improved speech separation performance. This study introduces a bio-inspired architecture called Fully Recurrent Convolutional Neural Network (FRCNN) to tackle the separation task. The FRCNN model incorporates bottom-up, top-down, and lateral connections to merge information processed at different time-scales represented by stages. Unlike the conventional method of updating stages in parallel, the proposed approach sequentially updates the stages in the bottom-up direction, then simultaneously fuses information from adjacent stages, and finally combines information from all stages to the bottom stage. Experimental results demonstrate that this asynchronous updating scheme achieves significantly superior outcomes with fewer parameters compared to the traditional synchronous updating scheme. Furthermore, the proposed model achieves a desirable balance between speech separation accuracy and computational efficiency, outperforming other state-of-the-art models on three benchmark datasets.