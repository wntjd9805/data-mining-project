This study examines two key problems in sequential decision-making: prediction with expert advice and the multi-armed bandit problem. We focus on scenarios where an adversary can manipulate losses and investigate the extent of robustness against such manipulation. The main finding of this paper is that optimal robustness can be achieved with a square-root relationship to the level of corruption. Specifically, we demonstrate that two types of algorithms, anytime Hedge with decreasing learning rate and algorithms with second-order regret bounds, achieve a regret of O(log N∆), where N, ∆, and C represent the number of experts, the gap parameter, and the corruption level respectively. We also establish a matching lower bound, indicating that this regret bound is nearly optimal. Additionally, for the multi-armed bandit problem, we provide a lower bound that is nearly optimal up to a logarithmic factor.