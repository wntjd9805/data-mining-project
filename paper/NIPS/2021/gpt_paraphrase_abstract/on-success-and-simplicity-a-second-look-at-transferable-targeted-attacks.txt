Transferability of targeted attacks is considered to be very challenging, but our investigation reveals that simple transferable attacks can achieve strong targeted transferability without the need for model training or additional data. This insight has been overlooked because previous attacks have focused on a small number of iterations, limiting their effectiveness. We also find that a simple logit loss outperforms the commonly used cross-entropy loss and the resource-intensive state of the art. Our analysis covers various transfer scenarios, including new and realistic ones, demonstrating that easy scenarios do not fully reveal the true strength of different attacks. Additionally, we show that the simple logit loss can generate targeted universal adversarial perturbations without requiring data. Our goal is to inspire a more meaningful evaluation of targeted transferability. The code is available at the provided GitHub link.