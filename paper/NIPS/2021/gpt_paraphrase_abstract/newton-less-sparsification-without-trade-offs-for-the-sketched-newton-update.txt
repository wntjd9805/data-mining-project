Randomized sketching is a technique used in second-order optimization to estimate the Hessian matrix of a function, reducing computational cost. The choice of sketching matrix affects the convergence rate of the optimization algorithm. A dense Gaussian sketching matrix is theoretically desirable but expensive. However, by using a sparsified Gaussian sketching matrix called Newton-LESS, the computational cost can be reduced without significantly affecting convergence properties. Newton-LESS has a similar local convergence rate as Gaussian embeddings and achieves state-of-the-art results for least squares solvers. Additionally, we extend the technique to include uniformly sparsified random sign matrices, which perform well in numerical experiments.