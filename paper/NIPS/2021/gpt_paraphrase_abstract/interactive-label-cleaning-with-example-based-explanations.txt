We address the problem of learning from noisy labeled data in situations where a human supervisor can be asked to re-label questionable examples. Current approaches are flawed because they only re-label examples that the model deems "suspicious". As a result, mislabeled examples that are not identified as suspicious are included in the training data, compromising the quality of the model. We propose a new method called CINCER, which cleans both new and past data by identifying pairs of incompatible examples. When a suspicious example is detected, CINCER finds a counter-example in the training set that the model considers maximally incompatible and asks the supervisor to re-label either or both examples to resolve any inconsistencies. The counter-examples are chosen to be maximally incompatible in order to explain the model's suspicion and convey as much information as possible when re-labeled. CINCER achieves this by using an efficient and reliable approximation of influence functions based on the Fisher information matrix. Our extensive evaluation demonstrates that by clarifying the reasons behind the model's suspicions and cleaning the counter-examples, we can significantly improve the quality of both the data and the models, especially when combined with our Fisher information matrix approximation.