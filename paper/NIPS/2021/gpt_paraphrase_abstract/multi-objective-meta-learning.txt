Recently, there has been growing interest in meta learning with multiple objectives, as many applications require considering multiple factors in designing learning models. Current gradient-based approaches for meta learning with multiple objectives typically combine these objectives into a single objective using weighted sums. Although this strategy is effective, it can be time-consuming to manually tune the weights associated with each objective. In contrast, this paper proposes a gradient-based Multi-Objective Meta Learning (MOML) framework that eliminates the need for manual weight tuning. MOML formulates the objective function as a Multi-Objective Bi-Level Optimization Problem (MOBLP), where the upper-level subproblem involves solving several potentially conflicting objectives for the meta learner. To solve the MOBLP, the paper introduces the first gradient-based optimization algorithm, which alternately solves the lower-level and upper-level subproblems using the gradient descent method and the gradient-based multi-objective optimization method, respectively. The paper proves the convergence properties of the proposed algorithm theoretically and demonstrates the effectiveness of the MOML framework in various meta learning problems through empirical evaluation, including few-shot learning, domain adaptation, multi-task learning, and neural architecture search. The source code for MOML is available at https://github.com/Baijiong-Lin/MOML.