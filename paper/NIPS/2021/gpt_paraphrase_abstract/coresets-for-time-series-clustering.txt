We investigate the creation of coresets for clustering problems involving time series data. This is a significant problem in various fields such as biology, medicine, and economics, as real-time sensors have become more prevalent and storage costs have decreased. Specifically, we focus on the scenario where N entities generate time series data following a Gaussian mixture model with autocorrelations across k clusters in Rd. Our main achievement is an algorithm that constructs coresets for the maximum likelihood objective of this mixture model. Our algorithm is efficient and, assuming a mild assumption on the covariance matrices of the Gaussians, the size of the coreset is not affected by the number of entities N or the number of observations for each entity. It only depends on k, d, and 1/ε (where ε is the error parameter) in a polynomial manner. To evaluate the performance of our coresets, we conduct empirical tests using synthetic data.