Graph Neural Networks (GNNs) are increasingly important due to their popularity and diverse applications. However, previous studies on their vulnerability to adversarial attacks have focused on small graphs. To bridge this gap, we investigate the attack and defense of GNNs on a larger scale. We propose two sparsity-aware first-order optimization attacks that maintain efficiency while optimizing a quadratic number of parameters relative to the number of nodes. We demonstrate that common surrogate losses are inadequate for global attacks on GNNs, and present alternative methods that can significantly enhance attack strength. Additionally, we enhance the reliability of GNNs by introducing a robust aggregation function called Soft Median, which effectively defends against attacks at all scales. Our attacks and defense mechanisms are evaluated using standard GNNs on graphs more than 100 times larger than previous studies. Furthermore, we extend our techniques to a scalable GNN, allowing us to scale up one order of magnitude.