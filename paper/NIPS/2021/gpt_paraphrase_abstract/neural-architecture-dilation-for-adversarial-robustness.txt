Convolutional neural networks (CNNs) have made significant advancements in architecture and scale, often outperforming humans in certain tasks. However, a recent discovery revealed that CNNs are susceptible to adversarial attacks. While adversarial training can enhance CNNs' robustness, there is a trade-off between standard accuracy and adversarial robustness. This study focuses on improving the adversarial robustness of backbone CNNs without sacrificing accuracy by introducing a dilation architecture. The proposed neural architecture dilation algorithm is designed to minimize computational overhead while pursuing adversarial robustness, supported by theoretical analyses on standard and adversarial error bounds. Experimental results on real-world datasets and benchmark neural networks validate the effectiveness of this algorithm in balancing accuracy and adversarial robustness.