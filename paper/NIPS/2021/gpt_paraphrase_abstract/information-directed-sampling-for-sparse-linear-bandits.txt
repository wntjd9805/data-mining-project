Stochastic sparse linear bandits provide a practical model for decision-making problems in high-dimensional online scenarios and have a valuable information-regret structure. In this study, we investigate the application of information-directed sampling (IDS), which effectively balances the trade-off between information acquisition and regret. We introduce a set of information-theoretic Bayesian regret bounds that closely align with established lower bounds for various problem instances, highlighting the adaptability of IDS. To efficiently implement sparse IDS, we propose an empirical Bayesian method for sparse posterior sampling using a spike-and-slab Gaussian-Laplace prior. Numerical findings demonstrate significant reductions in regret through sparse IDS compared to several baseline methods.