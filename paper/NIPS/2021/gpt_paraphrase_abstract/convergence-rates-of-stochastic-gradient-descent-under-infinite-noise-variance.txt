Recent research has shown that heavy tails can occur in stochastic gradient descent (SGD) in different scenarios. These heavy tails can cause the variance of the iterates to diverge, making it difficult to use conventional convergence analysis techniques that rely on second-order moments. This paper provides convergence guarantees for SGD under a state-dependent and heavy-tailed noise with potentially infinite variance, specifically for a class of strongly convex objectives. When the p-th moment of the noise exists for some p ∈ [1, 2), the paper introduces a condition called "p-positive (semi-)definiteness" on the Hessian matrix. This condition allows for an interesting interpolation between the positive semi-definite cone (p = 2) and the cone of diagonally dominant matrices with non-negative diagonal entries (p = 1). Under this condition, the paper provides a convergence rate for the distance to the global optimum in Lp. Additionally, the paper presents a generalized central limit theorem, which demonstrates that the properly scaled Polyak-Ruppert averaging converges weakly to a multi-variate α-stable random vector. The results of this study indicate that even under heavy-tailed noise with infinite variance, SGD can converge to the global optimum without requiring any modifications to the loss function or the algorithm itself, as typically needed in robust statistics. The implications of these results are shown for misspecified models in the presence of heavy-tailed data.