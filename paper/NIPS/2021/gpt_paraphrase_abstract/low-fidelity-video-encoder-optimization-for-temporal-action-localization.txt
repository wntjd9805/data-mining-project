Current temporal action localization (TAL) methods typically utilize a transfer learning pipeline, where a video encoder is first optimized on a large action classification dataset and then a TAL head is trained on the action localization dataset. However, this approach poses a task discrepancy issue for the video encoder. To address this problem, we propose a novel low-fidelity (LoFi) video encoder optimization method. By reducing the mini-batch composition in terms of temporal, spatial, or spatio-temporal resolution, we enable joint optimization of the video encoder and TAL head under GPU memory constraints. This allows the gradients to flow backwards through the video encoder conditioned on a TAL supervision loss, leading to more effective feature representations and solving the task discrepancy problem. Experimental results demonstrate that our LoFi optimization approach significantly improves the performance of existing TAL methods. Notably, even with a lightweight video encoder, our method outperforms two-stream alternatives. Our code is publicly available at the provided GitHub link.