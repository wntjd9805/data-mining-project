Variational Autoencoders (VAEs) are effective models for learning representations of complex data distributions. However, they have limitations such as assuming a simple Gaussian distribution for latent representations and facing practical challenges during training. Recently, regularized autoencoders have been introduced as a deterministic alternative to VAEs, simplifying the objective and training process. However, these models lack control over the latent distribution and require additional steps for generating comparable samples to VAEs. In this study, we propose an end-to-end trainable deterministic autoencoding framework that shapes the latent space during training and allows for expressive multi-modal latent distributions. Our training procedure provides direct evidence of the adequacy of the latent distribution in capturing complex aspects of the data. Experimental results demonstrate the model's expressiveness and sample quality across various continuous and discrete domains. The implementation can be found at https://github.com/boschresearch/GMM_DAE.