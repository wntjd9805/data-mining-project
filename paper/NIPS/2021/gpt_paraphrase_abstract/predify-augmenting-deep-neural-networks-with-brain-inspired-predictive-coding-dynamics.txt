Deep neural networks have proven to be highly effective in classifying images, but they are not as resilient to changes in input as human perception. In this study, we explore the potential of incorporating brain-inspired recurrent dynamics into deep convolutional networks to address this limitation. We draw inspiration from the "predictive coding" framework in neuroscience, where generative feedback is used to predict and reconstruct the activity patterns in each layer of the network. By iteratively updating the network's representations based on reconstruction errors and optimizing feedback weights using unsupervised training on natural images, we enhance the robustness of two popular networks, VGG16 and EfÔ¨ÅcientNetB0, against different types of corruptions and adversarial attacks. We believe that this framework could also benefit other feedforward networks. To encourage further research in this area, we have developed an open-source PyTorch-based package called Predify, which enables the implementation and investigation of the predictive coding dynamics in any convolutional neural network.