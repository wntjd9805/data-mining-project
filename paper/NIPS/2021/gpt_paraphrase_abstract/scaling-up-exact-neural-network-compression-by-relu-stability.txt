We have developed an algorithm that can compress a rectifier network while maintaining its functionality for a given input domain. Previous methods for determining the stability of neurons with Rectified Linear Unit (ReLU) activations required solving multiple discrete optimization problems. Our algorithm, on the other hand, solves a single optimization problem to identify all stable neurons. Compared to the current state-of-the-art method, our approach is approximately 183 times faster on CIFAR-10. This allows us to explore exact compression on deeper (5 × 100) and wider (2 × 800) networks within minutes. For classifiers trained with a certain level of regularization that does not affect accuracy, we can remove up to 56% of the connections on the CIFAR-10 dataset. The code for our algorithm is available at https://github.com/yuxwind/ExactCompression.