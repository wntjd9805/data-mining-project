The problem of generating new views using machine learning and computer vision has been a challenge for a long time. Recent advancements have led to the development of neural scene representations and rendering techniques that can create realistic images from any viewpoint. However, these representations are slow to train and render. In this study, we propose a new neural rendering approach called MetaNLR++, which aims to quickly learn a high-quality representation that can be rendered in real-time. Our approach combines a neural shape representation with 2D CNN-based image feature extraction, aggregation, and re-projection. By using meta learning, we reduce the training time to minutes by learning neural shape and image feature priors. The optimized shape and image features can then be extracted using traditional graphics techniques and rendered in real time. Our results demonstrate that MetaNLR++ achieves similar or better novel view synthesis outcomes in a fraction of the time compared to other methods.