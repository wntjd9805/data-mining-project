This study aims to develop bandit algorithms that can improve performance in certain environments without prior knowledge of those environments. The proposed algorithm for combinatorial semi-bandits has two main features: a best-of-three-worlds guarantee and multiple data-dependent regret bounds. The algorithm performs optimally in adversarial, stochastic, and stochastic with adversarial corruptions settings. It also performs well in environments that are "easy" according to certain metrics, such as cumulative loss for optimal actions, total quadratic variation of losses, and path-length of a loss sequence. The study also presents hybrid data-dependent regret bounds for adversarial linear bandits, including a first path-length regret bound that is nearly optimal.