Decentralized machine learning is a method where training data is distributed across multiple agents in a network. These agents work together to find a model that minimizes the average of all local loss functions. While gradient tracking algorithms can address the challenge of accounting for differences in local data distributions, the existing convergence rates for these algorithms are not optimal in terms of their dependence on the mixing parameter p. In this study, we provide a more precise analysis of the gradient tracking method in different settings: stochastic strongly convex, convex, and non-convex. We improve the dependency on p from O(p^-2) to O(p^-1c^-1) in the noiseless case and from O(p^-3/2) to O(p^-1/2c^-1) in the general stochastic case. Here, c â‰¥ p is related to the negative eigenvalues of the connectivity matrix and is typically a constant in practical applications. This improvement in convergence rates was made possible by a new proof technique, which may have independent value in other contexts.