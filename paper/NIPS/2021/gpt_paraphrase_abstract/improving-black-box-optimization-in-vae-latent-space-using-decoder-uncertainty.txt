Variational autoencoders (VAEs) offer a promising method for generating high-dimensional discrete objects that maximize a desired property, such as drug-likeness or function approximation. However, current approaches lack robustness as they may explore areas of the latent space where no training data is available, resulting in the generation of unrealistic or invalid objects. In this study, we propose using the uncertainty of the VAE decoder to guide the optimization process. Estimating uncertainty in the complex settings we consider is challenging due to high estimator variance. To address this, we introduce an importance sampling-based estimator that provides more reliable estimates of uncertainty. Our uncertainty-guided optimization method does not require any modifications to the model architecture or training process. It generates samples that achieve a better balance between the desired objective and the validity of the generated objects, sometimes improving both simultaneously. We demonstrate the advantages of our approach in various experimental scenarios, including digit generation, arithmetic expression approximation, and molecule generation for drug design.