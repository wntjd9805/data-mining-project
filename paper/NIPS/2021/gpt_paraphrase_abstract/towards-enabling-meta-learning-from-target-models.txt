Meta-learning can utilize previous learning experiences to improve the training of new tasks. This is usually done by optimizing a meta-model using the evaluation loss of task-specific solvers. Most current methods use a non-overlapping sampling approach, where support sets and query sets are used to train and evaluate solvers, respectively (S/Q protocol). However, an alternative approach called the S/T protocol, which involves comparing a task-specific solver to a target model that is either the optimal model or performs well on the task, offers more informative supervision. Although computationally expensive, this paper explores the S/T protocol and demonstrates that by using a small number of tasks with target models, classic meta-learning algorithms can show significant improvements without requiring excessive resources. The effectiveness of the S/T protocol is empirically verified in the context of few-shot learning, where target models are constructed by fine-tuning pre-trained networks on challenging tasks. Through knowledge distillation, the task-specific solvers are aligned with the target models.