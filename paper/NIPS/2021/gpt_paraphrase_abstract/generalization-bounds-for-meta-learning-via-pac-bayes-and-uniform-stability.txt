We aim to address the challenge of providing strong generalization guarantees in the field of meta-learning. Current generalization bounds either prove difficult to assess or offer weak guarantees, even in simple scenarios. To overcome this, we develop a probably approximately correct (PAC) bound for gradient-based meta-learning that utilizes two different generalization frameworks. These frameworks handle the distinct challenges of generalization at the "base" and "meta" levels. We utilize bounds for uniformly stable algorithms at the base level and incorporate bounds from the PAC-Bayes framework at the meta level. This approach yields a novel PAC bound that is particularly effective when the base learner adapts rapidly, which aligns with the objective of meta-learning. We demonstrate the superiority of our bound by comparing it to other bounds on a non-convex problem on the unit sphere and a text-based classification example. Furthermore, we introduce a practical regularization scheme inspired by our bound, which improves performance compared to standard techniques in scenarios where the bound is less accurate.