Recent blind super-resolution (SR) methods typically involve a two-branch approach, with one branch for degradation prediction and the other for conditional restoration. However, our experiments demonstrate that a one-branch network can achieve comparable performance to the two-branch scheme. This raises the question of how one-branch networks can automatically learn to differentiate between different types of degradations. To address this question, we propose a novel diagnostic tool called the Filter Attribution method based on Integral Gradient (FAIG). Unlike previous integral gradient methods, FAIG aims to identify the most discriminative filters instead of focusing on input pixels or features for degradation removal in blind SR networks. By utilizing these discovered filters, we develop a simple yet effective method to predict the degradation of an input image. Through FAIG, we make the following findings in one-branch blind SR networks: 1) It is possible to identify a very small number of discriminative filters (only 1% of the total) for each specific degradation; 2) The weights, locations, and connections of these discovered filters all play important roles in determining the network's function for a specific degradation; 3) The task of degradation prediction can be implicitly achieved by these discriminative filters without the need for explicit supervised learning. These findings not only enhance our understanding of the inner workings of one-branch blind SR networks but also offer insights for designing more efficient architectures and diagnosing networks in the context of blind SR. For access to the codes, please visit https://github.com/TencentARC/FAIG.