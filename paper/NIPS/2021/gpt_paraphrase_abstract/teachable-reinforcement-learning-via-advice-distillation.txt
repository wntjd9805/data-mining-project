Training automated agents to complete complex tasks in interactive environments is difficult due to various challenges associated with different learning approaches. Reinforcement learning requires manual engineering of reward functions, imitation learning requires specialized infrastructure and access to a human expert, and learning from intermediate forms of supervision is time-consuming and provides limited information. This paper suggests an alternative approach where agents learn from rich, interactive feedback. The proposed paradigm involves "teachable" decision-making systems that learn from structured advice provided by an external teacher. The authors outline a learning algorithm that first learns to interpret advice and then utilizes it to complete tasks without human supervision. The effectiveness of this approach is demonstrated in puzzle-solving, navigation, and locomotion domains, where agents trained with advice require significantly less human supervision compared to reinforcement learning and imitation learning methods.