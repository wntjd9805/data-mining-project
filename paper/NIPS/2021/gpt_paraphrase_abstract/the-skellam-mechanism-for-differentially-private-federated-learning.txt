We present the multi-dimensional Skellam mechanism, a discrete privacy mechanism that utilizes the difference between two independent Poisson random variables. We evaluate its privacy guarantees by analyzing the distribution of privacy loss and establish a precise bound on the RÃ©nyi divergence between two shifted Skellam distributions. We explore its application in federated learning with secure aggregation under communication constraints. Our theoretical analysis and extensive experiments show that the Skellam mechanism offers similar trade-offs between privacy and accuracy as the continuous Gaussian mechanism, even at low precision. Additionally, the Skellam mechanism supports summation and sampling by utilizing a Poisson distribution, which is a standard feature in machine learning and data analysis software. With its discrete nature, competitive privacy-accuracy trade-offs, and practical advantages, the Skellam mechanism is a promising alternative to the recently introduced discrete Gaussian mechanism.