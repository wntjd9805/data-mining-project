Machine learning advancements have sparked interest in Explainable AI (xAI) to help humans understand how machine learning models make decisions. However, the usefulness of xAI techniques in human-machine teaming has not been studied extensively. xAI has the potential to improve team situational awareness (SA) and the development of shared mental models, which are crucial for effective human-machine teams. This is particularly important in ad hoc human-machine teaming situations where agents lack prior knowledge of each other's decision-making strategies. In this study, we conducted two experiments to measure the benefits of using xAI techniques in a human-machine teaming scenario. Firstly, we found that xAI techniques can improve SA. Secondly, we investigated the impact of different levels of SA induced by a collaborative AI policy abstraction on ad hoc human-machine teaming performance. Our findings revealed that the benefits of xAI are not universal and depend on the composition of the human-machine team. Novices benefit from xAI by enhancing SA, but they also experience cognitive overload. Conversely, experts' performance declines when xAI support is added, suggesting that the attention required for xAI outweighs the benefits of additional information for SA enhancement. These results highlight the importance of carefully designing and deploying appropriate xAI techniques based on the specific human-machine team composition and how the xAI method enhances SA.