Neural network models can be unreliable and difficult to interpret due to hidden data biases. To address this issue, we aim to create models that have an understanding of what they do not know by incorporating inductive biases in the function space. By using periodic activation functions in Bayesian neural networks, we establish a connection between the prior on network weights and translation-invariant, stationary Gaussian process priors. This connection extends beyond sinusoidal activations to include triangular wave and periodic ReLU activation functions. Through experiments, we demonstrate that periodic activation functions achieve comparable performance for in-domain data and effectively detect sensitivity to perturbed inputs in deep neural networks for out-of-domain detection.