The proliferation of data-driven applications has raised serious privacy concerns in the field of artificial intelligence. Protecting the confidentiality of data during deep model training has been a major challenge. Federated Learning (FL) has gained popularity as a method for privacy-preserving training across multiple silos by allowing parameter-only communication. However, previous research has shown that FL suffers from a significant decrease in performance when the data distributions among clients are heterogeneous, especially in cross-domain scenarios such as traffic, aerial, and indoor domains. To address this problem, we propose a new approach called PartialFed, which loads only a subset of the global model's parameters instead of the entire model used in previous works. We first validate our algorithm, PartialFed-Fix, using manually decided loading strategies based on expert knowledge. Then, we develop PartialFed-Adaptive, which automatically selects personalized loading strategies for each client. Our algorithm demonstrates superior performance compared to existing methods in cross-domain federated classification and detection. By initializing a small fraction of layers locally, we achieve performance improvements of 4.88% and 2.65% on OfÔ¨Åce-Home and UODB datasets, respectively, compared to the FedAvg method. Further experiments show that the adaptive strategy performs significantly better in domains with large deviations, resulting in improvements of 4.03% and 4.89% in aerial and medical image detection compared to FedAvg.