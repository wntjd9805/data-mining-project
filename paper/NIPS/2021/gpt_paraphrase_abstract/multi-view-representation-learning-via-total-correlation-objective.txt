This paper presents a variational approach for Multi-View Representation Learning (MVRL), which aims to discover a shared representation of observations from different views. The proposed approach maximizes the reduction of total correlation by the representation, with the goal of learning an informative and concise latent representation that captures the correlation among multiple views. The paper introduces a tractable surrogate objective function that allows for fusion and calibration of observations in the representation space. The framework is shown to encompass existing multi-view generative models from an information theoretic perspective. Additionally, the approach is extended to the PartialMVRL (PMVRL) setting, where observations are missing without a regular pattern. Experimental results demonstrate the effectiveness of the proposed approach in multi-view translation and classification tasks, surpassing strong baseline methods.