There is a growing interest in post-hoc techniques that provide recourse to individuals affected by predictive models used in important decision-making processes, such as loan approvals. These techniques assume that the underlying predictive model remains unchanged. However, in practice, models are often updated, rendering previously prescribed recourses ineffective. To address this issue, we propose a new framework called RObust Algorithmic Recourse (ROAR), which uses adversarial training to find recourses that are resilient to model shifts. This is the first solution proposed for this critical problem. We also conduct theoretical analysis that highlights the importance of constructing recourses that can withstand model shifts. We quantify the probability of invalidation for recourses generated without considering model shifts and prove that the additional cost incurred by our robust recourses is limited. Experimental evaluation on various datasets demonstrates the effectiveness of our framework.