Advancements in machine learning over the past decade heavily rely on large-scale datasets, which are continuously growing in size. These datasets now also include different types of data. However, annotating large multi-modal datasets is challenging, and the annotations themselves may contain biases that we are unaware of. Deep neural network-based classifiers are susceptible to exploiting these biases and finding shortcuts. To address this concern, we introduce the perceptual score, a metric that measures the extent to which a model relies on different subsets of input features or modalities. By using the perceptual score, we discover a consistent trend across four popular datasets: newer, more accurate multi-modal models for visual question-answering or visual dialogue rely less on visual data compared to their predecessors. This trend is worrisome as it suggests that answers are increasingly inferred solely from textual cues. Additionally, the perceptual score can help analyze model biases by breaking down the score into contributions from different subsets of data. We aim to initiate a discussion on the perceptiveness of multi-modal models and urge researchers working on such classifiers to quantify perceptiveness using the proposed perceptual score.