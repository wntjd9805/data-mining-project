We examine the issue of optimizing a Lipschitz function f in a black-box setting, where the function is defined on a compact subset X of Rd. The challenge is to find an approximate maximum of f while also certifying the accuracy of the recommendations made by the algorithms. We determine the optimal number of evaluations required to achieve this goal, which is proportional to the integral (cid:82)X dx divided by (max(f) - f(x) + Îµ)d, under the assumption that X satisfies certain conditions. This finding solves a long-standing problem that dates back to 1991, which was previously only partially understood in one dimension. We utilize a packing bound from Bouttier et al. (2020) for the Piyavskii-Shubert algorithm to establish the upper bound, connecting it to the aforementioned integral. Additionally, we demonstrate that a certified version of the computationally feasible DOO algorithm aligns with these packing and integral bounds. Our lower bound, specific to each instance, deviates from traditional worst-case lower bounds in the Lipschitz context and relies on a localized worst-case analysis that may be valuable for other learning tasks.