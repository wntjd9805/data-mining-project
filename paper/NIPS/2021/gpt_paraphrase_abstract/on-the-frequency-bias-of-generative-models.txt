The main goal of Generative Adversarial Networks (GANs) is to generate new data that closely resembles the training data. However, recent studies have shown that current GAN architectures struggle to achieve this objective. Specifically, these studies have found that there are noticeable differences in the spectral statistics of real and generated images, particularly in the high-frequency range. The reasons for these differences are still debated, with some attributing them to the generator and others to the discriminator. In this study, we critically examine these explanations and offer insights into the effectiveness of proposed solutions for reducing high-frequency artifacts. To do this, we thoroughly analyze the architectures of both the generator and discriminator and investigate whether they have a bias towards certain frequency content that hinders the learning process. Our experiments lead to four key observations: 1) Different upsampling techniques used by the generator influence its spectral properties. 2) Upsampling-induced checkerboard artifacts alone cannot account for the spectral discrepancies, as the generator can compensate for them. 3) The discriminator's struggle lies not in detecting high frequencies, but rather in identifying low-magnitude frequencies. 4) Downsampling operations in the discriminator can negatively impact the quality of the training data. Despite analyzing various proposed approaches, we find that none of them fully resolve the spectral artifacts. Our findings suggest that improving the discriminator could be crucial in achieving a closer match between the generated and training data distributions.