We investigate a modified version of contextual linear bandits that has applications in routing and recommendation systems. The objective is to learn a hidden d-dimensional value w∗. Each round, we are presented with a set of possible actions Xt ⊆ Rd. If we choose action xt, we receive utility (cid:104)xt, w∗(cid:105) but only learn the identity of the best action arg maxx∈Xt(cid:104)x, w∗(cid:105). Our proposed algorithms for this problem achieve regret O(d log T ) and exp(O(d log d)) by utilizing cutting-plane algorithms that minimize the "regret" between the true point w∗ and the returned hyperplanes from the separation oracle. Additionally, we examine a variant where multiple recommendations can be provided. In this case, we present an algorithm with regret O(d2 log d) and a list size of poly(d). Finally, we develop efficient algorithms for a weaker version of the problem where the learner only learns the identity of actions that are better than the recommendation. Our results rely on novel algorithmic techniques in convex geometry, including a variation of Steiner's formula for the centroid of a convex set, which may have independent significance.