Deep neural networks are highly effective in computer vision tasks, but they struggle to generalize to simple image distortions. In contrast, the mammalian visual system is robust to various perturbations. Recent research suggests that this robustness is due to inductive biases encoded in the visual cortex. In this study, we utilized these biases through multi-task learning, training a deep network to classify images and predict neural activity in macaque primary visual cortex. We evaluated the network's generalization by testing its resistance to common image distortions. Co-training on monkey data improved the network's robustness, approaching the performance of an Oracle network trained on noisy images. Furthermore, the network's representations became more similar to the brain as its robustness increased. Our analysis revealed that the co-trained network focused more on content rather than noise, and exhibited sensitivity to salient regions in a scene. This work expands the transfer of inductive biases from biological to artificial neural networks, offering new insights into their impact.