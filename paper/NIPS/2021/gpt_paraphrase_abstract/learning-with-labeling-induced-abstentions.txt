In scenarios where we want to automate an expensive task using a machine learning algorithm and have limited labeling resources, the examples sent for labeling are often not suitable for the algorithm. For instance, in spam detection, human reviewers are highly efficient at identifying spam, making it unnecessary for the machine to evaluate those examples. This means that the distribution of examples sent to the machine depends on the labeling process. We propose a formalization of this scenario and present an algorithm that learns a model while deciding when to request a label, drawing from both abstention and active learning techniques. We provide an upper bound on the algorithm's label complexity and prove that it is the best achievable in this setting. We conduct comprehensive experiments, including a study to analyze different components of our algorithm. Our results demonstrate the effectiveness of our efficient algorithm compared to margin sampling on various datasets.