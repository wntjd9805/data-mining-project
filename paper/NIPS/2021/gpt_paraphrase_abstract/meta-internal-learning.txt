We propose a meta-learning approach to improve the limitations of single-image generation models. These models are trained on a single image, which limits their scale and application. By using a collection of images, our approach allows for more effective modeling of the internal statistics of the sample image. We generate a single-imageGAN model using a convolutional feedforward hypernetwork, which is trained over a dataset of images. This enables feature sharing among different models and interpolation in the space of generative models. The meta-learner is trained adversarially, with careful design choices justified by theoretical analysis. Our results show that the models obtained are suitable for common image applications, reduce training time per image without loss in performance, and introduce novel capabilities such as interpolation and feedforward modeling of novel images. Our code is available at: [GitHub link].