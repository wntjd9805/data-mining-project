Neural networks have proven to be more effective than kernel methods in practice, including neural tangent kernels. The existing explanations for this performance gap typically focus on the ability of neural networks to learn complex hypotheses, but it is uncertain whether these hypotheses accurately capture real-world data. In this study, we present an alternative explanation for the performance gap in image classification. We suggest that the ability to identify sparse signals in the presence of noise plays a crucial role. Our research demonstrates that a simple convolutional neural network trained using stochastic gradient descent can effectively filter out noise and identify the signal in a simple data distribution with sparse signal and high-variance noise. On the other hand, the neural tangent kernel, which relies on fixed predetermined features, fails to adapt to the signal in the same way. We support our theoretical findings with empirical evidence from CIFAR-10 and MNIST images with different backgrounds. As the background noise intensifies, the performance of the convolutional neural network remains relatively stable, while the neural tangent kernel experiences a significant decline in performance. This phenomenon, called local signal adaptivity (LSA), provides an explanation for why neural networks outperform kernel methods.