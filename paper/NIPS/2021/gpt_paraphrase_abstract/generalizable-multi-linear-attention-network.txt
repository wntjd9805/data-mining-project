Most multimodal sequential learning methods focus on obtaining strong individual representations and overlook capturing the joint representation of multiple modalities. The Bilinear Attention Network (BAN) is a commonly used integration method that associates features from different modalities using tensor operations. However, BAN is not suitable for handling more modalities due to the exponential increase in computational complexity of the attention map. To address this issue, we propose a new method called the Generalizable Multi-linear Attention Network (MAN). MAN can effectively associate more modalities in an acceptable computational complexity by using hierarchical approximation decomposition. We introduce the addition of random features to approximate non-linear softmax functions, which cannot be decomposed linearly. Additionally, we incorporate local sequential constraints as positional information, which can be easily combined with the addition of random features. We conduct extensive experiments on various datasets and tasks, and the results demonstrate that MAN achieves competitive performance compared to baseline methods, validating the effectiveness of our contributions.