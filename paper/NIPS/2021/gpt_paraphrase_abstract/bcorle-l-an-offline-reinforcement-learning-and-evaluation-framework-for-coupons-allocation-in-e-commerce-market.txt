Coupon allocation is crucial for businesses in the e-commerce market to enhance user activity and loyalty. However, the challenge lies in allocating coupons effectively within a fixed budget while maximizing user retention. Existing studies face limitations in real-time responsiveness and computational efficiency. To address these issues, we propose a framework called BCORLE(位) that utilizes budget-constrained offline reinforcement learning and evaluation with 位-generalization. This framework enables enterprises to develop a coupon allocation policy that improves user retention without exceeding the budget. By incorporating 位-generalization, the policy learning process can adapt to different 位 values, reducing computational overhead. Additionally, we introduce a novel offline reinforcement learning method and an off-policy evaluation algorithm for policy learning and evaluation, respectively. Experimental results from both simulation and real-world e-commerce markets validate the effectiveness of our approach.