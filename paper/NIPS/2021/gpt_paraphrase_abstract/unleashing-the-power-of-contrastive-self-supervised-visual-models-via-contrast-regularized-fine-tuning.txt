Contrastive self-supervised learning (CSL) has gained attention for pre-training models using unlabeled data. CSL models generate instance-discriminative visual features spread uniformly in the feature space. However, directly fine-tuning CSL models using cross-entropy may not be the most effective strategy, as it fails to reduce intra-class feature scattering present in CSL models. This study explores the benefits of applying contrastive learning to fine-tuning and finds that optimizing the contrastive loss improves discriminative representation learning and model optimization. Based on these findings, a new approach called Contrast-regularized tuning (Core-tuning) is proposed. Core-tuning incorporates a novel hard pair mining strategy for more effective contrastive fine-tuning and smooths the decision boundary to better leverage the learned discriminative feature space. Extensive experiments on image classification and semantic segmentation confirm the effectiveness of Core-tuning.