Neural agents trained in reinforcement learning can team up and communicate using discrete tokens. However, using one-hot vectors as communication tokens limits their ability to understand without prior knowledge. To overcome this, we propose using neural agent architectures that allow communication through discrete tokens derived from a continuous space. Our technique optimizes communication in various scenarios, unlike one-hot tokens which only work in limited situations. Through self-play experiments, we confirm that our agents learn to group tokens based on meaning, enabling effective communication in noisy environments. Furthermore, our method enables agents to understand human communication without labels, surpassing the use of one-hot communication.