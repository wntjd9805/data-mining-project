We investigate three interesting aspects of contrastive learning. Firstly, we extend the standard contrastive loss to a wider range of losses and discover that different versions of the generalized loss yield similar results when combined with a multi-layer non-linear projection head. Secondly, we explore whether instance-based contrastive learning, using a global image representation, can effectively learn from images containing multiple objects. Surprisingly, we find that despite operating on global instance-level features, hierarchical local features can still be learned. Lastly, we examine the phenomenon of feature suppression among competing features shared across augmented views. By constructing datasets with explicit and controllable competing features, we demonstrate that contrastive learning can be influenced by a few easily learnable shared features, which can suppress or even prevent the learning of other sets of competing features. This suppression effect is particularly evident when there are multiple objects in an image, with the dominant object inhibiting the learning of smaller objects. Existing contrastive learning methods heavily rely on data augmentation to prioritize certain features, and may struggle with learning saturation when the augmentations fail to fully address feature suppression. These findings pose challenges to current contrastive learning techniques.