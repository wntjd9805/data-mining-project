The field of neuromorphic computing offers the potential for highly efficient sensing and processing with low power and latency. However, there have been challenges in applying learning algorithms from traditional artificial neural networks (ANNs) to spiking neural networks (SNNs) for large-scale regression tasks. Additionally, creating an asynchronous and fully neuromorphic pipeline requires rethinking how information is received and accumulated. In this article, we address these challenges by focusing on the task of estimating optical flow from event-based camera inputs in a self-supervised manner. We modify the ANN training pipeline to encode minimal temporal information in the inputs and improve the convexity of the self-supervised loss function. We conduct experiments using various recurrent ANNs and SNNs in the proposed pipeline, examining factors such as parameter initialization, surrogate gradient shape, and adaptive neuronal mechanisms. Our findings indicate that initialization and surrogate gradient width are crucial for learning with sparse inputs, and the inclusion of adaptivity and learnable neuronal parameters can enhance performance. Overall, our proposed ANNs and SNNs perform on par with the current state-of-the-art ANNs trained in a self-supervised manner.