Hyperbolic space is valuable for organizing hierarchical data, but using regular floating-point numbers to represent it leads to performance issues due to inevitable numerical errors. Simply increasing float precision does not solve the problem and is computationally expensive on GPUs. This paper proposes a practical solution for accurate learning on hyperbolic space, specifically on GPUs. The approach involves representing hyperbolic space using multi-component floating-point (MCF) in the Poincar√© upper-half space model. Theoretical and experimental evidence demonstrates that our model has minimal numerical error. Moreover, when compared to previous methods, models represented by MCF achieve higher capacity and significantly faster performance on GPUs for embedding tasks across different datasets.