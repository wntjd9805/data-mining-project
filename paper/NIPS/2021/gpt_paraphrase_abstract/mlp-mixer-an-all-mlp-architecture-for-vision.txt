Convolutional Neural Networks (CNNs) and attention-based networks like the Vision Transformer are commonly used models in computer vision. However, this paper introduces MLP-Mixer, an architecture that relies solely on multi-layer perceptrons (MLPs). MLP-Mixer consists of two types of layers: one that applies MLPs independently to image patches, enhancing per-location features, and another that applies MLPs across patches, improving spatial information. Despite not using convolutions or attention, MLP-Mixer achieves competitive performance on image classification benchmarks when trained on large datasets or with modern regularization techniques. Additionally, MLP-Mixer's pre-training and inference costs are similar to state-of-the-art models. These findings encourage further exploration beyond the well-established CNNs and Transformers.