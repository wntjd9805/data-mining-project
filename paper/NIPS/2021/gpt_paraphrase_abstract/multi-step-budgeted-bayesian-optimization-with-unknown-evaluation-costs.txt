Bayesian optimization (BO) is an efficient method for optimizing expensive black-box functions. However, most BO methods do not consider the variability of evaluation costs across the optimization domain, which is often unknown in practical scenarios. Additionally, existing methods that address cost heterogeneity do not naturally incorporate a budget constraint on the total evaluation cost. This introduces a new dimension to the exploration-exploitation trade-off, where learning about the cost has its own cost. Current methods do not handle this trade-off effectively, resulting in poor performance. We prove that widely used acquisition functions, such as expected improvement, can be significantly worse compared to the optimal non-myopic policy. To address these limitations, we introduce a new acquisition function called budgeted multi-step expected improvement, which extends the classical expected improvement to handle heterogeneous and unknown evaluation costs. Our proposed acquisition function outperforms existing methods in various synthetic and real problems.