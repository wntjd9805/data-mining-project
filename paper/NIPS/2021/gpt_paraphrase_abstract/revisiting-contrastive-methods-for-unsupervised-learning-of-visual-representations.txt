Contrastive self-supervised learning has surpassed supervised pretraining in various tasks such as segmentation and object detection. However, current methods are mainly applied to curated datasets like ImageNet. This paper examines the impact of dataset biases on existing methods. Surprisingly, the approach of MoCo performs well across different types of datasets, including object- versus scene-centric, uniform versus long-tailed, and general versus domain-specific. Additionally, the paper explores potential enhancements to the approach to achieve even better results. Incorporating multi-scale cropping, stronger augmentations, and nearest neighbors to learn additional invariances improves the representations. Furthermore, when trained with a multi-crop strategy, MoCo learns spatially structured representations. These representations prove effective for tasks like semantic segment retrieval and video instance segmentation without the need for fine-tuning, and they perform comparably to specialized models. The authors hope that this study will be valuable for other researchers, and the code and models are available for public use.