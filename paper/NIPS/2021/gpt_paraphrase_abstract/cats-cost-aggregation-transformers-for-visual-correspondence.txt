We introduce a new cost aggregation network called Cost Aggregation Transform-ers (CATs) to establish dense correspondences between semantically similar images. This task is challenging due to variations in appearance and geometry within the same class. Cost aggregation is a crucial step in matching tasks, as the accuracy of the matches depends on the quality of this process. Existing methods, whether hand-crafted or CNN-based, have limitations in handling severe deformations or discerning incorrect matches due to limited receptive fields. CATs address these limitations by leveraging global consensus from the initial correlation map through architectural designs that incorporate self-attention mechanisms. We incorporate appearance affinity modeling to improve the cost aggregation process and disambiguate noisy correlation maps. Additionally, we propose multi-level aggregation to efficiently capture different semantic information from hierarchical feature representations. By using swapping self-attention technique and residual connections, we ensure consistent matching and facilitate the learning process, resulting in improved performance. We conduct experiments to validate the effectiveness of our model compared to state-of-the-art methods and provide extensive analysis. The code and trained models are available at https://sunghwanhong.github.io/CATs/.