We propose a method to learn a generative neural body model from unlabelled monocular videos using Neural Radiance Fields (NeRFs). Our model extends NeRFs by incorporating a skeleton to handle time-varying and articulated motion. We introduce a reparameterization technique that allows us to overcome the limitations of existing models and learn volumetric body shape and appearance from scratch. This approach does not require ground truth labels for appearance, pose, or 3D shape in the input videos. Our neural model improves accuracy on diverse datasets for tasks such as novel-view-synthesis and motion capture. More information can be found on our project website: https://lemonatsu.github.io/anerf/.