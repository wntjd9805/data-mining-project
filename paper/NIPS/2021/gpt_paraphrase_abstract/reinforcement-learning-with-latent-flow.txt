Current RL algorithms either assume temporal information is given in the state space or use frame-stacking to capture it from image observations. However, this is different from video classification architectures that use explicit encodings like optical flow. To address this, we propose Flare, an RL network architecture that encodes temporal information through latent vector differences. Flare achieves optimal performance in state-based RL without access to state velocity, using only positional state information. It is the most sample efficient model-free pixel-based RL algorithm on the DeepMind Control suite and outperforms the baseline on Atari games.