We investigate the capabilities of learned optimizers, which are parametric algorithms trained to solve optimization problems. Unlike traditional optimizers, learned optimizers utilize flexible and high-dimensional parameterizations. While these learned optimizers have shown improved performance, their underlying mechanisms remain unclear. We aim to understand how learned optimizers outperform baseline optimizers by analyzing and visualizing their behavior. Through our study, we find that learned optimizers exhibit interpretable behavior, including momentum, gradient clipping, learning rate schedules, and adaptation. We also uncover the dynamics and mechanisms within learned optimizers that orchestrate these computations. Our findings shed light on the previously ambiguous understanding of learned optimizers and provide tools for interpreting future variations of such optimizers.