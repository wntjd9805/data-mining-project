This study focuses on reinforcement learning (RL) environments where entities interact infrequently and independently. In such cases, RL agents have limited control over other entities. The researchers propose that learning can be enhanced by understanding when and how agents can influence their surroundings. They introduce a measure called situation-dependent causal influence, which utilizes conditional mutual information to identify influential states. The measure is integrated into RL algorithms to enhance exploration and off-policy learning. The modified algorithms demonstrate significant improvements in data efficiency for robotic manipulation tasks.