Deep Neural Networks (DNNs) are susceptible to adversarial attacks, where small changes to the input can cause the network to make incorrect predictions. Adversarial training is currently the most effective defense method, involving the addition of adversarial samples to the training set. However, we have discovered that there are subnetworks within randomly initialized networks that possess inherent robustness, matching or surpassing the accuracy of adversarially trained networks without any model training. We call these subnetworks Robust Scratch Tickets (RSTs), which are also efficient. Unlike the popular lottery ticket hypothesis, neither the original dense networks nor the identified RSTs require training. We conducted extensive experiments to validate and understand the existence and properties of RSTs, considering different models, datasets, sparsity patterns, and attacks. Additionally, we found poor transferability between RSTs of different sparsity ratios from the same randomly initialized dense network. To address this, we propose a Random RST Switch (R2S) technique that randomly switches between different RSTs as a defense method. Our findings about RSTs offer a new perspective on studying model robustness and extend the lottery ticket hypothesis. The code is available at: https://github.com/RICE-EIC/Robust-Scratch-Ticket.