The current research on deep learning for tabular data introduces various new architectures and demonstrates competitive results on different datasets. However, these models are often not compared adequately, and there is inconsistency in the benchmarks and experiment protocols used in previous studies. Consequently, it is unclear which models perform the best for both researchers and practitioners. Furthermore, there is a lack of effective baselines, which are user-friendly models that deliver strong performance across various problems.To address these issues, this study provides an overview of the main types of deep learning architectures for tabular data and improves the baselines by identifying two simple yet powerful models. The first model is a ResNet-like architecture that serves as a strong baseline, which has been missing in prior research. The second model is our modified version of the Transformer architecture for tabular data, which outperforms other solutions in most tasks. Both models are evaluated against numerous existing architectures using the same training and tuning protocols. Additionally, we compare the top deep learning models with Gradient Boosted Decision Trees and conclude that there is no universally superior solution.For easy access, the source code can be found at https://github.com/yandex-research/rtdl.