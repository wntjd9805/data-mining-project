Unsupervised domain adaptation has gained significant attention in academia as a means of transferring knowledge from labeled source domains to unlabeled target domains. However, current methods are limited in their ability to handle multiple source domains with varying distributions and often require access to source data during training, which is inefficient and impractical due to privacy concerns and storage limitations. To address these challenges, we propose a novel approach called Conﬁdent-Anchor-induced multi-source-free Domain Adaptation (CAiDA). This model explores knowledge adaptation from multiple source domains to the unlabeled target domain without the need for any source data, relying solely on pre-trained source models. We introduce a source-speciﬁc transferable perception module that quantifies the contributions of complementary knowledge from multiple source domains to the target domain. Additionally, we develop a conﬁdent-anchor-induced pseudo label generator to produce pseudo labels for the target domain without access to the source data. This generator constructs a conﬁdent anchor group and assigns each unconﬁdent target sample with a semantic-nearest conﬁdent anchor. We also propose a class-relationship-aware consistency loss to preserve consistent inter-class relationships by aligning soft confusion matrices across domains. Theoretical analysis demonstrates the advantages of using multi-source domains over a single source domain and establishes a new learning bound to quantify the effectiveness of exploiting multi-source domains. Experimental results on various datasets validate the superiority of our CAiDA model. The code for our model is available at https://github.com/Learning-group123/CAiDA.