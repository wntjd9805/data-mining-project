We propose a Siamese voxel-to-BEV tracker for 3D object tracking in sparse point clouds. Our approach includes a Siamese shape-aware feature learning network and a voxel-to-BEV target localization network. The shape-aware network captures the object's 3D shape information to learn discriminative features, enabling identification of potential targets in sparse point clouds. The voxel-to-BEV network localizes the tracked target by regressing its 2D center and z-axis center from a dense bird's eye view (BEV) feature map. We compress the point cloud along the z-axis to obtain the dense BEV map, improving the effectiveness of center regression. Our method outperforms current state-of-the-art methods on KITTI and nuScenes datasets. Code is available at https://github.com/fpthink/V2B.