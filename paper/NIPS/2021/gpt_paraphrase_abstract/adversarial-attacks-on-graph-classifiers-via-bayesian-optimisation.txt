Graph neural networks have become widely used in graph-based learning tasks, but they are vulnerable to adversarial attacks. While most research focuses on node-level classification tasks, little has been done to analyze attacks on graph-level classification, which has important real-life applications. Existing methods often require unrealistic conditions or a large number of queries. In this study, we propose a new attack method for graph classification models that is black-box, query-efficient, and parsimonious. We validate the effectiveness and flexibility of our method on various graph classification tasks, and analyze the interpretable patterns of the generated adversarial samples. The code for our method is available at https://github.com/xingchenwan/grabnel.