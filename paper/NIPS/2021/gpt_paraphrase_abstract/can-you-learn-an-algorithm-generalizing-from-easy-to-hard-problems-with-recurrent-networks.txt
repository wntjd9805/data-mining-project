Deep neural networks excel at recognizing visual patterns, but they struggle with reasoning tasks that humans find easy. Humans can apply reasoning strategies learned from simple problems to solve more difficult ones by spending more time on them. Computers typically achieve this through algorithms, which require more computation but can handle increasingly complex problems. In contrast, feed-forward neural networks have limited computational capacity due to their depth, and networks trained on simple problems cannot adapt their reasoning for harder ones. However, our research demonstrates that recurrent networks trained on simple problems can solve more complex problems by performing additional recurrences during inference. We showcase this algorithmic behavior in tasks such as preÔ¨Åx sum computation, mazes, and chess. In all three domains, networks trained on simple problems enhance their reasoning abilities during testing by taking more time to "think".