This study explores the application of deep reinforcement learning (RL) using neural networks to approximate the Q function. While previous RL theory focused on linear function approximation, little is known about using neural networks for nonlinear RL. The authors investigate function approximation using two-layer neural networks with ReLU and polynomial activation functions. They present two key findings: an efficient algorithm in the generative model setting and a sample complexity analysis in the realizability setting. Both results outperform linear methods.