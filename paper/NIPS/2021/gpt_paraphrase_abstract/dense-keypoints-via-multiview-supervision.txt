This paper introduces a novel approach for learning a dense keypoint detector using unlabeled multiview images. The main challenge lies in identifying the exact correspondences between keypoints in different views, as this information cannot be analytically derived or differentiated. Existing methods for learning sparse keypoints rely on these exact correspondences, making them unsuitable for this task. To address this challenge, we propose a new probabilistic epipolar constraint that incorporates two important properties. Firstly, we define a matchability measure that quantifies the likelihood of a point matching to its corresponding point in another image, thus relaxing the requirement for exact correspondences. Secondly, we ensure geometric consistency by requiring that all points in the continuous correspondence fields satisfy multiview consistency collectively. We formulate a probabilistic epipolar constraint by calculating a weighted average of epipolar errors based on the matchability, allowing us to generalize the point-to-point geometric error to the field-to-field geometric error. This generalization enables us to learn a dense keypoint detection model that is geometrically coherent, using a large number of unlabeled multiview images. To avoid degenerative cases, we incorporate a distillation-based regularization technique using a pretrained model. Additionally, we propose a new neural network architecture consisting of twin networks, which effectively minimizes the probabilistic epipolar errors by constructing affinity matrices for all possible correspondences between two view images. Our method outperforms existing approaches, including non-differentiable bootstrapping, in terms of keypoint accuracy, multiview consistency, and 3D reconstruction accuracy.