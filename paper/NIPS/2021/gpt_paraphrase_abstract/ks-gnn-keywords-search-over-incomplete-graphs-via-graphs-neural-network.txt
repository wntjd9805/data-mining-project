Keyword search over graphs is a crucial task for retrieving relevant information based on query keywords. Previous studies assumed complete graphs, but real-world graphs often have missing information, making the problem more difficult. To address this, we propose a novel model called KS-GNN that combines graph neural networks and auto-encoders. By considering latent relationships and keyword frequency, KS-GNN can mitigate the impact of missing information and learn representative node embeddings that preserve both graph structure and keyword features. Our model can efficiently answer keyword search queries on incomplete graphs with linear time complexity. Experimental results on real-world datasets demonstrate that KS-GNN consistently outperforms existing methods when dealing with missing information.