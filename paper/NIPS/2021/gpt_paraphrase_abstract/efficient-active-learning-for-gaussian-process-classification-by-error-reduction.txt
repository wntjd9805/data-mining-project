This study focuses on active learning in Gaussian Process Classification (GPC) and explores both the pool-based and query synthesis scenarios. Existing active learning strategies aim to minimize classification error by selecting instances that maximize Estimated Error Reduction (EER), but these strategies are computationally expensive as they require retraining the GPC for each query. Additionally, the non-smooth nature of EER prevents efficient exploration of the continuous instance space. To address these issues, the authors propose computationally efficient algorithms for EER-based active learning with GPC. These algorithms avoid the need for retraining the GPC for each query by deriving the joint predictive distribution of label pairs as a one-dimensional integral. The authors also develop the gradient chain rule to efficiently calculate the gradient of the acquisition function, enabling the first query synthesis active learning algorithm based on EER. Experimental results demonstrate the computational efficiency and superior performance of the proposed algorithms compared to existing state-of-the-art methods on synthetic and real-world datasets.