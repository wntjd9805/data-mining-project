Recent advancements in large language models have demonstrated their impressive ability to learn from limited examples, even when dealing with algorithmic patterns. However, the extent to which these models can capture different types of patterns and the minimal number of examples required for learning remains uncertain. To address this, we approach the question as a teaching problem with predefined assumptions and examine whether language models can identify basic algorithmic concepts using only a small set of examples. Our investigation involves comparing the performance of various GPT architectures, program induction systems, and human beings in terms of concept complexity and the need for additional examples. By conducting this comprehensive analysis of language models and machine teaching, we can gain insights into crucial aspects of artificial intelligence and machine learning. For instance, we can determine if strong priors, such as Occam's razor, can be distilled from data, thereby enabling the learning process with just a few examples.