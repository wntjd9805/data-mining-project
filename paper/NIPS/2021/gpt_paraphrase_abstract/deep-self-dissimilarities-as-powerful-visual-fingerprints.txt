Deep features extracted from classification networks are commonly used as image descriptors. In this study, we explore a previously unexplored characteristic of these features: their internal dissimilarity. While small image patches tend to have similar statistics across different image scales, we discovered that the distribution of deep features varies noticeably between scales. This property, known as deep self dissimilarity (DSD), can serve as a robust visual fingerprint. We demonstrate that image quality measures derived from DSD, both with and without reference images, are strongly correlated with human preference. Furthermore, incorporating DSD as a loss function in the training of image restoration networks produces results that are at least as realistic as those achieved by adversarial training methods, without the need for adversarial training.