Recent advancements in neural architecture search (NAS) have led to the development of tabular and surrogate benchmarks, which have enhanced the speed and reproducibility of NAS research. However, two widely used benchmarks lack complete training information for each architecture, limiting the application of multi-fidelity techniques like learning curve extrapolation. To address this, our study introduces NAS-Bench-111, NAS-Bench-311, and NAS-Bench-NLP11, surrogate benchmarks that provide full training information for every architecture, rather than just the final validation accuracy. We leverage singular value decomposition and noise modeling to create these benchmarks. By utilizing the complete training information, we demonstrate the effectiveness of a learning curve extrapolation framework in improving single-fidelity algorithms. This approach surpasses the claimed state-of-the-art performance of popular single-fidelity algorithms. The code and pretrained models can be accessed at https://github.com/automl/nas-bench-x11.