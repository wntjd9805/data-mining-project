The effectiveness of generalizing learned representations through contrastive learning relies heavily on the selection of extracted data features. However, it has been observed that the contrastive loss does not consistently guide the extraction of these features, which can have a negative impact on downstream tasks by inadvertently suppressing important predictive features. This phenomenon, known as "shortcuts," is influenced by the difficulty of the instance discrimination task, where pairs of similar points are distinguished from dissimilar ones. While harder pairs can enhance the representation of certain features, they also come at the expense of suppressing previously well-represented features. To address this issue, we propose a method called implicit feature modification (IFM), which alters positive and negative samples to encourage contrastive models to capture a wider range of predictive features. Empirical results demonstrate that IFM reduces feature suppression and improves performance in vision and medical imaging tasks. The code for IFM is available at: https://github.com/joshr17/IFM.