Simulation-based techniques, such as various versions of stochastic Runge-Kutta, are commonly used for inference with stochastic differential equations (SDEs) in machine learning. These methods are versatile and can be applied to both parametric and non-parametric models, including neural SDEs. However, stochastic Runge-Kutta can be inefficient in high-dimensional scenarios due to the use of sampling schemes. To address this inefficiency, we revisit classical SDE literature and develop direct approximations to the Fokker-Planck-Kolmogorov equation, which is typically intractable. We achieve this by matching moments. Our approach offers a fast and scalable workflow that can handle high-dimensional latent spaces. Additionally, it is suitable for scarce-data applications, where the model is specified by a non-parametric SDE with a driving Gaussian process velocity field.