Zero-shot learning (ZSL) is a method used to recognize unseen classes by transferring knowledge from seen classes. Existing approaches use a common space to align the visual and semantic domains, but this is ineffective because of the heterogeneous nature of the feature representations. To address this, we propose a novel framework called hierarchical semantic-visual adaptation (HSVA). HSVA uses a two-step adaptation process, involving structure and distribution adaptation. In the structure adaptation step, task-specific encoders are used to align the visual and semantic domains. This is achieved by minimizing the discrepancy between predictions from two classifiers. In the distribution adaptation step, the Wasserstein distance is minimized to align the visual and semantic distributions. Both adaptations are unified in a framework using partially-aligned variational autoencoders. Experimental results on four benchmark datasets show that HSVA outperforms existing methods in both conventional and generalized ZSL. The code for HSVA is available at https://github.com/shiming-chen/HSVA.