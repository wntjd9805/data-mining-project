Optimizing multiple competing objectives is a difficult problem in various fields. Multi-objective Bayesian optimization (MOBO) is an effective approach for finding the best trade-offs between these objectives. However, existing methods struggle when the observations are noisy. To overcome this limitation, we propose a new acquisition function called NEHVI. NEHVI incorporates a Bayesian treatment of the popular expected hypervolume improvement (EHVI) criterion and considers uncertainty in the Pareto frontier. We argue that generating multiple candidates in parallel is a form of EHVI with uncertainty in the Pareto frontier, and can be addressed using the same technique. We introduce a parallel variant called qNEHVI, which reduces the computational complexity of parallel EHVI. qNEHVI is optimal for hypervolume maximization in both noisy and noiseless environments, and can be optimized effectively using gradient-based methods. Our empirical results demonstrate that qNEHVI is more robust to observation noise compared to existing MOBO approaches. Additionally, it achieves state-of-the-art optimization performance and competitive wall-times in large-batch environments.