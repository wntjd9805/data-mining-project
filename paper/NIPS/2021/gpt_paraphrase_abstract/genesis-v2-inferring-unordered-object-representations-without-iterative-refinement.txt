Unsupervised learning of object-representations has made significant progress, but current methods have limitations in dealing with complex visual data and often rely on RNNs or iterative refinement. This study introduces an embedding-based approach that clusters pixel embeddings using a differentiable stochastic stick-breaking process. This approach allows for randomly ordered object representations without the need for predefined clusters. A new model called GENESIS-V2 is developed based on this approach, which can infer variable numbers of object representations without using RNNs or iterative refinement. Experimental results demonstrate that GENESIS-V2 outperforms recent baselines in unsupervised image segmentation and object-centric scene generation on both synthetic and real-world datasets with varying levels of complexity.