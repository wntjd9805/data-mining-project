We propose two new approaches for privacy-preserving machine learning (ML) that maintain differential privacy (DP) with respect to the labels of training examples. Our methods, which utilize the Laplace mechanism and the PATE framework, are demonstrated to be effective on standard benchmarks. While previous work has suggested Label DP schemes based on randomized response mechanisms, we argue that our approach, which combines additive Laplace noise with Bayesian inference (ALIBI), is better suited for typical ML tasks. Additionally, we show how our adaptation of the PATE framework, incorporating recent advancements in semi-supervised learning, can achieve high levels of privacy in certain scenarios. We provide both theoretical analysis and empirical evaluation of our algorithms' privacy guarantees, as well as their ability to resist memorization attacks. Our findings indicate that comparing algorithms based solely on their provable DP guarantees may be misleading, as a less private algorithm with a more rigorous analysis could be favored. The code for implementing our algorithms and conducting memorization attacks is available at https://github.com/facebookresearch/label_dp_antipodes.