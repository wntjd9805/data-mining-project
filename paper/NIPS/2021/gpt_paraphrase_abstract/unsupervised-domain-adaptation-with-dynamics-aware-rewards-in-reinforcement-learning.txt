Unsupervised reinforcement learning aims to acquire skills without prior goal representations. However, this can be time-consuming and limits rollout in expensive target environments. Training in another interaction-rich environment disrupts reproducibility of skills in the target environment. To address this, we propose an unsupervised domain adaptation method that uses a KL regularized objective to encourage skill emergence and align behaviors respecting dynamics shifts. This allows for the learning of adaptive skills. Empirical experiments show that our method effectively learns skills that can be smoothly deployed in the target environment.