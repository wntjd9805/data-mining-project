Despite the limitations in accessing data, machine learning models trained on large datasets have made significant advancements in various fields. However, their implementation in privacy-sensitive domains remains restricted. To overcome this challenge, we propose DP-Sinkhorn, a new generative method that learns data distributions from private data while ensuring differential privacy. DP-Sinkhorn utilizes the Sinkhorn divergence, which approximates the optimal transport distance, to minimize the difference between the model and data in a differentially private manner. It also introduces a novel technique to balance the trade-off between bias and variance in gradient estimates. Unlike existing approaches that rely on generative adversarial networks, DP-Sinkhorn does not require adversarial objectives, making it easier to train and deploy. In experiments, we outperform existing methods in image modeling benchmarks and demonstrate the differentially private synthesis of informative RGB images. For more information, please visit our project page: https://nv-tlabs.github.io/DP-Sinkhorn.