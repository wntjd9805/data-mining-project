We examine the challenge of searching for an input that maximizes a black-box objective function using a static dataset of input-output queries. One common approach is to use a proxy model, such as a deep neural network (DNN), to approximate the true objective function. However, a major issue is avoiding inputs that are adversarially optimized, meaning the DNN overestimates the true objective function. To address this problem, we propose a new framework called robust model adaptation (RoMA). RoMA involves two steps: (a) a pre-training strategy to train the proxy model robustly, and (b) a novel adaptation procedure that enables the proxy model to have robust estimates for a specific set of candidate solutions. Our approach leverages the local smoothness prior to mitigate the fragility of the DNN. Experimental results on various tasks demonstrate the effectiveness of RoMA compared to previous methods, achieving state-of-the-art performance. For example, RoMA outperforms all other methods in 4 out of 6 tasks and achieves the second-best results in the remaining tasks.