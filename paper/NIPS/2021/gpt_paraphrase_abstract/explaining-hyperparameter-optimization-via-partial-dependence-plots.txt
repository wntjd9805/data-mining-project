Automated hyperparameter optimization (HPO) helps improve machine learning models, but lacks explainability. To address this, we propose using interpretable machine learning (IML) to gain insights from experimental data obtained during HPO with Bayesian optimization (BO). BO focuses on promising regions, leading to a sampling bias. Existing IML techniques like partial dependence plot (PDP) can generate biased interpretations. To overcome this, we introduce a variant of PDP with estimated confidence bands by leveraging the posterior uncertainty of the BO surrogate model. Additionally, we suggest partitioning the hyperparameter space to obtain more confident and reliable PDPs in relevant sub-regions. In an experimental study, we demonstrate the improved quality of PDPs within sub-regions.