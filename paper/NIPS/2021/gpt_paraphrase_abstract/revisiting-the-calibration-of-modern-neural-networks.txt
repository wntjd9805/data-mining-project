Ensuring accurate estimation of predictive uncertainty in neural networks is crucial for their safe application. However, there have been reports of miscalibration in newer and more accurate models. In this study, we investigate this issue specifically for state-of-the-art image classification models. By examining the relationship between model calibration and accuracy, we find that the latest models, particularly those without convolutions, are better calibrated. Previous trends, such as calibration decay with distribution shift or model size, are less prominent in recent architectures. Additionally, we demonstrate that differences in model size and pretraining do not entirely account for these variations, suggesting that the architecture itself plays a significant role in calibration properties.