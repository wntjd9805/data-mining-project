Attention mechanisms are essential for deep learning models like Transformer to process sequences or images where position is important. This paper introduces a new method of positional encoding using learnable Fourier features. Instead of assigning a fixed token or vector to each position, we use a trainable encoding based on learnable Fourier feature mapping, adjusted with a multi-layer perceptron. This approach is especially beneficial for representing multi-dimensional positions, such as pixel positions on an image, where capturing complex positional relationships is necessary. Experimental results on various benchmark tasks demonstrate that our learnable Fourier feature representation for multi-dimensional positional encoding surpasses existing methods in terms of accuracy and convergence speed.