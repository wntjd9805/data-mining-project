We investigate the problem of training models that are robust against adversarial examples. Certifiable training aims to minimize the worst-case loss within a given perturbation range. The accuracy of the upper bound is crucial in developing robust models. However, Interval Bound Propagation (IBP) training, which uses looser bounds, has been shown to outperform models with tighter bounds. We uncover another important factor in certifiable training: the smoothness of the loss landscape. We observe significant variations in the loss landscapes among different linear relaxation-based methods, with the current state-of-the-art method exhibiting favorable optimization properties. To validate this finding, we introduce a new certifiable training method that possesses desired properties. By combining tightness and smoothness, our proposed method achieves satisfactory performance across a wide range of perturbations, whereas methods with only one of these factors excel within a specific perturbation range. Our code is accessible at https://github.com/sungyoon-lee/LossLandscapeMatters.