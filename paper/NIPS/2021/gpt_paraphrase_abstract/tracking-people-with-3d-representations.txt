We introduce a new method for tracking multiple individuals in video by utilizing 3D representations instead of traditional 2D representations. Our approach, called Human Mesh and Appearance Recovery (HMAR), extracts both the 3D geometry and appearance of individuals using a SMPL mesh and texture map. This 3D representation is resilient to changes in viewpoint and pose. Our method involves detecting bounding boxes for each person in a video clip and extracting their 3D appearance, pose, and location information using HMAR. These embedding vectors are then processed by a transformer to aggregate spatial and temporal information over the sequence. The resulting representations' similarity is used to assign each person to a tracklet. We evaluate our approach on various datasets and find that 3D representations outperform 2D representations, achieving state-of-the-art performance. Our code and results can be found at: https://brjathu.github.io/T3DP.