Convolutional Neural Networks (CNNs) are widely used for video action recognition, but training these networks with small batch sizes presents challenges for learning spatial-temporal representations. To address this, the authors propose Dynamic Normalization and Relay (DNR), an improved normalization design that enhances the learning of spatial-temporal representations in deep action recognition models. The authors observe that existing networks apply the same normalization parameters to all video data, neglecting the dependencies between neighboring frames and layers. DNR introduces two dynamic normalization relay modules that leverage cross-temporal and cross-layer feature distribution dependencies to estimate accurate layer-wise normalization parameters. These modules are lightweight recurrent structures conditioned on the current input features and normalize parameters from neighboring frames or the entire video clip. The authors evaluate DNR on public action recognition datasets and find that it significantly improves performance without the need for additional training techniques. The effectiveness of DNR is further validated on different backbone architectures and spatial-temporal networks. The code for DNR is available at a specified GitHub repository.