To address the challenges of manual hyperparameter tuning and slow convergence time in first-order methods for quadratic optimization, this study explores the use of Reinforcement Learning (RL) to learn a policy for tuning parameters and accelerating convergence. Through experiments using established quadratic programming benchmarks, the RLQP policy outperforms state-of-the-art solvers by up to three times. Furthermore, RLQP demonstrates strong generalization capabilities across various applications and problem dimensions. The code, models, and videos associated with this study can be accessed at https://berkeleyautomation.github.io/rlqp/.