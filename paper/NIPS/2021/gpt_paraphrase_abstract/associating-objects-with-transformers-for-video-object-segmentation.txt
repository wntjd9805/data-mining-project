This study focuses on improving the efficiency and effectiveness of embedding learning for semi-supervised video object segmentation in challenging multi-object scenarios. Current methods require matching and segmenting each target separately, which consumes significant computing resources. To address this issue, we propose an approach called Associating Objects with Transformers (AOT) that allows for the simultaneous matching and decoding of multiple objects. AOT achieves this by employing an identification mechanism to associate multiple targets in the same high-dimensional embedding space. To effectively model multi-object association, we introduce a Long Short-Term Transformer for hierarchical matching and propagation. We conducted extensive experiments on both multi-object and single-object benchmarks, comparing AOT variant networks with different complexities. Our R50-AOT-L outperformed state-of-the-art competitors on popular benchmarks, including YouTube-VOS (84.1% J & F), DAVIS 2017 (84.9%), and DAVIS 2016 (91.1%), while also achieving more than three times faster multi-object runtime. Additionally, our AOT-T demonstrated real-time multi-object speed on these benchmarks. Our AOT approach enabled us to rank first in the 3rd Large-scale VOS Challenge.