We present Habitat 2.0 (H2.0), a simulation platform that trains virtual robots in interactive 3D environments with complex physics scenarios. Our contributions include a dataset of artist-authored 3D apartments with movable objects, a high-performance physics-enabled simulator, and a benchmark suite for assistive robots. These engineering advancements allow us to compare deep reinforcement learning (RL) and classical sense-plan-act (SPA) pipelines in long-horizon tasks, focusing on generalization. Our findings show that hierarchical RL policies outperform flat RL policies in the benchmark tasks, but hierarchies with independent skills face challenges in transferring control between skills. Additionally, SPA pipelines are less robust compared to RL policies.