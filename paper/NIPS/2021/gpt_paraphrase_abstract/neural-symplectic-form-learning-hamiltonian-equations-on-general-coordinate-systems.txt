Recent research has focused on learning Hamiltonian equations, but existing methods rely on the use of generalized momenta, which are often unknown. This poses challenges when applying these models to real data. However, Hamiltonian equations can also be expressed using the symplectic 2-form, which is coordinate-free. In this study, we propose a model that uses neural networks to learn the symplectic form from data, allowing us to learn Hamiltonian equations from data represented in any coordinate system. This approach not only models both Hamiltonian and Lagrangian equations but also uncovers unknown Hamiltonian structures in the data. Our experiments demonstrate that even complex equations like the Lotka-Volterra equation can be learned using this method. By associating each symplectic 2-form with a skew-symmetric matrix, we leverage the fact that symplectic 2-forms are derived from differential 1-forms to improve the learning efficiency.