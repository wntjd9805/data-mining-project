Deep Neural Networks are vulnerable to adversarial attacks, leading to efforts to improve their robustness. However, current state-of-the-art defenses are computationally impractical for large-scale datasets. While single-step defenses show promise, they are not as effective as multi-step methods. To address this, we propose a novel Nuclear-Norm regularizer that smooths network predictions near data samples. Unlike previous approaches, our regularizer considers joint statistics of adversarial samples in a training minibatch, improving optimization for both attack generation and training. We also incorporate exponential averaging of network weights over iterations for further gains. Additionally, we introduce a Hybrid training approach that combines the effectiveness of a two-step defense with the efficiency of a single-step defense. Our approach outperforms multi-step defenses like TRADES and PGD-AT while being significantly more computationally efficient.