We propose a differentially private algorithm for the multi-armed bandit (MAB) problem in the shuffle model. This algorithm ensures an epsilon-delta privacy guarantee and has a regret that depends on the distribution. The regret is bounded by O(kT log T + k log T∆a√√), where T is the number of rounds, ∆a is the suboptimality gap of arm a, and k is the total number of arms. Our algorithm's regret nearly matches the best-known algorithms for the centralized model and outperforms the best-known algorithm in the local model.