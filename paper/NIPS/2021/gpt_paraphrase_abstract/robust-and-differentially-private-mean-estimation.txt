The increasing use of statistical learning and analysis from shared data in platforms like federated learning and meta-learning raises concerns about privacy and robustness. Participants should be able to contribute without compromising their sensitive information, while the system should be able to handle malicious participants inserting corrupted data. Current algorithms focus on either privacy or robustness, leaving the system vulnerable to the other. In this study, we address this issue by introducing PRIME, an efficient algorithm that achieves both privacy and robustness for estimating the mean from independent and identically distributed samples. We also present a new exponential time algorithm that improves the sample complexity of PRIME, achieving near-optimal results and matching a known lower bound for private mean estimation without robustness. This demonstrates that there is no additional statistical cost to simultaneously ensuring privacy and robustness.