The High-Resolution Transformer (HRFormer) is a novel approach that improves the efficiency and performance of dense prediction tasks compared to the original Vision Transformer. By utilizing the multi-resolution parallel design from HRNet and local-window self-attention, we address the high memory and computational costs. We also introduce a convolution into the FFN to exchange information across image windows. Our experiments on human pose estimation and semantic segmentation tasks show that HRFormer outperforms Swin transformer with fewer parameters and FLOPs. The code for HRFormer is available at: https://github.com/HRNet/HRFormer.