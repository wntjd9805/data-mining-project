Generalization to out-of-distribution (OOD) data is a major challenge in modern machine learning. Many algorithms focus on extracting invariant features to improve OOD generalization, but the theoretical understanding of which types of invariance guarantee this generalization is limited. Additionally, it is impossible to generalize to arbitrary out-of-distribution data. In this study, we take the first step in defining OOD and what it means for an OOD problem to be learnable. We introduce the concept of an expansion function, which quantifies the amplification of variance in test domains compared to training domains and provides a quantitative interpretation of invariant features. Using these definitions, we prove error bounds for OOD generalization, with the expansion function playing a crucial role. We also address the importance of model selection in OOD learning algorithms, as highlighted by recent research. Our theory naturally leads to a model selection criterion, and extensive experiments on benchmark OOD datasets demonstrate its superiority over baselines.