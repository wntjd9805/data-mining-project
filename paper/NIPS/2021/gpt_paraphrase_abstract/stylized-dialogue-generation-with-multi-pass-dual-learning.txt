Stylized dialogue generation is crucial for intelligent dialogue systems as it aims to generate responses in a given style based on the input context. Existing methods rely on back translation to create synthetic data for training, using the context, target style, and an intermediate style. However, these methods do not fully exploit the interaction between these texts and do not adequately model the pseudo contexts. To address these limitations, we propose multi-pass dual learning (MPDL) which leverages the duality between the context, response in target style, and response in intermediate style. MPDL establishes mappings among these three domains, with the context being reconstructed by the MPDL framework. The reconstruction error serves as the training signal. To assess the quality of synthetic data, we introduce discriminators that measure how well a pseudo sequence matches a specific domain. The evaluation result is used as a weight for that data. Our method achieves significant improvement over previous baselines according to the evaluation results.