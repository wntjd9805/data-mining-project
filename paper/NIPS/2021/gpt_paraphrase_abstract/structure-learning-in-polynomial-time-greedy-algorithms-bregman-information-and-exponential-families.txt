Greedy algorithms have been widely used in learning graphical models and statistical models with sparse structures. Despite their worst-case exponential runtime, greedy algorithms are popular in learning directed acyclic graphs. In practice, these algorithms are highly efficient. Our study focuses on a score-based greedy algorithm for learning DAGs, which is different from edge-greedy algorithms like GES and hill-climbing algorithms. Our approach is vertex-greedy and requires a polynomial number of score evaluations. We demonstrate that recent polynomial-time algorithms for learning DAG models can be seen as a special case of our algorithm, highlighting the rigorous interpretation of order-based algorithms as score-based algorithms. This insight leads us to explore new score functions and optimality conditions based on the duality between Bregman divergences and exponential families. We provide explicit bounds for sample and computational complexity. Furthermore, extensive experiments support the claim that our algorithm optimizes the score effectively in various scenarios.