This paper examines the underdamped Langevin diffusion (ULD) with a strongly-convex potential composed of a finite summation of N smooth components. We propose a discretization method that is efficient and only requires O(N + d^3) gradient evaluations to achieve an ε-error in approximating the d-dimensional ULD. We also prove a lower bound of gradient complexity as O(N + d^3), which demonstrates that our method is optimal in terms of dependence on N, ε, and d. Our method is particularly effective in sampling strongly-log-concave distributions, outperforming existing gradient-based sampling algorithms in terms of gradient complexity. Experimental results on both synthetic and real-world data consistently show the superiority of our new method compared to existing ULD approaches.