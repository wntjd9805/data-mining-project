Meta-learning is a technique that can improve the accuracy of a learner when there is limited data by leveraging previous experience from similar learning tasks. However, current methods often provide unreliable estimates of uncertainty and tend to be overly confident. To address these issues, we propose a new meta-learning framework called F-PACOH. This framework treats meta-learned priors as stochastic processes and applies meta-level regularization directly in the function space. By doing so, we are able to guide the probabilistic predictions of the meta-learner towards higher uncertainty in areas where there is not enough meta-training data, resulting in more accurate uncertainty estimates. Additionally, we demonstrate how our approach can be used in sequential decision making, where having reliable uncertainty quantification is crucial. In a benchmark study on meta-learning for Bayesian Optimization, F-PACOH outperforms other meta-learners and standard baselines.