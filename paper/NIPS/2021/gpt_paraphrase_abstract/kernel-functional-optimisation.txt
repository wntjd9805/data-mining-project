Conventional approaches to kernel selection rely on parametric kernel functions or a combination of them. However, these methods often yield suboptimal outcomes due to limitations imposed by the parametric forms. In this study, we present a new approach to kernel selection by utilizing efficient Bayesian optimization. Our method aims to identify the most suitable non-parametric kernel by expressing it as a linear combination of functions sampled from a prior Gaussian Process (GP) defined by a hyperkernel. Additionally, we introduce a mechanism to ensure the positive definiteness of the Gram matrix constructed using the resulting kernels. Our experimental results, which involve GP regression and Support Vector Machine (SVM) classification tasks on both synthetic functions and real-world datasets, demonstrate the superiority of our approach over the current state-of-the-art methods.