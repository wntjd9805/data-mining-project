Covariate shift is a major challenge in developing reliable machine learning models. It refers to a situation where the input distributions of the training and test sets differ while the conditional label distributions remain the same. Despite its prevalence in real-world applications, there has been a lack of theoretical understanding in the context of modern machine learning. This study investigates the high-dimensional asymptotics of random feature regression under covariate shift and provides a precise characterization of the limiting test error, bias, and variance. The findings establish a partial order over covariate shifts, which serves as a sufficient condition for determining whether the shift will negatively or positively impact test performance. The research reveals that overparameterized models demonstrate increased resilience to covariate shift, offering one of the first theoretical explanations for this commonly observed empirical phenomenon. Additionally, the analysis uncovers a direct linear relationship between in-distribution and out-of-distribution generalization performance, thereby explaining a recent surprising observation.