Decentralized optimization is gaining popularity in distributed machine learning, but it presents challenges in terms of synchronization costs. Various techniques like non-blocking communication, quantization, and local steps have been explored to reduce communication in the decentralized setting. However, analyzing optimization in this relaxed environment often assumes global communication rounds, requiring additional synchronization. This paper focuses on decentralized optimization in the asynchronous gossip model, where communication happens randomly between nodes. Surprisingly, we demonstrate that a variant of SGD called SwarmSGD can still converge in this setting, even when non-blocking communication, quantization, and local steps are combined, and even when node data distributions and graph topology are heterogeneous. Our analysis is based on a new connection with multi-dimensional load-balancing processes. We implement this algorithm in a super-computing environment and show that it outperforms previous decentralized methods in terms of training time, and even competes with carefully-tuned large-batch SGD for certain tasks.