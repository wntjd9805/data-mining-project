We introduce a novel set of adaptive first-order techniques for solving convex minimization problems that lack Lipschitz continuity or smoothness. Instead of relying on a global norm, we consider problems that are continuous or smooth with respect to a reference Bregman function. This approach covers a wide range of problems with singular objectives that cannot be addressed by conventional first-order methods designed for Lipschitz continuous/smooth problems. Examples include Fisher markets, Poisson tomography problems, and D-optimal design. Existing order-optimal adaptive methods like UNIXGRAD or ACCELEGRAD are not applicable in this context, particularly when randomness and uncertainty are present. To bridge this gap, we propose a new method called adaptive mirror descent (ADAMIR), which aims to achieve min-max optimal rates in problems that are relatively continuous or smooth, including stochastic ones.