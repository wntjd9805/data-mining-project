Current deep hashing models often use multiple learning objectives, leading to difficulties in training and reducing their effectiveness. This study proposes a novel deep hashing model with a single learning objective. By maximizing the cosine similarity between continuous codes and their corresponding binary orthogonal codes, the model achieves both discriminative hash codes and minimal quantization error. Code balancing is achieved through a Batch Normalization layer, and multi-label classification is simplified using label smoothing. This one-loss deep hashing model eliminates the need for tuning weights of various losses. Extensive experiments demonstrate the model's high effectiveness, surpassing state-of-the-art multi-loss hashing models on three large-scale instance retrieval benchmarks. The code is available at https://github.com/kamwoh/orthohash.