This study introduces CLIP-It, a unified framework that addresses both generic and query-focused video summarization. Existing models for video summarization often lack customization options and fail to utilize language models effectively. CLIP-It utilizes a language-guided multimodal transformer that scores video frames based on their importance and correlation with user-specified queries or automatically generated captions. The model can be trained in an unsupervised manner without ground-truth supervision. CLIP-It outperforms previous approaches by a significant margin on standard video summarization datasets (TVSum and SumMe) as well as a query-focused video summarization dataset (QFVS). The method demonstrates strong generalization capabilities, particularly in the transfer setting.