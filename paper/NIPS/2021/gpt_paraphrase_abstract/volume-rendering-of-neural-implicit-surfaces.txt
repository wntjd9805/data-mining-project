Neural volume rendering has gained popularity for generating new views of a scene using limited input images. However, previous techniques used a generic density function to model the geometry, leading to noisy and low-quality reconstructions. This paper aims to improve geometry representation and reconstruction by modeling the volume density as a function of the geometry, rather than the other way around. The authors propose using Laplace's cumulative distribution function applied to a signed distance function to define the volume density function, which offers several benefits including a useful bias for learning geometry, accurate sampling of viewing rays, and efficient disentanglement of shape and appearance. The application of this new density representation resulted in high-quality geometry reconstructions and the ability to switch shape and appearance between scenes.