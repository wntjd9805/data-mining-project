The integration and transmission of information from multiple sources to multiple targets is a fundamental aspect of neural systems. Partial information decomposition (PID), a newly emerging field, offers an information-theoretic perspective on these mechanisms by identifying the synergistic, redundant, and unique contributions to the mutual information between variables. While previous studies have focused on PID for Gaussian and discrete distributions, the exploration of general continuous distributions remains unexplored. In this study, we propose a method to estimate the unique information in continuous distributions, specifically for the scenario involving one versus two variables. Our approach combines copula decompositions and variational autoencoder optimization techniques to solve the optimization problem associated with fixed bivariate marginals. We validate our method by achieving excellent agreement with known analytical results for Gaussian distributions and demonstrate its effectiveness in various neural models inspired by the brain. Furthermore, our method successfully recovers the effective connectivity of a chaotic network of rate neurons and reveals a complex trade-off between redundancy, synergy, and unique information in recurrent networks trained to solve a generalized XOR task.