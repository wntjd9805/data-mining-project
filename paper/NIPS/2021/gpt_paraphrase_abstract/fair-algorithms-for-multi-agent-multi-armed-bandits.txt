We present a new version of the multi-armed bandit problem called the multi-agent variant. This problem involves N agents and K arms, where pulling an arm generates a stochastic reward for each agent. Unlike the traditional multi-armed bandit problem, the objective is not to determine the best arm overall, as each agent may have a different perception of the best arm for themselves. Instead, the goal is to develop a fair distribution over the arms. Drawing from existing research in economics and computer science, we adopt the Nash social welfare as our fairness measure. We introduce multi-agent adaptations of three well-known multi-armed bandit algorithms and demonstrate that they achieve sublinear regret, which is now evaluated based on the lost Nash social welfare.