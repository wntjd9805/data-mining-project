Deep Learning methods often produce over-confident estimates, especially in the low data regime. While the calibration of probabilistic models is well studied, calibrating highly parameterized models in the low-data regime presents unique challenges. This study shows that deep ensembles may not improve calibration properties. In fact, standard ensembling methods combined with modern techniques like mixup regularization can result in less calibrated models. The interplay between data augmentation, ensembling, and post-processing calibration methods in leveraging deep learning with limited data is explored. While ensembling techniques improve accuracy, the calibration of deep ensembles relies on subtle trade-offs. It is found that calibration methods like temperature scaling need to be adjusted slightly and applied after the averaging process when used with deep ensembles. Simulations demonstrate that this simple strategy can significantly reduce the Expected Calibration Error (ECE) compared to standard deep ensembles in the low data regime.