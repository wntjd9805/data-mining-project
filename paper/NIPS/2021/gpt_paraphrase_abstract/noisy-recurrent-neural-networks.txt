We present a general framework for analyzing recurrent neural networks (RNNs) that are trained using noise injected into hidden states. These RNNs can be seen as discrete versions of stochastic differential equations driven by input data. By studying this framework, we are able to understand how different noise injection methods implicitly regularize the model. We discover that in the presence of small noise, this regularization leads to flatter minima, encourages more stable dynamics, and favors models with larger classification margins in classification tasks. We also identify conditions for global stability, revealing the phenomenon of stochastic stabilization where noise injection improves stability during training. Empirical evidence supports our theory, demonstrating that RNNs trained with noise injection exhibit enhanced robustness to various input perturbations.