The rise of machine learning as a service and concerns over user privacy have led to an increasing need for private inference (PI). However, existing cryptographic methods for PI have computational overheads that make them impractical. This paper proposes optimizations for PI specifically tailored to neural networks. By rethinking ReLU computations and introducing a novel truncation method, we significantly reduce the cost per ReLU operation. These optimizations result in a stochastic ReLU that is well-suited for fault-tolerant neural network inference. The proposed optimizations, called Circa, achieve up to 4.7× storage and 3× runtime improvements over baseline implementations. Additionally, when combined with recent PI optimizations, Circa provides an additional 1.8× speedup.