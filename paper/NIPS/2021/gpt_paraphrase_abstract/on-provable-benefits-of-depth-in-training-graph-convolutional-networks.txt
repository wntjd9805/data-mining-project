Graph Convolutional Networks (GCNs) often experience decreased performance with increased layer count, commonly attributed to over-smoothing. However, a disconnect exists between the theoretical understanding of over-smoothing and the practical performance of GCNs. Contrary to common belief, over-smoothing does not necessarily occur in practice. Deeper models can actually be expressive, achieve high training accuracy, and converge to the global optimum with a linear convergence rate if properly trained. Nevertheless, empirical results reveal that these deeper models do not generalize well during testing, and the theoretical understanding of this behavior remains unclear. To gain a better understanding, we analyze the generalization capability of GCNs and find that the training strategies leading to high training accuracy significantly diminish the generalization ability of GCNs. Based on these findings, we propose a decoupled structure for GCNs that separates weight matrices from feature propagation. This preserves expressive power while ensuring good generalization performance. We validate our theory through empirical evaluations on various synthetic and real-world datasets.