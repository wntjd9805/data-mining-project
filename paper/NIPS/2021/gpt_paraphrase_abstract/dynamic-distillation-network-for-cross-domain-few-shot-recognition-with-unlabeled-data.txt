Most existing few-shot learning methods use meta-learning on a large base dataset, usually from the same domain as the target dataset. However, our focus is on cross-domain few-shot learning, where there is a significant difference between the base and target domains. The problem of cross-domain few-shot recognition with unlabeled target data has not been addressed much in previous research. The STARTUP method was the first to tackle this issue using self-training, but it has limitations in using a fixed teacher pretrained on a labeled base dataset to generate soft labels for unlabeled target samples. We propose a dynamic distillation-based approach to address this problem. Our approach involves imposing consistency regularization by comparing predictions from weakly-augmented versions of unlabeled images from a teacher network with strongly augmented versions of the same images from a student network. The teacher network's parameters are updated using an exponential moving average of the student network's parameters. Our experiments demonstrate that our proposed network learns representations that can be easily adapted to the target domain, despite not being trained on target-specific classes during the pretraining phase. Our model outperforms the current state-of-the-art method by 4.4% for 1-shot and 3.6% for 5-shot classification in the BSCD-FSL benchmark, and also achieves competitive performance in traditional in-domain few-shot learning tasks. The code for our model is available at: [URL].