We explore the idea of fairly distributing the cost of exploration in learning problems among different groups. To achieve this, we apply the Nash bargaining solution to the context of multi-armed bandits. In this approach, each time step is associated with a specific group from a finite set of groups in a "grouped" bandit. The utility gained by a group is measured by the reduction in their regret compared to what they would have incurred individually. We develop policies that result in the Nash bargaining solution, considering all possible incremental utilities under any policy. Our findings reveal that these policies strike a balance between fairness and regret, as the "price of fairness" is limited. Conversely, regret optimal policies can be arbitrarily unfair under certain conditions. To support our theoretical development, we present a case study on contextual bandits for warfarin dosing, where we examine the exploration costs across different races and age groups.