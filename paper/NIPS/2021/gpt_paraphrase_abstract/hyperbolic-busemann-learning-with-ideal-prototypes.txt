Hyperbolic space has gained popularity for representing various types of data, such as tree-like structures, text, and graphs. Previous studies have successfully applied deep learning with prototypes in Euclidean and hyperspherical spaces, and more recently, hyperbolic prototypes have been proposed for classification tasks. These hyperbolic prototypes allow for effective learning in low-dimensional output spaces and can leverage hierarchical relationships between classes. However, existing approaches require prior knowledge of class labels to position the hyperbolic prototypes. In this study, we introduce a new approach called Hyperbolic Busemann Learning, which overcomes the need for label information by positioning prototypes on the ideal boundary of the Poincar√© ball. To measure the proximity to these ideal prototypes, we introduce the penalized Busemann loss. We provide theoretical justification for using ideal prototypes and the proposed loss by demonstrating its equivalence to logistic regression in one-dimensional cases. Through empirical evaluation, we demonstrate that our approach offers a natural interpretation of classification confidence and outperforms recent hyperspherical and hyperbolic prototype methods.