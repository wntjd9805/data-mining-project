Cross-modal matching, a crucial aspect of tasks like cross-modal retrieval and vision-and-language understanding, involves establishing correspondence between different modalities. While numerous methods have been proposed in recent years, they often assume that the multimodal training data are accurately aligned. However, in practice, this assumption is costly or even impossible to fulfill. Hence, we introduce a new direction in cross-modal matching, termed noisy correspondence, which deals with the mismatch of paired samples. To address this problem, we propose a novel method called Noisy Correspondence Rectiﬁer (NCR). NCR separates the data into clean and noisy partitions using the memorization effect of neural networks and rectiﬁes the correspondence through an adaptive prediction model using co-teaching. We evaluate the effectiveness of our approach through experiments on image-text matching using datasets such as Flickr30K, MS-COCO, and Conceptual Captions, and demonstrate its success. The code is available at www.pengxi.me.