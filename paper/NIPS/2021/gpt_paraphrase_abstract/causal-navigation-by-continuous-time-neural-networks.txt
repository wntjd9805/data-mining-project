Imitation learning in rich, realistic environments is often limited by traditional neural models and their inability to generalize to domain shifts. This paper introduces a theoretical and experimental framework for learning causal representations using continuous-time neural networks, which outperform their discrete-time counterparts. The proposed method is evaluated in the visual-control learning of drones across various complex tasks. Results show that causal continuous-time deep models excel in navigation tasks where recurrent models struggle. These models learn intricate causal control representations from raw visual inputs and can solve a wide range of tasks through imitation learning.