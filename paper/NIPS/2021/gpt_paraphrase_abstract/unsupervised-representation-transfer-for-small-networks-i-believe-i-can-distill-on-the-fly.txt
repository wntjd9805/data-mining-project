We propose a new approach to unsupervised learning for small networks that combines self-supervised representation learning and knowledge distillation in a single training phase. Our method involves training a teacher model to produce consistent cluster assignments for different views of the same image, while simultaneously training a student model to mimic the teacher's predictions. To facilitate effective knowledge transfer, we use a domain classifier to guide the student's training based on discriminative features that are invariant to the shift in representation space between the teacher and student. Additionally, we introduce a network-driven multi-view generation paradigm to capture rich feature information within the network itself. Our experiments demonstrate that our student models outperform state-of-the-art offline distilled networks, even when using stronger self-supervised teachers and top-performing self-supervised models. Notably, our ResNet-18 model, trained with a ResNet-50 teacher, achieves a 68.3% ImageNet Top-1 accuracy on frozen feature linear evaluation, which is only 1.5% lower than the supervised baseline.