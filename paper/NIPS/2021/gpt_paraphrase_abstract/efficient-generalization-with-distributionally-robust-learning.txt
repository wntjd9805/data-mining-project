Distributionally robust learning (DRL) has gained popularity as a method to enhance the generalization of machine learning models. However, solving the minimax formulations associated with DRL is challenging. To address this, we propose a new stochastic gradient descent algorithm that efficiently solves the DRL formulation. Our approach applies gradient descent to the outer minimization formulation and estimates the gradient of the inner maximization using a sample average approximation. In each iteration, we sample a subset of the data without replacement, gradually increasing the subset size to ensure convergence. We rigorously prove convergence to a near-optimal solution under standard regularity assumptions. Additionally, for strongly convex losses, our algorithm achieves the best known rate of convergence up to a known threshold. Empirical results demonstrate the significant advantages of our approach compared to previous methods in improving model generalization.