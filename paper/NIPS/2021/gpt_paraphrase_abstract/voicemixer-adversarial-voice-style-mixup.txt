Despite recent advancements in voice conversion, there is still a noticeable disparity between the converted voice and the desired target voice. This gap largely stems from the inadequate separation of content and voice style in the source speech. Insufficient decomposition results in the converted speech retaining certain aspects of the source speech style or losing important content information. To address this issue, we introduce VoiceMixer, a novel approach that effectively decomposes and transfers voice style using an information bottleneck and adversarial feedback. Through self-supervised representation learning, our proposed information bottleneck can separate content and style while minimizing the loss of content information. Additionally, by decomposing the discriminator into content and style discriminators with self-supervision, our model achieves better generalization to the voice style of the converted speech. Experimental results demonstrate the superiority of our model in disentanglement and transfer performance, while preserving content information and improving audio quality.