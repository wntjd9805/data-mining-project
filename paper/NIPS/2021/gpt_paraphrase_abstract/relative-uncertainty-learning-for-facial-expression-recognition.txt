The credibility of facial expression recognition (FER) results is often compromised by inherent noises and uncertainties, such as ambiguous facial expressions and inconsistent labels. To address this issue and improve performance with noisy data, we propose a novel uncertainty learning method called Relative Uncertainty Learning (RUL). Unlike traditional approaches that assume Gaussian uncertainty distributions, RUL introduces an additional branch to learn uncertainty based on the relative difficulty of samples using feature mixup. We use uncertainties as weights to combine facial features and introduce an add-up loss to encourage uncertainty learning. RUL is easy to implement and does not require significant computational resources. Extensive experiments demonstrate that RUL surpasses existing FER uncertainty learning methods in both real-world and synthetic noisy FER datasets. Additionally, RUL performs well on other datasets such as CIFAR and Tiny ImageNet. The code for RUL is available at https://github.com/zyh-uaiaaaa/Relative-Uncertainty-Learning.