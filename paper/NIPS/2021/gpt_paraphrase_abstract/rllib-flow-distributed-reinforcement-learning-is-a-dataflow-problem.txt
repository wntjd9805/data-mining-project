Researchers and practitioners in the field of reinforcement learning (RL) often utilize parallel computation to develop new algorithms and systems. This paper re-evaluates the challenges of distributed RL by considering it as a distributed dataflow problem. By adopting this perspective, the authors demonstrate that RL can be implemented in a highly composable and efficient manner. They introduce RLlib Flow, a hybrid actor-dataflow programming model for distributed RL, and validate its practicality by adapting the full suite of algorithms in RLlib, a widely used distributed RL library. RLlib Flow offers significant reductions in code size (2-9Ã—) in real production scenarios and enables users to compose multi-agent algorithms that were previously impossible. The open-source code for RLlib Flow can be accessed at https://github.com/ray-project/ray/tree/master/rllib.