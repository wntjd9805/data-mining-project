This paper introduces a group-theoretic approach to understanding and evaluating visual representations. It argues that existing self-supervised learning methods only disentangle simple features, such as rotation and colorization, and fail to modularize more complex semantic factors. To address this limitation, the paper proposes an iterative SSL algorithm called IP-IRM, which effectively grounds abstract semantics and their corresponding group actions into concrete contrastive learning. IP-IRM partitions training samples into subsets representing entangled group elements and minimizes a subset-invariant contrastive loss to disentangle these elements. The paper proves that IP-IRM converges to a fully disentangled representation and demonstrates its effectiveness on various benchmarks. The code for IP-IRM is available at https://github.com/Wangt-CN/IP-IRM.