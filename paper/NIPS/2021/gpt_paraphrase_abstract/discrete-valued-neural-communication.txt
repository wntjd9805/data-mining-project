Deep learning has evolved from fully connected architectures to structured models with components such as transformers, modular architectures, and graph neural nets. These structured models have a bottleneck in communication among components, typically achieved through restricted connectivity and attention. This study aims to further tighten this bottleneck by introducing discreteness in the representations transmitted between components. The researchers hypothesize that this constraint serves as an effective inductive bias. Empirical evidence and theoretical results support the benefits of discretization in non-structured architectures, including increased noise robustness and reduced dimensionality. The study builds upon an existing technique for discretization and explores multi-headed discretization with shared codebooks as the output of each architectural component. The motivation behind this approach is the resemblance to human language, where communication occurs through discrete symbols. The experiments demonstrate that discrete-valued neural communication (DVNC) significantly enhances systematic generalization in various architectures, such as transformers, modular architectures, and graph neural networks. Additionally, the DVNC method proves to be robust to hyperparameter choices, making it practical for real-world applications.