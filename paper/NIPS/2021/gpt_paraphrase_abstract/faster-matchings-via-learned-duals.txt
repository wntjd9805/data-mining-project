Recent research has explored the potential of combining machine-learned predictions with algorithms to improve worst case lower bounds. This approach has been successful in the development of competitive online algorithms, but little attention has been given to enhancing algorithm running times using predictions. We take a preliminary step in this direction by combining machine-learned predictions with "warm-starting" primal-dual algorithms. We focus on weighted bipartite matching and its generalization to b-matching, which are important problems in combinatorial optimization. We identify three challenges when using learned dual variables in a primal-dual algorithm. Firstly, predicted duals may be infeasible, so we present an algorithm that efficiently maps predicted infeasible duals to nearby feasible solutions. Secondly, even if the duals are feasible, they may not be optimal, so we demonstrate that they can still be used to quickly find an optimal solution. Lastly, in order for these predictions to be useful, they must be learnable. We show that learning duals for matching has low sample complexity. Our theoretical findings are validated through experiments on both real and synthetic data. Consequently, we provide a rigorous, practical, and empirically effective method for computing bipartite matchings.