Neural networks and Gaussian processes have their own strengths and weaknesses. Understanding their relationship can help improve both methods. This study establishes a connection between the forward passes of neural networks and deep sparse Gaussian process models. By analyzing the interaction between activation functions and kernels, we interpret activation functions as interdomain inducing features. This leads to models that can be viewed as neural networks with better uncertainty prediction or deep Gaussian processes with higher prediction accuracy. Experimental results on regression and classification datasets support these claims.