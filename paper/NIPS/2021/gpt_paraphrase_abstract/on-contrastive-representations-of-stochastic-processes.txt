Learning representations of stochastic processes is a growing problem in machine learning. Current methods rely on exact reconstruction of observations, but this becomes challenging with high-dimensional observations or complex noise distributions. To overcome this, we introduce a unified framework called CRESP (Contrastive Representations of Stochastic Processes) that eliminates the need for exact reconstruction. We explore various applications for stochastic process representations and propose methods tailored to each application. Through empirical analysis, we demonstrate that our methods effectively learn representations of periodic functions, 3D objects, and dynamical processes. Moreover, our approaches handle noisy high-dimensional observations better than traditional methods and exhibit transferability to different downstream tasks.