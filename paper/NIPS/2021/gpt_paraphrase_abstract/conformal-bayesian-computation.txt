We present a scalable method for generating Bayesian predictive intervals that are both conformal and have finite sample calibration guarantees. Bayesian posterior predictive distributions, which represent subjective beliefs about outcomes given predictors, are used to assess model accuracy. However, these predictive intervals may have poor empirical coverage when the model is misspecified. In contrast, conformal inference provides finite sample frequentist guarantees on predictive confidence intervals without relying on model fidelity. By using 'add-one-in' importance sampling, we efficiently obtain conformal Bayesian predictive intervals from re-weighted posterior samples of model parameters. This approach differs from existing conformal methods that require expensive model re-fitting or data-splitting to achieve computational efficiency. We demonstrate the effectiveness of our method on various examples, including hierarchical models and partially exchangeable settings.