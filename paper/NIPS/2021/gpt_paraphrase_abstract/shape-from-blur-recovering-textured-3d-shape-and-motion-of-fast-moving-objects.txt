We propose a new approach to reconstructing the 3D shape, texture, and motion of an object from a single motion-blurred image. Unlike previous methods that only address deblurring in the 2D image domain, our approach accurately models all object properties in the 3D domain, resulting in improved image decomposition and sharper deblurring. We represent the appearance of a motion-blurred object as a combination of the background and a 3D object with constant translation and rotation. By minimizing a loss on reconstructing the input image using differentiable rendering and suitable regularizers, we can estimate the textured 3D mesh of the blurred object with high fidelity. Our method outperforms other approaches on benchmarks for deblurring fast moving objects. Qualitative results demonstrate that our reconstructed 3D mesh produces high-quality temporal super-resolution and new views of the deblurred object.