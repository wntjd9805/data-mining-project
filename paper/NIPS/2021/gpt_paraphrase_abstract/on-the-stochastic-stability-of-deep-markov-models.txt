Deep Markov models (DMM) are advanced generative models that offer scalable and expressive solutions for representation, learning, and inference problems. However, the stochastic stability of these models has not been thoroughly explored. This paper aims to address this gap by providing sufficient conditions for the stochastic stability of DMMs in the context of dynamical systems. We propose a stability analysis method that relies on the contraction of probabilistic maps represented by deep neural networks. We also investigate the impact of neural network weights' spectral properties and activation functions on the stability and dynamic behavior of DMMs with Gaussian distributions. Based on our findings, we propose practical methods for designing constrained DMMs that guarantee stability. We validate our theoretical results through numerical experiments that incorporate the proposed stability constraints.