Neural networks have excelled in tasks related to perception but struggle with tasks that involve both perception and higher-level reasoning. Customized approaches designed for specific tasks have typically performed better, but they are often inflexible and require significant modifications. In this study, we propose a more general neural network approach to dynamic visual reasoning problems that outperforms task-specific approaches in three different domains. Our method combines learned object-centric representations, self-attention, and self-supervised dynamics learning, and all three components are necessary for strong performance. This suggests that we can achieve both flexibility and performance in spatio-temporal or causal-style reasoning tasks by incorporating the right soft biases and learning objectives into neural networks.