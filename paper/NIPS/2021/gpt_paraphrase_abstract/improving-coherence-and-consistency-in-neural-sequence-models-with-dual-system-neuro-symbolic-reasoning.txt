Human reasoning can be seen as a combination of two systems: the intuitive and associative system (System 1) and the deliberative and logical system (System 2). Neural sequence models, which have been successful in performing complex tasks, resemble System 1 as they are fast and learn patterns from data, but they often lack consistency and coherence. This study aims to enhance existing System 1-like sequence models by incorporating logical reasoning inspired by System 2, without the need for training. The proposed method involves examining candidate generations from a neural sequence model for logical consistency using a symbolic reasoning module, which can accept or reject the generations. Neural inference is used to bridge the gap between the neural System 1 and the logical System 2. Results from storytelling and instruction-following tasks demonstrate that this approach can improve the coherence and accuracy of neural-based generations.