Learning how to execute algorithms is a well-studied problem. Previous research has shown that having access to the intermediate steps of a program or algorithm is crucial for systematic generalization in graph algorithms. However, in many reasoning tasks, we only have access to input and output examples, making algorithmic-style reasoning challenging. Inspired by the success of pre-training in Natural Language Processing (NLP) and Computer Vision, we aim to explore how we can transfer algorithmic reasoning knowledge. Specifically, we investigate the use of algorithms with known execution traces to solve similar tasks without such traces. We focus on two main types of graph algorithms: parallel algorithms (e.g., breadth-first search and Bellman-Ford) and sequential greedy algorithms (e.g., Prim and Dijkstra). Notably, due to the fundamental differences between algorithmic reasoning knowledge and feature extractors used in Computer Vision or NLP, standard transfer techniques may not be sufficient for systematic generalization. To test this hypothesis, we create a dataset containing nine algorithms and three graph types. Through empirical validation, we demonstrate that multi-task learning can be employed to successfully transfer algorithmic reasoning knowledge.