Humans have the ability to reason and recognize objects based on contextual clues, even if they have never encountered them before. Machine learning systems, on the other hand, often rely on spurious correlations in the training data, which limits their ability to generalize. In order to address this issue and still use contextual information for classification, we propose a new method called ProtoProp. This method involves learning prototypical representations of objects and their attributes independently, and then combining them through a compositional graph to create prototypes for novel attribute-object combinations. Our approach does not rely on external data and achieves superior results in compositional zero-shot learning tasks compared to existing methods. We evaluate our approach on various datasets and demonstrate the significance of each component of our method. The code for our method is available on GitHub.