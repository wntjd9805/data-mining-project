We examine the Online Lazy Gradient Descent method for optimization on a strongly convex domain with adversarial opponents. Previously, this algorithm was proven to achieve a regret of O(sqrt(N)) against opponents. However, we demonstrate that it possesses universality by also achieving an expected regret of O(log N) against i.i.d opponents. This is an improvement over the more intricate meta-algorithm proposed by Huang et al [20], which only achieves bounds of O(N log N) and O(log N). Furthermore, we establish that in strongly convex domains, the bounds for pseudo-regret and expected regret are equivalent.