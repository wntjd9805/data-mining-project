This study focuses on Imitation Learning from Observations alone (ILFO), where the learner is provided with expert demonstrations consisting solely of states visited by an expert, without knowledge of the expert's actions. To address this problem, we propose MobILE, a model-based framework that is proven to be efficient in solving ILFO. MobILE balances strategic exploration and imitation by incorporating the concept of optimism in the face of uncertainty into the distribution matching imitation learning (IL) framework. We provide a comprehensive analysis of MobILE and demonstrate its strong performance guarantees for certain well-known notions of structural complexity in MDP dynamics. Additionally, we establish that the ILFO problem is more challenging than the standard IL problem by presenting an exponential difference in sample complexity between the two. To validate our findings, we conduct experimental simulations on benchmark OpenAI Gym tasks, which confirm the effectiveness of MobILE. The code for implementing the MobILE framework is available at https://github.com/rahulkidambi/MobILE-NeurIPS2021.