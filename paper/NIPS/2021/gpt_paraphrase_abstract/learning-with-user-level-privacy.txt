We present algorithms for learning tasks that adhere to user-level differential privacy constraints. User-level DP ensures the privacy of a user's entire contribution rather than just individual samples, offering more realistic protection against information leaks. Our research demonstrates that as users provide more samples, the privacy cost decreases at a rate of O(1/m) for high-dimensional mean estimation, empirical risk minimization with smooth losses, stochastic convex optimization, and learning hypothesis classes with finite metric entropy. On the other hand, increasing the number of users, n, leads to a faster decrease in privacy cost at a rate of O(1/n). Additionally, we provide lower bounds that support the minimax optimality of our algorithms for mean estimation and stochastic convex optimization. Our algorithms employ innovative techniques for private mean estimation in any dimension, with error scaling based on the concentration radius Ï„ of the distribution rather than the entire range.