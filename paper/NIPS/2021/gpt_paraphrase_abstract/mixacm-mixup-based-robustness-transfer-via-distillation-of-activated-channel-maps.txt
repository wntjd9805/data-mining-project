Adversarial training is a commonly used defense mechanism against small, imperceptible changes in natural inputs that can deceive deep neural networks. However, this approach requires a significant amount of data, larger models, and additional computing resources, while also degrading the model's generalization performance. This study aims to find a more efficient way to achieve robustness by exploring knowledge transfer. The researchers demonstrate the transferability of robustness from an adversarially trained teacher model to a student model using mixup augmentation. They also propose a new method called Mixup-Based Activated Channel Maps (MixACM) Transfer, which transfers robustness without relying on expensive adversarial perturbations. Experimental results on multiple datasets and learning scenarios confirm that their approach successfully transfers robustness and improves generalization on natural images.