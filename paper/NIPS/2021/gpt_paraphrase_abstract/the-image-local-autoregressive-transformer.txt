AR models empowered by transformers have shown comparable or better performance than GANs for generating whole images. However, when applied to editing local image regions, these models face issues such as missing global information, slow inference speed, and information leakage. To overcome these limitations, we propose a new model called iLAT (imageLocal Autoregressive Transformer) that enhances locally guided image synthesis. iLAT uses a novel local autoregressive (LA) transformer with attention mask and convolution mechanisms to learn local discrete representations. This enables iLAT to efficiently synthesize local image regions based on key guidance information. We evaluate iLAT on various locally guided image syntheses, including pose-guided person image synthesis and face editing. Both quantitative and qualitative results demonstrate the effectiveness of our model.