Quantile regret bounds, such as those achieved by NormalHedge and similar methods, relax the objective of competing against the best individual expert to competing against a majority of experts on adversarial data. The semi-adversarial paradigm offers an alternative relaxation by considering data that may not be fully adversarial or stochastic. In this study, we propose novel root-logarithmic regularizers for FTRL that achieve the minimax optimal regret in both paradigms. These regularizers can be interpreted as variants of NormalHedge. We extend existing regret bounds to uncountable expert classes with arbitrary priors and provide the first lower bounds for quantile regret on finite expert classes. Additionally, we introduce an adaptively minimax optimal algorithm for the semi-adversarial paradigm, which adapts faster to the true unknown constraint and improves regret bounds compared to existing methods.