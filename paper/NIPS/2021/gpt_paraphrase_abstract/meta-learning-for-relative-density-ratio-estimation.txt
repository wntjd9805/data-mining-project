The density-ratio, a crucial factor in machine learning, represents the ratio of two probability densities. A relative density-ratio, an extended version of the density-ratio, has gained significant attention for its stability and applicability in outlier detection and dataset comparison. However, current methods for estimating the relative density-ratio require a large number of instances from both densities, which is often impractical. To address this limitation, we propose a meta-learning approach for relative density-ratio estimation. Our method leverages knowledge from related datasets to estimate the relative density-ratio using a few instances. We achieve this by employing neural networks to extract information from the datasets and generate appropriate instance embeddings for relative density-ratio estimation. We model the relative density-ratio using a linear model on the embedded space, allowing us to obtain a closed-form solution for its global optimum. This closed-form solution enables fast and efficient adaptation to a few instances, and its differentiability allows us to train our model to explicitly minimize the expected test error for relative density-ratio estimation after adaptation. Through empirical evaluations on three problems - relative density-ratio estimation, dataset comparison, and outlier detection - we demonstrate the effectiveness of our proposed method.