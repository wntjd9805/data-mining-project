This study addresses the threat of query-based black-box attacks on machine learning models in various real-world applications. The researchers propose a lightweight defense method called Random Noise Defense (RND), which involves adding proper Gaussian noise to each query. The effectiveness of RND against query-based black-box attacks and adaptive attacks is analyzed theoretically. The results demonstrate that the defense performance of RND depends on the ratio between the noise introduced by RND and the noise added by attackers for gradient estimation or local search. A higher magnitude ratio leads to stronger defense performance and is crucial for mitigating adaptive attacks. Building on this analysis, the researchers propose combining RND with Gaussian augmentation Fine-tuning (RND-GF) to achieve a better balance between defense performance and clean accuracy. RND can also be combined with other existing defense methods, such as adversarial training (AT), to further enhance adversarial robustness. Extensive experiments on CIFAR-10 and ImageNet datasets validate the theoretical findings and demonstrate the effectiveness of RND and RND-GF.