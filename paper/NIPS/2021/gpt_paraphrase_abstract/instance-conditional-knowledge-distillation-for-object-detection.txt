Knowledge distillation has been successful in classification tasks but remains challenging in detection tasks. This paper proposes a conditional distillation framework to distill knowledge that benefits both classification and localization for each instance. The framework includes a learnable conditional decoding module that retrieves information based on each target instance as a query. The condition information is encoded as a query and the teacher's representations are used as keys. The attention between the query and key measures the contribution of different features, guided by a localization-recognition-sensitive auxiliary task. Extensive experiments demonstrate the effectiveness of the proposed method, with impressive improvements observed in various settings. For example, the method improves RetinaNet with a ResNet-50 backbone from 37.4 to 40.7 mAP (+3.3) under a 1× schedule, surpassing even the teacher model (40.4 mAP) with a ResNet-101 backbone under a 3× schedule. The code for the proposed method is available at https://github.com/megvii-research/ICD.