Symbolic reasoning is a crucial aspect of human intelligence in areas like mathematics and logic. Machine learning algorithms face challenges in learning to solve symbolic problems, as existing models rely on human solutions or hand-engineered features that are not easily applicable to new domains. To address this, we propose treating symbolic domains as simple environments where unstructured text represents states and actions, and binary rewards indicate problem-solving success. Although this setup allows for easy specification of new domains, it poses difficulties in search and planning. We introduce five environments inspired by the Mathematics Common Core Curriculum and find that current Reinforcement Learning baselines perform poorly. To overcome these limitations, we present a novel learning algorithm called Contrastive Policy Learning (ConPoLe). ConPoLe optimizes the InfoNCE loss, which provides a lower bound on the mutual information between the current state and the next states leading to a solution. ConPoLe successfully solves all four domains and learns problem representations that accurately predict problem categories in a real mathematics curriculum. Our findings suggest new avenues for reinforcement learning in symbolic domains and potential applications in mathematics education.