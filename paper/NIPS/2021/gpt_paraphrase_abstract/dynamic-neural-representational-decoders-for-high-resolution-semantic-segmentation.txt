Semantic segmentation requires per-pixel prediction for an image. However, downsampling operations in the CNN backbone often lead to a severe reduction in the output resolution of segmentation networks. To recover the spatial resolution, previous methods have used upsampling decoders. In this study, we introduce a new decoder called the dynamic neural representational decoder (NRD), which is simple yet highly efficient. We represent local patches of semantic labels with compact neural networks, leveraging the smoothness prior in the semantic label space. These neural representations are dynamically generated and conditioned on the encoder network outputs. By efficiently decoding the desired semantic labels from these neural representations, we achieve high-resolution semantic segmentation predictions. Our proposed decoder outperforms DeeplabV3+'s decoder with only about 30% computational complexity and achieves competitive performance compared to methods using dilated encoders with only approximately 15% computational costs. Experimental results on the Cityscapes, ADE20K, and PASCAL Context datasets demonstrate the effectiveness and efficiency of our approach.