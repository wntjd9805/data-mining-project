Recent years have seen a rise in the popularity of neural implicit representations in 3D reconstruction due to their flexibility and expressiveness. However, these representations suffer from slow inference times and require careful initialization. In this study, we propose a differentiable point-to-mesh layer that leverages a differentiable formulation of Poisson Surface Reconstruction (PSR) to enable fast GPU-accelerated solutions for the indicator function using an oriented point cloud. This differentiable PSR layer allows us to efficiently bridge the explicit 3D point representation with the 3D mesh through the implicit indicator field, enabling end-to-end optimization of surface reconstruction metrics like Chamfer distance. This duality between points and meshes allows us to represent shapes as oriented point clouds, which are lightweight, expressive, and easier to interpret compared to neural implicit representations. Our Shape-As-Points (SAP) model outperforms neural implicit representations in terms of interpretability, lightweightness, and inference time acceleration by an order of magnitude. Additionally, SAP produces topology-agnostic, watertight manifold surfaces, unlike other explicit representations such as points, patches, and meshes. We demonstrate the effectiveness of SAP in surface reconstruction tasks involving unoriented point clouds and learning-based reconstruction.