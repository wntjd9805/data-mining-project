Recently, researchers have focused on compressing Generative Adversarial Networks (GANs) to reduce computational overhead and memory usage on edge devices with limited resources. However, most existing work in GAN compression only addresses compressing the generator, ignoring the discriminator. In this study, we propose a new compression scheme called GCC, which considers both the generator and discriminator. Within GCC, a selective activation discriminator is developed to automatically activate convolutional channels based on local and global constraints, maintaining equilibrium with the lightweight generator and preventing mode collapse. The original generator and discriminator are also optimized to serve as teacher models, progressively refining the pruned generator and selective activation discriminator. Furthermore, an online collaborative distillation scheme is introduced to leverage the intermediate features of the teacher models, enhancing the performance of the lightweight generator. Extensive experiments on various GAN-based generation tasks demonstrate the effectiveness and generalization of GCC. In image translation tasks, GCC achieves an 80% reduction in computational costs while maintaining comparable performance. The code and models for GCC are available at: [GitHub link].