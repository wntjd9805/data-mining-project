Machine-based speech quality assessment is a difficult task, especially in real-world scenarios where clean reference data is not available. Objective methods that rely on clean references have been commonly used, but they are ineffective in these situations. Non-intrusive methods that train neural networks to predict scores have gained attention, but they have limitations such as lack of robustness and reliance on labeled data. To address these challenges, we propose a new approach inspired by human ability to assess speech quality even with non-matching content. Our framework predicts a subjective relative quality score for a given speech signal compared to any provided reference, without using subjective data. We demonstrate that neural networks trained using our framework produce scores that correlate well with subjective mean opinion scores (MOS) and are competitive with existing methods. Additionally, our method allows for embedding quality-related information in neural networks, benefiting downstream tasks like speech enhancement.