We present a method called Shared Independent Component Analysis (ShICA) for identifying common components in multiple datasets or views. ShICA models each view as a linear transformation of shared independent components with additive Gaussian noise. We demonstrate that this model is identifiable when the components are either non-Gaussian or have diverse noise variances. We also show that Multiset Canonical Correlation Analysis (MultisetCCA) can recover the correct unmixing matrices in some cases, but it fails in the presence of sampling noise. To address this, we propose a new approach called ShICA-J, which combines MultisetCCA with joint diagonalization. Simulations indicate that ShICA-J achieves improved results and is computationally efficient. Additionally, we propose ShICA-ML, a maximum-likelihood method that leverages the non-Gaussianity of the components for more accurate estimation at a higher computational cost. ShICA also offers a principled method for estimating shared components. Empirical evidence from fMRI and MEG datasets demonstrates that ShICA outperforms alternative methods in accurately estimating the components.