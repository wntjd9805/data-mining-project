Graph Similarity Computation (GSC) is crucial for various graph applications like retrieval, plagiarism/anomaly detection, etc. However, the exact computation of graph similarity, such as Graph Edit Distance (GED), is a challenging problem that cannot be solved efficiently for large graphs. In recent years, graph neural network (GNN) based inexact methods have been developed to tackle this issue. These methods focus on designing dense interaction and feature fusion at the early stage to capture subtle differences between graphs. However, this approach involves a trade-off between speed and accuracy. In this paper, we propose a novel early-fusion approach for Slow Learning of graph similarity. Our approach involves designing a co-attention-based feature fusion network on multilevel GNN features. Additionally, to improve speed without sacrificing much accuracy, we introduce an efficient GSC solution by distilling knowledge from the slow early-fusion model to a student model for Fast Inference. This student model allows for offline collection of individual graph embeddings, significantly speeding up inference time. To address knowledge transfer instability, we decompose the dynamic joint embedding into static pseudo individual embeddings for precise teacher-student alignment. Experimental analysis on real-world datasets demonstrates the superiority of our approach in terms of both accuracy and efficiency. Notably, our method achieves more than a 10x speedup compared to prior art on the benchmark AIDS data.