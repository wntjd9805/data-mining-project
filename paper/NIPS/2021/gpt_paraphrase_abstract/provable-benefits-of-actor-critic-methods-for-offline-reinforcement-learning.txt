We propose a new offline actor-critic algorithm that incorporates the pessimism principle, resulting in several advantages compared to current methods. The algorithm is applicable in a more general setting than the low-rank MDP model and is computationally feasible. We provide an upper bound on the suboptimality gap of the policy produced by the algorithm, which depends on the data coverage of any comparator policy. This guarantee is complemented by a matching minimax lower bound.