We present ParK, an innovative solver for kernel ridge regression that achieves a reduction in space and time complexity while preserving statistical accuracy. Our approach combines partitioning, random projections, and iterative optimization. By constructing partitions in the feature space instead of the input space, we enhance orthogonality among local estimators, effectively controlling important factors such as local effective dimension and bias. We analyze the tradeoff between statistical accuracy and computational efficiency and validate our method through numerical experiments on large-scale datasets.