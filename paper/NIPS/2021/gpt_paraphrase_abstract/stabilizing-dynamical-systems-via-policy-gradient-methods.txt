This paper introduces a straightforward algorithm for stabilizing fully observed dynamical systems without the need for a known control system model. While model-free methods have gained popularity for their simplicity and flexibility, the specific area of stabilization through direct policy search has been largely overlooked. The algorithm presented in this paper solves a series of discounted LQR problems with gradually increasing discount factors. The authors provide proof that this method efficiently retrieves a stabilizing controller for both linear systems and smooth, nonlinear systems within a certain range of their equilibrium points. Unlike previous approaches, this algorithm does not require a predetermined stabilizing control policy. The effectiveness of this approach is empirically evaluated using common control benchmarks.