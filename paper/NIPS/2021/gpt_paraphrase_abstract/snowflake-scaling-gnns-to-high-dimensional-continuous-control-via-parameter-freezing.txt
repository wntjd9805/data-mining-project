Recent studies have demonstrated that graph neural networks (GNNs) can effectively learn locomotion control policies, comparable to those learned by multi-layer perceptrons (MLPs), with improved transfer and multi-task capabilities. However, these findings have been limited to small agents, as the performance of GNNs declines rapidly as the number of sensors and actuators increases. GNNs are particularly attractive for supervised learning tasks due to their ability to handle large graphs, but this advantage has not yet been realized in the context of locomotion control. We identify that the poor scaling of GNNs is a consequence of unstable policy updates, resulting from overfitting in certain areas of the network during training. To address this issue, we propose SNOWFLAKE, a training method for GNNs in high-dimensional continuous control, which involves freezing parameters in specific parts of the network. SNOWFLAKE significantly enhances the performance of GNNs in locomotion control for large agents, matching the performance of MLPs while offering superior transfer properties.