Compositional Design of Environments (CoDE) is a method that tackles the challenge of training deep reinforcement learning (RL) agents to solve complex, compositional tasks. These tasks involve completing interdependent sub-tasks represented as a dependency graph. RL agents struggle with such tasks due to long time horizons and sparse rewards. CoDE addresses this problem by training a Generator agent to build a series of compositional tasks based on the RL agent's skill level. This automatic curriculum allows the RL agent to learn more complex tasks and improves its performance on weak areas. CoDE also enhances the agent's ability to generalize to unseen tasks. We propose a new algorithm that overcomes the limitations of current environment generation techniques. Our approach is evaluated on various compositional tasks, including web page navigation. We introduce two benchmark frameworks, compositional MiniGrid and gMiniWoB, for generating compositional tasks. CoDE achieves a 4x higher success rate compared to the strongest baseline and demonstrates strong performance on real websites with 3500 primitive tasks.