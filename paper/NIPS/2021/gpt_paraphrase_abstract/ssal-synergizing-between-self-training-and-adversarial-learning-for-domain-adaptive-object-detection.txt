We investigate the adaptation of object detectors to new domains that exhibit significant variations in object appearance, viewpoints, and backgrounds. Current methods align domains using either image or instance-level feature alignment in an adversarial manner. However, this approach often fails to properly align classes due to unwanted background interference. To address this issue, a common solution is to use high confidence predictions on unlabeled data as pseudo labels to promote class-level alignment. However, these high confidence predictions are often unreliable due to poor calibration under domain shift. In this study, we propose using the model's predictive uncertainty to balance adversarial feature alignment and class-level alignment. Specifically, we measure predictive uncertainty for class assignments and bounding box predictions. We use predictions with low uncertainty to generate pseudo labels for self-supervision, while predictions with higher uncertainty are used to generate tiles for an adversarial feature alignment stage. This combination of tiling around uncertain object regions and generating pseudo labels from highly certain object regions allows us to capture both image and instance-level context during the model adaptation process. We conducted extensive experiments covering various domain shift scenarios, and our approach outperformed existing state-of-the-art methods with noticeable improvements.