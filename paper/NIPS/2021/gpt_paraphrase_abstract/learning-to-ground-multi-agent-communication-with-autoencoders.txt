Effective communication among agents necessitates the establishment of a shared language, known as a lingua franca. This language can be developed through a consensus-building process, although it may take numerous generations of trial and error. Alternatively, the environment can provide the lingua franca, with agents grounding their language in representations of the observed world. Our research introduces a straightforward method to ground language in learned representations, thereby facilitating decentralized multi-agent communication and coordination. We demonstrate that a commonly used representation learning algorithm, autoencoding, is capable of establishing a grounded common language. As agents transmit these representations, they acquire the ability to comprehend and respond to each other's statements, resulting in unexpectedly robust performance in various multi-agent communication scenarios.