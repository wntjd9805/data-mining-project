Gradient-based methods have been successful in training neural networks, despite the non-convex nature of the optimization objectives. However, the lack of generalizability across different problem setups has been a limitation in existing studies on provable guarantees for gradient descent-trained neural networks. To overcome this, we propose a unified non-convex optimization framework. We introduce the concepts of proxy convexity and proxy Polyak-Lojasiewicz (PL) inequalities, which hold when the original objective function leads to a proxy objective function implicitly minimized by gradient methods. Our analysis demonstrates that stochastic gradient descent (SGD) on objectives satisfying these properties provides efficient guarantees for proxy objective functions. Additionally, we show that many existing guarantees for neural networks trained by gradient descent can be unified through proxy convexity and proxy PL inequalities.