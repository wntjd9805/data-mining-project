We investigate the problem of estimating the mean of distributed vectors at a central server. When dealing with high-dimensional vectors, the cost of transmitting entire vectors can be prohibitive. To address this, we propose the use of sparsification techniques. While previous research on sparsified mean estimation does not consider the characteristics of the data vectors, in practical scenarios like federated learning, there may exist spatial and temporal correlations within the data. We exploit these correlations by modifying the decoding method used by the server for mean estimation. Our analysis of the resulting estimation error and experimental results for PCA, K-Means, and Logistic Regression demonstrate that our approach consistently outperforms more complex and costly sparsification methods.