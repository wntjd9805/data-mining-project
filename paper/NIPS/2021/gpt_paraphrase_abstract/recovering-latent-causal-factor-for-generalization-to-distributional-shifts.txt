The accuracy of learned models can be affected by changes in the distribution of data between training and target domains. This is because the models often learn features that are only correlated with the output, rather than having a causal relationship. This correlation, known as "spurious correlation," is specific to the domain and may not generalize to unseen domains. To address this issue, we propose a method called Latent Causal Invariance Models (LaCIM) that incorporates the underlying causal structure of the data and considers the source of distributional shifts. LaCIM introduces a pair of correlated latent factors: a causal factor and other factors. The correlation between these factors is determined by a domain variable that characterizes the distributional shifts. We demonstrate that conditioning on the latent variables ensures that the distribution of observed variables is shift-invariant. With this invariance, we can recover the causal factor without mixing information from the other factors, leading to accurate predictions. We use a Variational-Bayesian-based method to learn this invariance for prediction. We validate the effectiveness of our approach through experiments on real-world data with distributional shifts. Our code is publicly available at https://github.com/wubotong/LaCIM.