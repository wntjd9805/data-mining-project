This paper presents a method for modeling convolutional filters using a neural ordinary differential equation (ODE) in order to generate images with gradual changes. By decomposing filters into filter atoms and modeling them with a neural ODE, the generated images exhibit continuity. The proposed framework is supported by experiments involving image-to-image translation and image generation conditioned on continuous labels. The method allows for easy manipulation of the gradual change in generated images by controlling integration intervals of the neural ODE, without the need for auxiliary network components or heavy supervision. This research highlights the potential of using the subspace of network parameters to navigate the diverse appearance of image generation.