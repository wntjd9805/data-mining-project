Saliency maps are widely used to explain the decisions made by convolutional neural networks (CNNs) in image classification. Typically, a single saliency map is generated for each image, assigning weights to pixels based on their importance for classification. However, we argue that relying on a single saliency map provides an incomplete understanding, as there can be multiple maps that can equally explain the classification. To address this, we propose using a beam search algorithm to systematically search for multiple explanations for each image. Our findings reveal that many images have multiple localized explanations. However, presenting all of these explanations to users can be overwhelming and may not effectively reveal their shared and unique structures. To address this issue, we introduce structured attention graphs (SAGs), which visually represent sets of attention maps by showing how different combinations of image regions affect the classifier's confidence. We propose a method for computing a compact and representative SAG for visualization using diverse sampling. To evaluate the effectiveness of SAGs, we conducted a user study comparing them to traditional saliency maps in answering comparative counterfactual questions about image classifications. The results demonstrate that presenting SAGs significantly improves user accuracy compared to standard saliency map baselines.