This study investigates whether observational measures of information flow can be used to identify interventions in the context of fairness in machine learning. The researchers conducted experiments on artificial neural networks and used a framework called M-information flow to measure the flow of information about the true label (accuracy) and a protected attribute (bias) in the network. They compared the magnitudes of information flow with the effects of intervening on the network by pruning certain edges. The results showed that pruning edges with higher information flows about the protected attribute reduced bias more effectively. This suggests that M-information flow can provide meaningful targets for interventions. The study also examined the tradeoff between bias and accuracy and how estimates of information flows can be used to inform interventions that maintain accuracy while reducing bias.