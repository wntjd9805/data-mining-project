Current methods for training neural networks with user-level differential privacy in federated learning involve bounding the contribution of each user's model update by clipping it to a constant value. However, determining the appropriate clipping norm is challenging due to various factors such as model architecture, loss, data distribution, and client learning rate. To address this, we propose a method that dynamically clips the model updates to a value at a specified quantile of the update norm distribution. This value is estimated online with differential privacy guarantees. Our approach closely tracks the quantile, requires minimal privacy budget, and is compatible with compression and secure aggregation techniques. Furthermore, it can be analyzed jointly with DP-FedAvg. Experimental results demonstrate the effectiveness of adaptive clipping to the median update norm across different federated learning tasks, sometimes even surpassing the performance of hindsight-selected fixed clipping values without the need for hyperparameter tuning.