The Fisher information matrix (FIM) is a valuable tool in deep learning for understanding loss landscapes, optimizing models, and developing learning theories. However, the exact FIM is often difficult to compute, so it is typically estimated using empirical samples. In this study, we examine two unbiased and consistent estimators for the FIM based on different representations. We assess the quality of these estimators by analyzing their closed-form variances. Additionally, we investigate how the parametric structure of deep neural networks can impact the variance. We discuss the significance of this variance measure and its upper bounds in the context of deep learning.