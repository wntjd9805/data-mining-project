Deep neural networks have been successful in analyzing graph structured data, but most research focuses on node or graph-level supervised learning. Unsupervised representation learning at the graph-level has not been explored much, possibly due to the complexity of representing graphs. This complexity arises from the numerous equivalent adjacency matrices that can represent a graph. To address this issue, we propose a permutation-invariant variational autoencoder that indirectly learns to match the node order of input and output graphs without explicitly enforcing a specific node order or using computationally expensive graph matching techniques. Our model demonstrates its effectiveness in tasks such as graph reconstruction, generation, and interpolation. We also assess the quality of the learned representations for downstream tasks like graph-level classification and regression.