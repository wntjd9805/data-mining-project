This paper introduces a novel approach called DEAL for computing features from still images that are resistant to non-rigid deformations. Existing methods, including handcrafted and learning-based descriptors, struggle with invariance to these transformations. DEAL addresses this issue by employing polar sampling and spatial transformer warping techniques, enabling it to handle rotation, scale, and image deformations. The model is trained end-to-end using isometric non-rigid deformations on objects in a simulated environment, resulting in highly discriminative local features. Experimental results demonstrate that DEAL outperforms state-of-the-art descriptors in various datasets containing real and realistic synthetic deformable objects in still images. The source code and trained model of DEAL can be accessed at https://www.verlab.dcc.ufmg.br/descriptors/neurips2021.