We investigate a novel set of problems concerning the recovery of representations from corrupted data. Our approach involves utilizing a pre-trained representation learning network, such as CLIP, that operates on clean images. The objective is to reconstruct the representation of an image, R(x), when only a corrupted version, A(x), is available, with A being a known forward operator. To address this, we propose a supervised inversion technique that employs a contrastive objective to achieve high-quality representations for heavily corrupted images. Through evaluating our robust representations using a linear probe, we surpass the accuracy of end-to-end supervised baselines when classifying images with various types of distortions, including blurring, additive noise, and random pixel masking. Our evaluation on a subset of ImageNet demonstrates the resilience of our method against different levels of distortion. Moreover, even with a limited amount of labeled data, our method outperforms end-to-end baselines across a wide range of forward operators.