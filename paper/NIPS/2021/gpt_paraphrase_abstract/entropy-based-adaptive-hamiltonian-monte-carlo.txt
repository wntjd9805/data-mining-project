Hamiltonian Monte Carlo (HMC) is a commonly used Markov Chain Monte Carlo (MCMC) algorithm for sampling from an unnormalized probability distribution. The performance of HMC can be affected by the choice of mass matrix used in the leapfrog integrator. To address this issue, we propose a gradient-based algorithm that allows for the adaptation of the mass matrix. Our algorithm aims to increase sampling efficiency by maximizing an approximation of the proposal entropy, rather than relying on expected squared jumping distance as in previous approaches. We demonstrate that using multiple gradients in the HMC proposal is advantageous compared to a single gradient-step in Metropolis-adjusted Langevin proposals. Empirical evidence shows that our adaptation method can outperform different versions of HMC schemes by adjusting the mass matrix to the geometry of the target distribution and providing some control over the integration time.