We introduce a deep reinforcement learning agent that employs a model-based approach and dynamically focuses on important aspects of its environment during the planning process. To limit the number of entities attended to during planning, the agent utilizes a bottleneck mechanism in a set-based representation. Through experiments conducted in various customized environments, we find that this design enables the planning agents to effectively apply their learned skills to new and unfamiliar environments by selectively attending to relevant objects. This leads to improved generalization performance beyond the distribution of training data. For more details, please refer to the project page: https://github.com/PwnerHarry/CP.