We present PointOdyssey, a synthetic dataset and framework for training and evaluating fine-grained tracking algorithms. Our aim is to advance the field by focusing on long videos with realistic motion. To achieve naturalism, we animate deformable characters using real-world motion capture data, construct 3D scenes to match the motion capture environments, and render camera viewpoints using trajectories extracted from real videos. We introduce diversity by randomizing character appearance, motion profiles, materials, lighting, 3D assets, and atmospheric effects. Our dataset consists of 104 videos, averaging 2,000 frames each, with significantly more correspondence annotations compared to previous work. We demonstrate that existing methods can be trained from scratch on our dataset and surpass the performance of published variants. Additionally, we enhance the PIPs point tracking method by expanding its temporal receptive field, resulting in improved performance on PointOdyssey as well as two real-world benchmarks. Our dataset and code are publicly accessible at https://pointodyssey.com.