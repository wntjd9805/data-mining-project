Image captioning is a task that can benefit from using large-scale web-crawled data, which provides valuable information about the visual world. However, the data collected from the web contains image-text pairs that are not perfectly aligned, leading to difficulties in training an accurate captioning model. Although filtering strategies can remove noisy data, this approach also reduces the amount of useful information and can result in a lack of data. To overcome these challenges, we propose a Noise-aware Captioning (NoC) framework that effectively learns from web-crawled data while minimizing the impact of noise. Our approach involves training an alignment-level-controllable captioner using the alignment levels of the image-text pairs as a control signal. This allows the model to generate high-quality captions by adjusting the control signal to the desired alignment level during inference. Our framework is shown to be effective in handling noise through an in-depth analysis. Additionally, we demonstrate the capabilities of our model in zero-shot captioning and text-to-image retrieval tasks, showcasing the production of high-quality captions in terms of descriptiveness and distinctiveness. The code for our framework is available at https://github.com/kakaobrain/noc.