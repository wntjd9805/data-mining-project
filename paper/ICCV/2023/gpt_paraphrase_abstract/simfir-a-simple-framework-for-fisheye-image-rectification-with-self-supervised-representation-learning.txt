This study proposes SimFIR, a straightforward framework for rectifying fisheye images using self-supervised representation learning. The framework utilizes the distinct distortion patterns present in fisheye images, which are independent of the visual content, as informative cues for rectification. The process involves dividing the fisheye image into patches and extracting their representations using a Vision Transformer (ViT). To capture fine-grained distortion representations, the patches are associated with their specific distortion patterns based on the fisheye model. Additionally, a novel unified distortion-aware pretext task is designed to facilitate learning. The results demonstrate that SimFIR significantly improves the transfer performance on the rectification task, indicating the effectiveness of the learned representations. Extensive experiments validate the superiority of SimFIR over state-of-the-art algorithms and its strong generalization ability to real-world fisheye images.