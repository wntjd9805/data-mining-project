This paper introduces a new unsupervised multi-view stereo (MVS) method called CL-MVSNet that addresses the limitations of previous methods. These limitations include difficulties in distinguishing regions and view-dependent effects such as low-textured areas and reflections. CL-MVSNet integrates two contrastive branches into the MVS framework to provide additional supervisory signals. The image-level contrastive branch improves context awareness for more accurate depth estimation in indistinguishable regions. The scene-level contrastive branch enhances representation ability to handle view-dependent effects. Additionally, an L0.5 photometric consistency loss is introduced to prioritize accurate points while reducing the impact of undesirable ones, resulting in more accurate 3D geometry. Experimental results on DTU and Tanks&Temples benchmarks demonstrate that CL-MVSNet outperforms other end-to-end unsupervised MVS frameworks and achieves state-of-the-art performance compared to its supervised counterpart, even without fine-tuning.