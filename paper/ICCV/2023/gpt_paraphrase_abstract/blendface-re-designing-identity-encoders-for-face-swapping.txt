Generative adversarial networks (GANs) and face recognition models have made it possible to swap identities on images. Existing methods have proposed solutions for this, but they still suffer from the problem of swapping undesired attributes due to biases in widely used identity encoders like ArcFace. To overcome this issue, we introduce Blend-Face, a new identity encoder for face-swapping. BlendFace trains face recognition models on blended images with attributes replaced, which helps mitigate biases such as hairstyles. It provides disentangled identity features to generators and guides them through an identity loss function. Extensive experiments show that BlendFace improves the disentanglement of identity and attributes in face-swapping models, while maintaining comparable performance to previous methods. The code and models can be accessed at https://github.com/mapooon/BlendFace.