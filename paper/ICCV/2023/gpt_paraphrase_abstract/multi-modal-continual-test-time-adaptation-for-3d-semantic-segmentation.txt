This paper introduces Multi-Modal Continual Test-Time Adaptation (MM-CTTA), an extension of Continual Test-Time Adaptation (CTTA) for 3D semantic segmentation. MM-CTTA addresses the challenge of adapting to dynamic target domains while avoiding catastrophic forgetting. To overcome this challenge, the authors propose a method called Continual Cross-Modal Adaptive Clustering (CoMAC), which consists of two components. Firstly, an adaptive dual-stage mechanism generates reliable cross-modal predictions by attending to the reliable modality based on class-wise feature-centroid distance in the latent space. Secondly, class-wise momentum queues are designed to perform test-time adaptation without forgetting, capturing confident target features for adaptation while restoring pseudo-source features to revisit source knowledge. Additionally, the authors introduce two new benchmarks to facilitate future exploration of MM-CTTA. Experimental results demonstrate that the proposed method achieves state-of-the-art performance on both benchmarks. More information can be found on the project website: https://sites.google.com/view/mmcotta.