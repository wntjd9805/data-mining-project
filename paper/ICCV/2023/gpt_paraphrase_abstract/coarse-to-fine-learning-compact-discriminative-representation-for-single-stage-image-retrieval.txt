This study focuses on image retrieval, which involves finding visually similar images in a database to a given query image. Current two-stage methods, which involve retrieving and re-ranking images, have shown good performance but are inefficient for real-world applications. To address this, some approaches have combined global and local features into a single-stage retrieval process. However, these approaches face challenges such as dealing with backgrounds, occlusion, and viewpoint variations. In this study, we propose a Coarse-to-Fine framework called Compact Discriminative representation (CFCD) for single-stage image retrieval. Our framework only requires image-level labels for training. We introduce an adaptive softmax-based loss that dynamically adjusts its scale and margin within each mini-batch, progressively increasing them to improve supervision and intra-class compactness during training. Additionally, we propose a mechanism that selectively chooses prominent local descriptors and incorporates fine-grained semantic relations into the global representation using a hard negative sampling strategy to enhance inter-class distinctiveness at a global scale. Extensive experiments demonstrate the effectiveness of our method, achieving state-of-the-art performance on benchmark datasets like Revisited Oxford and Revisited Paris. The code for our method is available at https://github.com/bassyess/CFCD.