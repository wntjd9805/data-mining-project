We propose a new method for self-supervised learning of point cloud representations using differentiable neural rendering. Our approach aims to capture both geometric and appearance information in informative point cloud features by training a point-cloud encoder within a point-based neural renderer. We compare the rendered images with real images from a large RGB-D dataset to ensure realism. The trained point-cloud encoder can be easily incorporated into different tasks, including 3D detection, segmentation, reconstruction, and image synthesis. Through extensive experiments, we show that our approach outperforms existing pre-training methods in various tasks.