Holistic 3D scene understanding from a single-view observation, which involves generating instance shapes and 3D scene segmentation, has been a longstanding challenge. Existing approaches either focus solely on geometry or segmentation, or tackle the task through separate modules that are later combined for the final prediction. Taking inspiration from recent advancements in 2D vision that integrate image segmentation and detection using Transformer-based models, we propose Uni-3D, a comprehensive system for parsing and reconstructing 3D scenes from a single RGB image. Uni-3D employs a universal model with query-based representations to predict segments of object instances and scene layout. Additionally, we introduce a single Transformer for 2D depth-aware panoptic segmentation in Uni-3D, which provides queries that serve as robust shape priors in 3D. By seamlessly integrating 2D and 3D in its architecture, Uni-3D surpasses previous methods with significant improvements in performance.