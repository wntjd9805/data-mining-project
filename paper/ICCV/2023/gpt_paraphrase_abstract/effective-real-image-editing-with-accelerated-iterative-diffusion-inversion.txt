Despite recent advancements, manipulating and editing natural images using modern generative models remains challenging. The process of mapping a real image to its corresponding noise vector in the latent space, known as inversion, poses a major obstacle when using Generative Adversarial Network (GAN). Additionally, the linearization assumption in each inversion step of Denoising Diffusion Implicit Models (DDIM) introduces unreliability in the deterministic inversion process. Previous approaches to address inversion stability have often sacrificed computational efficiency. In this study, we propose an Accelerated Iterative Diffusion Inversion method (AIDI) that enhances reconstruction accuracy with minimal additional overhead in space and time complexity. By utilizing a novel blended guidance technique, we demonstrate that effective results can be achieved in various image editing tasks without relying heavily on classifiers for guidance in inversion. Furthermore, our proposed process proves to be more robust for rapid image editing in the 10 and 20 diffusion steps' regimes compared to other diffusion inversion based methods.