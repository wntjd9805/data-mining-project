Diffusion probabilistic models (DPMs) used in image synthesis often struggle with contextual reasoning and learning the relationships between object parts in an image, resulting in slow learning. To address this, we propose a solution called Masked Diffusion Transformer (MDT). MDT incorporates a mask latent modeling scheme to enhance DPMs' ability to learn contextual relations among object semantic parts in an image. During training, MDT operates in the latent space and masks certain tokens. It employs an asymmetric masking diffusion transformer to predict masked tokens based on unmasked ones while preserving the diffusion generation process. MDT can reconstruct complete image information from incomplete contextual input, enabling it to learn the associated relations among image tokens. Experimental results demonstrate that MDT outperforms existing methods in image synthesis, achieving a new state-of-the-art Frechet Inception Distance (FID) score in the ImageNet dataset. Furthermore, MDT exhibits approximately three times faster learning speed compared to the previous state-of-the-art Diffusion Transformer (DiT) model. The source code for MDT is publicly available at https://github.com/sail-sg/MDT.