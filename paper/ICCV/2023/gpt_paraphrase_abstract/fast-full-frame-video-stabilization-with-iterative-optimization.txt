Video stabilization is a challenging task that aims to transform shaky videos into visually pleasing ones. However, finding the right balance between computational speed and visual quality has remained an open challenge in this field. To address this, we propose a novel iterative optimization-based learning approach for video stabilization using synthetic datasets.Our approach consists of two interconnected submodules: motion trajectory smoothing and full-frame outpainting. Firstly, we develop a two-level stabilizing algorithm that utilizes a probabilistic flow field. By exploiting the confidence map associated with the estimated optical flow, we guide the search for shared regions through backpropagation. This allows us to create a smoother motion trajectory, improving the visual quality of the stabilized video.Secondly, we adopt a divide-and-conquer strategy and introduce a new multi-frame fusion technique to render full-frame stabilized views. This approach helps us overcome the computational limitations and enhances the overall visual quality of the stabilized video.An important insight of our iterative optimization approach is that the target video can be seen as the fixed point of a nonlinear mapping for video stabilization. We formulate video stabilization as a problem of minimizing jerkiness in motion trajectories, ensuring convergence with the aid of fixed-point theory.To validate the effectiveness of our proposed approach, we conducted extensive experiments and obtained promising results. Our approach outperforms existing methods in terms of both computational speed and visual quality. We will make the code for our approach available on GitHub to facilitate further research and application in the field of video stabilization.