In recent years, there has been a significant focus on 3D object detection from multi-view images. Previous methods have either used dense detection heads or distributed object queries in 3D space. In this study, we introduce MV2D, a Multi-View 2D Objects guided 3D Object Detector that can enhance any 2D object detector for multi-view 3D object detection. By leveraging the valuable priors provided by 2D detections, MV2D utilizes 2D detectors to generate object queries based on image semantics. These dynamically generated queries enable MV2D to accurately locate objects within the field of view. To ensure that the queries focus on specific objects and suppress interference from noise, we design a sparse cross attention module. Our evaluation on the nuScenes dataset demonstrates that the dynamic object queries and sparse feature aggregation greatly improve the 3D detection capability. MV2D achieves state-of-the-art performance compared to existing methods and can serve as a new baseline for future research. The code for MV2D is available at https://github.com/tusen-ai/MV2D.