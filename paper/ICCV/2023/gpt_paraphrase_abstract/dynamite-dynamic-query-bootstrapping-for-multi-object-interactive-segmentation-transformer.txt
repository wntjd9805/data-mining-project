Current instance segmentation methods for training rely on expensive pixel-precise ground-truth annotations. To address this issue, interactive segmentation networks have been developed to generate annotations based on user interactions. However, existing methods can only process one instance at a time and require a full forward pass through the deep network for each user interaction. In this paper, we propose a more efficient approach called DynaMITe. DynaMITe represents user interactions as spatio-temporal queries to a Transformer decoder, allowing for the segmentation of multiple object instances in a single iteration. Our architecture eliminates the need to re-compute image features during refinement and requires fewer interactions to segment multiple instances compared to other methods. We evaluate DynaMITe on various interactive segmentation benchmarks and introduce a new multi-instance benchmark. Our results demonstrate that DynaMITe achieves state-of-the-art performance in interactive segmentation.