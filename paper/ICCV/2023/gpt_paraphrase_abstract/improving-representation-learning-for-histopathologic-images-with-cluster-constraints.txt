Advancements in whole-slide image (WSI) scanners and computational capabilities have greatly contributed to the utilization of artificial intelligence in the analysis of histopathology slides. However, the current supervised learning methods used for WSI analysis face the challenge of requiring exhaustive labeling of high-resolution slides, which is a laborious and time-consuming process. On the other hand, self-supervised learning (SSL) pretraining strategies have emerged as a promising alternative as they do not rely on explicit data annotations. These SSL strategies are quickly closing the performance gap compared to supervised approaches. In this study, we present a SSL framework that aims to achieve transferable representation learning and meaningful clustering by combining invariance loss and clustering loss in WSI analysis. Significantly, our approach surpasses common SSL methods in downstream classification and clustering tasks, as demonstrated through tests conducted on the Camelyon16 and a pancreatic cancer dataset. For further information, including the code and additional details, please visit https://github.com/wwyi1828/CluSiam.