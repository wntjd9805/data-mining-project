This abstract discusses the use of line segments as powerful features in computer vision, highlighting their ability to provide structural cues and withstand changes in viewpoint and illumination. However, matching line segments is more challenging compared to points due to occlusions, lack of texture, and repetition. The paper proposes a new matching paradigm that unifies points, lines, and their descriptors into a single wireframe structure. The authors introduce GlueStick, a deep matching Graph Neural Network (GNN) that utilizes connectivity information between nodes to improve matching accuracy. The paper demonstrates that the joint matching of points and line segments in GlueStick outperforms state-of-the-art approaches that independently match these features across various datasets and tasks. The code for GlueStick is available on GitHub at https://github.com/cvg/GlueStick.