The current state-of-the-art in computer vision relies on fine-tuning large pre-trained vision models. However, as model sizes continue to grow exponentially, the traditional approach of full fine-tuning becomes impractical due to the storage and transmission overhead of storing individual network copies for each task. To address this challenge, Adapter-based Parameter-Efficient Tuning (PET) methods have been developed, which involve tuning lightweight adapters inserted into frozen pre-trained models.   This paper investigates how to make adapters even more efficient by determining the minimum size required to store a task-specific fine-tuned network. It is observed that the parameters of adapters converge at flat local minima, indicating their resistance to noise in parameter space and low numerical precision. To train low-precision adapters, a computational-efficient quantization method is proposed, which minimizes the quantization error.   Extensive experiments demonstrate that low-precision adapters exhibit minimal performance degradation, with even 1-bit precision being sufficient. In fact, 1-bit adapters outperform all other PET methods on both the VTAB-1K benchmark and few-shot FGVC tasks, while requiring the smallest storage size. This study highlights the significant potential of quantization techniques in PET, providing a general solution to improve the parameter efficiency of adapter-based PET methods. The code for this research can be found at https://github.com/JieShibo/PETL-ViT.