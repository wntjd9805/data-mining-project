The aim of Video Tagging is to identify multiple relevant tags for a given video. These tags are usually defined and uploaded by various users, resulting in a large quantity of tags that are not in a specific order within the video. Existing methods for multi-label classification and generation struggle to directly adapt to this task. To address this, a new generative model called Order-Prompted Tag Sequence Generation (OP-TSG) is proposed. OP-TSG treats video tagging as a problem of generating a sequence of tags, guided by order prompts that are aligned with the tags. This approach allows the model to focus on modeling the dependencies between tags, rather than the order in which they are generated. Additionally, the model uses a word-based generation strategy, enabling it to generate new tags. To evaluate the effectiveness and generalization of the proposed method, two benchmarks, CREATE-tagging for Chinese video tagging and Pexel-tagging for English image tagging, are established. Extensive results demonstrate that OP-TSG outperforms other methods, particularly in improving the results for rare tags, where it achieves a 3.3% and 3% improvement over state-of-the-art methods on CREATE-tagging and Pexel-tagging, respectively. Furthermore, OP-TSG generates novel tags on CREATE-tagging with a tag gain of 7.04%.