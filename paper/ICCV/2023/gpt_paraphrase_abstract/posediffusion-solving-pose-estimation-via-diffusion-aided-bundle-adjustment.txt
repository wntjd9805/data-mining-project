Camera pose estimation in computer vision has traditionally relied on classical methods like keypoint matching, RANSAC, and bundle adjustment. This paper presents a novel approach to the Structure from Motion (SfM) problem by formulating it within a probabilistic diffusion framework. By modeling the conditional distribution of camera poses based on input images, this method offers several advantages. Firstly, the diffusion framework aligns with the iterative process of bundle adjustment. Secondly, it seamlessly integrates geometric constraints from epipolar geometry. Thirdly, it excels in challenging scenarios with sparse views and wide baselines. Additionally, the proposed method can predict intrinsics and extrinsics for any number of images. Experimental results on real-world datasets demonstrate that our method, PoseDiffusion, outperforms both traditional SfM pipelines and learned approaches. Importantly, our method exhibits generalization across datasets without requiring further training. More information about the project can be found on the project page: https://posediffusion.github.io/.