Network pruning is a technique used to compress models while minimizing the loss in accuracy. However, traditional pruning methods have been found to inherit or even magnify biases present in AI systems. This has led to a new perspective on fairness-aware network pruning. Current approaches, such as combining pruning with debias methods or monitoring demographic disparities during pruning, have attempted to improve fairness. However, these methods have not been able to achieve an optimal balance between pruning ratio, accuracy, and fairness. This paper proposes an end-to-end learnable framework for fairness-aware network pruning. The framework optimizes both the pruning and debias tasks simultaneously through adversarial training. The training process takes into account evaluation metrics such as accuracy for pruning, as well as disparate impact (DI) and equalized odds (DEO) for fairness. Unlike traditional methods, our approach does not rely on handcrafted rules and can be adapted to different network structures. Extensive experimentation has shown that our approach has strong generalization capabilities and outperforms traditional pruning methods in terms of both pruning and debiasing. Specifically, our method achieves state-of-the-art pruning performance while significantly improving fairness by approximately 50%.