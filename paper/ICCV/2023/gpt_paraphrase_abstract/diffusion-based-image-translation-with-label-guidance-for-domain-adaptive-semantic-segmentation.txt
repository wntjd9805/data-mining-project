Current strategies in domain adaptive semantic segmentation (DASS) involve translating images from a source domain to a target domain in order to train target models. However, these existing methods struggle to maintain semantic consistency and preserve local details between the original and translated images. In this study, we propose a novel approach to address this challenge by incorporating source-domain labels as explicit guidance during the image translation process. We formulate cross-domain image translation as a denoising diffusion process and introduce a Semantic Gradient Guidance (SGG) method to constrain the translation process based on pixel-wise source labels. To handle domain gaps, we develop a Progressive Translation Learning (PTL) strategy that ensures the reliability of the SGG method across diverse domains. Through extensive experiments, we demonstrate the superiority of our approach over state-of-the-art methods in domain adaptive semantic segmentation.