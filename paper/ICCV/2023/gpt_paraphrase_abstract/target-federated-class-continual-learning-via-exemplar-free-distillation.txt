This paper addresses the issue of Federated Class-Continual Learning (FCCL) in federated learning, where new classes are added dynamically. Existing FCCL methods have limitations such as needing extra datasets or storing private data from previous tasks. The paper first shows that non-IID data worsens the problem of catastrophic forgetting in federated learning. To tackle this, the paper proposes a new method called TARGET (federatTed clAss-continual leaRninG viaExemplar-free disTillation) that mitigates catastrophic forgetting in FCCL while maintaining client data privacy. The proposed method utilizes the knowledge of old tasks learned by the global model and transfers it to the current task at the model level. Additionally, a generator is trained to generate synthetic data that mimics the global data distribution on each client at the data level. TARGET outperforms previous FCCL methods as it does not require extra datasets or the storage of real data from previous tasks, making it suitable for scenarios involving sensitive data.