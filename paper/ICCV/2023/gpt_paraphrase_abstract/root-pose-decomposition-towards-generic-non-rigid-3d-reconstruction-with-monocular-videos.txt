This study focuses on reconstructing three-dimensional (3D) models of objects that can change shape based on videos captured by a single RGB camera. The goal is to create highly accurate models for various object categories and scenes captured in a casual manner. Unlike previous methods, this approach does not rely on prior knowledge of the initial positions of objects or specific templates for each object category. The main concept of this method, called Root Pose Decomposition (RPD), involves maintaining a transformation for the root pose in each frame while simultaneously creating a dense field with local transformations to correct the root pose. The optimization of these local transformations is achieved through point registration to a canonical space. The RPD technique is also adapted to scenarios involving multiple objects, considering occlusions and individual differences. Consequently, RPD enables the reconstruction of non-rigid 3D models for complex scenarios that consist of objects with significant deformations, intricate motion patterns, occlusions, and variations in scale among different individuals. This pipeline has the potential to be applied to a wide range of objects encountered in real-world settings. Experimental results demonstrate that RPD outperforms state-of-the-art methods on challenging datasets such as DAVIS, OVIS, and AMA. Video results can be viewed at https://rpd-share.github.io.