We present a new approach to non-exemplar class-incremental learning, which aims to recognize both old and new classes without having access to old class samples. This poses a challenge as the shared neural pathways can only be distinguished by the incremental samples, leading to conflicts in class optimization. In order to address this issue, we propose a unique self-organizing pathway expansion scheme. Our scheme includes a strategy for organizing class-specific pathways, which reduces the coupling of optimization pathways among different classes, thereby enhancing the independence of the feature representation. Additionally, we incorporate a pathway-guided feature optimization mechanism to mitigate interference between updates for old and new classes. Through extensive experiments on four datasets, we demonstrate significant performance improvements compared to state-of-the-art methods, with margins of 1%, 3%, 2%, and 2% respectively.