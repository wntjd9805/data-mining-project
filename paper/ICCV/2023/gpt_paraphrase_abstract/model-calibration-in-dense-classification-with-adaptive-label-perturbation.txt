To ensure the reliability of deep neural networks used in safety-critical applications, it is essential to develop models that not only make accurate predictions but also provide confidence measures indicating the likelihood of correctness. However, current dense binary classification models often exhibit overconfidence, which compromises their calibration. In order to address this issue, we propose a method called Adaptive Stochastic Label Perturbation (ASLP) that enhances model calibration by introducing a unique level of label perturbation for each training image. ASLP employs a novel loss function called Self-Calibrating Binary Cross Entropy (SC-BCE), which combines stochastic label perturbation techniques (e.g., DisturbLabel) and label smoothing to improve calibration while maintaining classification accuracy. Inspired by the Maximum Entropy Inference principle from statistical mechanics, ASLP maximizes prediction entropy by considering missing information. This is achieved by either preserving classification accuracy on known data as a conservative approach or specifically improving model calibration by minimizing the gap between prediction accuracy and expected confidence for the target training label. Extensive experiments demonstrate that ASLP significantly enhances calibration of dense binary classification models for both in-distribution and out-of-distribution data. The code for ASLP implementation can be found at https://github.com/Carlisle-Liu/ASLP.