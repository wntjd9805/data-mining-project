We propose a learning-based approach to tackle the challenge of visually disambiguating whether a pair of similar images represent the same or different 3D surfaces. This task is difficult for humans and can lead to errors in 3D reconstruction algorithms. To address this, we introduce a new dataset called Doppelgangers, which contains pairs of images depicting similar structures with known labels. We also develop a network architecture that considers the spatial distribution of local keypoints and matches to improve reasoning about both local and global cues. Our method successfully distinguishes illusory matches in complex scenarios and can be integrated into Structure-from-Motion (SfM) pipelines to generate accurate 3D reconstructions. More details, including code, datasets, and additional results, can be found on our project page: doppelgangers-3d.github.io.