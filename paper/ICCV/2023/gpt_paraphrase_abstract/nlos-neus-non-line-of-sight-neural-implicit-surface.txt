This study focuses on non-line-of-sight (NLOS) imaging, which aims to infer hidden scenes using indirect light from visible objects. The authors propose a new approach called NLOS neural implicit surface (NLOS-NeuS) that extends the neural transient field (NeTF) to reconstruct three-dimensional surfaces in NLOS scenes. To ensure accurate learning, two constraints are introduced as loss functions, preventing the occurrence of non-zero level-set surfaces. Additionally, a lower bound constraint is incorporated based on the geometry of the first-returning photons. Experimental results demonstrate the necessity of these constraints for obtaining a correct signed distance function (SDF) in NLOS scenes. Compared to previous methods, NLOS-NeuS with its neural continuous representation allows for the reconstruction of smooth surfaces while preserving fine details. This study is the first to investigate neural implicit surfaces with volume rendering in NLOS scenes. The project page for further information can be found at https://yfujimura.github.io/nlos-neus/.