The growing interest in Monocular 3D Semantic Scene Completion (SSC) stems from its ability to predict complex semantics and geometry shapes using just a single image, without the need for 3D inputs. However, current state-of-the-art methods face several critical issues. These include the Feature Ambiguity of 2D features projected onto the 3D space, the Pose Ambiguity of 3D convolution, and the Computation Imbalance in 3D convolution across different depth levels.  To tackle these problems, we propose a new approach called Normalized Device Coordinates scene completion network (NDC-Scene). Instead of directly mapping the 2D feature map to the world space, our method extends it to a Normalized Device Coordinates (NDC) space through progressive restoration of depth using deconvolution operations. Experimental results show that transferring most of the computation to the NDC space benefits monocular SSC tasks. Additionally, we introduce a Depth-Adaptive Dual Decoder that simultaneously upsamples and fuses the 2D and 3D feature maps, further enhancing overall performance.  Extensive experiments demonstrate that our proposed method consistently outperforms state-of-the-art techniques on both the outdoor SemanticKITTI and indoor NYUv2 datasets. Our code is publicly available at https://github.com/Jiawei-Yao0812/NDCScene.