Event-based cameras provide reliable measurements for computer vision tasks in high-dynamic range environments and fast motion scenarios. However, integrating deep learning into event-based vision is hindered by the lack of annotated data due to the novelty of event cameras. To overcome this challenge, we propose an unsupervised domain adaptation algorithm that leverages the knowledge from annotated data captured by conventional cameras. Our approach utilizes contrastive learning and uncorrelated conditioning of data to train a deep network for event-based image classification. Experimental results demonstrate that our solution outperforms existing algorithms in this domain.