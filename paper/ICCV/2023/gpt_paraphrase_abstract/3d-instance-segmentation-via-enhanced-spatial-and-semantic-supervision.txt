Recent advancements in 3D instance segmentation have led to increased interest in this field. Traditional deep learning methods rely on point grouping and geometric clustering, which are manually designed. However, newer hybrid approaches have emerged that combine transformer decoders with convolutional backbones operating on voxelized scenes. These hybrid approaches face a challenge due to the sparse feature backbones, resulting in a lack of spatial understanding in the extracted features provided to the transformer decoder. Consequently, these approaches tend to predict separate objects as single instances. In order to overcome this limitation, we propose a novel approach for 3D point clouds instance segmentation. Our method addresses the challenge of generating distinct instance masks for objects that share similar appearances but are spatially separated. To achieve this, we utilize spatial and semantic supervision along with query refinement techniques to enhance the performance of hybrid 3D instance segmentation models. Specifically, we incorporate spatial features into the transformer block to improve differentiation between similar object queries. Additionally, we employ semantic supervision to enhance prediction accuracy based on the object class. Experimental results demonstrate that our proposed approach outperforms existing methods on the validation sets of ScanNet V2 and ScanNet200 datasets. As a result, our approach establishes a new state-of-the-art for 3D instance segmentation in terms of performance and accuracy.