We introduce SHIFT3D, a differentiable framework that produces 3D shapes that are both structurally plausible and challenging for 3D object detectors. These novel objects can help identify vulnerabilities in autonomous driving systems. Using a signed distanced function (SDF) representation, we demonstrate that gradient error signals enable us to smoothly modify the shape or pose of a 3D object, confusing downstream detectors. Crucially, the objects generated by SHIFT3D differ physically from the baseline objects while still maintaining their semantic recognizability. Our approach allows for the interpretation of failure modes in modern 3D object detectors and facilitates the early identification of potential safety risks in 3D perception systems, preventing critical failures.