The diffusion model (DM) has achieved state-of-the-art performance in image synthesis by using a sequential denoising network. However, image restoration (IR) requires generating results that align with ground-truth, making the traditional DM approach inefficient. To address this, we propose an efficient DM for IR called DiffIR, which includes a compact IR prior extraction network (CPEN), dynamic IR transformer (DIRformer), and denoising network. DiffIR has two training stages: pretraining and training DM. In pretraining, we use ground-truth images to capture a compact IR prior representation (IPR) with CPENS1, which guides the DIRformer. In the second stage, we directly estimate the same IRP as CPENS1 using only low-quality (LQ) images. DiffIR requires fewer iterations than traditional DM to achieve accurate estimations and generate stable and realistic results because the IPR is a compact vector. Additionally, our DiffIR model can jointly optimize CPENS2, DIRformer, and the denoising network due to the few iterations, reducing estimation errors. We conducted extensive experiments on various IR tasks, achieving state-of-the-art performance while consuming fewer computational resources. The code for DiffIR is available at https://github.com/Zj-BinXia/DiffIR.