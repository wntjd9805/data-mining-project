The challenge of understanding the visual world from a human perspective has long been a problem in computer vision. Egocentric videos, which capture a person's point of view, present unique difficulties due to their complex scenes and irregular motion. In this study, we propose a method called DEVI (self-supervised object detection from egocentric videos) to address the problem of detecting objects in egocentric videos without the need for annotations or pre-trained weights. DEVI learns category-specific and angle- and illumination-invariant features using appearance-based techniques. Our approach takes advantage of natural human behavior to sample diverse views of objects, and incorporates multi-view and scale-regression losses as well as a cluster residual module to handle complex scenes. Experimental results show that DEVI achieves improvements in object detection performance on egocentric datasets, while also reducing model complexity. Furthermore, DEVI also demonstrates competitive performance on datasets unrelated to the egocentric domain without requiring additional training or fine-tuning.