Magnetic Resonance Imaging (MRI) is commonly used for brain tumor segmentation and detection. However, it often lacks certain modalities in clinical practice, resulting in a decrease in prediction performance. Current implementations treat different modalities as independent during training, ignoring their complementarity. In this paper, we propose a framework called GSS (Category Aware Group Self-Support Learning) to address this information deficit. GSS considers the sensitivity of different modalities to different tumor regions and utilizes collaborative efforts between modalities to identify a common learning target. We also introduce a random mask to reduce biases. GSS can be easily integrated into existing multi-modal brain tumor segmentation systems without requiring specific architectural choices. Experimental results on BraTS2020, BraTS2018, and BraTS2015 datasets show that GSS improves the performance of state-of-the-art algorithms by an average of 1.27-3.20% in Dice coefficient. The code for GSS is available at https://github.com/qysgithubopen/GSS.