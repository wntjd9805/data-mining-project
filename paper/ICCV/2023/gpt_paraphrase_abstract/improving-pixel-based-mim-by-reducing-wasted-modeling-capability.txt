Progress in Masked Image Modeling (MIM) has been significant. Current MIM methods can be categorized into two groups: pixel-based and tokenizer-based approaches, based on the reconstruction target. While pixel-based methods have a simpler pipeline and lower computational cost, they tend to be biased towards high-frequency details. This paper conducts empirical studies to confirm this limitation and proposes a new method that incorporates low-level features from shallow layers to aid pixel reconstruction. By integrating this design into the base method, MAE, the wasted modeling capability of pixel-based MIM is reduced, leading to improved convergence and notable enhancements in various downstream tasks. Notably, this paper is the first to systematically investigate multi-level feature fusion for isotropic architectures like the standard Vision Transformer (ViT). When applied to a smaller model like ViT-S, the proposed method achieves significant performance gains, including 1.2% improvement in fine-tuning, 2.8% improvement in linear probing, and 2.6% improvement in semantic segmentation. The code and models are available in MMPretrain1.