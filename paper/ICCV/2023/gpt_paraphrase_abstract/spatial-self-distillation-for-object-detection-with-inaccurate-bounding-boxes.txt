The use of inaccurate bounding boxes in object detection has become popular due to the high cost of quality annotation data or the presence of low-quality annotations, such as for tiny objects. Previous approaches have relied on multiple instance learning (MIL) to select and refine low-quality boxes, but these methods suffer from issues like object drift, group prediction, and part domination without considering spatial information. In this paper, we propose a Spatial Self-Distillation based Object Detector (SSD-Det) that leverages spatial information to improve the accuracy of inaccurate bounding boxes. SSD-Det incorporates a Spatial Position Self-Distillation (SPSD) module to exploit spatial information and an interactive structure that combines spatial and category information, resulting in high-quality proposal boxes. To enhance the selection process, we introduce a Spatial Identity Self-Distillation (SISD) module in SSD-Det to determine spatial confidence and choose the best proposals. Our method achieves state-of-the-art performance on MS-COCO and VOC datasets with noisy box annotations, demonstrating its effectiveness. The code for our approach is available at https://github.com/ucas-vg/PointTinyBenchmark/tree/SSD-Det.