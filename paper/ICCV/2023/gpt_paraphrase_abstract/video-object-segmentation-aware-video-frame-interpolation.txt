Video frame interpolation (VFI) is a widely studied area with various applications such as video enhancement, video encoding, and slow-motion effects. Existing research has mainly focused on improving overall image quality for challenging sequences with occlusions, large motion, and dynamic texture. However, this approach overlooks the fact that foreground and background regions have different importance in perceptual image quality. Additionally, accurately synthesizing moving objects is crucial for computer vision applications.To address these issues, we propose a novel training framework called VOS-VFI that incorporates video object segmentation (VOS). This framework enables VFI models to interpolate frames with more precise object boundaries. We leverage VOS as an auxiliary task, introducing additional loss functions such as segmentation loss and bi-directional consistency loss to train the VFI models. Through extensive experiments, we demonstrate that VOS-VFI significantly improves the performance of existing VFI models by generating clear object boundaries. Furthermore, VOS-VFI proves effective across multiple benchmarks for various applications, including video object segmentation, object pose estimation, and visual tracking. The code for VOS-VFI is available at https://github.com/junsang7777/VOS-VFI.