Advancements in AI hardware accelerators have made it possible to apply deep learning algorithms to address low-level vision tasks on mobile devices. However, there are still two main challenges to overcome: integrating task-specific algorithms into a single neural network architecture and achieving real-time inference with a large number of parameters. To address these challenges, we propose a new network called SYENet, which has only 6K parameters and can handle multiple low-level vision tasks in real-time on mobile devices. SYENet consists of two branches with simple building blocks, and a Quadratic Connection Unit (QCU) is introduced to effectively connect the results from these branches. Additionally, we introduce an Outlier-Aware Loss to enhance the performance of the network in image processing. Our proposed method demonstrates superior performance compared to other networks in real-time applications such as Image Signal Processing (ISP), Low-Light Enhancement (LLE), and Super-Resolution (SR), achieving a throughput of 2K60FPS on Qualcomm 8 Gen 1 mobile SoC. Notably, SYENet achieved the highest score in the MAI 2022 Learned Smartphone ISP challenge for the ISP task.