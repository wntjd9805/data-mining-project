Modern computer vision services often require users to share raw feature descriptors with an untrusted server, posing a privacy risk. To address this, researchers proposed embedding the features within an affine subspace with adversarial samples. However, we demonstrate two inversion attacks that can recover the original image features from these embeddings, compromising privacy. Existing visual privacy methods lack theoretical guarantees, so we propose the first method to privatize image features using local differential privacy. This approach offers a guaranteed bound for privacy leakage regardless of attack strength and performs well in visual localization tasks while maintaining privacy.