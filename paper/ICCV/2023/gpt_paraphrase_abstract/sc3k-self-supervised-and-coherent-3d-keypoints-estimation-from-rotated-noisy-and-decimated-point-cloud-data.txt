This paper introduces a novel technique for determining keypoints in practical scenarios involving noisy, down-sampled, and arbitrarily rotated point cloud data (PCD) from various object categories. The proposed model follows several key principles: i) keypoints are inferred in a fully unsupervised manner without any annotation, ii) the keypoints have low position error and are resilient to PCD perturbations, iii) keypoints remain consistent for objects within the same category, and iv) keypoints are located proximal to the PCD surface to ensure compactness. To achieve these goals, a new self-supervised training strategy is proposed along with a model architecture that incorporates auxiliary losses to encourage the desired properties of the keypoints. Comparative experiments with state-of-the-art unsupervised methods demonstrate that our approach outperforms others by accurately estimating keypoints with increased coverage (+9.41%) and semantic consistency (+4.66%), effectively characterizing the 3D shape of the objects for downstream tasks. The code and data for this research can be found at the following link: https://github.com/IIT-PAVIS/SC3K.