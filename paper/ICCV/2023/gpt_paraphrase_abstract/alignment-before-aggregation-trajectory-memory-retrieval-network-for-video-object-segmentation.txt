Memory-based methods in semi-supervised video object segmentation have shown competitive performance by matching query and memory frames. However, these methods often overlook the fact that videos contain rich temporal information but redundant spatial information. This can lead to ambiguous correspondences when performing direct pixel-level global matching. To address this issue, we propose a Trajectory Memory Retrieval Network (TMRN) that reconciles the tension between spatial and temporal information. TMRN includes a spatial alignment module and a temporal aggregation module to retrieve memory frame information along the object trajectory. TMRN offers several advantages. Firstly, it captures temporal correspondence in a data-driven manner, aligning with the nature of video. Secondly, it customizes the spatial alignment module by utilizing SVD initialization and agent-level correlation to construct representative agents and rectify false matches caused by direct pairwise pixel-level correlation. Our extensive experiments on challenging benchmarks, including DAVIS 2017 validation/test and Youtube-VOS 2018/2019, demonstrate that TMRN consistently outperforms several leading methods.