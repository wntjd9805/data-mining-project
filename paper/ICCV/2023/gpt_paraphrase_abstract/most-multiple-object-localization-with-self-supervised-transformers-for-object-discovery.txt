This study addresses the complex task of unsupervised object localization. Previous research has shown that transformers trained with self-supervised learning possess object localization capabilities even without specific training for this task. In this study, we introduce a method called Multiple Object localization with Self-supervised Transformers (MOST), which utilizes features extracted from self-supervised transformers to localize multiple objects in real-world images. MOST employs box counting, a fractal analysis tool, to analyze the similarity maps of the features and identify tokens located within foreground patches. These identified tokens are then clustered together, and the tokens within each cluster are used to generate bounding boxes around foreground regions. Unlike current state-of-the-art methods, MOST can localize multiple objects per image and outperforms other algorithms on various object localization and discovery benchmarks using PASCAL-VOC 07, 12, and COCO20k datasets. Additionally, we demonstrate that MOST can be employed for self-supervised pre-training of object detectors, resulting in consistent improvements in fully and semi-supervised object detection, as well as unsupervised region proposal generation. Our project is publicly accessible at rssaketh.github.io/most.