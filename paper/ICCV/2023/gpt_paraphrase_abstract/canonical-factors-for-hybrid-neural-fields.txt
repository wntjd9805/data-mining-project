This study focuses on factored feature volumes, which offer a simple way to create neural fields that are more compact, efficient, and interpretable. However, these architectures also introduce biases that may not be beneficial for real-world data. The authors characterize the undesirable biases that arise when using these architectures for axis-aligned signals, which can result in significant differences in radiance field reconstruction. To address this issue, the authors propose learning a set of canonicalizing transformations to remove these biases and improve representations. They demonstrate the effectiveness of this approach in a two-dimensional model problem, where a hybrid architecture that learns both the transformations and scene appearance achieves significantly improved efficiency. The resulting architecture, named TILTED, is validated using various tasks such as 2D image, signed distance field, and radiance field reconstruction, showing improvements in quality, robustness, compactness, and runtime. The results highlight that TILTED can achieve capabilities comparable to larger baselines while exposing weaknesses in standard evaluation procedures for neural field representations.