We introduce Neural Fields for LiDAR (NFL), a technique that optimizes a neural field scene representation using LiDAR measurements to generate realistic LiDAR scans from different perspectives. By combining neural fields with a detailed model of the LiDAR sensing process, NFL accurately reproduces important sensor behaviors such as beam divergence, secondary returns, and ray dropping. We assess NFL using both synthetic and real LiDAR scans and demonstrate its superior performance compared to reconstruct-then-simulate methods and other NeRF-style approaches in the task of generating novel views with LiDAR. Additionally, the enhanced realism of the synthesized views reduces the gap between synthetic and real scans, leading to improved registration and semantic segmentation performance.