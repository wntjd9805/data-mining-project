The growth of the MLaaS market has raised concerns about data privacy and security. Private inference techniques using cryptography can address these concerns, but they often come with high computation and communication costs, especially for non-linear operations like ReLU. Existing attempts to reduce ReLU operations may require heuristic threshold selection or result in significant accuracy loss. This study presents AutoReP, a gradient-based approach that automates the selection of ReLU and polynomial functions to speed up private inference applications. It also introduces distribution-aware polynomial approximation (DaPa) to maintain model expressivity while accurately approximating ReLUs. Experimental results show that AutoReP significantly improves accuracy compared to current state-of-the-art methods, with improvements ranging from 6.12% to 9.45% on various datasets. Additionally, when applied to EfficientNet-B2 on the ImageNet dataset, AutoReP achieved 75.55% accuracy with a reduction of 176.1 times the ReLU budget. The code for AutoReP is available on Github.