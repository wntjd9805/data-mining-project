Recent advancements in camera-based 3D object detection have incorporated sequential frames to enhance detection performance by minimizing depth estimation errors. However, existing methods either use simplistic fusion techniques or are limited to static environments, disregarding the significance of object motion cues. Consequently, the potential of sequential images remains underutilized, leading to only marginal improvements in performance. To overcome this constraint, we propose an innovative 3D object detection model called P2D (Predict to Detect), which integrates a prediction scheme into the detection framework to explicitly extract and leverage motion features. P2D utilizes past frames to predict object information in the current frame, facilitating the learning of temporal motion features. Additionally, we introduce a novel method for aggregating temporal features that effectively utilizes Bird's-Eye-View (BEV) features based on the predicted object information. This integration results in highly accurate 3D object detection. Experimental results demonstrate that P2D outperforms the sequential image-based baseline, improving mean Average Precision (mAP) and Normalized Detection Score (NDS) by 3.0% and 3.7% respectively. These findings highlight the significant enhancement in detection accuracy achieved by incorporating a prediction scheme.