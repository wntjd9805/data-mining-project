This study presents a novel approach called inverse compositional learning (ICL) for weakly-supervised video relation grounding (VRG). The problem of VRG is challenging and important in the fields of cross-modal learning and video understanding. The proposed approach tackles this problem by considering relations at both holistic and partial levels, formulating VRG as a joint optimization problem. For holistic-level reasoning, the approach introduces an inverse attention mechanism and a compositional encoder to generate compositional relevance features. The inverse loss is also introduced to evaluate and learn the relevance between visual features and relation features. At the partial-level reasoning, a grounding by classification scheme is introduced. By utilizing the learned holistic-level features and partial-level features, the entire model is trained in an end-to-end manner. The proposed method is evaluated on two challenging datasets and compared with state-of-the-art methods, demonstrating its substantial superiority. Ablation studies further confirm the effectiveness of the approach.