The objective of video depth estimation is to accurately determine the depth of objects in a video. Existing methods often achieve temporal consistency by adjusting a depth model based on single images during testing, using geometry and re-projection constraints. However, this approach is inefficient and lacks robustness. Another approach is to learn how to enforce temporal consistency from data, but this requires well-designed models and a sufficient amount of video depth data.  To overcome these challenges, we propose a plug-and-play framework called Neural Video Depth Stabilizer (NVDS). NVDS is designed to stabilize inconsistent depth estimations and can be easily applied to different single-image depth models without additional effort. Additionally, we introduce a large-scale dataset called Video Depth in the Wild (VDW), which consists of 14,203 videos with over two million frames. This dataset is currently the largest natural-scene video depth dataset known to us.  We evaluate NVDS on the VDW dataset as well as two public benchmarks and observe significant improvements in consistency, accuracy, and efficiency compared to previous approaches. Our work serves as a strong foundation and provides a valuable dataset for the development of learning-based video depth models. We plan to make our dataset and code publicly available to facilitate future research.