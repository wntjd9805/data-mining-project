This paper examines the effectiveness of camouflage and proposes three scores to automatically evaluate its success. The authors measure camouflage by assessing the similarity between background and foreground features and the visibility of boundaries. They apply these scores to compare various camouflage datasets and integrate them into a generative model as an additional loss. The authors demonstrate the scalability of synthesizing effective camouflage images and videos using this model. They then use the generated synthetic dataset to train a transformer-based model for segmenting camouflaged animals in videos. Experimental results show superior performance in breaking camouflage on the MoCA-Mask benchmark.