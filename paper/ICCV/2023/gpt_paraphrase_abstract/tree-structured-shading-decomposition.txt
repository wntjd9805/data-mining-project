Our study focuses on deriving a tree-structured representation for object shading from a single image. Existing methods commonly use parametric or measured representations, which lack interpretability and ease of editing. To overcome this limitation, we propose the use of a shade tree representation, which combines basic shading nodes and compositing techniques to factorize object surface shading. This representation allows novice users to efficiently and intuitively edit object shading, even without knowledge of the underlying physical shading process.However, inferring the shade tree poses a challenge as it involves both discrete tree structure and continuous parameters of the tree nodes. To address this issue, we propose a hybrid approach. Our method involves an auto-regressive inference model that provides an initial estimation of the tree structure and node parameters. We then refine the inferred shade tree using an optimization algorithm.To evaluate our approach, we conduct experiments on various types of images, including synthetic images, captured reflectance, real images, and non-realistic vector drawings. The results demonstrate the effectiveness of our method and its potential applications, such as material editing, vectorized shading, and relighting.For more information about our project, please visit our website: https://chen-geng.com/inv-shade-trees.