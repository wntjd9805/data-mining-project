In recent years, camera-based 3D object detection in Bird's Eye View (BEV) space has gained significant attention. Dense detectors typically use a two-stage process involving the construction of a dense BEV feature and object detection in BEV space. However, this approach faces challenges such as complex view transformations and high computation costs. Sparse detectors, on the other hand, follow a query-based approach without explicitly constructing dense BEV features but achieve lower performance compared to dense detectors.This paper aims to address the performance gap by focusing on the adaptability of the detector in both BEV and image space. The proposed approach, called SparseBEV, is a fully sparse 3D object detector that outperforms dense detectors. SparseBEV incorporates three key designs: (1) scale-adaptive self-attention, which aggregates features with an adaptive receptive field in BEV space, (2) adaptive spatio-temporal sampling, which generates sampling locations guided by queries, and (3) adaptive mixing, which decodes sampled features with dynamic weights from the queries.On the test split of nuScenes dataset, SparseBEV achieves state-of-the-art performance with a Normalized Detection Score (NDS) of 67.5. On the validation split, SparseBEV achieves an NDS of 55.8 while maintaining a real-time inference speed of 23.5 frames per second (FPS). The code for SparseBEV is available at https://github.com/MCG-NJU/SparseBEV.