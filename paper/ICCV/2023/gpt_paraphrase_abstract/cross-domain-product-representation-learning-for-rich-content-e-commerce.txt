The rise of short video and live-streaming platforms has transformed the way consumers participate in online shopping. Instead of simply browsing product pages, consumers now prefer rich-content e-commerce, which allows them to buy products through dynamic and interactive media such as short videos and live streams. However, this new form of online shopping presents technical challenges, as products may be presented differently across various media platforms. To address this issue, it is crucial to establish a unified product representation that enables cross-domain product recognition. This will ensure an optimal user search experience and effective product recommendations. Despite the urgent need for a unified cross-domain product representation in the industry, previous studies have primarily focused on product pages and neglected short videos and live streams. To bridge this gap in the field of rich-content e-commerce, this paper introduces a comprehensive dataset called ROPE (cRoss-dOmainProduct rEcognition). ROPE encompasses a wide range of product categories and includes over 180,000 products, which correspond to millions of short videos and live streams. It is the first dataset that covers product pages, short videos, and live streams simultaneously, providing the foundation for establishing a unified product representation across different media domains. Additionally, this paper proposes a framework called COPE (Cross-dOmain Product rEpresentation) that unifies product representations in different domains through multimodal learning, incorporating both text and vision. Extensive experiments on various tasks demonstrate the effectiveness of COPE in learning a joint feature space for all product domains.