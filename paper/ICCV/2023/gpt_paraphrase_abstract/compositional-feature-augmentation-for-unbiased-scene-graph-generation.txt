Scene Graph Generation (SGG) is a task that involves identifying visual relation triplets in an image. Over the years, SGG has made significant progress by utilizing both intrinsic and extrinsic information in relation triplets. However, current SGG models are biased towards head predicates due to the prevalence of long-tailed predicate distributions. To address this bias, existing debiasing methods focus on rebalancing the training samples. This paper argues that these methods fail to enhance the diversity of relation triplet features, which is crucial for robust SGG. To tackle this issue, a new approach called Compositional Feature Augmentation (CFA) is proposed. CFA is the first unbiased SGG method that aims to increase the diversity of triplet features. It achieves this by decomposing each relation triplet feature into intrinsic and extrinsic components, corresponding to the intrinsic characteristics and extrinsic contexts of the triplet. Two feature augmentation modules are designed to enrich the feature diversity by replacing or mixing up the intrinsic or extrinsic features from other samples. CFA can be seamlessly integrated into various SGG frameworks due to its model-agnostic nature. Extensive experiments demonstrate that CFA achieves state-of-the-art performance across different evaluation metrics.