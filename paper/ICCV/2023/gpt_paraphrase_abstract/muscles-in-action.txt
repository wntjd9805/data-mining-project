This study introduces a novel approach to incorporating muscle activity into computer vision methods for representing human motion. A new dataset called Muscles in Action (MIA) is presented, which includes synchronized video and surface electromyography (sEMG) data of 10 subjects performing various exercises, totaling 12.5 hours. Using this dataset, a bidirectional representation is learned that can predict muscle activation from video and reconstruct motion from muscle activation. The model is evaluated on both in-distribution and out-of-distribution subjects and exercises. The study demonstrates how combining both modalities can enhance the generation of muscularly consistent motion. The integration of muscles into computer vision systems has the potential to enable more advanced models of virtual humans, with applications in sports, fitness, and augmented/virtual reality.