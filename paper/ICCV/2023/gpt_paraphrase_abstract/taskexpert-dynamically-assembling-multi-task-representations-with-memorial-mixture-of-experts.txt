Learning discriminative task-specific features for multiple distinct tasks simultaneously is a fundamental challenge in multi-task learning. Current models attempt to decode task-specific features directly from a shared task-generic feature, but this approach results in a static feature decoding process that produces less discriminative task-specific representations. To overcome this limitation, we propose TaskExpert, a novel multi-task mixture-of-experts model that enables dynamic decoding of task-specific features by learning multiple representative task-generic feature spaces. TaskExpert decomposes the backbone feature into several task-generic features using expert networks and then decodes task-specific features using dynamic task-specific gating networks. Additionally, we introduce a multi-task feature memory in TaskExpert to establish long-range modeling of task-specific representations from different layers, enhancing dynamic feature decoding. Extensive experiments on two competitive multi-task learning benchmarks for visual scene understanding (PASCAL-Context and NYUD-v2) demonstrate that TaskExpert outperforms previous best-performing methods across nine metrics. We will provide publicly available codes and models.