Interactive image segmentation is a useful tool for pixel-level annotation in segmentation tasks. However, current interactive segmentation pipelines suffer from inefficient computations due to two main issues. First, the sequential nature of the interaction between annotators and models limits the utilization of the models' parallelism capabilities. Second, the models handle repetitive and redundant processes by processing the entire image along with sparse variable clicks in each interaction step. To address these problems, we propose a method called InterFormer. InterFormer introduces a new pipeline that extracts and preprocesses the computationally expensive image processing part of the existing process. It employs a large vision transformer (ViT) on high-performance devices to preprocess images in parallel. Then, it uses a lightweight module called interactive multi-head self attention (I-MSA) for interactive segmentation. The deployment of the I-MSA module on low-power devices also extends the practical application of interactive segmentation. By utilizing preprocessed features, the I-MSA module can efficiently respond to annotator inputs in real-time.Experimental results on multiple datasets demonstrate the effectiveness of InterFormer. It outperforms previous interactive segmentation models in terms of computational efficiency and segmentation quality. Additionally, InterFormer achieves real-time high-quality interactive segmentation on CPU-only devices. The code for InterFormer is available at https://github.com/YouHuang67/InterFormer.