Semi-Supervised Semantic Segmentation (S4) is a method used to train a segmentation model when there are only a limited number of labeled images available, but a large number of unlabeled images. Previous approaches have used contrastive learning in the latent space to improve the robustness of representations by aggregating them to their prototypes in a supervised manner. However, these methods only rely on supervision from the model's output in logit space during unlabeled training. In contrast, our method utilizes the outputs from both logit space and representation space to obtain supervision collaboratively. This collaboration serves two purposes: 1) reducing the risk of overfitting to incorrect semantic information by using representations, and 2) enhancing the exchange of knowledge between the two spaces. Additionally, unlike previous approaches, we introduce the similarity between representations and prototypes as an indicator to adjust the training of underperforming representations, resulting in a more efficient contrastive learning process. Our method achieves competitive performance compared to state-of-the-art methods, as demonstrated on two public benchmarks.