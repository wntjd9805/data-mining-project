This paper introduces a new approach called "Context Graph Generation (CGG)" for understanding the 4D context of real-world scenes. The CGG task leverages calibrated multiview videos to extract semantic information such as object coordinates, trajectories, and relationships, and represents it in the form of a spatio-temporal context graph. To facilitate research in this area, the authors also present a benchmark dataset called "RealGraph" which consists of synchronized multiview videos with manual annotations including object bounding boxes, category labels, and semantic relationships. They propose a baseline algorithm called MCGNet to investigate the effectiveness of CGG on the RealGraph dataset, but acknowledge the challenges involved and encourage further exploration. More information about the project can be found on the project page at https://github.com/THU-luvision/RealGraph.