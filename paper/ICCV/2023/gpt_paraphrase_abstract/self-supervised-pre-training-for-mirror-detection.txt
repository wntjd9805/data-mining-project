Current mirror detection methods rely on supervised ImageNet pre-training to obtain effective image features. However, this pre-training approach, which emphasizes category-level discrimination, may not be suitable for mirror detection as it can result in overfitting to unrelated tasks like image classification. Recognizing the importance of mirror reflection in human perception, we propose a new self-supervised learning (SSL) pre-training framework to enhance mirror detection methods. Our framework consists of three stages: image-level pre-training to incorporate global mirror reflection features, patch-level pre-training to learn local mirror reflection from image patches, and pixel-level pre-training to capture mirror reflection by reconstructing corrupted mirror images. Experimental results demonstrate that our SSL pre-training framework outperforms previous CNN-based SSL pre-training frameworks and even surpasses supervised ImageNet pre-training in mirror detection. The code and models for our framework can be accessed at the provided URL.