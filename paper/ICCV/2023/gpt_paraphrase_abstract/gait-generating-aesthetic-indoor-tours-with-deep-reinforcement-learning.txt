Creating visually appealing shots in photography, cinematography, and virtual content creation is a crucial objective. However, determining camera placement and orientation often requires extensive manual effort or solving complex optimization problems. To address this challenge, we present GAIT, a framework that employs Deep Reinforcement Learning (DRL) to train an agent in automatically controlling a camera for generating aesthetically pleasing views in synthetic 3D indoor scenes. GAIT utilizes a neural aesthetics estimator trained on a crowdsourced dataset to ensure high aesthetic value in the generated frames. Furthermore, we introduce regularization techniques to enhance diversity and smoothness in the trajectories of the camera, while also constraining the agent's acceleration in the reward function to produce a seamless sequence of frames. Our method outperforms baseline algorithms, as confirmed by a perceptual user study and ablation studies. The code and visual results can be found on our project website: https://desaixie.github.io/gait-rl.