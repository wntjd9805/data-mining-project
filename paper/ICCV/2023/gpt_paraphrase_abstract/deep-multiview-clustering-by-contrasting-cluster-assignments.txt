The goal of multiview clustering (MVC) is to categorize data samples into clusters in order to uncover the underlying structure of multiview data. While deep learning-based methods have shown strong feature learning capabilities on large-scale datasets, the problem of exploring invariant representations of multiple views remains challenging. In this study, we propose a method called cross-view contrastive learning (CVCL) that addresses this problem. CVCL learns view-invariant representations and generates clustering results by contrasting cluster assignments across multiple views. The method involves using deep autoencoders to extract view-dependent features in the pretraining stage, followed by a cluster-level CVCL strategy that explores consistent semantic label information among the views in the fine-tuning stage. By employing this learning strategy, the CVCL method produces more discriminative cluster assignments. Additionally, we provide a theoretical analysis of soft cluster assignment alignment. Experimental results on various datasets demonstrate that the proposed CVCL method outperforms several state-of-the-art approaches.