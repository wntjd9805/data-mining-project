Deep learning has significantly advanced the field of 3D autonomous driving semantic segmentation. However, due to limited training data, these models are unable to effectively generalize to various real-world environments. This lack of domain generalization has been relatively unexplored in the context of 3D autonomous driving semantic segmentation. To address this gap, this paper introduces the first benchmark for this application, evaluating state-of-the-art methods and discussing the challenges associated with domain shifts in Laser Imaging Detection and Ranging (LiDAR) data. Additionally, the paper proposes a novel method called 3DLabelProp, which leverages the geometry and sequentiality of LiDAR data to enhance generalization performance by working on partially accumulated point clouds. This method achieves a mean Intersection over Union (mIoU) of 50.4% on SemanticPOSS and 55.2% on PandaSet solid-state LiDAR. Notably, it is trained solely on SemanticKITTI and outperforms the second best method by 5% and 33% on respective datasets. The code for this method is available on GitHub at https://github.com/JulesSanchez/3DLabelProp.