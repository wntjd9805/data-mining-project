We propose a method for completing incomplete scene reconstructions using semantic information. Existing methods rely on 3D convolution but produce rough and imprecise shapes. Our method, called deformable deep implicit templates (DDIT), completes each segmented instance in a scene by deforming a template using a latent code. The template is expressed by a deep implicit function and provides shape constraints. The latent code controls the deformation to capture fine details. To predict the code, we use a neural network that considers both intra- and inter-instance information. We also introduce an algorithm to transform instances between the world and canonical frames based on geometric constraints and a hierarchical tree. To improve accuracy, we jointly optimize the latent code and transformation by enforcing the zero-valued isosurface constraint. We also create a new dataset to address limitations of existing datasets. Experimental results demonstrate that our DDIT method outperforms state-of-the-art approaches.