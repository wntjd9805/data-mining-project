This study introduces a technique called Masked Knowledge Distillation (MKD) that enhances the process of knowledge distillation in fine-grained visual tasks. MKD utilizes a masked autoencoding scheme where random patches of the input image are masked, and the missing features are recovered by imitating the teacher's output. The approach includes an adaptive decoder architecture with a spatial alignment module, a simple decoder, and a spatial recovery module. Additionally, masked convolutions are introduced to ensure the masked patches are unaffected by other elements. Experimental results with object detection and semantic segmentation demonstrate that MKD outperforms conventional knowledge distillation methods. Notably, the proposed technique achieves state-of-the-art results by improving the performance of RetinaNet ResNet-18 and ResNet-50 from 33.4 to 37.5 mAP and 37.4 to 41.5 mAP, respectively.