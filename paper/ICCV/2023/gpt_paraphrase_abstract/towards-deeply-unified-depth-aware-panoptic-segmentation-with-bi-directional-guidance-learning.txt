Depth-aware panoptic segmentation is a growing field in computer vision that combines semantic and geometric understanding to improve scene interpretation. Existing approaches treat segmentation and depth estimation as separate tasks, limiting their ability to leverage cross-domain information. To address this limitation, we propose a unified framework that performs joint segmentation and depth estimation for each segment using the same object queries. We also introduce a method to incorporate scene geometry into object queries, enhancing the relationship between the two tasks. Additionally, we propose a bi-directional guidance learning approach to facilitate feature learning across tasks. Our method achieves state-of-the-art results on Cityscapes-DVPS and SemKITTI-DVPS datasets for depth-aware panoptic segmentation. Furthermore, our guidance learning approach demonstrates performance improvement, even with incomplete supervision labels. The code and models for our method are available at https://github.com/jwh97nn/DeepDPS.