Enhancing visual cues in low-light vision is a challenging task. Previous approaches have either correlated visual quality with machine perception or used illumination-degrading transformation methods trained on synthetic datasets. However, we propose that optimizing enhanced image representation based on the loss of the downstream task can lead to more expressive representations. To achieve this, we introduce a new module called FeatEnHancer, which combines multiscale features using multi-headed attention guided by a task-related loss function. Additionally, our intra-scale enhancement improves feature quality at each scale and combines features from different scales based on their importance for the task. FeatEnHancer is a versatile module that can be incorporated into any low-light vision pipeline. Through extensive experimentation, we demonstrate that the enhanced representation generated by FeatEnHancer consistently improves results in various low-light vision tasks such as dark object detection, face detection, nighttime semantic segmentation, and video object detection. These findings highlight the effectiveness of enhancing hierarchical features in low-light vision.