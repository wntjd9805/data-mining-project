This paper introduces a new approach for domain generalization, which involves training a model with samples from multiple domains and then testing it on a new, unseen domain. The proposed method leverages recent advancements in large vision-language models, specifically a CLIP teacher model, to train a smaller model that can generalize to unseen domains. The main technical contribution is a novel regularization technique that ensures the student model's learned image representations are similar to the teacher model's learned text representations obtained from encoding the corresponding image descriptions. The paper presents two variations of the loss function: absolute and relative distance, which provide specific guidance on how to regularize the training process of the student model. The proposed method, named RISE (Regularized Invariance with Semantic Embeddings), is evaluated on various benchmark datasets and demonstrated to outperform several state-of-the-art domain generalization methods. Notably, this work is the first to utilize knowledge distillation from a large vision-language model for domain generalization. By incorporating text-based information, RISE enhances the generalization capability of machine learning models.