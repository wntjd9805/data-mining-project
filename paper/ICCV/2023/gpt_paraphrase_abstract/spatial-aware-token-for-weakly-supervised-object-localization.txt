Weakly supervised object localization (WSOL) is a challenging task that aims to locate objects in images with only image-level supervision. Recent approaches have utilized visual transformers to tackle WSOL and have achieved significant success by leveraging long-range feature dependencies through self-attention mechanisms. However, existing transformer-based methods face optimization conflicts between classification and localization tasks as they synthesize classification feature maps as localization maps. To overcome this issue, we propose a solution that learns a task-specific spatial-aware token (SAT) to condition the localization process in a weakly supervised manner. The SAT approach involves introducing a spatial token in the input space to aggregate representations for the localization task. Additionally, a spatial aware attention module is constructed, enabling the spatial token to generate foreground probabilities for different patches through querying and extract localization knowledge from the classification task. Furthermore, we tackle the problem of sparse and unbalanced pixel-level supervision obtained from image-level labels by designing two spatial constraints: batch area loss and normalization loss. These constraints compensate for and enhance the supervision. Experimental results demonstrate that our proposed SAT method achieves state-of-the-art performance on both CUB-200 and ImageNet datasets, with 98.45% and 73.13% GT-known Loc (ground truth-known localization), respectively. Moreover, even when trained with only one image per class from ImageNet, SAT outperforms the current state-of-the-art method by 2.1% GT-known Loc. The code and models for SAT are available at https://github.com/wpy1999/SAT.