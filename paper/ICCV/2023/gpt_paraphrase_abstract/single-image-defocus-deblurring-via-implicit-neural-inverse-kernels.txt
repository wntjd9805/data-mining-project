This paper introduces a novel approach for single image defocus deblurring (SIDD) that overcomes the limitations of existing deep-learning-based methods. The challenge in SIDD is the spatially-varying nature of defocus blur, which is characterized by per-pixel point spread functions (PSFs). Current methods either suffer from overfitting or are under-parametrized, limiting their applicability to real-world images. To address these limitations, this paper proposes an interpretable approach that explicitly predicts inverse kernels with structural regularization. The approach is motivated by the observation that defocus PSFs within an image often have similar shapes but different sizes. The inverse kernels are represented linearly over a multi-scale dictionary parameterized by implicit neural representations. The representation coefficients are predicted using a duplex scale-recurrent neural network that performs fine-to-coarse and coarse-to-fine estimations. Extensive experiments demonstrate that the proposed approach achieves excellent performance using a lightweight model.