Panoptic segmentation is a task that involves assigning semantic and instance ID labels to each pixel of an image. Current approaches to this task use specialized architectures and loss functions because the task requires learning a high-dimensional mapping. However, we propose a different approach that treats panoptic segmentation as a discrete data generation problem, without relying on any task-specific biases. Our method involves using a diffusion model with a simple architecture and generic loss function to model panoptic masks. By incorporating past predictions as a conditioning signal, our method can also track object instances in video streams. Through extensive experiments, we show that our simple approach can achieve competitive performance compared to state-of-the-art specialized methods in similar settings.