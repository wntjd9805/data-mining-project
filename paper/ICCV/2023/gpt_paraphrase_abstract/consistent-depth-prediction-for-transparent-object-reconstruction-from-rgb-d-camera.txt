Estimating the depth of transparent objects is challenging for commercial depth cameras due to light reflection and refraction. This results in noisy and incorrect depth values for such objects, making it difficult for traditional methods to reconstruct scenes containing transparency. Previous depth prediction methods have failed to provide accurate reconstruction due to inconsistent predictions. To address this issue, we propose a real-time reconstruction method using a novel stereo-based depth prediction network that ensures consistency in depth prediction across a sequence of images. As there are no existing video datasets for transparent objects, we create a synthetic RGB-D video dataset featuring various transparent objects. Additionally, we capture real scenes using the RealSense D435i RGB-D camera to evaluate the generalizability of our approach. Our experiments demonstrate significant improvements in depth prediction accuracy and scene reconstruction compared to previous methods.