This paper introduces a new method for generating the 3D movement of a human interacting with an object. The main focus is on addressing the challenge of producing long-range and varied motions, which cannot be effectively achieved using existing auto-regressive models or path planning-based methods. To overcome this challenge, the authors propose a hierarchical generation framework. The framework initially generates a series of milestones and then synthesizes the motion based on these milestones. This approach allows for the generation of long-range motions by synthesizing multiple short motion sequences guided by the milestones. Experimental results using the NSM, COUCH, and SAMP datasets demonstrate that the proposed approach surpasses previous methods in terms of both motion quality and diversity. The source code for this approach can be found on the project page: https://zju3dv.github.io/hghoi.