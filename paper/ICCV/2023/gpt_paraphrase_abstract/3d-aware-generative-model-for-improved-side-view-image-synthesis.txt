This paper introduces SideGAN, a new method for training 3D generative adversarial networks (GANs) to generate photo-realistic images regardless of camera pose, particularly for side-view angles of faces. The degradation in image quality caused by blurry and noisy boundaries at certain viewpoints is addressed. This degradation is attributed to the challenge of simultaneously learning pose consistency and photo-realism from a dataset with imbalanced poses. To tackle this problem, the authors split it into two subproblems that can be solved more easily. The first subproblem involves discriminating whether a synthesized image looks real or not, while the second subproblem focuses on discriminating whether a synthesized image aligns with the camera pose. To address these subproblems, a dual-branched discriminator with two discrimination branches is proposed, along with a pose-matching loss to learn pose consistency in 3D GANs. Additionally, a pose sampling strategy is presented to increase learning opportunities for steep angles in a pose-imbalanced dataset. The effectiveness of the approach is validated through extensive experiments, demonstrating that SideGAN enables 3D GANs to generate high-quality geometries and photo-realistic images regardless of camera pose.