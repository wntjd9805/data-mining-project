We present Replay, a dataset consisting of multi-view, multi-modal videos capturing human social interactions. The scenes are filmed with high production quality, using various static cameras and wearable action cameras. The recordings also include a wide range of microphone positions throughout the room. In total, the dataset comprises over 4000 minutes of footage and more than 7 million timestamped high-resolution frames. These frames are annotated with camera poses and partially with foreground masks. The Replay dataset holds significant potential for various applications, including 3D reconstruction, novel-view synthesis, human body and face analysis, novel-view acoustic synthesis, and generative model training. We also offer a benchmark for training and evaluating novel-view synthesis, with two difficulty scenarios. Additionally, we assess the performance of several state-of-the-art methods using this new benchmark.