This paper introduces a new approach called neural radiance field (NeRF) with forward warping for generating novel views of dynamic scenes. Existing methods use a static NeRF to represent the canonical space and generate dynamic images by mapping sampled 3D points back to the canonical space using a learned backward flow field. However, this backward flow field is non-smooth and discontinuous, making it challenging to fit commonly used smooth motion models. To address this issue, the paper proposes estimating a smooth and continuous forward flow field and directly warping the canonical radiance field to other time steps. This forward flow field is beneficial for motion model learning. To achieve this, the canonical radiance field is represented using voxel grids, enabling efficient forward warping. The paper also introduces a differentiable warping process that includes an average splatting operation and an inpaint network to handle mapping issues. Thorough experiments demonstrate that the proposed method surpasses existing approaches in both novel view rendering and motion modeling, highlighting the effectiveness of the forward flow motion modeling. More information about the project can be found at https://npucvr.github.io/ForwardFlowDNeRF.