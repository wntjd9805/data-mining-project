Deep neural networks are easily tricked by adversarial examples, which highlights the importance of testing the model's robustness before using it. Attackers can create adversarial examples against surrogate models and then transfer them to victim models that are deployed in a black-box scenario. To make these attacks more effective, structure-based attackers modify the backpropagation path to prevent the attack from overfitting the surrogate model. However, existing structure-based attackers do not fully utilize the convolution module in convolutional neural networks (CNNs) and make heuristic modifications to the backpropagation graph, which limits their effectiveness.  In this paper, we propose a solution called backPropagation pAth Search (PAS) to address these two problems. Firstly, we introduce Skip-Conv, a method that adjusts the backpropagation path of the convolution operation through structural reparameterization. This helps to overcome the limitations of heuristic design in existing backpropagation paths. Additionally, we construct a Directed Acyclic Graph (DAG) search space, use a one-step approximation for path evaluation, and employ Bayesian Optimization to search for the optimal path.  We conducted comprehensive experiments in various transfer settings and found that PAS significantly improves the success rate of attacks on both normally trained and defense models. This improvement is substantial.