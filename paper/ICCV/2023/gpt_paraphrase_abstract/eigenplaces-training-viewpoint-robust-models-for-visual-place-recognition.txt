Visual Place Recognition is a task that involves predicting the location of an image based on its visual features. Traditionally, this is done by comparing the query image with a large database of geotagged photos using learned global descriptors. However, a major challenge arises when trying to recognize places from different viewpoints. To address this challenge, we propose a new method called EigenPlaces. This method trains a neural network on images captured from various viewpoints, incorporating viewpoint robustness into the learned global descriptors. The key idea behind EigenPlaces is to cluster the training data in a way that presents the model with different views of the same points of interest. Importantly, this selection process does not require additional supervision.We conducted experiments using a comprehensive set of datasets and found that EigenPlaces outperforms previous state-of-the-art methods on the majority of these datasets. Additionally, training with EigenPlaces requires 60% less GPU memory and utilizes 50% smaller descriptors compared to other approaches.For those interested, the code and trained models for EigenPlaces are available at https://github.com/gmberton/EigenPlaces. Furthermore, results using other baseline methods can be computed using the codebase at https://github.com/gmberton/auto_VPR.