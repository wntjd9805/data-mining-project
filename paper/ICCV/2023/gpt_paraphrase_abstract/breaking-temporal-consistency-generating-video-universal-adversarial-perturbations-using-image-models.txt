As the use of deep learning models for video analysis becomes more common, concerns about the vulnerability of these models to adversarial attacks are increasing. Universal Adversarial Perturbation (UAP) is a particularly significant threat, as it can deceive deep learning models across entire datasets with just a single perturbation. In order to address this issue, we propose a novel video UAP approach that utilizes image data and image model-based studies. This allows us to leverage the wealth of information available from image models for video applications.  However, there is a challenge in using image models for video attacks, as they have limited ability to analyze the temporal aspects of videos, which are crucial for successful attacks. To overcome this challenge, we introduce the Breaking Temporal Consistency (BTC) method, which is the first attempt to incorporate temporal information into video attacks using image models. Our goal is to generate adversarial videos that exhibit opposite patterns to the original videos. Specifically, BTC-UAP aims to minimize the similarity of features between neighboring frames in videos. Despite its simplicity, our approach is highly effective at attacking unseen video models. Furthermore, it is applicable to videos of varying lengths and is not affected by temporal shifts. Our approach outperforms existing methods in terms of effectiveness on various datasets, including ImageNet, UCF-101, and Kinetics-400.