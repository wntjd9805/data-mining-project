This paper presents a new approach called Robustness Critical Fine-Tuning (RiFT) to enhance the generalization ability of deep neural networks without compromising their adversarial robustness. The RiFT method exploits the redundant capacity for robustness by fine-tuning the non-robust-critical module of an adversarially trained model. To determine the non-robust-critical module, the authors introduce a measure called module robust criticality (MRC) that evaluates the significance of each module in terms of model robustness under worst-case weight perturbations. The module with the lowest MRC value is identified as the non-robust-critical module, and its weights are fine-tuned to obtain optimal fine-tuned weights. The authors demonstrate the effectiveness of RiFT on various models trained on different datasets, showing significant improvements in both generalization and out-of-distribution robustness, while maintaining or slightly enhancing adversarial robustness. The code for RiFT is available at https://github.com/Immortalise/RiFT.