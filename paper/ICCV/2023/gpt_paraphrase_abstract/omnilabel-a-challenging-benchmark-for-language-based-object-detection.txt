Language-based object detection is a promising approach to developing a natural interface for describing objects in images beyond simple category names. However, there is a lack of proper evaluation in this field. In this study, we introduce OmniLabel, which includes a new task definition, dataset, and evaluation metric. This task covers standard- and open-vocabulary detection, as well as referring expressions. The OmniLabel dataset consists of over 25,000 images with more than 28,000 unique object descriptions, making it a challenging benchmark for language-based object detection. Additionally, unlike existing benchmarks, our dataset includes negative examples in free-form text, allowing for a more comprehensive evaluation. We propose a modified average precision metric to handle the large label space and validate its effectiveness through evaluation of strong language-based baselines. OmniLabel serves as a valuable test bed for future research in language-based object detection. For more information, please visit our project website at https://www.omnilabel.org.