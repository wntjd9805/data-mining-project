Recent advancements in multi-view 3D detection using bird-eye-view (BEV) have shown significant improvements. However, the high memory consumption of current models poses challenges for deployment in vehicles, and the resulting latency affects real-time perception in streaming applications. Although quantization has been used to reduce model size, our research demonstrates that directly applying quantization to BEV tasks causes training instability and leads to unacceptable performance degradation. To address these issues, we propose a method called QD-BEV that incorporates a novel view-guided distillation (VGD) objective. This approach stabilizes the quantization-aware training (QAT) process and enhances model performance by leveraging both image features and BEV features. Our experiments reveal that QD-BEV achieves similar or even better accuracy compared to previous methods, while significantly improving efficiency. For instance, on the nuScenes datasets, the 4-bit weight and 6-bit activation quantized QD-BEV-Tiny model achieves a NDS score of 37.2% with a model size of only 15.8 MB, outperforming BevFormer-Tiny by 1.8% with an 8Ã— model compression. Similarly, on the Small and Base variants, QD-BEV models perform exceptionally well, achieving NDS scores of 47.9% (28.2 MB) and 50.9% (32.9 MB), respectively.