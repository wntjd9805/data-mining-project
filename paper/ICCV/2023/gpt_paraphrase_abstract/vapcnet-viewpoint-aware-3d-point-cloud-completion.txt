Current methods for completing 3D point clouds often overlook the fact that the completion process is closely tied to the viewpoint of a partial scan. However, determining the viewpoint of incomplete objects in real-world scenarios is typically time-consuming and expensive. In this study, we propose an unsupervised approach to learning viewpoint representations for 3D point cloud completion without explicitly estimating the viewpoint. Instead, we learn abstract representations of partial scans that can distinguish different viewpoints in the representation space. We also introduce a Viewpoint-Aware Point cloud Completion Network (VAPCNet) that can adapt to various viewpoints based on the learned representations. Our viewpoint representation learning scheme extracts discriminative representations to accurately determine viewpoint information. Experimental results on popular datasets demonstrate that our VAPCNet achieves state-of-the-art performance for point cloud completion. The source code for our approach is available at https://github.com/FZH92128/VAPCNet.