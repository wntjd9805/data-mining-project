The way people interact with objects is influenced by the functional roles of those objects, presenting a challenge in understanding and learning hand-object interactions. To address this, we introduce AffordPose, a dataset containing a large number of hand-object interactions with affordance-driven hand poses. We annotate specific part-level affordance labels for each object, allowing us to indicate the purpose and guide the localization of the hand-object interactions. This fine-grained annotation reveals the influence of hand-centered affordances on the arrangement of hand poses, while also showcasing diversity. The dataset comprises 26.7K hand-object interactions, each including the 3D object shape, part-level affordance label, and manually adjusted hand poses. Through comprehensive data analysis, we explore the common characteristics and diversity of hand-object interactions per affordance. Additionally, we conduct experiments to validate the effectiveness of our dataset in learning and generating fine-grained hand-object interactions based on affordance understanding. More information can be found on our project page: https://github.com/GentlesJan/AffordPose.