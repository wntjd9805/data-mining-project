This paper presents a new method called D3DP (Diffusion-based 3D Pose estimation) with JPMA (Joint-wise reProjection-based Multi-hypothesis Aggregation) for probabilistic 3D human pose estimation. D3DP generates multiple possible 3D pose hypotheses from a single 2D observation by diffusing ground truth 3D poses and using a denoiser. It is compatible with existing 3D pose estimators and allows users to balance efficiency and accuracy through customizable parameters. JPMA is proposed to combine the hypotheses generated by D3DP into a single 3D pose by reprojecting them to the 2D camera plane and selecting the best joint-by-joint based on reprojection errors. It utilizes joint-level aggregation and 2D prior information, which were overlooked by previous approaches. Experimental results on Human3.6M and MPI-INF-3DHP datasets demonstrate that our method outperforms state-of-the-art deterministic and probabilistic approaches by 1.5% and 8.9% respectively. The code for our method is available at https://github.com/paTRICK-swk/D3DP.