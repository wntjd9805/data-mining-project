Creating 3D human avatars with specific identities and artistic styles that can be easily animated using neural implicit fields remains a challenge. In this study, we propose a method called AvatarCraft that overcomes this challenge by employing diffusion models to guide the learning of geometry and texture for a neural avatar based on a single text prompt. We have carefully designed the optimization framework of neural implicit fields, incorporating a coarse-to-fine multi-bounding box training strategy, shape regularization, and diffusion-based constraints. These techniques enable us to generate high-quality geometry and texture for the avatar. Furthermore, we have made the avatar animatable by deforming the neural implicit field using an explicit warping field that maps a target human mesh to a template human mesh represented by parametric human models. This simplifies the animation and reshaping of the generated avatar by controlling pose and shape parameters. Through extensive experiments using various text descriptions, we have demonstrated the effectiveness and robustness of AvatarCraft in creating human avatars and rendering novel views, poses, and shapes. For more information, please visit our project page at https://avatar-craft.github.io/.