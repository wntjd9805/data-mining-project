This study introduces a new generative model called LayoutDiffusion for automatic layout generation in graphic design. The model treats layout generation as a discrete denoising diffusion process, where layouts are represented as sequences of discrete tokens. The goal is to reverse a mild forward process where layouts become increasingly chaotic with each step, while ensuring that neighboring layouts do not differ too much. This forward process is challenging to design due to the categorical and ordinal attributes of layouts. To address this challenge, the study identifies three critical factors for achieving a mild forward process: legality, coordinate proximity, and type disruption. Based on these factors, the researchers propose a block-wise transition matrix and a piece-wise linear noise schedule. Experimental results on RICO and PubLayNet datasets demonstrate that LayoutDiffusion outperforms existing approaches and enables conditional layout generation tasks without re-training. The model also achieves better performance overall. The project page for LayoutDiffusion can be found at https://layoutdiffusion.github.io.