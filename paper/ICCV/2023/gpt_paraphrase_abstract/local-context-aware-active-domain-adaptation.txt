Active Domain Adaptation (ADA) aims to adapt a model from a source domain to a target domain by querying the labels of a small number of selected target samples. Existing ADA techniques have not fully explored the importance of the local context of queried data, particularly when there is a large domain gap. To address this issue, we propose a new framework called LADA (Local context-aware ADA). LADA focuses on selecting informative target samples by introducing a novel criterion based on the local inconsistency of model predictions. Since the labeling budget is typically limited, fine-tuning the model solely on the queried data can be inefficient. To overcome this, we progressively augment the labeled target data with confident neighbors in a class-balanced manner. Experimental results demonstrate that our proposed criterion outperforms existing active selection strategies in choosing more informative target samples. Moreover, our comprehensive approach significantly outperforms recent ADA methods on various benchmark datasets. The code for LADA is available at https://github.com/tsun/LADA.