This study proposes a novel approach called Temporal Motion Aggregation (TMA) for event-based optical flow estimation. Event cameras can capture detailed object trajectories with high temporal resolution, providing useful motion cues. However, existing learning-based methods treat event data as static frames, disregarding the temporal continuity of events. The authors argue that temporal continuity is crucial for accurate optical flow estimation and introduce TMA to address this issue. TMA consists of three components: an event splitting strategy to incorporate intermediate motion information, a linear lookup strategy to align fine-grained motion features, and a novel motion pattern aggregation module to enhance consistent patterns. By considering fine-grained motion information, TMA produces better flow estimates early on, reducing the need for subsequent refinements. The effectiveness and superiority of TMA are demonstrated through extensive experiments on DSEC-Flow and MVSEC datasets. Notably, TMA achieves a 6% improvement in accuracy and a 40% reduction in inference time compared to E-RAFT. The code for TMA is available at https://github.com/ispc-lab/TMA.