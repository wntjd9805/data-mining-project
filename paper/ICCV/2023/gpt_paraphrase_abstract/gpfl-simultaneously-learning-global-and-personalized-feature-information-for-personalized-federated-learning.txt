Federated Learning (FL) is a popular approach known for its ability to preserve privacy and facilitate collaborative learning. Recently, personalized FL (pFL) has gained attention for its potential in addressing statistical variations and achieving personalized results within FL. However, existing pFL methods mainly focus on extracting global or personalized feature information separately during local training, which does not align with the collaborative and personalized goals of pFL. In order to overcome this limitation, we propose a new pFL method called GPFL, which aims to learn both global and personalized feature information simultaneously on each client. To evaluate the effectiveness of GPFL, we conducted extensive experiments using six datasets in three different statistically heterogeneous scenarios. The results demonstrate that GPFL outperforms ten state-of-the-art methods in terms of effectiveness, scalability, fairness, stability, and privacy. Additionally, GPFL effectively mitigates overfitting and achieves up to 8.99% higher accuracy compared to the baseline methods.