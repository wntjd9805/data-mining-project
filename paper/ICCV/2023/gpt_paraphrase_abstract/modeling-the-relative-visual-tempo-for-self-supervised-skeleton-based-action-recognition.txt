This paper proposes a novel approach called Relative Visual Tempo Contrastive Learning framework for skeleton action representation (RVTCLR). The authors argue that relative visual tempo is a more intuitive way to describe actions and can provide more effective supervision signals. To address the feature representation issue, the authors design a Relative Visual Tempo Learning (RVTL) task to explore motion information within video clips and an Appearance-Consistency (AC) task to learn appearance information simultaneously. This results in more representative spatiotemporal features. Additionally, the authors address the problem of sparse skeleton sequence data by introducing a Distribution-Consistency (DC) branch, which includes Skeleton-specific Data Augmentation (S-DA), Fine-grained Skeleton Encoding Module (FSEM), and Distribution-aware Diversity (DD) Loss. The entire method, referred to as RVTCLR+, achieves competitive results on the NTU RGB+D 60 and NTU RGB+D 120 datasets compared to state-of-the-art methods. The authors provide the code for their method and acknowledge the support of the New Generation AI Major Project and the National Natural Science Foundation of China.