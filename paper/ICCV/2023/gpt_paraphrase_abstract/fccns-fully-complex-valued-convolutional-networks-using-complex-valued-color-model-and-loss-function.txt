Despite the existence of complex-valued convolutional neural networks (iCNNs), they have certain limitations such as the absence of complex-valued image inputs and loss functions. These networks also have a combination of complex-valued convolutional layers and real-valued fully-connected layers, which results in a lack of consistent flow of complex-valued information. To address these inconsistencies, we propose a complex-valued color model and loss function, and convert fully-connected layers into convolutional layers. This leads to the development of Fully Complex-valued Convolutional Networks (FCCNs). FCCNs exclusively operate on complex-valued inputs, perform only complex-valued operations, and utilize a complex-valued loss function. This allows for an end-to-end flow of complex-valued information that is lacking in existing iCNNs. Through extensive experiments on five image classification benchmark datasets, we demonstrate that FCCNs consistently outperform existing iCNNs. The source code for FCCNs is available at https://github.com/saurabhya/FCCNs.