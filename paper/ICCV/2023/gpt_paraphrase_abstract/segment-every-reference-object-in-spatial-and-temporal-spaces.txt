This study introduces UniRef, a unified approach for reference-based object segmentation tasks, including referring image segmentation (RIS), referring video object segmentation (RVOS), and video object segmentation (VOS). Currently, existing methods for these tasks are designed separately, limiting their multi-task capabilities. UniRef addresses this issue by employing a multiway-fusion technique to handle different tasks based on their specific references. Additionally, a unified Transformer architecture is utilized for instance-level segmentation. By training UniRef on various benchmarks, it can perform multiple tasks simultaneously by specifying the appropriate references. The performance of UniRef is evaluated on different benchmarks, and the results demonstrate its state-of-the-art performance on RIS and RVOS, as well as competitive performance on VOS using a single network.