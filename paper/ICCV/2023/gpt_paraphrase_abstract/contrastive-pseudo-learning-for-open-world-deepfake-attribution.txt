The issue of identifying the source of forged faces has become more challenging with the advancement of generative techniques. While some recent studies have focused on detecting fake faces generated by GANs, there is a lack of attention towards identity swapping or expression transferring attacks. Additionally, the hidden traces of forgery in unknown attacks on unlabeled faces have not been thoroughly explored. To address this, we introduce a new benchmark called Open-World DeepFake Attribution (OW-DFA) to evaluate the performance of attribution methods against various types of fake faces in open-world scenarios. We propose a novel framework called Contrastive Pseudo Learning (CPL) for the OW-DFA task. This framework includes a Global-Local Voting module to align features of manipulated regions in forged faces and a Confidence-based Soft Pseudo-label strategy to address noise from similar methods in the unlabeled set. Furthermore, we enhance traceability performance through a multi-stage paradigm that incorporates pre-training and iterative learning. Extensive experiments confirm the effectiveness of our proposed method in OW-DFA, highlighting the interpretability of deepfake attribution and its impact on improving the security of deepfake detection.