Diffusion models have become popular for image generation and reconstruction due to their advantages. However, current diffusion-based methods mainly focus on 2D images, and recent 3D methods do not fully utilize the 3D distribution prior. To overcome this limitation, we propose a new approach that uses two pre-trained 2D diffusion models perpendicular to each other to solve 3D inverse problems. Our method effectively addresses the curse of dimensionality by representing the 3D data distribution as a product of 2D distributions in different directions. Experimental results demonstrate the effectiveness of our approach in various 3D medical image reconstruction tasks, such as MRI Z-axis super-resolution, compressed sensing MRI, and sparse-view CT. Our method produces high-quality voxel volumes suitable for medical applications. The code can be found at https://github.com/hyn2028/tpdm.