This paper introduces CORE, a model for multi-agent cooperative perception that focuses on the concept of cooperative reconstruction. The model recognizes that by working together, agents can obtain a more comprehensive understanding of the environment. It also acknowledges that this holistic observation can be used to guide the learning process of reconstructing the ideal observation through collaboration. CORE consists of three main components: a compressor to create more compact feature representations for efficient broadcasting, an attentive collaboration component for aggregating messages between agents, and a reconstruction module to reconstruct the observation based on the aggregated features. This learning-to-reconstruct approach is not limited to specific tasks and provides valuable supervision for promoting effective collaboration in perception tasks. The effectiveness of CORE is demonstrated through experiments on two large-scale multi-agent perception datasets, OPV2V and V2X-Sim, in the tasks of 3D object detection and semantic segmentation. The results show that CORE achieves state-of-the-art performance while being more communication-efficient.