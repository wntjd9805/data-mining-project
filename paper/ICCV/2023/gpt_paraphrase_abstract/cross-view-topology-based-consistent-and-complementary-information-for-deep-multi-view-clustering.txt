Multi-view clustering has been widely used to extract valuable information from different perspectives. While deep neural networks have shown superior representation learning capabilities in multi-view clustering, most existing approaches focus on merging and exploring consistent latent representations across multiple views, neglecting the abundant complementary information in each view. Additionally, finding correlations between multiple views in an unsupervised setting is a significant challenge. To address these issues, we propose a novel framework called CTCC (Cross-view Topology based Consistent and Complementary information extraction). This framework leverages a bipartite graph learning module to obtain deep embeddings for each view individually. CTCC then constructs a cross-view topological graph based on the OT distance between the bipartite graphs of each view. By utilizing this graph, we maximize the mutual information across views to learn consistent information and enhance the complementarity of each view by selectively isolating distributions from each other. Extensive experiments on five challenging datasets demonstrate that CTCC outperforms existing methods significantly.