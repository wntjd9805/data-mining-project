Scene reconstruction in challenging conditions, such as high-speed motion and low illumination, is crucial in various applications like augmented reality, virtual reality, drone navigation, and autonomous robotics. However, traditional motion estimation techniques are ineffective in these conditions due to excessive blur caused by high-speed motion and strong noise in low-light situations. Recently, single-photon cameras have emerged as a promising technology capable of capturing numerous photon frames per second with their high speed and extreme sensitivity. Unfortunately, traditional computer vision techniques are not suitable for analyzing the binary-valued photon data obtained from these cameras, as they are corrupted by significant Poisson noise. In this study, we propose a method for estimating extreme scene motion under challenging conditions, such as low light or high dynamic range, using a sequence of high-speed image frames captured by a single-photon camera. Our method involves iteratively improving the motion estimate by grouping and aggregating frames in a stratified manner after capturing them. We demonstrate the effectiveness of our approach by creating high-quality panoramas under fast motion and extremely low light conditions, as well as achieving super-resolution results using a custom single-photon camera prototype. For access to the code and supplemental material, please visit our project webpage.