Cross-View Geo-Localisation remains a difficult task that requires additional modules and preprocessing techniques to accurately determine the positions of images. Current approaches often use polar transformation to merge different views, but this leads to distorted images that need to be rectified. While adding hard negatives to the training batch can improve performance, existing loss functions in geo-localisation make it challenging to include them. In this study, we propose a simplified yet effective architecture based on contrastive learning with symmetric InfoNCE loss, which surpasses current state-of-the-art results. Our framework eliminates the need for aggregation modules and further preprocessing steps, while also enhancing the model's generalization capacity to unknown regions. We introduce two sampling strategies for hard negatives: the first utilizes geographically neighboring locations as a starting point, while the second leverages visual similarity between image embeddings to mine hard negative samples. Our model demonstrates excellent performance on popular cross-view datasets such as CVUSA, CVACT, University-1652, and VIGOR. Furthermore, a comparison between cross-area and same-area settings highlights the strong generalization capability of our model. Figure 1 showcases our two sampling strategies: one based on geographical distance between satellite images, and the other utilizing cosine similarity between street-view and satellite-view embeddings to identify hard negatives within a specified margin.