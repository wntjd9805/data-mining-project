Closed-set instance segmentation models currently rely on pre-defined class labels for each mask during training and evaluation. This limits their ability to detect novel objects. Open-world instance segmentation (OWIS) models address this challenge by detecting unknown objects in a class-agnostic manner. However, previous OWIS approaches completely eliminate category information during training to maintain the model's ability to generalize to unknown objects. In this study, we propose a new training mechanism called SegPrompt that utilizes category information to enhance the model's class-agnostic segmentation ability for both known and unknown categories. Additionally, the previous OWIS training setup exposes the unknown classes to the training set, which results in information leakage and is not realistic. Therefore, we introduce a new open-world benchmark that closely resembles real-world scenarios by dividing the dataset classes into known-seen and unseen parts. For the first time, we focus on the model's capability to discover objects that never appear in the training set images.Experimental results demonstrate that SegPrompt can improve overall and unseen detection performance by 5.6% and 6.1% in average recall on our new benchmark without affecting inference efficiency. We further validate the effectiveness of our method on existing cross-dataset transfer and strongly supervised settings, achieving relative improvements of 5.5% and 12.3% respectively. The code and data associated with our work are publicly available at: https://github.com/aim-uofa/SegPrompt.