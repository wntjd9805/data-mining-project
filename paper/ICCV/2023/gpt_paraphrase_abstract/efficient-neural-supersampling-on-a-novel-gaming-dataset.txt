Real-time rendering for video games has become increasingly difficult due to the demand for higher resolutions, framerates, and photorealism. To address this challenge, supersampling has emerged as an effective solution. Our research introduces a new neural algorithm for super-sampling rendered content that is four times more efficient than existing methods while maintaining the same level of accuracy. Furthermore, we have created a new dataset that includes additional information such as motion vectors and depth, generated using graphics rendering techniques at various resolutions. This dataset fills a gap in the current dataset landscape and can be a valuable resource for measuring progress in the field and advancing super-resolution techniques for gaming content.