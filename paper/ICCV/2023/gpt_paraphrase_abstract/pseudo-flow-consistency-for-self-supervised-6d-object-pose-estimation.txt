This paper presents a novel approach to self-supervised 6D object pose estimation that does not require additional depth information or accurate 2D segmentation masks. The proposed method utilizes pure RGB images for training and starts with a rough pose initialization obtained from networks trained on synthetic images. To refine the pose estimation, a geometry constraint is introduced using synthetic-to-real image pairs from multiple views. This constraint is formulated as pixel-level flow consistency using dynamically generated pseudo labels. The effectiveness of the proposed method is evaluated on three challenging datasets, showing superior performance compared to existing self-supervised methods, without the need for 2D annotations or extra depth images.