This paper focuses on the challenging task of recognizing and generating object-state compositions, particularly when dealing with unseen compositions involving cutting objects in different styles and the resulting object state changes. To address this, the authors introduce a new benchmark suite called Chop& Learn, which allows for learning objects and different cut styles from multiple viewpoints. Additionally, they propose a novel task called Compositional Image Generation, which enables the transfer of learned cut styles to different objects by generating new object-state images. The authors also utilize the dataset for Compositional Action Recognition in videos, highlighting its usefulness for various video-related tasks. The project website for further information can be accessed at https://chopnlearn.github.io.