Gaze estimation methods using a single camera face limitations in providing complete facial information, making the task more challenging. However, the availability of affordable dual cameras in various devices presents an opportunity to enhance gaze estimation performance through dual-view gaze estimation. This study introduces a dual-view gaze estimation network (DV-Gaze) that estimates gaze directions from a pair of images. The proposed DV-Gaze incorporates a dual-view interactive convolution (DIC) block to exchange dual-view information during convolution across multiple feature scales. It also includes a dual-view transformer that encodes camera poses to indicate position information for gaze estimation. Additionally, a dual-view gaze consistency loss is introduced to account for the geometric relation between dual-view gaze directions. DV-Gaze demonstrates superior performance on ETH-XGaze and EVE datasets and shows promising potential for dual-view gaze estimation. The codes for DV-Gaze are available at https://github.com/yihuacheng/DVGaze.