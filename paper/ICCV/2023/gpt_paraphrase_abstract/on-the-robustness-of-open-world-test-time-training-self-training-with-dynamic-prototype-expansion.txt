Research on test-time training/adaptation (TTT/TTA) has been driven by the need to generalize deep learning models to unknown target domain distributions with low latency. However, existing approaches mainly focus on improving test-time training performance using well-curated target domain data. This study reveals that many state-of-the-art methods fail to maintain performance when the target domain is contaminated with strong out-of-distribution (OOD) data, which is also known as open-world test-time training (OWTTT). The main reason for this failure is the inability to differentiate strong OOD samples from regular weak OOD samples. To address this issue and enhance the robustness of OWTTT, the authors propose an adaptive strong OOD pruning technique that improves the effectiveness of the self-training TTT method. Additionally, they introduce a method to dynamically expand prototypes to represent strong OOD samples, thereby enhancing the separation of weak and strong OOD data. Finally, the authors incorporate distribution alignment regularization into self-training, resulting in state-of-the-art performance on five OWTTT benchmarks. The code for this research is available at https://github.com/Yushu-Li/OWTTT.