We propose DDColor, an end-to-end method for image colorization that addresses the challenges of multi-modal uncertainty and high ill-posedness. Existing approaches, such as direct deep neural network training, often produce incorrect semantic colors and lack color richness. Transformer-based methods, although better, rely on manually designed priors, have poor generalization ability, and suffer from color bleeding effects. To overcome these limitations, our approach utilizes dual decoders: a pixel decoder and a query-based color decoder. The pixel decoder restores spatial resolution, while the color decoder refines color queries using rich visual features, eliminating the need for hand-crafted priors. These decoders establish correlations between color and multi-scale semantic representations through cross-attention, effectively reducing the color bleeding effect. Additionally, we introduce a simple yet effective colorfulness loss to enhance color richness. Extensive experiments demonstrate that DDColor outperforms existing state-of-the-art methods both quantitatively and qualitatively. Our codes and models are publicly available at https://github.com/piddnad/DDColor.