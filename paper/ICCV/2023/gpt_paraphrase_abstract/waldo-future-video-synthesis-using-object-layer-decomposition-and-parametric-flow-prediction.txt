This paper introduces WALDO (WArping Layer-Decomposed Objects), a new method for predicting future video frames using past frames. The technique involves decomposing individual images into multiple layers that combine object masks and a small set of control points. These layers are shared across all frames in each video, establishing dense inter-frame connections. Complex scene motions are modeled by combining parametric geometric transformations associated with each layer. The video synthesis process consists of identifying the layers associated with past frames, predicting the corresponding transformations for upcoming frames, warping the associated object regions accordingly, and filling in the remaining parts of the image. Extensive experiments conducted on various benchmarks, including urban videos (Cityscapes and KITTI) and videos with nonrigid motions (UCF-Sports and H3.6M), demonstrate that our approach consistently outperforms the current state-of-the-art methods by a significant margin in all cases. The project webpage provides access to the code, pretrained models, and video samples synthesized using our approach.