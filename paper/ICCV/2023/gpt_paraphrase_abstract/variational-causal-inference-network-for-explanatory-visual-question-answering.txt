Explanatory Visual Question Answering (EVQA) is a recently introduced task that involves answering visual questions and generating explanations for the reasoning processes. While traditional Visual Question Answering (VQA) focuses solely on providing answers, EVQA aims to enhance explainability and credibility by providing user-friendly explanations. However, current EVQA methods predict the answer and explanation separately, disregarding the causal relationship between them and the complex relationships among question words, visual regions, and explanation tokens. To address these issues, we propose a Variational Causal Inference Network (VCIN) that establishes the causal correlation between predicted answers and explanations while capturing cross-modal relationships to generate rational explanations. Our approach involves utilizing a vision-and-language pretrained model to extract visual and question features, constructing cross-modal relationships using a multimodal explanation gating transformer, and employing variational causal inference to establish the target causal structure and predict the answers. Through comprehensive experiments, we demonstrate that VCIN outperforms state-of-the-art EVQA methods. The answer format outputs only the abstraction.