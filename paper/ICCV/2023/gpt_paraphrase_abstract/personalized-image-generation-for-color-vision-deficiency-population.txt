Approximately 350 million people, accounting for 8% of the population, suffer from color vision deficiency (CVD). Current image generation algorithms have been successful in creating high-quality images, but they unintentionally exclude CVD populations as target users, making it difficult for them to understand the generated images like normal viewers. Although a simple approach combining generation models and recolor compensation methods can be used, it has limitations in producing CVD-friendly images since the input image content is not CVD-oriented and remains fixed during the recolor compensation process. Additionally, the varying degrees of CVD are often overlooked in existing recoloring methods, preventing full service to CVD populations. In response, we propose a personalized CVD-friendly image generation algorithm with two main features: (i) generating CVD-oriented images tailored to the needs of CVD populations, and (ii) generating customized images for individuals with different degrees of CVD by disentangling the color representation using a triple-latent structure. Quantitative and qualitative experiments demonstrate that our proposed image generation model produces practical and compelling results compared to normal generation models and combination baselines using various datasets. The code for our algorithm is available at: https://github.com/Jiangshuyi0V0/CVD-GAN.git.