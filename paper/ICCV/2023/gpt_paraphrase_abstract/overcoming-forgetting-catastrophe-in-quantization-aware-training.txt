Quantization is a method used to reduce memory usage by compressing networks to lower bits. However, current quantization processes that learn solely from current data often suffer from a forgetting catastrophe when applied to streaming data. This refers to a significant decline in performance on older task data after being trained on new tasks. To address this issue, we propose a lifelong quantization process called LifeQuant.   We analyze the forgetting catastrophe theoretically and identify the shift in quantization search space as the cause. To mitigate this problem, we aim to minimize the shift during quantization by introducing Proximal Quantization Space Search (ProxQ). ProxQ regularizes the search space during quantization, making it closer to a pre-defined standard space. Additionally, we utilize replay data, which is a subset of old task data, for retraining on new tasks. This helps alleviate the forgetting problem. However, the limited amount of replay data often leads to biased quantization performance favoring the new tasks.   To tackle this imbalance, we introduce a Balanced Lifelong Learning (BaLL) Loss. BaLL Loss reweights the influence of replay data in new task learning by leveraging the class distributions. Our experimental results demonstrate that LifeQuant achieves exceptional accuracy performance with a low forgetting rate.