The combination of CNNs and RNNs is commonly used to capture spatiotemporal dependencies in prediction tasks. However, CNNs are limited in their ability to capture such dependencies due to their focus on local spatial information. In this study, we propose a new recurrent cell called SwinLSTM that combines SwinTransformer blocks and a simplified LSTM. SwinLSTM replaces the convolutional structure in ConvLSTM with a self-attention mechanism. We also develop a network using SwinLSTM as the core for spatiotemporal prediction. Without any specific techniques, SwinLSTM outperforms existing methods on various datasets, including Moving MNIST, Human3.6m, TaxiBJ, and KTH. Notably, SwinLSTM significantly improves prediction accuracy compared to ConvLSTM. Our experimental results demonstrate that learning global spatial dependencies is more beneficial for capturing spatiotemporal dependencies. We believe that SwinLSTM can serve as a strong baseline for enhancing spatiotemporal prediction accuracy. The source code is publicly available at https://github.com/SongTang-x/SwinLSTM.