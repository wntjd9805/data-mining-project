We introduce a method for editing videos with spatially and temporally varying lighting and motion effects. Our approach involves decomposing the video into multiple layers, each consisting of a texture map, an original video mask, and a residual component capturing lighting variations. By making edits to the texture maps, we can apply them consistently across the entire video while preserving other elements. Our technique efficiently learns these layered representations for high-definition videos and enables real-time rendering on a single GPU. We demonstrate the effectiveness of our method through qualitative evaluations on different videos and propose feature-tracking evaluation metrics for objective assessment. For more information, visit our project page: https://lightbulb12294.github.io/hashing-nvd/.