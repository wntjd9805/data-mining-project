Large language models (LLMs) like GPT-3 and ChatGPT have shown impressive results in various natural language processing (NLP) tasks using in-context learning, where inference is based on a few demonstration examples. However, no research has been done to evaluate the ability of LLMs to perform document information extraction (DIE) using in-context learning. This poses two challenges: the modality and task gap. To address this, we propose ICL-D3IE, a simple yet effective in-context learning framework that allows LLMs to perform DIE with different types of demonstration examples. Our framework extracts the most difficult and distinct segments from training documents as hard demonstrations, which benefit all test instances. We design demonstrations that describe relationships to help LLMs understand positional relationships, and introduce formatting demonstrations for easy answer extraction. Additionally, the framework improves diverse demonstrations through iterative updates. Our experiments on three benchmark datasets demonstrate that ICL-D3IE enables Davinci-003/ChatGPT to achieve superior performance compared to previous methods that were fine-tuned with full training, both in the in-distribution (ID) and out-of-distribution (OOD) settings. The code for ICL-D3IE is available at https://github.com/MAEHCM/ICL-D3IE. The answer format only provides the abstraction.