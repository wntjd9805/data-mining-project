This abstract discusses the challenge of predicting future motions in videos while maintaining consistency in object appearances. The proposed solution is a two-stream video prediction framework called Motion-Matrix-based Video Prediction (MMVP). Unlike previous methods, MMVP separates motion and appearance information by using appearance-agnostic motion matrices. These matrices represent the temporal similarity of feature patches in the input frames and serve as the input for the motion prediction module. This design improves video prediction accuracy and efficiency while reducing the model size. Extensive experiments show that MMVP outperforms state-of-the-art systems on public datasets by a significant margin, achieving higher PSNR (Peak Signal-to-Noise Ratio) values and using smaller model sizes (84% or smaller). The official code and datasets used in this paper can be found at the provided link.