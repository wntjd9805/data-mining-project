In recent studies, various methods have been developed to enhance the quality of multi-contrast magnetic resonance imaging (MRI) through super-resolution (SR). These methods have shown better results compared to single-contrast SR techniques. However, there are still two main drawbacks in existing approaches. Firstly, they can only handle fixed integer upsampling scales, such as 2×, 3×, and 4×, which means separate models need to be trained and stored for each scale in clinical settings. Secondly, these methods lack direct interaction between different windows, as they utilize a square window architecture, leading to insufficient modeling of longer-range dependencies. Additionally, the relationship between reference images and target images is not fully explored.  To overcome these limitations, we propose a novel network called McASSR for multi-contrast MRI arbitrary-scale SR. The key innovation of our approach is the implementation of a rectangle-window cross-attention transformer, which effectively establishes longer-range dependencies in MR images without increasing computational complexity. Furthermore, we introduce the reference-aware implicit attention as an upsampling module, which enables arbitrary-scale super-resolution using implicit neural representation and incorporates additional information from the reference image. Through extensive experiments on both public and clinical datasets, we demonstrate that our McASSR outperforms state-of-the-art methods, highlighting its potential for clinical applications. The source code for our approach is available at https://github.com/GuangYuanKK/McASSR.