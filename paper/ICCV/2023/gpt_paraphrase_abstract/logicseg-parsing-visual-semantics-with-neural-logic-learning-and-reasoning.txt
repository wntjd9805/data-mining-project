The existing semantic segmentation models rely solely on data-driven approaches and do not consider the structured nature of the visual world. In contrast, human cognition abstracts visual perceptions at different levels and employs symbolic reasoning with structured abstractions. To bridge this gap, we introduce LOGICSEG, a comprehensive visual semantic parser that combines neural inductive learning and logic reasoning using both data and symbolic knowledge. We organize the semantic concepts into a hierarchy and derive a set of constraints to describe the symbolic relations, which are then formalized as first-order logic rules. By applying fuzzy logic-based continuous relaxation, we ground the logical formulas onto data and neural computational graphs, enabling logic-induced network training. During inference, we incorporate the logical constraints into the network through an iterative process, represented as matrix multiplications, to achieve coherent predictions aligned with the hierarchy using logic reasoning. These features make LOGICSEG a versatile and compact neural-logic machine that can be easily integrated into existing segmentation models. Extensive experiments conducted on four datasets using various segmentation models and backbones confirm the effectiveness and generality of LOGICSEG. This study paves the way for a new approach to visual semantic parsing.