IR-NeRF is a pose-free neural radiance field model that addresses the issue of biased and inaccurate pose estimation for real images. Traditional approaches train a coarse pose estimator using rendered images, resulting in a domain gap between real and rendered images. This leads to poor robustness in pose estimation and local minima in joint optimization. To overcome these limitations, IR-NeRF introduces implicit pose regularization by refining the pose estimator with unposed real images.  IR-NeRF constructs a scene codebook using a collection of 2D images, which stores scene features and implicitly captures the scene-specific pose distribution as priors. By leveraging these priors, the robustness of pose estimation is improved. The rationale is that a 2D real image can be accurately reconstructed from the scene codebook only if its estimated pose falls within the pose distribution.  Extensive experiments demonstrate that IR-NeRF outperforms existing state-of-the-art methods consistently across synthetic and real datasets. It achieves superior novel view synthesis, showcasing its effectiveness in generating realistic images from different perspectives.