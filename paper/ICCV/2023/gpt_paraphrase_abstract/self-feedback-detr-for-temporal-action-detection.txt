Temporal Action Detection (TAD) is a challenging task for real-world video applications. Previous models based on DETR have not performed well in TAD due to a problem with self-attention. The self-attention modules in DETR focus on a few key elements, resulting in a temporal collapse problem that hinders the effectiveness of the encoder and decoder. In this paper, we propose a novel framework called Self-DETR to address this issue. Self-DETR utilizes cross-attention maps of the decoder to reactivate the self-attention modules. By recovering the relationship between encoder features through matrix multiplication of the cross-attention map and its transpose, we restore the information within decoder queries. We guide the collapsed self-attention maps with a calculated guidance map to mitigate the temporal collapse problem in the encoder and decoder. Through extensive experiments, we demonstrate that Self-DETR resolves the temporal collapse problem by maintaining a high diversity of attention across all layers. Our simple framework achieves a new state-of-the-art performance on THUMOS14 and outperforms all other DETR-based approaches on ActivityNet-v1.3.