Deep learning has greatly improved single image super-resolution (SISR) in recent years, but further advancements are hindered by the increasing size of models. Therefore, there is a growing interest in developing efficient SISR models by improving feature representation. This study introduces a simple and versatile method called partial channel shifting (PCS) to enhance features and enhance the performance of SR models. Inspired by temporal shifting in video understanding, PCS displaces a portion of the channels along the spatial dimensions, resulting in an amplified effective receptive field and increased feature diversity at virtually no additional cost. PCS can be easily integrated into existing models as a plug-and-play component, requiring no extra network parameters or computational overhead. However, regulating the features with PCS presents challenges such as determining shifting directions, amplitudes, proportions, and patterns of shifted channels. To address these challenges, technical constraints are imposed to simplify the general channel shifting. Extensive experiments demonstrate that PCS effectively increases the effective receptive field, enhances feature diversity, and significantly improves SR recovery performance in existing models.