Many image denoising techniques using deep neural networks have surpassed traditional model-based methods. However, supervised training using a large real noise dataset is burdensome, leading to the emergence of self-supervised methods. Blind-spot networks, which exclude the center pixel of the receptive field, have been popular for self-supervised denoising. However, excluding input pixels results in lost information, particularly when the corresponding output position is excluded. Moreover, blind-spot networks struggle to reduce real camera noise due to the pixel-wise correlation of noise. To address these issues and create a more practical denoiser, we propose a novel self-supervised training framework. We derive the theoretical upper bound of a supervised loss where the network is guided by the downsampled blinded output. We also introduce a conditional blind-spot network (C-BSN) that selectively controls the blindness of the network to utilize center pixel information. Additionally, we utilize a random subsampler to reduce spatial noise correlation, ensuring that the C-BSN is free of visual artifacts often seen in downsample-based methods. Our extensive experiments demonstrate that the proposed C-BSN achieves state-of-the-art performance as a self-supervised denoiser on real-world datasets, providing visually pleasing results without the need for post-processing or refinement.