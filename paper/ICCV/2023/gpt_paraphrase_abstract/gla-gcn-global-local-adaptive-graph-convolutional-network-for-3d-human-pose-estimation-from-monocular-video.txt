Research on 3D human pose estimation has been ongoing for many years, yielding promising results. One area of focus is 3D human pose lifting, which involves training using both estimated pose and ground truth data. However, existing pose lifting methods often perform poorly when tested on ground truth data. We have observed that the performance of estimated pose can be improved by using high-quality 2D pose data, such as fine-tuning or advanced detectors. Therefore, our objective is to enhance 3D human pose lifting using ground truth data to improve the quality of estimated pose data. To achieve this, we propose a simple yet effective model called Global-local Adaptive Graph Convolutional Network (GLA-GCN). Our model represents the spatiotemporal structure through a graph representation and utilizes individually connected layers to trace local joint features for 3D human pose estimation. We validate our model design by conducting extensive experiments on three benchmark datasets: Human3.6M, HumanEva-I, and MPI-INF-3DHP. The experimental results demonstrate that our GLA-GCN, implemented with ground truth 2D poses, outperforms state-of-the-art methods with significant error reductions of up to 3%, 17%, and 14% on Human3.6M, HumanEva-I, and MPI-INF-3DHP, respectively.