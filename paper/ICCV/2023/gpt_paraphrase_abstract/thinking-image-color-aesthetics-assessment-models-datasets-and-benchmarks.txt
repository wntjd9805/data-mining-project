We present a comprehensive study on a novel task called image color aesthetics assessment (ICAA), which aims to evaluate color aesthetics based on human perception. ICAA is important for various applications such as imaging measurement and image analysis. However, due to the wide range of aesthetic preferences and numerous color combinations, ICAA poses more challenges compared to traditional image quality assessment tasks. To advance research in ICAA, we propose a baseline model called the Delegate Transformer. This model utilizes deformable transformers to dynamically allocate interest points and also incorporates a dedicated module to learn human color space segmentation behavior. Additionally, we have created a meticulously designed dataset called ICAA17K, which includes 17,000 images covering 30 popular color combinations, 80 devices, and 50 scenes. Each image in the dataset has been densely annotated by over 1,500 individuals. Furthermore, we have developed a large-scale benchmark consisting of 15 methods, making it the most comprehensive benchmark to date, based on two datasets: SPAQ and ICAA17K. Our work not only achieves state-of-the-art performance but also provides the research community with a roadmap for exploring solutions in the field of ICAA. The code and dataset for our study are available for access.