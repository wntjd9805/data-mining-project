This paper aims to reconsider the field of scene text recognition (STR) by taking into account the data-oriented perspective. The authors first examine six commonly used benchmarks for STR and find that performance has reached a plateau, with only 2.91% of benchmark images unable to be accurately recognized by a combination of 13 representative models. Although these results may suggest that STR has been solved, the authors argue that this is due to the relatively simple nature of the benchmarks, which masks the underlying challenges faced by STR. In order to address this, the authors introduce a new large-scale real STR dataset called Union14M, which consists of 4 million labeled images and 10 million unlabeled images. Using this dataset, they assess the performance of STR models in more complex real-world scenarios. The experiments reveal that the 13 models achieve an average accuracy of only 66.53% on the labeled images, indicating that STR still encounters numerous challenges in real-world settings. Through an analysis of the error patterns of the models, the authors identify seven open challenges in STR and develop a challenge-driven benchmark comprising eight distinct subsets to facilitate further advancements in the field. The authors find that STR is far from being solved and suggest that leveraging data, particularly through self-supervised pre-training using the 10 million unlabeled images, can greatly enhance the robustness of STR models in real-world scenarios and achieve state-of-the-art performance. The code and dataset for this study are available at https://github.com/Mountchicken/Union14M.