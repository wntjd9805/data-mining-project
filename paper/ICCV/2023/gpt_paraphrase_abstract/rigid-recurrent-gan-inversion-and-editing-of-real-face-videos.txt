We propose a new approach called Recurrent vIdeo GANInversion and eDiting (RIGID) for generating consistent and high-quality edits on real videos using GANs. Existing methods often produce inconsistent results when inverting video frames individually. Our framework addresses this issue by considering the temporal relations between frames. We maximize the fidelity and consistency of the inversion by learning a temporal compensated latent code. We also disentangle incoherent noises in the high-frequency domain from the latent space. Additionally, we introduce an in-between frame composition constraint to remove inconsistencies after attribute manipulation. Our framework learns the coherence between input frames in an end-to-end manner and can be applied to arbitrary editing tasks without re-training. Experimental results show that RIGID outperforms existing methods in both inversion and editing tasks. More information and results can be found at https://cnnlstm.github.io/RIGID.