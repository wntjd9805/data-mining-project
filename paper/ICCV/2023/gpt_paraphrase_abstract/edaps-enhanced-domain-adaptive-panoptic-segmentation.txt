The increasing use of autonomous industries has highlighted the importance of domain adaptation in the visual perception field, as it offers potential cost savings. Previous research has focused on domain-adaptive semantic segmentation in the transition from synthetic to real contexts, but panoptic segmentation, a crucial output of the perception stack, has been largely neglected in the domain adaptation community. In this study, we explore successful domain adaptation strategies from other fields and apply them to panoptic segmentation, demonstrating their effectiveness in enhancing domain adaptation. Additionally, we propose a novel architecture called EDAPS specifically designed for domain-adaptive panoptic segmentation. EDAPS utilizes a shared, domain-robust transformer encoder to facilitate the adaptation of semantic and instance features, along with task-specific decoders tailored to the requirements of domain-adaptive semantic and instance segmentation. As a result, the performance gap observed in challenging panoptic benchmarks is significantly reduced. EDAPS achieves a substantial improvement in state-of-the-art performance for panoptic segmentation UDA, with a margin of 20% on the SYNTHIA-to-Cityscapes dataset and an impressive 72% on the more difficult SYNTHIA-to-Mapillary Vistas dataset. The implementation of EDAPS is available at https://github.com/susaha/edaps.