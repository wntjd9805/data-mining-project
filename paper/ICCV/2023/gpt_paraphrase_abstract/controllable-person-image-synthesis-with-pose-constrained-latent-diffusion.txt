Controllable person image synthesis aims to generate an image based on specific changes in body pose or appearance specified by the user. Previous methods have used pixel-level denoising diffusion models conditioned on a coarse skeleton through cross-attention. However, these approaches have two limitations: low efficiency and inaccurate condition information. To overcome these limitations, we propose a new model called Pose-Constrained Latent Diffusion (PoCoLD). Instead of using a sparse pose representation like the skeleton, we leverage DensePose, which provides more detailed body structure information. To efficiently incorporate DensePose, we introduce a pose-constrained attention module that effectively models the interaction between appearance and pose. Extensive experiments demonstrate that our PoCoLD outperforms existing methods in terms of image synthesis quality. Importantly, during inference, it requires only half the memory compared to the latest diffusion-model-based alternative. Our code and models can be accessed at https://github.com/BrandonHanx/PoCoLD.