Semi-supervised learning is gaining attention for its ability to combine unlabeled data effectively. However, existing frameworks often discard uncertain samples using a fixed confidence threshold to avoid potentially incorrect pseudo labels. While this approach ensures high-quality pseudo labels, it leads to low utilization of the entire unlabeled set. In this study, we propose a novel method called ShrinkMatch that converts uncertain samples into certain ones by identifying and removing confusion classes related to the top-1 class. ShrinkMatch achieves this by adaptively seeking a shrunk class space for each uncertain sample, which includes only the original top-1 class and other less likely classes. By eliminating the confusion classes in this space, the top-1 confidence can be recalculated to meet the desired threshold. We also introduce consistency regularization between strongly and weakly augmented samples in the shrunk space to learn discriminative representations. Additionally, we address the varied reliability of uncertain samples and the improved model during training by designing two reweighting principles for our uncertain loss. Our method demonstrates impressive performance on commonly used benchmarks.