Semantic segmentation has made significant advancements with deep neural networks, but generating a single segmentation output may not be suitable for safety-critical domains like medical diagnostics and autonomous driving. In these cases, multiple correct segmentation maps are needed to reflect the true distribution of annotation maps. However, predicting conditional distributions of labels given an image is challenging due to multimodal distributions, high-dimensional output spaces, and limited annotation data. To tackle these challenges, we propose a conditional categorical diffusion model (CCDM) for semantic segmentation based on Denoising Diffusion Probabilistic Models. Our model is conditioned on the input image, allowing it to generate multiple segmentation label maps that account for the uncertainty arising from divergent ground truth annotations. Experimental results demonstrate that CCDM achieves state-of-the-art performance on LIDC, a stochastic semantic segmentation dataset, and outperforms established baselines on the classical segmentation dataset Cityscapes.