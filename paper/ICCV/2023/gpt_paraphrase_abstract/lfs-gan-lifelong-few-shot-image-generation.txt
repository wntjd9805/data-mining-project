We present a novel approach to address the challenging task of lifelong few-shot image generation. Our generative model learns a sequence of tasks using only a few samples per task, leading to issues of catastrophic forgetting and overfitting. Existing methods for lifelong GANs rely on modulation-based techniques to prevent catastrophic forgetting, but they require additional parameters and struggle to generate high-quality and diverse images with limited data. Similarly, current few-shot GANs suffer from severe catastrophic forgetting when learning multiple tasks. To overcome these challenges, we propose a framework called Lifelong Few-Shot GAN (LFS-GAN) that can generate high-quality and diverse images in the lifelong few-shot image generation task. Our framework utilizes a task-specific modulator called Learnable Factorized Tensor (LeFT), which is rank-constrained and has a rich representation ability. Additionally, we introduce a novel mode seeking loss to enhance the diversity of our model in low-data scenarios. Through extensive experiments, we demonstrate that LFS-GAN can generate high-fidelity and diverse images without experiencing forgetting or mode collapse in various domains, achieving state-of-the-art performance in lifelong few-shot image generation. Interestingly, our LFS-GAN even surpasses existing few-shot GANs in the few-shot image generation task. The code for our framework is available on Github.