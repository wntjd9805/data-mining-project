The Aria Digital Twin (ADT) is a comprehensive dataset captured using Aria glasses, providing detailed information about objects, environments, and human activities. It includes 200 sequences of real-world activities conducted by Aria wearers in two indoor scenes, with a total of 398 object instances. Each sequence includes raw data from multiple camera streams and IMU sensors, along with complete sensor calibration. The dataset also includes ground truth data, such as the 6DoF poses of the Aria devices, object poses, eye gaze vectors, human poses, image segmentations, and depth maps. Additionally, it provides photo-realistic synthetic renderings. ADT is unique in terms of its accuracy, photo-realism, and comprehensiveness compared to existing egocentric datasets. By making ADT available to the research community, our aim is to establish a new standard for evaluating egocentric machine perception, addressing challenging research problems like 3D object detection and tracking, scene understanding, sim-to-real learning, and human pose prediction. It also inspires new machine perception tasks for augmented reality applications. To demonstrate the usefulness of ADT, we have evaluated various state-of-the-art methods for object detection, segmentation, and image translation tasks, showcasing ADT as a benchmarking dataset.