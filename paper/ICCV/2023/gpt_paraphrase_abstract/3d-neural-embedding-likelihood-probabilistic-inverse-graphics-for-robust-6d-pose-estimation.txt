The perception and understanding of 3D scenes are crucial in computer vision and robotics. Inverse graphics is a method that aims to infer the 3D structure of a scene from 2D images. This paper introduces probabilistic modeling to the inverse graphics framework to quantify uncertainty and achieve robustness in 6D pose estimation tasks. The proposed model, 3D Neural Embedding Likelihood (3DNEL), combines neural embeddings from RGB images with depth information to improve the robustness of object pose estimation. The performance of 3DNEL on the YCB-Video dataset is comparable to state-of-the-art methods but more robust in challenging situations. Unlike discriminative approaches, 3DNEL's probabilistic generative formulation can model multiple objects in a scene, quantify uncertainty, and handle object pose tracking under heavy occlusion. Additionally, 3DNEL provides a framework for incorporating prior knowledge about the scene and objects, allowing for extensions to tasks like camera pose tracking from video.