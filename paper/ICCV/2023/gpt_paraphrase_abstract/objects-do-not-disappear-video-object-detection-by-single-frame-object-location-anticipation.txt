We leverage continuous smooth motion in three ways to enhance object detection in videos. Firstly, we utilize object motion as an additional form of supervision, improving accuracy by anticipating object locations based on a static keyframe. Secondly, we optimize efficiency by performing computationally expensive feature computations on a subset of frames. Since neighboring frames often contain redundant information, we only compute features for a single static keyframe and predict object locations in subsequent frames. Lastly, we reduce annotation costs by annotating only the keyframe and using smooth pseudo-motion for the frames in between. Through experiments on four datasets, namely YouTube-BoundingBoxes and Waymo Open dataset, we demonstrate improved computational efficiency, annotation efficiency, and mean average precision compared to the state-of-the-art ImageNet VID and EPIC KITCHENS-55. Our source code can be accessed at https://github.com/L-KID/Video-object-detection-by-location-anticipation.