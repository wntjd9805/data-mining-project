This study focuses on expanding a segmentation model to classify and segment instance-level novel categories in open vocabulary instance segmentation. Previous methods have relied on caption datasets and complex pipelines to establish mappings between image regions and words in captions. However, these methods introduce noise by matching non-visible words to image regions and lack consideration for context words. To address these limitations, the study proposes a joint Caption Grounding and Generation (CGG) framework. This framework incorporates a novel grounding loss that focuses on matching object nouns to improve learning efficiency. It also introduces a caption generation head to provide additional supervision and contextual modeling. The analysis and results demonstrate that the grounding and generation components complement each other, significantly improving the segmentation performance for novel classes. Experiments on the COCO dataset with Open Vocabulary Instance Segmentation (OVIS) and Open Set Panoptic Segmentation (OSPS) settings show the superiority of CGG. Specifically, CGG achieves a substantial improvement of 6.8% mAP for novel classes on the OVIS task and 15% PQ improvements for novel classes on the OSPS benchmark.