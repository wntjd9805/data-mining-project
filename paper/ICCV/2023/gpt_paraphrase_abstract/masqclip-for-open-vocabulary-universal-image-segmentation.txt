We introduce a novel approach called MasQCLIP for universal image segmentation that can handle instance, semantic, and panoptic segmentation within a unified framework. MasQCLIP seamlessly integrates with a pre-trained CLIP model by utilizing its dense features, eliminating the need for extensive parameter training. Our method introduces two key elements: 1) a student-teacher module that handles masks of unseen classes by distilling information from seen classes, and 2) a fine-tuning process to update model parameters for queries within the CLIP model. These simple and intuitive designs enable MasQCLIP to outperform competing methods significantly in all three tasks: open-vocabulary instance, semantic, and panoptic segmentation. For more information, please visit our project page at https://masqclip.github.io/.