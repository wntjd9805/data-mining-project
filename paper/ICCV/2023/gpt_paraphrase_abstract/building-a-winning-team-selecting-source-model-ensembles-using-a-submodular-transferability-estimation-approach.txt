The importance of estimating the transferability of pre-trained models for transfer learning tasks has grown in recent years. Previous efforts have proposed metrics to help users choose a model from a pool of pre-trained models without needing to fine-tune each one individually. However, these efforts have not considered the transferability of multiple-source models for a given task or the cohesiveness factor between them. They also neglect possible domain or task mismatch. To address these gaps, we introduce a new metric called OSBORN, which takes into account image domain difference, task difference, and the cohesiveness of models in an ensemble to estimate transferability. We evaluate OSBORN on image classification and semantic segmentation tasks using various datasets, model architectures, and pre-training methods. Compared to current metrics, MS-LEEP and E-LEEP, our proposed approach consistently outperforms them.