The study focuses on the alignment of 3D scene graphs, which are used to represent the world in embodied AI applications. These graphs have been proven useful in solving various tasks, such as navigation and room rearrangement. The researchers propose a method called SGAligner, which is capable of aligning pairs of 3D scene graphs even when there is unknown overlap and changes in the environment. They draw inspiration from multi-modality knowledge graphs and utilize contrastive learning to create a joint, multi-modal embedding space. The effectiveness of SGAligner is demonstrated through its application on the 3RScan dataset, where it accurately estimates the transformation between pairs of 3D scenes. To facilitate further research, the researchers have provided the code, benchmark, and trained models on their project website.