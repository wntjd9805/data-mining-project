Skeleton-based action recognition has become a popular research topic as it offers a compact representation of the human body's skeletal structure. Previous methods have made significant progress using graph convolutional networks (GCNs) and convolutional neural networks (CNNs) to extract spatial and temporal features. However, while spatial and temporal dependencies within the human skeleton have been explored independently, the spatio-temporal dependency has been largely overlooked. To address this gap, we present the Spatio-Temporal Curve Network (STC-Net), which effectively leverages the spatio-temporal dependency of the human skeleton. Our network consists of two innovative components: 1) The Spatio-Temporal Curve (STC) module, and 2) Dilated Kernels for Graph Convolution (DK-GC). The STC module dynamically adjusts the receptive field by identifying meaningful connections between adjacent frames' nodes. It generates spatio-temporal curves based on these connections, thereby providing adaptive spatio-temporal coverage. Additionally, we introduce DK-GC to consider long-range dependencies. By applying an extended kernel to the given adjacency matrices of the graph, DK-GC achieves a large receptive field without introducing any additional parameters. By combining these two modules, our STC-Net achieves state-of-the-art performance on four benchmark datasets for skeleton-based action recognition. The code for our method is publicly available at https://github.com/Jho-Yonsei/STC-Net.