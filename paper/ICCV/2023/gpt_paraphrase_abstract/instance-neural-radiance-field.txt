This study introduces Instance-NeRF, a novel learning-based NeRF 3D instance segmentation pipeline. Instance-NeRF utilizes a NeRF model pretrained from multi-view RGB images to learn 3D instance segmentation of a given scene. The approach employs a 3D proposal-based mask prediction network on sampled volumetric features from NeRF to generate discrete 3D instance masks. These coarse 3D masks are then projected to image space to match 2D segmentation masks from existing panoptic segmentation models, which are used for training supervision of the instance field. Notably, Instance-NeRF not only generates consistent 2D segmentation maps from novel views but also enables instance information querying at any 3D point, thereby enhancing NeRF object segmentation and manipulation. The proposed method achieves state-of-the-art results in pure inference on synthetic and real-world NeRF datasets containing complex indoor scenes. It outperforms previous NeRF segmentation works and competitive 2D segmentation methods in segmentation performance on unseen views. The code and data for this study are available at https://github.com/lyclyc52/Instance_NeRF.