TEMPO is a novel approach to 3D human pose estimation that addresses the issues of accuracy and computational cost. Existing methods are accurate but computationally expensive and optimized for single time-step prediction. In contrast, TEMPO is efficient and capable of predicting accurate poses while also tracking and forecasting human movement.To achieve this, TEMPO utilizes a robust spatiotemporal representation that combines spatial and temporal information. By recurrently computing per-person 2D pose features, the model fuses both spatial and temporal context into a single representation. This allows the model to leverage the spatiotemporal context and make more accurate pose predictions without sacrificing efficiency.Additionally, TEMPO utilizes this representation to track human poses over time and predict future poses. This provides a comprehensive understanding of human movement dynamics and enables the model to anticipate future poses.One notable advantage of TEMPO is its ability to generalize across datasets without the need for scene-specific fine-tuning. This makes the model versatile and applicable to various scenarios.In terms of performance, TEMPO outperforms TesseTrack on the CMU Panoptic Studio dataset. It achieves a 10% improvement in mean per joint position error (MPJPE) and a remarkable 33Ã— improvement in frames per second (FPS). These results demonstrate the effectiveness and efficiency of TEMPO in comparison to the state-of-the-art.For more information and practical demonstrations, the code and demos of TEMPO are available at https://rccchoudhury.github.io/tempo2023/.