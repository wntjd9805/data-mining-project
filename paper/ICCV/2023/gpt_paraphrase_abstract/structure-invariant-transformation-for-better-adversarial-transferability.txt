Deep Neural Networks (DNNs) are highly vulnerable to adversarial examples, highlighting the need for effective adversarial attacks to expose the weaknesses of DNNs in security-sensitive applications. Existing transfer-based attacks, while popular, do not perform as well as white-box attacks. Input transformation based attacks have shown promise in enhancing transferability. However, current methods lack diversity in the transformed images as they globally transform the input image. This research aims to improve diversity by locally applying various transformations to different parts of the input image while preserving its structure. The proposed attack, called Structure Invariant Transformation (SIA), applies random image transformations to each image block, creating a set of diverse images for gradient calculation. Extensive experiments on the ImageNet dataset demonstrate that SIA outperforms existing state-of-the-art input transformation based attacks on both CNN-based and transformer-based models, showcasing its effectiveness in boosting transferability. The code for SIA is available at https://github.com/xiaosen-wang/SIT.