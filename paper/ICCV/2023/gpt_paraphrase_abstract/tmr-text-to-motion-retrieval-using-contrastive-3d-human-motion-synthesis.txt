In this study, we propose a new method called TMR for retrieving 3D human motion from text descriptions. Unlike previous approaches that only use retrieval as an evaluation metric, we treat it as a separate task. Our approach builds upon the state-of-the-art text-to-motion synthesis model TEMOS and incorporates a contrastive loss to improve the structure of the cross-modal latent space. We demonstrate the importance of maintaining the motion generation loss and contrastive training for achieving good performance. We introduce a benchmark for evaluation and provide a detailed analysis of our results on various protocols. Through extensive experiments on the KIT-ML and HumanML3D datasets, we show that TMR significantly outperforms previous methods, reducing the median rank from 54 to 19. Additionally, we demonstrate the potential of our approach for moment retrieval. Our code and models can be accessed publicly at https://mathis.petrovich.fr/tmr.