This paper focuses on data augmentation techniques for action segmentation. The main contribution of this study is the augmentation of training videos in the deep feature space, rather than in the visual spatiotemporal domain like previous approaches. To achieve this, the original deep features of video frames are modified to make the resulting embeddings closer to the class decision boundaries. Additionally, action sequences in the original training videos are edited by inserting, deleting, and replacing actions to ensure that the resulting transcripts have a similar edit distance to the ground-truth transcripts. Instead of using supervised learning, reinforcement learning is employed for data augmentation because reliable oracles for optimal data modifications in the deep feature space are not available. A meta-model formulated as a Markov Game with multiple self-interested agents is used to modify frame embeddings, while new transcripts are generated using a fast and parameter-free Monte Carlo tree search. Experimental results demonstrate that the proposed data augmentation technique improves the performance of state-of-the-art action segmenters on the Breakfast, GTEA, and 50Salads datasets.