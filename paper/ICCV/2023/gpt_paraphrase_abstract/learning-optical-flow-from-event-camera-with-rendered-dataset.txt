This study focuses on the estimation of optical flow from event cameras. A major challenge in this field is the creation of a high-quality event-flow dataset that consists of accurate event values and flow labels. Previous datasets have been generated either by capturing real scenes using event cameras or by synthesizing datasets from images with overlaid foreground objects. However, these approaches have their limitations. The former method provides real event values but with sparse and inaccurate flow labels, while the latter method generates dense flow labels but with errors in the interpolated events. To overcome these challenges, the authors propose a physically accurate event-flow dataset created using computer graphics models. The dataset includes indoor and outdoor 3D scenes with diverse scene content variations. Different camera motions are also incorporated to simulate virtual capturing, resulting in images with accurate flow labels. Additionally, high-framerate videos are rendered between images to ensure accurate events. The density of events in the dataset can be adjusted, and an adaptive density module (ADM) is introduced to further improve performance. The experiments conducted demonstrate that training on this proposed dataset leads to improved performance compared to previous approaches. Furthermore, when equipped with the ADM, event-flow pipelines show further performance improvements. The code for this study is available at https://github.com/boomluo02/ADMFlow.