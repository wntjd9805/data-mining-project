The task of point cloud completion is to reconstruct the complete shape of an object based on an incomplete observation. Current methods either require complete point clouds or multiple partial observations for training. However, we present a new self-supervised framework called Partial2Complete (P2C) that can complete point cloud objects using only a single incomplete observation per object. Our framework takes in incomplete point clouds as input, groups them into local patches, and predicts masked patches by learning from different partial objects. We also introduce the Region-Aware Chamfer Distance to ensure shape consistency without limiting completion capability, and the Normal Consistency Constraint to encourage a continuous and complete surface. Unlike previous methods, P2C does not rely on multiple observations or complete point clouds as ground truth. Instead, it learns structural cues from a specific dataset to complete partial point clouds. We validate our approach on both synthetic ShapeNet data and real-world ScanNet data, demonstrating that P2C achieves comparable results to methods trained with complete shapes and outperforms methods trained with multiple partial observations. Our code is available at https://github.com/CuiRuikai/Partial2Complete. Figure 1 illustrates the conceptual comparison of different point cloud completion schemes, highlighting the uniqueness of our approach that only requires a single partial observation per object for learning.