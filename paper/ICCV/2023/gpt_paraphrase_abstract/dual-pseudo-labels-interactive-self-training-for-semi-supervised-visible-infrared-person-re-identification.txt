This abstract discusses the field of visible-infrared person re-identification (VI-ReID), which involves matching a specific person from a gallery of images captured from visible and infrared cameras. The majority of existing research focuses on fully supervised VI-ReID, which requires costly cross-modality annotation. To address this issue, the authors explore two semi-supervised settings: uni-semi-supervised, where only visible images are annotated, and bi-semi-supervised, where partial annotation is done in both modalities. These settings face challenges due to differences between visible and infrared images and the lack of correspondence supervision. The authors propose a dual pseudo-label interactive self-training (DPIS) method for these settings. DPIS combines pseudo-labels generated by different models to create a hybrid pseudo-label for unlabeled data. To mitigate the impact of noise in the hybrid pseudo-label, the authors introduce three modules: noise label penalty (NLP), noise correspondence calibration (NCC), and unreliable anchor learning (UAL). NLP penalizes noise labels, NCC calibrates noisy correspondences, and UAL mines hard-to-discriminate features. Experimental results on SYSU-MM01 and RegDB datasets demonstrate the impressive performance of DPIS in these semi-supervised settings.