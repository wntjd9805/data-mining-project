Ensuring the robustness of 3D perception systems in the face of natural corruptions is crucial for applications where safety is paramount. However, existing large-scale datasets for 3D perception are often meticulously cleaned, which does not accurately reflect the reliability of these systems in real-world deployment. To address this issue, we introduce Robo3D, a comprehensive benchmark designed to assess the robustness of 3D detectors and segmentors against out-of-distribution scenarios and natural corruptions commonly encountered in real-world environments.  Our benchmark includes eight types of corruptions, ranging from severe weather conditions to external disturbances and internal sensor failure. Through our investigation, we discovered that despite the promising progress made on standard benchmarks, state-of-the-art 3D perception models are still vulnerable to corruptions. We identified several key factors, such as data representations, augmentation schemes, and training strategies, that can significantly impact the performance of these models.  To enhance the robustness of 3D perception models, we propose a density-insensitive training framework and a simple flexible voxelization strategy. These approaches aim to improve the resilience of the models against corruptions. We hope that our benchmark and proposed methods will inspire future research in the development of more robust and reliable 3D perception models. Our robustness benchmark suite is publicly available, providing a valuable resource for the research community.