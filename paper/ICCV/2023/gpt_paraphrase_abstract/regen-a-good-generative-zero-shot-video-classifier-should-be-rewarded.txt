This paper aims to address the problem of transforming a generative video captioning model into an open-world video/action classification model. While video captioning models can generate descriptive captions for videos, these captions may not be sufficiently discriminative for video/action recognition. When fine-tuned to generate class names directly, video captioning models tend to overfit to the base classes, losing their ability to generalize to unseen classes. To overcome this issue, we propose a novel framework called ReGen, which utilizes reinforcement learning to enhance the discriminative nature of the generated captions. ReGen incorporates three objectives and reward functions: (1) a class-level discrimination reward that ensures the generated caption is correctly classified into the corresponding action class, (2) a CLIP reward that encourages the caption to remain descriptive of the input video, and (3) a grammar reward that maintains the grammatical correctness of the caption. Our experiments demonstrate that ReGen effectively trains a model to generate captions that are discriminative, video-specific, and grammatically correct. Notably, when evaluated on standard benchmarks for zero- and few-shot action classification, ReGen outperforms the previous state-of-the-art models.