We introduce a humanoid controller for physics-based motion imitation and fault-tolerant behavior in the presence of noisy input and unexpected falls. Our controller can learn from a large number of motion clips without external stabilizing forces and can recover naturally from failed states. The progressive multiplicative control policy (PMCP) forms the foundation of our controller, allowing efficient scaling for learning from extensive motion databases and incorporating new tasks without forgetting previous ones. We validate the effectiveness of our controller by imitating poses obtained from video-based pose estimators and language-based motion generators in a real-time multi-person avatar scenario.