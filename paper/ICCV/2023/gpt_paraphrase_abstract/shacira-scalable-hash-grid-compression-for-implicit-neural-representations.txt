The use of Implicit Neural Representations (INR) or neural fields has become popular for encoding multimedia signals like images and radiance fields while maintaining high quality. A recent development by MÃ¼ller et al. introduced learnable feature grids, which improved the training and sampling speed of INRs by replacing a large neural network with a multi-resolution look-up table and a smaller neural network. However, these feature grids require a large amount of memory, which can be a limitation for storage and streaming applications. In this study, we propose SHACIRA, a task-agnostic framework for compressing feature grids without the need for additional pruning or quantization stages. We achieve compression by reparameterizing feature grids with quantized latent weights and applying entropy regularization in the latent space. Our approach achieves high levels of compression across various domains, as demonstrated by quantitative and qualitative results on different datasets including images, videos, and radiance fields. Importantly, our method outperforms existing INR approaches without relying on large datasets or domain-specific heuristics. More information about our project can be found at https://shacira.github.io.