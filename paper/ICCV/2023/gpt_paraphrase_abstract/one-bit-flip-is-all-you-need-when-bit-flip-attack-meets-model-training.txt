Researchers are increasingly concerned about the security of deep neural networks (DNNs) that are commonly used on real-world devices. A new attack called the bit flip attack (BFA) has been proposed, which takes advantage of memory fault inject techniques like row hammer to target quantized models during the deployment stage. By flipping just a few bits, the targeted model can become useless or even be manipulated with malicious intent. To further minimize the number of necessary bit flips, we introduce a training-assisted bit flip attack. In this attack, the adversary participates in the training stage to create a high-risk model that can be later released. When combined with a corresponding malicious model, this high-risk model appears normal and can avoid detection by various methods. Our experiments on benchmark datasets demonstrate that an attacker can easily convert the high-risk but normal model into a malicious one on the victim's side by flipping only one critical bit on average during deployment. Furthermore, our attack remains a significant threat even when defenses are implemented. The code for reproducing the main experiments can be found at https://github.com/jianshuod/TBA.