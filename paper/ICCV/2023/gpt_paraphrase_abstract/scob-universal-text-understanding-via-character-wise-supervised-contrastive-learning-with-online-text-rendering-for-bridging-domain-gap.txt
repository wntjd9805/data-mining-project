Recent studies in visual document understanding have explored language model (LM)-based pre-training methods for modeling text in document images. However, existing pre-training methods that read all text from an image show instability and fail in broader domains, such as visual documents and scene text images. This limitation hinders real-world scenarios where processing text image inputs in diverse domains is crucial. To address this, we propose a novel pre-training method called SCOB. SCOB utilizes character-wise supervised contrastive learning with online text rendering to effectively pre-train document and scene text domains, bridging the domain gap. Additionally, SCOB enables weakly supervised learning, reducing annotation costs. Extensive benchmarks demonstrate that SCOB improves vanilla pre-training methods and achieves comparable performance to state-of-the-art methods. Our findings suggest that SCOB can be used generally and effectively for read-type pre-training methods. The code for SCOB is available at https://github.com/naver-ai/scob.