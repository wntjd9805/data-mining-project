The study focuses on place recognition, which is an essential component of long-term SLAM (Simultaneous Localization and Mapping) systems. Current methods for place recognition using LiDAR-based point cloud representations have high retrieval recall rates but may suffer from decreased performance when there are changes in viewpoint or scene. The researchers propose using bird's eye view (BEV) images as an alternative representation for place recognition. They demonstrate that a network called simpleNetVLAD, trained on BEV images, achieves comparable performance to existing methods in scenes with slight viewpoint changes. To address robustness to view variations, they introduce a rotation-invariant network called BEVPlace, which utilizes group convolution to extract rotation-equivariant local features and NetVLAD for global feature aggregation. The researchers also discover a correlation between the distance of BEV features and the geometric distance of point clouds, leading to the development of a method to estimate the position of query point clouds, expanding the application of place recognition. Experimental results on large-scale public datasets demonstrate that their method achieves state-of-the-art performance in terms of recall rates, is robust to view changes, exhibits strong generalization ability, and can estimate the positions of query point clouds. The source codes for their method are publicly available at the provided GitHub link.