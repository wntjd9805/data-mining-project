In low-view settings, reconstructing 3D human heads poses challenges due to limited views and high-frequency signals, leading to the risk of overfitting. To overcome this, we propose a two-stage training strategy that involves geometry decomposition. This strategy enables the gradual capture of high-frequency geometric details. Our approach involves representing 3D human heads using a combined signed distance field, which includes a smooth template, a non-rigid deformation, and a high-frequency displacement field. The template captures features independent of identity and expression and is trained alongside the deformation network using sparse and randomly selected views from multiple individuals. The displacement field, which captures individual-specific details, undergoes separate training for each person. Importantly, our network training does not require 3D supervision or object masks. Experimental results demonstrate the effectiveness and robustness of our geometry decomposition and two-stage training strategy. Compared to existing neural rendering approaches, our method achieves superior reconstruction accuracy and novel view synthesis in low-view settings. Additionally, the pre-trained template serves as a good initialization for our model when encountering unseen individuals.