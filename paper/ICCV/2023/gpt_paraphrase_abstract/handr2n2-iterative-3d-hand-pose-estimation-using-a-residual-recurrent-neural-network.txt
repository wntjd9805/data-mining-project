The task of estimating 3D hand poses is important for various human-computer interaction applications. Many deep learning models have been developed for this task, but they often require complex architectures or redundant parameters to achieve satisfactory performance. To address this limitation, this paper introduces HandR2N2, a compact neural network that uses a novel residual recurrent unit to iteratively estimate hand poses. The recurrent design allows the network to gradually optimize previously estimated joint locations by recursively exploring partial layers. Additionally, the model incorporates graph reasoning to capture the kinematic dependencies between joints, leading to improved performance. Experimental results demonstrate that the proposed model outperforms existing methods in terms of accuracy and efficiency on three hand pose benchmark datasets. The code and pre-trained models are publicly available at https://github.com/cwc1260/HandR2N2.