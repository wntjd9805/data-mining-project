Calibration methods are often necessary to correct the over-confidence of neural networks trained on distilled data. However, existing calibration methods like temperature scaling and mixup are ineffective for networks trained on distilled data from large source datasets. This is because the concentrated distribution of maximum logits and the loss of semantically meaningful but unrelated information in the distilled data make these networks uncalibratable. To overcome this issue, we propose Masked Temperature Scaling (MTS) and Masked Distillation Training (MDT). These methods address the limitations of distilled data and improve calibration results while maintaining the efficiency of dataset distillation.