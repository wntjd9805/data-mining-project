Prompt learning is a useful method for refining foundational models like CLIP for various tasks. However, traditional prompt training using cross-entropy loss can cause prompts to overfit to specific tasks and struggle to capture general features from the original model. This limits the model's ability to generalize. To address this, we propose a self-regularization framework called PromptSRC. PromptSRC optimizes prompts for both task-specific and task-agnostic representations through three approaches: regulating prompted representations with the frozen model, using self-ensemble of prompts to leverage their complementary strengths, and incorporating textual diversity to address sample diversity imbalance. PromptSRC is the first regularization framework for prompt learning that avoids overfitting by considering pre-trained model features, the training trajectory, and textual diversity. It guides prompts to maximize performance on downstream tasks while preserving CLIP's generalization capability. We conducted extensive experiments on four benchmarks, and PromptSRC outperformed existing methods. Our code and pre-trained models are publicly available at [URL].