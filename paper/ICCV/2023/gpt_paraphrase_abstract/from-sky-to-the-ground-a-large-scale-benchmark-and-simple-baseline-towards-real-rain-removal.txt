Learning-based image deraining methods have made significant progress, but the lack of large-scale high-quality paired training samples is hindering the advancement of real image deraining (RID). To overcome this challenge and improve RID, we have created a benchmark dataset called LHP-Rain, which consists of 3000 video sequences with 1 million high-resolution frame pairs (1920*1080). This dataset offers several advantages over existing ones, including a wider range and larger quantity of rain patterns, higher-resolution images, and higher-quality ground truth. In LHP-Rain, we have included not only classical rain streaks/veiling/occlusion in the sky but also rain splashing on the ground, which has been overlooked by the deraining community. Additionally, we have developed a robust low-rank tensor recovery model to generate ground truth with better separation of the static background from the dynamic rain. Furthermore, we have designed a transformer-based single image deraining baseline that incorporates self-attention and cross-layer attention to achieve discriminative feature representation in both the image and rain layers. Extensive experiments demonstrate the superiority of our dataset and deraining method compared to state-of-the-art approaches.