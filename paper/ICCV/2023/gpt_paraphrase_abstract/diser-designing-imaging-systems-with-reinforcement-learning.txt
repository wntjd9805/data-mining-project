Designing imaging systems involves cameras that capture visual information and perception models that interpret this information. Cameras consist of illumination sources, optical elements, and sensors, while perception models rely on algorithms. However, searching for the optimal combination of these building blocks is challenging due to the large search space. Additionally, the independent design of cameras and perception models often results in sub-optimal performance.To address these issues, this paper presents a novel approach. The four building blocks of imaging systems are formulated as a context-free grammar (CFG), enabling automatic searching using a learned camera designer. This joint optimization of the imaging system and task-specific perception models is achieved by transforming the CFG into a state-action space. Reinforcement learning is then employed to intelligently explore the vast space of possible imaging system configurations.The effectiveness of this approach is demonstrated through two tasks: depth estimation and camera rig design for autonomous vehicles. The results show that the proposed method outperforms industry-wide standards, highlighting its potential in automating imaging system design. For further information, please visit our project page at https://tzofi.github.io/diser.