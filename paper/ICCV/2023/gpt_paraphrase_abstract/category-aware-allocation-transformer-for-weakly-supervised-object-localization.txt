This abstract discusses the problem of weakly supervised object localization (WSOL), which aims to localize objects in images using only image-level labels as supervision. Recently, transformers have been used in WSOL and have shown impressive results. Transformers use self-attention mechanisms and multilayer perceptron structures to capture long-range feature dependencies and accurately localize objects. However, current transformer-based methods predict bounding boxes using category-agnostic attention maps, which can result in confused and noisy object localization. To address this issue, the authors propose a novel approach called Category-aware AllocationTRansformer (CATR). CATR learns category-aware representations for specific objects and generates corresponding category-aware attention maps for object localization.   The authors introduce a Category-aware Stimulation Module (CSM) to induce learnable category biases in the self-attention maps, providing auxiliary supervision to improve the effectiveness of transformer representations. They also design an Object Constraint Module (OCM) to refine the object regions in a self-supervised manner for the category-aware attention maps. Experimental results on the CUB-200-2011 and ILSVRC datasets demonstrate that CATR outperforms competing approaches, achieving significant and consistent performance improvements.