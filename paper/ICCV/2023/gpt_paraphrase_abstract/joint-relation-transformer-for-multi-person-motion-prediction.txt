The problem of predicting the motion of multiple individuals is difficult because it relies on both the past movements of each individual and their interactions with others. Transformer-based methods have shown promise in addressing this problem, but they lack the explicit representation of the relationships between joints, such as the structure of the skeleton and the pairwise distance, which is crucial for accurately modeling interactions. This paper proposes a solution called the Joint-Relation Transformer, which incorporates relation information to improve interaction modeling and enhance future motion prediction. The relation information includes the relative distance between joints and the physical constraints within and between individuals. To combine the relation and joint information, a novel joint-relation fusion layer with relation-aware attention is designed to update both features. Additionally, the relation information is supervised by forecasting future distance. Experimental results demonstrate that the proposed method achieves significant improvements in motion prediction accuracy on various datasets. The code for the method is available at the provided GitHub repository.