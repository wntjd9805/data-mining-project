Contrastive learning (CL) has gained attention for its ability to achieve high accuracy without supervision. However, the behavior of CL remains largely unexplored. Instead of focusing on learning objectives like previous studies, we investigate the spatial inductive bias in CL, which appears to be implicitly utilized through data augmentations. To understand the reliance of CL on this bias, we conduct an experiment where we disrupt the global or local spatial structures of an image using patch shuffling. By comparing the performance drop between experiments on the original and corrupted datasets, we quantify the reliance on specific inductive biases. Additionally, we examine the uniformity of the feature space to analyze the behavior of CL-pretrained models with the corrupted dataset. Our findings reveal that CL has a significantly higher reliance on spatial inductive bias than supervised learning, regardless of the specific CL algorithm or backbones used. This opens up a new avenue for studying the behavior of CL.