This study explores the use of network pruning for image super-resolution (SR) to reduce memory usage and computational requirements. Existing SR models have limitations in terms of memory footprint and intensive computations, hindering their deployment on edge devices. The main challenges in applying pruning methods for SR are the limited granularity and adaptability of filter pruning techniques, as well as the reliance on pre-trained networks in traditional SR approaches. To address these challenges, the study proposes a novel Iterative Soft Shrinkage-Percentage (ISS-P) method that directly trains sparse models from scratch using unstructured pruning. The ISS-P method optimizes the sparse structure of a randomly initialized network at each iteration and adjusts unimportant weights proportionally to their magnitude scale. This approach allows the sparse structures to adapt to the optimization process and maintains the trainability of the sparse model. Experimental results on benchmark datasets demonstrate the effectiveness of the proposed ISS-P method across various network architectures. The code for implementing the ISS-P method is available at https://github.com/Jiamian-Wang/Iterative-Soft-Shrinkage-SR.