The domain gap between synthetic and real data has been a major challenge in image deraining, making it difficult to remove rain from real images. Additionally, the lack of diverse and labeled real rain images has hindered progress in this field. In this study, we propose a new approach called the Physical Alignment and Controllable Generation Network (PCGNet) to address these challenges. Our method focuses on generating diverse and realistic rain images by combining the controllability of attributes from synthetic data and the realism of appearance from real data. We achieve this by disentangling the background, rain attributes, and appearance style from both synthetic and real data, and then aligning them using a novel weight moving strategy and a distribution modeling method. These aligned factors are incorporated into the generation model, allowing for a physical controllable mapping of attributes to real rain. Our experiments demonstrate that PCGNet can generate visually appealing rainy results, significantly improving the performance of existing deraining methods on both synthetic and real scenes.