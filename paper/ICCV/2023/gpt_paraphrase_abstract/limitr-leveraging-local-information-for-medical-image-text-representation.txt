Medical imaging analysis plays a crucial role in the diagnosis and treatment of various medical conditions. This study focuses on the analysis of chest X-ray images and their corresponding radiological reports. A novel model is proposed that learns a combined representation of X-ray images and textual reports. The model utilizes a unique alignment scheme that considers both local and global information, effectively integrating domain-specific information such as lateral images and consistent visual structures in chest images. Experimental results demonstrate the advantages of our representation in three retrieval tasks: text-image retrieval, class-based retrieval, and phrase-grounding. The code for our model is publicly accessible.