Physical adversarial attacks on deep neural networks (DNNs) have gained attention recently. Existing physical attacks involve using printed adversarial patches or camouflage to change the appearance of the target object. However, these methods produce noticeable adversarial patterns that lack stealthiness. Another physical attack method is optical attack, which offers better stealthiness but is weak during the daytime with sunlight. This paper introduces a new approach called the Reflected Light Attack (RFLA), which is effective and stealthy in both the digital and physical worlds. RFLA is implemented by placing a color transparent plastic sheet and a paper cutout of a specific shape in front of a mirror to create different colored geometries on the target object. The authors develop a framework using circles to model the reflected light on the target object. A circle, composed of a coordinate and radius, is optimized to represent various geometrical shapes based on the optimized angle. The fill color and transparency of the geometry shape are also optimized. The effectiveness of RFLA is extensively evaluated on different datasets and models, achieving a success rate of over 99% in the digital world. The proposed method is also tested in various physical environments using sunlight or a flashlight to verify its effectiveness.