Recent advancements in video instance segmentation (VIS) have led to impressive results using both offline and online methods. Offline methods offer temporally consistent predictions but are not suitable for real-time applications. On the other hand, online methods are more practical but struggle to maintain temporal consistency. This paper introduces a new online method called TCOVIS that effectively utilizes temporal information in video clips. TCOVIS employs a global instance assignment strategy and a spatio-temporal enhancement module to improve temporal consistency. To achieve this, the method performs optimal matching between predictions and ground truth across the entire video clip and utilizes the global optimal objective for model supervision. Additionally, TCOVIS captures spatial features and combines them with semantic features between frames, resulting in spatio-temporal enhancement. The proposed method is evaluated on four widely-used VIS benchmarks, namely YouTube-VIS 2019/2021/2022 and OVIS, and achieves state-of-the-art performance without any additional techniques. For example, on YouTube-VIS 2021, TCOVIS attains 49.5 AP and 61.3 AP using ResNet-50 and Swin-L backbones, respectively. The code for TCOVIS is available at https://github.com/jun-long-li/TCOVIS.