We introduce AdVerb, a novel audio-visual dereverberation framework that incorporates visual cues to estimate clean audio. While audio-only dereverberation is well-studied, our approach leverages the visual modality to enhance audio quality. By utilizing an image of the environment where the reverberated sound was recorded, AdVerb utilizes a unique geometry-aware cross-modal transformer architecture that captures the scene's geometry and audio-visual relationship. This architecture generates a complex ideal ratio mask, which, when applied to the reverberant audio, predicts the clean sound. Our method is shown to be highly effective through extensive quantitative and qualitative evaluations. Compared to traditional audio-only and audio-visual baselines, our approach significantly outperforms them across three downstream tasks: speech enhancement, speech recognition, and speaker verification. On the LibriSpeech test-clean set, we achieve relative improvements ranging from 18% to 82%. Additionally, we achieve highly satisfactory RT60 error scores on the AVSpeech dataset.