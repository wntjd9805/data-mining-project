Boundary localization is a difficult problem in Temporal Action Detection (TAD) due to two main challenges. Firstly, the movement feature in a video snippet is often overshadowed by the scene information. Secondly, the scale of action segments varies significantly throughout the video. To address these challenges, we propose two modules: the Movement Enhance Module (MEM) and the Scale Feature Pyramid Network (SFPN).   The MEM is designed to highlight the movement feature for better action localization. It consists of a Movement Feature Extractor (MFE) that extracts the movement feature, and a Multi-Relation Enhance Module (MREM) that captures valuable information correlations both locally and temporally.  The SFPN is designed to detect actions at multiple scales in videos. It includes a U-Shape Module that models different scale actions. Additionally, we develop a training and inference strategy to ensure that each pyramid layer is responsible only for actions at a specific scale.  We integrate these two modules into the Movement Enhance Network (MENet) and evaluate its performance on two challenging benchmarks: ActivityNet-1.3 and THUMOS-14. Our experiments demonstrate that MENet outperforms other representative TAD methods in terms of effectiveness.  In conclusion, our proposed MENet, which combines the MEM and SFPN modules, effectively addresses the challenges of boundary localization in TAD. It achieves superior performance compared to other methods on ActivityNet-1.3 and THUMOS-14 benchmarks.