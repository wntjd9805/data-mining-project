In contrastive self-supervised learning, the typical approach to learning discriminative representation involves bringing different augmented views of the same image closer together while pushing all other images apart. This method has been proven effective. However, this approach often results in undesirable views that contain different semantic concepts during the augmentation process. This compromises the semantic consistency of the representation when these augmentations are indiscriminately pulled closer in the feature space. To address this issue, we propose a novel method called semantics-consistent feature search (SCFS) that incorporates feature-level augmentation. The main idea behind SCFS is to adaptively search for features that are semantically consistent, thereby enhancing the contrast between semantically consistent regions in different augmentations. By doing so, the trained model can focus on meaningful object regions and improve its ability to represent semantics. Extensive experiments conducted on various datasets and tasks demonstrate that SCFS effectively enhances the performance of self-supervised learning, achieving state-of-the-art results in downstream tasks.