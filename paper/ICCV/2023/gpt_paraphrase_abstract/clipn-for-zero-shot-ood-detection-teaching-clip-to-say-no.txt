Out-of-distribution (OOD) detection involves training a model on an in-distribution (ID) dataset to determine if input images come from unknown classes. While there have been many OOD detection methods based on convolutional neural networks or transformers, there has been less focus on zero-shot OOD detection methods using CLIP, which only requires class names for the ID dataset. This paper introduces a new method called CLIP saying "no" (CLIPN) that enhances CLIP's ability to differentiate between OOD and ID samples using positive-semantic and negation-semantic prompts. The authors design a learnable "no" prompt and a "no" text encoder to capture negation semantics in images. They also propose two loss functions to teach CLIPN to associate images with "no" prompts, enabling it to identify unknown samples. Additionally, they propose threshold-free inference algorithms that utilize negation semantics and the text encoder for OOD detection. Experimental results on nine benchmark datasets demonstrate that CLIPN outperforms seven well-used algorithms in terms of AUROC and FPR95 for zero-shot OOD detection. The authors provide their CLIPN code on GitHub and suggest that it can be used as a foundation for leveraging CLIP in downstream OOD tasks.