We question the current evaluation methods for diffusion-based purification techniques. These methods aim to eliminate the negative effects of adversarial inputs during testing. They are gaining attention as an alternative to adversarial training because they separate the training and testing phases. However, the commonly used white-box attacks may not be the most effective for evaluating diffusion-based purification methods as they are designed for adversarial training. We analyze the current evaluation practices and suggest a new guideline for measuring the effectiveness of purification methods against adversarial attacks. Based on our analysis, we propose a new purification strategy that improves robustness compared to existing diffusion-based purification methods.