This study focuses on improving two key components, flow-based propagation and spatiotemporal Transformer, in video inpainting (VI) techniques. While these components have proven effective, they have limitations that hinder their performance. Previous approaches either performed propagation in the image or feature domain separately, leading to spatial misalignment or limited temporal range of feature propagation. To address these issues, the authors propose an enhanced framework called ProPainter. This framework introduces dual-domain propagation, combining image and feature warping to ensure accurate global correspondences. Additionally, a mask-guided sparse video Transformer is proposed to improve efficiency by discarding unnecessary tokens. ProPainter achieves significantly better results compared to previous methods, with a 1.46 dB improvement in PSNR while maintaining high efficiency.