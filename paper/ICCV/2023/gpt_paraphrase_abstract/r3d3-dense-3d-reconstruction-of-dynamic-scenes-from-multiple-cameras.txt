We propose R3D3, a multi-camera system for dense 3D reconstruction and ego-motion estimation in autonomous driving and robotics. Compared to complex, expensive systems, our approach offers a simpler and low-cost alternative. Existing camera-based 3D reconstruction methods struggle with complex dynamic scenes, often producing incomplete or inconsistent results. To address this, our system combines geometric estimation using spatial-temporal information from multiple cameras with monocular depth refinement. By integrating multi-camera feature correlation and dense bundle adjustment operators, we obtain reliable geometric depth and pose estimates. Additionally, we introduce learnable scene priors through a depth refinement network to improve reconstruction in challenging scenarios such as moving objects or low-textured regions. Our approach achieves dense and consistent 3D reconstruction in dynamic outdoor environments, surpassing the state-of-the-art performance on DDAD and NuScenes benchmarks.