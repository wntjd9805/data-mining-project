Mitochondria are important structures in cells that play a crucial role in studying cell functions. Automatic segmentation of mitochondria in electron microscopy (EM) images has become a topic of interest. However, existing methods face challenges in adapting to different scales and appearances of the input due to limitations in traditional CNN architecture. To address these limitations, we propose a new method called adaptive template transformer (ATFormer) for mitochondria segmentation. The ATFormer model has several advantages. Firstly, it utilizes a structural template learning module to acquire appearance-adaptive templates for different shapes of mitochondria. An optimal transport algorithm is then used to enhance the differences among these templates, activating corresponding regions more effectively. Secondly, a hierarchical attention learning mechanism is introduced to incorporate multi-level information, allowing the templates to be adaptive scale-aware classifiers for dense prediction. Extensive experiments on challenging benchmarks demonstrate that our ATFormer outperforms state-of-the-art methods in mitochondria segmentation. The proposed method utilizes learnable vectors as adaptive templates, which interact with multi-scale features to aggregate structure-aware information. These templates serve as appearance-adaptive scale-aware classifiers, generating more accurate activation for mitochondria of varying scales.