Domain adaptation (DA) is a technique that aims to transfer knowledge from a source domain, which has abundant labeled data, to a target domain, which has limited labeled data. Recent research has focused on analyzing the data structure of the target domain. We attempted to apply the Instance Discrimination Contrastive (IDCo) loss, which has been successful in self-supervised learning, directly to domain adaptation tasks. However, we found that the improvement was minimal, leading us to reconsider the limitations of IDCo loss for domain adaptation tasks.One limitation we identified is that IDCo loss may treat samples belonging to the same class as negatives. To address this, we propose using low-confidence samples to construct positive and negative pairs, which can mitigate this issue and better suit IDCo loss. Another limitation is that IDCo loss does not capture sufficient semantic information. To overcome this, we introduce domain-invariant and accurate semantic information from classifier weights and input data. We propose a feature enhancement technique called class relationship enhanced features, which uses probability-weighted class prototypes as input features for IDCo loss. This implicitly transfers the domain-invariant class relationship. Additionally, we propose a target-dominated cross-domain mixup method that incorporates accurate semantic information from the source domain.We evaluate our proposed method in unsupervised domain adaptation and other domain adaptation settings. Extensive experimental results demonstrate that our method enhances the effectiveness of IDCo loss and achieves state-of-the-art performance.