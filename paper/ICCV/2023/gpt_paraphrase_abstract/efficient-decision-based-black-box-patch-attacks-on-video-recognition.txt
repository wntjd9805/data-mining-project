The vulnerability of Deep Neural Networks (DNNs) to adversarial patches in input has been well-documented, but most research has focused on images rather than videos. Additionally, decision-based attacks, where attackers only have access to predicted labels, have not been thoroughly explored in the context of video models. This lack of study creates a gap in assessing the robustness of video models. To address this gap, this research investigates decision-based patch attacks on video models. The analysis reveals that the large parameter space of videos and limited information provided by decision-based models pose significant challenges and query burdens for attacks. To overcome these challenges, a spatial-temporal differential evolution (STDE) framework is proposed. STDE utilizes target videos as patch textures and selectively adds patches to keyframes based on temporal difference. The optimization objective is to minimize patch area, and spatial-temporal mutation and crossover are employed to find the global optimum. Experimental results demonstrate that STDE achieves superior performance in terms of threat, efficiency, and imperceptibility. As a result, STDE has the potential to serve as a valuable tool for evaluating the robustness of video recognition models.