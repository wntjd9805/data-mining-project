We introduce RANA, an advanced neural avatar that can generate realistic human images from various perspectives, poses, and lighting conditions. With just a short video clip of a person, RANA is able to create an avatar without any prior knowledge of the lighting environment. Our innovative framework disentangles the person's geometry, texture, and lighting from monocular RGB videos, making the otherwise complex task more manageable. Initially, RANA estimates the rough geometry and texture of the person using the SMPL+D model fitting. Then, it learns an articulated neural representation to produce higher quality image synthesis. RANA first generates normal and albedo maps to match the target body pose, and then applies spherical harmonics lighting to create the shaded image in the desired lighting environment. To enhance the performance, we propose pre-training RANA using synthetic images, which improves the separation between geometry and texture and enhances the robustness to new body poses. Additionally, we introduce a new synthetic dataset called Relighting Human for quantitative evaluation of our approach.