This paper introduces a novel approach to address the issue of entangled feature spaces in Generative Adversarial Networks (GANs), specifically in the context of image generation. While GANs can generate photo-realistic images, it is challenging to interpret and control the specific contents of these images. To tackle this problem, the authors propose an encoder-decoder model that decomposes the GAN space into a hierarchical latent space. They leverage 3D morphable face models to independently control parameters such as pose, expression, and illumination in the image synthesis process. This is achieved through a new latent space decomposition pipeline using transformer networks and generative models. The resulting decomposed space is then utilized to optimize a transformer-based GAN space controller for face editing. The authors use a StyleGAN2 model for faces, ensuring the preservation of photo-realism. Experimental results demonstrate that their method outperforms previous approaches in terms of identity preservation and editing precision, both qualitatively and quantitatively.