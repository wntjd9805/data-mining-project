The goal of dubbed video generation is to accurately synchronize the mouth movements of a facial video with the corresponding audio, while also preserving the identity of the person and the specific visual elements of the scene. Previous approaches have been successful in generating realistic lip movements by using a pre-trained audio-video synchronization metric called Sync-Loss. However, extending this to high-resolution videos has been challenging due to biases in the loss landscape that hinder the optimization of both Sync-Loss and visual quality, resulting in a loss of detail.To overcome this issue, we propose a shift-invariant learning approach that can generate high-resolution videos with realistic lip movements. Additionally, we utilize a pyramid network that generates images in a coarse-to-fine manner, which improves stability and lip synchronization. Our model surpasses state-of-the-art methods on various benchmark datasets, demonstrating its effectiveness in achieving accurate Lip-Sync while maintaining photo-realism and identity preservation.