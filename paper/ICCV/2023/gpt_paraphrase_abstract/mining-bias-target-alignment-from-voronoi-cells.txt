This study addresses the issue of biases in deep neural networks and their implications on fairness and generalization. Despite previous research efforts, biases persist in these networks, limiting their performance. The paper introduces a novel bias-agnostic approach to mitigate the impact of biases. Unlike traditional methods, this approach utilizes a metric to quantify bias alignment or misalignment on target classes. By leveraging this information, the proposed method discourages the propagation of bias-target alignment through the network. The researchers conducted experiments on commonly used datasets to compare this method with supervised and bias-specific approaches. The findings demonstrate that the proposed bias-agnostic method achieves comparable performance to state-of-the-art supervised approaches, even in scenarios with multiple biases within the same sample.