We propose a framework for efficient image coding using compressive autoencoders (CAEs) in deep learning. This addresses the computational expense of large-scale CAEs. Our framework employs three techniques. Firstly, spatially-adaptive convolution and normalization operators enable a block-wise nonlinear transform that allocates computational resources unevenly across the image based on a transform capacity map. Secondly, the just-unpenalized model capacity (JUMC) optimizes the transform capacity of each CAE block through rate-distortion-complexity optimization, determining the optimal capacity for the content of the source image. Lastly, a lightweight routing agent model predicts the transform capacity map for the CAEs by approximating JUMC targets. By activating the most suitable sub-CAE within the slimmable supernet, our approach achieves a computational speed-up of up to 40% with minimal increase in BD-Rate. This validates the ability of our approach to save computational resources in a content-aware manner.