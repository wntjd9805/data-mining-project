Visual Emotion Analysis (VEA) is a challenging task in affective computing that aims to predict people's emotional responses to visual stimuli. While previous research has focused on feature design, little attention has been given to dataset construction. To address this gap, we introduce EmoSet, a large-scale visual emotion dataset that stands out from existing datasets in terms of scale, annotation richness, diversity, and data balance. EmoSet consists of a total of 3.3 million images, with 118,102 of them meticulously annotated by human annotators, making it five times larger than the largest existing dataset. It encompasses images from social networks and artistic sources, maintaining a well-balanced representation of different emotion categories. In line with psychological studies, each image in EmoSet is annotated with a set of describable emotion attributes, including brightness, colorfulness, scene type, object class, facial expression, and human action. These attributes provide a precise and interpretable understanding of visual emotions. The relevance of these emotion attributes is confirmed through correlation analysis with visual emotion and the development of an attribute module, which aids in visual emotion recognition. We anticipate that EmoSet will offer valuable insights and encourage further research in the field of visual emotion analysis and understanding.