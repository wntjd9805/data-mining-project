Amodal segmentation in computer vision is a challenging task that involves inferring the complete shape of an object based on only its visible parts. Previous studies have used motion flow to integrate information across frames, but this approach has limitations when it comes to moving cameras and object deformation. In this paper, we propose a new approach called Efficient object-centric Representation amodal Segmentation (EoRaS) that leverages supervised signals and object-centric representation in real-world scenarios. We introduce a translation module to project image features into a Bird's-Eye View (BEV), which provides 3D information and improves feature quality. Additionally, we propose a multi-view fusion layer based temporal module that interacts with features from different views using attention mechanism to enhance object representation. Our method achieves state-of-the-art performance on both real-world and synthetic benchmarks. The code for our method is available at https://github.com/kfan21/EoRaS.