Motion deblurring from a blurred image is a challenging problem in computer vision due to the loss of information during the blurring process. Previous attempts to compensate for this loss have used event cameras, which have high temporal resolution. However, most studies assume pixel-wise alignment between image and event data, which is only possible with low-quality active-pixel sensor (APS) images and synthetic datasets. In real scenarios, aligning event-RGB data on a per-pixel basis is technically difficult as event and frame cameras have different optical axes. In this paper, we propose the Non-coaxial Event-guided Image Deblurring (NEID) approach, which uses a standard frame-based camera with a non-coaxial event camera. To achieve per-pixel alignment without additional devices, we introduce the NEID network, which aligns events to images and refines image features using temporally dense event features. We also present the first large-scale dataset of RGB frames with non-aligned events, specifically designed for motion deblurring with event cameras. Extensive experiments demonstrate that our method outperforms previous works in terms of performance and speed, making it suitable for practical applications of event cameras.