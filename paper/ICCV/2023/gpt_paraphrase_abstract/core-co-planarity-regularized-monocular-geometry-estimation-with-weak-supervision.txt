Monocular 3D geometry estimation, specifically the estimation of depth maps and surface normals, is challenging due to its ill-posed nature. Data-driven approaches, such as Deep Neural Networks (DNN), are commonly used to tackle this problem. However, acquiring reliable surface normals is difficult and time-consuming, leading to a heavy reliance on ground-truth normals for accurate predictions. In this study, we propose two designs: CO-planarity REgularized (CORE) loss functions and Structure-Aware Normal Estimator (SANE), which aim to minimize the dependency on ground-truth normals.  Our CORE loss functions utilize locally linear depth-normal orthogonality as pixel-level constraints under spherical coordinates. Additionally, we introduce Adaptive Polar Regularization (APR) to deal with numerical degeneracies. SANE enables multi-task learning with CORE loss functions for both depth and surface normal estimation, resulting in improved overall performance.   Extensive experiments demonstrate the effectiveness of our method on various DNN architectures and data benchmarks. Our depth estimation achieves state-of-the-art performance on indoor scenes and comparable performance on outdoor scenes across all metrics. Moreover, our surface normal estimation outperforms existing methods.