Backdoor attacks on deep neural networks (DNNs) have become a significant security concern. These attacks manipulate the model to output a specific result when a trigger is present, while behaving normally on benign samples. Existing defenses against backdoor attacks are ineffective or require access to benign samples, which may not be available in real-world scenarios. In this paper, we propose a novel dual-network training framework called The Victim and The Beneficiary (V&B). The V&B framework distinguishes between poisoned and benign samples using prediction entropy. It trains a powerful poisoned sample detector (Victim network) on suspicious samples and a clean model (Beneficiary network) on credible samples selected by the Victim. The framework also incorporates a semi-supervised suppression strategy to remove potential backdoors and improve model performance. To further prevent missed poisoned samples, we introduce a strong data augmentation method called AttentionMix, which complements the V&B framework. Extensive experiments on popular datasets against six state-of-the-art attacks demonstrate the effectiveness and robustness of our framework in preventing backdoor injection while maintaining performance on benign samples. The code for our framework is available at https://github.com/Zixuan-Zhu/VaB.