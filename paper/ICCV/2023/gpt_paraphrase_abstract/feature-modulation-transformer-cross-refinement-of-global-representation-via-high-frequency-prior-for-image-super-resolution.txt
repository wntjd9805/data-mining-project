Transformer-based methods have shown great promise in single image super-resolution (SISR) by effectively capturing long-range dependencies. However, current research has primarily focused on designing transformer blocks for global information extraction, neglecting the importance of incorporating high-frequency priors. We conducted experiments and discovered that transformer structures excel in capturing low-frequency information but have limited capacity in constructing high-frequency representations compared to convolutional counterparts. To address this, we propose the cross-refinement adaptive feature modulation transformer (CRAFT), which combines the strengths of both convolutional and transformer structures. CRAFT consists of three main components: the high-frequency enhancement residual block (HFERB) for extracting high-frequency information, the shift rectangle window attention block (SRWAB) for capturing global information, and the hybrid fusion block (HFB) for refining the global representation. Our experiments on various datasets demonstrate that CRAFT outperforms state-of-the-art methods by up to 0.29dB while utilizing fewer parameters. The source code can be accessed at the following link: https://github.com/AVC2-UESTC/CRAFT-SR.git.