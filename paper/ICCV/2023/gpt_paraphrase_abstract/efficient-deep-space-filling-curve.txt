Space-filling curves (SFCs) are commonly used in computer vision for tasks like data compression and hashing. Currently, the search for an optimal SFC is approached by finding a Hamiltonian circuit on the image grid graph. Existing methods use graph neural networks (GNN) to predict edge weights and generate a minimum spanning tree (MST) to construct the SFC. However, GNN-based methods are computationally expensive and memory-intensive. Additionally, MST generation is not differentiable, making it impractical for optimization through gradient descent. To address these challenges, we propose a GNN-based SFC-search framework with a tailored algorithm that significantly reduces computational costs. Furthermore, we introduce a siamese network learning scheme to optimize DNN-based models in an end-to-end manner. Extensive experiments demonstrate that our method outperforms both DNN-based methods and traditional SFCs, such as the Hilbert curve, across various benchmarks.