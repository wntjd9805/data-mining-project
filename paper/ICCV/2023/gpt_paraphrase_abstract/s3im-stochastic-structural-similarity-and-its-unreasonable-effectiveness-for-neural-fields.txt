We propose a new training paradigm for Neural Radiance Field (NeRF) and other neural field methods that takes into account the structural information provided by distant pixels. Previous research in this area has focused on optimizing point-wise predictions, but failed to utilize the collective supervision of pixels. We introduce a nonlocal multiplex training approach using a novel Stochastic Structural SIMilarity (S3IM) loss, which processes multiple data points as a whole set instead of independently. Our experiments demonstrate that S3IM significantly improves the performance of NeRF and neural surface representation. Quality metrics show notable improvements, particularly in challenging tasks such as novel view synthesis and surface reconstruction. For example, the test MSE loss decreases by 90% for TensoRF and DVGO, while NeuS achieves a 198% gain in F-score and a 64% reduction in Chamfer L1 distance. Additionally, S3IM remains robust even with sparse inputs, corrupted images, and dynamic scenes.