Pre-training is an effective strategy for improving visual models by training them with a limited number of labeled images. However, creating annotation masks for semantic segmentation requires a significant amount of labor and time, making it difficult to construct large-scale pre-training datasets with semantic labels. Additionally, the key factors for successful pre-training in semantic segmentation have not been fully explored. To address these challenges, this study introduces the Segmentation Radial Contour DataBase (SegRCDB), which applies formula-driven supervised learning for semantic segmentation for the first time. Unlike traditional methods, SegRCDB allows pre-training without real images or manual semantic labels. By leveraging insights into important pre-training elements for semantic segmentation, SegRCDB enables efficient pre-training. Experimental results demonstrate that pre-training with SegRCDB outperforms pre-training with COCO-Stuff in terms of mean intersection over union (mIoU) when fine-tuning on ADE-20k and Cityscapes datasets using the same number of training images. Furthermore, SegRCDB has the potential to significantly contribute to semantic segmentation pre-training and research by enabling the creation of large datasets without manual annotation. The SegRCDB dataset will be made available under a license that permits research and commercial use. The code for SegRCDB is accessible at: https://github.com/dahlian00/SegRCDB.