Implicit neural rendering has been successful in reconstructing large-scale scenes using signed distance function (SDF) representation with geometric priors. However, when applied to room-level scenes, this method may overlook structures in low-intensity areas and small, thin objects. Our experiments on three datasets have revealed limitations in the original color rendering loss and priors-embedded SDF scene representation. We have observed that the color rendering loss introduces optimization bias against low-intensity areas, leading to gradient vanishing and neglecting these regions. To address this issue, we propose a feature-based color rendering loss that utilizes non-zero feature values to reintroduce optimization signals. In addition, the SDF representation can be affected by objects along a ray path, causing disruptions in the monotonic change of SDF values when a single object is present. As a solution, we explore the use of the occupancy representation, which encodes each point individually and remains unaffected by objects along a querying ray. Through our experiments, we demonstrate that combining the feature-based rendering loss and the Occ-SDF hybrid representation scheme yields high-quality reconstruction results, particularly in challenging room-level scenarios. The code for our proposed method is available at https://github.com/shawLyu/Occ-SDF-Hybrid.