Input attribution is a popular technique for explaining deep neural networks in visual tasks. Integrated Gradients (IG) is a commonly used method due to its versatility and desirable properties. However, previous studies have revealed that IG can produce noisy and unreliable attributions when integrating gradients along the input space path. To address this issue, we propose estimating the distribution of possible attributions based on the selected integration path. We demonstrate that aggregating attributions from multiple paths instead of a single path can reduce noise. Drawing inspiration from the Stick-Breaking Process, we introduce a random process to generate diverse gradient integration paths. By obtaining multiple input attributions using randomized paths, we propose a novel attribution measure that utilizes the distribution of attributions at each input feature. Through qualitative evaluations, we observe that our method produces less noisy and object-aligned attributions. Furthermore, we assess its feasibility through quantitative evaluations.