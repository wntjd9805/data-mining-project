This study examines the use of Semantic information in Contrastive Learning (SemCL). A novel pretext task is proposed, where a contrast is made between objects and their environments in images. This allows the SemCL pretrained model to better understand the spatial relationship between objects and their surroundings. Several downstream tasks, including semantic/instance segmentation, object detection, and depth estimation, are conducted on various datasets such as PASCAl VOC, Cityscapes, COCO, KITTI, etc. The SemCL pretrained models outperform ImageNet pretrained models and demonstrate competitiveness with other well-known approaches in these tasks. These findings indicate that leveraging semantic information through a dedicated pretext task can yield significant improvements in spatial understanding benchmarks. The code for this work is available at https://github.com/sjiang95/semcl.