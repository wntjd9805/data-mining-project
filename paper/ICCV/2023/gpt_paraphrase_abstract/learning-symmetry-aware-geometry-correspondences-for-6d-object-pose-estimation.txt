Current methods for estimating the 6D pose of objects focus on objects that have been previously trained, limiting their use in dynamic real-world scenarios. In this study, we propose a framework called GCPose that can estimate the 6D pose of any unseen object without the need for re-training. Our method is based on geometry correspondence and utilizes object-agnostic geometry features to establish correspondences between the object-scene point cloud and object-model point cloud. We then solve for the 6D pose parameters using a least-squares fitting algorithm. To account for the symmetry of objects, we introduce a symmetry-aware matching loss that improves the learning of dense point-wise geometry features and enhances performance. We also employ online training data generation with special data augmentation and normalization techniques to enable the network to learn diverse geometry prior. By training on synthetic objects from ShapeNet, our method significantly outperforms previous approaches for unseen object pose estimation on various datasets. The code for our method is available at https://github.com/hikvision-research/GCPose.