Current multi-person mesh recovery methods struggle to accurately capture body poses and shapes in large-scale crowded scenes due to issues like mutual occlusion, severe scale variation, and complex spatial distribution. To overcome these challenges, we propose a novel approach that leverages crowd features to reconstruct groups of people from a single image. Our method utilizes a hypergraph relational reasoning network to capture complex and high-order relation correlations among individuals and groups within the crowd. Initially, we extract compact human features and location information from the original high-resolution image. By applying relational reasoning to these features, we can uncover the collective behavior and interaction patterns within the crowd, providing valuable group information for the reconstruction process. Subsequently, we use the updated individual features and localization information to regress human meshes in camera coordinates. To facilitate network training, we create pseudo ground-truth data for two crowd datasets, which can also serve as a resource for future research in pose estimation and human behavior understanding in crowded scenes. Experimental results demonstrate that our approach outperforms baseline methods in both crowded and common scenarios. We have made the code and datasets publicly available for further exploration.