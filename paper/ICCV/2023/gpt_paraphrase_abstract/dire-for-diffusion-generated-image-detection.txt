This study focuses on the development of a detector that can distinguish between real images and images generated by diffusion models. Existing detectors struggle to accurately identify images generated by diffusion models, even when trained with such images. To address this issue, the researchers propose a new image representation called DIffusion ReconstructionError (DIRE). DIRE measures the error between an input image and its reconstruction using a pre-trained diffusion model. It is observed that diffusion-generated images can be reconstructed by a diffusion model, while real images cannot. This observation suggests that DIRE can be used to distinguish between generated and real images. DIRE proves to be an effective method for detecting images generated by most diffusion models and is robust against various perturbations. The researchers also establish a benchmark dataset consisting of images generated by different diffusion models to evaluate the performance of diffusion-generated image detectors. Extensive experiments on this benchmark demonstrate that DIRE outperforms previous detectors. The code, models, and dataset used in this study are available at https://github.com/ZhendongWang6/DIRE.