This paper introduces a novel approach, called the multi-frequency representation enhancement module (MFE), to address the limitation of CNN in capturing long-range spatial-temporal dependencies in video super-resolution (VSR). The MFE module performs spatial-temporal information aggregation in the frequency domain. It consists of a spatial-frequency representation enhancement branch, which captures the long-range dependency in the spatial dimension, and an energy frequency representation enhancement branch, which obtains the inter-channel feature relationship. Additionally, the paper proposes a model training method called privilege training, which encodes privilege information from high-resolution videos to improve model training. By combining these two methods, a new VSR model called MFPI is introduced. The MFPI model outperforms existing methods by a significant margin while maintaining good efficiency on various datasets, including REDS4, Vimeo, Vid4, and UDM10.