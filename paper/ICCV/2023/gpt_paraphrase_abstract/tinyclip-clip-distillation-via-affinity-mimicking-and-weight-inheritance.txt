This paper introduces a new method called TinyCLIP for training large-scale language-image models. The method incorporates two key techniques: affinity mimicking and weight inheritance. Affinity mimicking allows student models to mimic the behavior of teacher models in learning cross-modal feature alignment. Weight inheritance transfers pre-trained weights from teacher models to their student counterparts, improving the efficiency of the distillation process. The method also includes a multi-stage progressive distillation to mitigate the loss of informative weights during extreme compression. Experimental results demonstrate that TinyCLIP can reduce the size of pre-trained models while maintaining comparable performance. Distillation with weight inheritance also speeds up training compared to training from scratch. TinyCLIP achieves impressive zero-shot performance on ImageNet and shows good transferability in downstream tasks. The code and models will be made available at aka.ms/tinyclip.