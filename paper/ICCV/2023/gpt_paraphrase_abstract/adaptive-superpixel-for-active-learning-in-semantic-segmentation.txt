We propose a cost-effective approach for learning semantic segmentation by using superpixels instead of pixel-wise annotations. Our method involves adaptive superpixel merging and querying selected superpixels using an acquisition function. This approach is more efficient compared to existing methods that rely on innate features and assume uniform superpixel sizes. While obtaining a dominant label per superpixel reduces annotation burden, it introduces noisy annotations. To address this, we implement a sieving mechanism to exclude potentially noisy annotations. Experimental results on Cityscapes and PAS-CAL VOC datasets validate the effectiveness of our approach.