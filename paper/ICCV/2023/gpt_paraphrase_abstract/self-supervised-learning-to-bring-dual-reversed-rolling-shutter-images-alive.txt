Modern consumer cameras commonly use a rolling shutter mechanism, which captures images by scanning scenes row-by-row. This approach can result in rolling shutter distortions, especially for dynamic scenes. Existing methods for correcting these distortions rely on fully supervised learning, where high framerate global shutter (GS) images are needed as ground-truth supervision. In this paper, we propose a self-supervised learning framework called SelfDRSC for correcting dual reversed rolling shutter distortions. Our approach trains a DRSC network to generate a high framerate GS video using only dual RS images with reversed distortions. We introduce a bidirectional distortion warping module to reconstruct the dual reversed RS images and use a self-supervised loss to enhance the cycle consistency between the input and reconstructed images. Our framework also allows for the supervision of GS images at arbitrary intermediate scanning times, enabling the learned DRSC network to generate a high framerate GS video. Additionally, we introduce a self-distillation strategy in the self-supervised loss to mitigate boundary artifacts in the generated GS images. Experimental results show that SelfDRSC achieves comparable or better quantitative metrics than state-of-the-art methods trained with full supervision on synthetic datasets. Furthermore, our SelfDRSC produces high framerate GS videos with improved correction textures and temporal consistency in real-world rolling shutter cases. The source code and trained models are publicly available at https://github.com/shangwei5/SelfDRSC.