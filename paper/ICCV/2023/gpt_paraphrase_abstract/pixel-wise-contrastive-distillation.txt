We present a new approach called Pixel-Wise Contrastive Distillation (PCD) for self-supervised distillation in dense prediction tasks. PCD attracts corresponding pixels from the output feature maps of both the student and teacher networks to transfer knowledge. We introduce a novel design called SpatialAdaptor, which reshapes a part of the teacher network while preserving the distribution of its output features. Our experiments show that this reshaping behavior improves the effectiveness of pixel-to-pixel distillation. Additionally, we incorporate a plug-in multi-head self-attention module that enhances the student's receptive field by explicitly relating pixels in its feature maps. PCD outperforms previous self-supervised distillation methods in various dense prediction tasks. When applied to a ResNet-18-FPN backbone, PCD achieves 37.4APbbox and 34.0APmask on the COCO dataset using Mask R-CNN. Our study aims to inspire future research on self-supervised pre-training of small models suitable for dense prediction tasks.