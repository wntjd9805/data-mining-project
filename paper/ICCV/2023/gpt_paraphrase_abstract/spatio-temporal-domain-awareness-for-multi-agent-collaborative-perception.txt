Collaborative perception using vehicle-to-everything communication has the potential to greatly enhance the perception abilities of autonomous vehicles compared to individual perception. However, there are several challenges in achieving effective information sharing in this field. This study introduces a new framework called SCOPE, which aims to improve collaborative perception by combining the spatial and temporal awareness of multiple on-road agents. SCOPE has three key strengths: (i) it incorporates temporal context to improve the representation of the target agent, (ii) it combines critical spatial information from different agents to overcome localization errors through multi-scale feature interactions, and (iii) it integrates multiple representations of the target agent using an adaptive fusion approach. The effectiveness of SCOPE is evaluated through experiments on both real-world and simulated collaborative 3D object detection tasks using three datasets. The results demonstrate the superiority of SCOPE and the importance of its proposed components. To learn more about this project, visit https://ydk122024.github.io/SCOPE/.