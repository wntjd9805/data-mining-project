The objective of this paper is to address the problem of distorted document image rectification and improve the readability of deformed documents. Previous methods have focused on rectifying the distortion without considering the readability of the document. In this paper, the authors propose a global and local fusion method that focuses on the foreground and text-line regions of the distorted document. They introduce cross attention to capture the features of these regions and effectively fuse them. The proposed method is evaluated on benchmark datasets and achieves state-of-the-art performance. Experimental analysis demonstrates that the method successfully rectifies distorted images and improves document readability. The code for the method is available on GitHub.