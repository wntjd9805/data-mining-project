Continual learning allows for the gradual acquisition of new tasks while retaining knowledge of previously learned tasks, resulting in improved performance overall. However, this approach presents challenges in terms of interpretability, as the reasons behind model predictions may change over time, causing interpretability concept drift. To address this issue, we propose a new method called Interpretable Class-InCrementalLEarning (ICICLE), which is exemplar-free and adopts a part-based approach. ICICLE introduces three key innovations: an interpretability regularization technique that distills prior concepts while maintaining user-friendly explanations, a proximity-based prototype initialization strategy tailored to fine-grained settings, and a task-recency bias compensation method specific to prototypical parts. Our experiments demonstrate that ICICLE effectively mitigates interpretability concept drift and outperforms existing exemplar-free methods in concept-based models.