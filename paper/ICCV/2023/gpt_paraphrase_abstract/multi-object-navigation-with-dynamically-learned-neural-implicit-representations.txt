The core abilities of autonomously navigating agents include understanding and mapping new environments. Traditional robotics approaches use SLAM variants to estimate maps independently, while end-to-end learning of navigation involves neural networks with some form of memory. These networks have inductive biases such as vectorial representations, birds-eye metric tensors, or topological structures. This study proposes structuring neural networks with two dynamic neural implicit representations: the Semantic Finder predicts the position of queried objects, and the Occupancy and Exploration Implicit Representation conveys information about explored areas and obstacles. A global read mechanism is used to query this representation, mapping from function space to embedding space. Both representations are utilized by an agent trained with Reinforcement Learning and learned online during each episode. The agent is evaluated on Multi-Object Navigation, demonstrating the significant impact of using neural implicit representations as a memory source.