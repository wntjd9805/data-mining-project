Our system enables an embodied agent to navigate to specific object instances using images. It tackles the challenges of semantic visual reasoning and exploration in unknown environments. The approach is modular, solving sub-tasks such as exploration, goal instance re-identification, goal localization, and local navigation. We use feature-matching to re-identify the goal instance in egocentric vision and project matched features to a map for goal localization. Each sub-task is solved using off-the-shelf components without requiring fine-tuning. In the HM3D InstanceImageNav benchmark, our system outperforms an end-to-end RL policy by 7x and a state-of-the-art ImageNav model by 2.3x (56% success compared to 25%). We also deploy this system on a mobile robot platform and achieve an 88% success rate in real-world scenarios across home and office environments.