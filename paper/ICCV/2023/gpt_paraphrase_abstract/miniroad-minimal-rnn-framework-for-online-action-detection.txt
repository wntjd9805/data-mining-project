Online Action Detection (OAD) refers to the task of identifying actions in streaming videos without access to future frames. While transformers have gained attention for their ability to capture long-range temporal structures, RNNs have been less favored due to their lower performance compared to transformer-based algorithms. This paper aims to understand the reasons behind the inferior performance of RNNs and proposes a solution to address the discrepancy between training and inference. The solution involves applying non-uniform weights to the loss computed at each time step, enabling the RNN model to learn from predictions in an environment resembling the inference stage. Extensive experiments on three benchmark datasets demonstrate that a minimal RNN-based model trained with this methodology performs equally or better than existing methods while significantly improving efficiency. The code for the proposed approach is available at https://github.com/jbistanbul/MiniROAD.