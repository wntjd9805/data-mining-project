Blending multiple images seamlessly is a challenging task, especially when the images are misaligned due to differences in camera poses and object shapes. Existing 2D methods struggle with this problem. To address these challenges, we propose a 3D-aware blending method using generative Neural Radiance Fields (NeRF). Our method consists of two key components: 3D-aware alignment and 3D-aware blending.  In the 3D-aware alignment step, we estimate the camera pose of the reference image in relation to the generative NeRFs. Then, we perform pose alignment for the objects. This allows us to accurately align the images in 3D space.  To leverage the 3D information of the generative NeRF, we introduce 3D-aware blending. Instead of blending the images in raw pixel space, we utilize volume density and blend on the NeRF's latent space. This approach takes into account the 3D structure of the scene, resulting in more accurate and realistic image blending.  Our method surpasses existing 2D baselines, as demonstrated by extensive quantitative and qualitative evaluations using the FFHQ and AFHQ-Cat datasets. It provides superior results in terms of both visual quality and alignment accuracy.