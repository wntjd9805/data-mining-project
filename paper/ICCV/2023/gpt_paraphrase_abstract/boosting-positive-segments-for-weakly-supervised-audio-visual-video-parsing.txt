This paper addresses the challenge of weakly supervised Audio-Visual Video Parsing (AVVP), which involves localizing audible or visible events and classifying them into known event categories. Existing methods for this task use multiple-instance learning (MIL) with attentive pooling, but they often miss identifying positive segments due to the constraints of weak supervision. To overcome this limitation, the authors propose a new approach that focuses on improving the detection of positive segments. They model the number of positive segments in a video as a latent variable and demonstrate that it can be represented as a Poisson binomial distribution over segment-level predictions. Since fine-grained supervision is not available, they employ an Expectation-Maximization approach to learn the model parameters by maximizing the evidence lower bound (ELBO). The authors iteratively estimate the minimum number of positive segments in a video and refine them to capture more positive segments. The proposed approach is evaluated through extensive experiments on AVVP tasks, which show that it significantly increases the number of positive segments compared to existing methods. Furthermore, experiments on Temporal Action Localization (TAL) demonstrate the potential of the proposed approach for generalization to similar MIL tasks.