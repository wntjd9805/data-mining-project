Currently, deep neural networks that process events typically convert them into dense, grid-like input representations before using a pre-existing network. However, selecting the most suitable representation for a given task usually involves training a neural network for each representation and then choosing the best one based on validation scores. This process is time-consuming. In this study, we address this issue by using the Gromov-Wasserstein Discrepancy (GWD) to select representations. GWD is much faster to compute than training a neural network and maintains the task performance ranking of event representations across various factors such as network backbones, datasets, and tasks. Therefore, representations with high task scores correspond to low GWD values. Leveraging this insight, we conducted a hyperparameter search on a wide range of event representations, leading us to discover novel and powerful representations that outperform the state-of-the-art. Our optimized representations achieve a 1.7 mAP improvement on the 1 Mpx dataset and a 0.3 mAP improvement on the Gen1 dataset, both of which are widely used for object detection benchmarks. Additionally, our representations achieve a 3.8% higher classification score on the mini N-ImageNet benchmark. Furthermore, we outperform the state-of-the-art by 2.1 mAP on the Gen1 dataset and outperform feed-forward methods by 6.0 mAP on the 1 Mpx dataset. This study introduces a previously unexplored area of explicit representation optimization for event-based learning. For access to open-source code, please visit the GitHub repository at https://github.com/uzh-rpg/event_representation_study.