The current benchmarks for video object segmentation (VOS) are limited to short-term videos lasting only a few seconds, where objects are consistently visible. These benchmarks do not accurately represent real-world scenarios, and the lack of long-term datasets hinders further investigation of VOS in realistic situations. Therefore, this paper introduces a new benchmark dataset called LVOS, which includes 220 videos totaling 421 minutes in duration. LVOS is the first densely annotated long-term VOS dataset available. The average length of videos in LVOS is 1.59 minutes, which is 20 times longer than existing VOS datasets. Each video in LVOS contains various attributes, including challenges derived from real-world environments such as long-term reappearing and cross-temporal similar objects. Using LVOS, we evaluate existing VOS algorithms and propose a novel approach called Diverse Dynamic Memory network (DDMemory). DDMemory utilizes three complementary memory banks to effectively leverage temporal information. Experimental results showcase the strengths and weaknesses of previous methods and offer promising directions for future research. The LVOS dataset, as well as the code, can be accessed at https://lingyihongfd.github.io/lvos.github.io/.