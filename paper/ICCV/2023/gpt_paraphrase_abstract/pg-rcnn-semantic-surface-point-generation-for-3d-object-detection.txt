The challenge in LiDAR-based 3D object detection is the incomplete spatial information due to long distance and occlusion. Existing two-stage detectors address this by adding more points to regions of interest (RoIs) with a pre-trained network. However, these methods generate dense point clouds for all RoIs, assuming objects always exist there, which leads to indiscriminate point generation for incorrect proposals. To overcome this, we propose a novel detector called Point Generation R-CNN (PG-RCNN) that generates semantic surface points for accurate detection. Our method uses a jointly trained RoI point generation module to estimate the shape and displacement of foreground objects. Each generated point is assigned a semantic feature indicating the estimated foreground probability. Experiments show that our method provides rich geometric and semantic information for refining false positive and misaligned proposals. PG-RCNN achieves competitive performance on the KITTI benchmark with fewer parameters than state-of-the-art models. The code is available at https://github.com/quotation2520/PG-RCNN.