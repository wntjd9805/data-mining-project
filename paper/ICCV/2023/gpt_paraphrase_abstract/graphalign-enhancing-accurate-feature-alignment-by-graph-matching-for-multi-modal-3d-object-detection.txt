GraphAlign is a feature alignment strategy for 3D object detection in autonomous driving, addressing the challenge of integrating LiDAR point clouds and camera images. Existing methods often overlook the accuracy errors in coordinate conversion between sensors, resulting in sub-optimal performance. To overcome this, GraphAlign utilizes graph matching to achieve more precise feature alignment. It combines image features from a semantic segmentation encoder and point cloud features from a 3DSparse CNN. To reduce computation, nearest neighbor relationships are constructed by calculating Euclidean distance within subspaces of point cloud features. Through projection calibration, the nearest neighbors of point cloud features are projected onto image features. By matching these nearest neighbors with a single point cloud to multiple images, a better feature alignment is sought. To further enhance the alignment, a self-attention module is employed to emphasize significant relations. Extensive experiments on the nuScenes benchmark demonstrate the effectiveness and efficiency of GraphAlign.