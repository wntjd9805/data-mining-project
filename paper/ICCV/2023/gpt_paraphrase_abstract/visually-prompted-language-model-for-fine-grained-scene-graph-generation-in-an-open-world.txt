Scene Graph Generation (SGG) is a task that involves extracting relationships between subjects, predicates, and objects in images for better understanding of visual information. While recent advancements have improved SGG, they still face challenges related to long-tail distribution, where less frequent predicates are harder to train and differentiate due to limited annotated data. Existing methods attempt to address this issue through predefined rules, but they lack scalability for different models and datasets.To overcome these limitations, we introduce the Cross-modal Predicate Boosting (CaCao) framework, which utilizes a visually-prompted language model to generate a wide range of fine-grained predicates in a resource-efficient manner. CaCao can be easily integrated into existing SGG models and effectively addresses the long-tail problem. Additionally, we propose the Entangled cross-modal prompt approach for open-world predicate scene graph generation (Epic), which enables models to generalize to unseen predicates in a zero-shot manner.We conducted extensive experiments on three benchmark datasets and found that CaCao consistently improves the performance of multiple scene graph generation models, regardless of the specific model architecture. Furthermore, our Epic approach achieves competitive results in open-world predicate prediction. The data and code used in this study are publicly available.In summary, our work presents a novel framework (CaCao) for generating diverse predicates in SGG and a new approach (Epic) for handling open-world scenarios. Our experiments demonstrate the effectiveness of CaCao in improving the performance of SGG models, and Epic achieves impressive results in predicting unseen predicates. The resources for this study are openly accessible.