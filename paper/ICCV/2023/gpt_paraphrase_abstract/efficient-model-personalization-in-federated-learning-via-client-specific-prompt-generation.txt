Federated learning (FL) is a decentralized learning approach that trains models using data from multiple clients without compromising privacy. However, the deployment of large-scale models in FL is hindered by data heterogeneity, limited resources, and communication constraints. To address this, we propose a personalized FL framework called pFedPG. This framework utilizes a personalized prompt generator at the server to produce client-specific visual prompts, enabling efficient model personalization while leveraging robust representations from large-scale models. Our framework optimizes personalized prompt adaptation locally and personalized prompt generation globally. The former trains visual prompts that adapt foundation models to each client, while the latter generates personalized prompts for all clients based on local optimization directions. Extensive experiments on benchmark datasets demonstrate the effectiveness of pFedPG in various scenarios of data heterogeneity, enabling efficient model personalization with improved computation and communication efficiency.