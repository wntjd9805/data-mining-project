Video generation has gained significant attention as a generative tool in recent years. However, there has been little focus on audio-to-video generation, despite the unique qualities of audio such as temporal semantics and magnitude. To address this gap, we propose The Power of Sound (TPoS) model, which incorporates audio input with changeable temporal semantics and magnitude. TPoS utilizes a latent stable diffusion model with textual semantic information to generate video frames, guided by sequential audio embedding from our pretrained Audio Encoder. This approach enables the production of audio reactive video content. We demonstrate the effectiveness of TPoS across various tasks and compare its performance with current state-of-the-art techniques in the field of audio-to-video generation. For more examples, please visit the following link: https://ku-vai.github.io/TPoS/.