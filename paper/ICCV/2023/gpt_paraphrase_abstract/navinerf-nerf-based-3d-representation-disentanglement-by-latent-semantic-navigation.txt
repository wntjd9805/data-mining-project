The exploration of disentangling 3D representations is a task that aims to understand and manipulate the underlying factors of 3D data, which is crucial for AI's understanding of our 3D world. However, this task is currently not well-studied and presents significant challenges. One challenge is that 3D representations are complex and contain more information than 2D images. Additionally, many 3D representations are not suitable for gradient-based optimization or disentanglement.   To tackle these challenges, we propose NaviNeRF, a novel method that utilizes NeRF as a differentiable 3D representation. NaviNeRF introduces a self-supervised navigation technique to identify interpretable semantic directions in the latent space. Notably, NaviNeRF is the first approach to achieve fine-grained 3D disentanglement without any prior knowledge or supervision.   NaviNeRF is built upon the generative NeRF pipeline and consists of an Outer Navigation Branch and an Inner Refinement Branch. These branches are complementary, with the outer navigation identifying global-view semantic directions and the inner refinement focusing on fine-grained attributes. We also introduce a synergistic loss to coordinate the two branches.   Extensive experiments demonstrate that NaviNeRF outperforms previous 3D-aware models in terms of fine-grained 3D disentanglement. Furthermore, NaviNeRF's performance is comparable to editing-oriented models that rely on semantic or geometry priors. Overall, NaviNeRF shows promising results in achieving a deeper understanding of 3D representations without the need for prior knowledge or supervision.