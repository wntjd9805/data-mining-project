Extensive research has been conducted on image restoration techniques for motion-related degradations such as blurry effects from global shutter (GS) and jello effects from rolling shutter (RS). Recently, it has been discovered that these degradations contain temporal information that can be utilized for video frame interpolation (VFI), which is a more challenging task than simple restoration. However, most VFI studies rely on synthetic data rather than real data. Furthermore, it is still unknown which type of degradation is more effective for VFI under the same imaging conditions. This paper introduces RD-VFI, the first real-world dataset for learning and evaluating degraded video frame interpolation. The dataset explores the performance differences of three degradation types: GS blur, RS distortion, and a hybrid effect caused by the rolling shutter with global reset (RSGR). The authors utilize a novel quad-axis imaging system to capture the dataset. To address the challenges posed by different degradations, the authors propose a unified Progressive MutualBoosting Network (PMBNet) model that can interpolate middle frames at any given time for all shutter modes. The PMBNet model incorporates a disentanglement strategy and dual-stream correction to adaptively handle various degradations in VFI. Experimental results demonstrate that the PMBNet outperforms state-of-the-art methods for all shutter modes.