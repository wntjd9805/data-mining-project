Our MATE is a novel method called Test-Time-Training (TTT) specifically designed for 3D data. It aims to enhance the robustness of deep networks trained for point cloud classification against distribution shifts that may occur in test data. Inspired by existing TTT methods in the 2D image domain, MATE also utilizes test data for adaptation. During test time, MATE employs a Masked Autoencoder objective, where a significant portion of each test point cloud is removed before being inputted to the network. The network is then tasked with reconstructing the complete point cloud and subsequently classifying it. We conducted experiments on various 3D object classification datasets to evaluate MATE's performance. The results demonstrate that MATE significantly improves the resilience of deep networks to different types of corruptions commonly found in 3D point clouds. Additionally, we found that MATE is highly efficient, requiring only a small fraction of points (as few as 5% of tokens) from each test sample for adaptation. This lightweight nature makes MATE suitable for real-time applications. Furthermore, our experiments show that MATE achieves competitive performance even when adapting sparsely on the test data, further reducing computational overhead. In Figure 1, we provide an overview of our Test-Time Training methodology. The encoder is adapted to a single out-of-distribution (OOD) test sample by updating its weights through a self-supervised reconstruction task. These updated weights are then used to make predictions on the test sample. It is important to note that the encoder, decoder, and classifier are co-trained in both the classification and reconstruction tasks, as outlined in [17].