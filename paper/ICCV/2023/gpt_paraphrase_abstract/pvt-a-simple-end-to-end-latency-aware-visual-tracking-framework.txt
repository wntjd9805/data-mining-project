This study addresses the issue of latency in visual object tracking, particularly for unmanned aerial vehicles (UAVs) with limited on-board computation. The authors propose a framework called end-to-end predictive visual tracking (PVT++), which optimizes the integration of motion information and visual knowledge from pre-trained tracker models to make robust predictions. They also introduce a relative motion factor to bridge the domain gap between training and evaluation, enabling PVT++ to perform well in complex UAV tracking scenarios. The authors present an evaluation benchmark for online tracking and demonstrate that PVT++ outperforms previous solutions in terms of accuracy and performance. The code for PVT++ is publicly available on GitHub.