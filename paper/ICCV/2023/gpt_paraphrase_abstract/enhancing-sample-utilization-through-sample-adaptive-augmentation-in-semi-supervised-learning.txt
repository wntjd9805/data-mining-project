In semi-supervised learning, unlabeled samples can be used to improve the model through augmentation and consistency regularization. However, some samples, even after strong augmentation, are still correctly classified with high confidence, indicating that they have already been well learned and don't contribute much to model optimization. These samples are referred to as "naive samples". Existing semi-supervised learning models ignore the characteristics of naive samples and treat all samples the same. To address this issue and further enhance the model, we propose sample adaptive augmentation (SAA). SAA consists of two modules: the sample selection module and the sample augmentation module. The sample selection module identifies naive samples based on historical training information at each epoch, and the naive samples are then augmented in a more diverse manner in the sample augmentation module. SAA is simple and lightweight, and when applied to FixMatch and FlexMatch models, it significantly improves their performance. For example, on CIFAR-10 with 40 labels, SAA improved the accuracy of FixMatch from 92.50% to 94.76% and that of FlexMatch from 95.01% to 95.31%. The code for SAA is available at the provided GitHub link. This work is supported by various funding sources. Figure 1 illustrates an example of a naive sample and the model performance during FixMatch training, showing slow or stagnant improvement at times.