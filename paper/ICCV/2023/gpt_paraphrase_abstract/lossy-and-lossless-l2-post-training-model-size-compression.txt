Deep neural networks have achieved impressive results in various visual tasks but their large sizes pose challenges for transmission and storage. Previous studies have explored compression methods to reduce model sizes, but they often focus on either lossy or lossless compression, making it difficult to achieve high compression ratios efficiently. This study proposes a post-training compression method that combines both lossy and lossless compression in a unified manner. The method introduces a parametric weight transformation to enable joint application of different lossy compression methods after training. It also incorporates a differentiable counter to guide the optimization of lossy compression, leading to better results for subsequent lossless compression. The proposed method allows for easy control of the desired global compression ratio and adaptive distribution of compression ratios across different layers. Experimental results show that the method can achieve a stable 10× compression ratio without sacrificing accuracy and a 20× compression ratio with only minor accuracy loss in a short time. The code for the method is available at the provided GitHub link.