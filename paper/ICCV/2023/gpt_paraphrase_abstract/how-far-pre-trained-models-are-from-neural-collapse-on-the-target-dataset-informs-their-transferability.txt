This paper examines model transferability estimation, which involves assessing the performance of pre-trained models on a downstream task without fine-tuning. Inspired by the concept of neural collapse (NC), which highlights specific feature geometry at the end of training, we define model transferability as the difference between the target activations produced by pre-trained models and their hypothetical state if fine-tuned on the target domain. We propose a metric that quantifies this difference based on three aspects of NC: the collapse of within-class variability, the formation of a simplex encoded label interpolation geometry structure, and the optimality of the nearest center classifier on training data. Through experiments on 11 datasets, we demonstrate that all three aspects of NC are necessary for accurate transferability estimation. Additionally, our approach achieves competitive accuracy while being approximately 10 times faster than existing methods.