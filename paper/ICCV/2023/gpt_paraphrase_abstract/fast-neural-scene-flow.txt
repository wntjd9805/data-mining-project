The Neural Scene Flow Prior (NSFP) is a method that is highly valued in the field of computer vision because it is resilient to out-of-distribution effects and can effectively handle dense lidar points. However, it is considerably slower compared to current state-of-the-art learning approaches. Previous efforts to speed up coordinate neural networks in other applications have primarily focused on architectural improvements. In this study, we demonstrate that the main computational bottleneck in scene flow estimation is the loss function itself, specifically the Chamfer distance. To address this issue, we propose using the distance transform (DT) as a more efficient and correspondence-free loss function, resulting in a significant improvement in runtime optimization. Our new approach, called Fast Neural Scene Flow (FNSF), achieves real-time performance comparable to learning methods without any training or bias towards out-of-distribution data. We evaluate FNSF on two large autonomous driving lidar datasets, Waymo Open and Argoverse, and provide the code for implementation.