Neural Radiance Fields have shown promise in generating new views of a scene with limited image observations. However, their application is hindered by the need for accurate camera parameters. This paper introduces adaptive positional encoding (APE) for bundle-adjusting neural radiance fields, allowing reconstruction of these fields without knowledge of camera poses or intrinsics. Inspired by Fourier series regression, the relationship between positional encoding and APE is explored, resulting in a trainable APE with all frequency bands. Additionally, period-activated multilayer perceptrons (PMLPs) are introduced to construct the implicit network for high-order scene representations and improve gradients during backpropagation. Experimental results on public datasets demonstrate that the proposed method, utilizing APE and PMLPs, outperforms current state-of-the-art methods in accurately determining camera poses and generating high-quality synthesized views.