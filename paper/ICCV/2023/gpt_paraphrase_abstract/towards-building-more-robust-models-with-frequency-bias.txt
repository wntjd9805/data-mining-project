Deep neural networks have achieved success in various fields, but their vulnerability to adversarial samples has hindered their broad applications. Previous research has highlighted the importance of low-frequency information in achieving robustness against adversarial attacks. However, attempts to leverage this frequency characteristic through direct application of low-pass filters to input images have resulted in the loss of discriminative information and poor generalizability to datasets with distinct frequency features. This paper introduces a plug-and-play module called the Frequency Preference Control Module, which adaptively reconfigures the low- and high-frequency components of intermediate feature representations. This module enhances the utilization of frequency for robust learning. Empirical studies demonstrate that our proposed module can easily be integrated into any adversarial training framework, thereby improving model robustness across different architectures and datasets. Furthermore, experiments were conducted to investigate how the frequency bias of robust models influences the adversarial training process and its final robustness, leading to interesting insights.