Efficient navigation towards specific objects in new environments requires understanding the spatial and semantic patterns in the layout of the environment. In this study, we propose a simple approach to learn these patterns by predicting the positions of unseen objects based on incomplete semantic maps. Unlike previous prediction-based navigation methods, our approach directly predicts unseen targets while utilizing the global context from all previously explored areas. Our prediction model is lightweight and can be trained in a supervised manner using a relatively small amount of passive data. Once trained, the model can be integrated into a modular pipeline for object navigation without the need for reinforcement learning. We demonstrate the effectiveness of our method on two object navigation datasets, HM3D and MP3D, achieving the state-of-the-art performance on both datasets without using any additional training data. The source code is available at https://ajzhai.github.io/PEANUT.