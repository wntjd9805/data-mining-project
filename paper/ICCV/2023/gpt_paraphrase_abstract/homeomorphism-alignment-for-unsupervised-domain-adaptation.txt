Current unsupervised domain adaptation (UDA) methods focus on aligning the features of the source and target domains in a common space. However, explicit distribution matching does not consider the discriminability of the learned features, and implicit methods like self-supervised learning are affected by noisy pseudo-labels. The main challenge is to create a common space that maintains the discriminative structure of both domains. To address this issue, we propose the HomeomorphisM Alignment (HMA) approach, which aligns the source and target data in two separate spaces. We construct an invertible neural network-based homeomorphism that maps between these spaces. Distribution matching is then used to connect this mapping, ensuring that the data's topological structure is preserved. This property allows for more discriminative model adaptation, using both the original and transformed features of the source data in a supervised manner and those of the target domain in an unsupervised manner. Theoretical analysis demonstrates that our method preserves the cluster/group structure of the data. Extensive experiments show that our approach achieves state-of-the-art results. The source code is available at https://github.com/buerzlh/HMA.