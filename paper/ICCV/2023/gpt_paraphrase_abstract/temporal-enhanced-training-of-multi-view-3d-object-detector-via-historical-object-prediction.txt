This paper introduces a new approach called Historical Object Prediction (HoP) for multi-view 3D detection, which aims to effectively leverage temporal information. HoP generates a pseudo Bird's-Eye View (BEV) feature from adjacent frames at a previous timestamp and uses this feature to predict the object set at that timestamp. The motivation behind HoP is to enable the detector to capture both the spatial location and temporal motion of objects occurring at historical timestamps, leading to more accurate BEV feature learning. The approach involves the design of short-term and long-term temporal decoders to generate the pseudo BEV feature without the need for camera images. An additional object decoder is attached to predict the object targets using the generated feature. Importantly, HoP is only performed during training, so there are no additional overheads during inference. The plug-and-play nature of HoP allows it to easily integrate into existing BEV detection frameworks. Additionally, HoP is complementary to existing temporal modeling methods, resulting in significant performance improvements. The effectiveness of HoP is evaluated on the nuScenes dataset, comparing it to representative methods such as BEVFormer and BEVDet4D-Depth. The results show that HoP outperforms all other 3D object detectors on the leaderboard, achieving 68.5% NDS and 62.4% mAP with ViT-L on the nuScenes test. The code for HoP is available on GitHub.