This paper introduces U-RED, an Unsupervised shape REtrieval and Deformation pipeline that aims to address the challenges of handling noisy partial observations in shape retrieval tasks. U-RED takes arbitrary object observations as input and retrieves geometrically similar CAD models from a pre-established database to closely match the target. The proposed pipeline tackles the issue of ambiguous one-to-many relationships between partial and full shapes by learning to project all possible full shapes onto a unit sphere, allowing for multiple potential retrievals. Additionally, U-RED addresses the problem of noise in real-world partial observations by incorporating a novel point-wise residual-guided metric that enables robust shape comparison. Experimental results on synthetic datasets (PartNet, ComplementMe) and a real-world dataset (Scan2CAD) demonstrate that U-RED outperforms existing state-of-the-art approaches by a significant margin under the Chamfer Distance metric.