This paper proposes a new method called Sequentially Global Rotation Estimation (SGRE) for 3D human mesh recovery from monocular RGB images. Unlike previous approaches that use the Skinned Multi-Person Linear (SMPL) model and suffer from accumulated errors, SGRE directly estimates the global rotation of each joint to improve accuracy. It incorporates a residual learning module that leverages complementary features and previously predicted rotations to guide the estimation of subsequent joints. SGRE outperforms existing regression-based methods on various benchmarks, achieving superior performance in terms of mean per joint position error (MPJPE), percentage of volume error (PVE), and average precision (AP). For example, it improves the latest method 3DCrowdNet by 3.3 mm MPJPE and 5.0 mm PVE on the 3DPW dataset, and 3.0 AP on the COCO dataset.