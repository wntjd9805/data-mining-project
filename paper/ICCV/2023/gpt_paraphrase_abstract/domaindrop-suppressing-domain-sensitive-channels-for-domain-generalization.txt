Deep Neural Networks have been successful in various visual tasks. However, they often perform poorly on unseen test data due to domain shifts. This paper presents a new approach to address this issue by enhancing the robustness of channels in feature maps to domain shifts. The authors observe that models trained on source domains have unstable activations in certain channels, which capture domain-specific features and behave abnormally in unseen target domains. To tackle this problem, they propose the DomainDrop framework, which uses a domain discriminator to identify and drop unstable channels during forward propagation. The authors theoretically prove that their framework effectively reduces the generalization bound. Extensive experiments on multiple benchmarks demonstrate that their framework outperforms other methods. The code for their framework is available at https://github.com/lingeringlight/DomainDrop.