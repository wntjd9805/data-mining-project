Reconstructing a 3D human mesh from a single RGB image is a difficult task due to depth ambiguity and self-occlusion, leading to a high level of uncertainty. Recent advancements in diffusion models have shown promising results in generating high-quality outputs by progressively reducing noise in input data. Building upon this idea, we propose a novel approach called Human Mesh Diffusion (HMDiff) to recover human mesh by treating it as a reverse diffusion process. To enhance the recovery process, we introduce a Distribution Alignment Technique (DAT) that incorporates input-specific distribution information into the diffusion process, providing valuable prior knowledge to simplify the mesh recovery task. Our method demonstrates superior performance compared to existing techniques on three widely used datasets. For more information, please visit our project page: https://gongjia0208.github.io/HMDiff/.