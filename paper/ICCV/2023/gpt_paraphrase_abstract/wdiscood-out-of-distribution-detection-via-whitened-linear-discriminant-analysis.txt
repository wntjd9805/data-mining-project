This study focuses on the challenge of detecting out-of-distribution (OOD) samples in deep neural networks, which often generate overconfident yet incorrect predictions when presented with unfamiliar data. The researchers propose a new method called WDiscOOD that uses Whitened Linear Discriminant Analysis to project features into two subspaces: the discriminative subspace, where the in-distribution (ID) classes are well separated, and the residual subspace, where the ID classes are closely clustered. By measuring the deviation of input data from the ID pattern in both subspaces, the researchers determine an OOD score. They evaluate the effectiveness of WDiscOOD on the ImageNet-1k benchmark with six OOD datasets that represent different distribution shifts. WDiscOOD outperforms other methods on various deep classifiers, including CNN and vision transformer architectures. The researchers also demonstrate that WDiscOOD effectively detects novel concepts in representation spaces trained with contrastive objectives, such as supervised contrastive loss and multi-modality contrastive loss.