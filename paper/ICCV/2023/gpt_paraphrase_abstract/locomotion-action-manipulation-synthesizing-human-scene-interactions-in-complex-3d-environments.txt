Synthesizing complex human motions in 3D environments with various behaviors has been difficult. To address this, we introduce LAMA, a framework that generates natural and believable long-term human movements in complex indoor settings. LAMA aims to encompass locomotion, scene interaction, and object manipulation within a unified framework. Unlike existing methods that rely on paired motion data and 3D scene scans for supervision, our approach formulates the problem as an optimization process at test-time, utilizing only human motion capture data for synthesis.LAMA combines a reinforcement learning framework with a motion matching algorithm for optimization. Additionally, it incorporates a motion editing framework through manifold learning to encompass different variations in interaction and manipulation. Extensive experiments demonstrate that LAMA surpasses previous approaches in generating realistic motions across challenging scenarios.To learn more about LAMA, please visit our project page: https://jiyewise.github.io/projects/LAMA/.