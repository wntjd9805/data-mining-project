We propose a new dataset called OMMO for large-scale outdoor scene reconstruction using Neural Radiance Fields (NeRF). This dataset contains calibrated images, point clouds, and prompt annotations of complex outdoor objects and scenes. We establish a benchmark for outdoor NeRF-based tasks such as novel view synthesis, diverse 3D representation, and multi-modal NeRF. The dataset is created by capturing real fly-view videos and selecting high-quality clips. We use a quality review module to refine images and remove low-quality frames and scenes that fail to calibrate. Volunteers label and review prompt annotations for each scene and keyframe. Compared to existing NeRF datasets, our dataset includes real-world urban and natural scenes with various scales, camera trajectories, and lighting conditions. Experiments demonstrate that our dataset can benchmark state-of-the-art NeRF methods on different tasks. The dataset is available at https://ommo.luchongshan.com/.