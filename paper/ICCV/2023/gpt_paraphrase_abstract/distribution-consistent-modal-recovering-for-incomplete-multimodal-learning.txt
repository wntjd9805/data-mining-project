Recovering missing modalities in incomplete multimodal learning is a popular approach as it can improve downstream tasks. However, current methods often estimate missing modalities directly from observed ones using deep neural networks, without considering the distribution gap between modalities. This leads to inconsistencies in the distributions of the recovered and true data. To address this, we propose a new recovery paradigm called Distribution-Consistent Modal Recovering (DiCMoR). DiCMoR transfers the distributions from available modalities to missing modalities, ensuring the distribution consistency of the recovered data. Our approach uses a class-specific flow-based modality recovery method that transforms cross-modal distributions based on the sample class. This method predicts a distribution-consistent space for the missing modality using the invertibility and exact density estimation of normalizing flow. The generated data from this predicted distribution is then integrated with available modalities for classification tasks. Experimental results demonstrate that DiCMoR outperforms existing state-of-the-art methods and is more robust in various missing pattern scenarios. Additionally, visualization results show that DiCMoR effectively mitigates distribution gaps between recovered and missing modalities. The code for DiCMoR is available at https://github.com/mdswyz/DiCMoR.