When using a pre-trained model to convert 2D human poses to 3D poses on a new dataset, there is often a significant decrease in performance due to differences in camera parameters and limited diversity in training data. This degradation is caused by a gap in the distribution of global pose positions between the source and target datasets, as well as a lack of diversity in local pose structures during training. To address these issues, we propose a framework called PoseDA for unsupervised domain adaptation in 3D human pose estimation. PoseDA combines global adaptation, which aligns global pose positions between the source and target domains using a global position alignment module, with local generalization, which enhances the diversity of 2D-3D pose mapping using a local pose augmentation module. These modules significantly improve performance without adding more learnable parameters. Additionally, we introduce a local pose augmentation scheme that increases the diversity of 3D poses through an adversarial training process involving an augmentation generator and an anchor discriminator. Our approach is applicable to most 2D-3D lifting models. In evaluations on the MPI-INF-3DHP dataset using a cross-dataset setup, PoseDA achieves an MPJPE of 61.3 mm, outperforming the previous state-of-the-art method by 10.2%.