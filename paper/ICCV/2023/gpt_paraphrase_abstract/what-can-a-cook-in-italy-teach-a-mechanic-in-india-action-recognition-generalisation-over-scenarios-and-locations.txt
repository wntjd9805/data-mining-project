We introduce a new problem in the field of action recognition: can a model accurately classify actions when they are performed in an unseen scenario and location? To address this, we present the Action Recognition Generalisation Over scenarios and locations dataset (ARGO1M), consisting of 1.1M video clips from the Ego4D dataset across 10 scenarios and 13 locations. Our experiments reveal that existing recognition models struggle to generalize over 10 proposed test splits, each involving an unseen scenario in an unseen location. To overcome this challenge, we propose a method called Cross-Instance Reconstruction (CIR) that represents each video by reconstructing it using videos from other domains. These reconstructions are accompanied by text narrations to guide the learning of a domain-generalizable representation. Extensive analysis and ablations conducted on ARGO1M demonstrate that CIR outperforms previous domain generalization approaches across all test splits. The code and data for our work can be found at https://chiaraplizz.github.io/what-can-a-cook/.