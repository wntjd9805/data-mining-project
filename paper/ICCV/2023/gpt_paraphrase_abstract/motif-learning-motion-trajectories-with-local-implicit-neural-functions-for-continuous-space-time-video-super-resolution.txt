This study focuses on continuous space-time video super-resolution (C-STVSR), which aims to enhance the resolution of a video in both space and time. A major challenge in C-STVSR is the temporal propagation of information between video frames. In order to overcome this challenge, the authors propose a space-time local implicit neural function that can learn forward motion for a range of pixels. They argue that learning individual motion trajectories is more effective than learning a mixture of motion trajectories with backward motion. To facilitate motion interpolation, they encode sparsely sampled forward motion from the input video as contextual input. Additionally, they introduce a reliability-aware splatting and decoding scheme. The proposed framework, called MoTIF, achieves state-of-the-art performance in C-STVSR. The source code for MoTIF can be found at https://github.com/sichun233746/MoTIF.