In the field of instance image retrieval, incorporating local spatial information within an image has proven to enhance retrieval performance. This has been achieved through the use of local visual descriptors and geometric verification. However, it would be beneficial to also incorporate spatial context awareness into global image representations. Global representation based image retrieval is attractive due to its simplicity, low memory usage, and compatibility with complex data structures. To address this, we propose a new framework for feature learning in instance image retrieval. Our approach integrates local spatial context information into the learned global feature representations. This is achieved by introducing a spatial context branch alongside the visual feature branch in a convolutional neural network (CNN) backbone. The spatial context branch includes two modules: online token learning and distance encoding. The former module indicates the types of surrounding descriptors for each local descriptor learned in the CNN, while the latter captures spatial distribution information. The visual feature branch and the spatial context branch are then combined to generate a single global feature representation for each image. Experimental results demonstrate that our spatial-context-aware approach significantly improves the performance of global representation based image retrieval while preserving its desirable properties. The code for our framework is available at https://github.com/Zy-Zhang/SpCa.