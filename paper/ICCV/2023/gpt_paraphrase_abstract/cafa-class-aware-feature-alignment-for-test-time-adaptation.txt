Despite recent advancements in deep learning, deep neural networks still struggle with performance degradation when applied to new data that differs from the training data. Test-time adaptation (TTA) aims to address this issue by adapting a model to unlabeled data during testing. TTA can be applied to pretrained networks without modifying their training procedures, allowing them to use a well-formed source distribution for adaptation. One possible approach to TTA is feature alignment, which involves aligning the representation space of test samples to the source distribution. However, performing feature alignment in TTA is challenging because access to labeled source data is restricted during adaptation. This means that the model cannot learn test data in a class-discriminative manner, as it could in other adaptation tasks like unsupervised domain adaptation. Based on this observation, we propose a simple yet effective feature alignment loss called Class-Aware Feature Alignment (CAFA). CAFA simultaneously encourages the model to learn target representations in a class-discriminative manner and effectively mitigates distribution shifts at test time. Our method does not require any hyperparameters or additional losses, unlike previous approaches. We conducted extensive experiments on six different datasets and consistently outperformed existing baselines.