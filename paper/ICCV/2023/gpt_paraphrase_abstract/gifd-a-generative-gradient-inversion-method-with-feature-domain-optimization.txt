Federated Learning (FL) is a distributed machine learning framework that aims to protect clients' privacy by allowing them to upload calculated gradients to a central server. However, recent studies have shown that these exchanged gradients can pose a risk to privacy, as attackers can leverage pre-trained generative adversarial networks (GAN) to recover sensitive data. Existing gradient inversion attacks in the latent space of GAN models have limitations in their expressive ability and generalizability. To address these challenges, we propose Gradient Inversion over Feature Domains (GIFD) which disassembles the GAN model and explores the feature domains of intermediate layers. Unlike previous methods that only optimize the initial latent code, GIFD progressively changes the optimized layer, moving closer to the output images. We also incorporate a regularizer to prevent the generation of unrealistic images by adding a small l1 ball constraint to the search range. Additionally, we extend GIFD to the out-of-distribution (OOD) setting, relaxing the assumption of matching data distributions between GAN training sets and FL tasks. Extensive experiments demonstrate that our method achieves pixel-level reconstruction and outperforms existing methods. GIFD also exhibits strong generalizability under different defense strategies and batch sizes.