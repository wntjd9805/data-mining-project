Contrastive learning models have shown impressive results in self-supervised learning, but they rely on having a sufficient number of positive pairs and enough variations between them. If these conditions are not met, the models lack semantic contrast and are prone to overfitting. To address these issues, we propose Hallucinator, a differentiable model that generates additional positive samples for better contrast. Hallucinator is optimized directly with the pre-training task and has minimal computational overhead. We also reduce the mutual information of hallucinated pairs and smooth them through non-linear operations to prevent over-confident learning models and achieve more transformation-invariant feature embeddings. Our empirical results demonstrate that Hallucinator generalizes well to various contrastive learning models, resulting in stable accuracy gains ranging from 0.3% to 3.0% on different datasets. We also observe improvements in transferring the pre-trained encoders to downstream tasks like object detection and segmentation.