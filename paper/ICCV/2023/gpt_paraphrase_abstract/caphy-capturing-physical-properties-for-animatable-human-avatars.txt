We introduce CaPhy, a new approach to creating realistic and dynamic clothing for animated human avatars. Our goal is to accurately capture the geometric and physical characteristics of real clothing through observations. By doing so, we can apply various poses to the avatar, resulting in authentic deformations and wrinkles in the clothing. Our method combines unsupervised and 3D-supervised training, utilizing scanned data to reconstruct physically realistic and human-conforming dynamic clothing models. Additionally, we optimize the physical parameters of the model using gradient constraints from physics-based losses. Unlike previous approaches, our method successfully handles novel poses with realistic cloth deformations. Through experiments on multiple subjects, we demonstrate that our method outperforms previous techniques in terms of quantitative and qualitative results in estimating garment properties.