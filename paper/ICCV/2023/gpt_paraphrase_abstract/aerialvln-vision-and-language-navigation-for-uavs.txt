The emergence of Vision-and-Language Navigation (VLN) tasks has garnered considerable interest in the fields of computer vision and natural language processing. While existing VLN tasks focus on ground navigation, there is a need for intelligent agents to navigate in the sky for tasks such as UAV-based goods delivery, traffic/security patrol, and scenery tours. Navigating in the sky is more complex due to factors like flying height and spatial relationship reasoning. To address this gap, we propose a new task called AerialVLN, which is focused on UAV-based navigation in outdoor environments. We have developed a 3D simulator that provides near-realistic images of 25 city-level scenarios. The simulator supports continuous navigation, environment extension, and configuration. Additionally, we have introduced an extended baseline model based on the widely-used cross-modal-alignment (CMA) navigation methods. However, our experiments show a significant performance gap between the baseline model and human performance, highlighting AerialVLN as a challenging task. The dataset and code for AerialVLN are available at https://github.com/AirVLN/AirVLN.