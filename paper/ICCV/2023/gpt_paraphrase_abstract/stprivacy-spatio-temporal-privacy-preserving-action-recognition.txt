Current methods of privacy-preserving action recognition (PPAR) primarily focus on removing spatial privacy at the frame level using 2D CNNs. However, these methods have two main limitations. Firstly, they fail to capture the temporal dynamics in videos, which are crucial for accurate action recognition. Secondly, they are susceptible to practical attacks where privacy is probed at the video level rather than individual frames. To overcome these challenges, we propose a novel framework called STPrivacy for video-level PPAR. Our approach introduces vision Transformers into PPAR, treating a video as a sequence of tubelets. We incorporate two complementary mechanisms, namely sparsification and anonymization, to address privacy concerns from a spatio-temporal perspective. The sparsification mechanism selectively discards tubelets that are irrelevant to the action being performed. The anonymization mechanism then employs adversarial learning to manipulate the remaining action-tubelets and eliminate privacy in the embedding space. These mechanisms offer significant advantages in terms of preserving privacy for human observers and adjusting the trade-off between action recognition accuracy and privacy preservation during deployment. Additionally, we contribute two large-scale PPAR benchmarks, VP-HMDB51 and VP-UCF101, to the research community. Through extensive evaluations on these benchmarks and two other tasks, we demonstrate the effectiveness and generalization capability of our proposed framework.