Current methods for text-driven generative domain adaptation, which combine pre-trained models with text, have the ability to generate images from various target domains. However, these methods still face issues such as overfitting and mode collapse. In this study, we examine mode collapse from a geometric standpoint and establish its connection to the Hessian matrix of the generator. To address this problem, we propose the use of spectral consistency regularization, which preserves the diversity of the source domain without constraining the semantic adaptation to the target domain. Additionally, we introduce granularity adaptive regularization, which allows for flexible control over the balance between diversity and stylization in the target model. Through extensive experiments and comparisons with state-of-the-art methods, we demonstrate the efficacy of our approach in preserving source domain diversity and generating high-quality target images. The source code for our method is available at https://github.com/Victarry/Adaptation-SCR.