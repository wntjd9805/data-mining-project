Two main approaches to object detection are CNN-based and Transformer-based. The former tackles object detection as a dense local matching problem, while the latter addresses it as a sparse global retrieval problem. Drawing on findings from neuroscience, which indicate that the brain's recognition decision relies on familiarity and recollection processes, we propose an efficient and effective object detection framework that incorporates both CNN-based and Transformer-based detectors. This framework consists of a shared backbone, a dual-stream encoder, and a dual-decoder. To better merge local and global features, we define a search space for the dual-stream encoder to find the optimal fusion solution. Additionally, we enhance coordination between the CNN and Transformer-based decoders by introducing a selective mask to the dual-decoder. This mask dynamically selects the more advantageous decoder for each position in the image based on high-level representation. Extensive experiments demonstrate that our approach improves the mean Average Precision (mAP) of various source detectors by 3.0-3.7 without increasing Floating Point Operations (FLOPs).