Creating realistic and precise full body avatar motion is crucial for immersive experiences in mixed reality scenarios. While Head-Mounted Devices (HMDs) offer limited input signals such as head and hands 6-DoF, recent approaches have shown impressive results in generating full body motion using only head and hands signals. However, existing methods rely on full hand visibility, which can be a challenge when using egocentric hand tracking without motion controllers. This is due to the restricted field of view of the HMD, leading to partial hand visibility. To address this issue, we propose HMD-NeMo, the first unified approach that generates plausible and accurate full body motion even when the hands are only partially visible. HMD-NeMo is a lightweight neural network that predicts full body motion in real-time. Central to HMD-NeMo is a spatio-temporal encoder with innovative temporally adaptable mask tokens, which promote realistic motion in the absence of hand observations. We extensively analyze the impact of different components in HMD-NeMo and evaluate its performance on the AMASS dataset, where it achieves state-of-the-art results.