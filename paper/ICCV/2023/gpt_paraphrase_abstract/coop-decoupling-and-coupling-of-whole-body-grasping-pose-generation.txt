Generating realistic human grasping motions in computer graphics has been a subject of interest. Previous studies have used keyframe-guided motion generation frameworks to model human grasping motions when objects are placed in front of them. However, these frameworks have limitations in capturing the full range of human grasping poses. To address this issue, we propose a new framework called COOP (DeCOupling and COupling of Whole-BodyGrasPing Pose Generation) that synthesizes life-like whole-body poses covering a wide range of human grasping capabilities. In COOP, we decouple the whole-body pose into body and hand poses, allowing us to pre-train the body model using out-of-domain data. We then couple these two generated body parts using a unified optimization algorithm. Additionally, we develop an evaluation method to assess the generalization ability of the models in generating grasping poses for objects at different positions. Experimental results demonstrate the effectiveness and superiority of our method. COOP has the potential to be used as a plug-and-play component in other domains of whole-body pose generation. Our models and code are publicly available.