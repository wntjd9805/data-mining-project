Scene text recognition has been extensively studied for many years due to its wide range of applications. However, there has been limited research on Chinese Text Recognition (CTR) despite the distinct characteristics of Chinese characters compared to Latin characters, such as intricate inner structures and numerous categories. The challenge of dealing with zero-shot and few-shot Chinese characters, especially due to the large number of categories, has not been adequately addressed. To address this, our paper proposes a two-stage framework for CTR inspired by human recognition of Chinese texts. In the first stage, we pre-train a CLIP-like model by aligning printed character images with Ideographic Description Sequences (IDS). This pre-training stage aims to simulate human recognition and obtain the canonical representation of each character. In the second stage, these learned representations are utilized to supervise the CTR model, improving traditional single-character recognition to text-line recognition through image-IDS matching. To evaluate the effectiveness of our proposed method, we conduct extensive experiments on both Chinese character recognition (CCR) and CTR. The results show that our method achieves the best performance in CCR and outperforms previous methods in most scenarios of the CTR benchmark. Importantly, our method can recognize zero-shot Chinese characters in text images without requiring fine-tuning, unlike previous methods that necessitate fine-tuning for new classes. The code for our method is available at https://github.com/FudanVI/FudanOCR/tree/main/image-ids-CTR.