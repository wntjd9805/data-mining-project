Current methods for dealing with the difference between training and test samples have focused on learning generalizable features during training and ignoring the specificity of unseen samples during testing. This paper addresses the challenge of adapting a trained CNN model to unseen domains during testing. To make the most of the information in the test data, the proposed method, called DomainAdaptor, combines an AdaMixBN module and a Generalized Entropy Minimization (GEM) loss. The AdaMixBN module addresses the domain shift by adaptively combining training and test statistics in the normalization layer using a dynamic mixture coefficient and a statistic transformation operation. To further enhance adaptation, the GEM loss extends the Entropy Minimization loss to better utilize information in the test data. Extensive experiments demonstrate that DomainAdaptor consistently outperforms state-of-the-art methods on four benchmarks. Additionally, our method shows significant improvement compared to existing methods in the few-data unseen domain. The code for DomainAdaptor is available at https://github.com/koncle/DomainAdaptor.