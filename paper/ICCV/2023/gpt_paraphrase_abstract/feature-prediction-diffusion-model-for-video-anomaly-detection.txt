Anomaly detection in videos is a difficult task in real-world applications, mainly due to the lack of large-scale annotated anomaly events. Existing video anomaly detection methods primarily focus on learning the distribution of normal samples to identify significantly deviated samples as anomalies. To improve the learning of normal motion and appearance, auxiliary networks are often used to extract foreground object or action information. These high-level semantic features help filter out background noise and enhance the accuracy of detection models. However, the effectiveness of these additional semantic models greatly influences the performance of video anomaly detection methods.In this study, we propose a novel approach based on diffusion models (DM) to predict video frame features for anomaly detection. DMs have impressive generative and anti-noise capabilities, making them suitable for this task. Our method aims to learn the distribution of normal samples without the need for additional high-level semantic feature extraction models. To achieve this, we develop two denoising diffusion implicit modules that predict and refine the features. The first module focuses on feature motion learning, while the second module concentrates on feature appearance learning. To the best of our knowledge, this is the first DM-based method for predicting frame features in video anomaly detection. The strong capacity of DMs allows our method to accurately predict normal features compared to non-DM-based feature prediction approaches. Extensive experiments demonstrate that our proposed approach outperforms state-of-the-art methods. The code for our approach is available at FPDM.