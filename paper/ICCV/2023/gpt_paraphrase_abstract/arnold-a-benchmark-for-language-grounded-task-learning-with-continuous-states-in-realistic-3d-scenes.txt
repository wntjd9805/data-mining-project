Understanding the continuous states of objects is crucial for learning and planning tasks in the real world. However, most existing benchmarks for task learning assume discrete object goal states, which makes it difficult to learn complex tasks and transfer policies from simulated environments to the real world. Additionally, state discretization limits a robot's ability to follow human instructions based on actions and states. To address these challenges, we introduce ARNOLD, a benchmark that evaluates language-grounded task learning with continuous states in realistic 3D scenes. ARNOLD consists of eight tasks that involve understanding object states and learning policies for continuous goals. To facilitate language-instructed learning, we provide expert demonstrations with template-generated language descriptions. We evaluate task performance using state-of-the-art language-conditioned policy learning models. Our findings indicate that current models for language-conditioned manipulations face significant challenges in generalizing to novel goal states, scenes, and objects. These results emphasize the need for new algorithms to bridge this gap and highlight the potential for further research in this area.