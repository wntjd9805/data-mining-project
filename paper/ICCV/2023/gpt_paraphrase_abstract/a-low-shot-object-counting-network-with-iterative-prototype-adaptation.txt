We explore the problem of counting objects in images with limited annotated data, either through a few-shot or no-shot approach. The current few-shot pipeline lacks accuracy in object localization and count estimation due to the neglect of shape information. To address this, we propose a novel network called LOCA (Low-shot Object Counting network with iterative prototype Adaptation). The key innovation is a module that iteratively combines the shape and appearance information from exemplars with image features to extract object prototypes. This module can be easily adapted to zero-shot scenarios, allowing LOCA to handle a wide range of low-shot counting problems. Our approach outperforms state-of-the-art methods on the FSC147 benchmark, achieving a 20-30% reduction in RMSE for one-shot and few-shot scenarios, and setting a new state-of-the-art for zero-shot scenarios. LOCA also demonstrates superior generalization capabilities. The code and models for LOCA are publicly available at https://github.com/djukicn/loca. Figure 1 illustrates how LOCA incorporates shape and appearance information into object queries, enabling precise counting of objects of various sizes in both densely and sparsely populated scenarios. Furthermore, LOCA extends to zero-shot scenarios and achieves excellent localization and count accuracy across the entire low-shot spectrum.