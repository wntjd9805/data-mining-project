This paper presents a novel approach to point cloud oversegmentation, which aims to produce meaningful partitions of a point cloud. Existing methods struggle to efficiently generate these partitions from large-scale LiDAR point clouds due to their complex and inefficient procedures. In contrast, the proposed method is a simple yet efficient end-to-end LiDAR oversegmentation network. It segments superpoints from the point cloud by grouping points based on low-level point embeddings. The process involves learning the similarity of points and obtaining low-level point embeddings through a local discriminative loss. A LiDAR point grouping algorithm is then used to generate homogeneous superpoints by considering both the similarity of point embeddings and the Euclidean distance of points in 3D space. To enhance accuracy, a superpoint refinement module is designed to assign hard boundary points to their corresponding superpoints. Experimental results on two large-scale outdoor datasets demonstrate that the proposed method achieves state-of-the-art performance in LiDAR oversegmentation. Notably, the inference time of the method is 100 times faster than that of other methods. Additionally, the learned superpoints are applied to LiDAR semantic segmentation, showing significant improvement compared to the baseline network. The code for the proposed method is available at https://github.com/fpthink/SuperLiDAR.