We propose a 3D generation pipeline that employs diffusion models to create authentic digital avatars of humans. Generating 3D human meshes has been challenging due to the diverse range of identities, poses, and stochastic details involved. To tackle this issue, we divide the problem into two parts: 2D normal map generation and normal map-based 3D reconstruction. We use a pose-conditional diffusion model to simultaneously generate realistic dual normal maps for the front and backside of clothed humans. For 3D reconstruction, we optimize the prior SMPL-X mesh based on the normal maps to obtain a detailed 3D mesh. To enhance high-frequency details, we introduce a diffusion resampling scheme for both body and facial regions, promoting the generation of lifelike digital avatars. Additionally, we seamlessly integrate a recent text-to-image diffusion model to enable text-based control over human identity. Our method, named Chupa, is capable of producing realistic 3D clothed humans with improved perceptual quality and a wider range of identities.