Recent developments in 3D hand pose estimation have shown promise, but their effectiveness heavily relies on the availability of large-scale annotated datasets, which are expensive and time-consuming to create. To address this limitation, we propose a self-supervised learning framework called HaMuCo. HaMuCo learns a hand pose estimator from pseudo 2D labels generated from multiple views. However, self-supervised learning faces challenges such as noisy labels and the "groupthink" effect from multiple views. To overcome these challenges, we introduce a cross-view interaction network that distills the single-view estimator by utilizing cross-view correlated features and enforcing multi-view consistency for collaborative learning. Both the single-view estimator and the cross-view interaction network are trained jointly in an end-to-end manner. Extensive experiments demonstrate that our approach achieves state-of-the-art performance in multi-view self-supervised hand pose estimation. Additionally, the proposed cross-view interaction network can also be used for hand pose estimation from multi-view input and outperforms previous methods in the same settings.