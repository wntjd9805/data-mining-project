Many existing visual object tracking methods rely on estimating the location of an object based on 2D segmentation or bounding box information in each frame of a video. However, this representation has limitations. In this study, we propose a new approach that enhances 2D tracking by incorporating an explicit object representation, specifically the textured 3D shape and 6DoF pose in each frame. Our method addresses the challenging problem of establishing dense correspondence between all 3D points on the object across all video frames, even when some points are not visible. To achieve this, we use differentiable rendering to re-render the input frames, a technique that has not been previously used for tracking. We optimize our approach by minimizing a novel loss function that estimates the optimal 3D shape, texture, and 6DoF pose. Through experiments on three datasets with mostly rigid objects, we demonstrate that our method outperforms the current state-of-the-art in 2D segmentation tracking.