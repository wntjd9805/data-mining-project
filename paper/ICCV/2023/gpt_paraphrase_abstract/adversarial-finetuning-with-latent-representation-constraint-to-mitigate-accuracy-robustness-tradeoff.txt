This paper focuses on the tradeoff between accuracy on clean examples and robustness against adversarial examples in deep neural networks (DNNs). While adversarial training (AT) enhances robustness, it compromises standard accuracy, resulting in a tradeoff. To address this tradeoff, a new AT method called ARREST is proposed, consisting of three components: adversarial finetuning (AFT), representation-guided knowledge distillation (RGKD), and noisy replay (NR). AFT trains a DNN on adversarial examples by initializing its parameters with a DNN that is pretrained on clean examples. RGKD and NR involve a regularization term and an algorithm, respectively, to preserve the latent representations of clean examples during AFT. RGKD penalizes the difference between the representations of the pretrained and AFT DNNs, while NR switches input adversarial examples to nonadversarial ones when there is a significant change in representation. Through the combination of these components, ARREST achieves both high accuracy and robustness. Experimental results demonstrate that ARREST effectively mitigates the tradeoff compared to previous AT-based methods.