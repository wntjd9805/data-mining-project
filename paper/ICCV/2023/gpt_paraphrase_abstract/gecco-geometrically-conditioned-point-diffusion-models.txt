Recently, there has been a lot of attention on diffusion models that can generate images based on text input. These models have gained popularity outside of the computer vision community. In this study, we focus on the task of generating point clouds, both with and without conditional images. To achieve this, we propose a new method that involves projecting sparse image features onto the point cloud and attaching them to each individual point during the denoising process. This approach improves the consistency of the generated point clouds and produces more accurate results compared to existing methods that use unstructured latent codes. Additionally, we incorporate recent continuous-time diffusion schemes into our method. Our experiments demonstrate that our approach performs on par with or better than the current state-of-the-art methods for both conditional and unconditional generation tasks on synthetic data. Furthermore, our method is faster, lighter, and provides tractable likelihoods. We also demonstrate that our method can scale to various indoor scenes.