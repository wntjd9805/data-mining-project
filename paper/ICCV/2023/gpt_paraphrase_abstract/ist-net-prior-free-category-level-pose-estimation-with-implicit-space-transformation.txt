The objective of category-level 6D pose estimation is to predict the poses and sizes of unseen objects within a specific category. Previous methods have achieved success by using category-specific 3D priors, which are obtained through collecting a large number of 3D models. However, this data collection process is time-consuming and often impractical. This study aims to investigate whether these priors are necessary for effective pose estimation. The empirical study reveals that the success of prior-based methods is not solely attributed to the 3D priors themselves, but rather to the explicit deformation process that aligns camera and world coordinates using world-space 3D models. Based on these findings, a prior-free implicit space transformation network called IST-Net is introduced. IST-Net transforms camera-space features to world-space counterparts and establishes correspondences between them without relying on 3D priors. Additionally, camera- and world-space enhancers are designed to enrich the features with pose-sensitive information and geometric constraints. Despite its simplicity, IST-Net achieves state-of-the-art performance without the need for priors, and it demonstrates top inference speed on the REAL275 benchmark. The IST-Net code and models are available at https://github.com/CVMI-Lab/IST-Net.