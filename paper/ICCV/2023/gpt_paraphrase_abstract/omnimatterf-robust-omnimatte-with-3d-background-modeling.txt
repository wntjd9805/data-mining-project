Video matting is a versatile technique used for various purposes, such as enhancing videos and aiding professionals in video production. Recent research has focused on matting methods that include effects like shadows and reflections, with Omnimatte being one such proposed method. However, existing approaches represent video backgrounds as 2D image layers, which limits their ability to handle complex scenes found in real-world videos. To address this limitation, we introduce a new video matting method called OmnimatteRF. Our approach combines dynamic 2D foreground layers with a 3D background model. The 2D layers preserve subject details, while the 3D background robustly reconstructs scenes in real-world videos. Through extensive experiments, we demonstrate that our method produces higher-quality scene reconstructions across various videos.