Many current methods for estimating the pose of objects in images rely on predicting 2D-3D correspondences and using a PnP solver to obtain the pose. However, the non-differentiable nature of PnP solvers makes it difficult to supervise these methods effectively. To address this, some methods have proposed differentiable PnP strategies to supervise the pose estimation after the PnP step. However, we argue that this approach conflicts with the averaging nature of the PnP problem, potentially leading to degraded accuracy of individual correspondences. To overcome this issue, we propose a new loss function that leverages the ground truth pose before solving the PnP problem. We linearize the PnP solver around the ground-truth pose and calculate the covariance of the resulting pose distribution. Our loss function is then defined based on the diagonal covariance elements, allowing us to consider the final pose estimate without suffering from the averaging issue of PnP. Through experiments, we demonstrate that our loss function consistently improves the accuracy of pose estimation for both dense and sparse correspondence-based methods. Our approach achieves state-of-the-art results on the Linemod-Occluded and YCB-Video datasets.