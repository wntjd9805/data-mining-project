Machine learning models are susceptible to adversarial perturbations, such as the adversarial patch attack, which involves placing a specially crafted sticker on an object to mispredict it. This poses a significant threat to cyber-physical systems like autonomous cars that rely on cameras. However, conducting research in this area is challenging due to the high cost of evaluating attacks and defenses in the real world, and the unrealistic nature of synthetic data. To address this, we propose the REAP benchmark, which allows for evaluations on real images under real-world conditions. This benchmark is built on the Mapillary Vistas dataset and includes over 14,000 traffic signs. Each sign is augmented with geometric and lighting transformations to realistically apply a digitally generated patch. Using this benchmark, we conducted large-scale assessments of adversarial patch attacks and found that the threat may be smaller than previously believed. We also discovered that the success rate of an attack on simpler digital simulations does not accurately predict its effectiveness in practice. The REAP benchmark is publicly available at https://github.com/wagner-group/reap-benchmark.