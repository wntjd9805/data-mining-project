Semantic occupancy perception is crucial for autonomous driving, as self-driving vehicles require accurate perception of the 3D structures in urban environments. However, existing benchmarks for evaluating surrounding perception algorithms lack diversity in urban scenes and only assess front-view predictions. To address this, we propose OpenOccupancy, the first benchmark for surrounding semantic occupancy perception. In this benchmark, we enhance the nuScenes dataset with dense semantic occupancy annotations. Unlike previous annotations that rely on LiDAR points, our annotations are densified using the Augmenting And Purifying (AAP) pipeline, which involves approximately 4000 human hours. Additionally, we establish camera-based, LiDAR-based, and multi-modal baselines for the OpenOccupancy benchmark. To tackle the computational burden of high-resolution 3D predictions, we introduce the Cascade Occupancy Network (CONet) to refine the coarse predictions, resulting in a performance improvement of approximately 30% compared to the baseline. We believe that the OpenOccupancy benchmark will stimulate the development of surrounding occupancy perception algorithms.