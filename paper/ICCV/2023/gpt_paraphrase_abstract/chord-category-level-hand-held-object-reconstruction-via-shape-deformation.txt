The ability to model the shape of hand-held objects is crucial for AI to understand daily tasks and learn manipulation skills. However, previous methods have struggled to accurately reconstruct the precise shapes of these objects due to a lack of prior shape knowledge and insufficient training data. Humans, on the other hand, have a limited number of effective ways to manipulate certain objects, such as mugs, because they have a strong understanding of the shape characteristics of these objects. Building on this insight, we propose a new method called CHORD for reconstructing hand-held objects by deforming a categorical shape prior. To ensure accurate reconstruction, CHORD incorporates awareness of appearance, shape, and interacting pose. We also introduce a new dataset called COMIC, which includes a wide range of object instances, materials, hand interactions, and viewing directions at the category level. Extensive evaluation demonstrates that CHORD outperforms existing approaches both quantitatively and qualitatively. The code, model, and datasets for CHORD are available at https://kailinli.github.io/CHORD.