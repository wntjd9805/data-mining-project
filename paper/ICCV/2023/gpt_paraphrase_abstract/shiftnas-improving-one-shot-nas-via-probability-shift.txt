One-shot Neural architecture search (One-shot NAS) is a time-efficient method for finding optimal subnet architectures and weights in various complexity cases through a single training process. However, the performance of subnets obtained through weight sharing is often lower than that of subnets obtained through retraining. This discrepancy is attributed to the use of uniform sampling in supernet training, where training resources are concentrated on subnets with intermediate computational resources. This approach does not account for the fact that subnets with different complexity regions require different training strategies for optimal performance. To address the issue of uniform sampling, we propose ShiftNAS, a method that adjusts the sampling probability based on subnet complexity. We achieve this by evaluating the performance variation of subnets with different complexities and designing an architecture generator that can efficiently provide subnets with the desired complexity. Both the sampling probability and the architecture generator can be trained end-to-end using gradient-based methods. With ShiftNAS, we can directly obtain the optimal model architecture and parameters for a given computational complexity. We evaluate ShiftNAS on various visual network models, including convolutional neural networks (CNNs) and vision transformers (ViTs), and demonstrate its model-agnostic nature. Experimental results on ImageNet show that ShiftNAS improves the performance of one-shot NAS without additional consumption. The source codes for ShiftNAS are available on GitHub.