Self-training via pseudo labeling is a popular method in semi-supervised learning for semantic segmentation using deep neural networks. However, current self-training algorithms suffer from using a fixed threshold to select unlabeled samples, which does not adapt to varying learning difficulties and model status. To address this, we propose Enhanced Soft Label (ESL), a curriculum learning approach that leverages the high-value supervisory signals in untrustworthy pseudo labels. ESL utilizes a Dynamic Soft Label (DSL) module to maintain high probability classes and make use of high entropy predictions. However, DSL introduces ambiguity between dominant classes, blurring the classification boundary. To overcome this, we introduce a pixel-to-part contrastive learning method with an unsupervised object part grouping mechanism to improve class distinction. Our experimental results on Pascal VOC 2012 and Cityscapes datasets demonstrate significant improvements over existing state-of-the-art approaches.