Recent advancements in large-scale text-to-image models have demonstrated impressive image synthesis capabilities. However, the integration of specific visual concepts into existing images remains a challenge. Existing methods fail to effectively preserve content or accurately translate visual concepts. To address this issue, we propose a novel framework called visual concept translator (VCT). VCT is designed to preserve content from the source image while accurately translating visual concepts based on a single reference image. The framework comprises two key processes: content-concept inversion (CCI) to extract contents and concepts, and content-concept fusion (CCF) to combine the extracted information and generate the target image. Remarkably, VCT achieves excellent results across a wide range of general image-to-image translation tasks using only one reference image. We conducted extensive experiments to validate the effectiveness and superiority of our proposed methods. The code for VCT is available at https://github.com/CrystalNeuro/visual-concept-translator.