The lack of a large video dataset for analyzing human behaviors in chaotic events hinders the development of applications such as crowd management and emergency response services. To address this gap, we introduce the Chaotic World dataset, which provides comprehensive annotations for various aspects of human behaviors in chaotic situations. This dataset includes fine-grained spatio-temporal annotations for sounds, individual actions, and group interactions, as well as text descriptions for each scene in each video. It consists of a total of 299,923 annotated instances for detecting human behaviors, 224,275 instances for analyzing interactions between people, 336,390 instances for localizing scenes of interest, and 378,093 instances for determining the source of sound. Given the complexity and challenges of chaotic events, such as large crowds and occlusions, our dataset aims to facilitate the development and evaluation of advanced models for analyzing human behaviors. In addition, we propose the IntelliCare model, which incorporates a Dynamic Knowledge Pathfinder module to analyze various aspects of chaotic scenes. Our experiments demonstrate promising results. The Chaotic World dataset and code are available at https://github.com/sutdcv/Chaotic-World.