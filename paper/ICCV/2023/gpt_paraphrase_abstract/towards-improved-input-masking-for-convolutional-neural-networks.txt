Removing features from input images in machine learning models is crucial for understanding and interpreting model predictions. However, this task is challenging for vision models as masking out parts of the image leads to significant distribution shifts. The use of a baseline color (such as grey or black) for masking is out of distribution, and the mask shape can introduce unwanted signals that influence the model's predictions. Recent advancements have addressed this issue in image masking for vision transformers.In this study, we propose a new masking method called layer masking for CNNs, which effectively reduces the missingness bias caused by masking. Layer masking applies a mask to intermediate activation maps, allowing the model to process only the unmasked input. Our method eliminates or minimizes the impact of mask shape or color on the model's output and outperforms techniques like LIME that replace the masked region with black or grey for interpretability.Layer masking is less affected by missingness bias compared to other masking strategies. We also demonstrate that the mask shape can leak information about the class, affecting estimates of the model's reliance on class-relevant features derived from input masking. Additionally, we discuss the limitations of data augmentation techniques in preventing the model's reliance on mask shape.In summary, our study introduces layer masking as an effective method for reducing missingness bias in CNNs. We highlight its advantages over other masking strategies and discuss the implications of mask shape on model reliance.