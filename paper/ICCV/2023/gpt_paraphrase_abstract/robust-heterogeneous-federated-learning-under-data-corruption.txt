This paper addresses the problem of data corruption in the model heterogeneous federated learning framework. Due to limitations in data collection, storage, and transmission conditions, as well as the presence of free-rider participants, clients may experience data corruption. To tackle this issue, the paper proposes a new method called Augmented Heterogeneous Federated Learning (AugHFL). AugHFL consists of two stages:   1) In the local update stage, a corruption-robust data augmentation strategy is employed to minimize the negative effects of local corruption. This strategy allows the models to acquire valuable local knowledge.  2) In the collaborative update stage, a robust re-weighted communication approach is designed to facilitate communication between heterogeneous models while minimizing the transfer of corrupted knowledge from others.  The effectiveness of AugHFL is demonstrated through extensive experiments, showcasing its ability to handle various corruption patterns in the model heterogeneous federated learning setting.