In recent years, deep learning has become increasingly successful and there has been a surge in the release of trained models. However, quantifying the functional distance between these models has proven to be challenging due to their complexity and differences in architecture and tasks. To address this issue, we propose a new approach called Model Gradient Field (ModelGiF), which extracts homogeneous representations from diverse pre-trained models. Our assumption is that each deep model uniquely determines a ModelGiF over the input space, and the similarity between ModelGiFs can be used to measure the distance between models. We validate the effectiveness of ModelGiF through various tests, including estimating task relatedness, protecting intellectual property, and verifying model unlearning. Our experimental results show that ModelGiF outperforms existing methods in these tasks. The code for ModelGiF is available at https://github.com/zju-vipa/modelgif.