The current datasets for interacting hand (IH) recognition are limited in terms of background and texture complexity, and the machine annotation of hand joints can lead to inaccuracies. There is also a lack of diversity in pose distribution. In order to address these limitations, we introduce RenderIH, a large-scale synthetic dataset for interacting hands. RenderIH consists of 1 million photo-realistic images with diverse backgrounds, perspectives, and hand textures. To ensure natural and diverse poses, we propose a new pose optimization algorithm. We also introduce TransHand, a transformer-based pose estimation network, to improve accuracy. Our dataset is not specific to any particular model and can enhance the accuracy of any hand pose estimation method compared to other real or synthetic datasets. Experimental results demonstrate that pretraining on RenderIH significantly reduces error from 6.76mm to 5.79mm, and TransHand outperforms other contemporary methods. The dataset and code are available at https://github.com/adwardlee/RenderIH.