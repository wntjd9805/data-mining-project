We introduce DINAR, a method for generating realistic rigged fullbody avatars from single RGB images. Like previous approaches, our method utilizes neural textures and the SMPL-X body model to produce avatars that are both visually realistic and easy to animate. To restore the texture, we employ a latent diffusion model and demonstrate how this model can be trained in the neural texture space. The use of the diffusion model enables us to accurately reconstruct unseen areas, such as the back of a person, based on the frontal view. Our pipeline is trained exclusively using 2D images and videos. Through experiments, we demonstrate that our approach achieves state-of-the-art rendering quality and exhibits strong generalization to new poses and viewpoints. Notably, our method surpasses the current state-of-the-art on the SnapshotPeople public benchmark.