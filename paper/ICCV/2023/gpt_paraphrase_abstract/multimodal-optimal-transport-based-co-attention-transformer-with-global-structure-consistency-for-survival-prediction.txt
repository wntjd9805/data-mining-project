Survival prediction is a complex task that involves predicting the risk of death based on the ranking of patients. This task can be improved by combining histology and genomic data. However, existing methods face challenges in effectively representing large pathological images and capturing interactions within the tumor microenvironment. Current approaches focus on local similarities between histology and genomics, but fail to consider global consistency between potential structures.   To address these challenges, we propose a framework called Multimodal Optimal Transport-based Co-Attention Transformer with global structure consistency. This framework uses optimal transport (OT) to match patches of a whole slide image (WSI) with gene embeddings, selecting informative patches to represent the WSI. Additionally, OT-based co-attention allows for the capture of structural interactions within the tumor microenvironment for survival prediction.   To overcome the computational complexity of OT, we propose a robust and efficient implementation using micro-batches of WSI patches and approximating the original OT with unbalanced mini-batch OT. Extensive experiments demonstrate the superiority of our method compared to state-of-the-art techniques on five benchmark datasets. The code for our method is publicly available.