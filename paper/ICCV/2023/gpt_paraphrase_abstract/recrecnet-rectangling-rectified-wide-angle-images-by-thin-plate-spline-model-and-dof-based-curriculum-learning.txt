The use of wide-angle lenses in virtual reality (VR) technologies is popular, but these lenses introduce significant radial distortion to the captured image. Previous efforts to rectify this distortion have resulted in changes to the image boundary, which can mislead current vision perception models. In this study, we propose a new learning model called the Rectangling Rectification Network (RecRecNet) to address this issue. Our model uses a thin-plate spline (TPS) module to achieve non-linear and non-rigid transformations for rectangling images. By learning control points on the rectified image, our model can flexibly warp the source structure to the target domain, achieving unsupervised deformation. To simplify the structure approximation process, we introduce a Degree of Freedom (DoF)-based curriculum learning approach, allowing our model to learn gradual deformation rules. By increasing the DoF at each curriculum stage, our network can investigate more detailed deformations and converge quickly on the final rectangling task. Experimental results demonstrate the superiority of our solution compared to other methods, both quantitatively and qualitatively. The code and dataset for our solution are available at https://github.com/KangLiao929/RecRecNet.