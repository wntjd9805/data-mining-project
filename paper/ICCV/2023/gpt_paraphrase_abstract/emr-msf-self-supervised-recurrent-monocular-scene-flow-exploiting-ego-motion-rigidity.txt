We present a new model called EMR-MSF for self-supervised monocular scene flow estimation. This approach aims to understand 3D structures and motions using only two consecutive monocular images. Current methods in this field suffer from accuracy issues due to inefficient network architecture and a lack of motion rigidity for regularization. To address these challenges, we leverage the advantages of network architecture design in supervised learning and propose an ego-motion aggregation module. This module incorporates explicit geometric constraints, including a rigidity soft mask to filter out dynamic regions and improve stability in ego-motion estimation. Additionally, we introduce a motion consistency loss and a mask regularization loss to fully utilize static regions. We also integrate efficient training strategies such as gradient detachment and enhanced view synthesis. Our method significantly outperforms previous self-supervised approaches and achieves comparable performance to supervised methods. On the KITTI scene flow benchmark, our approach improves the SF-all metric by 44% and demonstrates superior performance across various sub-tasks including depth estimation and visual odometry.