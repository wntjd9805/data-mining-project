We present a new method to annotate complex multi-object scenes in videos with a globally consistent 3D representation. Our approach involves assigning a CAD model to each object and placing it within the 3D coordinate frame of the scene using a 9-DoF pose transformation. This annotation process is semi-automatic and can be applied to RGB videos without the need for a depth sensor. Most of the steps are automated, and the human involvement is minimal and straightforward, making it suitable for crowd-sourcing. Leveraging this method, we have created a large-scale dataset called CAD-Estate by annotating real-estate videos from YouTube. CAD-Estate consists of 101k instances of 12k unique CAD models positioned within the 3D representations of 20k videos. Compared to the existing Scan2CAD dataset, CAD-Estate offers 7 times more instances and 4 times more unique CAD models. We demonstrate the advantages of pre-training a Mask2CAD model on CAD-Estate for the task of automatic 3D object reconstruction and pose estimation, showing improved performance in popular applications.