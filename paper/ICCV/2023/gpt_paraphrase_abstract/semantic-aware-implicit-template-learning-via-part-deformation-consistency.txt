Recent advances in unsupervised shape correspondence have demonstrated impressive results by learning implicit templates as neural fields. However, current approaches that rely solely on geometric information often produce suboptimal deformations for objects with high structural variability. This paper emphasizes the importance of consistent part deformation and introduces a semantic-aware implicit template learning framework to enable semantically plausible deformations.To achieve this, we utilize a self-supervised feature extractor to incorporate semantic priors. We propose a novel semantic-aware deformation code and introduce regularizations for part deformation, global deformation, and global scaling. Extensive experiments are conducted to validate the effectiveness of our approach compared to baseline methods in tasks such as keypoint transfer, part label transfer, and texture transfer. Notably, our framework exhibits even greater performance improvements in more challenging scenarios.Moreover, qualitative analyses are performed to further confirm the benefits of semantic-aware deformation. The code for our method is publicly available at https://github.com/mlvlab/PDC.