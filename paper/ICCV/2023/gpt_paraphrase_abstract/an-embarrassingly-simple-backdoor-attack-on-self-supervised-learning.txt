Self-supervised learning (SSL) is a new approach in machine learning that can learn complex data representations without relying on labels. It has been shown to improve adversarial robustness compared to supervised learning by making it difficult for adversaries to manipulate model predictions. However, it is unknown how this robustness applies to other types of attacks, such as backdoor attacks. In this study, we investigate the vulnerability of SSL to backdoor attacks and introduce CTRL, a simple yet effective self-supervised backdoor attack. By contaminating a small fraction of training data with undetectable poisoning samples, CTRL causes any input with a hidden trigger to be misclassified with a high probability at inference time. Our results indicate that SSL is similarly vulnerable to backdoor attacks compared to supervised learning. Furthermore, we find that the representation invariance property of SSL, which contributes to its adversarial robustness, may also be the reason for its susceptibility to backdoor attacks. This suggests that existing defenses against supervised backdoor attacks may not be applicable to SSL. The code for CTRL is available at https://github.com/meet-cjli/CTRL.