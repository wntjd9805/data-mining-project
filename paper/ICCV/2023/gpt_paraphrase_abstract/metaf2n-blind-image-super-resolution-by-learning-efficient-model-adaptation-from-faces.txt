The recovery of faces in blind image super-resolution is easier than natural scenes due to their structured characteristics. To address the time-consuming and uncertain optimization process in synthesizing realistic low-quality images, we propose MetaF2N. This method utilizes faces to fine-tune model parameters for adapting to the entire natural image in a Meta-learning framework, eliminating the need for degradation extraction and low-quality image synthesis. With only one fine-tuning step, MetaF2N achieves decent performance. To mitigate the impact of low-confidence areas, we incorporate MaskNet to predict loss weights adaptively. Our evaluation on a real-world low-quality dataset demonstrates that MetaF2N outperforms both synthetic and real-world datasets. The source code, pre-trained models, and collected datasets can be found at https://github.com/yinzhicun/MetaF2N.