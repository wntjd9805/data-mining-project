Fine-tuning a pre-trained visual model can address the problem of overfitting on vision tasks with limited training data by utilizing semantic information from large-scale pre-training data. However, the potential bias of the pre-training task and data on the fine-tuned model has received less attention compared to the issue of catastrophic forgetting. This study investigates this bias by showing that the fine-tuned classifier closely resembles the classifier induced by the pre-trained model. To effectively reduce this bias, the authors propose a method called Text Supervised fine-tuning (TeS) which incorporates a reference distribution obtained from a fixed text classifier to regularize the learned vision classifier. The TeS method is evaluated on 11 downstream tasks using various pre-trained vision models (ResNet and ViT) and text encoders (BERT and CLIP). The experimental results demonstrate consistent improvements with a significant margin across different scenarios, confirming the effectiveness of the proposed approach. The code for the TeS method is available at https://github.com/idstcv/TeS.