We propose a Multi-scale Residual Low-Pass Filter Network (MRLPFNet) that effectively addresses image deblurring by considering both image details and main structures. We observed that the difference between blurry and clear images contains both high-frequency and low-frequency information due to blur. Traditional residual learning is not effective in modeling the main structure distorted by blur. To handle this, we introduce a learnable low-pass filter using a self-attention mechanism to adaptively explore global contexts and improve modeling of low-frequency information. This filter is integrated into a Residual Low-Pass Filter (RLPF) module, which incorporates a fully convolutional neural network to model high-frequency information. The RLPF module is formulated as an end-to-end trainable network using an encoder-decoder architecture and includes a wavelet-based feature fusion for combining multi-scale features. Our experimental results demonstrate that our method outperforms state-of-the-art approaches on commonly-used benchmarks.