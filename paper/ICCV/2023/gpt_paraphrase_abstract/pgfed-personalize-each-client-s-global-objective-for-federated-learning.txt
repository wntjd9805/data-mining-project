Personalized federated learning has gained attention as a solution to the limitations of conventional federated learning. Unlike conventional FL, personalized FL allows for individual models for each client. However, existing personalized FL algorithms only transfer knowledge implicitly, which fails to fully utilize each client's potential. In response, we propose Personalized Global Federated Learning (PGFed), a new framework that enables each client to personalize its global objective by explicitly aggregating the empirical risks of itself and other clients. To address communication and privacy concerns, we estimate each client's risk through a first-order approximation. Additionally, we introduce a momentum upgrade called PGFedMo to further enhance the utilization of clients' empirical risks. Our experiments on various datasets demonstrate the consistent superiority of PGFed over previous methods. The code for PGFed is publicly available at https://github.com/ljaiverson/pgfed.