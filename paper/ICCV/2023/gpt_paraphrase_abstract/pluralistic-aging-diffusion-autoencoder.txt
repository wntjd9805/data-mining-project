This study addresses the challenge of face aging, which is a complex problem due to the existence of multiple possible aging patterns for a given input. Existing methods typically provide a single estimation, which limits the diversity of the generated aging patterns. To overcome this limitation, a new approach called CLIP-driven Pluralistic Aging Diffusion Autoencoder (PADA) is proposed. PADA utilizes diffusion models to generate diverse low-level aging details through a sequential denoising reverse process. Additionally, Probabilistic Aging Embedding (PAE) is introduced to capture diverse high-level aging patterns by representing age information as probabilistic distributions in the common CLIP latent space. To guide the learning process, a KL-divergence loss guided by text information is designed. The proposed method enables the generation of pluralistic face aging results conditioned on real-world aging texts and unseen face images. Experimental evaluations, both qualitative and quantitative, demonstrate that PADA produces more diverse and high-quality aging results compared to existing methods.