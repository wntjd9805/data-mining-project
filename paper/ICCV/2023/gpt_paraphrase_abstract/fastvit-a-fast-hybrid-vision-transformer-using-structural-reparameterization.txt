We present FastViT, a new hybrid vision transformer architecture that achieves a state-of-the-art balance between accuracy and latency. Our approach incorporates a novel token mixing operator called RepMixer, which reduces memory access cost by eliminating skip-connections in the network through structural reparameterization. Additionally, we employ train-time overparametrization and large kernel convolutions to enhance accuracy without significantly impacting latency. Our experiments demonstrate that FastViT outperforms other models in terms of speed, being 3.5 times faster than CMT, 4.9 times faster than EfficientNet, and faster than ConvNeXt on a mobile device while achieving the same level of accuracy on the ImageNet dataset. Moreover, at similar latency, FastViT achieves a 4.2% higher Top-1 accuracy on ImageNet compared to MobileOne. Our model consistently outperforms competing architectures across various tasks such as image classification, detection, segmentation, and 3D mesh regression, with notable improvements in latency on both mobile devices and desktop GPUs. Furthermore, FastViT exhibits robustness to out-of-distribution samples and corruptions, surpassing other robust models. The code and models for FastViT are available at https://github.com/apple/ ml-fastvit×××.