This paper introduces a new approach to point cloud registration, a crucial task in computer vision and robotics. The authors propose utilizing the invisible parts of each point cloud as masks, and treating the aligned point cloud pair as the target for reconstruction. They introduce a Masked Reconstruction Auxiliary Network (MRA) that reconstructs the complete point cloud by using encoded features from each point cloud, enhancing the capture of geometric details and overall structures. Unlike other methods that incorporate specific encoding methods into transformer models, the MRA can be easily integrated into other methods without sacrificing versatility or introducing additional computational complexity. The authors also present a novel transformer-based method called the Masked Reconstruction Transformer (MRT), which achieves precise and efficient alignment using standard transformers. Experimental results on various datasets demonstrate the superior performance of MRT compared to state-of-the-art methods. The code for MRA is available at a specified GitHub repository.