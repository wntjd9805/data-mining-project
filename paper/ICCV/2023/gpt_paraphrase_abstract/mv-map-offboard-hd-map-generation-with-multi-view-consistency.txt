Bird's-eye-view (BEV) perception models are often used to create high-definition maps (HD maps) with less human effort. However, these models frequently produce unreliable and inconsistent results when predicting HD maps from different viewpoints. This is because BEV perception is typically limited to onboard computation, which prevents algorithms from reasoning about multiple views simultaneously. This paper presents a solution to these limitations by proposing an offboard HD map generation setup. This setup takes advantage of the fact that HD maps are commonly built offline in data centers and can be reused. The proposed pipeline, called MV-Map, utilizes multi-view consistency and a "region-centric" framework to generate HD maps from an arbitrary number of frames. In MV-Map, the target HD maps are created by combining all the frames of onboard predictions, weighted by confidence scores provided by an "uncertainty network." To improve multi-view consistency, the uncertainty network is augmented with a global 3D structure optimized by a voxelized neural radiance field (Voxel-NeRF). Extensive experiments conducted on nuScenes demonstrate that MV-Map significantly enhances the quality of HD maps, emphasizing the importance of offboard methods for HD map generation. The code and model for MV-Map are available at https://github.com/ZiYang-xie/MV-Map.