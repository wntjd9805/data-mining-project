Spiking Neural Networks (SNNs) have the potential to be a more energy-efficient alternative to traditional artificial neural networks. However, the analysis and optimization of the inherent redundancy in SNNs have been overlooked. This study focuses on three key questions about redundancy in SNNs. The authors argue that this redundancy is caused by the spatio-temporal invariance of SNNs, which improves parameter utilization but also introduces a lot of noise spikes. The effects of spatio-temporal invariance on SNN dynamics and spike firing are analyzed. Based on these findings, an Advance Spatial Attention (ASA) module is proposed to optimize the membrane potential distribution of SNNs and regulate noise spike features. Experimental results show that this method significantly reduces spike firing while outperforming existing SNN baselines. The code for this study is available at https://github.com/BICLab/ASA-SNN.