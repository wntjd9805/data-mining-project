Large-scale pre-training models like CLIP and PaLI have shown strong generalization abilities in various visual domains and tasks. However, current image classification benchmarks only evaluate recognition within specific domains or tasks, which does not fully assess the universality of these pre-trained models. To address this, we introduce the Open-domain Visual Entity Recognition (OVEN) task, where models are required to link images to Wikipedia entities based on a text query. We create the OVEN-Wiki dataset by combining 14 existing datasets and grounding all labels to Wikipedia entities. OVEN-Wiki challenges models to choose from six million possible Wikipedia entities, making it the largest general visual recognition benchmark in terms of label count. Our analysis of state-of-the-art pre-trained models reveals significant room for improvement in generalizing to the vast label space. Surprisingly, a PaLI-based auto-regressive visual recognition model performs well, even on unseen Wikipedia entities. We also observe that different pre-trained models have varying strengths, with PaLI-based models achieving higher overall performance compared to CLIP-based models.