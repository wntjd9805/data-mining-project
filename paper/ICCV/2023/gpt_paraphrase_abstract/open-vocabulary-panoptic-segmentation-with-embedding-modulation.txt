Open-vocabulary image segmentation is a growing field with important real-world applications. Traditional closed-vocabulary methods are limited in their ability to recognize new objects, while recent open-vocabulary approaches have not performed well on both open- and closed-vocabulary tasks without additional data. In response, we propose OPSNet, a versatile and efficient framework for Open-vocabulary Panoptic Segmentation. Our framework includes an Embedding Modulation module and other carefully designed components that enhance embedding and information exchange between the segmentation model and the CLIP encoder. This leads to superior segmentation performance with reduced reliance on additional data. We extensively evaluated OPSNet on multiple datasets and achieved state-of-the-art results on COCO, ADE20K, Cityscapes, and PascalContext. Our approach demonstrates effectiveness and generality. More information can be found on our project page at https://opsnet-page.github.io.