Due to their impressive performance, Transformers have become essential in computer vision. However, their high computation cost limits their potential in video recognition. To address this, we propose the Semantic-aware Temporal Accumulation score (STA) method, which prunes spatio-temporal tokens based on two critical factors: temporal redundancy and semantic importance. The STA score determines whether a token represents a new occurrence or a known entity by analyzing token-to-token similarity in consecutive frames. Additionally, it evaluates each token's contribution to the overall prediction. Tokens with higher STA scores, indicating more temporal redundancy and lower semantics, are pruned. This pruning process is progressive and does not require additional parameters or re-training. We apply the STA module to off-the-shelf ViT and VideoSwin backbones and achieve a significant 30% reduction in computation with only a negligible âˆ¼0.2% drop in accuracy. The code for our method is available at https://github.com/Mark12Ding/STA.