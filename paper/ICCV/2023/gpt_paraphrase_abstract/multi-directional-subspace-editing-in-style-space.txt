This abstract presents a new approach to discovering distinct semantic directions in StyleGAN's latent space. The technique aims to identify orthogonal subspaces that allow for manipulation of specific attributes of human faces while minimizing unintended changes in other attributes. The model enables editing of a single attribute in multiple directions, resulting in a variety of generated images. A comparison with three state-of-the-art models demonstrates the superior performance of our method in terms of face editing and disentanglement abilities. Furthermore, we propose quantitative measures for evaluating attribute separation and disentanglement and provide evidence of our model's superiority.