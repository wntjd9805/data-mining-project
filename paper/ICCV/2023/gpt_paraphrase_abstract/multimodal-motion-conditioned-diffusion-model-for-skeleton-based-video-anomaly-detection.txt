Anomalies are uncommon occurrences that are often detected through One-Class Classification (OCC), which focuses on training models solely on normal behavior. Existing OCC techniques limit the range of normal motions and identify anything outside of this range as abnormal. However, this approach overlooks the fact that normal behavior can also exhibit variations due to humans performing actions in different ways. In this study, we propose a new generative model for video anomaly detection (VAD) that considers both normality and abnormality as multimodal. We utilize skeletal representations and advanced diffusion probabilistic models to generate diverse future human poses. By conditioning on past motion and leveraging the capabilities of diffusion processes, we generate future motions that are different but plausible. An anomaly is detected when the generated set of motions does not align with the expected future. Our model outperforms state-of-the-art techniques in anomaly detection on four established benchmarks: UBnormal, HR-UBnormal, HR-STC, and HR-Avenue.