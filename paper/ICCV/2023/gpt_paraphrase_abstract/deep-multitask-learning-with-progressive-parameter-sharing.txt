This paper presents a new approach called the Progressive Parameter-Sharing Strategy (MPPS) for training multitask learning models in computer vision. The MPPS method utilizes parameterized distributions to control the sharing of parameters among different tasks, based on the concept of Exclusive Capacity. To gradually increase the level of parameter sharing during the learning process, a scheduling mechanism inspired by curriculum learning is introduced. Additionally, a novel loss function is proposed to regularize the optimization of network parameters and the sharing probabilities of each neuron for each task. The effectiveness of the MPPS approach is demonstrated through comprehensive experiments on challenging datasets (Multi-CIFAR100, NYUv2, and Cityscapes) using various convolutional neural network architectures. The results show competitive performance and the potential for improved joint task performance when combined with existing state-of-the-art multitask learning solutions.