Nonlinear Activation (Act) models are crucial for neural representation learning as they help fit the underlying mappings. Traditional Act functions like Softplus and ReLU are inspired by neuronal behaviors. However, we aim to enhance the interpretability of Act models by reinterpreting neural feature Act through the lens of Multi-Criteria Decision-Making (MCDM). In this new perspective, activation models function as selective feature re-calibrators that suppress or emphasize features based on their importance scores measured by feature-filter similarities.To address the issue of mismatched feature scoring caused by differing norms of features and filters, we propose a set of desirable properties for effective Act models. We introduce Instantaneous Importance Estimation Units (IIEUs), a novel class of interpretable Act models that tackle this problem. These IIEUs re-calibrate features using the Instantaneous Importance (II) score, which is estimated using adaptive norm-decoupled feature-filter similarities. This approach allows us to capture cross-layer and cross-channel cues at a low computational cost.Extensive experiments conducted on various vision benchmarks demonstrate the significant improvements achieved by our IIEUs compared to state-of-the-art Act models. These results validate our interpretation of feature Act. By replacing popular Act models with IIEUs, even smaller ResNet-26 models outperform or match larger ResNet-101 models on ImageNet while using fewer parameters and computations.