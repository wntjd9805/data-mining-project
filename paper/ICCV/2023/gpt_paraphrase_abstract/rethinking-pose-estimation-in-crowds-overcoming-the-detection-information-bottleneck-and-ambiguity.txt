Pose estimation algorithms face a significant challenge when individuals interact frequently. Currently, there are two main approaches: the top-down approach, which combines an object detector with a pose estimator, and the bottom-up approach, which localizes all body parts and then links them to predict individual poses. However, both methods have limitations when individuals closely interact. Top-down methods struggle with overlapping individuals, while bottom-up methods often make inaccurate connections between distant body parts. To address these issues, we propose a new pipeline called bottom-up conditioned top-down pose estimation (BUCTD), which combines the strengths of both approaches. In our pipeline, we use a bottom-up model as the detector, which provides not only an estimated bounding box but also a pose proposal. This pose proposal is then used as a condition for an attention-based top-down model. We evaluate the performance and efficiency of our approach on animal and human pose estimation benchmarks, specifically CrowdPose and OCHuman. Our results show that our method outperforms previous state-of-the-art models by a significant margin, achieving 78.5 AP on CrowdPose and 48.5 AP on OCHuman. This represents an improvement of 8.6% and 7.8% over the prior art, respectively. Additionally, we demonstrate that our method significantly enhances performance on multi-animal benchmarks involving fish and monkeys. The code for our approach is available at https://github.com/amathislab/BUCTD.