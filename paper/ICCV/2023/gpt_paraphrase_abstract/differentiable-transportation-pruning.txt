Deep learning algorithms are increasingly being used on edge devices, but these devices have limited resources. To address this, efficient deployment of deep neural networks is necessary. Pruning methods are a valuable tool for edge deployment as they can improve storage, compute, memory bandwidth, and energy usage. This paper introduces a new and accurate pruning technique that allows for precise control over the size of the output network. The proposed method utilizes an efficient optimal transportation scheme that is made end-to-end differentiable. It automatically adjusts the exploration-exploitation behavior of the algorithm to discover accurate sparse sub-networks. The results demonstrate that this method outperforms previous pruning techniques on three different datasets, using five different models, across a wide range of pruning ratios. It also accommodates two types of sparsity budgets and pruning granularities.