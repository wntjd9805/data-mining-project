Current illumination estimation techniques have been designed for either indoor or outdoor environments, neglecting the diversity in lighting conditions. These methods either prioritize accurate energy capture, focusing on shading and cast shadows, or emphasize producing plausible texture with plausible reflections. Although some approaches offer editable lighting capabilities, they often use simplified lighting models that lack realism. To bridge this gap, we propose a novel method that combines a parametric light model with 360-degree panoramas, which can be used as high dynamic range images (HDRIs) in rendering engines. We leverage recent advancements in generative adversarial network (GAN)-based low dynamic range (LDR) panorama extrapolation to generate HDR images using parametric spherical gaussians. Our approach introduces a unique lighting co-modulation method that integrates lighting-related features throughout the generator, effectively linking the original or edited scene illumination with the panorama generation process. Our representation allows users to easily manipulate light direction, intensity, and number to influence shading and produce rich, complex reflections that seamlessly blend with the edits. Moreover, our method is applicable to both indoor and outdoor environments, achieving state-of-the-art results even when compared to domain-specific techniques.