Most current methods for 3D object detection using LiDAR focus on either single-domain learning or cross-domain adaptive learning. However, this approach is expensive and lacks scalability for autonomous driving systems. Therefore, it is desirable to train a universal 3D object detector that can work across multiple domains. In this study, we propose a novel approach to multi-domain learning and generalization for LiDAR-based 3D object detection. Our results demonstrate that jointly optimizing a detector using data from multiple domains improves its generalization capabilities compared to traditional single-domain models. To achieve this, we introduce a multi-domain knowledge transfer framework with universal feature transformation. This framework utilizes spatial and channel-wise knowledge from different domains to learn universal feature representations, enabling the optimization of a universal 3D object detector that can be deployed in various domains. Extensive experiments on four benchmark datasets (Waymo, KITTI, NuScenes, and ONCE) validate the superiority of our approach over state-of-the-art methods for multi-domain learning and generalization in LiDAR-based 3D object detection.