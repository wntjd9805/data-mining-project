Survival analysis in the field of genomics has shifted from examining clinical indicators to incorporating genomic profiles with pathological images. However, existing methods either directly combine pathological features and genomic profiles for survival prediction, overlooking cross-modal correlations, or use genomic profiles as a guide to integrate pathological image features, discarding irrelevant pathological information. To address these issues, we propose a framework called Cross-Modal Translation and Alignment (CMTA). This framework utilizes parallel encoder-decoder structures to integrate intra-modal information and generate cross-modal representation. By enhancing and recalibrating intra-modal representation using the generated cross-modal representation, the discrimination for comprehensive survival analysis is significantly improved. To explore intrinsic cross-modal correlations, we design a cross-modal attention module that acts as an information bridge between different modalities, facilitating cross-modal interactions and the transfer of complementary information. Our experiments on five public TCGA datasets demonstrate that our proposed framework outperforms existing methods. The source code for our framework has been released.