We present MVPSNet, a rapid and adaptable solution to Multi-view Photometric Stereo (MVPS). Our approach leverages a feature extraction network to effectively combine images from the same view captured under different lighting conditions, extracting geometric features from shading cues for stereo matching. We demonstrate the effectiveness of our Light Aggregated Feature Maps (LAFM) in feature matching, even in texture-less regions where traditional multi-view stereo methods often struggle. Our method achieves reconstruction results similar to the state-of-the-art PS-NeRF, while being 411Ã— faster during inference (105 seconds compared to 12 hours). Additionally, we introduce a synthetic dataset for MVPS, called sMVPS, which proves effective for training a versatile MVPS method.