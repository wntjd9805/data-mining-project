Enhancing low-light videos in the visible range is a difficult task. However, it can be made more manageable by incorporating near-infrared (NIR) information. This introduces a new challenge of acquiring appropriate multispectral data for training models. In this research, we demonstrate the feasibility and superiority of NIR-assisted low-light video enhancement by utilizing unpaired 24-hour data. This approach simplifies data collection and improves the overall performance on real-world data.   To address the differences between daytime and nighttime videos, we propose a method to transform daytime NIR and visible (VIS) data into a "nighttime mode." This involves using a relighting algorithm to generate realistic pseudo nighttime NIR data and a resampling strategy followed by a noiseGAN for nighttime VIS conversion. Additionally, we develop a temporal-aware network for video enhancement that extracts and merges temporal information from both directions. This network is trained using real daytime videos and pseudo nighttime videos.  To support our research, we capture multispectral data using a co-axial camera and create the Fulltime Multi-Spectral Video Dataset (FMSVD), which is the first dataset to include aligned 24-hour NIR and VIS videos. Compared to alternative methods, our approach significantly improves video quality and generalization ability on real-world data, as confirmed by evaluation metrics and visual assessment. The code and data for this research are available at the following link: https://github.com/MyNiuuu/NVEU.