Detecting image manipulation is becoming increasingly important as advanced manipulation techniques emerge. However, current learning-based approaches for manipulation detection require expensive pixel-level annotations for training and perform poorly on images with different types of manipulation compared to the training set. To overcome these limitations, we propose a weakly-supervised image manipulation detection method that only requires binary image-level labels (authentic or tampered) for training. This weakly-supervised approach allows for more training images and the ability to quickly adapt to new manipulation techniques. To improve generalization, we introduce weakly-supervised self-consistency learning (WSCL) which utilizes the weakly annotated images. WSCL learns two consistency properties: multi-source consistency (MSC) and inter-patch consistency (IPC). MSC leverages content-agnostic information from different sources and facilitates cross-source learning through an online pseudo label generation and refinement process. IPC performs global pair-wise patch-patch relationship reasoning to identify complete manipulation regions. Extensive experiments demonstrate that our weakly supervised WSCL method achieves competitive performance compared to fully-supervised approaches in both in-distribution and out-of-distribution evaluations, as well as reasonable manipulation localization ability.