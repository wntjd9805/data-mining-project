We propose a new method for synthesizing transferred images of hairstyles by considering the underlying head geometry in the input images. Traditional methods that use GANs to transfer hairstyles often produce awkward results due to differences in head pose, shape, and size. To overcome this, we use neural rendering to align the input heads in a volumetric space and ensure that the transferred hairstyle fits the target image. Our method, based on the geometric nature of neural rendering, allows us to generate view-varying images without causing distortions, which is a limitation of existing hairstyle transfer methods using traditional GAN generators. We demonstrate that our method outperforms other baselines in preserving the identity and hairstyle of the input images when synthesizing a transferred hairstyle image from any viewpoint.