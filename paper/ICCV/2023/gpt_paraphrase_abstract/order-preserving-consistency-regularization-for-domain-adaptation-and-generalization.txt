Deep learning models often struggle with cross-domain challenges when they are overly sensitive to domain-specific attributes such as lighting, background, and camera angle. To overcome this issue, a combination of data augmentation and consistency regularization is commonly used to reduce the model's sensitivity to these attributes. Consistency regularization ensures that the model produces the same representation or prediction for two different views of the same image. However, the current constraints imposed by consistency regularization are either too strict or do not preserve the order of classification probabilities. In this study, we introduce Order-preserving Consistency Regularization (OCR) for cross-domain tasks. By preserving the order of predictions, our method enhances the model's robustness to irrelevant transformations and reduces sensitivity to domain-specific attributes. Our comprehensive experiments demonstrate that OCR outperforms existing methods on five distinct cross-domain tasks.