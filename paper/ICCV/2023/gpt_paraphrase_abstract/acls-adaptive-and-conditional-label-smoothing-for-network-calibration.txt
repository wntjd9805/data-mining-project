We investigate the issue of adjusting miscalibrated confidences in deep neural networks through network calibration. Many existing methods for network calibration use regularization techniques to smooth out these miscalibrated confidences. While these methods have been successful in calibrating networks, there is still limited understanding of the underlying principles behind regularization in network calibration. In this study, we conduct a comprehensive analysis of current regularization-based methods to gain a better understanding of their impact on network calibration. Our analysis reveals two important findings: 1) regularization-based methods can be viewed as variations of label smoothing, and 2) they do not always produce desirable outcomes. Building on this analysis, we propose a new loss function called ACLS that combines the strengths of existing regularization methods while overcoming their limitations. We validate the effectiveness of ACLS through extensive experiments on image classification and semantic segmentation tasks using various benchmark datasets such as CIFAR10, Tiny-ImageNet, ImageNet, and PASCAL VOC. Our experimental results demonstrate the superiority of our loss function in achieving network calibration.