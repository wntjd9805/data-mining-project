Temporal action localization (TAL) is a challenging task in video understanding that involves recognizing and locating action instances. Most current approaches focus on predicting action classes and regressing offsets to boundaries, but they overlook the varying importance of each frame. To address this issue, we propose an Action Sensitivity Learning framework (ASL) that assesses the value of each frame and utilizes the generated action sensitivity to recalibrate the training procedure. Our framework includes a lightweight Action Sensitivity Evaluator that learns the action sensitivity at the class and instance levels. The outputs of these branches are combined to reweight the gradient of the two sub-tasks. Additionally, we design an Action Sensitive Contrastive Loss to enhance features based on the action sensitivity of each frame. This loss samples action-aware frames as positive pairs to separate them from action-irrelevant frames. Experimental results on various action localization benchmarks demonstrate that ASL outperforms the state-of-the-art methods in terms of average-mAP in different scenarios, such as single-labeled, densely-labeled, and egocentric datasets.