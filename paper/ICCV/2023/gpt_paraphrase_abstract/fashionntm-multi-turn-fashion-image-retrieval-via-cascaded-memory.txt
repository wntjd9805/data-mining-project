FashionNTM is a novel memory-based method for multi-turn textual feedback-based fashion image retrieval. It incorporates a Cascaded Memory Neural Turing Machine (CM-NTM) approach that enables the integration of information from past turns to retrieve new images. Unlike the vanilla Neural Turing Machine, CM-NTM operates on multiple inputs and learns complex relationships through individual read and write heads. Evaluation results demonstrate that FashionNTM outperforms the previous state-of-the-art algorithm by 50.5% on the Multi-turn FashionIQ dataset and shows a relative improvement of 12.6% on the Multi-turn Shoes dataset. The model exhibits memory retention across turns and is agnostic to turn order for non-contradictory feedback. User study results indicate that images retrieved by FashionNTM were preferred by 83.1% of participants compared to other multi-turn models.