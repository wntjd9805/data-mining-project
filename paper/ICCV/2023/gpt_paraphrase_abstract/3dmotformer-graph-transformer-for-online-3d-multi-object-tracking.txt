Accurately tracking 3D objects is crucial for autonomous vehicles and enables reliable downstream tasks. The tracking-by-detection paradigm has become popular due to its simplicity and efficiency. However, existing methods either rely on non-learned model-based algorithms with manually tuned parameters or face the challenge of adapting training to the online setting, leading to distribution mismatch and suboptimal performance. In this study, we propose 3DMOTFormer, a geometry-based 3D multi-object tracking framework that utilizes the transformer architecture. We employ an Edge-Augmented Graph Transformer to reason on the track-detection bipartite graph and perform data association through edge classification. To address the distribution mismatch, we introduce a novel online training strategy with autoregressive and recurrent forward pass as well as sequential batch optimization. Our approach achieves 71.2% and 68.2% AMOTA on the nuScenes validation and test split, respectively, using CenterPoint detections. Furthermore, the trained 3DMOTFormer model demonstrates good generalization across different object detectors. The code for our framework is available at: https://github.com/dsx0511/3DMOTFormer.