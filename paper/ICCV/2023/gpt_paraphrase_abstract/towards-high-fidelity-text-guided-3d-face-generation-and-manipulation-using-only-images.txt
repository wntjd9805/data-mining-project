We propose TG-3DFace, a method for generating realistic 3D faces using text guidance. This addresses the challenge of limited text-3D face data pairs in text-driven 3D face generation. Our approach combines an unconditional 3D face generation framework with text conditions, allowing us to learn text-guided 3D face generation using only text-2D face data. We also introduce two cross-modal alignment techniques, global contrastive learning and fine-grained alignment, to enhance semantic consistency between generated 3D faces and input texts. Additionally, we incorporate directional classifier guidance during the inference process to encourage creativity in out-of-domain generations. Compared to existing methods, TG-3DFace produces more realistic and aesthetically pleasing 3D faces, with a 9% improvement in multi-view consistency over Latent3D. The rendered face images generated by TG-3DFace also achieve higher FID and CLIP scores compared to text-to-2D face/image generation models, demonstrating our superiority in generating realistic and semantically consistent textures.