Advanced 3D object detection methods typically rely on large-scale, meticulously labeled datasets, which can be challenging and costly. Semi-supervised (SS3D) and weakly-supervised 3D object detection (WS3D) methods offer cost reductions but have drawbacks: they perform worse than fully-supervised methods and struggle to adapt to different detectors or scenes. This study explores weakly semi-supervised 3D object detection (WSS3D) using point annotations. The dataset used contains a small number of fully labeled objects and a large number of weakly labeled objects, with each object having a single point annotation. To make the most of these point annotations, a plain and non-hierarchical vision transformer called ViT-WSS3D is employed as a point-to-box converter. By capturing global interactions between LiDAR points and weak labels, ViT-WSS3D generates high-quality pseudo-bounding boxes that can be used to train any 3D detector without extensive tuning. Extensive experiments conducted on indoor and outdoor datasets (SUN RGBD and KITTI) demonstrate the effectiveness of the proposed method. Notably, when only 10% of the data is fully labeled and the rest is point labeled, ViT-WSS3D enables most detectors to achieve similar performance to the oracle model trained on 100% fully labeled data.