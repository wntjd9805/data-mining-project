Click-based interactive image segmentation is a technique used to extract objects from images with minimal user input. Currently, hierarchical backbones are commonly used in this field. However, the non-hierarchical Vision Transformer (ViT) has recently emerged as a strong contender for dense prediction tasks. This design allows the ViT to serve as a foundation model that can be fine-tuned without the need for a hierarchical backbone. Despite its simplicity and effectiveness, this approach has not yet been explored in interactive image segmentation. To address this gap, we propose SimpleClick, the first interactive segmentation method that utilizes a plain backbone. By introducing a symmetric patch embedding layer, we are able to encode user clicks into the backbone with minimal modifications. We pretrain the plain backbone as a masked autoencoder (MAE), and our method achieves state-of-the-art performance, surpassing the previous best result by 21.8% on the SBD dataset. We also evaluate our method on medical images, demonstrating its generalizability. Additionally, we provide a detailed computational analysis that highlights the practicality of our method as an annotation tool.