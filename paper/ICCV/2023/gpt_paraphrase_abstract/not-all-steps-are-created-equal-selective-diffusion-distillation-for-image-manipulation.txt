Selective Diffusion Distillation (SDD) is a new framework proposed in this paper to address the trade-off problem faced by conditional diffusion models in image manipulation tasks. These models typically add noise to images and then denoise them, but adding too much noise compromises image fidelity, while adding too little affects editability. This limitation hampers their practical applicability.   To overcome this dilemma, the authors introduce SDD, which ensures both fidelity and editability of images. Instead of directly editing images using a diffusion model, they train a feedforward image manipulation network guided by the diffusion model. Additionally, they propose an effective indicator to select the appropriate timestep that provides correct semantic guidance from the diffusion model.   By adopting this approach, the authors successfully avoid the trade-off problem caused by the diffusion process. Extensive experiments are conducted to demonstrate the advantages of the SDD framework. The code for implementing SDD is made publicly available at https://github.com/AndysonYs/Selective-Diffusion-Distillation.