In partial-label learning (PLL), each training example has a set of candidate labels, with only one being the true label. Most PLL studies focus on the instance-independent (II) case, where candidate labels are generated solely based on the true label. However, this approach may not be realistic as candidate labels are typically generated based on specific instance features. This has led to the emergence of instance-dependent PLL (ID-PLL). Unfortunately, existing ID-PLL studies lack a deep understanding of the inherent challenges involved.   In this paper, we conduct an empirical study to examine the process of label disambiguation in both II-PLL and ID-PLL. We discover that the decline in performance in ID-PLL is due to inaccurate supervision caused by a large number of under-disambiguated (UD) examples that fail to achieve complete disambiguation. To address this issue, we propose a novel two-stage PLL framework that includes selective disambiguation and candidate-aware thresholding.   Under this framework, we first select a subset of well-disambiguated (WD) examples based on the magnitude of normalized entropy (NE) and use them to train two networks. We then incorporate complementary supervision from the remaining examples to further improve the training. Additionally, we select additional WD examples from the remaining ones whose NE is lower than a specific class-wise WD-NE threshold. We also consider the remaining UD examples, whose NE is lower than a self-adaptive UD-NE threshold and whose predictions from the two networks agree, as WD examples for model training.   Extensive experiments demonstrate the superiority of our proposed method over existing PLL approaches.