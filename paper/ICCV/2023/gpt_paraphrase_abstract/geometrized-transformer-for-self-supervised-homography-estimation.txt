We introduce a new feature matching method called GeometrizedTransformer (GeoFormer) for homography estimation without the need for a detector. Existing detector-free methods like LoFTR struggle to accurately locate small regions for cross-attention diffusion in a computationally efficient manner. To address this issue, we propose a simple solution: utilizing classical RANSAC geometry for attentive region search. By obtaining coarse matches using LoFTR, we easily obtain a homography. This homography enables us to compute cross-attention in a focused manner, reducing the key/value sets required by Transformers to small fixed-sized regions instead of the entire image. As a result, local features can be improved using standard Transformers. GeoFormer is integrated into the LoFTR framework and the network is trained in a fully self-supervised manner by minimizing a multi-scale cross-entropy based matching loss on auto-generated training data. We extensively evaluate our method on various real-world datasets, including natural images, heavily manipulated pictures, and retinal images. The proposed GeoFormer method outperforms state-of-the-art approaches in these experiments.