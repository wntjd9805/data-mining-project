The objective of semi-supervised domain adaptation (SSDA) is to train a model using a combination of labeled source data and limited labeled target data to achieve the lowest error on unlabeled target data during testing. However, discrepancies between domains and within domains limit the improvement of classification accuracy. To address these challenges, we propose the Trico-training method, which incorporates a multilayer perceptron (MLP) classifier and two graph convolutional network (GCN) classifiers known as inter-view GCN and intra-view GCN classifiers. The first co-training strategy involves leveraging the correlation between the MLP and inter-view GCN classifiers to minimize inter-domain discrepancies. The inter-view GCN classifier provides pseudo labels to teach the MLP classifier, promoting alignment of class representations across domains. Additionally, the MLP classifier provides feedback to the inter-view GCN classifier using a concept called "pseudo-edge" for neighbor's feature aggregation, enhancing the inter-view GCN classifier's data structure mining ability and improving the quality of generated pseudo labels. The second co-training strategy between the MLP and intra-view GCN classifiers aims to reduce the intra-domain discrepancy by strengthening the correlation between labeled and unlabeled target data. To address the imbalance in classification accuracy between the inter-view and intra-view GCN classifiers, the third co-training strategy encourages them to collaborate. We evaluate the effectiveness of our proposed method on three standard SSDA benchmark datasets: Office-31, Office-Home, and DomainNet. The extended experimental results demonstrate that our method outperforms previous state-of-the-art approaches in SSDA.