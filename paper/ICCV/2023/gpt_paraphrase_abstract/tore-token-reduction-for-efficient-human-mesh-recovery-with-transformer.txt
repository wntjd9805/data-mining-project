This paper presents a set of effective strategies called TOken REduction (TORE) for recovering human mesh from monocular images using Transformer-based models. While Transformer-based structures achieve state-of-the-art performance, they suffer from high model complexity and computation cost due to redundant tokens. To address this issue, we propose token reduction strategies based on 3D geometry structure and 2D image features. By hierarchically recovering the mesh geometry and conducting token clustering, we pass fewer but more discriminative image feature tokens to the Transformer. This approach significantly reduces the number of tokens involved in complex interactions, resulting in a much lower computational cost without sacrificing shape recovery accuracy. Extensive experiments on various benchmarks confirm the effectiveness of our method. We also demonstrate the applicability of our method to hand mesh recovery. For more information, visit our project page at https://frank-zy-dou.github.io/projects/Tore/index.html.