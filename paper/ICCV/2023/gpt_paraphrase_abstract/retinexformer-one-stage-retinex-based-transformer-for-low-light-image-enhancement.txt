This study addresses the limitations of current deep learning algorithms used for enhancing low-light images based on the Retinex theory. These algorithms fail to consider the hidden corruptions in dark areas or introduced by the light-up process. Additionally, they rely on convolutional neural networks and require a complex multi-stage training pipeline, which hinders their ability to capture long-range dependencies. To overcome these limitations, the authors propose a one-stage Retinex-based Framework (ORF) that estimates illumination information to enhance low-light images and restore corruptions. They introduce an Illumination-Guided Transformer (IGT), which utilizes illumination representations to guide the modeling of non-local interactions between regions with different lighting conditions. By incorporating IGT into ORF, they develop a new algorithm called Retinexformer. Through extensive quantitative and qualitative experiments, the authors demonstrate that Retinexformer outperforms state-of-the-art methods on thirteen benchmark datasets. A user study and application on low-light object detection further confirm the practical value of their approach. The code for Retinexformer is available at https://github.com/caiyuanhao1998/Retinexformer.