Computer vision-based walking assistants are widely used to help visually impaired individuals navigate their surroundings. However, most of these systems rely on visual light images, which can be dangerous in low-light conditions like darkness or fog. To address this issue and improve the safety of vision-based walking assistants, we have developed a neural network called TINN (Thermal Infrared Blind Road Segmentation) that uses thermal infrared imaging instead. Unlike traditional segmentation techniques that focus on enhancing feature extraction and perception, our approach aims to preserve the inherent radiation characteristics in thermal imaging. We first modeled two important factors in thermal infrared imaging: thermal light atmospheric transmission and thermal inertia effect. Then, we used an encoder-decoder architecture to combine the features extracted by these two modules. To train the network and evaluate its effectiveness, we created a large-scale dataset called TBRSD (Thermal Infrared Blind Road Segmentation Dataset) with over 5,180 pixel-level manual annotations. Experimental results demonstrate that our method outperforms existing techniques and achieves state-of-the-art performance in thermal blind road segmentation, as validated on benchmark thermal infrared semantic segmentation datasets like MFNet and SODA. The dataset and our code are publicly available on GitHub at https://github.com/chenjzBUAA/TBRSD or on our website at http://xzbai.buaa.edu.cn/datasets.html.