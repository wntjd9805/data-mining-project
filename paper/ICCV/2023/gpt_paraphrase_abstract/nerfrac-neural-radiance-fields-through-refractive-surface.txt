Neural Radiance Fields (NeRF) is a widely used neural representation technique for generating new views of a scene. However, it is limited to rendering opaque scenes with diffuse reflection surfaces and struggles with complex refractive surfaces like water. To address this, we propose NeRFrac, a method for synthesizing novel views of scenes captured through refractive surfaces. NeRFrac uses a multilayer perceptron (MLP) called Refractive Field to estimate the distance from the ray origin to the refractive surface for each queried ray. By applying Snell's Law, we compute a refracted ray at each intersection point based on the input ray and the approximated local normal. Sampling points along the refracted ray, we then use a Radiance Field to estimate the radiance of the scene. Our approach accurately synthesizes novel views of the scene beneath the refractive surface while simultaneously reconstructing the refractive surface. We evaluate NeRFrac using both synthetic and real scenes observed through water surfaces, demonstrating its effectiveness in modeling scenes with wavy refractive surfaces. For more information and code implementation, please visit our GitHub page: https://github.com/Yifever20002/NeRFrac.