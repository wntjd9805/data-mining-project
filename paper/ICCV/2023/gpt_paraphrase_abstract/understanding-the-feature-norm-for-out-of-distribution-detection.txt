A neural network's hidden layer features exhibit higher vector norms for in-distribution samples and lower norms for out-of-distribution samples. This phenomenon is widely used but not fully understood. In this study, we investigate the underlying cause by analyzing the discriminative structures in the intermediate layers of a neural network. Our analysis reveals that the feature norm is a confidence value of a classifier hidden in the network layer, similar to classifier confidence in distinguishing out-of-distribution from in-distribution samples. We also find that the feature norm is class-agnostic and can detect out-of-distribution samples across different discriminative models. However, the conventional feature norm fails to capture the deactivation tendency of hidden layer neurons, leading to misidentification of in-distribution samples as out-of-distribution instances. To address this limitation, we propose a novel negative-aware norm (NAN) that captures both the activation and deactivation tendencies of hidden layer neurons. We conduct extensive experiments on NAN, demonstrating its effectiveness and compatibility with existing out-of-distribution detectors, as well as its capability in label-free environments.