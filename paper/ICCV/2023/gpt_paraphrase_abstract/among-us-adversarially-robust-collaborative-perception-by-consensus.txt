Collaborative perception using multiple robots can improve scene analysis compared to individual robots. However, it is susceptible to adversarial attacks when using deep learning. Existing adversarial defense methods require knowledge of the attacking mechanism, which is often unknown. In contrast, we propose a new defense strategy called ROBOSAC, which is based on sampling and can defend against unseen attackers. Our main idea is that collaborative perception should result in consensus rather than disagreement among team members. To achieve this, we introduce a hypothesize-and-verify framework, where perception results with and without collaboration from a random subset of teammates are compared until a consensus is reached. More teammates in the sampled subset generally lead to better perception performance, but they also require more sampling time to reject potential attackers. Therefore, we determine the number of sampling trials needed to ensure a desired attacker-free subset size or the maximum size of such a subset that can be successfully sampled within a given number of trials. We evaluate our method on the task of collaborative 3D object detection in autonomous driving scenarios.