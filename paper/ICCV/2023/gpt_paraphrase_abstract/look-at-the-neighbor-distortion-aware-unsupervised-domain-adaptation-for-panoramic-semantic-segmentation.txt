Recent efforts have been made to transfer knowledge from labeled pinhole images to unlabeled panoramic images through Unsupervised Domain Adaptation (UDA). This is done to address the domain gaps caused by style differences and distortion issues in the non-uniformly distributed pixels of equirectangular projection (ERP). Previous studies have focused on transferring knowledge based on geometric priors using complex multi-branch network architectures. However, this approach is computationally expensive and limited by the variation of distortion among pixels. In this paper, we discover that the neighborhood regions of pixels in ERP introduce less distortion. Based on this insight, we propose a simpler and more computationally efficient UDA framework for panoramic semantic segmentation. Our method utilizes distortion-aware attention (DA) to capture the distribution of neighboring pixels without relying on geometric constraints. Additionally, we introduce a class-wise feature aggregation (CFA) module to iteratively update feature representations using a memory bank, ensuring consistent optimization of feature similarity between the two domains. Extensive experiments demonstrate that our method achieves state-of-the-art performance while reducing parameters by 80%.