Vector Quantisation (VQ) is gaining popularity in machine learning for representation learning. However, optimizing the codevectors in existing VQ-VAE models is not straightforward due to codebook collapse. This phenomenon occurs when only a small subset of codevectors receive useful gradients for optimization, while the majority remain stagnant and unused. As a result, VQ struggles to effectively learn larger codebooks in complex computer vision tasks that require high-capacity representations. To address this issue, we propose a simple alternative method called Clustering VQ-VAE (CVQ-VAE) for online codebook learning. Our approach selects encoded features as anchors to update the "dead" codevectors, while still optimizing the active codevectors using the original loss function. By doing so, we bring the unused codevectors closer in distribution to the encoded features, increasing the chances of their selection and optimization. We extensively validate the generalization capability of our quantizer on various datasets, tasks (such as reconstruction and generation), and architectures (including VQ-VAE, VQGAN, and LDM). The integration of CVQ-VAE into existing models requires minimal code modifications.