Referring Expression Segmentation (RES) is a task that aims to segment objects in an image based on a given linguistic expression. However, in real-world scenarios, it is often difficult to determine if the described object actually exists in a specific image. In order to address this challenge, we propose a more realistic setting called Group-wise Referring Expression Segmentation (GRES), which expands RES to a group of related images where the described objects may exist in some but not all of the images. To support this new setting, we have created a dataset called Grouped Referring Dataset (GRD) that includes annotations for the target objects described by the given expressions. Additionally, we have developed a baseline method called Grouped Referring Segmenter (GRSer), which takes into account both the language-vision and intra-group vision-vision interactions to achieve state-of-the-art results not only on GRES but also on related tasks like Co-Salient Object Detection and traditional RES. Our dataset and codes are publicly available at https://github.com/shikras/d-cube.