Many self-supervised depth estimation models are trained using clear and sunny weather scenes, which limits their effectiveness in real-world scenarios where weather conditions vary. This paper proposes a method to address this issue by using computer graphics and generative models to simulate adverse weather effects and augment existing sunny-weather data. Previous attempts to use such data augmentations have shown to degrade performance rather than improve it. To overcome this, the paper introduces a pseudo-supervised loss that exploits the correspondence between unaugmented and augmented data for depth and pose estimation. This approach brings back some benefits of supervised learning without requiring labeled data. The paper also provides practical recommendations for weather-related augmentation of self-supervised depth estimation from monocular video, resulting in a reliable and efficient framework. Extensive testing demonstrates that the proposed method, called Robust-Depth, achieves state-of-the-art performance on the KITTI dataset and outperforms existing methods on challenging adverse condition datasets such as DrivingStereo, Foggy CityScape, and NuScenes-Night. The project website can be accessed at https://kieran514.github.io/Robust-Depth-Project/.