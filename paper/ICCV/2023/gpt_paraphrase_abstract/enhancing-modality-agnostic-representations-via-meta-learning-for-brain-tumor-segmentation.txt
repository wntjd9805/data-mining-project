In the field of medical imaging, different types of imaging techniques provide complementary information. However, in reality, not all imaging techniques may be available during the interpretation of medical images or even during the training of models. Previous methods, such as knowledge distillation or image synthesis, often assume that all imaging techniques are present for all subjects during training. This assumption is unrealistic and impractical because data collection practices vary across different medical sites.To address this issue, we propose a new approach to learn improved representations that are independent of specific imaging techniques. We achieve this by employing a meta-learning strategy during training, even when only a limited number of samples with complete imaging modalities are available. Meta-learning enables us to enhance partial imaging modality representations to resemble full modality representations by training on partial modality data and testing on limited samples with complete modalities. Furthermore, we incorporate an auxiliary adversarial learning branch to co-supervise the feature enrichment process. This involves using a missing modality detector as a discriminator to imitate the scenario where all imaging modalities are available. By doing so, we ensure that the enhanced representations capture the characteristics of the missing modality.Our proposed segmentation framework demonstrates superior performance compared to state-of-the-art brain tumor segmentation techniques when dealing with missing imaging modalities.