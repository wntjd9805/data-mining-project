We propose a novel approach called IHNet for scene flow estimation in autonomous driving. To improve accuracy, IHNet circulates high-resolution estimated information from the previous iteration to the low-resolution layer of the current iteration. This information serves as a guide for identifying matches and providing essential movement information. We also design a resampling scheme to enhance point correspondence between consecutive frames. By fine-tuning the target frame's coordinates using the previous estimated scene flow, we reduce the correspondence discrepancy caused by point sparsity. Our method outperforms the state-of-the-art WSAFlowNet by 20.1% on FlyingThings3D and 56.0% on KITTI scene flow datasets. The code is available at https://github.com/wangyunlhr/IHNet.