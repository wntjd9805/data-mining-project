Domain generalization (DG) aims to train a model on source domains that can effectively generalize to unseen domains. While the source domains differ in distribution, they are inherently related, sharing the same label space. Existing methods for achieving generalizable features typically focus on reducing the domain discrepancy by either learning domain-invariant features or mining domain-specific features. However, these approaches result in source domains that are either tightly aligned or completely unaligned, both of which fail to fully leverage the complementary information from multiple domains. To address this limitation and preserve more complementary information while reducing the domain gap, we propose a different approach. Instead of tightly aligning the multiple domains, we suggest combining them in a composite manner, where all domains are brought closer together while still maintaining their individual characteristics. This is achieved by employing an instance-adaptive classifier for each instance's classification, which deviates slightly from a universal classifier shared by samples from all domains. This adaptive classifier deviation allows instances from the same category but different domains to be dispersed around the class center rather than being tightly squeezed, resulting in improved generalization for unseen domain samples. As a result, the multiple domains are harmoniously composed around a universal core, resembling a dandelion, which we refer to as DandelionNet. Experimental evaluations on various DG benchmarks demonstrate that our proposed method can learn a model with superior generalization capabilities. Additionally, experiments on source-free domain adaptation further highlight the versatility of our approach.