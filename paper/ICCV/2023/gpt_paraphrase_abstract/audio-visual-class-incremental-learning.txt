This paper introduces a new method called AV-CIL for class-incremental learning in audio-visual video recognition. The current methods fail to preserve the semantic similarity between audio and visual features as the incremental step increases, leading to poor performance. To address this challenge, AV-CIL incorporates the Dual-Audio-Visual Similarity Constraint (D-AVSC) to maintain instance-aware and class-aware semantic similarity between audio-visual modalities. It also uses Visual Attention Distillation (VAD) to retain the previously learned audio-guided visual attentive ability. The authors created three audio-visual class-incremental datasets, AVE-Class-Incremental (AVE-CI), Kinetics-Sounds-Class-Incremental (K-S-CI), and VGGSound100-Class-Incremental (VS100-CI), based on the AVE, Kinetics-Sounds, and VGGSound datasets, respectively. Experimental results demonstrate that AV-CIL outperforms existing class-incremental learning methods in audio-visual class-incremental learning. The code and data for AV-CIL are available at https://github.com/weiguoPian/AV-CIL_ICCV2023.