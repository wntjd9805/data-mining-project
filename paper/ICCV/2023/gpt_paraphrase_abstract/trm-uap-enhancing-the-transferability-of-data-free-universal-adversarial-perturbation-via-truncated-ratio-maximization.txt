This paper presents a new approach to crafting universal adversarial perturbations (UAPs) that can fool CNN models for various data samples. Universal attacks are a more efficient and accurate way to evaluate the robustness of CNN models. While early universal attacks depend on data priors, recent attention has been focused on data-free universal attacks that generate UAPs from random noises. However, existing data-free UAP methods perturb all CNN feature layers equally, resulting in poor transferability.To address this issue, the authors propose a novel data-free universal attack called TRM-UAP. Unlike previous methods that maximize positive activation in convolution layers, TRM-UAP optimizes UAP generation based on the ratio of positive and negative activations. To enhance transferability, TRM-UAP applies the ratio maximization only to low-level generic features using a truncation strategy. Additionally, a curriculum optimization algorithm is incorporated to effectively learn the diversity of artificial images.Extensive experiments on the ImageNet dataset demonstrate that TRM-UAP achieves a state-of-the-art average fooling rate and excellent transferability across different CNN models compared to other data-free UAP methods. The code for TRM-UAP is available at https://github.com/RandolphCarter0/TRMUAP.