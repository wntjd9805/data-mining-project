Detecting deepfakes is a difficult task because existing methods often overfit to features that are not relevant to forgery detection and specific patterns associated with certain methods. This paper introduces a new approach to address these overfitting issues by identifying common forgery features. The approach involves decomposing image information into three components: forgery-irrelevant, method-specific forgery, and common forgery features. To ensure the separation of method-specific and common forgery features, a multi-task learning strategy is employed, including multi-class classification to predict the forgery method category and binary classification to distinguish real from fake. A conditional decoder is designed to generate reconstructed images using both forgery features and forgery-irrelevant features. Additionally, a contrastive regularization technique is proposed to encourage the disentanglement of common and specific forgery features. Ultimately, only the common forgery features are utilized for deepfake detection. Extensive evaluations demonstrate that this framework outperforms current state-of-the-art methods in terms of generalization.