This paper introduces a new task called IntentQA, which focuses on video intent reasoning. This task is important for AI as it allows AI agents to reason beyond basic recognition in daily tasks. To support this task, we also present a large-scale VideoQA dataset. We propose a Context-aware Video Intent Reasoning model (CaVIR) that includes a Video Query Language (VQL) for improved cross-modal representation, a Contrastive Learning module to leverage contrastive context, and a Commonsense Reasoning module for incorporating commonsense context. Through extensive experiments, we demonstrate the effectiveness of each component of our model, the superiority of our model over other baselines, and its ability to generalize to new VideoQA tasks. The dataset and codes for this task are available at: https://github.com/JoseponLee/IntentQA.git. The answer format of the model only outputs the abstract information.