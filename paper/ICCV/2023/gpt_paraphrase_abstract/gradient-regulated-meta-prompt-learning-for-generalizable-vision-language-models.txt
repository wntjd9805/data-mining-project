The emerging paradigm of prompt tuning allows vision-language pre-training models to adapt to downstream tasks efficiently by learning "soft prompts" to condition frozen pre-training models. However, prompt tuning faces challenges in few-shot scenarios, where it is sensitive to initialization and requires time-consuming processes to find a good initialization. This restricts the pre-training model's ability to adapt quickly. Additionally, prompt tuning can limit the generalizability of pre-training models as the learnable prompt tokens can overfit to limited training samples. To address these issues, we propose a Gradient-Regulated Meta-prompt learning (GRAM) framework. GRAM meta-learns an efficient soft prompt initialization for better adaptation and a lightweight gradient regulating function for strong cross-domain generalizability. It achieves this using only unlabeled image-text pre-training data. Unlike specific prompt tuning methods, GRAM can be easily incorporated into various prompt tuning methods in a model-agnostic way. Our comprehensive experiments demonstrate that GRAM consistently improves prompt tuning methods in different settings, including few-shot learning, cross-domain generalization, and cross-dataset generalization, across 11 datasets. Furthermore, GRAM enables mutually-enhanced textual and visual prompt tuning methods, resulting in better generalizability compared to unimodal prompt tuning methods.