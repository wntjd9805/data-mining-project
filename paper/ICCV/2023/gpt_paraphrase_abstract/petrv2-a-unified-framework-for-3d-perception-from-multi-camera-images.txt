This paper introduces PETRv2, a comprehensive framework for 3D perception from multi-view images. Building upon the previous PETR model, PETRv2 incorporates temporal modeling to enhance 3D object detection by utilizing temporal information from previous frames. This is achieved by extending the 3D position embedding (3D PE) in PETR, which enables temporal alignment of object positions across frames. Additionally, PETRv2 supports multi-task learning, such as BEV segmentation and 3D lane detection, through the introduction of task-specific queries initialized in different spaces. PETRv2 outperforms existing methods in 3D object detection, BEV segmentation, and 3D lane detection. The robustness of the PETR framework is thoroughly analyzed, and the code is made available at https://github.com/megvii-research/PETR.