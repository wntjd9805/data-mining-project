Backdoor defense is becoming increasingly important for machine learning security. Fine-tuning with benign data is a natural defense against backdoor effects, but recent studies have shown that vanilla fine-tuning is not effective with limited benign data. In this study, we investigate the poor performance of vanilla fine-tuning in mitigating backdoors and find that backdoor-related neurons are minimally affected. To improve backdoor defense, we propose a novel paradigm called FT-SAM. FT-SAM aims to reduce the weights of backdoor-related neurons by incorporating sharpness-aware minimization with fine-tuning. Our method achieves state-of-the-art defense performance on multiple datasets and network architectures. We provide extensive analysis to explain the mechanism behind FT-SAM's effectiveness. Overall, our work offers a promising approach to enhance the robustness of machine learning models against backdoor attacks. The codes can be found at https://github.com/SCLBD/BackdoorBench.