We present VideoFlow, a new framework for estimating optical flow in videos. Unlike previous methods that only estimate flow between two frames, VideoFlow simultaneously estimates bi-directional optical flows for multiple frames in a video by leveraging temporal cues. We introduce the TRi-frame Optical Flow (TROF) module, which estimates flows for the center frame using a three-frame approach. The information from the frame triplet is iteratively fused onto the center frame. To handle more frames, we propose the MOtion Propagation (MOP) module, which connects multiple TROFs and propagates motion features between adjacent TROFs. This iterative refinement allows information from individual TROFs to be propagated throughout the entire sequence via MOP. By effectively utilizing video information, VideoFlow achieves outstanding performance and ranks first on all public benchmarks. On the Sintel benchmark, VideoFlow achieves an average end-point-error (AEPE) of 1.649 and 0.991 on the final and clean passes, respectively, which is a 15.1% and 7.6% improvement compared to the best published results. On the KITTI-2015 benchmark, VideoFlow achieves an F1-all error of 3.65%, a 19.2% improvement compared to the best published result. The code for VideoFlow is available at https://github.com/XiaoyuShi97/VideoFlow.