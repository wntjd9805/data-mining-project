Source-free domain adaptive semantic segmentation has become increasingly popular as it allows for knowledge transfer from a well-trained source model without requiring access to the source domain. However, without labeled source data, reducing uncertainty in target pseudo labels becomes more challenging. To address this, we propose an innovative two-stream architecture that effectively learns from noisy pseudo labels. Our approach involves dual-head pseudo label denoising and cross-modal consistency regularization. For pseudo label denoising, we introduce a multimodal auxiliary network during training to enhance the correctness of pseudo labels using depth information guidance. For cross-modal consistency regularization, we enforce pixel-wise consistency between the predictions of the two streams, promoting smooth behavior for both modality variance and image perturbations. This regularization further reduces the impact of inaccurate pseudo labels in source-free unsupervised domain adaptation. Experimental results on GTA5 → Cityscapes and SYNTHIA → Cityscapes benchmarks demonstrate the superiority of our method, achieving new state-of-the-art mean Intersection over Union (mIoU) scores of 57.7% and 57.5%, respectively.