The development of face editing has advanced significantly with the introduction of StyleGAN. However, previous interactive methods, such as sketching and exemplar photos, have had limitations in terms of expressiveness and generality. To overcome these limitations, we propose a new interaction method called ClipFaceShop, which allows users to control face photos using abstract clipart consisting of simple semantic parts. This is a challenging task due to the domain gap between colorful face photos and abstract clipart with limited data. To address this problem, we introduce a framework built on top of StyleGAN that leverages the rich and disentangled visual features encoded in the W+ latent code. We also create a lightweight selective feature adaptor to predict a modifiable path towards the desired output photo. Since no labeled pairwise data is available for training, we design a set of losses to provide supervision signals for learning the modifiable path. Experimental results demonstrate that ClipFaceShop generates realistic and faithful face photos, preserving the same facial attributes as the reference clipart. Furthermore, ClipFaceShop supports clipart in diverse styles, including free-hand sketches.