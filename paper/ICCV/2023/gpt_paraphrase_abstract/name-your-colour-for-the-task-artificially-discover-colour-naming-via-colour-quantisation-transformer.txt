The theory that a color-naming system develops through efficient communication and perception is supported by linguistic studies, including an analysis of four decades of data from the Nafaanra language. This has led to the exploration of whether machine learning can develop a similar color-naming system by optimizing communication efficiency through high-level recognition performance. To achieve this, a novel color quantization transformer called CQFormer is proposed. CQFormer quantizes the color space while maintaining machine recognition accuracy on the quantized images. It does this by mapping an RGB image to an index map and generating a quantized image using a color palette. The palette is created by detecting proper colors within the entire color space. By considering color annotation, CQFormer achieves a balance between machine vision accuracy and perceptual color structure, such as distinct and stable color distribution. Interestingly, there is evidence of a consistent evolution pattern between our artificial color system and basic color terms in human languages. Additionally, our color quantization method offers efficient image compression while maintaining high performance in tasks such as classification and detection. Extensive experiments demonstrate the superior performance of our method with extremely low bit-rate colors, indicating potential integration into quantization networks for image to network activation. The source code for our method is available at https://github.com/ryeocthiv/CQFormer.