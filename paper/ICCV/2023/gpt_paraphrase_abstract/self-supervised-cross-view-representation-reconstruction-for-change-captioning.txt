This abstract discusses the challenge of change captioning, which involves describing the differences between similar images. The main difficulty lies in learning a stable difference representation, as changes in viewpoint can cause pseudo changes. To tackle this issue, the authors propose a self-supervised cross-view representation reconstruction (SCORER) network. They utilize a multi-head token-wise matching technique to model relationships between cross-view features. Through maximizing the contrastive alignment of similar images, SCORER learns two view-invariant image representations. These representations are then used to reconstruct unchanged object representations using cross-attention, enabling the learning of a stable difference representation for caption generation. Additionally, the authors introduce a cross-modal backward reasoning module to improve caption quality. This module creates a "hallucination" representation by considering the caption and the "before" representation. By pushing this representation closer to the "after" representation, the authors enforce informative captions about the differences in a self-supervised manner. The proposed method achieves state-of-the-art results on four datasets, as demonstrated through extensive experiments. The code for the method is available at https://github.com/tuyunbin/SCORER.