The objective of developing a benchmark is to establish a standardized procedure for impartial evaluation and promote advancements in a specific field. However, we acknowledge that existing protocols for action recognition may result in incomplete assessments due to various limitations. To comprehensively assess the effectiveness of spatiotemporal representation learning, we introduce BEAR, a novel benchmark for video Action Recognition. BEAR comprises 18 video datasets categorized into five groups (anomaly, gesture, daily, sports, and instructional), encompassing a diverse range of real-world applications. Through BEAR, we conduct a thorough evaluation of six commonly used spatiotemporal models that have been pre-trained using both supervised and self-supervised learning methods. We also examine transfer performance through standard fine-tuning, few-shot fine-tuning, and unsupervised domain adaptation. Our findings indicate that the current state-of-the-art falls short in guaranteeing high performance on datasets that closely resemble real-world applications. We believe that BEAR can serve as an equitable and challenging benchmark for evaluating the development of next-generation spatiotemporal learners. We have made our dataset, code, and models publicly available at: https://github.com/AndongDeng/BEAR.