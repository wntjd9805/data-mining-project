We present a novel approach for Unsupervised Domain Adaptation (UDA) using Energy-Based Learning (EBL). Our method has two main contributions: 1) EBL improves instance selection for self-training on the unlabelled target domain, and 2) alignment and normalization of energy scores enable the learning of domain-invariant representations. Regarding the first contribution, we demonstrate that an energy-based selection criterion can effectively model instance selections by mimicking the joint distribution between data and predictions in the target domain. This allows for accurate and reliable instance selection during self-training.Concerning the second contribution, we show that a combination of energy alignment and energy normalization processes can achieve stable domain alignment. This process ensures that the learned representations are invariant across different domains, enhancing the adaptability of the model.To validate our method, we implement it using the vision-transformer (ViT) backbone. Our experimental results demonstrate that our proposed approach outperforms state-of-the-art ViT-based UDA methods on various benchmarks such as DomainNet, Office-Home, and VISDA2017. This indicates the effectiveness and generalizability of our approach across different domains.