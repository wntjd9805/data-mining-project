Recently, the LaMa approach was introduced, which incorporates Fast Fourier Convolution (FFC) into image inpainting. FFC allows the fully convolutional network to have a global receptive field in its early layers and generate robust repeating textures. However, LaMa struggles to produce clear and sharp complex content. This paper identifies three key flaws in using FFC for image inpainting: spectrum shifting, unexpected spatial activation, and limited frequency receptive field. These flaws hinder the generation of intricate textures and faithful reconstruction. To address these issues, a new module called Unbiased Fast Fourier Convolution (UFFC) is proposed. UFFC modifies the vanilla FFC module by incorporating range transform and inverse transform, absolute position embedding, dynamic skip connection, and adaptive clip. This modification enables UFFC to efficiently capture frequency information and achieve reconstruction without introducing additional artifacts. Additionally, two novel perceptual losses are proposed to enhance generation quality and training robustness. Extensive experiments on benchmark datasets demonstrate that the proposed method outperforms state-of-the-art approaches in terms of texture-capturing ability and expressiveness.