Learning-based optical flow estimation models depend heavily on the realism of the training datasets. Existing methods for generating such datasets either use synthetic data or produce images with limited realism. However, the domain gap between these datasets and real-world scenes limits the ability of the trained model to generalize to real-world applications. To address this issue, we propose generating realistic optical flow datasets from real-world images.  Our approach involves two main steps. Firstly, we create highly realistic new images by constructing a layered depth representation called multiplane images (MPI) from single-view images. This allows us to generate novel view images that are highly realistic. To accurately generate optical flow maps corresponding to the new images, we calculate the optical flows of each plane using the camera matrix and plane depths. These layered optical flows are then projected into the output optical flow map using volume rendering.  Secondly, we ensure the realism of motion by introducing an independent object motion module that separates camera and dynamic object motion in MPI. This module addresses the limitations of MPI-based single-view methods, where optical flow is generated solely based on camera motion and does not account for any object movement. Additionally, we develop a depth-aware inpainting module to merge new images with dynamic objects and handle unnatural motion occlusions.  We validate the effectiveness of our method through extensive experiments on real-world datasets. Our approach outperforms existing methods in both unsupervised and supervised training of learning-based models. We will make the code publicly available at the following link: https://github.com/Sharpiless/MPI-Flow.