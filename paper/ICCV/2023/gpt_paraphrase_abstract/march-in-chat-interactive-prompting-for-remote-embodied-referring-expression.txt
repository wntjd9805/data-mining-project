In recent years, various Vision-and-Language Navigation (VLN) tasks have been introduced, ranging from room-based to object-based and indoor to outdoor scenarios. The REVERIE (Re-mote Embodied Referring Expression) task is particularly interesting because it only provides high-level instructions to the agent, resembling human commands. However, this task presents more challenges compared to other VLN tasks, as it requires agents to generate a navigation plan solely based on a brief instruction. Large Language Models (LLMs) have shown promise in robot action planning by providing suitable prompts. Nevertheless, the application of this strategy in the context of REVERIE remains unexplored, presenting new challenges. For instance, the LLM must be aware of the environment to adjust the navigation plan based on the current visual observations. Additionally, the LLM's planned actions should be adaptable to the larger and more complex REVERIE environment. This paper introduces a March-in-Chat (MiC) model that can dynamically communicate with the LLM and generate plans based on a newly proposed Room-and-Object Aware Scene Perceiver (ROASP). Through extensive evaluation on the REVERIE benchmark, our MiC model significantly outperforms the previous state-of-the-art in terms of SPL and RGSPL metrics. The source code for our model is available at https://github.com/YanyuanQiao/MiC.