Knowledge distillation (KD) is a promising technique that enables a smaller student model to learn valuable information from a larger teacher model, leading to improved performance. While KD methods have been extensively studied in the context of 2D detection tasks, they are not suitable for 3D monocular detection as they do not consider spatial cues. To address this limitation, we propose a novel distillation framework that leverages depth information to enhance the performance of the student model without requiring additional depth labels. Our approach includes two key components. Firstly, we introduce a perspective-induced feature imitation method that allows the student model to imitate features of farther objects from the teacher model by utilizing the perspective principle (i.e., the smaller the farther). Secondly, we construct a depth-guided matrix based on the predicted depth gap between the teacher and student models, which helps the student model learn more knowledge about objects that are farther away during the distillation process. Importantly, our method is compatible with various backbones used in advanced monocular detectors and does not introduce any additional inference time. Extensive experiments conducted on the KITTI and nuScenes benchmarks, under various settings, demonstrate that our proposed method surpasses the state-of-the-art KD methods in terms of performance.