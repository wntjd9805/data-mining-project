Recently, self-supervised learning (SSL) methods for scene images have grown rapidly. These methods typically rely on either dense matching or unsupervised object discovery, which can be computationally expensive. This paper proposes an alternative approach that treats scene/multi-label image SSL as a multi-label classification problem, simplifying the learning framework. The method, called Multi-Label Self-supervised Learning (MLS), assigns multiple binary pseudo-labels to each input image by comparing its embeddings with those in two dictionaries. The network is then optimized using binary cross entropy loss. Visualizations demonstrate that MLS can automatically identify semantically similar pseudo-positive pairs across different images, aiding contrastive learning. MLS achieves high-quality representations on MS-COCO and outperforms existing methods on classification, detection, and segmentation benchmarks. Additionally, MLS is simpler to implement and deploy, making it more accessible for further exploration.