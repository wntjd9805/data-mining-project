Developing accurate survival rate predictions based on multi-gigapixel histopathology images is a difficult task in digital pathology. Multiple Instance Learning (MIL) has been commonly used for this purpose by breaking the image into smaller patches. However, MIL fails to consider the individual cells within each patch, even though they are essential components of the tissue. In this study, we introduce a new method called CO-PILOT, which is a dynamic and hierarchical point-cloud-based approach for processing cellular graphs obtained from routine histopathology images. Our model utilizes both bottom-up information propagation and top-down conditional attention to enable adaptive focus at various levels of tissue hierarchy. Through extensive experiments, we demonstrate that our model surpasses all existing methods, including the hierarchical Vision Transformer (ViT), in terms of survival prediction across three datasets and four metrics. Additionally, our model successfully stratifies patients into different risk groups with statistically distinct outcomes, a task previously only achieved using genomic information. To facilitate further research, we provide a large dataset comprising 873 cellular graphs from 188 patients, along with their corresponding survival data. This dataset is among the largest publicly available datasets in this field.