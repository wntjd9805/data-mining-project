GlueNet, a newly proposed model, addresses the challenge of replacing or upgrading the text encoder in text-to-image (T2I) models. This is achieved by aligning the features from single-modal or multi-modal encoders with the latent space of an existing T2I model. GlueNet introduces a new training objective that uses parallel corpora to align the representation spaces of different encoders. The empirical results demonstrate that GlueNet efficiently enables various capabilities beyond previous state-of-the-art models. These include aligning multilingual language models with existing T2I models, allowing for image generation from captions in languages other than English, aligning multi-modal encoders with T2I models for sound-to-image generation, and upgrading the text encoder of the latent diffusion model for challenging case generation. The alignment of various feature representations through GlueNet enables flexible and efficient integration of new functionality into existing T2I models and opens up possibilities for X-to-image generation.