Self-supervised methods have made remarkable progress in learning high-level semantics and low-level temporal correspondence. Building on these results, we propose a novel approach to enhance object-centric representations by integrating these two features. Our preliminary experiments indicate that query slot attention can extract different semantic components from the RGB feature map, while random sampling based slot attention can exploit temporal correspondence cues between frames to assist instance identification. Motivated by these findings, we introduce a semantic-aware masked slot attention model that operates on fused semantic features and correspondence maps. This model consists of two stages of slot attention, where Gaussian distributions are used for slot initialization in the first stage to decompose potential semantics and generate semantic segmentation masks through iterative attention. In the second stage, slots are randomly sampled from the corresponding Gaussian distribution for each semantic component, and masked feature aggregation is performed within the semantic area to exploit temporal correspondence patterns for instance identification. To encourage temporally coherent object-centric representations, we employ semantic- and instance-level temporal consistency as self-supervision. Our model effectively identifies multiple object instances with semantic structure, achieving promising results on unsupervised video object discovery. Additionally, we achieve state-of-the-art performance on dense label propagation tasks, showcasing the potential of our approach for object-centric analysis. The code for our model is publicly available at https://github.com/shvdiwnkozbw/SMTC.