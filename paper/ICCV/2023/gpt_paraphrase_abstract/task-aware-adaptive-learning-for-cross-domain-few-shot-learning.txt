Current few-shot learning approaches have shown promising results for queries within a particular domain. However, they struggle with generalization across different domains. The limited availability of support data makes effective knowledge transfer challenging, especially due to domain-shift. Researchers have attempted to address this issue by introducing task-specific parameters that are optimized for each task. However, this approach fails to account for the diverse domain shifts between source and target tasks, thus limiting its effectiveness. In this paper, we highlight the dependence of task-specific parameter configuration on the target task. Having too many task-specific parameters may lead to overfitting, while too few may result in under-adaptation. We propose the Task-aware Adaptive Network (TA2-Net), which employs reinforcement learning to dynamically estimate the optimal task-specific parameter configuration for each test task. For instance, it learns that tasks with significant domain-shift require a larger number of task-specific parameters for effective adaptation. We evaluate our model on the Meta-dataset and demonstrate its superiority over existing state-of-the-art methods. The code for our model is available at https://github.com/PRIS-CV/TA2-Net.