This study introduces Language Embedded Radiance Fields (LERFs), a method that combines CLIP language embeddings with NeRF to facilitate language-based queries in 3D environments. LERF learns a dense, multi-scale language field within NeRF by rendering CLIP embeddings along training rays. This process ensures consistency and smoothness in the language field across multiple views. By optimizing LERF, it becomes capable of generating 3D relevancy maps for various language prompts in real-time. This technology has potential applications in robotics, vision-language models, and interacting with 3D scenes. LERF allows for pixel-aligned, zero-shot queries using 3D CLIP embeddings without the need for region proposals or masks. It supports open-vocabulary queries across the entire volume, including long-tail queries. Further information about the project can be found at https://lerf.io.