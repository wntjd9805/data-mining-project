This paper investigates the issue of static bias in video action recognition, where static features interfere with the learning of motion features, resulting in poor out-of-distribution generalization. While the video background is known to contribute to static bias, the authors also explore the potential bias induced by the video foreground, such as the actor's clothing. They empirically verify the existence of foreground static bias by creating test videos with conflicting signals from static and moving portions. To address this problem, the authors propose a technique called StillMix, which effectively learns robust action representations. StillMix identifies frames with bias-inducing static features using a 2D reference network and mixes them with training videos to suppress bias. This approach works even when the source of bias cannot be explicitly extracted or enumerated. To evaluate static bias accurately, the authors introduce two new benchmarks: SCUBA for static cues in the background and SCUFO for static cues in the foreground. Through extensive experiments, the authors demonstrate that StillMix successfully mitigates both types of static bias and improves video representations for downstream applications. The code for StillMix is available at https://github.com/lihaoxin05/StillMix.