Fine-grained capture of 3D Human-Object Interactions (HOIs) is crucial for understanding human activities and supporting various visual tasks. However, existing models often assume that humans interact with rigid objects using only a few body parts, limiting their applicability. This paper addresses the complex challenge of Full-Body Articulated Human-Object Interaction (f-AHOI), where complete human bodies interact with articulated objects that have interconnected movable joints. To facilitate research in this area, we introduce CHAIRS, an extensive dataset that captures f-AHOI through motion capture technology. This dataset includes 17.3 hours of diverse interactions involving 46 participants and 81 articulated and rigid sittable objects. CHAIRS provides realistic and physically plausible 3D meshes of both humans and articulated objects during the interactive sequences. We demonstrate the usefulness of CHAIRS by applying it to object pose estimation. By leveraging the geometric relationships inherent in HOI, we propose a novel model that uses human pose estimation to estimate the pose and shape of articulated objects within whole-body interactions. Given an image and an estimated human pose, our model reconstructs the pose and shape of the object, refining the reconstruction using a learned interaction prior. Our model outperforms baseline methods significantly in two evaluation scenarios. Additionally, we showcase the value of CHAIRS in a downstream task involving human pose generation conditioned on interacting with articulated objects. We believe that the availability of CHAIRS will advance the understanding of finer-grained interactions within the research community.