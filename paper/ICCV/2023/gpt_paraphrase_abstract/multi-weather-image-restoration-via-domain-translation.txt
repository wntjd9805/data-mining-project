Weather conditions such as rain, haze, and snow can negatively impact the performance of computer vision systems. Restoring multi-weather degraded images is crucial for these systems to function successfully. Current approaches train models using datasets that contain images with individual weather degradations. However, these methods may struggle when faced with real-world images that have multiple complex weather conditions. To address this issue, we propose a unified method for multi-weather image restoration based on domain translation. Our approach trains a network to simultaneously learn multiple weather degradations, making it robust for real-world conditions. Firstly, we introduce an instance-level domain translation technique combined with multi-attentive feature learning to generate different weather-degraded variations of the same scenario. Then, the original and translated images are fed into our novel multi-weather restoration network. This network leverages progressive multi-domain deformable alignment (PMDA) and cascaded multi-head attention (CMA) to effectively learn weather-invariant clues and perform restoration. Experimental results on synthetic and real-world image databases for hazy, rainy, and snowy conditions demonstrate that our model outperforms existing multi-weather image restoration methods. The code for our approach is available at https://github.com/pwp1208/Domain_Translation_Multi-weather_Restoration.