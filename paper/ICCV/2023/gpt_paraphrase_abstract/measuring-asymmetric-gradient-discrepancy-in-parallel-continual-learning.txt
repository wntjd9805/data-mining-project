We address the issues of training conflict and catastrophic forgetting in Parallel Continual Learning (PCL), where multiple tasks start and end training unpredictably. These issues arise due to the differences in directions and magnitudes of gradients from parallel tasks. To mitigate these problems, we propose an optimization problem that minimizes the distance between gradients, called Asymmetric Gradient Distance (AGD). AGD takes into account both the magnitude ratios and directions of gradients, and includes a tolerance when updating with a small gradient of inverse direction to reduce the imbalanced influence on parallel task training. Additionally, we introduce a novel strategy called Maximum Discrepancy Optimization (MaxDO) to minimize the maximum discrepancy among multiple gradients. By applying MaxDO with AGD, parallel training mitigates the impact of training conflict and suppresses catastrophic forgetting of finished tasks. We conduct extensive experiments on three image recognition datasets in task-incremental and class-incremental PCL, which demonstrate the effectiveness of our approach. Our code is available at https://github.com/fanlyu/maxdo.