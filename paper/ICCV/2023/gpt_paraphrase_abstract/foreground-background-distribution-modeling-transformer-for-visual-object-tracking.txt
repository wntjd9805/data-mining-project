Visual object tracking has become a crucial area of research with diverse applications. While pure Transformer-based trackers have made significant advancements, they struggle with complex backgrounds. To overcome these limitations, we propose a novel approach called F-BDMTrack, which incorporates a fore-background agent learning (FBAL) module and a distribution-aware attention (DA2) module within a unified transformer architecture. This approach offers several advantages. Firstly, the FBAL module effectively extracts fore-background information using specially designed agents. Secondly, the DA2 module prevents erroneous interaction between foreground and background by modeling similarities in their distribution. Lastly, F-BDMTrack can extract distinctive features in dynamic tracking scenarios, leading to more accurate target state estimation. Through extensive experiments, we demonstrate that F-BDMTrack outperforms existing state-of-the-art trackers on eight tracking benchmarks.