In this study, we examine the compositional structures found in data embeddings generated by pre-trained vision-language models (VLMs). Traditionally, compositionality has been associated with algebraic operations performed on word embeddings from an existing vocabulary. However, we propose a different approach by approximating representations from an encoder as combinations of a smaller set of vectors in the embedding space. These vectors can be considered as "ideal words" that can generate concepts directly within the embedding space of the model. To understand compositional structures from a geometric perspective, we introduce a framework. Additionally, we discuss the probabilistic implications of these compositional structures in VLM embeddings and provide insights into why they occur in practical scenarios. Furthermore, we conduct empirical analyses on CLIP's embeddings to explore these structures. We evaluate their utility in various vision-language tasks, such as classification, debiasing, and retrieval. Our findings demonstrate that simple linear algebraic operations on embedding vectors can serve as compositional and interpretable approaches for controlling the behavior of VLMs.