This paper introduces a camera relocalization algorithm that utilizes Neural Radiance Fields (NeRF) as an implicit map of a scene. Unlike previous methods that rely on pose regression or photometric alignment, this algorithm leverages dense local features obtained through volumetric rendering, trained with a self-supervised objective. As a result, it achieves higher accuracy compared to competing methods and can function effectively in dynamic outdoor environments with varying lighting conditions. Additionally, it can be easily integrated into any volumetric neural renderer. The proposed algorithm enables real-time computation of a device's precise position using a single RGB camera during navigation.