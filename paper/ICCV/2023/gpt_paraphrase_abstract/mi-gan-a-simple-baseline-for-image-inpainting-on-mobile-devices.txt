Recently, the research community has developed numerous deep learning-based methods for image inpainting, some of which have demonstrated impressive image completion capabilities. However, there is currently no image inpainting model specifically designed for mobile devices. To address this gap, we introduce Mobile Inpainting GAN (MI-GAN), a straightforward image inpainting baseline. MI-GAN offers computational efficiency that is approximately one order of magnitude lower and a smaller size compared to existing state-of-the-art inpainting models, making it suitable for deployment on mobile devices. Through comprehensive quantitative and qualitative evaluations, we demonstrate that MI-GAN performs comparably or even better than recent state-of-the-art approaches. Additionally, we conduct a user study comparing MI-GAN results with those obtained from various commercial mobile inpainting applications, which highlights the superiority of MI-GAN over existing apps. To achieve high-quality and efficient inpainting, we employ a combination of adversarial training, model re-parametrization, and knowledge distillation. Our models and code are publicly accessible at https://github.com/Picsart-AI-Research/MI-GAN.