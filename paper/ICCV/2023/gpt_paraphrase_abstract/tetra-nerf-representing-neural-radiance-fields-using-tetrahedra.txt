Neural Radiance Fields (NeRFs) have gained significant popularity for their ability to tackle problems related to novel view synthesis and 3D reconstruction. Typically, NeRFs employ a uniform voxel-based subdivision of the scene combined with a Multilayer Perceptron (MLP) for scene representation. However, this paper proposes an alternative approach that uses an adaptive representation based on tetrahedra obtained through Delaunay triangulation instead of uniform subdivision or point-based representations. This adaptive representation allows for efficient training and yields state-of-the-art results. By incorporating concepts from 3D geometry processing, triangle-based rendering, and modern neural radiance fields, our approach offers more detailed representations in areas near the surface compared to voxel-based representations. Additionally, compared to point-based representations, our method achieves better performance. The source code for our approach is publicly available at: https://jkulhanek.com/tetra-nerf.