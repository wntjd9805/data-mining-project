The performance of deep learning classifiers in training data is not always indicative of their performance in real-world applications. This is especially true if the classifier has learned from irrelevant features in the training data, as it can lead to unexpected failures in predictions. In this paper, we propose a framework that allows us to systematically identify these irrelevant features, known as spurious features, in large datasets like ImageNet. Unlike previous work that often operates in simplified scenarios or requires extensive annotations, we validate our approach using ImageNet and demonstrate that the presence of a harmful spurious feature alone is enough to trigger the prediction of a specific class. To facilitate further research, we introduce a new dataset called "Spurious ImageNet" that enables the assessment of any ImageNet classifier's reliance on harmful spurious features. Additionally, we present a simple mitigation method called SpuFix, which reduces the dependence of an ImageNet classifier on previously identified harmful spurious features without the need for additional labels or retraining. The code and data for our work are available at https://github.com/YanNeu/spuriousimagenet.