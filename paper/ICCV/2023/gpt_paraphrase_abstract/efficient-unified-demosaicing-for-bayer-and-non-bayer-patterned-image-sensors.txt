As CMOS image sensors (CIS) become smaller, mobile cameras are adopting non-Bayer color filter array (CFA) patterns such as Quad, Nona, and QÃ—Q. These patterns have homogeneous color units with adjacent pixels and offer advantages over conventional Bayer CFA in terms of changeable pixel-bin sizes for different lighting conditions. However, they can introduce visual artifacts during demosaicing due to their unique pixel pattern structures and sensor hardware characteristics. Previous demosaicing methods have primarily focused on Bayer CFA, requiring separate reconstruction methods for different non-Bayer CFAs and lighting conditions. This study presents an efficient unified demosaicing method called KLAP that can be applied to both conventional Bayer RAW and various non-Bayer CFAs' RAW data in different operation modes. KLAP utilizes CFA-adaptive filters for only 1% of key filters in the network for each CFA, yet still achieves effective demosaicing for all CFAs with comparable performance to larger models. Additionally, by incorporating meta-learning during inference (KLAP-M), the model can eliminate unknown sensor-generic artifacts in real RAW data, bridging the gap between synthetic images and real sensor RAW. KLAP and KLAP-M achieved state-of-the-art demosaicing performance in both synthetic and real RAW data for Bayer and non-Bayer CFAs.