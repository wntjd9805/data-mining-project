The focus of visible-infrared person re-identification (VI-ReID) is to match images of pedestrians with the same identity captured by different cameras. Existing methods that use part-based approaches have been successful in extracting detailed features from feature maps. However, these methods often suffer from misalignment issues due to irregular pedestrian movements, as they employ horizontal division to obtain part features. Additionally, most current methods measure similarity using Euclidean or cosine distance without considering the relationships between pedestrians. These limitations hinder the performance of existing works. To address these issues, we propose a Semantic Alignment and Affinity Inference framework (SAAI) that aligns latent semantic part features with learnable prototypes and improves inference using affinity information. Our framework introduces semantic-aligned feature learning, which aggregates the latent semantic part features by considering the similarity between pixel-wise features and learnable prototypes. We also devise an affinity inference module to optimize the inference process by incorporating pedestrian relationships. Our SAAI framework demonstrates favorable performance in extensive experiments conducted on the SYSU-MM01 and RegDB datasets. The code for our framework will be made available at https://github.com/xiaoye-hhh/SAAI.