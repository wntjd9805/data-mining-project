The use of multiple cameras in Multi-Camera Multi-Object Tracking (MC-MOT) is beneficial for handling occlusion and crowded scenes. Graph-based approaches have gained popularity for tracking problems, but they often do not effectively utilize spatial and temporal consistency. Instead, they rely on single-camera trackers that are prone to errors. This paper presents a new graph model that associates detected objects across cameras spatially before reconfiguring them into a temporal graph for Temporal Association. This two-stage approach allows for robust extraction of spatial and temporal-aware features and addresses the issue of fragmented tracklets. The model is designed for online tracking, making it suitable for real-world applications. Experimental results demonstrate that the proposed graph model extracts more distinguishing features for object tracking and achieves state-of-the-art performance on multiple public datasets. The code is available at the provided GitHub link.