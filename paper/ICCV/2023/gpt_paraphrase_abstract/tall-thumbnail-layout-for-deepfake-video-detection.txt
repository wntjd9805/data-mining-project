Deepfakes pose significant threats to society and cybersecurity, leading to widespread concerns. Detecting deepfake videos has become a critical topic, although existing methods are computationally intensive. This study introduces a straightforward yet effective approach called Thumbnail Layout (TALL) that transforms video clips into a predefined layout to preserve spatial and temporal dependencies. By masking consecutive frames in a fixed position and resizing them into sub-images arranged in a specific layout, TALL improves generalization. It is a model-agnostic and simple technique that requires minimal code modifications. Building upon the success of vision transformers, TALL is incorporated into Swin Transformer, resulting in a highly efficient and effective method called TALL-Swin. Through extensive experiments on both intra-dataset and cross-dataset scenarios, the validity and superiority of TALL and TALL-Swin are demonstrated. Notably, TALL-Swin achieves an impressive 90.79% AUC on the challenging cross-dataset task of FaceForensics++ â†’ Celeb-DF. The code for TALL-Swin is publicly available at https://github.com/rainy-xu/TALL4Deepfake.