Most existing Neural Radiance Field (NeRF) approaches focus on modeling single objects or levels of a scene. However, in real-world scenarios, scenes are often captured at multiple levels, resulting in a layered capture. This can greatly enhance immersive experiences by allowing seamless switching between levels. Unfortunately, current techniques struggle to model such scenes effectively. To address this limitation, we propose Strata-NeRF, a single neural radiance field that can implicitly capture scenes with multiple levels. Strata-NeRF achieves this by conditioning the NeRFs on Vector Quantized (VQ) latent representations, which enable sudden changes in scene structure. We evaluate our approach on a synthetic dataset with diverse scenes and validate its generalization on the real-world RealEstate10K dataset. Our results demonstrate that Strata-NeRF effectively captures stratified scenes, reduces artifacts, and produces high-fidelity views compared to existing methods. For more information, please visit https://ankitatiisc.github.io/Strata-NeRF/.