PARQ is a novel multi-view 3D object detector that utilizes transformer and pixel-aligned recurrent queries. Unlike previous approaches that either employ learnable features or encode 3D point positions as queries in the decoder, PARQ introduces appearance-enhanced queries initialized from reference points in 3D space. These queries are then updated with recurrent cross-attention operations to determine their 3D location. By incorporating pixel-aligned features and cross attention, PARQ is able to encode the essential 3D-to-2D correspondences and capture global contextual information from input images. The performance of PARQ surpasses that of existing methods on the ScanNet and ARKitScenes datasets. Additionally, it exhibits faster learning and detection capabilities, increased robustness to distribution shifts in reference points, and the ability to leverage additional input views without requiring retraining. Furthermore, PARQ allows for adaptable inference compute by adjusting the number of recurrent iterations. The code for PARQ is available at https://ymingxie.github.io/parq.