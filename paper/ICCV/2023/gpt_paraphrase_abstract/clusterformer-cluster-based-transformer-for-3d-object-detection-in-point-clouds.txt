The transformer has shown great potential in processing point cloud data due to its ability to handle the unstructured and sparse nature of point clouds. However, current query-based 3D detectors typically convert the features obtained from a sparse backbone into a structured Bird's Eye View (BEV) plane before using the transformer. This process destroys the sparsity of features, resulting in the introduction of empty tokens and additional resource consumption for the transformer.   In this paper, we propose a new query-based 3D detector called Clusterformer. Our Clusterformer treats each object as a cluster of 3D space, consisting mainly of non-empty voxels belonging to the same object. We utilize this cluster to directly generate proposals from the sparse voxel features through the transformer decoder. This cluster-based transformer structure effectively improves the performance and convergence speed of query-based detectors by leveraging the object prior information contained in the clusters.   Furthermore, we introduce a Query2Key strategy in our cluster-based transformer structure to iteratively enhance the key and value features with object-level information. Experimental results demonstrate that our proposed Clusterformer surpasses previous query-based detectors in terms of lower latency and memory usage. It achieves state-of-the-art performance on both the Waymo Open Datasets and KITTI Datasets.