This study aims to improve video segmentation by utilizing motion expressions to segment objects based on a sentence describing their motion. Existing video object datasets focus on salient objects and use language expressions with static attributes, neglecting the importance of motion. To address this, we introduce the MeViS dataset, which contains numerous motion expressions for complex environments. We evaluate five existing video object segmentation methods on MeViS and find that they are ineffective for motion expression-guided segmentation. We propose a baseline approach for the MeViS dataset and analyze the challenges involved. Our goal is to provide a platform for developing language-guided video segmentation algorithms that leverage motion expressions as a primary cue for object segmentation in complex scenes. The MeViS dataset is available at https://henghuiding.github.io/MeViS.