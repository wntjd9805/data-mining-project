Creating personalized 3D animatable avatars from a single camera has numerous practical applications in various fields such as gaming, virtual try-on, animation, and VR/XR. However, accurately modeling realistic clothing deformations using limited data is a significant challenge. Existing methods for generating 3D human models from depth data have drawbacks in terms of computational efficiency, mesh consistency, and flexibility in resolution and topology. For example, reconstructing shapes through implicit functions and extracting explicit meshes per frame is computationally expensive and cannot guarantee consistent meshes across frames. Additionally, predicting deformations on a pre-designed human template with a discrete surface lacks flexibility in resolution and topology. To address these limitations, we propose a new method called Neural Surface Fields (NSF) for modeling 3D clothed humans using monocular depth. NSF defines a neural field solely on the base surface, which represents a continuous and flexible displacement field. NSF can be adapted to different base surfaces with varying resolutions and topologies without the need for retraining during inference. Compared to existing approaches, our method eliminates the costly per-frame surface extraction process while maintaining mesh consistency and enabling the reconstruction of meshes with any desired resolution without retraining. To encourage further research in this area, we have made our code available on our project page at: https://yuxuan-xue.com/nsf.