The aim of domain generalization (DG) is to develop models that can perform well in unseen target domains by learning from one or multiple source domains. However, current approaches often suffer from a misalignment between the difficulty level of training samples and the capability of contemporary models, leading to overfitting or underfitting. To address this issue, we propose a framework called MoDify, which balances the model's capability and the difficulty of samples during training. MoDify consists of two components: MoDify-based Data Augmentation, which generates difficulty-aware training samples using an RGB Shuffle technique, and MoDify-based Network Optimization, which dynamically schedules training samples to ensure balanced and smooth learning. Despite its simplicity, MoDify achieves superior performance across multiple benchmarks and can be used as a complement to existing methods for different visual recognition tasks. Inspired by the Flow Theory, which suggests that learners have better outcomes when their skill level matches the task difficulty, MoDify adaptsively schedules training samples based on the alignment between sample difficulty and model capability. By addressing the misalignment, MoDify improves the generalization of trained models.