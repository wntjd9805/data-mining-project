Current unsupervised video object segmentation methods heavily rely on pre-trained segmentation models trained offline on labeled training video sets. However, these models struggle to generalize well to test videos from different domains due to potential distribution shifts. To address this issue, we propose an approach that performs online fine-tuning on the pre-trained segmentation model to adapt it to any ad-hoc videos during test time. Our method involves a two-step process: offline semi-supervised adversarial training and online self-supervised adversarial fine-tuning. In the offline training phase, we leverage unlabeled video frames to enhance the model's generalizability and align the features of labeled and unlabeled video frames. This process improves the overall performance of the segmentation model. In the online fine-tuning phase, we initialize a teacher model and a student model with the weights of the pre-trained segmentation model. The teacher model generates pseudo labels, which are then used to supervise the student model within an adversarial learning framework. By continuously updating the student model based on emerging patterns in each test video, our approach effectively reduces the domain gap at test time. We combine the offline training and online fine-tuning stages into a unified framework called Online Adversarial Self-Tuning (OAST) for unsupervised video object segmentation. Experimental results demonstrate that our method surpasses state-of-the-art approaches, achieving significant improvements on popular video object segmentation datasets.