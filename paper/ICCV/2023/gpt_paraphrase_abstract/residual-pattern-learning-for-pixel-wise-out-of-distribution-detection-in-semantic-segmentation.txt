Semantic segmentation models are used to classify pixels into different visual classes. However, when these models are deployed in an open world, it is important for them to not only classify pixels within their known classes but also detect pixels that do not belong to any known class. Previous methods have attempted to address this issue through model re-training using synthetic training images that include out-of-distribution (OoD) objects. However, these methods have limitations, such as a potential drop in accuracy for in-distribution segmentation and a lack of generalization to new contexts. In this paper, we propose a new approach that includes a residual pattern learning (RPL) module to assist the segmentation model in detecting OoD pixels without significantly affecting inlier segmentation accuracy. Additionally, we introduce a novel context-robust contrastive learning (CoroCL) technique that ensures the RPL module can robustly detect OoD pixels in different contexts. Our approach outperforms previous state-of-the-art methods by approximately 10% in false positive rate (FPR) and 7% in area under the precision-recall curve (AuPRC) on Fishyscapes, Segment-Me-If-You-Can, and RoadAnomaly datasets.