Charts pose a challenge in terms of comprehension due to their complexity and diverse types. Existing methods for understanding charts are either based on heuristic rules or rely too heavily on OCR systems, resulting in suboptimal performance. To address these issues, we present ChartReader, a unified framework that seamlessly combines chart derendering and comprehension tasks. Our approach involves a transformer-based module for detecting chart components and an extended pre-trained vision-language model for tasks related to converting charts into other formats (chart-to-X). By automatically learning the rules of charts from annotated datasets, our approach eliminates the need for manual rule-making, reducing effort and improving accuracy. We also introduce a technique for replacing data variables and extend the input and position embeddings of the pre-trained model for cross-task training. We evaluate ChartReader on tasks such as converting charts to tables, answering questions about charts, and converting charts to text, and demonstrate its superiority over existing methods. Our proposed framework significantly reduces the manual effort required for chart analysis and takes a step towards creating a universal chart understanding model. Additionally, our approach offers opportunities for easy integration with popular language models such as T5 and TaPas, enhancing their capability to comprehend charts.