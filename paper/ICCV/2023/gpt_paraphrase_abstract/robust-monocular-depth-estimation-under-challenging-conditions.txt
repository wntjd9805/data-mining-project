This paper addresses the limitations of current monocular depth estimation methods, which struggle to perform reliably in challenging lighting and weather conditions such as nighttime or rain. To overcome these safety-critical issues, the authors propose md4all, a simple and effective solution that works well in both ideal and adverse conditions, and for different types of learning supervision. The approach leverages the effectiveness of existing methods in perfect conditions to provide valid training signals regardless of the input. This is achieved by generating a set of complex samples that correspond to the normal training data, and then training the model using these samples to guide its self- or full-supervision. The standard losses are computed on the original images to ensure consistent performance across diverse conditions without the need for inference-time modifications. The authors conducted extensive experiments on two challenging public datasets, namely nuScenes and OxfordRobotCar, and the results demonstrate the effectiveness of their techniques, outperforming previous works significantly in both standard and challenging conditions. The source code and data for this research are available at https://md4all.github.io.