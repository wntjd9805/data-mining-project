Training object detectors with sparse annotations can lead to reduced performance. Previous methods have attempted to address this issue by using pseudo-labels for unlabeled boxes. However, these methods struggle with higher levels of sparsity due to noisy pseudo-labels. To overcome this problem, we propose an end-to-end system that utilizes Pseudo-positive mining to separate proposals into labeled and unlabeled regions. While labeled regions are processed conventionally, self-supervised learning is employed to handle the unlabeled regions, thus mitigating the negative impact of noisy pseudo-labels. This innovative approach offers several advantages, including improved robustness to higher levels of sparsity compared to existing methods. We conducted extensive experiments on the PASCAL-VOC and COCO datasets, achieving state-of-the-art performance. Additionally, we consolidated various splits used in the literature and established a standardized benchmark for this task. On average, our method outperformed previous state-of-the-art methods by 2.6, 3.9, and 9.6 mAP on three splits with increasing sparsity on COCO. Our project is publicly accessible at cs.umd.edu/~sakshams/SparseDet.