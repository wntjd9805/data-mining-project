The scarcity of annotated data poses a challenge for developing vision models for real-world applications. To overcome this challenge, data-efficient visual learning techniques such as semi-supervised learning have been adopted. However, the traditional cross-entropy supervision used in these techniques focuses solely on category discrimination and overlooks the semantic connection between concepts. This limitation leads to suboptimal utilization of limited labeled data. This paper proposes an innovative approach called BorLan, which aims to enhance data-efficient visual learning by leveraging linguistic knowledge. BorLan borrows knowledge from pretrained language models that possess rich semantics extracted from large corpora, compensating for the semantic deficiency caused by limited annotation in visual training. The approach incorporates a distribution alignment objective that guides the vision model to learn semantic-aware and domain-agnostic representations through linguistic knowledge. One notable advantage of this approach is its flexibility in combining different visual and linguistic models. Extensive experiments on semi-supervised learning, single domain generalization, and few-shot learning demonstrate the effectiveness of BorLan. The code for BorLan can be found at https://github.com/BIT-DA/BorLan.