We present a novel approach for Domain Continual Learning (DCL) of Face Anti-Spoofing (FAS) models. Unlike existing methods that require replay buffers to store previous data for rehearsal, our method is rehearsal-free, making it suitable for scenarios where previous data is unavailable due to privacy concerns. Our approach addresses both catastrophic forgetting and unseen domain generalization problems by introducing the Dynamic Central Difference Convolutional Adapter (DCDCA) to adapt Vision Transformer (ViT) models during the continual learning sessions. Additionally, we propose the Proxy Prototype Contrastive Regularization (PPCR) to mitigate forgetting without relying on previous data, by leveraging domain knowledge from proxy prototypes. We evaluate our method using two new protocols that assess generalization and anti-forgetting performance. Experimental results demonstrate that our approach improves generalization to unseen domains and mitigates catastrophic forgetting. The code and protocol files are available at https://github.com/RizhaoCai/DCL-FAS-ICCV2023.