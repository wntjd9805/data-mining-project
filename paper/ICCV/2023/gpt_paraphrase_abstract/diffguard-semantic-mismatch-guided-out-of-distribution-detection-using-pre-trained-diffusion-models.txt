This study focuses on detecting Out-of-Distribution (OOD) samples, which are samples that differ from all legal classes in terms of semantics. Previous research has used a conditional Generative Adversarial Network (cGAN) to increase the semantic mismatch in the image space and achieve good OOD detection performance on small datasets. However, this method is not suitable for larger datasets like IMAGENET due to the challenges in training cGANs with both input images and labels as conditions. To address this limitation, the authors propose using pre-trained diffusion models for OOD detection. These models are easier to train and can handle various conditions compared to cGANs. The proposed method, called DIFFGUARD, aims to enlarge the semantic difference between the reconstructed OOD image and the original input image based on the predicted label from the classifier. Several test-time techniques are also introduced to further enhance these differences. Experimental results demonstrate the effectiveness of DIFFGUARD on both CIFAR-10 and the challenging cases of IMAGENET. Additionally, the proposed method can be easily combined with existing OOD detection techniques to achieve state-of-the-art results.