Tutorial videos are becoming increasingly important for professional development and self-directed education. However, in order for users to fully benefit from these videos, they need to be easily searchable. This study focuses on moment detection, which involves identifying the specific time frame in a tutorial video where a particular event occurs. Previous research in moment detection has mainly focused on short videos, but tutorial videos are often much longer, posing challenges for existing approaches. To address this, the authors introduce the Behance Moment Detection (BMD) dataset, consisting of untrimmed, long-form tutorial videos with an average duration of over one hour. These videos have slowly evolving visual content and diverse dialogue. To tackle the unique challenges of this dataset, a new framework called LONGMOMENT-DETR is proposed, which outperforms existing methods. The authors also introduce a variation of the dataset with YouTube Chapter annotations and demonstrate that their framework can successfully enhance chapter detection performance. The code and data for this research can be found at https://github.com/ioanacroi/longmoment-detr.