Although transformers have improved semantic segmentation performance, there is a lack of exploration in domain adaptive transformers. We have identified that the domain gap leads to inconsistencies in self-attention, causing the transformer to focus on irrelevant regions or pixels, resulting in decreased accuracy in the target domain. To address this issue, we propose Cross-Domain Attention Consistency (CDAC), which adapts attention maps using cross-domain attention layers that share features between the source and target domains. CDAC enforces consistency between predictions from cross-domain attention and self-attention modules, promoting similar distributions across domains in both the attention and output of the model. We also ensure consistency in attention maps between different augmented views to enhance attention-based alignment. By combining these two components, CDAC reduces the discrepancies in attention maps across domains and improves the performance of the transformer in unsupervised domain adaptation settings. We evaluate our method on various widely used benchmarks and surpass the state-of-the-art baselines, such as GTAV-to-Cityscapes and Synthia-to-Cityscapes, by 1.3 and 1.5 percent point (pp) and 0.6 pp and 2.9 pp, respectively, when combined with two competitive Transformer-based backbones. Our code will be publicly available at the GitHub repository: https://github.com/wangkaihong/CDAC.