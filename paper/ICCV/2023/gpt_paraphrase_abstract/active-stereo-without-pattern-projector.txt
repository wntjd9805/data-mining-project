This paper introduces a new framework that combines the principles of active stereo with standard passive camera systems, eliminating the need for a physical pattern projector. Instead, a virtual pattern is projected onto the left and right images based on sparse measurements from a depth sensor. This framework can easily accommodate any depth sensor, allowing for the implementation of a virtual active stereo setup in any environment. This overcomes the limitations of pattern projectors, such as restricted working range and environmental constraints. The effectiveness of our approach is demonstrated through experiments using indoor and outdoor datasets, including both long and close-range scenarios. The results show that our framework enhances the accuracy of stereo algorithms and deep networks.