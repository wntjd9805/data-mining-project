We aim to overcome the challenge of developing efficient and accurate recognition systems when faced with limited labeled data. While larger models and more data generally lead to better recognition performance, many computer vision applications have resource constraints during both training and inference. Transfer learning is commonly used to train models with few labels, but it often requires computationally expensive fine-tuning of large base models. To address this trade-off between computation and accuracy, we propose a method called DISTILLNEAREST that uses task similarity metrics to select a suitable source model for distillation. We demonstrate the importance of a good selection process for achieving high performance in downstream tasks. However, DISTILLNEAREST assumes that a single source model matches the target task, which is not always the case. To overcome this limitation, we introduce DISTILLWEIGHTED, a weighted multi-source distillation method that combines multiple source models trained on different domains, taking into account their relevance to the target task. Our methods do not require access to the source data and only need features and pseudo-labels from the source models. In terms of accurate recognition under computational constraints, both DISTILLNEAREST and DISTILLWEIGHTED outperform transfer learning from ImageNet initializations and state-of-the-art semi-supervised techniques like FixMatch. Across eight diverse target tasks, our multi-source method outperforms the baselines by 5.6% and 4.5%, respectively. The code for our approach can be found at github.com/Kennethborup/DistillWeighted.