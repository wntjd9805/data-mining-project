Data-free knowledge distillation (DFKD) is a promising technique for addressing challenges related to model compression, security privacy, and transmission restrictions. While existing DFKD methods have achieved impressive results in coarse-grained classification tasks, they fall short in practical applications involving fine-grained visual categorization (FGVC) tasks that require more detailed distinctions between similar categories. To overcome this limitation, we propose DFKD-FGVC, an extension of DFKD specifically designed for FGVC tasks. Our approach incorporates an adversarial distillation framework with attention generator, mixed high-order attention distillation, and semantic feature contrast learning. We introduce a spatial-wise attention mechanism to the generator, allowing it to synthesize fine-grained images with more detailed discriminating parts. Additionally, we leverage a mixed high-order attention mechanism to capture complex interactions among parts and subtle differences among discriminative features of fine-grained categories, considering both local features and semantic context relationships. Furthermore, we utilize the teacher and student models of the distillation framework to compare high-level semantic feature maps in the hyperspace, highlighting differences between categories. We evaluate our approach on three widely-used FGVC benchmarks (Aircraft, Cars196, and CUB200) and demonstrate its superior performance. The code for our approach is available at https://github.com/RoryShao/DFKD-FGVC.git.