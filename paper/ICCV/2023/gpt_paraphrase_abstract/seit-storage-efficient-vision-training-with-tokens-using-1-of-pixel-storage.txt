To achieve more advanced vision models and accommodate massive datasets, it is crucial to have billion-scale images and sufficient storage capacity. However, limited storage infrastructure poses challenges in handling such large datasets. Although several storage-efficient training methods have been proposed, they often lack scalability or compromise performance. This paper presents a storage-efficient training strategy for vision classifiers, specifically for large-scale datasets like ImageNet. Our approach uses only 1024 tokens per instance, eliminating the need for raw pixel-level data. This token storage method requires less than 1% of the storage space needed for the original JPEG-compressed raw pixels. We also introduce token augmentations and a Stem-adaptor module, allowing our approach to leverage the same architecture as pixel-based methods with minimal modifications. Our experiments on ImageNet-1k demonstrate that our method significantly outperforms other storage-efficient training methods. We also showcase the effectiveness of our approach in storage-efficient pre-training and continual learning scenarios. The code for our method is available at https://github.com/naver-ai/seit.