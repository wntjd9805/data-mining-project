GO-SLAM is a deep-learning-based framework for dense visual Simultaneous Localization and Mapping (SLAM). It addresses the issues of error accumulation in camera tracking and distortion in reconstruction that are commonly found in neural implicit representations. The framework globally optimizes poses and 3D reconstruction in real-time by utilizing robust pose estimation, efficient loop closing, and online full bundle adjustment. It leverages the learned global geometry of input frames to optimize each frame individually. Additionally, it updates the implicit and continuous surface representation on-the-fly to maintain global consistency in 3D reconstruction. The performance of GO-SLAM surpasses that of state-of-the-art approaches in terms of tracking robustness and reconstruction accuracy, as demonstrated on various synthetic and real-world datasets. Moreover, GO-SLAM is versatile and can be used with monocular, stereo, and RGB-D input.