This study focuses on the problem of quickly and accurately identifying the most useful pre-trained model for a downstream task. Transferability measurement, which quantifies the transferability of a pre-trained model from a source task to a target task, is crucial for effective transfer learning. Existing methods measure transferability by assessing the discrimination ability of a source model on target data before transfer learning, but these methods fail to accurately estimate fine-tuning performance. Additionally, these methods are limited to selecting the best supervised pre-trained models with classifiers, while a general method applicable to various situations is needed.To address these issues, this work proposes a fast and accurate algorithm called TMI (TRANSFERABILITY MEASUREMENT WITH INTRA-CLASS FEATURE VARIANCE) for measuring transferability. The authors define transferability as the generalization of a pre-trained model on a target task, measured by evaluating the intra-class feature variance. Intra-class variance captures the model's adaptability to a new task and serves as a measure of transferability. Unlike previous methods that rely on optimal feature extractors and classifiers, intra-class variance provides a more accurate assessment. Extensive experiments on real-world datasets demonstrate that TMI outperforms other methods in selecting the top-5 best models and consistently exhibits better correlation in the majority of cases. Overall, this study presents a novel approach to measuring transferability that can be applied in a wide range of scenarios, including selecting self-supervised pre-trained models without classifiers and identifying the best transferring layer for a target task.