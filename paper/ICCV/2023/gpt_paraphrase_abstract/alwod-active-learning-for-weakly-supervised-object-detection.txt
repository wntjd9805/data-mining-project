ALWOD is a novel framework that tackles the problem of limited training datasets with precise object localization labels in object detection (OD). By combining active learning (AL) with weakly and semi-supervised object detection paradigms, ALWOD aims to improve OD performance. To address the dependence of AL on model initialization, ALWOD proposes an auxiliary image generator strategy that utilizes a small labeled set and a large weakly tagged set as a warm-start for AL. Additionally, ALWOD introduces a new AL acquisition function that leverages student-teacher OD pair disagreement and uncertainty to identify the most informative images for annotation. To complete the AL loop, ALWOD introduces a new labeling task that involves human annotators selecting and correcting model-proposed detections, enabling rapid and effective labeling of informative images. Experimental results on challenging benchmarks demonstrate that ALWOD significantly reduces the performance gap between OD models trained on few partially labeled instances and those trained on fully-labeled data. The code for ALWOD is publicly available on GitHub.