This study introduces SparseNeRF, a new framework that addresses the limitations of Neural Radiance Field (NeRF) when only a limited number of views are available. Existing depth-based models rely on accurate depth maps, which are difficult and expensive to capture. SparseNeRF leverages depth priors from real-world inaccurate observations, such as pre-trained depth models or coarse depth maps from consumer-level sensors. To ensure consistency with coarse depth maps, a local depth ranking method is proposed as a constraint on NeRFs. Additionally, a spatial continuity constraint is introduced to preserve the spatial continuity of the estimated depth. Surprisingly, SparseNeRF outperforms state-of-the-art few-shot NeRF methods, including depth-based models, on standard datasets. The researchers also collect a new dataset called NVS-RGBD, which contains real-world depth maps. Extensive experiments on this dataset further validate the superiority and generalizability of SparseNeRF. The code and dataset are available at https://sparsenerf.github.io/.