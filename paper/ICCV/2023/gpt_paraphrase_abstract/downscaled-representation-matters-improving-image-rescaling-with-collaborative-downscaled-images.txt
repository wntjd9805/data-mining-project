Deep learning networks have achieved significant success in the task of image rescaling, which involves learning optimal down-scaled representations to reconstruct high-resolution images. Compared to fixed downscaling methods like bicubic interpolation, image rescaling methods achieve superior reconstruction performance due to the learned down-scaled representations. Existing methods optimize the downscaling and upscaling models together to improve the downscaled representation. However, we propose a novel approach called Hierarchical Collaborative Downscaling (HCD) that directly optimizes the downscaled image itself instead of the down-/upscaling models. This is done through gradient descent with respect to the reconstruction loss in both high-resolution and low-resolution domains. Our extensive experiments demonstrate that HCD significantly enhances reconstruction performance in both quantitative and qualitative measures. We outperform popular image rescaling methods by more than 0.57 dB PSNR on Set5. Additionally, we showcase the versatility of HCD as it can effectively generalize across various image rescaling models. The code for HCD is publicly available at https://github.com/xubingna/HCD.