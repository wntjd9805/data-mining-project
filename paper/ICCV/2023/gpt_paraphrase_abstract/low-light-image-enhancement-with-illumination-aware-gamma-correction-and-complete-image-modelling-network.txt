This paper introduces a new network structure that incorporates illumination-aware gamma correction and complete image modeling to address the problem of enhancing low-light images. Traditional methods of directly learning deep representations from low-light images are ineffective in recovering normal illumination due to the presence of large-scale dark areas with limited information. To overcome this, we propose integrating gamma correction with deep networks to learn the correction factor gamma in a gradual manner, effectively perceiving the deviated illumination. To speed up the training and inference process, we approximate the gamma correction using Taylor Series instead of the computationally expensive exponential operation. Since dark areas typically occupy significant portions of low-light images, existing local modeling structures such as CNN and SwinIR are insufficient for accurately restoring illumination across the entire image. To address this, we introduce a novel Transformer block that employs a local-to-global hierarchical attention mechanism to simulate the dependencies among all pixels in the image. This enables the effective borrowing of information from well-lit regions to infer the dark areas. Extensive experiments conducted on multiple benchmark datasets demonstrate that our approach outperforms state-of-the-art methods in low-light image enhancement.