Our proposed method utilizes a rich-text editor with customizable options such as font style, size, color, and footnotes to overcome the limitations of plain text in text-to-image synthesis. We extract attributes from the rich text to enable precise control over style, token weighting, color rendering, and region synthesis. This is achieved through a region-based diffusion process where each word's region is obtained using attention maps. We enforce the text attributes for each region by creating region-specific detailed prompts and applying region-specific guidance. To maintain fidelity, we employ region-based injections. Through various examples, we demonstrate that our method outperforms strong baselines in generating images from rich text.