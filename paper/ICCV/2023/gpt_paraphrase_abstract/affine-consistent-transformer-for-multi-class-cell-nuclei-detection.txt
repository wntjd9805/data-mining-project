Multi-class cell nuclei detection is a crucial step in histopathology diagnosis as it enables efficient identification of cells with different shapes and distributions in digital pathology images. Existing methods often rely on complex intermediate representations and post-refinements, neglecting variations in cell density and fields of view. In this study, we present a novel approach called Affine-Consistent Transformer (AC-Former) that directly provides a sequence of nucleus positions. AC-Former consists of two sub-networks, a global and a local network, which are collaboratively trained. The local branch learns to infer distorted input images of smaller scales, while the global network generates large-scale predictions as additional supervision signals. To improve the training of the local network, we introduce an Adaptive Affine Transformer (AAT) module that automatically learns spatial transformations to warp the original images. This module focuses on capturing the transformed image regions that are most valuable for training the model. Experimental results show that our proposed method outperforms state-of-the-art algorithms on various benchmark datasets.