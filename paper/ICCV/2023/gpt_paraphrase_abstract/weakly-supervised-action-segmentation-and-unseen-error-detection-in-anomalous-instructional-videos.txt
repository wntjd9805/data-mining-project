We present a new approach for detecting errors and segmenting actions in instructional videos with limited supervision. To address the lack of appropriate data, we introduce the Anomalous Toy Assembly (ATA) dataset consisting of 1152 videos from 32 participants assembling different toys from various angles. The dataset includes a training set with 27 participants performing consistently and a test/validation set with 5 participants displaying abnormal behavior during the task. Our method utilizes a weakly labeled segmentation algorithm, an extension of the constrained Viterbi algorithm, to identify potential anomalous moments by comparing future anticipation with current recognition results. Unlike previous approaches, our method does not rely on training transcripts during testing, allowing for real-time inference of anomalous action sequences. Additionally, we propose a baseline for detecting predefined human errors based on the segmentation results and evaluate its performance on the ATA dataset. We conducted experiments on both the ATA and CSV datasets, and our method outperformed existing techniques in segmenting anomalous videos both online and offline.