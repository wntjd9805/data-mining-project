This paper investigates the use of class embeddings in semantic segmentation tasks in computer vision. It suggests that more explicit and meaningful class embeddings can be generated based on class masks. The proposed ECENet segmentation paradigm enhances class embeddings during interactions with multi-stage image features and explores the information flow between segmentation masks and class embeddings. To improve the discriminability and informativity of features, a Feature Reconstruction module is introduced. Experimental results demonstrate that ECENet outperforms other methods on the ADE20K dataset with reduced computational cost and achieves state-of-the-art results on the PASCAL-Context dataset. The code for ECENet can be accessed at https://gitee.com/mindspore/models and https://github.com/Carol-lyh/ECENet.