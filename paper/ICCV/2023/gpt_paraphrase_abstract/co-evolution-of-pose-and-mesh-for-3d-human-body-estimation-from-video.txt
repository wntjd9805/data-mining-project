Recovering 3D human motion accurately and smoothly from videos remains a challenge, despite advancements in single image-based 3D human mesh recovery. Current video-based methods estimate complex pose and shape parameters from coupled image features, which often lead to inconsistent pose motion and limited shape patterns. To address this issue, we propose a Pose and Mesh Co-Evolution network (PMCE) that decouples the task into two parts: 1) video-based 3D human pose estimation and 2) regression of mesh vertices from the estimated 3D pose and temporal image feature. Our approach includes a two-stream encoder that estimates mid-frame 3D pose and extracts a temporal image feature. We also introduce a co-evolution decoder that uses image-guided Adaptive Layer Normalization (AdaLN) to facilitate pose and mesh interactions and ensure proper fit to the human body shape. Extensive experiments on three benchmark datasets (3DPW, Human3.6M, and MPI-INF-3DHP) show that our PMCE outperforms previous state-of-the-art methods in terms of both per-frame accuracy and temporal consistency. The code for our approach is available at https://github.com/kasvii/PMCE.