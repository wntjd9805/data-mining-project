The paper presents Cascade-DETR, a novel approach for high-quality universal object detection. While current Transformer-based detection methods excel in the COCO benchmark, they struggle to perform well in diverse domains and accurately estimate object bounding boxes in complex environments. To address these limitations, Cascade-DETR introduces the Cascade Attention layer, which integrates object-centric information into the detection decoder by restricting attention to the previous box prediction. This layer enhances generalization to diverse domains and improves localization accuracy. Additionally, Cascade-DETR improves confidence calibration by predicting the expected Intersection over Union (IoU) of the query instead of relying on classification scores. The authors also introduce a new benchmark, UDB10, consisting of 10 datasets from diverse domains. Cascade-DETR outperforms existing DETR-based detectors on all datasets in UDB10, achieving significant improvements, even surpassing 10 mAP in some cases. The performance gains are particularly notable under stringent quality requirements. The code and pretrained models for Cascade-DETR are available at the provided GitHub link.