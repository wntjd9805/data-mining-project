Abstract
Although Deep Neural Networks (DNNs) have demon-strated excellent performance, they are vulnerable to ad-versarial patches that introduce perceptible and localized perturbations to the input. Generating adversarial patches on images has received much attention, while adversarial patches on videos have not been well investigated. Further, decision-based attacks, where attackers only access the pre-dicted hard labels by querying threat models, have not been well explored on video models either, even if they are prac-tical in real-world video recognition scenes. The absence of such studies leads to a huge gap in the robustness assess-ment for video models. To bridge this gap, this work first explores decision-based patch attacks on video models. We analyze that the huge parameter space brought by videos and the minimal information returned by decision-based models both greatly increase the attack difficulty and query burden. To achieve a query-efficient attack, we propose a spatial-temporal differential evolution (STDE) framework.
First, STDE introduces target videos as patch textures and only adds patches on keyframes that are adaptively selected by temporal difference. Second, STDE takes minimizing the patch area as the optimization objective and adopts spatial-temporal mutation and crossover to search for the global optimum without falling into the local optimum. Exper-iments show STDE has demonstrated state-of-the-art per-formance in terms of threat, efficiency and imperceptibility.
Hence, STDE has the potential to be a powerful tool for evaluating the robustness of video recognition models. 1.

Introduction
Deep Neural Networks (DNNs) have showcased excel-lent efficacy in computer vision tasks [12, 47, 46, 25, 24, 6].
However, recent studies indicate they are vulnerable to ad-*indicates equal contributions.
†indicates corresponding authors.
Figure 1. Given a source video and target video, STDE iteratively optimizes adversarial patches while requiring few queries. Com-pared to BSCA [4], STDE can achieve more potent attacks (e.g. targeted attacks) and generate smaller and sparser patches to im-prove the imperceptibility. versarial examples, which are carefully crafted inputs with imperceptible adversarial perturbations. When facing ad-versarial examples [34], DNNs predict wrong outputs with high confidence, posing serious security threats. Most studies of adversarial examples focus on the image mod-els [20, 14]. Wei et al. [39] indicate that the vulnerability also exists on video models. This vulnerability brings se-curity threats on video-related tasks, such as object track-ing [22, 23], video action recognition [19], etc. Therefore, it is indispensable to conduct thorough research on video adversarial examples for constructing more secure models.
Early studies of adversarial examples are concerned with perturbation-based attacks on image models [34, 20, 26, 2], where attackers add small lp norm perturbations to each pixel of inputs. Recently, researchers have found that patch attacks, where attackers add regional and percepti-ble patches on inputs, pose a significant threat to DNNs.
Further, many defense methods that are effective against perturbation-based attacks turn ineffective against patch at-tacks [44]. This demonstrates that patch attacks are non-negligible for evaluating model robustness. Although patch attacks have made great progress on image models [1, 18, 11, 44, 9, 16, 7], to our best investigation, BSCA [4] is cur-rently the only patch attack against video recognition mod-els. Since BSCA focuses too much on the imperceptibility of the patch, its attack performance is relatively moderate (especially for targeted attacks). Therefore, it is of great in-terest to study a video patch attack that balances threat and imperceptibility to evaluate the robustness of video models.
In pioneering work [1, 18], patch attacks are carried out in the white-box setting, where attackers can access the whole details of the model (e.g. parameters and gra-dients). Since the white-box is too ideal, more work [11] has explored black-box score-based attacks, where the ad-versary can only access the model output (e.g. labels and corresponding logits) by querying models and utilize log-its to design optimization strategies. Existing works pro-pose rich patch forms based on applications, including monochrome [11], color texture [44, 9], watermark [16] and bullet screens [4], etc. However, as model security and privacy concerns continue to grow, obtaining logits has be-come increasingly difficult, particularly for video models used in security-critical tasks. Therefore, it is of practical significance for video models to investigate decision-based patch attacks, which can only access the predicted label of the model and pose a greater threat. However, to the best of our knowledge, there is currently a lack of research in this area. This gap leads to potential vulnerabilities for video models and impedes the advancement of developing more robust video models.
To bridge this gap, we explore a new attack setting called decision-based patch attacks on video models. This setting combines the advantage of patch and decision-based attacks to improve the assessment system for video model robust-ness. However, there also exists lots of challenges: 1) Com-pared to images, the temporal dimension of videos substan-tially enlarges the parameter space and incurs a significant query burden. Particularly, the mutual complement of in-formation between frames increases the difficulty of attack. 2) The large parameter space of the patch (position, shape, texture) and the scarce output of the model (top-1 predicted label) can easily lead the attack to local optima [30], which reduces the efficiency of the attack.
To solve these challenges and achieve query-efficient decision-based patch attacks on video models, we pro-pose Spatial-Temporal Differential Evolution patch attack (STDE). To improve query efficiency, STDE reduces the pa-rameter space in the temporal and spatial domains. Specifi-cally, in the spatial domain, STDE introduces target videos as prior knowledge to fill the texture of the patch and uses paired coordinates to model the position and shape of the patch. In the temporal domain, STDE performs binary en-coding on the video sequence and selects keyframes accord-ing to the temporal difference, achieving a sparse attack.
After the modeling described above, the decision-based patch attack is transformed into a discrete combinatorial optimization problem. Therefore, we improve the classic heuristic algorithm [32] and propose a spatial-temporal dif-ferential evolution strategy that uses spatial-temporal muta-tion and crossover operations to avoid local optima. Fig-ure 1 shows an illustration of generating the video patch based on STDE in the decision-based patch attack setting.
Our main contributions and experiments are as follows:
• To our best knowledge, We are the first to com-bine patch attacks and decision-based attacks on video models, introducing a new attack scenario called decision-based patch attacks. This bridges the gap in robustness assessment of video models.
• To achieve query-efficient attacks in this new setting, we propose a novel attack STDE, which reduces the parameter space of video adversarial examples in spa-tial and temporal domains and uses spatial-temporal difference to search for the decision boundary.
• We conduct extensive experiments on video recog-nition models trained with UCF-101 and Kinetics-400 datasets. Compared with state-of-the-art methods,
STDE shows 100% fooling rates with smaller patch area and fewer queries. Due to the sparse distribution and small size of adversarial patches, STDE ensures both potent attack capability and imperceptibility. 2.