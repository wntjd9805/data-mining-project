Abstract
This paper introduces Delta Denoising Score (DDS) a novel diffusion-based scoring technique which optimizes a parametric model for the task of image editing. Unlike the existing Score Distillation Sampling (SDS), which queries the generative model with a single image-text pair, DDS utilizes an additional fixed query of a reference image-text pair to generate delta scores that represent the difference between the outputs of the two queries. By estimating noisy gradient directions introduced by SDS using the source im-age and its text description, DDS provides cleaner gradi-ent directions that modify the edited portions of the image while leaving others unchanged, thereby yielding a distilled edit of the source image. The analysis presented in this pa-per supports the power of the new score for image-to-image translation. We further show that the new score can be used to train an effective zero-shot image translation model. The experimental results show that the proposed loss term out-performs existing methods in terms of stability and quality, highlighting its potential for real-world applications. 1.

Introduction
Large-scale language-vision models have revolutioniz-ing the way images and visual content, in general, can be generated and edited. Recently, we are witnessing a surge in the development of text-to-image generative models, which utilize textual input to condition the generation of images. A promising avenue in this field is Score Distillation Sampling (SDS) [24] – a sampling mechanism that utilizes probability density distillation to optimize a parametric image genera-tor using a 2D diffusion model as a prior.
The effectiveness of the SDS stems from rich genera-tive prior of the diffusion model it samples from. This is in contrast to the direct use of a language-vision model, like
CLIP, which was trained using contrastive loss [25]. The prior of large generative diffusion models, like Stable Dif-fusion [27], DALLE-2 [26] and Imagen [31] is particularly rich and expressive and has been demonstrated to be highly z
ˆz z zt
ˆzt zt t∼U (0,1)
ϵ∼N (0,I) t∼U (0,1)
ϵ∼N (0,I)
ϵϕ
ˆϵϕ
∇θLSDS
∇θLDDS
ϵϕ
Figure 1: Delta Denoising Score (DDS) vs. Score Distilla-tion Sampling (SDS). Top: SDS allows optimizing a given image by querying the denoising model guided by a text prompt. However, it results in a blurred image away from the edited elements. Bottom: DDS, queries an additional reference branch aligned with its text-prompt, and gener-ates delta scores that represent the difference between the outputs of the two queries. DDS provides cleaner gradient directions that modify the edited portions of the optimized image, while leaving the others unchanged. effective in generating visually stunning assets across vari-ous domains, including images, 3D models and more.
Despite its usefulness, one of the primary issues associ-ated with SDS is its tendency to converge towards specific modes, which often leads to the production of blurry out-puts that only capture the elements explicitly described in
the prompt. In particular, using SDS to edit an existing im-age by initializing the optimization procedure from that im-age, may result in significant blurring of the image beyond the edited elements.
In this paper, we introduce a new diffusion-based scoring technique for optimizing a parametric model for the task of editing. Unlike SDS, which queries the generative model with a pair of image and text, our method utilizes an addi-tional query of a reference, aligned, pair; that is, the text de-scribes and agrees with the content of the image. Then, the output score is the difference, or delta, between the results of the two queries (see Figure 1). We refer to this scoring technique as Delta Denoising Score (DDS).
In its basic form, DDS is applied on two pairs of images and texts, one is a reference image-text that remains intact during the optimization, and the other is a target image that is optimized to match a target text prompt. The delta scoring provides effective gradients, which modify the edited por-tions of the image, while leaving the others unchanged. The key idea is that the source image and its text description, can be used for estimating undesirable and noisy gradients directions introduce by SDS. Then, if we want to alter only a portion of the image using a new text description, we can use our reference estimation and get a cleaner gradient di-rection to update the image.
DDS can be used as a prompt-to-prompt editing tech-nique that can modify images by only editing their captions, where no mask is provided or computed. Beyond that, Delta
Denoising Score enables us to train a distilled image-to-image model without the need of paired training dataset, yielding a zero-shot image translation technique. Training the model, requires only dataset of the source distribution, associated with simple captions that describe the source and target image distributions. As we shall show, such zero-shot training can be applied on a single or multi-task image translation, and the source distribution can include synthet-ically generated and real images.
To demonstrate the effectiveness of our approach, we conducted experiments comparing our model to existing state-of-the-art text-driven editing methods. 2.