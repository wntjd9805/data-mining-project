Abstract
We explore the task of zero-shot semantic segmenta-tion of 3D shapes by using large-scale off-the-shelf 2D im-age recognition models. Surprisingly, we ﬁnd that mod-ern zero-shot 2D object detectors are better suited for this task than contemporary text/image similarity predictors or even zero-shot 2D segmentation networks. Our key ﬁnding is that it is possible to extract accurate 3D segmentation maps from multi-view bounding box predictions by using the topological properties of the underlying surface. For this, we develop the Segmentation Assignment with Topo-logical Reweighting (SATR) algorithm and evaluate it on
ShapeNetPart and our proposed FAUST benchmarks. SATR achieves state-of-the-art performance and outperforms a baseline algorithm by 1.3% and 4% average mIoU on the
FAUST coarse and ﬁne-grained benchmarks, respectively, and by 5.2% average mIoU on the ShapeNetPart bench-mark. Our source code and data will be publicly released.
Project webpage: https://samir55.github.io/SATR/. 1.

Introduction
Recent developments in vision-language learning gave rise to many 2D image recognition models with extreme zero-shot generalization capabilities (e.g., [76, 70, 55, 54, 102]). The key driving force of their high zero-shot per-formance was their scale [11]: both in terms of the sheer amount of data [80, 49] and parameters [5, 97] and in terms of developing the architectures with better scalabil-ity [85, 31, 59]. However, extending this success to the 3D domain is hindered by the limited amount of available 3D data [2, 3], and also the higher computational cost of the corresponding architectural components [19]. For example,
the largest openly available 2D segmentation dataset [52] contains two orders of magnitude more instance annotations than the largest 3D segmentation one [79]. This forces us to explore other ways of performing zero-shot recognition in 3D, and in our work, we explore the usage of off-the-shelf 2D models for zero-shot 3D shape segmentation.
Zero-shot 3D shape segmentation is a recently emerged research area [22] with applications in text-based edit-ing [75, 4], stylization [65], and interactive visualization.
Given a 3D mesh, the user provides one or several text descriptions of their regions of interest, and the task is to categorize each face on the mesh into one of the given de-scriptions (or “background” class if it does not suit any).
To the best of our knowledge, the only previous work which explores this task is 3D Highlighter (3DH) [22]. The method uses an optimization-based search algorithm guided by CLIP [76] to select the necessary faces for a given text prompt. While showing strong zero-shot performance, 3DH has two drawbacks: 1) it struggles in ﬁne-grained segmen-tation, and 2) it is very sensitive to initialization (see Fig-ure 2). Moreover, due to its per-query optimization, the 5-10 minutes segmentation process is slow, taking up to on a recent GPU for a single semantic part.
⇡
In our work, we explore modern zero-shot 2D object de-tectors [55] and segmentors [54, 61] for 3D shape segmen-tation. Intuitively, 2D segmentation networks are a natural choice for this task: one can predict the segmentations for different views, and then directly propagate the predicted pixel classes onto the corresponding mesh faces. Moreover and surprisingly, we found that it is possible to achieve sub-stantially higher performance using a zero-shot 2D object detector [55]. To do this, we develop Segmentation As-signment with Topological Reweighting (SATR): a method that estimates a 3D segmentation map from multi-view 2D bounding box predictions by using the topological proper-ties of the underlying 3D surface.
For a given mesh and a text prompt, our method ﬁrst uses GLIP [55] to estimate the bounding boxes from dif-ferent camera views. However, relying exclusively on the bounding boxes provides only coarse guidance for 3D seg-mentation and is prone to “leaking” unrelated mesh faces into the target segment. This motivates us to develop two techniques to infer and reﬁne the proper segmentation. The
ﬁrst one, gaussian geodesic reweighting, performs robust reweighting of the faces based on their geodesic distances to the potential segment center. The second one, visibility smoothing, uses a graph kernel, which adjusts the inferred weights based on the visibility of its neighbors. When com-bined together, these techniques allow for achieving state-of-the-art results on zero-shot 3D shape segmentation, es-pecially for ﬁne-grained queries.
To the best of our knowledge, there are currently no quantitative benchmarks proposed for 3D mesh segmenta-elbow feet belly button shoulder 9
: d e e s 7 0 4 3
: d e e s
Figure 2: 3DHighlighter [23] is very sensitive to initialization. We observe that 3DHighlighter produces quite different results when using different seeds for the same prompt on different 3D shapes. tion, and all the evaluations are only qualitative [22]. For a more robust evaluation, we propose one quantitative bench-mark, which includes coarse and ﬁne-grained mesh seg-mentation categories. We also evaluate our method on
ShapeNetPart [95] benchmark. Our proposed benchmark is based on FAUST [9]: a human body dataset consisting of 100 real human scans. We manually segment 17 regions on one of the scans and use the shape correspondences pro-vided by FAUST to propagate them to all the other meshes.
We evaluate our approach along with existing methods on the proposed benchmarks and show the state-of-the-art performance of our developed ideas both quantitatively and qualitatively.
Speciﬁcally, SATR achieves 82.46% and 46.01% average mIoU on the coarse and ﬁne-grained
FAUST benchmarks and 31.9% average mIoU scores on the
ShapeNetPart benchmark, outperforming recent methods.
For ﬁne-grained categories, the advantage of our method is even higher: it surpasses a baseline method by at least 4% higher mIoU on average. We will publicly release our source code and benchmarks. 2.