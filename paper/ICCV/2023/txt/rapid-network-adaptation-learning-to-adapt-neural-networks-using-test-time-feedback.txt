Abstract
We propose a method for adapting neural networks to distribution shifts at test-time.
In contrast to training-time robustness mechanisms that attempt to anticipate and counter the shift, we create a closed-loop system and make use of test-time feedback signal to adapt a network on the fly. We show that this loop can be effectively implemented using a learning-based function, which realizes an amor-tized optimizer for the network. This leads to an adapta-tion method, named Rapid Network Adaptation (RNA), that is notably more flexible and orders of magnitude faster than the baselines. Through a broad set of experiments us-ing various adaptation signals and target tasks, we study the generality, efficiency, and flexibility of this method. We perform the evaluations using various datasets (Taskon-omy, Replica, ScanNet, Hypersim, COCO, ImageNet), tasks (depth, optical flow, semantic segmentation, classification), and distribution shifts (Cross-datasets, 2D and 3D Common
Corruptions) with promising results. 1.

Introduction
Neural networks are found to be unreliable against distri-bution shifts [23, 35, 43, 42, 29]. Examples of such shifts in-clude blur due to camera motion, object occlusions, changes in weather conditions and lighting, etc. The training-time strategies to deal with this issue attempt to anticipate the shifts that may occur and counter them at the training stage – for instance, by augmenting the training data or updating the architecture with corresponding robustness inductive bi-ases. As the possible shifts are numerous and unpredictable, this approach has inherent limitations. This is the main mo-tivation behind test-time adaptation methods, which instead aim to adapt to such shifts as they occur and recover from failure. In other words, these methods choose adaptation over anticipation (see Fig. 1). In this work, we propose a test-time adaptation framework that aims to perform an ef-Figure 1: Adaptive vs non-adaptive neural network pipelines. Top:
In order to be robust, non-adaptive methods include training-time inter-ventions that anticipate and counter the distribution shifts that will occur at test-time (e.g., via data augmentation). The learned model, fθ, is frozen at test-time, thus upon encountering an out-of-distribution input, its pre-dictions may collapse. Bottom: Adaptive methods create a closed-loop and use an adaptation signal at test-time. The adaptation signal is a quan-tity that can be computed at test-time from the environment. hϕ acts as a
“controller” by taking in an error feedback, computed from the adaptation signal and model predictions, to adapt fθ accordingly. It can be imple-mented as a (i) standard optimizer (e.g., using SGD) or (ii) neural network.
The former is equivalent to test-time optimization (TTO), while the latter aims to amortize the optimization process, by training a controller network to adapt fθ – thus, it can be more efficient and flexible. In this work, we study the latter approach and show its efficiency and flexibility. ficient adaptation of a given main network using a feedback signal.
One can consider performing “test-time optimiza-tion” (TTO) for this purpose, similar to previous works [91, 108, 27] e.g. simply using SGD to finetune the network to reduce a proxy loss [91]. While this can successfully adapt a network, it is unnecessarily inefficient as it does not make use of the learnable regularities in the adaptation pro-cess, and consequently, unconducive for real-world appli-cations. It also results in a rigid framework as the update mechanism is fixed to be the same as the training process of neural networks (SGD). We show this process can be effectively amortized using a learning-based feed-forward controller network, which yields orders of magnitude faster results (See Fig. 1, Sec. 4.3). In addition, it provides flex-ibility advantages as the controller is implemented using a neural network and can be engineered to include arbitrary inductive biases and desired features that could counter the suboptimalities of the adaptation signal. 2.