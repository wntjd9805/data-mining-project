Abstract
We present SegGPT, a generalist model for segmenting ev-erything in context. We unify various segmentation tasks into a generalist in-context learning framework that accommo-dates different kinds of segmentation data by transforming them into the same format of images. The training of Seg-GPT is formulated as an in-context coloring problem with random color mapping for each data sample. The objec-tive is to accomplish diverse tasks according to the context, rather than relying on specific colors. After training, Seg-GPT can perform arbitrary segmentation tasks in images
*Equal contribution. Correspondence to xinlong.wang96@gmail.com. or videos via in-context inference, such as object instance, stuff, part, contour, and text. SegGPT is evaluated on a broad range of tasks, including few-shot semantic segmenta-tion, video object segmentation, semantic segmentation, and panoptic segmentation. Our results show strong capabilities in segmenting in-domain and out-of-domain targets, either qualitatively or quantitatively. 1.

Introduction
Segmentation is one of the most fundamental problems in computer vision, which aims to localize and re-organize meaningful concepts at the pixel level, e.g., foreground, cat-egory, object instance, etc. During recent years, we have witnessed great progress in developing more accurate and faster algorithms for various segmentation tasks, such as fore-ground segmentation [45], interactive segmentation [55, 38], semantic segmentation [36, 32, 58, 43], instance segmenta-tion [20, 13, 4, 52], and panoptic segmentation [26, 7, 10].
However, these specialist segmentation models are lim-ited to specific tasks, classes, granularities, data types, etc.
A new model has to be trained when adapting to a different setting, e.g., to segment a novel concept, or to segment ob-jects in videos instead of images. This requires expensive annotation efforts and is not sustainable for a large number of segmentation tasks.
In this work, we aim to train a single model that is capable of solving diverse and unlimited segmentation tasks. The main challenges are twofold: (1) to incorporate those very different data types in training, e.g., part, semantic, instance, panoptic, person, medical image, aerial image, etc.; (2) to design a generalizable training scheme that differs from conventional multi-task learning, which is flexible on task definition and is capable of handling out-of-domain tasks.
To address these challenges, we present SegGPT, a gener-alist model for segmenting everything in context. We view segmentation as a general format for visual perception and unify different segmentation tasks into a generalist in-context learning framework [50]. This framework accommodates different kinds of segmentation data by transforming them into the same format of images. The training of SegGPT is formulated as an in-context coloring problem with random color mapping for each data sample. The objective is to color the corresponding areas, such as classes, object instances, parts, etc., only according to the context. By using a random coloring scheme, the model is forced to reference contextual information to complete the assigned task, instead of rely-ing on specific colors. This allows for a more flexible and generalizable approach to training. The remaining parts of training keep the same as [50] using a vanilla ViT [46] and a simple smooth-â„“1 [19] loss.
After training, SegGPT is able to perform diverse seg-mentation tasks in images or videos given a few examples via in-context inference, such as object instance, stuff, part, contour, text, etc. To effectively ensemble multiple exam-ples in context, we propose a simple yet effective context ensemble strategy, the feature ensemble, which can help the model benefit from the multi-example prompting setting.
Additionally, SegGPT can conveniently serve as a specialist model without updating the model parameters, by tuning a specific prompt for a specialized use case, such as in-domain
ADE20K semantic segmentation.
Our main contributions are as follows. (1) For the first time, we demonstrate a single generalist model capable of performing a diverse set of segmentation tasks automatically. (2) We evaluate the pre-trained SegGPT on a broad range of tasks directly, i.e., without fine-tuning, including few-shot semantic segmentation, video object segmentation, semantic segmentation, and panoptic segmentation. (3) Our results show strong capabilities in segmenting in-domain and out-of-domain targets, either qualitatively or quantitatively.
However, this work does not aim to claim new state-of-the-art results or outperform existing specialist methods across all benchmarks, as we believe that this may not be the responsibility of a general-purpose model. 2.