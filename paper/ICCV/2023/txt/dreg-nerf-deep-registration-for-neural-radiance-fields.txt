Abstract 1.

Introduction
Although Neural Radiance Fields (NeRF) is popular in the computer vision community recently, registering mul-tiple NeRFs has yet to gain much attention. Unlike the existing work, NeRF2NeRF [14], which is based on tra-ditional optimization methods and needs human annotated keypoints, we propose DReg-NeRF to solve the NeRF reg-istration problem on object-centric scenes without human intervention. After training NeRF models, our DReg-NeRF first extracts features from the occupancy grid in NeRF. Sub-sequently, our DReg-NeRF utilizes a transformer architec-ture with self-attention and cross-attention layers to learn the relations between pairwise NeRF blocks.
In contrast to state-of-the-art (SOTA) point cloud registration methods, the decoupled correspondences are supervised by surface fields without any ground truth overlapping labels. We con-struct a novel view synthesis dataset with 1,700+ 3D objects obtained from Objaverse to train our network. When eval-uated on the test set, our proposed method beats the SOTA point cloud registration methods by a large margin with a mean RPE = 9.67◦ and a mean RTE = 0.038. Our code is available at https://github.com/AIBluefisher/DReg-NeRF.
Scene reconstruction has many applications in the real world, for example, in augmented reality, ancient culture preservation, 3D content generation, etc. Recently, rapid progress has been made in increasing the reconstruction quality using neural radiance fields (NeRF) [26]. While previous works mostly focused on synthesizing images at the object level or unbounded scenes within a small area,
Block-NeRF [34] extends NeRF to city-scale scenes by splitting data into multiple intersected blocks. Specifically,
Block-NeRF trains multiple NeRF models in the same coor-dinate frame with the ground-truth camera poses provided by fusing multiple high-precision sensors. However, images can be collected without absolute pose information in some cases, e.g., when images are captured with digital cameras or in GPS-denied areas. In such cases, Block-NeRF cannot work since NeRF models are trained on different coordi-nate frames. Consequently, NeRF registration [14] is neces-sary for synthesizing consistent novel views from multiple
NeRFs trained in different coordinate frames.
Point cloud registration is a classic problem in 3D com-puter vision, which aims at computing the relative transfor-mation from the source point cloud to the target point cloud.
However, NeRF registration is under-explored since exist-ing works focus mostly on point cloud registration. Unlike point clouds that are simple explicit representation, NeRF encodes scenes implicitly, which makes registering multi-ple NeRFs more challenging. NeRF2NeRF [14] is the first work that tried to solve registering NeRFs by a traditional optimization-based approach. However, it requires human-annotated keypoints for initialization, which limits its ap-plication in the real world where human annotations can be impractical. In view of the above-mentioned challenges, we focus on the study of the NeRF registration problem by an-swering the following two questions: 1) Can we register two or multiple NeRFs together where only pre-trained models are accessible? 2) How to register NeRFs without any hu-man annotations and initializations?
We further use the following settings in our endeavor to answer the two challenging questions on NeRF registra-tion: 1) Images are collected into different blocks and no images are associated with known absolute position infor-mation. 2) Multiple NeRF blocks are trained individually where ground truth camera poses in each block are in their local coordinate frames. 3) Only the trained NeRF mod-els are accessible, and all training images are removed and therefore not available due to plausible privacy-preserving issues or disk limitations. We emphasize that NeRF reg-istration is a challenging task, and we focus more on the object-centric scenes in this paper. See Fig. 1 for the illus-tration of our task setting and dataset construction.
To solve the NeRF registration problem, we first utilize an occupancy grid along with each NeRF model to extract a voxel grid. The voxel grid is then fed into a 3D Feature
Pyramid Network (FPN) [21] to extract features. The re-sulting voxel feature grids are further processed by a trans-former module. In the transformer network, we first adopt a self-attention layer to enhance the intra-feature represen-tations within each voxel feature grid. We further utilize a cross-attention layer to learn the inter-feature relations be-tween the source feature grid and the target feature grid.
Finally, we use an attention head to decode the source fea-tures and target features into correspondences and confi-dence scores. Unlike SOTA point clouds registration meth-ods [16, 42], we utilize NeRF as geometric supervision and thus do not rely on pre-computed overlapping scores to mask correspondences outside the overlapping areas.
The main contributions of our work are:
• A dataset for registering multiple NeRF blocks, which is created by rendering 1, 700+ 3D objects that are downloaded from the Objaverse dataset.
• A novel network for registering NeRF blocks which do not rely on any human annotation and initializations.
• Exhaustive experiments to show the accuracy and gen-eralization ability of our method.
To the best of our knowledge, this is the first work on reg-istering NeRFs without a) any initializations from key-points or other registration methods and b) precom-puted ground-truth overlapping labels. 2.