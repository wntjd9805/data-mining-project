Abstract
Retouching images is an essential aspect of enhancing the visual appeal of photos. Although users often share common aesthetic preferences, their retouching methods may vary based on their individual preferences. Therefore, there is a need for white-box approaches that produce sat-isfying results and enable users to conveniently edit their images simultaneously. Recent white-box retouching meth-ods rely on cascaded global filters that provide image-level filter arguments but cannot perform fine-grained retouch-In contrast, colorists typically employ a divide-and-ing. conquer approach, performing a series of region-specific fine-grained enhancements when using traditional tools like
Davinci Resolve. We draw on this insight to develop a white-box framework for photo retouching using parallel region-specific filters, called RSFNet. Our model generates filter arguments (e.g., saturation, contrast, hue) and atten-tion maps of regions for each filter simultaneously. Instead of cascading filters, RSFNet employs linear summations of filters, allowing for a more diverse range of filter classes that can be trained more easily. Our experiments demon-strate that RSFNet achieves state-of-the-art results, offer-ing satisfying aesthetic appeal and increased user conve-nience for editable white-box retouching. Code is available at https://github.com/Vicky0522/RSFNet. 1.

Introduction
Photos and videos recorded by the camera usually lack aesthetic quality due to poor shooting condition and inexpe-rienced photographer. Artists often use professional-grade softwares (e.g., PhotoShop for image, Davinci Resolve for video) to enhance image and video quality. However, it re-quires professional retouching skills to conduct a series of sophisticated manual adjustments. The use of fool-proof applications that present various style templates simplifies the retouching procedure, but it is unable to achieve opti-Figure 1: Architecture of our white-box retouching frame-work. Our model generates filter arguments (e.g., satura-tion, midtones, highlights) and attention maps of regions for corrsponding filter simultaneously. Final result is obtained by conducting linear summations on filtered results. mal results due to the lack of enhancement capability.
Recent learning-based methods have demonstrated the strong capability of deep neural nets for automatic photo retouching. Automatic systems are established to generate the optimal result end-to-end. However, one of the most significant considerations is that retouching is not a problem with an exclusive solution. People have different retouching preferences. Even the same artist may retouch the same im-age in different styles to meet various demands. In order to provide convenience for manual edits, automatic retouching systems must provide not only the suggested result, but also the retouching strategy in a way understandable by humans.
Taking these considerations into account, we propose a white-box framework that uses the divide-and-conquer strategy employed by artists in traditional retouching tools.
Our model generates attention maps of regions as well as filter arguments for traditional edits for these regions. This allows users to alter the suggested results to their prefer-ences.
The main contributions of this work are as follows:
• We redefine the retouching problem according to the
divide-and-conquer strategy, focusing on finding atten-tion maps for regions and human-understandable filter adjustments per map to achieve the best results.
• We propose RSFNet, which generates pixel-level at-tention maps of regions and filter arguments simulta-neously. By conducting linear summations on the fil-tered results, our model demonstrates superior perfor-mance to global white-box retouching methods, with a wider range of filter classes for fine-grained enhance-ment and a simpler training procedure.
• We propose a scheme that allows users to edit RSFNet suggested results, demonstrating its effectiveness and convenience in image applications. 2.