Abstract
We introduce LDL, a fast and robust algorithm that localizes a panorama to a 3D map using line segments.
LDL focuses on the sparse structural information of lines in the scene, which is robust to illumination changes and can potentially enable efficient computation. While pre-vious line-based localization approaches tend to sacrifice accuracy or computation time, our method effectively ob-serves the holistic distribution of lines within panoramic images and 3D maps. Specifically, LDL matches the dis-tribution of lines with 2D and 3D line distance functions, which are further decomposed along principal directions of lines to increase the expressiveness. The distance functions provide coarse pose estimates by comparing the distribu-tional information, where the poses are further optimized using conventional local feature matching. As our pipeline solely leverages line geometry and local features, it does not require costly additional training of line-specific features or correspondence matching. Nevertheless, our method demonstrates robust performance on challenging scenar-ios including object layout changes, illumination shifts, and large-scale scenes, while exhibiting fast pose search termi-nating within a matter of milliseconds. We thus expect our method to serve as a practical solution for line-based local-ization, and complement the well-established point-based paradigm. The code for LDL is available through the fol-lowing link: https://github.com/82magnolia/ panoramic-localization. 1.

Introduction
Estimating the location of a mobile device or agent with respect to a 3D map, widely referred to as visual localiza-tion, has vast applications in robotics and AR/VR. Com-pared to perspective images, which are more widely used for localization, panorama images provide a 360â—¦ field of view that contains ample visual evidence from the holistic scene context. In this light, there have been recent advances in visual localization using panoramic images [6, 7, 23, 24]
Figure 1. Overview of our approach. LDL assumes a 3D map equipped with lines and local features, and similarly preprocesses the 2D panorama prior to localization. LDL then selects candi-date poses by matching 2D, 3D line distance functions through decomposition along principal directions that effectively represent the sparse geometry of lines. Finally, the selected poses are refined via local feature matching [39] and PnP-RANSAC [13, 25].
that demonstrate reasonably stable localization, with state-of-the-art methods leveraging a two-step process of can-didate pose selection and refinement [24, 38]. Neverthe-less, many existing methods for this task have limitations in computational efficiency and robustness, mainly stem-ming from the costly or unstable pose selection process. As global feature descriptors [2, 20] or a large number of col-ored points [23, 24] are the main components for this step, the pipelines can be memory and compute intensive or frag-ile to large illumination changes [23, 24].
To overcome such limitations, we explore the alterna-tive direction of using lines as the major cue for panoramic localization. Lines have a number of desirable properties compared to commonly used raw color, semantic labels or learned global features [7, 23, 38]. First, due to the long-standing work in line segment extraction [16, 17, 50, 53], it is cheap and stable to extract line segments even amidst dramatic changes in illumination or moderate motion blur.
Second, lines are sparse representations of a scene and can potentially lead to small memory consumption and compu-tation. Nevertheless, line segments alone are visually am-biguous compared to other localization cues (color, global features, etc.), which makes them harder to tailor for suc-cessful localization. While there exist prior works in line-based visual localization [14, 29, 51], many focus on using lines for pose refinement after finding coarse poses from conventional global feature comparisons [14, 51] or ex-hibit unstable performance compared to conventional point-based methods [29]. Further, prior works often involve ex-pensive line-specific feature extraction to distinguish con-texts and establish one-to-one line correspondences [51].
LDL is a fast and robust localization method that lever-ages the holistic context from lines in panoramas and 3D
In contrast to maps to effectively find the camera pose. previous works [14, 51], we retain our focus on using line segments for pose search based on the observation that conventional point-based matching [10, 39] performs sta-bly once given a good initial pose. As shown in Figure 1, given a panoramic image of an unknown location, we uti-lize the distribution of extracted line segments and com-pare it against those in the pre-captured 3D map. First, the candidate pose selection step rapidly evaluates an immense set of poses within a matter of milliseconds and selects the coarse poses to further optimize. Here LDL compares the distribution of lines in 2D and 3D evaluated on their spher-ical projections using distance functions, as shown in Fig-ure 1. The distance function imbues relative spatial context even in featureless regions and quickly matches poses with-out establishing explicit correspondences between detected lines. We further enhance the discriminative power of dis-tance functions by decomposition, and separately evaluate lines aligned with each principal directions. Once a small set of initial poses are found, LDL refines them with PnP-RANSAC [13, 25], where we leverage powerful local fea-tures from recent works [10, 39] to establish good 2D-3D correspondences.
We evaluate LDL in various indoor scenes where it performs competitively against all tested baselines while demonstrating robust performance in scenes with object changes or large illumination shifts. Further, LDL exhibits an order-of-magnitude faster runtime compared to global feature comparison [2, 15, 20] due to the efficient formu-lation. By only using the geometric information of lines and pre-trained visual features, we expect LDL to serve as a practical localization algorithm that could enhance and complement existing visual localization techniques. 2.