Abstract
We present a simple and effective Multi-scale Residual
Low-Pass Filter Network (MRLPFNet) that jointly explores the image details and main structures for image deblurring.
Our work is motivated by an observation that the differ-ence between the blurry image and the clear one not only contains high-frequency contents1 but also includes low-frequency information due to the influence of blur, while us-ing the standard residual learning is less effective for mod-eling the main structure distorted by the blur. Considering that the low-frequency contents usually correspond to main global structures that are spatially variant, we first pro-pose a learnable low-pass filter based on a self-attention mechanism to adaptively explore the global contexts for better modeling the low-frequency information. Then we embed it into a Residual Low-Pass Filter (RLPF) module, which involves an additional fully convolutional neural net-work with the standard residual learning to model the high-frequency information. We formulate the RLPF module into an end-to-end trainable network based on an encoder and decoder architecture and develop a wavelet-based feature fusion to fuse the multi-scale features. Experimental results show that our method performs favorably against state-of-the-art ones on commonly-used benchmarks. 1.

Introduction
The camera shake and object motion are usually in-evitable when taking photos with hand-held devices, which lead to significant motion blur effects. Restoring clear pho-tos from blurry ones has attracted lots of attention from both research and industry communities [40]. However, motion deblurring is quite challenging as only the blurred images are available while the blur and latent images are unknown.
Significant progress has been made in image restoration due to the development of deep neural networks that di-rectly learn the mapping from the degraded observation to
*Corresponding author 1Note that the high-frequency contents in an image correspond to the image details, while the low-frequency ones denote the main structures of an image. the clear image. It is well known that the residual learning strategy [7] has been widely used to ease the training of net-works, where a latent clear image I can be restored by the summation of the degraded input B and the output N (B) of a residual learning network N . This strategy has been proven to be effective in lots of image restoration tasks, e.g., image super-resolution, as the degraded image B shares the same main structures as the clear one I, and the residual between B and I mainly contains image details.
However, we note that the difference between a blurry in-put and its corresponding clear one not only contains image details but also involves some structures. Taking Figure 1 as an example, the main structures in the clear image (e.g., the pillars enclosed in the red boxes of Figure 1(f)) disappear due to the influence of the motion blur effect. Thus, in ad-dition to the details smoothed by the blur, some main struc-tures also exist in the residual between the blurry image and the clear one (see the part enclosed in the red box of Figure 1(b)). As demonstrated in [22], the standard residual learn-ing method [7] is effective for modeling the high-frequency information but less effective to restore the low-frequency contents. Figure 1(c) also shows that using the standard residual learning method may not estimate the main struc-tures of the residual image well, which thus affects the final image restoration (Figure 1(h)). Therefore, it is important for image deblurring to effectively model the main struc-tures distorted by the motion blur.
To alleviate the above-mentioned problem, the recent methods [15, 34] introduce a frequency branch based on the Fast Fourier Transform (FFT) in the residual network, which achieves good performance. However, as such a fre-quency branch is achieved by applying Conv1 + ReLU +
Conv12 to the concatenation of the real and imaginary parts of the residual image, it may not effectively model the spatially-variant property of the global main structures in the residual image (Figure 1(d)), resulting in fake structures caused by the blur in the final deblurred image (Figure 1(i)).
In this paper, we propose a Multi-scale Residual Low-Pass Filter Network (MRLPFNet) for high-quality image deblurring. Our goal is to effectively model both the low-2Conv1 + ReLU + Conv1 denotes two 1 × 1 convolutional layers with the usual ReLU activation in between.
(a) Blurry input (b) Difference of (a) & (f) (c) Residual by [37] (d) Residual by [15] (e) Residual by MRLPFNet (f) Ground truth (g) Restormer [36] (h) MPRNet [37]
Figure 1. Visual comparison with state-of-the-art image deblurring methods on a challenging example. Our work is motivated by an observation that the difference between the blurry image and its corresponding clear one not only contains high-frequency contents but also includes low-frequency information due to the influence of the blur as shown in (b). We thus develop a simple yet effective MRLPFNet to learn both image details and spatially-variant structures (see (e)), which thus leads to better-deblurred results as shown in (j). (j) MRLPFNet (Ours) (i) DeepRFT [15] frequency and high-frequency parts of the residual image between the blurry input and its corresponding clear output within the residual learning framework. To better explore the low-frequency information, we propose to intuitively apply a low-pass filter on the residual image to concentrate on the low-frequency part. In addition, as the low-frequency contents in an image correspond to the global main struc-tures, one of whose properties is that they are usually spa-tially variant, we exploit a learnable low-pass filter module based on a self-attention mechanism (as a basic module) to adaptively explore the global contexts so that the main structures can be better restored for image deblurring. Then we incorporate it in the proposed Residual Low-Pass Filter (RLPF) module with an additional residual learning branch based on a fully convolutional neural network (CNN) for modeling the high-frequency information.
Furthermore, the multi-scale strategy is widely used in image deblurring. As features from various scales have different spatial resolutions, resizing operations are usually used to fuse these features. However, simply using resiz-ing operations based on downsampling or upsampling will lead to information loss. To this end, we develop a sim-ple yet effective feature fusion module based on the wavelet transform to fuse the features with different spatial resolu-tions. Finally, we embed the proposed RLPF module and the wavelet-based feature fusion (WFF) module into an end-to-end trainable network within a coarse-to-fine framework.
The proposed approach achieves favorable performance on widely-used benchmarks.
The main contributions are summarized as follows.
• We propose an effective RLPF module to model both the high-frequency and low-frequency information of the difference between the network input and output for image deblurring. Specifically, a learnable low-pass filter is developed based on a self-attention mech-anism to adaptively explore the spatially-variant prop-erty of the global contexts to effectively reconstruct the low-frequency structures and a fully CNN with the residual learning is adopted to model the high-frequency information.
• We develop a simple yet effective feature fusion mod-ule based on the wavelet transform to fuse the features of different scales for better image deblurring.
• By training the proposed MRLPFNet in an end-to-end manner, we show that it performs favorably against state-of-the-art methods. 2.