Abstract
Online continual learning (CL) studies the problem of learning continuously from a single-pass data stream while adapting to new data and mitigating catastrophic forget-ting. Recently, by storing a small subset of old data, replay-based methods have shown promising performance. Unlike previous methods that focus on sample storage or knowl-edge distillation against catastrophic forgetting, this paper aims to understand why the online learning models fail to generalize well from a new perspective of shortcut learn-ing. We identify shortcut learning as the key limiting fac-tor for online CL, where the learned features may be bi-ased, not generalizable to new tasks, and may have an ad-verse impact on knowledge distillation. To tackle this issue, we present the online prototype learning (OnPro) frame-work for online CL. First, we propose online prototype equilibrium to learn representative features against short-cut learning and discriminative features to avoid class con-fusion, ultimately achieving an equilibrium status that sep-arates all seen classes well while learning new classes. Sec-ond, with the feedback of online prototypes, we devise a novel adaptive prototypical feedback mechanism to sense the classes that are easily misclassified and then enhance their boundaries. Extensive experimental results on widely-used benchmark datasets demonstrate the superior perfor-mance of OnPro over the state-of-the-art baseline meth-ods. Source code is available at https://github. com/weilllllls/OnPro. 1.

Introduction
Current artificial intelligence systems [30, 36, 52, 16] have shown excellent performance on the tasks at hand; however, they are prone to forget previously learned knowl-*Corresponding author
Figure 1. The visual explanations by GradCAM++ on the training set of CIFAR-10 (image size 32 × 32). Although all methods pre-dict the correct class, shortcut learning still exists in ER and DVC. edge while learning new tasks, known as catastrophic for-getting [20, 23, 9]. Continual learning (CL) [46, 44, 14, 19] aims to learn continuously from a non-stationary data stream while adapting to new data and mitigating catas-trophic forgetting, offering a promising path to human-like artificial general intelligence. Early CL works consider the task-incremental learning (TIL) setting, where the model selects the task-specific component for classification with task identifiers [1, 41, 50, 14]. However, this setting lacks flexibility in real-world scenarios. In this paper, we focus on a more general and realistic setting—the class-incremental learning (CIL) in the online CL mode [42, 13, 27, 51]— where the model learns incrementally classes in a sequence of tasks from a single-pass data stream and cannot access task identifiers at inference.
Various online CL methods have been proposed to mit-igate catastrophic forgetting [51, 43, 25, 28, 11, 5, 13].
Among them, replay-based methods [11, 43, 26, 2, 25] have shown promising performance by storing a subset of data from old classes as exemplars for experience replay. Unlike previous methods that focus on sample storage [51, 3], we are interested in how generalizable the learned features are to new classes, and aim to understand why the online learn-ing models fail to generalize well from a new perspective of shortcut learning.
Intuitively, the neural network tends to “take short-cuts” [22] and focuses on simplistic features. This behavior of shortcut learning is especially serious in online CL, since the model may learn biased and inadequate features from the single-pass data stream. Specifically, the model may be more inclined to learn trivial solutions unrelated to objects, which are hard to generalize and easily forgotten. Take
Fig. 1 as an example, when classifying two classes, saying airplanes in the sky and cat on the grass, the model may eas-ily identify the shortcut clue between two classes—blue sky vs. green grass—unfortunately, the learned features are del-icate and unrelated to the classes of interest. When new bird and deer classes come, which may also have sky or grass, the model has to be updated due to inapplicable previous knowledge, leading to poor generalization and catastrophic forgetting. Thus, learning representative features that best characterize the class is crucial to resist shortcut learning and catastrophic forgetting, especially in online CL.
In addition, the intuitive manifestation of catastrophic forgetting is the confusion between classes. To alleviate class confusion, many works [26, 41, 48, 4, 7, 55] em-ploy self-distillation [17, 32] to preserve previous knowl-edge. However, the premise for knowledge distillation to succeed is that the model has learned sufficient discrimina-tive features in old classes, and these features still remain discriminative when learning new classes. As mentioned above, the model may learn oversimplified features due to shortcut learning, significantly compromising the general-ization to new classes. Thus, distilling these biased features may have an adverse impact on new classes. In contrast, we consider a more general paradigm to maintain discrimina-tion among all seen classes, which can tackle the limitations of knowledge distillation.
In this paper, we aim to learn representative features of each class and discriminative features between classes, both crucial to mitigate catastrophic forgetting. Toward this end, we present the Online Prototype learning (OnPro) frame-work for online continual learning. The online prototype introduced is defined as “a representative embedding for a group of instances in a mini-batch.” There are two reasons for this design: (1) for new classes, the data arrives sequen-tially from a single-pass stream, and we cannot access all samples of one class at any time step (iteration); and (2) for old classes, computing the prototypes of all samples in the memory bank at each time step is computationally ex-pensive, especially for the online scenario with limited re-sources. Thus, our online prototypes only utilize the data available at the current time step (i.e., data within a mini-batch), which is more suitable for online CL.
To resist shortcut learning in online CL and maintain discrimination among seen classes, we first propose On-line Prototype Equilibrium (OPE) to learn representative and discriminative features for achieving an equilibrium sta-tus that separates all seen classes well while learning new classes. Second, instead of employing knowledge distil-lation that may distill unfaithful knowledge from previous models, we devise a novel Adaptive Prototypical Feedback (APF) that can leverage the feedback of online prototypes to first sense the classes—that are easily misclassified—and then adaptively enhance their decision boundaries.
The contributions are summarized as follows. 1) We identify shortcut learning as the key limiting factor for online CL, where the learned features may be bi-ased, not generalizable to new tasks, and may have an adverse impact on knowledge distillation. To the best of our knowledge, this is the first time to identify the short-cut learning issues in online CL, offering new insights into why online learning models fail to generalize well. 2) We present the online prototype learning framework for online CL, in which the proposed online prototype equi-librium encourages learning representative and discrim-inative features while adaptive prototypical feedback leverages the feedback of online prototypes to sense eas-ily misclassified classes and enhance their boundaries. 3) Extensive experimental results on widely-used bench-mark datasets demonstrate the superior performance of our method over the state-of-the-art baseline methods. 2.