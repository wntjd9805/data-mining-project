Abstract
The accuracy of the visual tasks for top-view ﬁsheye cameras is limited by the Euclidean geometry for pose-distorted objects in images. In this paper, we demonstrate the analogy between the ﬁsheye model and the Poincar´e ball and that learning the shape of convolution kernels in the Poincar´e Ball can alleviate the spatial distortion prob-lem. In particular, we propose the Deformable Convolution based on the Poincar´e Ball, named DCPB, which conducts the Graph Convolutional Network (GCN) in the Poincar´e ball and calculates the geodesic distances to Poincar´e hy-perplanes as the offsets and modulation scalars of the modulated deformable convolution. Besides, we explore an appropriate network structure in the baseline with the
DCPB. The DCPB markedly improves the neural network’s performance. Experimental results on the public dataset
THEODORE show that DCPB obtains a higher accuracy, and its efﬁciency demonstrates the potential for using tem-poral information in ﬁsheye videos. 1.

Introduction
Visual tasks for top-view ﬁsheye cameras are challeng-ing but with valuable practical signiﬁcance in real-world scenarios [18, 45]. Due to their large ﬁeld of view, top-view
ﬁsheye cameras are the most cost-effective devices to cap-ture 360◦ content and cover a more comprehensive range of applications in visual surveillance [17]. A traditional per-*This work is supported by the National Natural Science Foundation of China under grant 62271143, the National Key R&D Program of China under Grant 2020YFB1600700, and the Big Data Center of Southeast Uni-versity. spective camera samples a ﬁeld of view of the 3D scene projected onto a 2D plane with relative positions in the real world [35].
In contrast, a top-view ﬁsheye camera cap-tures the entire view surrounding its optical center. Thus, top-view ﬁsheye cameras provide more spatial information than traditional perspective cameras. However, the geomet-ric transformations inherent in ﬁsheye cameras cause spa-tial distortion, leading to magnifying objects near the cen-ter of ﬁsheye images while the objects away from the cen-ter of ﬁsheye images shrink [41, 46]. The spatial distortion considerably increases the difﬁculty of accurate visual tasks for top-view ﬁsheye cameras, demanding the algorithms to be robust. Besides, the algorithms trained on perspective cameras usually perform poorly on top-view ﬁsheye cam-eras [49, 51]. To solve these problems, many researchers are committed to adapting Convolutional Neural Networks (CNNs) to the severe distortion of ﬁsheye images for the higher accuracy of visual tasks.
In object detection, [17, 24] proposed CNNs that pre-dict arbitrarily rotated bounding boxes in a ﬁsheye image to increase IoU. [10, 36] rotated each ﬁsheye image and ap-plied YOLO [31] only to the upper center part of the image, where people usually appear upright. These methods only deal with the input and output of CNNs and ignore that a convolution kernel may not be appropriate for the distorted object. Deformable convolution [14] is proposed for ad-dressing the issue that geometric variations due to scale, pose, viewpoint, and part deformation degrade the perfor-mance of CNNs in object recognition and detection. In de-formable convolution, the grid sampling locations of stan-dard convolution are each offset by displacements learned for the preceding feature maps. Deformable ConvNets v2 (DCNv2) [50] introduced modulated deformable convolu-Figure 1. (a) The projection model of the top-view ﬁsheye camera. (b) The projection model of hyperboloid on the Poincar´e disk. tion to strengthen the ability of the model to vary the spatial distribution. [43] proposes a deformable subnetwork that can generate 4-dimensional deformation coefﬁcients and perform part alignment to handle object deformation. [4] replaces the ﬁxed convolution layer and pooling layer in
Cascade-RCNN [6] with the deformable convolution layer and deformable pooling layer to conduct object detection in top-view ﬁsheye cameras. To eliminate 2D-to-Sphere in-trinsic sampling distortions of ﬁsheye images, [7] uses de-formable convolutions to extract omnidirectional features with non-deformable Receptive Fields. These methods build deformable kernel functions on the convolution lay-ers in the Euclidean space and ignore that top-view ﬁsheye images have similar geometric properties with hyperbolic space [1]. To solve the problem that the neural network in Euclidean space lacks the ability to express the features of ﬁsheye images, we try to ﬁnd an appropriate geometric model in hyperbolic space and learn the features in it.
The Poincar´e ball, an n-dimensional hyperbolic geomet-ric model, is a stereographic projection of the hyperbolic space. As its two-dimensional form, the Poincar´e disk can achieve a more accurate approximation of the projection model of the top-view ﬁsheye camera, as shown in Fig. 1.
The Poincar´e ball is a conformal mapping that preserves angles between distorted lines [1]. Thus, the geodesic in the Poincar´e disk corresponds to any arc perpendicular to the disk’s boundary or diameter. By considering the sur-face area of a hypersphere of increasing radius centered at a particular point, the Poincar´e ball and ﬁsheye images can be seen to grow exponentially. In addition, the objects near the center of ﬁsheye images are magniﬁed while the objects away from the center shrink, like the induced distance [40] in the Poincar´e ball. Therefore, we think learning the rele-vant features of ﬁsheye images in the Poincar´e ball is feasi-ble.
In this paper, to improve the ability of the convolution kernel to extract distorted features from top-view ﬁsheye images, we propose the Deformable Convolution in the
Poincar´e Ball (DCPB) for top-view ﬁsheye cameras. We embed the features of the ﬁsheye image in the Euclidean space into the Poincar´e ball and then obtain the offsets and modulation scalars of the modulated deformable convolu-tion through the Graph Convolution Network (GCN) in the hyperbolic space. To thoroughly verify the increased mod-eling capacity of the DCPB, we conduct experiments on im-age semantic segmentation with the synthetic segmentation dataset THEODORE [34]. Specially, we incorporate the
DCPB into the segmentation networks UNet [32], and we show that our method improves the performance of CNN semantic segmentation on synthetic distortions.
Our contributions can be summarized as follows:
• We propose the DCPB which is a novel convolution method to learn the shape of the kernel in the Poincar´e ball for top-view ﬁsheye cameras, enabling the CNNs adapted to the severe distortion for the higher accuracy of visual tasks.
• We propose the method to project the feature from the
Poincar´e ball back to the Euclidean space by calcu-lating the Geodesic distance from features to Poincar´e hyperplanes, which enhances the information learning of the CNNs between different spaces.
• We explore an appropriate network structure for the
DCPB in the segmentation networks UNet and ver-ify the effectiveness of the convolution methods on the synthetic top-view ﬁsheye segmentation dataset. 2.