Abstract
Spiking Neural Networks (SNNs) are promising energy-efficient models for neuromorphic computing. For training the non-differentiable SNN methods, the backpropagation through time (BPTT) with surrogate gradients (SG) method has achieved high performance. However, this method suf-fers from considerable memory cost and training time dur-ing training. In this paper, we propose the Spatial Learning
Through Time (SLTT) method that can achieve high per-formance while greatly improving training efficiency com-pared with BPTT. First, we show that the backpropagation of SNNs through the temporal domain contributes just a lit-tle to the final calculated gradients. Thus, we propose to ignore the unimportant routes in the computational graph during backpropagation. The proposed method reduces the number of scalar multiplications and achieves a small mem-ory occupation that is independent of the total time steps.
Furthermore, we propose a variant of SLTT, called SLTT-K, that allows backpropagation only at K time steps, then the required number of scalar multiplications is further re-duced and is independent of the total time steps. Exper-iments on both static and neuromorphic datasets demon-strate superior training efficiency and performance of our
SLTT. In particular, our method achieves state-of-the-art accuracy on ImageNet, while the memory cost and train-ing time are reduced by more than 70% and 50%, re-spectively, compared with BPTT. Our code is available at https://github.com/qymeng94/SLTT. 1.

Introduction
Regarded as the third generation of neural network mod-els [35], Spiking Neural Networks (SNNs) have recently
*Corresponding author.
Figure 1: The training time and memory cost comparison be-tween the proposed SLTT-1 method and the BPTT with SG method on ImageNet. SLTT-1 achieves similar accuracy as BPTT, while owning better training efficiency than BPTT both theoreti-cally and experimentally. Please refer to Secs. 4 and 5 for details. attracted wide attention. SNNs imitate the neurodynamics of power-efficient biological networks, where neurons com-municate through spike trains (i.e., time series of spikes). A spiking neuron integrates input spike trains into its mem-brane potential. After the membrane potential exceeds a threshold, the neuron fires a spike and resets its potential
[21]. The spiking neuron is active only when it experiences spikes, thus enabling event-based computation. This char-acteristic makes SNNs energy-efficient when implemented on neuromorphic chips [38, 11, 43]. As a comparison, the power consumption of deep Artificial Neural Networks (ANNs) is substantial.
The computation of SNNs with discrete simulation can share a similar functional form as recurrent neural networks (RNNs) [40]. The unique component of SNNs is the non-differentiable threshold-triggered spike generation function.
The non-differentiability, as a result, hinders the effective
adoption of gradient-based optimization methods that can train RNNs successfully. Therefore, SNN training is still a challenging task. Among the existing SNN training meth-ods, backpropagation through time (BPTT) with surrogate gradient (SG) [9, 49] has recently achieved high perfor-mance on complicated datasets in a small number of time steps (i.e., short length of spike trains). The BPTT with
SG method defines well-behaved surrogate gradients to ap-proximate the derivative of the spike generation function.
Thus the SNNs can be trained through the gradient-based
BPTT framework [52], just like RNNs. With such frame-work, gradients are backpropagated through both the layer-by-layer spatial domain and the temporal domain. Accord-ingly, BPTT with SG suffers from considerable memory cost and training time that are proportional to the network size and the number of time steps. The training cost is fur-ther remarkable for large-scale datasets, such as ImageNet.
In this paper, we develop the Spatial Learning Through
Time (SLTT) method that can achieve high performance while significantly reducing the training time and memory cost compared with the BPTT with SG method. We first de-compose the gradients calculated by BPTT into spatial and temporal components. With the decomposition, the tempo-ral dependency in error backpropagation is explicitly pre-sented. We then analyze the contribution of temporal in-formation to the final calculated gradients, and propose the
SLTT method to delete the unimportant routes in the com-putational graph for backpropagation. In this way, the num-ber of scalar multiplications is reduced; thus, the training time is reduced. SLTT further enables online training by calculating gradient instantaneously at each time step, with-out the requirement of storing information of other time steps. Then the memory occupation is independent of the number of total time steps, avoiding the significant train-ing memory costs of BPTT. Due to the instantaneous gra-dient calculation, we also propose the SLTT-K method that conducts backpropagation only at K time steps. SLTT-K can further reduce the time complexity without performance loss. With the proposed techniques, we can obtain high-performance SNNs with superior training efficiency. The wall-clock training time and memory costs of SLTT-1 and
BPTT on ImageNet under the same experimental settings are shown in Fig. 1. Formally, our contributions include: 1. Based on our analysis of error backpropagation in
SNNs, we propose the Spatial Learning Through Time (SLTT) method to achieve better time and memory efficiency than the commonly used BPTT with SG method. Compared with the BPTT with SG method, the number of scalar multiplications is reduced, and the training memory is constant with the number of time steps, rather than grows linearly with it. 2. Benefiting from our online training framework, we propose the SLTT-K method that further reduces the time complexity of SLTT. The required number of scalar multiplication operations is reduced from Ω(T )1 to Ω(K), where T is the number of total time steps, and K < T is the parameter indicating the number of time steps to conduct backpropagation. 3. Our models achieve competitive SNN performance with superior training efficiency on CIFAR-10,
ImageNet, DVS-Gesture, and DVS-CIFAR-100,
CIFAR10 under different network settings or large-scale network structures. On ImageNet, our method achieves state-of-the-art accuracy while the memory cost and training time are reduced by more than 70% and 50%, respectively, compared with BPTT. 2.