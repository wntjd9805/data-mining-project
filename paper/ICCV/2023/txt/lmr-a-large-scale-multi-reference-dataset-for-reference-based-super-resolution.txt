Abstract
It is widely agreed that reference-based super-resolution (RefSR) achieves superior results by referring to simi-lar high quality images, compared to single image super-resolution (SISR). Intuitively, the more references, the bet-ter performance. However, previous RefSR methods have all focused on single-reference image training, while mul-tiple reference images are often available in testing or practical applications. The root cause of such training-testing mismatch is the absence of publicly available multi-reference SR training datasets, which greatly hinders re-search efforts on multi-reference super-resolution. To this end, we construct a large-scale, multi-reference super-resolution dataset, named LMR. It contains 112,142 groups of 300×300 training images, which is 10× of the exist-ing largest RefSR dataset. The image size is also some times larger. More importantly, each group is equipped with 5 reference images with different similarity levels. Fur-thermore, we propose a new baseline method for multi-reference super-resolution: MRefSR, including a Multi-Reference Attention Module (MAM) for feature fusion of an arbitrary number of reference images, and a Spatial Aware
Filtering Module (SAFM) for the fused feature selection.
The proposed MRefSR achieves significant improvements over state-of-the-art approaches on both quantitative and qualitative evaluations. Our code and data are available at: https://github.com/wdmwhh/MRefSR. 1.

Introduction
Single image super-resolution (SISR) is to restore a degraded low-resolution (LR) image to a texture-realistic
*Work done during an internship at Baidu Inc.
Figure 1. Visual comparison of single-reference training RefSR method C 2-Matching [12] and our multi-reference training
MRefSR. Our MRefSR can more fully utilize arbitrary number of multiple reference images to achieve the best results. The full-resolution comparison is provided in supplementary material. high-resolution (HR) image [11]. SISR has a wide range of applications in surveillance [40], astronomy [8], medical imaging [7], film and television [24, 14], and other indus-tries [27, 38, 34]. With the development of deep learning,
SISR has made great progress over these years [4, 5, 16, 19, 13, 41, 32, 20, 3, 23]. Compared with SISR, reference-based super-resolution (RefSR) can leverage relevant tex-tures from additional similar HR reference images, so it often achieves better performance. Similar high-definition images can be acquired from web-searching, expertly cu-rated data repositories or websites, etc.
Because of promising results shown by recent RefSR methods [29, 37, 43, 42, 28, 30, 12, 21, 35], it attracts more and more research interest. However, all these previous
RefSR methods have focused on using a single reference
image for training, but there are often multiple reference images available for testing or practical applications. To the best of our knowledge, the only RefSR training dataset cur-rently available is CUFED5 [42, 33], which has only 11,871 image pairs with a small resolution of 160×160. More im-portantly, there is only one reference image for each LR in-put image. However, in practical applications, multiple ref-erence images are often encountered. For example, testing set of CUFED5 has 126 input images and each has 5 refer-ence images with different similarity levels. Similarly, we can also easily find multiple reference images for any real test case. Due to the limitation of the only available train-ing dataset, previous RefSR methods do not make good use of multiple reference images in testing or practical applica-tions. The previous RefSR methods usually stitch together several reference images to get a large resolution image as one reference image to fit the models trained with only one reference image. Nevertheless, if the resolution of the refer-ence images is too large, this way of testing will exhaust the
GPU memory. Furthermore, the relationship among multi-ple reference images is not modeled effectively. So this is certainly much worse than a method designed specifically for multiple reference images. Therefore, a multi-reference
RefSR training dataset and a simple but effective multi-reference RefSR method are needed.
In this paper, we propose a large-scale, multi-reference
RefSR dataset, named LMR. The training set of LMR con-sists of 112,142 groups of 300×300 training images, each group containing 5 reference images of different similar-ity levels. LMR training dataset has 10 times images more than CUFED5, and the image size is also some times larger.
Such a sufficiently large training dataset will be beneficial for improving the generalization ability of models. We be-lieve this training dataset will greatly facilitate the RefSR research as it is the first RefSR training dataset with mul-tiple reference images. Meanwhile, the testing set of LMR has 142 groups of images and each group with 2∼6 refer-ence images. The side length of the testing images ranges from 800 to 1600.
With the help of LMR, we propose a new RefSR base-line method for multiple reference RefSR, named MRefSR.
First, we develop a Multi-Reference Attention Module (MAM) for feature fusion from an arbitrary number of ref-erence images. We treat the LR input feature as query, and candidate keys and values are generated from the aligned reference features corresponding to different reference im-ages. Then, attention across different aligned reference features is conducted to fuse features from different refer-ence images. Second, since not all LR feature points can well match the reference features, we use Spatial Aware
Filtering Module (SAFM) for fused feature selection. As shown in Figure 1, our MRefSR effectively utilizes infor-mation from multiple reference images to produce visually pleasing details. In summary, our contributions are three-fold:
• We contribute the first multi-reference RefSR dataset, named LMR, which contains 112,142 groups of 300×300 training images and each group has 5 ref-erence images for the input image. This dataset will enable RefSR research from single-reference to multi-reference images and largely promote the development of the RefSR research field.
• We propose a novel multi-reference baseline RefSR method MRefSR, using a multi-reference attention module for feature fusion of an arbitrary number of reference images, and a spatial aware filtering module for the fused feature selection. Our method effectively learns the relationship among multiple references and makes the best use of them, this is also thanks to the multi-reference dataset LRM.
• We conduct extensive experiments which demonstrate the superiority of the proposed LMR and the poten-tial of multi-reference RefSR methods. Our method achieves significant improvements over state-of-the-art approaches on both quantitative and qualitative evalu-ations. 2.