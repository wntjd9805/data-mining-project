Abstract
Shape generation is the practice of producing 3D shapes as various representations for 3D content creation. Previ-ous studies on 3D shape generation have focused on shape quality and structure, without or less considering the impor-tance of semantic information. Consequently, such genera-tive models often fail to preserve the semantic consistency of shape structure or enable manipulation of the semantic attributes of shapes during generation.
In this paper, we proposed a novel semantic generative model named 3D Se-mantic Subspace Traverser that utilizes semantic attributes for category-specific 3D shape generation and editing. Our method utilizes implicit functions as the 3D shape represen-tation and combines a novel latent-space GAN with a lin-ear subspace model to discover semantic dimensions in the local latent space of 3D shapes. Each dimension of the sub-space corresponds to a particular semantic attribute, and we can edit the attributes of generated shapes by traversing the coefficients of those dimensions. Experimental results demonstrate that our method can produce plausible shapes with complex structures and enable the editing of semantic attributes. The code and trained models are available at https://github.com/TrepangCat/3D Semantic Subspace Tra verser 1.

Introduction
Building a generative model to synthesize 3D shapes is a predominant topic in computer graphics and 3D vision since it is widely used in applications such as 3D content creation/reconstruction [9, 20, 44, 42], autonomous driving
[3, 7, 16], AR/VR [21], and robotics [19, 57]. Typically, a 3D shape generative model takes a random vector as in-put and produces a 3D shape as output. To evaluate the ef-fectiveness of generative models, researchers consider three aspects: quality, diversity, and controllability. The ideal 3D shape generative model should produce visually realis-tic and diverse 3D shapes while also enabling local structure
Figure 1. Different Editing Paradigm. Since SP-GAN is a point cloud generative model, we present its results as point clouds. As illustrated, the first row shows a typical method using part-level interpolation for shape editing. The second row is an example of the optimization-based method for shape editing. The last row shows how we traverse the local linear subspace to produce edited shapes with reasonable semantic structures. manipulation to achieve controllability.
Previous 3D shape generative models like variational au-toencoder (VAE) [18, 37, 39, 65, 61], generative adversarial network (GAN) [60, 1, 38, 8, 29, 34, 69], flow-based mod-els [64, 35, 33], and diffusion models [48, 66, 48, 70] have been applied to various 3D representations, including point clouds [1], voxels [60], mesh [18] and so on. By adopting the rapidly developed implicit function-based shape repre-sentation [8, 4, 53], the generated shapes show promising quality and diversity [69]. However, the ability to control and manipulate the local structures of generated shapes dur-ing the generation process remains a challenging task. It is crucial to develop methods for effective shape control that allows for the modification of local structures during the generation process.
Previous methods that edit local shapes can be classi-fied into two groups: interpolation-based methods [58, 61, 38, 51, 26, 39, 43, 40] and optimization-based methods
[23, 12, 13, 46, 9, 20]. The interpolation-based ones uti-lize part-level interpolation to edit shapes. However, since it does not consider the semantic relation between shape parts, it produces inconsistent results (see in the first row of Fig. 1). The optimization-based methods take the editing inputs, which are sketches, point moving operations, and so on, to optimize shapes. But its results focus on matching the editing inputs while ignoring other shape parts (see in the second row of Fig. 1). In light of this, we propose a new paradigm that utilizes the learned semantic information in the subspace (see in the last row of Fig. 1). During the gen-eration process, we can edit shapes by traversing semantic dimensions in the subspace to produce diverse results. More details are illustrated as follows:
We present 3D Semantic Subspace Traverser, a novel se-mantic generative model for 3D shape generation and edit-ing by leveraging the proposed local linear subspace models and the latent-space GAN. We adopt deep implicit function as the 3D representation and apply our GAN to the latent shape space, which is produced by a VAE. The GAN gener-ates shape features in the form of a shape code grid, which can be decoded into 3D shapes by the VAE decoder. To empower our 3D generative model with shape editing capa-bility, we embed the local linear subspace models into the
GAN. Those local linear subspace models can discover se-mantic dimensions from feature maps in an unsupervised manner. By traversing along those semantic dimensions, our GAN can control the semantic attributes of the gener-ated shapes, as shown in Fig. 1. The proposed 3D Semantic
Subspace Traverser generates plausible 3D shapes and en-ables semantically editing of 3D shapes, as evidenced by quantitative and qualitative results.
To summarize, the contributions of this work are:
• We propose 3D Semantic Subspace Traverser, a novel semantic generative model that facilitates semantic shape editing for 3D shapes.
• We present a new latent-space GAN that leverages shape code grids to enable implicit-function-based 3D generation, producing 3D shapes with diverse topolog-ical structures.
• We introduce a 3D local linear subspace model to un-supervisedly and progressively mine interpretable and controllable dimensions from generator layers.
• Superior performance has been achieved in both 3D shape generation and editing. 2.