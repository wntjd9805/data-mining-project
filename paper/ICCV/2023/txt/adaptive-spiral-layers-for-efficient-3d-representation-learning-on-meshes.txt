Abstract
The success of deep learning models on structured data has generated significant interest in extending their applica-tion to non-Euclidean domains. In this work, we introduce a novel intrinsic operator suitable for representation learning on 3D meshes. Our operator is specifically tailored to adapt its behavior to the irregular structure of the underlying graph and effectively utilize its long-range dependencies, while at the same time ensuring computational efficiency and ease of optimization.
In particular, inspired by the framework of Spiral Convolution, which extracts and trans-forms the vertices in the 3D mesh following a local spiral ordering, we propose a general operator that dynamically adjusts the length of the spiral trajectory and the param-eters of the transformation for each processed vertex and mesh. Then, we use polyadic decomposition to factorize its dense weight tensor into a sequence of lighter linear layers that separately process features and vertices information, hence significantly reducing the computational complexity without introducing any stringent inductive biases. No-tably, we leverage dynamic gating to achieve spatial adap-tivity and induce global reasoning with constant time com-plexity benefitting from an efficient dynamic pooling mech-anism based on Summed-Area-tables. Used as a drop-in replacement on existing architectures for shape correspon-dence our operator significantly improves the performance-efficiency trade-off, and in 3D shape generation with mor-phable models achieves state-of-the-art performance with a three-fold reduction in the number of parameters required.
Project page: https://github.com/Fb2221/DFC 1.

Introduction
Convolutional layers have emerged as the de facto stan-dard methodology to effectively capture local similarity on a grid, hence leading to a notable paradigm shift in fields that analyze regular Euclidean data, such as object detec-Figure 1: Visual comparison of SpiralConvolution (left) and our operator (right). Our proposed operator adapts to the un-derlying structure of the mesh, learning vertex-adaptive and mesh-adaptive spiral sequences of variable lengths, ranging from 7 to 70.
In contrast, the base SpiralConvolution operator works on a fixed receptive field of length 9. The weight tensors of both operators are shown in the image using Einstein notation and a schematic representation. Our proposed operator approximates its dense weight tensor through CP decomposition for efficient im-plementation. The subscripts indicate respectively: k a fixed se-quence length, m a variable sequence length, c, d input and output channels, n and i the number of vertices and meshes considered. tion, image classification, speech recognition, and machine translation. Recently, advances in geometric deep learn-ing have sparked interest towards processing non-Euclidean data, however, applying classic neural networks to such kind of data (i.e., 3D mesh or point cloud) still presents sig-nificant challenges.
Early deep-learning methods address this issue in an extrin-sic manner, applying convolutions directly in the 3D Eu-clidean space [58, 46], but suffer from high computational complexity and a lack of smoothness in the data represen-tation. Conversely, more recent methods propose intrin-sic methods for non-Euclidean domains [6], and are ca-pable of achieving better results than their extrinsic coun-terparts. For instance, mesh-based methods, which are tailored the specific topological connectivity of the ver-tices, typically achieve better performance and lower run times [4, 18, 16, 8]. In contrast, Graph Neural Networks (GNNs) build a more general representation, but tend to reach suboptimal results because they only leverage the graph nature of the meshes [50, 37, 17, 12, 15]. More re-cently SpiralNet [4] and its extension SpiralNet++ [18] de-fine anisotropic mesh operators that are analogous to 2D convolutions on patches. This is achieved by enforcing a local spiral ordering of the vertices of the mesh, to robustly capture local information. Despite the impressive applica-tion of this operator on 3D meshes that share a fixed topol-ogy, its expressivity is still constrained by a shared, static, and local set of weights that remains unchanged after train-ing. Consequently, the processing of SpiralNet is indepen-dent of the data and task at hand, it is not influenced by the vertex on which it is applied, and it is confined to consider-ing only local regions.
In this work, we propose to build upon the SpiralNet frame-work by overcoming these limitations, while maintaining the original properties of topology awareness, efficiency, and ease of optimization. We introduce a novel operator for 3D meshes, specifically designed to leverage the irregular structure and long-range dependencies inherently present in the mesh. Guided by the use of Einstein notation, we con-struct a light-weight mesh-operator by factorizing a dense and general weight tensor via CP decomposition. The fac-torization is designed to separate the processing of feature and vertex dimensions. Specifically, vertices are processed by promoting two different inductive biases. First, we en-able global reasoning by capturing long-range interactions using a dynamic learnable pooling layer implemented as
Summed-Area-Tables (SAT) which is capable of efficiently adapting the receptive field depending on the input. Sec-ond, we enable robust local reasoning by capturing local in-formation using a gating operator to dynamically adapt the response of our layer to both the input vertex and mesh. The proposed operator focuses on the application of 3D meshes that share a fixed topology, but can be extended to remeshed variants and it is suitable for tasks such as reconstruction, shape correspondence, and data synthesis.
In line with other work designed for 3D meshes on fixed topology [4, 18, 16, 8], we evaluate our methodology on two well-established tasks: namely, 3D shape correspon-dence and mesh generation through 3D Morphable Mod-els. Our findings demonstrate superior performance on the 3D human shape benchmarks of COMA, FAUST, SCAPE,
DFAUST and SYNHAND, quantitatively illustrating best-in-class results. In comparison to SpiralConv, our approach achieves state-of-the-art performance while reducing the parameter count by 64% and 84% respectively demonstrat-ing the efficacy of adaptive processing in practical applica-tions. An overview of our operator and its closest competi-tor is presented in Figure 1. 2.