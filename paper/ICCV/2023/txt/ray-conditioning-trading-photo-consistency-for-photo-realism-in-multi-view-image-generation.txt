Abstract
Multi-view image generation attracts particular atten-tion these days due to its promising 3D-related applications, e.g., image viewpoint editing. Most existing methods fol-low a paradigm where a 3D representation is first synthe-sized, and then rendered into 2D images to ensure photo-consistency across viewpoints. However, such explicit bias for photo-consistency sacrifices photo-realism, causing ge-ometry artifacts and loss of fine-scale details when these methods are applied to edit real images. To address this issue, we propose ray conditioning, a geometry-free alter-native that relaxes the photo-consistency constraint. Our method generates multi-view images by conditioning a 2D
GAN on a light field prior. With explicit viewpoint control, state-of-the-art photo-realism and identity consistency, our method is particularly suited for the viewpoint editing task. 1.

Introduction
Modeling the distributions of natural images has long been an important problem that is extensively studied. Gen-erative adversarial networks (GANs) and diffusion mod-els are two types of generative models that have suc-cessfully shown impressive capabilities of learning image distributions—the generated samples are almost indistin-guishable from real photos [11, 33, 16, 34].
While optimizing for the photo-realism of individual samples, these generative models rarely allow for multi-view image generation, where photo-consistency matters.
Recently, many multi-view image synthesizers have been proposed that try to optimize for both photo-realism and photo-consistency [6, 41, 13, 26]. They generally follow a
“synthesize-3D-then-render” paradigm: 3D representations are synthesized, and then images are rendered (at speci-fied camera poses). Such 3D-aware generative models, es-pecially EG3D [6], achieve high-quality multi-view image generation results, despite being trained only on single-view
] 6
[
. d n o
C e s o
P
] 6
[
D 3
G
E
. d n o
C y a
R
Input
Inversion
Rotation
Figure 1. Challenges With Viewpoint Editing. Conditioning a 2D GAN’s latent space on pose does not ensure that an identity re-mains consistent across views. 3D-aware GANs such as EG3D [6] struggle to reconstruct high-frequency details such as wrinkles and hair. Our ray conditioning method most faithfully reproduces the input image, and preserves identity when editing the viewpoint. image data with poses.
However, photo-realism and photo-consistency are of-tentimes two competing goals: photo-realism very ex-plicitly favors image quality over control, while photo-consistency more implicitly favors control over quality. A few examples of this conflict include fine-scale detail and view-dependent appearance in the multi-view 3D recon-struction and 3D generation problems. Details are either fil-tered from 3D representations (leaving them smoother and more diffuse than real ones) or misinterpreted as geometric artifacts [39]. As shown in Figure 1, although EG3D allows explicit camera control and generates photo-consistent im-ages at different viewpoints, it fails to reproduce the subtle details, e.g., the wrinkles and hairs, in the input image. Con-ditioning a 2D GAN’s latent space on camera pose does not ensure that the identity remains consistent across views.
Our work is motivated by the observation that, for cer-Input
Novel Views
Photoshop Blending
Figure 2. Viewpoint Editing with Ray Conditioning. Ray conditioning enables photo-realistic multi-view image editing on natural photos via GAN inversion. The left half shows headshots of four individuals and their corresponding synthesized results from another viewpoint.
The right half shows a portrait of two individuals (top row), the GAN inversion results of their faces (top row corners), and the resulting image (bottom row), in which their faces are replaced with synthesized faces looking in a different direction (bottom row corners). To produce the latter, we used Photoshop to blend the synthesized faces with the original image. tain classes of images with shared canonical structure, e.g. faces, it is possible to achieve viewpoint control without op-timizing explicitly for 3D structure. The result is a mod-ified 2D GAN that offers precise control over generated viewpoints without sacrificing photo-realism. Furthermore, we are able to train on data that does not contain multi-ple viewpoints of any single subject, letting us leverage the same diverse and abundant data used for regular GANs. Our method combines the photo-realism of existing GANs with the control offered by geometric models, outperforming re-lated methods in both generation and inversion quality. This makes our method particularly well-suited for viewpoint editing in static images.
Key to our method is the proposed ray conditioning mechanism that enables explicit viewpoint control. The method is simple. Rather than using a 3D model, our method conditions each pixel in a generated image on the ray through it—a technique inspired by the light field
[24, 12]. The spatial priors of ray conditioning enables the image synthesizer to learn multi-view consistency from only single-view image collections and their estimated poses. By choosing a geometry-free approach, we relax the 3D photo-consistency constraints in exchange for in-creased photo-realism. Despite this, our approach still of-fers competitive identity preservation capability when edit-ing viewpoints. Figure 2 represents the quality and control we can achieve with ray conditioning. Evaluation on both single-view and multi-view data shows that our method is a significant improvement in image quality over Light
Field Networks (LFNs), another geometry-free image syn-thesizer [31], demonstrating the promising potential of this line of research.
In summary, our contributions are as follows. 1. We propose a simple yet effective geometry-free gen-erative model named ray conditioning for multi-view image generation, and show that it achieves greater photo-realism than geometry-based baselines while maintaining explicit control of viewpoints. 2. We demonstrate the advantages of our method in the downstream application of editing real images’ view-points where photo-realism is favored over photo-consistency. 3. Our ray conditioning method is also the first geometry-free multi-view image synthesizer that can generate highly realistic images in high resolution (1024×1024) given only single-view posed image collections. 2.