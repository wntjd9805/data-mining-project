Abstract
Rotated object detection aims to identify and locate ob-In this sce-jects in images with arbitrary orientation. nario, the oriented directions of objects vary consider-ably across different images, while multiple orientations of objects exist within an image. This intrinsic charac-teristic makes it challenging for standard backbone net-works to extract high-quality features of these arbitrar-ily orientated objects. In this paper, we present Adaptive
Rotated Convolution (ARC) module to handle the afore-In our ARC module, the convo-mentioned challenges. lution kernels rotate adaptively to extract object features with varying orientations in different images, and an effi-cient conditional computation mechanism is introduced to accommodate the large orientation variations of objects within an image. The two designs work seamlessly in ro-tated object detection problem. Moreover, ARC can con-veniently serve as a plug-and-play module in various vi-sion backbones to boost their representation ability to de-tect oriented objects accurately. Experiments on commonly used benchmarks (DOTA and HRSC2016) demonstrate that equipped with our proposed ARC module in the backbone network, the performance of multiple popular oriented ob-ject detectors is significantly improved (e.g. +3.03% mAP on Rotated RetinaNet and +4.16% on CFA). Combined with the highly competitive method Oriented R-CNN, the pro-posed approach achieves state-of-the-art performance on the DOTA dataset with 81.77% mAP. Code is available at https://github.com/LeapLabTHU/ARC. 1.

Introduction
Rotated object detection has become an emerging re-search topic in recent years [74, 89, 56]. Different from generic object detection, where object instances are as-sumed to be aligned with the image axes, objects in the natural scenes are prone to be placed with arbitrary orienta-*Equal Contribution. (cid:66) Corresponding author.
Figure 1. The motivation of our work. In the rotated object de-tection scenario, object instances with similar visual appearance are placed with arbitrary orientation (e.g., the cars). As a result, it is reasonable to rotate the convolution kernels according to the orientation of the objects in a data-dependent manner rather than processing the image samples with the same static kernel. tion. This phenomenon is commonly observed in the field of scene text detection [93, 41, 40], face detection [38, 84], and aerial image recognition[32, 49, 74], etc. In particular, in Embodied AI [11, 77, 50, 80, 13] tasks, as the agents need to explore and interact with the environment [4, 3, 42], the captured images may contain an object from arbitrary view-points [15, 59]. This poses great challenges for detection algorithms to accurately locate oriented objects.
Recently, considerable progress has been achieved in de-tecting rotated objects. For instance, various rotated object representations [79, 17, 44, 34, 91] and more suitable loss functions for these object representations [56, 6, 88, 90, 92] have been extensively analyzed. The mechanisms of the rotated region of interest extraction [9, 76] and label as-signment strategies [52, 53] have also been well explored.
Moreover, the structure of the detection networks, includ-ing the neck [89, 86, 87] and head [19, 33] of detectors, and rotated region proposal networks [76, 7] has been compre-hensively studied as well. However, little effort has been made in the design of a proper backbone feature extractor.
The quality of the features extracted by backbone net-works is crucial to many vision tasks. In particular, rotated object detection raises great challenges for backbone net-work design, since the orientation of objects varies across different images.
In the meanwhile, multiple orientations of objects also exist within an image. Despite the signifi-cant differences between the images with generic items and those with oriented objects, the design of conventional vi-sual backbones has mostly ignored the inherent characteris-tics. Therefore, the architecture of standard backbone mod-els may be sub-optimal in the rotated object detection task.
In this paper, we address the above challenges by propos-ing a simple yet effective Adaptively Rotated Convolu-tion (ARC) module. In this module, the convolution kernel adaptively rotates to adjust the parameter conditioned on each input (Fig. 1), where the rotation angle is predicted by a routing function in a data-dependent manner. Further-more, an efficient conditional computation technique is em-ployed, which endows the detector with more adaptability to handle objects with various orientations within an im-age. Specifically, multiple kernels are rotated individually and then combined together before being applied for convo-lution operations. This combine-and-compute procedure is equivalent to performing convolution with different kernels separately and then summing up the obtained results, yet the computation could be significantly reduced [22]. The two designs work seamlessly, effectively enlarging the param-eter space and elegantly endowing the network with more flexibility to detect objects in different orientations.
The proposed ARC module can conveniently serve as a plug-and-play module in convolution layers with arbitrary kernel size. As a result, any backbone network with convo-lution layers can enjoy the powerful representation ability of rotated objects by using the ARC module. For example, we can replace the convolution layers with the ARC mod-ule in the commonly used backbone network ResNet [31] to build the proposed backbone network ARC-ResNet.
We evaluate our method on two popular rotated object detection benchmarks (DOTA [74] and HRSC2016 [49]).
Extensive experiments validate that with the backbone net-work equipped with our proposed adaptive rotated convolu-tion (ARC) module, the performance of various popular ori-ented object detectors can be effectively enhanced on both datasets. When combined with a highly competitive method
Oriented R-CNN [76], our approach achieves state-of-the-art performance on the DOTA-v1.0 benchmark. 2.