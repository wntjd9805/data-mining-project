Abstract 1.

Introduction
Neural radiance fields (NeRF) achieve impressive per-formance in novel view synthesis when trained on only sin-gle sequence data. However, leveraging multiple sequences captured by different cameras at different times is essential for better reconstruction performance. Multi-sequence data takes two main challenges: appearance variation due to dif-ferent lighting conditions and non-static objects like pedes-trians. To address these issues, we propose NeRF-MS, a novel approach to training NeRF with multi-sequence data.
Specifically, we utilize a triplet loss to regularize the distri-bution of per-image appearance code, which leads to better high-frequency texture and consistent appearance, such as specular reflections. Then, we explicitly model non-static objects to reduce floaters. Extensive results demonstrate that NeRF-MS not only outperforms state-of-the-art view synthesis methods on outdoor and synthetic scenes, but also achieves 3D consistent rendering and robust appearance controlling. Project page: https://nerf-ms.github.io/.
* Work done during an internship at Huawei Noah’s Ark Lab.
† Co-corresponding Author.
Neural radiance field [20] demonstrates great success for novel view synthesis when given a photo collection. It works best when photos are from a single sequence, which means they are captured by the same camera at the same time. Multiple sequences are collections of photos captured by different cameras at different times as shown in Fig 1.
Using multiple sequences is important for creating a bet-ter 3D reconstruction of a scene. By combining images captured from different cameras and at different times, we can fill in the gaps and improve the quality of poorly recon-structed regions. Furthermore, we can use videos captured at different seasons or times to show the changes or varia-tions in the scene over time. Additionally, videos captured by different visitors and cameras at the same event can pro-vide different perspectives or angles of the scene.
Multi-sequence data raise challenges for existing meth-ods. The first is appearance variance. Sequences are cap-tured under different conditions, e.g. sensor, lighting, and weather. Assigning a per-image appearance code [19, 5, 33] can handle extreme appearance changes. However, this gives the model too big flexibility, so the learned appearance code will overfit image content and camera pose, which
results in 3D inconsistent rendering and loss of complex texture in novel views, see Fig. 3. Moreover, it leads to ghosting during interpolation between different appearance codes. The second is sequence transient. Previous meth-ods split a scene into static and transient parts [30]. For multi-sequence data, an object can be static in the whole sequence (parked vehicle, standing pedestrian) but absent from other sequences. This kind of object can not be suc-cessfully categorized as transient, leading to a floater in the scene as shown in Fig. 5.
We propose NeRF-MS, a novel method for building neu-ral radiance fields using multiple sequences. Firstly, to ad-dress the overfitting appearance code due to high flexibility, we introduce a triplet loss that assumes similarity between images within a sequence and diversity between sequences.
With the triplet loss that constrains the distribution of ap-pearance latent codes, our method can reduce ambiguity in the reconstruction process and improve texture and reflec-tion fidelity. Since building a better latent space, we can per-form more natural appearance interpolation across different sequences. Secondly, We propose a transient decomposi-tion module to separate transient objects from static scenes better. By explicitly modeling sequence and image tran-sients separately, we prevent overfitting to sequence tran-sients and improve geometric reconstruction quality.
Our experiments on real-world outdoor dataset [29] and synthetic dataset [20] demonstrate that our approach achieves state-of-the-art performance in multi-sequence scenes by reconstructing 3D consistent appearance and re-ducing ghosting artifacts. Moreover, by controllable exper-iments on the synthetic dataset, we show that our method is robust against various multi-sequence settings and outper-forms the baseline consistently.
In conclusion, our contribution can be summarized as follow:
• A novel framework enabling neural radiance fields to perform novel view synthesis with multi-sequence im-ages captured in the wild.
• A triplet loss to regularize appearance code for reduc-ing the ambiguity of appearance variation, allowing high-fidelity rendering and controllable appearance.
• A sequence transient decomposition module to sep-arate transient objects and static scenes for reducing floaters in novel view synthesis. 2.