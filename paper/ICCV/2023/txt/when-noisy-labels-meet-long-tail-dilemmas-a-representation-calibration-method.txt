Abstract
Real-world large-scale datasets are both noisily labeled and class-imbalanced. The issues seriously hurt the gener-alization of trained models. It is hence significant to address the simultaneous incorrect labeling and class-imbalance, i.e., the problem of learning with noisy labels on long-tailed data. Previous works develop several methods for the problem. However, they always rely on strong assumptions that are invalid or hard to be checked in practice. In this paper, to handle the problem and address the limitations of prior works, we propose a representation calibration method RCAL. Specifically, RCAL works with the represen-tations extracted by unsupervised contrastive learning. We assume that without incorrect labeling and class imbalance, the representations of instances in each class conform to a multivariate Gaussian distribution, which is much milder and easier to be checked. Based on the assumption, we re-cover underlying representation distributions from polluted ones resulting from mislabeled and class-imbalanced data.
Additional data points are then sampled from the recovered distributions to help generalization. Moreover, during clas-sifier training, representation learning takes advantage of representation robustness brought by contrastive learning, which further improves the classifier performance. We de-rive theoretical results to discuss the effectiveness of our representation calibration. Experiments on multiple bench-marks justify our claims and confirm the superiority of the proposed method. 1.

Introduction
Deep learning has made rapid progress in many fields [16], primarily driven by large-scale and high-quality annotated datasets [30, 5, 18, 71, 62, 35]. Unfortunately, it
*Equal contributions. This work was completed when the first two au-thors were interns guided by the last author.
†Correspondance to Weiran Huang (weiran.huang@outlook.com) and
Chun Yuan (yuanc@sz.tsinghua.edu.cn).
Figure 1: The illustration of the problem setup. The ob-served data exhibit a long-tailed distribution. The number of clean data and mislabeled data varies in each class. is hard to obtain such perfect datasets in practice, mainly from two aspects: (1) a part of data is wrongly labeled due to its intrinsic ambiguity and mistakes of annota-tors [44, 34, 66, 60, 37]; (2) data is class-imbalanced, where a long-tailed class distribution exhibits [55, 83, 24].
In real-world settings, both imperfect situations usually coex-ist (see Figure 1). For example, the WebVision dataset [36], a large-scale image dataset crawled from the web, contains about 20% mislabeled data. Meanwhile, the number of ex-amples in the most frequent class is over 20 times that of examples in the most scarce class [28].
Although many previous works have emerged to address the problems of learning with noisy labels and learning with long-tailed data separately, they cannot work well when the two imperfect situations exist simultaneously. Namely, they are weak for learning with noisy labels on long-tailed data.
Concretely, the methods specialized for learning with noisy labels always rely on some assumptions. Nevertheless, the assumptions are invalid due to the long-tailed issue. For
example, the popularly used memorization effect [18] for tackling noisy labels cannot be applied, since clean data be-longing to tail classes show similar training dynamics to those mislabeled data, e.g., similar training losses [5, 64].
Also, the noise transition matrix used for handling noisy la-bels cannot be estimated accurately. This results from that the relied anchor points of tail classes cannot be identified from noisy data, as the estimations of noisy class posterior probabilities for tail classes are not accurate. Moreover, the methods specialized for learning with long-tailed data mainly adopt re-sampling and re-weighting techniques to balance the classifier. The side-effect of mislabeled data is not taken into consideration, which results in the accumula-tion of label errors.
The weaknesses of the above specialized methods moti-vate us to develop more advanced methods for the realistic problem of learning with noisy labels on long-tailed data.
Existing methods targeting this problem can be divided into two main categories. The methods in the first category are to distinguish mislabeled data from the data of tail classes for follow-up procedures. However, the distinguishment is adversely affected by mislabeled data, since the information used for the distinguishment comes from deep networks that are trained on noisy long-tailed data. The methods in the second category are to reduce the side-effects of mislabeled data and long-tailed data in a unified way, which rely on strong assumptions. For example, partial data should have the same aleatoric uncertainty [5], which is hard to check in practice.
In this paper, we focus on this realistic problem: learn-ing with noisy labels on long-tailed data. To address the issues of prior works, we propose a representation calibra-tion method named RCAL. Generally, RCAL works on the level of deep representations, i.e., extracted features by deep networks for instances. Technically, we first employ unsu-pervised contrastive learning to achieve representations for all training instances. As the procedure of representation learning is not influenced by corrupted training labels, the achieved representations are naturally robust [81, 69, 15].
Afterward, based upon the achieved representations, two representation calibration strategies are performed: distri-butional and individual representation calibrations.
In more detail, the distributional representation calibra-tion aims to recover representation distributions before data corruption. Specifically, we assume that before training data are corrupted, the deep representations of instances in each class conform to a multivariate Gaussian distribution.
Compared to the previously mentioned assumptions, the as-sumption used in this paper is much milder. Its rationality is also justified by many works [70, 55, 75]. With a density-based outlier detector, robust estimations of multivariate
Gaussian distributions are obtained. Moreover, since the in-sufficient data of tail classes may cause biased distribution estimations, the statistics of distributions from head classes are employed to calibrate the estimations for tail classes.
After the distributional calibration for all classes, we sample multiple data points from the recovered distributions, which makes training data more balanced and helps generaliza-tion1. As for individual representation calibration, consider-ing that the representations obtained by contrastive learning are robust, we restrict that the subsequent learned represen-tations during training are close to them. The individual representation calibration implicitly reduces the hypothesis space of deep networks, which mitigates their overfitting of mislabeled and long-tailed data. Through the above pro-cedure of representation calibration, the learned represen-tations on noisy long-tailed data are calibrated towards un-contaminated representations. The robustness of deep net-works is thereby enhanced with such calibrated representa-tions, following better classification performance.
The contributions of this paper are listed as follows. (1)
We focus on learning with noisy labels on long-tailed data, which is a realistic but challenging problem. The weak-nesses of previous works are carefully discussed. (2) We propose an advanced method RCAL for learning with noisy labels on long-tailed data. Our method benefits from the representations by contrastive learning, where two types of representation calibration strategies are proposed to im-(3) We derive theoretical re-prove network robustness. sults to confirm the effectiveness of our calibration strate-gies under some conditions. (4) We conduct extensive ex-periments on both simulated and real-world datasets. The results demonstrate our representation calibration method’s superiority over existing state-of-the-art methods. In addi-tion, detailed ablation studies and discussions are provided. 2.