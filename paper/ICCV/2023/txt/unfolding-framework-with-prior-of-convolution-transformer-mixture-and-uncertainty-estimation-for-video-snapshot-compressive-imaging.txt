Abstract
Truth
PnP
BIRNAT
DUN-3DUnet
Ours
Truth
We consider the problem of video snapshot compres-sive imaging (SCI), where sequential high-speed frames are modulated by different masks and captured by a sin-gle measurement. The underlying principle of reconstruct-ing multi-frame images from only one single measurement is to solve an ill-posed problem. By combining optimiza-tion algorithms and neural networks, deep unfolding net-works (DUNs) score tremendous achievements in solving inverse problems. In this paper, our proposed model is un-der the DUN framework and we propose a 3D Convolution-Transformer Mixture (CTM) module with a 3D efﬁcient and scalable attention model plugged in, which helps fully learn the correlation between temporal and spatial dimensions by virtue of Transformer. To our best knowledge, this is the
ﬁrst time that Transformer is employed to video SCI recon-struction. Besides, to further investigate the high-frequency information during the reconstruction process which are neglected in previous studies, we introduce variance esti-mation characterizing the uncertainty on a pixel-by-pixel basis. Extensive experimental results demonstrate that our proposed method achieves state-of-the-art (SOTA) (with a 1.2dB gain in PSNR over previous SOTA algorithm) re-sults. Code can be found on https://github.com/ zsm1211/CTM-SCI. 1.

Introduction
Nowadays, due to the ability of capturing high-dimensional data in an efﬁcient way, Snapshot Compres-Figure 1. Illustration of comparison between the reconstruction re-sults in the high-frequency details of previous SOTA algorithms and Ours. We present the details both in image domain (ﬁrst line) and frequency domain (second line). To be more visually clearly, we also present the intensity proﬁles extracted from the cross-section yellow lines in the ﬁrst example. Our proposed algorithm can reconstruct better high-frequency details. sive Imaging (SCI) [32, 59] has attracted much attention.
SCI system just employs a low-speed 2D camera to capture 3D sequential video frames, hyperspectral data, etc. [66, 3], where a digital micro-mirror device [17, 39] or a shifting mask [61] is utilized to modulate consequent frames. With
(cid:1872)(cid:3021) (cid:1872)(cid:2869)
…
…
…………………………………………………… k
Masks
Measurement n o i t a z i l a i t i n
I
…(cid:1872)(cid:2869)
………… (cid:1872)(cid:3021) or
Normalized
Frame (NF)
Reference
Frames (RF)
All CNN-based
Only with Low-Frequency Information
Hard to Capture 
Global Feature
High-Frequency 
Feature Map
RF
Transformer
&CNN-based 
Network
Uncertainty 
Estimation
……(cid:1872)(cid:2869)…(cid:1872)(cid:3021)
Uncertainty Map
Previous
Learning-based
Frameworks
……(cid:1872)(cid:2869)… (cid:1872)(cid:3021)
Our 
Framework
……(cid:1872)(cid:2869)… (cid:1872)(cid:3021)
Figure 2. Illustration of the design motivation. the knowledge of modulation, the captured single 2D mea-surement can be reconstructed to original sequential frames by algorithms [19, 50, 26, 51, 65, 62, 56]. In this paper, we focus on the reconstruction problem of video SCI systems.
To be concrete, the reconstruction process can be regard as solving an ill-posed inverse problem where the num-ber of pixels to be reconstructed is much higher than the number of known parameters. With the development of deep learning, deep neural networks has been employed to conduct the reconstruction in recent years, where con-volutional neural networks (CNN) are dominating. Com-pared to optimization-based algorithms, learning-based al-gorithms can directly map the measurement and the target images which makes it easier and faster to bring reconstruc-tion results up to the mark. To improve learning-based algo-rithms’ defect of lacking interpretability, recently proposed deep unfolding networks (DUNs) [50, 26, 51] combine the merits of both optimization-based and learning-based algo-rithms, and achieve the best results so far.
Motivation: As shown in Fig. 1, previous SOTA learning-based algorithms ideal for high-frequency detail reconstruction. In their initialization (de-tails in Fig. 3), as shown in the top-middle of Fig. 2, the
NF and RF both have a relatively clean background and clear stationary areas, which can directly feed the low-frequency information to the following network. However, the high-frequency features such as edges and textures can not be directly obtained from the measurement and are neglected by previous studies for video SCI. For the network structure, convolution-based backbone architec-tures have long dominated visual modeling in computer vi-sion [25, 40, 18, 16]. It is the same in the video SCI tasks, all previous SOTA learning-based algorithms are CNN-based.
Although CNN has many advantages, its receptive ﬁeld is usually small and relies on deeper layers or larger convolu-tion kernels, which is not conducive to capture global fea-tures such as contour features and texture features which are also the high-frequency features. By contrast, Trans-former can well capture long-distance dependencies and
[50, 5, 60] are not global inter-dependence between different regions, yet few researches of applying Transformer to video SCI are carried out.
To sum up, previous learning-based frameworks mainly suffer from following two problems: 1) High-frequency in-formation is not taken into consideration. 2) Compared to
Transformer, CNNs are weak in capturing global features, some of which are also high-frequency features like contour features and texture features. Due to the mutual inﬂuence of these two aspects in the reconstruction process, the ﬁdelity of the high-frequency details is compromised.
Contributions: Towards this end, hereby, we propose a
Transformer enabled deep unfolding framework for video
SCI and we further introduce uncertainty estimation to take high-frequency information as regularized prior under the unfolding framework into consideration for better recon-struction. Our contributions can be summarized as follows: 1) We propose a novel video Convolution-Transformer module, dubbed CTM, for video SCI that can well capture local and global spatial-temporal interactions which is composed of 3D CNN, 3D scalable blocked dense and dilated sparse attention. Note that the at-tention modules take both local and global information into consideration with only a linear complexity. 2) Unlike previous studies that only consider the low-frequency information such as the information of sta-tionary areas or backgrounds [5, 50, 4], we ﬁrst bring high-frequency information as regularized prior under the unfolding framework in video SCI for focusing on areas with high reconstruction uncer-tainty and improving the ﬁdelity of reconstruction, which is achieved by the variance estimation charac-terizing the uncertainty on a pixel-by-pixel basis. 3) We ﬁrst introduce Transformer for video SCI re-construction. Both real and simulation experiments demonstrate that our proposed framework outper-form previous SOTA algorithms with a large mar-gin of PSNR over 1.2dB. 2.