Abstract https://github.com/skhu101/SHERF.
Existing Human NeRF methods for reconstructing 3D hu-mans typically rely on multiple 2D images from multi-view cameras or monocular videos captured from fixed camera views. However, in real-world scenarios, human images are often captured from random camera angles, presenting challenges for high-quality 3D human reconstruction. In this paper, we propose SHERF, the first generalizable Hu-man NeRF model for recovering animatable 3D humans from a single input image. SHERF extracts and encodes 3D human representations in canonical space, enabling render-ing and animation from free views and poses. To achieve high-fidelity novel view and pose synthesis, the encoded 3D human representations should capture both global ap-pearance and local fine-grained textures. To this end, we propose a bank of 3D-aware hierarchical features, including global, point-level, and pixel-aligned features, to facilitate informative encoding.Global features enhance the informa-tion extracted from the single input image and complement the information missing from the partial 2D observation.
Point-level features provide strong clues of 3D human struc-ture, while pixel-aligned features preserve more fine-grained details. To effectively integrate the 3D-aware hierarchical feature bank, we design a feature fusion transformer. Exten-sive experiments on THuman, RenderPeople, ZJU_MoCap, and HuMMan datasets demonstrate that SHERF achieves state-of-the-art performance, with better generalizability for novel view and pose synthesis. Our code is available at
*Equal contribution 1.

Introduction
Human NeRFs aim to recover high-quality 3D humans from 2D observations, avoiding the need to capture ground truth 3D geometry information [58, 13, 57, 78, 54, 75, 68, 30, 31, 73, 39, 23, 15, 84]. The development of Human
NeRFs addresses a long-standing scientific request and has the potential to enable real-world applications e.g. VR/AR.
By leveraging Human NeRF, we can reconstruct 3D humans directly from 2D observations, saving time and effort to collect ground truth 3D information.
Existing Human NeRF methods can be classified into two categories. The first category focuses on reconstructing 3D humans from monocular or multi-view videos [58, 13, 57, 78, 54, 75, 68, 30, 31, 73]. These methods optimize subject-specific Human NeRF, which are time-consuming and not suitable for the rapid applications of Human NeRF. To ad-dress the slow optimization process, the second category of
Human NeRF methods [39, 23, 15, 84] propose to learn gen-eralizable Human NeRF models. These methods can recon-struct Human NeRF from a few multi-view human images in a single forward pass, which largely speeds-up the process.
Although these methods can achieve acceptable performance in 3D human reconstruction, they require multi-view images under well-defined camera angles, limiting their applicabil-ity in real-world scenarios where only a single image with a random angle is available. MonoNHR [15] addresses this gap by exploring novel view synthesis from a single image.
But it cannot animate the reconstructed Human NeRF with novel poses, still limiting its applicability.
Recovering animatable 3D humans from a single human image with generalizable Human NeRF is a challenging problem due to two main challenges. The first challenge is the missing information from the partial observation. Exist-ing generalizable Human NeRF [39, 23] focus too much on local feature preservation, while struggle to complement the missing information. The second challenge is reconstructing animatable 3D humans from a single human image. To make animatable Human NeRF from partial observations, it is necessary to complete missing appearance while also en-suring coherent understanding of 3D human structure. This poses additional challenges beyond the task of simply com-pleting missing information.
In this work, we propose SHERF, the first generalizable
Human NeRF based on single image inputs. We propose a hierarchical feature bank to address the challenge of infor-mation missing from the single image input. This feature bank includes global, point-level, and pixel-aligned features, which enable informative 3D human representations encod-ing. The hierarchical feature bank captures both the global human structure and local fine details, which are essential for high-fidelity human NeRF reconstruction. In addition, we introduce a feature fusion transformer to effectively merge features in the hierarchical feature bank. As illustrated in
Fig. 1, our method can reconstruct correct colors for visible areas and provide plausible guesses for non-observable ar-eas. The former is attributed to the fine-grained 3D-aware features that are crucial for reconstructing accurate geometry and color details, while the latter is enabled by the global features that allow color inference of invisible parts. The combination of these abilities leads to our methodâ€™s capabil-ity of generating high-quality novel views and poses.
To address the challenge of animatability, SHERF models the 3D human representation in canonical space, making it amenable to pose transformation and rendering. We use the
SMPL prior [46] to transform hierarchical features extracted from the input image to the canonical space, where they are encoded to better complete missing information and acquire the human structure information.
We evaluate SHERF on several datasets including THu-man [82], RenderPeople [1], ZJU_MoCap [59] and HuM-Man [9]. Our results show that SHERF outperforms previous state-of-the-art generalizable Human NeRF methods in both novel view and novel pose synthesis with single images as inputs. We also conduct a detailed analysis on the effects of varying input camera views, which provides further insights into SHERF. Our main contributions are as follows: 1) To the best of our knowledge, SHERF is the first generaliz-able Human NeRF model to recover animatable 3D humans from a single human image. It pushes the boundaries of
Human NeRF to a more general setting and bridges the gap of applying Human NeRF in real-world scenarios. 2) With 3D-aware hierarchical features, SHERF learns both fine-grained and global features to recover texture details and complement information missing from partial observations. 3) SHERF achieves state-of-the-art performance compared with previous generalizable Human NeRF methods [39, 23] in both novel view and novel pose synthesis on four large-scale datasets. 2.