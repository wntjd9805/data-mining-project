Abstract
Most research on facial expression recognition (FER) is conducted in highly controlled environments, but its perfor-mance is often unacceptable when applied to real-world sit-uations. This is because when unexpected objects occlude the face, the FER network faces difficulties extracting fa-cial features and accurately predicting facial expressions.
Therefore, occluded FER (OFER) is a challenging problem.
Previous studies on occlusion-aware FER have typically re-quired fully annotated facial images for training. However, collecting facial images with various occlusions and expres-sion annotations is time-consuming and expensive. Latent-OFER, the proposed method, can detect occlusions, restore occluded parts of the face as if they were unoccluded, and recognize them, improving FER accuracy. This approach involves three steps: First, the vision transformer (ViT)-based occlusion patch detector masks the occluded position by training only latent vectors from the unoccluded patches using the support vector data description algorithm. Sec-ond, the hybrid reconstruction network generates the mask-ing position as a complete image using the ViT and convolu-tional neural network (CNN). Last, the expression-relevant latent vector extractor retrieves and uses expression-related information from all latent vectors by applying a CNN-based class activation map. This mechanism has a sig-nificant advantage in preventing performance degradation from occlusion by unseen objects. The experimental results on several databases demonstrate the superiority of the pro-posed method over state-of-the-art methods. This code is available at https://github.com/leeisack/Latent-OFER. 1.

Introduction
Facial expression recognition (FER) has undergone re-markable advancements in recent years and is now widely used across various industries. However, the ability of FER models in the presence of occlusion remains a challenge.
*Corresponding author
Figure 1. Facial expression recognition (FER) performance on
RAF-DB according to the occluded proportions.
Figure 1 illustrates the accuracy of the previous state-of-the-art model for FER [58] for various occlusion proportions. In this study, we evaluated the robustness of the typical model in recognizing facial expressions using two types of occlu-sions: random sampling occlusion and grad occlusion. Ran-dom sampling occlusion divides the entire image into 196 patches and randomly masks them according to the propor-tion. Grad occlusion processes an image with an intention-ally occluded area that affects FER using gradient-weighted class activation mapping (Grad-CAM) [46]. This study re-veals a more substantial decrease in performance with the second type of occlusion, particularly when the occluded area is crucial for accurate FER. This finding has been ob-jectively measured using Grad-CAM [46].
Previous studies on FER [1, 2, 3, 5, 7, 13, 14, 15, 21, 23, 29, 31, 38, 43, 44, 49, 50, 54, 57, 60, 62, 63, 68, 69, 70] have not given adequate attention to the influence of occlusions.
However, addressing this challenge is crucial for enhancing the practical applications of FER in real-world scenarios.
Although research on occluded FER (OFER) is relatively scarce, its importance is increasingly recognized [66].
Currently, several approaches address OFER. The occlusion-robust feature extraction approach [9, 53] aims to identify an occlusion-insensitive and discriminative rep-resentation, but it is challenging because the types and loca-tions of occlusion are often unknown. The sub region anal-ysis approach [26, 55] divides regions based on facial land-marks and uses attention mechanisms to focus on crucial areas. However, the inability to detect facial landmarks due to occlusions can lead to errors in the FER process. The un-occluded image network assist approach [35, 61] uses two distinct networks: one trained on unoccluded images and the other trained on occluded images. This approach lever-ages unoccluded images as privileged information to assist in expression recognition in the presence of occlusion. It is unsuitable in real-world situations because it cannot differ-entiate between occluded and unoccluded images.
Hence, the proposed approach is the occlusion recovery-based approach, which aims to transform occluded images into complete images through a deocclusion process. We propose the deocclusive autoencoder for reconstructing fa-cial images. The deocclusive autoencoder can be function-ally divided into an occlusion detector and reconstruction module. The occlusion detector uses the vision transformer (ViT) support vector data description (SVDD) for the re-construction module. This approach enables the model to detect occlusion caused by unseen objects, an essential step in accurately generating deoccluded facial images. The re-construction network consists of the ViT structure and con-volutional neural network (CNN) structure for facial im-age reconstruction. We leverage the strengths of the ViT in generating realistic facial images despite varying poses and further refine them using the CNN. We call it the hy-brid reconstruction network. The hybrid reconstruction net-work enhances FER performance by generating deoccluded images that express detailed and vivid facial expression at-tributes. This enhancement is achieved by incorporating a self-assembly layer and semantic consistency loss. In con-trast, previous work on image reconstruction has primarily focused on achieving naturalness, which can result in dull facial expressions. Additionally, we use informative ViT-latent vectors obtained from the reconstruction process. We combine the CNN features and ViT-latent vectors for en-hanced facial expression predictions. The main contribu-tions in this work are summarized as follows:
• We propose an expression-relevant feature extractor that uses spatial attention to assign a higher weight to spe-cific facial features, allowing us to identify critical positions for FER. We can retrieve expression-relevant latent vectors from the ViT-latent space to extract valuable information using these positions as critical values.
•We propose ViT-SVDD, a patch-based occlusion detec-tion module optimized for ViT-based networks. As a self-supervised local classifier, the ViT-SVDD module is trained only on latent vectors of unoccluded facial images. This method accurately classifies occlusions caused by unseen objects for subsequent reconstruction.
• We propose a hybrid reconstruction network that com-bines the strengths of the ViT and CNN architectures with a self-assembly layer and semantic consistency loss to gen-erate facial images naturalness and rich in expression. This approach enhances the quality of deoccluded images and improves the accuracy of FER in challenging conditions. 2.