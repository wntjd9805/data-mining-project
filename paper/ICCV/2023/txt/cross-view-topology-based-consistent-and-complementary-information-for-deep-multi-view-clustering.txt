Abstract
Multi-view clustering aims to extract valuable informa-tion from different sources or perspectives. Over the years, the deep neural network has demonstrated its superior rep-resentation learning capability in multi-view clustering and achieved impressive performance. However, most existing deep clustering approaches are dedicated to merging and exploring the consistent latent representation across mul-tiple views while overlooking the abundant complementary information in each view. Furthermore, finding correlations between multiple views in an unsupervised setting is a sig-nificant challenge. To tackle these issues, we present a novel
Cross-view Topology based Consistent and Complementary information extraction framework, termed CTCC. In detail, deep embedding can be obtained from the bipartite graph learning module for each view individually. CTCC then constructs the cross-view topological graph based on the
OT distance between the bipartite graph of each view. Uti-lizing the above graph, we maximize the mutual information across views to learn consistent information and enhance the complementarity of each view by selectively isolating distributions from each other. Extensive experiments on five challenging datasets verify that CTCC outperforms existing methods significantly. 1.

Introduction
With the proliferation and diversity of unlabeled data, multi-view clustering[26, 21, 13, 44, 7] has become an in-creasingly popular unsupervised paradigm.
Its goal is to group data with similar features together by leveraging in-formation from multiple views. Conventional multi-view clustering[41, 19, 42, 31, 55] methods commonly rely on shared information after multi-view fusion for clustering.
Due to the limited ability of shallow methods to extract high-level information from data, their clustering perfor-*Corresponding author
Figure 1: W represents the topology graph between views.
We selectively combine consistent and complementary in-formation between views using a cross-view topology graph
W. Specifically, we utilize the mutual information maxi-mization module to obtain consistent information between different views. To selectively further the views incorpo-rating view-specific information, we use the view topology graph to identify views with rich view-specific information.
We pull them apart from other views to allow Z to obtain more complementary information. mance is highly contingent upon the quality of the raw data.
With the rapid development of deep learning[6, 25, 22], deep multi-view clustering(DMVC) approaches[49, 8, 15, 29, 10, 12] employ the powerful learning ability of neu-ral networks to learn a high-level common representation from multiple views that is beneficial for clustering, thus overcoming the drawback of traditional methods. As a re-sult, DMVC has made remarkable progress and attracted widespread attention in real-world applications.
Existing DMVC methods can be categorized into three types: graph-based methods[4, 45, 52, 20], subspace-based methods[37, 39, 53], and reconstruction-based methods[26, 51, 3, 40, 46]. These methods often utilize autoencoders or convolutional neural networks to learn the structural infor-mation by exploring the common representation or struc-ture in the latent space[49, 8, 15]. Their fundamental con-cepts revolve around fusing different views to uncover the common representation and achieve improved clustering ef-fects. However, in real-world scenarios, multi-view data is collected in diverse ways, and each view contains a sub-stantial amount of view-specific information. Solely focus-ing on the consistent information between multiple views can lead to significant information loss. Effectively utilizing the view-specific information in each view poses a pressing challenge. [50] has achieved remarkable results by decou-pling the view-common information from the view-specific information. However, it overlooks the affinity between views, treating each view equally. In real multi-view data, different views contribute differently to the clustering task.
Not all information within a view is equally essential. The correlation between pairwise views plays a crucial role in learning clustering-friendly representations, especially un-der unsupervised conditions. Thus, striking a balance be-tween consistent and complementary information from dif-ferent views is a challenging problem.
To tackle these challenges, we propose a novel multi-view deep clustering framework that leverages consistency and complementarity information, as well as cross-view topology. We establish a topological graph between views using bipartite graphs and balance the consistent and com-plementary information based on this graph. As illustrated in Fig. 1, we introduce the cross-view topology graph W into the framework to selectively learn consistent and com-plementary information. Specifically, to learn consistent representations across views, we maximize the mutual in-formation between views and also between views and con-sistent representations. Since different views contribute dif-ferently to consistent representations, we generate weights based on cross-view topological graphs to constrain the mu-tual information between different views. Furthermore, to utilize view-specific information, we split the views into two sets via the topological graph and use the OT distance between views to pull the two sets farther in the latent space, thereby retaining more view-specific information. In gen-eral, we integrate consistent and complementary informa-tion in the same framework through the topological graph.
We define the relationship between views according to the topological graph to obtain better clustering performance.
The contributions and novelties are summarized as fol-lows:
• In the paradigm of unsupervised learning, we propose a multi-view deep clustering framework based on bi-partite graphs. We employ OT distance to define the topological graph between views and selectively inte-grate the information from multiple views into a deep neural network framework. views and balance the consistent and complementary information from multiple views, thereby improving the clustering performance.
• Sufficient experiments demonstrate the effectiveness of selectively unifying consistent and complementary information of multi-view data into a deep clustering framework. 2.