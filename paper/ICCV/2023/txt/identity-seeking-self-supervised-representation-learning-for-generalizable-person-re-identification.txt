Abstract
This paper aims to learn a domain-generalizable (DG) person re-identification (ReID) representation from large-scale videos without any annotation. Prior DG ReID methods employ limited labeled data for training due to the high cost of annotation, which restricts further ad-vances. To overcome the barriers of data and annota-tion, we propose to utilize large-scale unsupervised data for training. The key issue lies in how to mine identity information. To this end, we propose an Identity-seeking
Self-supervised Representation learning (ISR) method. ISR constructs positive pairs from inter-frame images by mod-eling the instance association as a maximum-weight bi-partite matching problem. A reliability-guided contrastive loss is further presented to suppress the adverse impact of noisy positive pairs, ensuring that reliable positive pairs dominate the learning process. The training cost of ISR scales approximately linearly with the data size, making it feasible to utilize large-scale data for training.
The learned representation exhibits superior generalization ability. Without human annotation and fine-tuning, ISR achieves 87.0% Rank-1 on Market-1501 and 56.4% Rank-1 on MSMT17, outperforming the best supervised domain-generalizable method by 5.0% and 19.5%, respectively. In the pre-training→fine-tuning scenario, ISR achieves state-of-the-art performance, with 88.4% Rank-1 on MSMT17.
The code is at https://github.com/dcp15/ISR_
ICCV2023_Oral. 1.

Introduction
Person re-identification (ReID) aims to retrieve a person across non-overlapping camera views [60, 6, 86, 39, 14].
Although current full-supervised ReID methods [28, 31, 34, 42, 65, 22] have shown encouraging results on public
∗ Corresponding author
Figure 1. The core idea. (a) MoCo [25] learns instance discrimina-tion, which aims to learn a unique representation for each image. (b) ISR learns identity discrimination, which aims to learn similar representations for inter-frame images with the same identity. benchmarks, their performance significantly declines when applied to unseen domains. To enhance the generalization ability, unsupervised domain adaptation (UDA) [15, 84, 19, 1, 53] and domain generalizable (DG) ReID [57, 33, 12] techniques are extensively studied. However, both meth-ods have limitations that prevent their scaling in real-world applications. UDA ReID necessitates well-organized data from the target domain for adaptation. DG ReID, on the other hand, typically employs small-scale labeled training data due to the high cost of annotation, which hinders fur-ther progress. To this end, we propose to break through the constraints of human annotation and target domain adapta-tion on the generalization of person ReID.
This paper aims to learn domain-generalizable represen-tations without any annotation. The representation can be applied directly in arbitrary domains without fine-tuning.
Unlike prior DG ReID methods [57, 33, 12] that require labeled training data, we employ vast amounts of unlabeled internet videos for training. Specifically, our training set comprises 47.8 million unlabeled person images extracted from 74,000 video clips. The feasibility comes from two key factors: the low cost of acquiring videos from the inter-net and the diverse domains present in large-scale videos.
We learn a domain-generalizable ReID representation from
the large-scale unsupervised training data. The representa-tion is robust to unseen domains, exhibiting high application potential and value for open-world scenarios.
The core issue is learning identity discrimination.
In-spired by the great success of contrastive learning [25, 21, 8, 10] in large-scale unsupervised data, we propose to learn identity discrimination through contrastive information be-tween samples. It is not feasible to directly apply conven-tional unsupervised contrastive learning methods to ReID, because the objective of their pretext task (i.e., instance dis-crimination) conflicts with ReID required identity discrim-ination. For example, as in Figure 1(a), MoCo [25] regards two augmented views of an image as a positive pair, which prompts the model to learn a unique representation for each image. However, ReID aims to discriminate between iden-tities instead of instances, which expects multiple images from the same identity to have similar representations.
To achieve the objective of identity discrimination, we propose an Identity-seeking Self-supervised Representation learning (ISR) method. ISR aims to learn similar represen-tations for inter-frame images belonging to the same iden-tity, as illustrated in Figure 1(b). We first formulate the instance association between two frames as a maximum-weight bipartite matching problem, where positive pairs are mined by solving the optimal matching strategy. However, these positive pairs inevitably contain noise due to the unsu-pervised construction, which considerably undermines rep-resentation learning. Next, we introduce a reliability-guided contrastive loss to mitigate the adverse impact of noisy pos-itive pairs, ensuring that reliable positive pairs dominate the learning process. Moreover, the training cost of ISR scales approximately linearly with the size of the data, making it feasible to train on large-scale data.
Extensive experiments demonstrate the effectiveness of
ISR. Under the domain-generalizable settings, ISR with
ResNet50 [26] backbone achieves 45.7% Rank-1 and 21.2% mAP on the most challenging dataset MSMT17 [74], outperforming the best-supervised domain-generalizable method trained with multiple labeled datasets by +8.8% and +6.5%, respectively. When using a more data-hungry backbone, i.e., Swin-Transformer [44], the performance is even further improved, achieving 56.4% Rank-1 and 30.3% mAP on MSMT17. We also evaluate ISR under other prac-tical settings, such as pre-training for supervised fine-tuning or few-shot learning. ISR shows consistent improvements upon existing methods. For example, when serving as a pre-trained model for supervised fine-tuning, ISR achieves 88.4% Rank-1 on MSMT17, setting a new state-of-the-art.
The main contributions of this paper are:
• We propose an Identity-seeking Self-supervised Rep-resentation learning (ISR) method that can learn a domain-generalizable ReID representation from large-scale video data without any annotation.
• We propose a novel reliability-guided contrastive loss that effectively mitigates the adverse impact of noisy positive pairs, making reliable positive pairs dominate the representation learning process.
• Extensive experiments verify the effectiveness of ISR.
Notably, ISR achieves 87.0% Rank-1 on Market-1501 and 56.4% Rank-1 on MSMT17 without human anno-tation and fine-tuning, outperforming the best super-vised DG method by 5.0% and 19.5%, respectively. 2.