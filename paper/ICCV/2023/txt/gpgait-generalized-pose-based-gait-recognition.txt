Abstract
Recent works on pose-based gait recognition have demonstrated the potential of using such simple informa-tion to achieve results comparable to silhouette-based meth-ods. However, the generalization ability of pose-based methods on different datasets is undesirably inferior to that of silhouette-based ones, which has received little at-tention but hinders the application of these methods in real-world scenarios. To improve the generalization abil-ity of pose-based methods across datasets, we propose a
Generalized Pose-based Gait recognition (GPGait) frame-work. First, a Human-Oriented Transformation (HOT) and a series of Human-Oriented Descriptors (HOD) are pro-posed to obtain a unified pose representation with discrim-inative multi-features. Then, given the slight variations in the unified representation after HOT and HOD, it be-comes crucial for the network to extract local-global rela-tionships between the keypoints. To this end, a Part-Aware
Graph Convolutional Network (PAGCN) is proposed to en-able efficient graph partition and local-global spatial fea-ture extraction. Experiments on four public gait recognition datasets, CASIA-B, OUMVLP-Pose, Gait3D and GREW, show that our model demonstrates better and more stable cross-domain capabilities compared to existing skeleton-based methods, achieving comparable recognition results to silhouette-based ones. Code is available at https:
//github.com/BNU-IVC/FastPoseGait. 1.

Introduction
Gait recognition is an essential task in the human iden-tification field. Compared with existing biometric identifi-cation methods, such as face, fingerprint, and iris recogni-tion, it can capture long-distance gait features without the cooperation of subjects. Existing studies of gait recogni-tion can mainly be divided into two streams, appearance-based [4–6, 11, 12, 17, 39] and model-based methods [19, 21, 23, 31, 32, 38]. Specifically, the appearance-based meth-*Equal contribution
†Corresponding Author
Figure 1. GPGait achieves state-of-the-art generalization perfor-mance across four popular gait datasets. In each subgraph, three vertices correspond to the source domain. Arrows (−→) point to the target domain. Triangles in different colors represent the general-ization ability of different models under cross-domain settings. ods try to directly learn gait features from the silhouette se-quences and have been the dominant approach for a long time. And the model-based methods try to explicitly es-timate human body structures (e.g., keypoints or 3D mesh) for gait recognition. Despite that the performance is inferior to the appearance-based methods at the moment, the model-based methods have their own advantage of being robust to carrying and clothing, which is appealing to practical appli-cations and thus deserves continuous attention.
Model-based methods mostly take human poses (i.e., keypoints) as the input which encodes visual clues for body structure and proportion in an explicit way. Benefiting from the rapid development in pose estimation [2, 7, 16, 29] and graph-based models (GCN [28, 36] and Transformer [24]), pose-based methods have achieved fairly surprising results in some cases [31,32,38], e.g., GaitTR [38] introduces Spa-tial Transformer to establish overall spatial relationships be-tween keypoints. The model achieves much higher accu-racy than previous pose-based methods [31, 32] on CASIA-B [37], even surpassing the accuracy of appearance-based methods [4, 6, 11, 20] in clothes-changing conditions.
However, a vital problem is ignored in these research, i.e., generalization ability. Through a preliminary study as shown in Fig.1, we find that the performance of these meth-ods tends to drastically degrade when testing gait sequences from unseen environments, limiting the application in real-istic scenarios. Our analysis suggests that the decline in cross-domain performance can be linked to various factors: (1) scale variations due to the distance to cameras, (2) tilt and horizontal views due to the deployment of cameras, (3) offsets within the camera coordinate system. All these factors can cause intense changes in data distributions, re-sulting in a dramatic decline in performance when there are variations in cameras and environments.
To promote the research on model-based gait recogni-tion, we aim to design a framework for Generalized Pose-based Gait Recognition (GPGait) that can effectively im-prove the generalization ability of pose-based methods. Par-ticularly, we try to solve the problem from two perspectives: a human-oriented input that is comparable across different cameras, and a part-aware model that extracts fine-grained body features for recognition.
In terms of input format, we propose a Human-Oriented
Transformation (HOT) and a series of Human-Oriented De-scriptors (HOD) to obtain a unified and enriched represen-tation. Specifically, HOT consists of three steps, namely affine transform, body rescale, and body alignment, through which the original skeleton sequences captured in the cam-era coordinate system are transformed into unified repre-sentations in the human-oriented coordinate system. Then, to enrich the input, we carefully design a module named
Human-Oriented Descriptors (HOD) to generate individual-invariant features of bone and angle to explicitly reflect the body proportion and structure.
Regarding the modeling, we argue that the fine-grained learning for different human parts is the key to extracting discriminative gait features and improving the generaliza-tion ability. Although we can obtain a unified represen-tation with HOT and HOD, the uniform gait expression exhibits less variation over time compared to the original pose sequence. Therefore, it is imperative to capture the local-global relationships between the keypoints, where lo-cal features can capture the slight changes in pose and the global ones can represent the entire human structure. In-spired by the recent progress in the field of gait recogni-tion [3, 4, 6, 11, 20] and domain generalization [5], we de-sign a Part-Aware Graph Convolutional Network (PAGCN) which can efficiently implement graph partition and local-global relationship construction through mask operations on the adjacency matrix.
To summarize, we make the following three major con-tributions:
• In the HOT module, a series of human-oriented oper-ations are proposed to facilitate a uniform input that overcomes problems caused by various environmental covariances. The input is further enriched in the HOD module to explicitly reflect the skeleton structure and movement.
• We present PAGCN to achieve efficient graph parti-tion and local-global feature relation extraction under the unified pose representation. With different part-specific masks and a well-designed network structure, the method can not only capture fine-grained features and distinct local relations but also reduce the amount of calculations and the number of parameters required.
• Extensive experiments demonstrate that the proposed
GPGait framework achieves state-of-the-art general-ization results in all scenarios (indoor and outdoor) un-der cross-domain settings. Especially, the result of the cross-domain test on GREW−→CASIA-B outperforms previous methods by a large margin of 34.69%. 2.