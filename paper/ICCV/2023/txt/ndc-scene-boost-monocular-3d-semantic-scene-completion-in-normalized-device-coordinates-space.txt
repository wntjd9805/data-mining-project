Abstract
Monocular 3D Semantic Scene Completion (SSC) has garnered significant attention in recent years due to its po-tential to predict complex semantics and geometry shapes from a single image, requiring no 3D inputs.
In this pa-per, we identify several critical issues in current state-of-the-art methods, including the Feature Ambiguity of pro-jected 2D features in the ray to the 3D space, the Pose
Ambiguity of the 3D convolution, and the Computation
Imbalance in the 3D convolution across different depth levels.
To address these problems, we devise a novel
Normalized Device Coordinates scene completion network (NDC-Scene) that directly extends the 2D feature map to a
Normalized Device Coordinates (NDC) space, rather than to the world space directly, through progressive restora-tion of the dimension of depth with deconvolution oper-ations. Experiment results demonstrate that transferring the majority of computation from the target 3D space to the proposed normalized device coordinates space ben-efits monocular SSC tasks. Additionally, we design a
Depth-Adaptive Dual Decoder to simultaneously upsam-ple and fuse the 2D and 3D feature maps, further im-proving overall performance. Our extensive experiments confirm that the proposed method consistently outperforms state-of-the-art methods on both outdoor SemanticKITTI and indoor NYUv2 datasets. Our code are available at https://github.com/Jiawei-Yao0812/NDCScene. 1.

Introduction
Semantic Scene Completion (SSC) [38] is a crucial task in 3D scene understanding [43] [20], with wide applications like virtual reality, embodied AI, and autonomous driving,
*These authors contribute equally to this work.
†Corresponding authors.
Figure 1: Feature ambiguity. We compare (a) the feature maps generated by the proposed dual decoder in the normalized device coordinates space, and (b) the feature maps projected through FLoSP [7], with reference to the ground truth demonstrated in (c). In (b), the multi-scale 2D features are projected along their line of sight, which introduces ambiguity in both feature size and feature depth. Conversely, in the normalized device co-ordinates space, the semantics and occupancy are implicitly restored, as exemplified in (a). etc. Despite the growing body of research on this topic, the majority of existing SSC solutions [35] [6] [8] depend on in-put RGB image and corresponding 3D inputs such as depth image, truncated signed distance function (TSDF)1, etc., to forecast volumetric occupancy and the corresponding se-mantic labels. However, the reliance on these 3D data often entails the use of specialized and costly depth sensors, and thus limits the further application of the Semantic Scene
Completion algorithms. Recently, there is growing inter-est in monocular 3D semantic scene completion [7], which aims to reconstruct a volumetric 3D scene from a single
RGB image, thus eliminating the requirement of the addi-tional 3D inputs.
In the pioneering method Monoscene [7], the 2D fea-tures are lifted to the 3D space by inverting the perspective projection, where the same 2D features are propagated to 1TSDF is a representation to encode depth volume, where each voxel stores the distance value to its closest surface and the sign indicates whether the voxel is in visible spaces.
tation Imbalance (CI) on the 2D feature map, which is also demonstrated in Fig. 2 (b) and (c). Specifically, the con-volved positions in the target 3D space, when projected on the 2D pixels, distributes quite sparse on the close scenes while dense on the far scenes. Such sparse computation allocation can hardly capture a comprehensive structural representation, from the rich details of structure or texture which usually exists in the 2D pixels projected from the close scenes, such as the red shelf in Fig. 2 (b) and (c).
Based on the three ambiguities the computation imbal-ance noticed, we devise a novel framework named NDC-Scene. Concretely, to alleviate FSA and FDA, the 3D fea-ture maps are directly recovered in the NDC space, which strictly aligns with the image in hight and width, and ex-tened in the depth-wise dimension. This methodology en-ables the implicit learning of precise occupancy and se-mantics among voxels, circumventing any erroneous infer-ences that may arise from 2D projection semantics. Further-more, to address issues pertaining to PA and CI, we shift the majority computation units from the target 3D space to the NDC space. Extensive experiments on large-scale out-door and indoor datasets demonstrate the superiority of our method to the existing state-of-the-art methods. The contri-butions can be summarized as follows:
• According to the critical problems we noticed in the existing methods, we propose a novel method based on
Normalized Device Coordinates (NDC) space, which is proved to be a better space to put the majority 3D computation units than the target 3D space.
• In conjunction with the aforementioned camera space prediction, a pioneering depth-adaptive dual decoder is introduced to jointly upsample both 3D and 2D fea-tures and integrate them, thereby attaining more re-silient representations.
• Experimental results demonstrate that the proposed method outperforms state-of-the-art monocular se-mantic scene completion methods significantly on both outdoor and indoor datasets. 2.