Abstract
Semi-Supervised Learning (SSL) under class distribu-tion mismatch aims to tackle a challenging problem wherein unlabeled data contain lots of unknown categories unseen in the labeled ones.
In such mismatch scenarios, tradi-tional SSL suffers severe performance damage due to the harmful invasion of the instances with unknown categories into the target classifier. In this study, by strict mathemat-ical reasoning, we reveal that the SSL error under class distribution mismatch is composed of pseudo-labeling er-ror and invasion error, both of which jointly bound the
SSL population risk. To alleviate the SSL error, we pro-pose a robust SSL framework called Weight-Aware Distil-lation (WAD) that, by weights, selectively transfers knowl-edge beneficial to the target task from unsupervised con-trastive representation to the target classifier. Specifically,
WAD captures adaptive weights and high-quality pseudo-labels to target instances by exploring point mutual infor-mation (PMI) in representation space to maximize the role of unlabeled data and filter unknown categories. Theo-retically, we prove that WAD has a tight upper bound of population risk under class distribution mismatch. Exper-imentally, extensive results demonstrate that WAD outper-forms five state-of-the-art SSL approaches and one stan-dard baseline on two benchmark datasets, CIFAR10 and
CIFAR100, and an artificial cross-dataset. The code is available at https://github.com/RUC-DWBI-ML/ research/tree/main/WAD-master. 1.

Introduction
Deep neural networks (DNNs) have achieved remark-able success in fully-supervised learning tasks. However, sufficient labeled data are usually unavailable in real ap-plications due to the expensive annotation cost or even domain-specific knowledge required [8, 11, 12, 13]. Semi-*Corresponding Author
Figure 1. Example of class distribution mismatch. The unlabeled data contains categories that are unseen in labeled ones. supervised learning (SSL), as a powerful weakly-supervised technique, provides an effective way to improve DNNs by exploiting massive unlabeled data, and then it weakens the demand for human annotation [9, 14, 24, 34]. Generally, traditional SSL approaches assume that the labeled and un-labeled instances share the same class distribution, i.e., they come from identical categories. However, in real scenarios, this assumption hardly holds as unlabeled data inevitably contains lots of categories unseen in labeled ones. For instance, if unlabeled data are collected from the internet using keywords “cat” and “dog” (target categories), they may contain instances unrelated to these categories, such as “deer,” “horse,” or “airplane”(unknown categories), as shown in Figure 1. Similar scenarios occur in medical di-agnoses [11, 15] and house annotations of remote-sensing images [12, 13]. SSL in such mismatch scenarios is called
SSL under class distribution mismatch [12, 15].
Under class distribution mismatch, some SSL ap-proaches [8, 11, 15, 19, 37] have been proposed. Usually, most of them exploit pseudo-labeling or consistency regu-larization to expand the labeled pool, as well as filter in-stances with unknown categories by weights, just as shown in Figure 2. UASD [11] and T2T [19] filter out the instances with unknown categories by leveraging a hard weight, i.e., a
Figure 2. The paradigm of SSL under class distribution mismatch. threshold, on the accumulated network’s output or the out-of-distribution score. Although these two approaches re-duce the invasion of unknown categories, it is inevitable to keep off amounts of unlabeled instances with target cate-gories. Instead of hard weights, Guo et al. [15] assign a soft weight to the unlabeled instances according to the consis-tent empirical risk loss. In such case, many instances with unknown categories tend to have consistent outputs and get high weights, just as shown in Appendix 4.3, and then they may invade the target classifier and impair its performance.
Moreover, the existing SSL approaches with consistency regularization and pseudo-labeling heavily rely on the per-formance of the target classifier. Both [15] and [19] anno-tate pseudo labels by leveraging the prediction of the target classifier in training. Once the target classifier trained on limited labeled instances is biased by some instances with unknown categories, the subsequently updated target classi-fier may allow more unknown instances to invade. Accord-ingly, it is promising to propose a novel SSL approach that captures pseudo labels from representations produced by all available data rather than an immature classifier.
In this study, by strict theoretical analyses, we decou-ple the SSL error under class distribution mismatch into pseudo-labeling error and invasion error (seen in Subsec-tion 3.2). According to this discovery, a robust SSL frame-work called weight-aware distillation (WAD) is then pro-posed to distill pseudo labels and weights from the represen-tation space to the target classifier. Unlike the conventional distillation approaches [7, 17, 28] that simply train the stu-dent model using the prediction probability of the teacher model, WAD is a weight-aware distillation framework that adapts to mismatch problems. Specifically, we learn the representations from labeled and unlabeled data by unsuper-vised contrastive coding, as the teacher model. Then WAD captures adaptive weights as well as high-quality pseudo labels from the teacher model by leveraging point mutual information(PMI), and thus, the target classifier could se-lectively utilize the instances from target categories while filtering the ones with unknown categories.
Our main contributions are listed as follows. i) We theoretically analyze the population risk in an SSL manner and reveal that the SSL error under class dis-tribution mismatch is jointly controlled by pseudo-labeling error and invasion error. ii) We propose a distillation-based SSL framework,
WAD, that captures weights as well as pseudo labels from robust representations to the target classifier to filter unknown categories and make full use of targeted unlabeled instances as well. iii) Theoretically, we verify that the population risk of
WAD is tightly bounded. Experimentally, WAD out-performs five state-of-the-art SSL approaches and one standard baseline on several datasets. 2.