Abstract
Albeit the notable performance on in-domain test points, it is non-trivial for deep neural networks to attain satis-factory accuracy when deploying in the open world, where novel domains and object classes often occur. In this pa-per, we study a practical problem of Domain Generaliza-tion under Category Shift (DGCS), which aims to simulta-neously detect unknown-class samples and classify known-class samples in the target domains. Compared to prior DG works, we face two new challenges: 1) how to learn the con-cept of “unknown” during training with only source known-class samples, and 2) how to adapt the source-trained model to unseen environments for safe model deployment.
To this end, we propose a novel Activate and Reject (ART) framework to reshape the model’s decision boundary to ac-commodate unknown classes and conduct post hoc modifi-cation to further discriminate known and unknown classes using unlabeled test data. Specifically, during training, we promote the response to the unknown by optimizing the un-known probability and then smoothing the overall output to mitigate the overconfidence issue. At test time, we in-troduce a step-wise online adaptation method that predicts the label by virtue of the cross-domain nearest neighbor and class prototype information without updating the net-work’s parameters or using threshold-based mechanisms.
Experiments reveal that ART consistently improves the gen-eralization capability of deep networks on different vision tasks. For image classification, ART improves the H-score by 6.1% on average compared to the previous best method.
For object detection and semantic segmentation, we estab-lish new benchmarks and achieve competitive performance. 1.

Introduction
Deep neural networks have achieved unprecedented suc-cess in a myriad of vision tasks over the past decade. De-spite the promise, a well-trained model deployed in the open
*First two authors contributed equally.
†Corresponding authors.
Figure 1. DGCS in image classification and object detection tasks. and ever-changing world often struggles to deal with the domain shifts—the training and testing data do not follow the independent and identically distributed (i.i.d) assump-tion, and therefore deteriorates its safety and reliability in many safety-critical applications, such as autonomous driv-ing and computer-aided disease diagnosis. This gives rise to the importance of Domain Generalization (DG) [101, 83], a.k.a. out-of-distribution (OOD) generalization, which aims at generalizing predictive models trained on multiple (or a single) source domains to unseen target distributions.
In order to unearth domain-agnostic knowledge and al-leviate domain-specific components, a plethora of DG al-gorithms have been proposed, spanning invariant risk min-imization [2, 1], augmentation [81, 87, 105, 9], feature dis-entanglement [63, 49, 93], meta-learning [43, 44, 21], to name a few. Among them, a common assumption is that the label spaces of source and target domains are identi-cal, which may not always hold in practice. Suppose that we wished to deploy modern vision systems to recognize objects in an autonomous vehicle. When only the environ-ment (e.g., weather and illumination) and appearance (e.g., size and viewpoint) of previously seen objects can change, principled approaches are capable of correcting for the po-tential shifts on the fly. But what if the sudden arrival of new objects in an ever-changing world? Most existing DG methods will break and may even result in catastrophe, rais-ing strong concerns about model reliability. Although sev-eral prior arts [71, 106] have explored the open DG sce-narios, the “adaptivity gap” [22] between training and test distributions still hinders safe deployment of source-learned models [30].
To this premise, we challenge the status quo by raising an open question: can deep models learn what they don’t know during training and subsequently adapt to novel envi-ronments at test-time for safe model deployment? Thus, we consider a more realistic scenario namely Domain General-ization under Category Shift (DGCS) (see Fig. 1), wherein the source-trained model is expected to simultaneously de-tect unknown-class samples and categorize known-class samples under the presence of domain shifts. The core chal-lenges are: (i) no unknown-class data is available in train-ing and (ii) the mixture of domain and label shifts during test time. In this paper, we present a simple yet effective framework—Activate and RejecT (dubbed ART), which re-shapes the model’s decision boundary to accommodate un-known classes and adjusts the final prediction to reconcile the intrinsic tension between domain and label shifts. ART encapsulates two key components: (i) Unknown-aware Gra-dient Diffusion (UGD) to make the classifier give response to unknown dimension and smooth the decision boundary to mitigate overconfidence; (ii) Test-time Unknown Rejec-tion (TUR) to conduct post hoc modification to the learned classifier’s final predictions, making the decision bound-aries of different classes closer to the well-behaved case.
Specifically, the logit of unknown class is activated by minimizing the negative log-likelihood regarding unknown probability. However, we find that the learned probability will be suppressed due to the overconfidence w.r.t. known classes. Thus, we introduce a smoothed cross-entropy loss to promote the response to the unknown by adding the penalty on the L2 norm of the logits and using a temperature scaling parameter, where the former mitigates the excessive increase of the logit norm while the latter magnifies the ef-fect of logit penalty. Due to the unavailability of real target data in training, the source-trained decision boundaries be-tween known and unknown classes may still be ambiguous.
Therefore, TUR refines the source-trained classifier using unlabeled test data in an online adaptation manner. To be specific, TUR first determines if the input belongs to known classes or not via a cross-domain nearest neighbor search, based on prototype information and cyclic consistent con-straint; otherwise, the prediction will be made by a paral-lel module that measures the input’s similarity with a set of dynamically-updated target prototypes. TUR is training-free (no backward passes) and does not rely on threshold-based criteria nor impose any distributional assumptions.
Our key contributions are summarized as follows:
• We study a challenging DG problem (DGCS) and pro-pose a principled framework (ART) to jointly consider domain shift, label shift, and adaptivity gap.
• We propose an unknown-aware training objective to activate the unknown’s logit and alleviate the overcon-fidence issue, and an online adaptation strategy to per-form post hoc modification to the learned classifier’s prediction at test-time without additional tuning.
• Extensive experiments show that ART achieves supe-rior performance on a wide range of tasks including image classification, object detection, and semantic segmentation. In particular, on four image classifica-tion benchmarks (PACS, Office-Home, Office-31, and
Digits), ART improves the H-score by 6.1% on average compared to the previous best method. 2.