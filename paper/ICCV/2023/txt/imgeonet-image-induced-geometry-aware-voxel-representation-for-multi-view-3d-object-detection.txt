Abstract
We propose ImGeoNet, a multi-view image-based 3D ob-ject detection framework that models a 3D space by an image-induced geometry-aware voxel representation. Un-like previous methods which aggregate 2D features into 3D voxels without considering geometry, ImGeoNet learns to induce geometry from multi-view images to alleviate the confusion arising from voxels of free space, and during the inference phase, only images from multiple views are required. Besides, a powerful pre-trained 2D feature ex-tractor can be leveraged by our representation, leading to a more robust performance. To evaluate the effectiveness of ImGeoNet, we conduct quantitative and qualitative ex-periments on three indoor datasets, namely ARKitScenes,
ScanNetV2, and ScanNet200. The results demonstrate that
ImGeoNet outperforms the current state-of-the-art multi-view image-based method, ImVoxelNet, on all three datasets in terms of detection accuracy.
In addition, ImGeoNet shows great data efficiency by achieving results compara-ble to ImVoxelNet with 100 views while utilizing only 40 views. Furthermore, our studies indicate that our proposed image-induced geometry-aware representation can enable image-based methods to attain superior detection accuracy than the seminal point cloud-based method, VoteNet, in two practical scenarios: (1) scenarios where point clouds are sparse and noisy, such as in ARKitScenes, and (2) scenar-ios involve diverse object classes, particularly classes of small objects, as in the case in ScanNet200. Project page: https://ttaoretw.github.io/imgeonet.
*Work done in Amazon.
Figure 1. Geometry-aware voxel representation. (Top part) In contrast to prior works [56] (top left) that disregard the underly-ing geometry, our proposed ImGeoNet (top center) successfully preserves the geometric structure with respect to the ground truth (top right) while effectively reducing the number of voxels in free space.
In the visualization of ImGeoNet, voxels with a surface probability exceeding a predefined threshold are retained, other-wise removed. The color of each voxel is determined by averaging the colors of ground truth point clouds within the voxel. Missed free-space voxels are marked as cyan. (Bottom part) We present the detection results using bounding cubes that are color-coded based on the predicted categories. 1.

Introduction
Indoor 3D object detection has been an active area of computer vision research for over a decade, owing to its practical applications in robotics, augmented reality, and
In recent years, several studies [48, 16, 7, mixed reality. 85, 67, 34, 41, 14, 55] have demonstrated the effectiveness of methods based on point clouds in conjunction with deep learning techniques for indoor 3D object detection. How-ever, the applicability of these methods is limited by their reliance on data acquired from expensive 3D sensors such as depth cameras, stereo cameras, or laser scanners. In con-trast to point clouds, color images are more affordable and can capture semantically rich information akin to human vi-sion. Therefore, image-based indoor 3D object detection is a promising research direction.
Image-based methods for indoor monocular 3D object detection [18, 19, 45, 81] have demonstrated a satisfactory level of accuracy. Nonetheless, monocular methods en-counter challenges such as scale ambiguity, occlusion is-sues, and limited field of view. These issues can be miti-gated by providing multiple perspectives of the scene, lead-ing to a more robust and accurate 3D object detection re-sult. Previous works [44, 56] employ multi-view images to construct a feature volume, which is subsequently utilized for conducting 3D object detection [56]. Although these methods have exhibited state-of-the-art performance, they neglect the underlying geometric characteristics during the feature volume construction.
In this work, we propose ImGeoNet, a multi-view 3D object detection framework that models a 3D space by an image-induced geometry-aware voxel representation. Im-GeoNet learns to induce geometry from multi-view im-ages to reduce the importance of voxels representing free space, and during the inference phase, only images from multiple views are required. Specifically, ImGeoNet pre-dicts the likelihood of each voxel belonging to a surface, and subsequently weighting the feature volume according to this probability. The proposed approach exhibits a no-table enhancement in detection performance owing to the successful alleviation of confusion arising from voxels in free space. Besides, a powerful pre-trained 2D feature ex-tractor can be utilized by our representation, leading to more robust performance.
We conduct quantitative and qualitative experiments to evaluate the effectiveness of ImGeoNet on three in-door datasets, namely ARKitScenes [2], ScanNetV2 [10], and ScanNet200 [54]. The results demonstrate that Im-GeoNet outperforms the state-of-the-art multi-view image-based method, ImVoxelNet [56], by 3.8%, 12.5% and 17.4% in mAP@0.25 on ARKitScenes, ScanNetV2, and
ScanNet200, respectively. Additionally, ImGeoNet shows great data efficiency by achieving results comparable to
ImVoxelNet with 100 views while utilizing only 40 input views. Furthermore, the results of the experiments indi-cate that our proposed image-induced geometry-aware rep-resentation can enable image-based methods to attain supe-rior detection accuracy than the seminal point cloud-based method, VoteNet, in two practical scenarios: (1) scenarios where point clouds are sparse and noisy, such as in ARK-itScenes, and (2) scenarios involve diverse object classes, particularly classes of small objects, as in the case in Scan-Net200. Specifically, ImGeoNet outperforms VoteNet in these scenarios by at least 12.6% in terms of mAP@0.25.
The contributions of our work can be summarized as fol-lows:
• We introduce a multi-view object detection framework that utilizes an image-induced geometry-aware voxel representation to enhance image-based 3D object de-tection substantially.
• Our method achieves state-of-the-art performance for image-based 3D object detection on ARKitScenes,
ScanNetV2, and ScanNet200.
• Our studies demonstrate our proposed geometry-aware representation enables image-based methods to attain superior detection accuracy than the seminal point cloud-based method, VoteNet, in practical scenarios which consist of sparse and noisy point clouds or in-volve diverse classes. 2.