Abstract
Domain adaptive detection aims to improve the general-ity of a detector, learned from the labeled source domain, on the unlabeled target domain. In this work, drawing inspi-ration from the concept of stability from the control theory that a robust system requires to remain consistent both ex-ternally and internally regardless of disturbances, we pro-pose a novel framework that achieves unsupervised domain adaptive detection through stability analysis. In specific, we treat discrepancies between images and regions from differ-ent domains as disturbances, and introduce a novel simple but effective Network Stability Analysis (NSA) framework that considers various disturbances for domain adaptation.
Particularly, we explore three types of perturbations includ-ing heavy and light image-level disturbances and instance-level disturbance. For each type, NSA performs external consistency analysis on the outputs from raw and perturbed images and/or internal consistency analysis on their fea-tures, using teacher-student models. By integrating NSA into Faster R-CNN, we immediately achieve state-of-the-art results. In particular, we set a new record of 52.7% mAP on Cityscapes-to-FoggyCityscapes, showing the potential of
NSA for domain adaptive detection.
It is worth noticing, our NSA is designed for general purpose, and thus applica-ble to one-stage detection model (e.g., FCOS) besides the adopted one, as shown by experiments. Code is released at https://github.com/tiankongzhang/NSA. 1.

Introduction
Benefited by deep neural networks [27, 49, 13], ob-ject detection has witnessed considerable progress in recent years [28, 33, 43, 51, 62, 10]. Modern detectors are usually trained and tested on large-scale annotated datasets [8, 34].
Despite excellence, they easily degenerate when applied to
∗The two authors make equal contributions and are co-first authors.
†Corresponding author: Libo Zhang (libo@iscas.ac.cn).
Figure 1. Illustration of the proposed NSA framework that applies the specially designed NSAHID, NSALID and NSAInsD for differ-ent disturbances including HID, LID and InsD, respectively. images from a new target domain, which heavily limits their practical applications. To mitigate this, a naive solution is to collect a dataset for the new target domain to re-train a detector. Nevertheless, dataset creation is a nontrivial task that needs a large amount of labor. Besides, a new target domain could be arbitrary and it is impossible to collect datasets for all new target domains. To deal with this, re-searchers explore unsupervised domain adaptation (UDA) detection, aiming to transfer knowledge learned from an an-notated source domain to an unlabeled target domain.
Existing UDA detection can be generally classified into three families. The first branch focuses on aligning feature distributions of different domains to reduce their gap using, e.g., adversarial learning [5, 46, 64] and maximum mean discrepancy [35, 36, 37]. Despite effectiveness, these ap-proaches may suffer from three limitations. First, they usu-ally require both source and target datasets for training, re-straining their usage. Besides, they are problematic with lo-cal misalignment, principally because of unknown internal distribution of feature space distribution due to the lack of target domain annotations. Finally, a large amount of useful information among samples for different domain datasets
is ignored, resulting in inferior performance. Another line leverages self-training for UDA detection [45, 24, 25]. The core idea is to generate high-quality pseudo labels on the target domain and apply them for detector training. Al-though this strategy improves detection on the target do-main, it heavily relies on initial detection results, making them unstable. The third direction is to exploit the teacher-student model [2, 7]. Using consistency constraints of de-tector predictions regardless of external disturbance on in-put, these approaches exhibit robust domain adaptive de-tection. Despite this, they ignore the consistency for inter-nal features and external predictions under different distur-bances, resulting in degradation on the new target domain.
Contributions. Different than the above methods, we study
UDA detection from a new perspective. Particularly, we ob-serve that the changes of attributes (e.g., scale, view, transla-tion, color) for object and styles for instances are the major causes for domain differences. For a desired stable detector, both feature representations and prediction results should be consistent under these changes. Drawing inspiration from stability concept in control theory [1] where the good system needs to perform consistently in both external predictions and internal status in presence of disturbances, we propose a novel framework for UDA detection via Network Stabil-ity Analysis (NSA). The key idea is that, we regard discrep-ancy caused by distribution changes between two domains as data disturbance, and analyze influence of various distur-bances on internal features and external predictions.
More specifically, in this paper we consider three types of disturbances, Heavy and Light Image-level Disturbances (HID and LID) and Instance-level Disturbance (InsD), that involve general perturbations of color, view, texture, scale, translation and instance style in the images. The reason for disturbance division is that variations in images are signifi-cantly different and it is difficulty to use a single disturbance for analysis. For each type of disturbance, NSA performs external consistency analysis (ECA) on outputs of the orig-inal and the disturbed images and/or internal consistency analysis (ICA) on their features, both with teacher-student models. Considering each disturbance focuses on different aspects, the NSA is different, accordingly. Concretely, HID majorly focuses on large object or region variations in scales and views. Since the internal features greatly vary while the external detection results are coincident, we only perform
ECA in NSAHID (i.e., NSA for HID). Different from HID,
LID mainly contains slight scale and view changes in ob-jects and small pixel displacements, and the local seman-tics in the internal feature maps are highly similar. Thus, we perform both ECA and ICA in NSALID (i.e. NSA for
LID). InsD describes differences in instances belonging to the same category. Intuitively, objects of the same class may have adjacent spatial distributions. Inspired by this, we per-form ICA in NSAInsD (i.e., NSA for InsD). Specifically, with real and pseudo labels, we build an undirected graph based on pixel or instance features and further acquire the feature centers of all classes, which exist in an image batch, and select negative samples for each node in the undirected graph from the background region. Finally, the stable fea-ture distribution for all classes is learned with a contrastive loss function. Fig. 1 illustrates our idea.
By integrating our NSA of different disturbances into the popular Faster R-CNN [43], we immediately achieve state-of-the-art results on multiple benchmarks (i.e, Cityscapes
[6], FoggyCityscapes [47], RainCityscapes [19], KITTI [9],
Sim10k [23] and BDD100k [57]), revealing the great poten-tial of NSA for domain adaptive detection. Note that, NSA is designed for general purpose. We show this by plugging
NSA into the one-stage detector (e.g., FCOS [51]), and re-sults demonstrate promising performance.
In summary, our contributions are as follows: (i) we propose a novel unified Network Stability Analysis (NSA) framework for domain adaptive detection; (ii) we introduce the external consistency analysis (ECA) and internal con-sistency analysis (ICA) for NSA; and (iii) we integrate our
NSA for different disturbances into existing detectors and consistently achieve state-of-the-art results. 2.