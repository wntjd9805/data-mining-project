Abstract
False negatives (FN) in 3D object detection, e.g., miss-ing predictions of pedestrians, vehicles, or other obsta-cles, can lead to potentially dangerous situations in au-tonomous driving. While being fatal, this issue is under-studied in many current 3D detection methods.
In this work, we propose Hard Instance Probing (HIP), a gen-eral pipeline that identiﬁes FN in a multi-stage manner and guides the models to focus on excavating difﬁcult instances. For 3D object detection, we instantiate this method as FocalFormer3D, a simple yet effective detector that excels at excavating difﬁcult objects and improving prediction recall. FocalFormer3D features a multi-stage query generation to discover hard objects and a box-level transformer decoder to efﬁciently distinguish objects from massive object candidates. Experimental results on the nuScenes and Waymo datasets validate the superior perfor-mance of FocalFormer3D. The advantage leads to strong performance on both detection and tracking, in both Li-DAR and multi-modal settings. Notably, FocalFormer3D achieves a 70.5 mAP and 73.9 NDS on nuScenes detec-tion benchmark, while the nuScenes tracking benchmark shows 72.1 AMOTA, both ranking 1st place on the nuScenes
LiDAR leaderboard. Our code is available at https:
//github.com/NVlabs/FocalFormer3D. 1.

Introduction 3D object detection is an important yet challenging per-ception task. Recent state-of-the-art 3D object detectors mainly rely on bird’s eye view (BEV) representation [1–3], where features from multiple sensors are aggregated to con-struct a uniﬁed representation in the ego-vehicle coordinate space. There is a rich yet growing literature on BEV-based 3D detection, including multi-modal fusion [4–10], second-stage reﬁnements (surface point pooling [3], RoIPool [11– 14], and cross attention modules [4, 15]).
Figure 1. Visual example for Hard Instance Probing (HIP). By utilizing this multi-stage prediction approach, our model can pro-gressively focus on hard instances and facilitate its ability to grad-ually detect them. At each stage, the model generates some Posi-tive object candidates (represented by green circles). Object can-didates assigned to the ground-truth objects can be classiﬁed as either True Positives (TP, represented by green boxes) and False
Negatives (FN, represented by red boxes) during training. We ex-plicitly model the unmatched ground-truth objects as the hard in-stances, which become the main targets for the subsequent stage.
Conversely, Positives are considered easy samples (represented by gray boxes) and will be ignored in subsequent stages at both train-ing and inference time. At last, all heatmap predictions across stages are collected as the initial object candidates. We ignored the False Positives for better visualizations.
*Work done during an internship at NVIDIA.
†Corresponding author.
Despite the tremendous efforts, there has been limited exploration to explicitly address false negatives or missed
objects often caused by occlusions and clutter background.
False negatives are particularly concerning in autonomous driving as they cause missing information in the prediction and planning stacks. When an object or a part of an object is not detected, this can result in the autonomous vehicle being unaware of potential obstacles such as pedestrians, cyclists, or other vehicles. This is especially hazardous when the vehicle is moving at high speeds and can lead to potentially dangerous situations. Therefore, reducing false negatives is crucial to ensure the safety of autonomous driving.
To address the challenge of False Negatives in 3D detec-tion, we propose and formulate a pipeline called Hard In-stance Probing (HIP). Motivated by cascade-style decoder head for object detection [16–18], we propose a pipeline to probe false negative samples progressively, which signiﬁ-cantly improves the recall rate Fig. 1 illustrates the pipeline in a cascade manner. In each stage, HIP suppresses the true positive candidates and focuses on the false negative candi-dates from the previous stages. By iterating the HIP stage, our approach can save those hard false negatives.
Based on HIP, we introduce a 3D object detector, Fo-calFormer3D, as shown in Fig. 2. Especially, multi-stage heatmap predictions [3, 19] are employed to excavate dif-ﬁcult instances. We maintain a class-aware Accumulated
Positive Mask, indicating positive regions from prior stages.
Through this masking design, the model omits the training of easy positive candidates and thereby focuses on the hard instances (False Negatives). Finally, our decoder collects the positive predictions from all stages to produce the ob-ject candidates. FocalFormer3D consistently demonstrates considerable gains over baselines in terms of average recall.
In addition, we also introduce a box-level reﬁnement step to eliminate redundant object candidates. The approach employs a deformable transformer decoder [17] and repre-sents the candidates as box-level queries using RoIAlign.
This allows for box-level query interaction and iterative box reﬁnements, binding the object queries with sufﬁcient box context through RoIAlign [20, 21] on the bird’s eye view to perform relative bounding box reﬁnements. Finally, a rescoring strategy is adopted to select positive objects from object candidates. Our ablation study in Table 6 demon-strates the effectiveness of the local reﬁnement approach in processing adequate object candidates.
Our contributions can be summarized as follows: based and multi-modal settings. Notably, our model ranks 1st places on both nuScenes 3D LiDAR detec-tion and tracking leaderboard at time of submission. 2.