Abstract
Face Anti-Spoofing (FAS) is recently studied under the continual learning setting, where the FAS models are ex-pected to evolve after encountering data from new domains.
However, existing methods need extra replay buffers to store previous data for rehearsal, which becomes infeasible when previous data is unavailable because of privacy issues. In this paper, we propose the first rehearsal-free method for
Domain Continual Learning (DCL) of FAS, which deals with catastrophic forgetting and unseen domain general-ization problems simultaneously. For better generaliza-tion to unseen domains, we design the Dynamic Central
Difference Convolutional Adapter (DCDCA) to adapt Vi-sion Transformer (ViT) models during the continual learn-ing sessions. To alleviate the forgetting of previous do-mains without using previous data, we propose the Proxy
Prototype Contrastive Regularization (PPCR) to constrain the continual learning with previous domain knowledge from the proxy prototypes. Simulating practical DCL sce-narios, we devise two new protocols which evaluate both generalization and anti-forgetting performance. Exten-sive experimental results show that our proposed method can improve the generalization performance in unseen do-mains and alleviate the catastrophic forgetting of previous knowledge. The code and protocol files are released on https://github.com/RizhaoCai/DCL-FAS-ICCV2023. 1.

Introduction
Face recognition (FR) has been widely used in identity authentication because of its convenience. However, face recognition-based authentication systems are threatened by face spoofing attacks [48, 22, 63]. To protect FR systems
*Corresponding author
Figure 1. The rehearsal-free DCL consists of a sequence of learn-ing sessions. The FAS model is initially trained on a large-scale base domain and then continually adapts to new domains in the following continual sessions. For each continual session, only a few data of new domain is available for training and previous data is NOT available. After the DCL, the model is tested on all previ-ous domains and extra unseen domains. from spoofing attacks, various Face Anti-Spoofing (FAS) techniques are deployed to detect spoofing faces and reject malicious attempts [24, 23]. Although recent FAS meth-ods based on deep learning and neural networks achieve exquisite accuracy in intra-domain testing, the performance of existing methods heavily relies on the diversity of the training data and degrades severely if there are domain shifts between the training and testing data domains [26].
The cross-domain problem hence becomes the most chal-lenging issue of state-of-the-art FAS research.
To tackle the cross-domain problem, domain general-ization [50, 16, 61] and adaption [26, 13] techniques for
FAS have been extensively studied in recent years. Do-main generalization-based methods aim to develop a gen-eralized FAS model with training data from multiple source domains. Despite improving the generalization to some ex-tent, they are still not satisfactory in unseen domains. Be-sides, domain adaptation-based methods utilize target do-main data for model adaptation. Although the target domain performance can be significantly improved, the benefit is at the cost of expensive target data collection. Moreover, it is even impractical to collect sufficient data at a static point in time since the domain shifts are caused by constantly chang-ing factors like illuminations and attack types.
In real-world scenarios, the deployed FAS systems con-stantly encounter new data from various domains. The new data will be collected and become available for model train-ing gradually. Completely retraining a model from scratch with old and new data has both efficiency and privacy is-sues. Although fine-tuning the base model with the new data only is more efficient, the past knowledge will be forgotten after fine-tuning, and the performance on previ-ous data decreases dramatically, i.e. catastrophic forget-ting [44]. To adapt models efficiently, continual learn-ing methods for FAS have been proposed in recent works
[44, 49]. To alleviate the catastrophic forgetting, both meth-ods [44, 49] utilize replay buffers to store previous data for rehearsal while fine-tuning with new data. However, the use of replay buffers causes extra storage burdens. Even worse, the previous data is not always available for storage and transfer since face data contains identity information.
In this work, we tackle the FAS problem under the rehearsal-free Domain Continual Learning (DCL) setting.
Unlike existing work [49], where the FAS model is expected to learn sequentially from data of novel attack types, the aim of our work is to enable the FAS model to continu-ally evolve with the data from constantly varying domains.
Due to efficiency and privacy issues, previous data is not allowed to be stored and accessed for rehearsal, and only a few (low-shot) new data are available for continual learning, which are different from previous works [44, 49]. We first evaluate the baseline method under the DCL setting and ob-tain the below interesting observations from experiments: catastrophic forgetting usually occurs when the new com-ing data dataset has large domain gaps from previous ones, and a model with better performance of unseen domain gen-eralization usually forgets less previous domain knowledge.
Motivated by above the observations, we propose to address the DCL-FAS problem from the aspect of generalization.
During continual sessions, using a small amount of data may lead to overfitting, bringing poor generalization per-formance and catastrophic forgetting. To update models continually and efficiently, we introduce the Efficient Pa-rameter Transfer Learning (EPTL) paradigm for the DCL-FAS and utilize Adapters [12, 13] for Vision Transformer (ViT) [9]. By using the adapters, ViT models can be ef-ficiently adapted even with low-shot training data. How-ever, we find that vanilla adapters consisting of linear lay-ers cannot satisfy the need to extract fine-grained features for the FAS task. Hence, we replace the vanilla Linear
Adapter with our proposed Dynamic Central Difference
Convolutional Adapter (DCDCA), which empowers ViT with image-specific inductive bias by convolution and ex-tracts fine-grain features with adaptive central difference information [65]. Unlike [65] where the ratio of central difference information is fixed for all layers, the ratio in our designed DCDCA is self-adaptive to new data domains, which is more suitable in the DCL setting. Besides, to fur-ther improve the generalization performance, we optimize
DCDCA with contrastive regularization and reduce forget-ting during optimization by our proposed Proxy Prototype
Contrastive Regularization (PPCR). Without access to pre-vious data, our PPCR utilizes previous data knowledge ex-tracted from the class centroids of previous tasks, which are approximated by model weights of the fully-connected lay-ers, instead of previous data.
Our contributions include: 1) We formulate and tackle the FAS problem in a more practical scenario: low-shot and rehearsal-free Domain Continual Learning (DCL). In each continual learning session, only a few new data are available for training and no previous data is accessible; 2)
We design the Dynamic Central Difference Convolutional
Adapter (DCDCA) to efficiently adapt ViT-based models in continual domains and capture intrinsic live/spoof cues; 3) We propose the Proxy Prototype Contrastive Regulariza-tion (PPCR) to further improve the generalization and al-leviate the forgetting of FAS models during rehearsal-free
DCL; 4) We design two practical protocols to evaluate both anti-forgetting and generalization capacities of FAS models under DCL settings, with up to 15 public datasets covering both 2D and 3D attacks. We find that the proposed DCDCA and PPCR can significantly improve generalization while forgetting less over baselines on these two DCL protocols. 2.