Abstract 1.

Introduction
Unsupervised domain adaptation (UDA) has proven to be highly effective in transferring knowledge from a label-rich source domain to a label-scarce target domain. How-ever, the presence of additional novel categories in the target domain has led to the development of open-set do-main adaptation (ODA) and universal domain adaptation (UNDA). Existing ODA and UNDA methods treat all novel categories as a single, unified unknown class and attempt to detect it during training. However, we found that domain variance can lead to more significant view-noise in unsu-pervised data augmentation, which affects the effectiveness of contrastive learning (CL) and causes the model to be overconfident in novel category discovery. To address these issues, a framework named Soft-contrastive All-in-one Net-work (SAN) is proposed for ODA and UNDA tasks. SAN includes a novel data-augmentation-based soft contrastive learning (SCL) loss to fine-tune the backbone for feature transfer and a more human-intuitive classifier to improve new class discovery capability. The SCL loss weakens the adverse effects of the data augmentation view-noise prob-lem which is amplified in domain transfer tasks. The All-in-One (AIO) classifier overcomes the overconfidence problem of current mainstream closed-set and open-set classifiers.
Visualization and ablation experiments demonstrate the ef-fectiveness of the proposed innovations. Furthermore, ex-tensive experiment results on ODA and UNDA show that
SAN outperforms existing state-of-the-art methods.
The ∗ indicates equal contribution, † indicates corresponding author.
Zelin Zang, Senqiao Yang and Stan Z. Li are at AI Lab, Research Center for Industries of the Future, Westlake University. 1
In practical applications of classifiers, it is important to discover novel category that do not exist in the training data. Domain adaptation (DA) is a technique that trans-fers knowledge from label-rich training domains to new do-mains [1]. It has the potential to address new categories of discovery by investigating the generalization of deep mod-els to new domains. Traditional unsupervised domain adap-tation (UDA) [14] assumes that the source domain and the target domain completely share the sets of categories, i.e., closed-set DA. However, this assumption does not often hold in practice. There are several possible situations, such as the target domain containing types absent in the source (unknown categories), i.e., open-set DA (ODA) [3, 28], the source domain including classes absent in the target (source-private categories), i.e., partial DA (PDA) [4], or a mixture of ODA and PDA, called open-partial DA (OPDA).
Although many approaches have been tailored to a spe-cific setting, we cannot know the category shift in advance, which is an actual difficulty. To account for the uncertainty about the category shift, the task of universal domain adap-tation (UNDA) is proposed [38, 26]. The assumption is that the label distributions of labeled and unlabeled data can dif-fer, but we do not know the difference in advance. UNDA is a uniform and practical setting for novel category discovery since estimating the label distributions of unlabeled data is very hard in real applications.
The two main objectives of ODA and UNDA tasks are feature transfer and novel category discovery. However, the current methods have limitations in achieving both ob-jectives, which hinders further improvement of these tasks.
Specific problems are depicted in Fig. 1.
The view-noise problem in data augmentation affects the feature transfer. Recently, data-augmentation-based contrastive learning (CL) has been used for unsupervised
Figure 1: Problem demonstration and solutions. (a) View-noise problem in the backbone network fine-tuned by the CL. (a)-top shows the views generated by the same data augmentation scheme across three different domains. The difference in content style of the Clipart domain causes the regular data augmentation to produce views with vastly different semantics, producing noisy pairs. (b) Overconfidence problem of novel category classifiers. The dashed circle with a tick/cross means the test samples are classified correctly/incorrectly. fine-tune and has yielded excellent results in various down-stream tasks [7, 41, 40]. Therefore, several studies [39, 6] have attempted to enhance UNDA by introducing CL. How-ever, these approaches are not based on data-augmentation-based CL schemes but are based on neighbor relationships of the original data. Although view noise in CL has started to receive attention in network fine-tuning [9], the view noise problem in UNDA cannot be seen as similar to it.
Domain differences of data in UNDA introduce drastic and persistent view noise and cause more severe damage.
As shown in the top of Fig. 1 (a), a more severe view-noise problem occurs if the same augmentation scheme is used in different domain data. In detail, view 1 (v1) and view 2 (v2) are specific augmentation results across all doamins.
In ‘product’ domain and ‘art’ domain, v1 and v2 have similar semantics, noted as positive pairs, but they have different semantics in the ‘clipart’ domain, noted as noise pairs. The noise pairs contradict the accurate semantic information and, therefore, generate false gradients that cor-rupt the network training. More importantly, other data aug-mentation strategies, such as color perturbation, also lead to divergent semantic changes in different domains, leading to the view-noise problem. Addressing view-noise problem of cross-domain data augmentation training can further release the potential of CL on transfer learning.
Overconfidence problem of classifiers (closed-set clas-sifier and open-set classifier) affects novel category recognition performance. Recently, OVANet [27] and its variants [35] have received much attention. These meth-ods combine closed-set classifiers and open-set classifiers to identify known and unknown classes. However, each of the open-set classifiers only corresponds to a single known class. When determining whether a sample belongs to a novel class, the open-set classifier does not compete with other open-set classifiers. It only determines whether the output of this classifier is greater than a certain threshold.
This counter-intuitive strategy causes insufficient inter-class competition, which in turn leads to classifiers that are more likely to fall into overfitting and overconfidence. When la-bel noise is present in the source domain, such data is almost inevitable and the harmful effects of overconfidence are am-plified. As shown at the top of Fig. 1 (b), even though the closed-set classifier is not affected by label-noise, the classi-fication boundary of the open-set classifier can become very sharp due to label-noise and overfitting issues, which even-tually causes the target domain samples to be misclassified.
To address the challenges mentioned above, we propose the Soft-contrastive All-in-one Network (denoted as SAN) for both UNDA and ODA.
For view-noise problem, we introduce a soft contrastive learning (SCL) loss. Unlike the commonly used contrastive learning (CL) loss, our SCL loss considers the similarity of views in the latent space to assess the reliability of the view.
This enables us to construct a more effective loss function by incorporating reliability. In Fig. 1(a), we compare our
SCL loss to the CL loss in dealing with noise pair data and demonstrate that our SCL loss effectively reduces the influ-ence of noise pairs on the model.
For overconfidence problem of independent classi-fiers. An all-in-one (AIO) classifier is designed to re-place the closed-set classifier and open-set classifier. The decision-making process of the AIO classifier is closer to that of humans. The AIO classifier assumes that identifying a sample belonging to a novel category requires determin-ing that it does not belong to any known classes. Based on this assumption, a new loss function has been defined to train the AIO classifier. As shown in (b3) and (b4) of
Figure 1, as a result, the AIO classifier has smoother classi-fication boundaries and reduces the adverse effects of label noise by introducing more comprehensive competition.
In experiments, we extensively evaluate our method on
ODA and UNDA benchmarks and vary the proportion of unknown classes. The results show that the proposed SAN outperforms all baseline methods on various datasets of the
ODA and UNDA tasks. 2.