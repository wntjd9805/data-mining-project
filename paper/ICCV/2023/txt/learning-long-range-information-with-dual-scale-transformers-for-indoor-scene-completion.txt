Abstract
Due to the limited resolution of 3D sensors and the in-evitable mutual occlusion between objects, 3D scans of real scenes are commonly incomplete. Previous scene comple-tion methods struggle to capture long-range spatial context, resulting in unsatisfactory completion results. To alleviate the problem, we propose a novel Dual-Scale Transformer
Network (DST-Net) that efficiently utilizes both long-range and short-range spatial context information to improve the quality of 3D scene completion. To reduce the heavy com-putation cost of extracting long-range features via trans-formers, DST-Net adopts a self-supervised two-stage com-pletion strategy. In the first stage, we split the input scene into blocks and perform completion on individual blocks. In the second stage, the blocks are merged together as a whole and then further refined to improve completeness. More importantly, we propose a contrastive attention training strategy to encourage the transformers to learn distinguish-able features for better scene completion. Experiments on datasets of Matterport3D, ScanNet, and ICL-NUIM demon-strate that our method can generate better completion re-sults, and our method outperforms the state-of-the-art meth-ods quantitatively and qualitatively. 1.

Introduction
Indoor 3D reconstruction is an essential part of many ap-plications like AR/VR [19, 1], building information mod-eling (BIM)
[24, 32], automatic robot indoor navigation
[14] and so on [36, 38]. Due to the limited resolution of 3D sensors and the inevitable occlusion between objects in the scene, there always exist incomplete surfaces in the recon-struction results.
Recently, scene 3D completion based on deep learning
*Fei Luo and Chunxia Xiao are co-corresponding authors
â€ Xiaoxiao Long was interning at Wuhan University (a) Input (b) SG-NN (c) SPSG (d) Ours
Figure 1: Indoor scene completion on one case in the Mat-terport3D dataset. Comparison with the state-of-the-art methods SG-NN [6] and SPSG [8]. has made great progress. Dai et al.
[6] proposed a self-supervised method called SG-NN to complete the indoor scene with incomplete real-world scan data, which can get a more complete result compared to the training data. Dai et al. [8] further proposed SPSG to complete the 3D surface and texture. Most of the current methods use convolutional neural networks (CNN) for completion and achieve impres-sive progress. Nonetheless, receptive fields in CNN remain local at a certain resolution, limiting its ability to capture long-range information. This is very important for the scene completion task with incomplete inputs.
Recently, Vision Transformer (ViT) [27, 18, 10] has made great stride in the computer vision field, owing to its ability to sense long-range information. For the task of single object 3D completion, some methods [30,
33, 34] achieved better point cloud completion by using transformer-based architecture to extract global information with a spatial attention mechanism. However, there is few attempt to apply transformer to the task of large-scale scene completion, since the large-scale scenes contain complex layouts and various objects.
In this work, to use long-range information to handle large missing areas and precise completion of geometric shape in the scene, we propose a Dual-Scale Transformer
Network (DST-Net) and apply it in a two-stage manner.
Specifically, in the first stage, we use DST-Net to complete the blocks split from an incomplete scene, then merge the complete geometric blocks to get the entire scene output.
However, the generated results still have some small holes in local areas. To tackle it, in the second stage, we utilize scene-level information to refine the output scene of stage 1. In this stage, we fuse the ground truth and the first stage output as the supervision signal to focus on learning prob-lematic areas and ensure the consistency of learning.
It is difficult to obtain satisfactory performance when ap-plying transformer for scene completion, as the long-range and sparse incomplete information is more difficult to learn.
To solve this problem, our proposed DST-Net involves spe-cific transformer modules for different-level scene informa-tion. Furthermore, we propose a contrastive attention train-ing strategy to make the DST-Net efficiently learn similar and distinguishable shape features. Our method includes a structure loss to improve the accuracy of geometric struc-ture, and a CIoT (Cube Intersection over Target) loss to en-sure complete output voxels. One comparison case between the state-of-the-art methods and ours is illustrated in Fig. 1.
In summary, our contributions are as follows : 1. We propose a novel Dual-Scale Transformer Network (DST-Net) for indoor scene surface completion. We con-duct completion operations from the block level to the scene level to achieve better completion performance. 2. We propose a contrastive attention training strategy to make the transformer work robustly in scene completion. In addition, we propose a structure loss to improve the accu-racy of geometric shapes and a CIoT loss to make the scene more complete. 2.