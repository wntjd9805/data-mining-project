Abstract 1.

Introduction
Weakly-supervised image segmentation has recently at-tracted increasing research attentions, aiming to avoid the expensive pixel-wise labeling.
In this paper, we present an effective method, namely Point2Mask, to achieve high-quality panoptic prediction using only a single random point annotation per target for training. Specifically, we for-mulate the panoptic pseudo-mask generation as an Optimal
Transport (OT) problem, where each ground-truth (gt) point label and pixel sample are defined as the label supplier and consumer, respectively. The transportation cost is calcu-lated by the introduced task-oriented maps, which focus on the category-wise and instance-wise differences among the various thing and stuff targets. Furthermore, a centroid-based scheme is proposed to set the accurate unit number for each gt point supplier. Hence, the pseudo-mask genera-tion is converted into finding the optimal transport plan at a globally minimal transportation cost, which can be solved via the Sinkhorn-Knopp Iteration. Experimental results on
Pascal VOC and COCO demonstrate the promising per-formance of our proposed Point2Mask approach to point-supervised panoptic segmentation. Source code is available at: https://github.com/LiWentomng/Point2Mask.
Panoptic segmentation aims to obtain the pixel-wise la-bels of instance things and semantic stuff in the whole im-age, which plays an important role in applications such as autonomous driving, image editing and robotic ma-nipulation. Although having achieved promising perfor-mance, most of the existing panoptic segmentation ap-proaches [29, 10, 51, 8, 20, 47] are trained in a fully su-pervised manner, which heavily depend on the pixel-wise mask annotations, incurring expensive labeling costs.
To deal with this problem, weakly-supervised methods have recently attracted research attentions to obtain high-quality pixel-wise masks with label-efficient sparse anno-tations, such as bounding box [43, 26, 22, 27], multiple points [28], or the combination of them [9, 41]. Such meth-ods make image segmentation more accessible with lower annotation efforts for new categories or scene types.
In this paper, we explore a simpler yet more efficient anno-tation form, i.e., a single random point for each thing and stuff target, to achieve high-quality panoptic segmentation.
As discussed in [2], the cost of point-level labels is only marginally above image-level ones 1. Such a setting has 1On Pascal VOC [14], image labels cost around 20 sec./img, single point labels cost 22.1 sec./img, while full mask labels cost 239.7 sec./img.
at a globally minimal transportation cost, which can be ef-ficiently solved via the Sinkhorn-Knopp Iteration [12]. By making use of the pseudo-mask labels, the panoptic seg-mentation sub-network is optimized in a fully-supervised manner. The proposed Point2Mask method is an end-to-end training framework, where only the fully-supervised sub-network is retained for inference. Extensive experi-ments are conducted on Pascal VOC [14] and COCO [31] benchmarks, and the promising qualitative and quantitative results demonstrate the effectiveness of our proposed ap-proach. Notably, Point2Mask surpasses the state-of-the-art method [15] by 4.0% PQ on Pascal VOC and 3.1% PQ on COCO with the same ResNet-50 backbone [18], and achieves comparable performance with the fully-supervised methods using the Swin-L backbone [32]. Some qualitative results are shown in Fig. 1. 2.