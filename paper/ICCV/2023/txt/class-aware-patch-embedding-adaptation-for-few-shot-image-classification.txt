Abstract
“A picture is worth a thousand words”, significantly be-yond mere a categorization. Accompanied by that, many patches of the image could have completely irrelevant meanings with the categorization if they were indepen-dently observed. This could significantly reduce the effi-ciency of a large family of few-shot learning algorithms, which have limited data and highly rely on the compari-son of image patches. To address this issue, we propose a
Class-aware Patch Embedding Adaptation (CPEA) method to learn “class-aware embeddings” of the image patches.
The key idea of CPEA is to integrate patch embeddings with class-aware embeddings to make them class-relevant. Fur-thermore, we define a dense score matrix between class-relevant patch embeddings across images, based on which the degree of similarity between paired images is quantified.
Visualization results show that CPEA concentrates patch thus making them class-relevant. embeddings by class,
Extensive experiments on four benchmark datasets, mini-ImageNet, tieredImageNet, CIFAR-FS, and FC-100, indi-cate that our CPEA significantly outperforms the existing state-of-the-art methods. The source code is available at https://github.com/FushengHao/CPEA. 1.

Introduction
Real-world images are usually composed of many dif-ferent entities, e.g., two oxen grazing surrounded by a barn, a fence and trees as shown in Figure 1. Assigning a sin-gle annotation to each image that corresponds to only one type of entity is a common practice to construct computer vision datasets, e.g., CIFAR [33] and ImageNet [54]. Such an annotation can only describe part of an image’ contents.
This is acceptable in many classification scenarios, because the interference caused by other image contents can be mit-*Corresponding author (email: jun.cheng@siat.ac.cn).
Figure 1. Illustration of multiple entities from different classes si-multaneously existing in a real-world image. Despite being anno-tated as “ox”, the image contains entities of other classes, such as
“fence”, “barn”, “tree”, etc. The core idea of CPEA is to learn
“class-aware embeddings” of the image patches. igated by the use of a large number of labeled images.
Specifically, since each class contains a sufficient number of labeled images that vary greatly within the class and the corresponding entities always appear in these images, deep models trained on such data tend to pay attention to the fre-quently occurring class-relevant entities (e.g., “ox” in Fig-ure 1) while ignoring other irrelevant ones, especially those that frequently appear across classes [26].
Big challenges, however, arise in the context of few-shot image classification, in which approaches are expected to correctly identify new classes that are disjoint with the train-ing classes during the test phase, given only a few (e.g., one or five) labeled images for each of these new classes. The challenges are as follows: 1) Due to the scarcity of labeled images of new classes and the extremely limited number of class-relevant entities, it is very difficult for a model to identify which entity determines the class of an image. 2)
Entities contained in the training images but not covered by the training classes may happen to be the ones expected to be covered by the new classes at test time, which would in-troduce ambiguity. 3) Specific patterns learned during the training phase may be overemphasized, but they may not
be relevant to the new classes seen at test time, resulting in supervision collapse [14] and limited generalizability.
A promising solution is to align semantically-relevant regions [24, 27, 70, 14, 26]. SAML [24] proposes to use the activation-based attention to highlight semantically-relevant regions while suppressing others. CAN [27] per-forms cross-attention between class prototypes and query feature maps to highlight class-relevant regions. Deep-EMD [70] looks for the aligned regions by minimizing the earth movers’ distance. CTX [14] uses a Transformer-style attention mechanism to perform the spatial and semantic alignment and mitigates supervision collapse by incorpo-rating self-supervised learning in training. FewTURE [26] determines the most informative regions via online opti-mization and then uses them to reweigh patch correspon-dences. While these methods have shown great potential in eliminating interference and tackling supervision col-lapse, there still exist crucial drawbacks. Firstly, aligned semantically-relevant regions are not always beneficial for similarity measure, such as those that are irrelevant to the class of interest. Secondly, the scarcity of labeled images of new classes and the extremely limited number of class-relevant entities makes it difficult to deal with the inaccurate localization and alignment induced by large intra-class vari-ation and background clutter in real-world images.
In this paper, we deal with the above challenges from a new perspective and propose a Class-aware Patch Em-bedding Adaptation (CPEA) method that can eliminate the interference of single-label annotations without aligning semantically-relevant regions while avoiding supervision collapse. Specifically, we employ self-supervision pretrain-ing instead of the supervised one to avoid supervision col-lapse, with Masked Image Modelling [76] as a pretext task, which yields semantically meaningful patch embeddings.
Since the patch embeddings may be irrelevant to class of interest, this leads to the need for aligning semantically-relevant patches. We avoid the need for localization and alignment mechanisms by making patch embeddings class-relevant. To this end, we introduce a class-agnostic embed-ding and feed it into the transformer to interact with patch embeddings to make it class-aware. Then, patch embed-dings are adapted with the class-aware embeddings to make them class-relevant, which alleviates the scarcity of labeled images by increasing their amount. Furthermore, we define a dense score matrix between class-relevant patch embed-dings across images, based on which the degree of similar-ity between paired images is quantified.
Our main contributions are summarized as follows: 1)
We deal with the interference caused by single-label an-notations in few-shot settings from a new perspective and demonstrate that the interference can be successfully miti-gated without the need for localization and alignment mech-anisms. 2) We propose the CPEA, a novel method that makes patch embeddings class-relevant and measures the similarity between class-relevant patch embeddings across images in a dense manner, which improves transferability. 3) Visualizations show that our CPEA makes patch embed-dings class-relevant. Extensive experiments are conducted on four popular benchmark datasets and the results indi-cate that our CPEA achieves superior performance over the state-of-the-art methods. 2.