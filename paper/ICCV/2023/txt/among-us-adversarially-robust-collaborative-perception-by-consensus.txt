Abstract
Multiple robots could perceive a scene (e.g., detect ob-jects) collaboratively better than individuals, although eas-ily suffer from adversarial attacks when using deep learn-ing. This could be addressed by the adversarial defense, but its training requires the often-unknown attacking mecha-nism. Differently, we propose ROBOSAC, a novel sampling-based defense strategy generalizable to unseen attackers.
Our key idea is that collaborative perception should lead to consensus rather than dissensus in results compared to indi-vidual perception. This leads to our hypothesize-and-verify framework: perception results with and without collabora-tion from a random subset of teammates are compared until reaching a consensus.
In such a framework, more team-mates in the sampled subset often entail better perception performance but require longer sampling time to reject po-tential attackers. Thus, we derive how many sampling tri-als are needed to ensure the desired size of an attacker-free subset, or equivalently, the maximum size of such a subset that we can successfully sample within a given number of trials. We validate our method on the task of collaborative 3D object detection in autonomous driving scenarios. 1.

Introduction
Perception is a fundamental capability for autonomous robots to understand their surroundings [1–3]. Single-robot perception suffers from long-range or occlusion is-sues which stem from limited sensing capabilities and in-adequate individual viewpoints [4]. Therefore, collabora-tive perception (co-perception) is proposed to provide more viewpoints for each robot via communication, so that robots can see further and better [5–7].
In literature, raw-data-level and decision-level fusion both demonstrate satisfactory performance in terms of ro-bustness and precision [8, 9]. The recent development of deep learning has revolutionized many fields including
*indicates equal contribution
†Corresponding author. The work is supported by NSF grants 2238968 and 2026479.
Figure 1: Overview of ROBOSAC. Ego-robot aims to find several benign collaborators with a hypothesize-and-verify procedure until reaching a consensus or using up the sam-pling budget. Consensus is checked between the results with and without the selected teammates. robotic perception, and feature-level fusion has been pro-posed in which intermediate representations from a deep neural network (DNN) are shared amongst robots. Un-like raw-data-level and decision-level fusion approaches, feature-level fusion presents the advantages of good com-pressibility and the preservation of contextual information, further enhancing the performance-bandwidth trade-off in multi-robot perception [5, 10–12].
Although the original motivation for collaborative per-ception is to promote resilience and robustness via infor-mation sharing, the communication channel could poten-tially become a wide-open backdoor in DNN-based percep-tion models due to the well-known adversarial vulnerability of DNNs [13]. Prior work has shown that a maliciously-crafted imperceptible perturbation added on the shared fea-ture can drastically alter the perception output, jeopardizing the perception system [14]. To solve the safety concerns, adversarial training has been exploited [14], yet it intro-duces extra overhead during training and fails to generalize
to unseen attackers [15]. Besides, adversarial training may lead to a small loss of accuracy [16]. In a word, it is still non-trivial to achieve computationally-efficient and gener-alizable adversarial defense in collaborative perception.
In this work, different from applying adversarial train-ing after indiscriminately using all messages, we propose to enable the ego-robot to intelligently select benign col-laborators from teammates, instead of naively trusting all the teammates.
Inspired by random sample consensus (RANSAC) in robust estimation [17], we propose ROBust cOllaborative SAmple Consensus (ROBOSAC), a general sampling-based framework for adversarially robust collab-orative perception. Our key idea is that the robot is sup-posed to reach a consensus with its teammates after collab-oration, rather than largely diverging from its individual per-ception. Specifically, ROBOSAC utilizes the hypothesize-and-verify workflow: the robot samples a subset of team-mates and compares the results with and without the sam-pled teammates. After the consensus is verified, indicat-ing no attackers among us, the robot can output the per-ceptual results generated in collaboration with teammates for further decision-making, as shown in Fig. 1. Differ-ent from the widely-used adversarial training, ROBOSAC is attacker-agnostic and thus can easily generalize to unseen adversarial learning algorithms.
Meanwhile, ROBOSAC can be customized for either strong performance or high efficiency: as more benign teammates leading to better performance require more com-putation to reject the attackers, there exists a performance-computation trade-off in ROBOSAC. Formally, under vari-ous attacker ratios, we can compute the maximum number of attacker-free collaborators that could be found given a spe-cific sampling budget, and the upper bound of the number of sampling ensuring a desired number of benign teammates, all for achieving a guaranteed consensus probability. Addi-tionally, we propose an adaptive probing approach to handle the scenario of unknown attacker ratios, starting from trust-ing all the teammates and then gradually becoming more vigilant. Our contributions are summarized as:
• We develop ROBOSAC, a scalable, generalizable, and generally-applicable adversarially robust collaborative perception framework via multi-robot consensus.
• We propose aggressive-to-conservative probing (A2CP) with retrospect to estimate the attacker ratio efficiently.
• We conduct experiments on collaborative 3D object de-tection in safety-critical autonomous driving to validate the effectiveness of ROBOSAC. 2.