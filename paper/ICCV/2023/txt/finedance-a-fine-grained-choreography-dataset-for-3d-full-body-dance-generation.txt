Abstract
Generating full-body and multi-genre dance sequences from given music is a challenging task, due to the limita-tions of existing datasets and the inherent complexity of the fine-grained hand motion and dance genres.
To address these problems, we propose FineDance, which contains 14.6 hours of music-dance paired data, with fine-grained hand motions, fine-grained genres (22 dance genres), and accurate posture. To the best of our knowledge, FineDance is the largest music-dance paired dataset with the most dance genres. Additionally, to address monotonous and unnatural hand movements existing in previous methods, we propose a full-body dance generation network, which utilizes the diverse generation capabilities of the diffusion model to solve monotonous problems, and use expert nets to solve unreal problems. To further enhance the genre-matching and long-term stability of generated dances, we
∗ equal contribution, † corresponding author propose a Genre&Coherent aware Retrieval Module. Be-sides, we propose a novel metric named Genre Match-ing Score to evaluate the genre-matching degree between dance and music. Quantitative and qualitative experiments demonstrate the quality of FineDance, and the state-of-the-art performance of FineNet. The FineDance Dataset and more qualitative samples can be found at website. 1.

Introduction
Music and dance are two enduring art forms that can ex-press a wide range of human emotions, and they have be-come essential elements in modern entertainment industries such as concerts, movies, and games[11]. However, creat-ing high-quality 3D dance animations can be a costly and complex process that often involves skilled dancers, engi-neers, and expensive motion-capture equipment[5]. As a re-sult, there is growing interest in using artificial intelligence (AI) to generate 3D dance animations from music, which 1
has become a rapidly developing research topic.
Despite the wide range of research in this field [19, 14, 22, 21, 2, 49, 35, 5, 44, 36, 25, 46, 47], enerating high-quality dances is still limited by the existing datasets: (1)
Full-body expressiveness: Existing dance datasets contain few hand movements, and only 1.5 hours of full body dance data is available. The previous methods in motion genera-tion, treating body and hand as the same, lead to unnatural or monotonous hand motions, because the body and hand are in different feature spaces. However, uncoordinated body and hand motions can destroy the expressiveness of the overall dance. (2) Multi-genre: Existing datasets con-tain a limited number of dance genres, so the generated dances are not sufficient to match various music styles. Pre-vious methods struggle with limited coarse dance genres and have no suitable objective metric to measure the genre-matching degree between music and generated dances.
To address the limitations of existing datasets, we introduce a Fine-grained Choreography Dance dataset (FineDance).
It comprises over 14.6 hours of data col-lected from 346 paired songs and dances, was created by professional dancers and a motion capture system, which has accurate body and hand motions. The fine-grained 22 dance genres of FineDance spanning traditional and mod-ern styles, which make the genre-matching of generated dance sequences and given music become more challeng-ing. FineDance includes music, dance sequences, FilmBox (fbx) files, SMPL[23, 29], and multi-view videos.
Early music-driven dance synthesis methods [3, 16, 24, 32, 15, 35, 2, 48] often rely on motion graph-based al-gorithms where the dance fragments from a pre-existing music-dance database are stitched together to synthesize one dance. While such methods can synthesize long-term dances, they do not produce new dance fragments. Re-cently methods have employed generative networks such as VAE[33], GAN[30], Normalization Flow Network[40],
Diffusion[38]. But they focus solely on body part, while resulting in unnatural or neglecting hand movements, monotonous hand motions even trained with well-annotated body and hand labels. Additionally, the generative-based methods are limited by the long-term modeling ability of the networks, making them difficult to generate long-term dance sequences.
Therefore, we propose FineNet, a two-stage generative-synthesis network that addresses the limitations of pre-vious dance generation methods.
In the first stage, we propose a diffusion-based Full-body dance generation net-work (FDGN). The key of FDGN is to design two ex-pert networks, which are dedicated to the generation of body and hand motions, and use a Refine Net to assem-In the second stage, we propose ble them coordinately. a Genre&Coherence aware Retrieval Module (GCRM), which ensures the coherence of dance fragments and matches the genre between the music and the dances. Based on the suitable dance fragments retrieved by GCRM, we can produce genre-matching and long-term dances. A concep-tual overview of the dataset and method is shown in Fig-ure1. Finally, to objectively evaluate the genre-matching degree between generated dances and given music, we pro-pose a novel metric, named Genre-matching Score (GS).
Overall, our contributions can be summarized as follows:
• We release FineDance, which is the largest 3D mo-tion capture music-dance paired dataset with accurate full-body posture, containing 22 fine-grained genres.
FineDance encourages the development of AI chore-ography, motion prior, and full-body reconstruction methods.
• We present FineNet, which leverages expert networks and refine network to generate expressive full-body dances, and employs a cross-modal retrieval network to improve genre-matching scores.
• Extensive quantitative experiments and user studies demonstrate that our approach can generate multiple different genre-matched dances from arbitrary music with natural and flexible hand movements. 2.