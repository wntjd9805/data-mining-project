Abstract 1.

Introduction
Self-supervised monocular depth estimation (SS-MDE) has the potential to scale to vast quantities of data. Unfortu-nately, existing approaches limit themselves to the automo-tive domain, resulting in models incapable of generalizing to complex environments such as natural or indoor settings.
To address this, we propose a large-scale SlowTV dataset curated from YouTube, containing an order of magnitude more data than existing automotive datasets. SlowTV con-tains 1.7M images from a rich diversity of environments, such as worldwide seasonal hiking, scenic driving and scuba diving. Using this dataset, we train an SS-MDE model that provides zero-shot generalization to a large col-lection of indoor/outdoor datasets. The resulting model out-performs all existing SSL approaches and closes the gap on supervised SoTA, despite using a more efficient architecture.
We additionally introduce a collection of best-practices to further maximize performance and zero-shot generaliza-tion. This includes 1) aspect ratio augmentation, 2) cam-era intrinsic estimation, 3) support frame randomization and 4) flexible motion estimation. Code is available at https://github.com/jspenmar/slowtv_monodepth.
Reliably reconstructing the 3-D structure of the envi-ronment is a crucial component of many computer vision including autonomous driving, robotics, aug-pipelines, mented reality and scene understanding. Despite being an inherently ill-posed task, monocular depth estimation (MDE) has become of great interest due to its flexibility and applicability to many fields.
While traditional supervised methods achieve impressive results, they are limited both by the availability and qual-ity of annotated datasets. LiDAR data is expensive to col-lect and frequently exhibits boundary artefacts due to mo-tion correction. Meanwhile, Structure-from-Motion (SfM) is computationally expensive and can produce noisy, incom-plete or incorrect reconstructions. Self-supervised learning (SSL) instead leverages the photometric consistency across frames to simultaneously learn depth and Visual Odome-try (VO) without ground-truth annotations. As only stereo or monocular video is required, SSL has the potential to scale to much larger data quantities.
Unfortunately, existing SS-MDE approaches have relied exclusively on automotive data [18, 13, 24]. The limited di-versity of training environments results in models incapable
of generalizing to different scene types (e.g. natural or in-doors) or even other automotive datasets. Moreover, despite being fully convolutional, these models struggle to adapt to different image sizes. This further reduces performance on sources other than the original dataset.
Inspired by the recent success of supervised MDE [36, 47, 46], we develop an SS-MDE model capable of perform-ing zero-shot generalization beyond the automotive domain.
In doing so, we aim to bridge the performance gap between supervision and self-supervision. Unfortunately, most exist-ing supervised datasets are unsuitable for SSL, as they con-sist of isolated image and depth pairs. On the other hand, existing SSL datasets focus only on the automotive domain.
To overcome this, we make use of SlowTV as an un-tapped source of high-quality data. SlowTV is a television programming approach originating from Norway consist-ing of long, uninterrupted shots of relaxing events, such as train or boat journeys, nature hikes and driving. This rep-resents an ideal training source for SS-MDE, as it provides large quantities of data from highly diverse environments, usually with smooth motion and limited dynamic objects.
To improve the diversity of available data for SS-MDE, we have collated the SlowTV dataset, consisting of 1.7M frames from 40 videos curated from YouTube. This dataset consists of three main categories—natural, driving and underwater—each featuring a rich and diverse set of scenes.
We combine SlowTV with Mannequin Challenge [31] and
Kitti [18] to train our proposed models. SlowTV provides a general distribution across a wide range of natural scenes, while Mannequin Challenge covers indoor scenes with hu-mans and Kitti focuses on urban scenes. The resulting mod-els are trained with an order of magnitude more data than any existing SS-MDE approach. Contrary to many super-vised approaches [4, 72], we train a single model capable of generalizing to all scene types, rather than separate in-door/outdoor models. This closely resembles the zero-shot evaluation proposed by MiDaS [47] for supervised MDE.
The contributions of this paper can be summarized as: 1. We introduce a novel SS-MDE dataset of SlowTV
YouTube videos, consisting of 1.7M images.
It fea-tures a diverse range of environments including world-wide seasonal hiking, scenic driving and scuba diving. 2. We leverage SlowTV to train zero-shot models capable of adapting to a wide range of scenes. The models are evaluated on 7 datasets unseen during training. 3. We show that existing models fail to generalize to dif-ferent image shapes and propose an aspect ratio aug-mentation to mitigate this. 4. We greatly reduce the performance gap w.r.t. super-vised models, improving the applicability of SS-MDE to the real-world. We make the dataset, pretrained model and code available to the public. 2.