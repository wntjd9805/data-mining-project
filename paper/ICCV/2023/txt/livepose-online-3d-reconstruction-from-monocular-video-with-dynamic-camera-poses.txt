Abstract 1.

Introduction
Dense 3D reconstruction from RGB images tradition-ally assumes static camera pose estimates. This assump-tion has endured, even as recent works have increasingly focused on real-time methods for mobile devices. How-ever, the assumption of a fixed pose for each image does not hold for online execution: poses from real-time SLAM are dynamic and may be updated following events such as bundle adjustment and loop closure. This has been ad-dressed in the RGB-D setting, by de-integrating past views and re-integrating them with updated poses, but it remains largely untreated in the RGB-only setting. We formalize this problem to define the new task of dense online reconstruc-tion from dynamically-posed images. To support further re-search, we introduce a dataset called LivePose 1 containing the dynamic poses from a SLAM system running on Scan-Net [6]. We select three recent reconstruction systems and apply a framework based on de-integration to adapt each one to the dynamic-pose setting. In addition, we propose a novel, non-linear de-integration module that learns to re-move stale scene content. We show that responding to pose updates is critical for high-quality reconstruction, and that our de-integration framework is an effective solution. 1https://github.com/apple/ml-live-pose
RGB-only reconstruction using a monocular camera has seen great progress using learned priors to address the dif-ficulties associated with low-texture regions and the inher-ent ambiguity of image-based reconstruction. In particular, there has been strong interest in methods that are practical for real-time execution, a key component required for in-teractive applications on mobile devices. However, there is an additional requirement that has not been addressed in recent state-of-the-art reconstruction systems: a successful method must not only be real-time but also online.
Online operation implies that an algorithm must produce accurate incremental reconstructions at the time of image acquisition, using only past and present observations at each time point. This problem setting violates a key assumption made by existing works: the availability of an accurate, fully-optimized pose estimate for each view. Instead, in a real-world scanning scenario, a Simultaneous Localization and Mapping (SLAM) system suffers pose drift, resulting in a stream of dynamic pose estimates, where past poses are updated due to events such as pose graph optimization and loop closure. As detailed in Section 5, such pose updates from SLAM are ubiquitous in online scanning. It is critical for the reconstruction to stay in agreement with the SLAM system by respecting these updates, as we have illustrated in Figure 1.
Recent works on dense RGB-only reconstruction, how-ever, have not addressed the dynamic nature of camera pose estimates in online applications [2, 8, 18, 19, 23, 24]. Al-though these efforts have made great progress in reconstruc-tion quality, they have preserved the traditional problem formulation of statically-posed input images, providing no explicit mechanism for handling dynamic poses.
In con-trast, we acknowledge the presence of these updates, and we propose a solution by which existing RGB-only methods can incorporate pose update handling. We draw inspiration from BundleFusion [7], an RGB-D method that integrates new views into the scene with a linear update rule, such that past views can be de-integrated and re-integrated when an updated pose becomes available.
In this paper, we propose to use de-integration as a gen-eral framework for handling pose updates in online recon-struction from RGB images. We study three representa-tive RGB-only reconstruction methods that have assumed static poses [8, 18, 24]. For each method, we apply the de-integration framework as detailed in Section 4 to address its limitations with respect to the online setting. In particular, we develop a novel, non-linear de-integration method based on deep learning to support online reconstruction for meth-ods such as NeuralRecon [24] that use a learned, non-linear update rule. To validate this methodology and support fu-ture research, we release a novel and unique dataset called
LivePose, featuring complete, dynamic pose sequences for
ScanNet [6], generated using BundleFusion [7]. In our ex-periments (Section 6) we demonstrate the effectiveness of the de-integration approach, showing qualitative and quan-titative improvement among three state-of-the-art systems with respect to key reconstruction metrics.
Contributions. Our main contributions are as follows:
• We introduce and formalize a new vision task, dense online 3D reconstruction from dynamically-posed
RGB images, that more closely reflects the real-world setting for interactive applications on mobile devices. the first publicly-available dataset of dynamic SLAM pose estimates, containing the full SLAM pose stream for all 1,613 scans in the
ScanNet dataset.
• We release LivePose:
• We develop novel training and evaluation protocols to support reconstruction with dynamic poses.
• We propose a novel recurrent de-integration module that learns to handle pose updates by removing stale scene content, enabling dynamic-pose handling for methods with learned, recurrent view integration. 2.