Abstract
Neural radiance fields (NeRF) have garnered significant at-tention, with recent works such as Instant-NGP accelerat-ing NeRF training and evaluation through a combination of hashgrid-based positional encoding and neural networks.
However, effectively leveraging the spatial sparsity of 3D scenes remains a challenge. To cull away unnecessary re-gions of the feature grid, existing solutions rely on prior knowledge of object shape or periodically estimate object shape during training by repeated model evaluations, which are costly and wasteful. To address this issue, we propose
HollowNeRF, a novel compression solution for hashgrid-based NeRF which automatically sparsifies the feature grid during the training phase. Instead of directly compressing dense features, HollowNeRF trains a coarse 3D saliency mask that guides efficient feature pruning, and employs an alternating direction method of multipliers (ADMM) pruner to sparsify the 3D saliency mask during training. By ex-ploiting the sparsity in the 3D scene to redistribute hash collisions, HollowNeRF improves rendering quality while using a fraction of the parameters of comparable state-of-the-art solutions, leading to a better cost-accuracy trade-off. Our method delivers comparable rendering quality to
Instant-NGP, while utilizing just 31% of the parameters. In addition, our solution can achieve a PSNR accuracy gain of up to 1dB using only 56% of the parameters. 1.

Introduction
Neural Radiance Fields (NeRF [1, 15]) have gained widespread recognition across academia and industry due to their remarkable capability to generate photorealistic novel views of 3D scenes from a collection of 2D images.
In-spired by the volumetric representation, NeRF models the scene as a continuous 5D plenoptic function, enabling the creation of high-fidelity renderings with accurate lighting and shading effects. This technique has found versatile ap-Figure 1: Cross-section views of rendered 3D scenes. The left column shows the hollow interior of HollowNeRF’s rendering, while the middle column shows the solid inte-rior of Instant-NGP’s rendering. The right column displays
HollowNeRF’s rendering without slicing. plications in fields such as computer graphics, virtual and augmented reality, as well as robotics.
Training and evaluating NeRF models can be computa-tionally expensive, and many recent works [20, 16, 4, 22, 18, 23] have focused on improving the efficiency of NeRF.
Instant-NGP [16] is an established solution with state-of-the-art training speed. It employs a lightweight hashgrid for input encoding and a small multi-layer perceptron (MLP) to disambiguate hash collisions. However, the lightweight hashgrid unavoidably causes severe collisions at fine reso-lutions. These collisions are evenly scattered across the oc-cupied voxels, resulting in a suboptimal accuracy. Another line of research focuses on accelerating NeRF rendering by only sampling near the surface of interest, but has to rely on prior knowledge of surface geometries (either from conven-tional algorithms such as shape-from-silhouette [13] or an
MLP predicting the depth distribution along each camera ray [18]). However, a coarse surface estimation degrades
NeRF rendering quality, while a precise surface estimation adds too much complexity, defeating the purpose of accel-eration.
We propose HollowNeRF, a novel NeRF compression method using trainable hash collision mitigation to improve rendering accuracy while consuming less parameters than existing NeRF methods. Built on a hash-based pipeline from Instant-NGP, HollowNeRF prioritizes the important features (of visible voxels) and prunes unnecessary features (of invisible voxels), leading to a redistribution of hash col-lision probability across the 3D volume. When two vox-els direct to the same hash bucket, Instant-NGP shapes the shared feature in this bucket as a mixture of the desired features, which harms the accuracy. In contrast, Hollow-NeRF steers the shared feature to fit the more important voxel, and prunes the feature of the less important voxel to-ward 0, reducing interference to features sharing the same bucket. Specifically, when reading the feature of a certain voxel, HollowNeRF further scales the feature by a train-able saliency weight whose value captures the voxel’s visi-bility. To reduce the cost, we divide the 3D space into coarse grid regions and assign a saliency weight to capture each re-gion’s visibility, forming a trainable 3D saliency grid. Un-like existing methods [13, 18] that require prior knowledge of the surface geometries, HollowNeRF learns to prioritize the important features by training the saliency grid, which converges to a “hollow” saliency distribution across the 3D volume. Figure 1 showcases this “hollow” rendering result.
The proposed design consists of three main components: a trainable 3D saliency grid to guide the compression of dense features (§3.1); a soft zero-skipping gate that enhance the MLP in the NeRF model to ensure a feature compressed to 0 translates to a zero density in the 3D space (§3.2); a pruner to further push unnecessary features to exact 0 instead of a small non-zero value by alternating direction method of multipliers or ADMM [3] (§3.3). Our experi-ments demonstrate that HollowNeRF achieves better accu-racy (PSNR and LPIPS) than state-of-the-art methods while using significantly fewer parameters.
The key contributions of this work are:
• We propose a novel NeRF compression solution,
HollowNeRF, that learns to prioritize features defining the visible surface and prune invisible internal features without prior knowledge of surface geometries.
• We use an ADMM-based optimization framework to prune unnecessary features during NeRF training and enhance the MLP with a soft zero-skipping gate to en-sure that pruned features correctly map to zero density.
• We evaluate the performance of HollowNeRF on pop-ular NeRF datasets and our solution demonstrates a significantly superior balance between cost and accu-racy than state-of-the-art solutions. 2.