Abstract
Vision-language models such as CLIP [27] learn a generic text-image embedding from large-scale training data. A vision-language model can be adapted to a new classiﬁcation task through few-shot prompt tuning. We ﬁnd that such a prompt tuning process is highly robust to la-bel noises. This intrigues us to study the key reasons con-tributing to the robustness of the prompt tuning paradigm.
We conducted extensive experiments to explore this prop-erty and ﬁnd the key factors are: 1) the ﬁxed classname to-kens provide a strong regularization to the optimization of the model, reducing gradients induced by the noisy sam-ples; 2) the powerful pre-trained image-text embedding that is learned from diverse and generic web data provides strong prior knowledge for image classiﬁcation. Further, we demonstrate that noisy zero-shot predictions from CLIP can be used to tune its own prompt, signiﬁcantly enhancing prediction accuracy in the unsupervised setting. The code is available at https://github.com/CEWu/PTNL. 1.

Introduction
Large-scale vision-language models such as CLIP [27],
ALIGN [13], and CoCa [43] are transforming how we learn and interact with visual representations. Since these models learn to align the representations of a broad set of natural images with their textual descriptions, they have shown an exceptional ability to solve a wide range of tasks in a data-efﬁcient manner. For example, using the pre-trained text encoder, one can obtain a set of class embeddings by en-coding a canonical sentence such as “A photo of a <CLS>” and use them to recognize objects without a labeled dataset.
While promising, Zhou et al. [50] showed that these human-deﬁned sentences (also known as class prompts) can be un-stable, with seemingly equivalent descriptions leading to
*Work mostly done during an internship at ByteDance Inc.
)
% ( y c a r u c c
A
)
% ( y c a r u c c
A 70 60 50 40 30 20 90 80 70 60 50 40 30
ImageNet Finetuning
CLIP Zero-Shot
CLIP Linear Probe
CLIP Prompt Tuning
CLIP Prompt Tuning (+GCE) 0 12.5 25
Noise rate (%) 50 (a) DTD
ImageNet Finetuning
CLIP Zero-Shot
CLIP Linear Probe
CLIP Prompt Tuning
CLIP Prompt Tuning (+GCE) 0 12.5 25 50
Noise rate (%) (b) UCF101
Figure 1: Comparison with transfer learning approaches on two datasets with training labels that have incremental noisy rates. ImageNet Finetuning is ﬁnetuning pre-trained model on ImageNet. For the CLIP pre-trained model, Prompt Tun-ing is much more robust to the Linear Probe manner. By combining the generalized cross-entropy (GCE) [46], we further improve the robustness of Prompt Tuning to noisy labels. ResNet-50 is used for all approaches as their image encoders. different predictions. To address this issue, researchers have focused on prompt tuning [50], where a learnable prompt is learned from a small target dataset by back-propagation.
Since only the prompt needs to be trained, this framework is very data-efﬁcient. As a result, prompt-tuning has gained popularity for adapting vision-language models to down-stream tasks like few-shot learning [50, 49], continual learn-ing [38], and object segmentation [28].
While prompt tuning has proven effective when train-ing on downstream tasks with accurately annotated datasets, their robustness to noisy labels has been neglected. Since the quality of annotations for many applications can be low, learning with noisy labels is critical to solving real-world problems. In this work, we demonstrate that prompt tuning is robust to noisy labels, and investigate the mechanisms that enable this robustness. We hypothesize that the joint text and image embeddings of vision-language models can provide a well deﬁned structure to the classiﬁcation space (e.g., which classes are most similar and most distinct from each other). This model-informed structure compensates for the degradation of the structure present in the data due to label noise. To verify this hypothesis, we conducted ex-tensive experiments to study the impact of each component of a prompt tuning task with noisy labeled data. Beyond the robustness conferred by the structured label space, we show that this robustness can be further enhanced when the learnable prompts are trained using a robust loss function that mitigates the impact of outliers. Our study has revealed several interesting ﬁndings.
First, the classiﬁcation performance obtained by tuning the prompt through a pre-trained CLIP model is signiﬁ-cantly more robust to noisy labels than the traditional ﬁne-tuning or linear probing paradigms (see Figure 1). The ro-bustness of prompt tuning is evident not only due to their smaller performance degradation with higher noise rates, but also due to its ability to diminish the gradients induced by noisy samples. Second, while priming each class with a shared learnable prompt is necessary for adaptation, en-suring that the class name remains in the prompt strongly regularizes the class embeddings and prevents overﬁtting to the noisy labels. Finally, we demonstrate the beneﬁts of this robustness by showing that CLIP zero-shot (noisy) predictions can be used to tune its own prompt, and sig-niﬁcantly enhance CLIP prediction accuracy.
In fact, we show that, instead of focusing on samples with conﬁdent predictions (as proposed in prior unsupervised prompt tun-ing approaches [12]), prompt tuning beneﬁts more from an increased diversity of training samples as it can tolerate the noisier predictions associated with them.
The main contributions of our work are as follows:
• We demonstrate that prompt tuning for pre-trained vision-language models (e.g., CLIP) is more robust to noisy labels than traditional transfer learning ap-proaches, such as model ﬁne-tuning and linear probes.
• We further demonstrate that prompt tuning robustness can be further enhanced through the use of a robust training objective.
• We conduct an extensive analysis on why prompt tun-ing is robust to noisy labels to discover which compo-nents contribute the most to its robustness.
• Motivated by this property, we propose a simple yet ef-fective method for unsupervised prompt tuning, show-ing that randomly selected noisy pseudo labels can be effectively used to enhance CLIP zero-shot perfor-mance. The proposed robust prompt tuning outper-formed prior work [12] on a variety of datasets, even though noisier pseudo-labels are used for self-training. 2.