Abstract
The ability to perceive and understand 3D scenes is cru-cial for many applications in computer vision and robotics.
Inverse graphics is an appealing approach to 3D scene understanding that aims to infer the 3D scene structure from 2D images.
In this paper, we introduce probabilis-tic modeling to the inverse graphics framework to quantify uncertainty and achieve robustness in 6D pose estimation tasks. Specifically, we propose 3D Neural Embedding Like-lihood (3DNEL) as a unified probabilistic model over RGB-D images, and develop efficient inference procedures on 3D scene descriptions. 3DNEL effectively combines learned neural embeddings from RGB with depth information to improve robustness in sim-to-real 6D object pose estima-tion from RGB-D images. Performance on the YCB-Video dataset is on par with state-of-the-art yet is much more ro-bust in challenging regimes. In contrast to discriminative approaches, 3DNEL’s probabilistic generative formulation jointly models multiple objects in a scene, quantifies uncer-tainty in a principled way, and handles object pose tracking under heavy occlusion. Finally, 3DNEL provides a prin-cipled framework for incorporating prior knowledge about the scene and objects, which allows natural extension to ad-ditional tasks like camera pose tracking from video. 1.

Introduction 3D scene understanding is a fundamental problem in computer vision and robotics with numerous applications,
*Equal contribution including object recognition [50], robotic manipulation[51], and navigation[45].
Inverse graphics is an “analysis-by-synthesis” approach to 3D scene understanding that has found successful applications in a wide variety of tasks [16, 23, 10, 12, 26]. By synthesizing images from possible 3D descriptions of the scene and selecting the 3D scene de-scription that best agrees with the observed image, inverse graphics offers an intuitive and appealing way to reason about the 3D structure of a scene from 2D images. How-ever, challenges such as modeling the gap between rendered images and real-world observations and efficient inference have limited the widespread usage of 3D inverse graphics.
In this paper, we focus on 6D pose estimation, an impor-tant task in 3D scene understanding using inverse graphics that aims to infer the rigid SE(3) transformations (position and orientation) of objects in the camera frame given an image observation. We emphasize principled probabilistic modeling as a way to address the central challenges in 3D inverse graphics, and propose 3D Neural Embedding Like-lihood (3DNEL). Instead of naively rendering RGB images, 3DNEL uses learned neural embeddings to predict 2D-3D correspondences from RGB and combines this with depth to robustly evaluate the agreement of scene descriptions and real-world observations. This results in a unified probabilis-tic model over RGB-D images that jointly models multi-ple objects in a scene. We additionally develop efficient inference procedures using 3DNEL, both with stochastic search for 6D object pose estimation from static RGB-D images, and with particle filtering for object pose tracking from video.
We conduct extensive experiments on the popular YCB-Video (YCB-V) dataset [51]. Our results demonstrate that
3DNEL’s probabilistic formulation addresses 3D inverse graphics’ central challenges of bridging the gap between rendered images and real-world observations, significantly improving robustness in sim-to-real 6D pose estimation on challenging scenes with principled pose uncertainty quan-tification, while achieving accuracy on par with state-of-the-art (SOTA) approaches that require extensive tuning.
Additionally, 3DNEL’s joint modeling of multiple objects in a scene and natural support for uncertainty quantifica-tion enables robust object pose tracking under occlusion.
Furthermore, 3DNEL’s probabilistic formulation provides a principled framework for incorporating prior knowledge about the scene and objects, enabling easy extension to ad-ditional tasks like camera pose tracking from video, using principled inference in the same probabilistic model with-out task-specific retraining.
While the field of 6D pose estimation is currently dom-inated by discriminative approaches based on deep learn-ing, our probabilistic inverse graphics approach provides a complementary alternative that offers unique advantages in terms of robustness, uncertainty quantification and support for multiple tasks due to its probabilistic generative formu-lation. Our main contributions are three-fold:
• We propose a probabilistic inverse graphics approach to 6D pose estimation that can naturally support uncer-tainty quantification, track object poses with particle filtering, and incorporate additional knowledge about the scene and objects to handle camera pose tracking without task-specific retraining.
• We conduct extensive experiments on YCB-V and per-form on par with SOTA while improving robustness with significantly fewer large-error predictions.
• We show 3DNEL can handle challenging cases such as identifying pose uncertainties for symmetric objects and object pose tracking under heavy occlusion. 2.