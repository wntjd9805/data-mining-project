Abstract
Recovering information from non-line-of-sight (NLOS) imaging is a computationally-intensive inverse problem.
Most physics-based NLOS imaging methods address the complexity of this problem by assuming three-bounce re-flections and no self-occlusion. However, these assump-tions may break down for objects with large depth varia-tions, preventing physics-based algorithms from accurately reconstructing the details and high-frequency information.
On the other hand, while learning-based methods can avoid these assumptions, they may struggle to reconstruct de-tails without specific designs due to the spectral bias of neural networks. To overcome these issues, we propose a novel approach that enhances physics-based NLOS imag-ing methods by introducing a learnable inverse kernel in the Fourier domain and using an attention mechanism to improve the neural network to learn high-frequency infor-mation. Our method is evaluated on publicly available and new synthetic datasets, demonstrating its commend-able performance compared to prior physics-based and learning-based methods, especially for objects with large depth variations. Moreover, our approach generalizes well to real data and can be applied to tasks such as classifica-tion and depth reconstruction. We will make our code and dataset publicly available:https://sci2020.github.io.
1.

Introduction
Current non-line-of-sight (NLOS) imaging techniques typically adopt pulse lasers and time-resolved detectors to image hidden objects behind obstacles or around corners, as illustrated in Fig.1(a). To reconstruct the hidden objects from the detector’s measurements, known as NLOS tran-sients, most physics-based NLOS imaging methods, such as Light-cone transform (LCT) [25], assume that the NLOS scene only involves three-bounce reflections and has no self-occlusion, which simplifies the problem into a linear one in the Fourier domain. However, these assumptions may not hold for more complex objects with large depth variations, which are common in practical NLOS tasks, such as tilted vehicles in autonomous driving. In these sce-narios, the invalid assumptions of most physics-based meth-ods make it challenging to recover the high-frequency de-tails of the hidden objects. Moreover, studies have found that objects with large depth variations in NLOS problems typically have complex geometries and normal distribu-tions, which may result in a loss of high-frequency infor-mation in the Fourier domain [17] due to the limited NLOS aperture [18, 22], rendering the NLOS imaging problem highly ill-posed.
Learning-based methods avoid the assumptions, such as the three-bounce reflections and no self-occlusion, in physics-based NLOS reconstruction methods and leverage learned scene priors to compensate for the loss of high-frequency information in NLOS imaging process [7, 6, 23].
These methods achieve better results in scenes with large depth variations compared to physics-based methods. How-ever, existing learning-based methods lack dedicated de-signs to specifically address the problem of high-frequency information loss in scenes with significant depth varia-tions. Furthermore, due to the spectral bias of neural net-works [28, 4], the networks tend to learn low-frequency components, which makes them less sensitive to high-frequency details during NLOS reconstruction. Therefore, the current deep learning methods still face challenges in reconstructing high-frequency details in NLOS imaging, re-sulting in unsatisfactory reconstruction for complex objects with large depth variations.
To address the challenge of reconstructing high-frequency information and details in NLOS imaging, we propose an end-to-end deep learning framework that pri-marily operates in the Fourier domain, which is consis-tent with physics-based methods. We utilize a 3D convo-lutional neural network (CNN) and the fast Fourier trans-form (FFT) to extract frequency features (F-features) from raw NLOS transients. The inverse kernel of physics-based methods does not accurately capture high-frequency infor-mation from non-linear effects like self-occlusions, espe-cially for objects with large depth variations. We thus make the inverse kernel learnable in the Fourier domain and use self-attention and cross-attention to guide the net-work to embed learned scene priors into the low-frequency and high-frequency components of the kernel, respectively.
As shown in Fig.1(b), the kernel guided by attention mech-anisms contains richer high-frequency information than the physics-based kernel, resulting in finer reconstruction.
With the extracted F-features and the learned inverse ker-nel, we multiply them and use iFFT to obtain spatial fea-tures (S-features), which resemble physics-based methods.
The network-obtained S-features are suitable for end-to-end training for various tasks, such as 2D imaging, depth recon-struction, and object classification [3].
We evaluate our proposed method on three syntheic datasets, as well as additional experimental data. First, we validate our method on our new synthetic datasets for differ-ent tasks like 2D imaging, depth estimation and classifica-tions. Additionally, we test our method on a public dataset of motorbikes [6]. We demonstrate that our method can recover high-frequency details and get higher accuracy. Fi-nally, we show the effectiveness of our method on a public dataset [23].
We summarize our contributions as follows:
• We propose an end-to-end deep learning framework that learns an inverse kernel in the Fourier domain to reconstruct high-frequency information and details in NLOS imaging, particularly for objects with large depth variations.
• We evaluate our method on three different synthetic datasets and additional experimental data on various tasks, such as 2D imaging, depth reconstruction, and object classification. 2.