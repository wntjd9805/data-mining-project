Abstract
Learning image classification and image generation using the same set of network parameters presents a formidable challenge. Recent advanced approaches per-form well in one task often exhibit poor performance in the other. This work introduces an energy-based classi-fier and generator, namely EGC, which can achieve supe-rior performance in both tasks using a single neural net-work. Unlike conventional classifiers that produce a label given an image (i.e., a conditional distribution p(y|x)), the forward pass in EGC is a classification model that yields a joint distribution p(x, y), enabling a diffusion model in its backward pass by marginalizing out the label y to esti-mate the score function. Furthermore, EGC can be adapted for unsupervised learning by considering the label as la-tent variables. EGC achieves competitive generation results compared with state-of-the-art approaches on ImageNet-1k,
CelebA-HQ and LSUN Church, while achieving superior classification accuracy and robustness against adversarial attacks on CIFAR-10. This work marks the inaugural suc-cess in mastering both domains using a unified network pa-rameter set. We believe that EGC bridges the gap between discriminative and generative learning. Code will be re-leased at https://github.com/GuoQiushan/EGC.
Figure 2: FID and classification accuracy on ImageNet 256×256 dataset. The scatters plots on the vertical N/A line represent the image generation models, which are not available for classification. The scatter plot on the horizon-tal N/A line represents the classification model, which is not available for image generation. Remarkably, EGC achieves superior performance in both tasks with a single neural net-work, demonstrating its effectiveness in bridging the gap between discriminative and generative learning.
1.

Introduction
Image classification and generation are two fundamental tasks in computer vision that have seen significant advance-ments with the development of deep learning models. How-ever, many state-of-the-art approaches that perform well in one task often exhibit poor performance in the other or are not suitable for the other task. Both tasks can be formulated from a probabilistic perspective, where image classification task is interpreted as a conditional probability distribution p(y|x), and image generation task is the transformation of a known and easy-to-sample probability distribution p(z) to a target distribution p(x).
As an appealing class of probabilistic models, Energy-Based Models (EBM) [6, 9, 10, 11, 12, 15, 16, 29, 32, 41, 43, 55, 60, 65, 68] can explicitly model complex probabil-ity distribution. Furthermore, standard image classification models and some image generation models can be reinter-preted as EBMs [12, 16, 24, 33, 36, 37]. JEM [16] repur-poses a standard image classification model as an image generation model by leveraging the gradient of its inputs to guide the generation of new images. Despite the desir-able properties, EBMs face challenges in training due to the intractability of computing the exact likelihood and synthe-sizing exact samples from these models. Arbitrary energy models often exhibit sharp changes in gradients, leading to unstable sampling with Langevin dynamics. To ameliorate this issue, spectral normalization [40] is typically adopted for constraining the Lipschitz constant of the energy model
[6, 12, 16]. Even with this regularization technique, the samples generated by the energy-based model are still not competitive enough because the probability distribution of real data is usually sharp in the high-dimensional space, providing inaccurate guidance for image sampling in the low data density regions.
Diffusion models [21, 45, 49, 50, 51] have demonstrated competitive and even superior image generation perfor-mance compared to GAN [13] models. In diffusion models, images are perturbed with Gaussian noise through a diffu-sion process for training, and the reverse process is learned to transform the Gaussian distribution back to the data dis-tribution. As pointed out in [50], perturbing data points with noise populates low data density regions to improve the ac-curacy of estimated scores, resulting in stable training and image sampling.
Motivated by the flexibility of JEM and the stability of diffusion model, we propose a novel energy-based classi-fier and generator, namely EGC, which achieves superior performance in both image classification and generation tasks using a single neural network. EGC is a classifier in the forward pass and an image generator in the back-ward pass. Unlike a conventional classifier that predicts the condition distribution p(y|x) of the label given an im-age, the forward pass in EGC models the joint distribution p(x, y) of the noisy image and label, given the source im-age. By marginalizing out the label y, the gradient of log-probability of the noisy image (i.e., unconditional score) is used to restore image from noise. The classification proba-bility p(y|x) provides classifier guidance together with un-conditional score within one step backward pass.
We demonstrate the efficacy of EGC model on Im-ageNet, CIFAR-10, CIFAR-100, CelebA-HQ and LSUN datasets. The generated samples are of high fidelity and comparable to GAN-based methods, as shown in Fig. 1.
Additionally, our model shows superior classification accu-racy and robustness against adversarial attacks. On CIFAR-10, EGC surpasses existing methods of learning explicit
EBMs with an FID of 3.30 and an inception score of 9.43 while achieving a remarkable classification accuracy of 95.9%. This result even exceeds the classification per-formance of the discriminative model Wide ResNet-28-12, which shares a comparable architecture and number of pa-rameters with our model. On ImageNet-1k, EGC achieves an FID of 6.05 and an accuracy of 78.9%, as illustrated in
Fig. 2. We also demonstrate that naively optimizing the gra-dients of explicit energy functions as the score functions outperforms optimizing the probability density function via
Langevin sampling. Besides, EGC model does not require constraining the Lipschitz constant as in the previous meth-ods [6, 12, 16] by removing the normalization layers and in-serting spectral normalization layer. More interestingly, we demonstrate that the neural network effectively models the target data distribution even though we adopt optimization of the Fisher divergence instead of the probability pθ(xt).
Our contributions are listed as follows: (1) We propose a novel hybrid energy-based model,
EGC, which is trained in diffusion manner using Fisher di-vergence. In EGC, the forward pass is a classification model and the backward pass is a diffusion model that denoises data using the score function and conditional guidance. (2)
Our EGC model achieves competitive generation results to state-of-the-art approaches, while obtaining superior clas-sification results using a single neural network. EGC sur-passes existing methods of explicit EBMs by a significant margin. (3) We demonstrate that EGC model can be ap-plied in inpainting, semantic interpolation, high-resolution image generation (∼ 10242) and robustness improvement. 2.