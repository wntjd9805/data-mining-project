Abstract
Palm Tree
E n c o d e r maple_tree forest
Palm tree crab beetle lamp (cid:28694) 0.4 0.2 0.2 0.1 0.1 (cid:28694) 0 l l
C a s s
-r e a t i o n
R e p
.
We tackle the problem of novel class discovery, which aims to learn novel classes without supervision based on labeled data from known classes. A key challenge lies in transferring the knowledge in the known-class data to the learning of novel classes. Previous methods mainly focus on building a shared representation space for knowledge transfer and often ignore modeling class relations. To ad-dress this, we introduce a class relation representation for the novel classes based on the predicted class distribution of a model trained on known classes. Empirically, we ﬁnd that such class relation becomes less informative during typical discovery training. To prevent such information loss, we propose a novel knowledge distillation framework, which utilizes our class-relation representation to regularize the
In addition, to enable a ﬂexi-learning of novel classes. ble knowledge distillation scheme for each data point in novel classes, we develop a learnable weighting function for the regularization, which adaptively promotes knowl-edge transfer based on the semantic similarity between the novel and known classes. To validate the effectiveness and generalization of our method, we conduct extensive experi-ments on multiple benchmarks, including CIFAR100, Stan-ford Cars, CUB, and FGVC-Aircraft datasets. Our results demonstrate that the proposed method outperforms the pre-vious state-of-the-art methods by a signiﬁcant margin on almost all benchmarks. Code is available at here. 1.

Introduction
The recent development of deep learning has achieved remarkable success in a broad range of visual recognition tasks [14, 13, 22]. However, most traditional methods focus on the closed-world setting, in which all the visual classes are pre-deﬁned. As a result, it is usually difﬁcult to de-ploy the learned models in realistic settings with potential
In contrast, human visual systems can ef-novel classes.
*Both authors contributed equally.
Figure 1. In the upper panel, we apply the encoder and the known class classiﬁer to a novel sample of Palm tree, obtaining a class-relation representation. This representation encodes the relative distances between the representations of novel and known cate-gories. The triangles indicate a novel class, while the circles show known classes. The lower panel shows the averaged class-relation representation for all Palm Tree samples and displays the 5 nearest known classes for both the known class Supervised Trained Model and the Baseline Model [9]. We observe that the predictions from a trained model on novel class data indicate meaningful class rela-tion (e.g. maple tree, forest), which is lost in the Baseline Model.
ﬁciently acquire new concepts without supervision based on learned knowledge. Inspired by such an ability, several studies [12, 16] propose the task of Novel Class Discovery (NCD) which aims to discover novel categories from unla-beled data based on known-class data.
A key strategy for discovering novel classes is to trans-fer knowledge in known classes to promote the learning of novel classes. To achieve this, most existing NCD meth-ods [11, 31, 9] involve two training stages, including a supervised training stage followed by a discovery train-ing stage. In the supervised training stage, they typically initialize representation by learning from known classes.
In the discovery training stage, they transfer the learned knowledge to novel classes via sharing the feature repre-sentation space. While they have shown promising results, they are less effective in capturing the relationship between  
known and novel classes, which limits the scope of shared knowledge and potentially leads to inferior representations of novel classes. Nonetheless, it is difﬁcult to model the se-mantic relationship between the known and novel classes in the NCD setting as the novel classes are unknown.
To tackle this challenge, we introduce a class-relation representation for a novel class based on its similarity with the known classes. In particular, we leverage a well-known phenomenon of “dark knowledge” [15] and adopt the pre-dicted distribution of a well-trained model to encode the inter-class relationship. To that end, we ﬁrst train a model on the known classes using supervised learning and then
In apply the trained model to the data of novel classes.
Fig. 1 top and bottom-left, we visualize our class-relation representation and the average predictive distribution of a novel class, palm tree, respectively. Interestingly, we ob-serve that the distribution often focuses on related or co-occurred classes and hence properly reﬂects its class rela-tionship. For example, the palm tree class is closer to the maple and forest classes. However, a typical NCD baseline, which ﬁne-tunes the pre-trained model, is unable to main-tain such a similarity structure, as indicated by the example shown in Fig. 1 bottom-right. Here the palm tree class is more similar to the house class, which is less reasonable.
Motivated by the above observation, we propose a novel class-relation knowledge distillation framework for the task of novel class discovery. Our framework utilizes the class relation represented by the supervised trained model to reg-ularize the learning of novel classes in the discovery training stage, thus preserving the meaningful class relation knowl-edge and promoting knowledge transfer. Moreover, to pro-vide a ﬂexible knowledge transfer scheme for each data sample, we develop a simple but effective learnable weight function for the regularization, which allows us to adap-tively transfer knowledge based on the similarity between a novel class sample and known classes.
Speciﬁcally, we instantiate our framework with a two-head network architecture that includes an encoder and two classiﬁer heads for the known and novel classes, respec-tively. We ﬁrst initialize the feature representation through supervised learning on the known classes and then discover novel classes by minimizing a hybrid learning loss. Our loss consists of three terms: 1) a standard cross-entropy loss on the labeled data, which extracts semantic knowledge from the known classes; 2) an unsupervised clustering loss on the novel class data; and 3) a weighted Kullback–Leibler (KL) regularization term for distilling the class relation knowl-edge from the supervised trained model into the discovery of novel classes. Here the strength of each KL regulariza-tion term is controlled by a weight measuring the similarity between a novel sample and the known classes, which is de-rived from the predicted distribution on the known classes by the model in the discovery training stage.
To validate the effectiveness of our method, we con-duct extensive experiments on four datasets, including CI-FAR100, Stanford Cars, CUB, and FGVC-Aircraft. The re-sults show that our performances surpass the previous state of the art by a large margin in most cases, demonstrating the efﬁcacy of our novel design of learning framework. In summary, our main contributions are three-fold:
• We propose a simple and effective learning frame-work to facilitate knowledge transfer from the known to novel classes, which provides a new perspective to tackle novel class discovery problems.
• We propose a novel regularization strategy to capture class relation between known and novel classes via the classiﬁer output space, and develop a simple but ef-fective learnable weight function to adaptively transfer knowledge based on the strength of class relation.
• Our method signiﬁcantly outperforms previous works on various public benchmarks, illustrating the efﬁcacy of our design. 2.