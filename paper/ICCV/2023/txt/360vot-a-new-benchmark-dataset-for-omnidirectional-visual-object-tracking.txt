Abstract 360◦ images can provide an omnidirectional field of view which is important for stable and long-term scene percep-tion. In this paper, we explore 360◦ images for visual ob-ject tracking and perceive new challenges caused by large distortion, stitching artifacts, and other unique attributes of 360◦ images. To alleviate these problems, we take ad-vantage of novel representations of target localization, i.e., bounding field-of-view, and then introduce a general 360 tracking framework that can adopt typical trackers for om-nidirectional tracking. More importantly, we propose a new large-scale omnidirectional tracking benchmark dataset, 360VOT, in order to facilitate future research. 360VOT con-tains 120 sequences with up to 113K high-resolution frames in equirectangular projection. The tracking targets cover 32 categories in diverse scenarios. Moreover, we provide 4 types of unbiased ground truth, including (rotated) bound-ing boxes and (rotated) bounding field-of-views, as well as new metrics tailored for 360◦ images which allow for the accurate evaluation of omnidirectional tracking perfor-mance. Finally, we extensively evaluated 20 state-of-the-art visual trackers and provided a new baseline for future com-parisons. Homepage: https://360vot.hkustvgd.com 1.

Introduction
Visual object tracking is an essential problem in com-puter vision since it is demanded in various applications such as video analysis, human-machine interaction, and in-telligent robots. In the last decade, a large number of vi-sual tracking algorithms [19, 32, 11, 26, 1] and various benchmarks [42, 30, 24, 16, 22] have been proposed to pro-mote the development of the visual tracking community.
Whereas most existing research focuses on perspective vi-sual object tracking, there is little attention paid to omnidi-rectional visual object tracking.
Omnidirectional visual object tracking employs a 360◦ camera to track the target object. With its omnidirectional field-of-view (FoV), a 360◦ camera offers continuous ob-servation of the target over a longer period, minimizing the out-of-view issue. This advantage is crucial for intelligent
agents to achieve stable, long-term tracking, and percep-tion. In general, an ideal spherical camera model is used to describe the projection relationship of a 360◦ camera. The 360◦ image is widely represented by equirectangular pro-jection (ERP) [36], which has two main features: 1) cross-ing the image border and 2) extreme distortion as the lat-itude increases. Moreover, due to inherent limitations or manufacturing defects of the camera, the 360◦ image may suffer from stitching artifacts that would blur, break or du-plicate the shape of objects. Meanwhile, omnidirectional
FoV means it is inevitable to capture the photographers.
They would distract and occlude the targets. These phe-nomena are illustrated in Figure 1. Eventually, they bring new challenges for object tracking on 360◦ images.
To explore this problem and understand how the current tracking algorithms designed for perspective visual tracking perform, we proposed a challenging omnidirectional track-ing benchmark dataset, referred to as 360VOT. The bench-mark dataset is composed of 120 sequences, and each se-quence has an average of 940 frames with 3840 × 1920 resolution. Our benchmark encompasses a wide range of categories and diverse scenarios, such as indoor, underwa-ter, skydiving, and racing. Apart from 13 conventional attributes, 360VOT has additional 7 attributes, including the aforementioned challenges, fast motion on the sphere and latitude variation. Additionally, we introduce new rep-resentations to object tracking. Compared to the com-monly used bounding box (BBox), bounding field-of-view (BFoV) [9, 43] represents object localization on the unit sphere in an angular fashion. BFoV can better constrain the target on 360◦ images and is not subject to image reso-lution. Based on BFoV, we can properly crop the search re-gions, which enhances the performance of the conventional trackers devised for perspective visual tracking in omnidi-rectional tracking. To encourage future research, we pro-vide densely unbiased annotations as ground truth, includ-ing BBox and three advanced representations, i.e., rotated
BBox (rBBox), BFoV, and rotated BFoV (rBFoV). Accord-ingly, we develop new metrics tailored for 360◦ images to accurately evaluate omnidirectional tracking performances.
In summary, the contribution of this work includes:
• The proposed 360VOT, to the best of our knowledge, is the first benchmark dataset for omnidirectional visual ob-ject tracking.
• We explore the new representations for visual object tracking and provide four types of unbiased ground truth.
• We propose new metrics for omnidirectional tracking evaluation, which measure the dual success rate and angle precision on the sphere.
• We benchmark 20 state-of-the-art trackers on 360VOT with extensive evaluations and develop a new baseline for future comparisons.
Benchmark Videos
Total frames
Object classes
Attr. Annotation
Feature
ALOV300[35]
OTB100[42]
NUS-PRO[25]
TC128[28]
UAV123[30]
DTB70[27]
NfS[23]
UAVDT[14]
TrackingNet∗[31]
OxUvA[38]
LaSOT∗[16]
GOT-10k∗[22]
TOTB[17]
TREK-150[15]
VOT[24] 360VOT 314 100 365 129 123 70 100 100 511 337 280 420 225 150 62 120 64 152K 16 81K 8 135K 27 55K 9 113K 29 16K 17 383K 27 78K 226K 27 1.55M 22 85 685K 84 56K 15 86K 34 97K 37 20K 113K 32 14 11 12 11 12 11 9 14 15 6 14 6 12 17 9 20 sparse BBox dense BBox dense BBox dense BBox dense BBox dense BBox dense BBox sparse BBox sparse BBox sparse BBox dense BBox dense BBox dense BBox dense BBox dense BBox dense (r)BBox
& (r)BFoV diverse scenes short-term occlusion-level color enhanced
UAV
UAV high FPS
UAV large scale long-term category balance generic transparent
FPV annual 360◦ images
Table 1: Comparison of current popular benchmarks for vi-sual single object tracking in the literature. ∗ indicates that only the test set of each dataset is reported. 2.