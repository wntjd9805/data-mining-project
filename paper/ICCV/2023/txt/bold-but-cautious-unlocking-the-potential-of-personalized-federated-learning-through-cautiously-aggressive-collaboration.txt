Abstract
Personalized federated learning (PFL) reduces the im-pact of non-independent and identically distributed (non-IID) data among clients by allowing each client to train a personalized model when collaborating with others. A key question in PFL is to decide which parameters of a client should be localized or shared with others. In current main-stream approaches, all layers that are sensitive to non-IID data (such as classifier layers) are generally personalized.
The reasoning behind this approach is understandable, as localizing parameters that are easily influenced by non-IID data can prevent the potential negative effect of collabora-tion. However, we believe that this approach is too conser-vative for collaboration. For example, for a certain client, even if its parameters are easily influenced by non-IID data, it can still benefit by sharing these parameters with clients having similar data distribution. This observation empha-sizes the importance of considering not only the sensitivity to non-IID data but also the similarity of data distribution when determining which parameters should be localized in
PFL. This paper introduces a novel guideline for client col-laboration in PFL. Unlike existing approaches that prohibit all collaboration of sensitive parameters, our guideline al-lows clients to share more parameters with others, leading to improved model performance. Additionally, we propose a new PFL method named FedCAC, which employs a quan-titative metric to evaluate each parameter’s sensitivity to non-IID data and carefully selects collaborators based on
*Corresponding author this evaluation. Experimental results demonstrate that Fed-CAC enables clients to share more parameters with others, resulting in superior performance compared to state-of-the-art methods, particularly in scenarios where clients have diverse distributions. The code is integrated into our FL training framework: https://github.com/kxzxvbk/Fling. 1.

Introduction
Federated Learning (FL) [25] enables institutions or de-vices to train a global model collaboratively without ex-posing raw data.
It has been applied in many scenarios, such as computer vision [20, 5, 34], finance [21], healthcare
[28, 29], etc. However, when the data among clients are non-independent and identically distributed (non-IID), the local tasks of clients are different, which brings a great chal-lenge for training a global model for all clients [36, 7, 16].
Personalized federated learning (PFL) [6, 31, 17] allows each client to train a personalized model to focus on its data distribution. PFL aims to enable each client to get as much help as possible from other clients while minimizing the im-pact of non-IID data. A key question in PFL is to decide which parameters of a client should be localized to reduce the influence of non-IID or shared with others to get help.
To deal with this question, according to the character-istics of different neural network layers, the current main-stream work localizes layers sensitive to non-IID data while globally sharing the others. FedRep [4] and FedBN [18], for example, personalize classifier layers and batch normaliza-tion (BN) layers, respectively. The rationale behind these
(a) (b)
Figure 1: Two preliminary experiments. (a) verifies that the influence of non-IID varies with time. (b) verifies that parameters in the same layer have different sensitivities. methods is localizing parameters easily influenced by non-IID data to reduce the negative effect of collaboration.
However, although localizing sensitive layers can reduce the impact of non-IID data, these methods are too conserva-tive for collaboration. The client can not fully utilize other clients’ knowledge, and it is difficult to adapt to various complex non-IID scenarios. In addition, these methods are mostly empirical and heuristic and do not give a guideline for client collaboration.
We find that client collaboration depends not only on pa-rameter sensitivity but also on variations in data distribu-tion between clients. In non-IID scenarios, some clients still possess similar data distribution, allowing them to collabo-rate on sensitive parameters and benefit from each other. In this paper, we first propose a guideline for client parameter collaboration in PFL that takes both factors into account. It can be formulated as
U = I(Ψ · Ω). (1)
In the above equation, U ∈ {0, 1}N and Ui = 1 denotes that this parameter should not get contribution from client i. N denotes the total number of clients. I(·) is an indicator function. Ψ ∈ [0, 1]N , and Ψi indicates the data distribu-tion difference between the current client and client i. A larger Ψi implies the two clients have less similar data dis-tributions. Ω ∈ [0, 1] indicates the current sensitivity of the parameter to non-IID data. The larger the Ω, the more sensitive it is to non-IID data. This guideline offers a cau-tiously aggressive collaboration. Even sensitive parameters (i.e., Ω is large) can still collaborate with clients with simi-lar data distribution (i.e., Ψi is small), which enables a client can collaborate more with others while avoiding the nega-tive effect of non-IID data. Current methods can also be incorporated under this guideline. For each client i, they set
Ψj = 1, i ̸= j and select parameters sensitive to non-IID data in a layer-wise manner to set their Ω = 1.
In practical use of the guideline, Ω is a critical factor that must be taken into account. Our research shows that two effects should be considered. First, Ω varies over time. In the early training stage, the impact of non-IID data is min-imal, and parameters are less sensitive to non-IID data. As the training progresses, the impact of non-IID data becomes more pronounced, and parameters are more susceptible to its effects. To illustrate this, we conduct an experiment in-volving two clients in different non-IID scenarios and cal-culate the angle between their gradients in each round. As shown in Figure 1(a), in all non-IID scenarios (i.e., with all
α values), the angle between the two gradients increases as the training progresses, indicating that the two clients are increasingly negatively influenced by each other. In other words, the impact of non-IID data grows over time.
Second, we discover that the current approach of select-ing sensitive parameters layer-wise is too coarse-grained.
The Ω value of parameters within the same layer can be dif-ferent. To demonstrate this, we perform an experiment on the CIFAR-10 dataset with the CNN network. The propor-tion of samples of different classes in the training data is airplane:truck:cat:dog=4:4:1:1. We calculate the sensitivity of each parameter in the last layer of classifier, and the re-sults are displayed in Figure 1(b). Each square represents the sensitivity of a parameter in the model’s last layer, with darker colors indicating greater sensitivity. Each row in
Figure 1(b) corresponds to parameters related to a specific class. The results reveal that the sensitivity of parameters in the same layer differs significantly. This indicates that we must select sensitive parameters at the parameter level to ac-complish fine-grained collaboration. Additionally, this ex-periment demonstrates that the sensitivity of parameters is linked to data distribution. The parameters associated with the class that has more samples are more sensitive. This underscores the significance of considering differences in client data distribution (i.e., Ψ in Eq. (1) ) when collaborat-ing with sensitive parameters.
Building on the aforementioned guideline and observa-tion, we introduce a new PFL method called FedCAC. Fed-CAC utilizes a sensitivity-based quantitative metric to ac-cess each parameter in each round, identifying the param-eters sensitive to non-IID data as critical parameters and the rest as non-critical. All clients collaborate to train
non-critical parameters, while FedCAC implements a time-varying collaboration strategy for critical parameters. Ini-tially, each client receives assistance from a greater number of clients. As training progresses, it gradually collaborates only with clients that have more similar data distribution.
Our primary contributions are summarized as follows:
• We propose a client collaboration guideline in PFL, which comprehensively considers the differences in data distribution between clients and the sensitivity of parameters to non-IID data. This framework enables clients to collaborate more aggressively while care-fully avoiding the negative effect of non-IID data.
• Building upon the guideline, we propose a new
PFL method that selects sensitive parameters in a parameter-wise manner and implements time-varying collaboration for them, allowing them to benefit fully from the assistance of other clients, thereby improving performance.
• The experimental results on CIFAR-10, CIFAR-100, and Tiny ImageNet prove that the performance of our method is significantly improved compared with the existing methods. 2.