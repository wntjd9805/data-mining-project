Abstract
Given a classifier, the inherent property of semantic Out-of-Distribution (OOD) samples is that their contents differ from all legal classes in terms of semantics, namely seman-tic mismatch. There is a recent work that directly applies it to OOD detection, which employs a conditional Generative
Adversarial Network (cGAN) to enlarge semantic mismatch in the image space. While achieving remarkable OOD de-tection performance on small datasets, it is not applicable to IMAGENET-scale datasets due to the difficulty in training cGANs with both input images and labels as conditions.
As diffusion models are much easier to train and amenable to various conditions compared to cGANs, in this work, we propose to directly use pre-trained diffusion mod-els for semantic mismatch-guided OOD detection, named
DIFFGUARD. Specifically, given an OOD input image and the predicted label from the classifier, we try to enlarge the semantic difference between the reconstructed OOD image under these conditions and the original input im-age. We also present several test-time techniques to further strengthen such differences. Experimental results show that
DIFFGUARD is effective on both CIFAR-10 and hard cases of the large-scale IMAGENET, and it can be easily com-bined with existing OOD detection techniques to achieve state-of-the-art OOD detection results. 1.

Introduction
The effectiveness of deep learning models is largely con-tingent on the independent and identically distributed (i.i.d.) data assumption, i.e., test sets follow the same distribution as training samples [22]. However, in real-world scenarios, this assumption often does not hold true [6]. Consequently, the task of out-of-distribution (OOD) detection is essential for practical applications, so that OOD samples can be re-jected or taken special care of without harming the system’s performance [12].
Code: https://github.com/cure-lab/DiffGuard
For image classifiers, a primary objective of OOD detection is to identify samples having semantic shifts, whose contents differ from all legal classes in the train-ing dataset [50]. To differentiate such OOD samples and in-distribution (InD) ones, some existing solutions utilize information from the classifier itself, such as internal fea-tures [44], logits [11], or both [46]. While simple, these so-lutions inevitably face a trade-off between the InD classifi-cation accuracy and the over-confidence of the trained clas-sifier for OOD detection [32], especially on hard OOD in-puts. Some other methods propose using an auxiliary mod-ule for OOD detection based on either reconstruction qual-ity [3] or data density [34]. The auxiliary module does not affect the training process of the classifier, but these meth-ods tend to have a low OOD detection capability.
To the best of our knowledge, MoodCat [51] is the only attempt that directly models the semantic mismatch of OOD samples for detection. Specifically, it employs a conditional
Generative Adversarial Network (cGAN) to synthesize an image conditioned on the classifier’s output label together with the input image. For InD samples with correct la-bels, the synthesis procedure tries to reconstruct the origi-nal input; while for OOD samples with semantically differ-ent labels, ideally the synthesis result is dramatically differ-ent from the input image, thereby enabling OOD detection.
While inspiring, due to the difficulty in cGAN training with potentially conflicting conditions, MoodCat is not applica-ble to IMAGENET-scale datasets.
Recently, diffusion models have surpassed GANs in terms of both training stability and generation quality.
Moreover, they are amenable to various conditions during generation, including both label conditions [42, 16] and image-wise conditions through DDIM inversion [40]. With the above benefits, we propose a new semantic mismatch-guided OOD detection framework based on diffusion mod-els, called DIFFGUARD. Similar to [51], DIFFGUARD takes both the input image and the classifier’s output label as con-ditions for image synthesis and detects OODs by measuring the similarity between the input image and its conditional synthesis result.
However, it is non-trivial to apply diffusion models for semantic mismatch identification. A critical problem with label guidance in diffusion models is the lack of consider-ation for the classifier-under-protection. This issue arises in both types of guidance in diffusion models, namely clas-sifier guidance1 [42] and classifier-free guidance [16].
If the guidance cannot match the semantics of the classifier’s output, the synthesis result may fail to highlight the seman-tic mismatch of OODs. To address this problem, we pro-pose several techniques that effectively utilize information from the classifier-under-protection. Additionally, we pro-pose several test-time enhancement techniques to balance the guidance between the input image and the label condi-tion during generation, without even fine-tuning the diffu-sion model.
We evaluate the effectiveness of the proposed framework on the standard benchmark, OpenOOD [49]. Given CIFAR-10 or IMAGENET as the InD dataset, DIFFGUARD outper-forms or is on par with existing OOD detection solutions, and it can be easily combined with them to achieve state-of-the-art (SOTA) performance. We summarize the contribu-tions of this paper as follows:
• We propose a diffusion-based framework for detecting
OODs, which directly models the semantic mismatch of
OOD samples, and it is applicable to IMAGENET-scale datasets;
• We propose several test-time techniques to improve the effectiveness of conditioning in OOD detection. Our framework can work with any pre-trained diffusion mod-els without the need for fine-tuning, and can provide plug-and-play OOD detection capability for any classi-fier;
• Experimental results show that our framework achieves
SOTA performance on CIFAR-10 and demonstrates strong differentiation ability on hard OOD samples of
IMAGENET.
The rest of the paper is organized as follows. Section 2 introduces related OOD detection methods and diffusion models. Section 3 presents our framework and details the proposed solution. Experimental results are presented in
Section 4. We also provide discussion on limitations and future works in Section 5. Finally, we conclude this paper in Section 6. 2.