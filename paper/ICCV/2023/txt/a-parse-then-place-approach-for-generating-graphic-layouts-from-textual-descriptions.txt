Abstract
Creating layouts is a fundamental step in graphic de-sign. In this work, we propose to use text as the guidance to create graphic layouts, i.e., Text-to-Layout, aiming to lower the design barriers. Text-to-Layout is a challeng-ing task, because it needs to consider the implicit, com-bined, and incomplete layout constraints from text, each of which has not been studied in previous work. To address this, we present a two-stage approach, named parse-then-place. The approach introduces an intermediate representa-tion (IR) between text and layout to represent diverse layout constraints. With IR, Text-to-Layout is decomposed into a parse stage and a place stage. The parse stage takes a tex-tual description as input and generates an IR, in which the implicit constraints from the text are transformed into ex-plicit ones. The place stage generates layouts based on the
IR. To model combined and incomplete constraints, we use a Transformer-based layout generation model and carefully design a way to represent constraints and layouts as se-quences. Besides, we adopt the pretrain-then-finetune strat-egy to boost the performance of the layout generation model with large-scale unlabeled layouts. To evaluate our ap-proach, we construct two Text-to-Layout datasets and con-duct experiments on them. Quantitative results, qualitative analysis, and user studies demonstrate our approach’s ef-fectiveness. 1.

Introduction
Graphic design is ubiquitous in our daily life. Layout, the sizes and positions of design elements, is fundamental to a graphic design. However, creating layouts is a com-plex task that requires design expertise and consumes much time. While we may not have design knowledge and be unfamiliar with design tools, we have a strong linguistic
*Work done during an internship at Microsoft Research Asia.
Figure 1. An example of Text-to-Layout. (a) A user describes the desired layout in natural language. (b) A visually appealing layout is automatically generated. (c) The layout is a fundamental ingre-dient of the final graphic design. ability to express our requirements. That is also what we are doing in the communication with designers. Thus, we propose to use text as the guidance to create graphic lay-outs, i.e., Text-to-Layout (see Figure 1). This enables people without expertise to participate in the design. Moreover, it helps professional designers create drafts more efficiently, thereby reducing their workloads. Besides, it also makes the discussion between users and designers much smoother.
While automatic layout generation has been intensively studied [23, 1, 9, 20], Text-to-Layout is rarely investigated and remains a challenging task due to its unique way to specify layout constraints. (i) Implicit Constraint. Textual description tends to be abstract and vague, and thus layout constraints from the text are often specified in an implicit and vague way. Consider the description in Figure 1.
It describes the elements in a layout by their functional roles (e.g., news title and summary) rather than their primitive el-ement types (e.g., text box). It also states a vague, subjective position constraint (e.g., heading at the top) and implicitly poses a hierarchy constraint (e.g., news should be organized in a list). This characteristic makes Text-to-Layout dras-tically different from other conditional layout generation
tasks where constraints are explicitly specified [24, 21, 20]. (ii) Combined Constraint. Various types of layout con-straints are often jointly specified in text. For example, the description in Figure 1 poses 4 different kinds of constraints in total, including element type constraint (e.g., news title), size constraint (e.g., brief summary), position (e.g., heading at the top) and hierarchy (e.g., all news arranged in a list).
However, existing conditional layout generation approaches only tackle one certain kind of constraint at a time. Hence, how to model the combined constraints and create visually appealing layouts that satisfy all constraints simultaneously remains to be explored. (iii) Incomplete Constraint. Users tend not to describe all the elements in a layout, because do-ing so is extremely tedious. For instance, the description in
Figure 1 does not specify the image in each piece of news, but the images are indispensable for engaging audiences’ attention. Thus, it is necessary to auto-complete the omit-ted yet important elements. While previous work [9, 15] has studied the task of layout completion, it has not been jointly considered with other conditional layout generation tasks. In addition to the above challenges, Text-to-Layout also faces the serious problem of scarcity of labeled data.
Unlike the Text-to-Image task that has billions of text-image pairs from the Internet [31, 30, 33], it is prohibitively expen-sive to collect a similarly sized dataset for Text-to-Layout.
To tackle the challenging Text-to-Layout, our intuition is three-fold. First, implicit layout constraints in a text could be transformed into explicit ones. Considering the descrip-tion in Figure 1, the functional roles of elements can be transformed to corresponding primitive element type con-straints. Since this transformation does not require any lay-out generation capability, we can take advantage of pre-trained language models (PLM) that have achieved impres-sive natural language understanding performance even in a low-data regime [3, 29, 34]. In addition, generating layouts conditioned on explicit constraints is a well-studied setting in prior work [1, 20, 15]. We can learn from their successful experience to address the problem. Second, the state-of-the-art approach [15] has formulated conditional layout genera-tion as a sequence-to-sequence transformation problem and demonstrated the superiority of representing constraints and layouts as sequences. This motivates us to take the same formulation and seek a way to represent combined and in-complete constraints in Text-to-Layout as sequences. Third, graphic designs are ubiquitous and their layouts are often abundantly available [2, 22]. Though these layouts do not have corresponding textual descriptions, their large quantity and rich layout patterns are highly valuable for learning to generate high-quality, diverse layouts, especially when only scarce labeled data is available.
Motivated by the intuitions, we propose a two-stage approach for Text-to-Layout, called parse-then-place (see
Figure 2). The approach introduces an intermediate repre-sentation (IR) between text and layout to formally repre-sent diverse layout constraints, such as element type, size, and hierarchy. By introducing IR, our approach decom-poses Text-to-Layout into two stages: parse and place. The parse stage takes a textual description as input and outputs
IR. Since IR is a representation of layout constraints spec-ified in the text, we formulate the parse stage as a natural language understanding problem and finetune the T5 [29]
PLM to map the text to IR. The place stage generates lay-outs according to the constraints stated in IR. Inspired by
UniLayout [15], we use a Transformer-based layout gener-ation model and carefully design an input-output sequence format to represent combined, incomplete constraints and layouts. In addition, owing to the two-stage design of our approach, we can leverage large-scale unlabeled layouts to pretrain the layout generation model and then finetune it with labeled data.
To evaluate our approach, we construct two Text-to-Layout datasets: Web5K and RICO2.5K. Web5K targets
Web page layouts and contains 4,790 ⟨text, IR, layout⟩ samples, while RICO2.5K targets Android UI layouts and includes 2,412 samples. The quantitative and qualitative results on both datasets show that parse-then-place signifi-cantly outperforms baseline approaches in terms of percep-tual quality and consistency. We also conduct a user study to evaluate our approach more comprehensively. Compared to the baseline approaches, users find that our generated lay-outs better match textual descriptions in 47.6% and 56.0% of trials, and have higher quality in 52.2% and 62.5% of trials in Web5K and RICO2.5K, respectively. 2.