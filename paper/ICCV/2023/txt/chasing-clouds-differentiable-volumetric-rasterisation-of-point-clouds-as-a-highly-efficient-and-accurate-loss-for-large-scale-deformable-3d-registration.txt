Abstract
Learning-based registration for large-scale 3D point clouds has been shown to improve robustness and accuracy compared to classical methods and can be trained without supervision for locally rigid problems. However, for tasks with highly deformable structures, such as alignment of pulmonary vascular trees for medical diagnostics, previous approaches of self-supervision with regularisation and point distance losses have failed to succeed, leading to the need for complex synthetic augmentation strategies to obtain reliably strong supervision.
In this work, we introduce a novel Differentiable Volumetric Rasterisation of point Clouds (DiVRoC) that overcomes those limitations and offers a highly efficient and accurate loss for large-scale deformable 3D registration. DiVRoC drastically reduces the computational complexity for measuring point cloud distances for high-resolution data with over 100k 3D points and can also be employed to extrapolate and regularise sparse motion fields, as loss in a self-training setting and as objective function in instance optimisation.
DiVRoC can be successfully embedded into geometric registration networks, including PointPWC-Net and other graph CNNs. Our approach yields new state-of-the-art accuracy on the challenging PVT dataset in three different settings without training with manual ground truth: 1) unsupervised metric-based learning 2) self-supervised learning with pseudo labels generated by self-training and 3) optimisation based alignment without learning. https://github.com/mattiaspaul/
ChasingClouds 1.

Introduction
Learning-based point cloud or shape registration has seen increasing interest in computer vision and medical imaging over recent years [56] due to its ability to model 3D motion for sequences of (multi-view) depth images or
LiDAR measurements within a dynamic scene as well as for
Figure 1. Overview of our key contributions for unsupervised learning of highly deformable 3D point cloud registration. surface and tree-like representations in medical 3D scans.
Point clouds offer benefits of representing a 3D scene more sparsely and efficiently than voxelised volumes and they im-mensely reduce privacy concerns of data sharing since iden-tifying intensity information is removed. However, they come with the difficulty of defining convolutional opera-tors, neighbourhood information and loss functions without a regular grid. Many recent works define graph convolu-tional operators to solve point cloud classification and se-mantic segmentation tasks [4, 19, 45, 48, 57].
For scene flow estimation of predominantly rigid ob-jects that move dynamically a number of geometric network approaches for self-supervised and supervised learning of correspondences have been proposed: flow embedding lay-ers (FlowNet3D) [21], bilateral convolutions [13], optimal transport based solutions (FLOT) [34], cost volume based methods with multiple warping steps (PointPWC-Net) [49], iterative approaches (PV-RAFT) [47].
While scene flow estimation usually requires high frame rate throughput on moderately sized point clouds, 3D med-ical imaging for diagnosis mandates registration accuracies at millimetre-scale on high-resolution clouds but may al-low for computation times of hundreds of milliseconds to around 1 second even in interventional procedures. For re-lated work in medical registration and lung imaging the use of instance optimisation as a refinement to a robust network prediction has thus become imminent [14, 39, 38] to com-pensate subtle domain shifts that are introduced by the pa-tient specific anatomy, e.g. the topology of vascular trees is highly varying across a population.
To date, few methods have successfully addressed the registration of highly deformable geometric structures e.g. the lungs, as discussed in the recent NeurIPS paper on ro-bust optimal transport (RobOT) [38]. The authors in par-ticular state that a key lesson from their experiments and ablation studies on the new pulmonary vascular tree (PVT) dataset on respiratory motion estimation was that metric-based unsupervised learning did not yield to a competitive level of accuracy despite exploring a variety of point cloud metrics, including local Laplacian matching [49] as well as Chamfer and Wasserstein distances [10, 28]. They ar-gue that this is due to the complex geometric structure of the lung anatomy and the significant differences in shape found between inspiration and exhale scans that are usually not present in surface meshes or other clean point clouds that unsupervised methods were primarily designed for and evaluated on. RobOT therefore resorts to a sophisticated synthetic simulation of deformable lung motion to provide strong supervision. They propose a multistep approach that comprises affine pre-alignment, PointPWC flow prediction and robust optimal transport with post-processing to set a state-of-the-art accuracy of 2.86mm, which clearly outper-forms classical optimisation based methods.
Motivation: We argue that the difficulties of previous attempts to learn point cloud registration of intrinsically deformable structures without stronger supervision stems from three problems of related works. First, using a geo-metric network that can freely predict sparse displacements with only a soft penalty on the regularity of the deforma-tion makes unsupervised learning with a cost function that exhibits many local minima nearly infeasible. Hence, a stronger link between regularisation and network prediction has to be established. Second, point-based metrics can be prone to sparse differentiability with respect to the hyper-parameter choice, e.g. the nearest neighbours for the Cham-fer distance or blur in the sinkhorn metric used in optimal transport [11]. Third, the importance of highly efficient in-stance optimisation to compensate differences between the learned population model and patient-specific graph topol-ogy has so far been partially overlooked.
In this work, we overcome those difficulties by pre-senting a novel differentiable volumetric rasterisation (Di-VRoC) for 3D point cloud losses, which substantially re-duces the sparsity of the loss gradients and avoids quanti-sation errors (e.g. found in occupancy grids [24]) and can achieve new state-of-the-art accuracy in unsupervised reg-istration when embedded in a more explicit regularisation strategy again realised with DiVRoC. The new measure also excels at rapid instance optimisation that can for one be used in self-supervised learning (as pseudo ground truth) and helps to achieve highly accurate alignment of detailed point clouds while remaining competitive in inference run times. 1.1. Contribution
Our newly presented differentiable volumetric rasterisa-tion (DiVRoC) technique is the core strength of our method that constitutes the following key contributions: 1. Unsupervised learning of highly deformable point cloud registration. For the first time we demonstrate that geometric registration of vascular trees can be trained in an unsupervised fashion and more effectively than with stronger supervision through synthetically generated pairs. 2. A novel and highly scalable differentiable volumet-ric rasterisation technique for point clouds. This mod-ule enables a robust, accurate and fast computation of point cloud distances or losses with respective gradients for the corresponding displacement vectors.
It can also be em-ployed to densify and implicitly regularise sparse point cloud motion and helps to substantially stabilise training. 3. Sub-second large-motion instance optimisation on point cloud pairs with over 100k 3D points each that can correct residual errors of network predictions and provide pseudo ground truth for self-training of larger models. 4. New state-of-the-art performance on the challeng-ing PVT dataset. Ablation studies that demonstrate the benefits of DiVRoC for loss function, implicit regularisa-tion and instance optimisation over previous research. 5. A new dataset for out-of-domain evaluation with a total of 1500 manual landmark pair annotations for 30 scans and further large-scale point cloud data of cancer screening scans is created and will be made public. 2.