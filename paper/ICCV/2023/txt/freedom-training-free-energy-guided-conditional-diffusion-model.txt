Abstract
Recently, conditional diffusion models have gained pop-ularity in numerous applications due to their exceptional generation ability. However, many existing methods are training-required. They need to train a time-dependent clas-sifier or a condition-dependent score estimator, which in-creases the cost of constructing conditional diffusion mod-els and is inconvenient to transfer across different condi-tions. Some current works aim to overcome this limita-tion by proposing training-free solutions, but most can only be applied to a specific category of tasks and not to more general conditions.
In this work, we propose a training-Free conditional Diffusion Model (FreeDoM) used for var-ious conditions. Specifically, we leverage off-the-shelf pre-trained networks, such as a face detection model, to con-struct time-independent energy functions, which guide the generation process without requiring training. Further-more, because the construction of the energy function is very flexible and adaptable to various conditions, our pro-posed FreeDoM has a broader range of applications than existing training-free methods. FreeDoM is advantageous in its simplicity, effectiveness, and low cost. Experiments demonstrate that FreeDoM is effective for various condi-tions and suitable for diffusion models of diverse data do-mains, including image and latent code domains. Code is available at https://github.com/vvictoryuki/
FreeDoM . 1.

Introduction
Recently, diffusion models have been demonstrated to outperform previous state-of-the-art generative mod-els [10], such as GANs [12, 29, 3, 22, 24, 23]. The im-pressive generative power of diffusion models [15, 43, 45] has motivated researchers to apply diffusion models to var-ious downstream tasks. Conditional generation is one of the most popular focus areas. Conditional diffusion mod-els (CDMs) with diverse conditions have been proposed, such as text [20, 1, 13, 26, 36, 40, 35, 38, 25, 32], class la-bels [10], degraded images [5, 6, 7, 8, 19, 27, 42, 44, 47, 37, 39, 48], segmentation maps [31, 52], landmarks [31, 52], hand-drawn sketches [31, 52], style images [31, 52], etc.
These CDMs can be roughly divided into two categories: training-required or training-free.
A typical type of training-required CDMs trains a time-dependent classifier to guide the noisy image xt toward the given condition c [10, 32, 53, 26]. Another branch of
â€ Corresponding authors. This work was supported by Shenzhen Gen-eral Research Project under Grant JCYJ20220531093215035, KAUST Of-fice of Sponsored Research through the Visual Computing Center funding, and SDAIA-KAUST Center of Excellence in Data Science and Artificial
Intelligence. training-required CDMs directly trains a new score estima-tor s(xt, t, c) conditioned on c [31, 16, 36, 37, 39, 48, 52, 20, 1, 13, 35, 32]. These methods yield impressive perfor-mance but are not flexible. Once a new target condition is needed for generation, they have to retrain or finetune the models, which is inconvenient and expensive.
In contrast, training-free CDMs try to solve the same problems without extra training. [30, 11, 14] attempt to use the cross-attention control to realize the conditional gener-ation; [5, 6, 7, 8, 19, 27, 42, 44, 47, 46] directly modify the intermediate results to achieve zero-shot image restoration;
[28] realizes image translation by adjusting the initial noisy images. While these methods are effective in a single ap-plication, they are difficult to generalize to a wider range of conditions, e.g., style, face ID, and segmentation masks.
In order to make CDMs support a wide range of con-ditions in a training-free manner, this paper proposes a training-Free conditional Diffusion Model (FreeDoM) with the following two key points. Firstly, to emphasize generalization, we propose a sampling process guided by the energy function [53, 21], which is very flexible to con-struct and can be applied to various conditions. Secondly, to make the proposed method training-free, we use off-the-shelf pre-trained time-independent models, which are easily accessible online, to construct the energy function.
Our FreeDoM has the following advantages: (1) Sim-ple and effective. We only insert a derivative step of the energy function gradient into the unconditional sampling process of the original diffusion models. Extensive experi-ments show its effective controlling capability. (2) Low cost and efficient. The energy functions we construct are time-independent and do not need to be retrained. The diffusion models we choose do not need to be trained on the desired conditions. Thanks to the efficient time-travel strategy we use for large data domains, the number of sampling steps we use is quite small, which speeds up the sampling process while ensuring good generated results. (3) Amenable to a wide range of applications. The conditions our method supports include, but are not limited to, text, segmentation maps, sketches, landmarks, face IDs, style images, etc. In addition, various complex but interesting applications can be realized by combining multiple conditions. (4) Supports different types of diffusion models. Regardless of the con-sidered data domain, such as human face images, images in ImageNet, or latent codes extracted from an image en-coder, extensive experiments demonstrate that our method does well on all of them. 2.