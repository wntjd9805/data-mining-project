Abstract
The goal of Online Domain Adaptation for semantic seg-mentation is to handle unforeseeable domain changes that occur during deployment, like sudden weather events. How-ever, the high computational costs associated with brute-force adaptation make this paradigm unfeasible for real-world applications. In this paper we propose HAMLET, a
Hardware-Aware Modular Least Expensive Training frame-work for real-time domain adaptation. Our approach in-cludes a hardware-aware back-propagation orchestration agent (HAMT) and a dedicated domain-shift detector that enables active control over when and how the model is adapted (LT). Thanks to these advancements, our approach is capable of performing semantic segmentation while si-multaneously adapting at more than 29FPS on a single consumer-grade GPU. Our framework’s encouraging ac-curacy and speed trade-off is demonstrated on OnDA and
SHIFT benchmarks through experimental results. 1.

Introduction
Semantic segmentation aims at classifying an image at a pixel level, based on the local and global context, to enable a higher level of understanding of the depicted
Figure 2: Online adaptation methods on the Increasing
Storm. We plot mIoUs achieved on single domains. Colors from colder to warmer encode slower to faster methods. scene. In recent years, deep learning has become the dom-inant paradigm to tackle this task effectively employing
CNNs [5, 69, 4] or, more recently, transformers [65], at the expense of requiring large quantities of annotated images for training. Specifically, annotating for this task needs per-pixel labeling, which is an expensive and time-consuming task, severely limiting the availability of training data.
The use of simulations and graphics engines [42] to generate annotated frames enabled a marked decrease in the time and cost necessary to gather labeled data thanks
∗ Joint first authorship
† Part of the work done while at Univrses
to the availability of the ground truth. However, despite the increasing quality in data realism [47], there is a sub-stantial difference between simulated data generated by graphics engines and real-world images, such that leverag-ing these data for real-world applications requires adapt-ing over a significant domain shift. The promise of un-locking this cheap and plentiful source of training data has provided a major impulse behind the development of a large body of work on Unsupervised Domain Adaptation (UDA) techniques [74, 61, 18, 15, 55], consisting of train-ing semantic segmentation networks on labelled synthetic frames – the source domain – and then adapting the net-work to operate on real images, representing the target do-main, without requiring human annotation. However, the synthetic-to-real shift represents only one of many possi-ble domain transitions; specifically, when dealing with real-world deployment, domain shifts can occur from various causes, from different camera placements to different light-ing, weather conditions, urban scenario, or any possible combination of the above. Because of the combinatorial nature of the problem, it is simply impossible to evenly rep-resent all possible deployment domains in a dataset. This curse of dimensionality prevents having generalized robust perfomances [41, 45]. However, the recent advent of on-line domain adaptation [41] potentially allows us to face continuous and unpredictable domain shifts at deployment time, without requiring data associated with such domain shifts beforehand. Nonetheless, despite its potential, sev-eral severe limitations still hamper the online adaptation
In particular, continuously performing back-paradigm. propagation on a frame-by-frame schedule [41] incurs a high computational cost, which negatively affects the per-formance of the network, dropping its overall framerate to accommodate the need for continuous adaptation. Vari-ous factors are involved in this matter: first, the severity of this overhead is proportional to the complexity of the network itself – the larger the number of parameters, the heavier the adaptation process becomes; second, we argue that frame-by-frame optimization is an excessive process for the adaptation itself – not only the network might need much fewer optimization steps to effectively counter do-main shifts, but also such an intense adaptation definitely increases the likelihood of catastrophic forgetting over pre-vious domains [26, 45]. In summary, a practical solution for online domain adaptation in semantic segmentation that can effectively operate in real-world environments and ap-plications still seems to be a distant goal.
In this paper, we propose a novel framework aimed at overcoming these issues and thus allowing for real-time, on-line domain adaptation:
• We address the problem of online training by de-signing an automatic lightweight mechanism capable of significantly reducing back-propagation complex-ity. We exploit the model modularity to automati-cally choose to train the network subset which yields the highest improvement for the allocated optimisation time. This approach reduces back-propagation FLOPS by 34% while minimizing the impact on accuracy.
• In an orthogonal fashion to the previous contribution, we introduce a lightweight domain detector. This al-lows us to design principled strategies to activate train-ing only when it really matters as well as setting hy-perparameters to maximize adaptation speed. Overall, these strategies increase our speed by over 5× while sacrificing less than 2.6% in mIoU.
• We evaluate our method on multiple online domain adaptation benchmarks both fully synthetic [45] and semi-synthetic CityScapes domain sequences [41], showing superior accuracy and speed compared to other test-time adaptation strategies.
Fig. 1 demonstrates the superior real-time adaptation performance of HAMLET compared to slower methods such as CoTTA [57], which experience significant drops in performance when forced to maintain a similar framerate by adapting only once every 50 frames. In contrast, HAMLET achieves an impressive 29 FPS while maintaining high ac-curacy. Additionally, Fig. 2 offers a glimpse of HAMLET’s performance on the Increasing Storm benchmark [41], fur-ther highlighting its favorable accuracy-speed trade-off. 2.