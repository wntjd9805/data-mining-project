Abstract
In monocular depth estimation, uncertainty estimation approaches mainly target the data uncertainty introduced by image noise. In contrast to prior work, we address the uncertainty due to lack of knowledge, which is relevant for the detection of data not represented by the training distri-bution, the so-called out-of-distribution (OOD) data. Mo-tivated by anomaly detection, we propose to detect OOD images from an encoder-decoder depth estimation model based on the reconstruction error. Given the features ex-tracted with the fixed depth encoder, we train an image de-coder for image reconstruction using only in-distribution data. Consequently, OOD images result in a high recon-struction error, which we use to distinguish between in-and out-of-distribution samples. We built our experiments on the standard NYU Depth V2 and KITTI benchmarks as in-distribution data. Our post hoc method performs aston-ishingly well on different models and outperforms existing uncertainty estimation approaches without modifying the trained encoder-decoder depth estimation model. 1.

Introduction
Despite the astonishing performance of deep neural net-works in monocular depth estimation, image irregularities, e.g., reflections or occlusions, as well as unknown objects or completely unknown environments, lead to incorrect depth predictions. Figure 1 shows example predictions (center) from a depth estimation model trained on KITTI [14] for test images from the same dataset (top, left) as well as vir-tual KITTI [4] (bottom, left). Since virtual KITTI con-sists of synthetically generated data, the test image is not included in the training data and presents an unknown envi-ronment. The error plot (right) corresponding to the depth prediction (center) shows that the depth estimate for the truck, whose surface has reflections, is incorrectly estimated to be too high. Therefore, the truckâ€™s position is incorrect based on the depth estimates, highlighting the importance of identifying inputs for which the depth predictions are unre-liable. This is a crucial aspect for the usage in safety-critical applications such as automated driving or robotics.
The erroneous predictions, in general, can be due to dif-ferent types of uncertainty. The main distinction is between data uncertainty (aleatoric), which results from noise in the data, and model uncertainty (epistemic), which is due to lack of knowledge and therefore addressable with more di-verse training data [29]. Recent works [22, 29, 41, 46] al-ready target uncertainty estimation for depth estimation in the context of deep neural networks. Moreover, they eval-uate whether the uncertainty corresponds to the actual er-ror in the test data drawn from the same distribution as the training data. However, the current evaluation proto-col only addresses the aleatoric uncertainty but not the epis-temic uncertainty. Since epistemic uncertainty results from the lack of knowledge, it is relevant to detecting data not represented by the training distribution, so-called out-of-distribution (OOD) data. While OOD detection is an ac-tive research area in image classification [23, 24, 37, 44], it is rarely explored for complex and high-dimensional tasks like monocular depth estimation. Therefore, we specifically address the detection of OOD samples for depth estimates.
Motivated by the image anomaly detection approaches that rely on the reconstruction error [2, 7] of autoencoders to de-tect anomalous data, we propose to detect OOD inputs from depth estimation models also with the reconstruction error.
In fact, we train a decoder to reconstruct the input im-age from the features of an already trained and therefore fixed depth estimation model. Since we train the decoder in a post hoc fashion, the depth estimation performance of the underlying model is not affected. More precisely, our image decoder takes the features extracted with the depth encoder of the fixed depth estimation model as input and is trained to predict the original input image. To develop our decoder, we rely on a similar model architecture as the depth decoder. As a result, our method is applicable to vari-ous depth estimation models and independent of some spe-cific architecture, i.e., whether the depth estimation model is fully convolutional or transformer-based does not play any role. During inference, the reconstruction error between the predicted and input images serves as the OOD detection score. Our extensive experiments with the OOD detection evaluation protocol show promising results for our method compared to existing uncertainty estimation approaches.
Our contributions can be summarized as follows: To the best of our knowledge, we are the first to propose an
OOD detection method for monocular depth estimation.
For this, we do not use OOD examples but rely only on
In our simple and effective in-distribution training data. method, we present a second model, represented by an im-age decoder, to learn image reconstruction post hoc with features extracted by the depth encoder as input. We lever-age the reconstruction error as our OOD detection score.
We introduce an epistemic uncertainty evaluation protocol that addresses OOD detection with extensive experiments using the standard benchmarks NYU Depth V2 [38] and
KITTI [14] as in-distribution data and up to three different
OOD datasets. Models and code are publicly available.1 2.