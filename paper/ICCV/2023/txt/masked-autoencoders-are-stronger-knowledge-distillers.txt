Abstract
Knowledge distillation (KD) has shown great success in improving student’s performance by mimicking the interme-diate output of the high-capacity teacher in fine-grained visual tasks, e.g. object detection. This paper proposes a technique called Masked Knowledge Distillation (MKD) that enhances this process using a masked autoencoding scheme. In MKD, random patches of the input image are masked, and the corresponding missing feature is recov-ered by forcing it to imitate the output of the teacher. MKD is based on two core designs. First, using the student as the encoder, we develop an adaptive decoder architec-ture, which includes a spatial alignment module that op-erates on the multi-scale features in the feature pyramid network (FPN) [20], a simple decoder, and a spatial re-covery module that mimics the teacher’s output from the latent representation and mask tokens. Second, we intro-duce the masked convolution in each convolution block to keep the masked patches unaffected by others. By coupling these two designs, we can further improve the completeness and effectiveness of teacher knowledge learning. We con-duct extensive experiments on different architectures with object detection and semantic segmentation. The results show that all the students can achieve further improvements compared to the conventional KD. Notably, we establish the new state-of-the-art results by boosting RetinaNet ResNet-18, and ResNet-50 from 33.4 to 37.5 mAP, and 37.4 to 41.5 mAP, respectively. 1.

Introduction
As fundamental tasks in computer vision, high-level vi-sual predictions such as object detection, instance segmen-tation, and semantic segmentation have been widely used in various practical applications. In real-world scenarios, im-proving the performance of the deployable models is cru-cial. Improving the performance of a lightweight student
*Work done during internship at SenseTime Research.
†Corresponding authors.
Figure 1: Visualization of feature maps of teacher networks (RetinaNet-ResX101) and student networks (RetinaNet-Res50) with different KD paradigms. model via a high-capacity teacher introduces an effective paradigm, which is widely known as Knowledge Distilla-tion (KD) [16, 4]. For dense visual prediction tasks, feature-based distillation [17, 7, 11] is more beneficial for the stu-dent to mimic the teacher’s intermediate features. Some elaborated feature-based distillation methods [29, 4, 40, 18] have established the state-of-the-art performance for many lightweight models such as ResNet-18 [15].
The core bottleneck of such feature-based KD is how to learn the complete knowledge from the teacher’s output containing about 20K spatial coordinates (calculated on the
COCO training set). According to our experiment, 72% of them are simple enough and converge quickly to achieve
∼90% similarity with the teacher’s output. The remain-ing important knowledge is suppressed by this large num-ber of simple samples, and it is difficult for the student to learn effectively. To further verify the existence of infor-mation redundancy in teacher features, we conduct experi-ments that, when 30% of the features are randomly masked during training and testing on Retina-R101 (38.4 mAP), it still achieved similar performance (38.1 mAP). Previous works [34, 46] point out similar observations that each pixel contributes equally if using a common distillation loss (e.g.
MSE), which will cause the network to easily learn a lot of similar information and is hard to identify important in-formation. So they use attention [45, 40] and decouple the
foreground and background feature [34, 46] to help alleviate this problem. But attention can still lead to the imbalance of information learning.
In order to learn the complete information without be-ing affected by the spatial redundancy in teacher features, we introduce the Mask Image Modeling (MIM) mecha-nism to effectively promote the learning of this informa-tion. To be more specific, we propose a new Masked
Knowledge Distillation (MKD) framework to improve the knowledge learning of the student via the masked autoen-coding paradigm. The core idea is that we mask random patches of the input image of the student while maintain-ing the whole input image for the teacher, and then recover the corresponding missing feature by forcing the student to imitate the output of the teacher. In this way, the student network is encouraged to predict the masked patches with corrupted input images and learn the relationship between the masked area and its surrounding regions, rather than simply imitating the output feature of the teacher at visible patches. We conduct some experiments trying to excavate the potential ability of the students. As shown in Fig. 1, according to the feature comparison in the red box, it can be observed that student network using MKD learns more complete knowledge from teacher than the direct feature-based method [1] and the attention-based method [40].
We introduce two crucial designs to alleviate some bot-tlenecks in this framework. First, due to the masked im-age input, directly applying the normal convolution in the convolutional neural networks (CNN) will confuse the la-tent representation in visible and invisible patches. There-fore, we adopt the masked convolution [10, 23] to keep the masked patches not affected by others in each convolution block. Second, multi-scale features are often used in fine-grained high-level visual tasks which have different masked sizes, leading to inconsistent feature reconstruction. We de-veloped an adaptive decoder architecture for this problem to predict the teacher’s feature in the corresponding masked area. More specifically, a spatial alignment module is first operated on the multi-scale features to align them to the same spatial resolution. A mask token is then replicated multiple times to replace the features in the masked area.
The features in the visible patches and mask tokens are sent to an adaptive transformer decoder to reconstruct the teacher’s feature. Finally, we conduct the spatial recovery module to convert the same spatial resolution to the original multi-scale resolution to perform feature-based distillation.
In our method, by the mask autoencoding paradigm with asymmetric input for student and teacher, the student is forced to infer the teacher’s features in the invisible patches by imitating the teacher’s features in the visible patches. We observe that the mask tokens in the decoder try to absorb knowledge from their adjacent region to restore the features in the masked region. Completely restoring the masked fea-Figure 2: The average L2 distance between student’s feature and teacher’s feature calculated at the unmasked areas with
RetinaNet-ResX101 distilling RetinaNet-Res50. tures drives it to fully learn the teacher’s corresponding in-formation in these adjacent areas. As shown in Fig. 2, the
L2 distance value in adjacent regions of the mask can be lower with masked input. This verifies the claim that the student network can better learn the teacher’s knowledge in our learning manner. MKD can be directly used in differ-ent architectures and various dense visual prediction tasks, e.g., object detection and semantic segmentation. The re-sults show that MKD can improve considerably cooperated with conventional feature-based distillation. For instance, with MKD in RetinaNet, the mAP of student ResNet-18 is greatly improved to 37.5, 4.1% higher than the baseline, and also outperforms the previous SOTA methods. To sum up, our contributions are as follows:
• We propose a new paradigm for feature-based distilla-tion named MKD, using mask autoencoding scheme to effectively learn the complete knowledge in the teacher network. MKD masks random patches of the input im-age and recovers the corresponding masked feature by forcing it to imitate the teacher’s output.
• We introduce the masked convolution and adaptive de-coder module in MKD to make it easy to cooperate with different architectures in fine-grained visual tasks, e.g., object detection and semantic segmentation.
• Extensive experiments on various models and tasks verify the effectiveness of our method. For different student architectures and tasks, MKD can further im-prove the performance of feature-based distillation and establish new state-of-the-art. 2.