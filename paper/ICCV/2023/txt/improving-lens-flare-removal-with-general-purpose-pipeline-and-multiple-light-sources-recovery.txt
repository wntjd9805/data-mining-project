Abstract
When taking images against strong light sources, the re-sulting images often contain heterogeneous ﬂare artifacts.
These artifacts can importantly affect image visual quality and downstream computer vision tasks. While collecting real data pairs of ﬂare-corrupted/ﬂare-free images for train-ing ﬂare removal models is challenging, current methods utilize the direct-add approach to synthesize data. However, these methods do not consider automatic exposure and tone mapping in image signal processing pipeline (ISP), lead-ing to the limited generalization capability of deep models training using such data. Besides, existing methods struggle to handle multiple light sources due to the different sizes, shapes and illuminance of various light sources. In this paper, we propose a solution to improve the performance of lens ﬂare removal by revisiting the ISP and remodeling
*Corresponding author: liangdong@nuaa.edu.cn the principle of automatic exposure in the synthesis pipeline and design a more reliable light sources recovery strategy.
The new pipeline approaches realistic imaging by discrim-inating the local and global illumination through convex combination, avoiding global illumination shifting and local over-saturation. Our strategy for recovering multiple light sources convexly averages the input and output of the neu-ral network based on illuminance levels, thereby avoiding the need for a hard threshold in identifying light sources.
We also contribute a new ﬂare removal testing dataset con-taining the ﬂare-corrupted images captured by ten types of consumer electronics. The dataset facilitates the veriﬁcation of the generalization capability of ﬂare removal methods.
Extensive experiments show that our solution can effectively improve the performance of lens ﬂare removal and push the frontier toward more general situations.
1.

Introduction
Lens ﬂare artifacts commonly appear in the forms of ha-los, streaks, saturated blobs, and color bleeding [31]. These artifacts can be roughly classiﬁed into two groups: scatter-ing ﬂare and reﬂective ﬂare. Scattering ﬂare occurs due to dust or wears in front of the lens, while reﬂective ﬂare is caused by light reﬂection within the lens system. Physically, anti-reﬂection coating inside the lens system can partially suppress ﬂare. However, in smartphone imaging with a sim-pliﬁed lens system and easily contaminated lens surfaces,
ﬂare is exacerbated. Lens ﬂare not only affects the visual quality of images but also degrades the performance of down-stream computer vision tasks such as object detection in an automatic driving system. Removing lens ﬂare from an im-age is an extremely challenging task since it is closely related to the properties of the light sources, such as the incident angle, location, size, intensity, and spectrum, as well as the heterogeneous lens types.
Like other low-level computer vision tasks such as reﬂec-tion removal [9, 19], low light enhancement [11, 20, 16], and haze removal [21, 12, 15], the lack of paired training data is the biggest obstacle in the task of ﬂare removal. Creat-ing large amounts of paired training data is time-consuming and labour-intensive. To solve this issue, a recent work [31] created a ﬂare dataset with 2001 captured ﬂare-only images and 3000 simulated ﬂare-only images. To address the is-sue of trained models performing poorly in nighttime, a new dataset Flare7K [6] was created speciﬁcally to remove nighttime ﬂares. However, these works assume that the ﬂare-free and ﬂare-only images are two independent layers and directly adds them in the RAW space. As the RAW for-mats of both ﬂare and scene are not available, this work regards the inverse gamma transformed image as the RAW image, ignoring the typical tone mapping operator (TMO) in an image signal processing pipeline (ISP) (see Figure. 3).
Since the transformation from RAW to RGB image is ir-reversible, directly adding the two layers may suffer from the over-saturation issue with low contrast, as shown in Fig-ure. 2(a). Furthermore, most consumer cameras are equipped with auto-exposure (AE), which automatically adjusts the aperture and shutter speed to control the amount of light.
Consequently, directly adding a ﬂare image can brighten the scene, which is inconsistent with AE and causes an overall intensity distribution shift. (see Figure. 4)
In addition to the drawbacks of the existing ﬂare synthesis pipeline, the light source recovery problem still challenges current ﬂare removal methods, particularly in recovering multiple light sources. Most networks typically remove the light source along with the ﬂare, as they cannot identify and separate the light source from the ﬂare. To alleviate this prob-lem, recent methods [31, 6] tend to ﬁnd the brightest con-nectivity component and apply a smoothing post-processing operation. The failure to do so may result in an unrealistic light source appearance, as the failure case in Figure. 2(c).
Unlike the previous works that focus on data prepara-tion in daytime [31] and nighttime [31, 6] or design speciﬁc networks [23], we provide two key insights to improve the performance of lens ﬂare removal, both of which are ignored by the previous research: (1) How to synthesize more re-alistic ﬂare-corrupted images to simulate the general AE mode and takes tone mapping into consideration? (2) How to recover one or multiple light sources naturally and avoid the hard threshold?
To achieve that, we ﬁrst revisit the ISP and remodel the optical synthesis principle. Then we propose a solution to generate more realistic ﬂare-corrupted images and pre-serve multiple light sources well in the ﬁnal results. Rather than directly adding the scene and ﬂare, our data synthe-sis pipeline generates ﬂare-corrupted images by pixel-wise convex combinations between the scene and ﬂare image in inverse gamma space. Our new pipeline effectively avoids the issues of global illumination shifting and local over-saturation in synthetic images. Unlike previous methods, where the light sources are always affected along with the
ﬂare, our method can recover multiple light sources well.
It convexly averages of the input and output of the neural network based on illuminance levels and avoids the hard threshold when identifying light sources. In addition, we contribute a new ﬂare removal testing dataset containing the ﬂare-corrupted images captured by ten types of con-sumer electronics to supplement existing lens ﬂare datasets.
Extensive experiments demonstrate the effectiveness and contributions of our key designs. Our main contributions are summarized below.
• We systematically analyze the drawbacks of exist-ing lens ﬂare synthesis and creatively propose a new pipeline to generate more realistic ﬂare-corrupted im-ages and avoid illumination distribution shift for ﬂare removal.
• We solve the challenging light source preservation issue in ﬂare removal using an elegant strategy that can re-cover multiple light sources with heterogeneous shapes, illumination, and quantities.
• We contribute a new dataset that contains real ﬂare-corrupted images captured by diverse consumer elec-tronics, which provides an avenue to examine the gen-eralization performance of ﬂare removal methods. 2.