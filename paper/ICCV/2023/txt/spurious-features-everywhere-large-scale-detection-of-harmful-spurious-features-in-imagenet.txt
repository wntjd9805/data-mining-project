Abstract
Spurious Features in Training Data bird feeder grafﬁti eucalyptus label
Benchmark performance of deep learning classiﬁers alone is not a reliable predictor for the performance of a deployed model. In particular, if the image classiﬁer has picked up spurious features in the training data, its predic-tions can fail in unexpected ways.
In this paper, we de-velop a framework that allows us to systematically iden-tify spurious features in large datasets like ImageNet. It is based on our neural PCA components and their visualiza-tion. Previous work on spurious features often operates in toy settings or requires costly pixel-wise annotations.
In contrast, we work with ImageNet and validate our results by showing that presence of the harmful spurious feature of a class alone is sufﬁcient to trigger the prediction of that class. We introduce the novel dataset “Spurious ImageNet” which allows to measure the reliance of any ImageNet clas-siﬁer on harmful spurious features. Moreover, we introduce
SpuFix as a simple mitigation method to reduce the depen-dence of any ImageNet classiﬁer on previously identiﬁed harmful spurious features without requiring additional la-bels or retraining of the model. We provide code and data at https:// github.com/ YanNeu/ spurious imagenet. 1.

Introduction
Deep learning has led to tremendous progress in image classiﬁcation [37, 50] and natural language processing [14].
Over the years, however, it has become apparent, that evalu-ating predictive performance on a ﬁxed test set is not neces-sarily indicative of the performance when image classiﬁers are deployed in the wild. Several potential failure cases have been discovered. This starts with a lack of robust-ness due to image corruptions [31], adversarial perturba-tions [68], and arbitrary predictions on out-of-distribution inputs [45, 32, 30]. In this paper, we consider the problem of identifying and debugging image classiﬁers from spuri-ous features [2]. Spurious features in image classiﬁcation are features that co-occur with the actual class object and are picked up by the classiﬁer. In the worst case, they lead to shortcut learning [25], where only the spurious but not the
Hummingbird Freight Car
Koala
Hard Disc
Images from the web with spurious feature but no class features classiﬁed as class below
Hummingbird Freight Car
Koala
Hard Disc
Figure 1: Top: Examples of spurious features found via our neural PCA components but not in previous study [61].
Bottom: We validate our spurious features by mining im-ages from the web showing only the spurious feature but not the class. They are classiﬁed by four ImageNet models as the corresponding class. Some of them even contain Im-ageNet classes (bees on feeder, grasshopper in leaves). correct feature is associated with the class, e.g., [86] found that a pneumonia detector’s bad generalization across hos-pitals was caused by the neural network learning to iden-tify the hospital where the training data originated from. A weaker form of spurious feature (at least from a learning perspective) is the case when the classiﬁer picks up the cor-rect class features, e.g., of a hummingbird, but additionally associates a spurious feature, e.g., a bird feeder, with the class as they appear together on a subset of the training set.
This becomes a harmful spurious feature if only the spuri-ous feature without the class feature is sufﬁcient to trigger the classiﬁcation of that class, see Fig. 1 for an illustration of
such spurious features found via our method. Harmful spu-rious features are difﬁcult to detect and thus can easily go unnoticed, leading to unexpected behaviour of a deployed image classiﬁer.
In this paper we make the following key contributions:
• we develop a pipeline for the detection of harmful spuri-ous features with little human supervision based on our class-wise neural PCA (NPCA) components of an adver-sarially robust classiﬁer together with their Neural PCA
Feature Visualization (NPFV).
• unlike prior work, which used masking images or pixel-wise annotations, we validate our found spurious features by using our NPCA components to ﬁnd real images con-taining only the spurious feature but not the class object.
• using these images we create the dataset “Spurious Im-ageNet” and propose a measure for dependence on spu-rious features. We do a large-scale evaluation of state-of-the-art (SOTA) ImageNet models. We show that the spurious features found for the robust model generalize to non-robust classiﬁers. Moreover, we analyze the in-ﬂuence of different training setups, e.g. pre-training on
ImageNet21k or larger datasets like LAION.
• we develop SpuFix, a technique to mitigate the depen-dence on identiﬁed harmful spurious features without re-quiring new labels or retraining, and show how to trans-fer it to any ImageNet classiﬁer. SpuFix consistently im-proves the dependence on harmful spurious features even for SOTA models with negligible impact on test accuracy. 2.