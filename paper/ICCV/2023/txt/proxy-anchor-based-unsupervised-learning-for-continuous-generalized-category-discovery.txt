Abstract
Recent advances in deep learning have significantly im-proved the performance of various computer vision appli-cations. However, discovering novel categories in an in-cremental learning scenario remains a challenging problem due to the lack of prior knowledge about the number and na-ture of new categories. Existing methods for novel category discovery are limited by their reliance on labeled datasets and prior knowledge about the number of novel categories and the proportion of novel samples in the batch. To ad-dress the limitations and more accurately reflect real-world scenarios, in this paper, we propose a novel unsupervised class incremental learning approach for discovering novel categories on unlabeled sets without prior knowledge. The proposed method fine-tunes the feature extractor and proxy anchors on labeled sets, then splits samples into old and novel categories and clusters on the unlabeled dataset. Fur-thermore, the proxy anchors-based exemplar generates rep-resentative category vectors to mitigate catastrophic forget-ting. Experimental results demonstrate that our proposed approach outperforms the state-of-the-art methods on fine-grained datasets under real-world scenarios. 1.

Introduction
Deep neural networks have achieved remarkable perfor-mance in various computer vision tasks. However, current systems are still subject to constraints that are manually supervised and do not consider continual incremental cat-egories. For extending to real-world environments, there are still gaps to catch up by overcoming the constraints and improving their abilities in fundamental tasks. Specifically, humans still perform better than machines in object cog-nitive and grouping skills (e.g. recognizing new products or clothing on shopping and categorizing undefined moving objects while driving).
Various methods have been proposed to address the limitations of the tasks by considering real-world circum-stances, as presented in Figure 1 and Table 1.
In detail,
Novel Category Discovery (NCD) [10, 11, 43] and Gen-eralized Category Discovery (GCD) [36, 6] aim to recog-nize not only pre-trained categories but also discover novel categories using a given dataset. NCD considers a disjoint dataset where labeled and unlabeled novel samples have no intersection with each other. In contrast, GCD exploits the joint set with intersected categories, making GCD a more complicated task than NCD. However, these approaches do not consider the class incremental scheme. Class incremen-tal NCD (class-iNCD) [33, 15] has been proposed to adopt the incremental categories on NCD task, but they still fo-cus on improving novel category discovery performance us-ing the disjoint set, which is an unrealistic constraint. To address this issue, Grow and Merge (GM) [42] proposes a scenario that exploits the joint unlabeled dataset in the incremental novel category discovery task, which is called
Continuous Category Discovery Mixed Incremental (CCD-MI). However, most existing methods require prior knowl-edge, such as the number of unlabeled classes for NCD and class-iNCD, or the proportion of the novel samples in the batch for CCD-MI. Such prior knowledge requirements are not enough to mimic the real-world, as we lack information about the unlabeled sets.
To overcome these constraints, we propose a novel sce-nario that better represents real-world circumstances by re-moving constraints on the available data. We assume that the given datasets are unlabeled joint sets without provid-ing prior knowledge about the data. Employing the sce-nario, we propose a novel unsupervised class incremental
(a) NCD (b) GCD (c) class-iNCD (d) CCD-MI (e) CGCD
Figure 1. Comparison of existing and proposed scenarios for novel category discovery. The solid and dash-lined circles indicate labeled and unlabeled samples, respectively, with sample color depicting the class label. The circle with i denotes the number of novel classes (pink) and the proportion of novel class samples in a batch (dark blue).
Task
Method
Continual learning
NCD
GCD
RankStat [10, 11], DRNCD [43]
GCD [36], XCon [6]
Not considered
Not considered class-iNCD FRoST [33], NCDwF [15]
CCD-MI
GM [42]
CGCD
Ours
Considered
Considered
Considered
Constraints
Assumption:
Yl ∩ Yu = ∅
Required
Not required
Required
Not required
Number of novel classes
Required
Not required
Required
Not required
Proportion of new class data
Not required
Not required
Not required
Required
Not required
Not required
Not required
Table 1. Comparison of existing and proposed novel category discovery settings and the constraints learning approach to simultaneously address the problems of discovering incremental novel categories and alleviating catastrophic forgetting. In addition, we focus on recogniz-ing fine-grained objects, which is a more realistic use case for various applications in real-world applications.
The proposed method exploits a deep metric learning scheme, proxy anchor (PA) [18] that presents fast and re-liable convergence and robustness against noise samples, and also considers the relations between samples. Then, we divide the unlabeled data into old and novel categories using PAs, which inherit discriminative features of old cat-egories. The cosine similarity is measured between the PAs and the samples, and then initially separated datasets are acquired on a criterion. For further splitting, we adopt a noisy label learning scheme, and then assign the predictions of the previous model and the clustering results by a non-parametric approach to old and novel categorized samples, respectively. To mitigate the forgetting, we use a PA-based exemplar, which inherits more representative features. In the experimental results, we demonstrate that the proposed method outperforms the existing state-of-the-art in discov-ering novel categories and forgetting alleviation on various fine-grained datasets. Specifically, the proposed method does not require any prior knowledge and considers contin-ual learning on unlabeled joint datasets, making it a more realistic and practical solution for real-world scenarios.
The main contributions of the proposed method can be summarized as follows.
• We introduce a novel scenario, called Continuous Gen-eralized novel Category Discovery (CGCD), which is well-suited to tackle the challenges of discovering novel categories in real-world scenarios by removing the constraint that unlabeled data belong to only novel categories.
• We propose a novel unsupervised learning approach for incremental novel category discovery that does not require prior knowledge of the number of novel cate-gories or the proportion of new class data.
• We present a noisy label learning approach and deep metric learning to split unlabeled data into old and novel categories, and also show mitigation of catas-trophic forgetting using a deep metric-based exemplar.
• The proposed method outperforms the state-of-the-art methods in novel category discovery and forgetting mitigation on various fine-grained datasets. 2. Problem Definition 2.1. Continuous Generalized Category Discovery
As presented in Figure 1 and Table 1, various envi-ronmental schemes have been proposed to mimic real-world circumstances. Notable approaches include NCD
[10, 11, 43], GCD [36], class-iNCD [33, 15], and CCD [42].
NCD considers disjoint datasets between labeled and unla-beled sets (i.e. Yl∩Yu = ∅) and requires prior knowledge of the number of unlabeled categories |Yu|. In contrast, GCD exploits the joint set (i.e. Yl ∩ Yu ̸= ∅). Although GCD is a more challenging task than NCD, it still does not consider continuous incremental category discovery.
Figure 2. Overview of the proposed CGCD framework. The framework comprises three steps. The first step is that the network model is fine-tuned on the target dataset using the labeled dataset. In the second step, the discovery of novel categories is performed on the joint and unlabeled dataset, which is split into unseen and seen sets using the initial and fine split methods. Pseudo-labels are assigned to the unlabeled dataset using the previous model’s predictions (seen case) and non-parametric clustering results (unseen case). In the last step, a new model is trained on the fine split dataset, which incorporates new proxy anchors based on clustering results.
Class-iNCD is an extension of NCD to the continual learning scheme. However, the method trains on the dis-joint dataset under class incremental stages and has a re-quirement for |Yu|. CCD also trains on discovering novel classes under the continual learning scheme with the joint dataset. Although CCD does not require |Yu|, it still needs the proportion of the novel class data in a batch as prior knowledge, which is used to filter out the data.
To address these limitations, we propose a more chal-lenging problem, named Continuous Generalized novel
Category Discovery (CGCD), that is closer to real-world circumstances.
In CGCD, we exploit the unlabeled joint dataset in incremental steps without providing any prior knowledge and aim to discover novel classes. This formu-lation is more representative of real-world scenarios, where we are not aware of the number of unlabeled categories and the characteristics of the dataset. 2.2. Setting of Continuous Generalized Category
Discovery
Fine-grained datasets consist of similar objects, such as canines [16], indoor scenes [30], vehicles [25], and birds [37], in constrained circumstances. Compared to coarse datasets such as CIFAR [19] and ImageNet [20], fine-grained datasets are closer to real-world scenarios.
Therefore, we focus on training and discovering novel classes with fine-grained datasets to mimic real-world cir-cumstances better.
CGCD employs the joint unlabeled dataset in incremen-tal steps, and Table 2 describes the dataset partitioning used in the one-time incremental category discovery. First, the
Dataset
All classes
Initial step Category incremental step
Old class
Old class New class
CUB-200 200 67
MIT67
Stanford Dogs 120
FGVC Aircraft 100 160 (0.8) 53 (0.8) 96 (0.8) 80 (0.8) 160 (0.2) 53 (0.2) 96 (0.2) 80 (0.2) 40 (1.0) 14 (1.0) 24 (1.0) 20 (1.0)
Table 2. Dataset configurations for one-time incremental category scenarios. The number of classes and the proportion of data from each class in parentheses are presented. Note that the ratios in parentheses are hidden information that is not revealed to the learning methods. set of classes is partitioned into old classes and new classes at a certain rate, for example, 8 : 2. The initial step uti-lizes labeled dataset D0 consisting of old classes only. Then the following incremental step utilizes unlabeled dataset D1 consisting of both old classes and new classes, which reflect more realistic and challenging real-world scenarios. The key element of the proposed method is to decide whether the unlabeled data point belongs to the old classes (seen) or new classes (unseen). The samples belonging to the old classes are assigned to labeled dataset D0 and unlabeled dataset D1, and the rest of all the new class samples are assigned to D1.
Here the choice of 8 : 2 is an arbitrary example, and it is important to note that this ratio is just for data generation purposes and is not revealed to the learning methods. 3. Method
As described in Figure 2, our proposed method consists of three steps: the initial step, the novel category discov-In the ini-ery step, and the category incremental step. tial step, we fine-tune a pre-trained model on the labeled dataset D0 = {(x, y) ∈ Xl × Yl}, and obtain the embed-ding vector z using the model f (·), denoted as z = f 0(x).
We then use these vectors to train PAs [18] of each cate-gory, represented as p = g0(z), and also construct well-representative exemplars. In the following novel category discovery step, the given unlabeled joint datasets are de-noted as D1 = {x|x ∈ Xu}. We first separate them into old and novel categories through the initial and the fine splits.
Since the separated sets are unlabeled, we pseudo-label for old and novel classes using the previous model prediction and non-parametric clustering results, respectively.
In the category incremental step, the acquired set is trained to improve the performance of discovering novel categories. To avoid catastrophic forgetting, we exploit gen-erated features by the exemplar and feature distillation be-tween earlier and new models. The proposed model does not require any prior knowledge, such as |Yu| and the ratio of novel class samples in a batch. We evaluate the perfor-mance of the proposed method using the validation dataset, which includes all categories. 3.1. Initial Step: Fine Tune
Existing NCD methods do not account for noisy cate-gories, such as those categorized from old to novel or from novel to old, which can impair novel discovery performance and accumulate errors in the continuous procedure. To ad-dress these limitations, in this work, we propose a novel approach that leverages the benefits of PA to complement and improve the existing approaches. PA is a metric learn-ing method that combines proxy- and pair-based methods to achieve rapid and reliable convergence, and robustness against noisy samples, and considers relations between data to extract meaningful semantic information.
Following the method, the embedding vector z from the initial model f 0 is trained to map to each proxy anchor p = g0(z). Let the set of all proxy anchors as P 0 in the labeled data D0. In this manner, the number of proxy anchors of D0 is the number of classes of the labeled set (i.e. |P 0| = |Yl|) in the initial step. We train the model and proxy anchors using the following loss function defined in [18]:
L0 pa(Z 0) = 1
|P 0+| (cid:88) (cid:18) log 1 + (cid:88) (cid:19) e−α(s(z,p)−δ) p∈P 0+ z∈Z0+ p
+ 1
|P 0| (cid:88) p∈P 0 (cid:18) log 1 + (cid:88) (cid:19) eα(s(z,p)+δ) z∈Z0− p (1) where δ > 0 is a margin and α > 0 is a scaling factor. The function s(·,·) indicates the cosine similarity score. P 0+ represents same class PAs(e.g.positive) in the batch. Each proxy p divides the set of embedding vector Z 0 as Z 0+ and p (a) Initial Split (b) Fine Split
Figure 3. Separation results on joint unlabeled datasets p . Z 0+
Z 0− p = Z 0 − Z 0+ p denotes the same class embedding points with the proxy anchor p. The first term aims to pull p and its dissimilar but hard positive data together, while the last term is to push p and its similar but hard negatives apart. 3.2. Discovering Novel Categories Step
Separation: In this procedure, we aim to split the given joint dataset D1 into the novel and old categories without any prior knowledge. We conduct this task in two stages: initial split and fine split. In the initial split, we compute the cosine similarity between p and each embedding vector zi ∈ Z 1, where zi = f 0(xi) and xi ∈ D1. Because the set of proxy anchors P 0 represents the old categories, we classify a sample to the old class if the maximum similarity score of zi is larger than a threshold ϵ. We set ϵ = 0 since it is the median of the score ranges. The initial split is defined as:


˜yi = 0, if max p∈P 0 (s(zi, p)) ≥ ϵ = 0 (2)
 1, otherwise
To acquire a cleaner novel and old dataset, we propose a noisy labeling scheme, fine split, which involves an it-erative training of a simple multilayer perceptron (MLP) based classifier m(·) on the binarized dataset. The initial split results in noisy and inaccurate separation, as shown in Figure 3 (a). Among them, only the data on both ends of the spectrum are assumed the clean and utilized to train the classifier. The loss of split network m(·) is defined as follows:
Lsp = −Ezc∈Z1 c
[˜yc log(m(zc)) + (1 − ˜yc) log(1 − m(zc))] (3) where zc denotes clean embedding vectors, and Z 1 c rep-resents the set of clean vectors. ˜yc indicates the pseudo label of the clean data. After the warm-up training, the classi-fier is trained with re-assigned pseudo labels and the more cleaned data, which is divided with the Gaussian mixture model (GMM). Consequently, the Figure 3 (b) shows the cleaner separated results.
Pseudo-labeling: After the separation, both the old D1 old and the novel categories D1 new are still unlabeled. Thus, we use pseudo-labels to assign labels to each sample. For
D1 old, we use the predictions of the previous model and proxy anchors to assign pseudo-labels. In contrast, we use a
non-parametric clustering approach named Affinity propa-gation [8] to assign pseudo-labels to D1 new. In this manner, our proposed approach does not require any prior knowl-edge. Finally, from the clustering results, we obtain an esti-mate of the number of novel categories, denoted as | ˆYn|. 3.3. Category Incremental Step
Training modified model and PAs: To improve the per-formance of discovering novel categories, we modify the model since the previous model has PAs only for |Yl| classes and cannot categorize novel classes. We add new p for | ˆYn| classes, increasing the total number of PAs like
|P 1| = |Yl| + | ˆYn|. The loss function to train the modified model f 1 and PA p = g1(z) is reformulated as follows:
L1 pa(Z 1) = 1
|P 1+| (cid:88) (cid:18) log 1 + (cid:88) (cid:19) e−α(s(z,p)−δ) p∈P 1+ z∈Z1+ p
+ 1
|P 1| (cid:88) p∈P 1 (cid:18) log 1 + (cid:88) (cid:19) eα(s(z,p)+δ) z∈Z1− p (4)
Avoiding forgetting: In the continual learning scheme, it is essential to alleviate catastrophic forgetting. We adopt feature replay, which leverages the PA information belong-ing to old categories. Each well-trained p inherits the rep-resentation power for each category. We employ each p to generate features by following the Gaussian distribution
N (p0, σ2), p0 ∈ P 0. The number of generated features is determined based on data balancing, for example, the num-ber of newly categorized samples in a batch. The generated features are concatenated into a batch, and the model and
PAs are trained using the following loss function: ex( ˜Z) = L1
L1 pa( ˜Z),
˜Z = {˜z ∼ N (p0, σ2)} (5)
Also, we utilize the distillation of the extracted embed-ding vectors from the present f 1 and the previous model f 0.
The distillation loss Lkd is described as follows: 4. Experimental Results 4.1. Implementation Details
We utilized the widely used augmentation techniques, in-cluding random crop after padding and random horizontal flip. All the experiments were trained for 60 epochs using
AdamW optimizer with weight decay set to 0.0001. The initial learning rate was set to 0.0001 for the model f (·), while for the PAs, it was set to 0.01. The learning rate was decayed by a factor of 0.5 every five epochs. We used the threshold ϵ only once for the initial split to divide the set into old and novel categories, and we set it to 0 for all the datasets and networks. For fine split, we used an MLP-based network architecture that consists of two dense layers with a batch normalization layer. The model was trained for three epochs using AdamW with a learning rate of 0.0001.
The hyperparameters for PAs, α and δ, were set to 32 and 0.1, respectively.
For fair comparisons of various methods, such as NCD, class-iNCD, and CCD, we follow the hyperparameters and the network architectures of the original implementations, referring to the papers for details. All the reported perfor-mances are average results over three runs. 4.2. Evaluation Metrics
We evaluate the methods using metrics based on the clus-ter accuracy measurement, called Hungarian assignment al-gorithm [21]. The evaluation metric is defined as follows:
Mt = 1
|D|
|D| (cid:88) i=1
I(yi = h∗(y∗ i )) (8) where |D| is the size of the validation dataset D and h∗ is the optimal assignment. So, Mt measures the cluster accuracy at step t on the D. In this manner, Mall and Mo indicate the cluster accuracy metrics of the whole and old categories using Mt, respectively. Furthermore, we employ two more metrics that, Mf and Md, which are proposed on GM [42] and described as follows: kd(zo) = −E
L1
= −E zo∈Z1 old xo∈D1 old o − zo∥2
∥z0
∥f 0(xo) − f 1(xo)∥2 (6) where z0 represents the embedding vector for fixed pre-vious feature network f 0. Z 1 old denotes seen data from
Z 1 = {Z 1 old ∪ Z 1 new}.
In conclusion, the loss consists of three different losses in the continuous category discovery step. One loss is for training the PAs and the model on D1, the others are to avoid forgetting by using generated features and knowledge dis-tillation. L1 is described as follows:
L1 = L1 pa(Z 1) + L1 ex( ˜Z) + L1 kd(zo) (7)
Mf = max
{M0 o − Mt o}, t
Md = 1
|T | (cid:88) i=T
Mi n. (9) (10) o and Mt where M0 o are the old class cluster accuracy at the initial step and category incremental t step, respectively. So
Mf measures the maximum forgetting values for old cate-gories in the entire step and should be sufficiently low; if not, the method is not valuable in practical applications.
In Equation (10), |T | is the number of increased steps, and
Md evaluates the averaged performance of novel category discovery in unlabeled joint datasets in each step. It means
Method
Mall ↑Mo ↑ Mf ↓ Md ↑ Mall ↑Mo ↑ Mf ↓ Md ↑ Mall ↑Mo ↑ Mf ↓ Md ↑ Mall ↑Mo ↑ Mf ↓ Md ↑
CUB-200
MIT67
Stanford Dogs
FGVC aircraft
Supervised 61.69 45.83 23.32 16.63
DRNCD [43] 9.80 10.47 58.51 34.24
FRoST [33] 18.19 17.34 12.18 17.20 55.56 40.90 19.52 18.34 26.99 27.67 49.07 38.91 23.21 23.55 15.96 24.74 64.26 47.57 25.43 17.01 16.39 10.34 65.83 63.36 22.62 22.23 14.29 26.06 64.62 48.17 26.24 18.12 18.73 19.50 57.05 45.63 32.61 33.53 15.19 27.69
GM [42]
Ours 6.43 6.57 39.82 5.92 54.75 58.80 15.47 40.90 16.52 16.77 42.26 15.50 54.45 64.23 10.64 18.58 5.99 5.98 50.36 5.98 66.25 76.15 6.77 30.04 12.00 11.63 53.35 13.46 37.28 41.60 14.66 20.04
Table 3. Comparison results under continuous generalized categorized discovery scenario. The results present the mean over three runs.
Figure 4. Qualitative evaluation results of the proposed method using the CUB-200 dataset on ResNet-18. The first five columns with blue boxes denote well-clustered examples. The last two columns represent failed prediction results, including example images with purple boxes denoting hard negatives and those with red boxes indicating incorrect categorization. the higher method, the more appropriate method in real-world applications. 4.3. Comparison with State-of-the-arts Methods
We conducted a series of experiments to compare the cluster accuracy performance of our proposed method with state-of-the-art approaches, as presented in Table 1. In the experiments, we excluded the GCD task, including XCon, as it focuses on discovering novel categories blended with labeled and unlabeled datasets and evaluates unknown dis-covery performance on only train datasets, not validation datasets, in their papers. Therefore, we compared our pro-posed method with other approaches, including Dual rank
NCD (DRNCD) [43], FRoST [33], and GM, which are the representative methods that record the state-of-the-art re-sults of each task.
We first evaluated the one-step incremental category set-ting and reported the comparison results in Table 3. The supervised method is the setting of a supervised continual learning manner, literally. We observed catastrophic forget-ting in supervised learning. DRNCD is one of the NCD approaches and recorded the outstanding performances of
Md on MIT67, Stanford Dogs, and FGVC aircraft. How-ever, the method requires prior knowledge of the number of novel categories and does not identify specific classes, but only knows whether the samples are included in the novel category or not. Thus, the results are not regarded as outperforming. Instead, the method shows the highest results of Mf , which means that the method focuses on learning novel categories without considering the preven-tion of forgetting previous categorical knowledge. In this regard, NCD is not sufficient to extend novel class incre-mental learning schemes. FRoST showed competitive re-sults of discovering novel classes and decreased forgetting results Mf on all datasets compared to DRNCD. Never-theless, considering the required knowledge, the other met-rics results, Mall and Mo were not competitive. GM pro-posed the CCD setting, which is the most similar to CGCD, in the perspective of the unknown number of novel cat-egories and discovering novel and old categories on new unlabeled datasets. However, the method requires a cru-cial parameter, which is the ratio of novel category sam-ples on the new dataset. Without considering the ratio,
GM recorded the lowest results of Mall, Mo, and Md.
(a) Novel category discovery Md (b) Catastrophic forgetting Mf
Figure 5. Performances of novel category discovery and forgetting on two-step incremental novel categories experiment
The proposed method showed outstanding performance on the various datasets without requiring any prior informa-tion about new incoming unlabeled datasets. Our method recorded the second-best Mf on the CUB-200 dataset and the best Mf on the other datasets, such as MIT67, Dogs, and FGVC aircraft, by the effects of PA-based exemplar.
On Md, the method was also competitive and compared to the GM, which has the most similar setting to our method.
To evaluate the proposed method qualitatively, we clus-tered the evaluation dataset using the CUB-200 dataset.
In Figure 4, our method well-discovered novel categories and clustered them correctly. Each row is clustered into the same category, and the classes are novel categories on the evaluation dataset. The left five columns are well-clustered, while the last two are not. The sixth-column images are still reasonable, but the last-columns are the worst cases. 4.4. Two-step Novel Category Discovery
We present a two-step incremental category discovery experiment on the CUB-200 dataset using ResNet-18. The dataset configurations are more complicated as the datasets are joint sets in incremental steps. The initial step, the first incremental step, and the second incremental step have novel classes in each step, at a rate of 8 : 1 : 1, respectively.
Each step has its dataset and is indicated as D0, D1, and D2.
The samples belonging to novel labeled classes in the ini-tial step are assigned to D0, D1, and D2 at a rate of 8 : 1 : 1.
Similarly, the samples belonging to novel classes in the first incremental step are assigned to D1, and D2 at a rate of 8 : 2. Finally, the rest of the samples are assigned to D2.
Figure 5 describes the performance of the experiments.
Since each incremental step is trained for 60 epochs, there are deep drops at the 60th epoch when new PAs are added.
In addition, the cluster accuracy of the old categories, which belong to the D0, decreases by about 20%. The reason is that the number of old categories in the second incremental step is increased compared to the first step. The exemplar cannot focus on only generating the features of D0. How-ever, the performance of Md increased steadily. 4.5. Ablation Study
Effectiveness of separations: We conducted an ablation study to show the effectiveness of our proposed splitter,
Network
Fine Split
ResNet-18
ResNet-50
ViT-B-16 without with without with without with
Metric
Mall ↑ Mo ↑ Mf ↓ Md ↑ 53.32 54.75 66.53 68.09 70.22 72.51 57.63 16.56 36.47 58.80 15.47 40.90 71.07 71.75 9.12 8.44 48.76 53.79 73.02 10.75 59.24 65.60 9.49 74.28
Table 4. Ablation study for the proposed fine split on the CUB-200 using three different network architectures, including ResNet-18 and ResNet-50 pre-trained on ImageNet, and ViT-B-16 pre-trained on DINO-ImageNet. The results present the mean over three runs.
Network
Exemplar
Metric
Mall ↑ Mo ↑ Mf ↓ Md ↑
ResNet-18 without 38.24
Data mean and std. 40.23 54.75
Proxy anchors 37.31 36.88 41.89 40.56 33.63 37.22 58.80 15.47 40.90
Table 5. Effectiveness of the proposed PA-based exemplar on the
CUB-200 dataset using ResNet-18 pre-trained on ImageNet which consists of a combination of two different methods: the cosine similarity score and a binary splitter using the noise label approach. The ablation experiments were de-signed such that one used only the cosine similarity score, and another used both methods. As shown in Table 4, the approach using both methods presents improvements in both old and novel discovery performances. The results re-veal the effectiveness of noise labeling for data separation.
Effectiveness of Proxy anchor exemplar: To mitigate catastrophic forgetting, various approaches, such as re-play [2], prototype [31, 33], and pseudo-latents [15], have been proposed. Most of these methods exploit the computed average of feature embedding vectors or input data-driven values. However, we propose a novel PA-based exemplar approach and evaluate its efficiency. As shown in Table 5, the method without the exemplar recorded the highest novel discovery performances but also showed the highest forget-ting. Adopting a general exemplar approach using mean and standard deviation values from the former dataset, Mf slightly decreased, but Md is the lowest. However, our pro-posed method with the PA-based exemplar recorded the best
Mf and competitive Md. We analyze that the PAs have representatives of each cluster since PA inherits the relation between data to data and then representative figures of each class. Hence, our PA-based method leads to mitigating for-getting, and we confirm that it is a proper approach.
Robustness of class and sample blending ratio vari-ants: In general, the capability to recognize novel cate-gories largely depends on a powerful and well-trained ini-tial model with the target datasets. The more classes and
Ratio
Metric
Yold : Ynew Mall ↑ Mo ↑ Mf ↓ Md ↑ 9 : 1 8 : 2 7 : 3 6 : 4 5 : 5 61.34 54.75 52.66 48.78 45.28 63.22 58.80 58.42 57.90 62.41 11.83 15.47 14.67 15.16 11.30 44.73 40.90 39.50 35.53 28.55
Table 6. Qualitative evaluation by changing the ratio of classes and samples on the CUB-200 using ResNet18 pre-trained on ImageNet samples are included in the initial training dataset D0, the better the model learns representative features to fit the sets.
To evaluate the robustness of the proposed model, we con-ducted experiments with variants of the number of samples and classes in D0. As described in Table 6, decreasing the number of classes and data in the labeled set decreased the discovery of novel classes and clustering accuracies as the number of unlabeled novel data increased. On the other hand, catastrophic forgetting could increase since the num-ber of novel data increases. However, forgetting was main-tained within a reasonable boundary, indicating the effec-tiveness of our PA-based exemplar. The results suggest that our method has the robustness of the variants. 5.