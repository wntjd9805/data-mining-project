Abstract
Under-display camera (UDC) systems remove the screen notch for bezel-free displays and provide a better interac-tive experience. The main challenge is that the pixel ar-ray of light-emitting diodes used for display diffracts and attenuates the incident light, leading to complex degrada-tion. Existing models eliminate spatial diffraction by maxi-mizing model capacity through complex design and ignore the periodic distribution of diffraction in the frequency do-main, which prevents these approaches from satisfactory
In this paper, we introduce a new perspective to results. handle various diffraction in UDC images by jointly ex-ploring the feature restoration in the frequency and spa-tial domains, and present a Frequency and Spatial Interac-tive Learning Network (FSI). It consists of a series of well-designed Frequency-Spatial Joint (FSJ) modules for feature learning and a color transform module for color enhance-ment. In particular, in the FSJ module, a frequency learning block uses the Fourier transform to eliminate spectral bias, a spatial learning block uses a multi-distillation structure to supplement the absence of local details, and a dual transfer unit to facilitate the interactive learning between features of different domains. Experimental results demonstrate the su-periority of the proposed FSI over state-of-the-art models, through extensive quantitative and qualitative evaluations in three widely-used UDC benchmarks. 1.

Introduction
Under-display camera (UDC) systems are the foundation of full-screen display devices where the lens mounts un-der the display. It removes screen notches and provides a higher screen-to-body ratio without disrupting the screen’s integrity [25, 38]. Recently, rising demand for full-screen devices enable the study of UDC to attract attention [8, 44].
To implement the full-screen display, it is essential to densely arrange some organic light-emitting diode (OLED) in the display area above the camera. However, this de-Figure 1. A comparison between FSI and other SOTA methods (DISCNet [7], BNUDC [14]) on SYNTH dataset. The upper right shows the amplitude-frequency curves horizontally oriented on clipped frequency bands of 0 to 35. The vertical axis indicates the amplitude difference between different methods and ground truth. The results of the proposed FSI are superior to others to approximate the curve of ground truth (best viewed in color). sign also brings various image degradation. Specifically, the degradations are mainly due to 1) diffraction artifacts generated by the periodic gaps between the pixel grids as apertures1, illustrated by Fig. 2(a), and 2) color shift from multiple thin-film layers in an OLED [7, 14, 45]. Besides, the regions with different diffraction intensities in the image cause different degrees of degradation, bringing challenges for diffraction removal. Typically, in Fig. 2(b), around the light source, diffraction causes flares that saturate one or more channels of the image, resulting in content loss.
To solve these challenges, recent years have witnessed an increasing number of UDC image restoration approaches, which can be categorized into two paradigms. The for-mer makes attempts to leverage the prior knowledge of the diffraction blur kernel, i.e., point spread function (PSF), 1Light diffracts as it propagates through obstacles with similar sizes to its wavelength.
learning [27, 36] has made significant progress in various low-level tasks recently [16, 32, 37, 40, 47]. This demon-strates that learning in the frequency domain not only helps to eliminate textures produced by the diffraction, but also enriches the global representation of features to reconstruct the image content [22, 32, 36, 47]. Therefore, a more promising solution is to explore proper ways of utilizing frequency learning to eliminate diffraction and reconstruct textures in UDC image restoration.
In this paper, we propose a novel Frequency and Spatial
Interactive learning network (FSI) for UDC image restora-tion. The key insight of FSI is to explore the prop-erties of diffraction in the frequency domain, eliminate the diffraction-producing frequency components and recon-struct the loss of textures by joint learning in the frequency and spatial domains. The overview is shown in Fig. 3, FSI consists of a series of carefully designed Frequency-Spatial
Joint (FSJ) modules and a Color Transform (CT) module.
Specifically, in the FSJ module, a frequency learning block formulates image features as horizontal and vertical spec-tral components by Fourier transform to eliminate diffrac-tion from both directions, a spatial learning block extracts hierarchical features step-by-step with a multi-distillation structure to further supplement the absence of local details, and a dual transfer unit enables the two parts to interact se-lectively and facilitates the joint learning. The CT mod-ule predicts a set of coefficients for blending different color spaces to adjust the color temperature.
Our contributions are summarized as follows:
• We propose a novel frequency and spatial interactive learning network (FSI), which is the first work to intro-duce frequency learning into UDC image restoration.
By learning in the frequency domain, our method ef-fectively eliminates the various diffraction and recon-structs the textures.
• We propose a frequency-spatial joint (FSJ) module, which introduces a new perspective to explore the union of information in frequency and spatial domains, providing inspiration for other PSF-conditional tasks.
• Extensive experiments demonstrate that the proposed method can significantly outperform existing SOTA methods in three widely-used UDC benchmarks. 2.