Abstract
Most in-the-wild images are stored in Low Dynamic
Range (LDR) form, serving as a partial observation of the
High Dynamic Range (HDR) visual world. Despite limited dynamic range, these LDR images are often captured with different exposures, implicitly containing information about the underlying HDR image distribution. Inspired by this in-tuition, in this work we present, to the best of our knowledge, the first method for learning a generative model of HDR images from in-the-wild LDR image collections in a fully unsupervised manner. The key idea is to train a generative adversarial network (GAN) to generate HDR images which, when projected to LDR under various exposures, are indis-tinguishable from real LDR images. The projection from
HDR to LDR is achieved via a camera model that captures the stochasticity in exposure and camera response function.
Experiments show that our method GlowGAN can synthesize photorealistic HDR images in many challenging cases such as landscapes, lightning, or windows, where previous super-vised generative models produce overexposed images. With the assistance of GlowGAN, we showcase the novel applica-tion of unsupervised inverse tone mapping (GlowGAN-ITM) that sets a new paradigm in this field. Unlike previous meth-ods that gradually complete information from LDR input,
GlowGAN-ITM searches the entire HDR image manifold modeled by GlowGAN for the HDR images which can be mapped back to the LDR input. GlowGAN-ITM achieves more realistic reconstruction of overexposed regions com-pared to state-of-the-art supervised learning models, despite not requiring HDR images or paired multi-exposure images for training.
1.

Introduction
High Dynamic Range (HDR) images [57] are capable of capturing and displaying much richer appearance informa-tion than Low Dynamic Range (LDR) images, thus playing an important role in image representation and visualization.
The most popular method to acquire HDR images is multiple exposure blending, which requires capturing a set of LDR im-ages of the same scene with different exposures [13, 52, 59].
However, this is time and effort intensive and only suitable for static scenes. Due to this limitation, existing HDR image datasets only cover limited scene categories and have much fewer images than LDR datasets. Thus, supervised learning methods [16, 47, 14, 41, 45, 43, 19, 71, 70, 28] that recon-struct an HDR image from an LDR image are constrained by the HDR datasets and cannot extend to cases where no
HDR training data is available, e.g., lightnings or campfires.
While HDR images are hard to collect, it is much easier to collect a large number of LDR images from the Inter-net. This motivates us to investigate a new unsupervised learning problem: Can we learn to reconstruct HDR images from in-the-wild LDR images? The LDR images do not need to depict the same scene, it is enough if they contain a roughly similar class of scenes (e.g., landscapes) with var-ious exposures. This weak multi-exposure assumption is often naturally satisfied for in-the-wild LDR datasets as im-ages can come from different camera parameters or different adjustments of the auto-exposure mode. This problem is challenging as only a single exposure is available for each scene; therefore, a way to merge the multi-exposure infor-mation spread across different scenes is required.
In this work, we address this challenge via GlowGAN, which, to our knowledge, is the first method to learn an HDR generative model from in-the-wild LDR image collections in a fully unsupervised manner. GlowGAN uses adversarial training of an HDR generator with a discriminator that op-erates merely in LDR. Specifically, the generator produces an HDR image, which is projected to LDR via a camera model and is then sent to the discriminator as a fake image for adversarial training. The camera model consists of mul-tiplying the HDR sample with an exposure value, clipping the dynamic range, and applying a camera response func-tion (CRF). Importantly, during training, we use a randomly sampled exposure from a prior Gaussian distribution when projecting HDR to LDR. This requires the generated HDR images to be realistic under any possible exposure, thus only valid HDR samples would satisfy this “multi-exposure con-straint”. Furthermore, we also model the stochasticity in the non-linear camera response by randomly sampling CRFs ac-cording to a well-established parametric distribution [16, 21].
During inference, we can disable the camera model so that the generator produces HDR imagery directly.
We conduct extensive experiments on several datasets collected from the Internet, including landscapes, windows, lightning, fireplaces, and fireworks. By training on these
LDR images, GlowGAN successfully learns to generate high-quality HDR images that capture rich appearance infor-mation. These images can be presented on HDR displays, or via suitable tone mapping to create appealing imagery. In contrast, previous unconditional GANs tend to miss infor-mation in over- or under-exposed regions.
By modeling a distribution of HDR images, GlowGAN paves the way for new applications such as unsupervised inverse tone mapping (GlowGAN-ITM). ITM aims to re-construct an HDR image from a single-exposure LDR input, where a key challenge is to restore the flat-white overex-posed regions [16, 19]. We can use a pre-trained GlowGAN as a prior and apply GAN inversion to optimize latent code and exposure, making the model generate the corresponding
HDR image for the input LDR image. An exciting result is that our method can, without using any HDR imagery or paired multi-exposure data, reconstruct starkly more plau-sible information for large overexposed regions than other supervised learning approaches trained on such data. Our contributions are summarized as follows:
• We are the first to present unsupervised learning of
HDR images from in-the-wild LDR images. This gets rid of the reliance on ground truth HDR images that are much harder to collect.
• To achieve this, we propose a novel GlowGAN, which bridges HDR space and LDR space via a camera model.
GlowGAN can synthesize diverse high-quality images with a much higher dynamic range than vanilla GANs, opening up new avenues for getting cheap abundant
HDR data.
• Using GlowGAN as a prior, we design an unsuper-vised inverse tone mapping method GlowGAN-ITM, which reconstructs large overexposed regions signifi-cantly better than the state-of-the-art fully-supervised approaches.
Our code, pre-trained models, and datasets are publicly avail-able under https://glowgan.mpi-inf.mpg.de. 2.