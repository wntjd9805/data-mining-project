Abstract
In autonomous driving (AD), accurate perception is in-dispensable to achieving safe and secure driving. Due to its safety-criticality, the security of AD perception has been widely studied. Among different attacks on AD perception, the physical adversarial object evasion attacks are espe-cially severe. However, we find that all existing literature only evaluates their attack effect at the targeted AI compo-nent level but not at the system level, i.e., with the entire system semantics and context such as the full AD pipeline.
Thereby, this raises a critical research question: can these existing researches effectively achieve system-level attack effects (e.g., traffic rule violations) in the real-world AD context? In this work, we conduct the first measurement study on whether and how effectively the existing designs can lead to system-level effects, especially for the STOP sign-evasion attacks due to their popularity and severity.
Our evaluation results show that all the representative prior works cannot achieve any system-level effects. We ob-serve two design limitations in the prior works: 1) physical model-inconsistent object size distribution in pixel sampling and 2) lack of vehicle plant model and AD system model consideration. Then, we propose SysAdv, a novel system-driven attack design in the AD context and our evaluation results show that the system-level effects can be significantly improved, i.e., the violation rate increases by around 70%. 1.

Introduction
Autonomous Driving (AD) vehicles are now a reality in our daily life, where a wide variety of commercial and pri-vate AD vehicles are driving on the road. For instance, the millions of Tesla cars [30] equipped with Autopilot [54] are publicly available. To ensure safe and correct driving, a fundamental pillar is perception, which is designed to de-tect surrounding objects in real time. Due to the safety- and security-criticality of AD perception, various prior works have studied its security, especially the ones that aim at causing the evasion of critical physical road objects (e.g.,
STOP signs and pedestrians), or physical adversarial ob-ject evasion attack [7, 8, 12, 16, 27, 32, 62, 66, 70].
Although these attacks are all motivated by causing er-roneous driving behaviors at the AD system level (e.g., ve-hicle collisions and traffic rule violations), we find that so far they predominately only evaluate the attack success at the targeted AI component level alone (e.g., judged by per-frame object misdetection rates [12, 16, 27, 66, 70]), without further evaluation at the system level. Specifically, to sys-tematically perform such system-level evaluation, we need to measure the end-to-end system-level attack success met-rics (e.g., collision rates) with the full system-level attack context enclosing the attack-targeted AI component, for ex-ample, the remaining AD system pipeline such as object tracking, planning, and control, closed-loop control, and the attack-targeted driving scenario. In this paper, we call such system-level attack context system model for such adversar-ial attacks (§2). This thus raises a critical research question: can these existing works on physical adversarial object eva-sion attacks effectively achieve the desired system-level at-tack effects in the realistic AD system settings?
To systematically answer this critical research question, we conduct the first measurement study on representative prior object-evasion attacks with regard to their capabili-ties in causing system-level effects (§3). We propose a gen-eral framework, i.e., a system model, including perception modeling from the physical world, to measure STOP sign-evasion attack which is our target due to its high represen-tativeness [53] and its direct impacts on driving correctness and road safety. Our results show that all the representa-tive existing works cannot cause any STOP sign traffic rule violation within the system model including a representa-tive closed-loop control AD system in the common speed range for STOP sign-controlled roads in the real world even though the most effective attack can achieve more than 70% average attack success rate at the AI component alone.
We further investigate the root causes and find that all the existing works have design limitations on achieving effective system-level effects due to the lack of a system model in AD context for attack design: 1) physical model-inconsistent object size distribution in pixel sampling and 2) lack of vehicle plant model and AD system model con-sideration (detailed in §4). We further propose SysAdv, a system-driven attack design, which can be integrated with all state-of-the-art attack methods to significantly improve system-level effects by overcoming the two limitations.
We evaluate our novel proposed attack design in our plat-form and show that the system-level effect can be signifi-cantly improved in §5, i.e., the system violation rate can be increased by around 70%. To further validate the generality of our attack, we also examine generality on different AD system parameters (§5.2) and different object types (§5.3), which shows improvement at both component- and system-level. Demo videos are at the project website: https:
//sites.google.com/view/cav-sec/sysadv.
To sum up, this paper makes the following contributions:
• We conduct the first measurement study on the system-level effect of the representative prior object-evasion attacks with our proposed novel evaluation framework (i.e., system model) including 4 popular object detec-tors and 3 state-of-the-art object-evasion attacks.
• We identify the limitations of prior works which hin-der them in potently achieving system-level effects and propose SysAdv, a system-driven adversarial object-evasion attack with the system model in AD context.
• We further evaluate SysAdv and show that the system-level effect of SysAdv can be significantly improved, i.e., the system violation rate increases by around 70%. 2.