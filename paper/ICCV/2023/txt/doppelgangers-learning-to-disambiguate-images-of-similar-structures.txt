Abstract
We consider the visual disambiguation task of determin-ing whether a pair of visually similar images depict the same or distinct 3D surfaces (e.g., the same or opposite sides of a symmetric building). Illusory image matches, where two images observe distinct but visually similar 3D surfaces, can be challenging for humans to differentiate, and can also lead 3D reconstruction algorithms to produce erroneous results. We propose a learning-based approach to visual dis-ambiguation, formulating it as a binary classification task on image pairs. To that end, we introduce a new dataset for this problem, Doppelgangers, which includes image pairs of similar structures with ground truth labels. We also design a network architecture that takes the spatial distribution of local keypoints and matches as input, allowing for better reasoning about both local and global cues. Our evaluation shows that our method can distinguish illusory matches in difficult cases, and can be integrated into SfM pipelines to produce correct, disambiguated 3D reconstructions. See our project page for our code, datasets, and more results: doppelgangers-3d.github.io. 1.

Introduction
From time to time we are faced with the task of distin-guishing between two things that are nearly indistinguish-able, but are not the same object. Examples of such looka-likes include identical twin siblings, two similar keys on a keychain, and two cups on a table at a party—only one of which is ours. While these objects might look identical, there are often subtle cues we can use to tell them apart; for instance, even “identical” twins are not truly visually identical, but have perceptible differences.
Computer vision systems also face a version of this prob-lem. In particular, our work considers geometric vision tasks like 3D reconstruction, where methods often must determine whether two images depict the exact same 3D surface in the world, or two different 3D surfaces that happen to look very similar—where wrong answers can lead to wrong 3D
Figure 1. These image pairs observe distinct but visually similar 3D surfaces. Can you spot the differences and distinguish between the two images in each pair? Hints in the footnote.1 Such illusory image matches can fool humans, and also fool 3D reconstruction algorithms into thinking they share 3D correspondence. We propose a new method to disambiguate these kinds of false matches from image pairs that truly observe the same structure. models. We call this task visual disambiguation, but you could also call it the Big Ben problem: London’s Big Ben is a clock tower with four-way symmetry, where the four sides of the tower look nearly the same. Local feature match-ing methods like SIFT easily confuse one side for another, finding many matches between distinct 3D surfaces. These spurious matches lead structure from motion methods to pro-duce incorrect reconstructions where multiple sides collapse together. Yet views of different sides of Big Ben are not truly identical—the individual bricks are different, the back-grounds are different, etc. If matching methods knew what to look for, they could perhaps tell the different sides apart.
Figure 1 shows other examples of this “spot the difference” problem—see if you can tell these structures apart yourself.
We call illusory image matches like those in Fig. 1 doppel-gangers, after the idea of two distinct people or objects that look very similar. Prior methods for disambiguating doppel-gangers in the context of 3D vision have devised heuristics 1Attend to: (a) the sculptures on the bottom half of the monument, (b) the shape of the facade’s roof (flat or triangular), (c) the location of the smaller tower (left or right), and (d) the background (with or without a mountain). Note that (a), (b), (c) show different faces of the same building, while (d) shows replicas of the same castle in different Disney parks.
that analyze the structure of a full image collection. In con-trast, our paper explores the fundamental building block of pairwise image comparison: can we automatically deter-mine whether two views are the same, or just similar? We formulate this visual disambiguation problem as a binary classification task on image pairs, and develop a learning-based solution.
Our solution involves assembling a new dataset, Dop-pelgangers, consisting of image pairs that either depict the same surface (positives) or two different, similar surfaces (negatives). Creating Doppelgangers involved a challenging data curation task, since even humans can struggle to dis-tinguish same from similar. We show how to use existing image annotations stored in the Wikimedia Commons image database to automatically create a large set of labeled image pairs. We find that simply training a deep network model using these raw image pairs performs poorly. Therefore, we also design a network where we provide useful information in the form of local features and 2D correspondence.
On our Doppelgangers test set, we find that our method works remarkably well on challenging disambiguation tasks, and significantly better than baselines and alternative net-work designs. We also explore the use of our learned classi-fier as a simple pre-processing filter on scene graphs com-puted in structure from motion pipelines like COLMAP [31], and find that it significantly improves the correctness of reconstructions on a set of difficult scenes, outperforming more complex visual disambiguation algorithms.
In summary, our paper makes the following contributions:
• We formulate the visual disambiguation problem on pairs of images.
• Based on this formulation, we create the Doppelgangers
Dataset, leveraging the existing cataloging of imagery on Wikimedia Commons.
• We design a network architecture well-suited for solv-ing pairwise visual disambiguation as a classification problem. We show that training this network on our dataset leads to strong classification performance and downstream utility to SfM problems. 2.