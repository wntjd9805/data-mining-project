Abstract
The availability of large-scale authentic face databases has been crucial to the significant advances made in face recognition research over the past decade. However, legal and ethical concerns led to the recent retraction of many of these databases by their creators, raising questions about the continuity of future face recognition research without one of its key resources. Synthetic datasets have emerged as a promising alternative to privacy-sensitive authentic data for face recognition development. However, recent synthetic datasets that are used to train face recognition models suf-fer either from limitations in intra-class diversity or cross-class (identity) discrimination, leading to less optimal ac-curacies, far away from the accuracies achieved by mod-els trained on authentic data. This paper targets this issue by proposing IDiff-Face, a novel approach based on con-ditional latent diffusion models for synthetic identity gen-eration with realistic identity variations for face recogni-tion training. Through extensive evaluations, our proposed synthetic-based face recognition approach pushed the lim-its of state-of-the-art performances, achieving, for example, 98.00% accuracy on the Labeled Faces in the Wild (LFW) benchmark, far ahead from the recent synthetic-based face recognition solutions with 95.40% and bridging the gap to authentic-based face recognition with 99.82% accuracy*. 1.

Introduction
Face Recognition (FR) is one of the most widely used biometric technologies due to the high accuracies achieved by the recent FRs [31, 56, 4] with a wide range of appli-cations such as logical access control to portable devices
[42, 9]. This ubiquitous adoption has been fuelled by the application of deep learning to FR and the rapid research advances in this direction, mainly on novel margin-penalty based softmax losses [14, 4] and deep network architectures
*https://github.com/fdbtrs/idiff-face
[24, 9]. However, this rapid progress has only been possi-ble due to the public availability of large-scale FR training databases [11, 23]. Such databases contain millions of im-ages, and they are typically collected from the internet with-out proper user consent, which raises concerns about the le-gal and ethical use of these databases for FR development.
Since, for example, the European Union (EU) adopted the General Data Protection Regulation (GDPR) [18] in 2018, more justified criticism of the associated privacy risks has been raised against the usage of public biomet-ric datasets that were collected without proper consent. The
GDPR explicitly grants individuals the ”right to be forgot-ten” and enforces stricter requirements on the collection, distribution, and usage of face databases, making it ex-tremely hard, or even infeasible, to maintain such regula-tions. Thus, many of them [11, 3, 23] that are widely used to train FRs were retracted by their creators to avoid legal complications, which raises the question about continuity of
FR research since the availability of one of its key resources became questionable.
As an effort to address these legal and ethical concerns, synthetic data has recently emerged as a promising alterna-tive to authentic databases for FR training [43, 6, 7, 10, 2, 5].
This is also the trend for FR subsystems, such as morph-ing and spoof attack detection [13, 19] and face images quality assessment [1]. This research direction is driven by the progress on Deep Generative Models (DGMs), a model designed to learn the probability distribution of a certain dataset, enabling the generation of completely new syn-thetic samples. This process can be conditioned on specific attributes such as age, facial expression, and a defined set of visual appearances, e.g. the lighting condition and head pose [15, 52, 54, 21]. Most of the DGM approaches for generating synthetic faces are based on Generative Adver-sarial Networks (GANs) [22, 15, 49, 33, 6]. A number of recent works [37, 7, 43] utilized GANs [15, 29] to gener-ate synthetic data for FR training. The reported results by
SOTA synthetic-based FR showed significant degradation in the verification accuracies in comparison to FR trained
thetic identities that are identity-separable, with a desir-able relatively large intra-class diversity. Our approach fol-lows the common concept [45] of dividing the training into two stages by first training an AE (or using a pre-trained
AE) and then leveraging the resulting representational low-dimensional latent space of the AE for DM training [45].
The identity condition is introduced to our IDiff-Face by projecting the training images into a low-dimensional fea-ture representation and then injecting it into the DM’s in-termediate representations through a Cross-Attention (CA) mechanism [45]. To ensure that our synthetic data contains, to a large degree, realistic variations and to avoid overfit-ting our IDiff-Face to the information encoded in the iden-tity context, we proposed a simple, yet effective Contex-tual Partial Dropout (CPD) approach that partially drops out components with a certain probability of the identity con-text during the training phase, thus the term ”fizzy” in our title. We first demonstrate the identity discrimination and intra-class variation of our synthetically generated data. We also compared our dataset in terms of identity-separability and intra-class variation, with the recent SOTA synthetic datasets. As we empirically present in this paper, the syn-thetic datasets that are used in SOTA synthetic-based FR training maintain, to some degree, identity discrimination, however, only with a low intra-class variation or vice versa.
Unlike these approaches, our proposed IDiff-Face offers a more realistic trade-off between identity discrimination and intra-class variation that is controlled by CPD. Achieving this realistic trade-off between these two properties is nec-essary to achieve verification accuracy that is close to ver-ification accuracies achieved by FRs trained on authentic data as authentic data naturally contains such properties.
By utilizing our synthetic data (500K images) for FR train-ing and under the same training setups and dataset size, our synthetic-based FR achieved an average accuracy of 88.20%, significantly outperforming all SOTA synthetic-based FRs (best average accuracy was 83.45%) and clos-ing the gap to SOTA FR trained on authentic data, where the average accuracy on CASIA-WebFace [59] (500K im-ages) and MS1MV2 [23, 14] (5.8M images) were 94.92% and 97.18%, respectively. Our model also outperformed human-level performance in face verification, where the re-ported accuracy on Labeled Faces in the Wild (LFW) [26] was 97.5% [35] and our model achieved 98.00%. 2.