Abstract
Foundational image-language models have generated considerable interest due to their efficient adaptation to downstream tasks by prompt learning. Prompt learning treats part of the language model input as trainable while freezing the rest, and optimizes an Empirical Risk Mini-mization objective. However, Empirical Risk Minimization is known to suffer from distributional shifts which hurt gen-eralizability to prompts unseen during training. By lever-aging the regularization ability of Bayesian methods, we frame prompt learning from the Bayesian perspective and formulate it as a variational inference problem. Our ap-proach regularizes the prompt space, reduces overfitting to the seen prompts and improves the prompt generalization on unseen prompts. Our framework is implemented by model-ing the input prompt space in a probabilistic manner, as an a priori distribution which makes our proposal compatible with prompt learning approaches that are unconditional or conditional on the image. We demonstrate empirically on 15 benchmarks that Bayesian prompt learning provides an appropriate coverage of the prompt space, prevents learn-ing spurious features, and exploits transferable invariant features. This results in better generalization of unseen prompts, even across different datasets and domains.
Code available at: https://github.com/saic-fi/Bayesian-Prompt-Learning 1.

Introduction
In the continuous quest for better pre-training strategies, models based on image and language supervision have set impressive milestones, with CLIP [38], ALIGN [22] and
Flamingo [1] being leading examples. Contrastively trained image-language models consist of image and text encoders that align semantically-related concepts in a joint embed-ding space. Such models offer impressive zero-shot image classification by using the text encoder to generate classi-fier weights from arbitrarily newly defined category classes
*Most work done during an internship at Samsung AI Cambridge.
†Equal advising
Figure 1: We present a Bayesian perspective on prompt learning by formulating it as a variational inference problem (right column). Our framework models the prompt space as an a priori distribution which makes our proposal compat-ible with common prompt learning approaches that are un-conditional (top) or conditional on the image (bottom). without relying on any visual data. In particular, the class name is used within a handcrafted prompt template and then tokenized and encoded into the shared embedding space to generate new classifier weights. Rather than manually defining prompts, both Lester et al. [28] and Zhou et al.
[55] demonstrated prompts can instead be optimized in a data-driven manner through backpropagation. However, as prompt learning typically has access to only a few training examples per prompt, overfitting to the seen prompts in lieu of the unseen prompts is common [55]. In this paper, we strive to mitigate the overfitting behavior of prompt learn-ing so as to improve generalization for unseen prompts.
Others before us have considered the generalization problem in prompt learning as well, e.g., [55, 54], be it they all seek to optimize a so-called Empirical Risk Minimiza-tion. It is, however, well known that Empirical Risk Min-imization based models degrade drastically when training and testing distributions are different [37, 2]. To relax the i.i.d. assumption, Peters et al. [37] suggest exploiting the
“invariance principle” for better generalization. Unfortu-nately, Invariant Risk Minimization methods for deep neu-ral networks as of yet fail to deliver competitive results, as observed in [15, 31, 30]. To alleviate this limitation, Lin et al. [30] propose a Bayesian treatment of Invariant Risk
Minimization that alleviates overfitting with deep models by defining a regularization term over the posterior distri-bution of classifiers, minimizing this term, and pushing the model’s backbone to learn invariant features. We take inspi-ration from this Bayesian Invariant Risk Minimization [30] and propose the first Bayesian prompt learning approach.
We make three contributions. First, we frame prompt learning from the Bayesian perspective and formulate it as a variational inference problem (see Figure 1). This formula-tion provides several benefits. First, it naturally injects noise during prompt learning and induces a regularization term that encourages the model to learn informative prompts, scattered in the prompt space, for each downstream task.
As a direct result, we regularize the prompt space, reduce overfitting to seen prompts, and improve generalization on unseen prompts. Second, our framework models the input prompt space in a probabilistic manner, as an a priori distri-bution which makes our proposal compatible with prompt learning approaches that are unconditional [55] or condi-tional on the image [54]. Third, we empirically demon-strate on 15 benchmarks that Bayesian prompt learning pro-vides an appropriate coverage of the prompt space, prevents learning spurious features, and exploits transferable invari-ant features, leading to a better generalization of unseen prompts, even across different datasets and domains. 2.