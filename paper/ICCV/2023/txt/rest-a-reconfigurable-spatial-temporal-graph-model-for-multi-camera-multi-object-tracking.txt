Abstract
Multi-Camera Multi-Object Tracking (MC-MOT) uti-lizes information from multiple views to better handle prob-lems with occlusion and crowded scenes. Recently, the use of graph-based approaches to solve tracking problems has become very popular. However, many current graph-based methods do not effectively utilize information regard-ing spatial and temporal consistency. Instead, they rely on single-camera trackers as input, which are prone to frag-mentation and ID switch errors.
In this paper, we pro-pose a novel reconfigurable graph model that first asso-ciates all detected objects across cameras spatially before reconfiguring it into a temporal graph for Temporal Asso-ciation. This two-stage association approach enables us to extract robust spatial and temporal-aware features and address the problem with fragmented tracklets. Further-more, our model is designed for online tracking, making it suitable for real-world applications. Experimental re-sults show that the proposed graph model is able to ex-tract more discriminating features for object tracking, and our model achieves state-of-the-art performance on several public datasets. Code is available at https://github. com/chengche6230/ReST. 1.

Introduction
Multi-Object Tracking (MOT) is an important task in computer vision, which involves object detection and track-ing multiple objects over time in an image sequence. It can be applied to several real-world scenarios, such as video surveillance, autonomous vehicles, and sports analysis. De-spite numerous research methods proposed for MOT, the problem of fragmented tracklets or ID switching caused by frequent occlusion in crowded scenes remains a major challenge. One potential solution is to track objects un-der a multi-camera setting, which is called a Multi-Camera
Multi-Object Tracking (MC-MOT) task. By leveraging in-formation from multiple cameras, occluded objects in one view may become clearly visible in another view, allowing (a) Single-camera tracker (b) Our ReST tracker
Figure 1: Example of handling object occlusion for MC-MOT. (a) When occlusion occurs at time t (red dotted box), the single-camera tracker generates fragmented tracklets and causes ID switch errors. (b) Our ReST tracker corrects object ID in c1 via Spatial and Temporal Association, by leveraging spatial and temporal consistency. for more accurate object tracking results.
Most of tracking-by-detection paradigms [1] adopt
Kalman filter [17] in the data association stage. It serves as a motion model, predicting the next possible position and matching with previous detection. However, such method is usually deterministic and cannot adapt to the dynamically changing environment.
In addition, the tracking results are difficult to achieve globally optimal, since the illumi-nation, relative geometry distance, or sampling rate varies from dataset to dataset, which is common in real-world sce-narios. Accordingly, there is another fashion reformulat-ing the association problem into link prediction on graph
It allows a trainable model to determine
[5, 18, 25, 27]. how strong the connection is between two detections. Thus, objects can be dynamically associated depending on envi-ronmental conditions.
However, there still remains some issues in current graph-based models for MC-MOT. First of all, many ap-proaches rely on single-camera tracker to generate the ini-tial tracklets [13, 25, 27, 37]. Although many methods have been proposed to refine tracklets, tracking errors in single-view are often left unaddressed. Additionally, these meth-ods do not fully leverage the rich spatial and temporal infor-mation that is crucial for MC-MOT task. Recently, spatial-temporal models have been employed to learn representa-tive features for tracklets. However, the resulting graphs are usually complex and hard to optimize.
In this paper, we propose a novel Reconfigurable Spatial-Temporal graph model (ReST) for MC-MOT to overcome the problems mentioned above. The MC-MOT problem is re-formulated as two sub-tasks, Spatial Association and
Temporal Association, in our approach. In Spatial Associa-tion, it focuses on matching objects across different views.
Temporal Association exploits temporal information, such as speed and time, to build temporal graph which associates objects across frames. By splitting the problem into two sub-tasks, spatial and temporal consistency can be individ-In ad-ually optimized to achieve better tracking results. dition, the graph model becomes smaller and easy to opti-mize. To bridge two association stages, Graph Reconfig-uration module is proposed to aggregate information from spatial and temporal graph models. The merits of involving graph reconfiguration are two-fold. Firstly, when the nodes of the same object are merged, the reconfigured graph be-comes very compact. Secondly, the refinement of the graph model can be iteratively performed in each reconfiguration step during inference, leading to more representative fea-ture extraction and better tracking results. As depicted in
Figure 1a, when the girl is occluded, fragmented tracklets are produced, causing the ID switch problem. In Figure 1b, correct object ID can be retained by employing spatial and temporal consistency via Spatial Association, Temporal As-sociation, and Graph Reconfiguration modules.
The proposed graph model is called reconfigurable be-cause the vertex set and edge set of spatial and temporal graphs are reconfigured to construct a new graph at each time. Thus, it tends to adapt to dynamic scenes. Unlike existing methods, our model does not rely on the results from single-camera tracker. The tracking and association of the detected objects is accomplished through iteratively constructing spatial and temporal graphs. Our model is de-signed for online object tracking since it does not use or rely on any information from future frames.
Contributions Our contributions can be summarized as follows. 1) The Multi-Camera Multi-Object Tracking prob-lem is formulated as two sub-tasks in the proposed graph model, Spatial Association and Temporal Association. This enables the employment of spatial and temporal consistency and better model optimization. 2) Graph Reconfiguration module is proposed to leverage tracking results from two stages. This makes the object tracking apt to dynamic scene changes and online tracking scenarios. 3) Experimental re-sults demonstrate that our model achieves state-of-the-art performance on Wildtrack and competitive results on other benchmark datasets. 2.