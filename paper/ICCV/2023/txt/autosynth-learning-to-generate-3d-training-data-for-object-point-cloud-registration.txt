Abstract
In the current deep learning paradigm, the amount and quality of training data are as critical as the network archi-tecture and its training details. However, collecting, pro-cessing, and annotating real data at scale is difficult, ex-pensive, and time-consuming, particularly for tasks such as 3D object registration. While synthetic datasets can be cre-ated, they require expertise to design and include a limited number of categories.
In this paper, we introduce a new approach called AutoSynth, which automatically generates 3D training data for point cloud registration. Specifically,
AutoSynth automatically curates an optimal dataset by ex-ploring a search space encompassing millions of potential datasets with diverse 3D shapes at a low cost. To achieve this, we generate synthetic 3D datasets by assembling shape primitives, and develop a meta-learning strategy to search for the best training data for 3D registration on real point clouds. For this search to remain tractable, we replace the point cloud registration network with a much smaller surrogate network, leading to a 4056.43 times speedup.
We demonstrate the generality of our approach by imple-menting it with two different point cloud registration net-works, BPNet [13] and IDAM [34]. Our results on TUD-L [26], LINEMOD [23] and Occluded-LINEMOD [7] evi-dence that a neural network trained on our searched dataset yields consistently better performance than the same one trained on the widely used ModelNet40 dataset [65]. 1.

Introduction 3D point cloud registration, which aims to estimate the relative transformation between two given point clouds, is a traditional computer vision task. With the advent of deep learning, point cloud registration is nowadays commonly tackled with deep networks, achieving impressive results.
The main research direction in this area consists of de-signing new network architectures to improve performance.
Here, by contrast, we argue that the quantity and quality of training data have as crucial an impact on the networks’ performance as its architecture and training details, and thus advocate data creation as a research goal in itself.
The traditional approach to collecting 3D registration data consists of scanning real objects. This, however, is highly time-consuming and does not scale to the quantity of data commonly expected for deep network training. Gener-ating synthetic data, therefore, comes as a promising alter-native. Nevertheless, it requires access to 3D object models, thus often limiting the number of categories, and human ex-pertise to generate realistic data, typically leading to a do-main gap w.r.t. real-world point clouds despite best efforts.
In this work, we address this by introducing an approach dubbed AutoSynth, automating the process of curating a 3D dataset. Specifically, we aim for the resulting dataset to act as effective training data for a 3D object registration net-work that will then be deployed on real-world point clouds.
To achieve this, we develop a meta-learning strategy that searches for the optimal dataset over a space encompass-ing millions of potential datasets, covering a wide diver-sity of 3D shapes. The search is guided by a target real-world dataset, thus producing data that reduces the domain gap. Our experiments demonstrate that the resulting train-ing dataset yields improved registration performance not only on the target data but on other real-world point clouds.
For this to be possible, we design a very large search space based on the assumption that complex shapes can be created by combining simple primitives. Diverse datasets can then be sampled from this space, and we design an evo-lutionary algorithm to automatically curate the best training dataset to achieve high performance on the target data. Em-ploying a registration network in the search process, how-ever, would be impractical as even the smallest competitive model would require 1, 875 GPU days on a single RTX8000 for only 1, 000 search steps. To make the search tractable, we observe that the true quality function, i.e., the accuracy of the registration network of interest, can be replaced with a proxy one, i.e., the reconstruction accuracy of an autoen-coder. Specifically, our experiments evidence that, for the same training and testing data, registration accuracy and re-construction quality follow the same trend, even when using
an autoencoder whose architecture is orders of magnitude smaller than that of any registration network able to produce nontrivial results. As such, our approach yields a 4056.43× speedup compared to using a registration network.
We demonstrate the generality of our approach by imple-menting it with two different point cloud registration net-works, BPNet [13] and IDAM [34]. Our results on TUD-L [26], LINEMOD [23] and Occluded-LINEMOD [7] con-sistently demonstrate that a neural network trained on our searched dataset achieves better performance than the same one trained on the widely used ModelNet40 dataset [65].
Our main contributions can be summarized as follows:
• We present AutoSynth, a novel meta-learning-based approach to automatically generate large amounts of 3D training data and curate an optimal dataset for point cloud registration.
• We show that the search can be made tractable by leveraging a surrogate network that is 4056.43 times more efficient than the point cloud registration one.
• We evidence that using a single scanned real-object as target dataset during the search yields a training set that leads to good generalization ability. 2.