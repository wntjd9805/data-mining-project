Abstract
Domain generalization (DG) aims to learn domain-generalizable models from one or multiple source domains that can perform well in unseen target domains. Despite its recent progress, most existing work suffers from the mis-alignment between the difficulty level of training samples and the capability of contemporarily trained models, lead-ing to over-fitting or under-fitting in the trained general-ization model. We design MoDify, a Momentum Difficulty framework that tackles the misalignment by balancing the seesaw between the model’s capability and the samples’ dif-ficulties along the training process. MoDify consists of two novel designs that collaborate to fight against the misalign-ment while learning domain-generalizable models. The first is MoDify-based Data Augmentation which exploits an
RGB Shuffle technique to generate difficulty-aware train-ing samples on the fly. The second is MoDify-based Net-work Optimization which dynamically schedules the train-ing samples for balanced and smooth learning with appro-priate difficulty. Without bells and whistles, a simple imple-mentation of MoDify achieves superior performance across multiple benchmarks. In addition, MoDify can complement existing methods as a plug-in, and it is generic and can work for different visual recognition tasks.
Figure 1. Illustration of the proposed MoDify framework. Train-ing domain-generalizable models often suffer from clear under-fitting (or over-fitting) if keep feeding over-difficult (or over-easy) training samples, especially at the early (or later) training stage, both leading to degraded generalization of the trained models (as illustrated in yellow/blue lines).
Inspired by the Flow The-ory [16] that a learner usually has better learning outcome when the learner’s skill and the task difficulty are well aligned (i.e., ly-ing within the Flow Channel), the proposed MoDify schedules the training samples adaptively according to the alignment between the sample difficulty and the capability of contemporarily trained models (as illustrated in red line). 1.

Introduction
Deep neural networks (DNNs)
[23, 30, 48] have achieved significant progress in recent years with numerous network architectures and learning algorithms designed for various discriminative tasks. In the area of computer vision,
DNNs have achieved great success in various visual recog-nition tasks such as image segmentation [7, 58, 52], object detection [45, 5], etc. However, deep network training often suffers from a misfitting problem, being either over-fitting or under-fitting due to the misalignment between the capac-ity of networks under training and the complexity of train-*Corresponding author. ing data. While applying a misfit deep network model to the data from a different domain, the misfitting problem can be greatly enlarged due to the distribution bias and distribution shift across domains.
Domain generalization aims to mitigate the misfitting problem by learning a domain generalizable model that can work well in new domains. It has been widely studied via different augmentation strategies, e.g., domain randomiza-tion [41, 56, 26, 51], feature augmentation [31, 40, 11], and data augmentation [61, 39], targeting to obtain generaliza-tion capability by seeing more training data with various diverse characteristics. However, the aforementioned meth-ods mostly neglect the misalignment between the difficulty level of training samples and the capability of the contem-porary models along the training process, leading to misfit deep network models and degraded performance.
The Flow Theory [16] has been widely studied in the field of learning and education, which suggests that a learner has optimal learning outcomes when the capabil-ity of the learner is well aligned with the difficulty level of learning tasks throughout the learning process. Inspired by this theory, we design MoDify, a Momentum Difficulty framework that aims to tackle the misfitting problem in deep network training. The idea is to dynamically gauge the difficulty level of training samples along the training pro-cess, and feed training samples whose difficulty level is well aligned with the capability of the contemporary deep network model under training. This directly leads to a bal-anced learning process between the difficulty level of train-ing samples and the model capability as illustrated in Fig. 1, which helps mitigate the misfitting problem effectively.
MoDify consists of two novel designs for balanced and smooth learning. The first is MoDify-based Data
Augmentation (MoDify-DA) that produces augmented training samples with relevant difficulty levels on the fly. The second is MoDify-based Network Optimization (MoDify-NO) that achieves progressive network training by considering the difficulty level of training samples. The two designs work in a collaborative manner to maintain the difficulty-capability balance, which coordinate the aug-mentation and network training smoothly according to the model’s capability. Moreover, we employ an efficient yet effective RGB Shuffle technique that enables online sample augmentation by shuffling the color channels while preserv-ing spatial structures efficiently. RGB Shuffle improves the generalization of the trained model effectively. MoDify has three desirable features: 1) it is generic and performs well across different visual recognition tasks such as image se-mantic segmentation and object detection; 2) it is an online technique with negligible computational cost; 3) it is com-plementary with existing DG methods and can be incorpo-rated with consistent performance boosts.
In summary, the contributions of this work are threefold.
First, we propose MoDify, a novel momentum difficulty framework that effectively addresses the network misfitting problem by maintaining the balance between the difficulty level of training samples and the capability of the contem-porary models along the training process. Second, we de-sign MoDify-DA and MoDify-NO, the former generates difficulty-aware augmentation samples on the fly while the latter coordinates for a smooth learning process by dropping over-simple samples and postponing over-difficult samples to a later training phase. Third, extensive experiments show that a simple implementation of MoDify achieves superior performance consistently across multiple benchmarks and visual recognition tasks. 2.