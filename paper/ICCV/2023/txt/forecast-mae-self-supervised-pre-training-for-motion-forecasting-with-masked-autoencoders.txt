Abstract
This study explores the application of self-supervised learning (SSL) to the task of motion forecasting, an area that has not yet been extensively investigated despite the widespread success of SSL in computer vision and natu-ral language processing. To address this gap, we intro-duce Forecast-MAE, an extension of the mask autoencoders framework that is specifically designed for self-supervised learning of the motion forecasting task. Our approach in-cludes a novel masking strategy that leverages the strong interconnections between agents’ trajectories and road net-works, involving complementary masking of agents’ future or history trajectories and random masking of lane seg-ments. Our experiments on the challenging Argoverse 2 mo-tion forecasting benchmark show that Forecast-MAE, which utilizes standard Transformer blocks with minimal induc-tive bias, achieves competitive performance compared to state-of-the-art methods that rely on supervised learning and sophisticated designs. Moreover, it outperforms the previous self-supervised learning method by a significant margin. Code is available at https://github.com/ jchengai/forecast-mae. 1.

Introduction
Motion forecasting is a rapidly developing research field that plays a critical role in advanced autonomous driving systems [22]. This task involves predicting the future tra-jectories of other vehicles and pedestrians, while taking into account the intricate interactions and road layouts. The in-herent multi-modal driving behaviors of agents, combined with diverse road networks, make motion forecasting an es-pecially challenging undertaking.
Self-supervised learning (SSL) is an innovative approach that enables the acquisition of valuable latent features from unlabelled data. By pre-training the model on pretext tasks and pseudo-labels derived from the data, and subsequently
*Corresponding author: Ming Liu
Figure 1. Reconstruction result on Argoverse 2 validation sce-nario. (a) The origin scenario. (b) 50% of agents’ trajectory is masked using a complementary masking strategy (either history or future is masked). 50% of the lane segments are masked ran-domly. (c) Scenario reconstructed by the proposed Forecast-MAE. fine-tuning on downstream tasks, SSL has demonstrated an ability to learn more extensive and adaptable latent features, leading to remarkable advancements in computer vision [3] and natural language processing (NLP) [10]. Nevertheless, despite its widespread popularity and success, there remains a notable lack of exploration of SSL in the motion forecast-ing domain. We have identified two principal challenges associated with integrating SSL into motion forecasting: (i) Motion forecasting pre-training requires annotated data, which sets it apart from fields such as computer vi-sion and NLP where unlabeled raw inputs are easily acces-sible. In motion forecasting, we rely on annotated track-ing sequences and hand-crafted high-definition maps that are typically collected by expensive onboard sensors and
require human annotation labor [5, 43, 12]. This poses a challenge to scaling up self-supervised pre-training, a key aspect of SSL’s success. To address this challenge, very re-cent work PreTraM [44] proposed generating additional ras-terized map patches (28.8M) cropped from local regions of the entire HD map to train a robust map encoder with con-trastive learning. Although this approach yielded notable performance improvements compared to the baseline, it is limited to models based on rasterized map representations, which have a significant performance gap compared to more recent vector-based or graph-based models. However, an-other pioneering work, SSL-Lanes [1], demonstrated that carefully designed pretext tasks can significantly enhance performance without using extra data by learning richer fea-tures. In this paper, we follow this approach to learn better and more generalized features using the existing dataset. (ii) The task of motion forecasting involves incorporat-ing multiple modal inputs, such as static map features, spa-tiotemporal agent motion features, and semantic scene con-texts [39, 26, 13, 4, 36, 50, 29, 9, 52]. While various self-supervised learning methods have proven successful in dealing with single-modal inputs such as the image [3], text [10], or point cloud [47, 32], developing pretexts that establish cross-modal interconnections is not an easy task.
SSL-Lanes concentrated on designing pretext tasks for each specific input modality, such as lane node masking or agent maneuver classification. Nevertheless, they did not explore the combination of these different tasks or develop pretext tasks that explicitly involve multiple modal inputs. Authors of PreTraM drew inspiration from CLIP’s [35] cross-modal contrastive learning framework involving text and images.
They devised a technique for pre-training map and trajec-tory encoders by pairing batches of (map, trajectory) train-ing instances. Nevertheless, their approach merely encom-passes the history trajectory-map connection, thereby re-stricting the scope of modality interconnections to a par-ticular type. This study confronts this challenge by utiliz-ing a masked autoencoder framework that can assimilate all cross-modal interdependencies within a unified scene re-construction task.
The masked autoencoder (MAE) [20] has garnered sig-nificant attention due to its recent achievements in image-based self-supervised learning. This approach involves masking a portion of the input data and reconstructing the missing part using an autoencoder structure. The effective-ness of MAE has also been demonstrated in other domains, such as audio [21] and point cloud [32]. An intriguing ques-tion arises: can we extend MAE to motion forecasting? In-deed, motion forecasting itself can be viewed as a mask-ing and reconstructing task, wherein the future trajectory of agents is masked and predicted. Based on the strong cor-relation between agents’ historical and future trajectories and road networks, we further extend this concept to the en-tire scene reconstruction. Specifically, we mask agents’ his-tory trajectory or future trajectory in a complementary man-ner (i.e. either history or future is masked), and randomly mask non-overlapping lane segments, shown in Figure 1.
This masking scheme offers several advantages. Firstly, the model must learn how to reconstruct the future from past motion and, in turn, infer history from the future, with lim-ited access to lane structures. This pretext task allows the model to establish a robust bidirectional relationship be-tween past and future motion. Secondly, the model learns to reconstruct lane segments by jointly utilizing neighboring visible lanes, agents’ history and future trajectories, thereby establishing a more profound cross-modal understanding.
To this end, we introduce Forecast-MAE, an extension of the masked autoencoder framework specifically designed for self-supervised learning of the motion forecasting task.
Our methodology comprises a novel masking design that exploits the strong interdependencies among all agents’ tra-jectories and road networks. Despite being simple and in-corporating minimal inductive bias, our proposed Forecast-MAE performs strongly on the challenging Argoverse 2 (AV2) motion forecasting benchmark [43] and significantly outperforms the previous self-supervised learning method.
Our contribution can be summarized as follows:
• To our best knowledge, we propose the first masked autoencoding framework for self-supervised learning on the motion forecasting task. Without extra data or pseudo-labels, our method greatly improves the per-formance of motion forecasting through pre-training compared to training from scratch.
• We introduce a straightforward yet highly effective masking scheme that facilitates the learning of bi-directional motion connections and cross-modal rela-tionships within a single reconstruction pretext task.
• We show that our approach, based entirely on standard
Transformers with minimal inductive bias, achieves competitive performance compared to the state-of-the-art with supervised learning on the challenging Argo-verse 2 benchmark, and significantly outperforms the previous self-supervised learning method.
• Our findings suggest that SSL can be a promising ap-proach for motion forecasting, and we anticipate that this may spark greater interest in the field. 2.