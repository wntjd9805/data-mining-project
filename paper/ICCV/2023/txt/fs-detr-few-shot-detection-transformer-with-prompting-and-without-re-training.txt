Abstract
This paper is on Few-Shot Object Detection (FSOD), where given a few templates (examples) depicting a novel class (not seen during training), the goal is to detect all of its occurrences within a set of images. From a practi-cal perspective, an FSOD system must fulfil the following desiderata: (a) it must be used as is, without requiring any fine-tuning at test time, (b) it must be able to process an arbi-trary number of novel objects concurrently while supporting an arbitrary number of examples from each class and (c) it must achieve accuracy comparable to a closed system. To-wards satisfying (a)-(c), in this work, we make the following contributions: We introduce, for the first time, a simple, yet powerful, few-shot detection transformer (FS-DETR) based on visual prompting that can address both desiderata (a) and (b). Our system builds upon the DETR framework, extend-ing it based on two key ideas: (1) feed the provided visual templates of the novel classes as visual prompts during test time, and (2) “stamp” these prompts with pseudo-class em-beddings (akin to soft prompting), which are then predicted
Importantly, we show that at the output of the decoder. our system is not only more flexible than existing methods, but also, it makes a step towards satisfying desideratum (c).
Specifically, it is significantly more accurate than all meth-ods that do not require fine-tuning and even matches and outperforms the current state-of-the-art fine-tuning based methods on the most well-established benchmarks (PASCAL
VOC & MSCOCO). 1.

Introduction
Thanks to the advent of deep learning, object detection has witnessed tremendous progress over the last years. How-ever, the standard setting of training and testing on a closed set of classes has specific important limitations. Firstly, it’s unfeasible to annotate all objects of relevance present in-the-wild, thus, current systems are trained only on a small subset.
It does not seem straightforward to significantly scale up this figure. Secondly, human perception operates mostly under the open set recognition/detection setting. Humans can de-tect/track new unseen objects on the fly, typically using a single template, without requiring any “re-training” or “fine-tuning” of their “detection” skills, arguably a consequence of the prior representation learned, an aspect we sought to exploit here too. Finally, important applications in robotics, where agents may interact with previously unseen objects, might require their subsequent detection on the fly without any re-training. Few-Shot Object Detection (FSOD) refers to the problem of detecting a novel class not seen during training and, hence, can potentially address many of the aforementioned challenges.
There are still important desiderata that current FSOD system must address in order to be practical and flexible to use: (a) They must be used as is, not requiring any re-training (e.g. fine-tuning) at test time - a crucial component for autonomous exploration [24]. However, many existing state-of-the-art FSOD systems (e.g. [37, 44, 32]) rely on re-training with the few available examples of the unseen classes. While such systems are still useful, the require-ment for re-training makes them significantly more difficult to deploy on the fly and in real-time or on devices with limited capabilities for training. (b) They must be able to handle an arbitrary number of novel objects (and moreover an arbitrary number of examples per novel class) simulta-neously during test time, in a single forward pass without requiring batching. This is akin to how closed systems work, which are able to detect multiple objects concurrently. How-ever, to our knowledge there is no FSOD system possessing this property without requiring re-training. (c) They must attain classification accuracy that is comparable to that of closed systems. However, existing FSOD systems are far from achieving such high accuracy, especially for difficult datasets like MSCOCO.
This work aims to significantly advance the state-of-the-art in all three above-mentioned challenges. To this end, and building upon the DETR [3] framework, we propose a system, called Few-Shot Detection Prompting (FS-DETR), capable of detecting multiple novel classes at once, support-ing a variable number of examples per class, and importantly, without any extra re-training. In our system, the visual tem-plate(s) (i.e. prompts) from the new class(es) are used, dur-1
ing test time, in two ways: (1) in FS-DETR’s encoder to filter the backbone’s image features via cross-attention, and more importantly, (2) as visual prompts in FS-DETR’s de-coder, “stamped” with special pseudo-class encodings and prepended to the learnable object queries. The pseudo-class encodings are used as pseudo-classes which a classification head attached to the object queries is trained to predict via a Cross-Entropy loss. Finally, the output of the decoder are the predicted pseudo-classes and regressed bounding boxes.
The two components, when combined allow the creation of a FSOD model that can localise, within one forward pass multiple objects at once, each with an arbitrary number of examples, without retraining.
Contrary to prior work (e.g. TSF [21] and AirDet [24]),
FS-DETR, akin to soft-prompting [19], “instructs” the model in the input space regarding the visual appearance of the searched object(s). The network is then capable of predict-ing for each prompt (i.e. visual template) all the locations at which it is present in the image, if any. This is achieved with-out any additional modules or carefully engineered structures and feature filtering mechanisms (e.g. TSF [21] AirDet [24]).
Instead, we directly append the prompts to the object queries of the decoder.
In summary, our main contributions are: 1. We propose a fine-tuning-free Few-Shot Detection
Prompting (FS-DETR) method which is capable of de-tecting multiple novel objects at once, and can support an arbitrary number of samples per class in an efficient manner via soft visual prompting. 2. We show that all these features can be enabled by ex-tending DETR based on two key ideas: (1) feed the provided visual templates of novel classes as visual prompts during test time, and (2) “stamp” these prompts with (class agnostic) pseudo-class embeddings, which are then predicted at the output of the decoder along with bounding boxes (akin to soft-prompting). 3. We also propose a simple and efficient yet powerful pipeline consisting of unsupervised pre-training fol-lowed by prompt-like base class training. 4. In addition to being more flexible, our system matches and outperforms state-of-the-art results on the standard
FSOD setting on PASCAL VOC and MSCOCO. Specif-ically, FS-DETR outperforms the not re-trained meth-ods of [13, 24] and most re-training based methods on extreme few-shot settings (k = 1, 2), while being competitive for more shots. 2.