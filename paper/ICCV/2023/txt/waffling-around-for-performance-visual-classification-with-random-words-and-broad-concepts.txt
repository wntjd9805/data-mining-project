Abstract
The visual classification performance of vision-language models such as CLIP has been shown to benefit from ad-ditional semantic knowledge from large language models (LLMs) such as GPT-3. In particular, averaging over LLM-generated class descriptors, e.g. “waffle, which has a round shape”, can notably improve generalization performance.
In this work, we critically study this behavior and propose
WaffleCLIP, a framework for zero-shot visual classifica-tion which simply replaces LLM-generated descriptors with random character and word descriptors. Without query-ing external models, we achieve comparable performance gains on a large number of visual classification tasks. This allows WaffleCLIP to both serve as a low-cost alterna-tive, as well as a sanity check for any future LLM-based vision-language model extensions. We conduct an extensive experimental study on the impact and shortcomings of ad-ditional semantics introduced with LLM-generated descrip-tors, and showcase how - if available - semantic context is better leveraged by querying LLMs for high-level con-cepts, which we show can be done to jointly resolve po-tential class name ambiguities. Code is available here: https://github.com/ExplainableML/WaffleCLIP. 1.

Introduction
Task-specific tuning of natural language prompts [31, 67, 8, 26] can improve the performance of large vision-language models (VLMs) [47]. However, if the model does not have access to additional training data, i.e. in the zero-Instead, a promising shot setting, this is not an option. alternative [42, 46, 36] is querying large language mod-els (LLMs) to provide additional semantic context to en-rich class representations. Extending classnames with fine-grained class descriptors generated by GPT-3 [5] and mini-mal human intervention has experimentally shown to boost results [36, 46], for instance with class-based descriptors on
Figure 1: Substituting GPT-3 generated fine-grained de-scriptors with random word or character sequences yields competitive performance. High-level concepts further re-solve classname ambiguities for additional gains. top of classnames, e.g. a round shape for waffle [36].
However, close inspection of GPT-3 generated seman-tic cues indicates a high degree of diversity, limited vi-sual relevance, and ambiguity [36]. For instance, multi-ple descriptors can be assigned to the same class despite likely not co-occurring, e.g. “steamed” and “fried”, or non-visual attributes might be mentioned, e.g. “a sour and spicy smell”, or the class interpretation might be ambiguous, e.g.
“webbed feet” for “Peking duck” as a food item. Hence, the underlying drivers of performance improvements when using generated fine-grained class descriptors are unclear.
To understand these performance gains, we first show that each set of class-specific GPT-3 generated descriptors can be replaced with a fixed set of randomly selected, class-independent descriptors while still retaining similar bene-fits in performance. Motivated by this observation, we take this one step further and propose WaffleCLIP, named af-ter waffling around the class name, that replaces the LLM-generated fine-grained descriptors, e.g. a round shape, a grid pattern, with random words (e.g. ”foot loud”) or char-acter lists (e.g. ”jmhj, !J#m”) based on average class name length and word counts (cf. Figure 1). As WaffleCLIP does not require access to LLMs for additional context (un-like e.g. [36, 42, 46, 56]), it remains inherently zero-shot.
Consequently, it also serves as an important sanity check for future methods utilizing external model queries.
Naturally, the convincing performance of WaffleCLIP across benchmarks raises questions regarding the true ben-efits of additional semantics introduced by LLM-generated descriptors. We provide answers with extensive experi-ments, showcasing that semantic descriptors produced by
LLMs offer a structurally different and complementary im-pact on the classification behavior. However, we find this not to be fully driven by additionally introduced semantics, but rather a different form of structured noise ensembling.
Instead, we show that actual semantic context is bet-ter introduced through coarse-grained, high-level concepts.
Given access to external LLMs, we suggest a query mech-anism for GPT-3 to automatically generate these concepts (e.g. food for waffle, peking duck), while jointly resolving issues of context-dependent class label ambiguity.
In summary, our contributions are: 1) We motivate and propose WaffleCLIP to use random character and word de-scriptors to enhance the semantic retrieval process in VLMs (particularly CLIP); 2) we demonstrate that WaffleCLIP yields comparable zero-shot classification performances at lower cost compared to methods reliant on LLM-generated descriptors, thus also serving as an important sanity check for future models; 3) we extensively study the seman-tic context introduced through LLM-generated descrip-tors and propose (automatically extracted) high-level LLM-generated concepts as an alternative for better use of seman-tics while tackling classname ambiguities. 2.