Abstract
Prompt tuning, a recently emerging paradigm, enables the powerful vision-language pre-training models to adapt to downstream tasks in a parameter- and data- efficient way, by learning the “soft prompts” to condition frozen pre-training models. Though effective, it is particularly prob-lematic in the few-shot scenario, where prompt tuning per-formance is sensitive to the initialization and requires a time-consuming process to find a good initialization, thus restricting the fast adaptation ability of the pre-training
In addition, prompt tuning could undermine the models. generalizability of the pre-training models, because the learnable prompt tokens are easy to overfit to the limited training samples. To address these issues, we introduce a novel Gradient-RegulAted Meta-prompt learning (GRAM) framework that jointly meta-learns an efficient soft prompt initialization for better adaptation and a lightweight gra-dient regulating function for strong cross-domain general-izability in a meta-learning paradigm using only the unla-beled image-text pre-training data. Rather than designing a specific prompt tuning method, our GRAM can be eas-ily incorporated into various prompt tuning methods in a model-agnostic way, and comprehensive experiments show that GRAM brings about consistent improvement for them in several settings (i.e., few-shot learning, cross-domain generalization, cross-dataset generalization, etc.) over 11 datasets. Further, experiments show that GRAM enables the orthogonal methods of textual and visual prompt tuning to work in a mutually-enhanced way, offering better gener-alizability beyond the uni-modal prompt tuning methods.
*Equal Contribution.
†Work done when interning at Huawei Cloud.
‡Corresponding Author.
Figure 1: (a) Prompt tuning accuracy varies significantly with different initialization. (b) As the training continues,
CoOp’s performance drops severely while our GRAM pre-vents CoOp from overfitting to spurious correlations. 1.

Introduction
Pre-trained on vast image-text pairs that cover almost an infinite range of concepts in the real-world, recent vision-language pre-training models [44, 16, 22] have exhibited impressive generalizability on a wide variety of downstream tasks [1, 32, 29, 28, 59]. By simply infilling a hand-crafted template (e.g., “a photo of a [CLASS]”) prompt with real class names as input to the text encoder, the pre-training models can achieve zero-shot image classification.
While effective, a slight word change in prompt templates could lead to a huge difference in performance [62]. Thus, identifying suitable prompts for different tasks requires time-consuming attempts by experts on an extra large vali-dation set. Instead of manually designing hard prompts (dis-crete language words), some recent prompt tuning meth-ods [62, 61, 63, 17, 20] are proposed to learn a set of soft prompts (continuous embeddings) using a few labeled data.
Despite clear improvements on the downstream tasks,
prompt tuning for few-shot generalization still has two lim-itations: (1) Initialization-sensitive issue: performance is particularly sensitive to the initialization of soft prompts.
Figure 1(a) shows that the average few-shot performance varies significantly due to different initialization. Every time we encounter a new task, we need to carefully tune different initialization, which restricts the pre-training mod-els from fast adapting to new tasks. (2) Generalizability degradation: since all the prompt tokens are fine-tuned on limited training samples, it can easily overfit to some spurious correlations or in-distribution patterns, damaging the generalizability of the pre-training models. As shown in Figure 1(b), CoOp achieves the best results at the early stage. However, as the training continues, its generalizabil-ity decreases significantly.
In this paper, we propose a novel Gradient-RegulAted
Meta-prompt learning (GRAM) framework to jointly meta-learn an efficient soft prompt initialization that learns to better adapt to new prompting tasks and a lightweight gra-dient regulating function that learns to transform the raw fine-tuning gradient into a consistent direction across do-mains to prevent prompt tuning from damaging the gener-alizability of the pre-training models.
Meta-learning [7], also known as learning to learn, op-timizes the ability to quickly learn new tasks with only a few samples by transferring the knowledge from learning across a set of meta-training tasks. Typical meta-learning algorithms usually assume access to a distribution of well-annotated meta-training tasks. Differently, we resort to large-scale image-text pairs on the Internet, which is eas-ily available and contains a broader set of visual concepts.
Specifically, we first design a Cross-Modal Hierarchi-cal Clustering algorithm to organize the large-scale image-text data into a hierarchical structure, where the image-text data is first grouped into different semantic topics accord-ing to the text descriptions, and each topic of data is fur-ther grouped into multiple domains according to the image contents. Then, a diverse set of meta-training classification tasks can be derived by subsampling from the set of seman-tic topics. For each meta-training task, we simulate domain shift between support set and query set by sampling exam-ples from different domains. The meta-optimization objec-tive is then defined as: after fine-tuning the prompt initial-ization by one or a few steps using the regulated gradient over a few support set samples, the newly prompted pre-training model should directly perform well on the query set domain. The soft prompt initialization and the gradi-ent regulating function are jointly updated according to the meta gradient directions over the query set samples, thus explicitly learning to better adapt to the new tasks and to avoid overfitting to specific in-domain biases.
Moreover, we provide analysis to show that the proposed gradient regulating function is learned to regulate the gradi-ent into a consistent direction across domains, thus avoiding overfitting to some spurious correlations of a single domain.
Note that, our method is model-agnostic. Comprehensive experiments show that GRAM is generalizable to different prompt tuning methods, significantly boosting all models’ performance and generalizability. Further, GRAM enables the harmonious and efficient integration of two orthogo-nal methods - textual prompt tuning (i.e., CoOp) and vi-sual prompt tuning (i.e., VPT). By jointly meta-learning an efficient initialization for both textual and visual prompts,
GRAM ensures that both the textual and visual prompts are optimized for better adaptation to new tasks in a comple-mentary way. The resulting UNIversal Gradient-RegulAted
Meta-prompt (UNIGRAM) leverages this seamless inte-gration to unlock the greater potential of both methods and achieves superior few-shot generalization performance.
Our contributions are mainly three-fold:
• We propose an innovative Gradient-RegulAted Meta-prompt learning (GRAM) framework that explicitly optimizes the adaptation capability to new prompting tasks and the generalization capability to novel do-mains in a bi-level meta-learning paradigm using only unlabeled image-text pre-training data.
• GRAM can be easily incorporated into different prompt tuning methods in a plug-and-play fashion, and the extensive experiments over 11 datasets illustrate the superior generalizability of our GRAM on base-to-new, cross-domain, and cross-dataset generalization.
• In addition, GRAM enables the orthogonal methods of textual and visual prompt tuning to work in a mutually-enhanced manner, offering stronger generalizability. 2.