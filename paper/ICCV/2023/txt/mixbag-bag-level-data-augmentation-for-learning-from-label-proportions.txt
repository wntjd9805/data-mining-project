Abstract
Learning from label proportions (LLP) is a promising weakly supervised learning problem. In LLP, a set of in-stances (bag) has label proportions, but no instance-level labels are given. LLP aims to train an instance-level classi-fier by using the label proportions of the bag. In this paper, we propose a bag-level data augmentation method for LLP called MixBag, based on the key observation from our pre-liminary experiments; that the instance-level classification accuracy improves as the number of labeled bags increases even though the total number of instances is fixed. We also propose a confidence interval loss designed based on sta-tistical theory to use the augmented bags effectively. To the best of our knowledge, this is the first attempt to pro-pose bag-level data augmentation for LLP. The advantage of MixBag is that it can be applied to instance-level data augmentation techniques and any LLP method that uses the proportion loss. Experimental results demonstrate this ad-vantage and the effectiveness of our method. 1.

Introduction
In general classification tasks, a model is trained on datasets where each piece of data (instance) has class labels.
However, instance-level annotations cost a lot, and there are many cases in which instance-level annotation cannot be disclosed to the public for privacy reasons [23]. In such a situation, we only know the label proportions given to a set of instances (bag) and must train a model from these label proportions to classify each instance. This problem setting is known as learning from label proportions (LLP) [1].
Figure 1 illustrates the problem setup of LLP. A bag B consists of instances (e.g., images). Bag-level labels are given as training data instead of instance-level labels (class labels of each instance x are unknown). The label propor-tion pi of bag Bi is given as a bag-level label. For example, if a bag B0 contains 60, 100, and 40 instances of class 1, 2, and 3, respectively, pi = (0.3, 0.5, 0.2)T. LLP aims to train an instance-level classifier by using the label proportions of a bag. It is a weakly supervised learning task.
Figure 1. Illustration of learning from label proportions. LLP aims to train an instance-level classifier by using label proportions of a bag as training data instead of instance-level labels.
Many LLP methods have been proposed to address this challenging task [1, 24, 28, 27, 18, 19]. Most of them are based on the proportion loss, which evaluates the difference between the given proportion pi and the estimated propor-tion ˆpi, and can be calculated by taking the average of the class probabilities of the instances in a bag. The methods based on the proportion loss work well when bag-level la-bels (label proportions) are sufficient. However, the accu-racy decreases as the number of labeled bags decreases, i.e., insufficient labeled data causes difficulty in training a net-work, which is known in machine learning tasks.
In such cases, instance-level data augmentation is of-ten an effective way to improve accuracy. Many instance-level data augmentation techniques, such as perturbation, for general classification tasks have been proposed, and
Instance-their effectiveness has been demonstrated [25]. level data augmentation may improve the accuracy in LLP.
However, it does not increase the number of labeled bags from the original one, and it is difficult to generate various bags with different proportions without using instance-level labels (these are unknown in LLP).
This paper proposes a bag-level data augmentation for 1
LLP that can generate new bags with various label propor-tions. To design an effective bag-level data augmentation technique, we conducted a detailed analysis of what sit-uation can improve the accuracy in LLP. As a result, we found an important observation that the accuracy improves as the number of labeled bags increases, even though the to-tal number of instances is fixed, i.e., different bags overlap each other as shown in Figure 2 (Right). On the basis of this observation, we propose a bag-level data augmentation called MixBag. MixBag increases the number of labeled bags artificially by sampling instances from a pair of origi-nal bags and mixing them: this operation mimics the above observations. The expected label proportion of a generated mixed bag can be calculated by those of the original bags.
However, it may have a gap from the actual proportion of the mixed bag because randomly selected instances do not follow the proportion of the original ones. This gap ad-versely affects the training.
We thus introduce a confidence interval loss that helps to train a classification network by using the generated bags while avoiding this adverse effect by a proportion gap; it is statistically guaranteed. To the best of our knowledge, this is the first attempt to propose bag-level data augmentation for LLP. Experiments using eight datasets demonstrate the effectiveness of our method in various cases; our method improved the classification accuracy on all datasets. Our main contributions are summarized as follows.
• We examined how the number of labeled bags and the bag size affect the performance in LLP. From the pre-liminary experiments, we concluded that the accuracy improves as the number of labeled bags increases, even though the total number of instances is fixed.
• We proposed MixBag with a confidence interval loss.
This method artificially increases the number of la-beled bags, and the confidence interval loss helps train a classification network using the generated bags.
• We demonstrated that MixBag can be applied to any of the current LLP methods and any of the instance-level augmentation methods. Experimental results show that our method improved classification accuracy on various datasets. 2.