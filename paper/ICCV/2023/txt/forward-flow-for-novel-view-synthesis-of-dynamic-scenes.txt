Abstract
This paper proposes a neural radiance field (NeRF) ap-proach for novel view synthesis of dynamic scenes using forward warping. Existing methods often adopt a static
NeRF to represent the canonical space, and render dy-namic images at other time steps by mapping the sampled 3D points back to the canonical space with the learned backward flow field. However, this backward flow field is non-smooth and discontinuous, which is difficult to be fit-ted by commonly used smooth motion models. To address this problem, we propose to estimate the forward flow field and directly warp the canonical radiance field to other time steps. Such forward flow field is smooth and continuous within the object region, which benefits the motion model learning. To achieve this goal, we represent the canonical radiance field with voxel grids to enable efficient forward warping, and propose a differentiable warping process, in-cluding an average splatting operation and an inpaint net-work, to resolve the many-to-one and one-to-many map-ping issues. Thorough experiments show that our method outperforms existing methods in both novel view render-ing and motion modeling, demonstrating the effectiveness of our forward flow motion modeling. Project page: https:
//npucvr.github.io/ForwardFlowDNeRF. 1.

Introduction
Novel view synthesis (NVS) is a challenging and long-standing problem in computer vision and graphics, which has many applications in virtual reality, augmented reality, data augmentation, image editing, etc. Recently, differen-tiable neural rendering [26, 30, 59] has been introduced into this area. In particular, the neural radiance field (NeRF) [26]
† Corresponding author (daiyuchao@nwpu.edu.cn). The first three authors also with the Shaanxi Key Laboratory of Information Acqui-sition and Processing.
Figure 1. Comparison of backward flow and forward flow. This figure shows an example of backward and forward flow changes. (a) An example of dynamic scene. (b) With the bucket lifting up, different types of points cover the green point p, which needs very different backward flows to map this point back to canonical space. (d) shows the norm changes of the backward flow, which is not smooth. (c) On the other hand, the forward flow of position q, which maps the constant object point from canonical space to other times, is smooth and continuous. (e) shows the norm changes of the forward flow. promotes this area significantly and attracts lots of interest within a short time. NeRF [26] produces realistic images by representing the 3D world with a multi-layer perceptron (MLP), which maps the input 3D coordinates and 2D view direction to target density and color.
While the original NeRF [26] can only model static scenes, a series of works extend the NeRF-based framework from static to dynamic scenes [9, 13, 19, 32, 36, 49, 51, 55].
One of the promising directions is using a canonical space representation [15, 36, 49]. This representation sets one of the time steps as canonical time and models the static scene with a canonical radiance field. To render images at other time steps, a deformation field is used to estimate the
backward flow for moving the 3D points from the current time step back to the canonical time step. Although the canonical-based representation with the backward flow is easy to implement, the backward flow field is non-smooth and discontinuous. As shown in Fig. 1(b), for a fixed 3D position along the timeline, there will be different types of points covering the position p, which needs discontin-uous flows to map them back to canonical space (Fig. 1(d)).
So the backward flow cannot be fitted well with commonly used smooth motion models (MLP, for example). Also, dis-tortions are introduced to the static canonical space geom-etry due to the failure of the motion model, as shown in
Fig. 8.
To solve the problem of backward flow, we propose us-ing forward flow as the deformation model. Instead of warp-ing the sampled points on image rays at other time steps back to the canonical time and rendering at the canonical space, we propose to warp the whole canonical radiance field from the canonical time to other time steps using for-ward deformation flow and render at corresponding time steps. In this way, the forward flow estimated by the defor-mation model will be smooth and continuous for the same 3D position along the timeline (Fig. 1(c) and (e)). Note that
SNARF [7] has also used forward warping based on an in-verse skinning model, but it is designed for dynamic human modeling and cannot be used in general scenes. In this pa-per, we aim to achieve forward warping for general scenes, which means we must warp the whole space.
However, introducing forward warping into the canon-ical space based NeRF methods is not straightforward as there are three main problems to be solved. First, the tra-ditional canonical radiance field in existing methods cannot be warped explicitly, since the radiance field is represented as a continuous function parameterized by an MLP. To solve this problem, we propose to use the voxel grid to represent the canonical radiance field as it is finite and discrete. Re-cent voxel-based methods [27,44,62] have proven the effec-tiveness of this representation. The other two problems are the many-to-one and one-to-many mapping issues brought by the inherent property of the forward warping operation.
To address them, we propose a differentiable forward warp-ing method consisting of an average splatting operation and an inpaint network to solve the many-to-one and one-to-many issue, respectively. Extensive experiments have been conducted to verify the effectiveness of our method.
Our key contributions can be summarized as follows:
• To the best of our knowledge, we are the first to inves-tigate forward warping in dynamic view synthesis for general scenes. We propose a novel canonical based
NeRF with forward flow motion modeling for dynamic view synthesis. Thanks to the forward flow field, our method can better represent the object motions, and explicitly recover the trajectory of a surface point.
• We introduce voxel grid based canonical radiance field to enable reasonable computation of forward warping, and propose a differentiable forward warping method, including an average splatting operation and an inpaint network, to solve the many-to-one and one-to-many is-sues of forward warping.
• Experiments on multiple datasets show that our method outperforms existing methods on the D-NeRF [36] dataset, Hypernerf [33] dataset, NHR [54] dataset and our proposed dataset. 2.