Abstract
Attributed to the unstructured and sparse nature of point clouds, the transformer shows greater potential in point clouds data processing. However, the recent query-based 3D detectors usually project the features acquired from a sparse backbone into the structured and compact Bird’s Eye
View(BEV) plane before adopting the transformer, which destroys the sparsity of features, introducing empty tokens and additional resource consumption for the transformer.
To this end, in this paper, we propose a novel query-based 3D detector called Clusterformer, our Clusterformer re-gards each object as a cluster of 3D space which mainly consists of the non-empty voxels belonging to the same ob-ject, and leverages the cluster to conduct the transformer decoder to generate the proposals from the sparse voxel fea-tures directly. Such cluster-based transformer structure can effectively improve the performance and convergence speed of query-based detectors by making use of the object prior information contained in the clusters. Additionally, we in-troduce a Query2Key strategy to enhance the key and value features with the object-level information iteratively in our cluster-based transformer structure. Experimental results show that the proposed Clusterformer outperforms the pre-vious query-based detectors with a lower latency and mem-ory usage, which achieves state-of-the-art performance on the Waymo Open Datasets and KITTI Datasets. 1.

Introduction
LiDAR 3D object detection is a fundamental task in var-ious application fields such as autonomous driving systems and robotics navigation, which has attained wide attention in recent years [27, 39, 34, 26, 14, 41]. Unlike the im-ages with a regular structure in the 2D tasks, the point clouds from LiDAR sensors are unstructured and sparse, making it challenging to directly adopt the convolution neu-ral network (CNN). To tackle this challenge, some detec-†Equal contribution, *Corresponding author.
Figure 1. (a): The illustration of our cluster-based query initializa-tion and interaction range. We group the foreground non-empty voxels into different clusters(shown in different colors) based on center voting, and leverage the cluster center(represented by pur-ple rectangle) to initialize the queries. Additionally, we limit the interaction range in the same cluster to make the query only focus on an interest region. (b): Visualization of the attention map in proposed intra-cluster cross-attention(the red color denotes higher attention weight), which shows that the queries can adaptively ag-gregate crucial voxel features(such as the roof and corner area of a vehicle) in each cluster by the intra-cluster cross-attention. tors [27, 21, 35, 38] extract geometric features directly from point clouds based on the PointNet [22] or PointNet++ [23], while other approaches [34, 26, 14, 25] voxelize the raw point clouds into discrete grids then utilize standard CNN.
Witnessing the remarkable research achievements in vi-sion tasks [5, 17, 2, 42], the transformer has also drawn growing attention in point clouds processing recently [18, 7, 12, 41, 1, 6, 20], and shows greater potential com-pared to CNN and PointNet since it can directly pro-cess sparse variable-length point clouds and holds pow-erful ability in capturing contextual dependencies among points. Among them,
[41, 1, 6, 20] mainly leverage the transformer decoder to generate the detections from a set of predefined queries in an end-to-end manner which are also called query-based detectors. Following the currently mainstream grid-based detectors, these query-based detec-tors also project the sparse features into the BEV plane before adopting the transformer. Although we can ob-tain meaningful initial queries based on the learned BEV
center heatmap [41, 1] which is significant for the query-based detectors, we believe such projection for transformer structure still has the following drawbacks: 1) since the
Transformer structure holds powerful ability in processing variable-length sequential data, projecting the sparse and sequential point clouds into the regular and compact BEV plane for transformer structure is unnecessary; 2) the BEV projection destroys the natural sparsity of the features from a sparse convolution backbone, introducing empty ”tokens” for the transformer structure and additional resource con-sumption; Unlike these query-based detectors for outdoor scenes, the 3DETR [19] adopts the transformer decoder on the raw point clouds directly. However the initial queries in 3DETR are acquired from the 3D space by the Far-thest Point Sampling (FPS), such query initialization can’t achieve satisfactory performance for outdoor scenes due to the fact that point clouds in outdoor scenes are sparse and unevenly distributed compared to indoor scenes.
Based on the above observations, in this paper, we seek to design an effective query-based detector for outdoor scenes to leverage the ability of transformer structures in processing sparse sequence point clouds. To achieve this goal, one crucial factor is to acquire meaningful query point such as object centers [41, 1] from the sparse 3D space. In-spired by the concept of cluster in the 3D panoptic segmen-tation [15, 40], we propose a novel query-based 3D detec-tor called Clusterformer. Our Clusterformer regards each object as a cluster of 3D space which mainly consists of the non-empty voxels belonging to the same object and first obtains different clusters based on center voting. Since the cluster centers are closed to the object centers after center voting, we encode the cluster centers as the initial queries.
In this way, our Clusterformer can acquire the initial queries which contain accurate location information of candidates from 3D space in outdoor scenes.
The other significant factor for the query-based detectors is a reasonable interaction range for queries that directly influence the convergence speed [42, 20]. In our Cluster-former, we design an intra-cluster cross-attention to decode the queries into final detections, the cluster-based query ini-tialization allows us to perform intra-cluster interaction be-tween the queries and the grouped voxel features, which can keep the queries only focus on an interest region. We also introduce a Query2Key strategy to enhance the key and value features in the intra-cluster cross-attention with object-level information, which is contained in the query features. Since we have dropped abundant background and empty voxels in the cluster generating process, the cluster-based transformer structure can work in an efficient way.
Extensive experiments are conducted on the Waymo
Open Dataset [30] and KITTI dataset [10] to show the state-of-the-art performance of the Clusterformer, the contribu-tion of our Clusterformer can be summarized as follows: 1) A cluster-based transformer called Clusterformer is proposed for outdoor 3D object detection, which applies the transformer on the sparse voxel features to generate propos-als directly; 2) We leverage the clusters to acquire the initial queries and perform intra-cluster interaction in our Clusterformer to improve the performance and convergence speed by making use of the object prior information contained in clusters, we also conduct extensive experiments to explore how query initialization strategy and interaction range affect the per-formance of query-based detectors; 3) A simple but effective strategy is introduced to en-hance the key and value features with object-level informa-tion during the multiple transformer decoder layers; 4) The proposed Clusterformer has acquired state-of-the-art performance on the large-scale Waymo Open dataset and
KITTI dataset. 2.