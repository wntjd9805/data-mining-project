Abstract
Label noise is pervasive in real-world applications, which influences the optimization of neural network mod-els. This paper investigates a realistic but understudied problem of image retrieval under label noise, which could lead to severe overfitting or memorization of noisy samples during optimization. Moreover, identifying noisy samples correctly is still a challenging problem for retrieval mod-els.
In this paper, we propose a novel approach called
Prototypical Mixing and Retrieval-based Refinement (TI-TAN) for label noise-resistant image retrieval, which cor-rects label noise and mitigates the effects of the memoriza-tion simultaneously. Specifically, we first characterize nu-merous prototypes with Gaussian distributions in the hidden space, which would direct the Mixing procedure in provid-ing synthesized samples. These samples are fed into a sim-ilarity learning framework with varying emphasis based on the prototypical structure to learn semantics with reduced overfitting. In addition, we retrieve comparable samples for each prototype from simple to complex, which refine noisy samples in an accurate and class-balanced manner. Com-prehensive experiments on five benchmark datasets demon-strate the superiority of our proposed TITAN compared with various competing baselines. 1.

Introduction
Content-based image retrieval has been an essential re-search area in computer vision [7], with various applica-tions in search engineering [49, 13] and medical image anal-ysis [19]. Content-based image retrieval can be divided
*Equal contribution. †Corresponding author. into instance-level retrieval [1, 62] and category-level re-trieval [45, 43, 53]. The former focuses on capturing the
In recent years, same instance in different environments. category-level retrieval has gained popularity by delivering samples from a massive database with results grouped by the same category as the query [36].
The core of successful category-level retrieval is to map instances to data points in the feature space while preserv-ing similarity connections. The majority of current ap-proaches focus on similarity learning [46, 35], which use pairwise [30] and triplet [16, 50] objectives to maintain se-mantics in the embedding space. These approaches pro-mote the proximity of semantically similar samples in the embedding space and the separation of semantically dif-ferent samples. An alternative strategy is to utilize prox-ies [53, 36, 21, 14]. These methods map each class into the deep feature space to guide semantics learning in a point-wise manner. A few of studies use binary descriptors to improve efficiency [44, 56], which results in a candidate set followed by further refinement for precise image retrieval.
Despite their considerable success, these retrieval sys-tems often presume that the semantic labels in the training set are accurate. In real-world applications, this assumption could be invalidated by the possibility of annotation mis-takes and inadequate automated collecting tactics [47, 54].
For instance, web-based sources often include tags and cap-tions, which are usually utilized to provide label informa-tion for convenience. These approaches could generate ex-tensive label noise to collected datasets. To address this issue, this work studies a practical topic named image re-trieval with label noise. Although there are extensive pa-pers to study the problem of robust learning in classification tasks [29, 12, 25], retrieval models under label noise are still underexplored with unsatisfactory performance in practice.
the superiority of our TITAN by comparing it to a number of benchmarks. The contribution of this paper can be sum-marized as follows:
• This paper studies a less-explored but practical problem named label noise-resistant image retrieval and proposes a novel method named TITAN for this problem.
• On the one hand, TITAN measures the distributions of different prototypes and then generates synthesis data to prevent the memorization of noisy samples. On the other hand, TITAN retrieves comparable samples for each pro-totype from easy to hard, promising accurate and class-balanced label refinement.
• Extensive experiments on five benchmark datasets demonstrate the superiority of our TITAN compared with various baseline methods in different settings. 2.