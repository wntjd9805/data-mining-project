Abstract
Detection transformer (DETR) relies on one-to-one as-signment, assigning one ground-truth object to one predic-tion, for end-to-end detection without NMS post-processing.
It is known that one-to-many assignment, assigning one ground-truth object to multiple predictions, succeeds in de-tection methods such as Faster R-CNN and FCOS. While the naive one-to-many assignment does not work for DETR, and it remains challenging to apply one-to-many assign-ment for DETR training.
In this paper, we introduce
Group DETR, a simple yet efficient DETR training ap-proach that introduces a group-wise way for one-to-many assignment. This approach involves using multiple groups of object queries, conducting one-to-one assignment within each group, and performing decoder self-attention sepa-rately. It resembles data augmentation with automatically-learned object query augmentation.
It is also equivalent to simultaneously training parameter-sharing networks of the same architecture, introducing more supervision and thus improving DETR training. The inference process is the same as DETR trained normally and only needs one group of queries without any architecture modification. Group
DETR is versatile and is applicable to various DETR vari-ants. The experiments show that Group DETR signifi-cantly speeds up the training convergence and improves the performance of various DETR-based models. Code will be available at https://github.com/Atten4Vis/
GroupDETR. 1.

Introduction
Detection Transformer (DETR) [2] conducts end-to-the need of many hand-end object detection without
*Equal contribution.
â€ Corresponding author.
Figure 1. Group DETR accelerates the training process for
DETR variants. The training convergence curves are obtained on COCO val2017 [24] with ResNet-50 [13]. Dashed and bold curves correspond to the baseline models and the Group DETR counterparts. Best viewed in color. crafted components, such as non-maximum suppression (NMS) [14] and anchor generation [33, 23, 32]. The ar-chitecture consists of a CNN [13] and transformer en-coder [37], and a transformer decoder that consists of self-attention, cross-attention and FFNs, followed by class and box prediction FFNs. During training, one-to-one assign-ment, where one ground-truth object is assigned to one sin-gle prediction, is applied for learning to only promote the predictions assigned to ground-truth objects, and demote the duplicate predictions.
This work explores the solutions to accelerate the DETR training process. Previous solutions contain two main lines.
The one line is to modify cross-attention so that informa-tive image regions are selected for effectively and efficiently collecting the information from image features. Example methods include sparse sampling, through deformable at-tention [47], and spatial modulations with modifying object queries [8, 30, 4, 40, 43, 25, 9]. The other line is to sta-bilize one-to-one assignment during training, e.g., feeding ground-truth bounding boxes with noises into transformer
decoder [20, 44].
We are interested in the second line. Instead of focus-ing on stabilizing the assignment like DN-DETR [20], we study the assignment scheme for efficient DETR training from a new perspective: introducing more supervision. It has been proven that assigning one ground-truth object to multiple predictions, i.e., one-to-many assignment, is suc-cessful in traditional object detection methods, e.g., Faster
R-CNN [33] and FCOS [36] with more anchors and pixels assigned to one ground-truth object. Unfortunately, naive one-to-many assignment does not work for DETR training.
It remains a challenge to apply one-to-many assignment to
DETR training.
We present a simple yet efficient DETR training ap-proach that uses a group-wise way for one-to-many assign-ment, called Group DETR. Our approach is based on that end-to-end detection with successful removal of NMS post-processing for DETR comes from the joint effect of two components [2, 30]: decoder self-attention, which collects the information of other predictions, and one-to-one assign-ment, which expects to learn to score one prediction higher and other duplicate predictions lower for one ground-truth object.
Our approach adopts K groups of object queries, and in-troduces group-wise one-to-many assignment. This assign-ment scheme conducts one-to-one assignment within each group of object queries, resulting in that one ground-truth object is assigned to multiple predictions. It is encouraged that the prediction assigned to the ground-truth object gets a high score, and other duplicate predictions from the same group of queries get low scores. In other words, the pre-dictions make competition within each group. Thus, our approach uses separate self-attention, i.e., self-attention is done for each group separately, eliminating the influence of predictions from other groups and easing DETR training.
Regarding inference, it is the same as DETR trained nor-mally, and only needs a single group of object queries.
The resulting architecture is equivalent to DETR with a group of parallel decoders, illustrated in Figure 2 (a).
During training, the parallel decoders boost each other through sharing decoder parameters and using different ob-ject queries. On the other hand, using more groups of object queries resembles data augmentation, and behaves as query augmentation. It introduces more supervision and improve the decoder training. In addition, it is empirically observed that the encoder training is also improved, presumably with the help of the improved decoder.
Group DETR is versatile and is applicable to various
DETR variants. Extensive experiments demonstrates that our approach is effective in achieving fast training conver-gence, shown in Figure 1. Group DETR obtains consistent improvements on various DETR-based methods [30, 25, 20, 44]. For instance, Group DETR significantly improves
Conditional DETR-C5 by 5.0 mAP with 12-epoch training on COCO [24]. The non-trivial improvements hold when we adopt longer training schedules (e.g., 36 epochs and 50 epochs). Furthermore, Group DETR outperforms baseline methods for multi-view 3D object detection [26, 27] and instance segmentation [5]. 2.