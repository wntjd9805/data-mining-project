Abstract
We present a novel unsupervised domain adaption method for person re-identification (reID) that generalizes a model trained on a labeled source domain to an unlabeled target domain. We introduce a camera-driven curriculum learning (CaCL) framework that leverages camera labels of person images to transfer knowledge from source to tar-get domains progressively. To this end, we divide target do-main dataset into multiple subsets based on the camera la-bels, and initially train our model with a single subset (i.e., images captured by a single camera). We then gradually exploit more subsets for training, according to a curricu-lum sequence obtained with a camera-driven scheduling rule. The scheduler considers maximum mean discrepan-cies (MMD) between each subset and the source domain dataset, such that the subset closer to the source domain is exploited earlier within the curriculum. For each curricu-lum sequence, we generate pseudo labels of person images in a target domain to train a reID model in a supervised way. We have observed that the pseudo labels are highly biased toward cameras, suggesting that person images ob-tained from the same camera are likely to have the same pseudo labels, even for different IDs. To address the camera bias problem, we also introduce a camera-diversity (CD) loss encouraging person images of the same pseudo label, but captured across various cameras, to involve more for discriminative feature learning, providing person represen-tations robust to inter-camera variations. Experimental re-sults on standard benchmarks, including real-to-real and synthetic-to-real scenarios, demonstrate the effectiveness of our framework.
Figure 1: We visualize in (a) a t-SNE plot for features extracted from person images in Market1501 [55] and
MSMT17 [45], using a reID model trained on MSMT17, where MSMT17 and Market1501 are source and target do-mains, respectively. The samples from different cameras in the target domain are distinguished by different colors.
The model trained on a single domain offers features that are highly biased towards camera labels of person images for other domains. We propose to establish a camera-driven curriculum, as shown in (b), and initially train our model using images captured by a single camera, then gradually exploit more images captured using multiple cameras. To further alleviate the camera bias issue, we compute cluster-wise weights, as in (c), to encourage clusters containing im-ages obtained from various cameras to involve more during the adaptation process. 1.

Introduction
The objective of person re-identification (reID) is to re-trieve person images of the same ID as a query person across
*Corresponding author non-overlapping cameras [48, 56]. Current reID approaches mainly adopt a supervised learning paradigm by exploit-ing person ID labels, and focus on learning discriminative person representations in a single domain. However, reID
models trained on a specific domain typically fail to gen-eralize to other domains [7, 45], thus limiting the applica-bility in real-world scenarios. To address this issue, recent works [5, 45, 52, 53] exploit unsupervised domain adap-tation techniques, transferring knowledge learned from a source domain to re-identify persons in a target one, where
ID labels for the source domain are provided only [33]. This enables performing reID on the target domain without ad-ditional annotations, which is typically time-consuming and labor-intensive to obtain [29, 35, 55]. Unsupervised domain adaptive (UDA) reID is challenging due to the following reasons. Transferring knowledge from one domain to an-other is difficult due to the distribution gap between camera topologies for different domains [35, 45, 55]. Moreover, it is difficult to learn discriminative person representations for the target domain without ID labels, due to the large intra-class variations, particularly between person images captured by different cameras.
In recent years, most UDA reID methods [5, 11, 13, 19, 21, 31, 51, 52, 53, 57] exploit pseudo ID labels for target images to mitigate the discrepancies between source and target domains. To generate pseudo labels for the target domain, these methods first extract features from target im-ages, using a reID model pre-trained on the source domain, and apply a clustering algorithm (e.g., DBSCAN [9]) on the features. They then assign the same ID label to the im-ages which belong to the same cluster, facilitating training with target images in a supervised manner. While the UDA reID methods have allowed significant advances for UDA reID, they mainly have two limitations. First, current ap-proaches still focus on transferring knowledge from source to target in a domain-level. Namely, they attempt to adapt a model trained on a source domain to the target one at once, by regarding target images as a whole. This is not effective for transferring knowledge for UDA reID, since source and target domains have different camera topolo-gies. Second, pseudo labels for the target domain are highly biased towards camera labels of images (Fig. 1(a)). That is, person images captured by the same camera are likely to be assigned to the same pseudo ID label, even for the persons with different IDs. Directly training a reID model with such labels rather hinders discriminative feature learn-ing [5, 52, 53], particularly for the person images of the same ID but captured by different cameras.
In this paper, we present a novel framework for UDA reID that performs a progressive adaptation exploiting cam-era labels of person images. We conjecture that domain adaptation in a domain-level regime might be suboptimal, especially in the context of reID, since the distribution of a camera topology is highly unique for each domain. In order to consider an abrupt change on the camera topology from source to target domains, we propose a camera-driven cur-riculum learning (CaCL) leveraging camera labels of per-son images, facilitating a progressive adaptation (Fig. 1(b)).
To implement this idea, we first decompose a target domain dataset into multiple subsets w.r.t the camera labels. Start-ing from a single subset (i.e., images obtained from a sin-gle camera), we gradually add subsets to train our model, according to a curriculum sequence obtained by a camera-driven scheduling rule. The scheduler considers maximum mean discrepancies (MMD) [16] between each subset and the source domain dataset, such that a closer subset w.r.t the source dataset is exploited earlier within the curriculum. We also introduce a camera-diversity (CD) loss that encourages the clusters having person images obtained from various cameras to involve more for discriminative feature learn-ing (Fig. 1(c)). It further incorporates a selective scheme for training that discards trivial clusters, only consisting of per-son images taken from the same camera. A model trained with CD loss is able to offer person representations more robust to inter-camera variations, compared to conven-tional cross-entropy [58] and triplet [20] losses, even when training with pseudo labels biased to camera labels. To-gether with CaCL and the CD loss, we achieve a new state of the art on standard UDA reID benchmarks, including real-to-real (e.g., Market1501 [55]-to-MSMT17 [45] and
MSMT17-to-Market1501) and synthetic-to-real (e.g., Per-sonX [41]-to-Market1501 and Unreal [49]-to-MSMT17) scenarios, and demonstrate the effectiveness of our ap-proach with extensive experimental results and ablative analyses.
Our main contributions can be summarized as follows: (1) We introduce a novel curriculum learning framework for
UDA reID that leverages camera labels of person images.
To the best of our knowledge, this is the first to incorporate a curriculum learning scheme for UDA reID. We also present the camera-driven scheduler that determines the curriculum sequence for multiple subsets in a target domain. (2) We present the CD loss to learn discriminative person represen-tations, particularly robust to inter-camera variations, even when training with pseudo labels biased to camera labels. (3) We set a new state of the art on standard benchmarks for
UDA reID, including real-to-real and synthetic-to-real sce-narios, and demonstrate the effectiveness of our framework. 2.