Abstract
Open-world instance segmentation is a rising task, which aims to segment all objects in the image by learning from a limited number of base-category objects. This task is challenging, as the number of unseen categories could be hundreds of times larger than that of seen categories.
Recently, the DETR-like models have been extensively stud-ied in the closed world while stay unexplored in the open world. In this paper, we utilize the Transformer for open-world instance segmentation and present SWORD. Firstly, we introduce to attach the stop-gradient operation before classification head and further add IoU heads for discov-ering novel objects. We demonstrate that a simple stop-gradient operation not only prevents the novel objects from being suppressed as background, but also allows the net-work to enjoy the merit of heuristic label assignment. Sec-ondly, we propose a novel contrastive learning framework to enlarge the representations between objects and back-ground. Specifically, we maintain a universal object queue to obtain the object center, and dynamically select positive and negative samples from the object queries for contrastive learning. While the previous works only focus on pursuing average recall and neglect average precision, we show the prominence of SWORD by giving consideration to both cri-teria. Our models achieve state-of-the-art performance in various open-world cross-category and cross-dataset gen-eralizations. Particularly, in VOC to non-VOC setup, our method sets new state-of-the-art results of 40.0% on ARb 100 and 34.9% on ARm 100. For COCO to UVO generalization,
SWORD significantly outperforms the previous best open-world model by 5.9% on APm and 8.1% on ARm 100. 1.

Introduction
The standard instance segmentation models [21, 42, 11] are developed to segment the objects from a predefined tax-onomy, which is not often reflective of the diversity of ob-Table 1: The open-world generalization setups, which are established by the recent advanced approaches [26, 38, 46].
The values in the bracket indicate the class numbers.
Dataset
Train
Evaluate
Image Mask
Cross-cateory Generalization
COCO
LVIS
VOC(20)
COCO(80) non-VOC(60) non-COCO(1123) 95k 100k 493k 455k
Cross-dataset Generalization
UVO
COCO(80)
Objects365 COCO(80) non-COCO(-) non-COCO(285) 118k 118k 860k 860k ject classes encountered in the real world. Recently, class-agnostic open-world instance segmentation introduced by the advanced approaches [26, 38, 46] has gained increasing attention in the community. It requires the models to seg-ment all objects of arbitrary categories in the image while only base-category objects can be seen during training. This task is highly challenging, as the number of unseen cate-gories can be orders of magnitude larger than the number of seen categories. As shown in the second row of Table 1, for
COCO to LVIS setup, there are 1123 non-COCO classes for out-of-domain evaluation while only objects belonging to 80 COCO classes are annotated in the training set. Besides, a critical challenge in the open-world scenario is that the novel objects and background co-exist in the un-annotated regions. Consequently, the closed-world instance segmen-tation models fail to recognize unseen objects (Figure 1a) as they equally treat the novel objects and background as negative samples during training.
Recently, DETR-like [3, 55] models based on Trans-formers [43] have exhibited superior performance in stan-dard object detection and instance segmentation tasks.
However, the study of these Transformer-based models in the field of open-world instance segmentation is still a blank page to the community, as the previous works have exclu-sively relied on the Mask-RCNN [21] architecture. In this work, we aim to fill in the gap by delving deeply into the recent advanced Deformable-DETR [55].
An inspiring open-world method OLN [26] proposes a classification-free network and estimates the scores of re-gions purely by localization quality (e.g., IoU score).
In this manner, novel objects would not be penalized as back-ground due to the absence of classification learning. And the localization quality score is proven to be a better ob-jectness cue for discovering novel objects.
Inspired by this spirit, a straightforward solution for Transformer-based models in open-world instance segmentation is to replace the classification head with IoU heads. However, this could lead to two negative effects: (i) The Transformer-based models are optimized with set prediction loss [3], where the classification score is indispensible for label assign-Figure 2: SWORD† achieves the state-of-the-art perfor-mance on various settings compared with other open-world methods. The results are reported based on ARm 100 by de-fault. The metric of Objects365 [39] is ARb 100 since it does not provide mask annotations. ment. Therefore, simply removing the classification head could be harmful to the process. (ii) The network would inherit the limitation of OLN that lacks the discriminative ability to differentiate the objects and background. This is because OLN is only trained with positive samples and thus fails to perceive the background. As a result, it would produce numerous false positives (Figure 1b) and result in fairly low average precision (AP). For example, in COCO to UVO (all) generalization, ARm 100 of OLN [26] increases from 36.7% to 42.1% while APm significantly drops from 20.7% to 14.0% when compared with Mask-RCNN [21].
In this work, we cut off the above obstacles and propose
SWORD, unsealing the secrets of Transformer-based mod-els for open-world instance segmentation. We first intro-duce to attach a stop-grad operation before the classi-fication head and further add the IoU heads for predicting object scores. This not only prevents the novel object from being suppressed as background so as to improve the re-call ability of network, but also allows the DETR-like mod-els to preserve the classification head for heuristic label as-signment. Using stop-grad alone, however, would in-evitably reduce the network’s discrimination. Therefore, we then design a novel contrastive learning framework for learning the discriminative representations between objects and background. The core idea is to ensure similar rep-resentations among objects while enlarging the distinction between the objects and background in the feature space.
Specifically, we maintain a universal object queue to store the annotated object embeddings during training. The av-eraged feature of the queue, i.e., object center, captures the common characteristics of objects and plays as the role of
query in contrastive learning. The positive and hard nega-tive samples are dynamically selected from query embed-dings according to the matching cost [44, 34] with ground-truth. Contrastive learning is the key to reducing false posi-tives for network and greatly improves average precision.
To this end, SWORD not only reveals the strong abil-ity in recalling novel objects, but also achieves high av-erage precision. We further develop a model SWORD†, which has exactly the same architecture of Deformable-DETR [55] but is trained on the combination of annotations and pseudo ground-truths generated by SWORD. SWORD† shows clear performance gains compared with its counter-part under the open-world setups. To summarize, the con-tributions of this work are:
• A simple yet effective framework SWORD is presented, which is the first study of Transformer-based model for open-world instance segmentation.
• We introduce the stop-grad operation to kill two birds with one stone: preventing the side-effect of classification learning to discover novel objects in open-world setups, and enabling the heuristic label assignment for DETR-like models.
• We design a novel contrastive learning method to learn the discriminative representations between objects and background, which is essential for achieving high aver-age precision for the network.
• Extensive experiments demonstrate that our models achieve state-of-the-art performance on several bench-marks including COCO [31], LVIS [16], UVO [47] and
Objects365 [39], as shown in Figure 2. 2.