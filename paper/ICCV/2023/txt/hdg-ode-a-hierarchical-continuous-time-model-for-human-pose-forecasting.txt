Abstract activities.
Recently, human pose estimation has attracted more and more attention due to its importance in many real applica-tions. Although many efforts have been put on extracting 2D poses from static images, there are still some severe prob-lems to be solved. A critical one is occlusion, which is more obvious in multi-person scenarios and makes it even more difficult to recover the corresponding 3D poses. When we consider a sequence of images, the temporal correlation among the contexts can be utilized to help us ease the prob-lem, but most of the current works only rely on discrete-time models and estimate the joint locations of all people within a whole sparse graph. In this paper, we propose a new frame-work, Hierarchical Dynamic Graph Ordinary Differential
Equation (HDG-ODE), to tackle the 3D pose forecasting task from 2D skeleton representations in videos. Our frame-work adopts ODE, a continuous-time model, as the base to predict the 3D joint positions at any time. Considering the structural-property of the skeleton data in representing human poses and the possible irregularity caused by occlu-sion, we propose the use of dynamic graph convolution as the basic operator. To reduce the computational complex-ity introduced by the sparsity of the pose graph, our model takes a hierarchical structure where the encoding process at the observation timestamp is done in a cascade manner while the propagation between observations is conducted in parallel. The performance studies on several datasets demonstrate that our model is effective and can out-perform other methods with fewer parameters. 1.

Introduction
With the progress in the computer vision field, human-related contents have attracted more and more attention, as they are very important in many real-world applications.
Some examples are autonomous driving, human-computer interaction and anomaly detection. Among these contents, human poses are the most basic and important ones since their accurate and timely estimation or even forecasting usu-ally serve as the first step for further analyzing complex
Human pose estimation is not a novel topic but has been studied for many years. Its performance, however, is still not satisfactory enough to meet the demands of many prac-tical applications. Since A. Toshev and C. Szegedy pro-posed DeepPose [69] to represent human poses by the lo-cations of a set of joints from human skeletons and first time utilized the regression method of deep learning to es-timate the corresponding 2D coordinates, a lot of efforts
[78, 51, 87, 20, 86, 19, 79, 77, 54, 67, 95, 94, 3, 66, 74, 73] have been made to get the accurate estimation in the pres-ence of occlusion resulted from the perspective limitation of images. These methods [14, 33, 55, 65, 34, 68, 38, 53, 16, 71, 58, 48, 99, 100, 84] are extended to multi-person scenar-ios, where the occlusion problem is more severe. Although some progress has been made, 2D locations cannot perfectly restore the human poses, and are never our final goals for this task. Recently, more and more works have been focusing on 3D pose estimation with raw images [15, 24, 6, 91] or extracted 2D poses [96, 21, 5, 18, 93, 39, 97, 83, 17, 43, 91] as input. Besides the inherent occlusion problems, the lack of depth in monocular images also limits the performance of algorithms. Although some schemes relying on multi-view images [50, 60, 94, 80, 72, 10, 70, 28, 40, 25, 11] or other sensors [54, 31, 27, 94] can ease this problem to some de-gree, we have to admit that paired images of different views or complementary sensors are not always available in most scenarios. The core problem is how to just utilize limited in-formation in monocular images to extract the corresponding 3D poses of people. If a sequence of images (i.e. video) is available, the temporal context carried can be also helpful for the task [1, 81, 7, 47, 76]. They not only provide information to make up the missing joints caused by the occlusion and provide hints for joints’ locations in the future, but also help group the detected joints belonging to a specific person in multi-person scenarios. So in this paper, we mainly focus on restoration from a sequence of monocular multi-person 2D skeletons to predict the corresponding 3D poses at a future time point.
Some related methods [64, 9, 75, 82, 41, 11, 98, 26, 13, 63, 36] usually applied graph neural networks to encode the
2D human joints and propagated the information through recurrent neural networks or directly used spatial-temporal graph convolutional networks. However, almost all of them only focused on single-person scenarios, while in most of cases, the relations among people in the scene are also help-ful for the forecasting. Also, there exist several limitations in these works. Firstly, traditional recurrent neural networks, such as GRU or LSTM, all use discrete-time sequential mod-els, which have a fixed propagation step and are not flexible enough to deal with different moving speeds of different human joints. The performance of these models will be compromised when the video frequency is not high or the cameras need to scan around in a certain period instead of shooting a fixed scene. For example, if the human pose is recorded every second in the video, discrete-time models cannot provide the forecasting result within 1 second. In-stead, we propose to use neural ordinary differential equation (NeuralODE), a continuous-time model, to propagate infor-mation along the temporal axis in our framework. Secondly, we notice that any joint of a person is only connected to its nearest neighbors, which makes the adjacency matrix used in the graph convolution very sparse, and leads to inefficient calculations in turn. To reduce the meaningless calculations and increase the efficiency of our model, we propose to utilize a hierarchical structure to decompose a sparsely con-nected graph into several dense graphs and encode them in a cascade manner. By doing so, we can also deal with edges of different types separately, such as the edges between people and the edges connecting joints within each person. Lastly, the whole and fixed binary adjacency matrix is used for the graph convolution in the literature, although the actual con-nections of joints only occupy a very small part of the graph due to the occlusion. Instead, we propose to provide dynamic topology information at each time stamp. Different from works [21, 96, 84, 58, 42, 43] which learned another weight matrix from fully observed input, we propose to learn the weight matrix from partial input to more timely capture the effect of every specific connection in the graph and multiply it with the time-varying dynamic binary adjacency matrix to form the final one used in graph convolutions.
To summarize, the main contributions of this paper are three folds:
• We propose a continuous-time framework which takes the sequence of 2D skeletons extracted from a multi-person video as the input to forecast the multi-person 3D poses in any future time.
• We design our model as a hierarchical structure to re-duce the computational complexity for multi-person scenarios, and also deal with different connection types in the graph.
• We utilize dynamic graph convolutions to deal with the irregular input caused by occlusions.
In the remaining of this paper, we will briefly introduce the related works in Sec. 2 and give the details of our model in Sec. 3. The performance of our model is demonstrated through experiments in Sec. 4. Finally, we will conclude our work in Sec. 5. The corresponding source code can be found at https://github.com/SBU-YCX/HDG-ODE. 2.