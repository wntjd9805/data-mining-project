Abstract
Many Vision-and-Language Navigation (VLN) tasks have been proposed in recent years, from room-based to object-based and indoor to outdoor. The REVERIE (Re-mote Embodied Referring Expression) is interesting since it only provides high-level instructions to the agent, which are closer to human commands in practice. Nevertheless, this poses more challenges than other VLN tasks since it requires agents to infer a navigation plan only based on a short instruction. Large Language Models (LLMs) show great potential in robot action planning by providing proper prompts. Still, this strategy has not been explored under the
REVERIE settings. There are several new challenges. For example, the LLM should be environment-aware so that the navigation plan can be adjusted based on the current visual observation. Moreover, the LLM planned actions should be adaptable to the much larger and more complex REVERIE environment. This paper proposes a March-in-Chat (MiC) model that can talk to the LLM on the ﬂy and plan dynam-ically based on a newly proposed Room-and-Object Aware
Scene Perceiver (ROASP). Our MiC model outperforms the previous state-of-the-art by large margins by SPL and
RGSPL metrics on the REVERIE benchmark. The source code is available at https://github.com/YanyuanQiao/MiC 1.

Introduction
Vision-and-Language Navigation (VLN), which lies at the intersection of computer vision, natural language pro-cessing and robotics, has aroused great attention from re-search communities in the past few years. Given instruc-tions in natural language, the VLN agent should navigate to the target location based on the dynamic observations in the 3D simulated environments. Since VLN has great
*Corresponding author
REVERIE Instruction: 
Clean the small picture in front of the large mirror.
The target object is: ____
A small picture
I am in hallway, I can see sofa, table,…
What should I do?
Walk through the hallway
LLM
LLM
Figure 1: Our March-in-Chat (MiC) model is talking to a
Large Language Model (LLM) to generate navigation plans on the ﬂy, with the REVERIE instruction and the dynamic room-and-object information as inputs. potential in real-world applications such as domestic as-sistant robots, a large amount of speciﬁc VLN tasks have been proposed, including R2R [4] and RxR [21] that ask the agent to navigate from one room to another in a photo-realistic environment according to the ﬁne-grained instruc-tion, NDH [36] provides detailed dialogues which imply the instruction, TouchDown [7] extends the task into an outdoor environment, REVERIE [27] and SOON [39] that addition-ally require the agent’s ability of remote object grounding and ALFRED [33] that asks the agent to interact with the target object in a single room of the synthetic environment.
Most of these VLN tasks provide detailed step-by-step instructions to the agent, such as “Go up the stairs and then walk the length of the couch. Walk past the dining area and into the kitchen. Stop in front of the refrigerator.” in
R2R. Although detailed instructions can help the agent bet-ter achieve the navigation goal in the simulated environ-ments, it has a big gap towards real applications where hu-man beings tend to give coarse-grained high-level instruc-tions such as “Go to the refrigerator on the second ﬂoor”.
Contrary to other tasks, the Remote Embodied Referring
Expression (REVERIE) task is more likely to empower the real-world applications of VLN, of which the instructions are closer to those in practice, such as “Empty the wash-ing machine on level one”. Such high-level instruction is more challenging for VLN agents since it requires them to be more competent in perceiving the surrounding environ-ment and the navigation progress and correspondingly mak-ing reasonable plans for the next steps.
Recently, Large Language Models (LLMs) that internal-ize a wealth of commonsense knowledge show great po-tential in action planning for some embodied tasks with the help of suitable in-context learning. However, previous works mainly utilize LLMs to plan atomic actions of object manipulation in a very limited space with simple scenes.
These predeﬁned atomic actions can be easily planned well by the LLMs planners with a uniﬁed template. Different from these embodied tasks, REVERIE requires large-area exploration from one room to another, which is complex in the layout of rooms and scenes with diverse objects.
In this work, to adapt LLMs as the planner for REVERIE with the ability of comprehensive scene perception, we pro-pose a novel model named March in Chat (MiC), which enables the LLM as an environment-aware instruction plan-ner through on-the-ﬂy dialogues between the agent and the
LLM as Fig. 1 shows. Speciﬁcally, the agent is initially situated at the starting position given a high-level coarse-grained REVERIE instruction. First, a Goal-Oriented Static
Planning (GOSP) module queries the LLM to point out the target object and infer where the thing may be by us-ing the rich world knowledge internalized in the LLM.
Secondly, the agent’s Room-and-Object Aware Scene Per-ceiver (ROASP) describes the current observation and asks the LLM to generate step-by-step ﬁne-grained planning for the next navigation steps. Then, if the ROASP ﬁnds the room has changed, the LLM is queried again by the Scene-Oriented Dynamic Planning (SODP) module to generate a new ﬁne-grained step-by-step planning, which will be con-catenated with all previous responses from the LLM. The agent will march under the guidance of such interactive prompting until the task is ﬁnished.
To evaluate our proposed MiC, we conduct experiments on the REVERIE benchmark. Our MiC achieves a new state-of-the-art performance in all metrics on REVERIE val unseen set and REVERIE test unseen set. Mainly, MiC ob-tains 41.97% on the primary navigation metric of SPL and 26.17% on the major object grounding metric of RGSPL on test split, which is at least 3.09% and 3.49% higher than the previous SoTA results. We also conduct ablation studies to validate the contributions of different components in MiC and the effect of scene-aware perception in dynamic plan-ning generation. These promising results demonstrate the effectiveness of our proposed MiC.
In summary, we make the following contributions:
• We propose a novel March-in-Chat (MiC) model, which lets the REVERIE agent talk with an LLM on the ﬂy to make plans for the next few steps.
• Two planning modules, namely Goal-Oriented Static
Planning (GOSP) module, and Scene-Oriented Dy-namic Planning (SODP) module, and one Room-and-Object Aware Scene Perceiver (ROASP) module, are proposed.
• Extensive quantitative and qualitative experiments are conducted on REVERIE to validate the effectiveness of our method. 2.