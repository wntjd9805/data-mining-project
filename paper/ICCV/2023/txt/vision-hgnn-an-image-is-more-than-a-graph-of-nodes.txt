Abstract
The realm of graph-based modeling has proven its adaptability across diverse real-world data types. How-ever, its applicability to general computer vision tasks had been limited until the introduction of the Vision Graph Neu-ral Network (ViG). ViG divides input images into patches, conceptualized as nodes, constructing a graph through con-nections to nearest neighbors. Nonetheless, this method of graph construction confines itself to simple pairwise rela-tionships, leading to surplus edges and unwarranted mem-ory and computation expenses. In this paper, we enhance
ViG by transcending conventional “pairwise” linkages and harnessing the power of the hypergraph to encapsulate im-age information. Our objective is to encompass more in-tricate inter-patch associations.
In both training and in-ference phases, we adeptly establish and update the hy-pergraph structure using the Fuzzy C-Means method, en-suring minimal computational burden. This augmentation yields the Vision HyperGraph Neural Network (ViHGNN).
The model’s efficacy is empirically substantiated through its state-of-the-art performance on both image classifica-tion and object detection tasks, courtesy of the hypergraph structure learning module that uncovers higher-order rela-tionships. Our code is available at: https://github. com/VITA-Group/ViHGNN. 1.

Introduction
The rapid strides made in deep learning have ushered in remarkable successes across diverse computer vision models. These encompass Convolutional Neural Networks (CNNs)[35, 33, 22], Vision Transformers (ViTs)[11, 2], and
MLP-based vision models [54, 55]. In these networks, input images find representation either as a regular grid of pixels in the Euclidean space or as sequences of patches.
Nonetheless, the potential for more versatile image pro-cessing through a graph structure remains untapped. A recent development, ViG [18], has ingeniously harnessed
Graph Neural Networks (GNNs) for substantial advance-Figure 1. The illustration of image topologies modeled in differ-ence visual backbones. (a) CNNs treat images as regular grids, (b)
ViT parses images as full-connected graphs, (c) ViGs process im-ages as sparse graphs with pairwise edges, while (d) our ViHGNN models images as a hypergraph, a “more universal” structure. ments in large-scale visual tasks. To mitigate excessive node proliferation, ViG borrows the partitioning concept from ViT, segmenting the image into smaller patches and designating each patch as a node. Consequently, the ViG framework forges connections between nodes and their closest neighbors, constructing an adaptable graph. Fur-thermore, the graph itself emerges as a generalized data structure, encompassing grids and sequences as distinct in-stances within its broader graph context.
While the success of ViG has effectively showcased the advantages of treating an image as a graph in terms of en-hancing flexibility and effectiveness in visual perception, there exist limitations to using a graph as the optimal data structure for image representation. These limitations are rooted in two primary reasons:
• Complexity of Relationships: A fundamental con-straint of a simple graph lies in its ability to exclu-sively connect two nodes, thereby solely accommo-dating pairwise relationships. This inadequacy is ev-ident when it comes to modeling high-order relations inherent in images. Consider the task of object recog-nition in computer vision, where an image is typically divided into patches, each representing a segment of the object. This division introduces intricate inter- and intra-object dependencies that a straightforward graph struggles to capture. This complexity arises from the interplay of patches belonging to the same or distinct objects. Consequently, a conventional graph structure
finds it challenging to effectively model such multi-faceted relationships between patches.
• Redundancy in Edge Generation: Another drawback tied to simple graph representations pertains to the generation of redundant edges during image portrayal.
ViG constructs its graph by identifying the nearest neighbors for each patch node and subsequently form-ing edges between these node pairs. During this pro-cess, all image patches are transformed into feature vectors, and feature distances are computed to de-termine nearest neighbors. This approach becomes problematic when considering that an object within an image is often an amalgamation of multiple patches, yielding similar feature vectors for patches belong-ing to the same object. Consequently, the graph con-struction method can inadvertently give rise to extra-neous edges. In a worst-case scenario, an image with n patches could potentially generate n2 edges, leading to quadratic complexity.
The aforementioned considerations underscore the lim-itations inherent in relying on a simple graph as the fun-damental data structure for image representation. Conse-quently, it is imperative to explore alternative methodolo-gies that effectively address these concerns, thus enhanc-ing the refinement of visual perception models. In light of this, we propose a robust evolution of ViG, where the hy-pergraph assumes the role of image representation. This innovative framework, named Vision HyperGraph Neural
Network (ViHGNN), introduces a dynamic approach to im-age representation. Specifically, a hypergraph serves as a generalized extension of a graph, characterized by a collec-tion of nodes and hyperedges. In contrast to the pairwise connections in a simple graph, hyperedges within a hyper-graph can link any number of nodes. Essentially, a graph can be viewed as a specialized form of a hypergraph, only accounting for pairwise connections between data points.
Distinctively, hypergraphs exhibit superior aptitude in cap-turing the intricate correlations existing within images, tran-scending the limitations of pairwise relations. For tangible illustrations, please refer to Figure 1.
However, a fundamental challenge persists: determin-ing the optimal hypergraph structure for image represen-tation. This encapsulates a compelling “chicken-and-egg” quandary: the aspiration to utilize the hypergraph for im-age representation juxtaposed with the absence of a read-ily available hypergraph structure. Inspired by ViG’s graph construction approach, we start by utilizing the patch fea-tures to construct the initial hypergraph. Subsequently, patch embeddings are generated by the initial hypergraph structure, and then these embeddings are harnessed for the construction of a renewed hypergraph structure. Crucially, both the patch embeddings and the hypergraph structure un-dergo dynamic updates, culminating in a self-reinforcing
“feedback loop” of learning processes.
In our ViHGNN framework, we choose the Fuzzy C-Means (see Sec. 3.3.) to construct and update the hypergraph structure, incurring negligible computational overhead. Our contributions are summarized as follows:
• We advance beyond the ViG framework by introduc-ing a novel paradigm termed ViHGNN, which inter-prets an image as a dynamic hypergraph. Unlike ViG,
ViHGNN not only captures higher-order relationships within images but also mitigates redundant memory and computational expenses linked to graph structures.
• To establish a robust hypergraph representation for im-ages, we seamlessly integrate an adaptive hypergraph structure learning module within the framework, en-hancing representation with little incurring overhead.
This hypergraphical portrayal of images yields dis-cernible advantages for downstream visual tasks.
• We execute comprehensive experiments to underscore the efficacy of the ViHGNN model across visual tasks, including image classification and object detection.
Specifically, our ViHGNN model achieves a top-1 ac-curacy of 83.9% in the ImageNet classification task and an impressive 43.1% Average Precision (AP) in the COCO object detection task. 2.