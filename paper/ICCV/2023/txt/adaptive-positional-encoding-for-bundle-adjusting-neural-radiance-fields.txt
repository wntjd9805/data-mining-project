Abstract
Neural Radiance Fields have shown great potential to synthesize novel views with only a few discrete image ob-servations of the world. However, the requirement of ac-curate camera parameters to learn scene representations
In this paper, we present limits its further application. adaptive positional encoding (APE) for bundle-adjusting neural radiance fields to reconstruct the neural radiance fields from unknown camera poses (or even intrinsics). In-spired by Fourier series regression, we investigate its re-lationship with the positional encoding method and there-fore propose APE where all frequency bands are trainable.
Furthermore, we introduce period-activated multilayer per-ceptrons (PMLPs) to construct the implicit network for the high-order scene representations and fine-grained gradi-ents during backpropagation. Experimental results on pub-lic datasets demonstrate that the proposed method with APE and PMLPs can outperform the state-of-the-art methods in accurate camera poses and high-fidelity view synthesis. 1.

Introduction
Simultaneously localizing from the given camera frames and reconstructing the scene from multi-view 2D images is one of the crucial tasks in computer vision, which can carry out self-localization as well as sense surroundings through visual information as human beings do. Most classic meth-ods, such as Structure from Motion (SfM) [35, 1] and Si-multaneously Localization and Mapping (SLAM) [30, 10, 11], leverage the similarity of texture patterns to find the correspondences. Then, all states are estimated, including camera parameters (intrinsic and extrinsic parameters) and a map in conventional representations (e.g., sparse 3D point cloud [17]). However, the quality of the created map repre-sentations depends on the correspondences, and the sparse
*Corresponding author
Figure 1. Fourier Series Regression. Fitting 1D signal (blue curve, duration T , period Tb) requires a Fourier series with proper frequencies (bottom, green curve). Conversely, Fourier series re-gression with improper frequencies (top, red curve) cannot fit well. nature of common 3D point clouds limits downstream vi-sion tasks that require dense geometric reasoning.
Different from explicitly reconstructing scenes from im-ages, Neural Radiance Fields (NeRF) [28] present a contin-uous function to parameterize the scene through an implicit neural network [38, 25] mapping 3D point positions and di-rection to color and volume density. By volume rendering theorem [43, 19], NeRF can realize high-fidelity dense rep-resentation results with a few observed images of the scene.
Although many follow-up works [2, 15, 26, 18, 32, 47, 49] have improved the performance of NeRF in various aspects, most require pre-provided accurate camera parameters, typ-ically obtained through off-the-shelf SfM tools, limiting this technique to realize simultaneous localization and recon-struction in more practice scenarios.
There are some methods [6, 22, 40] jointly optimizing implicit network parameters, camera poses (extrinsic pa-rameters), and even camera intrinsic parameters to address the solution of training radiance field representations with-out accurate camera parameters. They additionally optimize the camera parameters with frequency encoding via back-propagation of the NeRF model [45]. However, the second-order derivatives of ReLU-activated MLPs, which make up classic NeRF, are zero and thus incapable of modeling the fine-grained information contained in higher-order deriva-tives of radiance fields [37]. Therefore, it is difficult for
ReLU-activated MLPs to derive more fine-grained gradient information to update camera parameters.
It should be noted that positional encoding (PE) [41] plays a critical role in neural radiance field methods. PE can embed the input (spatial position and direction in
NeRF) in a high-dimensional frequency space, similar to the Fourier transform. However, since the information of different scenes is distributed in different frequencies, dif-ferent scenes require different Fourier series to better fit.
Therefore, PE in most methods with fixed handcraft fre-quency parameters limits the performance of joint optimiza-tion, and the frequency parameters of PE should be adaptive to the scene and also optimized during simultaneous local-ization and radiance field reconstruction.
In this paper, we address the problem of training neu-ral radiance fields from unknown camera parameters (in-trinsic and extrinsic) — the joint problem of reconstruct-ing the 3D scene, registering the camera poses (extrinsics), and updating the camera intrinsics. We propose adaptive positional encoding (APE) for bundle-adjusting neural ra-diance fields that can simultaneously optimize implicit net-work parameters and camera parameters. Inspired by the
Fourier series, which shows that regression with proper fre-quency parameters can produce better performance in fit-ting the reference curve, as shown in Fig. 1, we propose
APE that can better fit the distribution of radiance informa-tion in the field. After encoding the input, period-activated multilayer perceptrons (PMLPs) are introduced to implic-itly reconstruct the scene since PMLPs can represent com-plex higher-order information hidden in nature signals [31] and can yield more effective and fine-grained gradients for updating camera and APE parameters. In the training step, in addition to the photometric loss, a frequency diversity loss function is designed for APE, preventing the adaptive frequency parameters from converging to a single band and thereby losing fine representation ability. In experiments, the proposed method is compared to state-of-the-art meth-ods to prove that the proposed method can learn the higher-order representation of neural radiance fields and estimate camera parameters. Finally, a comprehensive ablation study is carried out to show the effectiveness of APE and PMLPs.
The main contributions of this work are as follows:
• We propose adaptive positional encoding for bundle-adjusting neural radiance fields that can jointly recon-struct the 3D scene, register the camera poses, and up-date the camera intrinsics.
• We propose adaptive positional encoding that can adaptively fit radiance fields with proper frequency pa-rameters to realize a high-synthesis quality.
• We reconstruct the radiance fields using adaptive po-sitional encoding and period-activated multilayer per-ceptrons, that can represent complex scenes and pro-vide more fine-grained gradients for updating APE and camera parameters. 2.