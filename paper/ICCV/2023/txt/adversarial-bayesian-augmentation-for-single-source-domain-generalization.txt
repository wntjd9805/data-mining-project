Abstract
Generalizing to unseen image domains is a challenging problem primarily due to the lack of diverse training data, inaccessible target data, and the large domain shift that may exist in many real-world settings. As such data augmenta-tion is a critical component of domain generalization meth-ods that seek to address this problem. We present Adversar-ial Bayesian Augmentation (ABA), a novel algorithm that learns to generate image augmentations in the challenging single-source domain generalization setting. ABA draws on the strengths of adversarial learning and Bayesian neural networks to guide the generation of diverse data augmen-tations – these synthesized image domains aid the classi-fier in generalizing to unseen domains. We demonstrate the strength of ABA on several types of domain shift includ-ing style shift, subpopulation shift, and shift in the medi-cal imaging setting. ABA outperforms all previous state-of-the-art methods, including pre-specified augmentations, pixel-based and convolutional-based augmentations. Code: https://github.com/shengcheng/ABA. 1.

Introduction
Improving the generalization of deep neural networks to out-of-distribution samples is a fundamental yet chal-lenging problem in machine learning and computer vi-sion [48, 25, 34]. Typically, neural networks are trained and tested on data samples from the same distribution (under the i.i.d. assumption); under this setting, image classifiers have achieved impressive performances. However, in real-world applications, the distribution of test samples can drastically differ from the training samples [47, 37]. This is especially problematic when the process of acquiring labeled samples from the target test domain is expensive or infeasible, mak-ing it difficult to apply semi-supervised learning for domain adaptation [55, 53]. Therefore, there is a need to develop techniques that enable deep neural networks to capture the domain-invariant patterns in the data [34, 51], facilitating improved generalization to out-of-distribution samples.
In the multi-source domain generalization (MSDG) set-Figure 1: An illustration of the diversity introduced by Ad-versial Bayesian Augmentations. The blue and orange sur-faces represent the source (seen) and target (unseen) do-mains respectively. The red dots represent the samples aug-mented by ABA; these augmentations expose the classifier to regions closer to the target domain, thereby improving image classifiers’ generalization to unseen domains. ting, where there are multiple source domains for training, domain label information can be leveraged to learn the do-main shift [34, 7, 51]. Prior information about the target domain is also useful to design specific data augmenta-tion methods to tackle domain shift. For instance, if it is known that the target domain contains sketches, skeletoniz-ing the source images is a good solution [13]; if it is known that the target domain contains geometric transformations, rotation/translation/scaling would be a suitable augmenta-tion [21]; or if attributes of the target domain are known they can be used for learning data augmentations [14]. How-ever, these methods assume that we know the properties of the target domain – such knowledge is not available in the single-source domain generalization (SSDG) setting. In the
SSDG setting, where only one domain is available for train-ing, it is more challenging to address the domain shift issue.
In this paper, we focus on the strict SSDG setting, where only one source domain is available for training and no prior knowledge is available about the target domain.
Recent work in SSDG focuses on augmenting the data in order to simulate the presence of out-of-distribution do-Figure 2: The Adversarial Bayesian Augmentation framework (left panel), the improvement of our method (ABA5-layers) over
ERM on each dataset, where samples in source and target domain are displayed under the name of the dataset (middle panel), and summarization of results on a wide range of domain generalization benchmarks (right panel). mains. One way involves learning-free data augmentation methods, such as RandConv [52], Augmix [19] and Ji-Gen [3] – here the data augmentation is pre-specified and does not evolve or adapt during training. Another approach is based on adversarial perturbations, which involves gen-erating adversarial samples to improve generalization, such as Augmax [49], ADA [47], M-ADA [39], and ALT [15].
Although the Bayesian neural networks as the backbone of the classifier show good generalization ability to out-of-distribution samples intrinsically [30, 51, 4], and some papers [40] use Bayesian neural networks for generating images, none of the work directly augments the data by
Bayesian neural network for domain generalization.
In this paper, we present a novel approach called Adver-sarial Bayesian Augmentation, dubbed ABA, which draws on the strengths of adversarial learning and Bayesian neu-ral networks to generate more diverse data and improve generalization on different domains, as shown in Figure 2.
Specifically, the adversarial learning-based methods, which explore a wider augmentation space, already outperforms learning-free methods [15, 49] on SSDG. The introduction of weight uncertainty by the Bayesian neural network fur-ther enhances the strength of data augmentation, as shown in Figure 1. Our experimental results demonstrate the supe-rior performance of ABA compared to existing methods.
The key contributions and findings of the paper thus are:
• We introduce a novel data augmentation method, dubbed
ABA, which combines adversarial learning and Bayesian neural network, to improve the diversity of training data for single-source domain generalization setting.
• We empirically validate the effectiveness of our proposed method on four datasets, covering three types of domain generalization, namely style generalization, subpopula-tion generalization, and medical imaging generalization.
Our method outperforms all existing state-of-art methods on all four datasets.
• We investigate the core driving forces from ABA which enable the generation of diverse data and conduct compre-hensive ablation study on how the model hyperparameters impact the overall system’s performance. 2.