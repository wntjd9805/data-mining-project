Abstract
Facial sketch synthesis (FSS) aims to generate a vivid sketch portrait from a given facial photo. Existing FSS methods merely rely on 2D representations of facial seman-tic or appearance. However, professional human artists usually use outlines or shadings to covey 3D geometry.
Thus facial 3D geometry (e.g. depth map) is extremely im-portant for FSS. Besides, different artists may use diverse drawing techniques and create multiple styles of sketches; but the style is globally consistent in a sketch.
Inspired by such observations, in this paper, we propose a novel
Human-Inspired Dynamic Adaptation (HIDA) method. Spe-cially, we propose to dynamically modulate neuron acti-vations based on a joint consideration of both facial 3D geometry and 2D appearance, as well as globally consis-tent style control. Besides, we use deformable convolutions at coarse-scales to align deep features, for generating ab-stract and distinct outlines. Experiments show that HIDA can generate high-quality sketches in multiple styles, and significantly outperforms previous methods, over a large range of challenging faces. Besides, HIDA allows pre-cise style control of the synthesized sketch, and general-izes well to natural scenes and other artistic styles. Our code and results have been released online at: https:
//github.com/AiArt-HDU/HIDA. 1.

Introduction
Making computers create arts like human beings, is a longstanding and challenging topic, in the artificial intel-ligence (AI) area [2]. To this end, researchers have made great efforts and proposed numerous methods, such as neu-ral style transfer (NST) [17] and image-to-image translation (I2IT) [18, 46]. These methods mainly tackle cluttered im-age styles, such as oil paintings [17]. In this paper, we are interested in creating artistic sketches from facial photos, which is referred to as face sketch synthesis (FSS) [34].
For now, there has been significant progress in FSS
* Corresponding Author
Figure 1: Illustration of facial photos, depth maps, multi-style facial sketches drawn by human artists [8], and the corresponding results synthesized by our method.
[43],
Specially, semi-supervised learning [5], inspired by the excellent success of Generative Adver-researchers sarial Networks (GANs) [18]. have proposed various techniques, including embedding image prior self-attention/transformer based methods [11, 47, 9], hierarchi-cal GANs [28, 40, 8], composition assistance [37], and se-mantic adaptive normalization [21], to boost the quality of synthesized sketches. However, all these methods merely use 2D appearance or semantic representations of the input photo. They may fail to handle serious variations in appear-ance, such as the pose, lighting, expression, and skin color.
To tackle this challenge, we propose a novel method, in-spired by how human artists draw a sketch. We observe that facial 3D geometry plays a significant role in human artists’ drawing process. Besides, a professional human artist con-siders comprehensive information, including facial 3D ge-ometry, 2D appearance, and the artistic style, to execute a sketch portrait. We summarize the drawing methodologies of human artists [22] into the following four folds:
• Local 3D geometry conveyor: First, artists typically use abstract and deformable outlines to characterize major geometry, and use different shading methodolo-gies, e.g. hatching, blending, and stippling, to convey local 3D structures [3].
• Local 2D appearance representation: Second, artists may use different shading or tonal techniques to repre-sent local 2D facial appearance, so as to depict varia-tions in lighting, color, texture, etc.
• Sketches in diverse styles: Third, different artists may use diverse drawing methods and create multiple styles of sketches. In other words, they may use divergent textures to represent the same facial area. Fig. 1 shows three styles of sketches drawn by artists [8]. Obvi-ously, Style1 is extremely abstract and mainly contains sketchy outlines. In contrast, Style3 depicts facial 3D geometry with a lot of shading textures.
• Globally consistent style: Finally, the style of pencil-drawing is usually consistent in a single sketch. As shown in Fig. 1, although there are distinct inter-style divergences, the style of pencil-drawing is globally consistent across different regions inside each sketch.
Inspired by these observations, we seek to guide the syn-thesis of sketch portraits by using comprehensive informa-tion, including facial 3D geometry and 2D appearance, as well as global style control. In the implementation, given a facial photo, we use the depth map to represent its 3D ge-ometry, and use the encoding features to represent its 2D appearance. Afterwards, we combine them with a style map to dynamically modulate deep features for generating a sketch. Inspired by the success of SPADE [27] in style control [41] and the local flexibility of dynamic neural net-works [14], we propose to dynamically modulate neuron activations, based on a joint consideration of all these in-formation. Such modulation is conducted though both dy-namic normalization and activation. Specially, we propose a novel dynamic activation function, termed Informative
ACON (InfoACON), and a dynamic normalization module, termed DySPADE. In addition, we use deformable convo-lutions [7] to align deep features [16] at coarse scales for generating abstract and distinct sketchy outlines. Initially, the dynamic adaptation and deformation simulate the flexi-bility and abstract process of human artists during drawing.
Based on the above mentioned contributions, we build a Human-Inspired Dynamic Adaptation (HIDA) method for FSS. We conduct experiments on several challenging datasets, including the FS2K [8], the FFHQ [20], and a col-lection of faces in-the-wild. Our method outperforms state-of-the-art (SOTA) methods both qualitatively and quantita-tively. Besides, our method allows precise style control and can produce high-quality sketches in multiple styles. Even for faces with serious variations, the synthesized sketches present realistic textures and preserve facial geometric de-tails. In addition, extensive ablation studies demonstrate the effectiveness of the proposed dynamic and adaptive modu-lation techniques. Finally, our model, although trained for faces, can generate high-quality sketches for natural scenes. 2.