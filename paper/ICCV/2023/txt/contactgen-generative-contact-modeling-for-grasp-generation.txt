Abstract
This paper presents a novel object-centric contact rep-resentation ContactGen for hand-object interaction. The
ContactGen comprises 3 components: a contact map indi-cates the contact location, a part map represents the contact hand part, and a direction map tells the contact direction within each part. Given an input object, we propose a con-ditional generative model to predict ContactGen and adopt model-based optimization to predict diverse and geomet-rically feasible grasps. Experimental results demonstrate our method can generate high-fidelity and diverse human grasps for various objects. 1.

Introduction
Modeling hand-object interaction [2, 9, 14, 21, 30, 37, 45, 57,67] has gained substantial importance across various do-†Work started at an internship at Adobe Research.
*Equal advising, alphabetic order mains in animation, games, and augmented and virtual real-ity [23, 26, 62, 64]. For instance, given an object, one would like to create a computational model to reason about the dif-ferent ways a human hand can interact with it, e.g., how to grasp the object using a single hand. To ensure realism and authenticity in these interactions, a precise understanding of contacts is crucial [5–7]. A thorough contact modeling should account for factors such as which regions of the ob-ject are likely to make contact, which parts of the hand will touch the object, the strength of the contact force, and the direction of the contact, among others. In contrast, the lack of thorough and precise modeling can result in unnatural and unrealistic interactions, such as insufficient contact or excessive penetration.
Previous approaches often rely on a contact map [17, 25, 27, 44, 56] applied to object point clouds, where values are bounded within the [0, 1] range to indicate the status of point contacts. Nevertheless, simply modeling contact maps does not fully capture the details of contact. Specifically, even with the contact map, ambiguities remain regarding which
regions of the hand are in contact and the manner of contact.
Moreover, a single contact map falls short of representing the structured uncertainty inherent in hand-object interac-tions.
In this paper, we address the aforementioned challenges by introducing a novel contact representation called Con-tactGen. ContactGen provides a comprehensive presenta-tion that encodes the specific contact parts of both the object and hand, along with the precise touch direction. Specif-ically, for each point on the object’s surface, ContactGen models: (1) the contact region on the object’s surface, rep-resented as a contact probability; (2) the specific part of the hand making contact, be it various fingertip regions or the palm, in the form of a categorical probability; and (3) the orientation of the touch with respect to the hand part mak-ing contact, represented as a spherical coordinate. Fig. 1 depicts the three components of the presented ContactGen.
Our approach significantly expands the traditional contact map, offering a precise and unambiguous representation of hand-object interactions.
Next, we introduce a novel, generative method that learns to produce diverse yet realistic ContactGen for any given object during inference. To account for uncertain-ties, we implement a hierarchical conditional Variational
Autoencoder (CVAE) [54]. This CVAE sequentially mod-els the contact map, the hand part map, and the contact co-ordinate. When provided with a 3D object as a conditional input, our CVAE initially models the probabilities of con-tact maps. From this, one can sample contact maps, using these samples as additional conditioning variables, to infer the distribution of the hand part map and sample from the distribution. Lastly, direction maps can be generated based on the sampled contact map and hand part map. This se-quential generation strategy separates variations within the entire space into distinct components, ensuring explicit un-certainty modeling for each component.
The proposed ContactGen is applied to human grasp synthesis [28,34,35,46], whose objective is to generate a di-verse physically plausible human grasps for various objects.
In contrast to existing work [10, 27, 29, 30, 56], which pri-marily addresses grasp uncertainty within the hand space, our key innovation lies in addressing this uncertainty within the object space. We achieve this by designing a novel con-tact solver that effectively derives hand grasp poses from
ContactGen. The ContactGen is sampled from our CVAE model and linked to the specific object. As a result, our de-sign yields more realistic and organic hand grasps, as shown by improved contact, diminished penetration, and increased stability. Additionally, the hierarchical contact modeling fosters greater diversity in the generated grasps. Our exper-iments validate the efficacy of our method in ensuring both diversity and fidelity in hand-object interactions, surpassing the performance of current state-of-the-art techniques.
Method
Hand Model
Contact Modeling
Object-centric
Grasping Field [30]
GraspTTA [27]
ContactOpt [17]
TOCH [73]
Ours point cloud mesh mesh mesh mesh/sdf location part direction
✓
✗
✗
✓
✓
✓
✓
✓
✓
✓
✗
✗
✗
✗
✓
✗
✗
✗
✓
✓
Table 1: Contact representation comparison between different methods of hand-object interaction. Most existing work adopt con-tact map, which is insufficient to recover the underlying grasp.
In summary, our contributions are as follows:
• We introduce ContactGen, a novel object-centric rep-resentation that concurrently models the contact parts of both the hand and the object, as well as the contact direction relative to each part.
• We propose a sequential CVAE model that learns to grasp the uncertainty inherent in hand-object interac-tions using our contact representation.
• We develop a novel human grasp synthesis algo-rithm, merging our suggested generative modeling with model-based optimization. This combination pro-duces enhanced fidelity and diversity compared to cur-rent methods. 2.