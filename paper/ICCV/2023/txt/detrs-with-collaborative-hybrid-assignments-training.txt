Abstract
In this paper, we provide the observation that too few queries assigned as positive samples in DETR with one-to-one set matching leads to sparse supervision on the en-coder’s output which considerably hurt the discriminative feature learning of the encoder and vice visa for attention learning in the decoder. To alleviate this, we present a novel collaborative hybrid assignments training scheme, namely
Co-DETR, to learn more efficient and effective DETR-based detectors from versatile label assignment manners. This new training scheme can easily enhance the encoder’s learning ability in end-to-end detectors by training the mul-tiple parallel auxiliary heads supervised by one-to-many la-bel assignments such as ATSS and Faster RCNN. In addi-tion, we conduct extra customized positive queries by ex-tracting the positive coordinates from these auxiliary heads to improve the training efficiency of positive samples in the decoder. In inference, these auxiliary heads are discarded and thus our method introduces no additional parameters and computational cost to the original detector while re-quiring no hand-crafted non-maximum suppression (NMS).
We conduct extensive experiments to evaluate the effective-ness of the proposed approach on DETR variants, including
DAB-DETR, Deformable-DETR, and DINO-Deformable-DETR. The state-of-the-art DINO-Deformable-DETR with
Swin-L can be improved from 58.5% to 59.5% AP on COCO val. Surprisingly, incorporated with ViT-L backbone, we achieve 66.0% AP on COCO test-dev and 67.9% AP on
LVIS val, outperforming previous methods by clear mar-gins with much fewer model sizes. Codes are available at https://github.com/Sense-X/Co-DETR. 1.

Introduction
Object detection is a fundamental task in computer vi-sion, which requires us to localize the object and classify its category. The seminal R-CNN families [11, 27, 14] and
*Corresponding author.
Figure 1: Co-DETR outperforms other methods with the same ResNet-50 backbone by large margins on COCO val. a series of variants [30, 43, 36] such as ATSS [40], Reti-naNet [21], FCOS [31], and PAA [17] lead to the significant breakthrough of object detection task. One-to-many label assignment is the core scheme of them, where each ground-truth box is assigned to multiple coordinates in the detec-tor’s output as the supervised target cooperated with propos-als [11, 27], anchors [21] or window centers [31]. Despite their promising performance, these detectors heavily rely on many hand-designed components like a non-maximum suppression procedure or anchor generation [1]. To con-duct a more flexible end-to-end detector, DEtection TRans-former (DETR) [1] is proposed to view the object detection as a set prediction problem and introduce the one-to-one set matching scheme based on a transformer encoder-decoder architecture.
In this manner, each ground-truth box will only be assigned to one specific query, and multiple hand-designed components that encode prior knowledge are no longer needed. This approach introduces a flexible detec-tion pipeline and encourages many DETR variants to fur-ther improve it. However, the performance of the vanilla end-to-end object detector is still inferior to the traditional detectors with one-to-many label assignments.
Figure 2: IoF-IoB curves for the feature discriminability score in the encoder and attention discriminability score in the decoder.
In this paper, we try to make DETR-based detectors superior to conventional detectors while maintaining their end-to-end merit. To address this challenge, we focus on the intuitive drawback of one-to-one set matching that it ex-plores less positive queries. This will lead to severe ineffi-cient training issues. We detailedly analyze this from two aspects, the latent representation generated by the encoder and the attention learning in the decoder. We first compare the discriminability score of the latent features between the
Deformable-DETR [42] and the one-to-many label assign-ment method where we simply replace the decoder with the ATSS head. The feature l2-norm in each spatial co-ordinate is utilized to represent the discriminability score.
Given the encoder’s output F ∈ RC×H×W , we can obtain the discriminability score map S ∈ R1×H×W . The object can be better detected when the scores in the correspond-ing area are higher. As shown in Figure 2, we demonstrate the IoF-IoB curve (IoF: intersection over foreground, IoB: intersection over background) by applying different thresh-olds on the discriminability scores (details in Section 3.4).
The higher IoF-IoB curve in ATSS indicates that it’s eas-ier to distinguish the foreground and background. We fur-ther visualize the discriminability score map S in Figure 3.
It’s obvious that the features in some salient areas are fully activated in the one-to-many label assignment method but less explored in one-to-one set matching. For the explo-ration of decoder training, we also demonstrate the IoF-IoB curve of the cross-attention score in the decoder based on the Deformable-DETR and the Group-DETR [5] which in-troduces more positive queries into the decoder. The il-lustration in Figure 2 shows that too few positive queries also influence attention learning and increasing more posi-tive queries in the decoder can slightly alleviate this.
This significant observation motivates us to present a simple but effective method, a collaborative hybrid assign-ment training scheme (Co-DETR). The key insight of Co-DETR is to use versatile one-to-many label assignments to improve the training efficiency and effectiveness of both the encoder and decoder. More specifically, we integrate the auxiliary heads with the output of the transformer encoder.
These heads can be supervised by versatile one-to-many la-bel assignments such as ATSS [40], FCOS [31], and Faster
Figure 3: Visualizations of discriminability scores in the encoder.
RCNN [27]. Different label assignments enrich the super-visions on the encoder’s output which forces it to be dis-criminative enough to support the training convergence of these heads. To further improve the training efficiency of the decoder, we elaborately encode the coordinates of posi-tive samples in these auxiliary heads, including the positive anchors and positive proposals. They are sent to the origi-nal decoder as multiple groups of positive queries to predict the pre-assigned categories and bounding boxes. Positive coordinates in each auxiliary head serve as an independent group that is isolated from the other groups. Versatile one-to-many label assignments can introduce lavish (positive query, ground-truth) pairs to improve the decoder’s train-ing efficiency. Note that, only the original decoder is used during inference, thus the proposed training scheme only introduces extra overheads during training.
We conduct extensive experiments to evaluate the effi-ciency and effectiveness of the proposed method.
Illus-trated in Figure 3, Co-DETR greatly alleviates the poorly encoder’s feature learning in one-to-one set matching. As a plug-and-play approach, we easily combine it with different
DETR variants, including DAB-DETR [23], Deformable-DETR [42], and DINO-Deformable-DETR [38]. As shown in Figure 1, Co-DETR achieves faster training convergence and even higher performance. Specifically, we improve the basic Deformable-DETR by 5.8% AP in 12-epoch train-ing and 3.2% AP in 36-epoch training. The state-of-the-art DINO-Deformable-DETR with Swin-L [25] can still be improved from 58.5% to 59.5% AP on COCO val.
Surprisingly, incorporated with ViT-L [8] backbone, we achieve 66.0% AP on COCO test-dev and 67.9% AP on LVIS val, establishing the new state-of-the-art detector with much fewer model sizes. 2.