Abstract
Input attribution is a widely used explanation method for deep neural networks, especially in visual tasks. Among various attribution methods, Integrated Gradients (IG) [28] is frequently used because of its model-agnostic applicabil-ity and desirable axioms. However, previous work [24, 8, 9] has shown that such method often produces noisy and un-reliable attributions during the integration of the gradients over the path defined in the input space. In this paper, we tackle this issue by estimating the distribution of the possi-ble attributions according to the integrating path selection.
We show that such noisy attribution can be reduced by ag-gregating attributions from the multiple paths instead of us-ing a single path. Inspired by Stick-Breaking Process [20], we suggest a random process to generate rich and various sampling of the gradient integrating path. Using multiple input attributions obtained from randomized path, we pro-pose a novel attribution measure using the distribution of attributions at each input features. We identify proposed method qualitatively show less-noisy and object-aligned at-tribution and its feasibility through the quantitative evalua-tions. 1.

Introduction
Along with the steep improvement and the real world application of the deep learning models [4, 31], discover-ing the evidence of the black-box model decision is consid-ered to be important for debugging the malfunction [12] and promise the safety and the fairness [5] of the models. Within the vast literature of explaining the decision of the deep models, input attribution [22, 2, 21, 28] is one of widely used methods to quantify the relative contribution of each features to the model output. Input attribution provides the explanation in the form of heatmaps, which is useful to indi-cate the spatial existence of evidences, especially in visual tasks.
*work done while in UNIST
†corresponding author
Among various approaches to compute the input attribu-tions, Integrated Gradient (IG), one of widely used methods, and its variants [28, 15, 9] are of particular interest in our work. These methods explore the input space along the pre-defined path and integrate the gradients to provide the reli-able attributions. The integration path of such methods con-sists of a baseline which represents the missingness of fea-tures and a connecting line between the input and the base-line. With different desired properties, various paths can be used to compute the attribution. For example, Guided
IG [9] proposes the adaptive path to alleviate the high and noisy gradients unrelated to the prediction. The selection of baseline can also affect to the attribution results [27].
While the above methods address the importance of se-lecting appropriate integration path, in this paper, we claim that the single path is not reliable enough to interpret the decision of neural networks. We provide a simple example that the attribution computed by a single path provides high variance according to different path selection. For better re-liability, we propose a novel attribution method to take the expectation of the path-integrated attribution over the dis-tribution of possible paths. To sample from the distribution over the vast variety of possible paths, we adopt the no-tion of Stick-Breaking Process, which is one sort of stochas-tic processes that samples the probability distribution. The main contributions of our work are summarized as,
• Address the inconsistency of attribution according to the selection of the integration path, and propose a novel attribution method that takes the expectation over the distribution of random paths to retain the reli-ability of attribution.
• Propose a sampling method to generate a random in-tegration path inspired by the Stick-Breaking Process.
From the proposed method, we can generate the vast integration paths efficiently.
• Evaluate the attribution in qualitative and quantita-tive measure to validate the reliability of the proposed method on various of architecture of the networks.
Figure 1: An illustration of Stick-breaking Path Integration (SPI) for the given input x. Using the realized distribution G from
SBP, we randomly generate the integration path in the input domain by taking CDF of each distribution (colored lines in the left-bottom). From the sampled paths, we apply the gradient integration along each path to gather the multiple attribution samples. By taking the average, the attribution of SPI can be obtained. 2.