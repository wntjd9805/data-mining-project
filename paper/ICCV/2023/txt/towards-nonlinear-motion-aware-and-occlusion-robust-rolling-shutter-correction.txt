Abstract
This paper addresses the problem of rolling shutter cor-rection in complex nonlinear and dynamic scenes with ex-treme occlusion. Existing methods suffer from two main drawbacks. Firstly, they face challenges in estimating the accurate correction field due to the uniform velocity as-sumption, leading to significant image correction errors under complex motion. Secondly, the drastic occlusion in dynamic scenes prevents current solutions from achiev-ing better image quality because of the inherent difficul-ties in aligning and aggregating multiple frames. To tackle these challenges, we model the curvilinear trajectory of pix-els analytically and propose a geometry-based Quadratic
Rolling Shutter (QRS) motion solver, which precisely esti-mates the high-order correction field of individual pixels.
Besides, to reconstruct high-quality occlusion frames in dy-namic scenes, we present a 3D video architecture that effec-tively Aligns and Aggregates multi-frame context, namely,
RSA2-Net. We evaluate our method across a broad range of cameras and video sequences, demonstrating its significant superiority. Specifically, our method surpasses the state-of-the-art by +4.98, +0.77, and +4.33 of PSNR on Carla-RS, Fastec-RS, and BS-RSC datasets, respectively. Code is available at https://github.com/DelinQu/qrsc. 1.

Introduction
The rolling shutter (RS) mechanism widely integrated in consumer video cameras continues to gather photos during the acquisition process, thus effectively increasing sensitiv-ity [10]. The RS cameras donate CMOS sensors and scan the scene sequentially instead of instantly taking a snapshot of the entire scene, like the global shutter (GS) using the
CCD sensor [19]. The time slot between consecutive scan lines causes motion artifacts called the RS effect, e.g., wob-∗ Authors contributed equally: dlqu22@m.fudan.edu.cn
† Corresponding author
Figure 1: Illustration of the challenges in complex nonlinear motion and dynamic scenes with occlusion. The proposed method models the curvilinear trajectory and reconstructs the high-quality occlusion region from adjacent frames of the video stream.
In contrast, the state-of-the-art fails to correct the pole and causes significant unaligned artifacts on the bottom right car. ble and skew, under extreme motion conditions [1]. In ad-dition to the detrimental visual artifacts, the RS effect dam-ages numerous 3D vision algorithms based on GS assump-tions, such as camera pose estimation [1, 4], structure-from-motion [34] and SLAM [20, 17]. Therefore, rolling shutter correction (RSC) is significant in photography and has at-tracted considerable research attention in the last decades.
Existing works on RS correction are generally cate-gorized into single-frame and multi-frame methods. The single-frame methods are based on strict geometric assump-tions [27, 24] or simplified camera motion [26, 15], thus obtaining unsatisfied results in complex scenes. In compar-ison, multi-frame methods are more sensible and achieve higher performance [36]. Typically, the correction field be-tween two frames is estimated by a neural block [28] to re-cover the GS frame [18, 2, 7]. Nevertheless, existing RSC methods cannot produce satisfying results because of the
following limitations: 1) Complex higher-order motion: Current methods based on cost volume [18, 35, 30, 2] face challenges in esti-mating the accurate correction field since the field cannot be effectively supervised during training [2]. Besides, RSC so-lutions depending on optical flow use the uniform velocity assumption [5, 7, 25], ignoring the nonlinear movements.
However, the motion in real scenes can be complex and variable, and the inaccuracy of correction fields will accu-mulate row by row and eventually lead to significant image correction errors e.g., the distorted pole and house corrected by AdaRSC [2] in Fig. 1. 2) Scene occlusion: As shown in Fig. 1, object edge occlusion around the entity and image border occlusion pre-vent RSC solutions from better image synthetic quality. De-spite the most recent multiple frames method [7, 2] trying to compensate for occluded pixels from consecutive frames, the visual performance cannot satisfy the regular applica-tion due to the inherent difficulties in aligning and aggre-gating multiple frames.
To address the challenges, we model the curvilinear tra-jectory of pixels analytically and propose a geometry-based
Quadratic Rolling Shutter (QRS) motion solver, which pre-cisely estimates the high-order correction field of individ-ual pixel based on the forward and backward optical flows.
Benefiting from the rigorous modeling of the RS mecha-nism, the QRS motion solver demonstrates a strong gener-alization performance across various datasets and handles
RS temporal super-resolution tasks [5]. Besides, to recon-struct high-quality occlusion frames in extreme scenes, we present a 3D video architecture which effectively Aligns and Aggregates multi-frame context, namely, RSA2-Net.
Tab. 1 exhibits the superiority of the proposed method, and our contributions can be summarized as follows:
• We analytically model the trajectory in complex non-linear movements and present a novel geometry-based quadratic rolling shutter motion solver that precisely esti-mates the high-order correction field of individual pixels.
• We propose a self-alignment 3D video architecture for high-quality frame aggregation and synthesis against ex-treme scene occlusion.
• A broad range of evaluations demonstrates the signif-icant superiority and generalization ability of our pro-posed method over state-of-the-art methods. 2.