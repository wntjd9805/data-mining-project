Abstract
Point cloud registration is essential in computer vision and robotics. In this paper, a critical observation is made that the invisible parts of each point cloud can be directly utilized as inherent masks, and the aligned point cloud pair can be regarded as the reconstruction target. Motivated by this observation, we rethink the point cloud registra-tion problem as a masking and reconstruction task. To this end, a generic and concise auxiliary training network, the
Masked Reconstruction Auxiliary Network (MRA), is pro-posed. The MRA reconstructs the complete point cloud by separately using the encoded features of each point cloud obtained from the backbone, guiding the contextual features in the backbone to capture fine-grained geometric details and the overall structures of point cloud pairs. Unlike re-cently developed high-performing methods that incorporate specific encoding methods into transformer models, which sacrifice versatility and introduce significant computational complexity during the inference process, our MRA can be easily inserted into other methods to further improve regis-tration accuracy. Additionally, the MRA is detached after training, thereby avoiding extra computational complexity during the inference process. Building upon the MRA, we present a novel transformer-based method, the Masked Re-construction Transformer (MRT), which achieves both pre-cise and efficient alignment using standard transformers.
Extensive experiments conducted on the 3DMatch, Model-Net40, and KITTI datasets demonstrate the superior perfor-mance of our MRT over state-of-the-art methods. Codes are available at https://github.com/CGuangyan-BIT/MRA. 1.

Introduction
Point cloud registration is a fundamental problem in computer vision and robotics that aims to recover an op-*Corresponding author: Yufeng Yue (yueyufeng@bit.edu.cn). This work was supported by the National Natural Science Foundation of China under Grant No. NSFC 62233002, 62003039, 61973034, U1913203, the
National Key RD Program of China (2022ZD0118), the CAST program under Grant No. YESS20200126.
Figure 1. Our MRA considers the invisible parts of each point cloud as inherent masks. During training, the encoded features ob-tained from the backbone, along with mask tokens, are processed by a decoder that separately constructs the complete point cloud.
In this manner, the MRA guides the backbone to capture the geo-metric details and overall structures. After training, the decoder is detached, thereby avoiding extra inference time. timal transformation for point cloud pair alignment. Recent advances in 3D point representation have led to significant attention on learning-based methods [2, 9, 28, 45], such as
PointNetLK [2], which utilize neural networks to separately extract point-wise features and establish point-to-point cor-respondences. Nonetheless, the lack of interaction between point clouds hinders the ability to accurately register par-tially visible point clouds. Inspired by the recent advances in transformers, transformer-based methods [15, 40, 45, 46] incorporate transformers to exchange information and en-code contextual information, exhibiting significant registra-tion accuracy and robustness improvements. However, the limited shared characteristics of low-overlap point cloud pairs produce ambiguity when identifying common struc-tures, thus degrading the performance of such methods.
Recently proposed methods [8,29,35,38] have attempted to address this limitation by introducing dedicated designed encoding methods for measuring pairwise consistency, fa-cilitating the common structure identification and reliable
These methods have been correspondence generation. 1
shown to be effective in low-overlap scenarios. However, such modifications can be limiting constraints in terms of versatility. In addition, these methods incur extra inference time due to their additional encoding calculations.
To mitigate these issues, we revisit the problem of point cloud registration and make a crucial observation: the invis-ible parts of each point cloud can serve as inherent masks, whereas the aligned point cloud pair can be treated as the re-construction objective. This observation leads us to exploit the adaptation of the masked data modeling (MDM), which has exhibited remarkable potential in natural language pro-cessing (NLP) [11, 24] and computer vision [20, 48].
In-spired by this insight, we redefine the point cloud registra-tion problem as a masking and reconstruction task.
However, adapting MDM to point cloud registration is not straightforward as other point cloud tasks [34, 36].
Firstly, unlike other tasks that only capture relations within a single point cloud, the registration task handles two point clouds. Secondly, the pretraining-tuning paradigm, which is commonly utilized in other tasks, presents difficulties for point cloud registration due to the relatively limited quan-tity of training data. These differences emphasize the chal-lenges of adapting MDM in point cloud registration, par-ticularly in terms of capturing relations across point clouds and enabling single-shot model training.
Driven by this analysis, we propose a generic plug-and-play training network, termed the Masked Reconstruction
Auxiliary Network (MRA). During training, as illustrated in
Fig. 1, the MRA separately utilizes the encoded representa-tions of each point cloud obtained from the backbone, to re-construct the complete point cloud in the coordinate space.
After training, the MRA is detached, thus avoiding extra in-ference time. Unlike previous MDM methods that operate only on visible parts for reconstruction, the MRA takes full advantage of the transformations between point clouds to avoid early leakage of location information. Consequently, it directly utilizes the contextual information obtained from two point clouds, resulting in a concise approach that allows for both inter-point-cloud relation modeling and single-shot model training. Furthermore, this design enables MRA to guide the contextual features in the backbone to capture the geometric details and overall structures of point cloud pairs.
Benefiting from these advantages of our MRA, spatial deviations in the putative corresponding points can be pre-dicted. To this end, the Deviation Correction module is de-signed to refine the predicted coordinates of the correspond-ing points. Building upon the proposed modules, we present a novel transformer-based method, Masked Reconstruction
Transformer (MRT), which leverages standard transform-ers and achieves precise and efficient alignment of point clouds. Experiments conducted on various datasets demon-strate that our MRT outperforms state-of-the-art (SOTA) methods and the MRA enhances registration accuracy while avoiding extra inference time. Our main contributions are:
• A novel perspective for rethinking point cloud regis-tration as a masking and reconstruction process is pro-posed. Based on this perspective, we present the MRT that achieves precise point cloud alignment.
• A versatile plug-and-play training network, the MRA, is developed to guide the backbone by reconstructing the complete point cloud without extra inference time.
• A correspondence prediction module, Deviation Cor-rection, is proposed to compensate for the deviation between the corresponding points.
• Extensive experiments show that our method outper-forms the baselines and achieves SOTA performance on the 3DMatch, ModelNet40, and KITTI datasets. 2.