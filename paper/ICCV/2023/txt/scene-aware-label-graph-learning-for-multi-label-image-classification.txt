Abstract
Multi-label image classification refers to assigning a set of labels for an image. One of the main challenges of this task is how to effectively capture the correlation among la-bels. Existing studies on this issue mostly rely on the sta-tistical label co-occurrence or semantic similarity of la-bels. However, an important fact is ignored that the co-occurrence of labels is closely related with image scenes (indoor, outdoor, etc.), which is a vital characteristic in multi-label image classification.
In this paper, a novel scene-aware label graph learning framework is proposed, which is capable of learning visual representations for la-bels while fully perceiving their co-occurrence relationships under variable scenes. Specifically, our framework is able to detect scene categories of images without relying on manual annotations, and keeps track of the co-occurring labels by maintaining a global co-occurrence matrix for each scene category throughout the whole training phase.
These scene-independent co-occurrence matrices are fur-ther employed to guide the interactions among label repre-sentations in a graph propagation manner towards accurate label prediction. Extensive experiments on public bench-marks demonstrate the superiority of our framework. 1.

Introduction
Multi-label image classification is a fundamental task in computer vision, which requires to recognize multiple la-bels for an image. A main issue for this task is how to fully mine the correlation among these labels.
Implicit meth-ods [23, 5] resort to sequential models or graph models to exploit the latent co-occurrence relationship among labels.
Instead, explicit methods directly model a co-occurrence probability matrix among labels from data, such as dataset-level label co-occurrence [3] and instance-level label co-occurrence [31]. However, the former is obtained statisti-*Corresponding author.
Figure 1. A brief illustration of the proposed scene-aware label graph learning framework. The semantic attention module maps the label embeddings into visual representations, and the label co-occurrence module detects the scene category of the input image and updates the co-occurrence frequency matrix accordingly. The semantic interaction module constructs a label graph for the in-teraction of label representations under the guidance of the scene-aware co-occurrence matrix for final prediction. cally on the entire data, which is coarse and may lead to wrong interactions between labels. As for the latter, it is difficult to learn an accurate co-occurrence matrix for each image, which limits its utility in guiding label interactions.
In this work, we consider an important fact that the la-bel co-occurrence heavily relies on the scene categories of images. For example, we expect chairs or tables co-occurring with persons in an indoor scene, while cars or buildings instead in an outdoor scene. Therefore, a nat-ural idea is to divide the training images into several in-dependent groups according to their scene categories and count the label co-occurrence matrix for each group sepa-rately. Then the images in each group share the same co-occurrence matrix for subsequent feature interactions. Ob-viously, the obtained group-level label co-occurrence can provide more accurate guidance for feature interaction be-tween labels than the dataset-level one [3] and the instance-level one [31], However, the scene category of images is unknown and human-expensive to annotate. It is crucial to accurately partition training data into groups with the same scene category without relying on annotations.
To address the aforementioned issue, we propose an ef-fective scene-aware label co-occurrence module that main-tains a label co-occurrence frequency matrix for each scene category. Each matrix element represents the number of oc-currences of the label pair for the corresponding row and column. They are firstly initialized with zero at the be-ginning of training, and then continuously counts the co-occurring labels of images by detecting their scene cate-gories throughout the whole training phase. However, due to the lack of scene annotations, we observe the collapse of the scene detection component and the predicted scene distribution is always dominated by a specific scene cate-gory in practice, which is known as the winner-take-all phe-nomenon [21]. To overcome this, we propose an entropy-based loss, which encourages a sharp distribution of scene categories for a single sample but a smoother average dis-tribution over a batch of samples. With this supervision, the scene detection component can not only clearly identify the scene category for an input image, but also provide a diverse prediction on scene categories for the whole dataset.
Figure 1 illustrates a basic pipeline of the Scene-Aware
Label Graph Learning (SALGL) framework. Concretely, for an input image and a candidate label set, label embed-dings and visual feature maps are first extracted via a lan-guage model and a vision backbone, respectively. They are subsequently fed into the semantic attention module to build alignments with each other, producing semantically related visual representations for each label. Meanwhile, the global pooling feature of the input image is input into the scene-aware label co-occurrence module to detect its scene cate-gory and update the label co-occurrence matrix accordingly.
Then, in the semantic interaction module, a label graph is constructed with labels as nodes and the co-occurrent re-lationships as edges. The visual representations of labels are fed into the graph to explore their interactions under the guidance of the scene-aware label co-occurrence. Finally, we train a separate classifier for each label with its visual representation to determine whether the current label exists in the image. Overall, the main contributions of this paper are summarized as follows:
• We are the first to explore the correlation between la-bel co-occurrence and scene categories, and propose an effective approach to dynamically model the label co-occurrence for adapting the variable image scenes.
• We propose an advanced entropy-based auxiliary loss that enables unsupervised learning of scene informa-tion of images from dataset and prevents the scene de-tection component from collapsing.
• We frame an end-to-end label graph learning frame-work capable of perceiving image scenes and enrich-ing label representations, which achieves state-of-the-art performance on public benchmarks. 2.