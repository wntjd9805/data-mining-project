Abstract
Generalizing deep learning models to unknown target domain distribution with low latency has motivated re-search into test-time training/adaptation (TTT/TTA). Exist-ing approaches often focus on improving test-time train-ing performance under well-curated target domain data.
As figured out in this work, many state-of-the-art meth-ods fail to maintain the performance when the target do-main is contaminated with strong out-of-distribution (OOD) data, a.k.a. open-world test-time training (OWTTT). The failure is mainly due to the inability to distinguish strong
OOD samples from regular weak OOD samples. To im-prove the robustness of OWTTT we first develop an adap-tive strong OOD pruning which improves the efficacy of the self-training TTT method. We further propose a way to dy-namically expand the prototypes to represent strong OOD samples for an improved weak/strong OOD data separa-tion. Finally, we regularize self-training with distribution alignment and the combination yields the state-of-the-art performance on 5 OWTTT benchmarks. The code is avail-able at https://github.com/Yushu-Li/OWTTT. 1.

Introduction
The distribution gap between training and testing data poses great challenges to the generalization of modern deep learning methods [34, 4]. To improve model’s generaliza-tion to testing data which may feature a different data distri-bution from the training data, domain adaptation has been extensively studied [44] to learn domain invariant features.
Nevertheless, the existing unsupervised domain adaptation paradigm requires simultaneous access to both source and target domain data with an off-line training stage [12, 41].
In a realistic scenario, access to target domain data may not become available until the inference stage, and instant
†Correspondence to Xun Xu: alex.xun.xu@gmail.com and Kui
Jia: kuijia@gmail.com.
Figure 1: Existing test-time training methods suffer sub-stantially when target domain data is contaminated with strong OOD samples. We illustrate the results by test-time training on CIFAR10-C contaminated by SVHN as strong OOD samples, with reference to values extracted from Tab 1. prediction on testing data is required without further ado.
Therefore, these requirements give rise to the emergence of a new paradigm of adaptation at test time, a.k.a. test-time training/adaptation (TTT/TTA) [40, 43].
The success of TTT has been demonstrated on many syn-thesized corrupted target domain data [18], manually se-lected hard samples [35] and adversarial samples [8]. Nev-ertheless, the boundary of existing TTT methods’ capa-bility is yet to be fully explored.
In particular, to enable
TTT in the open-world, focus has been shifted to investi-gating open-world scenarios where TTT methods could fail.
Among these scenarios, when testing data is not drawn in an i.i.d. fashion, TTT methods may be biased towards the continually changing distribution [45, 14]. When the target domain consists of testing data drawn from both source and target distributions, [29] developed a non-forgetting training paradigm to avoid failure on source domain samples. When
TTT must be updated with small batch size, shifting dis-tribution, and class imbalanced testing data, [30] proposed to swap out the batch normalization and remove unreliable pseudo labels for improved robustness.
Despite many efforts into developing stable and robust
TTT methods under a more realistic open-world environ-ment, in this work, we delve into an overlooked, but very commonly seen open-world scenario where the target do-main may contain testing data drawn from a significantly different distribution, e.g. different semantic classes than source domain, or simply random noise. We refer to the above testing data as strong out-of-distribution (strong
OOD) data, as opposed to distribution-shifted testing data, e.g. common corruptions, which are referred to as weak
OOD data in this work. The ignorance of this realistic set-ting by existing works, thus, drives us to explore improving the robustness of open-world test-time training (OWTTT) where testing data is contaminated with strong OOD sam-ples.
As shown in Fig. 1, we first empirically evaluate exist-ing TTT methods and reveal that TTT methods through self-training [43, 25] and distribution alignment [27, 39] would all suffer substantially subject to strong OOD sam-ples. These results suggest applying existing TTT tech-niques fails to achieve safe test-time training in the open-world. We attribute the failure to the following two reasons.
First, self-training based TTT [25] struggles to deal with strong OOD samples as it has to assign testing samples to known classes. Despite some low confident samples that could be filtered out by applying a threshold as adopted in semi-supervised learning [38], it is still not guaranteed to prune out all strong OOD samples. This issue exacerbates when strong OOD samples are not “strong enough”. For ex-ample, when adapting the model pre-trained on CIFAR10 to
CIFAR10-C, testing samples drawn from CIFAR100-C are significantly more difficult to be pruned out than random noise samples. Thereby, learning from incorrectly labeled strong OOD samples would weaken the model’s discrimina-tion on weak OOD samples. Second, distribution alignment based approaches would suffer when strong OOD samples are counted for estimating target domain distribution. Both global distribution alignment [27] and category-wise distri-bution alignment [39] could be affected and lead to less ac-curate feature distribution alignment.
With the potential causes for the failure of existing TTT methods in mind, we propose two techniques to improve the robustness of open-world TTT under a self-training frame-work. First, we build the baseline of TTT upon a variant of self-training, i.e. clustering in the target domain with source domain prototypes as cluster centers. To lessen the influ-ence of self-training with incorrectly pseudo-labeled strong
OOD samples, we design a hyper-parameter-free method to prune out strong OOD samples. To further separate the fea-tures of weak and strong OOD samples, we allow the proto-type pool to expand by including isolated strong OOD sam-ples. Therefore, self-training will allow strong OOD sam-ples to form tight clusters around newly expanded strong
OOD prototypes. Second, as strong OOD samples are likely to be attracted by newly grown prototypes, a more accurate distribution characterizing the target domain data can be es-timated. This would benefit distribution alignment between source and target domains. Therefore, we further propose to regularize self-training with global distribution alignment to reduce the risk of confirmation bias [3]. Finally, to synthe-size an open-world TTT scenario, we employ CIFAR10-C,
CIFAR100-C, ImageNet-C, VisDA-C, ImageNet-R, Tiny-ImageNet, MNIST, and SVHN datasets and create a bench-mark by treating one dataset as weak OOD and others as strong OOD. We refer to this benchmark as the open-world test-time training benchmark and hope this would encour-age more future works to pay attention to the robustness of test-time training in more realistic scenarios.
We summarize the contributions of this work below.
• Overlooked by existing studies into test-time training, we argue that open-world test-time training (OWTTT) could be spoiled by strong OOD testing data. We demonstrated that without special treatment state-of-the-art TTT methods fail to generalize well under the open-world protocol.
• We introduce a baseline method by prototype clus-tering with distribution alignment regularization. A strong OOD detector and prototype expansion are fur-ther developed to improve the robustness of the base-line under OWTTT protocol.
• We established a benchmark for evaluating OWTTT protocol covering multiple types of domain shift, in-cluding common corruptions and style transfer. Our approach achieves state-of-the-art performance on the proposed benchmark. 2.