Abstract
Weakly supervised person search aims to jointly de-tect and match persons with only bounding box annota-tions. Existing approaches typically focus on improving the features by exploring the relations of persons. How-ever, scale variation problem is a more severe obstacle and under-studied that a person often owns images with different scales (resolutions). For one thing, small-scale images contain less information of a person, thus affect-ing the accuracy of the generated pseudo labels. For an-other, different similarities between cross-scale images of a person increase the difficulty of matching.
In this pa-per, we address it by proposing a novel one-step frame-work, named Self-similarity driven Scale-invariant Learn-ing (SSL). Scale invariance can be explored based on the self-similarity prior that it shows the same statistical prop-erties of an image at different scales. To this end, we intro-duce a Multi-scale Exemplar Branch to guide the network in concentrating on the foreground and learning scale-invariant features by hard exemplars mining. To enhance the discriminative power of the learned features, we fur-ther introduce a dynamic pseudo label prediction that pro-gressively seeks true labels for training. Experimental re-sults on two standard benchmarks, i.e., PRW and CUHK-SYSU datasets, demonstrate that the proposed method can solve scale variation problem effectively and perform favor-ably against state-of-the-art methods. Code is available at https://github.com/Wangbenzhi/SSL.git.
*Equal Contribution.
†Corresponding Author.
Figure 1. The scale variation of the same person on PRW and
CUHK-SYSU datasets. 1.

Introduction
Recent years have witnessed the remarkable success of person search which is to match persons existed in real-world scene images. It is often taken as a joint task con-sisting of person detection [26, 29, 46] and re-identification (re-id) [32, 43, 36]. To achieve high performance, existing methods are commonly trained in a fully supervised setting
[4, 1, 41, 45, 13, 20, 23, 5] where the bounding boxes and identity labels are required. However, it is time-consuming and labor-intensive to annotate both of them in a large-scale dataset, which encourages some researchers to embark on reducing the supervision.
Considering that it is much easier to annotate bound-ing boxes than person identities, we dedicate this paper to weakly supervised person search which only needs bound-ing box annotations. Intuitively, we can address it with a su-pervised detection model and an unsupervised re-id model
[37, 44, 11, 12, 6] independently. To be specific, we first train a detector to crop person images and then apply an un-supervised re-id model for matching, which is regarded as a two-step person search model. Nevertheless, one of the ma-jor drawbacks of such two-step methods is low efficiency,
i.e., it is of high computational cost with two network pa-rameters during training and inconvenient for testing.
In contrast, one-step methods can be trained and tested more effectively and efficiently [14, 40]. Han et al. [14] use a
Region Siamese Network to learn consistent features by ex-amining relations between auto-cropped images and man-ually cropped ones. Yan et al.
[40] learn discriminative features by exploring the visual context clues. According to the learned features, both of them generate pseudo labels to make full use of unlabeled data and further learn discrimina-tive features. Although promising results are achieved, they fail to take into account the scale variation problem that a person often owns images with different scales (resolutions) because the same person is captured at different distances and camera views. As shown in Fig. 1, the images of a per-son from PRW and CUHK-SYSU datasets have large varia-tions in scale. Since it is unable to resize the input images to a fixed scale for one-step methods, the existing scale varia-tion problem will further affect the procedure of the pseudo label prediction and the subsequent person matching.
In this paper, we propose a novel Self-similarity driven
Scale-invariant Learning (SSL) weakly supervised person search framework to solve the scale variation problem. It consists of two branches: Main Branch and Multi-scale Ex-emplar Branch. The former branch takes the scene image as the input and applies a detector to extract instance features for each person. However, the detected person often have different scales, which adds to the difficulty in matching. To solve it, we design the latter branch. Specifically, we first crop the foreground of person images by using the given bounding boxes and generated binary masks. Each cropped image is regarded as an exemplar. Then, we resize each of the exemplars to several fixed scales. At last, we formulate a scale-invariant loss by hard exemplar mining. Guided by
Multi-scale Exemplar Branch, we can enable Main Branch to learn scale-invariant features. To further make the fea-tures more discriminative, we introduce a dynamic multi-label learning to explore the information in unlabeled data, which enjoys two merits: (1) It can find true labels of unla-beled data progressively and (2) It is adaptable to different datasets. Finally, we integrate the scale-invariant loss and multi-label learning loss together and optimize them jointly.
Our contributions are summarized as follows:
• We propose a novel end-to-end Self-similarity driven
Scale-invariant Learning framework to solve the task of weakly supervised person search. It bridges the gap between person detection and re-id by using a multi-scale exemplar branch as guidance.
• We design a scale-invariant loss to solve the scale variation problem and a dynamic multi-label learning which is adaptable to different datasets.
• We confirm the efficacy of the proposed method by achieving state-of-the-art performance on PRW and
CUHK-SYSU datasets. 2.