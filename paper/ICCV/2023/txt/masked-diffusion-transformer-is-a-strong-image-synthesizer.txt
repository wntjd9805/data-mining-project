Abstract
Despite its success in image synthesis, we observe that diffusion probabilistic models (DPMs) often lack contex-tual reasoning ability to learn the relations among object parts in an image, leading to a slow learning process. To solve this issue, we propose a Masked Diffusion Transformer (MDT) that introduces a mask latent modeling scheme to explicitly enhance the DPMs’ ability to contextual relation learning among object semantic parts in an image. During training, MDT operates in the latent space to mask certain tokens. Then, an asymmetric masking diffusion transformer is designed to predict masked tokens from unmasked ones while maintaining the diffusion generation process. Our
MDT can reconstruct the full information of an image from its incomplete contextual input, thus enabling it to learn the associated relations among image tokens. Experimen-tal results show that MDT achieves superior image synthe-sis performance, e.g., a new SOTA FID score in the Im-ageNet data set, and has about 3× faster learning speed than the previous SOTA DiT. The source code is released at https://github.com/sail-sg/MDT. 1.

Introduction
Diffusion probabilistic models (DPMs) [11, 38] have been at the forefront of recent advances in image-level generative models, often surpassing the previously state-of-the-art (SOTA) generative adversarial networks (GANs)
[4, 17, 37, 54]. Additionally, DPMs have demonstrated their success in numerous other applications, including text-to-image generation [38] and speech generation [24]. DPMs adopt a time-inverted Stochastic Differential Equation (SDE) to gradually map a Gaussian noise into a sample by multiple time steps, with each step corresponding to a network eval-uation. In practice, generating a sample is time-consuming due to the thousands of time steps required for the SDE to converge. To address this issue, various generation sampling strategies [21,32,41] have been proposed to accelerate the in-*This work was done while S. Gao was a research intern at Sea AI Lab.
†Pan Zhou and Ming-Ming Cheng are joint corresponding authors. i
T
D
T
D
M
K 0 5
-D
I
F 50k 100k 200k
Increasing training steps. 300k
DiT-S/2
MDT-S/2 3000k
DiT-S/2
MDT-S/2
∼3.2×
∼3.0×
Training steps (k)
Training time (days)
Figure 1. Top: Visual examples of MDT/DiT [35]. Down: learn-ing progress comparison between DiT and MDT w.r.t. training steps/time on 8×A100 GPUs. MDT has about 3× faster learning speed than DiT while achieving superior FID scores. ference speed. Nevertheless, improving the training speed of
DPMs is less explored but highly desired. Training of DPMs also unavoidably requires a large number of time steps to ensure the convergence of SDEs, making it very computa-tionally expensive, especially in this era where large-scale models [11,35] and data [9,14,44] are often used to improve generation performance.
In this work, we ﬁrst observe that DPMs often struggle to learn the associated relations among object parts in an image. This leads to its slow learning process during train-ing. Speciﬁcally, as illustrated in Fig. 1, the classical DPM,
DDPM [21] with DiT [35] as the backbone, has learned the shape of a dog at the 50k-th training step, then learns its one eye and mouth until at the 200k-th step while missing another eye. Also, the relative position of two ears is not very accurate, even at the 300k-th step. This learning pro-cess reveals that DPMs fail to learn the associated relations
among semantic parts and independently learn each seman-tic part. The reason behind this phenomenon is that DPMs maximize the log probability of real data by minimizing the per-pixel prediction loss, which ignores the associated relations among object parts in an image, thus resulting in their slow learning progress.
Inspired by the above observation, we propose an effec-tive Masked Diffusion Transformer (MDT) to improve the training efﬁciency of DPMs. MDT proposes a mask latent modeling scheme designed for transformer-based DPMs to explicitly enhance contextual learning ability and improve the associated relation learning among semantic parts in an image. Speciﬁcally, following [35, 38], MDT operates the diffusion process in the latent space to save computational costs. It masks certain image tokens and designs an asymmet-ric diffusion transformer structure to predict masked tokens from unmasked ones in a diffusion generation manner. To this end, the asymmetric structure contains an encoder, a side-interpolater, and a decoder. The encoder and decoder modify the transformer block in DiT [35] by inserting global and local token position information to help predict masked tokens. The encoder only processes unmasked tokens dur-ing training handling all tokens during inference, as there are no masks. So to ensure the decoder always processes all tokens for training prediction or inference generation, a side-interpolater implemented by a small network aims to predict masked tokens from encoder output during training, and it is removed during inference.
With the masking latent modeling scheme, our MDT can reconstruct the full information of an image from its con-textual incomplete input, learning the associated relations among semantic parts in an image. As shown in Fig. 1, MDT typically generates two eyes of the dog at almost the same training steps, indicating that it correctly learns the associ-ated semantics of an image by utilizing the mask latent mod-eling scheme. In contrast, DiT [35] cannot easily synthesize a dog with the correct semantic part relations. This com-parison shows MDT’s superior relation modeling and faster learning ability over DiT. Experimental results demonstrate that MDT achieves superior performance on the image syn-thesis task, and set the new SOTA on class-conditional image synthesis on the ImageNet dataset, as shown in Fig. 2 and
Tab. 2. MDT also enjoys about 3× faster learning progress during training than the SOTA DPMs, namely DiT, as demon-strated by Fig. 1 and Tab. 1. We hope our work can inspire more work on speeding up the diffusion training process with uniﬁed representation learning.
The main contributions are summarised as follows:
• By introducing an effective mask latent modeling scheme, we proposed a masked diffusion transformer method, which, for the ﬁrst time, explicitly enhances the contextual learning ability of DPMs.
Figure 2. Visualization of images generated by the MDT-XL/2.
• Experiments show that our method better synthesis im-ages while using much less training time than SOTA. 2.