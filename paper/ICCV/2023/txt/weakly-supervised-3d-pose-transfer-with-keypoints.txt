Abstract
The main challenges of 3D pose transfer are: 1) Lack of paired training data with different characters perform-ing the same pose; 2) Disentangling pose and shape infor-mation from the target mesh; 3) Difficulty in applying to meshes with different topologies. We thus propose a novel weakly-supervised keypoint-based framework to overcome these difficulties. Specifically, we use a topology-agnostic keypoint detector with inverse kinematics to compute trans-formations between the source and target meshes. Our method only requires supervision on the keypoints, can be applied to meshes with different topologies and is shape-invariant for the target which allows extraction of pose-only information from the target meshes without transferring shape information. We further design a cycle reconstruction to perform self-supervised pose transfer without the need for ground truth deformed mesh with the same pose and shape as the target and source, respectively. We evaluate our approach on benchmark human and animal datasets, where we achieve superior performance compared to the state-of-the-art unsupervised approaches and even compa-rable performance with the fully supervised approaches. We test on the more challenging Mixamo dataset to verify our approachâ€™s ability in handling meshes with different topolo-gies and complex clothes. Cross-dataset evaluation further shows the strong generalization ability of our approach.
Our source code is available at: https://github. com/jinnan-chen/3D-Pose-Transfer. 1.

Introduction 3D Pose transfer refers to transferring the pose from a target input to a source input while keeping the identity in-formation of the source at the same time. Pose transfer is an important research topic in computer vision because of its wide applications in many real-world applications such as augmented/virtual reality (AR/VR), movie making, gam-ing, metaverse, etc.
Significant progress has been made for 3D pose trans-fer with the development of deep learning-based methods
Figure 1. Examples of our pose transfer results on human and an-imal. Given a source mesh and a target mesh, we aim to transfer the pose from the target to the source.
[28, 20, 26, 8, 7]. However, 3D pose transfer remains a very challenging task due to the lack of paired training data since it is difficult to obtain data of two characters perform-ing the same pose. To alleviate this problem, existing works
[26, 20, 8] generate such paired data synthetically using the
SMPL [18] and SMAL [29] models. The advantage of syn-thetic data is that it is convenient to generate paired train-ing data by keeping the pose parameter of different meshes the same. However, the data generated from SMPL and
SMAL has a strong bias for both shape and pose infor-mation due to the model parameterization. Consequently, a network trained with synthetic data cannot adapt well to real 3D meshes with large shape and pose variations. Unsu-pervised approaches are proposed in [28, 7, 10] to circum-vent the requirement for paired training data. These works adopt an auto-encoder-based framework to learn the shape and pose embeddings implicitly. The pose transfer can then be achieved by swapping the pose code between the source and target meshes. Although data-efficient, these works only show results for 3D pose transfer between meshes with the same topology. Furthermore, the shape and pose infor-mation are not fully disentangled in [10, 28] due to their implicit representation.
We propose a 3D pose transfer model weakly-supervised with keypoints to mitigate the limitations of existing works.
Our method is weakly-supervised since we only need the supervision on keypoints instead of ground truth deformed
mesh. As shown in Fig. 1, our approach achieves accu-rate 3D pose transfer although we do not use ground truth paired data. Specifically, we first detect keypoints on both source and target meshes with a topology-agnostic Point-net [6]. We then compute the transformation matrices be-tween the two sets of keypoints with the differentiable Scal-able Inverse and Forward Kinematics (IK/FK) functions, and propagate the transformations to all vertices of the source mesh with Linear Blending Skin (LBS)-based mo-tion propagation. To circumvent the lack of the ground truth
LBS skinning weights, we also design a Gaussian Mixture
Model (GMM)-based pseudo label to supervise the skin-ning weights. We choose keypoints because it is easy to detect and there are correspondences between subjects of the same category. Ground truth for keypoints is also avail-able for most datasets. Furthermore, in contrast to the im-plicit methods, our combination of keypoint-based transfor-mation estimation and differentiable IK/FK helps disentan-glement of the pose from the shape information of the target.
Given that direct supervision for the deformed mesh is not available, we propose a cycle reconstruction that can be trained on realistic stylized meshes without the ground truth deformed mesh: the deformed mesh is exploited as a new target pose to reconstruct the original target mesh.
This cycle reconstruction enforces the pose transfer from the target to the source mesh. Since our model operates on keypoints, it is topology-agnostic and thus can be ap-plied to meshes with large shape variations and different topologies. Furthermore, shape regularizers are also added to enforce the consistency between the deformed and source meshes. We evaluate our approach on the commonly used
SMPL-synthetic dataset NPT [26] , SMAL-based [29] ani-mal dataset and FAUST [4] from real scans, where we out-perform existing unsupervised approaches and even achieve comparable performance with fully-supervised approaches.
To further evaluate our method on more complex and di-verse topologies, we also collect a new 3D mesh dataset from Mixamo [1], where we show better performance than the existing work. Experiments show the superiority of the proposed method compared to the state-of-the-art 3D pose transfer methods.
Our contributions can be summarized as: 1) We pro-pose a new 3D pose transfer framework for training data without ground truth supervision on the output deformed mesh. 2) Our approach is the first keypoint-based data-driven method for 3D pose transfer, and achieves bet-ter shape and pose disentanglement when combined with
IK/FK. 3) Our approach is topology-agnostic, and thus can be applied to meshes with different topologies and non-T-pose source mesh. 4) We achieve superior performance compared to the state-of-the-art unsupervised approaches on FAUST dataset and supervised approaches on Mixamo dataset, and even achieve comparable performance with the fully supervised approaches on the NPT and SMAL datasets. 2.