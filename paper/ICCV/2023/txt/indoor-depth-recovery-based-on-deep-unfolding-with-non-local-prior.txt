Abstract
In recent years, depth recovery based on deep net-works has achieved great success. However, the existing state-of-the-art network designs perform like black boxes in depth recovery tasks, lacking a clear mechanism. Uti-lizing the property that there is a large amount of non-local common characteristics in depth images, we propose a novel model-guided depth recovery method, namely the
DC-NLAR model. A non-local auto-regressive regular term is also embedded into our model to capture more non-local depth information. To fully use the excellent performance of neural networks, we develop a deep image prior to better describe the characteristic of depth images. We also intro-duce an implicit data consistency term to tackle the degen-erate operator with high heterogeneity. We then unfold the proposed model into networks by using the half-quadratic splitting algorithm. This proposed method is experimented on the NYU-Depth V2 and SUN RGB-D datasets, and the experimental results achieve comparable performance to that of deep learning methods. 1.

Introduction
Dense depth recovery from sparse depth maps is crucial for various applications, including human-computer inter-action [23], scene reconstruction [24], augmented realities
[14] and autonomous driving. Therefore, depth recovery is currently a significant research area in the field of computer vision. Accurate depth maps have been shown to provide necessary 3D information for many computer vision tasks, including semantic labeling [19, 32], robot navigation [9], 3D reconstruction [27, 21], and so on. While high-quality texture information is easily captured by modern color cam-eras, the acquisition of depth information remains a chal-†These authors contributed equally to this work.
*Corresponding author.
Figure 1. Examples of indoor depth maps. (a) the sampled points of the original depth map collected by the NYU dataset; (b) the complete depth map by our model; (c) the pseudo depth map from the SUN RGB-D dataset [31]; (d) the corresponding depth recov-ery result of our model. lenging task under realistic conditions. Although some sensors can directly acquire depth information for indoor scenes, they often suffer from reflection and missing pixels on transparent surfaces, leading to inaccurate depth maps.
Therefore, the estimation of the missing depth information for sparse depth maps has been extensively studied. In con-trast to depth images, rgb images provide rich color and tex-ture information. As a result, rgb images corresponding to depth maps are often utilized to guide depth recovery.
By the different starting points, they can be divided into two major categories: traditional model-based methods and data-driven methods. Among the early model-based depth recovery methods, Dong et al. [7] proposed a unified vari-ational method that incorporates joint local and non-local regularization. Xue et al. [39] proposed a low gradient reg-ularization to improve the excessive and spurious details in the restored region, which commonly arise from the low-rank method. This approach enables better characterization of depth images with sparse gradients. Yuan et al. [25] used non-local low rank to model the global similarity structure between depth blocks and combined it with Total variation (TV) [2] to capture the correlation between local depth pix-els. These methods transform the depth recovery problem into a mathematical optimization problem that can make full use of the essential information of the image.
The advancements in deep learning, as evidenced by re-cent studies [4, 15, 18, 29, 41], have showcased the effec-tiveness of deep learning models in various tasks. Simi-larly, convolutional neural networks (CNNs) have emerged as powerful tools for depth recovery tasks. Early methods estimated dense depth directly from rgb images and sparse depth images. Ma [20] proposed an encoder-decoder struc-ture to recover dense depth maps from sparse depth maps, guided by rgb images. This work highlights the significance of CNNs in the realm of depth restoration tasks. However, the dense depth maps predicted by previous methods often suffer from inaccuracies. To further generate finer and com-plete depth maps, a lot of work has emerged recently. Wang et al. [35] proposed an end-to-end GAN-based network that effectively integrates the original depth maps and rgb im-ages to efficiently obtain accurate depth estimates.
Although CNNs have achieved excellent performance in depth recovery tasks, they often overlook the specific characteristics of depth images. On the other hand, tra-ditional model-driven approaches attempt to transform the tasks into mathematically interpretable problems. However, they heavily depend on manually designed parameters dur-ing the solution process, which may not guarantee the dis-covery of an optimal solution. In our task, the challenge lies in recovering the complete depth map from sparse raw depth data using a random selection of a few hundred depth samples or the incomplete original depth map, as shown in
Fig. 1. Considering its sparsity and similarity, we propose a deep unfolding model that combines traditional mathemati-cal models with deep networks, and the contributions of our work can be summarized as follows:
• We first propose a deep unfolding model applied to the depth recovery tasks, which integrates the advan-tages of traditional mathematical models with CNNs to learn more generalized prior information about depth images. To enhance the global understanding of depth images, a non-local auto-regressive regularization term is introduced into our model. This term facilitates the recovery of the depth map by leveraging similarities among depth patches.
• We derive an alternate optimization algorithm for each variable to optimize this model, and then unfold the it-erative algorithm into a deep network. Specifically, as the degenerate operator with highly global heterogene-ity, we develop a convolutional network to build data consistency term and further integrate it with a gradi-ent descent process.
• Our proposed method has experimented on the NYU-Depth V2 and SUN RGB-D datasets, and the exper-imental results achieve comparable performance with deep learning-based methods, demonstrating its effec-tiveness and availability in terms of performance for depth recovery tasks. 2.