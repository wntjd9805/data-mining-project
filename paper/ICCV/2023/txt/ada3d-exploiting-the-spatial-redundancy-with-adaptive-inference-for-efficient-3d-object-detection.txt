Abstract
Voxel-based methods have achieved state-of-the-art per-formance for 3D object detection in autonomous driv-ing. However, their significant computational and memory costs pose a challenge for their application to resource-constrained vehicles. One reason for this high resource consumption is the presence of a large number of redundant background points in Lidar point clouds, resulting in spa-tial redundancy in both 3D voxel and BEV map represen-tations. To address this issue, we propose an adaptive in-ference framework called Ada3D, which focuses on reduc-ing the spatial redundancy to compress the model’s com-putational and memory cost. Ada3D adaptively filters the redundant input, guided by a lightweight importance pre-dictor and the unique properties of the Lidar point cloud.
Additionally, we maintain the BEV features’ intrinsic spar-sity by introducing the Sparsity Preserving Batch Normal-ization. With Ada3D, we achieve 40% reduction for 3D voxels and decrease the density of 2D BEV feature maps from 100% to 20% without sacrificing accuracy. Ada3D reduces the model computational and memory cost by 5×, and achieves 1.52× / 1.45× end-to-end GPU latency and 1.5× / 4.5× GPU peak memory optimization for the 3D and 2D backbone respectively. 1.

Introduction
The perception of the 3D scene plays a vital role in au-tonomous driving systems.
It’s essential that the percep-tion of the surrounding 3D scene is both quick and accu-rate, which places high demands on both performance and latency for perception methods.
Voxel-based 3D deep learning methods convert the in-*Corresponding Authors
Figure 1: Ada3D is an adaptive inference framework that exploits the spatial redundancy for both the 3D voxel and 2D BEV features. put point cloud into sparse voxels by quantizing them into regular grids, and achieve state-of-the-art performance [13].
However, current voxel-based methods struggle to meet the real-time demand on self-driving cars due to constrained re-sources [14]. As a result, it is crucial to improve the effi-ciency of voxel-based 3D perception methods (e.g., reduce the GPU latency and peak memory).
There are two main factors contributing to the exces-sively long processing time for 3D perception methods.
Firstly, the model size is excessive, and it contains time-consuming operations such as 3D sparse convolution [14].
Secondly, the algorithm needs to process a large amount of input points (e.g., 30K for nuScenes). Prior researches focus on solving the former issue by compressing the model both at the operation-level [9, 15] and architecture-level [25, 32]. In this paper, we take a different approach and improve the model’s efficiency from the data level.
The typical pipeline of voxel-based 3D detector is dis-played in Fig. 1, the 3D backbone extracts feature from the input point cloud. The 3D features are then projected to bird-eye-view (BEV) space along the z-axis and further pro-cessed by the 2D backbone with normal 2D convolutions.
We discover that there exists spatial redundancy for both the 3D voxel and 2D BEV features. For 3D voxels, As shown in Fig. 1, a large number of points in the input point cloud represents the road plane and buildings, which are redundant “background” for 3D detection. We further val-idate the redundancy of the point cloud with quantitative results in Fig. 2. When we randomly drop 30% of the in-put points or 70% of the points excluding those within the ground-truth bounding box (the “foreground”), we only ob-serve a subtle drop in performance. Existing 3D CNNs treat all input points equally, thus wasting a substantial amount of computation and memory on the less-informative back-ground area. Regarding 2D BEV features, as shown in
Fig. 1, only a small portion of (e.g., 5% for KITTI) pixels have projected feature values in the BEV space, while oth-ers are background pixels with zero value. However, current methods treat these sparse BEV features as dense and apply normal CNN to them. As can be observed in the lower part of Fig. 2, the feature map loses sparsity after the first batch normalization layer, which fails to utilize the sparse nature of the Lidar-projected BEV feature map.
To compress the data’s spatial redundancy, we propose an adaptive inference method Ada3D. We adopt adaptive inference to both the 3D and 2D backbone and selectively filter out redundant 3D voxels and 2D BEV features during inference. We employ a lightweight predictor to evaluate the importance of input features in the BEV space. The predictor score is combined with the density of the Lidar point cloud to determine which features to drop. In addi-tion, we introduce a simple yet effective technique called sparsity-preserving batch normalization, which efficiently eliminates background pixels and preserves sparsity for 2D
BEV features. Through adaptively skipping redundant fea-tures, Ada3D reduces the computational and memory costs of the model by 5× and achieves 1.4 × end-to-end speedup and 2.2× GPU peak memory optimization on RTX3090 without compromising performance.
The contributions of this paper could be summarized into three aspects, as follows: 1. We introduce the adaptive inference method Ada3D that leverages spatial redundancy for efficient 3D ob-ject detection.
Figure 2: Empirical evidence of spatial redundancy in 3D and 2D data. Upper: The KITTI Cars Moderate AP un-der different drop rates with random dropping and ground-truth excluded dropping. Lower: The sparsity of different layer’s 2D BEV features. 2. We design a shared predictor to evaluate the impor-tance of input features, and combine the predictor score with point cloud density as the criterion for drop-ping redundant features. 3. We propose sparsity-preserving batch normalization to maintain the sparsity for the 2D backbone. 2.