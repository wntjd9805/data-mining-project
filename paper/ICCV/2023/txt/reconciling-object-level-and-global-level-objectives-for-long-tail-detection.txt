Abstract
Large vocabulary object detectors are often faced with the long-tailed label distributions, seriously degrading their ability to detect rarely seen categories. On one hand, the rare objects are prone to be misclassified as frequent cate-gories. On the other hand, due to the limitation on the to-tal number of detections per image, detectors usually rank all the confidence scores globally and filter out the lower-ranking ones. This may result in missed detection during inference, especially for the rare categories that naturally come with lower scores. Existing methods mainly focus on the former problem and design various classification loss to enhance the object-level classification accuracy, but largely overlook the global-level ranking task. In this paper, we propose a novel framework that Reconciles Object-level and Global-level (ROG) objectives to address both prob-lems. As a multi-task learning framework, ROG simulta-neously trains the model with two tasks: classifying each object proposal individually and ranking all the confidence scores globally. Specifically, complementary to the object-level classification loss for model discrimination, we design a generalized average precision (GAP) loss to explicitly op-timize the global-level score ranking across different ob-jects. For each category, GAP loss generates balanced gra-dients to rectify the ranking errors. In experiments, we show that GAP loss is highly versatile to be plugged into various advanced methods and brings considerable benefits. Code is at https://github.com/EricZsy/ROG. 1.

Introduction
The development of modern convolutional neural net-works (CNNs) gives rise to great advances in object detec-tion [14, 36, 29] and instance segmentation [49, 54]. So far, the state-of-the-art object detectors typically rely heavily on a huge amount of annotated data [27]. However, with the
*Corresponding author. (a) (b) (c)
Figure 1. The two major causes degrading detection performance for rare categories: misclassification (MC) and missed detection (MD). (a) The common pipeline of an object detector. The boxes with solid line and dashed line are foregrounds and backgrounds respectively. The dots denote the predictions for these boxes, fol-lowed by their confidence scores. (b) Rare object soccer is mis-classified as person in the classification task. (c) Missed detection for soccer caused by global ranking and filtering. rapid growth of data scale, the long-tail effect has become a bottleneck in training object detectors for real-world use. In large vocabulary image datasets such as LVIS [15], there are only a few categories containing abundant instances, while most other rare categories seldom appear. Detectors natu-rally lean towards the frequent categories and usually fail in detecting those rarely seen objects.
In Figure 1, we analyze that the undesired phenomenon is mainly derived from two aspects. First, the significantly more frequent objects dominate the training process, and thereby suppress the rare categories by overwhelming dis-couraging gradients [42]. As a result, the latter is more likely to be predicted with lower confidence scores and mis-classified, e.g., the soccer is classified as the frequent cat-egory person in Figure 1(b). Second, during inference, the rare objects are prone to be lost due to a seemingly triv-ial detail: the global ranking and filtering for all the scores in each image. Before non-maximum suppression (NMS), all the scores are collected together and the ones below a certain threshold will be filtered out. In addition, consid-ering the memory limit, the object detectors usually have limitations on the maximum number of detections per im-age. Therefore, after NMS, all the detected objects in an image will be ranked by their confidence scores, and only the top-K of them will be reserved for final results. Since the scores for rare categories are relatively low, they are eas-ily squeezed out in the global-level and cross-object ranking competition (see Figure 1(c)). The two problems, respec-tively arising in training and inference phase, are relevant but of different emphasis. The former presents the chal-lenge of classifying each object accurately, while the latter focuses on how to rank all the scores fairly.
Prior works in long-tail detection mainly focus on the former problem, i.e., misclassification from tail to head.
To calibrate the classification bias, a variety of special-ized classification loss functions are proposed. Some of them re-weight the classification loss based on class prior
[42, 17, 1] or training status [41, 45, 48], while others
[43, 37, 12, 19, 47] design class-wise margins for calibrated decision boundaries. Although modifying the classifica-tion loss could enhance model discrimination and improve object-level classification accuracy, it is not able to give a direct solution to the cross-object ranking task. In fact, even though a rare object is classified correctly, it is still possi-ble to be missed due to the low confidence score. Recall that for object detection, the classification accuracy is not a comprehensive indicator, while average precision (AP) is a more widely used metric. Motivated by this, some work
[4, 30, 31, 7] replace the classification task with a ranking task to learn to rank every positive sample above all the neg-ative samples. Detectors trained by ranking-based loss may be good at ranking task but not discriminative enough. For example, the loss could be minimized to zero even if the scores of positive samples are only slightly higher than that of negative ones. More importantly, these ranking algo-rithms are category-agnostic that weights all ground-truth samples equally, no matter which categories they belong to.
It is still inconsistent with the AP metric1 which is averaged over each category. Especially, under long-tail distribution, the gradients for ranking rare-category samples are weak, and will be easily deflected by frequent categories.
To address the aforementioned problems in long-tail detection, it is highly considerable to reconcile both the 1Note that in COCO [27], there is no distinction between AP and mean average precision (mAP). They are both averaged over all categories. We follow their notations and use AP throughout the paper for consistency. object-level discrimination objective and global-level rank-ing objective during training. Therefore, in this paper, we present ROG, a multi-task learning framework that simulta-neously learns two tasks: classifying each object proposal individually and ranking all confidence scores globally. The object-level discrimination objective aims to train a discrim-inative classifier that could classify each object accurately.
It also ensures a unified score distribution across categories.
On this basis, the global-level ranking objective is proposed to optimize the cross-object ranking orders via a generalized average precision loss. For each specific category, the loss is calculated by ranking errors between category-specific positive-negative pairs. Then the generalized precision loss is averaged over all categories, and thus generates balanced gradients to re-rank samples for each category equally. Fol-lowing [5], the error-driven update algorithm is adopted to optimize the non-differentiable ranking loss. As a whole, the classification task and the ranking task complement each other to jointly cater to the classification and ranking proce-dures in object detection. In addition, the two tasks could be trained harmoniously: the classification scores are pro-vided for the ranking task, and the ranking task could im-prove scores of positive samples and reduce scores of nega-tive samples which in turn promotes the classification task.
Extensive experiments are conducted on the challenging
LVIS [15] and OpenImages [22] datasets. We show that the generalized average precision loss is highly versatile to cooperate with existing methods. As a whole framework,
ROG consistently improves the performance of state-of-the-art methods, across various classification losses [41, 19], sampling strategies [15] and post-processing methods [33].
To sum up, the main contribution of this work is a ROG framework that considers both object-level classification task and global-level ranking task in long-tail detection. It is motivated by the overlooked ranking and filtering proce-dure in inference phase, and aims to learn to classify each object and rank all the confidence scores simultaneously. A generalized average precision loss is proposed to rectify the ranking errors for each category equally. The extensive ex-periments validate the effectiveness of ROG. 2.