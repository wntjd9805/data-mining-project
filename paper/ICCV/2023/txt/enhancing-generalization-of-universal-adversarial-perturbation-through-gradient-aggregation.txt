Abstract
Deep neural networks are vulnerable to universal adver-sarial perturbation (UAP), an instance-agnostic perturba-tion capable of fooling the target model for most samples.
Compared to instance-specific adversarial examples, UAP is more challenging as it needs to generalize across various samples and models. In this paper, we examine the serious dilemma of UAP generation methods from a generalization perspective – the gradient vanishing problem using small-batch stochastic gradient optimization and the local optima problem using large-batch optimization. To address these problems, we propose a simple and effective method called
Stochastic Gradient Aggregation (SGA), which alleviates the gradient vanishing and escapes from poor local optima at the same time. Specifically, SGA employs the small-batch training to perform multiple iterations of inner pre-search.
Then, all the inner gradients are aggregated as a one-step gradient estimation to enhance the gradient stability and reduce quantization errors. Extensive experiments on the standard ImageNet dataset demonstrate that our method significantly enhances the generalization ability of UAP and outperforms other state-of-the-art methods. The code is available at https://github.com/liuxuannan/
Stochastic-Gradient-Aggregation. 1.

Introduction
Deep neural networks (DNNs) have achieved significant success in computer vision [9, 35, 34, 8, 11, 12], but are widely known to be vulnerable to adversarial examples [36, 23, 26, 7, 15, 19, 39]. A more critical property of adver-sarial examples is that they have shown good transferability between different models [18, 25, 5, 6, 17, 40, 50, 38, 29].
Unlike the instance-specific adversarial examples, a recent work [22] reveals the existence of universal adversarial per-turbation (UAP) which can deceive the majority of samples.
Compared to the instance-specific adversarial examples,
*Corresponding author
Figure 1. A universal adversarial perturbation is applied to images belonging to different categories to get visually similar adversarial examples with high attack success rates in the white-box scenario.
Left images: the original natural images. Central image: the
UAP by applying SGA on the VGG16 model (rescaled to [0,255]).
Right images: the adversarial images. the generation of UAP is more challenging. Since most
UAPs are generated with limited training samples and are expected to be applied to various unknown samples [14, 28, 33, 16] and even a variety of tasks [41, 4, 30, 1, 27, 51], the diversity of samples and models has created dual demands for higher generalization ability of UAPs. Therefore, we aim to investigate the limitation of the current UAPs and improve the generalization ability.
Despite many works on UAP, there are two main issues in the generation of UAP. (1) Gradient instability. Due to the inherent difference of samples and model parameters, the optimization paths for adversarial perturbations vary widely, as shown in Fig 2 (a). Such instability may hin-der the optimization of adversarial attacks in the correct di-rection [38, 42, 37]. (2) Quantization error. The adversar-samples to perform the inner iterations for pre-search. Then we aggregate all inner gradients as a one-step iterative gra-dient for updating UAP, as illustrated in Fig 2 (b) and (d).
The key idea is to cope with gradient vanishing by enhanc-ing the gradient stability and decreasing the use of quantiza-tion operations while introducing the noisy gradients to es-cape from sharp local optima. To the best of our knowledge, this is the first work to investigate the limitation of existing universal attacks through the perspective of generalization.
The main contributions of our paper are as follows:
• We investigate two issues behind the low generaliza-tion ability of existing UAP works, i.e., gradient insta-bility and quantization error, and further identify the gradient vanishing phenomenon when the iterative gra-dients have high fluctuations.
• We propose stochasitc gradient aggregation (SGA) that stabilizes the update directions and reduces quantiza-tion errors to alleviate the gradient vanishing in the small-batch optimization.
• Our method can be easily integrated with transferabil-ity attack methods. Extensive experiments demon-strate the superior generalization of UAP generated by the proposed SGA compared to the state-of-the-art methods under various attack settings. 2.