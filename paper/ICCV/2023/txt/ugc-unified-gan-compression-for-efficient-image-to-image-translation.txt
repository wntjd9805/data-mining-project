Abstract
Recent years have witnessed the prevailing progress of Generative Adversarial Networks (GANs) in image-to-image translation. However, the success of these GAN mod-els hinges on ponderous computational costs and labor-expensive training data. Current efficient GAN learning techniques often fall into two orthogonal aspects: i) model ii) data/label-slimming via reduced calculation costs; efficient learning with fewer training data/labels. To com-bine the best of both worlds, we propose a new learning paradigm, Unified GAN Compression (UGC), with a uni-fied optimization objective to seamlessly prompt the syn-ergy of model-efficient and label-efficient learning. UGC sets up semi-supervised-driven network architecture search and adaptive online semi-supervised distillation stages se-quentially, which formulates a heterogeneous mutual learn-ing scheme to obtain an architecture-flexible, label-efficient,
⋆Equal contribution. †Corresponding author. and performance-excellent model. Extensive experiments demonstrate that UGC obtains state-of-the-art lightweight models even with less than 50% labels. UGC that com-presses 40× MACs can achieve 21.43 FID on edges→shoes with 25% labels, which even outperforms the original model with 100% labels by 2.75 FID. 1.

Introduction
Recently, Generative Adversarial Networks (GANs)[12, 1, 32, 33, 4, 17, 55] have achieved prominent results in various visual generative tasks, such as image-to-image translation[17, 44, 30, 55, 7] and style transfer[21, 22, 39, 9]. Albeit with varying degrees of progress, most of its recent successes rely on explosive computational com-plexities or extensive labeled images. Training or de-ploying these excellent GAN models with unwieldy re-source demands is arduous, especially in the hardware-constrained[23, 35, 18] or low-data regime[52, 5, 27]. To
tools, formulating a heterogeneous mutual learning scheme.
In the first stage, semi-supervised learning optimizes sub-networks within the search space via distillation loss on un-labeled images, leveraging the weight-sharing mechanism to facilitate the network architecture search (NAS) proce-dure.
In the second stage, the discriminator-free student network is optimized in the online distillation setting, em-ploying the teacher discriminator to guide the label-efficient
GAN learning procedure. The contributions of this paper can be summarized in three-fold:
• New Insight: To the best of our knowledge, we of-fer the first attempt to design a unified optimization paradigm for GAN compression, which pioneers to advance image-to-image translation based GAN com-pression into jointly modeling both model-efficient and label-efficient GAN learning. We believe that our work can provide inspired insight and suggests a new path forward in efficient GAN learning.
• Unified and Pioneering: UGC seamlessly integrates three orthogonal compression techniques, i.e., net-work architecture search, online distillation and semi-supervised learning, to be jointly optimized in a collab-orative framework. On the one hand, semi-supervised learning provides auxiliary supervision signals to facil-itate NAS and the distillation procedure. On the other hand, NAS and distillation technology promote obtain-ing an architecture-flexible and performance-excellent model.
• High Effectiveness:
Extensive experiments on edges→shoes [48] and cityscapes [8]) demonstrate that UGC successes to compress pix2pix [17] by 39×
MACs , pix2pixHD by 17× and GauGAN by 31× , and achieves state-of-the-art compression performance (see Figure 1). Under this extreme compression ratio,
UGC can further reduce 50% of labels without losing the visual fidelity of generated images. Compared with the existing competitive approaches, UGC helps to ob-tain better image quality with much less computational costs and labels. UGC provides a feasible solution for deploying GAN in the hardware-constrained and label-limited regime. 2.