Abstract
In this paper, a novel Diffusion-based 3D Pose esti-mation (D3DP) method with Joint-wise reProjection-based
Multi-hypothesis Aggregation (JPMA) is proposed for prob-abilistic 3D human pose estimation. On the one hand,
D3DP generates multiple possible 3D pose hypotheses for a single 2D observation. It gradually diffuses the ground truth 3D poses to a random distribution, and learns a de-noiser conditioned on 2D keypoints to recover the uncon-taminated 3D poses. The proposed D3DP is compatible with existing 3D pose estimators and supports users to balance efficiency and accuracy during inference through two customizable parameters. On the other hand, JPMA is proposed to assemble multiple hypotheses generated by
D3DP into a single 3D pose for practical use.
It repro-jects 3D pose hypotheses to the 2D camera plane, selects the best hypothesis joint-by-joint based on the reprojec-tion errors, and combines the selected joints into the fi-nal pose. The proposed JPMA conducts aggregation at the joint level and makes use of the 2D prior informa-tion, both of which have been overlooked by previous ap-proaches. Extensive experiments on Human3.6M and MPI-INF-3DHP datasets show that our method outperforms the state-of-the-art deterministic and probabilistic approaches by 1.5% and 8.9%, respectively. Code is available at https://github.com/paTRICK-swk/D3DP. 1.

Introduction
Monocular 3D human pose estimation aims to locate the 3D positions of human body joints from 2D images or videos.
It plays a crucial role in various applications, such as human-computer interaction, metaverse, and self-driving. This task can be decomposed into two steps: first estimating the 2D locations of human joints using off-the-Figure 1: Thumbnail of our D3DP approach with multi-hypothesis aggregation. (a) Training: we gradually destroy the ground truth 3D pose and reverse this process by a de-noiser to obtain a clean 3D prediction. (b) Inference: multi-ple Gaussian noises are passed through the denoiser, which is conditioned on 2D keypoints, to generate plausible 3D pose hypotheses. Then, the proposed multi-hypothesis ag-gregation method is utilized to yield the final output. shelf 2D keypoint detectors (e.g., CPN [11], OpenPose [6]); and then mapping these 2D locations to their correspond-ing 3D positions. In this work, we focus on the latter step, also known as the 2D-to-3D lifting process, following re-cent approaches[14, 42, 64, 47].
Existing works can be divided into two categories: de-terministic and probabilistic approaches. Deterministic ap-proaches [61, 36, 65, 47, 34] are designed to produce a sin-gle, definite 3D pose for each image, which is practical in real-world applications. Probabilistic approaches [59, 30, 24, 49, 40] represent the 2D-to-3D lifting as a probability distribution and produce a set of possible solutions for each image, which allows for uncertainty and ambiguity in the lifting process. This paper focuses on probabilistic meth-ods but combines the advantages of deterministic methods, i.e., we aggregate multiple pose hypotheses into a single, higher-quality 3D pose for practical use.
Previous probabilistic approaches use generative models (e.g., generative adversarial networks [17] or normalizing flows [43]) to predict multiple 3D pose hypotheses. Despite the great progress achieved, they still have the following two disadvantages: 1) They either (i) rely on special net-work designs and have poor compatibility [33, 59, 31, 52], or (ii) cannot specify the number of hypotheses based on actual needs [33, 30, 40]. 2) Although these methods gen-erate multiple possible hypotheses, an individual 3D pose is still needed for practical use. They generally average over multiple hypotheses at the pose level to obtain the fi-nal output [49, 30], which does not take into account the differences between joints and the prior distribution of 2D keypoints. Consequently, the averaged result is much worse than the best of all hypotheses.
To address the first problem, we exploit Denoising Dif-fusion Probabilistic Models (DDPMs) [18] for 3D human pose estimation and introduce a novel approach called
Diffusion-based 3D Pose estimation (D3DP). As shown in
Fig. 1, our approach involves adding varying levels of noise to the ground truth 3D poses and learning a denoiser to predict the original data during training. During inference, we generate initial 3D poses by sampling pure noise from a Gaussian distribution. These poses are then sent to the denoiser, which is conditioned on 2D keypoints, to predict multiple 3D pose hypotheses. Compared to previous ap-proaches, our method is superior in two aspects. (i) The de-noiser has the compatibility to use existing 3D human pose estimators as the backbone, which enables an easy transfor-mation from a deterministic approach into a probabilistic version. (ii) The number of hypotheses can be customized during inference. Besides, the proposed method progres-sively refines the generated results, which supports an ad-ditional adjustable parameter (number of iterations). More hypotheses and iterations bring better results at the expense of greater computational overhead. These two parameters help to strike a balance between performance and efficiency under limited computing resources.
To address the second problem, we focus on how to ag-gregate multiple 3D pose hypotheses into a single, more ac-curate 3D prediction. It is observed that the upper-bound performance of aggregation at the joint level is much higher than that at the pose level (Section 4.5), as the former con-ducts aggregation at a finer granularity. This observation drives us to propose a joint-wise reprojection-based multi-hypothesis aggregation (JPMA) method, which reprojects 3D pose hypotheses back to the 2D camera plane and con-ducts the joint-level selection of the best hypothesis based on the reprojection errors. The selected joints are assembled into a complete 3D pose as the final output. The proposed method uses joints as granularity, allowing a more diverse combination of hypotheses. In addition, the marginal distri-bution of 2D keypoints is taken into account, thus aiding the modeling of the posterior distribution of the final 3D pose.
Compared to previous methods that use the averaged pose,
JPMA integrates joint-level geometric priors into the multi-hypothesis aggregation, and hence improves the prediction performance.
Our contributions can be summarized as follows:
• We propose a diffusion-based 3D human pose estima-tion (D3DP) method, which is compatible and cus-tomizable.
• When multiple hypotheses are combined into a single prediction, we observe that the upper bound of perfor-mance for aggregation at the joint level is significantly higher than that at the pose level. This observation drives us to conduct joint-by-joint aggregation. To the best of our knowledge, we are the first to tackle this problem from the joint perspective.
• We propose a joint-wise reprojection-based multi-hypothesis aggregation (JPMA) method, which lever-ages the 2D prior at the joint level to improve the accu-racy of the final 3D prediction. The proposed method proves to be more effective than existing pose-level ag-gregation methods.
• Our method outperforms both the state-of-the-art de-terministic and probabilistic approaches on 3D human pose estimation benchmarks. 2.