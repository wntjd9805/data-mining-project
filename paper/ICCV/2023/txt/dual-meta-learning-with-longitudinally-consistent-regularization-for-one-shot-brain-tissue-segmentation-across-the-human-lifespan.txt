Abstract
Brain tissue segmentation is essential for neuroscience and clinical studies. However, segmentation on longitudinal data is challenging due to dynamic brain changes across the lifespan. Previous researches mainly focus on self-supervision with regularizations and will lose longitudinal generalization when fine-tuning on a specific age group. In this paper, we propose a dual meta-learning paradigm to learn longitudinally consistent representations and persist when fine-tuning. Specifically, we learn a plug-and-play feature extractor to extract longitudinal-consistent anatom-ical representations by meta-feature learning and a well-initialized task head for fine-tuning by meta-initialization learning. Besides, two class-aware regularizations are pro-posed to encourage longitudinal consistency. Experimen-tal results on the iSeg2019 and ADNI datasets demon-strate the effectiveness of our method. Our code is avail-able at https://github.com/ladderlab-xjtu/
DuMeta. 1.

Introduction
Accurate brain tissue segmentation is essential in diverse neuroscience and clinical studies, e.g., population analyses of brain cortical architectures and individualized diagnosis of brain diseases. Due to spatiotemporally dynamic changes in brain structures and functions across the human lifespan, brain magnetic resonance images (MRIs) present longitu-dinally heterogenous appearances, leading to varying seg-mentation difficulties at different periods [37]. Infancy and the elderly are two particularly challenging times for tissue segmentation, as a result of (atypical) developmental and degenerative processes. For example, as shown in Fig. 1 (a), the brains of infants before six month old have inverse con-trasts between gray matter (GM) and white matter (WM)
Figure 1. (a) Brain morphology and tissue contrast of 6-month-old infants from the iSeg2019 dataset. (b) Aging and Alzheimer processes of the elderly from the ADNI dataset. compared with following periods, and the isointense phase around six-month-old exhibits extremely low inter-tissue contrast. In contrast, the brains of the elderly and patients with Alzheimer’s disease have enlarged cerebrospinal fluid (CSF) and atrophied GM, as shown in Fig. 1 (b). These challenges significantly hamper the generalization and lon-gitudinal consistency of existing learning-based methods for automatic brain tissue segmentation [25, 39, 18, 9], es-pecially considering that labeled training samples for spe-cific time points could be very limited in practice.
To address the above challenges, some methods in the lit-erature [32, 29] designed contrastive self-supervised learn-ing (SSL) strategies to learn longitudinally consistent rep-resentations, which are then fine-tuned on a specific age group for downstream tasks like tissue segmentation. Such
SSL methods commonly have three technical limitations from the application perspective. That is, they usually re-quire longitudinally paired images of the same subjects in the pre-training phase, which is practically hard to satisfy.
Besides, the fine-tuned segmentation models are typically restricted to match up with the appearance of a specific age group, sacrificing/losing the generalization capacity to other groups. Moreover, fine-tuning a segmentation model is it-self a challenging task, especially when there is not enough labeled training data from the target age group.
In this paper, we revisit and reformulate the idea of longi-tudinally generalized (or age-agnostic) representation learn-ing. By nature, it is reasonable to make two fundamental as-sumptions: 1) independent of changing MRI appearances, the high-order differences between different tissue types (e.g., in semantic space) are relatively stable in terms of the time trajectory; 2) accurate tissue segmentation requires a reliable mapping function to seamlessly fuse semantic in-formation with age-specific high-resolution image details.
In line with such assumptions, we propose a unified meta-learning framework to concurrently learns to learn a uni-versal feature extractor (e.g., the encoder) for age-agnostic (i.e., longitudinally consistent) anatomical representation learning and a well-initialized segmentation head (e.g., the decoder) that can be flexibly adapted by few age-specific samples (e.g., one labeled MRI) to establish accurate seg-mentation models generalizable across the lifespan.
Overall, the technical and practical contributions of this paper are four-fold:
• We propose a dual meta-learning (DuMeta) paradigm for the construction of longitudinally generalized seg-mentation networks. Our DuMeta unifies the ad-vantages of both meta-feature learning and meta-initialization learning [22, 14] in a compact bi-level optimization framework, which contributes to the joint learning of an age-agnostic plug-and-play feature ex-tractor and a reliably pre-trained segmentation head that can be efficiently adapted to different age groups.
• For the purpose of learning to learn a universal fea-ture extractor generalizable across the lifespan, we de-sign an intra-tissue temporal similarity regularization and an inter-tissue spatial orthogonality regularization, which are combined together to encourage longitudi-nal consistency in hierarchically multi-scale represen-tation learning. In contrast to previous SSL works, our design explicitly considers class information and has no need of longitudinally paired training data.
• Our DuMeta coupled with the two class-aware regu-larization terms features a practically attractive meta-learning strategy. It only needs cross-sectional training samples in the meta-learning stage and as less as one labeled image from an unseen age group to establish an accurate brain tissue segmentation model.
• Under the challenging experimental setting of one-shot segmentation, our method significantly outperformed the state-of-the-art longitudinally consistent learning methods on both the infant and elderly datasets. 2.