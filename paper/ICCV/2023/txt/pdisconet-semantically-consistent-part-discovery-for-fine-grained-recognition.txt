Abstract
Fine-grained classification often requires recognizing specific object parts, such as beak shape and wing pat-terns for birds. Encouraging a fine-grained classification model to first detect such parts and then using them to infer the class could help us gauge whether the model is indeed looking at the right details better than with inter-pretability methods that provide a single attribution map.
We propose PDiscoNet to discover object parts by using only image-level class labels along with priors encour-aging the parts to be: discriminative, compact, distinct from each other, equivariant to rigid transforms, and ac-In addition to us-tive in at least some of the images. ing the appropriate losses to encode these priors, we pro-pose to use part-dropout, where full part feature vectors are dropped at once to prevent a single part from dominating in the classification, and part feature vector modulation, which makes the information coming from each part distinct from the perspective of the classifier. Our results on CUB,
CelebA, and PartImageNet show that the proposed method provides substantially better part discovery performance than previous methods while not requiring any additional hyper-parameter tuning and without penalizing the clas-sification performance. The code is available at https:
//github.com/robertdvdk/part_detection 1.

Introduction
Commonly used approaches to inspect a deep learning model’s inner workings yield a saliency map that indicates which regions contributed the most to the output [5, 29]. If the model seems to focus on image regions that are known to be irrelevant, (e.g. the background or the wrong object), it becomes clear that the model has picked up on spurious correlations and cannot be trusted. This observation could
Figure 1. Our PDiscoNet extracts semantically consistent parts, without any part annotations, and reasons on these parts before combining the results into a final fine-grained classification output. then be used to improve future iterations of the model, for instance, by eliminating or compensating for the detected spurious correlations. However, this type of approach of-fers little information when the model provides an incorrect answer but the saliency map suggests that it is attending to the correct image regions.
Other approaches aim at modifying the model architec-ture itself in order to ensure that the provided explanation actually reflects the decision process of the model [10, 6].
In particular, the saliency map explanation can be en-riched by dividing it in multiple semantically interpretable parts, mimicking the traditional approaches of tackling fine-grained visual categorization (FGVC), in which image-level part annotations were leveraged [22] in order to help the model differentiate between similar classes by helping it fo-cus on the relevant parts. In this manner, we have more in-formation to judge the adequacy of the model’s reasoning: even if the correct object is highlighted, we will be suspi-cious of the result if the part map that the model generally associated to the head of a bird seems to highlight the feet in one particular image. We thus posit that a model that clas-sifies images based on just a few discriminative regions that are semantically consistent across images would be more interpretable than one which highlights the whole object, as one can immediately visualise the parts of the image that have been attended to and interpret their semantics across
images. By inspecting a few images and their correspond-ing detected parts, we can easily assign semantic meaning to each part (e.g., bird beak, vehicle wheel) and judge whether the correct parts are being detected in a new image.
Even if the model correctly assigns high saliency to the object of interest, we will know to mistrust the result in case the discovered part semantics are not respected. This way of interpreting the models has an additional advantage over post-hoc methods in that we can be more certain that the model only uses information from the indicated regions.
Such models have also been shown to be more robust; ir-relevant parts are filtered out by only looking at the dis-covered discriminative regions, which can have a positive impact on generalization capability and thus robustness to occlusion [37] and adversarial attacks [30].
Discovering meaningful and discriminative parts using only image-level class labels requires the use of additional priors that encode our expectations on the characteristics of these parts along with a model architecture that allows for these priors to be implemented. We design a model, based on a Convolutional Neural Network (CNN) back-bone, which discovers discriminative parts of objects by be-ing forced to use the discovered parts as a bottleneck for fine-grained classification. The fine-grained setting ensures a high level of similarity between classes, enabling the pos-sibility of discovering semantic parts that are shared by mul-tiple classes. In our part bottleneck, class logits are inde-pendently extracted from each of the discovered parts be-fore being combined for the final classification, along with a dropout layer that affects whole parts at a time, ensures that all discovered parts are relevant to classification. 2.