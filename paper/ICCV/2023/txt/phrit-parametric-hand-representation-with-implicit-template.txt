Abstract
We propose PHRIT, a novel approach for parametric hand mesh modeling with an implicit template that com-bines the advantages of both parametric meshes and im-plicit representations. Our method represents deformable hand shapes using signed distance fields (SDFs) with part-based shape priors, utilizing a deformation field to exe-cute the deformation. The model offers efficient high-fidelity hand reconstruction by deforming the canonical template at infinite resolution. Additionally, it is fully differentiable and can be easily used in hand modeling since it can be driven by the skeleton and shape latent codes. We evaluate PHRIT on multiple downstream tasks, including skeleton-driven hand reconstruction, shapes from point clouds, and single-view 3D reconstruction, demonstrating that our approach achieves realistic and immersive hand modeling with state-of-the-art performance. 1.

Introduction
The human hand plays a vital role in communication and interaction, making high-fidelity hand modeling crucial for
†Equal contributions.
∗Corresponding author. immersive applications, especially in the era of digital twins and metaverses. High-fidelity hand modeling can facilitate immersive applications such as virtual meetings and video games. However, to drive these real-time applications, it’s essential to achieve realistic reconstruction results, ensure stable cross-user generalization, and optimize the recon-struction process for efficiency.
Previous research on hand geometry modeling can be divided into two broad categories: parametric meshes and implicit representations. Parametric meshes rely on a pre-defined mesh template that is deformed to match posed hands [32, 44, 61]. While this approach is efficient and provides useful dense correspondence between the recon-structed hand and the canonical template [21, 60], it re-quires careful supervision to learn the deformation of each vertex. This can be difficult and expensive, as noted in [32].
This challenge has led previous work to either sacrifice res-olution [61] or resort to leveraging weak supervisions [44], which may limit the model’s generalization to personalized settings. In contrast, recent implicit representations [13, 26] take a different approach to hand geometry modeling by fo-cusing on the continuous representation of static shapes. By learning implicit functions such as signed distance and oc-cupancy fields, they can represent high-fidelity, resolution-Method
Diff.
Effi.
Corres.
Conti. non-rigidity of the deformation.
Parametric Hand Meshes
Implicit Hand Representation
PHRIT (Ours)
✔
✔
✔
✔
✘
✔
✔
✘
✔
✘
✔
✔
Table 1: A comparison of PHRIT with parametric hand meshes and implicit hand representation in terms of some key properties.
Diff.: whether the reconstruction is differentiable. Effi.: whether reconstruction is efficient without onerous pose-processing such as Marching Cubes [36]. Corres.: whether dense correspondences are maintained during reconstruction. Conti.: whether this repre-sentation is continuous in the output space. independent shapes. However, the method requires time-consuming post-processing to obtain reconstructions and lacks dense correspondence between the reconstructions.
Overall, both approaches have their strengths and weak-nesses, and neither fully meets the requirements for high fidelity, generalization ability, and efficiency.
To combine the advantages of both paradigms, we pro-pose PHRIT (as shown in Fig. 1), a parametric hand model with an implicit template that can generate high-fidelity hand reconstructions for various poses and identities (i.e., generalization ability) with favorable properties such as dif-ferentiation, correspondence, efficiency, and continuity. As summarized in Table 1, our proposed method combines some key strengths of existing paradigms. We argue that our method achieves continuity to parameterized hand rep-resentations by introducing an implicit representation (i.e., using SDF to represent the hand) while maintaining effi-ciency during inference and maintaining the dense corre-spondences through our novel deformation field to learn per-vertex deformation implicitly.
Specifically, PHRIT learns to deform a canonical hand with theoretically unlimited resolution based on implicit representation. To achieve efficiency and continuity (i.e., high fidelity), we represent the canonical hand with an SDF using a neural network. This means that the canonical hand mesh only needs to be extracted once for all inferences.
Along with the learning of implicit canonical hand, MLPs are utilized to retrieve per-vertex deformation of the canon-ical hand conditioned on both poses and shapes. To learn such deformation, we use real-world 3D hand scans [61] and develop a novel deformation field that bridges the SDF of deformed and canonical hand space to build dense cor-respondences (i.e., per-vertex deformation) implicitly. To improve the generalization towards unseen poses and iden-tities, we adopt a part-based design [15] on deformation learning, but rather eliminate the requirement of ground-truth bone transformation by deriving local coordinate sys-tems directly upon the hand skeleton based on [26]. Addi-tionally, we adopt the locally pose-aware design similar to
[6] on deformation learning to boost generalization. More-over, we propose a skip-connection structure, which is ex-perimentally proven to be more effective in capturing the
In summary, our contributions are:
• We introduce a neural hand model combining paramet-ric meshes and implicit representations to efficiently produce high-fidelity hand reconstruction with full dif-ferentiability to the skeleton and shape latent codes.
• We develop a novel deformation field to learn point-wise deformation and implicitly establish a dense cor-respondence between the canonical hand and its de-formed shape.
• Experiments demonstrate our method achieves state-of-the-art performance in multiple hand modeling tasks, including reconstruction from skeleton, point clouds, and images, resulting in immersive results. 2.