Abstract
Existing face generators exhibit exceptional perfor-mance on faces in small to medium poses (with respect to frontal faces) but struggle to produce realistic results for large poses. The distorted rendering results on large poses in 3D-aware generators further show that the generated 3D face shapes are far from the distribution of 3D faces in reality. We find that the above issues are caused by the training dataset’s pose imbalance. To this end, we present
LPFF, a large-pose Flickr face dataset comprised of 19,590 high-quality real large-pose portrait images. We utilize our dataset to train a 2D face generator that can process large-pose face images, as well as a 3D-aware generator that can generate realistic human face geometry. To better validate our pose-conditional 3D-aware generators, we develop a new FID measure to evaluate the 3D-level performance.
Through this novel FID measure and other experiments, we show that LPFF can help 2D face generators extend their latent space and better manipulate the large-pose data, and help 3D-aware face generators achieve better view consis-tency and more realistic 3D reconstruction results. 1.

Introduction
Since the first introduction by Goodfellow in 2014, gen-erative adversarial networks (GANs) [11] have significantly advanced the performance of 2D high-resolution image generation. GANs can accomplish a variety of down-stream image editing tasks, particularly face modification
[2, 16, 42, 43], thanks to the excellent image quality and se-mantic features in its latent space. Recently, plenty of 3D-aware generators [12, 30, 5, 52, 35, 9, 41, 40] have been pro-posed to learn 3D-consistent face portrait generation from 2D image datasets. 3D-aware generators can describe and represent geometry in their latent space while rendering ob-jects from different camera perspectives using volumetric rendering. Researchers carefully designed generator archi-*Corresponding author.
Figure 1: Image and shape samples generated by EG3D models [5] trained with the same training strategy but us-ing different datasets (our new dataset LPFF and FFHQ for (a) and FFHQ for (b)). The generators are conditioned by the average camera parameters. Shapes are iso-surfaces ex-tracted from the corresponding density fields using march-ing cubes. Our dataset helps reduce distorted, “seam”,
“wall-mounted”, and blurry artifacts exhibited in (b). tectures and training strategies to accelerate training, reduce memory overheads, and increase rendering resolution.
Both the existing 2D and 3D approaches, however, are unable to process large-pose face data. Regarding 2D face generators, those large-pose data are actually outside of their latent space, which prevents them from generating rea-sonable large-pose data, thus causing at least two problems.
First, as shown in Fig. 2 (left), moving the latent code along the yaw pose editing direction will cause it to reach the edge of the latent space before faces become profile. Second, as shown by the results of image inversion in Fig. 2 (right), it is challenging to project large-pose images to the latent space, let alone perform semantic modification on them.
One of the goals of 3D-aware generators is to model realis-tic human face geometry, but existing 3D-aware generators trained on 2D image datasets still have difficulty producing realistic geometry. This issue is more serious when render-Figure 2: StyleGAN2 [22]’s large-pose performance when trained on FFHQ. InterfaceGAN [38] is used to edit the yaw angle of randomly sampled latent codes. We use optimization-based GAN inversion to obtain the latent codes of target large-pose real images. ing the results at extreme poses. As shown in Fig. 3, faces synthesized by those methods have noticeable artifacts, in-cluding distortion, blurring, and stratification. In Fig. 1 (b),
EG3D shows a “wall-mounted” and distorted 3D represen-tation without ears. All these indicate that the generated face shapes are not realistic enough.
The above issues in the face generators are mainly caused by the unbalanced camera pose distribution of the narrow-range training dataset. Flickr-Faces-HQ Dataset (FFHQ) is a popular high-quality face dataset used to train those face generators, but it mainly contains images limited to small to medium poses. As a result, 2D and 3D-aware generators cannot learn a correct large-pose face distribu-tion without sufficient large-pose data. To avoid artifacts under large poses, downstream applications [42, 28, 24, 46, 16, 17, 1, 49] based on those face generators typically sam-ple small poses, which limits their application scenarios.
It is difficult to get a pose-balanced dataset. First, large-pose faces are nearly impossible to detect using Dlib [23], a popular face detector, and the one used to crop FFHQ. Sec-ond, simply replicating extremely limited large-pose data to balance the pose distribution is insufficient to help extend the camera distribution. As a result, it is critical to collect a large number of large-pose, in-the-wild, and high-resolution face images, which are lacking in existing datasets.
In this paper, we propose a novel high-quality face dataset containing 19,590 real large-pose face images, named Large-Pose-Flickr-Faces Dataset (LPFF), as a sup-plement to FFHQ, in order to extend the camera pose dis-tribution of FFHQ and train 2D and 3D-aware face genera-tors that are free of the aforementioned problems. Given the difficulty of large-pose face detection and the imbal-anced distribution of camera poses in real-life photographs, we design a face detection and alignment pipeline that is better suited to large-pose images. Our method can also gather large amounts of large-pose data based on pose den-sity. We retrain StyleGAN2-ada [19] to demonstrate how our dataset can assist 2D face generators in generating and editing large-pose faces. We retrain EG3D [5] as an exam-Figure 3: 3D-aware generators trained on FFHQ (StyleN-eRF [12], StyleSDF [30], EG3D [5], and IDE-3D [42]) achieve excellent image synthesis performance on faces in small to medium poses (Top), but exhibit obvious artifacts at steep angles (Bottom). ple to demonstrate how our dataset can aid 3D face gener-ators in understanding realistic face geometry and appear-ance across a wide range of camera poses.
In order to better evaluate the 3D-level performance of EG3D models trained on different datasets, we propose a new FID mea-sure for pose-conditional 3D-aware generators. Extensive experiments show that our dataset leads to realistic large-pose face generation and manipulation in the 2D generator.
Furthermore, our dataset results in more realistic face ge-ometry generation in the 3D-aware generator.
Our paper makes the following major contributions: 1)
A novel data processing and filtering method that can col-lect large-pose face data from the Flickr website according to camera pose distribution, leading to a novel face dataset that contains 19,590 high-quality real large-pose face im-ages. 2) A retrained 2D face generator that can process large-pose face images. 3) A retrained 3D-aware generator that can generate realistic human face geometry. 4) A new
FID measure for pose-conditional 3D-aware generators. 2.