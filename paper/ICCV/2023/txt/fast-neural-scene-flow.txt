Abstract
Neural Scene Flow Prior (NSFP) is of significant interest to the vision community due to its inherent robustness to out-of-distribution (OOD) effects and its ability to deal with dense lidar points. The approach utilizes a coordinate neural network to estimate scene flow at runtime, without any training. However, it is up to 100 times slower than current state-of-the-art learning methods.
In other applications such as image, video, and radiance function reconstruction innovations in speeding up the runtime performance of coordinate networks have centered upon architectural
In this paper, we demonstrate that scene flow changes. is different—with the dominant computational bottleneck stemming from the loss function itself (i.e., Chamfer distance). Further, we rediscover the distance transform (DT) as an efficient, correspondence-free loss function that dramatically speeds up the runtime optimization. Our fast neural scene flow (FNSF) approach reports for the first time real-time performance comparable to learning methods,
*Part of the work was done while at Argo AI. Corresponding e-mail: xueqian.li@adelaide.edu.au. Code available at https://github.com/Lilac-Lee/FastNSF.git without any training or OOD bias on two of the largest open autonomous driving (AV) lidar datasets Waymo Open [62] and Argoverse [8]. 1.

Introduction
Neural Scene Flow Prior (NSFP) [37] is considered the dominant method in open-world perception [47] and scene densification [37, 69] using lidar (see Fig. 1 (a)). NSFP achieves state-of-the-art scene flow estimates from dense lidar point clouds (up to 150k+ points) and works on a variety of sensor setups with little to no refinement or adaptation. Unlike supervised or unsupervised learning-based methods, NSFP does not require learning from large offline datasets and has no limits on point density (<8k for most learning methods). Instead, it leverages the architecture of a neural network to implicitly regularize the flow estimate and employs a runtime optimization that can easily scale to large out-of-distribution (OOD) scenes, which is a challenge for current learning-based methods [15, 31, 37, 47, 51].
A fundamental drawback, however, to NSFP is the speed of its runtime optimization which is in some instances of orders of magnitude slower than its learning counterparts
(see Fig. 1). As a result, NSFP has widely been used offline for (i) providing scene flow supervision for efficient learning methods and (ii) as a pre-processing step for training open-world perception systems [47]. However, the considerable computational cost of NSFP limits its current applications only to these offline tasks.
A central narrative of our approach is that the dominant computational burden in runtime scene flow optimization (NSFP) is not the network architecture, but the loss function— specifically Chamfer distance (CD) [17]. This differs considerably from other applications of coordinate networks throughout vision and learning such as neural radiance fields (NeRF [44]) and high-fidelity image reconstruction ( [61]) which have gained significant speedups through architectural innovations [83]. A visual depiction of this discrepancy can be found in Fig. 1 (b).
Key to our approach is the use of correspondence-free loss function—distance transform (DT) [5, 13, 58] as a proxy for the computationally expensive CD loss. Even though
DT has been extensively studied by the graphics and vision community over a few decades, its application as an efficient loss function in deep geometry has largely been overlooked up until this point. We believe that the inherent efficiencies of the DT are especially pertinent for runtime network training such as in NSFP. Our approach shares similarities with
Plenoxels [81]—a recent approach for efficient radiance field estimation using coordinate networks—as we trade memory consumption for computation time, allowing for significant speedups during runtime, which provides an alternative solution when exploring more efficient loss functions for dense scene flow estimation. We differ from Plenoxels, however, in that our memory consumption stems from our proposed loss function, not the neural architecture itself. for the first
In this paper, we present time an approximately real-time (for 8k points) runtime optimization method as computationally efficient as leading learning methods whilst preserving the scalability to dense point clouds and state-of-the-art performance on OOD scenes like
NSFP. We compare the performance and the computation time of our approach on two of the largest open lidar AV datasets available: Waymo Open [62] and Argoverse [8]. Our fast neural scene flow achieves up to ∼30 times speedup than
NSFP [37] (our faster implementation) and of comparable speed to leading learning-based methods (see Fig. 1 (c)) with the same number of points (8,192). It opens up the possibility of employing a fast, robust, and generalizable approach for dense scene flow, which is not prone to OOD effects in real-time vision and robotic applications. 25,27,28,36,53] formulate an optimization problem utilizing
RGB or depth information, and learning-based RGB/RGB-D methods [6, 29, 30, 57, 60, 64, 78] rely on single/multiple image features which encode with a large amount of data supervisions. On the other hand, to estimate scene flow directly from 3D, traditional point cloud-based methods [1, 11, 50] solve for a non-rigid registration problem, while recent work prefers full-supervised learning [23,34,38,39,52, 71, 73, 75] that uses point-based features or self-supervised learning [3, 21, 45, 65, 75] that employs a self-supervised loss. Recent non-learning-based methods [37, 51] draw our attention back to runtime optimization that easily scales to large data. Graph prior [51] explicitly builds a graph on the point cloud and uses a graph Laplacian regularizer. While neural scene flow prior [37] uses the network as an implicit regularizer to smooth motions. In this paper, we explore point cloud-based scene flow using runtime optimization.
Accelerating coordinate networks. There exists a line of work [9, 20, 26, 46, 56, 81, 82] that focuses on accelerating coordinate networks by trading slow, memory efficient, deep network architectures for fast, memory hungry, shallow architectures. Most of these innovations have been applied to the problem of neural radiance fields most notably
Plenoxels [81] and TensorRF [9]. Recently, this trend was generalized for arbitrary signals through the introduction of complex positional encoding [83] with shallow linear networks. In this paper, we claim that these architectural innovations have little utility in speeding up neural scene flow without first addressing the computational cost of the
Chamfer loss it uses.
Distance transform. DT [4, 5, 13, 41, 58] has played an important role in image processing, especially binary image analysis [48, 66]. Further applications are also found in medical image segmentation [12, 33, 59, 70, 72], robotics motion planning [55,76], geometric representation [7,10,49], and accelerated point cloud registration [19, 79]. Among them, various distance measures have been used, such as city block, chessboard, and Euclidean distance [13, 77].
Naturally, Euclidean distance is preferred in computing point distance but it is also the most difficult metric to compute due to the temporal complexity [22]. Many work attempts to speedup Euclidean DT computation including raster-scan-based algorithms [5, 18, 35, 41, 54], fast marching-based algorithms [16, 40, 68], etc., and has achieved linear time computation. In this paper, we investigate the raster-scan-based algorithm for the 3D point cloud. 3. Approach 2.