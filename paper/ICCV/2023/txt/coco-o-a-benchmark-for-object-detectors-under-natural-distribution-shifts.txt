Abstract
Practical object detection application can lose its effec-tiveness on image inputs with natural distribution shifts.
This problem leads the research community to pay more attention on the robustness of detectors under Out-Of-Distribution (OOD) inputs.
Existing works construct datasets to benchmark the detector’s OOD robustness for a speciﬁc application scenario, e.g., Autonomous Driving.
However, these datasets lack universality and are hard to benchmark general detectors built on common tasks such as COCO. To give a more comprehensive robustness as-sessment, we introduce COCO-O(ut-of-distribution), a test dataset based on COCO with 6 types of natural distribu-tion shifts. COCO-O has a large distribution gap with training data and results in a signiﬁcant 55.7% relative performance drop on a Faster R-CNN detector. We lever-age COCO-O to conduct experiments on more than 100 modern object detectors to investigate if their improve-ments are credible or just over-ﬁtting to the COCO test set. Unfortunately, most classic detectors in early years do not exhibit strong OOD generalization. We further study the robustness effect on recent breakthroughs of de-tector’s architecture design, augmentation and pre-training techniques.
Some empirical ﬁndings are revealed: 1)
Compared with detection head or neck, backbone is the most important part for robustness; 2) An end-to-end de-tection transformer design brings no enhancement, and may even reduce robustness; 3) Large-scale foundation models have made a great leap on robust object detec-tion. We hope our COCO-O could provide a rich testbed for robustness study of object detection. The dataset will be available at https://github.com/alibaba/ easyrobust/tree/main/benchmarks/coco_o. 1.

Introduction
Deep learning has achieved tremendous success in the
ﬁeld of computer vision. As a prerequisite, Deep Neural
Networks (DNNs) rely on a rigorous assumption that train-This research is supported in part by the National Key Research and
Development Program of China under Grant No.2020AAA0140000.
ing and testing data are independent and identically dis-tributed. This ideal hypothesis is hardly satisﬁed in real-world applications, where the model may encounter data with distribution drift due to environmental changes, result-ing in a signiﬁcant decrease in performance and posing po-tential security issues. To solve this problem, the robustness study [37, 57, 74, 10] of DNNs under distribution shifts has emerged in the research area of image classiﬁcation.
However, most robustness researches merely focus on classiﬁcation, and do not pay equal attention to other vi-sion tasks, such as object detection. This phenomenon can be attributed to the lack of benchmark datasets.
In con-trast with holistic benchmarks [40, 63, 78, 38, 3] on Ima-geNet classiﬁcation, the detection robustness benchmarks are limited. Previous work [58] benchmarks robustness using synthetic corruptions, however, it remains unclear if such simulated data can approximate real-world scenar-ios. Thus some other works collect images from internet to construct datasets. [16, 45, 36, 50, 98] use road scene datasets [89, 17, 44, 25] to benchmark domain generaliza-tion of detectors. Such scene-speciﬁc dataset lacks univer-sality and domain diversity, leading to a biased assessment of robustness. For evaluation on common tasks,
[95, 43] collect natural OOD images based on PASCAL VOC [21].
However, VOC is a small-scale detection task with limited number of categories, which has lagged behind the current standard evaluation protocol, e.g. COCO [53], LVIS [31] for detectors. We argue that more comprehensive and chal-lenging benchmarks should be proposed to measure natural
OOD robustness of modern detectors in 2020s.
In this work, we present COCO-O, a novel test dataset for COCO detection task which benchmarks robustness of object detectors under natural distribution shifts. COCO-O consists of 6,782 online-collected images belonging to 6 test domains: sketch, weather, cartoon, painting, tattoo and handmake. We compare our COCO-O with previous ro-bust detection benchmarks in Table 1. Compared to VOC-related datasets, our COCO-O is more comprehensive with richer types of OOD shifts and larger dataset scale. COCO-O is fully compatible with the modern COCO evaluation protocol. Moreover, compared with COCO-related bench-marks, COCO-O is more challenging and can lead to 55.7% relative performance drop on a Faster R-CNN detector. By calculating the Fr´echet Inception Distance (FID) [41] to clean distribution, we show our COCO-O (with FID=132) has larger distribution shifts than COCO-C [58].
Taking advantage from the proposed COCO-O, we ad-ditionally contribute extensive experiments on more than 100 modern object detectors to investigate the credibility of their reported improvements and whether they are just over-ﬁtting to the COCO test set. An overview of some key re-sults is shown in Figure 1. Through a more precise Effective
Robustness (ER) metric [1] which eliminates extra impact
Datasets
OOD Class Natural
Images
Types Num.
Performance
Drop (%)
FID
VOC Scale Robustness Benchmarks
OOD-CV [95]
Clipart1k [43]
Watercolor2k [43]
Comic2k [43] 5 1 1 1
#
#
#
#
COCO Scale Robustness Benchmarks 2,632 1,000 2,000 2,000 10 20 6 6 26.6% 59.8% 39.1% 71.5%
COCO-C [58]
COCO-O (Ours) 15 6 80 80 0⇤ 6,782 49.8% 55.7%
#
# 91 148 113 147 41 132
Table 1: Overview of existing general robust detection benchmark. ⇤Note that COCO-C has only synthetic images. brought by the variance of ID performance, we make a frus-trating observation that most classic detectors have no great progress on robustness. However, recent breakthroughs in Visual Transformers (ViTs) [19] and large-scale vision foundation models have brought new hope for OOD robust-ness. Especially, zero-shot detectors [48, 20] pre-trained with massive image-language pairs exhibit great effective-ness on our COCO-O. Our results inspire future research to explore training data scaling or fusing external knowl-edge of human language to achieve more robust detection.
Besides, we analyse how OOD robustness is inﬂuenced by detector architecture, augmentation, pre-training, etc. Some interesting ﬁndings are revealed, which can be summarized as: 1) Compared with the detection head or neck, backbone is the most important part for detector’s robustness. Our empirical study shows scaling up backbone model or using advanced backbone design, e.g. ResNeXt [87], Swin [56] can bring greater robustness gains. 2) Detection transform-ers [7, 99] are more vulnerable than traditional non-end-to-end detectors under natural distribution shifts. Note that it is different from the previous experience [61, 2, 59] in clas-siﬁcation tasks, where ViTs are regarded as a robust learner.
We hope our COCO-O could provide a rich testbed for ro-bustness study of object detection, and we appeal that de-tection algorithms proposed in future should also evaluate their OOD generalization ability.
Our contributions are summarized below:
• We propose COCO-O, the ﬁrst COCO-scale test dataset for evaluating the robustness of detectors un-der natural distribution shifts.
• We benchmark the robustness of 100+ modern detec-tors and provide a thorough comparison in Section 4.
• Through analysing the impact factors of detector’s ro-bustness. We reveal some ﬁndings in Section 4.1 that can help to develop more robust detection algorithms. 2.