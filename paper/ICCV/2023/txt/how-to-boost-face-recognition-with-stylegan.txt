Abstract
State-of-the-art face recognition systems require vast amounts of labeled training data. Given the priority of privacy in face recognition applications, the data is lim-ited to celebrity web crawls, which have issues such as limited numbers of identities. On the other hand, self-supervised revolution in the industry motivates research on the adaptation of related techniques to facial recogni-tion. One of the most popular practical tricks is to augment the dataset by the samples drawn from generative models while preserving the identity. We show that a simple ap-proach based on fine-tuning pSp encoder for StyleGAN al-lows to improve upon the state-of-the-art facial recognition and performs better compared to training on synthetic face identities. We also collect large-scale unlabeled datasets with controllable ethnic constitution – AfricanFaceSet-5M (5 million images of different people) and AsianFaceSet-3M (3 million images of different people) – and we show that pretraining on each of them improves recognition of the respective ethnicities (as well as others), while com-bining all unlabeled datasets results in the biggest per-formance increase. Our self-supervised strategy is the most useful with limited amounts of labeled training data, which can be beneficial for more tailored face recognition tasks and when facing privacy concerns. Evaluation is based on a standard RFW dataset and a new large-scale
RB-WebFace benchmark. The code and data are made pub-licly available at https://github.com/seva100/ stylegan-for-facerec. 1.

Introduction
Modern face recognition methods rely on deep convo-lutional networks trained on large-scale datasets [54, 7, 23, 60]. These methods are now being integrated into a vast number of real-world applications, ranging from face unlock for smartphones and photo organizers to law en-forcement systems and border control. A typical open face recognition dataset consists of web-crawled images of celebrities, leading to limited size and lack of bal-ance in subgroups, such as ethnicity, age, etc. Train-ing a state-of-the-art solution, however, requires enormous amounts of labeled data, scraping which may lead to pri-vacy and legal issues. We suggest and study an alterna-tive solution to using celebrity photos – pretraining the face recognition backbone on a generative task. Specif-ically, we first train StyleGAN2-ADA [29] on collected
Figure 2: Our method is trained in three consecutive steps. First, we fit StyleGAN2-ADA to the face image distribution of the unlabeled prior dataset Dprior. Second, the pSp encoder is trained (also on Dprior) to map images to the latent codes in the learned latent space. Finally, the encoder, which is pretrained to extract meaningful features from an image, is fine-tuned for the downstream face recognition task with the ArcFace loss (similar losses can be used instead) on Df acerec. The two first steps comprise the self-supervised pretraining stage; i.e., no identity labels are required for them.
We show that, unlabeled data (which we later refer to as an unlabeled prior dataset) to fit the face image distribution. Subsequently, we train an encoder (following pixel2style2pixel (pSp) ar-chitecture [41]) that maps input images to vectors in the
Importantly, dur-learned StyleGAN2-ADA latent space. ing the pretraining steps, no identity labels are used, so we can use diverse datasets crawled from the Internet without compromising privacy. Finally, we transfer the learned pSp encoder convolutional weights into the face recognition net-work and train it in a standard face recognition setup. in contrast to training face recogni-tion tasks on StyleGAN generated data (also demonstrated in [38, 39] and studied e.g. in [36]), our encoder pretraining step significantly boosts the final performance. The idea of augmenting face recognition datasets with synthetic data is widespread and constitutes many approaches, however, un-clear and heuristic definition of the target label limits the amount of useful signal that can be transferred into the face recognition model this way. Our approach goes hand-in-hand with the current development of self-supervised learn-ing [15, 35, 12, 16] and makes up one of the first approaches of its application to face recognition [26, 33]. This allows us to demonstrate vast improvements on limited labeled train-ing data compared to the setup without self-supervised pre-training (for instance, 10% verification accuracy increase for only 1% of the labeled data used).
The simplicity of the data collection procedure also al-lows us to control the distribution of the unlabeled data and thus influence the decrease of the error rates for specific de-mographic groups. Despite the fact that the current state-of-the-art algorithms often demonstrate very low average error rates [13, 47, 51, 48], it is considered unethical to inte-grate face recognition solutions that exhibit significant eth-nic, age, or gender bias. Such bias is present both in open-source face recognition methods [20, 53, 49, 19, 28, 44, 46] and in comprehensively evaluated commercial face recog-nition systems [22], resulting in significantly different error rates measured for the groups of interest. The topic has at-tracted significant attention in other areas of computer vi-sion operating in face domain [8, 14, 21, 40] and in the me-dia.
We constructively demonstrate that collecting large amounts of in-the-wild face images of a given group of interest is feasible (and can be done semi-automatically), while collecting datasets with identity labels is problem-atic. The labels require linking photos of the same per-son taken in different conditions, which means the person must be tracked. This typically constrains public datasets to celebrities, gathered using search engines [23, 54, 7, 60], while social networks and companies that provide services with photos use input from users. Second, the collected in-the-wild data, treated as a set of faces without identity labels (but labeled with the group attribution), can be effi-ciently used for self-supervised pretraining for face recogni-tion networks, subsequently fine-tuned on the standard face recognition datasets (see Fig. 1).
To summarize our main contribution, we present a novel self-supervised method for improving the performance of face recognition based on StyleGAN pretraining. This al-lows to leverage large-scale amounts of available unlabeled data for face recognition. While the improvement is the most significant on limited data, pretraining is also helpful for large-scale labeled datasets. 2.