Abstract 1.

Introduction
NeRFs have enabled highly realistic synthesis of human faces including complex appearance and reflectance effects of hair and skin. These methods typically require a large number of multi-view input images, making the process hardware intensive and cumbersome, limiting applicability to unconstrained settings. We propose a novel volumetric human face prior that enables the synthesis of ultra high-resolution novel views of subjects that are not part of the prior’s training distribution. This prior model consists of an identity-conditioned NeRF, trained on a dataset of low-resolution multi-view images of diverse humans with known camera calibration. A simple sparse landmark-based 3D alignment of the training dataset allows our model to learn a smooth latent space of geometry and appearance despite a limited number of training identities. A high-quality vol-umetric representation of a novel subject can be obtained by model fitting to 2 or 3 camera views of arbitrary resolu-tion. Importantly, our method requires as few as two views of casually captured images as input at inference time.
Reconstruction and novel view synthesis of faces are challenging problems in 3D computer vision. Achieving high-quality photorealistic synthesis is difficult due to the underlying complex geometry and light transport effects ex-hibited by organic surfaces. Traditional techniques use ex-plicit geometry and appearance representations for model-ing individual face parts such as hair [14], skin [17], eyes
[4], teeth [59] and lips [16]. Such methods often require specialised expertise and hardware and limit the applica-tions to professional use cases.
Recent advances in volumetric modelling [3, 26, 31, 48] have enabled learned, photorealistic view synthesis of both general scenes and specific object categories such as faces from 2D images alone. Such approaches are particularly well-suited to model challenging effects such as hair strands and skin reflectance. The higher dimensionality of the vol-umetric reconstruction problem is inherently more ambigu-ous than surface-based methods. Thus, initial developments in neural volumetric rendering methods [3, 31] relied on an order-of-magnitude higher number of input images (> 100) 1
Figure 2. Our key contribution is a prior face model (left), learned from a multiview dataset of faces captured in a controlled setting. The prior model is resolution independent and can be fine-tuned to synthesise novel views at high resolution given as few as two images from a target identity captured in the studio (middle left) or in-the-wild (middle right). to make the solution tractable. Such a large image acqui-sition cost limits application to wider casual consumer use cases. Hence, few-shot volumetric reconstruction, of both general scenes and specific object categories such as human faces, remains a prized open problem.
This problem of the inherent ambiguity of volumetric neural reconstruction from few images has generally been i) Regularisation: using natural approached in 3 ways: statistics to constrain the density field better such as low entropy [3, 46] along camera rays, 3D spatial smooth-ness [35] and deep surfaces [66] to avoid degenerate so-lutions such as floating artifacts; ii) initialisation: meta-learnt initialisation [53] of the underlying representation (network weights) to aid faster and more accurate conver-gence during optimisation; iii) data-driven subspace pri-ors: using large and diverse datasets to learn generative
[7, 9, 10, 12, 13, 18, 68] or reconstructive [6, 44, 46, 57] priors of the scene volume.
For human faces, large in-the-wild datasets [21, 22, 25] have proved to be particularly attractive in learning a smooth, diverse, and differentiable subspace that allow for few-shot reconstruction of novel subjects by performing in-version and finetuning of the model on a small set of im-ages of the target identity [47]. But such general datasets i) and generative models also suffer from disadvantages:
The sharp distribution of frontal head poses in these datasets prevents generalisation to more extreme camera views, and ii) the computational challenge of training a 3D volume on such large datasets results in very limited output resolutions.
In this paper, we propose a novel volumetric prior for faces that is learned from a multi-view dataset of diverse r o i r
P o
/
W r o i r
P h t i
W
Input
Training Result
Novel Views
Figure 3. Naively training on two images leads to overfitting and the model fails to synthesise novel views. With the proposed prior, the model can render view-consistent novel views. human faces. Our model consists of a neural radiance field (NeRF) conditioned on learnt per-identity embeddings trained to generate 3D consistent views from the dataset.
We perform a pre-processing step that aligns the geometry of the captured subjects [46]. This geometric alignment of the training identities allows our prior model to learn a con-tinuous latent space using only image reconstruction losses.
At test time, we perform model inversion to compute the embedding for a novel target identity from the given small set of views of arbitrary high resolution. In an out-of-model finetuning step, the resulting embedding and model are fur-ther trained with the given images. This results in NeRF model of the target subject that can synthesise high-quality images. Without our prior, the model cannot estimate a 3D consistent volume and overfits to the sparse training views (Fig. 3).
While we present a novel data-driven subspace prior, we also extensively evaluate the role of regularisation and ini-tialisation in achieving plausible 3D face volumes from few images by comparing with relevant state-of-the-art tech-niques and performing design ablations of our method.
In summary, we contribute:
• A prior model for faces that can be finetuned to gen-erate a high-quality volumetric 3D representation of a target identity from two or more views.
• Ultra high-resolution 3D consistent view-synthesis (demonstrated up to 4k resolution).
• Generalisation to in-the-wild indoor and outdoor cap-tures, including challenging lighting conditions. 2.