Abstract
Priors are essential for reconstructing images from noisy and/or incomplete measurements. The choice of the prior determines both the quality and uncertainty of recovered images. We propose turning score-based diffusion models into principled image priors (“score-based priors”) for an-alyzing a posterior of images given measurements. Previ-ously, probabilistic priors were limited to handcrafted reg-ularizers and simple distributions. In this work, we empir-ically validate the theoretically-proven probability function of a score-based diffusion model. We show how to sam-ple from resulting posteriors by using this probability func-tion for variational inference. Our results, including exper-iments on denoising, deblurring, and interferometric imag-ing, suggest that score-based priors enable principled in-ference with a sophisticated, data-driven image prior. 1.

Introduction
Priors are crucial for solving inverse problems in compu-tational imaging, which tend to be ill-posed due to noisy and limited sensors. When many different images agree with observed measurements, a prior helps constrain solutions according to desired image statistics. How to incorporate a sophisticated prior, however, is not straightforward. Our work addresses the problem of incorporating a rich prior into principled approaches to inverse problems.
Previous work poses a tradeoff: using principled meth-ods requires simple priors, while using deep-learned pri-ors precludes precise analysis. On the principled side,
Bayesian-inference methods model the posterior distribu-tion of images x conditioned on measurements y: p(x y)
|
∝ p(y
| x) p(x).
This Bayesian framework supports a modular approach to inverse problems where the likelihood p(y x) is defined by an expert based on knowledge of how measurements are obtained, and the prior p(x) is defined independently. Fur-thermore, it allows for principled solutions. Maximum a posteriori (MAP) estimation can be done by optimizing the posterior probability. Posterior sampling, which is useful
|
for uncertainty quantification, can be done with MCMC or variational inference. But since such methods require the value or gradient of p(x), they have been limited to simple priors (e.g., Gaussian) and weighted regularizers (e.g., total variation). In practice, the relative weights of the prior and likelihood terms are usually tuned by hand, introducing a human bias that is unsatisfactory for scientific applications.
On the deep-learning side, solutions leveraging an im-plicit, deep-learned prior may look convincing but do not lend themselves to principled analysis. For example, a con-volutional neural network (CNN) can be trained in a su-pervised way to output images given measurements, but its prior cannot be probed and does not generalize to new tasks. Recent work shows how to condition a diffusion model — a type of generative model whose prior is cap-tured in a learned image denoiser — on arbitrary measure-ments [13, 14, 15, 16, 27, 66, 69], but the methods depend on hand-tuned hyperparameters and do not sample from a true posterior except in auspicious cases. To get the best of both worlds (traditional Bayesian inference and modern deep learning), we need a way to incorporate the expressive prior of a deep-learned model into a traditional, principled
Bayesian-inference approach.
We propose employing a diffusion model as the prior in Bayesian inference for imaging. A score-based prior is the distribution under a score-based diffusion model [70], which has been proven to allow for exact probabilities (a feature under-explored in practice). In this paper, we first review related work and then investigate the probability function, including empirical validation of its accuracy.
The main contribution of this paper is establishing score-based priors as an interface between modern deep-learning and traditional inverse problem-solving, giving proven, principled approaches direct access to learned, rich priors.
Under our framework, we train a score-based prior once on a dataset of images. Paired with any likelihood p(y x), this prior can be plugged into any inference algorithm that uses the value or gradient of the posterior. We demonstrate this with an existing variational-inference approach for pos-terior sampling and show results for three inverse problems: denoising, a version of deblurring, and interferometry. In-terferometry is used for black-hole imaging (Fig. 1) and highlights the benefits of score-based priors for scientific applications, which call for exact posterior sampling given standalone priors to accurately quantify uncertainty.
| 2.