Abstract
While bird’s-eye-view (BEV) perception models can be helpful in building high-definition maps (HD maps) with less human labor, their results are often unreliable and demonstrate noticeable inconsistencies in the predicted HD maps from different viewpoints. This is because BEV per-ception is typically set up in an “onboard” manner, which restricts the computation and prevents algorithms from si-multaneously reasoning multiple views. This paper over-comes these limitations and advocates a more practical
“offboard” HD map generation setup that removes the com-putation constraints, based on the fact that HD maps are commonly reusable infrastructures built offline in data cen-ters. To this end, we propose a novel offboard pipeline called MV-Map that capitalizes multi-view consistency and can handle an arbitrary number of frames with the key de-sign of a “region-centric” framework. In MV-Map, the tar-get HD maps are created by aggregating all the frames of onboard predictions, weighted by the confidence scores as-signed by an “uncertainty network.” To further enhance multi-view consistency, we augment the uncertainty net-work with the global 3D structure optimized by a voxelized neural radiance field (Voxel-NeRF). Extensive experiments on nuScenes show that our MV-Map significantly improves the quality of HD maps, further highlighting the importance of offboard methods for HD map generation. Our code and model are available at https : //github.com/
ZiYang-xie/MV-Map. 1.

Introduction
High-definition maps (HD maps) play a crucial role in ensuring the safe navigation of autonomous vehicles, by providing essential positional and semantic information about road elements.
Ideally, one would expect the pro-cess of constructing HD maps to be as simple as collect-ing numerous sensory data while driving and then utiliz-ing an automatic algorithm to extract the road elements,
*Equal contribution.
Figure 1: Current onboard methods generate unreliable HD map predictions that are inconsistent across multiple views, due to occlusions or viewpoint changes. By contrast, our offboard pipeline constructs a unified and multi-view con-sistent HD map with clearer lanes. Our key design is a region-centric framework that aggregates single-frame in-formation for each target HD map region. as illustrated in Fig. 1. However, the mainstream solutions generally involve human annotators, as seen in widely-used datasets [3, 4, 8, 39]. This design is based on the consider-ation of the infrastructure role and high re-usability of HD maps, which can serve autonomous vehicles for virtually infinite times after a single construction process before any environmental changes. Even so, the expense of manual annotation obstructs the expansion of autonomous driving to new locations, and we aim to develop reliable algorithms that can decrease or replace the need for human labor in HD map construction.
Towards this goal, there have been recent attempts that automatically generate HD maps using bird’s-eye-view (BEV) perception [11, 13, 15]. However, their results are often unreliable, as illustrated by noticeable inconsistencies in the predicted HD maps from different viewpoints (a rep-resentative example is in Fig. 1). We argue that multi-view consistency is an intrinsic property of HD maps, because the rigid and static HD maps shouldn’t change significantly after simply switching viewpoints. The violations of con-sistency arise from the fact that existing BEV perception
average of HD map patches guided by the confidence.
We further enhance the consensus among all the frames by augmenting the uncertainty network with cross-view consistency information. Our key insight is to learn a co-herent 3D structure from diverse views and provide it as an auxiliary input to the uncertainty network. For this purpose, we exploit neural radiance fields (NeRFs) [22], a state-of-the-art approach that represents 3D structures of scenes. As shown in Fig. 2, our NeRF model synthesizes a high-quality scene structure. Compared with alternative 3D reconstruction strategies like structure from motion (e.g.,
COLMAP [34]), NeRF is more preferred from a practi-cal perspective, because its runtime grows linearly with the frame number, whereas COLMAP increases quadratically.
Moreover, NeRF is fully self-supervised and does not re-quire additional annotations, unlike multi-view stereo meth-ods such as MVSNet [44]. To improve the scalability of
NeRF, we leverage a voxelized variant of NeRF (Voxel-NeRF) to promote efficiency and propose loss functions that implicitly guide the concentration of NeRF on the near-ground geometry related to HD map generation. Addition-ally, we highlight NeRF’s flexibility and scalability to an ar-bitrary number of views, making it critical in offboard HD map generation.
To summarize, we make the following contributions: 1. We are the first to study the problem of learning to gen-erate HD maps offboard, and we are also the first vision-oriented offboard study to our best knowledge. 2. We propose an effective region-centric framework MV-Map that can generate a multi-view consistent HD map from an arbitrarily large number of frames. 3. We introduce and extend Voxel-NeRF to encode the 3D structure from all frames for HD map generation tasks, further guiding the fusion for multi-view consistency.
Large-scale experiments on nuScenes [3] show that MV-Map significantly improves HD map quality. Notably, MV-Map can effectively utilize an increasing number of input frames, making it attractive for real-world applications. 2.