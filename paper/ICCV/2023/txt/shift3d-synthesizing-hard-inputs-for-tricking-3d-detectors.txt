Abstract
Baseline Car
Challenging Car
We present SHIFT3D, a differentiable pipeline for gen-erating 3D shapes that are structurally plausible yet chal-lenging to 3D object detectors. In safety-critical applica-tions like autonomous driving, discovering such novel chal-lenging objects can offer insight into unknown vulnerabili-ties of 3D detectors. By representing objects with a signed distanced function (SDF), we show that gradient error sig-nals allow us to smoothly deform the shape or pose of a 3D object in order to confuse a downstream 3D detector.
Importantly, the objects generated by SHIFT3D physically differ from the baseline object yet retain a semantically rec-ognizable shape. Our approach provides interpretable fail-ure modes for modern 3D object detectors, and can aid in preemptive discovery of potential safety risks within 3D per-ception systems before these risks become critical failures. 1.

Introduction
As 3D computer vision models become ubiquitous in real-world applications, their reliability becomes a critical safety concern should they fail in undetected or unaddressed ways. Autonomous vehicles, for example, rely heavily on 3D vision, and failures on the road within these systems can lead to collisions and other dangerous events.
Like most statistical models, contemporary 3D detec-tors are typically susceptible to failure on rare or unknown events encountered in the real world. Most solutions in the
ﬁeld tend to be reactive, with more data being collected a posteriori [6, 10, 25] or models being ad-hoc retrained to target speciﬁc already-labeled data [5, 16]. However, when a single failure can lead to loss of life on the road, there is an urgent need for detecting these failures in a proactive way. Therein lies one of the central challenges of deploying safe AI in practice: a model trained on a ﬁnite dataset can
*hongge.chen@getcruise.com
†yuning.chai@getcruise.com
SHIFT3D
Detected  (Score=0.91)
Not Detected   (Score=0.04) 3D Scene (BEV) 3D Scene (BEV)
Figure 1: SHIFT3D creates challenging 3D objects from a baseline real object and inserts them with realistic occlu-sions into a point cloud scene. We also synthesize occlu-sion patterns, therefore the synthetic objects can be placed in various locations in the scene. perform poorly on data it has not seen, but by deﬁnition we cannot just collect unknown data to better understand what a model does not know.
In this paper, we propose SHIFT3D (Synthesizing Hard
Inputs for Tricking 3D Detectors), an approach to proac-tively synthesizing hard examples for 3D object detection through generative modeling. SHIFT3D works by per-turbing pre-existing objects into hard examples for 3D vi-sion models, and as we demonstrate, works well in the au-tonomous driving setting. The perturbative approach pro-vides multiple beneﬁts for us: we can explore new parts of the input distribution which are not explicitly represented by the training data, and the perturbation in the shape space allows us to interpret precisely what changes in shape are most salient in making the example challenging. Since in-terpretability is a key beneﬁt of this process, it is also impor-tant for these perturbations to be naturalistic, with changes easily recognizable by the human eye. We use naturalistic
primarily to contrast with the traditional adversarial class of perturbations [21, 29, 9, 17], where minuscule changes produce data that challenges the deep model, but which are imperceptible to the human eye and thus not very helpful for diagnosing model scalability issues in the real world.
Like traditional methods of adversarial attack [9], we use gradients as our primary signal to generate challeng-ing input deformations which then confuse the downstream model. However, unlike traditional methods of adversar-ial attack, our method creates 3D objects with observable changes within the object topology that reﬂect meaningful challenges to the downstream model. To ensure this prop-erty, we perform gradient perturbations not on the 3D object directly but only in an appropriate latent space, and allow a decoder to interpret the perturbed latent space into a ﬁnal 3D object. In this work, the decoder is a pre-trained signed distance function (SDF) network [18], which is a popular model to decode a latent vector into a 3D surface. Addi-tionally, we can also perturb the pose of the object without shape deformation. Our synthesized examples are also ro-bust to background scene choice and to insertion location, making it easy to turn a challenging SHIFT3D object into a fully realized challenging scene.
SHIFT3D operates as follows: a baseline object is taken from some reference mesh and we obtain a latent encoding z for the baseline object from a pretrained DeepSDF [18] model. The DeepSDF object is then placed in a new point cloud at pose θ (position and orientation), with postprocess-ing to add occlusions so the insertion will look physically plausible. This new scene is sent through a pretrained 3D object detector, which assigns a detection score to the in-serted object. This pipeline allows us to differentiate the detection score all the way back to the DeepSDF shape en-coding z, along with the pose parameters θ. We then ﬁnd the gradients that maximize the detection error and apply these perturbations to the latent encoding as well as to θ, which we then decode into a ﬁnal 3D object. Whether we change z (shape) or θ (pose), we will demonstrate that these
ﬁnal 3D objects have reliably low detection scores and vi-sually look substantially different from the baseline object.
Our main contributions within this work are as follows:
• We introduce SHIFT3D, a pipeline to generate chal-lenging 3D objects and insert them with realistic oc-clusions into a point cloud scene.
• We show that SHIFT3D can be made fully differen-tiable through an implicit differentiation setup, which can extend perturbations beyond the shape of the 3D object and to its placement geometry as well.
• We test SHIFT3D in the autonomous driving setting, and show that the objects generated by SHIFT3D con-sistently mislead our LiDAR-based 3D detector and are robustly transferable between different locations within a scene and different scenes as well. 2.