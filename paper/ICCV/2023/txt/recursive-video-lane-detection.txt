Abstract
A novel algorithm to detect road lanes in videos, called recursive video lane detector (RVLD), is proposed in this paper, which propagates the state of a current frame recur-sively to the next frame. RVLD consists of an intra-frame lane detector (ILD) and a predictive lane detector (PLD).
First, we design ILD to localize lanes in a still frame. Sec-ond, we develop PLD to exploit the information of the previ-ous frame for lane detection in a current frame. To this end, we estimate a motion ﬁeld and warp the previous output to the current frame. Using the warped information, we reﬁne the feature map of the current frame to detect lanes more reliably. Experimental results show that RVLD outperforms existing detectors on video lane datasets. Our codes are available at https://github.com/dongkwonjin/RVLD. 1.

Introduction
Lane detection is a task to localize lanes in a road scene, which is crucial for either autonomous or human driving.
For lane detection, it is necessary to exploit visual cues of lanes, as illustrated in Figure 1(a). Early methods extract low-level features such as image gradients or colors [1–4].
Recently, deep learning techniques have been developed to cope with challenging scenes. Some of them are based on semantic segmentation [5–9], in which each pixel is clas-siﬁed into either lane category or not. To ensure lane con-tinuity, several techniques have been proposed, including parametric curve modeling [10–14] and keypoint associa-tion [15–17]. However, despite yielding promising results, they may fail to detect less visible lanes, as in Figure 1(b).
To detect such lanes reliably, anchor-based lane detectors
[18–21] have been proposed. They generate a set of lane an-chors, detect lanes through the binary classiﬁcation of each anchor, and then regress the detected ones. However, all these methods detect lanes from still images without con-sidering high inter-frame correlation in a video.
In autonomous driving systems, video frames are cap-tured consecutively. Video lane detection aims to detect lanes in such a video by exploiting inter-frame correlation, (a) (b) (c) (cid:1835)(cid:3047)(cid:2879)(cid:2871) (cid:1835)(cid:3047)(cid:2879)(cid:2870) (cid:1835)(cid:3047)(cid:2879)(cid:2869) (cid:1835)(cid:3047)
Figure 1. (a) For lane detection, it is required to identify visible lane pixels, represented by yellow lines in the insets. (b) Due to occlusions by nearby vehicles or glistening conditions on wet roads, lanes may be unobvious, which are depicted by orange dot-ted lines. Besides, lanes may not be marked at crossroads. (c) In a current frame I t, which is also the rightmost one in (b), some lane parts are occluded by a vehicle but visible in past frames. By utilizing visual cues along the temporal axis, depicted by cyan ar-rows, we can localize the implied lane parts more reliably. rather than processing each frame independently. It can de-tect implied lanes in a current frame more reliably using past information, as shown in Figure 1(c). But, relatively few techniques have been proposed for video lane detec-tion. Zou et al. [22] developed a memory network to ag-gregate the features of past and current frames. Similarly, in [23–26], they combined the features of a current frame with those of past frames and then detected lanes from the mixed features. However, these techniques require several past frames as input and do not reuse the mixed features in subsequent frames.
Recently, the ﬁrst video lane dataset called VIL-100 [24] was constructed, containing 100 videos. However, the num-ber of images is only 10K, and most images are collected from highway scenes. Also, OpenLane [27], a huge dataset for 3D lane detection, was proposed. It consists of 200K images from 1,000 videos and annotates lanes with both 2D and 3D coordinates. But, it is unsuitable for video lane de-tection because it provides annotations for visible lane parts only: First, the same lane is sometimes broken into multiple parts. Second, some annotations are temporally incoherent because of invisible parts in certain frames. To overcome
these issues, we modify OpenLane by ﬁlling in missing lane parts semi-automatically based on matrix completion [28].
The modiﬁed dataset is called OpenLane-V.
In this paper, we propose a novel video lane detector called RVLD, which records the state of a current frame and passes it recursively to the next frame to improve de-tection results. Figure 2 is an overview of the proposed
RVLD. First, we design the intra-frame lane detector (ILD) that performs encoding, decoding, and then non-maximum suppression (NMS) to localize lanes in a still image. Sec-ond, we develop the predictive — or inter-frame — lane detector (PLD) to detect lanes in a current frame using the information in the previous one. Speciﬁcally, we estimate a motion ﬁeld between adjacent frames and warp the previ-ous output to the current frame. Using the warped informa-tion, we reﬁne the feature map of the current frame to de-tect lanes more reliably. Experimental results show that the proposed RVLD outperforms existing techniques on both
VIL-100 and OpenLane-V datasets.
This work has the following major contributions:
• The proposed RVLD improves the detection results in a current frame using a single previous frame only and yields outstanding performances on video datasets.
• We develop simple yet effective modules for motion estimation and feature reﬁnement to exploit the previ-ous information reliably.
• We modify the OpenLane dataset to make it more suit-able for video lane detection. It is called OpenLane-V.1
• We introduce two metrics, ﬂickering and missing rates, for video lane detection. 2.