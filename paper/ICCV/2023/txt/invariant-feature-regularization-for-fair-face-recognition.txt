Abstract
Fair face recognition is all about learning invariant fea-ture that generalizes to unseen faces in any demographic group. Unfortunately, face datasets inevitably capture the imbalanced demographic attributes that are ubiquitous in real-world observations, and the model learns biased fea-ture that generalizes poorly in the minority group. We point out that the bias arises due to the confounding demographic attributes, which mislead the model to capture the spurious demographic-specific feature. The confounding effect can only be removed by causal intervention, which requires the confounder annotations. However, such annotations can be prohibitively expensive due to the diversity of the demo-graphic attributes. To tackle this, we propose to generate di-verse data partitions iteratively in an unsupervised fashion.
Each data partition acts as a self-annotated confounder, en-abling our Invariant Feature Regularization (INV-REG) to deconfound. INV-REG is orthogonal to existing methods, and combining INV-REG with two strong baselines (Arcface and CIFP) leads to new state-of-the-art that improves face recognition on a variety of demographic groups. Code is available at https://github.com/milliema/InvReg. 1.

Introduction
Face recognition is essentially an out-of-distribution generalization problem, where the goal is to learn feature that generalizes to unseen faces in deployment [32]. In par-ticular, due to its wide application in sensitive areas such as crime prevention [41], fair face recognition becomes a pressing need [10, 14, 35]. This means that the model must perform equally well on all demographic groups, i.e., it learns the causal feature (e.g., face identity) invariant to the demographic attributes (e.g., race or gender).
However, demographic attributes are naturally imbal-anced in data at scale, e.g., as shown in Figure 1 first row, in the prevailing MS-Celeb-1M dataset [12], “non-Caucasian” and “female” are the minority racial and gender groups, re-Figure 1: Biased model trained on the dataset with imbal-anced demographic attributes. (a) and (b) show the attribute proportions and verification accuracy on race and gender, respectively. (c) Grad-CAM [31] attention maps of face im-ages from two racial groups. (d) Misidentified cases. spectively. Furthermore, a model naively trained on this imbalanced dataset underperforms on the minority groups in deployment, e.g., more than 10% accuracy decrease on
“non-Caucasian”, and 5% decrease on “female”. In partic-ular, by analyzing the attention maps across the two racial groups in Figure 1c, we observe that besides the causal fea-ture (e.g., facial attributes like eyes and nose), the model additionally focuses on the spurious demographic-specific feature (e.g., hairstyle) on the minority group. This is be-cause the less diverse face images in each non-Caucasian identity tend to share the hairstyle, making it a valid context to distinguish identities. Yet this demographic-specific con-text generalizes poorly to unseen faces, e.g., misidentifying the same identity with different hairstyles as in Figure 1d.
From a causal point of view, the bias stems from the confounding effect [26, 27, 11]. In face recognition, when trained to predict the identity label Y given the face image
Figure 2: Comparison of different face recognition approaches. (a) Standard supervised training (biased to race and gender). (b) Learning with ground-truth race partition (biased to gender). (c) Our INV-REG without using any annotation of ground-truth demographic attribute (invariant to race and gender).
X, the model is confounded by the demographic attributes
D (e.g., D =“non-Caucasian”), which is the common cause of X and Y . Specifically, the training image X is sampled from the demographic group specified by the attributes D (i.e., D → X), and any demographic-specific feature that is discriminative towards Y (e.g., hairstyle) serves as contex-tual cue when predicting the identity (i.e., D → Y ). Hence, in pursuit of a lower classification loss, the model recklessly exploits the context feature (X ← D → Y ) which may not generalize to unseen faces. The confounding effect is more pronounced on the minority group, e.g., in the extreme case where D =“dark skin” only has one identity, learning the
“dark skin” feature alone (D → Y ) can tell the identity apart from “light skin” ones, yet this spurious feature fails to distinguish different “dark skin” identities in deployment.
The aforementioned confounding effect can only be re-moved by causal intervention [27, 26]. One way is to col-lect a balanced dataset with diverse faces in all demographic groups (i.e., adjusting the demographic attribute D). After all, if there is no demographic-specific context in any group, the model can only learn the causal feature. However, this is impractical due to the prohibitive data collection cost.
Note that “balanced” without “diverse” is ineffective since the spurious context still persists, as shown by the limited success on small balanced dataset [34]. The other way is backdoor adjustment [26], which can be implemented by data partition (Section 3.2). For example, in contrast to the naive supervised training on all images in Figure 2a, some works [11, 34, 19, 35] partition the training images into “race” splits (i.e., adjusting “race”), and train a model invariant across the splits as illustrated in Figure 2b. How-ever, since the demographic attributes are diverse in prac-tice, using only the “race” splits is far from sufficient.
To this end, we propose Invariant Feature Regulariza-tion, dubbed as INV-REG, which iteratively self-annotates the confounders by learning data partitions, as illustrated in
Figure 2c. Our INV-REG hinges on the invariance of causal relation [26, 25]: causal feature is invariantly discrimina-tive across the splits in any confounder partition. Its contra-position enables 1) partition learning about confounder: if the current feature is not invariantly discriminative across the learned splits, the partition corresponds to a confound-ing demographic attribute. Then we perform 2) feature learning to achieve invariance across the learned splits (i.e., causal intervention), which removes its confounding effect.
We iterate between the two steps to learn causal feature in-variant to diverse demographic attributes.
Our contributions are summarized below:
• We propose a partition learning strategy to self-annotate the demographic attributes (i.e., confounder) in the form of data partitions (Section 4.1). In particular, our approach discovers diverse demographic partitions without relying on any ground-truth annotation.
• We use the discovered partitions to impose an invariant regularization in training to learn causal feature robust in all demographic groups (Section 4.2).
• Overall, INV-REG is a regularization module orthogonal to existing face recognition methods. Combining INV-REG with two strong baselines leads to new state-of-the-art results, i.e., 79.44% on Arcface and 81.17% on CIFP for average multi-racial accuracy (Section 5.2). 2.