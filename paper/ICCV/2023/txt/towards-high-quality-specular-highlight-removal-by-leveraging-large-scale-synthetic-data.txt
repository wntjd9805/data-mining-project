Abstract
This paper aims to remove specular highlights from a single object-level image. Although previous methods have made some progresses, their performance remains some-what limited, particularly for real images with complex specular highlights. To this end, we propose a three-stage network to address them. Specifically, given an input image, we first decompose it into the albedo, shading, and specular residue components to estimate a coarse specular-free im-age. Then, we further refine the coarse result to alleviate its visual artifacts such as color distortion. Finally, we adjust the tone of the refined result to match the tone of the input as closely as possible. In addition, to facilitate network train-ing and quantitative evaluation, we present a large-scale synthetic dataset of object-level images, covering diverse objects and illumination conditions. Extensive experiments illustrate that our network is able to generalize well to un-seen real object-level images, and even produce good re-sults for scene-level images with multiple background ob-jects and complex lighting. 1.

Introduction
Specular highlights are very common in the real world, but they are usually undesirable in photographs, since they can degrade the image quality.
In daily life, users often want to achieve the specular-free image from an image.
For example, specular highlights in facial or document im-ages sweep away skin details or meaningful texture patterns which are very important to users. Removing specular high-lights from a single image enables recovering visual content with better perceptibility. Moreover, it has many related applications such as recoloring [1], light source estimation
*Corresponding author.
[11], recognition of specular objects [18], and intrinsic im-age decomposition [31]. Thus, specular highlight removal is a long-standing and challenging problem in computer vi-sion and computer graphics.
To address this problem, researchers have proposed var-ious specular highlight methods. They can be roughly di-vided into two categories: traditional methods [25, 29, 13, 24] based on intensity and chromaticity analysis as well as optimization, and deep learning-based methods [30, 4, 28].
However, the traditional methods often produce unsatisfac-tory or even poor results with visual artifacts such as black color block and detail missing; see Figure 1(b). The main reason is that they fail to capture high-level semantic infor-mation to recover the missing colors and details underneath specular highlights using those meaningful and reliable in-formation from the non-highlight region.
In addition, al-though the deep learning-based methods have achieved cer-tain performance improvement, they may still produce un-satisfactory results with visual artifacts such as illumination residue and color distortion; see Figure 1(c)(e). It is partly attributed to the fact that they are trained on relatively sim-ple images in which materials and illumination conditions are not diverse enough, leading to their limited generaliza-tion to unseen images.
We in this paper propose a three-stage specular high-light removal network, consisting of (i) physics-based spec-ular highlight removal, (ii) specular-free refinement, and (iii) tone correction. In the first stage, based on a physics-based formation model, we decompose an input image into its albedo, shading, and specular residue components, and then estimate a coarse specular-free image. In the second stage, we further refine the coarse result to alleviate visual artifacts for improving the quality. In the third stage, we adjust the tone of the refined result to produce the final re-sult with the similar tone of the input. In addition, to facili-tate network training and quantitative evaluation, we build a
Figure 1. Visual comparison of our method against state-of-the-art methods on a challenging image with nearly white material surfaces. (a) Input. (b) Yang et al. [29]. (c) Fu et al. [4]. (d) Wu et al. [28]. (e) Ours. large-scale synthetic dataset rendered by software using di-verse 3D models and real HDR environment maps. Figure 1 presents the visual comparison on a real image. As shown, our method is able to produce high-quality specular-free im-ages without noticeable artifacts encountered by previous methods. Below, we summarize the major contributions of our work.
• We propose a three-stage specular highlight removal network to progressively eliminate multiple types of visual artifacts such as color distortion and tone incon-sistency.
• We present a large-scale synthetic dataset of object-level images, in which each specular highlight image has corresponding ground truth albedo, shading, spec-ular residue, and specular-free images.
• We conduct extensive experiments on existing datasets and our new dataset, and demonstrate that our method achieves better quantitative and qualitative results than state-of-the-art methods. 2.