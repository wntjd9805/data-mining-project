Abstract (cid:49)(cid:82)(cid:38)(cid:35)(cid:28)(cid:19)(cid:3)(cid:82)(cid:81)(cid:3)(cid:54)(cid:37)(cid:39)(cid:3)(cid:71)(cid:68)(cid:87)(cid:68)(cid:86)(cid:72)(cid:87)
Click-based interactive image segmentation aims at ex-tracting objects with a limited user clicking. A hierarchical backbone is the de-facto architecture for current methods.
Recently, the plain, non-hierarchical Vision Transformer (ViT) has emerged as a competitive backbone for dense pre-diction tasks. This design allows the original ViT to be a foundation model that can be ﬁnetuned for downstream tasks without redesigning a hierarchical backbone for pretrain-ing. Although this design is simple and has been proven eﬀective, it has not yet been explored for interactive image segmentation. To ﬁll this gap, we propose SimpleClick, the ﬁrst interactive segmentation method that leverages a plain backbone. Based on the plain backbone, we intro-duce a symmetric patch embedding layer that encodes clicks into the backbone with minor modiﬁcations to the back-bone itself. With the plain backbone pretrained as a masked autoencoder (MAE), SimpleClick achieves state-of-the-art performance. Remarkably, our method achieves 4.15
NoC@90 on SBD, improving 21.8% over the previous best result. Extensive evaluation on medical images demon-strates the generalizability of our method. We provide a de-tailed computational analysis, highlighting the suitability of our method as a practical annotation tool. 1.

Introduction
The goal of interactive image segmentation is to obtain high-quality pixel-level annotations with limited user inter-action such as clicking. Interactive image segmentation ap-proaches have been widely applied to annotate large-scale image datasets, which drive the success of deep models in various applications, including video understanding [5, 49], self-driving [7], and medical imaging [32, 41]. Much re-search has been devoted to explore interactive image seg-mentation with diﬀerent interaction types, such as bound-ing boxes [47], polygons [1], clicks [43], scribbles [45], and their combinations [51]. Among them, the click-based approach is most common due to its simplicity and well-established training and evaluation protocols. (cid:3)(cid:3) (cid:3)(cid:3)       Swin 
Transformer (cid:27) (cid:26) (cid:25) (cid:24) (cid:23) (cid:3)(cid:3) (cid:3)(cid:3) (cid:3)(cid:3) (cid:3)(cid:3) (cid:3)(cid:3)
SegFormer
ResNet
HRNet (cid:3)(cid:3) (cid:3)(cid:3) (cid:3)(cid:3)
Plain ViT (cid:22)
Figure 1. Interactive segmentation results on SBD [20]. The metric “NoC@90" denotes the number of clicks required to obtain 90% IoU. The area of each bubble is proportional to the FLOPs of a model variant (Tab. 5). We show that plain ViTs outperform all hierarchical backbones for interactive image segmentation at a moderate computational cost.
Recent advances in click-based approaches mainly lie in two orthogonal directions: 1) the development of more ef-fective backbone networks and 2) the exploration of more elaborate reﬁnement modules built upon the backbone. For the former direction, diﬀerent hierarchical backbones, in-cluding both ConvNets [30,43] and ViTs [10,33], have been developed for interactive segmentation. For the latter di-rection, various reﬁnement modules, including local reﬁne-ment [10, 30] and click imitation [34], have been proposed to further boost segmentation performance. In this work, we delve into the former direction and focus on exploring a plain backbone for interactive segmentation.
A hierarchical backbone is the predominant architecture for current interactive segmentation methods. This design is deeply rooted in ConvNets, represented by ResNet [22], and has been adopted by ViTs, represented by the Swin Trans-former [35]. The motivation for a hierarchical backbone stems from the locality of convolution operations, leading
to insuﬃcient model receptive ﬁeld size without the hier-archy. To increase the receptive ﬁeld size, ConvNets have to progressively downsample feature maps to capture more global contextual information. Therefore, they often require a feature pyramid network such as FPN [28] to aggregate multi-scale representations for high-quality segmentation.
However, this reasoning no longer applies for a plain ViT, in which global information can be captured from the ﬁrst self-attention block. Because all feature maps in the ViT are of the same resolution, the motivation for an FPN-like feature pyramid also no longer remains. The above reason-ing is supported by a recent ﬁnding that a plain ViT can serve as a strong backbone for object detection [26]. This
ﬁnding indicates a general-purpose ViT backbone might be suitable for other tasks, which then can decouple pretraining from ﬁnetuning and transfer the beneﬁts from readily avail-able pretrained ViT models (e.g. MAE [21]) to these tasks.
However, although this design is simple and has been proven eﬀective, it has not yet been explored in interactive segmen-tation. In this work, we propose SimpleClick, the ﬁrst plain-backbone method for interactive segmentation. The core of SimpleClick is a plain ViT backbone that main-tains single-scale representations throughout. We only use the last feature map from the plain backbone to build a sim-ple feature pyramid for segmentation, largely decoupling the general-purpose backbone from the segmentation-speciﬁc modules. To make SimpleClick more eﬃcient, we use a light-weight MLP decoder to transform the simple feature pyramid into a segmentation (see Sec. 3 for details).
We extensively evaluate our method on 10 public bench-marks, including both natural and medical images. With the plain backbone pretrained as a MAE [21], our method achieves 4.15 NoC@90 on SBD, which outperforms the pre-vious best method by 21.8% without a complex FPN-like design and local reﬁnement. We demonstrate the generaliz-ability of our method by out-of-domain evaluation on medi-cal images. We further analyze the computational eﬃciency of SimpleClick, highlighting its suitability as a practical annotation tool.
Our main contributions are:
• We propose SimpleClick, the ﬁrst plain-backbone method for interactive image segmentation.
• SimpleClick achieves state-of-the-art performance on natural images and shows strong generalizability on med-ical images.
• SimpleClick meets the computational eﬃciency re-quirement for a practical annotation tool, highlighting its readiness for real-world applications. 2.