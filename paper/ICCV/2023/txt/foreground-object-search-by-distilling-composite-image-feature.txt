Abstract
Foreground object search (FOS) aims to find compati-ble foreground objects for a given background image, pro-ducing realistic composite image. We observe that com-petitive retrieval performance could be achieved by us-ing a discriminator to predict the compatibility of com-posite image, but this approach has unaffordable time
To this end, we propose a novel FOS method cost. via distilling composite feature (DiscoFOS). Specifically, the abovementioned discriminator serves as teacher net-work. The student network employs two encoders to ex-tract foreground feature and background feature. Their interaction output is enforced to match the composite image feature from the teacher network. Additionally, previous works did not release their datasets, so we contribute two datasets for FOS task: S-FOSD dataset with synthetic composite images and R-FOSD dataset with real composite images. Extensive experiments on our two datasets demonstrate the superiority of the pro-posed method over previous approaches. The dataset and code are available at https://github.com/bcmi/
Foreground-Object-Search-Dataset-FOSD. 1.

Introduction
Foreground Object Search (FOS) aims to find compati-ble foregrounds from specified category for a given back-ground image which has a query bounding box indicating the foreground location [42]. More precisely, an object is compatible with a background image if it can be realisti-cally composited into the image [44], as illustrated in Fig-ure 1. FOS is a core technique in many image composition applications [24]. For example, FOS technique can help
*Corresponding author
Figure 1. Illustration of foreground object search. Given a back-ground image with query bounding box (yellow), foreground ob-ject search aims to find compatible foreground objects of a speci-fied category from a database, which is composited with the back-ground to produce a realistic composite image. users acquire suitable foregrounds from a foreground pool automatically and efficiently for object insertion in photo editing [19]. Moreover, FOS also can be used to fill a region comprising undesired objects using new foreground [44].
There exist many factors that affect the compatibil-ity between background and foreground, including seman-tics, style (e.g., color and texture), lighting, and geome-try (e.g., shape and viewpoint). Previous works on FOS may consider different factors. For example, early meth-ods [42, 44] focused on the semantic compatibility. Re-cent works [19, 37, 47] considered geometry and other fac-tors, including style [37] and lighting [47]. In this paper, we focus on semantics and geometry compatibility follow-ing [19], because incompatible color and lighting between the background and foreground can be tackled to some ex-tent by image harmonization [6, 21, 4].
The general pipeline of most existing methods [42, 44, 47, 19, 37] is to learn an embedding space with two en-coders respectively for background and foreground, so that compatible background and foreground are close to each other in this space. Alternatively, some approaches [46, 44] trained a discriminator to predict background-foreground compatibility by feeding the composite image. Based on preliminary experiments, we observe that the discriminator can achieve much better results than encoders when taking the cropped composite image as input (see teacher network in Figure 3). We conjecture that the forward pass in the dis-criminator allows thorough interaction between background and foreground, which could provide useful contextual cues for estimating background-foreground compatibility. How-ever, given a background image, it is very time-consuming to composite with each foreground image and perform for-ward computation for each composite image. Motivated by this, we propose a novel FOS framework called Disco-FOS via knowledge distillation. Specifically, we distill the knowledge of composite image from the discriminator to two encoders, in which we enforce the interaction output of foreground feature and background feature to match with the composite image feature. How to design the interaction between two encoders is challenging, due to the trade-off between performance and computational cost. On the one hand, insufficient interaction between two encoders may be unable to mimic the rich knowledge in composite im-age feature. On the other hand, sufficient interaction would largely increase the computational burden. Considering the abovementioned trade-off, we perform interaction only on the last feature maps of two encoders, which achieves sig-nificant performance improvement with acceptable compu-tational overhead.
Since previous works (CAIS [42], UFO [44], and GALA
[47]) did not release their datasets, we build our own datasets based on an existing large-scale real-world dataset, i.e., Open Images [15], as illustrated in Figure 2. We con-struct two FOS Datasets respectively containing Synthetic composite images and Real composite images, abbreviated as S-FOSD and R-FOSD respectively. We first introduce the S-FOSD dataset. Given a real image with instance seg-mentation mask, we choose one object and fill its bound-ing box with image mean values to get the background.
Meanwhile, we crop out this object as foreground. After re-moving unsuitable categories and occluded foregrounds, the resultant dataset contains 57,859 backgrounds and 63,619 foregrounds. Following [42, 47], for each background im-age, we deem the foreground object from the same image as ground-truth. For R-FOSD dataset, we collect images from
Internet as background images and draw a bounding box at the expected foreground location as query bounding box.
R-FOSD dataset shares the same foregrounds with the test set of S-FOSD dataset. Then we employ multiple human annotators to label the compatibility of each pair of back-In summary, S-FOSD dataset is ground and foreground. lowcost and highly scalable, but has neither complete back-ground nor ground-truth negative samples. Oppositely, R-FOSD dataset has complete background image with both positive and negative foregrounds annotated by human, yet is unscalable due to the high annotation cost. In our exper-iments, S-FOSD dataset is used for both training and vali-dating model, while R-FOSD dataset is only used for model evaluation. More details about dataset construction could be found in Section 3.
We evaluate our method on the proposed datasets, which validates the superiority of the proposed method over pre-vious approaches. Our major contributions can be summa-rized as follows: 1) To facilitate the research on FOS task, we contribute two public datasets: S-FOSD dataset with synthetic composite images and R-FOSD dataset with real composite images. 2) We propose a novel method named
DiscoFOS that improves foreground object search by dis-tilling the knowledge of composite image feature into two encoders. 3) Extensive experiments demonstrate the supe-riority of the proposed method over previous baselines on our datasets. 2.