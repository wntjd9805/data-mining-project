Abstract
Personalized federated learning has received an upsurge of attention due to the mediocre performance of conven-tional federated learning (FL) over heterogeneous data.
Unlike conventional FL which trains a single global con-sensus model, personalized FL allows different models for different clients. However, existing personalized FL algo-rithms only implicitly transfer the collaborative knowledge across the federation by embedding the knowledge into the aggregated model or regularization. We observed that this implicit knowledge transfer fails to maximize the potential of each client’s empirical risk toward other clients. Based on our observation, in this work, we propose Personalized
Global Federated Learning (PGFed), a novel personalized
FL framework that enables each client to personalize its own global objective by explicitly and adaptively aggregat-ing the empirical risks of itself and other clients. To avoid massive (O(N 2)) communication overhead and potential privacy leakage while achieving this, each client’s risk is estimated through a first-order approximation for other clients’ adaptive risk aggregation. On top of PGFed, we develop a momentum upgrade, dubbed PGFedMo, to more efficiently utilize clients’ empirical risks. Our extensive ex-periments on four datasets under different federated set-tings show consistent improvements of PGFed over previ-ous state-of-the-art methods. The code is publicly available at https://github.com/ljaiverson/pgfed. 1.

Introduction
Recent years have witnessed the prosperity of feder-ated learning (FL) [26, 14, 21, 39] in collaborative machine learning where the participating clients are subject to strict privacy rules [38]. Conventional FL aims to train a sin-gle global consensus model by orchestrating the participat-Figure 1. In PGFed, the explicit collaborative knowledge trans-fer shows in the design of the local objective as a “personalized global” objective at client i, where non-local risks are involved. ing clients with a central server. The most notable FL al-gorithm, FedAvg [26], proceeds the training by exchang-ing between clients and server only the locally updated and globally aggregated model weights, leaving the private datasets intact. As a privacy-preserving machine learning technique, FL tremendously boosts new collaborations of decentralized parties in a number of areas [41, 16, 24, 14].
Unfortunately, along with the emergence of conventional
FL, new challenges have been posed in terms of systems and statistical heterogeneity [21]. Systems heterogeneity ad-dresses the variability of clients’ computation abilities, sizes of storage, or even the choices of model architecture due to different hardware constraints of the clients. Whereas sta-tistical heterogeneity, the focus of this work, refers to the non-IID data among the clients, which could lead to non-guaranteed convergence [22, 30] and poor generalizability performance [32], even after fine-tuning [13].
Over the years, the mediocre performance of conven-tional FL over heterogeneous data has not only promoted solutions that improve the single consensus model on top of FedAvg [22, 1, 15, 20], a new paradigm, personalized
FL [36, 18], has emerged as well. In this paradigm, person-alized models are allowed for each individual client. Some efforts in this direction focus on different personalized lay-ers and optimization techniques [23, 5, 29]. Leveraging
multi-task [44] or meta-learning [10] is also shown to be beneficial in personalized FL [34, 7, 3]. Other works in-clude clustered FL [9, 33, 31], interpolation of personalized models [43, 25, 6], and fine-tuning [28, 19, 40].
However, in most existing personalized FL algo-rithms [23, 5, 6, 12, 2, 7, 4, 28], the way in which the collaborative knowledge is transferred from the server to the clients is implicit. Here, we consider the collaborative knowledge as non-local information, such as the global ob-jective of FedAvg, F (θ) = (cid:80) i piFi(θ), where θ is the global model and Fi(·) represents client i’s local objec-tive whose weights are denoted as pi’s.
In addition, we define “implicitness” by defining its opposite side, “ex-plicitness”, as a direct engagement with multiple clients’ empirical risks. For instance, updating the global model of FedAvg is explicit, where the direct engagement is achieved through communication. However, this can hardly be the case for updating clients’ personalized models, as it would take O(N 2) communication overhead to trans-mit each client’s personalized model to every client, as-suming FedAvg’s communication cost is O(N ) over N clients. Consequently, most personalized FL algorithms im-plicitly transfer the collaborative knowledge from the server to the clients by embedding it into the aggregation of model weights or as different kinds of regularizers.
Why should we care about the “explicitness”, especially for updating the personalized models? Let us first assume all communication has zero cost, and, as an example, de-sign a client’s explicit local objective as a “personalized global objective” in the same form as the global objec-tive of FedAvg (weighted sum of all clients’ risks), i.e.
Fi(θi) = fi(θi) + µ/(N − 1) (cid:80) j̸=i fj(θi), where Fi(·) and fi(·) are client i’s local objective and empirical risk, re-spectively, and µ is a hyperparameter. By this means, the clients are no longer limited to implicitly acquiring the col-laborative knowledge in an embedded (from the aggregated model weights) form.
The motivation behind this explicit design is that it facil-itates the generalizability of the personalized models by di-rectly penalizing their performance over other clients’ risks, contributing to more informative updates and therefore bet-ter local performance. On the other hand, an implicit per-sonalization scheme embeds the non-local information into the aggregated model weights, preventing the clients from directly engaging with other clients’ risks.
We further demonstrate this motivation and the benefit of the explicit design by an empirical study: we personalize the output global model of FedAvg through S = 6 steps of local gradient-based update, supposing that the O(SN 2) communication cost is affordable for now. We compare the exemplar explicit design of each client’s local objective with a simple implicit method, i.e. the local fine-tuning of
FedAvg where each client’s local objective is only its own
Figure 2. In the task of personalizing the output of FedAvg on
CIFAR10 with 100 heterogeneous clients, the performance of the exemplar explicit local objective and an implicit local objective, assuming the communication cost is affordable. Figure (a) and (b) show the trend of the mean personalized test accuracy, and the his-togram and density estimation of the individual gain, respectively. empirical risk (Fi(θi) = fi(θi)).
The result of this empirical study are shown in Fig. 2.
On CIFAR10 dataset with 100 heterogeneous clients, we observe that the explicit transfer of collaborative knowl-edge exhibits a stronger ability to adapt the model to-wards clients’ local data than the implicit counterpart, with a mean individual performance gain of 7.73% over local test data from the initial global model, 2.33% higher than
Intriguing as the re-that of an implicit personalization. sults may seem, how can we transfer this idea back to the communication-expensive real-world FL settings where ac-quiring all fj(θi) ∀i, j ∈ [N ] will cost O(N 2) communi-cation overhead? Our solution is to estimate fj(θi) by ap-proximation as shown in Fig. 1.
Based on the above observation, in this work, we pro-pose Personalized Global Federated Learning (PGFed), a novel personalized FL framework that enables each client to personalize its own global objective by explicitly and adaptively aggregating the empirical risks of itself and other clients. To avoid massive communication overhead and potential privacy leakage, each client’s risk is estimated through a first-order approximation for other clients’ adap-tive risk aggregation. Thereby, the clients are able to explic-itly acquire the collaborative knowledge, and their person-alized models can enjoy better generalizability. We summa-rize our contributions as follows:
• We uncover that the explicitness of a personalized FL al-gorithm empowers itself with stronger adaptation ability.
Based on this observation, we propose PGFed, a novel explicit personalized FL algorithm that frames the local objective of each client as a personalized global objective.
• To the best of our knowledge, PGFed is the first work
in the field to achieve explicit transfer of global collabo-rative knowledge among the clients, without introducing the seemingly unavoidable O(N 2) communication costs.
• On top of PGFed, we develop a momentum upgrade, dubbed PGFedMo, to let the clients more efficiently uti-lize other clients’ empirical risks.
• We evaluate PGFed and PGFedMo on four datasets un-der different FL settings. The results show that both algo-rithms outperform the compared state-of-the-art personal-ized FL methods, with up to 15.47% boost in accuracy. 2.