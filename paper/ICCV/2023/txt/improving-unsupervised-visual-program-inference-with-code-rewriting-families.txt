Abstract
Programs offer compactness and structure that makes them an attractive representation for visual data. We ex-plore how code rewriting can be used to improve systems for inferring programs from visual data. We first propose
Sparse Intermittent Rewrite Injection (SIRI), a framework for unsupervised bootstrapped learning. SIRI sparsely ap-plies code rewrite operations over a dataset of training pro-grams, injecting the improved programs back into the train-ing set. We design a family of rewriters for visual pro-gramming domains: parameter optimization, code pruning, and code grafting. For three shape programming languages in 2D and 3D, we show that using SIRI with our family of rewriters improves performance: better reconstructions and faster convergence rates, compared with bootstrapped learning methods that do not use rewriters or use them naively. Finally, we demonstrate that our family of rewrit-ers can be effectively used at test time to improve the output of SIRI predictions. For 2D and 3D CSG, we outperform or match the reconstruction performance of recent domain-specific neural architectures, while producing more parsi-monious programs, that use significantly fewer primitives. 1.

Introduction
Visual data is often highly structured: manufactured shapes are produced by assembling parts; vector graphics images are built from layers of primitives; detailed textures can be created via intricate compositions of noise functions.
Visual programs, i.e. programs that produce visual out-puts when executed, are a natural approach to capturing this complexity in a structure-aware fashion. Access to well-written visual programs supports downstream applications across visual computing domains, including editing, gen-erative modeling, and structural analysis. But how can we obtain a program which generates a given visual datum?
Project page: https://bardofcodes.github.io/coref/
Figure 1. Our method SIRI (top row) generates highly compact yet accurate programs, in contrast to CSG-Stump [24] (bottom row), which generates programs with numerous primitives. Here, we show shapes rendered with colored primitives.
Visual Program Inference (VPI) methods aim to solve this problem by automatically inferring programs that rep-resent visual inputs. Solving this search problem is very difficult: the space of possible programs is often vast, even when constrained by a domain-specific language (DSL). To overcome this challenge, recent works have investigated learning-based solutions, where a neural network is em-ployed to guide the search. When a dataset of visual pro-grams exist, such networks can be trained in a supervised fashion [36, 33, 37, 38, 13]. Unfortunately, most domains lack such data, so recent works have investigated how to train VPI networks in an unsupervised fashion.
Learning to infer visual programs without supervision is challenging: programs usually contain discrete and continu-ous elements, which complicates end-to-end learning. Var-ious solutions have been proposed to work around this is-sue: end-to-end learning is possible with neural architec-tures that act as a smooth relaxations of program execu-tors [24], while policy gradient reinforcement learning [26]
and bootstrapped learning methods [15] are able to treat program executors as (potentially non-differentiable) ‘black boxes.’ These solutions come with downsides: designing differentiable relaxations is challenging (or even impossi-ble) for some domains; reinforcement learning suffers from noisy gradients and slow convergence; bootstrapped learn-ing methods are prone to getting stuck in local minima.
Moreover, a seldom acknowledged limitations of these latter methods is that they treat programs as just sequences of tokens. We argue that this view is suboptimal: programs are structured objects that support domain-specific reason-ing to meaningfully constrain and guide the VPI search pro-cess. One example of such reasoning is the use of domain-specific operations that modify programs toward optimizing an objective—we call such operations rewrites. Rewrites have been explored in the context of VPI tasks, but primar-ily as a test-time optimization, e.g. finding better continu-ous parameters for a fixed program structure. While such optimization is useful, our claim is that other rewrite opera-tions are similarly useful, especially when used in tandem, and that they can be employed to benefit VPI network learn-ing, not only as test-time optimization schemes.
In this paper, we investigate how to use code rewrit-ing to improve visual program inference. Unlike prior work, we focus on families of code rewriters, each of which makes improvements to a program with some goal in mind. We propose Sparse Intermittent Rewrite Injec-tion (SIRI), a bootstrapped learning algorithm that sparsely applies rewriters and injects rewritten programs into a search-train loop at intermittent intervals. To realize SIRI, we design a family of rewrites applicable to multiple vi-sual programming DSLs: gradient-based parameter opti-mization (Parameter Optimization), removing spurious sub-programs (Code Pruning), and sub-program substitutions from a cache (Code Grafting). We also propose a test-time rewriting scheme that searches for improved programs through interleaved rewrites that is well-suited to the types of programs inferred by SIRI-trained networks.
We evaluate SIRI and our family of rewriters (PO, CP,
CG) on three shape program DSLs: 2D Constructive Solid
Geometry (CSG), 3D CSG, and ShapeAssembly [13]. We compare VPI networks trained with SIRI to VPI networks trained by PLAD, a recently-proposed bootstrapped learn-ing method [15], and find that SIRI both increases recon-struction performance and converges significantly faster.
We further show that naively combining our rewrite fam-ilies with PLAD performs much worse than SIRI, and in some domains even worsens performance compared with
PLAD. Finally, we demonstrate that combining SIRI with our test-time rewriting scheme infers visual programs that can match (3D CSG [24]) or surpass (2D CSG [16]) re-construction performance of domain-specific neural archi-tectures while producing significantly more parsimonious programs (see number of primitives, Figure 1).
In summary, we make the following contributions: 1. Sparse Intermittent Rewrite Injection, a framework for unsupervised visual program inference that leverages a family of code rewriters. 2. A family of code rewriters applicable to multiple DSLs that benefit VPI learning methods and can be used in a test-time rewriting scheme. 2.