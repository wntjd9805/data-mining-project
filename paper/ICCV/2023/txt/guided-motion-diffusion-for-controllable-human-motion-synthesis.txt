Abstract 1.

Introduction
Denoising diffusion models have shown great promise in human motion synthesis conditioned on natural language descriptions. However, integrating spatial constraints, such as pre-defined motion trajectories and obstacles, remains a challenge despite being essential for bridging the gap between isolated human motion and its surrounding envi-ronment. To address this issue, we propose Guided Motion
Diffusion (GMD), a method that incorporates spatial con-straints into the motion generation process. Specifically, we propose an effective feature projection scheme that manip-ulates motion representation to enhance the coherency be-tween spatial information and local poses. Together with a new imputation formulation, the generated motion can re-liably conform to spatial constraints such as global motion trajectories. Furthermore, given sparse spatial constraints (e.g. sparse keyframes), we introduce a new dense guid-ance approach to turn a sparse signal, which is susceptible to being ignored during the reverse steps, into denser sig-nals to guide the generated motion to the given constraints.
Our extensive experiments justify the development of GMD, which achieves a significant improvement over state-of-the-art methods in text-based motion generation while allowing control of the synthesized motions with spatial constraints.
Recently, denoising diffusion models have emerged as a promising approach for human motion generation [11, 62, 64] outperforming other alternatives such as GAN or VAE in terms of both quality and diversity [7, 51, 58]. Several studies have focused on generating motion based on ex-pressive text prompts [7, 51], or music [52, 64]. The state-of-the-art motion generation methods, such as MDM [51], utilize classifier-free guidance to generate motion condi-tioned on text prompts. However, incorporating spatial con-straints into diffusion models remains underexplored. Hu-man motions consist of both semantic and spatial informa-tion, where the semantic aspect can be described using nat-ural languages or action labels and the spatial aspect gov-erns physical interaction with surroundings. To generate realistic human motion in a 3D environment, both aspects must be incorporated. Our experiments show that simply adding spatial constraint guidance, such as global trajecto-ries, into the state-of-the-art models or using imputation and in-painting approaches do not yield satisfactory results.
We identify two main issues that make the motion diffu-sion models likely to ignore the guidance when conditioned on spatial objectives: the sparseness of global orientation
To effectively incorporate sparse spatial constraints into the motion generation process, we propose GMD, a novel and principled Guided Motion Diffusion model. To allevi-ate the discrepancy between local pose and global orienta-tion in the guided denoising steps, we introduce emphasis projection, a general representation manipulation method that we use to increase the importance of spatial informa-tion during training. Additionally, we derive a new imputa-tion and inpainting formulation that enables the existing in-painting techniques to operate in the projected space, which we leverage to generate significantly more coherent motion under guidance by spatial conditions. Then, to address the highly sparse guidance, we draw inspiration from the credit assignment problem in Reinforcement Learning [50, 54], where sparse rewards can be distributed along a trajectory to allow for efficient learning [3]. Our key insight is that motion denoisers, including the diffusion model itself, can be used to expand the spatial guidance signal at a specific location to its neighboring locations without any additional model. By turning a sparse signal into a dense one by back-propagating through a denoiser, it enables us to achieve high-quality controllable motion synthesis, even with ex-tremely sparse guidance signals.
In summary, our contributions are: (1) Emphasis projec-tion, a method to adjust relative importance between dif-ferent parts of the representation vector, which we use to encourage coherency between spatial information and lo-cal poses to allow spatial guidance. (2) Dense signal prop-agation, a conditioning method to tackle the sparse guid-ance problem. (3) GMD, an effective spatially controllable motion generation method that enables the unexplored syn-thesizing of motions based on free-text and spatial condi-tioning by integrating the above contributions into our pro-posed Unet-based architecture. We provide extensive anal-ysis to support our design decisions and show the versatility of GMD on three tasks: trajectory conditioning, keyframe conditioning, and obstacle avoidance. Additionally, GMDâ€™s model also significantly outperforms the state-of-the-art in traditional text-to-motion tasks. 2.