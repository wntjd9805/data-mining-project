Abstract
We study the problem of few-shot physically-aware artic-ulated mesh generation. By observing an articulated object dataset containing only a few examples, we wish to learn a model that can generate diverse meshes with high vi-sual fidelity and physical validity. Previous mesh generative models either have difficulties in depicting a diverse data space from only a few examples or fail to ensure physical validity of their samples. Regarding the above challenges, we propose two key innovations, including 1) a hierarchi-cal mesh deformation-based generative model based upon the divide-and-conquer philosophy to alleviate the few-shot challenge by borrowing transferrable deformation patterns from large scale rigid meshes and 2) a physics-aware de-formation correction scheme to encourage physically plau-sible generations. We conduct extensive experiments on 6 articulated categories to demonstrate the superiority of our method in generating articulated meshes with better diversity, higher visual fidelity, and better physical valid-ity over previous methods in the few-shot setting. Further, we validate solid contributions of our two innovations in the ablation study. Project page with code is available at meowuu7.github.io/few-arti-obj-gen. 1.

Introduction
Generative models have aroused a wide spectrum of in-terests in recent years for their creativity and broad down-stream application scenarios [29, 30, 34, 17, 8, 26]. Spe-cific to 3D generation, a variety of techniques such as de-noising diffusion [23, 42, 6, 39] have also been discussed for a while. Among them, mesh generation is indeed im-portant since the mesh representation can support a wider range of downstream applications such as rendering and physical simulation compared to other representations such as point clouds. Existing works mainly focus on generat-ing meshes for whole objects [8, 26, 6, 19, 30] considering without modeling object functionalities at all. Besides, they
Figure 1. Overview. We present a hierarchical mesh deformation-based generative model to solve the challenging yet important few-shot physically-aware articulated mesh generation problem. It tackles the few-shot challenge by borrowing shared convex level deformation patterns from large-scale rigid meshes and incorporates a deformation correction scheme to further enhance the model’s ability to generate physically real-istic meshes. mainly rely on reconstructing meshes from other kinds of representations such as implicit fields [8, 6, 19] instead of generating meshes directly. In this work, we go one step further and consider mesh generation for articulated objects that can support physically realistic articulations. This not only helps understand the object distribution in real-world assets, but also allows an intelligent agent to learn segment-ing [20, 22], tracking [36], reasoning [10] and manipulat-ing [38] articulated objects through a simulation environ-ment. We focus on the articulated mesh generative model that can generate object meshes with diverse geometry, high visual fidelity, and correct physics.
Training a generative model on publicly available articu-lated mesh datasets to depict a diverse physically-plausible data space not limited to training assets presents two main challenges to the methodology. First, existing articulated object datasets are usually very restricted in scale. For ex-ample, the PartNet-Mobility Dataset [37] contains an av-erage of 51 meshes per category. This naturally requires a few-shot generative model to learn from a very limited number of meshes. Adapting previous approaches imme-diately without carefully considering the few-shot nature would lead to models suffering from poor generative abil-ity. Second, we need to pursue physically plausible gen-eration to ensure the generated meshes are not only visu-ally appealing but also functionally sound to support correc-tion articulation functions, i.e., attached parts without self-penetrations in the full articulation range.
Despite recent advancements in mesh generation com-munity such as a wide variety of models proposed in exist-ing works [8, 41, 6, 33, 19], they are typically challenged by the following difficulties and always fail to solve our prob-lem: 1) Lack of the ability to learn a wide data space not limited to training shapes in the few-shot setting. 2) Dif-ficulty in modeling crucial object-level shape constraints imposed by the functionality of articulated objects. Fail-ure to consider these requirements would result in physi-cally unrealistic samples [8, 6, 26]. Modeling such physi-cal constraints for articulated meshes is a non-trivial task, as it requires accounting for diverse penetration phenomena caused by different types of articulation motions. To our best knowledge, we are the first that presents a valid frame-work to address such two difficulties for articulated mesh generation.
Our work designs a hierarchical mesh deformation-based generative model that tackles the aforementioned chal-lenges using two key innovations: (1) Hierarchical mesh deformation with transfer learning. We introduce an object-convex shape hierarchy and learn the hierarchical articu-lated mesh generative model. The model is trained by first learning the deformation-based generative model at the leaf convex level and then synchronizing individual convex-level deformation spaces at the root level. We identify that different categories tend to share convex-level deformation patterns and leverage this insight to learn and transfer rich deformation prior from large-scale rigid datasets to expand the model’s generative capacity. (2) Physics-aware defor-mation correction. To address self-penetrations of deformed articulated meshes during mesh articulation, we further in-troduce a deformation correction scheme. It is composed of an auxiliary loss penalizing self-penetrations during mesh articulation and a collision response-based shape optimiza-tion strategy. By integrating this scheme into the hierar-chical mesh deformation model, we successfully guide the model to generate more physically realistic deformations, resulting in physically correct articulated meshes finally.
We conduct extensive experiments on 6 categories from the PartNet-Mobility dataset [37] for evaluation. As demon-strated by both the quantitative and qualitative results, we can consistently outperform all baseline methods regarding the fidelity, diversity and physical plausibility of generated meshes, e.g., an average of 10.4% higher coverage ratio, 43.7% lower minimum matching distance score, and 26.5% lower collision score. Ablation studies further validate the value of our design in deformation pattern transfer learn-ing, the hierarchical mesh generation approach, and the ef-fectiveness as well as the versatility of our physics-aware correction scheme.
Our key contributions are as follows: (1) We present the first solution, to our best knowledge, for the challenging yet important few-shot physically-aware articulated mesh generation problem with two effective and non-trivial tech-(2) We propose a hierarchical mesh nical innovations. deformation-based generative model based upon the divide-and-conquer philosophy. This design allows us to learn a diverse data space by borrowing shared deformation pat-terns from large-scale rigid object datasets. (3) We propose a physics-aware deformation correction scheme to encour-age the hierarchical generative model to produce physically realistic deformations, resulting in improved physical valid-ity of the generated samples. This scheme can also be effec-tively integrated into other deformation-based mesh genera-tive models, thereby enhancing the physical validity of their samples as well. 2.