Abstract
Pre-training is a strong strategy for enhancing visual models to efficiently train them with a limited number of labeled images. In semantic segmentation, creating annota-tion masks requires an intensive amount of labor and time, and therefore, a large-scale pre-training dataset with se-mantic labels is quite difficult to construct. Moreover, what matters in semantic segmentation pre-training has not been fully investigated. In this paper, we propose the Segmen-tation Radial Contour DataBase (SegRCDB), which for the first time applies formula-driven supervised learning for se-mantic segmentation. SegRCDB enables pre-training for semantic segmentation without real images or any manual semantic labels. SegRCDB is based on insights about what is important in pre-training for semantic segmentation and allows efficient pre-training. Pre-training with SegRCDB achieved higher mIoU than the pre-training with COCO-Stuff for fine-tuning on ADE-20k and Cityscapes with the same number of training images. SegRCDB has a high po-tential to contribute to semantic segmentation pre-training and investigation by enabling the creation of large datasets without manual annotation. The SegRCDB dataset will be released under a license that allows research and commer-cial use. Code is available at: https://github.com/ dahlian00/SegRCDB 1.

Introduction
Preparing a semantic segmentation dataset requires pixel-level, dense annotation, and therefore, creating a fully annotated dataset incurs a huge amount of effort. For a dataset such as Cityscapes [7], around 90 minutes per image is required for pixel-level annotation. This makes it difficult to create a large semantic segmentation dataset.
To perform training with a limited dataset, using a pre-trained model with a large-scale image dataset is a promis-ing method for enhancing network performance in terms of recognition accuracy. The use of a model pre-trained on a larger-scale image dataset has become a standard approach.
Undoubtedly, ImageNet [8] is one of the de-facto-standard
Figure 1. Segmentation Radial Contour DataBase (SegRCDB).
We developed the first formula-driven supervised learning (FDSL) method for semantic segmentation. We created a precise pixel-wise ground truth mask without manual effort. datasets, even in the semantic segmentation field. However, ethical issues have been reported in terms of dataset biases and privacy violations [24, 40, 41]. There have also been re-ports [42, 34] that one of the most frequently used segmen-tation datasets (Microsoft COCO [18]) also raises concerns regarding transfer learning due to ethical issues.
To overcome these technical (manual annotation) and ethical (fairness and dataset transparency) problems, a syn-thetic dataset can be implemented to construct a pre-trained segmentation model. Synthetic datasets for semantic seg-mentation have been created for specialized use in certain domains [27, 29, 22]. However, even though the annota-tion time is reduced, McCormac et al. reported that it took up to approximately one month using 4-12 GPUs to pro-duce a 5M-image dataset [22]. For automatic dataset cre-ation, we must define a 3D scene design that includes object categories and positional content, and consider the camera
trajectory. There is still potential for more efficient devel-opment of synthetic segmentation data that is applicable to general domains.
However, there has not been enough research to deter-mine what factors are effective in pre-training semantic seg-mentation. It is not clear which dataset parameters are use-ful for pre-training semantic segmentation, such as the num-ber of classes and the presence of occlusions. Identifying these critical parameters will allow us to build a synthetic dataset that is more efficient for pre-training semantic seg-mentation.
Formula-driven supervised learning (FDSL) [14] has been proposed and improved in the context of visual rep-resentation learning without real images. FDSL enables the automatic construction of large-scale image datasets through simultaneous image and label generation based on a simple mathematical formula. It was reported that the im-age dataset, which consists of complicated contours (e.g.,
Radial Contour DataBase; RCDB), allows effective image classification [12]. The object contours are mainly captured in the pre-training phase, and the visual representation is transferred to determine object categories in a real image.
The FDSL framework has not been applied to acquiring a visual representation for semantic segmentation.
In this paper, we propose the first formula-driven su-pervised learning for semantic segmentation and create the
SegRCDB dataset. We assume that a model pre-trained us-ing radial contours can further improve the recognition abil-ity of semantic segmentation since semantic masks are as-signed to radial contour areas. To take advantage of making image patterns and ground truth masks based on a simple equation without real-image collection or manual annota-tion, we thoroughly investigated the effectiveness of differ-ent configurations (e.g., occlusion between objects, types of mask annotation) in pre-training. The SegRCDB will con-tribute to semantic segmentation tasks and reduce the time and effort required to create ground truths for large-scale image datasets.
The main contributions of this study are as follows:
• We developed the first FDSL method for semantic seg-mentation. We created a precise pixel-wise mask (Fig-ure 1) without any manual effort.
• We investigated what elements are effective for im-proving the accuracy in pre-training for semantic seg-mentation, and created SegRCDB based on the results.
• Our SegRCDB has great potential for effectively pre-training a semantic segmentation model based on a massive amount of pixel-level ground truth. The pro-posed method performed better than the COCO-Stuff-164k baseline (e.g., 43.39 vs. 43.85 mIoU on ADE-20k) and the GTA5 baseline (e.g., 71.00 vs. 73.06 mIoU on Cityscapes). 2.