Abstract
Rain can significantly degrade image quality and visibil-ity, making deraining a critical area of research in computer vision. Despite recent progress in learning-based derain-ing methods, there is a lack of focus on nighttime derain-ing due to the unique challenges posed by non-uniform lo-cal illuminations from artificial light sources. Rain streaks in these scenes have diverse appearances that are tightly related to their relative positions to light sources, mak-ing it difficult for existing deraining methods to effectively handle them.
In this paper, we highlight the importance of rain streak location information in nighttime deraining.
Specifically, we propose a Rain Location Prior (RLP) that is learned implicitly from rainy images using a recurrent residual model. This learned prior contains location in-formation of rain streaks and, when injected into derain-ing models, can significantly improve their performance.
To further improve the effectiveness of the learned prior, we also propose a Rain Prior Injection Module (RPIM) to modulate the prior before injection, increasing the impor-tance of features within rain streak areas. Experimental results demonstrate that our approach outperforms exist-ing state-of-the-art methods by about 1dB and effectively improves the performance of deraining models. We also evaluate our method on real night rainy images to show the capability to handle real scenes with fully synthetic data for training. Our method represents a significant step forward in the area of nighttime deraining and highlights the importance of location information in this challeng-ing problem. The code is publicly available at https:
//github.com/zkawfanx/RLP. 1.

Introduction
While rain degrades image quality and visibility, it can be particularly problematic at night, because the low light condition and complex illuminations make it more difficult to distinguish rain streaks from other image features. This
*Corresponding author: fuying@bit.edu.cn (a) Rainy (b) Uformer (c) RLP (d) Ours
Figure 1: (a) In night scenes, appearances of rain are highly dependent on locations relative to light sources. (b) Derain result of state-of-the-art method Uformer [34]. (c) Visual-ization of the proposed Rain Location Prior (RLP), which indicates the location of rain streaks and suppresses areas of light sources. (d) Derain result of our method. not only hinders the performance of high-level vision algo-rithms, e.g., object detection [13, 29] and tracking [2, 35], but also poses a safety risk for autonomous vehicles [6, 28] and other applications that rely on accurate visual informa-tion. Therefore, there is an increasing need for developing nighttime deraining methods.
Unfortunately, despite recent advances in deep learning
[34, 39, 40], which have significantly improved the per-formance, current endeavors predominantly focus on day-time scenarios, leaving the realm of nighttime deraining still largely unexplored. The most frequently utilized datasets
[16, 32] scarcely encompass night scenes, neither does the synthesizing procedure consider interactions between rain and light sources. This hinders the direct application of existing methods to nighttime deraining. Recently, some datasets [20, 42] have started to cover previously ignored night scenes, which may enable careful study on nighttime deraining. Since there is no prior method specifically tar-geting nighttime deraining, we attempt to handle real night rainy scenes with the help of the recently developed dataset.
Night scenes differ from day scenes in that there is no uniform global illumination; instead, darkness and non-uniform local illuminations dominate [12, 22, 25, 41, 45].
It results in the totally different appearance of night rain, which varies drastically at different spatial locations (i.e.
only rain streaks near light sources are more discernible, as shown in Figure 2). Intuitively, it could facilitate the re-moval of rain streaks if precise locations were obtained in advance, which is often impractical in real scenes. Like-wise, it is a common practice [14, 26] to train deep models to predict the locations of raindrop (i.e. raindrop mask) in the raindrop removal community. Therefore, identifying the rain location becomes more crucial than in day scenes.
In this paper, we propose a novel deraining method tar-geting night scenes. Firstly, we highlight the importance of location information of rain streaks for nighttime derain-ing, as the appearance of rain streaks is highly varying at different spatial locations at night. Thus, we propose a Rain
Location Prior (RLP) which can be implicitly learned by re-current residual models. It can reveal the location informa-tion of rain streaks in night scenes and be incorporated into deraining methods to improve their performance, includ-ing CNN-based and Transformer-based ones. Secondly, we propose a Rain Prior Injection Module (RPIM) to increase the importance of features within rain streak areas indicated by RLP. Deraining models can focus more on recovering lost information within rain streak areas and get a further in-crease in performance. Finally, we perform comprehensive experiments to demonstrate the effectiveness of our method.
Our method outperforms existing state-of-the-art methods quantitatively and qualitatively on synthetic data. Further-more, we demonstrate the capability of our method in han-dling real scenes. We also conduct ablation studies to eval-uate the effectiveness of each component in our method. To summarize, the contributions of our paper are as follows:
• We propose a nighttime deraining method, which high-lights the importance of location information of rain streaks for night scenes.
• We propose Rain Location Prior (RLP) and Rain Prior
Injection Module (RPIM), which are the keys to re-vealing location information and boosting the perfor-mance of nighttime deraining.
• We demonstrate the state-of-the-art performance of our method on both synthetic and real night rainy scenes from rigorous experiments and ablation studies. (a) (b)
Figure 2: Comparisons between synthetic and real rainy im-ages. Synthetic images from (a) Rain100H [36], (b) GTAV-NightRain [42] and (c) real image from the Internet. (c) high-frequency details as input. Li et al. [21] proposed Re-current Squeeze-and-Excitation Context Aggregation Net (RESCAN) which is a recurrent network feeding output of the previous stage to the next one. Ren et al. [27] proposed
PReNet with recurrent and residual design to balance per-formance and model complexity. Jiang et al. [16] proposed
Multi-Scale Progressive Fusion Network (MSPFN) utiliz-ing the multi-scale and recurrent strategy. Deng et al. [7] proposed to remove rain streaks and recover lost details with two parallel sub-networks. Yi et al. [37] proposed to pro-tect structure information and guide network training with residue channel prior. Wang et al. [32] proposed SPatial
Attentive Network (SPANet) which also utilizes residual blocks. Wang et al. [31] proposed Rain Convolutional Dic-tionary Network (RCDNet) to integrate the physical struc-ture of residual rain streaks. Liang et al. [24] proposed a
Deraining Recursive Transformer (DRT) with less parame-ters. In this work, we compare with some recent deraining models on night scenes.
Image restoration backbones. Recently, powerful image restoration backbones [4, 5, 9] outperform previous meth-ods on multiple tasks. Zamir et al. [40] proposed MPRNet making full use of encoder-decoder architecture and multi-stage strategies. They also proposed Restormer [39] to effi-ciently handle high-resolution images with the Transformer model. Wang et al. [34] also proposed a Transformer-based model following U-Net architecture and achieved promis-ing performance on several tasks. While Tu et al. [30] proposed a multi-axis MLP-based architecture in a UNet-shaped hierarchical structure. Despite their robustness and capability, they fail to remove rain streaks in night scenes. 2.