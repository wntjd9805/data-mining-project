Abstract (A) CAM-based Mechanism
Weakly supervised object localization (WSOL) aims to localize objects based on only image-level labels as su-pervision. Recently, transformers have been introduced into WSOL, yielding impressive results. The self-attention mechanism and multilayer perceptron structure in trans-formers preserve long-range feature dependency, facilitat-ing complete localization of the full object extent. How-ever, current transformer-based methods predict bounding boxes using category-agnostic attention maps, which may lead to confused and noisy object localization. To address this issue, we propose a novel Category-aware Allocation
TRansformer (CATR) that learns category-aware repre-sentations for specific objects and produces correspond-ing category-aware attention maps for object localization.
First, we introduce a Category-aware Stimulation Mod-ule (CSM) to induce learnable category biases for self-attention maps, providing auxiliary supervision to guide the learning of more effective transformer representations.
Second, we design an Object Constraint Module (OCM) to refine the object regions for the category-aware attention maps in a self-supervised manner. Extensive experiments on the CUB-200-2011 and ILSVRC datasets demonstrate that the proposed CATR achieves significant and consistent performance improvements over competing approaches. 1.

Introduction
Weakly supervised learning utilizes minimal supervision or coarse annotations for training.
In particular, weakly supervised object localization (WSOL) aims to locate ob-jects using only image-level annotations, making it an at-tractive research area in various applications due to the
*Corresponding author.
Image
Feature maps
Localization map (B) Transformer-based Mechanism
Image
Feature maps
Localization map (C) Our Mechanism
Attention map
Image
Feature maps
Localization map
Attention map
Figure 1. The comparison of different mechanisms for generating localization maps: (A) The CAM-based mechanism [19, 3] uses feature maps of the class label, which tends to capture the most dis-criminative regions in the localization map. (B) The transformer-based mechanism [8, 5] combines the category-agnostic attention map with the category-aware feature map, which brings person noise to the localization map. (C) Our mechanism investigates category awareness in self-attention maps to generate a category-aware attention map, which is then coupled with the category-aware feature map to produce an accurate localization map. The predicted bounding boxes are in red. Best viewed in color. elimination of the need for costly bounding box annota-tions [4, 35, 8, 14, 1].
To tackle the challenge of WSOL with only image-level labels, most approaches [36, 32, 19, 3, 21, 9] rely on Class
Activation Maps (CAM) [38] to discover discriminative im-age regions for localizing potential target objects. How-ever, these methods tend to grossly underestimate object re-gions and produce much smaller bounding boxes than the actual range, as illustrated in Fig. 1 (A). To capture more object parts, different techniques have been proposed to en-hance CAM, such as graph propagation [40], data augmen-tation [33, 15], adversarial erasing [3, 6, 19] and spatial re-lation activation [32, 37, 9]. Despite their promising suc-cess, existing approaches still exhibit limited performance to completely localize objects, owing to the inherent char-acteristic of convolutional neural networks (CNNs) [22, 5], i.e., failing to explore the global feature relations properly.
Recently, visual transformers [26] have made significant breakthroughs in computer vision, demonstrating that pure transformers can be as effective as CNNs for feature extrac-tion. Gao et al. [8] first combined the semantic-aware to-kens with the semantic-agnostic attention map to generate a localization map. Chen et al. [5] and Bai et al. [1] further explored the local-continuous visual patterns and semantic similarities of transformers for object localization, respec-tively. The current transformer-based methods couple the attention map upon the class tokens with the feature map of the specific category to generate a localization map, as illustrated in Fig. 1 (B). The feature map of the specific cat-egory is obtained according to the ground-truth image-level class label, while the attention map upon the class tokens that captures the long-range feature dependency is category-agnostic (not distinguishable to object classes) and is not competent to category-aware localization [8]. As a result, it brings category-agnostic noise to the localization maps, which affects the generation of bounding boxes.
Based on the above analysis, we propose a simple but effective framework called Category-aware Allocation
TRansformer (CATR), which employs category informa-tion to exploit category-aware transformer attention. As il-lustrated in Fig. 1 (C), our approach focuses on generating category-aware attention maps, which can effectively learn the discriminative representation of specific object classes.
Two category-aware maps are combined to generate the lo-calization maps, which significantly reduces the impact of background clutter. Specifically, we introduce a Category-aware Stimulation Module (CSM) into the transformer at-tention mechanism, which induces a learning bias to asso-ciate self-attention maps with a specific category. CSM can be viewed as auxiliary supervision to guide the learning of more effective transformer representations and establishes a strong one-to-one connection between the self-attention maps and the corresponding classes. Moreover, we design an Object Constraint Module (OCM) to refine object re-gions for category-aware attention maps in a self-supervised manner. OCM restricts background clutter and generates pixel-level pseudo labels guided by the self-attention maps, which helps to activate precise object regions. Furthermore, we apply an automatic weighted loss mechanism [16] to ad-just the loss weights during training. To validate the effec-tiveness of the proposed CATR, we conduct comprehensive experiments on challenging WSOL benchmarks. The con-tributions of this work are as follows:
• We propose the Category-aware Allocation Trans-former (CATR) for weakly supervised object localiza-tion, which significantly enhances the category aware-ness of self-attention maps among long-range feature dependency.
• We introduce the Category-aware Stimulation Mod-ule (CSM) to learn a specific category for the self-attention maps among the different transformer blocks.
• We propose an Object Constraint Module (OCM) to refine the object regions for category-aware attention maps in a self-supervised manner.
• CATR achieves new state-of-the-art performance on the CUB-200-2011 and ILSVRC datasets with 79.62% and 56.90% Top-1 localization accuracy, respectively. 2.