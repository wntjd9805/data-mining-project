Abstract
Understanding the continuous states of objects is essen-tial for task learning and planning in the real world. How-ever, most existing task learning benchmarks assume discrete (e.g., binary) object goal states, which poses challenges for the learning of complex tasks and transferring learned policy from simulated environments to the real world. Furthermore, state discretization limits a robot’s ability to follow human instructions based on the grounding of actions and states. To tackle these challenges, we present ARNOLD, a benchmark that evaluates language-grounded task learning with con-tinuous states in realistic 3D scenes. ARNOLD is comprised of 8 language-conditioned tasks that involve understanding object states and learning policies for continuous goals. To promote language-instructed learning, we provide expert
* Equal contribution. Corresponding authors: Ran Gong, Jiangyong
Huang, Baoxiong Jia, and Siyuan Huang. demonstrations with template-generated language descrip-tions. We assess task performance by utilizing the latest language-conditioned policy learning models. Our results indicate that current models for language-conditioned ma-nipulations continue to experience significant challenges in novel goal-state generalizations, scene generalizations, and object generalizations. These findings highlight the need to develop new algorithms that address this gap and under-score the potential for further research in this area.
Project website: https://arnold-benchmark.github.io. 1.

Introduction
The ability to ground language is a crucial skill that has evolved over the course of human history, allowing people to learn and describe concepts, perform tasks, and commu-nicate with one another. While recent developments have 1
enabled the grounding of concepts in images [66, 39, 68, 21], the interaction with physical environments [10, 2, 83, 43, 61, 36, 35, 28, 26, 24, 86, 78, 9, 15], and language understand-ing in physical environments [49, 1, 64, 88, 76, 22, 79, 63], few researchers have investigated the grounding of actions in daily tasks [70, 89, 71, 80]. Given that humans can com-prehend object status and relate language instructions to the physical environment, a pertinent question arises: How can we imbue robotic systems with the same capacity to un-derstand and execute language instructions in the physical world?
Learning action grounding in daily activities is a challeng-ing task that presents several non-trivial difficulties. Firstly, robotic tasks rely heavily on detailed scene understanding for successful execution. This includes the understanding of geometry information, layouts, and visual appearances.
The various combinations of scene configurations, including novel appearances, objects, and spatial positions further ex-acerbate this challenge. Therefore, it is crucial for robotic systems to acquire generalizable skills that can be transferred to different domains and settings.
Secondly, humans possess an exquisite ability to under-stand desired goal states precisely. This ability allows us to effortlessly map from simple descriptions (e.g., a cup half filled, a door fully opened, etc.) to the precise status of phys-ical properties (e.g., half the volume, pulled to 180◦, etc.).
However, it is exceedingly challenging for robots to learn the precise goal state from abstracted language instructions, especially when referring to an implicit range of continu-ous object states (e.g., a bit of coffee, slightly open, etc.)
[41, 30, 56]. As a result, there is an urgent need for robot systems to maintain a mapping from language instructions to precise goal states in a continuous world.
A necessary first step toward tackling these challenges is to develop realistic robot simulation systems that enable
Indeed, notable recent ad-language-grounded learning. vances in simulated environments have facilitated grounded task learning [8, 72, 57, 89, 53]. Despite the impressive progress, these benchmarks suffer from several limitations that hinder the effective operation of robots in the real world: (1) They typically assume that tasks are performed in sim-ple and clean environments, rather than in scenes that are spatially occupied by clutter and visually disturbed by di-verse textured backgrounds [42, 45, 89, 71]. (2) They as-sume discrete (e.g., binary) object states and perfect motor control that ignore the low-level geometry and dynamics of objects [75, 73, 16] and, consequently, they do not at-tempt in-depth physical state understanding or fine-grained manipulation skills. (3) These benchmarks do not ground instructions to precise states [89, 70], thus neglecting the challenging problem of grounding language to object states.
To address these critical challenges of language-grounded task learning, we introduce a new benchmark, robot
ARNOLD, for grounding task instructions to precise robot actions and object states in realistic natural scenes (Fig. 1).
Specifically, we leverage a highly accurate physics simula-tion engine to create eight challenging robot manipulation tasks that include continuous robot motion, friction-based grasping, and a variety of object state manipulations. Each task is associated with a set of goals sampled from a contin-uous range of object states and their corresponding detailed task descriptions in human language form. We further pro-vide plentiful demonstrations of each task with trajectories generated with a template-based planner for robot learning.
To provide an in-depth evaluation of language-grounded task learning, we complement prior research with an evalu-ation that targets the ability of agents to generalize learned language-grounded skills to unseen scenarios, including novel scenes, novel objects, and our featured novel goal states. We have meticulously curated a collection of 40 distinctive objects and 20 scenes from open-source datasets [84, 40, 18] and designed data splits for evalu-ating different aspects of agents’ generalization ability in language-grounded task learning. Furthermore, we provide thorough experimental analyses and show that state-of-the-art language-conditioned manipulation models still suffer with regard both to grounding and generalization. Addi-tionally, we show that state modeling is crucial for tasks in
ARNOLD through carefully designed ablation studies.
In summary, ARNOLD makes the following contributions:
• A realistic 3D interactive environment with diverse scenes, objects, and continuous object states, facilitating the learning and evaluation of precise robot manipulation.
• A systematic benchmark comprising eight challenging language-grounded robotic tasks and evaluation splits for different aspects of skill generalization.
• Extensive experiments and analyses of state-of-the-art language-conditioned manipulation models, revealing their strengths and weaknesses in promoting future re-search on language-grounded task learning. 2.