Abstract
Weakly supervised object localization (WSOL) is a chal-lenging task aiming to localize objects with only image-level supervision. Recent works apply visual transformer to WSOL and achieve significant success by exploiting the long-range feature dependency in self-attention mecha-nism. However, existing transformer-based methods synthe-size the classification feature maps as the localization map, which leads to optimization conflicts between classification and localization tasks. To address this problem, we propose to learn a task-specific spatial-aware token (SAT) to con-dition localization in a weakly supervised manner. Specif-ically, a spatial token is first introduced in the input space to aggregate representations for localization task. Then a spatial aware attention module is constructed, which allows spatial token to generate foreground probabilities of differ-ent patches by querying and to extract localization knowl-edge from the classification task. Besides, for the problem of sparse and unbalanced pixel-level supervision obtained from the image-level label, two spatial constraints, includ-ing batch area loss and normalization loss, are designed to compensate and enhance this supervision. Experiments show that the proposed SAT achieves state-of-the-art per-formance on both CUB-200 and ImageNet, with 98.45% and 73.13% GT-known Loc, respectively. Even under the extreme setting of using only 1 image per class from Ima-geNet for training, SAT already exceeds the SOTA method by 2.1% GT-known Loc. Code and models are available at https://github.com/wpy1999/SAT. 1.

Introduction
Weakly supervised object localization (WSOL) aims to localize objects with only image-level labels available.
Since no expensive bounding box or pixel-level annota-â€  Corresponding author. c o
L n w o n k
-T
G
Tunable Parameters
Few-shot learning
Figure 1. GT-known Loc on ImageNet. The proposed method only needs to fine-tune a small number of parameters or requires a few training images to achieve significant improvement. tions are required, WSOL significantly reduces the cost of manual annotations [21, 44, 12, 13, 4, 43, 22, 45] and has attracted increasing attention in the research commu-nity [40, 42, 41, 39, 10, 27, 29, 28, 14, 38, 23].
As a representative work, CAM [48] extracts class acti-vation maps from the classifier as localization maps. How-ever, CAM is usually coarse and focuses on the most dis-criminative regions, leading to imprecise and incomplete localization results. To solve these problems, many CNN-based methods have been proposed, such as adversarial era-sure [22, 45, 6, 16], divergent activation [36, 40, 22], seed region growing [30, 46], regularization [18, 13, 47], feature refining [1, 37, 30], regression-based [35, 43, 9].
Recently, transformer [7, 24] has been introduced to the field of computer vision with great success. Benefiting from the long-range feature dependency, the attention map upon the class token usually can capture the object region relevant to classification in the whole image, thus it is widely used for localization in the transformer-based WSOL methods.
The pioneering work TS-CAM [8] accumulates attention maps of each layer and mixes them with semantic-aware maps to achieve localization task. Further, to address the problem that transformer lacks inherent spatial coherence
of the object, LCTR [3] and SCM [2] propose to consider cross-patch information and use activation diffusion to in-crease the local continuity of localization map, respectively.
Existing transformer-based methods synthesize the fea-ture maps learned by the classification task, such as atten-tion maps, as the localization map, and try to increase its connectivity and completeness. However, this convenient approach results in optimization conflicts between classifi-cation and localization tasks. 1) For classification, making classification feature maps learn more object regions with low discrimination will reduce the classification ability. 2)
For localization, the learning of the localization map is lim-ited by the properties of the feature maps. For example, the attention map is generated by the softmax function, which is difficult to produce a balanced and comprehensive response over the object. Therefore, to achieve a more promising localization performance and avoid optimization conflicts, it is necessary to construct task-specific parameters for the generation and learning of localization map.
Based on transformer architecture, a straightforward idea is to introduce a spatial token in the input space to aggre-gate global representation for the localization task. And the localization map can be further obtained by interacting the spatial token with each patch in the forward propagation. To this end, we propose a Spatial-Query Attention (SQA) mod-ule that takes the spatial token as a query to calculate the similarity with different patches and produces the localiza-tion map efficiently. Meanwhile, to make the spatial-aware token obtain localization supervision from image-level la-bels, the localization map is treated as a visual cue to par-ticipate in the calculation of cross attention, thus the gener-ation and learning of localization map can be well adapted to the transformer-based classification model.
Building upon this efficient SQA module, we propose a simple but effective Spatial-Aware Token (SAT) approach, as shown in Fig. 2. Specifically, a task-specific spatial token is introduced in the input space. To achieve the localization task, several SQA modules are applied in the transformer to produce localization maps learned from different layers and aggregate them together. In this way, the final localiza-tion map can maximally capture the localization knowledge from the whole classification model. However, the pixel-level supervision generated by image-level labels is sparse and unbalanced. To compensate and strengthen this super-vision, we propose two spatial constraints, including batch area loss and normalization loss. Batch area loss aims to provide a sparse area supervision with prior knowledge to compensate for the insufficient supervision. Normalization loss is employed to enhance pixel-level supervision by en-couraging the localization map to be more discriminatory.
Benefiting from the task-specific spatial token and avoid-ing optimization conflicts, SAT releases the potential of the model and achieves excellent performance in both classifi-cation and localization tasks. Besides, unlike synthetic clas-sification feature maps as localization results, the generation and learning of localization map in SAT rely mainly on an extra lightweight token, which brings advantages of data-efficiency and tuning-efficiency. As illustrated in Fig. 1,
SAT outperforms SOTA method SCM by 2.1% GT-known
Loc with less than 0.1% training data on ImageNet.
In summary, the contributions of this paper include: 1) We propose to learn a task-specific spatial token to im-plement the localization task, instead of synthesizing clas-sification feature maps, thus avoiding optimization conflicts between classification and localization tasks. 2) We propose a simple but effective spatial-aware token (SAT) pipeline for WSOL, which utilizes a spatial-query at-tention (SQA) module to generate localization map through a spatial token and supervise it with two spatial constraints, including batch area loss and normalization loss. 3) Extensive experiments show that SAT outperforms
SOTA methods by a large margin on multiple benchmarks and performs excellently even under extreme settings. 2.