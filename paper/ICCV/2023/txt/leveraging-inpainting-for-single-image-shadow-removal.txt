Abstract
Fully-supervised shadow removal methods achieve the best restoration qualities on public datasets but still generate some shadow remnants. One of the reasons is the lack of large-scale shadow & shadow-free image pairs. Unsuper-vised methods can alleviate the issue but their restoration qualities are much lower than those of fully-supervised meth-ods. In this work, we find that pretraining shadow removal networks on the image inpainting dataset can reduce the shadow remnants significantly: a naive encoder-decoder net-work gets competitive restoration quality w.r.t. the state-of-the-art methods via only 10% shadow & shadow-free image pairs. After analyzing networks with/without inpainting pre-training via the information stored in the weight (IIW), we find that inpainting pretraining improves restoration quality in non-shadow regions and enhances the generalization abil-ity of networks significantly. Additionally, shadow removal fine-tuning enables networks to fill in the details of shadow regions. Inspired by these observations we formulate shadow removal as an adaptive fusion task that takes advantage of both shadow removal and image inpainting. Specifically, we develop an adaptive fusion network consisting of two encoders, an adaptive fusion block, and a decoder. The two encoders are responsible for extracting the features from the shadow image and the shadow-masked image respectively.
The adaptive fusion block is responsible for combining these features in an adaptive manner. Finally, the decoder con-verts the adaptive fused features to the desired shadow-free result. The extensive experiments show that our method empowered with inpainting outperforms all state-of-the-art methods. We have realized codes and models in https:
//github.com/tsingqguo/inpaint4shadow 1.

Introduction
Shadows in images are formed when some objects block the light source, which not only reduces the image quality but also affects the subsequent intelligent tasks like visual ob-ject detection [34][9], objects tracking [36], face recognition
[44], face landmark detection [8], etc. Single-image shadow removal is to map the shadow regions to their shadow-free counterparts, which can enhance the visual quality and bene-fit the intelligent tasks.
In recent years, with the development of advanced learn-ing algorithms and deep architectures (i.e., GAN [12] and 1
CycleGAN [46]), deep learning-based shadow removal meth-ods [25, 10, 37] have achieved significant progress and ob-tained top restoration qualities on public datasets. How-ever, these methods may still lead to some shadow remnants.
As the two cases shown in Fig. 1, even the state-of-the-art method SG-ShadowNet [37] generates obviously inconsis-tent colors across shadow boundaries. One of the reasons is the lack of large-scale shadow & shadow-free image pairs.
The commonly-used ISTD+ dataset[24] only contains 1330 pairs of shadow and shadow-free images for training. To alleviate the requirements for the amounts of image pairs, researchers also develop weakly-supervised [11, 25, 31] and unsupervised shadow removal methods [22, 30, 20, 31].
However, all these methods still have a large gap to the fully-supervised methods (See the results in Fig. 1 (a)).
Meanwhile, several works [18, 40] have demonstrated that pretraining networks to predict masked patches from unmasked patches on a large-scale dataset can enhance the fully-supervised training on another small-scale dataset sig-nificantly. Actually, the task predicting masked patches is a special image inpainting task [27] that aims to fill miss-ing pixels. Inspired by these works, we seek to leverage the image inpainting task for high-quality shadow removal.
Specifically, given a deep network, we first train it on the image inpainting dataset where we can mask all clean im-ages randomly and get large-scale clean & masked image pairs for free. Then, we finetune the network on the shadow removal dataset with limited shadow & shadow-free image pairs. As shown in Fig. 1, a naive encoder-decoder net-work pretrained on the inpainting dataset and fine-tuned on the 10% shadow data can achieve competitive restoration qualities (i.e. RMSE) at the shadow regions w.r.t. the state-of-the-art methods (e.g., SP+M-Net [24]). Moreover, when we compare the networks with and without inpainting pre-training in the Fig. 1 (b), we see that inpainting pretraining can eliminate the shadow remnants effectively.
We further analyze the features of the networks with/without inpainting pretraining and see that inpainting pretraining not only improves restoration quality in non-shadow regions but also enhances the generalization ability of networks. This improvement in generalization ability can be proved by using the PAC-Bayes theorem to measure the amount of information stored in the networkâ€™s weights (IIW)
[38]. Furthermore, fine-tuning the networks for shadow re-moval enables them to fill in the details of shadow regions, thereby improving the overall restoration quality of the im-ages. To utilize the respective advantages of shadow removal and image inpainting, we formulate shadow removal as an adaptive fusion task of shadow removal and image inpainting where make the shadow removal and image inpainting focus on the shadow and non-shadow regions respectively. To ad-dress this task, we propose an adaptive fusion network which consisting of two encoders, an adaptive fusion block, and a decoder. The two encoders are responsible for extracting the features from the shadow image and the shadow-masked im-age respectively. The adaptive fusion block is responsible for combining the extracted features in an adaptive manner and the decoder converts the adaptively fused features into the desired shadow-free result. Our final method outperforms all state-of-the-art methods on the public datasets (See Fig. 1(a)) and reduces the shadow remnants significantly. 2.