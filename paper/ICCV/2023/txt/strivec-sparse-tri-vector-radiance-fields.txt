Abstract
We propose Strivec, a novel neural representation that models a 3D scene as a radiance field with sparsely dis-tributed and compactly factorized local tensor feature grids.
Our approach leverages tensor decomposition, following the recent work TensoRF [6], to model the tensor grids. In contrast to TensoRF which uses a global tensor and focuses on their vector-matrix decomposition, we propose to uti-lize a cloud of local tensors and apply the classic CANDE-COMP/PARAFAC (CP) decomposition [4] to factorize each tensor into triple vectors that express local feature distribu-tions along spatial axes and compactly encode a local neu-ral field. We also apply multi-scale tensor grids to discover the geometry and appearance commonalities and exploit spatial coherence with the tri-vector factorization at mul-tiple local scales. The final radiance field properties are re-gressed by aggregating neural features from multiple local tensors across all scales. Our tri-vector tensors are sparsely distributed around the actual scene surface, discovered by a fast coarse reconstruction, leveraging the sparsity of a 3D scene. We demonstrate that our model can achieve better rendering quality while using significantly fewer parame-ters than previous methods, including TensoRF and Instant-NGP [23]. 1.

Introduction
Representing 3D scenes as radiance fields [22] has en-abled photo-realistic rendering quality and emerged as a popular design choice in 3D vision and graphics appli-cations. While many methods [27, 42, 3] (following
NeRF [22]) purely use MLPs to represent neural fields, re-cent works, like TensoRF [6] and Instant-NGP [23], have demonstrated the advantages of using shared global feature encoding for radiance field modeling, in terms of speed, compactness, and quality. However, these methods share and assign neural features uniformly in a scene (with ten-sor factors or hash tables), assuming the scene content is
∗Equal contribution.
Code and results: https://github.com/Zerg-Overmind/Strivec
Figure 1: We compare with previous methods in terms of rendering quality (PSNR) and model capacity (number of parameters) on the NeRF Synthetic dataset on the bottom.
Our method and TensoRF are shown with different model sizes. Our approach consistently achieve better rendering quality with fewer model parameters than TensoRF, as well as other methods like iNGP. On the top, we show one ex-ample of visual comparisons of the mic scene that has chal-lenging fine-grained geometric structures, where our ap-proach captures most of the details and is the closest to the reference. Note that the results of NeRF and Point-NeRF use 200k optimization steps while the rest use only 30k steps. equally complex over the entire space, which can be inef-ficient (requiring high model capacity) to accurately model intricate local scene details (see Fig.1).
We aim to accurately and compactly model a 3D scene and reproduce the complex local details. To this end, we propose Strivec, a novel neural scene representation that utilizes sparsely distributed and compactly factorized local tensor grids to model a volumetric radiance field for high-quality novel view synthesis. As shown in Fig.1, our ap-proach is able to accurately model the complex scene struc-tures that are not recovered well by previous methods. More importantly, our superior rendering quality is achieved with much less model capacity.
In particular, we base our model on TensoRF [6], a recent approach that leverages tensor factorization in radiance field modeling. It is fast, compact, and of high rendering quality.
TensoRF applies CP and vector-matrix (VM) decomposi-tion techniques to factorize a field into vectors and matri-ces and model the entire scene as a global factorized ten-sor. Instead of a single global tensor, we leverage a sparse set of multiple small local tensors distributed around the scene surface for more efficient scene modeling. Specifi-cally, each of our tensors represents a local radiance field in-side its local bounding box and is compactly modeled with factorized triple vectors based on the CP decomposition.
Note that the global CP decomposition in TensoRF has led to a highly compact model but cannot achieve compa-rable rendering quality to their VM decomposition. This is because a tri-vector CP component is rank-one, while a global feature grid of an entire 3D scene is often complex and of high rank, requiring a large (impractical) number of
CP components for high accuracy. TensoRF addresses this by introducing matrix factors in their VM decomposition, essentially increasing the rank of each tensor component.
Our model instead consists of multiple small tensor grids, exploiting local spatial commonalities in a scene. Com-pared to a global tensor, our local tensor is less complex and of much lower rank, thus effectively reducing the required number of CP components (per tensor) and enabling prac-tical high-quality radiance field reconstruction with highly compact tri-vector factors. Our local tri-vector tensors can lead to superior rendering quality and compactness over
TensoRF’s VM model (see Fig. 1). We also observe that our local tensors are generally more robust than a global tensor against the orientation of spatial axes (which can affect the rank of a tensor and thus affects the quality; see Fig. 2).
Importantly, adopting local tensors (instead of a global one) also brings us the flexibility to allocate neural features according to the actual scene distribution, enabling more efficient scene modeling and better usage of model param-eters than a global representation. To do so, we pre-acquire coarse scene geometry – that can be easily achieved via a fast RGBσ volume reconstruction (like DVGO [32]) or multi-view stereo (like Point-NeRF [39]) – to directly dis-tribute local tensors around the actual scene surface, leading to a sparse scene representation that avoids unnecessarily modeling the empty scene space. Note that while previous methods have also leveraged sparse representations (with voxels [19, 41] or points [39]) of radiance fields, their lo-cal features are modeled and optimized independently. Our model instead correlates a group of local features inside a local box and compactly express them with triple vectors, uniquely exploiting the local spatial coherence along axes and imposing local low-rank priors in the feature encoding via tensor factorization. Moreover, unlike previous sparse representations that only use a single-scale feature grid or point cloud, we distribute multi-scale local tensors to effec-tively model the scene geometry and appearance at multiple scales in a hierarchical manner. In particular, for an arbi-trary 3D location, we aggregate the neural features from its neighboring tri-vector components at all scales and decode the volume density and view-dependent color from the ag-gregated features for radiance field rendering.
Our approach takes the best of previous local and global radiance field representations. Compared with global repre-sentations like TensoRF and Instant-NGP, our model takes advantage of the sparsity of a scene more directly; com-pared with local representations like Plenoxels and Point-NeRF, our model makes use of the local smoothness and coherence of scene geometry and appearance. As shown in our experimental results on both synthetic and real datasets, our model is able to achieve state-of-the-art rendering qual-ity on these datasets, outperforming previous methods, in-cluding TensoRF and Instant-NGP, while using significantly fewer model parameters, demonstrating the superior repre-sentational power of our model. 2.