Abstract
Unsupervised domain adaptation (DA) with the aid of pseudo labeling techniques has emerged as a crucial ap-proach for domain-adaptive 3D object detection. While ef-fective, existing DA methods suffer from a substantial drop in performance when applied to a multi-class training set-ting, due to the co-existence of low-quality pseudo labels and class imbalance issues. In this paper, we address this challenge by proposing a novel ReDB framework tailored for learning to detect all classes at once. Our approach produces Reliable, Diverse, and class-Balanced pseudo 3D boxes to iteratively guide the self-training on a distribu-tionally different target domain. To alleviate disruptions caused by the environmental discrepancy (e.g., beam num-bers), the proposed cross-domain examination (CDE) as-sesses the correctness of pseudo labels by copy-pasting tar-get instances into a source environment and measuring the prediction consistency. To reduce computational overhead and mitigate the object shift (e.g., scales and point densi-ties), we design an overlapped boxes counting (OBC) metric that allows to uniformly downsample pseudo-labeled ob-jects across different geometric characteristics. To confront the issue of inter-class imbalance, we progressively aug-ment the target point clouds with a class-balanced set of pseudo-labeled target instances and source objects, which boosts recognition accuracies on both frequently appearing and rare classes. Experimental results on three benchmark datasets using both voxel-based (i.e., SECOND) and point-based 3D detectors (i.e., PointRCNN) demonstrate that our proposed ReDB approach outperforms existing 3D domain adaptation methods by a large margin, improving 23.15% mAP on the nuScenes → KITTI task. The code is available at https://github.com/zhuoxiao-chen/ReDB-DA-3Ddet. 1.

Introduction
As LiDAR-based 3D object detection continues to gain traction in various applications such as robotic systems
[1, 40, 60, 56, 83, 74] and self-driving automobiles [8, 59,
Figure 1: Top: An illustration of the domain gap in 3D point clouds. Bottom: Average Precision (AP) drop of ST3D [70] when applied to the multi-class adaptation from nuScenes to KITTI (left), and from Waymo to KITTI (right). 42, 61, 2, 78, 37, 39, 32, 25, 38], it becomes increasingly vital to address the challenges of deploying detectors in real-world scenes. The primary obstacles stem from the discrepancy between the training and test point cloud data, which are commonly curated from different scenes, loca-tions, times, and sensor types, creating a domain gap. This domain gap mainly comes from the object shift and envi-ronmental shift, and can significantly degrade the prediction accuracy of 3D detectors. Object shift [62, 36] refers to the changes in the spatial distribution, point density, and scale of objects between the training and test domains. For in-stance, the average length of cars in the Waymo dataset [52] is significantly different from the one in the KITTI dataset
[15] by around 0.91 meters [62]. Environmental shift, on the other hand, arises from composite differences in the sur-rounding environment such as inconsistent beam numbers, angles, point cloud ranges, and data acquisition locations.
For example, in Fig 1, Waymo generates 3D scenes by 64-beam LiDAR sensors, while nuScenes [3] comprises more sparse 32-beam environments with double large beam an-gles.
The co-existence of object shift and environmental shift poses a great challenge to the 3D detection models to be deployed in the wild. To combat such a problem, domain-adaptive 3D detection approaches [36, 71, 70, 79, 80] have been exploited to adapt the model trained on a labeled dataset (i.e., source domain) to an unlabeled dataset from a different distribution (i.e., target domain).
In this area, pioneering research of ST3D [70] presents a self-training paradigm that generates pseudo-labeled bounding boxes to supervise the subsequent learning on the target point clouds.
In the same vein, later studies [36, 79, 71, 76, 77] seek dif-ferent solutions based on self-supervised techniques, such as mean-teacher framework [36] and contrastive learning
[79] for stable optimization and obtaining better embed-dings.
Revisiting Domain-adaptive 3D Detection Setup.
The aforementioned domain-adaptive 3D detection approaches have typically followed a single-class training setting, where the models are trained to adapt to each class sepa-rately. While it is more practical and fairer to train the mod-els with all classes, our empirical study has shown that the detection performance of prior works decreases consider-ably when switching to a multi-class setting (Fig 1). Such an average precision (AP) drop can be attributed to the poor quality of produced pseudo labels (i.e., erroneous and re-dundant) and the lower recognition accuracy of rare classes (e.g., 91 times fewer bicycles than cars in Waymo [52]).
In this work, we propose a novel REDB framework (Fig 2) that aims to generate Reliable, Diverse, class-Balanced pseudo labels for the domain-adaptive 3D detection task.
Our approach addresses the challenge of multi-class learn-ing by incorporating the following three mechanisms:
Reliability: Cross-domain Examination. To remove er-roneous pseudo labels of high confidence and avoid error accumulation in self-training, we introduce a cross-domain examination (CDE) strategy to assess pseudo label reliabil-ity. After copying the pseudo-labeled target objects into a familiar source environment, the reliability is measured by the consistency i.e., Intersection-over-Union (IoU) between two box predictions in the target domain and the source domain, respectively. Any objects with low IoUs will be considered unreliable and then discarded. To prevent point conflicts between the source and target point clouds, we re-move the source points that fall within the region where pseudo-labeled objects will be copied to. The proposed
CDE ensures that the accepted pseudo-labeled instances are domain-agnostic and less affected by environmental shifts.
Diversity: OBC-based Downsampling. To avoid redun-dant pseudo labels that are frequently and similarly scaled, it is important to prevent the trained detector from collaps-ing into a fixed pattern that may only detect certain types of objects (e.g., small-sized cars), and miss other instances of unique styles (e.g., buses and trucks). In order to enhance geometric diversity, we derive a metric called overlapped boxes counting (OBC) metric to uniformly downsample the pseudo labels. The metric design is motivated by the ob-servation that 3D detector tends to predict more boxes for objects with uncommon geometries, as they are harder to lo-calize with only a few tight boxes. We count the number of regressed boxes surrounding each detected object as OBC and use kernel density estimation (KDE) to estimate its em-pirical distribution. We then apply downsampling according to the inverse probability of KDE, effectively reducing the number of pseudo labels in the high-density OBC region, where objects have similar and frequent geometries. By learning from a diverse subset of pseudo labels, the 3D de-tector can better identify objects of various scales and point densities, potentially mitigating object shift.
Balance: Class-balanced Self-Training. Despite the fact that reliable and diverse pseudo labels can be selected by the previous two modules, there still exists a significant inter-class imbalance. To achieve class-balanced self-training, we randomly inject pseudo-labeled objects into each target point cloud, with an equal number of samples from each category. By learning from such class-balanced target data, the model can better grasp the holistic semantics of the tar-get labels. To enable a smooth transition of learning from the source data to the target data, we first augment the target data with labeled source objects in a class-balanced manner for the initial few steps. We then gradually reduce the ratio of source objects and increase the number of RED labels as the self-training proceeds. This progressive class-balanced self-training allows the model to adapt stably to the target domain, enhancing recognition for both frequently appear-ing and rare classes.
Our work rectifies the setup of domain-adaptive 3D detection to a multi-class scenario and proposes a novel
REDB framework for pseudo labeling in domain-adaptive 3D detection. Extensive experiments on three large-scale testbeds evidence that the proposed REDB is of exceptional adaptability for both voxel-based and point-based contem-porary 3D detectors in varying environments, improving 3D mAP of 20.66% and 23.15% over state-of-the-art methods on the nuScenes → KITTI tasks, respectively. 2.