Abstract
Mitochondria, as tiny structures within the cell, are of significant importance in studying cell functions for biolog-ical and clinical analysis. And exploring how to automat-ically segment mitochondria in electron microscopy (EM) images has attracted increasing attention. However, most of existing methods struggle to adapt to different scales and appearances of the input due to the inherent limita-tions of the traditional CNN architecture. To mitigate these limitations, we propose a novel adaptive template trans-former (ATFormer) for mitochondria segmentation. The proposed ATFormer model enjoys several merits. First, the designed structural template learning module can acquire appearance-adaptive templates of background, foreground and contour to sense the characteristics of different shapes of mitochondria. And we further adopt an optimal transport algorithm to enlarge the discrepancy among diverse tem-plates to activate corresponding regions fully. Second, we introduce a hierarchical attention learning mechanism to absorb multi-level information for templates to be adaptive scale-aware classifiers for dense prediction. Extensive ex-perimental results on three challenging benchmarks includ-ing MitoEM, Lucchi and NucMM-Z datasets demonstrate that our ATFormer performs favorably against state-of-the-art mitochondria segmentation methods.
Figure 1. Comparison of the previous methods and our method. (a)
Most existing methods use the traditional CNN architecture to ex-tract features, with a simple and weight-fixed classifier at the end of the network for per-voxel classification, resulting in incomplete or missing activation. (b) We propose a set of learnable vectors as adaptive templates of background, foreground and contour, which interact with multi-scale features to aggregate structure-aware in-formation. Then, these templates are used as appearance-adaptive scale-aware classifiers to generate more accurate activation for mi-tochondria of different scales. 1.

Introduction
Studying the morphology of mitochondria is vital for understanding cell physiology, and changes in their shape are tightly linked to neurodegeneration, lifespan and cell death [6, 4, 19, 36]. As representative membrane-bound or-ganelles, mitochondria provide power for cells as the main
*Equal contribution
†Corresponding author. place to perform aerobic respiration [49, 36, 5, 52], how-ever, their micrometer size makes it challenging to conduct observational analysis. Electron microscopy (EM), as one of the practical tools for investigating the morphology of structures at the sub-cubic millimeter scale [38, 41], en-ables neuroscientists to obtain images with higher resolu-tion. Due to its large data size and numerous cluttered irrelevant organelles, manual labeling is extremely time-consuming and labor-intensive, which leads to the persistent desire for automatic segmentation algorithms of mitochon-dria.
With significant advances in deep learning (DL), DL-based methods have paved the way for new research direc-tions toward automated mitochondria segmentation. As a representative work, Liu et al. [24] produce segmentation results of mitochondria after the detection process inspired by Mask R-CNN [15], while Cellpose [40] adopts a stan-dard U-Net [37] to generate final predictions. Notably, the above methods only utilize 2D networks to learn the rep-resentation of volumetric EM images, neglecting the asso-ciation between slices in 3D space. To alleviate this issue, recent works design the fully automated pipeline for seg-mentation based on 3D convolutional network [54, 52], in which several consecutive slices are leveraged as input to achieve promising results.
Recently, some methods in biomedical image analy-sis [9, 14, 2, 13, 16] introduce the transformer [46] architec-ture for feature encoding. However, they still use the con-ventional decoder for upsampling and a convolution-based classifier for prediction, thus fail to explore the full potential of transformers, leaving two issues to be solved: (1) Unsuit-able to handle large appearance variations. When deal-ing with diverse input images during inference, it is hard to handle large variations in appearance by adopting a weight-fixed classifier as shown in Figure 1(a). Especially in real
EM images, mitochondria exist in a variety of appearances, such as rings, threads, dumbbells, etc. Thus it is essential to empower the classifier to be appearance-adaptive to sense the characteristics of different types of mitochondria. (2)
Unaware of scale variations. Existing methods leverage a conventional CNN-based classifier for dense prediction, which cannot adapt to large-scale variations and fully ex-ploit the hierarchical information to recognize objects with significantly different sizes in 3D space accurately. There-fore, it is crucial to design scale-friendly classifiers in order to achieve a better performance with more accurate segmen-tation of mitochondria of all sizes.
In this paper, we propose a novel Adaptive Template
Transformer (ATFormer) to obtain adaptive scale-aware classifiers tailored for mitochondria segmentation, includ-ing a structural template learning module and a hierarchical attention learning mechanism. In the structural template learning module, to obtain appearance-adaptive classi-fiers and capture structure-aware information, we design three groups of learnable templates aiming to three specific categories (background, foreground and contour). Each category corresponds to several complementary templates rather than a single one. Benefiting from the strong abil-ity of transformers, we can obtain appearance-adaptive tem-plates by cross-attention with voxel embeddings. Besides, to avoid the possibility of different templates perceiving repetitive area information, we further propose a regular-ization term with an optimal transport algorithm to enlarge the discrepancy among diverse templates. In the hierarchi-cal attention learning mechanism, in order to attain scale-aware classifiers from coarse to fine level, we elegantly de-sign several attention gates which enhance the context ex-traction by self-attention and transport multi-level features into each layer of the structural template learning module, making templates absorb hierarchical information. In this way, the structural templates then aggregate explicit suffi-cient semantic information and evolve into adaptive scale-aware classifiers, so that our network can further strengthen the integrity region with finer activation of the whole mito-chondria of different scales.
To sum up, our contributions can be summarized as fol-lows:
• We propose a novel adaptive template transformer (AT-Former) for mitochondria segmentation in EM images.
Specifically, we design the structural template learning module to acquire adaptive templates of background, foreground and contour for dense predictions, and the hierarchical attention learning mechanism to make the templates adapt to mitochondria of different scales.
• To make the distribution of adaptive templates more discrete and diverse, we further adopt a regularization term with an optimal transport algorithm for full acti-vation.
• Extensive experimental results on three challenging benchmarks including MitoEM, Lucchi and NucMM-Z demonstrate that our proposed method performs fa-vorably against state-of-the-art mitochondria segmen-tation methods. 2.