Abstract
Recent studies have investigated how to achieve robust-ness for unsupervised domain adaptation (UDA). While most efforts focus on adversarial robustness, i.e. how the model performs against unseen malicious adversarial per-turbations, robustness against benign common corruption (RaCC) surprisingly remains under-explored for UDA. To-wards improving RaCC for UDA methods in an unsuper-vised manner, we propose a novel Distributionally and Dis-cretely Adversarial Regularization (DDAR) framework in this paper. Formulated as a min-max optimization with a distribution distance, DDAR1 is theoretically well-founded to ensure generalization over unknown common corrup-tions. Meanwhile, we show that our regularization scheme effectively reduces a surrogate of RaCC, i.e., the perceptual distance between natural data and common corruption. To enable a abetter adversarial regularization, the design of the optimization pipeline relies on an image discretization scheme that can transform ”out-of-distribution” adversar-ial data into “in-distribution” data augmentation. Through extensive experiments, in terms of RaCC, our method is su-perior to conventional unsupervised regularization mech-anisms, widely improves the robustness of existing UDA methods, and achieves state-of-the-art performance. 1.

Introduction
Although Deep Neural Networks have achieved impres-sive performance for various applications [15, 19, 14, 39, 27, 34], they may not generalize well on new data due to the data distribution shift problem. One of such shift is
*Majority of the work was done at Duke Kunshan University.
†Corresponding author. 1The codes are available at https://github.com/gzqhappy/DDAR. called domain shift where data may come from a new tar-get domain.Unsupervised Domain Adaptation (UDA) aims to address this domain shift with access to labeled source domain data and unlabeled target domain data. The funda-mental objective is to infer the domain-invariant representa-tions [9, 63] from data.
The vanilla UDA task assumes the data of the target do-main is all clean without any corruption, which is unfortu-nately impractical in most cases. In other words, the tar-get domain not only faces the label scarcity problem but also may suffer from the data corruption problem, includ-ing common corruption [16] and adversarial attack [30].
As such, recent studies have investigated how to achieve robustness for UDA. While most efforts [59, 3, 11] fo-cus on applying Adversarial Training (AT) [29] to improve
UDA’s robustness against the malicious adversarial pertur-bations [48, 13] (i.e. small perturbations imperceptible to humans which can however easily fool the model), robust-ness against benign common corruption (RaCC)[16] sur-prisingly remains under-explored.
Common corruptions such as noise, blur, and digital defects that may occur in the real world are more rel-evant to practical applications [16].
For instance, au-tonomous cars should be able to identify pedestrians in un-usual weather that would incur heavy noise from their sen-sors [45]. In recent studies, one of the main interests has fo-cused on investigating data-dependent regularization meth-ods [17, 62, 54, 6, 12, 40, 46, 22, 31].
However, conventional methods are not directly applica-ble to UDA. The primary reason is that most of the previ-ous methods rely on supervised learning, while labels are not available in UDA tasks. Therefore, an unsupervised approach needs to be explored. On the other hand, data augmentation methods commonly come up with trade-offs between robustness and standard accuracy during or after
training. For instance, some heuristic transformations im-prove performance on some types of corruptions but reduce significantly the performance on clean images [42]; AT with conventional adversarial data (in pixel-space) suffers from over-smoothed decision boundary [56] and sharper train-ing loss landscape [26], since strong ”attack” introduced by augmented Out-of-distribution data in maximization stage.
Despite the importance of RaCC, only a few studies have investigated it in UDA. The pioneered study [57] reveals that adversarial data enlarging the domain shift can be a surrogate of common corruption. Since the adversarial data are generated in the pixel space, the training process has to rely on strong supervision provided by a noisy teacher, a pre-trained UDA model. As a result, an effective unsu-pervised regularization mechanism for UDA has not been investigated.
This paper investigates an unsupervised adversarial reg-ularization framework to improve RaCC for UDA, named
Distributionally and Discretlly Adversarial Regulariza-tion (DDAR). Different from conventional classifier-tailored method [31, 51, 64, 37, 25, 24, 4], DDAR formulates a min-max optimization by using a distribution distance. The generated adversarial data are considered as the worst-case w.r.t. the latent distribution of natural data so that some other perturbed data (not only the worst ones w.r.t. classi-fier but those crucial for common corruptions) are also im-plicitly considered. As such, minimizing the distribution distance between natural data and adversarial data enables the model to generalize well on unknown types of common corruptions that share similar distribution with adversarial data. Moreover, to enable a abetter adversarial regulariza-tion, leveraging the insight from [31], we integrate an image discretization (ID) scheme into our optimization pipeline.
ID transforms the pixel-space adversarial data into an ”in-distribution” data augmentation which alleviates problem-atic regularization of AT.
To further improve the regularization performance, we update the distribution distance measurement to the Wasser-stein distance on semantic space. Theoretically, we demon-strate that the proposed adversarial regularization certifies a tighter upper bound than previous methods by encouraging a better-estimated hypothesis-induced distribution distance.
Empirically, compared with the previous unsupervised ap-proach, such as the virtual adversarial training (VAT) [33] and adversarial feature desensitization (AFD) [4], our ap-proach achieves much better generalization to unknown common corruptions by reducing the perceptual distance
[32] between natural data and common corruptions, which can be considered as an effective indicator for RaCC.
In a nutshell, our key contributions are listed as follows: 1) We propose an unsupervised adversarial regulariza-tion method, working as a plug-in component, to enable ro-bustness against common corruptions for UDA methods. 2) While it is theoretically well-founded, our novel reg-ularization mechanism empirically certifies a better gener-alization over the multiple types of common corruptions, compared with previous unsupervised methods. 3) Through extensive experiments on UDA benchmarks, our method consistently improves RaCC of various UDA methods, achieving new state-of-the-art. 2.