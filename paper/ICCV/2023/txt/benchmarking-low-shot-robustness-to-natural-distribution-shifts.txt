Abstract
Robustness to natural distribution shifts has seen re-markable progress thanks to recent pre-training strategies combined with better fine-tuning methods. However, such fine-tuning assumes access to large amounts of labelled data, and the extent to which the observations hold when the amount of training data is not as high remains unknown.
We address this gap by performing the first in-depth study of robustness to various natural distribution shifts in dif-ferent low-shot regimes: spanning datasets, architectures, pre-trained initializations, and state-of-the-art robustness interventions. Most importantly, we find that there is no single model of choice that is often more robust than others, and existing interventions can fail to improve robustness on some datasets even if they do so in the full-shot regime. We hope that our work will motivate the community to focus on this problem of practical importance. Our code and low-shot subsets are publicly available at this url. 1.

Introduction
In the past decade, Computer Vision has made significant progress due to advanced architectures like Convolutional
Neural Networks (CNNs) and Vision Transformers (ViTs), large datasets, and sophisticated training strategies [1, 2, 3, 4]. However, early learning techniques heavily focused their evaluation on ImageNet [5] performance, which raised concerns about their ability to generalize to distribution shifts [6, 7]. To address this, researchers have proposed a wide-range of evaluation datasets [8, 9, 10, 11, 12] that can be used to measure out-of-distribution (OOD) performance of models trained and validated with in-domain (ID) data.
Recent methods [13, 14, 15, 16, 17] use self-supervised or large-scale vision-language pre-trained models (such as
CLIP [4]) and fine-tune them on fully labelled ID data to achieve impressive performance on such datasets. Unfortu-nately, fine-tuning requires large amounts of data and com-pute that may not be accessible to most practitioners. More-∗Equal contribution; ⋆Project lead; †Currently affiliated with AWS AI
Labs, work done prior to joining.
Figure 1: Low-Shot Robustness Setting. (a) We assume access to a pre-trained model trained on large-scale datasets such as Ima-geNet [5] and limited in-domain images (in the order of thousands) for training. We use different kinds of fine-tuning methods that have been shown to improve robustness when there is typically or-der of magnitudes higher training data. (b) We then evaluate the (low-shot) fine-tuned model on out-of-domain (OOD) data. over, it can be difficult and expensive to collect and consis-tently annotate such data, especially in settings like camera traps where images can vary significantly in quality, light-ing, and pose (e.g iWildCam [18]). Such challenges are also echoed by prior work [19] and compounded by the fact that many images may belong to rare or endangered species, making annotations even more difficult to obtain. There-fore, it is important to study which models and fine-tuning methods provide strong OOD robustness performance when trained with few ID images. We refer to this setting of fine-tuning a pre-trained model on low-shot ID images followed by evaluation on OOD images as the “low-shot robustness” setting (see Fig. 1).
From works that demonstrate robustness in the full-shot regime, we seem to arrive at the following conclu-sions for robustness to natural distribution shifts in the full-shot regime: (1) Amongst ImageNet pre-trained initializa-tions, SSL ViTs are more robust than their supervised and
CNN counterparts, with the more recent ones being better
[13, 14]. (2) Even without additional robustness interven-tions (i.e. methods to improve robustness), pre-trained mod-els on large external datasets such as CLIP [4] provide supe-rior robustness [16]. (3) Such models when combined with 1
state-of-the-art robustness interventions lead to significant robustness improvements on several datasets [15, 16, 17].
In this paper, we question to what extent these conclusions hold true when the amount of training data is not as high.
Overall, we perform the first in-depth study of robust-ness to various natural distribution shifts in different low-shot regimes: spanning datasets, architectures, pre-trained initializations, and state-of-the-art robustness interventions.
Through our experiments, we aim to answer the following key questions:
Q1. For ImageNet pre-trained models, what kind of pre-training strategies and architectures are most effective for robustness in low-shot regimes?
A: Self-supervised ViTs generally perform better than
CNNs and the supervised counterparts (where applicable) on both ID and OOD shifts, but no single initialization or model size works better across datasets.
• For ImageNet and iWildCam [18] datasets, MSN
ViT [14] performs better than other models on OOD shifts, however a smaller model size (ViTS-16) works better for iWildCam but not for ImageNet.
• For Camleyon [20] dataset which is non object-centric, DINO ViTS-16 [21] outperforms other models including DINO ViTB-16 and MSN ViTS-16 on both ID and OOD shifts.
Q2. Do models pre-trained on large external datasets, such as CLIP, provide superior robustness compared to
ImageNet pre-trained ones on different datasets?
A: While we generally conform with the findings of re-cent works [15, 16, 17] and find that models such as CLIP
[4] provide superior robustness on ImageNet and in full-shot regimes, we find that ImageNet pre-trained models can be better on other datasets such as iWildCam and
Camelyon in the low-shot regimes.
• Comparing ViTB-16 architecture on these datasets,
DINO initialization outperforms CLIP (zero-shot or otherwise) and ImageNet-21k [22] supervised ViT on both ID and OOD shifts.
• ImageNet supervised ViT [23] significantly outper-forms ImageNet-21k supervised ViT on OOD shifts.
Q3. When using robustness interventions, does better ro-bustness in the full-shot regime also imply better robust-ness in the low-shot regimes?
A: Not always. We find that depending on the initializa-tion, existing interventions can fail to improve robustness in the full-shot regime or in some of the low-shot regimes for datasets other than ImageNet.
• On iWildCam, interventions often fail to improve robustness with MSN ViTB-16 in the full-shot regime. On the other hand, only WiSE-FT [16] sig-nificantly improves robustness with CLIP ViTB-16 in both the full and low-shot regimes.
• On Camelyon, while interventions often improve robustness in the full-shot regime for both MSN and
CLIP ViTB-16, they fail to do so either in extreme (∼ 3000 images) or in moderate (∼ 15000 images) low-shot regimes, except WiSE-FT with CLIP.
As highlighted by our findings, conventional wisdom for robustness to natural distribution shifts in the full-shot regime might not apply in the low-shot regimes, and should be seen as an important challenge for future work. 2.