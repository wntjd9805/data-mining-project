Abstract
Efficient detectors for edge devices are often optimized for parameters or speed count metrics, which remain in weak correlation with the energy of detectors. However, some vision applications of convolutional neural networks, such as always-on surveillance cameras, are critical for en-ergy constraints. This paper aims to serve as a baseline by designing detectors to reach tradeoffs between energy and performance from two perspectives: 1) We extensively analyze various CNNs to identify low-energy architectures, including selecting activation functions, convolutions oper-ators, and feature fusion structures on necks. These under-appreciated details in past work seriously affect the energy consumption of detectors; 2) To break through the dilem-matic energy-performance problem, we propose a balanced detector driven by energy using discovered low-energy com-In addition to the novel con-ponents named FemtoDet. struction, we improve FemtoDet by considering convolu-tions and training strategy optimizations. Specifically, we develop a new instance boundary enhancement (IBE) mod-ule for convolution optimization to overcome the contradic-tion between the limited capacity of CNNs and detection tasks in diverse spatial representations, and propose a re-cursive warm-restart (RecWR) for optimizing training strat-egy to escape the sub-optimization of light-weight detectors by considering the data shift produced in popular augmen-tations. As a result, FemtoDet with only 68.77k parameters achieves a competitive score of 46.3 AP50 on PASCAL VOC and 1.11 W & 64.47 FPS on Qualcomm Snapdragon 865
CPU platforms. Extensive experiments on COCO and TJU-DHD datasets indicate that the proposed method achieves competitive results in diverse scenes. 1.

Introduction
The deployment of efficient convolutional neural net-works (CNNs) enabled immense progress [23, 29, 30, 31, 4, 9, 41] in vision detectors for edge devices, in which they
∗Corresponding author; First author’s Email: yh.peng.tu@gmail.com consistently reduce parameters and speed counts for im-proving accuracy. However, these metrics are not correlated well with the efficiency of the models in terms of energy.
Evaluation metrics, such as parameters, do not take into ac-count the energy cost of models, resulting in a nontrivial effect on the energy cost of detectors. Compared with the same architecture, the parameters of models are positively correlated with their energy cost (shown in Table 2). How-ever, in the case of equal model parameters, their energy consumption may be negatively correlated or even irrele-vant to the model parameters (shown in Table 1). Consider-ing that various activation functions, convolution operators, and feature fuse structures may not increase model param-eters, but generate more energy costs. Similarly, the speed count is also not well correlated with energy, as it can be op-timized by the degree of parallelism. These disconnections will leave customized efficient detectors unavailable, when they are deployed under severe energy constraints like the always-on surveillance cameras.
This paper aims to reduce the energy costs of efficient object detectors, while improving their performances by achieving energy versus performance tradeoffs. Specifi-cally, these bottlenecks fall into several categories: 1) Detector components with unknown energy. Most current object detection methods focus either on latency-oriented [5, 34, 44] or accuracy-oriented [9, 38, 32, 36] works. There are very limited works toward the energy cost of the detector components, which is the first obstacle to designing energy-performance-balanced detectors. To iden-tify energy-efficient components of detectors, we followed
[42] to benchmark their energy metrics from three types of structures, i.e., activation functions, convolution opera-tors, and necks of detectors. The following finding is ac-quired: Firstly, some activation functions have been widely used, because of their ability to improve models without adding more parameters. They have increased costs, yet received very limited attention. As shown in Table 1, we set ReLU [1] based models as a baseline. When replac-ing the ReLU with the GELU [16], 4.40% performance is gained, while 12.50% energy cost is increased, and the corresponding factor of the mean energy versus the perfor-mance tradeoffs (Eq. 1) drops 7.16%. In addition, although large kernel convolutions [25] can improve models (Table 2), the increased energy cost is unacceptable. As seen in
Table 2, the large kernel convolutions are equipped to en-able the model to rise by around 1.87% in performance, but with more energy costs (16.20%) than in the small kernel size of convolutions (shown in the second row of Table 2).
Finally, the standard FPN [21, 22, 39, 10, 37] in the de-tectors also causes significant energy costs. We observe that this situation is happened due to multi-feature fusion paths following either bottom-to-up or top-to-down way, re-sulting in frequent data reading in memory for data cover-age. However, it is shown that the up-down fusion between multi-features may not necessary. As shown in Table 3, we propose a simple SharedNeck for replacing FPN to reduce around 5.77% energy costs, while obtaining 6.25% perfor-mance gains. SharedNeck uses an adaptive fusion between multi-features by learning convolution, instead of feature-by-feature bottom-to-up or top-to-down fusions, as operated in FPN. Based on these analyses, we further build upon a low-energy detector, named FemtoDet. Surprisingly, Fem-toDet just has 68.77k parameters and 1.1W power on the platform. 2) Optimization for CNN is another bottleneck, since obtaining a favorable detector is very challenging, es-pecially for a small number of parameters. Light-weight de-tectors are restricted by their limited capacities [6], which will cause obfuscation on feature maps of the instances’ boundaries of interesting objects, as shown in Figure 2 (b).
Ambiguous instance boundaries on the features may raise the risk of false detection in the models. For this prob-lem, we propose a novel instance boundary enhancement module (IBE), which emphasizes the potential of the object boundary information: The parameter reuse mechanism is first applied to integrate local descriptors with convolution operation to make robust and diverse instance boundary fea-ture representation. But this operation would cause feature un-alignment between normal features and integrated fea-tures. Then, in order to sufficiently exploit these two types of features, we design dual-normalization in IBE, as to re-align the features (Fig. 4 of the Appendix). IBE employs a shared convolution yet an independent batch normaliza-tion layer for separate normalization is also adopted. Fi-nally, we add normal and integrated features together be-hind the dual-normalization layer.
IBE provides a novel form of parameter reuse to generate new local descriptors from shared convolution operators. This method can cap-ture object boundary information by integrating gradient cues around the learned convolution. After trained, IBE modules can be folded into simple convolution operators, thus requiring no extra computations anymore; In addi-tion, data augmentation is a common approach for efficient detector training. Using well-designed strong augmenta-tions is conducive to improving the generalization of mod-els [31, 9]. However, how to prevent data shifts between training and validation images has not been explored, while training data suffers strong augmentations. It is found that the produced data shifts by strong augmentations would prevent light-weight detectors from moving toward global optimization. A common view is that strong image augmen-tations can effectively encourage networks to learn diverse features [11]. But for light-weight detectors, these diverse features cannot assist the models in making better general-izations in the validation set. In other words, light-weight detectors are more susceptible to these ignored data shifts because of their limited capacities. Furthermore, we pro-pose an effective training strategy, namely recursive warm-restart (RecWR), to adapt these diverse features to improve the model’s generalization. RecWR works based on multi-stage training while gradually weakening data augmenta-tion strength. This method can help the limited-capacity detectors jump out of local optima under the assistance of high-dimension & diverse features. The effectiveness of the IBE and RecWR has been evaluated on PASCAL VOC dataset. And the experimental results show that IBE can improve FemtoDet ∼ 7.72% performance, while incurring no extra parameter burdens, as compared to the original ar-chitecture; RecWR can improve FemtoDet ∼ 6.19% per-formance by gradually weakening the data augmentation strength in multi-stage learning. By jointly training Fem-toDet with IBE and RecWR, our proposed methodology can go over the YOLOX [9] by 51.34% in performance when using the same-level parameters.
Something worth mentioning is that FemtoDet is spe-cially designed for hierarchical intelligent chips to enable always-on alerts: the always-on low power, high-recall, and decent accuracy - it achieved 85.8 AR20 & 76.3 AP20 (Ta-ble 7) while performing pedestrian detection on TJU-DHD.
In addition, FemtoDet is poor in detecting small objects but is excellent in detecting medium and large objects, which they are more interested in, with 88.8 AR20-m & 94.1
AP20-m / 95.3 AR20-l & 98.6 AP20-l (Table 7) on TJU-DHD. Information can be passed to other models after iden-tifying possible objects of interest, and high-precision ro-bust models are then initiated for accurate recognition. The always-on smart products have a wide range of applications, e.g., in-home monitoring or robots. Hence, the loose met-ric (e.g., AP50 or AP20) and data scenario with moderate difficulty (e.g., VOC) can well reflect the application ability of FemtoDet. Further, the experiments on COCO datasets have verified that the proposed method is suitable for di-verse scenarios resulting in competitive results. 2.