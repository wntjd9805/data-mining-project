Abstract
Existing machine learning (ML) models are often frag-ile in open environments because the data distribution fre-quently shifts. To address this problem, domain general-ization (DG) aims to explore underlying invariant patterns for stable prediction across domains. In this work, we first characterize that this failure of conventional ML models in DG attributes to an inadequate identification of causal structures. We further propose a novel invariant Directed
Acyclic Graph (dubbed iDAG) searching framework that attains an invariant graphical relation as the proxy to the causality structure from the intrinsic data-generating pro-cess. To enable tractable computation, iDAG solves a con-strained optimization objective built on a set of representa-tive class-conditional prototypes. Additionally, we integrate a hierarchical contrastive learning module, which poses a strong effect of clustering, for enhanced prototypes as well as stabler prediction. Extensive experiments on the syn-thetic and real-world benchmarks demonstrate that iDAG outperforms the state-of-the-art approaches, verifying the superiority of causal structure identification for DG. The code of iDAG is available at https://github.com/ lccurious/iDAG. 1.

Introduction
An imperative goal of deep learning is to learn repre-sentations that faithfully represent task-oriented semantics and also generalize to different domains. It is known, how-ever, that the performance of current models trained by the
Empirical Risk Minimization (ERM) paradigm relies heav-ily on the i.i.d. assumptions and suffers a dramatic perfor-mance drop when inferring on Out-Of-Distribution (OOD) datasets [50]. However, when we deploy our models in the real world, we have little control over the distribution we observe; for instance, variables may change in frequency or new feature combinations may emerge that were not in-cluded in the training set [21]. In response to this challenge,
*Corresponding author
Figure 1. Multiple causally related factors may be present in vi-sual data, and these factors are structurally organized together and present a higher level of semantics. However, due to domain di-versity, the learned color factors in one domain can be useless in others; the spurious factors that dominate classification in one do-main can be misleading in others. iDAG seeks to estimate the DAG which represents the directed causal relations between factors.
Domain Generalization (DG) is proposed to improve per-formance in OOD inference by learning invariant features over the source domains that are generalizable to distribu-tions different from those observed during training [5, 35].
The most substantial challenge of DG is the spurious cor-relations may mislead the models to cheating classify the easier-to-fit features rather than true attributes [3]. As we exemplified in Figure 1, the reasons for such cheating are two-fold. First, some discriminative features appeared in training domains, but may disappear in test domains, which is known as diveristy shift. Second, there exists correla-tion shift that induces spurious features for predictions, e.g., the background of an image can dominate the classification during training. To cope with these problems, a plethora of methods have been proposed to learn domain invariant features, including content-style disentanglement [61], con-structing auxiliary task as penalty [7], force risks invariant cross-domains [3, 30]. However, most of them focus on re-lations from features to labels, and a unified consideration of modeling the global relationship between features and semantics remains underexplored.
With further scrutinizing the key causes above, we find that both challenges stem from the wrong identification of causal relations. Indeed, the most substantial concept for achieving DG [43, 41] is eliciting the causal structure across domains that invariantly controls the data-generating pro-cess. To this end, we propose to reformulate DG to a novel invariant causal graph searching problem. Once obtaining the directed acyclic graph (DAG) relations between latent factors, both the spurious correlation and diversity shift can be naturally recognized and removed by estimation of a global picture of causal graph among factors and label (see
Figure 1). Despite the promise, it is non-trivial to identify the DAGs since the feature distribution constantly changes over the course of training. To date, few efforts have been made to resolve this.
In this study, we investigate a novel domain general-ization framework by learning invariant Directed Acyclic
Graph-structured feature relations (dubbed iDAG), which discovers the intrinsic feature organizations for stable label prediction. The core of iDAG is a constrained optimization problem that minimizes the trace of the adjacent matrix ex-ponential, which guarantees the acyclicity and eliminates the spurious relations simultaneously. To prevent travel-ing the whole dataset in every training step, we design a prototype-based dataset proxy technique for efficient and stable optimization. Furthermore, iDAG incorporates a hi-erarchical contrastive learning module that aligns the latent causal factors to improve the representativeness of the pro-totypes and achieve stabler prediction. Comprehensive ex-periments show that iDAG accomplishes the state-of-the-art performance on various benchmark datasets, and is able to mitigate both diversity and correlation shifts in a unified framework. 2.