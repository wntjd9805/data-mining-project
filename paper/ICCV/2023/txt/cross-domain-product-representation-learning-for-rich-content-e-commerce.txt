Abstract
The proliferation of short video and live-streaming plat-forms has revolutionized how consumers engage in online shopping. Instead of browsing product pages, consumers are now turning to rich-content e-commerce, where they can purchase products through dynamic and interactive me-dia like short videos and live streams. This emerging form of online shopping has introduced technical challenges, as products may be presented differently across various me-dia domains. Therefore, a unified product representation is essential for achieving cross-domain product recognition to ensure an optimal user search experience and effective product recommendations. Despite the urgent industrial need for a unified cross-domain product representation, previous studies have predominantly focused only on prod-uct pages without taking into account short videos and live streams. To fill the gap in the rich-content e-commerce area, in this paper, we introduce a large-scale cRoss-dOmain
Product rEcognition dataset, called ROPE. ROPE covers a wide range of product categories and contains over 180,000 products, corresponding to millions of short videos and live streams. It is the first dataset to cover product pages, short videos, and live streams simultaneously, providing the ba-sis for establishing a unified product representation across different media domains. Furthermore, we propose a Cross-dOmain Product rEpresentation framework, namely COPE, which unifies product representations in different domains through multimodal learning including text and vision. Ex-tensive experiments on downstream tasks demonstrate the effectiveness of COPE in learning a joint feature space for all product domains. 1.

Introduction
Recently, with the vicissitude in time spent by customers on entertainment media, the way consumers shop online
*Equal contribution.
†Corresponding authors.
Figure 1. Illustrate the importance of cross-domain product rep-resentation for rich-content e-commerce. There are two solid de-mands for such new e-commerce: 1) The platform needs to pro-vide accurate product results of product page, short video, and live streaming corresponding to user’s query; 2) The platform is able to recommend similar products of interest according to user’s be-havior history. Both of the two tasks highly depend on a high-performance cross-domain product representation. Examples are from the popular rich-content e-commerce platforms, including
TikTok, Kwai and Taobao. has transformed significantly, and rich-content e-commerce is becoming increasingly popular.
In the rich-content e-commerce area, the products are sold not only with tradi-tional product pages but also with dynamic and interactive media formats, i.e., short videos and live streams. As a re-sult, consumers are increasingly relying on these formats to make informed purchase decisions. This shift has facil-itated a more engaging shopping experience, bridging the gap between consumers and sellers while presenting new opportunities for platforms to capitalize on.
Despite the advantages of rich-content e-commerce, it presents several technical challenges. One of the most sig-nificant challenges is the inconsistency in product presenta-tion across different media domains. For instance, a prod-uct may appear entirely different in a live stream than on
a traditional product page. Establishing a unified product representation across different domains is curial and desper-ately needed in industrial scenarios to address the inconsis-tency problem. As shown in Figure 1, when users search for a particular product, the unified product representation en-sures an enjoyable search experience that the returned prod-uct pages, short videos, and live streams precisely describe the same product. When the platform recommends products for users, the unified product representations are beneficial to exploiting users’ consuming behaviors in different media for comprehensive product recommendations.
In spite of the urgent industrial need for a unified cross-domain product representation, prior efforts have concen-trated solely on the product page domain. The most com-mon way to learn the product representations is to train a product classification model with product images and ti-tles [12, 14, 26, 27]. However, such representations are far from acceptable in rich-content e-commerce. Specifically, the pictures displayed on the product pages are generally well-shot by professionals, while in short videos and live streaming, the posture of the products and the positions they occupy in the scene often change a lot. Moreover, in live streams and short videos, it is not always guaranteed that products are visible at every moment. Short videos may be mixed with the story plot, while live streams may con-tain chats between the sellers and their audiences. These contents are generally irrelevant to the products. To bridge this gap and push forward the related research, we collect a large amount of real data from online shopping platforms and present the first large-scale cRoss-dOmain Product rEcognition dataset, ROPE. Our dataset contains 3,056,624 product pages, 5,867,526 short videos, and 3,495,097 live streams of 189,958 different products. It covers all product categories of online shopping scenarios. To the best of our knowledge, ROPE is the rich-content e-commerce dataset, including product pages, short videos, and live streams. We hope that the publication of ROPE will attract more re-searchers to the field of content commerce and drive the development of related technologies.
In addition to the ROPE dataset, we propose a Cross-dOmain Product rEpresentation baseline, COPE, that maps product pages, short videos, and live streams into the same feature space to build a unified product representation.
Based on the ROPE dataset, we evaluate the COPE model on the cross-domain retrieval and few-shot classification tasks. The experimental results show significant improve-ment over the existing state-of-the-arts.
In summary, our contributions are as follows: 1) As far as we know, our work is the first exploration that tries to build a unified product representation across the product pages, short videos, and live streams to meet the urgent industrial need of the emerging rich-content e-commerce. 2) We collect realistic data from online e-commerce platforms and build a large-scale cRoss-dOmain Product rEcognition dataset, ROPE. It contains 3,056,624 product pages, 5,867,526 short videos, and 3,495,097 live streams belonging to 189,958 different products. The included product categories cover the full spectrum of online shop-ping scenarios. 3) A Cross-dOmain Product rEpresentation model,
COPE, is proposed to learn the cross-domain product rep-resentations. The experimental results prove the superiority of the COPE model to the existing methods. 2.