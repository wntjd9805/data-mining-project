Abstract
In partial-label learning (PLL), each training example has a set of candidate labels, among which only one is the true label. Most existing PLL studies focus on the instance-independent (II) case, where the generation of candidate labels is only dependent on the true label. However, this II-PLL paradigm could be unrealistic, since candidate labels are usually generated according to the specific features of the instance. Therefore, instance-dependent PLL (ID-PLL) has attracted increasing attention recently. Unfortunately, existing ID-PLL studies lack an insightful perception of the intrinsic challenge in ID-PLL. In this paper, we start with an empirical study of the dynamics of label disambiguation in both II-PLL and ID-PLL. We found that the performance degradation of ID-PLL stems from the inaccurate supervi-sion caused by massive under-disambiguated (UD) exam-ples that do not achieve complete disambiguation. To solve this problem, we propose a novel two-stage PLL framework including selective disambiguation and candidate-aware thresholding. Specifically, we first choose a part of well-disambiguated (WD) examples based on the magnitude of normalized entropy (NE) and integrate harmless comple-mentary supervision from the remaining ones to train two networks. Next, the remaining examples whose NE is lower than the specific class-wise WD-NE threshold are selected as additional WD ones. Meanwhile, the remaining UD examples, whose NE is lower than the self-adaptive UD-NE threshold and whose predictions from two networks are agreed, are also regarded as WD ones for model train-ing. Extensive experiments demonstrate that our proposed method outperforms state-of-the-art PLL methods. 1.

Introduction
The development of modern deep neural networks (DNNs) relies on a large amount of perfectly labeled
*Corresponding author.
Figure 1. Illustration of the difference of labeling confidence after label disambiguation between II-PLL (left) and ID-PLL (right).
We can see that the difficulty of identifying the true label (blue) of examples with various types of candidate labels (CLs) is promi-nently different. In addition, the image with sharp labeling confi-dence on random CLs is well-disambiguated, while the image with flat labeling confidence on ID CLs is under-disambiguated. data in real-world tasks. However, collecting such high-quality data in real-world scenarios is considerably time-consuming and laborious even for experienced labeling ex-perts [28]. To alleviate this issue, researchers have paid much attention to partial-label learning (PLL), a weakly-supervised learning paradigm that is labeling-friendly for non-expert annotators, allowing to assign a candidate la-bel set [6]. In particular, a majority of previous PLL works implicitly employ an instance-independent (II) assumption that the generation of each candidate label for an instance is of equiprobability and independent of the instance itself.
But, this ideal assumption is unrealistic in real-world sce-narios [22]. From the perspective of an image annotator, the probability of a domain class being selected as a candidate label is related to the visual perception information (i.e., se-mantic, color, and shape) of an image itself. This case is called instance-dependent (ID) [23] where the generation of candidate labels is according to the specific features of
Figure 2. Dynamics of label disambiguation during the training on CIFAR-10 under ID and II cases. Figure (a) presents the average normalized entropy towards all training examples at each iteration, reflecting the whole status of label disambiguation. A lower entropy value implies that more partially labeled training examples are well-disambiguated; Figure (b) shows the accuracy of label disambiguation for WD and UD examples respectively; Figures (c) and (d) display the normalized entropy distribution of correctly disambiguated (blue) and falsely disambiguated (red) examples at the early epoch respectively. the instance, and has attracted much attention in the PLL community recently.
To learn from the partially-labeled examples in II-PLL, self-training based label disambiguation (LD) has achieved great success, which progressively refines soft labeling con-fidences [6, 24, 19] at each iteration towards each partially-labeled example for the model training based on various means such as the network prediction [11, 19], class acti-vation map (CAM) [24], class prototypes [16] or consis-tency regularization [19]. Unfortunately, these PLL meth-ods show a serious degradation of performance in ID-PLL
[22, 23]. To alleviate this issue, researchers have started to design specific ID-PLL algorithms recently [23, 13]. How-ever, existing ID-PLL studies lack an insightful perception of intrinsic challenges in ID-PLL. In this paper, we start with an empirical study of the dynamics of LD both in II-PLL and ID-PLL. To achieve a thorough exploration, we first introduce a pivotal statistic to evaluate the status of LD: normalized entropy (NE) of labeling confidences (the de-tailed definition is referred to as Eq.(3)). The implication is that a low NE indicates a better status of LD. Based on this metric, we record the labeling confidence and corre-sponding NE towards all training examples at each iteration based on PRODEN [11] on CIFAR-10 under both II and
ID cases. Based on the statistics, we can analyze the dy-namics of LD from three various aspects: the whole status of LD, disambiguation accuracy, and NE distribution. The experiment results are shown in Figure 2. In Figure 2 (a), we calculate the average NE of labeling confidence towards all training examples at each iteration, reflecting the whole status of LD. We can see that the curves of LD on II-PLL (q “ r0.1, 0.3, 0.5s) reach near zero, while the curve on ID-PLL is close to 0.22. This phenomenon means that most examples in II-PLL have been well-disambiguated (WD), while a mass of under-disambiguated (UD) examples on ID-PLL do not achieve complete disambiguation (i.e., main-taining a relative high NE). To further explore the charac-teristic of UD examples, we divide the whole training ex-amples into well-disambiguated WD and UD ones based on a fixed threshold and calculate the accuracy of labeling con-fidence for them at each iteration respectively. The result is shown in Figure 2 (b). We can see that UD examples main-tain a lower oscillating disambiguation accuracy than WD ones. On the other hand, we plot the empirical NE distribu-tion of correctly identified (True in blue) and falsely identi-fied (False in red) examples at epoch 15 on II (q “ 0.5) and 30 on ID respectively. As shown in Figure 2 (c) and (d), we can see that both in II-PLL and ID-PLL, correctly identified examples have lower NE than falsely identified ones, and correctly identified examples in ID-PLL have more falsely identified low NE examples which is a knotty problem in the model training. Based on these empirical observations, we have revealed the intrinsic challenge in ID-PLL com-pared with II-PLL lies in massive UD examples with in-accurate supervision in the training procedure. Moreover, the under-disambiguation phenomenon also motivates us to think about how to determine whether a partially labeled training example has been disambiguated. In the above em-pirical study, we simply use a fixed threshold of NE to dis-criminate WD from UD ones. However, training examples with various candidate label sets have different intrinsic dif-ficulties of LD, and the NE of training examples varies dy-namically with the learning process of networks. Therefore, it may be intractable to assign an appropriate fixed threshold for all training examples [17].
To address these challenges, we propose a novel two-stage PLL framework including selective disambiguation and candidate-aware thresholding. Specifically, due to the negative role of the UD example in ID-PLL, we first choose a part of WD examples based on the magnitude of NE and meanwhile integrate harmless complementary supervision from the remaining ones to train two networks simultane-ously. This selective disambiguation procedure is expected to learn two well-trained networks that are powerful enough to handle the remaining examples. Next, instead of using a fixed threshold of NE, we propose a dynamic candidate-aware thresholding scheme that respectively maintains a class-wise WD-NE threshold reflecting the different diffi-culties of LD on each class and a self-adaptive UD-NE threshold indicating the whole status of LD on UD exam-ples. Based on these two thresholds, we select the remain-ing examples whose NE is lower than the specific class-wise
WD-NE threshold as additional WD ones to supplement the selected WD set in Stage 1. Meanwhile, we also select UD examples whose NE is lower than the UD-NE threshold and whose predictions from two networks are agreed, as WD ones for model training. In this way, we only leverage these selected WD examples for model training in Stage 2. Ex-tensive experiments demonstrate that our proposed method outperforms state-of-the-art PLL methods. Our contribu-tion is summarized as follows:
• We discover that the performance degradation of ID-PLL stems from the inaccurate supervision caused by a mass of UD examples.
• We propose a novel two-stage PLL framework in-cluding selective disambiguation and candidate-aware thresholding for UD examples.
• Empirically, extensive experiments show our proposed framework’s superiority and effectiveness in both II-PLL and ID-PLL. 2.