Abstract
The following three factors restrict the application of existing low-light image enhancement methods: unpre-dictable brightness degradation and noise, inherent gap be-tween metric-favorable and visual-friendly versions, and the limited paired training data. To address these lim-itations, we propose an implicit Neural Representation method for Cooperative low-light image enhancement, dubbed NeRCo. It robustly recovers perceptual-friendly re-sults in an unsupervised manner. Concretely, NeRCo uni-ﬁes the diverse degradation factors of real-world scenes with a controllable ﬁtting function, leading to better ro-bustness. In addition, for the output results, we introduce semantic-oriented supervision with priors from the pre-trained vision-language model. Instead of merely following reference images, it encourages results to meet subjective expectations, ﬁnding more visual-friendly solutions. Fur-ther, to ease the reliance on paired data and reduce solution space, we develop a dual-closed-loop constrained enhance-ment module. It is trained cooperatively with other afﬁli-ated modules in a self-supervised manner. Finally, extensive experiments demonstrate the robustness and superior effec-tiveness of our proposed NeRCo. Our code is available at https://github.com/Ysz2022/NeRCo. 1.

Introduction
Due to the degraded brightness in low-light images cov-ering objects and reducing contrast, low-light images have severely impacted the subsequent high-level computer vi-sual tasks (e.g., semantic segmentation [15], and object de-tection [26], etc.). Hence, it is of practical importance to remedy the brightness degradation for assisting the explo-ration of sophisticated dark environment. Low-light image enhancement, which aims to recover the desired content in degraded regions, has drawn wide attention in recent years
[10, 11, 12, 16, 27, 34].
Corresponding author∗. Independent researcher†.
This work was supported in part by Shenzhen General Research
Project under Grant JCYJ20220531093215035.
Input
URetinexNet (2022) [47]
SCI (2022) [28]
NeRCo (Ours)
Figure 1: Comparison with two state-of-the-art methods on the LIME [12] dataset. One can see that we recovered more authentic color and visual-friendly contents.
Over the past few years, proliﬁc algorithms have been proposed to address this classic ill-posed problem, which can be roughly categorized into two groups: conven-tional model-based methods (e.g., gamma correction [32],
Retinex-based model [33], and histogram equalization [34]) and recent deep learning-based methods [16, 25, 47]. The former formulates the degradation as a physical model and treats enhancement as the problem of estimating model pa-rameters, but is limited in characterizing diverse low-light factors and requires massive hand-crafted priors. The lat-ter elaborates various models to adjust tone and contrast, which is able to learn from massive data automatically. Es-sentially, they are trained to learn a mapping from input to output domain. In real-world scenarios, however, many samples are far away from the feature space of input do-main, causing a trained model to lack stable effect. We propose to normalize the degradation before enhancement to bring these samples closer to the input domain. Besides, existing supervised methods highly rely on paired training data and mainly attempt to produce metric-favorable results,
i.e., similar to the ground truth. But the limited supervised datasets and the inherent gap between metric-oriented and visual-friendly versions inevitably impact their effective-ness. We develop a cooperative training strategy to address it. As shown in Fig. 1, we test on the LIME [12] dataset, which only consists of low-light images without normal-light references. One can see that even the recently pro-posed top-performing algorithms perform severe color cast.
Speciﬁcally, our key insights are: i) Normalizing the in-put with a controllable ﬁtting function to reduce the un-predictable degradation features in real-world scenar-ios. We adopt neural representation to reproduce the de-graded scene before the enhancement operation. By manip-ulating the positional encoding, we selectively avoid regen-erating extreme degradation, which objectively realizes nor-malization and thereby decreases enhancement difﬁculty. ii) Supervising the output with different modalities to achieve both metric-favorable and perceptual-oriented enhancement. We employ multi-modal learning to super-vise from both textual and image perspectives. Compared with image supervision, which contains varying brightness across different samples, the feature space of the designed prompt is more stable and accurate in describing bright-ness. During training, our results are not only encouraged to be similar to references, but also forced to match their related prompts. In this way, we bridge the gap between the metric-favorable and the perceptual-friendly versions. iii) Developing an unsupervised training strategy to ease the reliance on the paired data. We propose to train the enhancement module with a dual-closed-loop cooperative adversarial constraint procedure, which learns in an unsu-pervised manner. More related loss functions are also pro-posed to further reduce the solution space. Beneﬁting from these, we recover more authentic tone and better contrast (see Fig. 1). Overall, our contributions are as follows:
• We are the ﬁrst to utilize the controllable ﬁtting capa-bility of neural representation in low-light image en-hancement. It normalizes lightness degradation and re-moves natural noise without any additional operations, providing new ideas for future work.
• For the ﬁrst time, we introduce multi-modal learning to low-light image enhancement. Beneﬁting from its efﬁcient vision-language priors, our method learns di-verse features, resulting in perceptually better results.
• We develop an unsupervised cooperative adversarial learning strategy to ease the reliance on the paired training data. In which the appearance-based discrim-ination ensures authenticity from both color and detail levels, improving the quality of the restored results.
• Extensive experiments are conducted on representative benchmarks, manifesting the superiority of our NeRCo against a rich set of state-of-the-art algorithms. Espe-cially, it even outperforms some supervised methods. 2.