Abstract
This paper aims at the distorted document image recti-fication problem, the objective to eliminate the geometric distortion in the document images and realize document intelligence.
Improving the readability of distorted docu-ments is crucial to effectively extract information from de-formed images. According to our observations, the fore-ground and text-line of the original warped image can rep-resent the deformation tendency. However, previous dis-torted image rectification methods pay little attention to the readability of the warped paper. In this paper, we fo-cus on the foreground and text-line regions of distorted paper and proposes a global and local fusion method to improve the rectification effect of distorted images and enhance the readability of document images. We intro-duce cross attention to capture the features of the fore-ground and text-lines in the warped document and effec-tively fuse them. The proposed method is evaluated quan-titatively and qualitatively on the public DocUNet bench-mark and DIR300 Dataset, which achieve state-of-the-art performances. Experimental analysis shows the proposed method can well perform overall geometric rectification of distorted images and effectively improve document read-ability (using the metrics of Character Error Rate and Edit
Distance). The code is available at https://github. com/xiaomore/Document-Image-Dewarping. 1.

Introduction
In our daily life, there are various documents, such as pa-pers, posters, receipts and so on. These documents contain a wealth of information. At present, document intelligence can automatically extract the information in the document, and then obtain structured data (text content, key field ex-traction, table structure, document layout analysis), which greatly facilitates people’s lives. However, with the popu-*Corresponding authors.
Figure 1. Compared with the text results using Tesseract [32] as
OCR engine. Row 1: distorted images. Row 2: rectified by our method. We use color to highlight the detected text boxes. larization of mobile electronic devices, it is more and more convenient for people to take pictures with smart phones or portable cameras to capture electronic documents. When taking pictures, due to the different positions, illumination conditions of these devices, the angle of paper placement, deformation and other problems, the images taken are dis-torted or deformed to varying degrees, and it is difficult to extract useful information from these distorted pictures, as shown in Figure 1. Even wrong information is extracted, which brings great challenges to obtaining key information of documents and realizing document intelligence.
As early as many years ago, the problem of document image distortion rectification has been paid attention to. In the traditional rectification method before deep learning was widely used, several previous methods [3, 36, 17] accord-ing to the deformation characteristics of the image, relying on multi-view, get the best boundary through the regression method, and use the boundary segmentation method to de-warped the segmentation graphics. Tian and Narasimhan
[35] reconstructs warped document images from 2D to 3D by detecting text-lines in the image. In the time since, some works [16, 15] have also captured prior knowledge in de-formed images by detecting text lines in order to bring gains to image rectification. However, these methods of restor-ing the 3D shape of images through auxiliary hardware or multi-view methods will bring time consuming and expen-sive problems.
With the arrival of the era of deep learning, Convolu-tional Neural Network (CNN) and Transformer have been introduced to solve the geometric rectification of distorted document images. Most current methods dewarping the in-put image by learning the mapping relationship between the input distorted image and the dense 2D coordinate map area [26, 8, 1, 11, 14, 10]. The method of
[26, 8] used the UNet structure networks to regress the dense 2D co-ordinates mapping according to the input distorted image.
However, it is difficult for CNN to capture the long-distance dependence of distorted paper. For methods [11, 10] that focus on image foreground, they proposed to remove the document background in the preprocessing stage before ge-ometric rectification the network. And then introduces the multi-layer transformer of Encoder-Decoder structure after the convolution network to dewarp the distorted paper. But these methods based on setting the binarization threshold to remove the background will lose the information of the original image. There are also some works such as [14, 10] proposed to use document boundaries, 3D world coordi-nates and text-lines to construct deformation fields, which reduces the error rate of text recognition. These two meth-ods have no obvious interaction between the text-line and the original distorted image, which makes the text-line area unable to be effectively focused.
In geometrically deformed images, the distortion degree of image foreground and text-lines varies with different scenes. It is necessary to establish an explicit invariant fea-ture in the distorted image foreground to represent the core document and text-line region features robustly, to suppress the interference of background and deformation. Since the foreground information of the document image can clearly represent the deformation amplitude, we use the foreground features representation of the input image. The text-line re-gions can represent the distorted state of the local position in dewarped images. In order to enhance the reading quality of the image, we considering it is necessary to pay more at-tention to the area of the text-lines. Therefore, we propose to represent local information using text-line information, extract the characteristics of the corresponding position in the image. Besides, based on our observations, when us-ing the deformation field for distortion rectification, for the dewarped image, the areas in the same horizontal direction should have the same vertical coordinates in the deforma-tion field. For example, for text-lines, the text area of the same line should have the same ordinate. This is a very critical starting point for our design model.
From the perspective of readability, we propose a novel distortion image rectification model based on cross atten-tion mechanism, which fuses the features of the image foreground and text line. The features of the foreground and text-line regions respectively focus on the features of the corresponding positions in the original warped image.
The foreground and text-line features are each represent the global and local information of the distorted image, which have complementary effects.
In addition, in order to en-hance the interaction between global and local features, we share the two cross attention branches of foreground and text-lines, which also reduces the amount of model param-eters to a certain extent.
The main contributions of our work are summarized as follows:
• We propose to use foreground and text line information to guide the model to focus on the global and local features of distorted paper, so as to reduce background interference and improve the readability of document images.
• We introduce cross-attention to explore more effective interaction between paper deformation trend and orig-inal distorted image.
• We conduct extensive experiments and show the state-of-the-art results on the existing prevalent benchmarks. 2.