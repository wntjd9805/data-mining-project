Abstract
Deep neural networks suffer from catastrophic forgetting in continual learning, where they tend to lose information about previously learned tasks when optimizing a new in-coming task. Recent strategies isolate the important param-eters for previous tasks to retain old knowledge while learn-ing the new task. However, using the fixed old knowledge might act as an obstacle to capturing novel representations.
To overcome this limitation, we propose a framework that evolves the previously allocated parameters by absorbing the knowledge of the new task. The approach performs un-der two different networks. The base network learns knowl-edge of sequential tasks, and the sparsity-inducing hyper-network generates parameters for each time step for evolv-ing old knowledge. The generated parameters transform old parameters of the base network to reflect the new knowl-edge. We design the hypernetwork to generate sparse pa-rameters conditional to the task-specific information and the structural information of the base network. We evalu-ate the proposed approach on class-incremental and task-incremental learning scenarios for image classification and video action recognition tasks. Experimental results show that the proposed method consistently outperforms a large variety of continual learning approaches for those scenar-ios by evolving old knowledge. 1.

Introduction
The ability of deep learning to incrementally accumu-late knowledge for sequentially incoming tasks is an impor-tant capability required for modern AI algorithms. How-ever, deep neural networks tend to lose previously acquired knowledge while learning new data. This limitation of deep neural networks, called catastrophic forgetting, has been in-vestigated by previous studies [29, 17]. Catastrophic for-getting significantly degrades performance when data from previous tasks (task-incremental) or already-learned class
*This work was done independently, without any support from SAIT. data (class-incremental) cannot be accessed. Under those incremental learning scenarios, continual learning methods have toiled to preserve the previous knowledge.
Various approaches have been proposed for continual learning and are categorized into three types: regularization
[2, 4, 20, 17, 48], data rehearsal [5, 26, 32, 35, 38, 47], and parameter isolation [1, 30, 28]. The conventional continual learning methods introduced regularization approaches to suppress changes in important parameters [48, 2] or input-output mappings from a network trained up to previous tasks [22, 7]. The network is trained in a way that con-tributable parameters to the performance of the previously trained model remain unchanged. On the other hand, data rehearsal methods [25, 35] address catastrophic forgetting by accessing old data. The old data can be obtained by stor-ing some data from old tasks [35, 47] or leveraging a gen-erative network [38]. However, the privacy of data and the difficulty of learning generative models limit their versatil-ity. Recently, parameter isolation approaches [28, 30, 15] construct a disjoint set of parameters for each task, prevent-ing it from mixing old and new knowledge. These methods learn a new set of parameters by associating all [28] or some helpful old knowledge [15].
Unlike other approaches, the parameter isolation ap-proach is designed to prevent forgetting without requiring access to old data by disallowing updates to previous sets of parameters. Despite this advantage, these methods can limit the ability to learn new tasks by relying on parameters that were learned for older tasks and remain unchanged. We ob-serve that this limitation arises when there is a low correla-tion between the old and new data. This raises the question:
In parameter isolation-based continual learning, is it pos-sible to transform the knowledge from old tasks to fit newer tasks better?
In this paper, we introduce a novel method for transform-ing prior knowledge into a form that can aid in learning new tasks. The approach involves reframing the parameter selec-tion problem, which previous works [15] have addressed, as a generation problem. The proposed framework emphasizes a subset of pre-trained knowledge, selecting and highlight-ing it for use in learning new tasks. Specifically, the frame-work consists of two networks: base network and hypernet-work. The base network constructs disjoint parameter sets for sequential tasks. The proposed transformer-based [42] hypernetwork generates a small set of influential parameters that significantly impact the loss. The impact of each ele-ment of generated parameters is evaluated by the difference in loss computed with and without its inclusion in the learn-ing process. Also, generated parameters are conditioned on the information of the current task (task token) and the layer of the base network (layer embedding). The gener-ated parameters transform the previous set of parameters in the base network to further accommodate new knowledge.
In addition, compared to existing hypernetworks that gen-erate a small set of parameters and apply it to all the layers
[13, 44], the proposed hypernetwork adaptively generates parameters according to the layer configurations defined in the base network. Through this strategy, the quantity of layer embeddings for ResNet-50 is reduced by a substantial factor of 24. Furthermore, by leveraging a matrix decom-position technique to represent generated parameters com-pactly, we achieve a noteworthy reduction in the parameters necessary for the hypernetwork.
We evaluate the effectiveness of the proposed method in both class-incremental and task-incremental learning sce-narios using classification benchmark datasets. Further-more, we demonstrate the efficacy of the proposed method
[28, 15] in these scenarios by applying it to video action recognition datasets [19]. Experimental results show that the proposed method performs better than its competitors for most learning scenarios while introducing minor mem-ory overhead from the hypernetwork. The contributions of our work are mainly three-fold: (1) We present a novel ap-proach to evolving previous knowledge in continual learn-(2) ing, aimed at reflecting the knowledge of new tasks.
We propose a transformer-based hypernetwork that gener-ates customized parameters for new tasks while suppress-ing the generation of redundant parameters that have lit-tle impact on the loss. (3) Experimental results on diverse benchmarks for video action recognition and image classi-fication demonstrate that ours outperforms its competitors with lower network capacity requirements to perform tasks. 2.