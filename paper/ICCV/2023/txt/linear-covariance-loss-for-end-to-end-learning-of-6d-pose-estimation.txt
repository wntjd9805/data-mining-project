Abstract
Most modern image-based 6D object pose estimation methods learn to predict 2D-3D correspondences, from which the pose can be obtained using a PnP solver. Because of the non-differentiable nature of common PnP solvers, these methods are supervised via the individual correspon-dences. To address this, several methods have designed differentiable PnP strategies, thus imposing supervision on the pose obtained after the PnP step. Here, we argue that this conflicts with the averaging nature of the PnP problem, leading to gradients that may encourage the network to de-grade the accuracy of individual correspondences. To ad-dress this, we derive a loss function that exploits the ground truth pose before solving the PnP problem. Specifically, we linearize the PnP solver around the ground-truth pose and compute the covariance of the resulting pose distribution.
We then define our loss based on the diagonal covariance elements, which entails considering the final pose estimate yet not suffering from the PnP averaging issue. Our ex-periments show that our loss consistently improves the pose estimation accuracy for both dense and sparse correspon-dence based methods, achieving state-of-the-art results on both Linemod-Occluded and YCB-Video. 1.

Introduction
Estimating the 6D pose of 3D objects from monocular images is a core computer vision task, with many real world applications, such as robotics manipulation [53, 54], au-tonomous driving [9, 48] and augmented reality [10, 32].
Although this task can be facilitated by the use of RGBD input, depth sensors are not ubiquitous, and thus 6D ob-ject pose estimation from RGB images remains an active research area.
With the development of deep neural networks (DNNs), early methods [1, 14, 26, 49] formulated pose estima-tion as a regression problem, directly mapping the in-put image to the 6D object pose. More recently, most works [5, 21, 23, 33, 35, 38, 39, 41, 42, 43, 44] draw inspi-ration from geometry and seek to predict 2D-3D correspon-Figure 1. Difference between other differentiable PnP losses and our proposed loss. Other methods (first row) first solve for the object pose from noisy correspondences, and then compute the loss based on the resulting pose and the ground truth. By con-trast, we (second row) utilize the ground-truth pose to estimate the residual variance of the correspondences and compute the co-variance of the pose distribution. We define our loss based on the diagonal elements of this covariance. dences, from which the 6D pose can be obtained by solving the Perspective-n-Points (PnP) problem. While effective, these methods supervise the training process with the indi-vidual correspondences, and not with the ground-truth pose itself, as standard PnP solvers are not differentiable.
To enable end-to-end training, several attempts have been made to incorporate the PnP solver as a differentiable network layer [3, 4, 6]. While these methods make it possi-ble to employ pose-driven loss functions to train the DNN, they only leverage the optimal pose as supervision, thus not imposing constraints on other pose candidates. In [7], this was addressed by deriving a loss function based on the pos-terior pose distribution, encouraging a larger posterior for the ground truth and smaller posteriors for the other poses.
Nevertheless, to the best of our knowledge, all of these differentiable PnP layers have a common property: They first solve the PnP problem to obtain either the pose [3, 4, 6] or the posterior pose distribution [7], and then compute the error to be backpropagated based on a dedicated loss func-Figure 2. Gradients after averaging.
In this toy example, the gradient will drive ˆa2 away from the true a value, although ¯a is driven closer to a. tion and the ground-truth pose. That is, they introduce the ground-truth information only after the pose has been com-puted. While this may seem a natural strategy when incor-porating a differentiable layer, we argue that this conflicts with the averaging nature of the PnP problem, which aggre-gates multiple noisy measurements into a single estimate.
To illustrate this, let us consider a simpler problem with two noisy measurements, ˆa1 and ˆa2, of a value a, and seek to minimize the distance between the average value ¯a = (ˆa1 + ˆa2)/2 and a, i.e., |¯a − a|. As ˆa1 and ˆa2 contribute to the loss in the same manner, they are updated with the same gradient, irrespectively of their individual error w.r.t. a. For example, as depicted in Fig. 2, if ˆa1 and ˆa2 are on either side of a, the gradient will drive one of these estimates further from the true a value, i.e., degrade the individual prediction quality of this estimate.
In the case of PnP, 4 2D-3D correspondences are in gen-eral sufficient to obtain a unique pose [28]. If more than 4 correspondences are provided, the PnP solver performs a form of “averaging”, and thus may yield a similar effect as in the previous toy example: It may encourage a decrease in accuracy of some of the correspondences, thus essentially providing confusing signal in the network training process.
While this can be alleviated by using the pose-driven loss in conjunction with correspondence-level supervision, this strategy circumvents the problem instead of addressing it.
By contrast, in this paper, we introduce an approach to explicitly tackle the gradient issue arising from the averag-ing process of the PnP problem. To this end, we leverage the covariance of the pose distribution computed by exploiting the ground-truth pose before solving for the pose, as illus-trated by Fig. 1. Given noisy 2D-3D correspondences as input to the PnP solver, we consider the distribution of PnP-computed poses around the ground-truth one. We then ap-proximate the covariance of this distribution by linearizing the PnP solver around the ground truth. This lets us de-sign a loss function that minimizes the diagonal covariance elements, which entails minimizing the 2D-3D correspon-dence residuals while nonetheless considering the pose esti-mated via PnP. Our formalism also applies to the weighted
PnP scenario, allowing us to compute weights for the in-dividual correspondences so as to emphasize the ones that benefit the pose estimate.
Our experiments on several datasets and using both sparse and dense correspondence based methods evidence the benefits of our approach.
In particular, applying our loss to the state-of-the-art ZebraPose [43], lets us achieve state-of-the-art performance on both the LM-O and YCB-V datasets. Our code is available at https://github. com/fulliu/lc. 2.