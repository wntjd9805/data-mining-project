Abstract
Out-of-distribution (OOD) generalization is a critical ability for deep learning models in many real-world scenar-ios including healthcare and autonomous vehicles. Recently, different techniques have been proposed to improve OOD generalization. Among these methods, gradient-based regu-larizers have shown promising performance compared with other competitors. Despite this success, our understanding of the role of Hessian and gradient alignment in domain generalization is still limited. To address this shortcoming, we analyze the role of the classifier’s head Hessian matrix and gradient in domain generalization using recent OOD theory of transferability. Theoretically, we show that spec-tral norm between the classifier’s head Hessian matrices across domains is an upper bound of the transfer measure, a notion of distance between target and source domains. Fur-thermore, we analyze all the attributes that get aligned when we encourage similarity between Hessians and gradients.
Our analysis explains the success of many regularizers like
CORAL, IRM, V-REx, Fish, IGA, and Fishr as they regularize part of the classifier’s head Hessian and/or gradient. Finally, we propose two simple yet effective methods to match the classifier’s head Hessians and gradients in an efficient way, based on the Hessian Gradient Product (HGP) and Hutchin-son’s method (Hutchinson), and without directly calculating
Hessians. We validate the OOD generalization ability of proposed methods in different scenarios, including transfer-ability, severe correlation shift, label shift and diversity shift.
Our results show that Hessian alignment methods achieve promising performance on various OOD benchmarks. The code is available here. 1.

Introduction
A typical assumption in the design of current supervised deep learning algorithms is identical distributions of test and training data. Unfortunately, in real-world problems, this assumption is not always true (Koyama and Yamaguchi,
*Equal contribution. 2021) and the distribution gap between test and training data degrades the performance of deep learning models (Wang et al., 2022). In practice, not only is there a distribution shift between test and training data, but also the training data does not follow the i.i.d. assumption but contains data from multiple domains. Histopathology medical datasets are a concrete example where each hospital is using different types of staining procedures and/or scanners (Chang et al., 2021). In such a scenario, a deep learning model often fails to generalize its knowledge to unseen domains. Arjovsky et al. (2019) argue that the main reason behind poor OOD generalization is the tendency of deep learning models to capture simple spurious correlations instead of real causal information. In order to improve OOD generalization, the learning algorithm has to learn from invariant mechanisms.
The problem setup in domain generalization (DG) as-sumes the training set contains data from multiple sources (domains) where the task remains the same across differ-ent data sources (Muandet et al., 2013). Furthermore, we assume there is a causal mechanism that remains invariant across different domains and hopefully for OOD data. Al-though many learning algorithms have been proposed to capture invariance, a recent work by Gulrajani and Lopez-Paz (2020) shows that given a standard experimental setting, the classic Empirical Risk Minimization (ERM) algorithm (Vapnik, 1999), which minimizes the average of losses across different training domains, outperforms many recently pro-posed domain generalization methods. This suggests that many current algorithms may not be successful in capturing the invariance in data.
Out of the effective DG algorithms, one recent and promising line of research is gradient-based methods which try to capture invariance in gradient space (Parascandolo et al., 2020; Koyama and Yamaguchi, 2021; Shi et al., 2021;
Rame et al., 2022). One fast and simple explanation for this success can be derived from the seminal work by Jaakkola and Haussler (1998). According to this work, given a gen-erative model, the gradient with respect to each parameter quantifies the role of that parameter in the generation of a data point. With this intuition, encouraging the similarity between gradients across environments can be translated as
Figure 1: Visualization of Hessian alignment for domain generalization. δ denotes the small deviation from an optimum.
Hessian alignment matches the curvature and thus improves the transfer measure between source and target domains. enforcing the network parameters to contribute the same for different environments which captures a notion of invariance.
Beyond gradient matching, the Invariant Learning Consis-tency (ILC) measure (Parascandolo et al., 2020) motivates matching Hessians across different environments after con-vergence, given that we found the optimal solution for all environments and that the Hessian matrix is diagonal. Al-though the efforts in Parascandolo et al. (2020); Koyama and
Yamaguchi (2021); Rame et al. (2022) improve our under-standing of the role of Hessians and gradients to some extent, the ILC measure is built based on heuristics and is only valid under restricted assumptions like diagonal Hessian matrices.
Moreover, it is not exactly clear what attributes are getting aligned when we match gradients or even Hessians. Finally, the proposed methods to align gradients or Hessians (e.g.,
ANDmask, Parascandolo et al. 2020) seem to be suboptimal as discussed by follow-up works (Shahtalebi et al., 2021;
Rame et al., 2022).
To address these limitations, in this paper, we study the role of Hessians and gradients in domain generalization.
Since Hessians for the whole neural networks are hard to compute, we focus on Hessians of the classifier head, which contains more information than one usually expects. We summarize our contributions as follows:
• To justify Hessian matching, we utilize a recent concept from statistical learning theory, called transfer measure (Zhang et al., 2021), which describes transferability be-tween target and source domains. Unlike ILC, transfer measure avoids the restrictive assumptions of diagonal
Hessians. We theoretically show that the distance be-tween the classifier’s head Hessians is an upper bound of the transfer measure.
• Furthermore, we show that Hessians and gradient align-ment can be treated as feature matching. Our analysis of feature matching compares other DG algorithms like
CORAL (Sun and Saenko, 2016) and V-REx (Krueger et al., 2021) in a unified framework. Especially, the success of CORAL can be attributed to approximate
Hessian alignment using our analysis.
• Last but not least, to match Hessians efficiently, we propose two simple yet effective methods, based on different estimation of the Hessian. To our knowledge, these methods are the first DG algorithms based on
Hessian estimation that align Hessians and gradients simultaneously.
Figure 1 provides an intuitive explanation why Hessian alignment can reduce domain shift through minimizing trans-ferability. With Hessian matching, the transfer measure, or the excess risk gap between source and target domains, is minimized. This makes any near-optimal source classifier to be also near-optimal on the target, and thus improves the transferability and OOD generalization. 2. Problem Setting and