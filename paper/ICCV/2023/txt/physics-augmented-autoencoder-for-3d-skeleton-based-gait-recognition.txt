Abstract
In this paper, we introduce physics-augmented autoen-coder (PAA) framework for 3D skeleton-based human gait recognition. Specifically, we construct the autoencoder with a graph-convolution-based encoder and a physics-based decoder. The encoder takes the skeleton sequence as in-put and produces the generalized positions and forces of each joint, which are taken by the decoder to reconstruct the input skeleton based on the Lagrangian dynamics. In this way, the intermediate representations are physically plausi-ble and discriminative. During the inference, the decoder is discared and a RNN-based classifier takes the output of the encoder for gait recognition. We evaluated our proposed method on three benchmark datasets including Gait3D,
GREW, and KinectGait. Our method achieves state-of-the-art performance for 3D skeleton-based gait recogni-tion. Furthermore, extensive ablation studies show that our method generalizes better and is more robust with small-scale training data by incorporating the physics knowledge.
We also validated the physical plausibility of the intermedi-ate representations by making force predictions on real data with physical annotations. 1.

Introduction
In general, gait refers to the walking style of a person.
It is a unique biometric pattern varying from person to per-son. Gait recognition aims at identifying humans based on their gaits. It has many important applications such as secu-rity surveillance [2], smart homes [58], and healthcare [43].
Extensive work have been focusing on 2D-based gait recog-nition such as using silhouettes [11], gait energy image [32] and 2D human skeleton [49]. However, 2D-based gait recognition suffers from occlusion and changing of view angles. The occlusion caused by the clothes and stuffs be-ing carried introduce irrelevant information which lead to degradation of the performance. And 2D-based methods may not generalize well if the training data and query input are from different view angles. Besides, human gait is a dy-namic process taking place in the 3D space. 2D-based gait
Figure 1: Illustration of physics-augmented autoencoder (PAA). It contains a graph-convolution-based encoder and a physics-based decoder to generate physical representations, which are fed into a classifier for gait recognition. recognition methods rely on appearance features, which ig-nore the underlying physical dynamics that are crucial for model robustness and generalization. So modeling 3D is intuitive and effective for the understanding of gait. On the other hand, 2D-based methods may require large amount of data for training, which is impractical for many real cases.
To address these issues, we study 3D skeleton-based gait recognition in this paper, with a focus on modeling the physical dynamics of human gait. The objective is to leverage the widely applicable physics laws to improve the model generalization, robustness, and interpretability. By incorporating the physics knowledge into the model, we aim to obtain physical features of human gait so that they can be used for recognition. Specifically, we model the hu-man joint positions and forces in the generalized coordi-nates. With the joint positions and the forces applied onto them, the gait dynamics can be captured in a compact and precise way. Another advantage of modeling physics is that the model can generalize better since the embedded physics laws are universal for different subjects.
To encode the physical representations of human gait, we adopt an autoencoder [20, 61] architecture. Specifically, we construct a spatial-temporal graph convolution network as the encoder to better adapt the skeleton topology of the in-put. The output of the graph convolution network is fed into two networks to predict the joint positions and forces in the generalized coordinates, which are treated as the interme-diate representations of the autoencoder. Then the decoder takes the generalized joint positions and forces to recon-struct the input skeleton sequence based on the Lagrangian
dynamics [62]. Indeed, the decoder is a differentiable solver that embeds the physical constraints. In this way, the inter-mediate representations should capture the physical dynam-ics otherwise the decoder cannot reconstruct the input gait sequence correctly.
Different from appearance-based features that are ex-tracted by purely data-driven models, the intermediate rep-resentations of PAA are the fundamental parameters that dominate the human gait process. Thus, we expect them to be more generalizable and robust for gait recognition.
With these physical representations, we use a recurrent neu-ral network as the classifier to perform the gait recognition.
For the training, the autoencoder and the classifier are optimized by the reconstruction loss and gait recognition loss respectively. Specifically, we first train the autoencoder with the reconstruct loss and then jointly train the classifier with autoencoder. During the inference, only the encoder and classifier are kept for gait recognition. We evaluated the proposed method on three benchmark datasets including
Gait3D [65], GREW [66], and KinectGait [1]. To demon-strate the effectiveness of physics modeling, we applied the proposed PAA on data with physical annotations to verify the force prediction. We also conducted extensive ablation studies for the model components, generalization, and ro-bustness.
In summary, the main contributions of this paper are:
• We propose a physics-augmented autoenoder for 3D skeleton-based gait recognition that models the under-lying physical dynamics of human gait. The physical representations are learned by the autoencoder in an unsupervised manner.
• By incorporating the physics modeling, the obtained physical features are more compact and precise. We verify the physical plausibility of the encoded repre-sentations by applying PAA on real data with physical annotations and compare with the ground truth.
• The proposed PAA achieves state-of-the-art perfor-mance on three benchmark datasets. We also demon-strate that PAA generalizes better and is more data-efficient by extensive ablation studies. 2.