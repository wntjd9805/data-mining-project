Abstract
In this work, we seek to predict camera poses across scenes with a multi-task learning manner, where we view the localization of each scene as a new task. We propose
OFVL-MS, a unified framework that dispenses with the tra-ditional practice of training a model for each individual scene and relieves gradient conflict induced by optimizing multiple scenes collectively, enabling efficient storage yet precise visual localization for all scenes. Technically, in the forward pass of OFVL-MS, we design a layer-adaptive sharing policy with a learnable score for each layer to au-tomatically determine whether the layer is shared or not.
Such sharing policy empowers us to acquire task-shared pa-rameters for a reduction of storage cost and task-specific parameters for learning scene-related features to alleviate gradient conflict. In the backward pass of OFVL-MS, we introduce a gradient normalization algorithm that homoge-nizes the gradient magnitude of the task-shared parameters so that all tasks converge at the same pace. Furthermore, a sparse penalty loss is applied on the learnable scores to fa-cilitate parameter sharing for all tasks without performance degradation. We conduct comprehensive experiments on multiple benchmarks and our new released indoor dataset
LIVL, showing that OFVL-MS families significantly outper-form the state-of-the-arts with fewer parameters. We also verify that OFVL-MS can generalize to a new scene with much few parameters while gaining superior localization performance. The dataset and evaluation code is available at https://github.com/mooncake199809/UFVL-Net. 1.

Introduction
Visual localization, a challenging task that aims to fore-cast 6-DOF camera pose on a provided RGB image, is an integral part of several computer vision tasks, such as simul-*Corresponding author. taneous localization and mapping [51, 32, 5] and structure-from-motion [11, 31].
Typically, classical structure-based visual localization frameworks [36, 34, 59, 58] construct 2D keypoints and 3D scene coordinates associations by matching local de-scriptors, and afterwards use a RANSAC-based PnP algo-rithm [15, 25] to retrieve camera pose. Recently, with the advancements of deep learning [57, 56, 41, 49, 48], scene coordinate regression (SCoRe) based methods [26, 13, 61, 53, 16, 10], which trains a convolutional neural network (CNN) to regress the 3D scene coordinate corresponding to each pixel in the input image and calculates camera pose with PnP algorithm [25], establish state-of-the-art localiza-tion performance in small static scenes. Compared with structure-based methods, these methods require no database of images or local descriptors and can benefit from high-precision sensors. While SCoRe based methods achieve impressive results, they come with some drawbacks. Scene coordinate regression is scene-specific and required to be trained for new scenes, resulting in a linear increase in to-tal model size with the number of scenes. After witness-ing the success of SCoRe-based methods, a naive problem arise: could a single SCoRe-based model predict 3D coor-dinates for multiple scenes concurrently and generalize to a new scene? Solving this problem is a key step towards truly
SCoRe-based model deployment on autonomous robots.
A naive solution to this problem is that using a shared backbone to extract features from multiple scenes and then leveraging different regression heads to regress scene co-ordinates for each scene. Nevertheless, jointly optimizing cross-scene localization with a fully shared backbone exists an insurmountable obstacle, i.e., gradient conflict induced by competition among different tasks for shared parame-ters, resulting in inferior performance compared with learn-ing tasks separately [27, 7, 14, 17]. Towards this end, we propose OFVL-MS, a unified SCoRe-based framework that optimizes visual localization of multiple scenes collectively.
OFVL-MS is a multi-task learning (MTL) [12, 23, 29, 8,
57, 52, 33, 47] framework where localization of each scene is treated as an individual task. OFVL-MS offers benefits in terms of model complexity and learning efficiency since substantial parameters of the network are shared among multiple scenes, which renders the model more pragmatic to be deployed on robotics. Technically, OFVL-MS elimi-nates gradient conflict from forward and backward pass.
In the forward pass, we design a layer-adaptive sharing policy to automatically determine whether each active layer of the backbone is shared or not, from which we derive task-shared parameters for efficient storage and task-specific pa-rameters for mitigating gradient conflict. The central idea of the layer-adaptive sharing policy is to transform the layer selection of the backbone into a learnable problem, so that deciding which layers of the backbone to be shared or not can be done during training by solving a joint optimiza-tion problem. In the backward pass, inspired by gradient homogenization algorithms in classical multi-task learning
[21, 28], we introduce a gradient normalization algorithm that homogenizes the gradient magnitude of the task-shared parameters across scenes to ensure all tasks converge at a similar but optimal pace, further relieving gradient conflict.
We also apply a penalty loss on the active layers to prompt all tasks to share as many parameters as possible while im-proving the performance of some tasks that benefit from the shared parameters, as illustrated in Sec. 4.4 and Sec. 4.7.
Experiments show that OFVL-MS achieves excellent lo-calization performance on several benchmarks, including 7-Scenes dataset[39], 12-Scenes datasets [45] and our re-leased large indoor dataset LIVL in terms of median po-sitional and rotational errors, etc. We also demonstrate that
OFVL-MS can generalize to a new scene with much few parameters while maintaining exceptional performance.
To summarize, the contributions of this work are as fol-lows: (1) We propose OFVL-MS, a unified visual localiza-tion framework that optimizes localization tasks of differ-ent scenes collectively in a multi-task learning manner. (2)
We propose a layer-adaptive sharing policy for OFVL-MS to automatically determine, rather than manually, whether each active layer of backbone is shared or not. A penalty loss is also applied to promote layer sharing across scenes. (3) We introduce a gradient normalization algorithm to ho-mogenize gradient magnitudes of the task-shared parame-ters, enabling all tasks to converge at same pace. (4) We publish a new large indoor dataset LIVL that provides a new test benchmark for visual localization. (5) We demon-strate that OFVL-MS can generalize to a new scene with much fewer parameters while retaining superior localiza-tion performance. 2.