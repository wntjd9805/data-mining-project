Abstract
Existing open vocabulary object detection (OVD) works expand the object detector toward open categories by re-placing the classifier with the category text embeddings and optimizing the region-text alignment on data of the base cat-egories. However, both the class-agnostic proposal gen-erator and the classifier are biased to the seen classes as demonstrated by the gaps of objectness and accuracy as-sessment between base and novel classes.
In this paper, an open corpus, composed of a set of external object con-cepts and clustered to several centroids, is introduced to im-prove the generalization ability in the detector. We propose the generalized objectness assessment (GOAT) in the pro-posal generator based on the visual-text alignment, where the similarities of visual feature to the cluster centroids are summarized as the objectness. This simple heuristic eval-uates objectness with concepts in open corpus and is thus generalized to open categories. We further propose cate-gory expanding (CE) with open corpus in two training tasks, which enables the detector to perceive more categories in the feature space and get more reasonable optimization di-rection. For the classification task, we introduce an open corpus classifier by reconstructing original classifier with similar words in text space. For the image-caption align-ment task, the open corpus centroids are incorporated to en-large the negative samples in the contrastive loss. Extensive experiments demonstrate the effectiveness of GOAT and CE, which greatly improve the performance on novel classes and get new state-of-the-art on the OVD benchmarks. 1.

Introduction
As a fundamental task in computer vision community, object detection is previously bounded in a close-set vocab-ulary to localize and categorize objects in images. Extend-ing to new categories requires exhaustive human annotated
*corresponding author
Figure 1: Illustration of the objectness comparison between the base and novel objects assessed by the proposal gener-ators and the proposed GOAT. Conventional proposal gen-erators prefer base categories and the proposed GOAT is generalized for open categories. The objectness scores af-ter sigmoid function are summarized for all base and novel categories and normalized for comparison. data and specific retraining strategies. Inspired by success of the large-scale visual-language (VL) models [28, 18] ap-plied to open vocabulary recognition, recent open vocabu-lary object detection (OVD) works transfer the multi-modal capabilities of pre-trained VL models to object detection.
The semantic categories are represented as text embeddings and the alignment of region-text feature space enables to detect novel categories described by text inputs.
OVD expands traditional object detection to open cate-gories and frees the requirement of costly human annota-tions, which has recently attracted growing interest. In the seminal work, OVR-CNN [37] defines the notion of OVD and adapts a trained VL model on a Faster-RCNN architec-ture to align visual features with the category embeddings
for region classification. RegionCLIP [41] and GLIP [19] adapt the CLIP model to region recognition by fine-tuning with grounding data or pseudo-labeled detection data. Zhou et al. [42] and Lin et al. [21] combine object detection with external recognition or caption datasets to improve the gen-eralization ability. The class-agnostic proposal generators (e.g., RPN [29] or Center head [43]) in these works are ex-pected to be generalized to open categories.
However, we found these proposal generators are usu-ally trained on the seen classes and biased toward them. As shown in Figure 1, the proposal generator trained on COCO
[22] or LVIS [14] dataset usually gives higher objectness estimations on the seen classes. It indeed undermines the generalization ability on novel categories. In this paper, we propose a generalized objectness assessment (GOAT) strat-egy by referencing visual features to the open object corpus with a set of object concepts collected from the recognition
[7] and caption datasets [5, 30]. The anchor features are projected to the same feature space with text embeddings and the similarities of anchor feature to the centroids of con-cept clusters are summarized as the generalized objectness.
This simple heuristic evaluates objectness with concepts in an open corpus and is theoretically generalized for open cat-egories. As demonstrated in Figure 1, GOAT is generalized for both novel and base objects and suppresses the back-ground for two kinds of proposal generators and datasets.
Based on the open corpus, we also propose category ex-panding (CE) to enlarge the positive and negative category sets in two aspects. For the region classification, we addi-tionally introduce an open corpus classifier (OCC) by re-constructing each category embedding in original classifier with similar words in the text feature space. OCC encour-ages the feature to fit open categories similar to the seen classes and avoids to over-fit the seen classes.
It essen-tially enlarges the positive sets for all the categories with the surrounding clusters. For the image-caption matching, the open corpus clusters are used to enrich the negative sam-ples, which is proved effective to improve the performance in contrastive loss. Category expanding enables the model to perceive more positive and negative categories in the fea-ture space and get more reasonable optimization directions.
In summary, we introduce an open object corpus to im-prove the generalization ability of OV detector. The contri-butions can be summarized as follows:
• Based on the open corpus, we propose a GOAT mod-ule in the proposal generator. GOAT assesses visual objectness with open object concepts and is thus gen-eralized to open categories.
• Based on the open corpus, we propose the category ex-panding to enrich the positive and negative samples in two stags. In the classification stage, an open corpus classifier is reconstructed to avoid over-fitting the seen classes. In the alignment stage, the open clusters are incorporated to enlarge the negative samples in con-trastive loss.
• We give detailed illustrations and qualitative results to dissect the proposed method, which achieves new state-of-the-art performance on the OVD benchmarks. 2.