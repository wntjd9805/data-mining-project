Abstract
Due to the mutual occlusion, severe scale variation, and complex spatial distribution, the current multi-person mesh recovery methods cannot produce accurate absolute body poses and shapes in large-scale crowded scenes. To ad-dress the obstacles, we fully exploit crowd features for re-constructing groups of people from a monocular image. A novel hypergraph relational reasoning network is proposed to formulate the complex and high-order relation corre-lations among individuals and groups in the crowd. We first extract compact human features and location infor-mation from the original high-resolution image. By con-ducting the relational reasoning on the extracted individ-ual features, the underlying crowd collectiveness and in-teraction relationship can provide additional group infor-mation for the reconstruction. Finally, the updated indi-vidual features and the localization information are used to regress human meshes in camera coordinates. To facili-tate the network training, we further build pseudo ground-*Corresponding author. E-mail: yangangwang@seu.edu.cn. All the authors from Southeast University are affiliated with the Key Laboratory of Measurement and Control of Complex Systems of Engineering, Min-istry of Education, Nanjing, China. This work was supported in part by the National Natural Science Foundation of China (No. 62076061), the
Natural Science Foundation of Jiangsu Province (No. BK20220127). truth on two crowd datasets, which may also promote fu-ture research on pose estimation and human behavior un-derstanding in crowded scenes. The experimental results show that our approach outperforms other baseline meth-ods both in crowded and common scenarios. The code and datasets are publicly available at https://github. com/boycehbz/GroupRec. 1.

Introduction
Although immense progress has been made in monocu-lar multi-person human mesh recovery in recent years, the existing methods still cannot accurately reconstruct groups of people from large-scale crowded scenes. The top-down formulation [16, 38, 29, 34] iteratively predicts each indi-vidual from tightly cropped image patches, which discards the interaction relationships and location information in the original camera coordinates. Alternatively, the bottom-up formulation [64, 75, 63, 74] parses inter-person interac-tions with global pixel-level cues and enables its impres-sive performance on occluded cases. However, bottom-up methods always fail in large-scale scenes like Fig. 1 since they require downsampling images to low-resolution (e.g., 512×512) to satisfy computational constraints.
Recently, a few works have attempted to estimate hu-man poses in large-scale crowded scenes. Several tech-niques like composite fields [41] and occlusion augmenta-tion [23, 28] in 2D pose estimation are proposed for ad-dressing the low-resolution inputs. PandaNet [7] further lifts the root-relative 3D poses from the 2D detections with an anchor-based representation. Nevertheless, these works cannot be used to reconstruct absolute body meshes in cam-era coordinates due to the inherent coupling between depth and body shape. In addition, the challenges of a huge num-ber of people, severe mutual occlusions, and complex spa-tial distribution make the problem far from being solved.
Different from a few people or single-person cases, it is very common that the crowd in large-scale scenes show significant interactive and collective motions [79, 52]. As shown in Fig. 2, the individuals in the same group even have similar poses. Based on this observation, our key-idea is to fully exploit the collectiveness and social interaction in crowds, and promote human mesh recovery in large-scale scenes with a relational reasoning.
However, the idea faces two technical obstacles. First, the limited hardware without a compact representation, memory cannot afford the relational reasoning for a large number of people. Second, the existing networks can hardly formulate the complex and high-order correlation among different individuals and groups in the crowd. To address the obstacles, we propose a multiscale hypergraph to rep-resent the individuals and groups in different scales, and discard the redundant image features in the relational rea-soning. Specifically, we first detect bounding-boxes [4, 22] and extract valid human features in the original image. Dif-ferent from previous top-down methods, we also record the bounding-box information, which preserves the vital global location cues [44] to regress humans in absolute cam-era coordinates. The compact features and corresponding bounding-boxes depict expressive and high-resolution hu-man information in the crowd image. Then, a multiscale hypergraph network is constructed for the relational rea-soning. Based on the hypergraph structure [21], we rep-resent the individuals with hypergraph nodes, and the nodes on the same hyperedge are regarded as a group. Since hu-man groups in a crowd image have unordered structure, the connection relationships of hyperedges cannot be defined with hand-crafted adjacency matrix like previous graph-based pose estimation methods [9, 15]. We thus introduce a differentiable optimization to infer the graph topology, and then assign the individuals with high human feature similarity to the same group. Subsequently, we initialize the nodes with individual human features, and the features for different individuals and groups can pass through the hypergraph via node-to-hyperedge and hyperedge-to-node phases. After the relational reasoning, the updated individ-ual features with group information in the nodes can be uti-lized to regress the groups of people with absolute positions.
Figure 2: Collective motions are common in human crowd.
In addition, since no existing 3D human dataset is captured in real large-scale scenes, we further build pseudo ground-truth on Panda [67] and CrowdPose [42] to relieve the do-main gap for synthetic data. The datasets may promote fu-ture research on pose estimation and human behavior un-derstanding in large-scale scenes. The main contributions of this work are summarized as follows.
• We reconstruct crowds from single color images and verify that crowds can provide essential knowledge for multi-person mesh recovery.
• We propose a hypergraph relational reasoning net-work to formulate correlations among individuals and groups, which exploits crowd collectiveness and so-cial interaction to improve human mesh recovery in crowded scenes.
• We build pseudo ground-truth on 2 crowd datasets to promote the research on pose estimation and human behavior understanding in large-scale crowded scenes. 2.