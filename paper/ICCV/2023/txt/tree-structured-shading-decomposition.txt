Abstract
We study inferring a tree-structured representation from a single image for object shading. Prior work typically uses the parametric or measured representation to model shad-ing, which is neither interpretable nor easily editable. We propose using the shade tree representation, which combines basic shading nodes and compositing methods to factor-ize object surface shading. The shade tree representation enables novice users who are unfamiliar with the physical shading process to edit object shading in an efficient and in-tuitive manner. A main challenge in inferring the shade tree is that the inference problem involves both the discrete tree structure and the continuous parameters of the tree nodes.
We propose a hybrid approach to address this issue. We in-troduce an auto-regressive inference model to generate a rough estimation of the tree structure and node parameters, and then we fine-tune the inferred shade tree through an optimization algorithm. We show experiments on synthetic images, captured reflectance, real images, and non-realistic
∗Equal contribution. vector drawings, allowing downstream applications such as material editing, vectorized shading, and relighting. Project website: https://chen-geng.com/inv-shade-trees. 1.

Introduction
Analyzing the shading process in images is fundamental to computer vision and graphics. In particular, the shad-ing process models how the appearances of surfaces are generated from an object’s material properties and lighting conditions. Traditional methods formulate it as the prob-lem of intrinsic decomposition, which expresses the shading as the product of reflectance and albedo [2, 13]. However, this representation is limited in applicability as it assumes a Lambertian surface. Another popular line of works on inverse rendering aims at reconstructing analytical represen-tations [35, 39, 42, 58, 59] or measured representations [30] for materials and lighting. Yet, such physical representations are often difficult to interpret in human perception and not user-friendly for image manipulation tasks.
The choice of shading representation in inverse graphics
Figure 2. Illustration of downstream applications using the shade tree representation extracted from a single image. For object relighting in (e) and (f), insets show the changed lighting condition. is important in that it affects what downstream tasks can be accomplished with that representation. The Shade tree model is a popular representation for shading in the for-ward rendering community [7]. One important application of this representation is that it models how vector graphics are shaded [38]. Due to its tree structure, this representation is highly interpretable and easily editable. Thus, it is a wor-thy and interesting task to recover such representation from visual observations.
In this work, we study recovering the shade tree repre-sentation from a single image. We define our shade tree as a binary tree that contains predefined base nodes (like
“highlight” and “albedo”) and operations (like “screen mode” and “mix”). Fig. 1 shows examples of our extracted shade trees and subsequently edited materials produced from these extracted trees. In particular, we focus on decomposing the
“shading” of objects. The input shading can be considered as spherical reflectance maps or “MatCaps” obtained from existing pipeline [46, 51].
Despite its desirable high interpretability and editability, inferring such a structured representation from a single im-age has inherent challenges. First, a shade tree contains both continuous parameters for leaf nodes as well as a discrete tree structure, making it difficult to optimize directly. Second, different combinations of base nodes and operations can lead to equivalent structures, introducing additional ambiguities for deterministic inference methods. To infer both discrete structure and continuous parameters, we propose a novel two-stage approach to iteratively decompose an input observation into a shade tree. In the first stage, we use an auto-regressive model to recursively decompose nodes to generate an initial tree structure. Then, we perform sub-structure searching and parameter optimization to fine-tune the tree representation.
To deal with the structural ambiguity, we propose a multiple sampling strategy to allow non-deterministic inference that accounts for the multi-modal distribution of plausible shade trees.
Our extensive experiments show the effectiveness of the proposed approach in decomposing the shading of objects using the shade tree representation. Further, we apply our ap-proach to real shadings and non-realistic vector drawings and demonstrate applications on real images. We demonstrate various downstream tasks in Fig. 2.
In summary, our contributions are three-fold. First, we formulate the problem of inferring shade trees from a single image, aiming at understanding the shading of objects with an interpretable representation. Second, we design a novel hybrid approach, integrating an amortized-inference pipeline and an optimization-based solver. Third, we conduct exten-sive experiments to show the effectiveness of our method and demonstrate potential applications of our method. 2.