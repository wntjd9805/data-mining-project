Abstract
A critical obstacle preventing NeRF models from being deployed broadly in the wild is their reliance on accurate camera poses. Consequently, there is growing interest in extending NeRF models to jointly optimize camera poses and scene representation, which offers an alternative to off-the-shelf SfM pipelines which have well-understood failure modes. Existing approaches for unposed NeRF operate un-der limiting assumptions, such as a prior pose distribution or coarse pose initialization, making them less effective in a general setting. In this work, we propose a novel approach,
LU-NeRF, that jointly estimates camera poses and neural radiance fields with relaxed assumptions on pose configu-ration. Our approach operates in a local-to-global man-ner, where we first optimize over local subsets of the data, dubbed “mini-scenes.” LU-NeRF estimates local pose and geometry for this challenging few-shot task. The mini-scene poses are brought into a global reference frame through a robust pose synchronization step, where a final global op-timization of pose and scene can be performed. We show our LU-NeRF pipeline outperforms prior attempts at un-posed NeRF without making restrictive assumptions on the pose prior. This allows us to operate in the general SE(3) pose setting, unlike the baselines. Our results also indi-cate our model can be complementary to feature-based SfM pipelines as it compares favorably to COLMAP on low-texture and low-resolution images. 1.

Introduction
NeRF [34] was introduced as a powerful method to tackle the problem of learning neural scene representations and photorealistic view synthesis, and subsequent research has focused on addressing its limitations to extend its ap-plicability to a wider range of use cases (see [54, 59] for surveys). One of the few remaining hurdles for view syn-thesis in the wild is the need for accurate localization. As images captured in the wild have unknown poses, these ap-*Work done during an internship at Google.
Website: https://zezhoucheng.github.io/lu-nerf/ proaches often use structure-from-motion (SfM) [48, 40] to determine the camera poses. There is often no recourse when SfM fails (see Fig. 7 for an example), and in fact, even small inaccuracies in camera pose estimation can have a dramatic impact on photorealism.
Few prior attempts have been made to reduce the reliance on SfM by integrating pose estimation directly within the
NeRF framework. However, the problem is severely un-derconstrained (see Fig. 1) and current approaches make additional assumptions to make the problem tractable.
For example, NeRf−− [56] focuses on pose estimation in forward-facing configurations, BARF [29] initialization must be close to the true poses, and GNeRF [32] assumes a 2D camera model (upright cameras on a hemisphere).
We propose an approach for jointly estimating the cam-era pose and scene representation from images from a single scene while allowing for a more general camera configura-tion than previously possible. Conceptually, our approach is organized in a local-to-global learning framework using
NeRFs. In the local processing stage we partition the scene into overlapping subsets, each containing only a few images (we call these subsets mini-scenes). Knowing images in a mini-scene are mostly nearby is what makes the joint esti-mation of pose and scene better conditioned than perform-ing the same task globally. In the global stage, the over-lapping mini-scenes are registered in a common reference frame through pose synchronization, followed by jointly re-fining all poses and learning the global scene representation.
This organization into mini-scenes requires learning from a few local unposed images. Although methods exist for few-shot novel view synthesis [60, 27, 38, 20, 12, 11], and separately for optimizing unknown poses [29, 32, 56], the combined setting presents new challenges. Our model must reconcile the ambiguities prevalent in the local un-posed setting – in particular the mirror symmetry ambigu-ity [39], where two distinct 3D scenes and camera configu-rations produce similar images under affine projection.
We introduce a Local Unposed NeRF (LU-NeRF) model to address these challenges in a principled way. The infor-mation from the LU-NeRFs (estimated poses, confidences, and mirror symmetry analysis) is used to register all cam-Figure 1. Jointly optimizing camera poses and scene representation over a full scene is difficult and underconstrained. This example is the
Lego scene with 100 images from the Blender dataset. Left: When provided noisy observations of the true camera locations, BARF [29] cannot converge to the correct poses. Middle: GNeRF [32] assumes a 2D camera representation (azimuth, elevation) which is accurate for the Blender dataset which has that exact configuration (upright cameras on a sphere). However, GNeRF also requires an accurate prior distribution on poses for sampling. The Lego images live on one hemisphere, but when GNeRF’s prior distribution is the full sphere it also fails to localize the images accurately. Right: Our full model, LU-NeRF+Sync, is able to recover poses almost perfectly in this particular example. By taking a local-to-global approach, we avoid having strong assumptions about camera representation or pose priors.
Following [29, 32] pose errors for each method are reported after optimal global alignment of estimated poses to ground truth poses. To put the translation errors in context, the Blender cameras are on a sphere of radius 4.03. eras in a common reference frame through pose synchro-nization [19, 42, 23], after which we refine the poses and optimize the neural scene representations using all images.
In summary, our key contributions are:
• A local-to-global pipeline that learns both the camera poses in a general configuration and a neural scene rep-resentation from only an unposed image set.
• LU-NeRF, a novel model for few-shot local unposed
NeRF. LU-NeRF is tailored to the unique challenges we have identified in this setting, such as reconciling mirror-symmetric configurations.
Each phase along our local-to-global process is designed with robustness in mind, and the consequence is that our pipeline can be successful even when the initial mini-scenes contain frequent outliers (see Sec 4 for a discussion on different mini-scene construction techniques). The perfor-mance of our method surpasses prior works that jointly op-timize camera poses and scene representation, while also being flexible enough to operate in the general SE(3) pose setting unlike prior techniques. Our experiments indicate that our pipeline is complementary to the feature-based SfM pipelines used to initialize NeRF models, and is more reli-able in low-texture or low-resolution settings. 2.