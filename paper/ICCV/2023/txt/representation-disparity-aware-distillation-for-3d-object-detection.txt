Abstract
In this paper, we focus on developing knowledge dis-tillation (KD) for compact 3D detectors. We observe that off-the-shelf KD methods manifest their efficacy only when the teacher model and student counterpart share similar in-termediate feature representations. This might explain why they are less effective in building extreme-compact 3D de-tectors where significant representation disparity arises due primarily to the intrinsic sparsity and irregularity in 3D point clouds. This paper presents a novel representation disparity-aware distillation (RDD) method to address the representation disparity issue and reduce performance gap between compact students and over-parameterized teach-ers. This is accomplished by building our RDD from an in-novative perspective of information bottleneck (IB), which can effectively minimize the disparity of proposal region pairs from student and teacher in features and logits. Ex-tensive experiments are performed to demonstrate the su-periority of our RDD over existing KD methods. For ex-ample, our RDD increases mAP of CP-Voxel-S to 57.1% on nuScenes dataset, which even surpasses teacher perfor-mance while taking up only 42% FLOPs. 1.

Introduction 3D object detection in point clouds [25, 40, 29] is a fun-damental perception task with broad applications on au-tonomous driving, robotics and smart city, etc. Benefi-cial from the large-scale 3D perception datasets [8, 2, 32] as well as advanced point [25], pillar [18, 37] and voxel based [9, 21] representations of sparse and irregular LiDAR point cloud scenes, 3D detection has achieved remarkable progress [28, 44]. Unfortunately, stronger performance is often accompanied with heavier computation burden, there-fore the adoption in real-world applications still remains a challenging problem.
† Equal contribution.
∗ Corresponding author: xbcao@buaa.edu.cn 1 Code: https://github.com/YanjingLi0202/RDD
Figure 1. Visualization of intermediate neck features from teacher
CP-Voxel [44] and student CP-Voxel-XXS [41]. Student† denotes
CP-Voxel-XXS distilled by [41]. “F-P” denotes false positive pre-dictions from the detector. The second and fourth column images show false positives on the original inputs where the red boxes denote false positives from the detector. Off-the-shelf implemen-tation fails to tackle false positives if significant disparity exists between teacher (c) and student (g) feature maps.
Recent attempts to improve efficiency focus on devel-oping specified architectures for point-based 3D object de-tectors [5, 46], not generalizable to a wide spectrum of pillar/voxel-based methods [47, 18, 28, 44, 7, 40]. Here, we aim at a model-agnostic framework for obtaining efficient and accurate 3D object detectors with knowledge distilla-tion (KD). Due to its effectiveness, generality and simplic-ity, KD has become a popular strategy to develop efficient models in a variety of 2D tasks [12, 21, 6, 13], which im-proves the performance of a lightweight student model by harvesting knowledge from an accurate yet computationally heavy teacher model.
The recent art [41] employs pivotal position logit KD to enhance the performance of compact 3D detectors. How-ever, as we analyze in this paper, the intrinsic representation
Therefore, in this paper we propose a novel 3D detector oriented representation disparity-aware distillation (RDD) method to address the above issue and reduce performance gap between compact students and over-parameterized teachers. Framework of our RDD is illustrated in Fig. 3, where the distillation objective is actually formulated un-der the principle of information bottleneck (IB) to maxi-mize the mutual information between intermediate features of teacher and students. To this end, for each region pro-posal in teacher (student) model, our RDD first pair it by cropping a counterpart region in the same location of stu-dent (teacher) model. We measure representation disparity in each pair with mutual information under the IB frame-work and then learn to weight the region pairs to better bilaterally transfer information between teacher and stu-dent. In contrast to off-the-shelf pivotal position logit KD or simply involving ground truths [36, 41], the weighted information is transferred by a feature-level representation disparity-aware distillation as well as logit-level representa-tion disparity-aware distillation loss.
We compare our RDD against state-of-the-art 2D and 3D
KD methods [6, 34, 24, 41, 45] on datasets of KITTI [8] and large-scale nuScenes [2]. Extensive results reveal that our method outperforms the others by a considerable margin.
For instance, on nuScenes, the CP-Voxel-S [41] distilled by our RDD obtains 57.1% mAP with only 42% FLOPs of CP-Voxel [44], achieving a new state-of-the-art. 2.