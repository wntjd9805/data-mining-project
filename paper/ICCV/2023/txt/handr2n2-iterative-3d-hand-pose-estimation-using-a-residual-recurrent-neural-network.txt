Abstract 3D hand pose estimation is a critical task in various human-computer interaction applications. Numerous deep learning based estimation models in this domain have been actively explored. However, the existing models follow a non-recurrent scheme and thus require complex architec-tures or redundant parameters in order to achieve accept-able model capacity. To tackle this limitation, this paper proposes HandR2N2, a compact neural network that itera-tively regresses the hand pose using a novel residual recur-rent unit. The recurrent design allows recursive exploita-tion of partial layers to gradually optimize previously esti-mated joint locations.
In addition, we exploit graph rea-soning to capture kinematic dependencies between joints for better performance. Experimental results show that the proposed model significantly outperforms the existing meth-ods on three hand pose benchmark datasets in terms of both accuracy and efficiency. Codes and pre-trained mod-els are publicly available at https://github.com/ cwc1260/HandR2N2. 1.

Introduction 3D hand pose estimation, which estimates the 3D po-sitions of hand keypoints, provides a fundamental under-standing of human hand activity. Thus, it is a critical task for many human-computer interaction applications such as robotics and augmented/virtual reality. With the assis-tance of deep learning techniques and low-cost depth cam-eras, numerous studies have contributed to the substantial progress in the field of hand pose estimation. However, ac-curate and efficient hand pose estimation is still challenging because of the various probability of hand orientations, se-vere self-occlusion, and noisy depth images [12, 9, 18, 6].
Most of the recent state-of-the-art approaches are based on deep learning, especially deep convolutional neural net-works (CNNs). Such CNN-based approaches [31, 10, 13,
Figure 1. Illustration of the recurrent concept. For each iteration, our proposed recurrent architecture samples local points around joints from previous iteration to generate displacements to refine the joint locations. 25, 1, 8, 23, 6, 23] generally accept 2D depth images as an input, which can be directly processed by the 2D con-volutional layers. However, it is difficult for a 2D CNN to capture the highly non-linear mapping from a 2D depth image to the 3D hand pose, significantly restricting its ef-ficiency and accuracy. Therefore, a line of works [11, 18] discretized 2D input images into 3D volumetric representa-tions and subsequently applied a 3D CNN for direct 3D-to-3D inference. However, a critical drawback of a 3D
CNN is its computational overhead that increases cubically with an increase of the input resolution [4]. In contrast, an-other series of hand pose estimation models [9, 12, 2, 15, 4] have presented remarkable performances by using PointNet
[20, 21], which allows the models to accept a set of contin-uous 3D coordinates converted from an input hand image without discretization.
Despite the accuracy improvement achieved by the aforementioned approaches, they still suffer from large and complex model architectures that require substantial com-putational overheads. Thus, these methods are not suitable for resource-limited devices such as wearable or hand-held devices. Furthermore, all the existing approaches follow a non-recurrent architecture. As a result, they are not flex-ible for varying resource constraints and accuracy targets. 1
In this work, we tackle these limitations using a recurrent architecture whose capacity can be dynamically adjusted to achieve either higher accuracy or higher efficiency by itera-tively using a part of model parameters.
The recurrent structure can achieve the high capacity of deeper networks by the recursive use of fewer shared parameters [34]. Various image processing models that used a recurrent neural network (RNN) as an explicit it-erative approach have already yielded encouraging results
[30, 5, 35, 26]. To fully take advantage of the RNN in a hand pose estimation task, we propose a novel residual recurrent neural network, HandR2N2, that iteratively regresses accu-rate 3D hand pose from an input hand point cloud. Intu-itively, HandR2N2 can be served as a general optimizer that recursively searches the optimal joint locations using the observation captured by the previous estimation, as shown in Figure 1.
To implement HandR2N2, we introduce two novel com-ponents: 1) a residual recurrent unit (RRU) and 2) an ini-tialization module. The RRU is a key component that it-eratively proceeds for updating its joint-wise hidden states and coordinate estimations. The initial joint-wise states and coordinates of the RRU are globally estimated by the ini-tialization module.
The RRU specifically integrates with an attentive gate that can explore optimal points from a group of candidate points for the improved accuracy. Since the proposed RRU only computes the features contributed to the specific joints, it is more efficient than the similar prior model in [5], which re-computes the entire point features. Moreover, RRU ex-ploits graph reasoning, which is based on a novel channel-wise graph convolutional network (GCN). GCN is capable to model the graph-structured data, making it particularly suitable for the kinematically structured hand data [8]. The use of the proposed channel-wise GCN enables the RRU to recursively enhance the hidden states by capturing the strong kinematic dependencies between joints. More im-portantly, the number of RRU iterations during inference can be dynamically scaled to be different from the train-ing iteration. Specifically, the RRU inference iterations can be configured large to enhance the model capacity and ac-curacy, or small to reduce the computation requirement.
Therefore, HandR2N2 is capable of adapting varying com-plexity and accuracy requirements as shown in Figure 2.
We evaluate HandR2N2 on three challenging bench-marks, ICVL [28], MSRA [27], and NYU [31] datasets.
The results show that our network achieves a new state-of-the-art record. The proposed network reports the min-imum mean distance errors of 5.70 mm, 6.42 mm and 7.27 mm on the ICVL, MSRA and NYU datasets, respectively.
Meanwhile, it requires only 1.3 M parameters and runs with adjustable complexity 0.72+0.34×I GFLOPs, where I in-dicates the number of iterations. Thus, our model requires
Figure 2. Comparison between operation count and estimation error. I is the iteration number of HandR2N2 during inference. less computation for the highest accuracy compared with other state-of-the-art methods, as shown in Figure 2.
The key contributions of this paper are summarised as follows:
• We propose a novel iterative neural network architec-ture that takes the hand point cloud as input and pro-gressively estimates the accurate 3D hand joint coordi-nates.
• We propose a novel residual recurrent unit that cap-tures new local observations around previously gener-ated coordinates to refine joint-wise hidden states and coordinate estimation. It also leverages a graph neural network to model dependency between the joints for performance improvement.
• We conduct extensive experiments to analyze the effi-ciency and effectiveness of our proposed network. 2.