Abstract have shown
Self-supervised methods remarkable progress in learning high-level semantics and low-level
Building on these results, temporal correspondence. we take one step further and explore the possibility of integrating these two features to enhance object-centric representations. Our preliminary experiments indicate that query slot attention can extract different semantic components from the RGB feature map, while random sampling based slot attention can exploit temporal cor-respondence cues between frames to assist instance identification. Motivated by this, we propose a novel semantic-aware masked slot attention on top of the fused semantic features and correspondence maps. It comprises two slot attention stages with a set of shared learnable
In the first stage, we use the
Gaussian distributions. mean vectors as slot initialization to decompose potential semantics and generate semantic segmentation masks through iterative attention. In the second stage, for each semantics, we randomly sample slots from the correspond-ing Gaussian distribution and perform masked feature aggregation within the semantic area to exploit temporal correspondence patterns for instance identification. We adopt semantic- and instance-level temporal consistency as self-supervision to encourage temporally coherent object-centric representations. Our model effectively identifies multiple object instances with semantic structure, reaching promising results on unsupervised video object discovery.
Furthermore, we achieve state-of-the-art performance on dense label propagation tasks, demonstrating the potential for object-centric analysis. The code is released at https://github.com/shvdiwnkozbw/SMTC. 1.

Introduction
As one of the fundamental cognitive capabilities, human beings easily distinguish different objects, establish visual
*Corresponding author. Email: dhlin@ie.cuhk.edu.hk. (a) Query slot attention on semantic feature. (b) Random sampling slot attention on correspondence map.
Figure 1. Fig. 1(a) presents the results of query slot attention on top of the RGB feature map. It successfully decomposes different semantics, e.g., camels and fence. Fig. 1(b) visualizes the corre-spondence map after PCA dimensionality reduction, showing that different instances have different correspondence patterns. And the slot attention with random sampling coarsely distinguishes two camels with some redundant borders. Best viewed in color. correspondence and perform object-centric analysis from temporally continuous observations. This ability can be at-tributed to two indispensable visual mechanisms: high-level semantic discrimination as well as low-level temporal corre-spondence, which enable humans to effectively understand and interact with the world.
Motivated by this, computer vision researchers equip machines with these capacities to enhance object-centric perception [79, 60, 34]. To achieve this goal, early works rely on human annotations or weak supervision to per-ceive object semantics [60, 63, 13], identify geometric po-sitions [39, 71, 31, 91], and establish temporal correspon-dence [41, 79, 75, 77], but their generalization ability is limited. Recently, there emerge a host of fully unsuper-vised methods to learn robust representations for seman-tic discrimination [14, 38, 33, 70, 29, 37, 12] or spatio-temporal correspondence [44, 81, 86, 55, 52, 43], which achieve promising performance. Given this encouraging re-sult, we naturally come up with a question: Is it possible to jointly leverage the semantics and correspondence to dis-cover object instances and distill object-centric representa-tions without human annotations?
Regarding this problem, our intuition is that the high-level semantics delineates meaningful foreground areas in a top-down manner, while when looking into more frames, the low-level correspondence temporally associates coher-ent objects and separates individual instances in a bottom-up fashion. For instance, in a football scene, the seman-tic cue differentiates the foreground that includes several players, while the temporal correspondence links distinct players through dynamic movements and geometric rela-tionships. These two aspects collectively contribute to object-centric representations. Unfortunately, most of the existing works only concentrate on one of these features.
[14, 38, 33, 70, 82] succeed in developing high-level se-mantics, but this abstract semantics alone is insufficient to distinguish instances. Whereas, [44, 81, 78, 55] excel in de-tailed correspondence, but lack semantic structure and re-sult in redundancy and ambiguity.
In this paper, we propose a new architecture, Seman-tics Meets Temporal Correspondence (SMTC), to jointly leverage semantics and temporal correspondence to dis-till object-centric representations from RGB sequences.
Specifically, we first extract frame-wise visual features as the semantic representation. Then we calculate dense feature correlations between adjacent frames as the cor-respondence map which encodes temporal relationships.
To mine the object-centric knowledge, we take inspiration from [59, 88, 50, 25], and investigate using different for-mulations of slot attention on them. The preliminary ex-periments show that the original slot attention with ran-dom sampling on RGB feature map suffers from complex scene components in real-world videos [59, 72], but the re-vised query slot attention [88, 46] can decompose differ-ent semantic components as shown in Fig. 1(a). As for the correspondence map, different objects present diverse temporal correspondence patterns. Comparing to semantic features, these patterns reveal low-level geometric relation-ships, which are comparatively simple but vary with specific scenes. Hence, query slot attention fails but the random sampling based formulation performs surprisingly well as shown in Fig. 1(b), coarsely separating different object ar-eas with some redundant borders.
Motivated by this, we develop semantic-aware masked slot attention, which comprises a set of Gaussian distribu-tions with learnable mean and standard deviation vectors, on top of the fused semantic and correspondence represen-tations. The intuition is that the mean vectors could rep-resent potential semantic centers, which act similarly to the query slot attention to separate semantic components.
While the deviation vectors introduce perturbations around the semantic centers to capture distinct temporal correspon-dence patterns of different instances. Technically, we for-mulate two slot attention stages to achieve this goal. Firstly, we use the mean vectors as slot initialization to generate semantic segmentation masks. Secondly, for each seman-tics, we randomly sample slot vectors from the Gaussian distribution, then perform iterative attention and masked aggregation within the corresponding semantic mask area to distinguish instances. We enforce temporal consistency on the semantic masks as well as object instance slots to enhance temporal coherency and refine object-centric rep-resentations. Comparing with existing works on object-centric learning in videos [25, 50, 88, 84], our model is free of pre-computed motion or depth prior, and explicitly iden-tifies multiple objects with semantic structure.
In summary, our contributions are: (1) We propose a novel self-supervised architecture that unifies semantic dis-crimination and temporal correspondence to distill object-centric representations in videos. (2) We demonstrate that simple feature correlation can effectively represent tem-poral correspondence cues when used in conjunction with semantic features. Building on this observation, we de-velop semantic-aware masked slot attention, which oper-ates on fused visual features and correspondence maps, to distinguish multiple object instances with semantic struc-(3) We ture without relying on motion or depth priors. achieve promising results on unsupervised object discovery in both single and multiple object scenarios, and reach state-of-the-art performance on label propagation tasks, demon-strating that we learn discriminative and temporally consis-tent object-centric representations. 2.