Abstract
Semantic segmentation of point clouds in autonomous driving datasets requires techniques that can process large numbers of points efficiently. Sparse 3D convolutions have become the de-facto tools to construct deep neural networks for this task: they exploit point cloud sparsity to reduce the memory and computational loads and are at the core of today’s best methods. In this paper, we propose an al-ternative method that reaches the level of state-of-the-art methods without requiring sparse convolutions. We actu-ally show that such level of performance is achievable by relying on tools a priori unfit for large scale and high-performing 3D perception.
In particular, we propose a novel 3D backbone, WaffleIron, made almost exclusively of MLPs and dense 2D convolutions and present how to train it to reach high performance on SemanticKITTI and nuScenes. We believe that WaffleIron is a compelling al-ternative to backbones using sparse 3D convolutions, espe-cially in frameworks and on hardware where those convo-lutions are not readily available. The code is available at https://github.com/valeoai/WaffleIron. 1.

Introduction
Lidar sensors deliver rich information about the 3D envi-ronment surrounding autonomous vehicles. Semantic seg-mentation of point clouds delivered by these lidars permits to autonomous vehicles to make sense of this 3D informa-tion in order to take proper and safe decisions. When study-ing the leaderboard of SemanticKITTI [2], we rapidly no-tice that all the top methods leverage sparse 3D convolu-tions. For example, the recent work 2DPASS [43] relies on an adapted version of SPVCNN [34] which, once trained with the help of images of the scene captured synchronously with the lidar, is currently the state-of-the-art method. As another example, Cylinder3D [51], later improved in [12], use sparse 3D convolutions on cylindrical voxels (particu-larly adapted to rotating lidars) with asymmetrical kernels suited to capture the geometry of the main objects in driv-ing scenes.
Despite the undeniable success and efficiency of sparse convolutions, we seek here for 3D backbones which are free of them.
Indeed, sparse convolutions remain available in a limited number of deep learning frameworks and hard-ware (essentially PyTorch and NVIDIA GPUs). One rea-son might be because they are challenging to implement ef-ficiently [33]. Another reason may be because they are not as widely used as, e.g., dense 2D convolutions, and are thus not the first to be implemented in a new framework. There-fore, we would like to construct a 3D backbone (i) built with tools more broadly available than sparse convolutions, but which (ii) can reach the level of performance of the top methods on automotive datasets, while (iii) remaining easy to implement and to use. This would offer a compelling alternative to sparse 3D backbone, especially when sparse convolutions are not available.
We actually construct a novel 3D backbone built almost exclusively with standard MLPs and dense 2D convolu-tions, both readily available in all deep learning frameworks thanks to their wide use in the whole field of computer vi-sion. Our backbone architecture, WaffleIron, is illustrated in Fig. 1, and is inspired by the recent MLP-Mixer [36]. It takes as input a point cloud with a token associated to each point. All these point tokens are then updated by a sequence of layers, each containing a token-mixing step (made of dense 2D convolutions) and a channel-mixing step (made of a MLP shared across points).
In addition, we explain how to train WaffleIron to make it reach the performance of the current best methods on au-tomotive semantic segmentation benchmarks. The perfor-mance we obtain shows that standard MLPs and dense 2D convolutions, despite being a priori unfit for 3D segmenta-tion, are sufficient to construct a 3D backbone reaching the state of the art.
Finally, WaffleIron is at least as easy to implement and to tune as any other backbone. The implementation consists in repeated applications of basic layers directly on the point tokens (an example of complete implementation is available in the supplementary material). The performance increases with the network width and depth, until an eventual satura-tion. The main hyperparameter to tune is the resolution of the 2D grid used for discretization before 2D convolution, but for which we observe stable results over a wide range
Figure 1. WaffleIron backbone. This 3D backbone takes as input point tokens, provided by an embedding layer (not represented), and updates these point representations L times via a point token-mixing layer (containing the WI block) followed by a channel-mixing layer.
The WI block consists of a 2D projection along one of the main axes, a feed-forward network (FFN) with two dense channel-wise 2D convolutions with a ReLU activation in the hidden layer, and a simple copy of the 2D features to the 3D points. The channel-mixing layer contains a batch-norm, a MLP shared accross each point, and a residual connection. The WaffleIron backbone is free of any point downsampling or upsampling layer, farthest point sampling, nearest neighbor search, or sparse convolution. of values (facilitating its tuning). The two most technical components to implement are reduced to: (i) the embed-ding layer used before WaffleIron and providing the point tokens, and (ii) the 2D projections followed by feature dis-cretizations (applied before dense 2D convolutions).
In summary, our contributions are the following.
• We propose a novel and easy-to-implement 3D back-bone for automotive point cloud semantic segmenta-tion, which is essentially made of standard MLPs and dense 2D convolutions.
• We show that the hyperparameters of WaffleIron are easy to tune: the performance increases with the width and depth, until an eventual saturation; the perfor-mance is stable over a large range of 2D grid resolu-tions.
• We present how to train WaffleIron to reach the per-formance of top-entries on two autonomous driving benchmarks: SemanticKITTI [2] and nuScenes [5].
This shows that standard MLPs and dense 2D convo-lutions are actually sufficient to compete with the state of the art. 2.