Abstract
This paper focuses on an under-explored yet important problem: Federated Class-Continual Learning (FCCL), where new classes are dynamically added in federated learning. Existing FCCL works suffer from various lim-itations, such as requiring additional datasets or storing the private data from previous tasks. In response, we first demonstrate that non-IID data exacerbates catastrophic forgetting issue in FL. Then we propose a novel method called TARGET (federatTed clAss-continual leaRninG via
Exemplar-free disTillation), which alleviates catastrophic forgetting in FCCL while preserving client data privacy.
Our proposed method leverages the previously trained global model to transfer knowledge of old tasks to the cur-rent task at the model level. Moreover, a generator is trained to produce synthetic data to simulate the global dis-tribution of data on each client at the data level. Compared to previous FCCL methods, TARGET does not require any additional datasets or storing real data from previous tasks, which makes it ideal for data-sensitive scenarios. 1.

Introduction
Federated Learning (FL) is a privacy-aware learning paradigm that facilitates collaborations among multiple en-tities (e.g., edge devices or organizations) [38, 20, 28, 66, 17]. Each entity or client in FL retains data locally and transfers only training updates to the central server for ag-gregation.
Conventional FL studies assume that the data classes and domains are static, but the new classes could emerge and data domains could change over time in reality [64,
*Work done during internship at Sony AI.
†Corresponding author. 40, 1, 65]. For example, multiple health institutions could use FL to collaborate and train models to identify COVID-19 [56, 9, 2] strains; new COVID-19 strains, however, con-tinue to emerge due to high mutation rate of virus. An in-tuitive solution to this issue of continuously emerging data classes is training new models from scratch, but this is im-practical as it would require significant extra computation cost. Another method is transfer learning from the previ-ously trained model, but this method suffers from catas-trophic forgetting [23, 22, 47, 16], degrading performance on the previous classes.
To address these issues, recent research [36, 11, 3, 19] has introduced the concept of Continual Learning (CL) [61, 42, 51, 49, 48] within the FL framework. These meth-ods, collectively referred to as Federated Continual Learn-ing (FCL), aim to mitigate the problems of catastrophic for-getting in FL. In most FCL scenarios, new classes are dy-namically added, which we call Federated Class-Continual
Learning (FCCL). FCCL allows local clients to continu-ously collect new data, and new classes can be added at any time.
Unfortunately, existing FCCL works suffer from various limitations. For example, Ma et al. [36] utilize an unla-beled surrogate dataset to address the catastrophic forget-ting problem, which may be difficult to obtain in some data sensitive scenarios. Furthermore, the usage of an unla-beled surrogate dataset may not be ideal for certain types of data, as it may not capture the full complexity of the orig-inal data. In CL, exemplar-based methods [44, 33, 54, 13] have achieved leading performance. An exemplar refers to a sample or instance of a previously seen data point that is retained in a memory buffer for future use in the learn-ing process. Dong et al. [11] propose a exemplar-based method that stores historical data to address catastrophic forgetting. However, in many privacy-sensitive scenarios (e.g., hospitals and medical research institutions), users are
not permitted to store data from previous tasks due to pri-vacy and policy concerns and data will not be kept for a long time [21, 53, 34, 50]. In summary, the majority of FCCL methods train the global model with additional datasets or previous task data, which could potentially violate data pri-vacy regulations. This dilemma prompts us to consider the following question:
Question: How to effectively alleviate the catastrophic forgetting problem in the FCCL without storing the local private data of the client or any additional datasets?
To address this question, we conduct a systematic anal-ysis and observe that the imbalanced distribution of data among clients in FL exacerbates the catastrophic forgetting
In order to fix this problem: problem (see Section 3.3). 1) at the model level, we leverage the previously trained global model to transfer knowledge of the old tasks to the current task. 2) at the data level, we train a generator to produce synthetic data that aims to simulate the global distribution of data on each client. Drawing on these in-sights, we present a method called TARGET (federatTed clAss-continual leaRninG via Exemplar-free disTillation) that mitigates catastrophic forgetting in FCCL without com-promising clients’ data privacy.
Our contributions can be concluded as follows:
• We are the first to demonstrate that non-independent and identically distributed (non-IID) data exacerbates catastrophic forgetting issue in FL. Then we propose a novel method called TARGET, which alleviates the catastrophic forgetting in FCCL by leveraging global information.
• Compared to previous FCCL methods, TARGET doesn’t require extra datasets or data from previous tasks, it can be applied in data sensitive scenarios.
• Extensive experiments demonstrate the efficacy of our proposed method. For example, when partitioning the CIFAR-100 dataset into five tasks, our method achieves an accuracy of 36.31%, which is about 6% higher than the best baseline method. 2.