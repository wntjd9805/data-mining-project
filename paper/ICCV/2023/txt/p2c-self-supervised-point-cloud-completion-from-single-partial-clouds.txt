Abstract
Point cloud completion aims to recover the complete shape based on a partial observation. Existing methods re-quire either complete point clouds or multiple partial obser-vations of the same object for learning. In contrast to pre-vious approaches, we present Partial2Complete (P2C), the first self-supervised framework that completes point cloud objects using training samples consisting of only a single incomplete point cloud per object. Specifically, our frame-work groups incomplete point clouds into local patches as input and predicts masked patches by learning prior in-formation from different partial objects. We also propose
Region-Aware Chamfer Distance to regularize shape mis-match without limiting completion capability, and devise the Normal Consistency Constraint to incorporate a lo-cal planarity assumption, encouraging the recovered shape surface to be continuous and complete. In this way, P2C no longer needs multiple observations or complete point clouds as ground truth. Instead, structural cues are learned from a category-specific dataset to complete partial point clouds of objects. We demonstrate the effectiveness of our approach on both synthetic ShapeNet data and real-world
ScanNet data, showing that P2C produces comparable re-sults to methods trained with complete shapes, and out-performs methods learned with multiple partial observa-tions. Code is available at https://github.com/
CuiRuikai/Partial2Complete.
Figure 1. Conceptual comparison of point cloud completion schemes. Let x(i) k be the k-th incomplete observation of object i, while ˆy(i) and y(i) be the corresponding completed prediction and ground truth, respectively. (a) Supervised approaches rely on paired partial-complete samples. (b) Unpaired methods require partial point clouds and complete examples to guide predictions to match the input shape and follow the complete shape distribu-tion. (c) Weakly-supervised models learn completion based on (d) consistency across multi-view partial samples of an object.
Our scheme differs from existing settings as only a single partial observation per object instance is available for learning. 1.

Introduction
Point clouds are widely used for 3D shape representa-tion and play a crucial role in a range of applications [18, 30, 28, 29]. However, real-world raw point clouds are col-lected from sources such as laser scanners [10] and depth cameras [8], and so are often incomplete and noisy due to occlusions and varying lighting conditions. For this reason,
*Email: ruikai.cui@anu.edu.au
†Corresponding author. Email: shi.qiu@anu.edu.au point cloud completion (PCC) [40, 9, 34, 14] is studied to obtain complete point clouds from partial ones.
Supervised learning [39, 34, 24] offers a straightforward solution, where both partial point clouds and ground truth completions are required during training. Nevertheless, col-lecting complete point clouds is challenging. As a result, training data pairs are often obtained by simulating occlu-sions on 3D model collections like ShapeNet [5]. Due to the distribution gap between real and simulated data, the real-world performance of these approaches is often limited.
Unpaired (or unsupervised) PCC [6] is an alternative to
supervised PCC, which trains a category-specific network using only partial point clouds and a set of example com-plete shapes of the same category. This approach enables the use of incomplete shapes from large-scale real scans and virtual 3D object datasets, as the partial points and com-plete shapes do not need to be paired. However, obtaining a large, complete, and clean 3D point cloud dataset remains challenging, due to factors such as labor cost, equipment ex-penses, etc. Weakly-supervised methods [13, 23, 31] have been proposed by constructing weak supervision cues us-ing multiple unaligned observations from different views of the same object. However, the performance can be signifi-cantly affected by alignment errors, and collecting observa-tions from many views is difficult due to hardware limita-tions or viewing angle restrictions.
To address these challenges, we propose a new self-supervised approach to PCC, where for training, we only require one point cloud observation with unknown incom-pleteness per object. This novel setting offers several ben-efits for completion: 1) it eliminates the need for complete samples, thereby reducing the difficulty and expense of an-notation; 2) partial objects can be easily collected from the actual world even if only a single viewing angle is available, significantly expanding the scope of training data; 3) by leveraging the unknown incompleteness assumption, partial samples, complete shapes and weakly-supervised cues can be unified in the learning framework to improve comple-tion quality. Fig. 1 illustrates the difference of our proposed setting with existing main schemes.
In this paper, we introduce Partial2Complete (P2C), an effective approach for training a category-specific point cloud completion network using only single partial point clouds. Inspired by He et al. [15], P2C groups input points as patches that represent a small but possibly continuous region on the underlying surface, where we expect the net-work to predict masked patches based on unmasked regions.
Our approach assumes that a structural prior can be learned by observing a number of training objects with different missing parts, guiding the reconstruction of severely incom-plete point clouds. Furthermore, we develop the cycle con-straint [43] from unpaired image translation to propose a latent reconstruction loss to the framework. This regular-ization ensures that completing different partial regions of the same object leads to the same completed shape.
We also present two new components to address prob-lems that are unique to the self-supervised setting. First, tra-ditional point cloud distance measures [40, 36] lack aware-ness of complete or missing regions that occur in the com-pletion task, leading to either limited completion capability or mismatching predictions. To address this challenge, we introduce Region-Aware Chamfer Distance (RCD) to esti-mate point cloud correspondence based on regions centered at dynamically generated skeleton points. By optimising
RCD, possible outlier points can be pulled to the target point set and completion of missing regions will not be restricted.
On the other hand, motivated by techniques that use dif-ferential geometry-based surface curvature to describe and identify local surface shape [2, 20, 35, 33], we propose the
Normal Consistency Constraint (NCC) to encourage gener-ated points to follow the local 2D surface manifold of the incomplete point cloud. The NCC queries the normal direc-tion similarity for nearby points and computes the similarity variance as a regularizer to encourage local planarity.
We apply P2C to synthetic and real-world completion tasks to comprehensively verify its effectiveness. We show that, without any complete shape examples, our approach not only achieves comparable results against methods with access to complete samples, but also outperforms weakly-supervised methods trained with multiple incomplete obser-vations. In summary, our main contributions are:
• We propose, P2C, the first self-supervised framework that is able to complete point clouds with only a single partial point cloud per object for learning.
• We design a novel distance measure, Region-Aware
Chamfer Distance, which overcomes problems of re-stricting completion and insufficient supervision, by constructing local regions around dynamically con-structed skeleton points.
• We present the Normal Consistency Constraint to re-fine shape predictions to follow the local surface man-ifold by minimizing a novel consistency metric, im-proving surface continuity and completeness. 2.