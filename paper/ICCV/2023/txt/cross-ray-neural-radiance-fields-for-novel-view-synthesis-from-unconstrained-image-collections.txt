Abstract 1.

Introduction
Neural Radiance Fields (NeRF) is a revolutionary ap-proach for rendering scenes by sampling a single ray per pixel and it has demonstrated impressive capabilities in novel-view synthesis from static scene images. However, in practice, we usually need to recover NeRF from uncon-strained image collections, which poses two challenges: 1) the images often have dynamic changes in appearance be-cause of different capturing time and camera settings; 2) the images may contain transient objects such as humans and cars, leading to occlusion and ghosting artifacts. Con-ventional approaches seek to address these challenges by locally utilizing a single ray to synthesize a color of a pixel.
In contrast, humans typically perceive appearance and ob-jects by globally utilizing information across multiple pixels.
To mimic the perception process of humans, in this paper, we propose Cross-Ray NeRF (CR-NeRF) that leverages interac-tive information across multiple rays to synthesize occlusion-free novel views with the same appearances as the images.
Specifically, to model varying appearances, we first propose to represent multiple rays with a novel cross-ray feature and then recover the appearance by fusing global statistics, i.e., feature covariance of the rays and the image appear-ance. Moreover, to avoid occlusion introduced by transient objects, we propose a transient objects handler and intro-duce a grid sampling strategy for masking out the transient objects. We theoretically find that leveraging correlation across multiple rays promotes capturing more global infor-mation. Moreover, extensive experimental results on large real-world datasets verify the effectiveness of CR-NeRF. The code and data can be found at https://github.com/
YifYang993/CR-NeRF-PyTorch.git. 2Corresponding author. 1This work was done when Yifan Yang was a research intern at
Guangzhou Shiyuan Electronics Co., Ltd.
Novel-view synthesis is a long-standing problem in com-puter vision that has paved the way for numerous appli-cations such as virtual reality and digital humans [13, 45].
More recently, the emergence of Neural Radiance Fields (NeRF) has driven the field forward, as it has shown signif-icant performance in reconstructing 3D geometry [50] and recovering the appearance [3, 35, 1] from multi-view image sets. However, NeRF assumes that the images do not have variable appearances and moving objects [31] (called the static scene assumption c.f. Sec. 3), which leads to signifi-cant performance degradation on large-scale Internet image collections. To expand the scope of NeRF, we aim to ex-ploit the collections and provide a 3D immersive experience through which we can visit international landmarks such as the Brandenburg Gate, and the Trevi Fountain from different viewpoints and times of one day.
To achieve this, we address the problem of recovering an appearance-controllable and anti-occlusion NeRF from unconstrained image collections. In other words, by recon-structing the NeRF representation, we control the appearance of the scene based on photos with various photometric con-ditions, while eliminating occlusions caused by the images.
Although providing a sense of immersion, reconstructing
NeRF with these images faces the following two challenges. 1) Varying appearances: Imaging two tourists who take photos in the same viewpoint but under various conditions, e.g., different capturing times, diverse weather (e.g., sunny, rainy, and foggy), and different camera settings (e.g., aper-ture, shutter, and ISO). This varying condition causes that although multiple photographs are taken of the same scene, they look dramatically different. 2) Transient occlusion:
Even with a constant appearance, transient objects such as cars and Pedestrians may obscure the scene. Since these objects are usually captured by only one photographer, it is usually impractical to reconstruct these objects in high quality. The above challenges conflict with the static-scene
through which we detect transient objects by considering global information of an image region. From this perspec-tive, we segment the unconstrained images for a visibility map of the objects. To avoid computation overhead, we introduce a grid sample strategy that samples the segmented maps to pair with the input rays. We theoretically analyze that leveraging correlation across multiple rays promotes capturing more global information.
We summarize our contributions in three folds:
• A new cross-ray paradigm for novel-view synthesis from unconstrained photo collections: We find that existing methods fall short of producing satisfactory visual outcomes from unconstrained photo collections via a single-ray-level paradigm, primarily due to the neglect of the potential co-operative interaction among multiple rays. To address this, we propose a novel cross-ray paradigm, which exploits the global information across multiple rays.
• An interactive and global scheme for addressing vary-ing appearances: Unlike existing methods that process each ray independently, we represent multiple rays by introducing a cross-ray feature, which facilitates the interaction among rays through feature covariance. This enables us to inject a global informative appearance representation into the scene, resulting in more realistic and efficient appearance model-ing. Our theoretical analysis demonstrates the necessity of considering multiple rays for appearance modeling.
• A novel segmentation technique for processing tran-sient objects: We reformulate the transient object problem as a segmentation problem. We use global information of an unconstrained image to segment a visibility map. More-over, we apply grid sampling to pair the map with multiple rays. Empirical results show that CR-NeRF eliminates the transient objects in reconstructed images. 2.