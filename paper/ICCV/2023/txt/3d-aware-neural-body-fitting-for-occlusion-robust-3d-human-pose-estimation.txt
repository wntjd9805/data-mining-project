Abstract
Regression-based methods for 3D human pose estima-tion directly predict the 3D pose parameters from a 2D im-age using deep networks. While achieving state-of-the-art performance on standard benchmarks, their performance degrades under occlusion. In contrast, optimization-based methods fit a parametric body model to 2D features in an iterative manner. The localized reconstruction loss can potentially make them robust to occlusion, but they suffer from the 2D-3D ambiguity. Motivated by the recent suc-cess of generative models in rigid object pose estimation, we propose 3D-aware Neural Body Fitting (3DNBF) - an approximate analysis-by-synthesis approach to 3D human pose estimation with SOTA performance and occlusion ro-bustness.
In particular, we propose a generative model of deep features based on a volumetric human represen-tation with Gaussian ellipsoidal kernels emitting 3D pose-dependent feature vectors. The neural features are trained with contrastive learning to become 3D-aware and hence to overcome the 2D-3D ambiguity. Experiments show that 3DNBF outperforms other approaches on both occluded and standard benchmarks. Code is available at https:
//github.com/edz-o/3DNBF 1.

Introduction
Monocular 3D human pose estimation (HPE) is a long-standing problem of computer vision. Regression-based methods [12, 24, 49, 53, 69, 71] directly regress the 3D pose parameters of a human body model, such as SMPL [40], and learn to overcome the inherent 2D-3D ambiguity of the prediction task from the training data. However, the perfor-mance of regression-based methods degrades when humans are partially occluded, as demonstrated by related work [26] and in our experiments (Figure 1 (c)). Optimization-based methods [4,27,51,77,79] fit a parametric body model to 2D representations, such as keypoint detections [24, 28] or seg-âˆ—Indicates equal contribution.
Figure 1: 3D human pose estimation under occlusion. Per-formance of regression-based methods [22] degrades un-der occlusion (c). Traditional optimization-based methods can be robust occlusion, but they suffer from the 2D-3D ambiguity in monocular 3D HPE (d). Our generative ap-proach resolves the 2D-3D ambiguity through analysis-by-synthesis in a 3D-aware feature space (e). mentation maps [49, 53, 81], in an iterative manner. They are relatively robust to occlusion but perform worse than regression-based methods in 3D HPE particularly because they suffer from the 2D-3D ambiguity (Figure 1(d)), even when regularized with strong 3D priors [51], because the manually designed 2D features lack 3D information.
Recently, generative models have been shown to be suc-cessful with improved robustness to occlusion in object recognition [31] and rigid object pose estimation [73] for certain object categories. The idea is to formulate vision tasks as inverse graphics or analysis-by-synthesis [25, 80]
- searching for the parameters in a generative model (e.g. computer graphics models) that best explain the observed image while an outlier process can be introduced to ex-plain occluded regions. However, performing analysis-by-synthesis in RGB pixel space is challenging due to the lack of both good generative models and efficient algorithms to inverse them. Instead, they perform approximate analysis-by-synthesis in deep feature space. However, the generative models used are 2D-based or simple cuboid-like 3D struc-tures with features invariant to the 3D viewpoint, making 1
them less suitable for 3D HPE. body parts, to resolve the 2D-3D ambiguity.
In this work, we propose a 3D-aware Neural Body
Fitting (3DNBF) framework that enables feature-level analysis-by-synthesis for 3D HPE, which is highly robust to occlusion (Figure 1(e)). Specifically, we propose a novel generative model of deep network features for human body, named Neural Body Volumes (NBV). NBV is an explicit volume-based parametric body representation consisting of a set of Gaussian ellipsoidal kernels that emit feature vec-tors. Compared with the popular mesh representation, our volume representation is analytically differentiable, pro-vides smooth gradients, i.e. is efficient to optimize, and rigorously handles self-occlusion [56]. We employ a fac-torized likelihood model for feature maps which is further made robust to partial occlusion by incorporating robust loss functions [18]. To overcome the 2D-3D ambiguity, we impose a distribution on the kernel features conditioned on pose parameters making them pose-dependent.
Unlike optimization-based methods that manually de-sign the feature representation which may lose information, we learn the features from data. In particular, we introduce a contrastive learning framework [2,13,76] to learn features that are invariant to instance-specific details (such as color of the clothes), meanwhile encouraging them to capture lo-cal 3D pose information of the human body parts, i.e. being 3D-aware. The generative model is learned with the fea-ture extractor network iteratively. For more efficient infer-ence, we attach a regression head to the feature extractor to predict the pose and shape parameters from the feature di-rectly. During inference, we initialize NBV with the predic-tion from our regressor head and optimize the human pose by maximizing the likelihood of the target feature map un-der the generative model using gradient-based optimization.
We find this combined approach can resolve common errors of regression-based methods, such as when the pose of par-tially occluded parts is not estimated correctly (Figure 1).
We evaluate 3DNBF on three existing 3D HPE datasets: 3DPW [72], 3DPW-Occ [82] and 3DOH50K [82], and pro-pose a more challenging adversarial evaluation protocol 3DPW-AdvOcc for occlusion robustness. Our experimen-tal results show that 3DNBF outperforms state-of-the-art (SOTA) regression-based methods as well as optimization-based approaches by a large margin under occlusion while maintaining SOTA performance on non-occluded data. In summary, our main contributions are: 1. We propose 3DNBF - an approximate analysis-by-synthesis approach for 3D HPE at feature level with a volume-based neural generative model NBV for hu-man body with pose-dependent kernel features. 2. We introduce a contrastive learning framework to train
NBV with a feature extractor such that the feature ac-tivations capture the local 3D-pose information of the 3. We demonstrate on four datasets that 3DNBF outper-forms SOTA regression-based and optimization-based methods, particularly when under occlusion. 2.