Abstract
We present ShapeScaffolder, a structure-based neural network for generating colored 3D shapes based on text input. The approach, similar to providing scaffolds as in-ternal structural supports and adding more details to them, aims to capture finer text-shape connections and improve the quality of generated shapes. Traditional text-to-shape methods often generate 3D shapes as a whole. However, humans tend to understand both shape and text as being structure-based. For example, a table is interpreted as be-ing composed of legs, a seat, and a back; similarly, texts possess inherent linguistic structures that can be analyzed as dependency graphs, depicting the relationships between entities within the text. We believe structure-aware shape generation can bring finer text-shape connections and im-prove shape generation quality. However, the lack of ex-plicit shape structure and the high freedom of text structure make cross-modality learning challenging. To address these challenges, we first build the structured shape implicit fields in an unsupervised manner. We then propose the part-level attention mechanism between shape parts and textual graph nodes to align the two modalities at the structural level. Fi-nally, we employ a shape refiner to add further detail to the predicted structure, yielding the final results. Extensive experimentation demonstrates that our approaches outper-form state-of-the-art methods in terms of both shape fidelity and shape-text matching. Our methods also allow for part-level manipulation and improved part-level completeness. 1.

Introduction
The advance of 3D representation learning and gener-ative models has sparked increasing interest in 3D shape generation. However, text-guided shape generation remains a challenging task. Many current approaches generate the 3D shape as a whole when no part information is utilized, while others treat text as a simple collection of words in or-der to provide finer guidance. Both shape and text, however, possess inherent internal structures that can be leveraged to
Figure 1. Text to shape generation with structure awareness. Raw description generates the initial coarse shape with structures. Fur-ther correspondence is built between shape parts and text graph nodes for fine-grained refinement. improve the alignment between the two modalities.
Humans are born with a sense of physical understanding of the world [3]. Studies have shown that the human vi-sual system perceives objects as hierarchical arrangements of parts [4], comprising high-level structural properties and low-level details. In addition, humans use language to de-scribe objects, including their appearance, structure, and functions. It has been discovered that language, shaped by the human brain over time, has evolved to have hierarchi-cal linguistic structures in order to convey more complex meanings [10]. This suggests that structure-based reason-ing is present in both the visual and language modalities.
While this is intuitive and effortless for humans, it is a chal-lenge for intelligent algorithms to understand the structural connection between these two modalities.
In this research, we aim to augment shape generation from text with an awareness of structure in both shape and language modalities. This would allow for shape genera-tion to be guided not only by high-level descriptions, such as a sentence but also refined with part-level guidance from semantic text entities. This process is similar to how hu-mans create visual artworks: sketching an idea’s gist and then progressively refining the details. However, there are
several challenges to overcome. One challenge is that the shape structures are unknown unless annotated segmenta-tion labels are provided. Even with annotation, where the process is time-consuming and labor-intensive, the defini-tion of “parts” in shapes is subjective and ambiguous at multiple levels. Another challenge is that text descriptions of shapes are diverse and complex, making it difficult to op-timize learning. In addition, for colored shapes, the align-ment between structure and color representation must also be taken into consideration.
To address the challenges above, we propose a two-stage approach. First, we leverage an unsupervised hierarchical shape structure given part hierarchy is a prevalent and effec-tive approach for representing shape structures, as demon-strated in previous research [22, 28]. To achieve this, we introduce a decomposition model to progressively decom-pose the shape into parts at multiple levels of granularity, from coarse to fine, such that each level can reconstruct the entire shape. Additionally, we learn color reconstruction at the part level. Fig. 1 illustrates the process. While the struc-tures and parts identified in the first stage hold significance within the shape domain, they do not have a corresponding relationship with the text. In the second step, we establish a connection between the shape structure and the text struc-ture. We utilize linguistic dependency graphs, which can be used to represent the structural elements present in the text, as attention signals to form the structure-level connec-tion. Through these two steps, we are able to improve the generation results at the part level by building upon the es-tablished structure.
In our experimentation on the ShapeNet dataset [7], we have demonstrated the efficacy of utilizing a structure-aware representation in improving the correspondence be-tween text and shape. As a result of the part-aware refine-ment, we observe a significant improvement in the qual-ity of generated shapes, particularly in terms of their con-stituent parts. Additionally, our approach attains state-of-the-art results regarding several commonly used met-rics such as Intersection over Union (IOU), Accuracy, and
Inception Score (IS). Furthermore, through further explo-ration of the latent shape structure space, it is demonstrated that our method has the capability of generating previously unseen shapes.
The main contributions of this work are: (1) An unsuper-vised hierarchical decoder for building shape structural im-plicit field. (2) A structure-aware text-to-shape generation method that improves part-level correspondence and refine-ment. (3) Comprehensive experiments that demonstrate the effectiveness of our method. 2.