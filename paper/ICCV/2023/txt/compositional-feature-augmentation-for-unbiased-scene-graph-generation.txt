Abstract
Scene Graph Generation (SGG) aims to detect all the vi-sual relation triplets <sub, pred, obj> in a given image.
With the emergence of various advanced techniques for bet-ter utilizing both the intrinsic and extrinsic information in each relation triplet, SGG has achieved great progress over the recent years. However, due to the ubiquitous long-tailed predicate distributions, today’s SGG models are still easily biased to the head predicates. Currently, the most prevalent debiasing solutions for SGG are re-balancing methods, e.g., changing the distributions of original training samples. In this paper, we argue that all existing re-balancing strategies fail to increase the diversity of the relation triplet features of each predicate, which is critical for robust SGG. To this end, we propose a novel Compositional Feature Augmenta-tion (CFA) strategy, which is the ﬁrst unbiased SGG work to mitigate the bias issue from the perspective of increas-ing the diversity of triplet features. Speciﬁcally, we ﬁrst de-compose each relation triplet feature into two components: intrinsic feature and extrinsic feature, which correspond to the intrinsic characteristics and extrinsic contexts of a rela-tion triplet, respectively. Then, we design two different fea-ture augmentation modules to enrich the feature diversity of original relation triplets by replacing or mixing up either their intrinsic or extrinsic features from other samples. Due to its model-agnostic nature, CFA can be seamlessly incor-porated into various SGG frameworks. Extensive ablations have shown that CFA achieves a new state-of-the-art per-formance on the trade-off between different metrics. 1.

Introduction
As one of the fundamental comprehensive visual scene understanding tasks, Scene Graph Generation (SGG) has attracted unprecedented interest from our community and has made great progress in recent years [29, 47, 44, 2, 4, 35, 24, 26, 21, 43, 23, 32]. Speciﬁcally, SGG aims to trans-† Corresponding author. Work was done when Lin Li visited HKUST. o f n
I c i s n i r t n
I o f n
I c i s n i r t x
E wave hand pole surfboard
Entity Prediction on holding
Predicate Prediction pole surfboard
Entity Prediction on holding
Predicate Prediction
Triplet Feature of laying on
Triplet Feature of on
Enhanced Triplet Feature
Original Decision Boundary
New Decision Boundary laying on laying on on on (a) (b)
Re-balancing
CFA
Figure 1: (a) The intrinsic and extrinsic information for
SGG. The entity prediction is for the green box, and the predicate prediction is for the relation between the red and green boxes. (b) Illustration of the diversity of feature space and decision boundary between on and laying on be-fore and after using re-balancing and CFA. Each sample de-notes the corresponding visual triplet features. form an image into a visually-grounded graph representa-tion (i.e., scene graph) where each node represents an ob-ject instance with a bounding box and each directed edge represents the corresponding predicate between the two ob-jects. Thus, each scene graph can also be formulated as a set of visual relation triplets (i.e., <sub, pred, obj>).
Since such structural representations can provide strong ex-plainable potentials, SGG has been widely-used in various downstream tasks, such as visual question answering, im-age retrieval, and captioning.
In general, due to the extremely diverse visual appear-ance of different visual relation triplets, recent SGG meth-     
ods all consider both intrinsic and extrinsic information for entity and predicate classiﬁcation [44, 36, 30]. By “intrinsic information”, we mean these intrinsic characteristics of the subjects and objects, such as their visual, semantic, and spa-tial features. For example in Figure 1(a), with the help of these intrinsic features, we can easily infer all possible en-tity categories (e.g., pole or surfboard) and predicate categories (e.g., on or holding) of each triplet. However, sometimes it is still hard to conﬁrm the exact correct pre-dictions with only intrinsic information, especially for tiny objects. Thus, it is also essential to consider other “extrinsic information” in the same image, such as the context features from neighbor objects. As shown in Figure 1(a), after en-coding the features of surrounding objects (e.g., wave and hand), we can easily infer that the categories of the entity and predicate should be surfboard and holding.
Although numerous advanced techniques have been pro-posed to effectively leverage both intrinsic and extrinsic in-formation, today’s SGG methods still fail to predict some informative predicates due to the ubiquitous long-tailed predicate distribution in prevalent SGG datasets [20]. Such a distribution is characterized by few categories with vast samples (head1) and many categories with rare samples (tail). Since the discrepancy of feature diversity and sample size among different categories, the learned decision bound-ary becomes improper (c.f . Figure 1(b)), i.e., their predic-tions are biased towards the head predicates (e.g., on) and they are error-prone for the tail ones (e.g., laying on).
To overcome the bias issue, the most prevalent unbiased
SGG solutions are re-balancing strategies, e.g., sample re-sampling [26, 49] and loss re-weighting [41, 1, 27, 31, 17].
They alleviate the negative impact of long-tailed distribu-tion by increasing samples or loss weights of tail classes.
Then, the decision boundaries are adjusted to reduce the bias introduced by imbalanced distributions. However, we argue that all the existing re-balancing strategies fail to in-crease the diversity of relation triplet features2 of each pred-icate, i.e., they only change the frequencies or contributions of existing relation triplet features (c.f . Figure 1(b)). Since these tail categories are under-represented, it is still hard to infer the complete data distribution, i.e., making it chal-lenging to ﬁnd the optimal direction to adjust the decision boundaries [6, 38]. For example in Figure 1(b), the fea-ture space of laying on is so sparse that the decision boundary can be adjusted within a large range. The perfor-mance of this naive adjustment without “complete” distri-bution is always sensitive to hyperparameters, i.e., exces-sively increasing the sample number or loss weight of tail predicates may cause some head predicate samples to be in-1We directly use “tail”, “body”, and “head” categories to represent the predicate categories in the tail, body, and head parts of the number distri-butions of different predicates in SGG datasets, respectively. 2We use the “relation triplet feature” to represent the combination of both intrinsic and extrinsic features of each visual relation triplet. (cid:19)(cid:10)(cid:13)(cid:5)(cid:14)(cid:19) (cid:15)(cid:10)(cid:11)(cid:11)(cid:14)(cid:19) (cid:11)(cid:2)(cid:12)(cid:15) (cid:3)(cid:6)(cid:9)(cid:10)(cid:13)(cid:5) (cid:17)(cid:6)(cid:2)(cid:18) (cid:13)(cid:6)(cid:2)(cid:16) (cid:9)(cid:8) (cid:14)(cid:7) (cid:4)(cid:9)(cid:2)(cid:10)(cid:16) (cid:3)(cid:6)(cid:5) (cid:19)(cid:10)(cid:13)(cid:5)(cid:14)(cid:19) (cid:17)(cid:6)(cid:2)(cid:18) (cid:15)(cid:10)(cid:11)(cid:11)(cid:14)(cid:19) (cid:11)(cid:2)(cid:12)(cid:15) (cid:13)(cid:6)(cid:2)(cid:16) (cid:7)(cid:2)(cid:11)(cid:6)(cid:8)(cid:5)(cid:1)(cid:9)(cid:8) (cid:3)(cid:6)(cid:9)(cid:10)(cid:13)(cid:5) (cid:14)(cid:7) (cid:4)(cid:9)(cid:2)(cid:10)(cid:16) (cid:3)(cid:6)(cid:5) (cid:2)(cid:11)(cid:3)(cid:1)(cid:7)(cid:18)(cid:17)(cid:15)(cid:13)(cid:14)(cid:16)(cid:13)(cid:12)(cid:4)(cid:6)(cid:8)(cid:5) (cid:4)(cid:9)(cid:5) (cid:11)(cid:2)(cid:20)(cid:10)(cid:13)(cid:8)(cid:1)(cid:14)(cid:13) (cid:3)(cid:6)(cid:5) (cid:3)(cid:2)(cid:10) (cid:11)(cid:2)(cid:20)(cid:10)(cid:13)(cid:8)(cid:1)(cid:14)(cid:13) (cid:3)(cid:6)(cid:5) (cid:2)(cid:10)(cid:3)(cid:1)(cid:9)(cid:14)(cid:17)(cid:15)(cid:13)(cid:14)(cid:16)(cid:13)(cid:12)(cid:4)(cid:6)(cid:8)(cid:5)
Figure 2: (a) Intrinsic-CFA: Replacing the entity feature of tail predicate triplet dog-laying on-bed from dog to cat to enhance the intrinsic feature. (b) Extrnisc-CFA:
Mixing up the feature of tail predicate triplet pillow-laying on-bed into the context of pillow-on-bed to enhance the extrinsic feature. correctly predicted as tail classes (right solid line), and vice versa (left solid line).
In this paper, we propose a novel Compositional Fea-ture Augmentation (CFA) strategy for unbiased SGG, which tries to solve the bias issue by enhancing the diversity of re-lation triplet features, especially for tail predicates. Speciﬁ-cally, CFA consists of two components: an intrinsic feature augmentation (intrinsic-CFA) and an extrinsic feature aug-mentation (extrinsic-CFA), which enhance the intrinsic and extrinsic features2, respectively. As shown in Figure 1(b), by increasing the feature diversity of the tail predicates (e.g., laying on), SGG models can easily learn the proper de-cision boundaries (vs. re-balancing strategies).
For intrinsic-CFA, we replace the entity features (e.g., subject or object) of a tail predicate triplet with other “suit-able” entity features. To determine the suitable entity cate-gories for the augmentation, we propose a new hierarchical clustering method to ﬁnd the correlations between differ-ent entity categories, and then we regard the entity features from the same cluster are suitable. Speciﬁcally, we calcu-late the category correlation by pattern, context, and seman-tic similarities. For example in Figure 2(a), the entity cat-egories cat and dog are in the same cluster, i.e., we can augment the intrinsic feature by replacing the dog entity feature with a cat entity feature. For extrinsic-CFA, we take advantage of the context or interactions of other triplets (i.e., context triplets) and enhance the features of tail pred-icate triplets by these context triplets. Speciﬁcally, given a context triplet randomly selected from an image, we ﬁrst se-lect a reasonable tail predicate triplet as the target by limit-ing the categories and relative position of two objects. Then, to minimize the impact on the prediction of other triplets in the original image and make use of the extrinsic features of
the context triplet, we use a mixup operation to fuse the fea-tures of targeted tail predicate triplet into the context triplet.
For example in Figure 2(b), triplet pillow-laying on-bed is mixed up into the image of pillow-on-bed.
We evaluate CFA on two most prevalent and challenging
SGG datasets: Visual Genome (VG) [20] and GQA [16].
Since CFA is a model-agnostic debiasing strategy, it can be seamlessly incorporated into various SGG architectures3 and consistently improve their performance. Unsurpris-ingly, CFA can achieve a new state-of-the-art performance on the trade-off between different metrics. Extensive abla-tions and results on multiple SGG tasks and backbones have shown the generalization ability and effectiveness of CFA.
In summary, we make three contributions in this paper: 1. We reveal the issue of existing re-balancing methods, i.e., the lack of triplet feature diversity of tail categories. To this end, we are the ﬁrst to tackle unbiased SGG from the perspective of increasing the diversity of triplet features. 2. We propose the model-agnostic CFA for unbiased SGG, which is an efﬁcient and novel compositional learning framework that spans the feature space of the tail cate-gories by two independent plug-and-play modules. 3. Extensive results show the effectiveness of CFA, i.e., it achieves a new SOTA performance on SGG benchmarks. 2.