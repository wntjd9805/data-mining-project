Abstract
Denoising diffusion models hold great promise for gen-erating diverse and realistic human motions. However, ex-isting motion diffusion models largely disregard the laws of physics in the diffusion process and often generate physically-implausible motions with pronounced artifacts such as floating, foot sliding, and ground penetration. This seriously impacts the quality of generated motions and lim-its their real-world application. To address this issue, we present a novel physics-guided motion diffusion model (PhysDiff), which incorporates physical constraints into the diffusion process. Specifically, we propose a physics-based motion projection module that uses motion imitation in a physics simulator to project the denoised motion of a diffusion step to a physically-plausible motion. The pro-jected motion is further used in the next diffusion step to guide the denoising diffusion process. Intuitively, the use of physics in our model iteratively pulls the motion toward a physically-plausible space, which cannot be achieved by simple post-processing. Experiments on large-scale human motion datasets show that our approach achieves state-of-the-art motion quality and improves physical plausibility drastically (>78% for all datasets). 1.

Introduction
Deep learning-based human motion generation is an im-portant task with numerous applications in animation, gam-ing, and virtual reality. In common settings such as text-to-motion synthesis, we need to learn a conditional generative model that can capture the multi-modal distribution of hu-man motions. The distribution can be highly complex due to the high variety of human motions and the intricate in-teraction between human body parts. Denoising diffusion models [73, 25, 74] are a class of generative models that are especially suited for this task due to their strong ability to model complex distributions, which has been demonstrated extensively in the image generation domain [67, 62, 66, 13].
These models have exhibited strong mode coverage often indicated by high test likelihood [75, 33, 79]. They also
(Left) Performing one physics-based projection step
Figure 2. (post-processing) at the end yields unnatural motion since the mo-tion is too physically-implausible to correct. (Right) Our approach solves this issue by iteratively applying physics and diffusion. have better training stability compared to generative adver-sarial networks (GANs [19]) and better sample quality com-pared to variational autoencoders (VAEs [34]) and normal-izing flows [72, 79, 78, 4]. Motivated by this, recent works have proposed motion diffusion models [77, 92] which sig-nificantly outperform standard deep generative models in motion generation performance.
However, existing motion diffusion models overlook one essential aspect of human motion – the underlying laws of physics. Even though diffusion models have a supe-rior ability to model the distribution of human motion, they still have no explicit mechanisms to enforce physical con-straints or model the complex dynamics induced by forces and contact. As a result, the motions they generate often contain pronounced artifacts such as floating, foot sliding, and ground penetration. This severely hinders many real-world applications such as animation and virtual reality, where humans are highly sensitive to the slightest clue of physical inaccuracy [63, 27]. In light of this, a critical prob-lem we need to address is making human motion diffusion models physics-aware.
To tackle this problem, we propose a novel physics-guided motion diffusion model (PhysDiff) that instills the laws of physics into the denoising diffusion process. Specif-ically, PhysDiff leverages a physics-based motion projec-tion module (details provided later) that projects an input motion to a physically-plausible space. During the diffusion process, we use the motion projection module to project the denoised motion of a diffusion step into a physically-plausible motion. This new motion is further used in the next diffusion step to guide the denoising diffusion process.
Note that it may be tempting to only add the physics-based projection at the end of the diffusion process, i.e., using physics as a post-processing step. However, this can pro-duce unnatural motions since the final denoised kinematic motion from diffusion may be too physically-implausible to be corrected by physics (see Fig. 2 for an example) and the motion may be pushed away from the data distribution. In-stead, we need to embed the projection in the diffusion pro-cess and apply physics and diffusion iteratively to keep the motion close to the data distribution while moving toward the physically-plausible space (see Sec. 4.4).
The physics-based motion projection module serves the vital role of enforcing physical constraints in PhysDiff, which is achieved by motion imitation in a physics simu-lator. Specifically, using large-scale motion capture data, we train a motion imitation policy that can control a char-acter agent in the simulator to mimic a vast range of input motions. The resulting simulated motion enforces physi-cal constraints and removes artifacts such as floating, foot sliding, and ground penetration. Once trained, the motion imitation policy can be used to mimic the denoised motion of a diffusion step to output a physically-plausible motion.
We evaluate our model, PhysDiff, on two tasks: text-to-motion generation and action-to-motion generation. Since our approach is agnostic to the specific instantiation of the denoising network used for diffusion, we test two state-of-the-art (SOTA) motion diffusion models (MDM [77] and
MotionDiffuse [92]) as our model’s denoiser. For text-to-motion generation, our model outperforms SOTA mo-tion diffusion models significantly on the large-scale Hu-manML3D [22] benchmark, reducing physical errors by more than 86% while also improving the motion quality by more than 20% as measured by the Frechet inception distance (FID). For action-to-motion generation, our model again improves the physics error metric by more than 78% on HumanAct12 [23] and 94% on UESTC [29] while also achieving competitive FID scores.
We further perform extensive experiments to investigate various schedules of the physics-based projection, i.e., at which diffusion timesteps to perform the projection.
In-terestingly, we observe a trade-off between physical plau-sibility and motion quality when varying the number of physics-based projection steps. Specifically, while more projection steps always lead to better physical plausibil-ity, the motion quality increases before a certain number of steps and decreases after that, i.e., the resulting motion satisfies the physical constraints but still may look unnatu-ral. This observation guides us to use a balanced number of physics-based projection steps where both high physi-cal plausibility and motion quality is achieved. We also find that adding the physics-based projection to late diffu-sion steps performs better than early steps. We hypothesize that motions from early diffusion steps may tend toward the mean motion of the training data and the physics-based pro-jection could push the motion further away from the data distribution, thus hampering the diffusion process. Finally, we also show that our approach outperforms physics-based post-processing (single or multiple steps) in motion quality and physical plausibility significantly.
Our contributions are summarized as follows:
• We present a novel physics-guided motion diffusion model that generates physically-plausible motions by instilling the laws of physics into the diffusion process.
Its plug-and-play nature makes it flexible to use with
different kinematic diffusion models.
• We propose to leverage human motion imitation in a physics simulator as a motion projection module to en-force physical constraints.
• Our model achieves SOTA performance in motion quality and drastically improves physical plausibility on large-scale motion datasets. Our extensive analy-sis also provides insights such as schedules and trade-offs, and we demonstrate significant improvements over physics-based post-processing. 2.