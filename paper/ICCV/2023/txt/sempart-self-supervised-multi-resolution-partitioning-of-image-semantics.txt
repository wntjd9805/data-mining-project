Abstract 1.

Introduction
Accurately determining salient regions of an image is challenging when labeled data is scarce. DINO-based self-supervised approaches have recently leveraged meaningful image semantics captured by patch-wise features for lo-cating foreground objects. Recent methods have also in-corporated intuitive priors and demonstrated value in un-supervised methods for object partitioning. In this paper, we propose SEMPART, which jointly infers coarse and ﬁne bi-partitions over an image’s DINO-based semantic graph.
Furthermore, SEMPART preserves ﬁne boundary details us-ing graph-driven regularization and successfully distills the coarse mask semantics into the ﬁne mask. Our salient ob-ject detection and single object localization ﬁndings suggest that SEMPART produces high-quality masks rapidly without additional post-processing and beneﬁts from co-optimizing the coarse and ﬁne branches.
Identifying salient regions of an image prone to holding visual attention remains a long-standing fuzzy problem [59] relying signiﬁcantly on carefully annotated data [51, 5, 54].
Recently self-supervised (SSL) mechanisms based on large-scale pre-trained backbones [9, 6, 22], such as DINO [7], have demonstrated increased capability in segmenting im-ages [21, 30] and extracting objects in the foreground [41, 39, 54, 4, 42].
The unavailability of labels is limiting to inferring high-quality object masks. However, many recent methods have demonstrated that incorporating well-informed priors into the partitioning process is signiﬁcantly beneﬁcial to ﬁnding saliency regions and foreground objects in an unsupervised setting [36, 41, 46, 47, 31, 54, 4, 39].
Different forms of statistical independence of the fore-ground have driven recent approaches, with the most recent state-of-the-art focusing on movability [4] of the salient ob-pervised image segmentation, which has further translated to recent ﬁndings in [39, 54, 40].
[20, 19] discuss the beneﬁt of learning to predict spec-tral decomposition for a graph and employ graph neural networks in a reinforcement learning setup for predictively performing the normalized cut. More recently, [43] lever-aged normalized cut for regularizing a convolutional net-work driven by partial cross entropy loss in a weakly super-vised setting and demonstrated signiﬁcant performance im-provement. More broadly, spectral partitioning of semantic graphs [39, 54, 30, 1] has become an emerging underlying theme for detecting salient regions.
Contributions. In this paper, we propose SEMPART, which builds on ideas from [54, 12, 11] for producing high-quality foreground masks in an SSL setting. SEMPART learns a transformer-based encoder that reﬁnes the patchwise DINO features for inferring a relaxation of graph cut that mini-mizes the expected normalized cut loss [20] over a semantic graph informed by DINO feature correspondences.
As seen in [54, 41, 7], the foreground masks obtained abandon the ﬁne boundary details from processing features at a low resolution. Unlike [39, 54, 41], which perform successive reﬁnement of the coarse masks post-inference,
SEMPART implements a convolutional ﬁne branch that pro-cesses and supplements the transformed DINO features with RGB features at progressively increasing resolutions for producing original resolution ﬁne masks. Motivated by
[12, 11], SEMPART treats the coarse mask as the source and the image as a guide for inferring high-quality ﬁne masks (see Figure 1, Table 1) regularized by weighted neighborhood-based graph total variation [48].
In summary, our contributions are as follows:
• We propose a novel strategy for co-optimizing coarse and ﬁne masks, that decouples image partitioning into semantic separation of rich self-supervised features and high-frequency detailing, respectively.
• SEMPART outperforms recent state-of-the-art methods in saliency detection by 3.7% in max Fβ and 2.7% in
IoU on average and emits high-quality bounding boxes for locating objects.
• SEMPART produces high-quality ﬁne masks rapidly by eliminating time-consuming post-inference itera-tive reﬁnement and saving 200ms on average. 2.