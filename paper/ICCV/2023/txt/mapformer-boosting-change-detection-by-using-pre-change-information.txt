Abstract
Change detection in remote sensing imagery is essential for a variety of applications such as urban planning, disas-ter management, and climate research. However, existing methods for identifying semantically changed areas over-look the availability of semantic information in the form of existing maps describing features of the earth’s surface.
In this paper, we leverage this information for change de-tection in bi-temporal images. We show that the simple integration of the additional information via concatena-tion of latent representations suffices to significantly out-perform state-of-the-art change detection methods. Mo-tivated by this observation, we propose the new task of
Conditional Change Detection, where pre-change seman-tic information is used as input next to bi-temporal im-ages. To fully exploit the extra information, we propose
MapFormer, a novel architecture based on a multi-modal feature fusion module that allows for feature processing conditioned on the available semantic information. We further employ a supervised, cross-modal contrastive loss to guide the learning of visual representations. Our ap-proach outperforms existing change detection methods by an absolute 11.7% and 18.4% in terms of binary change
IoU on DynamicEarthNet and HRSCD, respectively. Fur-thermore, we demonstrate the robustness of our approach to the quality of the pre-change semantic information and the absence pre-change imagery. The code is available at https://github.com/mxbh/mapformer. 1.

Introduction
Earth observation data has become increasingly avail-able in recent years, providing valuable insights into vari-ous fields such as climate research, disaster management, and urban planning.
In the course of this, enormous ef-forts have been made towards creating rich semantic maps of the earth. For instance, OpenStreetMap provides vast amounts of data containing manual annotations around the globe. In addition, deep learning techniques are nowadays used to produce semantic map data at a large scale, e.g., [23]
Figure 1: Advantage of our approach over existing change detection methods (represented by ChangeFormer [2] here) on a sample of DynamicEarthNet [26]. Employing seman-tic pre-change information allows to extract better features and improves change detection quality. generated building footprints for the entire African conti-nent. As a result, we live in a world that has been exten-sively mapped. However, we live in a constantly changing world where the earth’s surface is subject to various influ-ences. These influences can be natural, e.g., earthquakes, extreme weather, floods, wildfires, and changes in vege-tation, but also directly caused by humans, e.g., building construction, deforestation, and agriculture. In fact, the im-pact of civilization on our planet has never been higher than in recent years, with drastic consequences for ecosystems and wildlife [9, 24]. Therefore, monitoring changes in the earth’s surface with up-to-date earth observation data is be-coming increasingly important.
In technical terms, this challenge is addressed by the task of change detection, where bi-temporal images are compared in order to segment pixels that have semanti-cally changed. Today, deep-learning-based methods for change detection achieve state-of-the-art performance [14, 15]. However, the research community so far mostly ig-nored the fact that existing semantic information like maps may be employed for change detection. To the best of our knowledge, semantic map information has been considered an additional input next to bi-temporal images for detect-ing change only for the specific task of updating road net-works [3]. Although this approach is only possible if se-mantic information for the area of interest is available, we argue that maps are available for most parts of the world to-day. Alternatively, pre-trained neural networks can be used to generate a map containing the features of interest. Fur-thermore, when updating a map, a pre-change version of the map has to be available in the first place.
In this paper, we tap into this direction in a general way and establish the novel task of Conditional Change Detec-tion (see Figure 1). We demonstrate that the usage of se-mantic information in form of a pixelwise map has a strong impact on change detection by showing that a simple base-line (concatenating bi-temporal image features and map fea-tures) is already able to outperform state-of-the-art change detection methods, which do not use semantic pre-change information. Furthermore, we propose MapFormer, a novel architecture to fully exploit the additional information. At its core, we integrate a newly designed multi-modal fea-ture fusion module based on the idea that the pre-change semantics should dynamically influence the processing of hidden features. Additionally, we apply a supervised con-trastive loss on the learned image features, guiding the im-age encoder during training and further improving the per-formance. We also show that our approach can be applied without bi-temporal imagery, detecting change by only pro-cessing a pre-change map and current imagery. We call this task Cross-modal Change Detection. We conduct exper-iments on the publicly available and challenging datasets
DynamicEarthNet [26] and HRSCD [8].
To sum up, our main contributions are as follows:
• We investigate the novel tasks of Conditional Change
Detection and Cross-modal Change Detection and in-troduce simple baselines that outperform state-of-the-art change detection methods.
• We propose MapFormer, a novel architecture consist-ing of a multi-modal feature fusion module and a su-pervised contrastive loss, allowing us to effectively merge image features and semantic information.
• We conduct detailed experiments and ablations demonstrating our approach’s consistent performance gains, robustness, and practicability. 2.