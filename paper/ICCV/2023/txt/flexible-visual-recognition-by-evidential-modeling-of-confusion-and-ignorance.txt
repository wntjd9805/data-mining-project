Abstract
In real-world scenarios, typical visual recognition sys-tems could fail under two major causes, i.e., the misclas-sification between known classes and the excusable misbe-havior on unknown-class images. To tackle these deficien-cies, flexible visual recognition should dynamically predict multiple classes when they are unconfident between choices and reject making predictions when the input is entirely out of the training distribution. Two challenges emerge along with this novel task. First, prediction uncertainty should be separately quantified as confusion depicting inter-class uncertainties and ignorance identifying out-of-distribution samples. Second, both confusion and ignorance should be comparable between samples to enable effective decision-making.
In this paper, we propose to model these two sources of uncertainty explicitly with the theory of Subjec-tive Logic. Regarding recognition as an evidence-collecting process, confusion is then defined as conflicting evidence, while ignorance is the absence of evidence. By predicting
Dirichlet concentration parameters for singletons, compre-hensive subjective opinions, including confusion and igno-rance, could be achieved via further evidence combinations.
Through a series of experiments on synthetic data analysis, visual recognition, and open-set detection, we demonstrate the effectiveness of our methods in quantifying two sources of uncertainties and dealing with flexible recognition. 1.

Introduction
When employing visual classifiers in open-world condi-tions, obtaining reliable uncertainty estimations could sig-nificantly benefit downstream tasks, including autonomous driving [1, 13, 37], medical diagnosis [36, 49], and embod-ied intelligence [40, 35]. Recent uncertainty quantification techniques [53, 15, 28, 32, 34, 33, 9, 43] have achieved no-table progress toward this goal by saying “I do not know” when the testing distributions differ from the training. How-ever, besides directly giving no prediction, a more flexible
Figure 1: Classification of the proposed approach on im-ages interpolated from a known-known-unknown triplet. Ig-norance reflects the lack of evidence, whereas confusion is caused by conflicting evidence, i.e., evidence that fails to provide discrimination between specific classes. A flexible visual recognition system could provide combined predic-tions when having large confusion and reject making pre-dictions for unknown-class samples. Note the mixup im-ages are for illustrative purposes and are not a requisite in our training. and informative visual recognition system could also give combined predictions when possible, implying the correct answer is one of its predictions but uncertain. Naturally, the capability of rejecting or providing unspecific predictions demands separately measuring different sources of uncer-tainties, i.e., ignorance and confusion, if seen from the Sub-jective Logic [21] perspective. Furthermore, to enable flexi-ble recognition, both uncertainties should possess the virtue of comparability between samples and in-sample additivity.
In evidential deep learning, the training of a recogni-tion model could be regarded as an evidence-collecting pro-cess [21, 44]. Unlike ignorance describing a total lack of ev-idence, confusion is defined as conflicting evidence, which mandates the existence of multiple hypotheses in the frame of discernment. In other words, we cannot assess confusion for a single-class classification problem. The mass of confu-sion between two classes then reflects shared features that contribute to both classes while not discriminative. Like-wise, confusion exists for all combinations of classes larger than two. Unlike typical visual classifiers that only predict
a single output, flexible predictions could be obtained if we could combine singleton belief derived from class-exclusive evidence with their inter-class confusion.
With great potential for explicitly estimating confusion and ignorance, this area is still under-explored for deep vi-sual classifiers. Recent methods regard uncertainties as the degree of mismatch between training and testing distribu-tions, which comprise but do not distinguish between con-fusion and ignorance. Deep Bayesian models, including dropout [15, 22] and ensemble-based approximations [28, 51, 4], require multiple forwards to estimate the posterior predictive distribution. Evidential models [44, 1, 11, 5] pre-dict parameters of the posterior of class distribution directly.
However, these models regard uncertainty as a whole term covering both confusion and ignorance, making it infeasible to perform flexible visual recognition further.
Distinct from existing uncertainty quantification meth-ods, the proposed method models confusion and ignorance for each sample separately, which provides valuable infor-mation to facilitate various visual tasks, including flexible visual recognition. An illustrative example with the predic-tion of our method is shown in Fig. 1. Under the theory of
Subjective Logic [6, 21], confusion is defined as the shared evidence contributing to multiple categories while not dis-criminative between them, while ignorance is completely missing evidence.
The contribution of this paper could be summarized as follow: (1) The proposed method could explicitly predict two sources of uncertainties, i.e., confusion and ignorance, simultaneously for each sample. (2) The solution to confu-sion and ignorance is based on standard architectures, and the training does not rely on external information. (3) The effectiveness of the proposed method is extensively val-idated across different experiments, including studies on synthetic data, visual recognitions, and open-set detections. 2.