Abstract
With autonomous industries on the rise, domain adapta-tion of the visual perception stack is an important research direction due to the cost savings promise. Much prior art was dedicated to domain-adaptive semantic segmentation in the synthetic-to-real context. Despite being a crucial out-put of the perception stack, panoptic segmentation has been largely overlooked by the domain adaptation community.
Therefore, we revisit well-performing domain adaptation strategies from other fields, adapt them to panoptic segmen-tation, and show that they can effectively enhance panoptic domain adaptation. Further, we study the panoptic network design and propose a novel architecture (EDAPS) designed explicitly for domain-adaptive panoptic segmentation.
It uses a shared, domain-robust transformer encoder to facil-itate the joint adaptation of semantic and instance features, but task-specific decoders tailored for the specific require-ments of both domain-adaptive semantic and instance seg-mentation. As a result, the performance gap seen in chal-lenging panoptic benchmarks is substantially narrowed.
EDAPS significantly improves the state-of-the-art perfor-mance for panoptic segmentation UDA by a large margin of 20% on SYNTHIA-to-Cityscapes and even 72% on the more challenging SYNTHIA-to-Mapillary Vistas. The implemen-tation is available at https://github.com/susaha/edaps. 1.

Introduction
Panoptic segmentation [30] of images is a core computer vision task that jointly solves two related problems – se-mantic segmentation and instance segmentation. With the rise of robotics and emerging autonomous driving markets, efficient visual perception stacks are in high demand. How-ever, large-scale supervised learning of panoptic segmen-tation [7, 30, 29, 49, 70, 44] is prohibitively expensive as it requires dense annotations for both semantics and instances, which require time-consuming manual labeling.
*These authors contributed equally to this work.
Figure 1: EDAPS is an architecture and a collection of recipes, designed specifically for Domain-Adaptive Panop-tic Segmentation.
It demonstrates a significant improve-ment over the prior art on the challenging synthetic-to-real benchmarks. As shown above, it is better than CVRN [25] on SYNTHIA → Cityscapes by 9 mPQ.
A promising alternative to circumvent this issue is to learn from abundantly available photo-realistic synthetic images [51, 50] as their ground truth annotations can be au-tomatically generated by the rendering engine. However, often models trained on synthetic data (source domain) fail to generalize well on the real data (target domain) due to differences in data distribution, known as the domain gap.
A common remedy to this problem is to minimize the do-main gap using Unsupervised Domain Adaptation (UDA).
This field is actively studied for image classification [38, 14, 39, 54, 48], object detection [4, 53, 71, 6, 33], and se-mantic segmentation [19, 61, 18, 32, 52, 60, 20, 21, 22].
However, UDA for panoptic segmentation is often over-looked and there are only two works, namely CVRN [25] and UniDAPS [75], which address this problem from the synthetic-to-real point of view. Compared to the related semantic segmentation UDA, these approaches achieve only subpar performance. Specifically, the relative perfor-mance of the best UDA and fully-supervised learning ap-proaches to panoptic segmentation (64% in UniDAPS [75])
is much smaller than that of semantic segmentation (88% in
DAFormer [20]).
To understand the root cause of the identified perfor-mance gap, we revisit the progress of UDA in semantic segmentation, lift the well-performing UDA strategies to panoptic segmentation, and show that they can effectively enhance panoptic segmentation UDA.
Further, we revisit the panoptic network design and con-duct a study of principal architecture designs for panoptic segmentation with respect to their UDA capabilities. We show that previous UDA methods took sub-optimal design choices. While separating the networks for both tasks pre-vents the network from jointly adapting task-shared fea-tures from the source to the target domain (see Fig. 2 a), a shared encoder-decoder cannot accommodate the differ-ent needs (such as task-specific knowledge or architecture design) when adapting both tasks (see Fig. 2 b).
To address these problems, we propose EDAPS, a net-work architecture that is particularly designed for domain-adaptive panoptic segmentation.
It uses a shared trans-former [63] encoder to facilitate the joint adaptation of se-mantic and instance features, but task-specific decoders tai-lored for the specific requirements of both domain-adaptive semantic segmentation and domain-adaptive instance seg-mentation (see Fig. 2 c). Specifically, separate decoders can learn task-specific parameters, mitigating the issue of con-flicting gradients [74], and their architectures can be inde-pendently chosen to best suit semantic or instance segmen-tation. Even though this design was used in the supervised setting, we are the first to identify its strong potential specif-ically for panoptic UDA.
Utilizing the enhanced panoptic UDA and the enhanced domain-adaptive panoptic network design, EDAPS shows significant performance gains over the prior works on a number of standard perception benchmarks (Fig. 1).
EDAPS improves the state-of-the-art mPQ from 33.0 to 41.2 on On SYNTHIA → Cityscapes and from 21.3 to 36.6 on SYNTHIA → Mapillary Vistas. EDAPS trains seman-tic segmentation and instance segmentation tasks together using a joint training optimization. Therefore, EDAPS can be trained end-to-end in a single stage and the training only requires 21 hours on a single RTX 2080 Ti GPU, which im-proves its applicability for the community.
The main contribution of EDAPS is the novel combina-tion of network components and UDA strategies on a sys-tem level, which results in a major relative gain in the state-of-the-art panoptic segmentation UDA performance of 20% on SYNTHIA-to-Cityscapes and even 72% on the more challenging SYNTHIA-to-Mapillary Vistas. In par-ticular, we carefully study various principal panoptic archi-tectures for their UDA capability and identify a network design that is particularly suited for panoptic UDA. It im-proves the UDA performance over strong baselines, while
Figure 2: Overview of network architectures employed in prior panoptic UDA works and the proposed architecture.
CVRN [25] (a) does not share parameters between panoptic branches, whereas UniDAPS [75] (b) resorts to the opposite extreme and shares everything. With EDAPS (c), we pro-pose to share the encoder but to use task-specific decoders, which facilitates panoptic domain adaptation. being parameter-efficient and fast at inference. Further, this is the first paper that lifts recent UDA techniques to panoptic segmentation and systematically studies their effectiveness for panoptic UDA. 2.