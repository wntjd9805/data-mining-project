Abstract
Anomaly segmentation is a critical task for driving ap-plications, and it is approached traditionally as a per-pixel classification problem. However, reasoning individ-ually about each pixel without considering their contex-tual semantics results in high uncertainty around the ob-jects’ boundaries and numerous false positives. We pro-pose a paradigm change by shifting from a per-pixel classi-fication to a mask classification. Our mask-based method,
Mask2Anomaly, demonstrates the feasibility of integrating an anomaly detection method in a mask-classification ar-chitecture. Mask2Anomaly includes several technical nov-elties that are designed to improve the detection of anoma-lies in masks: i) a global masked attention module to focus individually on the foreground and background regions; ii) a mask contrastive learning that maximizes the margin be-tween an anomaly and known classes; and iii) a mask re-finement solution to reduce false positives. Mask2Anomaly achieves new state-of-the-art results across a range of benchmarks, both in the per-pixel and component-level evaluations. In particular, Mask2Anomaly reduces the av-erage false positives rate by 60% w.r.t. the previous state-of-the-art. 1.

Introduction
Figure 1: Per-pixel vs per-mask Anomaly Segmenta-tion: Dense Hybrid [22], the state-of-the-art method for
AS based on per-pixel classification can detect the anoma-lies, but it produces many false positives. Anomaly seg-mentation can be cast as a mask classification problem, but naively using MSP [25] on top of Mask2Former [12] does not produce good results. Our Mask2Anomaly ex-ploits mask-transformers properties to refine the classifi-cation of anomalies, drastically reducing false positives. fpixel and fmask denotes per-pixel, and per-mask architec-ture. Anomalies in the output image are represented in red.
Semantic segmentation [14, 41, 50, 48, 42] plays a piv-otal role in self-driving cars, being used to obtain a detailed understanding of the surroundings of a vehicle. Gener-ally, semantic segmentation models are trained to recognize a pre-defined set of semantic classes (e.g. car, pedestrian, road, etc.); however, in real-world applications, they may encounter objects not belonging to such categories (e.g. ani-mals or cargo dropped on the road). Therefore, it is essential for these models to identify objects in a scene that are not present during training i.e. anomalies, both to avoid poten-tial dangers and to enable continual learning [37, 8, 17, 7] and open-world solutions [6].
Anomaly segmentation (AS) [3, 47, 20, 27] addresses this problem, i.e. it aims to segment objects from classes that were absent during training. Existing AS methods are built upon the idea of individually classifying the pixels and assigning to each of them an anomaly score. This score may be given by a pixel-level discriminative method [1, 27, 22, 43], by estimating the uncertainty of the individual pixel predictions [39], or by comparing the per-pixel discrepancy between the original image and a synthetic image generated from the semantic predictions [34, 45, 46]. However, rea-soning on the pixels individually produces noisy anomaly scores, thus leading to a high number of false positives and poorly localized anomalies (see Fig. 1).
In this paper, we address this problem by casting AS as a mask classification task rather than a pixel classifica-tion. This idea stems from the recent advances in mask-transformer architectures [12, 13], which demonstrated that it is possible to achieve remarkable performance across var-ious segmentation tasks by classifying masks, rather than pixels. We hypothesize that mask-transformer architectures are better suited to detect anomalies than per-pixel archi-tectures [11, 26], because masks encourage objectness and thus can capture anomalies as whole entities, leading to more congruent anomaly scores and reduced false positives.
To enable the segmentation of anomalies at the mask level, we revisit the Maximum Softmax Probability (MSP) [25], a classic method used in per-pixel AS, and apply it to the masks produced by a mask-transformer model. However, the effectiveness of such an approach hinges on the model’s capability to output masks that capture well anomalies and we found that naively using MSP on top of the best mask-transformer architecture [12] does not yield good results (see Fig. 1). Hence, we propose several technical contri-butions to improve the capability of mask-transformer ar-chitectures to capture anomalies and reject false positives in driving scenes (see Fig. 1): the architectural level, we propose a global masked-attention mechanism that allows the model to focus on both the foreground objects and on the back-ground while retaining the efficiency of the original masked-attention [12].
• At
• At the training level, we have developed a mask con-trastive learning framework that utilizes outlier masks from additional out-of-distribution data to maximize the separation between anomalies and known classes.
• At the inference level, we propose a mask-based re-finement solution that reduces false positives by filter-ing masks based on the panoptic principle [28] that dis-tinguishes between “things” and “stuff”.
We integrate these contributions on top of the mask archi-tecture [12] and term this solution Mask2Anomaly. To the best of our knowledge, Mask2Anomaly is the first demonstration of an AS method that detects anomalies at the mask level. We tested Mask2Anomaly on stan-dard anomaly segmentation benchmarks for road scenes (Road Anomaly [34], Fishyscapes [4], Segment Me If You
Can [9]), achieving the best results among all AS methods by a significant margin. In particular, Mask2Anomaly re-duces on average the false positives rate by more than half w.r.t. the previous state-of-the-art. Code and pre-trained models will be made publicly available upon acceptance. 2.