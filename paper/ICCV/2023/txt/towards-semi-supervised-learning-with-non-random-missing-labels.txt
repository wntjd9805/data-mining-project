Abstract
Semi-supervised learning (SSL) tackles the label missing problem by enabling the effective usage of unlabeled data.
While existing SSL methods focus on the traditional setting, a practical and challenging scenario called label Missing
Not At Random (MNAR) is usually ignored. In MNAR, the labeled and unlabeled data fall into different class distribu-tions resulting in biased label imputation, which deteriorates the performance of SSL models. In this work, class tran-sition tracking based Pseudo-Rectifying Guidance (PRG) is devised for MNAR. We explore the class-level guidance information obtained by the Markov random walk, which is modeled on a dynamically created graph built over the class tracking matrix. PRG unifies the historical informa-tion of class distribution and class transitions caused by the pseudo-rectifying procedure to maintain the model’s un-biased enthusiasm towards assigning pseudo-labels to all classes, so as the quality of pseudo-labels on both popular classes and rare classes in MNAR could be improved. Fi-nally, we show the superior performance of PRG across a variety of MNAR scenarios, outperforming the latest SSL approaches combining bias removal solutions by a large margin. Code and model weights are available at https:
//github.com/NJUyued/PRG4SSL-MNAR. 1.

Introduction
Semi-supervised learning (SSL), which is in the ascen-dant, yields promising results in solving the shortage of large-scale labeled data [4, 29]. Current prevailing SSL methods
[2, 27, 38, 7, 11] utilize the model trained on the labeled data to impute pseudo-labels for the unlabeled data, thereby boosting the model performance. Although these methods have made exciting advances in SSL, they only work well in the conventional setting, i.e., the labeled and unlabeled data fall into the same (balanced) class distribution. Once this set-ting is not guaranteed, the gap between the class distributions of the labeled and unlabeled data will lead to a significant accuracy drop of the pseudo-labels, resulting in strong con-firmation bias [1] which ultimately corrupts the performance
*Corresponding author: syh@nju.edu.cn.
Figure 1: An example of the MNAR scenarios on CIFAR-10 (see Sec. 4 for details). The class distribution of total data is balanced whereas labeled data is unevenly distributed across classes. For better illustration, the y-axis has different scaling for labeled (blue) and unlabeled data (green). of SSL models. [14] originally terms the scenario of the labeled and unlabeled data belonging to mismatched class distributions as label Missing Not At Random (MNAR) and proposes an unified doubly robust framework to train an unbiased SSL model in MNAR. During the same period,
[39, 6] also independently explored the issue of mismatched distributions. For example, a typical MNAR scenario is shown in Fig. 1, in which the popular classes of labeled data cause the model to ignore the rare classes, increasingly magnifying the bias in label imputation on the unlabeled data. It is worth noting that although some recent SSL meth-ods [15, 32] are proposed to deal with the class imbalance, they are still built upon the assumption of the matched class distributions between the labeled and unlabeled data, and their performance inevitably declines in MNAR.
MNAR is a more realistic scenario than the conventional
SSL setting. In the practical labeling process, labeling all classes uniformly is usually not affordable because some classes are more difficult to recognize [26, 23]. Mean-while, most automatic data collection methods also have difficulty in ensuring that the collected labeled data is bal-anced [22, 14]. In a nutshell, MNAR is almost inevitable in
SSL. In MNAR, the tricky troublemaker is the mismatched class distributions between the labeled and unlabeled data.
Training under MNAR, the model increasingly favors some classes, seriously affecting the pseudo-rectifying procedure.
Pseudo-rectifying is defined as the change of the label assign-ment decision made by the SSL model for the same sample according to the knowledge learned at each new epoch. This
(a) (b) (c)
Figure 2: Results of FixMatch [27] in MNAR and the conventional SSL setting (i.e., balanced labeled and unlabeled data).
The models are trained on CIFAR-10 with WRN-28-2 backbone [37]. (a) and (b): Class-wise pseudo-label error rate. (c):
Confusion matrix of pseudo-labels. In (b) and (c), experiments are conducted with the setting of Fig. 1, whereas in (a) with the conventional setting. The label amount used in (a) is the same as that in (b) and (c). process may cause class transition, i.e., given a sample, its class prediction at the current epoch is different from that at the last epoch. In the self-training process of the SSL model driven by the labeled data, the model is expected to gradually rectify the pseudo-labels mispredicted for the unlabeled data in last epoches. With pseudo-rectifying, the model trapped in the learning of extremely noisy pseudo-labels will be rescued due to its ability to correct these labels.
Unfortunately, the pseudo-rectifying ability of the SSL model could be severely perturbed in MNAR. Taking the setting in Fig. 1 for example, the model’s “confidence” in predicting the pseudo-labels into the labeled rare classes is attenuated by over-learning the samples of the labeled pop-ular classes. Thus, the model fails to rectify those pseudo-labels mispredicted as the popular classes to the correct rare classes (even if the class distribution is balanced in unlabeled data). As shown in Fig. 2b, compared with Fix-Match [27] trained in the conventional setting (Fig. 2a),
FixMatch trained in MNAR (Fig. 1) significantly deterio-rates its pseudo-rectifying ability. Even after many iterations, the error rates of the pseudo-labels predicted for labeled rare classes remain high. This phenomenon hints the necessity to provide additional guidance to the rectifying procedure to ad-dress MNAR. Meanwhile, as observed in Fig. 2c, we notice that the mispredicted pseudo-labels for each class are often concentrated in a few classes, rather than scattered across all other classes. Intuitively, a class can easily be confused with the classes similar to it. For example, as shown in Fig. 2c, the “automobile” samples are massively mispredicted as the most similar class: “truck”. Inspired by this, we argue that it is feasible to guide pseudo-rectifying from the class level, i.e., pointing out the latent direction of class transition based on its current class prediction only. For instance, given a sam-ple classified as “truck”, the model could be given a chance to classify it as “automobile” sometimes, and vice versa. No-tably, our approach does not require predefined semantically similar classes. We believe that two classes are conceptually similar only if they are frequently misclassified to each other by the classifier. In this sense, we develop a novel definition of the similarity of two classes, which is directly determined by model’s output. Even if there are no semantically similar classes, as long as the model makes incorrect prediction dur-ing the training, this still leads to class transitions which has seldom been investigated before. Our intuition could be re-garded as perturbations on some confident class predictions to preserve the pseudo-rectifying ability of the model. Such a strategy does not rely on the matched class distributions assumption and therefore is amenable to MNAR.
Given the motivations above, we propose class transi-tion tracking based Pseudo-Rectifying Guidance (PRG) to address SSL in MNAR, which is shown in Fig. 3. Our main idea can be presented as dynamically tracking the class transitions caused by pseudo-rectifying procedures at pre-vious epoch to provide the class-level guidance for pseudo-rectifying at next epoch. We argue that every class transition of each pseudo-label could become the cure for the dete-rioration of the pseudo-rectifying ability of the traditional
SSL methods in MNAR. A graph is first built on the class tracking matrix recording each pseudo-label’s class transi-tions occurring in pseudo-rectifying procedure. Then we propose to model the class transition by the Markov random walk, which brings information about the difference in the propensity to rectify pseudo-labels of one class into various other classes. Specifically, we guide the class transitions of each pseudo-label during the rectifying process according to the transition probability corresponding to the current class prediction. The probability is obtained by the transition ma-trix of Markov random walk, and it is also rescaled based on the class distribution of assigned pseudo-labels to better provide class-level guidance. PRG recalls classes that are easily overlooked but appear in class transition history. They are deemed as similar to the ground-truth and have more chance to be assigned rather than simply letting the model assign the classes it favors without hesitation. In sum, PRG perturbs some confident class predictions to preserve the pseudo-rectifying ability of the model with the usage of tran-Figure 3: Overview of PRG. Class tracking matrix C is obtained by tracking the class transitions of pseudo-labels (e.g., px1 for sample x1) between epoch e and epoch e + 1 caused by pseudo-rectifying procedure (Eq. (5)). The Markov random walk defined by transition matrix H (each row Hi represents the transition probability vector corresponding to class i) is modeled on the graph constructed over C. Generally, given a pseudo-label, e.g., px2 for sample x2, class- and batch-rescaled H (i.e.,
H′) is utilized to provide the class-level pseudo-rectifying guidance for px2 according to its class prediction ˆp = arg max(px2) (Eqs. (6)∼(7)). Finally, the rescaled pseudo-label ˜px2 is used for the training. sition history and class distribution information, which could help improve the quality of pseudo-labels suffered from bi-ased label imputation caused by MNAR. We evaluate PRG on several widely-used SSL benchmarks, demonstrating its effectiveness in coping with SSL in MNAR.
• What is the novelty and contribution? Towards address-ing SSL in MNAR, we propose transition tracking based
Pseudo-Rectifying Guidance (PRG) to mitigate the ad-verse effects of mismatched distributions via combining information from the class transition history. We propose that the pseudo-rectifying guidance can be carried out from the class level, by modeling the class transition of the pseudo-label as a Markov random walk on the graph.
• How about the performance improvement? Our solu-tion is computation and memory friendly without introduc-ing additional network components. PRG achieves supe-rior performance in MNAR under various protocols and, e.g., it outperforms CADR [14], a newly-proposed method for addressing MNAR, by up to 15.11% on CIFAR-10 and 15.21% on mini-ImageNet in accuracy. 2.