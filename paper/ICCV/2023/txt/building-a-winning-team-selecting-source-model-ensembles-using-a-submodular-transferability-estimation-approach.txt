Abstract
Estimating the transferability of publicly available pre-trained models to a target task has assumed an important place for transfer learning tasks in recent years. Exist-ing efforts propose metrics that allow a user to choose one model from a pool of pre-trained models without having to fine-tune each model individually and identify one explicitly.
With the growth in the number of available pre-trained mod-els and the popularity of model ensembles, it also becomes essential to study the transferability of multiple-source mod-els for a given target task. The few existing efforts study transferability in such multi-source ensemble settings using just the outputs of the classification layer and neglect pos-sible domain or task mismatch. Moreover, they overlook the most important factor while selecting the source mod-els, viz., the cohesiveness factor between them, which can impact the performance and confidence in the prediction of the ensemble. To address these gaps, we propose a novel
Optimal tranSport-based suBmOdular tRaNsferability met-ric (OSBORN) to estimate the transferability of an ensem-ble of models to a downstream task. OSBORN collectively accounts for image domain difference, task difference, and cohesiveness of models in the ensemble to provide reliable estimates of transferability. We gauge the performance of
OSBORN on both image classification and semantic seg-mentation tasks. Our setup includes 28 source datasets, 11 target datasets, 5 model architectures, and 2 pre-training methods. We benchmark our method against current state-of-the-art metrics MS-LEEP and E-LEEP, and outperform them consistently using the proposed approach. 1.

Introduction
In computer vision, transfer learning is a go-to strategy to train Deep Neural Networks (DNNs) on newer domains and datasets across tasks such as image classification [30, 21], image segmentation [44, 60] and object detection [16, 42].
This widespread usage is due to the easy availability of a large pool of open-sourced pre-trained models (trained on large-scale datasets such as ImageNet [31, 3]), which, when fine-tuned, achieve faster convergence and better per-formance than training from scratch. However, every time a user wants to employ transfer learning, the question that has increasingly grown relevant with an increased number of source models is: “Which combination of dataset and architecture should I pick to fine-tune to achieve the best performance on my target dataset?”. To solve this, we need a tool that helps us choose a source or set of source models, which require minimal fine-tuning and achieves maximal performance.
Transferability estimation (TE) metrics have been pro-posed in recent years to tackle this problem [48, 36, 58, 47, 39]. With these metrics, a particular source model can be se-lected without conducting expensive fine-tuning of all avail-able source models on the target training set. Most efforts in this direction are, however limited by their capability of selecting only a single source model, thus restricting their use in an ensemble learning setting. There has been only one work so far [1] which extends an existing single-source transferability estimation method [36] to an ensemble set-ting. While this work showed promising results, it did not consider the similarity between source and target datasets in the latent representation space, or account for the rela-tionships between individual models in the ensemble. This problem space remains nascent at this time, necessitating more efforts to estimate transferability reliably in different conditions.
Ensemble models have been popular for a few decades now in machine learning [14, 7, 51]. Ensemble models are known to increase task accuracy, decrease overall predictive variance and increase robustness against out-of-distribution
Figure 1. Illustration of the objective and problem setting of our proposed metric. the Spider-Man movie (2002), hence the emoji.) (Trivia: OSBORN is also the main antagonist in data samples [15]. Recent efforts have shown the usefulness of ensembles of pre-trained models [52], especially consid-ering the widespread availability of pre-trained models in the community [41]. The problem of estimating transfer-ability for a model ensemble from a large source model pool becomes even more relevant in this context.
In this work, we introduce a novel transferability esti-mation metric specifically designed for ensemble selection called Optimal Transport-based Submodular Transferability metric (OSBORN). As stated earlier, a recent effort in this direction [1] showed promising results for such a score, but focused on individual model’s performance (via the classi-fier’s outputs) and did not consider the feature (latent rep-resentation) space mismatch, or how these models interact with each other in the ensemble. To address this, OSBORN measures the latent space mismatch between the source and the target datasets (domain difference) in addition to the mismatch in the classifier’s outputs (task difference). Also, to account for the interaction between models in the ensem-ble, we introduce a novel model cohesion term, which cap-tures the mutual cooperation between models towards form-ing an ensemble. Cohesion is required to ensure that indi-vidual models in an ensemble are in agreement with each other in terms of predictions (and not voting out each other).
Thus, in this work, we propose a domain, task and cohesion-aware transferability estimator for ensemble selection from a source pool of multiple models.
Beyond bringing the abovementioned factors into trans-ferability estimation for ensembles, we show that the pro-posed score can be viewed as a submodular set function [4].
This allows us to follow a greedy maximization strategy, which is known to provide a high-quality solution for the problem based on well-known theoretical guarantees [34].
We thus select cohesive and closely related models for a par-ticular target dataset. To evaluate our metric, we conduct extensive experiments using 28 source datasets, 11 target datasets, and 5 model architectures. In downstream tasks, we consider fully-supervised pre-training-based image clas-sification, self-supervised pre-training-based image classifi-cation, semantic segmentation as well as domain adaptation.
Table 1 presents an overview of our experiment breadth, as compared to other recent efforts on this problem. In particu-lar, to the best of our knowledge, we are the first to perform transferability estimation of ensembles for image classifica-tion and domain adaptation tasks.
To summarize, we make the following contributions: (1)
We introduce a novel transferability estimation metric for ensemble selection that considers domain similarity, task similarity and inter-model cohesion in its design; (2) We show that viewing the proposed metric as a submodular set function allows us to use a simple greedy maximiza-tion strategy to select a source model ensemble for a given target dataset; (3) We study the performance of our met-ric across a wide range of downstream tasks and model pools;(4) We evaluate the reliability of our metric using different correlation metrics in our studies, and also carry out additional analysis and ablation studies to study its use-fulness. We outperform earlier methods by a margin of 58.62%, 66.06%, and 96.36% in terms of Pearson Correla-tion Coefficient (PCC), Kendall τ (KT) [25] and Weighted
Kendall τ (WKT) [50] for the image classification task. 1 2.