Abstract
Seed area generation is usually the starting point of weakly supervised semantic segmentation (WSSS). Comput-ing the Class Activation Map (CAM) from a multi-label classification network is the de facto paradigm for seed area generation, but CAMs generated from Convolutional
Neural Networks (CNNs) and Transformers are prone to be under- and over-activated, respectively, which makes the strategies to refine CAMs for CNNs usually inappropriate for Transformers, and vice versa. In this paper, we propose a Unified optimization paradigm for Seed Area GEneration (USAGE) for both types of networks, in which the objec-tive function to be optimized consists of two terms: One is a generation loss, which controls the shape of seed ar-eas by a temperature parameter following a deterministic principle for different types of networks; The other is a reg-ularization loss, which ensures the consistency between the seed areas that are generated by self-adaptive network ad-justment from different views, to overturn false activation in seed areas. Experimental results show that USAGE con-sistently improves seed area generation for both CNNs and
Transformers by large margins, e.g., outperforming state-of-the-art methods by a mIoU of 4.1% on PASCAL VOC.
Moreover, based on the USAGE-generated seed areas on
Transformers, we achieve state-of-the-art WSSS results on both PASCAL VOC and MS COCO. 1.

Introduction
The goal of weakly supervised semantic segmentation (WSSS) is to train a semantic segmentation model under weak supervision, i.e., image-level labels, so that the burden of relying on pixel-level labels is largely reduced. Among various types of weak supervision, we focus on studying (cid:66)Corresponding Author.
Image
Feature Map
Seed Area Generation (b) USAGE (a) CAM
. t a v i t c a
. r e d n
U
. t a v i t c a
. r e v
O
CNN
Trans
Figure 1. Seed area visualization. (a) CAM-based seed areas gen-erated from a CNN (ResNet38 [48]) and a Transformer (DeiT-S [42]). (b) USAGE-based seed areas (ours) generated from the
CNN and the Transformer.
WSSS under image-level labels [12, 20, 17, 18, 10, 37], which is considered one of the most challenging scenarios and has attracted increasing attention.
Seed area generation is usually the first step of WSSS, which produces an initial pseudo mask based on the image-level labels on each training image. This is often achieved by first optimizing a mapping between the dense feature map of the image and the image-level labels (i.e., training a deep neural network for multi-class classification), and then inferring the contribution of each location on the fea-ture map to the classification result w.r.t. each specific class.
The Class Activation Map (CAM) [28] has been the de facto paradigm for seed area generation. However, it is known that, based on the CAM, seed areas generated from Convolutional Neural Networks (CNNs) are prone to
In addition, when the backbone be under-activated [3]. is changed from CNNs to Transformers (which have been adopted in WSSS very recently and report state-of-the-art performance [51]), the CAM is inversely prone to re-sult in over-activated seed areas [35], as shown in Fig. 1.
Consequently, it is difficult to design a seed area gen-eration paradigm that is appropriate for both CNN-based
and Transformer-based WSSS. For example, the widely used CAM refinement strategy-“seed and expand” [20] has achieved success in CNN-based WSSS, but it is easy to de-teriorate the over-activation of seed areas in Transformer-based WSSS.
In this paper, we propose a Unified optimization paradigm for Seed Area GEneration (USAGE) for both types of networks, in which the objective function to be op-timized consists of two terms: a generation loss and a regu-larization loss. The generation loss measures the fitness be-tween the contribution of a seed area and the classification result and controls the shape of the seed area by introducing a temperature parameter based on a deterministic principle.
This means how to set the temperature parameter for differ-ent types of networks is deterministic, i.e., set a small/large temperature for Transformers/CNNs to sharpen/smooth the seed area.
The regularization loss is designed to ensure the consis-tency between the seed areas that are generated from dif-ferent views, which can overturn false activation in seed areas. Previous WSSS methods [45, 19] mainly adopt ge-ometric transformations to generate different views to in-stantiate such a regularization loss, which has achieved a great success on CNN-based WSSS, but this view gener-ation strategy might not be appropriate for Transformer-based WSSS, since Transformers are insensitive to various geometric transformations [34]. Besides, geometric trans-formations, e.g., multi-crop, may generate views that only contain the background region, which may make the consis-tency optimization process ill-posed. To alleviate the issue, we propose a self-adaptive network adjustment strategy to generate different views. In particular, we obtain different views by making adjustments to the architecture of the clas-sification network, where the magnitudes of adjustments are determined by the learning status of the network. This strat-egy is shown to be effective for both types of networks in rectifying erroneously activated seed areas.
Extensive experiments show that USAGE can signifi-cantly improve the quality of the seed areas for both CNNs and Transformers. Furthermore, under the paradigm of
USAGE, our instantiation for transformers, i.e., applying sharpening and regularization on the seed areas, leads to new state-of-the-art WSSS results on both the PASCAL
VOC [11] and MS COCO [29] dataset. 2.