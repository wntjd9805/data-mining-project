Abstract 1.

Introduction 3D GAN inversion aims to achieve high reconstruction
ﬁdelity and reasonable 3D geometry simultaneously from a single image input. However, existing 3D GAN inversion methods rely on time-consuming optimization for each in-dividual case. In this work, we introduce a novel encoder-based inversion framework based on EG3D, one of the most widely-used 3D GAN models. We leverage the inherent properties of EG3D’s latent space to design a discrimina-tor and a background depth regularization. This enables us to train a geometry-aware encoder capable of converting the input image into corresponding latent code. Addition-ally, we explore the feature space of EG3D and develop an adaptive reﬁnement stage that improves the representation ability of features in EG3D to enhance the recovery of ﬁne-grained textural details. Finally, we propose an occlusion-aware fusion operation to prevent distortion in unobserved regions. Our method achieves impressive results compa-rable to optimization-based methods while operating up to 500 times faster. Our framework is well-suited for applica-tions such as semantic editing.
∗ Equal contributions; † Corresponding author.
Recent advances in 3D-aware generative adversarial net-works (GAN) (e.g. [5, 6, 14, 32]) have integrated neural ra-diance ﬁelds (NeRF) [27] into style-based generation, re-sulting in remarkable success in generating highly realistic 3D portraits. Similar to 2D GAN inversion techniques, 3D
GAN inversion also projects images into the latent space of pre-trained 3D GAN models. However, in addition to pursuing faithful image reconstruction and preserving ﬁned details, 3D GAN inversion also aims for accurate 3D geom-etry, which is critical for generating realistic and consistent multi-view images. This ability to ensure the correctness of 3D geometry is a crucial advantage of 3D GAN inversion over its 2D counterpart.
Some optimization-based methods, such as [21, 47, 49],
ﬁrst invert the image to a latent code to obtain a coarse 3D shape. They then synthesize pseudo-multi-view images with this shape using a warping process. These pseudo im-ages are used as supervision to optimize the parameters of the 3D GAN for more precise 3D geometry and better de-tail preservation. While these iterative optimization-based pipelines can prevent shape collapse and produce accurate                            
results, the optimization process needs to be performed for each individual case, which is time-consuming and imprac-tical for many applications.
See Fig. 1 for some examples of inversion and editing of human portraits and cat faces obtained by our method. Our contribution can be summarised as following:
Several encoder-based methods [22, 23] leverage a pre-trained 3D GAN to generate proxy data by randomly sam-pling latent codes and camera poses. They then employ these paired proxy data to train an encoder in a self-supervised fashion and further reﬁne features in 3D GAN.
These encoder-based techniques offer higher efﬁciency but lower high-ﬁdelity reconstruction ability. Moreover, due to a domain gap between the paired proxy data and real im-ages, the encoder may invert the in-the-wild images to un-suitable latent codes. To address this issue, we study the properties of the latent space in 3D GAN and develop a geometry-aware encoder that predicts the latent code in-corporating these properties. Furthermore, since the latent code can not preserve details of input images well, we ex-plore the characteristics of feature space in 3D GAN to help our method improve the performance in reconstruct-ing the original appearance. The latent and feature spaces are widely discussed in 2D GAN inversion [11, 24, 42].
This paper presents a novel encoder-based method for inverting 3D images generated by EG3D [5], a well-known and high-quality 3D GAN. Our approach is simple yet ef-fective and is based on the discovery of a speciﬁc latent space within EG3D, which we call the canonical latent space Wc. We ﬁnd that latent codes belonging to this space can produce human faces with superior 3D shape and texture quality following two principles. Firstly, the input pose before the mapping network of EG3D must be a static canonical pose throughout the generation process.
Secondly, the depth of the background should fall within a
ﬁxed range. Based on this, we propose using an encoder to invert the image into this canonical latent space using a proposed latent code discriminator and depth regulariza-tion. Although our encoder produces a suitable latent code that preserves the reasonable 3D shape of the input image, but the code is low dimension, making it challenging to cap-ture texture details. To address this, similar to the 2D GAN inversion [3, 45], we reﬁne the selected features in EG3D based on the residual between the input image and recon-struction image with predicted latent code. Meanwhile, we also ﬁnd there is a canonical feature space Fc in EG3D, so we design an alignment module to project the reﬁned feature to the canonical feature space. Moreover, we intro-duce an occlusion-aware fusion operation to avoid texture and shape distortions in reconstructing invisible regions.
We conduct comprehensive experiments to evaluate the efﬁciency and effectiveness of our method, and the results demonstrate that our method achieves high-quality inver-sion comparable to optimization-based methods and supe-rior to other encoder-based methods. We also demonstrate our approach is effective in 3D-aware editing applications.
• We conduct an exploration on the latent space and fea-ture space of EG3D and discover the presence of a canonical attribute.
• Based on our analysis of the characteristics of the canonical latent space, we propose a geometry-aware encoder by utilizing a canonical latent discriminator and depth regularization.
• We introduce an alignment module based on the canonical feature space and an occlusion-aware method to reﬁne the selected features of the generator and supplement high-quality details.
• The proposed method exhibits competitive perfor-mance with existing methods in human portraits, both qualitatively and quantitatively. Additionally, our method can also generalize to the cat faces and is ef-fective in 3D editing tasks. 2.