Abstract
Recently, 3D object detection with sparse annotations has received great attention. However, current detectors usually perform poorly under very limited annotations. To address this problem, we propose a novel Contrastive In-stance feature mining method, named CoIn. To better identify indistinguishable features learned through limited supervision, we design a Multi-Class contrastive learn-ing module (MCcont) to enhance feature discrimination.
Meanwhile, we propose a feature-level pseudo-label mining framework consisting of an instance feature mining module (InF-Mining) and a Labeled-to-Pseudo contrastive learn-ing module (LPcont). These two modules exploit latent in-stances in feature space to supervise the training of detec-tors with limited annotations. Extensive experiments with
KITTI dataset, Waymo open dataset, and nuScenes dataset show that under limited annotations, our method greatly improves the performance of baseline detectors: Center-Point, Voxel-RCNN, and CasA. Combining CoIn with an iterative training strategy, we propose a CoIn++ pipeline, which requires only 2% annotations in the KITTI dataset to achieve performance comparable to the fully supervised methods. The code is available at https://github. com/xmuqimingxia/CoIn. 1.

Introduction
Recently, 3D object detection, which is becoming in-creasingly important in a variety of vision applications, in-cluding autonomous driving, indoor robots, and virtual re-ality, has received much attention [32, 4, 11, 45, 38, 37, 21, 16, 35, 1]. Popular detectors rely heavily on a large num-ber of high-quality instance-level 3D annotations. How-ever, annotating 3D bounding boxes is time-consuming and labor-intensive, and, therefore, is prohibitive for large-scale datasets.
The development of effective 3D object detectors using only limited annotations has recently received increasing at-*Corresponding author
Figure 1. Comparison of performance with different annotation rates under the KITTI-3D-Car. Green and orange represent
CenterPoint[39] and our proposed CoIn, respectively. tention [17, 14, 27, 20, 42]. However, when annotations are limited, two main challenges hinder the effectiveness of 3D object detection. (1) Indistinguishable Features. With limited annotations, it is often difficult for a model that has insufficient training supervision to differentiate foreground points from back-ground points. Consequently, extracted features of differ-ent objects are often not well clustered (see supplementary materials). We designate such kinds of features as indis-tinguishable features. This issue is a critical bottleneck toward more accurate detection. In 2D vision, contrastive learning-based methods [10, 8] have proven effective in en-hancing discriminability against indistinguishable features.
However, rather than multi-class object classification tasks in common 3D detection problems, contrastive learning is studied mainly for binary classification tasks. (2) Lacking reliable initial pseudo labels. To deal with limited annotations, recent sparsely-/semi-supervised 3D detectors usually adopt instance-level pseudo-label mining methods to mine unlabeled latent instances [14, 29]. These strategies rely on the assumption that initial detectors al-ready generate relatively reliable detections that are used as preliminary pseudo-labels. However, often this is not pos-sible if the annotation is very limited. In such a scenario, initial detectors are often unreliable and in insufficient quan-tity to produce reasonable pseudo-labels. Fig. 1 shows some examples where SOTA detectors, such as CenterPoint [39] hardly provide reliable preliminary pseudo-labels when an-notations are very limited (e.g., 2%).
Recent studies on 3D object detection with lim-ited annotations adopt three general strategies: weakly-supervised, semi-supervised, and sparsely-supervised ap-proaches. Weakly-supervised strategies [20, 17] adopt non-instance-level annotations (e.g., WS3D[17] adopts point-annotation as supervision signal). However, to achieve desirable performance, a certain number of full annota-tions are still required in these methods. Semi-supervised methods [27, 42] select only a part of the scenes for full annotations. Sparsely-supervised methods [14] annotate only some instances in each scene (e.g., [14] annotates one instance per scene and reduces the annotation work-load to about 20%). Although these approaches signifi-cantly reduce annotation workload, applying them to a large training dataset is still labor-intensive. Furthermore, the semi/sparsely-supervised methods require a reliable initial detector to generate pseudo labels. However, if annotations are very limited, initially generated pseudo-labels usually suffer from significant noise. Such low-quality pseudo-labels make it very difficult to support subsequent pro-cesses. We focus here on developing detectors that have further reduced dependence on annotations.
Specifically, our proposed method consists of a Multi-Class contrastive learning module (MCcont), an Instance
Feature Mining module (InF-Mining), and a Labeled-to-Pseudo contrastive learning module (LPcont). MCcont si-multaneously interacts with features from multiple cate-gories. Features of the same category constitute a posi-tive sample space; those of the remaining categories consti-tute a negative sample space thereby helping reduce intra-class distance and increase inter-class distance in the fea-ture space, and improve the discrimination of features for 3D detection. The InF-Mining module mines feature-level pseudo-labels by exploiting the similarity of features of the same category. We decode the spatial position of the 3D ob-ject from the location of the feature-level pseudo-label. By applying the contrastive learning strategy, LPcont selects la-beled instance features as positive samples and limits the redundancy of pseudo-positive samples.
We verified this design through extensive experiments on the well-known KITTI dataset [7] with 2% annotations.
In the moderate level car class, our proposed CoIn signif-icantly improves the baseline detectors CenterPoint [39],
Voxel-RCNN [5], and CasA [31] by 23.27%, 13.5%, and 17.95%, respectively. Besides, when combining CoIn with iterative training, our model requires only 2% annotations to achieve similar detection accuracy with those fully su-pervised methods.
In summary, our contributions are three-fold:
• We propose a Multi- Class contrastive learning module (MCcont), which enhances the discriminability of fea-tures by contrasting the instance features across mul-tiple categories, thereby improving detection perfor-mance.
• We design an end-to-end feature-level pseudo-label mining framework through two new modules: InF-Mining and LPcont. Without requiring repeated man-ual iterations, InF-Mining directly mines unlabeled supervised signals, and LPcont guarantees the correct-ness of pseudo-positive signals.
• Extensive experiments demonstrated the superiority of CoIn, which effectively improves the performance of baseline detectors. Moreover, by using only very limited annotation, CoIn can be effectively combined with self-training-based methods to achieve similar performance to those fully supervised methods. 2.