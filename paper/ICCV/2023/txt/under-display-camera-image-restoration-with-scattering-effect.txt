Abstract
The under-display camera (UDC) provides consumers with a full-screen visual experience without any obstruc-tion due to notches or punched holes. However, the semi-transparent nature of the display inevitably introduces the severe degradation into UDC images. In this work, we ad-dress the UDC image restoration problem with the speciﬁc consideration of the scattering effect caused by the display.
We explicitly model the scattering effect by treating the dis-play as a piece of homogeneous scattering medium. With the physical model of the scattering effect, we improve the image formation pipeline for the image synthesis to con-struct a realistic UDC dataset with ground truths. To sup-press the scattering effect for the eventual UDC image re-covery, a two-branch restoration network is designed. More speciﬁcally, the scattering branch leverages global model-ing capabilities of the channel-wise self-attention to esti-mate parameters of the scattering effect from degraded im-ages. While the image branch exploits the local represen-tation advantage of CNN to recover clear scenes, implicitly guided by the scattering branch. Extensive experiments are conducted on both real-world and synthesized data, demon-strating the superiority of the proposed method over the state-of-the-art UDC restoration techniques. The source code and dataset are available at https://github. com/NamecantbeNULL/SRUDC. 1.

Introduction
The adoption of under-display cameras (UDCs) has gained the popularity as a solution to avoid the inconve-nience of notches and punched holes on the screen. This design meets the growing demand for full-screen hand-held devices and improves consumers’ visual experience. How-ever, the semi-transparent nature of the display covered on
†Corresponding author. (a) UDC image (b) DISCNet [6] (c) DAGF [31] (d) UDCUnet [18] (e) BNUDC [11] (f) Ours
Figure 1. An example of the UDC image restoration on a real-scene image. (a) Degraded UDC image, (b-e) Outputs of state-of-the-art methods w/o considering the scattering effect, (f) Our result, capable of removing the haziness and contrast distortion, while restoring ﬁne details. (Zoom in for a better view.) the camera inevitably introduces various types of the degra-dation, e.g., contrast distortion, blurring, haziness, noise, and diffraction artifacts around light sources, into the cap-tured UDC images. To mitigate these issues, rapidly evolv-ing UDC image restoration methods [42, 6, 14, 11, 8, 21, 43, 12, 4, 31, 7, 5] in recent years are dedicated to recov-ering degraded images. Most of these methods focus on the degradation of high-frequency components, e.g., blur-ring, noise, and diffraction artifacts, while simply modeling the deterioration of low-frequency components as the pixel intensity attenuation. Whereas, the scattering effect of the display, which can result in the degradation such as con-trast distortion and haziness, has been neglected in previous
UDC restoration methods. Such a negligence may signiﬁ-cantly limit the restoration performance and generalization of existing methods on real-scene images.
Essentially, the scattering effect is a common phe-nomenon in UDC imaging systems [26]. When incident light enters the display, it travels through multiple stacked layers, e.g., the cathode, the substrate, etc., before reach-ing the camera sensor. During this process, collisions with small particles within these layers alter the propagation di-rection of some photons. Consequently, the total energy of the incident radiance is suppressed and part of the light is converted into scattered light, which generates contrast distortion and haziness. These types of degradation due to the scattering effect not only affect the visual quality of the captured UDC images, but also may cause the high-level vi-sion systems to fail when UDC images are fed as the input.
Surprisingly, as far as we know, the scattering effect has never been explicitly addressed in the UDC image restora-tion task. Due to the scattering effect, on one hand, there is a gap between the real-world and synthetic UDC images gen-erated by the existing data synthesis pipeline. On the other hand, the restoration methods necessitate special designs for the scattering-induced degradation in UDC images. These two reasons motivate us to take into account the scattering effect for better restoring the captured UDC images.
In this work, we model the UDC scattering effect by decomposing the irradiance received by the camera into transmitted and scattered components and calculating them separately. Based on the proposed UDC scattering model, we enhance the existing image formation pipeline (IFP) to generate realistic UDC images with paired ground truths.
We show that compared to the existing IFP, our enhanced method produces synthetic UDC images that are closer to real-captured ones. To restore UDC images with the scat-tering effect, we propose a two-branch deep network con-sisting of a scattering branch and an image branch. The scattering branch estimates the parameters of the scatter-ing effect from degraded images, while the image branch recovers clear scenes guided by the scattering branch. In the scattering branch, we propose transposed self-attention blocks (TSABs) to leverage the global modeling capability
[37, 32] of the channel-wise self-attention (CSA). In the im-age branch, we use Convolutional Neural Network (CNN) as the backbone to exploit its local representation advantage
[29, 3]. To effectively combine the information from both branches, we devise a feature fusion module, which adap-tively modulates the deep features with the global informa-tion from the scattering branch. Fig. 1 presents an example of UDC image restoration on a real-scene image.
In summary, our contributions are as follows:
• We propose a new UDC imaging model by explicitly considering the scattering effect, which causes unex-pected haziness and contrast distortion. The image for-mation pipeline is then enhanced, generating more re-alistic UDC synthetic images.
• Guided by the proposed UDC imaging model with the scattering effect, we specially design a dual-branch deep framework, which leverages global modeling ca-pabilities of CSA and the local representation advan-tage of CNN, to restore the UDC image.
• Extensive experiments demonstrate signiﬁcant perfor-mance gains on both real-world and synthetic data.
Compared with state-of-the-art methods, the visual quality of resulting images is dramatically improved. 2.