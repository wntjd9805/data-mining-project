Abstract
The problem of predicting driver attention from the driv-ing perspective is gaining increasing research focus due to its remarkable significance for autonomous driving and as-sisted driving systems. The driving experience is extremely important for safe driving, a skilled driver is able to effort-lessly predict oncoming danger (before it becomes salient) based on the driving experience and quickly pay attention to the corresponding zones. However, the nonobjective driv-ing experience is difficult to model, so a mechanism simu-lating the driver experience accumulation procedure is ab-sent in existing methods, and the current methods usually follow the technique line of saliency prediction methods to predict driver attention. In this paper, we propose a Feed-Back Loop Network (FBLNet), which attempts to model the driving experience accumulation procedure. By over-and-over iterations, FBLNet generates the incremental knowl-edge that carries rich historically-accumulative and long-term temporal information. The incremental knowledge in our model is like the driving experience of humans. Under the guidance of the incremental knowledge, our model fuses the CNN feature and Transformer feature that are extracted from the input image to predict driver attention. Our model exhibits a solid advantage over existing methods, achieving an outstanding performance improvement on two driver at-tention benchmark datasets. 1.

Introduction
Accurately predicting where a driver should look is ex-tremely important for assisted driving [14], accident avoid-ance [19], and driverless driving [37]. According to the road traffic injuries report 1 of WHO in 2022, nearly 1.3 million
Zhixiong Nan∗ is the corresponding author.
This work was supported by the National Natural Science Foundation of China under Grant (62006180 and 62106026) and CCF-AFSG Research
Fund (RF20220009, 02160026050171). 1https://www.who.int/zh/news-room/fact-sheets/detail/road-traffic-injuries
Figure 1: The comparison of the mainstream existing archi-tectures (i.e., (a) CNN based encoder-decoder architecture and (b) CNN- Transformer based encoder-decoder architec-ture) and our architecture (i.e., (c) FBLNet). people die in traffic accidents every year, and a high propor-tion of death result from driver attention distraction. Many accidents could be avoided if a system is able to accurately predict where a driver should look and timely send the at-tention distraction warning. Therefore, driver attention pre-diction is significant for developing safer autonomous driv-ing or assisted driving systems. On account of the remark-able research significance of driver attention prediction, it is attracting increasingly wide research focuses, and many excellent models [36, 21, 39, 30] have been proposed.
The traffic scene is challenge and complex. It is highly dynamic, random and diverse. A driver may confront var-ious scenarios, such as cutting in cars, crossing pedestri-ans and emergently-appearing motorbikes. To safely drive in such scenarios, driving experience is the key point. A skilled driver could effortlessly predict the most likely area where the danger may appear. For example, when a side front car is following another slowly driving car in front of it, the side front car may change to our lane, which is dangerous and we should pay more attention to it to avoid the collision. What’s more, an experienced driver could pre-dict the potentially dangerous zones according to the current traffic scene even if the danger is not visible at the current time, and pay attention to the dangerous zones to guarantee 1
safety. Therefore, it has great significance if we could de-sign a driver attention prediction model that possesses the ability to accumulate the driving experience like a human.
Unfortunately, after reviewing the recent literature re-garding attention prediction [28, 27], we have not found a work that is struggling in this direction. Existing mod-els can be coarsely divided into two categories. One kind of model is CNN (Convolution Neural Network) based encoder-decoder, as shown in Fig. 1(a). The other kind is CNN-Transformer based encoder-decoder, as shown in
Fig. 1(b), which first uses CNN to extract local features, then adopts Transformer to explore the global context of the local features, and finally adds a decoder at the end of Trans-former. These models have remarkably driven the develop-ment of this field. However, their core idea is similar to that of models for saliency prediction, ignoring the importance of long-term historically-accumulative information (similar to the driving experience) for driver attention prediction.
As a result, driver attention can be hardly predicted when saliency target is not consistent with driver attention.
Aiming at designing a driver attention prediction model that is able to simulate human driving experience accumu-lation procedure, this paper proposes a FeedBack Loop
Network (FBLNet). Essentially different from existing models, the novelty of FBLNet is the feedback loop mech-anism that continuously fetches data from the decoder module in every round of training procedure to iteratively update the incremental knowledge. The feedback loop mechanism enables the incremental knowledge to carry historically-accumulative and long-term temporal informa-tion, making the whole model have a similar ability as a human accumulating the driving experience.
Fig. 1(c) illustrates the coarse structure of our model.
Given an input image, CNN encoder and Transformer en-coder extract the features of the input image, and the feedback loop is responsible for updating the incremental knowledge. The fusion module accepts image features and the incremental knowledge as the input, and outputs the fu-sion feature. The fusion feature is upsampled by the de-coder module to construct the driver attention heatmap. To evaluate our model, a series of comparison and diagnos-tic experiments are conducted on two public datasets. The comparison experiment results show that our model has a solid advantage over the baselines, achieving significant im-provement on six metrics. The diagnostic experiment re-sults validate the effectiveness of our proposed feedback loop module, fusion module and encoder module.
The contributions of this paper are as follows. 1) As
Fig 1 shown, our proposed FBLNet is essentially different from all existing methods for driver attention prediction.
Our FBLNet can utillze the historically-accumulative and long-term temporal information by a feedback loop struc-ture like a human driver accumulating his driving experi-ence. Extensive experimental results on two driver attention benchmark datasets show that FBLNet outperforms existing models for attention prediction . 2) We also propose the in-cremental knowledge guided fusion module. This novel fu-sion module can explore the inter-relationship between dif-ferent kinds of features and guides the CNN feature and the
Transformer feature to update in accordance with incremen-tal knowledge during the training process. 2.