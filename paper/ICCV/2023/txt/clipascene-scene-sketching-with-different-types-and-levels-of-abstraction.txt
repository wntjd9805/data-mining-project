Abstraction
Yael Vinker
Tel Aviv University yaelvi116@gmail.com
Yuval Alaluf
Tel Aviv University yuvalalaluf@gmail.com
Daniel Cohen-Or
Tel Aviv University cohenor@gmail.com
Ariel Shamir
Reichman University arik@runi.ac.il
Figure 1. Our method converts a scene image into a sketch with different types and levels of abstraction by disentangling abstraction into two axes of control: fidelity and simplicity. The sketches on the left were selected from a complete matrix generated by our method (an example is shown on the right), encompassing a broad range of possible sketch abstractions for a given image. Our sketches are generated in vector form, which can be easily used by designers for further editing.
Abstract 1.

Introduction
In this paper, we present a method for converting a given scene image into a sketch using different types and mul-tiple levels of abstraction. We distinguish between two types of abstraction. The first considers the fidelity of the sketch, varying its representation from a more precise por-trayal of the input to a looser depiction. The second is defined by the visual simplicity of the sketch, moving from a detailed depiction to a sparse sketch. Using an explicit disentanglement into two abstraction axes — and multi-ple levels for each one — provides users additional con-trol over selecting the desired sketch based on their per-sonal goals and preferences. To form a sketch at a given level of fidelity and simplification, we train two MLP net-works. The first network learns the desired placement of strokes, while the second network learns to gradually re-move strokes from the sketch without harming its recogniz-ability and semantics. Our approach is able to generate sketches of complex scenes including those with complex backgrounds (e.g. natural and urban settings) and subjects (e.g. animals and people) while depicting gradual abstrac-tions of the input scene in terms of fidelity and simplicity. https://clipascene.github.io/CLIPascene/
Several studies have demonstrated that abstract, mini-mal representations are not only visually pleasing but also helpful in conveying an idea more effectively by empha-sizing the essence of the subject [13, 3]. In this paper, we concentrate on converting photographs of natural scenes to sketches as a prominent minimal representation.
Converting a photograph to a sketch involves abstraction, which requires the ability to understand, analyze, and inter-pret the complexity of the visual scene. A scene consists of multiple objects of varying complexity, as well as rela-tionships between the foreground and background (see Fig-ure 2). Therefore, when sketching a scene, the artist has many options regarding how to express the various compo-nents and the relations between them (see Figure 3).
In a similar manner, computational sketching methods must deal with scene complexity and consider a variety of abstraction levels. Our work focuses on the challenging task of scene sketching while doing so using different types and multiple levels of abstraction. Only a few previous works at-tempted to produce sketches with multiple levels of abstrac-tion. However, these works focus specifically on the task of object sketching [34, 25] or portrait sketching [1], and of-ten simply use the number of strokes to define the level of
A
B
Figure 2. Scene complexity. (A) contains a single, central object with a simple background, (B) contains multiple objects (the cat and vase) with a slightly more complicated background, and (C) contains both foreground and background that include many de-tails. Our work tackles all types of scenes.
C
Figure 3. Drawings of different scenes by different artists. Notice the significant differences in style and level of abstraction between the drawings — moving from more detailed and precise (left) to more abstract (right). The second row shows how the level of ab-straction not only varies between drawings, but also within the same drawing. Where each drawing contains areas that are rel-atively more detailed (red) and more abstract (blue). abstraction. We are not aware of any previous work that at-tempts to separate different types of abstractions. Moreover, existing works for scene sketching often focus on produc-ing sketches based on certain styles, without taking into ac-count the abstraction level, which is an essential concept in sketching. Lastly, most existing methods for scene sketch-ing do not produce sketches in vector format. Providing vector-based sketches is a natural choice for sketches as it allows further editing by designers (such as in Fig. 6).
We define two axes representing two types of abstrac-tions and produce sketches by gradually moving along these axes. The first axis governs the fidelity of the sketch. This axis moves from more precise sketches, where the sketch composition follows the geometry and structure of the pho-tograph to more loose sketches, where the composition re-lies more on the semantics of the scene. An example is shown in Figure 4, where the leftmost sketch follows the contours of the mountains on the horizon, and as we move right, the mountains and the flowers in the front gradually deviate from the edges present in the input, but still convey the correct semantics of the scene. The second axis governs the level of details of the sketch and moves from detailed to sparse depictions, which appear more abstract. Hence, we refer to this axis as the simplicity axis. An example can be seen in Figure 5, where the same general characteristics of
Figure 4. The fidelity axis. From left to right, using the same num-ber of strokes the sketches gradually depart from the geometry of the input image, but still convey the semantics of the scene.
Figure 5. The simplicity axis. On the left, we start with a more detailed sketch and as we move to the right the sketch is gradually simplified while still remaining consistent with the overall appear-ance of the initial sketch. the scene (e.g. the mountains and flowers) are captured in all sketches, but with gradually fewer details.
To deal with scene complexity, we separate the fore-ground and background elements and sketch each of them separately. This explicit separation and the disentanglement into two abstraction axes provide a more flexible framework for computational sketching, where users can choose the de-sired sketch from a range of possibilities, according to their goals and personal taste.
We define a sketch as a set of B´ezier curves, and train a simple multi-layer perceptron (MLP) network to learn the stroke parameters. Training is performed per image (e.g. without an external dataset) and is guided by a pre-trained
CLIP-ViT model [29, 7], leveraging its powerful ability to capture the semantics and global context of the entire scene.
To realize the fidelity axis, we utilize different inter-mediate layers of CLIP-ViT to guide the training process, where shallow layers preserve the geometry of the image and deeper layers encourage the creation of looser sketches that emphasize the scene’s semantics.
To realize the simplicity axis, we jointly train an addi-tional MLP network that learns how to best discard strokes gradually and smoothly, without harming the recognizabil-ity of the sketch. As shall be discussed, the use of the net-works over a direct optimization-based approach allows us to define the level of details implicitly in a learnable fashion, as opposed to explicitly determining the number of strokes.
The resulting sketches demonstrate our ability to cope with various scenes and to capture their core characteristics while providing gradual abstraction along both the fidelity and simplicity axes, as shown in Figure 1. We compare our results with existing methods for scene sketching. We addi-tionally evaluate our results quantitatively and demonstrate that the generated sketches, although abstract, successfully preserve the geometry and semantics of the input scene.
ing approaches that provides sketches with multiple levels of abstraction and in vector form, which allows for a wider range of editing and manipulation.
Sketch Abstraction While abstractions are fundamental to sketches, only a few works have attempted to create sketches at multiple levels of abstraction, while no previ-ous works have done so over an entire scene. Berger et al. [1] collected portrait sketches at different levels of ab-straction from seven artists to learn a mapping from a face photograph to a portrait sketch. Their method is limited to faces only and requires a new dataset for each desired level of abstraction. Muhammad et al. [25] train a reinforcement learning agent to remove strokes from a given sketch with-out harming the sketch’s recognizability. The recognition signal is given by a sketch classifier trained on nine classes from the QuickDraw dataset [11]. Their method is therefore limited only to objects from the classes seen during training and requires extensive training.
CLIPasso Most similar to our work is CLIPasso [34] which was designed for object sketching at multiple lev-els of abstraction. They define a sketch as a set of B´ezier curves and optimize the stroke parameters with respect to a CLIP-based [29] similarity loss between the input image and generated sketch. Multiple levels of abstraction are re-alized by reducing the number of strokes used to compose the sketch. In contrast to CLIPasso, our method is not re-stricted to objects and can handle the challenging task of scene sketching. Additionally, while Vinker et al. examine only a single form of abstraction, we disentangle abstraction into two distinct axes controlling both the simplicity and the fidelity of the sketch. Moreover, in CLIPasso, the user is re-quired to explicitly define the number of strokes needed to obtain the desired abstraction. However, different images require a different number of strokes, which is difficult to determine in advance. In contrast, we implicitly learn the desired number of strokes by training two MLP networks to achieve a desired trade-off between simplicity and fidelity with respect to the input image. 3. Method
Given an input image I of a scene, our goal is to pro-duce a set of corresponding sketches at n levels of fidelity and m levels of simplicity, forming a sketch abstraction ma-trix of size m × n. We begin by producing a set of sketches along the fidelity axis (Sections 3.1 and 3.2) with no simpli-fication, thus forming the top row in the abstraction matrix.
Next, for each sketch at a given level of fidelity, we per-form an iterative visual simplification by learning how to best remove select strokes and adjust the locations of the re-maining strokes (Section 3.3). For clarity, in the following we describe our method taking into account the entire scene as a whole. However, to allow for greater control over the
Figure 6. Artistic stylization of the strokes using Adobe Illustrator. 2.