Abstract 1.

Introduction
Current semi-supervised object detection (SSOD) algo-rithms typically assume class balanced datasets (PASCAL
VOC etc.) or slightly class imbalanced datasets (MS-COCO, etc). This assumption can be easily violated since real world datasets can be extremely class imbalanced in nature, thus making the performance of semi-supervised ob-ject detectors far from satisfactory. Besides, the research for this problem in SSOD is severely under-explored. To bridge this research gap, we comprehensively study the class imbalance problem for SSOD under more challeng-ing scenarios, thus forming the ﬁrst experimental setting for class imbalanced SSOD (CI-SSOD). Moreover, we pro-pose a simple yet effective gradient-based sampling frame-work that tackles the class imbalance problem from the perspective of two types of conﬁrmation biases. To tackle conﬁrmation bias towards majority classes, the gradient-based reweighting and gradient-based thresholding mod-ules leverage the gradients from each class to fully bal-ance the inﬂuence of the majority and minority classes. To tackle the conﬁrmation bias from incorrect pseudo labels of minority classes, the class-rebalancing sampling mod-ule resamples unlabeled data following the guidance of the gradient-based reweighting module. Experiments on three proposed sub-tasks, namely MS-COCO, MS-COCO
→ Object365 and LVIS, suggest that our method outper-forms current class imbalanced object detectors by clear margins, serving as a baseline for future research in CI-SSOD. Code will be available at https://github. com/nightkeepers/CI-SSOD.
*Equally-contributed authors.
†Work done during an internship at Baidu.
‡Corresponding author.
Different types of objects in nature appear at different frequencies, and there is bound to be class imbalance in the dataset corresponding to object detection. Class imbalance refers to the scenario when a number of classes are over-represented (also known as majority classes), having more samples than others (also known as minority classes) in the dataset. Semi-supervised object detection (SSOD) utilizes both labeled and unlabeled data to improve the performance of an object detector. Although current SSOD methods have achieved promising performance on standard benchmark datasets (MS-COCO, PASCAL VOC, etc), these datasets are assumed to be class balanced or slightly class imbal-anced. This underlying assumption can be easily violated when applying current SSOD methods to real-world scenar-ios where datasets are extremely class imbalanced in nature.
For example, the sample distribution of corner cases in au-tonomous driving is scarce. As a result, the performance of these SSOD methods often suffers, especially for those minority classes. Besides, the research efforts dedicated to tackling the class imbalance problem in SSOD are severely under-explored.
In contrast, there are extensive literature on learning a class-balanced detector in supervised settings such as Long-tailed object detection (LTOD) and Few-shot object de-tection (FSOD). LTOD balances the inﬂuence of majority and minority classes by data re-sampling [6, 36] and class-balanced losses [32, 16]. Current FSOD methods transfer knowledge learned from the majority classes to the minor-ity classes by ﬁne-tuning [26, 12] or meta-learning-based strategies [15, 9]. However, both LTOD and FSOD meth-ods are devised in a supervised manner and thus cannot fully exploit the potential information in unlabeled data, making them prone to overﬁt the limited labeled images of minority classes. Besides, an increasing number of re-search efforts are dedicated to tackling the class imbalance problem in semi-supervised learning for the image classiﬁ-cation task [35, 10, 25]. But simply applying these meth-ods to SSOD generates inferior performance as manifested in our experiments in later sections. This is because the resampling and pseudo labeling strategies are tailored for image-wise annotations but not for box-wise annotations.
Since there always exist multiple instances in an image, the resampling of pseudo labels on image-aspect enlarges the negative impact of incorrect pseudo labels and “supervision collapse”[4]. Current SSOD methods alleviate the class im-balance problem by using focal loss [22, 23] or by apply-ing class-wise thresholds [3, 17]. Nevertheless, these meth-ods fail to generate high-quality pseudo labels for minority classes in the extremely class imbalanced semi-supervised datasets due to the so-called conﬁrmation bias [1]. The con-ﬁrmation biases are mainly from two parts: (1) The model biased toward majority classes tends to predict pseudo la-bels that are also biased toward majority classes. Using these pseudo labels to train the detector reinforces detec-tors to produce more pseudo labels for majority classes and thus overﬁts to the biased pseudo labels. (2) The pseudo la-bels of minority classes are prone to be incorrect. Since the proportion of ground truth annotations for these classes is small, the incorrect pseudo labels easily dominate the train-ing for these classes, thus making the detector ﬁt with the incorrect information of these pseudo labels.
Setting
SSOD
LTOD
FSOD
CI-SSOD
Labeled  images
Unlabeled  images
Class  imbalance
Evaluation (cid:1591) (cid:1591) (cid:1591) (cid:1591) (cid:1591) (cid:28741) (cid:28741) (cid:1591)
Slight
Majority+Minority
Serious Majority+Minority
Serious
Minority
Serious Majority+Minority
Figure 1. Differences of our proposed CI-SSOD with respect to other related object detection tasks. “CI-SSOD” represents class imbalanced SSOD. “Majority” and “Minority” represent the ma-jority and minority classes respectively.
According to the analysis above, conducting a compre-hensive study of the class imbalanced problem in SSOD re-quires considering two scenarios: (1) There are abundant unlabeled instances for the minority classes in the unlabeled images. A detector learned under such scenarios mainly suffers from the ﬁrst type of conﬁrmation bias commonly existed in current benchmarks. (2) The instances of minor-ity classes in unlabeled images are naturally scarce. In this case, the second type of conﬁrmation bias is the main ob-stacle to learn a balanced detector. To this end, we propose a new setting to comprehensively study the class imbal-anced problem in SSOD, namely class imbalanced SSOD (CI-SSOD). Compared to existing benchmarks, CI-SSOD aims to build a balanced detector that could perform well for both majority and minority classes with the help of un-labeled data under more challenging class imbalance sce-narios. We summarize the difference in Fig. 1.
Designing a detector for CI-SSOD is still under-explored. Directly combining methods from LTOD (Eqlv2, etc.) or FSOD (DeFRCN, etc.) with SSOD (Soft teacher, etc.) generates inferior performance as proven in our ex-periments in later sections. The primary reason is that the combined methods fail to consider the two types of conﬁr-mation bias mentioned above, thus generating pseudo labels with low precision and recall and leading to ineffective us-age of the unlabeled data. Monitoring dynamic model sta-tus during training is essential for designing a good detec-tor under CI-SSOD. Based on this observation, we propose a simple yet effective gradient-based sampling framework for CI-SSOD from the perspective of two types of conﬁr-mation biases mentioned above. To tackle the ﬁrst type of conﬁrmation bias, we propose a Gradient-based Reweight-ing (GbR) module that introduces a new perspective to fully balance class-wise positive and negative gradients by esti-mating class weights from a gradient matrix. This matrix serves as a metric to measure the model training status and formulates the optimization target for class weights, alle-viating the conﬁrmation bias toward majority classes. Be-sides, we also present a Gradient-based Thresholding (GbT) module that modiﬁes the class-wise thresholds for the unla-beled data following the guidance of the solved weights in the GbR module. To tackle the second type of conﬁrmation bias, we present a Class-rebalancing Sampling (CrS) mod-ule. The CrS module considers not only class frequencies but also the conﬁdence of pseudo labels and the dynamic class-wise thresholds from the GbT module, which drives the model to learn from pseudo labels with high conﬁdence, alleviating the noise from incorrect pseudo labels.
To conclude, this paper has the following contributions:
• We extend the class imbalance study to SSOD, form-ing a new comprehensive setting, namely CI-SSOD.
• We introduce a simple yet effective gradient-based sampling framework for CI-SSOD from the perspec-tive of two types of conﬁrmation biases.
• Extensive experiments on the MS-COCO, MS-COCO→Object365, and LVIS sub-tasks show that our method outperforms all existing class imbalanced based methods by clear margins, demonstrating the su-periority of our method. 2.