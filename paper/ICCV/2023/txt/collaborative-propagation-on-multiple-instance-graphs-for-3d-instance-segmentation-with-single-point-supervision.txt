Abstract
Instance segmentation on 3D point clouds has been at-tracting increasing attention due to its wide applications, especially in scene understanding areas. However, most ex-isting methods operate on fully annotated data while man-ually preparing ground-truth labels at point-level is very cumbersome and labor-intensive. To address this issue, we propose a novel weakly supervised method RWSeg that only requires labeling one object with one point. With these sparse weak labels, we introduce a unified framework with two branches to propagate semantic and instance informa-tion respectively to unknown regions using self-attention and a cross-graph random walk method. Specifically, we propose a Cross-graph Competing Random Walks (CRW) algorithm that encourages competition among different in-stance graphs to resolve ambiguities in closely placed ob-jects, improving instance assignment accuracy. RWSeg gen-erates high-quality instance-level pseudo labels. Exper-imental results on ScanNet-v2 and S3DIS datasets show that our approach achieves comparable performance with fully-supervised methods and outperforms previous weakly-supervised methods by a substantial margin. 1.

Introduction
With the rapid development of 3D sensing technology, point cloud based scene understanding has become a popu-lar research topic in recent years. Instance segmentation is one of the most fundamental tasks in this field and has many applications in robotics, autonomous driving, AR/VR, etc.
Given a 3D point cloud depicting a scene, this task requires predicting not only a semantic category but also an instance id to differentiate objects at point level. Many deep learn-ing methods have been developed for this task, showing promising results. However, most of these methods operate
*Corresponding author: G.Lin (e-mail:gslin@ntu.edu.sg)
Figure 1. Comparisons of our approach RWSeg with two recent weakly supervised 3D instance segmentation methods and the fully-supervised baseline on two datasets. Our method achieves better results than other weakly supervised methods with the same amount of weak annotations. on point-wise fully annotated data to supervise the network training.
Manually creating data annotations at point level is very cumbersome and labor-intensive. Although some tools have been adopted to assist, the average time used to annotate one scene is about 22.3 minutes on ScanNet-v2 dataset [10]. To alleviate this issue, several types of weak annotations have been proposed, such as scene-level annotation, subcloud-level annotation [47], 2D image based annotation and 3D bounding box annotation [1, 8]. However, not all weak la-bel types are easy to obtain in practice. In this work, we adopt the annotation method used in SegGroup [40] and
“One Thing One Click” [33], which only requires anno-tating a single point for each object. As shown in Figure 2, this results in very sparse initial annotations, with less than 0.02% of total points requiring labeling. According to
[40, 33], this annotation method takes less than two minutes per scene, significantly reducing the need for human effort.
Tao et al. [40] and Tang et al. [39] have investigated the
”One-thing-one-click” approach to address the challenge of weakly supervised 3D instance segmentation. These tech-niques construct graphs on top of the over-segmentation
Figure 2. Pipeline of our proposed weakly supervised method for 3D instance segmentation. The input point cloud is annotated with a single point for each object (enlarged for better visualizations). We use a 3D U-Net backbone based on submanifold sparse convolution
[17] to extract point features. Next, we apply average pooling to the points within the same supervoxel. To facilitate semantic feature propagation, we utilize a self-attention module. Finally, our novel Cross-graph Competing Random Walks (CRW) module leverages the inputs from both branches to generate high-quality pseudo labels for further network training. outcomes and apply Graph Convolution Network (GCN) or inter-superpoint affinity for label propagation. However, these approaches encounter some issues. SegGroup [40] re-lies solely on a cross-entropy loss for its semantic predic-tion with a greedy algorithm for clustering, hence lacking instance-related information. Besides, this method is only designed for the purpose of generating pseudo labels, and therefore requires to utilize these pseudo labels as ground-truth to train a separate network for prediction. 3D-WSIS
[39] utilizes an offset loss and an affinity loss to produce better discriminative features, but their graph is based on the over-segmented point clouds, and the feature of each super-voxel is simply obtained through average pooling of point features and coordinates. The size of supervoxels can vary significantly in their setup, and the initial weak labels can be located at any part of objects, resulting in an unbalanced at-traction to neighboring nodes. This may lead to difficulty in identifying precise boundaries, particularly when multiple instances are located close to each other.
In this paper, we propose a novel weakly supervised learning approach, named RWSeg, for 3D point cloud in-stance segmentation. With only one point annotation per instance, we focus on two key considerations: (1) effective feature propagation is critical for generating high-quality pseudo labels, and (2) leveraging the interactions among in-stance graphs can be beneficial in finding more accurate in-stance boundaries and improving the quality of clustering.
To address the limitations of previous methods, we are moti-vated to develop a unified structure for both feature learning and feature propagation.
Convolutional Neural Network (CNN) can extract good local features. However, long-range dependencies can hardly be captured due to its relatively small receptive field.
The limitations of CNNs in capturing long-range dependen-cies are exacerbated in weakly supervised learning scenar-ios, where only a limited number of certain labels are avail-able to supervise the training process. To this end, we intro-duce a self-attention module after the 3D CNN backbone, which can effectively propagate long-range information to unknown regions.
For instance pseudo label generation, a customized ran-dom walk algorithm on point-level is developed for 3D weakly instance segmentation. The point clouds are first split by their categories, and for each category, multiple in-stance graphs are built and random walk propagation is per-formed on each of them. The total energy on each individual graph is identical, based on the assumption that same-class objects tend to have similar sizes. A competing mechanism is designed to perform collaborative propagation on multi-ple instance graphs. To sum up, the key contributions of our work are as follows:
• We design a unified framework for weakly supervised 3D instance segmentation. To enhance the feature propagation, we introduce a self-attention module to capture long-range dependencies.
• We propose a novel algorithm to perform collabora-tive propagation on multiple instance graphs to gen-erate high-quality instance pseudo labels. The de-signed competing mechanism helps to resolve ambigu-ous cases in 3D instance segmentation task.
• With significantly fewer annotations, our method bridges the gap between weakly supervised learning and fully supervised learning in 3D instance segmen-tation.
2.