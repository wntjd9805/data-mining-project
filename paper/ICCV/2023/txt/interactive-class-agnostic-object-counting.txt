Abstract (cid:2)(cid:14)(cid:16)(cid:20)(cid:19)(cid:1)(cid:10)(cid:13)(cid:4)(cid:9)(cid:8)(cid:1)(cid:26)(cid:1)(cid:8)(cid:21)(cid:8)(cid:13)(cid:16)(cid:12)(cid:4)(cid:17)(cid:18) (cid:3)(cid:17)(cid:8)(cid:7)(cid:10)(cid:6)(cid:19)(cid:8)(cid:7)(cid:1)(cid:7)(cid:8)(cid:14)(cid:18)(cid:10)(cid:19)(cid:22)(cid:1)(cid:13)(cid:4)(cid:16)
We propose a novel framework for interactive class-agnostic object counting, where a human user can in-teractively provide feedback to improve the accuracy of a counter. Our framework consists of two main compo-nents: a user-friendly visualizer to gather feedback and an efﬁcient mechanism to incorporate it.
In each itera-tion, we produce a density map to show the current pre-diction result, and we segment it into non-overlapping re-gions with an easily veriﬁable number of objects. The user can provide feedback by selecting a region with obvious counting errors and specifying the range for the estimated number of objects within it. To improve the counting re-sult, we develop a novel adaptation loss to force the vi-sual counter to output the predicted count within the user-speciﬁed range. For effective and efﬁcient adaptation, we propose a reﬁnement module that can be used with any density-based visual counter, and only the parameters in the reﬁnement module will be updated during adaptation.
Our experiments on two challenging class-agnostic object counting benchmarks, FSCD-LVIS and FSC-147, show that our method can reduce the mean absolute error of multi-ple state-of-the-art visual counters by roughly 30% to 40% with minimal user input. Our project can be found at https://yifehuang97.github.io/ICACountProjectPage/. 1.

Introduction
The need for counting objects in images arises in many applications, and signiﬁcant progress has been made for both class-speciﬁc [17, 30, 13, 46, 47, 9, 3, 24, 44, 25, 19, 38, 23, 16, 34, 36, 1] and class-agnostic [49, 35, 33, 41, 51, 26, 31, 32] counting. However, unlike in many other computer vision tasks where the predicted results can be veriﬁed for reliability, visual counting results are difﬁcult to validate, as illustrated in Fig. 1. Mistakes can be made, and often there are no mechanisms to correct them. To enhance the practicality of visual counting methods, the results need
*Work done at Stony Brook University, prior to joining Amazon (cid:23)(cid:24)(cid:25)(cid:1) (cid:15)(cid:5)(cid:11)(cid:8)(cid:6)(cid:19)(cid:18)
Figure 1. Given an input image and several exemplar objects, a class-agnostic counter will output a density map and the total ob-ject count. It is often challenging to validate these outputs, making it difﬁcult to adopt automatic visual counting in practice. To im-prove the practicality of a visual counter, we propose an interactive framework that allows a human user to quickly detect mistakes and improve performance based on the identiﬁed errors. to be more intuitive and veriﬁable, and feedback mecha-nisms should be incorporated to allow errors to be corrected.
This necessitates a human-in-the-loop framework that can interactively display the predicted results, collect user feed-back, and adapt the visual counter to reduce counting errors.
It is, however, challenging to develop an interactive framework for visual counting. The ﬁrst challenge is to provide the user with an intuitive visualizer for the count-ing result. Current state-of-the-art visual counting meth-ods typically generate a density map and then sum the den-sity values to obtain the ﬁnal count. However, as shown in Fig. 1, verifying the ﬁnal predicted count can be difﬁ-cult, as can verifying the intermediate density map, due to the mismatch between the continuous nature of the density map and the discrete nature of the objects in the image. The second challenge is to design an appropriate user interac-tion method that requires minimal user effort while being suited for providing feedback on object counting. The third challenge is developing an effective adaptation scheme for the selected interaction type that can incorporate user feed-back and improve the performance of visual counters. In this paper, we address all three aforementioned challenges to develop an interactive framework for visual counting.
For the ﬁrst challenge, we propose a novel segmentation method that segments a density map into non-overlapping regions, where the sum of density values in each region is a near-integer value that can be easily veriﬁed. This provides the user with a more natural and understandable interpreta-tion of the predicted density map. Notably, developing such
an algorithm that must also be suitably fast for an interactive system is challenging, which constitutes a technical contri-bution of our paper.
For the second challenge, we propose a novel type of in-teraction that enables the user to provide feedback with just two mouse clicks: the ﬁrst click selects the region, and the second click selects the appropriate range for the number of objects in the chosen region. The proposed user inter-action method is unique as it is speciﬁcally tailored for ob-ject counting and requires minimal user effort. Firstly, the auto-generated segmentation map allows the user to select an image region using just one mouse click, which is faster compared to drawing a polygon or scribbles. Secondly, by leveraging the humans’ subitizing ability, which allows them to estimate the number of objects in a set quickly with-out counting them individually, we can obtain an approxi-mate count with just another mouse click, which is quicker than one by one counting using dot annotations.
For the third challenge, we develop an interactive adap-tation loss based on range constraints. To update the visual counter efﬁciently and effectively and to reduce the disrup-tion of the learned knowledge in the visual counter, we pro-pose the reﬁnement module that directly reﬁnes the spatial similarity feature in the regression head. Furthermore, we propose a technique to estimate the user’s feedback conﬁ-dence and use this conﬁdence to adjust the learning rate and gradient steps during the adaptation process.
In this paper, we primarily focus on class-agnostic count-ing, and we demonstrate the effectiveness of our framework with experiments on FSC-147 [35] and FSCD-LVIS [31].
However, our framework can be extended to category-speciﬁc counting, as will be seen in our experiments on sev-eral crowd-counting and car-counting benchmarks, includ-ing ShanghaiTech [52], UCF-QNRF [11], and CARPK [8].
We also conduct a user study to investigate the practicality of our method in a real-world setting.
In short, the main contribution of our paper is a frame-work that improves the accuracy and practicality of visual counting. Our technical contributions include: (1) a novel segmentation method that quickly segments density maps into non-overlapping regions with near-integer density val-ues, which enhances the interpretability of predicted density maps for users; (2) an innovative user feedback scheme that requires minimal user effort for object counting by utilizing subitizing ability and auto-generated segmentation maps; and (3) an effective adaptation approach that incorporates the user’s feedback into the visual counter through a reﬁne-ment module and a conﬁdence estimation method. 2.