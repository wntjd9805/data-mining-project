Abstract
In Parallel Continual Learning (PCL), the parallel multi-ple tasks start and end training unpredictably, thus suffering from both training conflict and catastrophic forgetting issues.
The two issues are raised because the gradients from parallel tasks differ in directions and magnitudes. Thus, in this paper, we formulate the PCL into a minimum distance optimization problem among gradients and propose an explicit Asymmet-ric Gradient Distance (AGD) to evaluate the gradient dis-crepancy in PCL. AGD considers both gradient magnitude ratios and directions, and has a tolerance when updating with a small gradient of inverse direction, which reduces the imbalanced influence of gradients on parallel task train-ing. Moreover, we present a novel Maximum Discrepancy
Optimization (MaxDO) strategy to minimize the maximum discrepancy among multiple gradients. Solving by MaxDO with AGD, parallel training reduces the influence of the training conflict and suppresses the catastrophic forgetting of finished tasks. Extensive experiments validate the effec-tiveness of our approach on three image recognition datasets in task-incremental and class-incremental PCL. Our code is available at https://github.com/fanlyu/maxdo. 1.

Introduction
Continual Learning (CL) [25, 27, 31, 43], aims to contin-uously learn new knowledge from a sequence of tasks with non-overlapping data streams over a lifelong time. In the era of Internet of Things, people are using many smart devices, where multi-source data and tasks would be accessed at any time. A CL system should respond to parallel data streams from multiple devices. We study Parallel Continual Learn-ing (PCL), as shown in Fig. 1, where an unfixed number of tasks are trained in a parallel way at any time. Specifically, according to the access time of each task, PCL builds an adaptive number of parallel data pipes, thus enabling instant response to new-coming tasks without pending.
*Corresponding author.
Due to the parallel data streams from different tasks, PCL suffers from not only the catastrophic forgetting but the train-ing conflict among parallel tasks. Most existing methods in
CL are proposed to tackle the catastrophic forgetting [19, 25], including regularization-based [25, 8, 16, 51, 1], rehearsal-based [31, 9, 21, 4, 41, 36], and architecture-based [33, 49, 39, 38] methods. In PCL, the training processes of differ-ent tasks are diverse, i.e., each task starts and ends training unpredictably (see Fig. 1). Thereby the gradient from differ-ent task differs in direction and magnitude [50] and may be neutralized. The gradient discrepancies lead to catastrophic forgetting and training conflict issues, which may fail the learning of some tasks. At any time in PCL, therefore, we present that the problem can be formulated to find an optimal gradient in a minimum distance multi-objective optimization, where each objective is to minimize the distance to a target gradient. In general, the distance metric is proportional to the effect of the optimal gradient on the corresponding task.
In most situations, the mentioned distance metric D be-tween gradients is set to symmetric intuitively, such as the
Euclidean distance and cosine distance. In other words, we usually have D(x, y) = D(y, x) for any x and y. However, the gradient influence is imbalanced among parallel tasks in the gradient descent. For example, in Fig. 1, at the marked time, we have three gradients with diverse directions and magnitudes, and updating with any of them provides differ-ent influences to the other two. In the minimum distance problem, the optimal solution should have the minimum negative influence on all parallel tasks, but using symmetric metrics means the influences are optimized indistinguishably at the same time. Due to the fact that the gradients are with wide differences, the solution may have large biases, which would get the near-fitting task out of its local minimum but has less impact on a new-coming task.
To measure the gradient discrepancy, we hold the opinion that the distance metric in the min-distance problem should be asymmetric. First, though the metric is bound up with both the gradient magnitude and direction, the influences on model training from gradients should be asymmetric, where the model should have more tolerance to small gradients even if they indicate an inverse direction. Second, because
Figure 1. Overview of the proposed method in PCL. Left: PCL trains parallel tasks according to their access time without pending. Middle:
At any time, gradients from different tasks (corresponding colors) have unpredicted direction and magnitude (the length of vectors). Right:
We formulate PCL into a min-distance problem and propose an asymmetric distance for effective optimization. gradients are with different magnitudes, the discrepancy between two large gradients is often set to larger than that be-tween small gradients when using symmetric distance, such as Euclidean distance. Directly optimizing using magnitude-aware distance values may lead to the solution close to large gradients and thus hinder the kepping of old tasks. To mit-igate the bias from the magnitude difference, it is better to employ the magnitude ratio instead of magnitude itself.
Motivated by this, in this paper, we propose an explicit measurement for the learning from gradient discrepancy in
PCL, named Asymmetric Gradient Distance (AGD), which considers gradient magnitude ratios and directions, and sets a tolerance for smaller gradients. As shown in Fig. 1, the proposed AGD is used in solving the minimum distance problem with multiple gradients from parallel tasks. Then, we propose an effective optimization strategy for minimizing the gradient discrepancy to avoid self-interference. We name the strategy Maximum Discrepancy Optimization (MaxDO), which minimizes the maximum discrepancy from each gra-dient to the others. Moreover, to address the catastrophic forgetting issue, we follow the rehearsal strategy [31] in tra-ditional CL and build an extra memory data stream. The rehearsal data stream is used to provide a gradient of finished tasks in MaxDO. Solving by MaxDO with AGD, parallel training mitigates the impacts of the diverse training process and slows the catastrophic forgetting of finished tasks. Ex-tensive results on three datasets show the superiority and effectiveness of our approach.
Our main contributions are three-fold: (1) We formulate the PCL into a minimum distance problem and compare symmetric and asymmetric distances. We show that symmetric metrics are not effective in solving the problem and suggest asymmetric metrics. (2) We propose an asymmetric metric, named AGD, to eval-uate the gradient discrepancy, which is proportional to the gradient magnitude ratios and directions. AGD mea-sures the imbalance of gradient influence in PCL. (3) We propose MaxDO for minimizing gradient discrep-ancy of different tasks, which maximumly reduces the asymmetric discrepancy from a gradient to the others.
MaxDO avoids the self-interference among gradients and reduces training conflict and catastrophic forgetting. 2.