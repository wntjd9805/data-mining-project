Abstract
Video inpainting aims at filling in missing regions of a video. However, when dealing with dynamic scenes with camera or object movements, annotating the inpainting target becomes laborious and impractical. In this paper, we resolve the one-shot video inpainting problem in which only one annotated first frame is provided. A naive solu-tion is to propagate the initial target to the other frames with techniques like object tracking. In this context, the main obstacles are the unreliable propagation and the par-tially inpainted artifacts due to the inaccurate mask. For the former problem, we propose curricular inactivation to replace the hard masking mechanism for indicating the in-painting target, which is robust to erroneous predictions in long-term video inpainting. For the latter, we explore the properties of inpainting residue and present an on-*Both authors contributed equally to this research.
†Corresponding authors: Xuemiao Xu (xuemx@scut.edu.cn) and
Shengfeng He (shengfenghe@smu.edu.sg). line residue removal method in an iterative detect-and-refine manner. Extensive experiments on several real-world datasets demonstrate the quantitative and qualitative supe-riorities of our proposed method in one-shot video inpaint-ing. More importantly, our method is extremely flexible that can be integrated with arbitrary traditional inpaint-ing models, activating them to perform the reliable one-shot video inpainting task. Video demonstrations can be found in our supplement, and our code can be found at https://github.com/Arise-zwy/CIRI. 1.

Introduction
Video inpainting aims at filling holes with plausible con-tent that is spatially and temporally consistent with the orig-inal video. It serves as an essential and fundamental func-tion in numerous video editing applications, such as scratch restoration [14, 36], video retargeting [1, 20], and object removal [18].
Existing methods have a strong assumption that the in-painting targets are well-defined across all the frames, and thus their research focus lies on connecting individual in-painting results with coherency [16, 19, 21, 22, 44]. How-ever, this problem definition is too ideal that cannot be real-ized in practical scenarios. A short video with a few seconds can contain hundreds of frames, and annotating all of them for every editing task is obviously laborious and infeasible.
In this paper, we aim to resolve a challenging video in-painting problem that only the annotation of the first frame is available. This practical setting has not been studied in more depth, but it is explored from an object segmenta-tion perspective. For instance, existing one-shot inpainting models [18, 28] focus only on improving the mask prop-agation quality. However, they neglect the fact that the predicted/propagated masks cannot be always perfect.
Here we address this dilemma from a pure inpainting aspect. We embrace the truth that predicted masks are erroneous, and therefore concentrate on coping with these inaccuracies in the inpainting framework. To this end, we propose a Curricular Inactivation framework for
Residue-aware one-shot video Inpainting (CIRI). First, we observe that the main source of inpainting errors comes from the hard masking mechanism. It assumes all target pixels are included in the mask and no others are left outside, which is obviously false in the one-shot setting. We therefore, tailor a new target indication mechanism, curricular inactivation, to tolerate inaccurate target masks. Specifically, instead of masking out the target regions in the image space that might ruin good image content, we propose to inactivate multi-scale feature responses of the predicted areas. More importantly, we introduce a dual-curriculum learning strategy into our inactivation to gradually transfer the depen-dency from the perfect ground truth to the inaccurate mask.
Second, it is inevitable to have partial regions unsuccessfully inpainted when using an incomplete mask, and these regions are shown in different data distributions to either foreground or background. We therefore design an online residue removal scheme to actively detect these artifacts and remove them iteratively during the inference stage. Fig. 1 shows our overall pipeline of one-shot video inpainting.
To quantitatively evaluate the proposed method, we con-struct a synthetic object removal dataset based on Youtube-VOS [41], DAVIS [29], and OVID [30]. Extensive experi-ments on this synthetic dataset as well as other real-world datasets demonstrate superior performance over state-of-the-art traditional and one-shot video inpainting methods.
Another important feature of our method is that the pro-posed two main modules are completely plug-and-play that can convert traditional methods to one-shot inpainting and significantly boost their performances.
In summary, our main contributions are threefold:
• We propose a curricular inactivation strategy to substi-tute hard masking for indicating inpainting targets in an unreliable input scenario. On one hand, it inactivates multi-scale feature responses to prevent destroying orig-inal good image content. On the other hand, we use curriculum learning to progressively tolerate imperfect input masks.
• We explore the property of inpainting artifacts, and present an online learning strategy for iteratively detect-ing and removing inpainting residues in the inference phase.
• The proposed method not only demonstrates superior performances over state-of-the-art inpainting methods, but also enables converting arbitrary inpainting models to the one-shot setting with a significant performance improvement. 2.