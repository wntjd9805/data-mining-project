Abstract
Video anomaly detection is an ill-posed problem because it relies on many parameters such as appearance, pose, camera angle, background, and more. We distill the prob-lem to anomaly detection of human pose, thus decreasing the risk of nuisance parameters such as appearance affect-ing the result. Focusing on pose alone also has the side benefit of reducing bias against distinct minority groups.
Our model works directly on human pose graph se-quences and is exceptionally lightweight (∼1K parame-ters), capable of running on any machine able to run the pose estimation with negligible additional resources. We leverage the highly compact pose representation in a nor-malizing flows framework, which we extend to tackle the unique characteristics of spatio-temporal pose data and show its advantages in this use case.
The algorithm is quite general and can handle training data of only normal examples as well as a supervised setting that consists of labeled normal and abnormal examples.
We report state-of-the-art results on two anomaly detec-tion benchmarks - the unsupervised ShanghaiTech dataset and the recent supervised UBnormal dataset. Code avail-able at https://github.com/orhir/STG-NF. 1.

Introduction
Research on human anomaly detection aims to detect un-usual events such as violence or people needing assistance due to an accident [9]. As these instances are time-critical, the surveillance footage requires immediate processing to enable instant support on-site. This raises the need for fast and reliable methods to detect abnormal events.
Although investigated extensively [1, 8, 13, 14, 23, 28, 29, 36, 39, 40, 46], anomaly detection in videos remains a difficult task. Utilizing conventional discriminative meth-ods is challenging as the amount of video data captured ex-ceeds our ability to label it manually. Furthermore, as ab-normal events are far more infrequent than normal ones, the goal is to detect anomalies using only normal events.
We desire an unsupervised algorithm that can detect ab-normal actions based on the context of past normal activi-ties. Moreover, we require the method to disregard nuisance parameters in the videos, such as background clutter, illumi-nation changes, and other factors unrelated to the extent of the human activity normality.
This is why we only use skeleton data. This represen-tation distills anomaly detection to human activity. Hu-man pose sequences are highly semantic, intuitive, and very low dimensional signals, incorporating information regarding the extent of a video’s normality [28, 29, 36].
They also provide interpretability for the abnormality in the scene, as each human’s pose sequence is given a nor-mality score. A side-effect of working only with skeleton representation is that it can reduce privacy violation and bias that might be associated with appearance-based meth-ods [3, 6, 9, 24, 30, 33, 38].
Previous pose-based methods build on autoencoders to reconstruct or predict future poses [29, 36]. They use re-construction error as a proxy for the normality score. How-ever, autoencoders tend to generalize strongly, i.e., anoma-lies can be reconstructed as well as normal samples [15].
Markovitz et al. [28] suggested using a Dirichlet process mixture to determine the normality score. However, these scoring algorithms are ineffective for anomaly detection as they highly depend on the autoencoder’s generalization ca-pabilities and performance [4, 17, 41]. The use of memory mechanisms [16, 32] or multi-modal data [14, 25, 31] can suppress this generalization to some extent but at the cost of additional memory consumption and computation.
In contrast, our end-to-end approach is based on a nor-malizing flows architecture, which learns the data distribu-tion and scores the samples according to their likelihood instead of relying on reconstruction error. We leverage the highly semantic pose representation to extend the architec-ture of normalizing flows, adapting it explicitly for human pose data using spatio-temporal graph convolution blocks.
Kirichenko et al. [21] show that while normalizing flows perform poorly when trained on pixel data, they can detect
OOD images when trained on high-level semantic represen-tations. But, unlike pixels, pose data holds substantial se-mantic value. Thus, abstracting videos to pose data forces
Figure 1. Framework Overview: An overview of our unsupervised framework. We perform pose estimation and tracking on the input video. Our Spatio-Temporal Graph Normalizing Flows (STG-NF) network processes each pose sequence separately. During training, our model learns a bijective mapping from data distribution PX (pose sequences) to a latent Gaussian distribution PZ . Training is done by minimizing the negative log-likelihood of the training data, leveraging the invertibility of our architecture, and using the change of variables formula. During inference, we estimate the probability of each pose sequence. normalizing flows to concentrate on semantic features. To our knowledge, we are the first to propose a pose-based nor-malizing flows approach for anomaly detection.
Utilizing low-dimensional pose data directly as a feature eliminates the need for autoencoders, used as feature ex-tractors. This results in an incredibly lightweight network that runs in real-time (∼1K parameters, 0.95G FLOPS, and inference speed of 189 FPS1), demanding negligible addi-tional resources for any device capable of running pose esti-mation. Note that the pre-trained pose estimator and tracker we use for preprocessing (we do not train or fine-tune this model) is of size 83M parameters. But, as we are not limited to a specific pose estimator, we may benefit from improve-ments in pose estimation algorithms such as better accuracy and run-time optimization.
Our framework is as follows. Given a sequence of video frames, we use pose estimation to extract the keypoints of every person in each frame and use a pose tracker to track the skeletons across the frames. Eventually, each person in a clip is represented as a temporal pose graph. Our net-work maps the training samples into a Gaussian-distributed latent space and calculates the probability of a human pose sequence. Figure 1 provides an overview of this framework.
Our model works both in the usual unsupervised setting, where only normal data is given for training, and in the su-pervised setting, where both normal and abnormal training data are provided.
In the supervised setting, we use our suggested normalizing flows model with a Gaussian Mix-ture Model prior, which forces the network to assign low probabilities to known abnormal samples.
We demonstrate our algorithm in the two settings. The 1On a single Nvidia Titan XP GPU. first is the widely used ShanghaiTech Campus dataset [23].
In this unsupervised setting, the training data consists of only normal videos, and the test data consists of both nor-mal and abnormal videos. For the supervised setting, we use the recent synthetic UBnormal dataset [1], which con-sists of both normal and abnormal training data. We also test this dataset in the common unsupervised setting.
Extensive experiments show that our model outperforms previous pose-based and appearance-based state-of-the-art methods for both settings. In addition, the ablation study shows our method is robust to noise and can generalize across different datasets. To summarize, we propose three key contributions:
• Introducing a normalizing flows architecture for both supervised and unsupervised video anomaly detection;
• Extending normalizing flows networks to tackle the unique aspects of human pose data;
• State-of-the-art AUC of 85.9% for ShanghaiTech and 79.2% for UBnormal anomaly detection benchmarks. 2.