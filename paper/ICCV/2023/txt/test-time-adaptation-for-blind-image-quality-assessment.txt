Abstract
While the design of blind image quality assessment (IQA) algorithms has improved significantly, the distribution shift between the training and testing scenarios often leads to a poor performance of these methods at inference time. This motivates the study of test time adaptation (TTA) techniques to improve their performance at inference time. Existing auxiliary tasks and loss functions used for TTA may not be relevant for quality-aware adaptation of the pre-trained model. In this work, we introduce two novel quality-relevant auxiliary tasks at the batch and sample levels to enable
TTA for blind IQA. In particular, we introduce a group con-trastive loss at the batch level and a relative rank loss at the sample level to make the model quality aware and adapt to the target data. Our experiments reveal that even us-ing a small batch of images from the test distribution helps achieve significant improvement in performance by updat-ing the batch normalization statistics of the source model. 1.

Introduction
The problem of image quality assessment (IQA) is ex-tremely important in diverse image capture, processing, and sharing applications. However, a reference image is often not available for quality assessment. No reference (NR) or blind IQA primarily deals with the question of predicting image quality without using a reference image. Such NR
IQA algorithms are often designed using machine learn-ing approaches. More recently, deep learning based ap-proaches have been extremely successful in achieving im-pressive performance. However, IQA applications are quite diverse and deal with several different distortions and distri-butional shifts. IQA models often have poor generalization ability and find it difficult to perform well under such shifts.
Test time adaptation (TTA) has emerged as an important approach to address distributional shifts at test time [8]. It has been shown that by modifying a few global parameters of the model using a suitable loss that does not require the
∗Authors contributed equally to this work
§https://github.com/subhadeeproy2000/TTA-IQA ground truth, one can significantly improve the performance of the model on the test data. Further, source-free adap-tation, where the source data on which the original model was trained is not available while updating the model, is a realistic setting. While such approaches have been studied extensively in image classification literature [31, 33], there is hardly any literature on TTA for IQA.
There are multiple challenges in designing TTA for IQA.
Typical losses used for TTA, such as entropy minimiza-tion [33], are not applicable for IQA. For example, IQA is often studied in the regression context. This makes it difficult to extend models based on class confidences [24] or class prototypes [10] for classification to IQA. Also, the relevance of other self-supervised tasks such as rotation pre-diction [14], context prediction [5], colorization [15], noise prediction [1], feature clustering [3] for adapting IQA mod-els is not clear. While contrastive learning has also been employed for TTA [20], such a framework is not explicitly based on contrasting image quality, and its relevance is also not clear.
Our main contribution is in the design of auxiliary tasks to enable TTA for IQA. We start with a source model trained on a large IQA dataset and fine-tune the model on individ-ual batches of test samples. The first task we introduce for adaptation is based on contrasting groups of low and high quality images in a batch. Thus, we exploit the initial knowledge of the source model and try to adapt it by enforc-ing quality relationships among the batch of samples. Such a group contrastive (GC) learning approach fits naturally to our setting to account for any errors on individual samples that the source model may be prone to.
In contrast to the GC learning that depends on the batch, our second auxiliary task is an image specific task based on distorted augmentations of different types. Here, our goal is to enable the model to rank the image quality of further dis-torted versions of each test sample. We explore the role of different distortion types to leverage the maximum benefit of this task. While GC learning is more effective when sam-ples in a batch are diverse in quality, the rank order based learning is more effective when the quality of the images is not extremely poor. Thus, a combination of the tasks
helps overcome the shortcoming of both tasks and leads to an overall superior performance.
We study the TTA problem under different settings of source and target datasets for multiple state of the art IQA models. Our results show significant improvements of the source model and the importance of TTA for IQA. We sum-marize our main contributions as follows:
• We propose source-free test time adaptation tech-niques in the context of blind image quality assess-ment to mitigate distribution shifts between train and test data.
• We formulate two novel quality-aware self-supervised auxiliary tasks to adapt to the test data distribution.
While group contrastive learning helps capture qual-ity discriminative information among several images within a batch, rank ordering helps maintain the qual-ity order between two different distorted versions of the same image.
• We show that our TTA method can significantly improve the performance of four different quality-aware source models, each on four different test IQA databases. 2.