Abstract 3D multi-object tracking (MOT) is vital for many ap-plications including autonomous driving vehicles and ser-vice robots. With the commonly used tracking-by-detection paradigm, 3D MOT has made important progress in recent years. However, these methods only use the detection boxes of the current frame to obtain trajectory-box association re-sults, which makes it impossible for the tracker to recover objects missed by the detector. In this paper, we present Tra-jectoryFormer, a novel point-cloud-based 3D MOT frame-work. To recover the missed object by detector, we gener-ates multiple trajectory hypotheses with hybrid candidate boxes, including temporally predicted boxes and current-frame detection boxes, for trajectory-box association. The predicted boxes can propagate objectâ€™s history trajectory information to the current frame and thus the network can tolerate short-term miss detection of the tracked objects.
We combine long-term object motion feature and short-term object appearance feature to create per-hypothesis feature embedding, which reduces the computational overhead for spatial-temporal encoding. Additionally, we introduce a
Global-Local Interaction Module to conduct information interaction among all hypotheses and models their spatial relations, leading to accurate estimation of hypotheses. Our
TrajectoryFormer achieves state-of-the-art performance on the Waymo 3D MOT benchmarks. Code is available at https://github.com/poodarchu/EFG. 1.

Introduction 3D multi-object tracking (MOT) is an essential and crit-ical task in the fields of autonomous driving and robotics.
It plays a vital role in enabling systems to accurately per-ceive their surrounding dynamic environment and make ap-propriate responses. Among the various sensors used in au-*Corresponding authors tonomous driving, LiDAR-based systems have emerged as a popular choice because they can capture accurate and de-tailed 3D information of the environment, enabling more precise object detection and tracking. Therefore, 3D MOT based on LiDAR point clouds shows great potential to im-prove the safety and efficiency of autonomous vehicles.
Tracking-by-detection is a popular paradigm that has demonstrated excellent performance on the 3D MOT task [34, 13, 27, 1, 15]. Previous methods, such as Center-Point [34] and SimpleTrack [13], rely on heuristic rules to associate objects across frames. These methods use manu-ally designed affinity metrics such as distance, intersection over union (IoU), and GIoU to match a history trajectory with a current detection box based on their positional rela-tionship. However, these heuristic rules are not robust as they cannot be trained and different categories may prefer different association metrics [13]. Moreover, these meth-ods only consider pair-wise position relationships between boxes, without considering comprehensive global context information, which often results in low-quality trajectories.
Other methods have attempted to enhance 3D MOT by modeling the spatial context among different boxes. Polar-MOT [8] adopts Graph Neural Network (GNN) to establish the spatial-temporal relationship between trajectories and different boxes, followed by edge classification to conduct association. Similarly, InterTrack [30] employs attention mechanisms to interact between trajectories and all boxes, generating the affinity matrix for association. These meth-ods generally leverage global context information, result-ing in improved tracking performance compared to heuristic methods. However, they still only rely on detection boxes for associating with existing trajectories, which limits the recall rate when the detector misses objects. Thus, incor-porating additional box candidates for association has great potential to improve the recall and performance of 3D MOT.
To overcome the limitations of existing approaches, we present TrajectoryFormer, a point-cloud-based 3D MOT 1
framework. Our framework generates multiple trajectory hypotheses with hybrid candidate boxes, enabling robust tracking of challenging objects. It employs a per-hypothesis feature encoding module and a cross-hypothesis feature in-teraction module to learn representative features for select-ing the best hypotheses. The per-hypothesis feature encod-ing module encodes both the appearance and motion infor-mation of each hypothesis, whereas the feature interaction module captures the contextual relationship among all hy-potheses. By leveraging multiple hypotheses and contextual information, TrajectoryFormer can enhance tracking perfor-mance in challenging scenarios with limited overhead.
Specifically, our framework first generates multiple tra-jectory hypotheses for each existing trajectory using two types of association candidate boxes: temporally predicted boxes and current frame detection boxes. Unlike existing approaches that only consider detection boxes at the cur-rent frame, we design a small motion prediction network that generate predicted boxes for several future frames of each history trajectory. This allows us to generate multiple trajectory hypotheses for an object by linking its history tra-jectory with both temporally predicted boxes (generated by its motion prediction at different past time steps) and cur-rent frame detection boxes (matched by nearest distance of box centers). Such a strategy enables the network to recover objects missed by the detector at the current moment and provides additional association options that can help correct trajectory errors caused by low-quality detection boxes.
After generating multiple trajectory hypotheses, Tra-jectoryFormer combines long-term object motion feature and short-term object appearance feature to create per-hypothesis feature embedding. More specifically, we adopt a PointNet-like [19] neural network to encode the motion feature for each trajectory hypothesis via encoding its long-term sequence boxes, and a small transformer-based neural network on the cropped object points to encode its appear-ance feature. Note that we only encode the object appear-ance feature based on short-term point clouds, since it not only requires very limited computational overhead but also avoids handling long-term object point variations. The con-catenation of two types of features that capture complemen-tary information for each trajectory hypothesis creates the per-hypothesis feature embedding. This embedding enables the evaluation of each hypothesis quality and facilitates the modeling of relationships among multiple hypotheses.
To jointly consider the trajectory association across all objects, we introduce a global-local Interaction module that models spatial relations of all trajectory hypotheses. It uses a transformer-based neural network to alternately conduct scene-level (e.g., all trajectory hypotheses within the scene) and ID-level (e.g., multiple trajectory hypotheses of each object) feature interactions on the hypotheses, leading to more accurate estimation of hypotheses. During inference,
TrajectoryFormer selects the hypothesis with the highest confidence as the best association result for each object.
The selected hypothesis is then refined using its extracted features to generate a more accurate trajectory.
In summary, our contributions are three-fold: 1) We propose TrajectoryFormer, a novel transformer-based 3D
MOT tracking framework, which generates multiple trajec-tory hypotheses that incorporate both predicted and detected boxes to better track challenging objects. 2) To better en-code each hypothesis, we incorporate both long-term tra-jectory motion features and short-term object appearance features. Additionally, the framework employs a global-local interaction module to model relationships among all hypotheses to adaptively determine the optimal trajectory-box association. 3) We demonstrate the effectiveness of our proposed approach through extensive experiments, and our framework achieves state-of-the-art results for 3D MOT on the challenging Waymo 3D tracking benchmark. 2.