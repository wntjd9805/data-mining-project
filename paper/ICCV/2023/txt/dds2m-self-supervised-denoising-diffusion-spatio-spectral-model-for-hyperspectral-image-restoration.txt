Abstract
Diffusion models have recently received a surge of inter-est due to their impressive performance for image restora-tion, especially in terms of noise robustness. However, exist-ing diffusion-based methods are trained on a large amount of training data and perform very well in-distribution, but can be quite susceptible to distribution shift. This is es-pecially inappropriate for data-starved hyperspectral im-age (HSI) restoration. To tackle this problem, this work puts forth a self-supervised diffusion model for HSI restora-tion, namely Denoising Diffusion Spatio-Spectral Model (DDS2M), which works by inferring the parameters of the proposed Variational Spatio-Spectral Module (VS2M) dur-ing the reverse diffusion process, solely using the degraded
HSI without any extra training data.
In VS2M, a varia-tional inference-based loss function is customized to en-able the untrained spatial and spectral networks to learn the posterior distribution, which serves as the transitions of the sampling chain to help reverse the diffusion process.
Beneﬁting from its self-supervised nature and the diffusion process, DDS2M enjoys stronger generalization ability to various HSIs compared to existing diffusion-based methods and superior robustness to noise compared to existing HSI restoration methods. Extensive experiments on HSI denois-ing, noisy HSI completion and super-resolution on a vari-ety of HSIs demonstrate DDS2M’s superiority over the ex-isting task-speciﬁc state-of-the-arts. Code is available at: https://github.com/miaoyuchun/DDS2M . 1.

Introduction
As a new trendy generative model, diffusion models [37, 13, 28, 38] have attracted signiﬁcant attention in the com-munity owing to their state-of-the-art performance in im-age synthesis [7]. In essence, diffusion model is a param-eterized sampling chain trained using a variational bound
*Corresponding Author
Figure 1. Comparison between DDRM and our self-supervised
DDS2M. (a) DDRM utilizes a denoising network pre-trained on a large number of extra training data to reverse the diffusion process. (b) Our DDS2M works by inferring the untrained neural networks’ parameters {θ, ζ} during the reverse diffusion process, only us-ing the degraded HSI y without any extra training data. The un-trained neural networks and the variational inference-based loss function constitute the proposed Variational Spatio-Spectral Mod-ule (VS2M). objective, which is equivalent to that of score-based mod-els [39, 40, 41]. After training, samples are generated by the sampling chain, starting from white noise and gradually denoising to a clean image.
Remarkably, diffusion models can go beyond image syn-thesis [11, 32, 20], and have been widely utilized in image restoration tasks, such as super-resolution [16, 46, 34, 6], in-painting [16, 46, 33, 21, 39, 41], denoising [16], and so on.
Among these methods, DDRM [16], a diffusion-based im-age restoration framework, has achieved powerful robust-ness to noise, which is also noteworthy for hyperspectral images (HSIs). HSIs often suffer from noise corruption due
to the limited light, photon effects, and atmospheric inter-ference [19]. This motivates us to inherit the powerful noise robustness of DDRM [16] to HSI restoration by capitalizing on the power of diffusion model for HSI restoration.
However, harnessing the power of the diffusion model for HSI restoration is challenging. The bottleneck lies in the poor generalization ability to HSIs in various scenar-ios. Existing diffusion-based methods are excessively de-pendent on the adversity and quantity of the training data, and often focus on a speciﬁc domain, such as the face. As a result, these methods may perform very well in-distribution, but can be quite susceptible to distribution shifts, resulting in degraded performance. This is particularly inappropriate for data-poor applications such as HSI restoration, where very limited HSIs are available for training [27]. This is because HSIs are much more expensive to acquire in real-world scenarios, compared to natural RGB images. In ad-dition, different sensors often admit large different speci-ﬁcations, such as the frequency band used, the spatial and spectral resolution. Therefore, a diffusion model trained on
HSIs captured by one sensor may not be useful for HSIs captured by other sensors. In addition to the generalization ability issues mentioned above, how to leverage the intrinsic structure of HSIs is also critical for harnessing the power of the diffusion model for HSI restoration. Bearing the above concerns in mind, an effective diffusion model tailored for
HSI restoration, which is able to generalize to HSIs in var-ious practical scenarios and leverage the intrinsic structure of HSIs, is highly desired.
To address the generalization ability problem mentioned above, one remedy is to use the emerging untrained neu-ral networks, such as those in [42, 36, 9]. These methods learn a generative neural network directly from a single de-graded image, rather than from a large volume of external training data. The rationale is that an appropriate neural network architecture, without training data, could already encode much critical low-level image statistical prior infor-mation. Owing to their training data-independent nature, untrained networks can usually generalize well to the wild data. Meanwhile, due to our need to ﬂexibly cope with vari-ous HSIs in real scenarios, untrained networks are rendered as a natural choice. In addition, their powerful expressive-ness allows the deployment of such untrained networks in the diffusion models for HSI restoration.
In this work, we put force a self-supervised Denoising
Diffusion Spatio-Spectral Model (DDS2M), which can clev-erly alleviate the generalization ability problem, while ex-ploiting the intrinsic structure information of the underly-ing HSIs. DDS2M is a denoising diffusion generative model that progressively and stochastically denoises samples into restored results conditioned on the degraded HSI and the degradation model after a ﬁnite time. Unlike existing diffu-sion models [37, 13, 38, 16, 46], which use a neural network pre-trained a large number of training data, DDS2M reverses the diffusion process by virtue of the proposed Variational
Spatio-Spectral Module (VS2M), solely using the degraded
HSI without any extra training data; see Figure 1 for visual comparison with DDRM [16].
Speciﬁcally, the proposed VS2M consists of two types of untrained networks (i.e., untrained spatial and spectral net-works) and a customized variational inference-based loss function. The untrained spatial and spectral networks lever-age the intrinsic structure of HSIs by modeling the abun-dance maps and endmembers derived from the linear mix-ture model [3], respectively. The variational inference-based loss function is customized to enable these untrained networks to learn the posterior distribution of the task at hand. The speciﬁc contributions of this work are summa-rized as follows:
• We propose a self-supervised Deep Diffusion Spatio-Spectral Model (DDS2M). Beneﬁting from its diffusion pro-cess and self-supervised nature, DDS2M enjoys stronger ro-bustness to noise relative to existing HSI restoration meth-ods and superior generalization ability to various HSIs rel-ative to existing diffusion-based methods. To the best of our knowledge, DDS2M is the ﬁrst self-supervised diffusion model that can restore HSI only using the degraded HSI without any additional training data.
• We design a variational spatio-spectral module (VS2M) to help reverse the diffusion process, which serves as the transitions of the sampling chain. VS2M is capable of ap-proximating the posterior distribution of the task at hand by leveraging the intrinsic structure of the underlying HSI.
• Extensive experiments on HSI denoising, noisy HSI com-pletion and super-resolution illustrate the superiority of
DDS2M over the existing task-speciﬁc state-of-the-arts, es-pecially in terms of the robustness to noise, and the gener-alization ability to HSIs in diverse scenarios. 2.