Abstract
Fully- and semi-supervised semantic segmentation of biomedical images have been advanced with the devel-opment of deep neural networks (DNNs). So far, how-ever, DNN models are usually designed to support one of these two learning schemes, unified models that support both fully- and semi-supervised segmentation remain lim-ited. Furthermore, few fully-supervised models focus on the intrinsic low frequency (LF) and high frequency (HF) information of images to improve performance. Pertur-bations in consistency-based semi-supervised models are often artificially designed. They may introduce negative
In this learning bias that are not beneficial for training. study, we propose a wavelet-based LF and HF fusion model
XNet, which supports both fully- and semi-supervised se-mantic segmentation and outperforms state-of-the-art mod-els in both fields. It emphasizes extracting LF and HF in-formation for consistency training to alleviate the learning bias caused by artificial perturbations. Extensive experi-ments on two 2D and two 3D datasets demonstrate the ef-fectiveness of our model. Code is available at https:
//github.com/Yanfeng-Zhou/XNet. 1.

Introduction
Semantic segmentation is a fundamental task in biomed-ical image analysis, where the goal is to assign a class la-bel to each pixel. Methods for semantic segmentation of biomedical images based on convolutional neural networks (CNNs) have achieved remarkable success [42, 47, 23, 8].
Some studies extend these methods to 3D and achieve promising results on volumetric segmentation [35, 10, 62, 37]. Recently, the combination of transformers and CNNs
*Corresponding author. has become popular [5, 54, 53, 20, 54]. Transformers can capture long-range dependencies [50, 13, 30] to compensate for the limited receptive fields of CNNs.
However, most of the existing methods focus on model architecture to better extract features [67, 38, 65]. Few methods explore the intrinsic LF and HF information of im-ages that may be useful for segmentation [58, 49].
For semantic segmentation of biomedical images, super-vised methods require large-scale labeled images, which are costly and time-consuming to produce. To alleviate this problem, researchers propose semi-supervised methods that learn with a small number of labeled images and a substan-tial number of unlabeled images [48, 51, 59]. The com-mon solutions include adversarial training [36, 46], pseudo-labeling [16, 60, 56] and consistency regularization [6, 12].
Consistency regularization is currently the best performing method [32, 34], it perturbs input images, intermediate fea-tures or output predictions, allowing models to learn consis-tency from the perturbation [26, 39, 34].
However, current perturbation strategies are artificially designed, such as rotation [26], noise addition [39], distance mapping [32] and dropout [39], etc. They may introduce negative learning bias, such as segmenting noisy images is equivalent to learning an extra denoising task.
Furthermore, fully- and semi-supervised semantic seg-mentation are regarded as two different research fields. Uni-fied models that simultaneously achieves state-of-the-art re-main limited.
To solve the above problems, we propose a wavelet-based LF and HF fusion model XNet. XNet can simulta-neously realize fully-supervised learning based on LF and
HF information fusion, and semi-supervised learning based on LF and HF outputs consistency. To be specific, we use wavelet transform to generate LF and HF images and feed them into XNet. XNet fuses their LF and HF information and then generates dual-branch segmentation predictions.
For supervised learning, segmentation predictions absorb the complete LF and HF information of raw images. For semi-supervised learning, dual-output pays different atten-tion to LF and HF information leading to consistency differ-ences. These differences are used for training on unlabeled images.
Motivation. For semantic segmentation problem, the
HF information generally represents image details, while the LF information are often abstract semantics (the LF and
HF images in Figure 2 intuitively show their differences).
The strategy of extracting and fusing different frequency information can help model better focus on LF seman-tics and HF details to improve performance. Furthermore, our model uses wavelet transform to generate LF and HF images for consistency difference-based semi-supervised learning. These consistency differences stem from the dif-ferent focus on LF and HF information, which alleviates the learning bias caused by artificial design.
Our contributions are summarized as follows:
• We propose a low and high frequency fusion model XNet, which achieves state-of-the-art in both fully- and semi-supervised semantic segmentation of biomedical images simultaneously.
• XNet uses wavelet transform to generate LF and HF images for consistency learning, which can alleviate the learning bias caused by artificial perturbations.
• Extensive benchmarking on two 2D and two 3D pub-lic biomedical datasets confirms the effectiveness of
XNet. 2.