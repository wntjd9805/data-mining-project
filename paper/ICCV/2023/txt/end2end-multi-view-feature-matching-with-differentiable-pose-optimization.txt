Abstract 1.

Introduction
Erroneous feature matches have severe impact on sub-sequent camera pose estimation and often require addi-tional, time-costly measures, like RANSAC, for outlier re-jection. Our method tackles this challenge by addressing feature matching and pose optimization jointly. To this end, we propose a graph attention network to predict im-age correspondences along with confidence weights. The resulting matches serve as weighted constraints in a differ-entiable pose estimation. Training feature matching with gradients from pose optimization naturally learns to down-weight outliers and boosts pose estimation on image pairs compared to SuperGlue by 6.7% on ScanNet. At the same time, it reduces the pose estimation time by over 50% and renders RANSAC iterations unnecessary. Moreover, we in-tegrate information from multiple views by spanning the graph across multiple frames to predict the matches all at once. Multi-view matching combined with end-to-end train-ing improves the pose estimation metrics on Matterport3D by 18.5% compared to SuperGlue.
Feature matching is a key component in many 3D vision applications such as structure from motion (SfM) or simul-taneous localization and mapping (SLAM). Conventional pose estimation is a multi-step process: feature detection finds interest points, for which local descriptors are com-puted. Based on the descriptors, pairs of keypoints from dif-ferent images are matched, which defines constraints in the pose optimization. A major challenge lies in the ambiguity of matching local descriptors by nearest-neighbor search, which is error-prone, particularly in texture-less areas or in presence of repetitive patterns. Hand-crafted heuristics or outlier filters become necessary to circumvent this problem to some degree.
Recent learning-based approaches [45, 48, 26, 35] in-stead leverage the greater image context to improve the matching, e.g., SuperGlue [45] introduces a graph neural network (GNN) for descriptor matching on an image pair.
Graph edges connect keypoints from arbitrary locations and enable reasoning in a broad context, leading to globally well-informed solutions compared to convolutional neural networks (CNN) with limited receptive field. The receptive field in SuperGlue, however, remains limited by the two-view setup, despite that more images are typically available in pose estimation tasks. Our idea is to further facilitate information flow by joining multiple views in the match-ing process. This way, we allow multi-view correlation to strengthen geometric reasoning and confidence prediction.
Joint matching of multiple images integrates well into pose estimation pipelines, as they typically solve for more than two cameras.
Additionally, we note that accurate feature matching, in and of itself, does not necessarily give rise to accurate pose estimation, as the spatial distribution of feature matches is essential for robust pose optimization. For instance, per-fectly precise matches may form a degenerate case (e.g., lying on a line) and thus have no value for pose optimiza-tion. In addition, confidence scores predicted by matching networks do not necessarily reflect the value of matches to-wards pose optimization. Feature matching and pose es-timation are thus tightly coupled problems, for which we propose a joint solution.
We encode keypoints and descriptors from multiple im-ages to construct a graph, where self-attention provides con-text awareness within the same image and cross-attention enables reasoning with respect to all other images. A GNN predicts matches along with confidence weights, which de-fine constraints on the camera poses that we optimize with a differentiable solver. The GNN is trained end-to-end us-ing gradients from the pose optimization. From this feed-back, the network learns to produce valuable matches for pose estimation and thereby learns effective outlier rejec-tion. We evaluate our method on image pairs and in a multi-view setting on ScanNet [14], Matterport3D [10], and
MegaDepth [30] datasets and show that our joint approach to feature matching and pose estimation improves over prior work on learned feature matching, enabled by the following contributions:
• We introduce an end-to-end trainable pose estimation that both guides confidence weights of feature matches in an unsupervised fashion and backpropagates gradi-ents to inform the matching network.
• We propose a multi-view graph attention network to learn feature matches simultaneously across multiple frames. 2.