Abstract
Thanks to the excellent global modeling capability of at-tention mechanisms, the Vision Transformer has achieved better results than ConvNet in many computer tasks. How-ever, in generating hierarchical feature maps, the Trans-former still adopts the ConvNet feature aggregation scheme.
This leads to the problem that the semantic information of the grid area of image becomes confused after feature aggregation, making it difficult for attention to accurately model global relationships. To address this, we propose the
Hierarchy Aware Feature Aggregation framework (HAFA).
HAFA enhances the extraction of local features adaptively in shallow layers where semantic information is weak, while is able to aggregate patches with similar semantics in deep layers. The clear semantic information of the aggregated patches, enables the attention mechanism to more accu-rately model global information at the semantic level. Ex-tensive experiments show that after using the HAFA frame-work, significant improvements have been achieved relative to the baseline models in image classification, object detec-tion, and semantic segmentation tasks. 1.

Introduction
The success of Transformer [37, 7, 18] in natural lan-guage processing (NLP) has inspired the research of Vision
Transformer in the field of computer vision [9]. Benefiting from the excellent global modeling and asymmetric data processing abilities of Transformer, Vision Transformers have witnessed new state of the arts in various vision tasks like image classification [9, 24, 34, 42, 35], object detection
[2, 59, 11, 54] and semantic segmentation [55, 44, 31, 38].
Compared to Convolutional Neural Networks (Con-vNets), Transformers inherently have better global model-*Hongmin Liu is the corresponding author
Figure 1. Comparison of feature aggregation based on Fixed Grids and the proposed Hierarchy Aware Feature Aggregation (HAFA).
Left: An image is conceptualized into multiple fixed grids.
In the shallow layers, the sampling center is fixed at the grid center, while in the deep layers, the semantic information is fragmented across multiple grids, leading to inaccurate semantic segmenta-tion. Right: In the shallow layers, HAFA adaptively changes the sampling center through learning, enhancing local information perception. In the deep layers, HAFA aggregates semantic similar patches to ensure the integrity of semantic information. Compared to the fixed grids in the left figure, HAFA performs better in se-mantic segmentation due to its hierarchy aware way of conducting adaptive feature aggregation.
ing capabilities. This is because the attention mechanism can directly model global relationships, so the Transformer does not need to establish global relationships through downsampling using sliding windows, as is the case of
ConvNets. Nevertheless, in order to directly incorporate the Transformer into existing frameworks for downstream tasks[2, 59, 55, 48], it is still crucial to generate hierarchical feature maps for the Transformer. However, currently al-most all Transformers, such as Swin Transformer [24] and
PVT [40], still generate hierarchical feature maps follow-ing the downsampling method of ConvNets. As shown on the left side of Figure 1, in this paradigm, the image is di-vided into multiple fixed grids and downsampling is per-formed using a fixed-size sliding window to generate hier-archical feature maps. It is worth noting that this approach can lead to a serious problem: one object may be separated into multiple grids, results in the complete semantic infor-mation of objects being destroyed, in other words, multiple fragmented semantic information of different objects can be contained within a same grid. After downsampling with a fixed-size sliding window, the semantic information within the grid becomes confused, which further leads to inaccu-racy in modeling global relationships through attention. As a result, downstream tasks may suffer from inaccurate seg-mentation or missed segmentation.
To address the above issue of ConvNets paradigm in building hierarchical vision Transformers, we propose a Hi-erarchy Aware Feature Aggregation framework (HAFA).
Specifically, HAFA consists of two parts: a Semantic In-formation Aggregation (SIA) module and a Local Adap-tive Feature Aggregation (LAA) module. The SIA mod-ule utilizes clustering to group patches with similar seman-tics in the feature space, which will be later aggregated for global relationship modeling using Transformer. Due to the fact that only patches with similar semantic information are aggregated, the semantic information is not confused after aggregation, which allows for accurate modeling of global relationships. Consequently, this approach effectively im-proves over inaccurate or missed segmentation in down-stream tasks. As clustering in the feature space will result in missing of spatial distribution of patches, we propose to preserve the fine-grained spatial distribution of patches in the SIA module by conducting patch merging only on queries in Transformer. On the other hand, the quality of establishing deep semantic information largely depends on the extraction of shallow features, and Transformers tend to learn better local texture information in shallow learn-ing than other layers, it is still necessary to use Transformer in the early stages. However, clustering shallow features is noisy due to the weaker semantic information contained in them. Therefore, we propose a Local Adaptive Feature
Aggregation module (LAA) for shallow layers. LAA learns from the local texture information obtained by the model, adaptively changes the sampling center of the patch, and enhances the capture of local, especially edge information.
Since the LAA module is feature-adaptive, it can effectively capture local information and avoid the loss of local infor-mation, such as edge information, caused by fixed grid seg-mentation and down-sampling by sliding windows. This ul-timately helps to address the problem of incomplete seman-tic information construction in deep layers.
In summary, the proposed HAFA framework uses the LAA module to enhance the learning of local texture information in shallow layers, enabling deeper layers to establish high-quality se-mantic information. In deep layers, the SIA module enables the model to establish global relationships more accurately.
LAA and SIA modules work together in a hierarchy-aware way.
The contributions are summarized as follows:
• A novel hierarchical feature aggregation framework called HAFA is proposed, which can be applied as a plugin to Transformers, resulting in a significant im-provement in performance with only a negligible in-crease in computational cost.
• Two feature-adaptive aggregation modules (LAA and
SIA) are introduced in HAFA, which contribute to build hierarchical Vision Transformers with differ-ent and dynamic relationship modeling in a hierarchy aware way.
• Extensive experimental results indicate that HAFA consistently improves over various models, especially in downstream dense prediction tasks, with notable improvements on small object detection and semantic segmentation. 2.