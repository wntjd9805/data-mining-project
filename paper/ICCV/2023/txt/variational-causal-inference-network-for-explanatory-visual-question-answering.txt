Abstract
Explanatory Visual Question Answering (EVQA) is a re-cently proposed multimodal reasoning task that requires an-swering visual questions and generating multimodal expla-nations for the reasoning processes. Unlike traditional Vi-sual Question Answering (VQA) which focuses solely on an-swering, EVQA aims to provide user-friendly explanations to enhance the explainability and credibility of reasoning models. However, existing EVQA methods typically predict the answer and explanation separately, which ignores the causal correlation between them. Moreover, they neglect the complex relationships among question words, visual re-gions, and explanation tokens. To address these issues, we propose a Variational Causal Inference Network (VCIN) that establishes the causal correlation between predicted answers and explanations, and captures cross-modal rela-tionships to generate rational explanations. First, we uti-lize a vision-and-language pretrained model to extract vi-sual features and question features. Secondly, we propose a multimodal explanation gating transformer that constructs cross-modal relationships and generates rational explana-tions. Finally, we propose a variational causal inference to establish the target causal structure and predict the an-swers. Comprehensive experiments demonstrate the superi-ority of VCIN over state-of-the-art EVQA methods. 1.

Introduction
Multimodal reasoning is a vital ability for humans and a fundamental problem for artificial intelligence [27, 39, 8].
Despite the promising performance of deep neural networks on various multimodal reasoning tasks [35, 37, 47, 34, 36], existing models typically generate reasoning results without explaining the rationale behind their results. Consequently, the low explainability of the generated results severely re-Figure 1. An example of Visual Question Answering (VQA) and
Explanatory Visual Question Answering (EVQA): VQA requires answering the question with a related image, while EVQA addi-tionally requires explaining the reasoning process. duces the credibility and restricts the application of reason-ing models. To address this issue, Chen and Zhao [11] re-cently proposed Explanatory Visual Question Answering (EVQA) task, which expands upon Visual Question An-swering (VQA) [5, 15] by requiring multimodal reasoning explanations. As shown in Figure 1, while traditional VQA aims to answer a question with a related image, EVQA goes further by demanding an explanation of the reasoning pro-cess. This extension creates the possibility for improved explainability and credibility of reasoning models.
Due to the definition of EVQA that the generated ex-planation should interpret the reasoning process of the in-ference model, it is crucial to maintain consistency between the predicted answer and explanation, or the inferred results can be incredible for users. However, existing methods for
EVQA [11] predict the answer and the explanation sepa-rately based on the input multimodal information, which ig-nore the consistency relation between two outputs and may infer inconsistent results. As shown in Figure 2, the state-on eliminating biased dependency, we propose to estab-lish the ignored causal correlation in the Structural Causal
Model (SCM) for EVQA. Additionally, we propose an au-tomatic Consistency (Con.) metric to evaluate the answer-explanation consistency and facilitate the research of cred-ible reasoning for EVQA. For Challenge 2, we design a multimodal explanation gating transformer to capture com-plex relationships among question words, visual regions, and explanation tokens, which can generate coherent and ra-tional explanations of the reasoning processes. To flexibly generate multimodal explanations, we adopt a multimodal gating network to dynamically select word tokens and vi-sual tokens for explanation generation. Comprehensive ex-periments on EVQA benchmark datasets demonstrate a sig-nificant performance boost of our proposed model com-pared with the state-of-the-art methods. In brief, the con-tributions of this paper are listed as follows:
• We propose an end-to-end Variational Causal Infer-ence Network (VCIN) by converting the target SCM into deep variational inference and designing a multi-modal explanation gating transformer to improve both the credibility and quality of the inferred results for
Explanatory Visual Question Answering (EVQA).
• We propose a novel variational causal inference to es-tablish the causal correlation between answer and ex-planation while reasoning, which can significantly im-prove the answer-explanation consistency of the pre-dicted results. Additionally, we propose an auto-matic metric named Consistency (Con.) to evaluate the answer-explanation consistency and facilitate the research of credible reasoning for EVQA.
• We design a multimodal explanation gating trans-former to capture complex relationships among ques-tion words, visual regions, and explanation tokens for generating rational multimodal explanations of reason-ing processes. Additionally, we utilize a multimodal gating network to flexibly generate visual and textual tokens in explanations.
• Extensive experiments on EVQA benchmark datasets indicate the superiority of the proposed method com-pared with the state-of-the-art methods in terms of both the quality and consistency of the inferred results. 2.