Abstract
We propose a novel approach to self-supervised learning of point cloud representations by differentiable neural ren-dering. Motivated by the fact that informative point cloud features should be able to encode rich geometry and ap-pearance cues and render realistic images, we train a point-cloud encoder within a devised point-based neural renderer by comparing the rendered images with real images on mas-sive RGB-D data. The learned point-cloud encoder can be easily integrated into various downstream tasks, including not only high-level tasks like 3D detection and segmentation but also low-level tasks like 3D reconstruction and image synthesis. Extensive experiments on various tasks demon-strate the superiority of our approach compared to existing pre-training methods. 1.

Introduction
We have witnessed the widespread success of supervised learning in developing vision tasks, such as image clas-In sification [17, 10] and object detection [43, 16, 22]. contrast to the 2D image domain, current 3D point cloud benchmarks only maintain limited annotations, in terms of quantity and diversity, due to the extremely high cost of la-borious labeling. Self-supervised learning (SSL) for point cloud [52, 18, 23, 20, 6, 41, 62, 48, 59, 56, 36, 25, 61, 31], consequently, becomes one of the main driving forces and has attracted increasing attention in the 3D research com-munity.
Previous SSL methods for learning effective 3D rep-resentation can be roughly categorized into two groups: contrast-based [52, 18, 23, 20, 6, 41, 62] and completion-based [48, 59, 56, 36, 25, 61, 31]. Contrast-based meth-ods are designed to maintain invariant representation un-der different transformations. To achieve this, informative samples are required. In the 2D image domain, the above challenge is addressed by (1) introducing efficient posi-tive/negative sampling methods, (2) using a large batch size
â€ denote corresponding author.
Figure 1. This work proposes a novel point cloud pre-training method via neural rendering, named Ponder. Ponder is directly trained with RGB-D image supervision, and can be used for vari-ous applications, e.g. 3D object detection, 3D semantic segmenta-tion, 3d scene reconstruction, and image synthesis. and storing representative samples, and (3) applying vari-ous data augmentation policies. Inspired by these works, many works [52, 18, 23, 20, 6, 41, 62] are proposed to learn geometry-invariant features on 3D point cloud.
Completion-based methods are another line of research for 3D SSL, which utilizes a pre-training task of recon-structing the masked point cloud based on partial observa-tions. By maintaining a high masking ratio, such a simple task encourages the model to learn a holistic understand-ing of the input beyond low-level statistics. Although the masked autoencoders have been successfully applied for
SSL in images [14] and videos [11, 47], it remains chal-lenging and still in exploration due to the inherent irregular-ity and sparsity of the point cloud data.
Different from the two groups of methods above, we pro-pose point cloud pre-training via neural rendering (Pon-der). Our motivation is that neural rendering, one of the most amazing progress and domain-specific design in 3D vision, can be leveraged to enforce the point cloud features being able to encode rich geometry and appearance cues.
As illustrated in Figure 1, we address the task of learning representative 3D features via point cloud rendering. To the best of our knowledge, this is the first exploration of neural rendering for pre-training 3D point cloud models. Specif-2.