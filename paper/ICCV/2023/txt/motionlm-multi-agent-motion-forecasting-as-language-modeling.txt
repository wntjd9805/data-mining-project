Abstract
Reliable forecasting of the future behavior of road agents is a critical component to safe planning in autonomous ve-hicles. Here, we represent continuous trajectories as se-quences of discrete motion tokens and cast multi-agent mo-tion prediction as a language modeling task over this do-main. Our model, MotionLM, provides several advantages:
First, it does not require anchors or explicit latent variable optimization to learn multimodal distributions. Instead, we leverage a single standard language modeling objective, maximizing the average log probability over sequence to-kens. Second, our approach bypasses post-hoc interaction heuristics where individual agent trajectory generation is conducted prior to interactive scoring. Instead, MotionLM produces joint distributions over interactive agent futures in a single autoregressive decoding process. In addition, the model’s sequential factorization enables temporally causal conditional rollouts. The proposed approach establishes new state-of-the-art performance for multi-agent motion prediction on the Waymo Open Motion Dataset, ranking 1st on the interactive challenge leaderboard. 1.

Introduction
Modern sequence models often employ a next-token pre-diction objective that incorporates minimal domain-speciﬁc assumptions. For example, autoregressive language mod-els [3, 10] are pre-trained to maximize the probability of the next observed subword conditioned on the previous text; there is no predeﬁned notion of parsing or syntax built in.
This approach has found success in continuous domains as well, such as audio [2] and image generation [49]. Leverag-ing the ﬂexibility of arbitrary categorical distributions, the above works represent continuous data with a set of discrete
⇤Work done during an internship at Waymo. aseff, bensapp
Contact:
@waymo.com
{
}
Vocabulary
…
…
Motion token sequence:
... t=1 t=2 t=T
Figure 1. Our model autoregressively generates sequences of dis-crete motion tokens for a set of agents to produce consistent inter-active trajectory forecasts. tokens, reminiscent of language model vocabularies.
In driving scenarios, road users may be likened to par-ticipants in a constant dialogue, continuously exchanging a dynamic series of actions and reactions mirroring the ﬂu-idity and complexity of communication. Navigating this rich web of interactions requires the ability to anticipate the likely maneuvers and responses of the involved actors. Just as today’s language models can capture sophisticated dis-tributions over conversations, can we leverage similar se-quence models to forecast the behavior of road agents?
A common simpliﬁcation to modeling the full future world state has been to decompose the joint distribution of agent behavior into independent per-agent marginal distri-butions. Although there has been much progress on this task [8, 47, 12, 25, 31, 5, 6, 21], marginal predictions are insufﬁcient as inputs to a planning system; they do not rep-resent the future dependencies between the actions of differ-ent agents, leading to inconsistent scene-level forecasting.
Of the existing joint prediction approaches, some apply
a separation between marginal trajectory generation and in-teractive scoring [40, 42, 29]. For example, Luo et al. [29] initially produce a small set of marginal trajectories for each agent independently, before assigning a learned potential to each inter-agent trajectory pair through a belief propaga-tion algorithm. Sun et al. [42] use a manual heuristic to tag agents as either inﬂuencers or reactors, and then pairs marginal and conditional predictions to form joint predic-tions.
We also note that because these approaches do not ex-plicitly model temporal dependencies within trajectories, their conditional forecasts may be more susceptible to spu-rious correlations, leading to less realistic reaction predic-tions. For example, these models can capture the cor-relation between a lead agent decelerating and a trail-ing agent decelerating, but may fail to infer which one is likely causing the other to slow down. In contrast, previ-ous joint models employing an autoregressive factorization, e.g., [36, 43, 39], do respect future temporal dependencies.
These models have generally relied on explicit latent vari-ables for diversity, optimized via either an evidence lower bound or normalizing ﬂow.
In this work, we combine trajectory generation and in-teraction modeling in a single, temporally causal, decod-ing process over discrete motion tokens (Fig. 1), leverag-ing a simple training objective inspired by autoregressive language models. Our model, MotionLM, is trained to directly maximize the log probability of these token se-quences among interacting agents. At inference time, joint trajectories are produced step-by-step, where interacting agents sample tokens simultaneously, attend to one another, and repeat. In contrast to previous approaches which man-ually enforce trajectory multimodality during training, our model is entirely latent variable and anchor-free, with mul-timodality emerging solely as a characteristic of sampling.
MotionLM may be applied to several downstream behavior prediction tasks, including marginal, joint, and conditional predictions.
This work makes the following contributions: 1. We cast multi-agent motion forecasting as a language modeling task, introducing a temporally causal de-coder over discrete motion tokens trained with a causal language modeling loss. 2. We pair sampling from our model with a simple roll-out aggregation scheme that facilitates weighted mode identiﬁcation for joint trajectories, establishing new state-of-the-art performance on the Waymo Open Mo-tion Dataset interaction prediction challenge (6% im-provement in the ranking joint mAP metric). 3. We perform extensive ablations of our approach as well as analysis of its temporally causal conditional predictions, which are largely unsupported by current joint forecasting models. 2.