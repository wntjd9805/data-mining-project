Abstract
Neural Radiance Field (NeRF) approaches learn the un-derlying 3D representation of a scene and generate photo-realistic novel views with high fidelity. However, most pro-posed settings concentrate on modelling a single object or a single level of a scene. However, in the real world, we may capture a scene at multiple levels, resulting in a lay-ered capture. For example, tourists usually capture a mon-ument’s exterior structure before capturing the inner struc-ture. Modelling such scenes in 3D with seamless switch-ing between levels can drastically improve immersive ex-periences. However, most existing techniques struggle in modelling such scenes. We propose Strata-NeRF, a single neural radiance field that implicitly captures a scene with multiple levels. Strata-NeRF achieves this by conditioning the NeRFs on Vector Quantized (VQ) latent representations which allow sudden changes in scene structure. We evalu-ate the effectiveness of our approach in multi-layered syn-thetic dataset comprising diverse scenes and then further validate its generalization on the real-world RealEstate10K dataset. We find that Strata-NeRF effectively captures stratified scenes, minimizes artifacts, and synthesizes high-fidelity views compared to existing approaches. https:
//ankitatiisc.github.io/Strata-NeRF/ 1.

Introduction
Novel view synthesis is an ill-posed problem widely en-countered in various areas such as augmented reality [24, 28], virtual reality [11], etc. A paradigm change for solving these kinds of problems was brought by the introduction of Neural Radiance Fields (NeRF) [34]. NeRFs are neu-ral networks that take in the spatial coordinates and camera parameters as input and output the corresponding radiance field. Earlier version of NeRFs enable the generation of high-fidelity novel views for bounded scenes, significantly improving over existing techniques like Structure From Mo-tion [47]. Further, the capability of NeRFs have been re-cently extended to model unbounded scenes by Mip-NeRF 360 [2]. This enabled NeRFs to model complex real-world
Figure 1. Top, wireframe view of a multi-layered stratified scene with three levels (monkey head inside sphere inside a cube). The camera colors indicate views of a specific level. Strata-NeRF en-ables high-quality reconstruction of such stratified scenes using a single neural network. scenes, where the scene content can exist at any distance from the camera.
However, similar to unboundedness in scenes, hierar-chies in scenes are also natural. For example, images cap-tured in a house can be categorized into images captured outside and inside across various rooms. Modelling such hi-erarchical scenes jointly for all levels through a NeRF could be particularly useful in cases of Virtual Reality applica-tions. As it would not require switching to a different NeRF for each level, reducing memory requirement and latency in switching. Further, as the different hierarchies of a scene usually share texture and architectural commonalities, it could lead to effective knowledge sharing and reduce the re-quirement of training independent models. For tackling the above novel objective, we introduce a paradigm of scenes that can be deconstructed into several tiers, termed “Strat-ified Scenes”. A “stratified” scene has several levels or
a new state-of-the-art. In summary,
• We first introduce the task of implicit representation for 3D stratified (hierarchial) scenes using a single ra-diance field network. For this, we introduce a novel synthetic dataset comprising of scenes ranging from simple to complex geometries.
• For implicit modelling of the stratified scenes, we pro-pose Strata-NeRF, which conditions the radiance field based on discrete Vector-Quantized (VQ) latents to model the sudden changes in scenes due to change in hierarchical level (i.e. strata).
• Strata-NeRF significantly outperforms the baselines across the synthetic dataset and generalizes well on the real-world scene dataset of RealState10k. 2.