Abstract
Contemporary domain adaptation offers a practical so-lution for achieving cross-domain transfer of semantic seg-mentation between labelled source data and unlabeled tar-get data. These solutions have gained significant pop-ularity; however, they require the model to be retrained when the test environment changes. This can result in unbearable costs in certain applications due to the time-consuming training process and concerns regarding data privacy. One-shot domain adaptation methods attempt to overcome these challenges by transferring the pre-trained source model to the target domain using only one target data. Despite this, the referring style transfer module still faces issues with computation cost and over-fitting prob-lems. To address this problem, we propose a novel frame-work called Informative Data Mining (IDM) that enables efficient one-shot domain adaptation for semantic segmen-tation. Specifically, IDM provides an uncertainty-based se-lection criterion to identify the most informative samples, which facilitates quick adaptation and reduces redundant training. We then perform a model adaptation method using these selected samples, which includes patch-wise mixing and prototype-based information maximization to update the model. This approach effectively enhances adaptation and mitigates the overfitting problem. In general, we pro-vide empirical evidence of the effectiveness and efficiency of IDM. Our approach outperforms existing methods and achieves a new state-of-the-art one-shot performance of 56.7%/55.4% on the GTA5/SYNTHIA to Cityscapes adap-tation tasks, respectively. The code will be released at https://github.com/yxiwang/IDM . 1.

Introduction
Semantic segmentation is a fundamental computer vision task that has made remarkable progress with the help of
*Zhaoxiang Zhang is the corresponding author.
Figure 1. We consider the one-shot domain adaptation scenario, where only one single target image is used to fit the trained source model. It is realistic for the adaptation model to tackle dynam-ically changing target environments, such as suddenly occurrent weather (e.g. foggy, rainy, night, snow). Our method aims to achieve quick adaptation for one-shot domain adaptation. vast amounts of pixel-level annotated training data. How-ever, collecting such large-scale datasets requires tremen-dous labeling efforts in terms of time and cost. For in-stance, annotating a single image in the Cityscapes dataset can take about 90 minutes and cost 1.5 dollars [7]. To re-duce this burden of labeling, previous cross-domain seman-tic segmentation approaches [24, 39, 26, 41, 53, 21, 56, 38] have been developed. These methods transfer the knowl-edge from label-rich synthetic data (source) [32, 33] to the unlabeled real-world data (target) [7], referred to as domain adaptive semantic segmentation (DASS).
Despite significant efforts in developing DASS methods, most of them still suffer from the following limitations.
First, existing approaches train an adaptation model from a specific source domain to a specific target domain. There-fore, they require retraining the model every time when the 1
test environment changes, which is inflexible and inefficient in handling a dynamic domain shift scenario. Second, these methods need access to the entire target dataset to achieve model adaptation, which is impractical in some realistic scenarios due to privacy or storage concerns. As depicted in Figure 1, an autonomous driving model often faces sud-den weather or illumination changes, resulting in a scarcity of images at the beginning of environmental shifts. There-fore, it is crucial for the model to rapidly adapt to the new conditions with a limited amount of target data. Although previous works [25, 49] have attempted to address the one-shot domain adaptation problem, the introduced style trans-fer module usually requires additional style images by an extra optimizing model. This makes it inefficient to adapt quickly to different scenarios.
In contrast to pioneering works, our method provides a new direction for OSDA by exploring the abundant infor-mation hidden in the source domain due to the rare target data accessible. To achieve this goal, two key ideas exist to address this problem. First, we select the most informa-tive samples for training, which can reflect the target distri-bution and reduce the redundant back-propagation process.
Second, we diversify the target distribution to alleviate the over-fitting problem caused by the limited availability of one-shot target data. To this end, we propose the Informa-tive Data Mining (IDM) approach, which includes a sample selection strategy and an efficient model adaptation tech-nique. Specifically, we first introduce an uncertainty-based selection criterion to identify the most informative training samples from the source data. These samples can reflect the target distribution and contribute significantly to model adaptation. Therefore, the sample selection criteria aim to filter the most informative images with 1) higher prediction uncertainty values and 2) higher diversity. Unlike existing works choosing low-uncertainty target samples to refine the target model, our method filters target-style-like source im-ages for training. On the other hand, we devise a model adaptation method seeking to alleviate the over-fitting prob-lem by diversifying the distribution of the target domain.
Concretely, we first diversify the semantic content of target data by a patch-wise mixing method and then use prototype-based information maximization to ensure the output of di-versity for the selected source data, which can significantly alleviate the over-fitting problem. With the proposed IDM method, the model can be efficiently adapted to the target data without over-fitting.
Our contributions can be summarized as follows: 1)
We propose a new efficient one-shot adaptation framework for cross-domain semantic segmentation, which aims at quickly adapting the trained source model to the target data with only hundreds of training iterations. 2) We propose a novel sample selection scheme to filter out the most infor-mative training samples for reducing redundant optimiza-tion and devise an uncertainty minimization training tech-nique for model adaptation.3) We show the efficacy and efficiency of our method by achieving a new state-of-the-art performance on one-shot domain adaptive semantic seg-mentation, with 56.7% mIoU on GTA5 to Cityscapes and 55.4% mIoU on SYNTHIA to Cityscapes. 2.