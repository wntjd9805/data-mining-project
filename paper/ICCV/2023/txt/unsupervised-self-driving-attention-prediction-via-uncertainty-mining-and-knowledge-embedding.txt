Abstract
Predicting attention regions of interest is an impor-tant yet challenging task for self-driving systems. Existing methodologies rely on large-scale labeled traffic datasets that are labor-intensive to obtain. Besides, the huge do-main gap between natural scenes and traffic scenes in current datasets also limits the potential for model train-ing. To address these challenges, we are the first to in-troduce an unsupervised way to predict self-driving atten-tion by uncertainty modeling and driving knowledge in-tegration. Our approach’s Uncertainty Mining Branch (UMB) discovers commonalities and differences from mul-tiple generated pseudo-labels achieved from models pre-trained on natural scenes by actively measuring the un-certainty. Meanwhile, our Knowledge Embedding Block (KEB) bridges the domain gap by incorporating driving knowledge to adaptively refine the generated pseudo-labels.
Quantitative and qualitative results with equivalent or even more impressive performance compared to fully-supervised state-of-the-art approaches across all three public datasets demonstrate the effectiveness of the proposed method and the potential of this direction. The code is available at https://github.com/zaplm/DriverAttention.
Figure 1. Illustration of the proposed unsupervised self-driving at-tention prediction model. Instead of relying on the ground truth labels provided by traffic datasets, our method only uses pseudo-labels generated from models pre-trained on natural scenes, and then refined the results by uncertainty mining and knowledge em-bedding. The red dashed line corresponds to the pre-training stage, the black dashed line refers to the training process, and the black solid line means the testing process. 1.

Introduction
With the huge development of autonomous driving, pre-dicting attention regions for self-driving systems [2; 41] has drawn rapid interest in the community. The predicted at-tention region provides rich contextual information to assist autonomous driving systems by locating salient areas in the
*Corresponding author. traffic scene [49; 50; 60]. Most importantly, these salient areas are always the riskiest areas, where small perception errors can cause great harm to driver’s safety [25]. There-fore, with a successful attention area prediction, computa-tion resources can be reallocated to enhance the perception accuracy in these fatal areas to reduce driving risks, as well as increase the explainability and improve the reliability of autonomous driving systems [28].
Numerous datasets [1; 13; 59] and methods [2; 27; 30;
38; 42; 59] have been proposed to address self-driving atten-tion prediction task. Though achieving encouraging perfor-mance, these methods are trained in fully-supervised ways on large-scale labeled datasets which are hard to build and unreliable. For example, one of the widely-used datasets in self-driving named DR(eye)VE [1] was collected in two months, by recording eight drivers taking turns driving on the same route to obtain fixation data. However, simply av-eraging the attention of eight drivers into one driving video will lead to the wrong attention target. Another common difficulty is the huge mismatch between the collected data and real-world environments. Another self-driving dataset
BDD-A [59] was constructed by asking 45 participants to watch the same recorded video and imagine themselves as the drivers. But, these simulated virtual environments in-evitably brought inconsistencies to real-world conditions for human labeling. Therefore, current fully-supervised methods suffer from potential biases in public datasets and then are too hard to extend to new environments. Fur-thermore, large-scale pre-trained models [4] have already demonstrated strong capability in representation learning, which can be beneficial to lots of downstream tasks. But how to bridge the domain gap between the specific situation (e.g. self-driving scenes) and the common data pre-trained model used (e.g. natural scenes) is still a challenge.
To address the above-mentioned issues, we propose a novel unsupervised framework to self-driving attention pre-diction, which means 1) we do not use any ground-truth labels given by self-driving datasets, 2) we only use pseudo-labels generated from models pre-trained on natural scene datasets, 3) we train a model on the source domain and to adapt it to the samples in the target domain (in our case is from natural to traffic scenes) following unsupervised do-main adaptation [16; 22; 53]. Specifically, our proposed model is achieved with two newly-designed parts: an uncer-tainty mining branch is proposed to exploit pseudo-labels’ uncertainties by aligning the various distributions and thus make the result reliable; another is a knowledge embedding block which is introduced to transfer the traffic knowledge into the natural domain by segmenting the focal traffic ob-jects with Mask-RCNN [17] pre-trained on MS-COCO [31] and then enhance each pseudo-label’s attention region.
In summary, our contributions can be listed as follows: (1) We propose a novel unsupervised framework to pre-dict self-driving attention regions, which is not relying on any labels on traffic datasets. To the best of our knowl-edge, this is the first work to introduce such an unsupervised method to this specific task. (2) We introduce an uncertainty mining branch to pro-duce highly plausible attention maps by estimating the com-monality and distinction between multiple easily obtained pseudo-labels from models pre-trained on natural scenes. (3) We design a knowledge embedding block by in-corporating rich driving knowledge to refine the produced pseudo-labels, which bridges the domain gap between au-tonomous driving and common domains (e.g. natural scene, daily life, and sports scene). (4) Extensive experiments on three public benchmarks with comparable or even better results compared with fully-supervised state-of-the-art approaches demonstrate the ef-fectiveness and superiority of the proposed method. 2.