Abstract 1. Image model-based optimization
As video analysis using deep learning models becomes more widespread, the vulnerability of such models to ad-versarial attacks is becoming a pressing concern. In par-ticular, Universal Adversarial Perturbation (UAP) poses a signiﬁcant threat, as a single perturbation can mislead deep learning models on entire datasets. We propose a novel video UAP using image data and image model. This en-ables us to take advantage of the rich image data and im-age model-based studies available for video applications.
However, there is a challenge that image models are limited in their ability to analyze the temporal aspects of videos, which is crucial for a successful video attack. To address this challenge, we introduce the Breaking Temporal Con-sistancy (BTC) method, which is the ﬁrst attempt to incor-porate temporal information into video attacks using im-age models. We aim to generate adversarial videos that have opposite patterns to the original. Speciﬁcally, BTC-UAP minimizes the feature similarity between neighboring frames in videos. Our approach is simple but effective at attacking unseen video models. Additionally, it is applica-ble to videos of varying lengths and invariant to temporal shifts. Our approach surpasses existing methods in terms of effectiveness on various datasets, including ImageNet,
UCF-101, and Kinetics-400. 1.

Introduction
Deep learning models have achieved remarkable perfor-mance in various computer vision tasks [5, 2, 33, 13, 1], including image and video recognition. However, there is growing concern about the robustness and reliability of these models, as they have been shown to be vulnerable to adversarial attacks [34, 6, 42]. Adversarial attacks use imperceptible perturbations to manipulate the inputs to pro-duce inaccurate predictions. These attacks can have serious consequences in various applications of deep neural net-works, such as autonomous vehicles and surveillance cam-eras [35] where false activity detection [19] can cause se-+
Image
Model
BTC-UAP
Image
Feature Space
Minimize Similarity
Pseudo Video 2. Video model-based adversarial attack
Videos
+ BTC-UAP
Repeated
…
…
…
ST-UAP
…
…
Video
Model
Video
Model
Soccer 
Juggling
Baby 
Crawling
All Videos Sharing repeated BTC-UAP
Figure 1: Overall illustration of Breaking Temporal
Consistency Method. We propose a novel approach to minimize the similarity between features of consecutive frames in video adversarial attacks. Please note that the il-lustrated BTC-UAP is not a real representation, but rather serves as a visual aid. The different colors represent the low similarity between features. rious consequences. Despite these concerns, the problem of adversarial attacks on video models remains largely un-solved.
Adversarial attacks can be broadly categorized into white-box [37, 14, 29] and black-box [39, 40] attacks.
White-box attacks exploit model information to generate adversarial examples, while black-box attacks are more challenging due to the lack of model access. In real-world scenarios, accessing the target model is often difﬁcult or im-possible, so black-box attacks are more practical. One way to launch black-box attacks is by leveraging the transfer-ability of adversarial examples [39, 40, 42, 7, 24], applying adversarial examples crafted using accessible source mod-els to the target models. Transfer-based attacks can also be cross-modal [40], which enables attackers to transfer adver-sarial examples between different modalities, such as image to video. For most cases, crafting adversarial examples still requires optimization for each individual adversarial exam-ple. On the other hand, Universal Adversarial Perturbations (UAPs) [26, 37, 14, 43, 23] poses a powerful threat as a sin-Repeat N times
Goal:  Generate (cid:2012)(cid:3015) (cid:4666)(cid:1828)(cid:1846)(cid:1829) (cid:3398) (cid:1847)(cid:1827)(cid:1842)(cid:4667) (cid:2196)
To Optimize (cid:2238)(cid:2170) (n (cid:3404) (cid:883)(cid:481) (cid:485) (cid:481) (cid:1840)(cid:484) (cid:4667) (cid:2206)(cid:2197)(cid:2200)(cid:2189) (cid:2196) (cid:3397) (cid:2238)(cid:2170) (cid:3041)(cid:2879)(cid:2869) (cid:3397) (cid:2012)(cid:3015) (cid:3041)(cid:2878)(cid:2869) (cid:3397) (cid:2012)(cid:3015) (Number of frames N)
Image Dataset
Choose
Randomly (cid:3397)(cid:2174)(cid:2183)(cid:2196)(cid:2186)(cid:2197)(cid:2195) (cid:2170)(cid:2197)(cid:2191)(cid:2201)(cid:2187)(cid:2778) (cid:3397)(cid:2174)(cid:2183)(cid:2196)(cid:2186)(cid:2197)(cid:2195) (cid:2170)(cid:2197)(cid:2191)(cid:2201)(cid:2187)(cid:2779)
Breaking Temporal Consistency Loss
Feature Space 1. Adversarial Loss (  ) (cid:2196) (cid:4667) (cid:2162)(cid:4666)(cid:2206)(cid:2183)(cid:2186)(cid:2204) (cid:1832)(cid:4666)(cid:1876)(cid:3028)(cid:3031)(cid:3049) (cid:3041)(cid:2879)(cid:2869)(cid:4667) (cid:4593) (cid:1832)(cid:4666)(cid:1876)(cid:3042)(cid:3045)(cid:3034) (cid:4667)
Boosting 
Feature Diversity (cid:4593)(cid:4593) (cid:4667) (cid:1832)(cid:4666)(cid:1876)(cid:3042)(cid:3045)(cid:3034)
Image
Model (cid:1832)(cid:4666)(cid:1876)(cid:3028)(cid:3031)(cid:3049) (cid:3041)(cid:2878)(cid:2869)(cid:4667) (cid:4593) (cid:1832)(cid:4666)(cid:1876)(cid:3042)(cid:3045)(cid:3034) (cid:4667) (cid:4593)(cid:4593) (cid:4667) (cid:1832)(cid:4666)(cid:1876)(cid:3042)(cid:3045)(cid:3034) (cid:1832)(cid:4666)(cid:1876)(cid:3028)(cid:3031)(cid:3049) (cid:3041)(cid:2879)(cid:2869)(cid:4667) (cid:2196) (cid:4667) (cid:2162)(cid:4666)(cid:2206)(cid:2183)(cid:2186)(cid:2204) (cid:1832)(cid:4666)(cid:1876)(cid:3028)(cid:3031)(cid:3049) (cid:3041)(cid:2878)(cid:2869)(cid:4667) 2. Temporal similarity Loss (  )
Figure 2: Details of Breaking Temporal Consistancy Method. Our goal is to create BTC-UAP for video attacks composed of N frames. We treat each frame of the UAP as an individual image, and add it to the original image to generate corresponding adversarial images. To ensure that these images are adversarial, we use an Adversarial Loss and prevent overﬁtting with the
Feature Diversity method. Additionally, while treating the adversarial images as a pseudo video, we apply the Temporal
Similarity Loss to the video frames and make each frame distinct from one another. gle perturbation can mislead deep learning models on entire datasets. This is considered a highly practical attack method in scenarios where it may be difﬁcult or impossible to op-timize adversarial perturbations for each individual dataset every time, such as real-time systems.
Our study aims to extend the applicability of UAPs gen-erated using image data and models, to the domain of video data and models. The overall scheme is illustrated in Fig. 1. This extension allows signiﬁcant beneﬁts as it allows us to leverage the wealth of image data [4] and image model-based studies [6, 42, 7, 24, 3] available for video applica-tions. Furthermore, generating UAPs using image data re-quires relatively less computation compared to using video data. However, we face signiﬁcant challenges due to the lack of access to video data [32, 17] and video models
[9, 45, 36]. There are two main challenges in generating adversarial videos using image models only [12, 30, 15].
Firstly, image models have limited capability in effectively analyzing the passage of time, which is a crucial aspect for videos. Secondly, UAPs should be applicable to unseen videos of varying lengths. Despite the importance of tempo-ral information, prior research has not been able to address these challenges.
As the ﬁrst paper to consider temporal information in video attacks using image models and data, our study ad-dresses this issue with the Breaking Temporal Consis-tancy (BTC) method, as illustrated in Fig. 2. Our target
UAP is a video consisting of N frames. Motivated by the high similarity pattern between neighboring frames in the original video, our UAP aims to generate adversarial videos that have opposite patterns to the original. To achieve this, we jointly optimize the adversarial and temporal aspects of the UAPs. First, to make the UAPs adversarial, we min-imize the feature similarity between the original and ad-versarial images in the feature space using the Adversar-ial Loss. We treat the frames of the UAPs as images, and add them to the original to create corresponding adversarial images. To ensure universality across unseen datasets and prevent overﬁtting, we incorporate randomness using the
Feature Diversity method. Second, we minimize the sim-ilarity between each frame of the UAPs using the Temporal
Similarity Loss. To achieve this, we treat the adversarial images as a pseudo-video sequence and minimize the simi-larity among them.
We named our proposed UAP as BTC-UAP, which stands for Breaking Temporal Consistancy Universal Ad-versarial Perturbation. To ensure length-agnosticity of
BTC-UAP, we apply it repeatedly until it covers entire frames of the video. Moreover, our approach is tempo-ral shift invariant, meaning that the starting point of the
UAP is irrelevant. Through extensive experiments on vari-ous datasets, including ImageNet, UCF-101, and Kinetics-400, we demonstrate that our simple but effective approach achieves superior performance compared to existing meth-ods.
To summarize our study:
• We propose a novel video UAP using image data and image models, which allows us to leverage the wealth of image data and image model-based studies available for video applications.
• Our study proposes the Breaking Temporal Consis-tancy method as the ﬁrst attempt to incorporate tempo-ral information into video attacks using image models.
Our BTC-UAP makes adversarial videos with oppo-site patterns to the original by minimizing the feature similarity between neighboring frames in videos.
(a) Original Video (b) Applied I2V-UAP (c) Applied BTC-UAP (ours) x e d n
I e m a r
F
Frame Index
Frame Index
Frame Index
Figure 3: The feature similarity of frames within videos.
This heatmap shows the average feature similarity between frames in the UCF-101 dataset, with brighter colors indicat-ing lower levels of similarity.
• BTC-UAP is both temporal shift invariant and length-agnostic, making it a highly practical video attack method that can be applied to videos of varying lengths and datasets. We demonstrate the effectiveness of
BTC-UAP through extensive experiments on various datasets, including ImageNet, UCF-101, and Kinetics-400, outperforming existing methods. 2.