Abstract
State-of-the-art lane detection methods often rely on spe-cific knowledge about lanes – such as straight lines and parametric curves – to detect lane lines. While the specific knowledge can ease the modeling process, it poses chal-lenges in handling lane lines with complex topologies (e.g., dense, forked, curved, etc.). Recently, dynamic convolution-based methods have shown promising performance by uti-lizing the features from some key locations of a lane line, such as the starting point, as convolutional kernels, and convoluting them with the whole feature map to detect lane lines. While such methods reduce the reliance on specific knowledge, the kernels computed from the key locations fail to capture the lane line’s global structure due to its long and thin structure, leading to inaccurate detection of lane lines with complex topologies. In addition, the kernels re-sulting from the key locations are sensitive to occlusion and lane intersections. To overcome these limitations, we pro-pose a transformer-based dynamic kernel generation archi-tecture for lane detection. It utilizes a transformer to gen-erate dynamic convolutional kernels for each lane line in the input image, and then detect these lane lines with dy-namic convolution. Compared to the kernels generated from the key locations of a lane line, the kernels generated with the transformer can capture the lane line’s global struc-ture from the whole feature map, enabling them to effec-tively handle occlusions and lane lines with complex topolo-gies. We evaluate our method on three lane detection bench-marks, and the results demonstrate its state-of-the-art per-formance. Specifically, our method achieves an F1 score of 63.40 on OpenLane and 88.47 on CurveLanes, surpassing the state of the art by 4.30 and 2.37 points, respectively.
*Corresponding Author. This work was supported in part by the Aus-tralian Research Council for funding of the ARC Training Centre in Op-timisation Technologies, Integrated Methodologies and Applications (OP-TIMA), under grant IC200100009. This work is also supported in part by the computational resources of the Spartan HPC system at UniMelb.
Figure 1. Examples of lanes lines in real scenes. The lane lines often have complex topologies, and are in diverse road scenarios. (a) The lane lines are blocked by vehicles. (b) The lane lines have forked and curved structures. (c) The lane lines are dense and blocked. (d) The lane lines are extremly curved. The lighting and weather conditions in these four pictures are also very different. 1.

Introduction
Lane detection is a fundamental task in Autonomous
Driving System (ADS) and Advanced Driver Assistance
System (ADAS). It plays a crucial role in the down-streaming tasks, such as driving route planning, lane keep-ing assist, and adaptive cruise control. As shown in Figure 1, lane detection in real scenes is very challenging, since lane lines usually have complex topologies such as dense, curved, and forked structures, and are often blocked by ve-hicles and pedestrians. Furthermore, to be deployed on real-time vehicle-based systems, the lane detection algorithms need to have high running speed.
Traditional lane detection methods [16, 29, 12, 18, 4] usually rely on hand-crafted features and post-processing techniques like Hough Transform [7]. These methods are limited in representation ability and robustness, making them difficult to handle the diversity of lane lines in dif-ferent road scenarios. Deep-learning-based lane detection
methods [32, 24, 2, 14, 25, 22, 8, 10, 17, 13] have recently achieved great success, thanks to the powerful representa-tion ability of convolutional neural networks (CNN). Exist-ing methods often rely on specific background knowledge – such as straight line anchors [32, 24, 2] and parametric curves [14, 25] – to detect lane lines.
Although the specific background knowledge can ease the modeling process, it causes difficulty in handling occlu-sions and lane lines with complex topologies (e.g., dense, forked, curved, etc.), as shown in Figure 1. For example, the anchor-based methods [32, 24, 2] detect lane lines by generating a set of anchors and then regressing the offsets from the anchors to the target lane lines. Unfortunately, the lane lines in real scenes are often curved or forked, which are difficult to be covered by the pre-defined anchors. The parameter-based methods [14, 25] represent lane lines with parametric curves and then detect lane lines by predicting the curve parameters. However, the extremely curved lane lines are difficult to be fit by the parametric curves.
Recently, dynamic convolution-based methods, e.g.,
CondLaneNet [13], have shown promising performance by considering the features from some key locations of a lane line, such as the starting point, as convolutional kernels, and convoluting them with the whole feature map to detect lane lines. By reducing the reliance on specific knowledge, these methods can achieve better results than the previous anchor-based and parameter-based methods. However, the kernels computed from the key locations fail to capture the lane line’s global information due to its long and thin structure, leading to inaccurate detection of lane lines with complex topologies. In addition, the kernels resulting from the key locations are sensitive to occlusions and lane intersections.
For instance, detecting starting points can be challenging when they are obscured by vehicles or pedestrians. Addi-tionally, it is difficult to differentiate between multiple lane lines that share the same starting point.
To overcome this limitation, we propose a transformer-based dynamic kernel generation architecture for lane de-tection, which further reduces the reliance on specific knowledge.
It utilizes a transformer to generate dynamic convolutional kernels for each lane line in the input image, and then detects these lane lines by convoluting these ker-nels with the whole feature map. Compared to the kernels generated from some key locations of a lane line, the ker-nels generated with transformer can capture the lane line’s global information from the whole feature map, enabling them to effectively handle occlusions and lane lines with complex topologies (as shown in Fig. 2(b) and (c)).
As illustrated in Fig. 2(a), the transformer employs a set of learnable parameter vectors, called lane queries, as lane templates to search for lane points throughout the whole feature map. It then fuses the features of the searched lane points by a weighted sum to generate dynamic kernels for
Figure 2. A simple illustration of the proposed method, and the comparison results between our method and CondLaneNet[13] uner the case of occlusion. In (a), the dashed box part corresponds to the transformer decoder part in Fig. 3, which consists of M layers. In each layer, the lane queries are updated with the lane features, and the lane features in the final layer is transformed to the dynamic kernels via MLPs. each lane line. Thus, the generated kernels can capture the global information of the lane lines. The lane queries repre-sent different lane prototypes, which are learned from anno-tated data and can approximate various lane lines. There are two sets of dynamic kernels that generate the heat map and offset map for each lane line, respectively. The final lane points are obtained from the heat maps and offset maps af-ter a post-processing. During training, a bipartite matching loss is calculated between the predicted and ground-truth lane lines based on Hungarian algorithm [9]. We test our method on three lane detection benchmarks, and the results demonstrate its state-of-the-art performance. 2.