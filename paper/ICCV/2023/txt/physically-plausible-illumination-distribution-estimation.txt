Abstract
A camera’s auto-white-balance (AWB) module operates under the assumption that there is a single dominant illumi-nation in a captured scene. AWB methods estimate an im-age’s dominant illumination and use it as the target “white point” for correction. However, in natural scenes, there are often many light sources present. We performed a user study that revealed that non-dominant illuminations often produce visually pleasing white-balanced images and, in some cases, are even preferred over the dominant illumi-nation. Motivated by this observation, we revisit AWB to predict a distribution of plausible illuminations for use in white balance. As part of this effort, we extend the Cube++ illumination estimation dataset [12] to provide ground truth illumination distributions per image. Using this new ground truth data, we describe how to train a lightweight neural network method to predict the scene’s illumination distri-bution. We describe how our idea can be used with existing image formats by embedding the estimated distribution in the RAW image to enable users to generate visually plausi-ble white-balance images. 1.

Introduction
Illumination estimation (IE) is the core operation per-formed by a camera’s auto white balance (AWB) module.
IE algorithms estimate the sensor’s response to scene il-lumination directly from an image in order to remove the color cast caused by the illumination. White balance cor-rection is performed by scaling the image’s color channels such that the estimated illumination value becomes achro-matic (i.e., R=G=B). Because the white balance correc-tion procedure results in the estimated illumination being mapped to the achromatic color line, the estimated illumi-nant is often called the “white point” of the image. White balance correction simulates the mechanism of color con-stancy in the human visual system [17] to achieve realistic and aesthetically pleasing images.
IE algorithms operate under the assumption that a sin-Figure 1. This figure shows the illumination distribution captured by the chrome ball on the SpyderCube calibration tool as described in Sec. 3. The distribution is plotted in the sensor’s chromaticity plane. Three different visually plausible white-balance corrections are shown based on illuminations (i.e., white points) sampled from the distribution. gle light source serves as the dominant illumination in the scene. Most IE datasets for benchmarking and training have only a ground truth illumination label per image. This is achieved by placing an achromatic calibration object (e.g., a grey patch, grey ball, or grey cube) in the scene and mea-suring the average color recorded by the camera sensor of the calibration object.
However, most real scenes contain multiple light
In outdoor environments, the sun, sky, and sources [1]. shadows can be treated as different illuminations.
In in-door environments, artificial light sources (e.g., tungsten, fluorescent, LED) and natural light from the windows of-ten illuminate the scene. In such cases, estimating a ground truth illumination value for a scene is highly dependent on the position and orientation of the gray patch. Moreover, white balance corrections performed using non-dominant environment illuminations often result in visually pleasing images (e.g., Fig. 1).
In this paper, we consider a new formulation of the IE problem that allows for a physically-plausible model of
Instead of estimating complex illumination in the scene. a single dominant illumination, we propose to estimate a global illumination distribution for the whole scene. Sam-pling the illumination distribution allows us to generate a family of plausible white-balance corrections.
Contribution We leverage the existing Cube++ dataset [12] to establish ground truth illumination distributions for 4198 images by extracting color values from the chrome ball present in the Cube++ images. We perform a user study to verify that images white balanced with illuminations sam-pled from the extracted distributions are preferred over re-sults obtained on samples from outside the distribution.
Next, we examine how to an illumination distribution given a single input image. We describe how to adapt spatially-varying illuminant estimation algorithms and a DNN-based method to predict an illumination distribution. These base-line methods, however, produce suboptimal results. To ad-dress this, we propose a lightweight neural network trained on our dataset using a two-dimensional earth mover’s dis-tance as a discrete version of the Wasserstein metric for the loss function. We show that a properly configured EMD provides compatibility with previous single-illuminant so-lutions estimated for angular and reproduction errors [16].
Our simple neural network provides better results than the baseline approaches. Finally, we discuss how an es-timated illumination distribution could be embedded and used within the DNG RAW file format. 2.