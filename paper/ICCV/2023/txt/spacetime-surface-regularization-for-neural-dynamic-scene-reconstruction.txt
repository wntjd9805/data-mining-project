Abstract
We propose an algorithm, 4DRegSDF, for the spacetime surface regularization to improve the fidelity of neural ren-dering and reconstruction in dynamic scenes. The key idea is to impose local rigidity on the deformable Signed Dis-tance Function (SDF) for temporal coherency. Our ap-proach works by (1) sampling points on the deformed sur-face by taking gradient steps toward the steepest direc-tion along SDF, (2) extracting differential surface geom-etry, such as tangent plane or curvature, at each sample, and (3) adjusting the local rigidity at different timestamps.
This enables our dynamic surface regularization to align 4D spacetime geometry via 3D canonical space more ac-curately. Experiments demonstrate that our 4DRegSDF achieves state-of-the-art performance in both reconstruc-tion and rendering quality over synthetic and real-world datasets. https://4dregsdf.github.io/ 1.

Introduction
Reconstructing 4D dynamic scenes from natural videos is one of the fundamental problems of vision tasks that are widely used in various fields, such as robotics, autonomous driving, virtual reality, and many more [6, 8, 14, 24, 32].
It requires an understanding of not just the geometry of scenes but also the texture, illumination, material proper-ties, and refraction for photo-realistic rendering.
How-ever, because of the difficulty in reconstructing static 3D geometry alone, learning the dynamics jointly has been a challenge that most conventional methods decomposed the task into multiple stages of geometry reconstruction, mo-tion representation, texture mapping, and illumination es-timation [6, 15, 33, 49, 68]. Such sequential pipelines that first reconstruct geometry and learn motion separately are not robust to many failure modes of each stage, resulting in inaccurate reconstruction, which is one of the major bottle-necks for photo-realistic and geometry-oriented spacetime scene understanding.
Work done during the internship at NVIDIA.
Figure 1. We present an implicit surface regularization method that fully utilizes the properties of SDF for robust shape reconstruction and novel-view rendering in dynamic scenes.
The recent advances in neural implicit representations, however, made accurate 3D reconstruction with differen-tiable volumetric rendering possible [40,41,46,50]. Milden-hall et al. [41] use sinusoidal encoding on the position as an input to multi-layered perceptrons (MLPs) to learn ap-pearance and geometry of the target static scene. Specifi-cally for photo-realistic rendering, neural radiance fields [4, 41, 54, 61, 63, 71, 79] mostly use density and color as the main output. However, the density representation can result in artifacts such as floaters and blurry boundaries since the density representation has high degrees of freedom [67,70].
For accurate 3D reconstruction, the Signed Distance Func-tion (SDF) started to gain traction for its high fidelity 3D surface reconstruction [26, 47, 70, 76, 81]. One of the key component for SDF learning is the Eikonol loss [25] which regularizes the SDF to have valid gradient. This acts as a strong regularization not just on the surface but on the en-tirety of the empty space.
However, the 4D surface reconstruction from monocu-lar RGB videos – which we reconstruct a dynamic scene – is still a highly ill-posed problem where we have to recon-struct geometry and the dynamics of the scene simultane-ously. Recent studies proposed to decompose the 4D space into a static geometry/texture (canonical model) and defor-mation to embed physical constraints into the 4D represen-tation [51, 54]. The decomposition of the geometry could regularize the 4D space, but many papers use additional cues such as flow, or depth prediction [16, 21, 31, 34, 35, 69, 72, 78]. Still, the reconstruction is an ill-posed problem and it often fails for two reasons: (1) learning deformation is sensitive to topological variation and illumination change that often requires energy minimization terms for stable training. [28, 51, 60, 66]; (2) using the density representa-tion – which has high degrees of freedom – could result in overfitting, floaters, and blurry reconstructions [29, 37, 44] as shown in Fig. 1. Thus, regularizing the spacetime domain is one of the most crucial parts of the 4D scene understand-ing in terms of geometry and graphics.
In this paper, we propose an algorithm for spacetime surface regularization that improves the fidelity of neu-ral rendering and reconstruction in dynamic scenes. The key idea is to enforce the local rigidity on the deformable
Signed Distance Function (SDF) for the 4D geometry rep-resentation. This allows us to (1) regularize the recon-struction using more explicit surface representation instead of fuzzy density measure [41]; (2) sample geometry effi-ciently for surface regularizations. Specifically, previous studies [37, 47, 70] show that Signed Distance Function can reconstruct geometries accurately with fewer images since learning the distance to the nearest surface to represent a surface is strong regularizations compared to the density function. In addition, the signed distance encodes not just distance but direction to the closest surface from gradients, thus allowing efficient surface sampling. Then, the sam-pled points are used to minimize the deformation energy and align 4D spacetime geometry via 3D canonical space.
We use three datasets to evaluate our method: one syn-thetic dataset from Pumarola et al. [54], and two real datasets: Park et al. [52] and Gao et al. [22]. Our method achieves state-of-the-art performance on both geometry rep-resentation and appearance as visualized in Fig. 1. We sum-marize our contributions as follows:
• Extends the energy minimization in conventional 4D surface reconstruction studies into learning neural dy-namic scene reconstruction.
• Regularize geometric properties of the 4D surface by the total variation of the curvature (TVC) and the ab-solute curvature of the SDF.
• Robust performance of rendering and reconstruction under the dynamic few-shot setup compared to recent implicit geometric regularization studies [20, 44]. 2.