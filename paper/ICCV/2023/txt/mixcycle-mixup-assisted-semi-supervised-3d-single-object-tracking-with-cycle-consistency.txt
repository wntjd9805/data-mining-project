Abstract 3D single object tracking (SOT) is an indispensable part of automated driving. Existing approaches rely heavily on large, densely labeled datasets. However, annotating point clouds is both costly and time-consuming. Inspired by the great success of cycle tracking in unsupervised 2D SOT, we introduce the first semi-supervised approach to 3D SOT.
Specifically, we introduce two cycle-consistency strategies for supervision: 1) Self tracking cycles, which leverage la-bels to help the model converge better in the early stages of training; 2) forward-backward cycles, which strengthen the tracker’s robustness to motion variations and the tem-plate noise caused by the template update strategy. Further-more, we propose a data augmentation strategy named SOT-Mixup to improve the tracker’s robustness to point cloud diversity. SOTMixup generates training samples by sam-pling points in two point clouds with a mixing rate and as-signs a reasonable loss weight for training according to the mixing rate. The resulting MixCycle approach gen-eralizes to appearance matching-based trackers. On the
KITTI benchmark, based on the P2B tracker [16], Mix-Cycle trained with 10% labels outperforms P2B trained with 100% labels, and achieves a 28.4% precision improve-ment when using 1% labels. Our code will be released at https://github.com/Mumuqiao/MixCycle. 1.

Introduction 3D single object tracking (SOT) plays a critical role in the field of autonomous driving. For example, given object detection [15, 33] results as input, it can output the neces-sary information for trajectory prediction [8]. The goal of
SOT is to regress the center position and 3D bounding-box (BBox) of an object of interest in a search area, given the point cloud (PC) patch and BBox of the object template.
*Corresponding author
Figure 1. Comparison of MixCycle and fully-supervised meth-ods [16, 25, 34], all trained with 1% labels on KITTI [5]. ‘Succ.’ and ‘Prec.’ represent Success and Precision, respectively.
This is a very challenging task because (i) point clouds ob-tained with, e.g., LiDAR sensors, suffer from occlusions and point sparsity, complicating the tracker’s task of finding the object of interest; (ii) the point distribution for an object may vary significantly, making it difficult for the model to learn discriminative object features.
To tackle the above challenges, existing 3D SOT mod-els [6, 16, 4, 9, 10, 25, 34, 18, 35] rely on large scale an-notated point cloud datasets for training. Unfortunately, obtaining annotations for this task, as for many 3D tasks, is extremely time-consuming. Furthermore, as shown in
Fig. 1, the performance of these methods degrades dramat-ically as the number of labeled samples decreases. Never-theless, no semi-supervised or unsupervised methods have been explored so far in 3D SOT.
As shown in Fig. 2, the matching-based tracker of [34] can still track the target at the very beginning of a sequence by predicting a motion offset relative to the reference coor-dinate, even though there are no points in the template for appearance matching. This indicates that the appearance
Figure 2. We observe that appearance matching-based trackers can learn the objects motion distribution and track them even in the absence of points for appearance matching. For instance, BAT [34] manages to track objects in extremely sparse point clouds. matching-based trackers can learn motion information. By contrast, in 2D SOT, many trackers [23, 24, 36, 29] employ cycle consistency to leverage unsupervised data. Specifi-cally, they encourage forward and backward tracking to pro-duce consistent motions. In principle, we expect to apply this idea to 3D SOT and make trackers to learn the object’s motion distribution in unlabeled data. However, transfer-ring these 2D methods directly to 3D is challenging. First, since the point cloud is sparse and the environment is clut-tered with objects, it is hard to find meaningful patches to use as pseudo labels for training. Second, unsupervised 2D
SOT methods rely on the assumption that the target appears in every frame of the sequence. Unfortunately, this assump-tion is not always satisfied in point cloud datasets such as
KITTI [5], NuScenes [1], and Waymo [20]. This is because they are built for the multi-object tracking task, and can-not guarantee that the tracking object exists in the whole sequence.
In this paper, we introduce a label-efficient way to train 3D SOT trackers. We call it MixCycle - a 3D SOT ap-proach based on a novel SOTMixup data augmentation strategy for semi-supervised Cycle tracking. Specifically, we first develop a tracking framework exploiting both self and forward-backward tracking cycles. Self tracking con-sistency is performed to cover the object point cloud ap-pearance variation, and forward-backward consistency is built for learning the object’s motion distribution. Second, we present a data augmentation method for 3D SOT called
SOTMixup, which is inspired by the success of mixup [31] and Manifold mixup [22]. Without changing the total num-ber of points in the search area, SOTMixup samples points in a random point cloud and the search area point cloud ac-cording to the mixing rate and generates training samples.
Specifically, the random point cloud is sampled from the la-beled training set. SOTMixup thus increases the tracker’s robustness to point cloud variations. We evaluate MixCycle on KITTI, NuScenes, and Waymo. As shown in Fig. 1, our experiments clearly demonstrate the label efficiency, gener-alization and remarkable performance of our method on the 3D SOT task.
Contributions: (i) We propose the first semi-supervised 3D SOT framework. It exploits self and forward-backward consistency as supervision and generalizes to appearance (ii) We introduce a SOTMixup matching-based trackers. augmentation strategy that increases the tracker’s robust-ness to point distribution variations and allows it to learn motion information in extreme situations. (iii) Our frame-work demonstrates a remarkable performance in terms of label efficiency, achieving better results than existing super-vised methods in our experiments on KITTI NuScenes, and
Waymo when using fewer labels. In particular, we surpass
P2B [16] trained on 100% labels while only using 10% la-bels. 2.