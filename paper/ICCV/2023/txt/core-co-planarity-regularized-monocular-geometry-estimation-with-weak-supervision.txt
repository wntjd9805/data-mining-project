Abstract
The ill-posed nature of monocular 3D geometry (depth map and surface normals) estimation makes it rely mostly on data-driven approaches such as Deep Neural Networks (DNN). However, data acquisition of surface normals, es-pecially the reliable normals, is acknowledged difficult.
Commonly, reconstruction of surface normals with high quality is heuristic and time-consuming. Such fact urges methodologies to minimize dependency on ground-truth normals when predicting 3D geometry. In this work, we de-vise CO-planarity REgularized (CORE) loss functions and
Structure-Aware Normal Estimator (SANE). Without involv-ing any knowledge of ground-truth normals, these two de-signs enable pixel-wise 3D geometry estimation weakly su-pervised by only ground-truth depth map. For CORE loss functions, the key idea is to exploit locally linear depth-normal orthogonality under spherical coordinates as pixel-level constraints, and utilize our designed Adaptive Polar
Regularization (APR) to resolve underlying numerical de-generacies. Meanwhile, SANE easily establishes multi-task learning with CORE loss functions on both depth and sur-face normal estimation, leading to the whole performance leap. Extensive experiments present the effectiveness of our method on various DNN architectures and data bench-marks. The experimental results demonstrate that our depth estimation achieves the state-of-the-art performance across all metrics on indoor scenes and comparable performance on outdoor scenes. In addition, our surface normal estima-tion is overall superior. 1.

Introduction
Depth and surface normals are essential elements of 3D geometry. With the assistance of surface normals, depth map is able to faithfully describe the characteristics of the 3D scenes [4], which benefits various 3D applications, e.g.,
Figure 1: Our weakly supervised monocular 3D geometry estimation. CORE loss functions distinguish our method from others.
Instead of proposing surface normal candi-dates in local or global depth regions, we properly regular-ize and utilize the pixel-level depth-normal constraints for pixel-wise loss functions, which enable the efficient end-to-end training with only ground-truth depth map. 3D reconstruction [33, 4], augmented reality [18] and au-tonomous driving [16]. To recover 3D geometry, monoc-ular depth and surface normal estimation provide the most convenient solutions, and meanwhile define the challenging ill-posed problems.
Recent approaches mostly tackle these two ill-posed problems as genuine data-driven tasks by DNN regression or classification. However, it is widely acknowledged that data acquisition of surface normals is not a straightforward task [22, 8, 41, 3]. Particularly, the reliable surface normals are much more difficult to be obtained [22, 8, 3]. There are various commercial sensors such as LiDAR and ToF to acquire depth map directly, but no alternative available for surface normals. To acquire surface normals, the com-mon practice is to involve least-square plane fitting from the depth maps [41]. Unfortunately, these depth maps cap-tured by consumer-level sensors are usually contaminated by noises, resulting in deteriorated quality on generated surface normals [22, 41, 3]. As a compromise, heuristic and time-consuming post-processing is commonly involved during preparation of the ground truth normals [22, 8].
It is certainly a meaningful advantage to be able to pre-dict surface normals by depending less or none of ground-truth normals. One idea is to employ pre-trained surface normal estimation network, followed by refinement that makes use of depth-normal consistency [38, 32, 34, 4]. On the condition of pre-training, the later refinement is effec-tive even without ground-truth normals. However, the pre-training still involves the ground truth as prerequisites, and the depth-normal consistency is utilized for building refine-ment rather than guiding regression from scratch. Another idea is about the proposal of surface normal candidates from depth map or point cloud, including differentiable least-square [32, 30, 31], local differentiation [17, 20] and ran-dom sampling [41, 29]. Nevertheless, when the proposal of depth region shrinks to a small local area or finally pixel level, suboptimal and noisy surface normal candidates could appear. At this time, more supervision by ground-truth nor-mals are demanded [17, 20, 29]. As for the global proposal, it would suffer from computational burden and insufficient local features [32, 30, 31, 41].
In this work, we propose novel Co-planarity Regularized (CORE) loss functions derived from regularized spheri-cal depth-normal constraints at pixel level. These CORE loss functions establish pixel-wise surface normal regres-sion weakly supervised by only ground-truth depth map.
It is worth noting that we particularly express pixel-level depth-normal constraints with spherical coordinates, and regularize these constraints by the polar view. Similar to the occurrence of suboptimal surface normal candidates, depth-normal constraints are progressively weakened towards the pixel level, resulting in the emergence of degeneracies dur-ing back-propagation (see Sec. 3.1). By re-formulating depth-normal constraints under spherical coordinates, we observe that the degeneracies are mostly attributed to the polar angle collapse as shown in Fig. 2. To counter this, we devise a novel Adaptive Polar Regularization (APR) term as a part of CORE loss functions. This term adaptively penal-izes polar angle estimation at the sub-optimal state, thus re-solving the degeneracies. As a result, the regularized spher-ical depth-normal constraints can be used as stable pixel-level constraints that serve as loss functions to efficiently guide surface normal regression from scratch. Moreover, our surface normal prediction is visualized in Fig. 1 and
Sec. 4, which presents plenty of local geometry details.
Another advantage of our method is that CORE loss functions are perfect for multi-task learning on both depth and surface normal estimation. Accordingly, we design a
Structure-Aware Normal Estimator (SANE) that collabo-Figure 2: The polar angle collapse. When depth supervision is shrinking towards the pixel level, the depth-normal con-straints are progressively weaken, which leads to the overall prediction distribution of polar angle ˆθ excessively concen-trated near 0 (the green histogram). The polar angle esti-mates collapse in ranges other than ≈ 0. After regularized by our APR, these pixel-level constraints become feasible and stable pixel-wise CORE loss functions that recover po-lar estimation from the collapse (the blue histogram). rates with our CORE loss functions. SANE can be easily applied as a side branch to existing encoder-decoder archi-tectures of depth estimation as shown in Fig. 3. Driven by
CORE loss functions, both depth estimation from the origi-nal architecture and surface normal estimation from SANE mutually achieves performance leap.
Our main contributions are as follows:
• We devise CORE loss functions from the pixel-level constraints of depth-normal orthogonality. Without any pre-training or surface normal candidates, CORE loss functions enable pixel-wise surface normal regres-sion in a weakly supervised manner by only ground-truth depth map.
• We propose SANE to collaborate with CORE loss functions for multi-task learning. SANE can be eas-ily plugged to existing encoder-decoder approaches of depth estimation without breaking their integrity, which meanwhile benefits the whole performance.
• We achieve steady depth enhancement and superior surface normal prediction. For depth estimation, the experimental results show new state-of-the-art perfor-mance across all metrics on NYUv2 and ScanNetv2, and comparable performance on KITTI. For surface normal estimation, despite of weak supervision, it is even comparable with relevant supervised methods. 2.