Abstract
The problem of realistic VQA (RVQA), where a model has to reject unanswerable questions (UQs) and answer an-swerable ones (AQs), is studied. We first point out 2 draw-backs in current RVQA research, where (1) datasets contain too many unchallenging UQs and (2) a large number of an-notated UQs are required for training. To resolve the first drawback, we propose a new testing dataset, RGQA, which combines AQs from an existing VQA dataset with around 29K human-annotated UQs. These UQs consist of both fine-grained and coarse-grained image-question pairs gen-erated with 2 approaches: CLIP-based and Perturbation-based. To address the second drawback, we introduce an unsupervised training approach. This combines pseudo
UQs obtained by randomly pairing images and questions, with an RoI Mixup procedure to generate more fine-grained pseudo UQs, and model ensembling to regularize model confidence. Experiments show that using pseudo UQs sig-nificantly outperforms RVQA baselines. RoI Mixup and model ensembling further increase the gain. Finally, hu-man evaluation reveals a performance gap between humans and models, showing that more RVQA research is needed.
Code and dataset is released on https://github. com/chihhuiho/RGQA. 1.

Introduction
Visual Question Answering (VQA) is a challenging task that requires a machine to understand a question in natural language, perceive an image, and produce an answer. De-spite extensive research in VQA [3, 12, 19, 36, 20, 42, 7, 54], little attention has been given to VQA robustness. In this work, we consider robustness to unanswerable ques-tions (UQs), which cannot be answered by image inspec-tion, as in Fig. 1(b). This is opposed to the traditional an-swerable questions (AQ), such as in Fig. 1(a).
Lack of robustness to UQs is problematic because, in the
*The first two authors contributed equally to this work.
Figure 1: Realistic VQA. In VQA, a vision system answers a question by inspection of an image. However, existing approaches have no awareness if the question is answerable (AQ), such as in (a), or unanswerable (UQ), as in (b). A realistic VQA system only answers AQs. (c) RVQA performance of prior (yellow) vs. proposed (blue) models. absence of image information, the VQA system frequently resorts to the answer statistically most correlated with the question. In the figure, the absence of food in (b) entices the robot to pick the answer corresponding to the “side of food” most commonly “cut” in the dataset, which happens to be the “top” (perhaps because the dataset is rich in cake images). The problem is that a decision by the robot to act on this answer would be catastrophic for the cat in the scene.
More generally, the inability to reject UQs signals a deeper perceptual deficiency and exposes VQA systems to attacks.
Vulnerability to UQs can create safety hazards for indoor robots [2] or assistants for the visually impaired [14] and reduces user trust in VQA models (see appendix for vari-ous examples from the recent large-scale BLIP model [29]).
When faced with a UQ, the VQA system should refuse to answer or ask for more information. More precisely, it should assess the question, decide to (a) “accept” or “re-ject” it, and only (b) answer the accepted questions. Since this resembles the idea of a “realistic model” for classifica-tion [50, 48], we denote it realistic VQA (RVQA).
Although some prior works have addressed RVQA, ex-isting formulations are not conducive to practical RVQA
systems, for three reasons. First, existing formulations ad-dress the supervised training of RVQA models. This, how-ever, requires a significant number of annotated UQs [40, 35, 14]. The collection of a set of annotated UQs large enough to train a modern VQA network is expensive, fre-quently not even plausible. This is compounded by the ex-istence of many types of UQs: training on one type does not guarantee generalization to another. Second, prior datasets generate UQs by randomly paring images and questions from an existing VQA dataset [40, 35, 21, 45]. This, how-ever, tends to produce obviously unrelated pairs of images and questions with low semantic similarity, that are easy to reject.
In the real world, RVQA models must be able to handle both simple and challenging UQs. Finally, the
VQA datasets that support RVQA, such as VizWiz [14], are designed for a specific application domain, frequently con-taining images with few objects. This prevents the modeling of complex image-question relationships.
To address these drawbacks, we consider the problem of unsupervised RVQA. We start by curating a new evaluation dataset for this task, based on testdev set of the widely used
GQA dataset [19]. The new dataset, denoted as realistic
GQA (RGQA), is composed of 26, 591 AQs in the testdev set of GQA and 29, 046 additional human-annotated UQs.
To penalize RVQA models that overfit on a specific type of
UQs, we generate candidate UQ by two methods. CLIP-based UQ generation produces candidate UQs by retrieving questions sorted by CLIP [39] similarity score between im-age and question. Perturbation-based (PT-based) UQ gen-eration perturbs the object, attribute, and relation phrases in a question. For each method, we further generate a set of easy and a set of hard candidate UQs, leading to a total of four RGQA subsets. All candidate UQs are finally anno-tated by humans, to guarantee they are unanswerable.
Since each AQ in RGQA is complemented by its answer, the dataset enables measuring the accuracy of both AQ/UQ detection and VQA accuracy. For this, we propose the
ACC-FPR curve [9], a joint measure of VQA accuracy for
AQs and UQ rejection performance. This is complemented by introducing 3 new unsupervised RVQA methods that es-tablish a set of baselines for future RVQA work. These are classifiers with a binary output per class, which elicit a re-jection when all class outputs are below a threshold. Three methods differ in training strategy and are shown capable of producing RVQA models that both reject UQs and answer
AQs correctly, outperforming prior RVQA methods.
The first is to train the classifier with pseudo UQs, ob-tained by randomly pairing images and questions. This suf-fers from the fact that pseudo UQs are noisy and not always challenging. The second improves the sampling of image-question pairs, by using a RoI Mixup strategy to encourage the model to spot fine-grained mismatches between image and question during training. The third address the limita-tions of random sampling at the classifier output, by ensem-bling multiple RVQA models. Experiments show that all strategies enhance RVQA performance and that they can be combined to achieve best results. As shown in Fig. 1(c), this combination (blue) significantly exceeds the performance of existing VQA models (yellow) under the joint objective of rejecting UQs and correctly answering AQs.
Overall, three contributions are made to VQA. First, we introduce RGQA, a new challenging testing dataset for evaluating RVQA. It contains both fine- and coarse-grained image-question pairs which better align with real-world sce-narios than previous datasets. Second, we propose an unsu-pervised training strategy that uses free pseudo UQs, com-bining random sampling, RoI Mixup, and model ensem-bling. Finally, extensive experiments demonstrate the effec-tiveness of the proposed methods over prior RVQA meth-ods. We also show that the proposed models under-perform humans, which encourages future work in the RVQA prob-lem. 2.