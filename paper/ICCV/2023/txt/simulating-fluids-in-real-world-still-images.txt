Abstract realistic results. Code, and dataset are publicly available.
In this work, we tackle the problem of real-world fluid animation from a still image. The key of our system is a surface-based layered representation, where the scene is decoupled into a surface fluid layer and an impervi-ous background layer with corresponding transparencies to characterize the composition of the two layers. The ani-mated video can be produced by warping only the surface fluid layer according to the estimation of fluid motions and recombining it with the background.
In addition, we in-troduce surface-only fluid simulation, a 2.5D fluid calcula-tion, as a replacement for motion estimation. Specifically, we leverage triangular mesh based on a monocular depth estimator to represent fluid surface layer and simulate the motion with the inspiration of classic physics theory of hy-brid Lagrangian-Eulerian method, along with a learnable network so as to adapt to complex real-world image tex-tures. Extensive experiments indicate our methodâ€™s com-petitive performance for common fluid scenes and better ro-bustness and reasonability under complex transparent fluid scenarios. Moreover, as proposed surface-based layer rep-resentation and surface-only fluid simulation naturally dis-entangle the scene, interactive editing such as adding ob-jects and texture replacing could be easily achieved with
*Equal contribution and joint first authorship. (cid:0)Corresponding authors. 1.

Introduction
Given an image of a scene containing liquid such as streams and waterfalls, humans can imagine how the liq-uid in the still image would move. The problem of ani-mating fluid from a single image has become a blooming topic recently studied by a series of work [6, 11, 27, 9, 21].
Their general pipeline can be summarized as: (1) estimat-ing optical flow that indicates the movement of liquid and (2) synthesizing future frame image based on the motion estimation. Although these methods achieve impressive vi-sual effects on simple fluid regions, how to handle com-plex contents with challenging transparency, collisions, and thin structures in real-world scenes is still a challenging and open problem.
The key to the limitation of previous work is that the generation process of videos is modeled in a global man-ner. Specifically, the subsequent frames are generated based on warping existing textures on input images [3] or neural features [6]. Such operations regard the scene as a whole and warp all the contents in the scene together. For some complex transparent fluid cases, as shown in Figure 2(b), we can see through the water to observe the background rocks beneath the liquid. Textures on those static objects
Project page: https://slr-sfs.github.io/
are also improperly deformed and result in unnatural anima-tions. To decompose the influence of motion on fluids and surrounding static objects, we propose a two-layer represen-tation for scenes with fluids, namely Surface-based Layered
Representation (SLR), which models the motion of the sur-face fluid and the rest background separately. To achieve such decomposition from the still image during inference, we propose a temporal-based training scheme, which facil-itates the network to learn the decomposition with multiple supervisions over spatial and temporal dimensions of run-ning fluid videos.
Another major difficulty in animating a single fluid im-age is predicting the motion flow of the fluid. There exist two types of methods. The first category is the interactive motion prediction methods. They require sparse hints (ie, labelling the velocity direction and relative amplitude) on random pixels of the liquid region as additional inputs. The feature clustering model [27] or convolutional network [11] is then used to generate a dense motion field. As the pre-cision depends on the level of motion details a user can provide, such methods are time-costing in complex fluid scenes. The second category is automatic methods [6].
These works regard the task as a domain transformation problem, and use image-to-image translation techniques to predict the motion represented by 2-channel optical flows.
Ambiguous velocity (e.g., a flat river surface can flow ei-ther to the left or to the right, as shown in Figure 2(a)) and tremendous changes of velocity in a period of time caused by the collisions with objects (as shown in Figure 2(c)) may pose great challenges to the above methods. To tackle the challenges, we introduce a simplified Navier-Stokes sim-ulation into the motion estimation process, called Surface-only Fluid Simulation (SFS). Specifically, the initial motion prediction of the liquid region is firstly calculated through sparse user inputs and interpolation inside the whole region.
In parallel, a 3D mesh is built based on a monocular depth estimator. Then, the N-S equation is solved on the mesh surfaces and based on the initial motion to obtain a simu-lated motion field in a short period of time. Finally, since the real thickness of the fluid is neglected during the simu-lation, a refinement step is expected to compensate for the motion offset at height. Thus, a DNN-based motion transla-tor is applied subsequently to obtain the refined motion field that adapts naturally to the input image. With SFS, we can enforce precise controls on the movement of fluid.
In summary, our work has three major contributions. (a)
We propose a new and learnable representation, surface-based layered representation, which decomposes the fluid surface and the static objects in the scene to better synthe-size the fluid animating videos from a single fluid image. (b) We design a surface-only fluid simulation to model the evolution of the image fluids with better visual effects. (c)
Based on the proposed surface-based layered representation
Figure 2. Motivation. (a) Given a still input image, the motion may be ambiguous. (b) Animating via previous SOTA method [11] causes background rocks beneath the liquid improperly deformed. (c) Motion prediction methods such as [11, 27] cannot well capture motion changes caused by the collisions with objects. and surface-only fluid simulation, image editing with flu-ids is achieved with realistic and vivid results. In addition,
We can easily extend our fluid animation system to down-stream editing tasks, thanks to the SLR and SFS designs in our framework. For example, we can augment objects in the fluid region or background region, and simulate the interac-tions between the fluids and objects. We can also replace textures to different layers to create different scenes. 2.