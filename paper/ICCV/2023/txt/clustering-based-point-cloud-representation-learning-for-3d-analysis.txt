Abstract
Point cloud analysis (such as 3D segmentation and detec-tion) is a challenging task, because of not only the irregular geometries of many millions of unordered points, but also the great variations caused by depth, viewpoint, occlusion, etc.
Current studies put much focus on the adaption of neural networks to the complex geometries of point clouds, but are blind to a fundamental question: how to learn an appropriate point embedding space that is aware of both discriminative semantics and challenging variations? As a response, we propose a clustering based supervised learning scheme for point cloud analysis. Unlike current de-facto, scene-wise training paradigm, our algorithm conducts within-class clus-tering on the point embedding space for automatically dis-covering subclass patterns which are latent yet representative across scenes. The mined patterns are, in turn, used to re-paint the embedding space, so as to respect the underlying distribution of the entire training dataset and improve the robustness to the variations. Our algorithm is principled and readily pluggable to modern point cloud segmentation networks during training, without extra overhead during test-ing. With various 3D network architectures (i.e., voxel-based, point-based, Transformer-based, automatically searched), our algorithm shows notable improvements on famous point cloud segmentation datasets (i.e., 2.0-2.6% on single-scan and 2.0-2.2% multi-scan of SemanticKITTI, 1.8-1.9% on S3DIS, in terms of mIoU). Our algorithm also demonstrates utility in 3D detection, showing 2.0-3.4% mAP gains on KITTI. 1.

Introduction
During the last few years, point cloud analysis, such as 3D segmentation, has attracted increasing research effort, due to the wide applications in autonomous driving, intel-ligent robotics, airborne laser scanning, and virtual reality.
In particular, the advances in deep learning signiﬁcantly pushed forward the state-of-the-art in this ﬁeld. Applying standard neural networks which are specialized for grid-like 1Corresponding author: Yi Yang. data, such as natural images, to point clouds is nontrivial, as point data are unorganized and irregular. To adapt neural networks to the geometries of point data, considerable effort has been made and representative achievements include: i) projection-/voxel-based networks [1–11] that project irreg-ular point clouds to regular representations, so that mature 2D/3D convolution can be applied for segmentation; and ii) point-based networks [12–16] that ingest raw point clouds directly, by using permutation-invariant operator [17–21], graph convolution [22], customized convolution [23–25], or self-attention (Transformer) based architecture [26–28].
Nevertheless, the challenges in point cloud analysis stem not only from the intrinsic non-Euclidean nature of point data, but also from the large intra-class variations caused by depth, occlusion, viewpoint, shape, etc. Despite various fancy point structure-aware network designs and their encouraging re-sults, a fundamental issue was long ignored: how to learn a good point embedding space that is discriminative for semantic categorization yet robust for point data variations?
Mitigating this issue demands a powerful learning regime that is aware of latent variation modes (or representative ﬁne-grained patterns) – comprehensively describing the potential structure of point data. However, in practice, it is infeasible to precisely annotate, or even roughly identify, the underlying data patterns in point clouds. This may be the reason behind the common choice that point cloud segmentation is learned as point-wise classiﬁcation; any ﬁne-grained patterns that the point data may possess are left to be ‘mysteriously’ learned through the supervision from high-level semantic tags.
These novel insights motivate us to devise a clustering analysis based training scheme for point cloud segmentation.
It complements the standard supervised learning of point-wise classiﬁcation with unsupervised clustering and regular-ization of the feature space. Speciﬁcally, clustering is con-ducted inside each labeled semantic class to automatically discover informative yet hidden subclass patterns without explicit annotation. The discovered subclass patterns es-sentially capture the underlying ﬁne-grained distribution of the whole training dataset. They are then used to reshape the point embedding space, achieved by explicitly inspiring inter-subclass/-cluster discriminativeness, and reducing intra-subclass/-cluster variation. Such regularized representation space in turn facilitates the discovery of typical within-class variation modes, and beneﬁts point recognition eventually.
Our learning algorithm enjoys several appealing advan-tanges: First, it raises a dataset-level context-aware training strategy. Unlike the current de-facto, scene-wise training pa-radigm, our algorithm groups point features across training scenes, and conducts clustering based representation learn-ing. By probing the global data distribution, our algorithm encourages the highly ﬂexible feature space to be discretized into a few distinct subcluster centers, easing the difﬁculty of the ﬁnal semantic classiﬁcation. Second, it is efﬁcient for large-scale point cloud training. To avoid time-consuming clustering of massive point data, we opt the Sinkhorn-Knopp algorithm [29, 30] that solves cluster assignment using fast matrix-vector algebra [31]. Moreover, to follow closely the drifting representation during network training, a momentum update strategy is adopted for online approximation of the subcluster centers. Third, it is principled enough to be seam-lessly incorporated into the training process of any modern point cloud segmentation networks, without bringing extra computation burden or model parameters during inference.
For thorough evaluation, we approach our training algori-thm on four remarkable point cloud segmentation models, i.e., Cylinder3D [16] (voxel-based), KPConv [25] (point-based), PTV1 [26] (Transformer-based), SPVNAS [32] (neural architecture search (NAS) based), and conduct experi-ments on 3D point cloud segmentation for urban scenes (i.e.,
SemanticKITTI [33] single-scan) and indoor environments (i.e., S3DIS [34]) as well as 4D segmentation of point cloud sequences (i.e., SemanticKITTI [33] multi-scan). Results show that our algorithm owns 2.2-2.6%, 1.9-2.2%, 1.8%, and 2.0% mIoU gains over Cylinder3D, KPConv, PTV1, and
SPVNAS, respectively. Our algorithm even promotes 3D de-tectors Second [35] and PointPillar [36] by 2.7-3.4% and 2.0-2.2% mAP on KITTI [37], verifying its high generality. 2.