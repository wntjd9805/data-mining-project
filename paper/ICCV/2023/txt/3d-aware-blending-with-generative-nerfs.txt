Abstract (a) Original (b) Reference (c) 2D method (d) Ours
Image blending aims to combine multiple images seam-lessly. It remains challenging for existing 2D-based methods, especially when input images are misaligned due to differ-ences in 3D camera poses and object shapes. To tackle these issues, we propose a 3D-aware blending method using gen-erative Neural Radiance Fields (NeRF), including two key components: 3D-aware alignment and 3D-aware blending.
For 3D-aware alignment, we ﬁrst estimate the camera pose of the reference image with respect to generative NeRFs and then perform pose alignment for objects. To further lever-age 3D information of the generative NeRF, we propose 3D-aware blending that utilizes volume density and blends on the NeRF’s latent space, rather than raw pixel space.
Collectively, our method outperforms existing 2D baselines, as validated by extensive quantitative and qualitative evalu-ations with FFHQ and AFHQ-Cat. d e n g i l a y l h g u o
R d e n g i l a s i
M 1.

Introduction
Image blending aims at combining elements from mul-tiple images naturally, enabling a wide range of applica-tions in content creation, and virtual and augmented reali-ties [95, 96]. However, blending images seamlessly requires delicate adjustment of color, texture, and shape, often re-quiring users’ expertise and tedious manual processes. To reduce human efforts, researchers have proposed various au-tomatic image blending algorithms, including classic meth-ods [62, 49, 7, 76] and deep neural networks [93, 79, 54].
Despite signiﬁcant progress, blending two unaligned im-ages remains a challenge. Current 2D-based methods often assume that object shapes and camera poses have been accu-rately aligned. As shown in Figure 1c, even slight misalign-ment can produce unnatural results, as it is obvious to human eyes that foreground and background objects were captured using different cameras. Several methods [34, 52, 12, 66, 86] warp an image via 2D afﬁne transformation. However, these approaches do not account for 3D geometric differences, such as out-of-plane rotation and 3D shape differences. 3D alignment is much more difﬁcult for users and algorithms, as it requires inferring the 3D structure from a single view.
Figure 1: Image blending is challenging for unaligned original and reference images. Existing 2D-based methods [42] struggle to synthesize realistic results due to the 3D object pose differences between foreground and background. In contrast, we propose a 3D-aware blending method that aligns and composes unaligned images without manual effort.
Additionally, even though previous methods get aligned im-ages, they blend images in 2D space. Blending images using only 2D signals, such as pixel values (RGB) or 2D feature maps, doesn’t account for the 3D structure of objects.
To address the above issues, we propose a 3D-aware image blending method based on generative Neural Radiance
Fields (NeRFs) [9, 33, 10, 59, 67, 91]. Generative NeRFs learn to synthesize images in 3D using only collections of single-view images. Our method projects the input images to the latent space of generative NeRFs and performs 3D-aware alignment by novel view synthesis. We then perform blending on NeRFs’ latent space. Concretely, we formulate an optimization problem in which a latent code is optimized to synthesize an image and volume density of the foreground  
Reference image 2
D b l e n d i n g
Reference image 3
D
-a w a r e a l i g n m e n t
Aligned reference 2
D b l e n d i n g
Reference image 3
D
-a w a r e a l i g n m e n t
NeRF space 3
D
-a w a r e b l e n d i n g
Original image
Original image
Original image
NeRF space (a) 2D blending (b) 2D blending with our 3D-aware alignment (c) Proposed method (Ours)
Figure 2: Comparison with the existing blending methods. Red lines denote target blending parts. (a) 2D blending. 2D blending methods compose two images without any 3D-aware alignment. (b) 2D blending with 3D-aware alignment. To address misalignment, we apply our 3D-aware alignment method to existing 2D blending methods. (c) Proposed method. We propose 3D-aware blending after applying our 3D-aware alignment. Note that all methods do not use 3D labels or 3D morphable models. close to the reference while preserving the background of the original.
Figure 2 shows critical differences between our approach and previous methods. Figure 2a shows a classic 2D blending method composing two 2D images without alignment. We then show the performance of the 2D blending method can be improved using our 3D-aware alignment with generative
NeRFs as shown in Figure 2b. To further exploit 3D infor-mation, we propose to compose two images in the NeRFs’ latent space instead of 2D pixel space. Figure 2c shows our
ﬁnal method.
We demonstrate the effectiveness of our 3D-aware align-ment and 3D-aware blending (volume density) on unaligned images. Extensive experiments show that our method out-performs both classic and learning-based methods regarding both photorealism and faithfulness to the input images. Ad-ditionally, our method can disentangle color and geometric changes during blending, and create multi-view consistent results. To our knowledge, our method is the ﬁrst general-purpose 3D-aware image blending method capable of blend-ing a diverse set of unaligned images. 2.