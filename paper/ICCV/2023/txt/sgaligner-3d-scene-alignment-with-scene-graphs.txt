Abstract
Building 3D scene graphs has recently emerged as a topic in scene representation for several embodied AI ap-plications to represent the world in a structured and rich manner. With their increased use in solving downstream tasks (e.g., navigation and room rearrangement), can we leverage and recycle them for creating 3D maps of environ-ments, a pivotal step in agent operation? We focus on the fundamental problem of aligning pairs of 3D scene graphs whose overlap can range from zero to partial and can con-tain arbitrary changes. We propose SGAligner, the first method for aligning pairs of 3D scene graphs that is robust to in-the-wild scenarios (i.e., unknown overlap – if any – and changes in the environment). We get inspired by multi-modality knowledge graphs and use contrastive learning to learn a joint, multi-modal embedding space. We evaluate on the 3RScan dataset and further showcase that our method can be used for estimating the transformation between pairs of 3D scenes. Since benchmarks for these tasks are missing, we create them on this dataset. The code, benchmark, and trained models are available on the project website. 1.

Introduction
Generating accurate 3D maps of environments is a key focus in computer vision and robotics, being a fundamental component for agents and machines to operate within the scene, make decisions, and perform tasks. As such, these i.e., containing information maps should be actionable, (such as objects, instances, their position, and relationship to other elements) that allows agents to perform an action and represented such that it is easily scalable, updateable, and shareable. Recently, 3D scene graphs [2, 40, 33, 18] have emerged as a topic in scene representation, providing a structured and rich way to represent the world. Not only do they fit the above requirements, but they can also be a lighter-weight [6] and more privacy-aware representation of 3D scenes than the predominantly used 3D point clouds or voxel grids – hence being easier and safer to share across
Figure 1. SGAligner. We address the problem of aligning 3D scene graphs of environments using multi-modal learning and leverage the output for the downstream task of 3D point cloud reg-istration. Our approach operates directly on 3D scene graph level, is fast and robust to real-world scenarios. agents and humans operating in the same scene [22, 47].
Given their potential, 3D scene graphs are increasingly used in embodied agents as a representation – commonly built on the fly – to perform robotic navigation [35, 34, 32, 22, 6] and task completion [12, 1, 31, 17, 20]. Since more and more agents are already building 3D scene graphs for downstream tasks, we investigate how to leverage and re-cycle them for creating 3D maps of the environment – a pivotal step in the agent operation – directly on the scene graph level. Specifically, we examine the fundamental prob-lem of aligning partial 3D scene graphs of an environment that originate from different observations. We focus on real-world scenarios and specifically formulate the problem as follows: given two 3D scene graphs that represent 3D scenes whose overlap can range from zero to partial or full and can contain changes, our goal is to find an alignment across nodes, if it exists. Interestingly enough, even though entity alignment (i.e., node alignment) is used in knowledge graphs and in linguistics [24, 13, 26, 46, 7, 9, 36, 23], the task of aligning 3D scene graphs of environments has not been explored. An important note is that entity alignment in these domains assumes that there is overlap between graphs and that all inputs contain true information.
We propose SGAligner, the first method for aligning pairs of 3D scene graphs that is robust to in-the-wild sce-narios (i.e., unknown overlap – if any – and changes in the environment) (see Figure 1). We get inspired by en-tity alignment methods in multi-modality knowledge graphs
[23] and redesign them for our setting. 3D scene graphs represent three main types of information [40, 2, 33]: se-mantic entities in the scene (e.g., object instances), their at-tributes (e.g., category, size, and material), and relationships between the entities (e.g., relative position and attribute sim-ilarity). The main premise is to independently encode each of these modalities with the ultimate objective of learning a joint embedding that can reason how similar two nodes are.
Given node matches, we perform the scene graph alignment using the matches with the highest similarity.
We additionally demonstrate our scene graph alignment method on the tasks of 3D point cloud registration and 3D alignment of a local 3D point cloud on a larger map that contains changes.
Instead of directly computing 3D cor-respondences on the entire point clouds [15, 29, 43, 3], we use the alignment as coarse initialization for the registration.
We further refine it by computing 3D correspondences [29] on the individual point clouds (i.e., object instance point clouds) of each matched node pair. This is followed by ro-bustly estimating [11] the rigid point cloud transformation using the correspondences from all matched nodes.
We evaluate all three tasks on the 3RScan [39] dataset, which contains 3D point clouds captured over time along with their 3D scene graph annotations [40]. Since 3RScan does not provide partial scene graphs of the same scene or a point cloud registration benchmark and there is no 3D scene graph alignment benchmark, we create the data, metrics, and evaluation needed for these tasks in 3RScan. Our ex-periments show that our approach reduces the relative trans-lation error of state-of-the-art GeoTransformer [29] by 40% in point cloud registration, while being 3× faster during the overlap check, since it does not need to process the entire point clouds. Detailed ablation studies, along with experi-ments on the task of aligning a changed local 3D scene to a prior 3D map, demonstrate robustness of our approach.
We summarize the contributions of this paper as follows:
• We propose SGAligner, the first method for aligning pairs of 3D scene graphs whose overlap can range from zero to partial and that may contain changes.
• We demonstrate the potential of our method on the tasks of 3D point cloud registration, 3D point cloud mosaicking and 3D alignment of a point cloud in a larger map that contains changes.
• We create a scene graph alignment and 3D point cloud registration benchmark on the 3RScan [39, 40] dataset, with data, metrics, and evaluation procedure. 2.