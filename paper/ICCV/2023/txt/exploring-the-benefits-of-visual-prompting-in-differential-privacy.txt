Abstract
Visual Prompting (VP) is an emerging and powerful technique that allows sample-efficient adaptation to down-stream tasks by engineering a well-trained frozen source model. In this work, we explore the benefits of VP in con-structing compelling neural network classifiers with dif-ferential privacy (DP). We explore and integrate VP into canonical DP training methods and demonstrate its sim-plicity and efficiency. In particular, we discover that VP in tandem with PATE, a state-of-the-art DP training method that leverages the knowledge transfer from an ensemble of teachers, achieves the state-of-the-art privacy-utility trade-off with minimum expenditure of privacy budget. Moreover, we conduct additional experiments on cross-domain image classification with a sufficient domain gap to further unveil the advantage of VP in DP. Lastly, we also conduct exten-sive ablation studies to validate the effectiveness and contri-bution of VP under DP consideration. Our code is available at https://github.com/EzzzLi/Prompt-PATE. 1.

Introduction
Originating from the domain of deep learning for natural language processing, prompt engineering has gained signif-icant popularity as an emergent technique for efficient adop-tion and adaptation of pre-trained language models for solv-ing different downstream tasks [24]. In recent years, the no-tion of prompting has been extended to other domains and data modalities, especially in computer vision and images
[18, 3]. Specifically, the term visual prompting (VP) has been coined by [3], and the authors show competitive accu-racy of VP on some downstream image classification tasks over linear probing (i.e., attaching a trainable linear head to
*Corresponding Author.
†This work was supported in part by the National Natural Science
Foundation of China under Grants 61802298 and 62172329. a pre-trained model) when used with a large vision model such as CLIP [35] (only the image encoder). It is worth not-ing that VP in [3] can be viewed as a special case of model reprogramming (MR) [8] on a pre-trained model. MR in-serts an input transformation layer and an output mapping layer into a pre-trained frozen model for fine-tuning down-stream tasks. MR is equivalent to VP in [3] when the in-put transformation is a trainable input perturbation and the output mapping is a specified source-target label correspon-dence or a set of text prompts for label inference (e.g., “a photo of [predicted class]”). Throughout this paper, for ease of elucidation, we will use VP and MR interchangeably.
VP has been extensively studied for various use cases, ranging from image classification [3], enhancing adversar-ial robustness [6], image-inpainting [4], cross-domain adap-tation [39, 31], to name a few. In this paper, we explore yet another benefit of VP with pre-trained models – deep learn-ing with differential privacy (DP). In deep learning, scal-ing the training parameters of a neural network often leads to improved task performance (e.g., a classification model with higher accuracy) [19]. However, with a DP budget, training a larger neural network usually means more con-sumption of data privacy [27]. Motivated by this dilemma of the tradeoff between neural network capacity and DP, we aim to study the following fundamental question:
Can VP with a pre-trained model (trained on non-private data) improve the privacy-accuracy tradeoff in off-the-shelf
DP-training mechanisms?
In this paper, we give an affirmative answer to this question, validated through a comprehensive analysis and empirical comparisons. We purposely focus on existing DP-training mechanisms, in order to study the benefit of improved per-formance contributed by VP. Our proposed approach ap-plies VP (at data inputs) to off-the-shelf DP-training mech-anisms, together with a pre-trained model trained on non-private data. Particularly, when VP is used in PATE (Pri-vate Aggregation of Teacher Ensembles) [33], a DP training
mechanism, we show that the classification accuracy under a privacy constraint can achieve the current state-of-the-art performance (SOTA) (over 97%) on the common bench-mark of CIFAR-10 classification task. Furthermore, we also demonstrate that the performance increases with minimum expenditure of privacy budget. Consequently, our results uncovered new benefits of VP in DP and offer new use cases and insights into prompt engineering.
Contribution. We highlight our main contributions as fol-lows. We are the first to explore the benefits of VP with pre-trained models in the design of DP classifiers. By leverag-ing VP, we present Prom-PATE as a training strategy for DP classifiers. While sophisticated backbones are usually diffi-cult to be used in DP training, Prom-PATE has great flexi-bility in utilizing the high accuracy of the backbone without compromising privacy. Overall, Prom-PATE enjoys the fol-lowing characteristics. Prom-PATE relies on VP to resolve the demand for huge data from PATE, improving practi-cality and accuracy.
In the design, the public pre-trained models are utilized twice, significantly growing the accu-racy. Through extensive experiments, we demonstrate that
Prom-PATE outperforms current DP classifiers on CIFAR-10, showing an accuracy 97.07% under a privacy budget of ϵ = 1.019. We also show significant accuracy gain of
Prom-PATE in other datasets over existing methods. 2.