Abstract
As advanced image manipulation techniques emerge, de-tecting the manipulation becomes increasingly important.
Despite the success of recent learning-based approaches for image manipulation detection, they typically require ex-pensive pixel-level annotations to train, while exhibiting degraded performance when testing on images that are dif-ferently manipulated compared with training images. To address these limitations, we propose weakly-supervised image manipulation detection, such that only binary image-level labels (authentic or tampered with) are required for training purpose. Such a weakly-supervised setting can leverage more training images and has the potential to adapt quickly to new manipulation techniques. To improve the generalization ability, we propose weakly-supervised self-consistency learning (WSCL) to leverage the weakly anno-tated images. Speciﬁcally, two consistency properties are learned: multi-source consistency (MSC) and inter-patch consistency (IPC). MSC exploits different content-agnostic information and enables cross-source learning via an online pseudo label generation and reﬁnement process. IPC per-forms global pair-wise patch-patch relationship reasoning to discover a complete region of manipulation. Extensive experiments validate that our WSCL, even though is weakly supervised, exhibits competitive performance compared with fully-supervised counterpart under both in-distribution and out-of-distribution evaluations, as well as reasonable manip-ulation localization ability. 1.

Introduction
With the advent of increasingly powerful image editing techniques [39, 24, 26, 56, 36, 20, 59, 58, 61, 20, 44], im-age manipulation has never been so convenient, and can be easily accomplished using natural language [44, 20, 44] or sketch [39, 59, 58, 61] by general users. Such advances allow malicious users to easily manipulate images, creat-ing fake news, promoting blackmail, and generating Deep-(a) In-distribution (IND) manipula-tion detection result on the testing split of the CASIA dataset [10, 11]. (b) Out-of-distribution (OOD) ma-nipulation detection results, which are averaged over Columbia [17],
Coverage [51] and IMD2020 [33].
Figure 1. Image-level manipulation detection performance compar-ison with existing fully-supervised methods [65, 57, 22, 6]. All methods are trained on CASIA [10, 11]. Our weakly-supervised method achieves comparable performance with fully-supervised methods under both IND and OOD manipulation detections. fakes [60, 48]. Thus, detecting the authenticity of an image is crucial for media forensics and credible information sharing.
Despite previous efforts to detect image manipulations, existing solutions still confront several challenges when deal-ing with real problems. First, although learning-based image manipulation techniques demonstrate excellent performance compared with traditional methods, they may not easily generalize well to testing images that are manipulated differ-ently compared with training images. As more sophisticated image manipulation techniques continue to emerge, it is ex-ceedingly challenging, if not impracticable, to encompass all manipulation methods in the training data to enable effec-tive handling of novel manipulations. As shown in Fig. 1, despite work well in the training image dataset, the perfor-mance of learning-based methods can degrade considerably when testing on out-of-distribution images, i.e., the unknown unknowns. Moreover, most learning-based methods for de-tecting image manipulation rely on the full supervision, i.e., training with pixel-level mask [42, 25, 55, 57, 65, 6, 9].
This approach is commonly adopted due to the creation of image manipulation datasets using sophisticated soft-ware [17, 11, 51, 15], where manipulated images and masks
are generated simultaneously. Although the pixel-mask can provide full supervision to help the model differentiate au-thentic and tampered image regions, the cost of such image annotation is non-trivial and limits the amount of the training images. On the other hand, emerging language-driven image editing/synthesis or sketch-based manipulation methods do not necessarily generate pixel-level masks during the edit-ing process [39, 59, 58, 61, 44, 20, 44, 36], but still have great potential to help train image manipulation detection if properly used.
To address the limitations of previous fully-supervised image manipulation detection methods, we propose weakly-supervised image manipulation detection (W-IMD), where only binary image-level labels are required to tell whether a given image is authentic or tampered with, thereby elim-inating the need for pixel-level masks during training. We observe that image manipulation detection typically relies on inconsistency detection between features of the manipu-lated regions compared to features from the surrounding re-gions. Thus, we propose two different self-consistency learn-ing schemes: (1) multi-source consistency (MSC) and (2) inter-patch consistency (IPC) to achieve weakly-supervised self-consistency learning (WSCL) that aims to improve the generalization ability of image manipulation detection.
For (1) multi-source consistency (MSC) learning, we take advantage of content-agnostic information by using dif-ferent noise patterns in the image [14, 2] in a late-fusion manner. Speciﬁcally, we build an exclusive model on differ-ent sources (e.g., raw RGB image, and its noise maps) and generate an ensemble prediction by averaging predictions from different models. Intuitively, each source may focus on different locations, and locations where all models have consistent high/low activations and are likely to be manip-ulated/authentic. Hence, we use the ensemble prediction as a pseudo ground truth to guide each individual model, and enable them to learn cross-source information. When combining predictions from different sources, the ensemble model can be more reliable and accurate than single mod-els. For (2) the inter-patch consistency (IPC) learning, it learns global pair-wise image patch-patch similarities in a self-supervised learning manner. By learning the pair-wise relationship, IPC helps the model to differentiate low-level authentic and tampered image patch features. Enforcing the IPC constraints helps to correct potential false positives, estimate a more complete image region of manipulation, and mitigate overﬁtting.
We conducted experiments on seven benchmark datasets to validate the effectiveness of our weakly-supervised method.
First, we follow the conventional setting of image manipulation detection and demonstrate that our
WSCL achieves comparable image-level detection perfor-mances with several fully-supervised methods under both in-distribution and out-of-distribution evaluations. Further-more, we validate that our method can be easily extended to new manipulations where only image-level labels are avail-able. By ﬁne-tuning on the image-level labels, our WSCL achieves even better performance. Finally, we also demon-strate that our method achieves reasonable pixel-level ma-nipulation localization performance even under the setting of weakly-supervised learning.
To summarize, our contributions are threefold.
• We ﬁrst propose weakly-supervised image manipula-tion detection (W-IMD), where only binary image-level labels are required to achieve image manipulation de-tection. Such a paradigm eliminates the need for pixel-level annotations and can be easily adapted to new mask-free image editing techniques.
• We propose weakly-supervised self-consistency learn-ing (WSCL) for the W-IMD task. By exploiting the multi-source consistency and inter-patch consistency, our WSCL learns and fuses information from differ-ent content-agnostic sources, performs global image patch-patch relationship learning, and promotes generic image manipulation detection. Our WSCL also has the capability to locate the manipulation region in the pixel-level1.
• Experiments validate that our WSCL achieves strong in-distribution and out-of-distribution image manipulation detection capability, promising results when ﬁne-tuned with image-level labels on novel manipulations, and reasonable manipulation localization ability. 2.