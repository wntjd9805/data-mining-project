Abstract
Visible-infrared person re-identification (VI-ReID) fo-cuses on matching the pedestrian images of the same iden-tity captured by different modality cameras. The part-based methods achieve great success by extracting fine-grained features from feature maps. But most existing part-based methods employ horizontal division to obtain part features suffering from misalignment caused by irregular pedestrian movements. Moreover, most current methods use Euclidean or cosine distance of the output features to measure the similarity without considering the pedestrian relationships.
Misaligned part features and naive inference methods both limit the performance of existing works. We propose a Se-mantic Alignment and Affinity Inference framework (SAAI), which aims to align latent semantic part features with the learnable prototypes and improve inference with affinity in-formation. Specifically, we first propose semantic-aligned feature learning that employs the similarity between pixel-wise features and learnable prototypes to aggregate the la-tent semantic part features. Then, we devise an affinity in-ference module to optimize the inference with pedestrian re-lationships. Comprehensive experimental results conducted on the SYSU-MM01 and RegDB datasets demonstrate the favorable performance of our SAAI framework. Our code will be released at https://github.com/xiaoye-hhh/SAAI. 1.

Introduction
Person re-identification (ReID) is the task of retrieving pedestrian images shot by different cameras. Most existing person ReID methods [12, 16, 17, 40] focus on matching the images shot by visible cameras, essentially addressing a single-modality pedestrian matching assignment. However, the generally visible surveillance cameras cannot capture pedestrian information well under poor illumination con-*Corresponding author
Figure 1. Framework Differences. (a) Most existing part-based methods extract horizontal part features from feature maps and employ naive inference (e.g., Euclidean and cosine distance) to match images. Differently, our method extracts latent semantic part features and utilizes affinity information. (b) The part features extracted by our method have better semantic information. (c) Our affinity inference utilizes pedestrian relationships to optimize the distance calculation. Lines represent image relationships. Thicker lines indicate higher affinity. The green and red circles denote positive and negative gallery images, respectively. ditions. In response to this challenge, modern surveillance cameras can automatically switch to infrared mode for cap-turing images under low-light conditions. This technolog-ical advancement increases interest in researching visible-infrared person re-identification (VI-ReID).
VI-ReID suffers from substantial modality discrepancy and other factors (e.g., viewpoints, backgrounds, and move-ments). The factors leading to a sizeable intra-class dis-crepancy make matching difficult. Figure 1 (a) exhibits that existing methods [13, 23, 24, 35] extract horizontal part fea-tures to alleviate this problem. Figure 1 (b) illustrates that pedestrian parts (e.g., arms) are not located in a fixed po-sition due to movements. Therefore, the simple horizontal partition by fixed height can cause part features to become
semantic misalignments, which limits the performance.
Moreover, Figure 1 (a) exhibits that most existing meth-ods employ naive inference methods to calculate the sim-ilarity between query and gallery images. As shown in
Figure 1 (c), these methods ignore the affinity information among gallery images by treating them as a single entity.
The gallery images belong to the same modality without modality discrepancy, which can provide helpful affinity information to improve matching. Accordingly, SIM [14] proposes to use the similarity among the gallery images and calculate the Jaccard distance to boost matching. However, when calculating Jaccard distance, the element relationship is binary, inadequately utilizing affinity information.
We propose a Semantic Alignment and Affinity Infer-ence framework (SAAI), which aligns latent semantic part features and better utilizes auxiliary affinity information.
The SAAI framework consists of a semantic-aligned feature learning (SAFL) and an affinity inference module (AIM).
Specifically, SAFL first splits feature maps into pixel-wise features. Then, this method aggregates pixel-wise fea-tures with similar content by the similarity. This method concatenates the extracted latent semantic part features onto global features to provide local information. Finally, we use a dual-branch BNNeck to normalize features of both modalities, reducing the modality discrepancy. We devise a part diversity constraint to increase the diversity of latent semantic part features without additional annotations. Fur-thermore, we introduce a center separation loss to steer the network toward discerning pedestrian relationships.
Moreover, we propose the AIM to calculate the distance with the additional information from the affinity matrix.
This module first calculates the query-gallery affinity ma-trix like most existing methods. Then, AIM calculates the gallery-gallery affinity matrix as references. Finally, AIM uses query-gallery and gallery-gallery affinity matrices to revise the distance measurement. AIM can optimize infer-ence with affinity information among images. We propose a noise suppression algorithm to reduce the impact of inaccu-rate affinity values. Moreover, we devise a mean expansion method to increase the matching stability.
Our main contributions are summarized below:
• We propose an end-to-end Semantic Alignment and
Affinity Inference framework (SAAI) for VI-ReID to explore the joint application of semantic-aligned fea-ture learning and the affinity inference method.
• We propose a semantic-aligned feature learning (SAFL) to align the latent semantic part features. In addition, we devise an affinity inference module (AIM) to utilize pedestrian relationships for matching.
• Comprehensive experimental results demonstrate the effectiveness of the proposed framework. It achieves superior performance compared to state-of-the-art methods across various test settings. 2.