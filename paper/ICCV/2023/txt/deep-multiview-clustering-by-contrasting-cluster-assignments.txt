Abstract
Multiview clustering (MVC) aims to reveal the underly-ing structure of multiview data by categorizing data sam-ples into clusters. Deep learning-based methods exhibit strong feature learning capabilities on large-scale datasets.
For most existing deep MVC methods, exploring the invari-ant representations of multiple views is still an intractable problem. In this paper, we propose a cross-view contrastive learning (CVCL) method that learns view-invariant rep-resentations and produces clustering results by contrast-ing the cluster assignments among multiple views. Specif-ically, we first employ deep autoencoders to extract view-dependent features in the pretraining stage. Then, a cluster-level CVCL strategy is presented to explore consistent se-mantic label information among the multiple views in the fine-tuning stage. Thus, the proposed CVCL method is able to produce more discriminative cluster assignments by virtue of this learning strategy. Moreover, we provide a the-oretical analysis of soft cluster assignment alignment. The extensive experimental results obtained on several datasets demonstrate that the proposed CVCL method outperforms several state-of-the-art approaches. 1.

Introduction
Multiview data are usually represented by different types of features or collected from multiple sources. All views share the same semantic information contained in the mul-tiview data. Simultaneously, the data information derived from multiple views is complementary [6, 36]. The goal of multiview clustering (MVC) is to divide data samples into different groups according to their distinct feature informa-tion.
MVC has attracted increasing attention for many ma-chine learning tasks, including feature selection [36], scene recognition [23] and information retrieval [8, 41, 5]. The ex-*Corresponding author isting literature involving traditional machine learning tech-niques can be roughly divided into four categories, includ-ing subspace learning-based methods [5, 26], nonnegative matrix factorization (NMF)-based methods [32, 9], graph learning-based methods [6, 11], and multiple kernel-based methods [16, 17]. These traditional shallow models often exhibit limited capabilities to conduct feature representation learning on large-scale datasets [31].
A number of deep learning-based methods have been proposed to alleviate the above problems [28, 37, 13, 21, 39, 42, 14, 35]. The goal of these deep MVC methods is to learn a more discriminative consensus representation by transforming each view with a corresponding view-specific encoder network. For example, Xie et al. [35] proposed a deep embedding-based clustering method that simultane-ously learns feature representations and cluster assignments using deep neural networks. Li et al. [14] proposed a deep adversarial MVC method that learns the intrinsic structure embedded in multiview data. Zhou et al.
[42] proposed an end-to-end adversarial attention network that makes use of adversarial learning and an attention mechanism to align latent feature distributions and evaluate the importance of different modalities. These methods yield significantly im-proved clustering performance. However, they fail to con-sider the semantic label consistency among multiple views, which may lead to difficulty in learning consistent cluster assignments.
Recently, contrastive learning has been integrated into deep learning models to learn discriminative representa-tions of multiple views [12, 7]. Most existing contrastive learning-based methods attempt to maximize the mutual in-formation contained among the assignment distributions of multiple views [37, 30, 3]. For example, Yang et al. [38] took advantage of the available data pairs as positive sam-ples and randomly chose some cross-view samples as nega-tive samples for MVC. In particular, the term “cross-view” means that any two views among multiple views are in-volved in the contrastive learning process. Caron et al. [3] presented an unsupervised visual feature learning method
that enforces consistency between the cluster assignments produced for different augmentations. Xu et al. [37] pre-sented a multilevel feature learning (MFL) method to gen-erate features at different levels for contrastive MVC, e.g., low-level features, high-level features and semantic fea-tures. However, which features play critical roles in con-trastive feature learning remains unknown [27, 30]. This still leaves an important open question: ”which representa-tion should be invariant to multiple views?” Therefore, this motivates us to develop a cross-view contrastive learning (CVCL) model to build a more reasonable view-invariant representation scheme for multiview learning.
In this paper, we present a CVCL method that learns view-invariant representations for MVC. In contrast with most existing deep MVC methods, a cluster-level CVCL strategy is introduced to capture consistent semantic label information across multiple views. By contrasting cluster assignments among multiple views, the proposed CVCL method learns view-invariant representations between pos-itive pairs for MVC. The cluster assignments derived from positive pairs reasonably align the invariant representations among multiple views. Such an alignment flexibly de-scribes the consistent semantic labels obtained from indi-vidual views, which are used to measure the intrinsic re-lationships among the data samples. The K-dimensional assignment probability represents the cluster assignment of each sample in the corresponding view. Based on these view-invariant representations, the contrastive loss of the proposed CVCL method encourages the K-dimensional cluster assignments produced for positive pairs to be simi-lar and pushes the cluster assignments provided for negative pairs apart. In addition, we provide a theoretical explanation for the realizability of soft cluster assignment alignment.
Our major contributions are summarized as follows.
• A CVCL model that contains a two-stage training scheme is proposed to learn view-invariant represen-tations in an end-to-end manner.
• By contrasting the cluster assignments among multiple views, a cluster-level CVCL strategy is presented to explore consistent semantic label information.
• A theoretical analysis of the alignment among the pro-duced view-invariant representations explains why the
CVCL model is able to work effectively under certain conditions.
• Extensive experiments conducted on seven multiview datasets demonstrate the effectiveness of the proposed
CVCL method. 2.