Abstract
Deep learning models fail on cross-domain challenges if the model is oversensitive to domain-specific attributes, e.g., lightning, background, camera angle, etc. To alleviate this problem, data augmentation coupled with consistency regularization are commonly adopted to make the model less sensitive to domain-specific attributes. Consistency regularization enforces the model to output the same rep-resentation or prediction for two views of one image. These constraints, however, are either too strict or not order-preserving for the classification probabilities. In this work, we propose the Order-preserving Consistency Regulariza-tion (OCR) for cross-domain tasks. The order-preserving property for the prediction makes the model robust to task-irrelevant transformations. As a result, the model becomes less sensitive to the domain-specific attributes. The compre-hensive experiments show that our method achieves clear advantages on five different cross-domain tasks. 1.

Introduction
Deep neural networks have demonstrated their power in many computer vision tasks, especially when the training and test sets follow the same distribution. However, when we deploy a model in a real-world environment, we often encounter domain shifts between the training and test sets, which reduces the expected test-set performance and makes us unable to deploy with confidence [50]. For some safety-critical applications, e.g., tumor recognition [22] and au-tonomous driving [19], a failing model is fatal.
Image data consists of a variety of attributes such as texture, shooting angle, etc. shape, color, background,
We refer to one or more task-related attributes as label
*This work was done when Mengmeng Jing was a visiting student at
University of Amsterdam.
†Currently with United Imaging Healthcare, Co., Ltd., China.
Figure 1. The required output of three consistency regulariza-tions. Different shapes represent different categories. For different greens, the darker the color, the larger the classification probabil-ity. Representation-based method requires the output to be the same as the original. OCR only requires an order-preserving out-put and allows the output to vary. The prediction-based method is not order-preserving, which may cause the probability of the horse being classified to mouse is higher than that of donkey although donkeys are obviously more similar to horses than mice. attributes, and the remaining irrelevant ones as domain-specific attributes. Wiles et al. [69] demonstrate the domain-specific attributes cause the distribution shifts, thus weakening the generalization of the model. Data augmen-tation coupled with consistency regularization is commonly employed to make a model invariant to the domain-specific attributes [68, 8, 27, 59, 4, 10, 11, 21]. Data augmentation perturbs the data so that the domain-specific information is incorporated into the perturbed image. By imposing a con-sistency regularization on the representations of the same image before and after perturbation, the model becomes less
sensitive to the domain-specific attributes.
The existing consistency regularization methods can be divided into two categories: representation-based meth-ods [32, 61, 57] and prediction-based methods [4, 44, 71].
For the representation-based methods, usually the ℓ1 or ℓ2 loss is employed to enforce the model to output the same representation, even though two different views are fed into the model. This constraint, however, is too strict, which may bring difficulties to the training of the model. For ex-ample, different works on self-supervised learning [10, 11, 21] have reached a consensus that one of the representations needs to go through a non-linear prediction head before per-forming consistency regularization with the other. With the network model being a symmetric structure, directly impos-ing consistency regularization on the two representations will result in a model collapse.
Alternatively, the prediction-based methods [4, 44, 71] employ the cross-entropy loss to regularize the maximum classification probability of two representations to be the same.
In other words, they ignore the order of the other classes, which would reduce the discriminability of the model. For example, consider a classification problem of three classes: horse, donkey and mouse. As illustrated in
Fig. 1, for an image of a horse, the cross-entropy loss only regularizes the maximum classification probability of two representations to be horse, but it ignores the classification probability of donkey and mouse. If the order of classifica-tion probability is horse>donkey>mouse before augmenta-tion, it may become horse>mouse>donkey after augmen-tation. Although the classification results have not changed, the discrimination of the model has reduced as donkeys are obviously more similar to horses than mice.
In view of these problems, we propose Order-preserving
Consistency Regularization (OCR) for cross-domain tasks.
OCR is able to enhance the model robustness to domain-specific attributes without the need of an asymmetric achi-tecture or a stop gradient. Specifically, we compute the residual component which is the variation in the augmented representation relative to the original representation. We postulate that if the model is robust to domain-specific at-tributes, the residual component should contain little or no task-related information. For example, in the classification task, when we classify the residual component, we regular-ize it to have the same probability to be classified into each category. In this way, the classification probabilities of the augmented representation are order-preserving compared to the original representation. As a result, the model becomes less sensitive to the domain-specific attributes. The core idea of OCR is that we allow the model to output different representations for two views of the same image, as long as the residual component contains as little task-related infor-mation as possible.
The contributions of this paper are threefold: 1. We propose Order-preserving Consistency Regulariza-tion (OCR) to enhance model robustness to domain-specific attributes. Compared with representation-based methods, OCR relaxes the constraints on model it allows the model to output differ-training, ent representations for two views of the same image.
Compared with prediction-based method, OCR main-tains the order of the classification probabilities before and after augmentation, which helps the model to be less sensitive to the domain-specific attributes. i.e., 2. We provide a theoretical analysis for OCR. We prove that the representation-based method is a special case of OCR. Moreover, OCR can reduce the mutual infor-mation between the domain-specific attributes and the label attribute. 3. We test our method on five different cross-domain vision tasks to demonstrate the effectiveness of our method. In particular, OCR helps to enhance the ro-bustness of the model against adversarial attacks. 2.