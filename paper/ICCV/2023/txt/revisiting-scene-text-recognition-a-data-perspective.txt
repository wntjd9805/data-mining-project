Abstract
This paper aims to re-assess scene text recognition (STR) from a data-oriented perspective. We begin by revisiting the six commonly used benchmarks in STR and observe a trend of performance saturation, whereby only 2.91% of the benchmark images cannot be accurately recognized by an ensemble of 13 representative models. While these re-sults are impressive and suggest that STR could be consid-ered solved, however, we argue that this is primarily due to the less challenging nature of the common benchmarks, thus concealing the underlying issues that STR faces. To this end, we consolidate a large-scale real STR dataset, namely Union14M, which comprises 4 million labeled im-ages and 10 million unlabeled images, to assess the per-formance of STR models in more complex real-world sce-narios. Our experiments demonstrate that the 13 models can only achieve an average accuracy of 66.53% on the 4 million labeled images, indicating that STR still faces numerous challenges in the real world. By analyzing the error patterns of the 13 models, we identify seven open challenges in STR and develop a challenge-driven bench-mark consisting of eight distinct subsets to facilitate fur-ther progress in the ﬁeld. Our exploration demonstrates that STR is far from being solved and leveraging data may be a promising solution. In this regard, we ﬁnd that utiliz-ing the 10 million unlabeled images through self-supervised pre-training can signiﬁcantly improve the robustness of STR model in real-world scenarios and leads to state-of-the-art performance. Code and dataset is available at https:
//github.com/Mountchicken/Union14M . 1.

Introduction
The success of deep learning in visual recognition tasks heavily depends on expansive labeled data. A widely used paradigm [2, 9, 10, 32, 62] in STR is training models on
*Corresponding author.
Figure 1. Average accuracy of STR models on six commonly used benchmarks as reported in their original papers. Models are trained with synthetic data. large-scale synthetic datasets [17, 18, 12, 61] and evaluat-ing on six real benchmarks [43, 42, 55, 38, 21, 20]. Promis-ingly, current progress in STR has exhibited a trend of ac-curacy saturation (depicted in Fig. 1). The challenges in the common benchmarks seem “solved”, suggested by the nar-row scope for improvement, and the slowdown step of per-formance gain in recent SOTAs. This phenomenon inspires us to raise questions of 1) whether the common benchmarks remain sufﬁcient to promote future progress, and 2) whether this accuracy saturation implies that STR is solved.
For the ﬁrst question, we start by selecting 13 representa-tive models (listed in Tab. 3), including CTC-based [47, 9], attention-based [48, 34, 25, 24, 46, 56, 63], and language model-based [62, 10, 57, 39] models. We then evaluate their performance on the six STR benchmarks to ﬁnd their joint errors. As depicted in Fig. 2, only 3.9% (298 images) of the total 7672 benchmark images can not be correctly rec-ognized by any of the 13 models, among which 25.5% of the images are incorrectly annotated, and 35.2% images are barely recognizable (human unrecognizable samples). This suggests that there might be a maximum of 2.91% (222 im-ages) and a minimum of 1.53% (117 images, excluding hu-man unrecognizable samples) scope for accuracy improve-ment. Therefore, the common benchmarks give limited in-sight into future STR research.
The accuracy saturation in common benchmarks can ob-scure challenges that STR models still face. Therefore,
less text, and artistic text. Furthermore, we identify three additional challenges that are prevalent in the real world but have received less attention in the STR community, namely multi-words text, salient text, and incomplete text.
To enable more thorough evaluations of STR models in real-world scenarios and to encourage future research on the seven aforementioned challenges, we construct a challenge-driven benchmark, which comprises eight subsets with 400,000 generic samples and 9,383 challenge-speciﬁc sam-ples sourced from Union14M-L. Extensive baseline exper-iments are conducted on this new benchmark and we ﬁnd that despite utilizing real data for training, the current SOTA model can only achieve an average accuracy of 74.6%. This indicates that STR still faces numerous challenges in the real world and also answers the second question that STR is far from being solved.
Essentially, we infer that the sub-optimal performance of STR models in the real world can be attributed to data problems, e.g., the lack of sufﬁcient real labeled data for training. To solve STR from a data perspective, we pro-pose a solution of utilizing unlabeled data. Speciﬁcally, we investigate a Vision Transformer-based [8] STR model (Fig. 5), which can leverage the 10M unlabeled images in Union14M-U through self-supervised pre-training. The pre-trained ViT model exhibits powerful textual representa-tion capabilities, and after ﬁne-tuning on real labeled data, it achieves SOTA performance on both six common bench-marks and the proposed challenge-driven benchmark. Our contributions are summarized as follows:
• We analyze STR from a data perspective and arrive at two macro ﬁndings. Firstly, the common benchmarks are insufﬁcient in presenting adequate challenges for advancing the ﬁeld of STR. Secondly, despite signif-icant progress, STR models still struggle to perform well in real-world scenarios. It is safe to say that STR is still far from being solved.
• We consolidate a large-scale real STR dataset to in-vestigate the performance of STR models in the real world. Through quantitative analysis, we reveal that current STR models fail to address seven open chal-lenges. Therefore, we propose a challenge-driven benchmark to facilitate future comprehensive and in-depth studies in the ﬁeld of STR.
• We exploit the potential of unlabeled data and observe that they can lead to signiﬁcant performance gains through self-supervised pre-training, offering a prac-tical solution for STR in the real world. 2.