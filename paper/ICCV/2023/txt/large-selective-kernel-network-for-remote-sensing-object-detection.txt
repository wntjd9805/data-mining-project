Abstract
Recent research on remote sensing object detection has largely focused on improving the representation of oriented bounding boxes but has overlooked the unique prior knowl-edge presented in remote sensing scenarios. Such prior knowledge can be useful because tiny remote sensing ob-jects may be mistakenly detected without referencing a suf-ficiently long-range context, which can vary for different objects. This paper considers these priors and proposes the lightweight Large Selective Kernel Network (LSKNet).
LSKNet can dynamically adjust its large spatial receptive field to better model the ranging context of various objects in remote sensing scenarios. To our knowledge, large and selective kernel mechanisms have not been previously ex-plored in remote sensing object detection. Without bells and whistles, our lightweight LSKNet sets new state-of-the-art scores on standard benchmarks, i.e., HRSC2016 (98.46% mAP), DOTA-v1.0 (81.85% mAP), and FAIR1M-v1.0 (47.87% mAP). 1.

Introduction
Remote sensing object detection [47, 57, 82] focuses on identifying and locating objects of interest in aerial images, such as vehicles, ships or aircraft. In recent years, one main-stream trend has been to generate bounding boxes that accu-rately fit the orientation of the objects being detected rather than simply drawing horizontal boxes around them. Conse-quently, much research has focused on improving the rep-resentation of oriented bounding boxes for remote sensing object detection. This has largely been achieved through the development of specialized detection frameworks (i.e., RoI
Transformer [12], Oriented R-CNN [69], and R3Det [75]) and oriented box encoding (i.e., gliding vertex [71] and midpoint offset box encoding [69]). Additionally, several loss functions, including GWD [77], KLD [79], and Modu-lated Loss [54], have been further proposed to enhance the
*Corresponding authors.
Team URL: https://github.com/IMPlus-PCALab
Project page: https://github.com/zcablii/LSKNet
Figure 1. Successfully detecting remote sensing objects requires using a wide range of contextual information. Detectors with a limited receptive field may easily lead to incorrect results. performance of these approaches.
Despite these advances, relatively few works have con-sidered the strong prior knowledge of remote sensing im-ages. Aerial images are typically captured at high resolu-tions from a bird’s eye view. In particular, most objects in aerial images may be small and difficult to identify based on their appearance alone. Instead, recognizing these ob-jects relies on their context, as the surrounding environment can provide valuable clues about their shape, orientation, and other characteristics. According to an analysis of the remote sensing data, we identify two important priors:
• Accurate detection often requires a wide range of contextual information. As illustrated in Fig. 1, the limited context used by object detectors in remote sensing images can often lead to incorrect classifica-tions. Rather than their appearance, the context distin-guishes the ship from the vehicle.
• The contextual information required for different objects is very different. As shown in Fig. 2, the soccer field requires relatively less contextual infor-mation because of the unique distinguishable court borderlines. In contrast, the roundabout may require more context information to distinguish between gar-dens and ring-like buildings. Intersections, especially those partially covered by trees, require an extremely large receptive field due to the long-range dependen-cies between the intersecting roads.
To address the challenge of accurately detecting objects
stage RoI transformer [12] uses fully-connected layers to rotate candidate horizontal anchor boxes in the first stage, and then features within the boxes are extracted for fur-ther regression and classification. SCRDet [78] uses an attention mechanism to reduce background noise and im-prove the modelling of crowded and small objects. Ori-ented RCNN [69] and Gliding Vertex [71] introduce new box encoding systems to address the instability of train-ing losses caused by rotation angle periodicity. Some ap-proaches [32, 61, 87] treat remote sensing detection as a point detection task [74], providing an alternative way of addressing remote sensing detection problems.
Rather than relying on the proposed anchors, one-stage detection frameworks classify and regress oriented bound-ing boxes directly from grid densely sampled anchors. The one-stage S2A network [23] extracts robust object features via oriented feature alignment and orientation-invariant fea-ture extraction. DRN [50], on the other hand, leverages at-tention mechanisms to dynamically refined the backbone’s extracted features for more accurate predictions. In contrast with Oriented RCNN and Gliding Vertex, RSDet [54] ad-dresses the discontinuity of regression loss by introducing a modulated loss. LD [86] enhances the localization qual-ity of oriented bounding boxes by distillation. AOPG [6] and R3Det [75] adopt a progressive regression approach, refining bounding boxes from coarse to fine granularity. In addition to CNN, AO2-DETR [9] introduces a transformer-based detection framework, DETR [4], into remote sensing detection tasks, which brings more research diversity.
While these approaches have achieved promising results in addressing the issue of rotation variance, they do not con-sider the strong and valuable prior information presented in aerial images. Instead, our approach uses the large kernel and spatial selective mechanism to better model these pri-ors without modifying the current detection framework. 2.2. Large Kernel Networks
Transformer-based [59] models, such as the Vision
Transformer (ViT) [1, 11, 14, 53, 60], Swin transformer [25, 39, 51, 64, 70, 83], and pyramid transformer [62, 67], have gained popularity in computer vision. Research [17, 45, 55, 72, 85] has demonstrated that the large receptive field is a key factor in their success. Recent work has shown that well-designed convolutional networks with large receptive fields can also be highly competitive with transformer-based models. For example, ConvNeXt [40] uses 7×7 depth-wise convolutions in its backbone, resulting in significant per-formance improvements in downstream tasks. In addition,
RepLKNet [13] even uses a 31×31 convolutional kernel via re-parameterization, achieving compelling performance. A subsequent work SLaK [38], further expands the kernel size to 51×51 through kernel decomposition and sparse group techniques. RF-Next [18] automatically searches for a fixed
Figure 2. The wide range of contextual information required for different object types is very different by human criteria. The ob-jects with red boxes are the exact ground-truth annotations. in remote sensing images, which often require a wide and dynamic range of contextual information, we propose a novel lightweight detection backbone called Large Selec-tive Kernel Network (LSKNet). Our approach involves dy-namically adjusting the receptive field of the feature ex-traction backbone to more effectively process the varying wide context of the objects being detected. This is achieved through a spatial selective mechanism, which efficiently weights the features processed by a sequence of large depth-wise kernels and then spatially merge them. The weights of these kernels are determined dynamically based on the input, allowing the model to adaptively use different large kernels and adjust the receptive field for each target in space as needed.
To our knowledge, the proposed LSKNet is the first to in-vestigate using large and selective kernels for remote sens-ing object detection. Despite its simplicity and lightweight nature, our model achieves state-of-the-art performance on three popular datasets: HRSC2016 (98.46% mAP), DOTA-v1.0 (81.85% mAP), and FAIR1M-v1.0 (47.87% mAP), surpassing previously published results. Furthermore, we demonstrate that our model’s behaviour aligns with the two priors above, which in turn verifies the effectiveness of the proposed mechanism. 2.