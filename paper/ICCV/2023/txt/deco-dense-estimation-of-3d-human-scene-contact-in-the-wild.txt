Abstract
Understanding how humans use physical contact to inter-act with the world is key to enabling human-centric artificial intelligence. While inferring 3D contact is crucial for mod-eling realistic and physically-plausible human-object inter-actions, existing methods either focus on 2D, consider body joints rather than the surface, use coarse 3D body regions, or do not generalize to in-the-wild images. In contrast, we focus on inferring dense, 3D contact between the full body surface and objects in arbitrary images. To achieve this, we first collect DAMON, a new dataset containing dense vertex-level contact annotations paired with RGB images containing complex human-object and human-scene con-tact. Second, we train DECO, a novel 3D contact detector that uses both body-part-driven and scene-context-driven attention to estimate vertex-level contact on the SMPL body.
DECO builds on the insight that human observers recognize contact by reasoning about the contacting body parts, their proximity to scene objects, and the surrounding scene con-* Equal contribution text. We perform extensive evaluations of our detector on
DAMON as well as on the RICH and BEHAVE datasets. We significantly outperform existing SOTA methods across all benchmarks. We also show qualitatively that DECO gen-eralizes well to diverse and challenging real-world human interactions in natural images. The code, data, and models are available at https://deco.is.tue.mpg.de. 1.

Introduction
Humans rely on contact to interact with the world. While we use our hands and feet to support grasping and locomo-tion, we also leverage our entire body surface in our daily interactions with the world; see Fig. 1. We sit on our but-tocks and thighs, lie on our backs, kneel on our knees, carry bags on our shoulders, and move heavy objects by holding them against our bodies. Executing everyday tasks involves diverse full-body and object contact. Thus, modeling and inferring contact from images or videos is essential for ap-plications such as human activity understanding, robotics, biomechanics, and augmented or virtual reality.
Inferring contact from images has recently received at-tention. While some methods infer contact for hands [48], feet [51], self contact [15, 47], or person-person contact [14], others focus on human-scene or human-object contact for the full body [8, 28]. HOT [8] infers contact in 2D by training on in-the-wild images with crowd-sourced 2D contact areas, while BSTRO [28] infers 3D contact on a body mesh and is trained on images paired with 3D body and scene meshes reconstructed with a multi-camera system.
In contrast to prior work, we seek to represent detailed scene contacts across the full body and to infer these from in-the-wild images as illustrated in Fig. 1. To that end, we need both an appropriate training dataset and an inference method.
Note that manipulating objects is fundamentally 3D. Thus, we must capture, model, and understand contact in 3D. Also note that some contacts support the body, while others do not.
When sitting on a chair and drinking a cup of coffee, the body is supported by the buttocks on the chair and feet on the floor, while the coffee cup does not support the body. The former is critical for physical reasoning about human pose and motion, while the latter is important to understand how we interact with objects. The type of contact is therefore important to represent. For a method to robustly estimate contact for arbitrary images we need a rich dataset that combines in-the-wild images with precise 3D annotations; see Fig. 2. This is a huge challenge.
To address this challenge, we present a novel method and a new dataset. We first collect a dataset with 3D contact annotations for in-the-wild images using a novel interactive 3D labelling tool (Fig. 2). We then train a novel 3D contact detector that takes a single image as input and produces dense contact labels on a 3D body mesh (Fig. 1). Training on our new dataset means that the method generalizes well.
Contact data: To train a 3D contact detector that is both accurate and robust, we need appropriate training data. How-ever, existing datasets for 3D contact [3, 24, 28] involve pre-scanning a 3D scene and estimating 3D human pose and shape (HPS) of people in the scene. These approaches are limited in the complexity of the human-scene interac-tions, the size of the dataset, and very few methods capture human-object interactions paired with image data [4, 29].
An alternative is to use synthetic data [59], but getting realis-tic synthetic data of complex human contacts is challenging, causing a domain gap between the dataset and real images.
In contrast, crowdsourced image annotations support many tasks in computer vision such as image classifica-tion [12], object detection [41, 72], semantic segmenta-tion [27, 41], 2D human pose estimation [1, 6], and 3D body shape estimation [10, 61]. HOT [8] takes this approach for human-object contact, but the labels are all in 2D, while con-tact is fundamentally 3D. Consequently, we collect a large dataset with dense 3D contact annotations for in-the-wild images, called DAMON (Dense Annotation of 3D huMan
Figure 2: Sample contact annotations from the DAMON dataset. Left to Right: RGB image, two views showing human-supported contact (color-coded by object labels), and two views showing scene-supported contact.
Object contact in Natural images). We enable this with a new interactive software tool that lets people “paint” con-tact areas on a 3D body mesh such that these reflect the observed contact in images. We use Amazon Mechanical
Turk, train human annotators for our task, and collect a rich corpus of 3D contact annotations for standard datasets of in-the-wild images of diverse human-object interactions, i.e.,
V-COCO [22] and HAKE [37]; Fig. 2 shows samples of our dataset. Note how contact and support regions are distin-guished as are the semantic labels related to object contact.
Contact detection: As noted in the literature [8, 28], con-tact areas are ipso facto occluded in images, thus, detecting contact requires reasoning about the involved body-parts and scene elements. To this end, BSTRO [28] uses a transformer
[39] with positional encoding based on body-vertex posi-tions to implicitly learn the context around these, but has no explicit attention over body or scene parts. HOT [8, 28], on the other hand, focuses only on 2D, pulls image features, and processes them with two branches in parallel, a contact branch and a body-part attention branch; the latter helps the
contact features attend areas on and around body parts.
We go beyond prior work to estimate detailed 3D contact on the body. Our method, DECO (Dense Estimation of 3D human-scene COntact in the wild), introduces two technical novelties: (1) DECO uses not only body-part-driven atten-tion, but also adds scene-context-driven attention, as well as a cross-attention module; this explicitly encourages contact features computed from the image to attend to meaningful areas both on (and near) body parts and scene elements. (2) DECO uses a new 2D Pixel Anchoring Loss (PAL) that relates the inferred 3D contacts to the respective image pix-els. For this, we infer a 3D body mesh with CLIFF [38] (SOTA for HPS), detect which vertices of this are in con-tact with DECO, project the 3D contact vertices onto the image, and encourage them to lie in HOT’s corresponding 2D contact-area annotations. Note that this brings together both crowd-sourced 2D and 3D contact annotations.
Experiments: We perform detailed quantitative experi-ments and find that DECO outperforms BSTRO on the test sets of RICH and DAMON, when both are trained on the same data. Ablation studies show that our two-branch archi-tecture effectively combines body part and scene information.
We also provide ablation studies of the backbone and training data. We show that the inferred contact from DECO signif-icantly outperforms methods that compute the geometric vertex distance between a reconstructed object and human mesh [73, 81]. Finally, we use DECO’s estimated contact in the task of 3D human pose and shape estimation and find that exploiting estimated contact improves accuracy.
Contributions: In summary, our contributions are (1)
We collect DAMON, a large-scale dataset with dense vertex-level 3D contact annotations for in-the-wild images of human-object interactions. (2) Using DAMON, we train
DECO, a novel regressor that cross-attends to both body parts and scene elements to predict 3D contact on a body.
DECO outperforms existing contact detectors, and all its components contribute to performance. This shows that learning 3D contact estimation from natural images is possi-(3) We integrate DECO’s inferred 3D contacts into ble. a 3D HPS method and show that this boosts accuracy. (4) Our data, models, and code are available at https:
//deco.is.tue.mpg.de. 2.