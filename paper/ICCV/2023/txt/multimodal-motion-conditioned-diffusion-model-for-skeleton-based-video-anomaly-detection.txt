Abstract
Anomalies are rare and anomaly detection is often there-fore framed as One-Class Classification (OCC), i.e. trained solely on normalcy. Leading OCC techniques constrain the latent representations of normal1 motions to limited vol-umes and detect as abnormal anything outside, which ac-counts satisfactorily for the openset’ness of anomalies. But normalcy shares the same openset’ness property since hu-mans can perform the same action in several ways, which the leading techniques neglect.
We propose a novel generative model for video anomaly detection (VAD), which assumes that both normality and abnormality are multimodal. We consider skeletal represen-tations and leverage state-of-the-art diffusion probabilistic models to generate multimodal future human poses. We contribute a novel conditioning on the past motion of people and exploit the improved mode coverage capabilities of dif-fusion processes to generate different-but-plausible future motions. Upon the statistical aggregation of future modes, an anomaly is detected when the generated set of motions is not pertinent to the actual future. We validate our model on 4 established benchmarks: UBnormal, HR-UBnormal,
HR-STC, and HR-Avenue, with extensive experiments sur-passing state-of-the-art results. 1.

Introduction
Video Anomaly Detection (VAD) is a crucial task in computer vision and security applications. It enables early detection of unusual or abnormal events in videos, such as accidents, illnesses, or people’s behavior which may threaten public safety [41]. However, several aspects make
VAD a challenging task. Firstly, the definition of anomaly
*Authors contributed equally.
Figure 1: MoCoDAD detects anomalies by synthesizing and statistically aggregating multi-modal future motions, conditioned on past poses (frames on the left). Red (top) and green (bottom) distributions represent examples of anomaly and normality generations (2d mapped via t-SNE).
Within the distribution modes (dashed-contoured), the red dots are the actual true futures corresponding to the condi-tioning past frames. In the case of normality, the true future lies within a main distribution mode, and the generated pre-dictions are pertinent. In the case of abnormality, the true future lies in the tail of the distribution modes, which yields poorer predictions, highlighting anomalies. is highly subjective and varies depending on the context and application, making it difficult to define it universally. Sec-ondly, anomalies are intrinsically rare. To account for data scarcity, models generally learn from regular samples only (also known as One Class Classification - OCC) or have to
cope with the data imbalance. Thirdly, anomaly detection is intrinsically an openset problem, and modeling anomalies needs to account for diversity beyond the training set.
An “ideal” model for anomaly detection should con-sider that there are infinitely many anomalous and non-anomalous ways of performing an action. Current state-of-the-art OCC techniques [9, 24, 25, 26] fail to address this issue.
Indeed, they focus on learning either a single reconstruction or prediction of the input, or deriving a la-tent representation of normal1 actions, thereby constraining them to a limited latent volume. This last approach suc-cessfully accounts for the openset’ness of anomalies, i.e., anything mapped outside the normality region is considered abnormal. However, forcing normality into constrained vol-umes may not work for diverse-but-still-normal behaviors, i.e., OCC misclassifies as anomalous those not fitting in the volume.
We propose Motion Conditioned Diffusion Anomaly
Detection - hereafter MoCoDAD - a novel generative model for VAD, which assumes that both normality and abnormal-ity are multimodal2. Given a motion sequence, be it normal or anomalous, the sequence is split and the later (future) frames are corrupted to become random noise. Conditioned on the first (past) clean input frames, MoCoDAD synthe-sizes multimodal reconstructions of the corrupted frames.
MoCoDAD discerns normality from anomaly by compar-ing the multimodal distributions. In the case of normality, the generated motions are diverse but pertinent, i.e. they are biased towards the true uncorrupted frames. In the case of abnormality, the synthesized motion is also diverse, but it lacks pertinence, as shown in Fig. 1 and discussed in Sec. 5.
MoCoDAD is the first diffusion-based technique for video anomaly detection. We are inspired by Denoising
Diffusion Probabilistic Models (DDPMs) [40, 14], state-of-the-art, among others, in image synthesis [31, 30, 33], motion synthesis [43, 49], and 3D generation tasks [53].
DDPMs are selected for their improved mode cover-age [48], i.e. they generate diverse multimodal motions, which MoCoDAD statistically aggregates (see the respec-tive ablative study in Sec. 5).
Besides multimodality, a crucial aspect of MoCoDAD is the choice of the conditioning strategy to guide the synthe-sis. We consider human motion as skeletal representations and propose corrupting the body joint coordinates at each frame by displacing them with random translations. Condi-tioning refers to the process that provides the model with the uncorrupted first part of the motion sequence (past) to guide the denoising of the corrupted second part (future). In this study, we compare three modeling choices to find the most 1To avoid ambiguity, in this work, the term “normal” is the contrary of anomalous, not the synonym of “Gaussian”. Normal refers to “normality” (or “normalcy”). Anomalous/abnormal refers to abnormality/anomaly. 2In this work, multimodal refers to distributions with multiple modes, not to mixing modalities (video, audio, text, etc.) suitable conditioning strategy. We experiment with (1) di-rectly feeding the denoising module with the concatenation of the uncorrupted poses with the displaced sequence [35].
For the other two strategies, we get a latent representation of the input (via (2) an encoding module and (3) an autoen-coder) and feed the network with this learned representation (cf. Sec. 3.2). The third strategy works best (cf. Sec. 5.3). of anomalies, human-related
We evaluate MoCoDAD on three challenging bench-marks namely, HR-UBnormal [1, 9], HR-ShanghaiTech Campus [23, 26] (HR-STC), and HR-Avenue [22, 26], and on the most recent VAD dataset UBnormal [1]. MoCoDAD achieves state-of-the-art (SoA) performance on all four datasets, which demonstrates the effectiveness of modeling multi-modality for normal and abnormal motions. Notably, by not using appearance, MoCoDAD benefits increased privacy protection (no visual facial nor body features) and better computational efficiency, thanks to the lightweight body kinematic representations. We summarize our contributions as follows:
• A novel generative VAD model based on compar-ing the multimodality of normal and abnormal motion generations;
• The first probabilistic diffusion-based approach for
VAD, which fully exploits the enhanced mode-coverage capabilities of diffusive probabilistic models;
• A novel motion-based conditioning on the clean input sequence to steer the synthesis towards diverse perti-nent motion in the case of normality;
• A thorough validation on UBnormal, HR-UBnormal,
HR-STC, and HR-Avenue benchmarks where we out-perform the SoA by 5.1%, 4.4%, .5%, .8%, respec-tively. 2.