Abstract
Existing shadow detection datasets often contain missing or mislabeled shadows, which can hinder the performance of deep learning models trained directly on such data. To address this issue, we propose SILT, the Shadow-aware It-erative Label Tuning framework, which explicitly consid-ers noise in shadow labels and trains the deep model in a self-training manner. Specifically, we incorporate strong data augmentations with shadow counterfeiting to help the network better recognize non-shadow regions and alleviate overfitting. We also devise a simple yet effective label tun-ing strategy with global-local fusion and shadow-aware fil-tering to encourage the network to make significant refine-ments on the noisy labels. We evaluate the performance of
SILT by relabeling the test set of the SBU [55] dataset and conducting various experiments. Our results show that even a simple U-Net [42] trained with SILT can outperform all state-of-the-art methods by a large margin. When trained on SBU / UCF [78] / ISTD [56], our network can success-fully reduce the Balanced Error Rate by 25.2% / 36.9% / 21.3% over the best state-of-the-art method. 1.

Introduction
Detecting shadows is very challenging, since shadows have no specific shapes, colors, or textures, and their in-tensity may just be slightly lower than the surroundings.
Thanks to the advances in deep learning, many works [81, 80, 3, 73] have been developed and they show great progress in detecting shadows. They mostly propose new and deli-cate network architectures and train the network directly on shadow datasets with labeled shadow regions.
However, it can be observed that labels in existing datasets [78, 13] may not be accurate. For example, as
Fig. 1 shows, the training samples may lack details (row 1); some shadows could be incomplete (row 2); some self
*Joint first authors
â€ Corresponding author (xwhu@cse.cuhk.edu.hk) (a) Training images in existing datasets (b) Original labels in existing datasets
Figure 1. Column (b): Labels in existing datasets may not be ac-curate. Column (c): Our automatically-refined annotations. Note that row 1 is from UCF [78] and rows 2-4 are from SBU [55]. (c) Our refined labels shadows may be missed (row 3); and the annotations could be rough (row 4). Fundamentally, there are two main rea-sons. First, the annotations of the SBU [55] dataset are generated from a manually lazy-labeled dataset using an
LSSVM-based method, so the resulting annotations can be noisy, and some detailed and background shadows may be ignored. Second, the perception of shadow can be sub-jective, especially for self shadow and soft shadow. Since datasets are typically prepared by several human annotators, shadow and non-shadow regions could be labeled inconsis-tently in the same dataset. Hence, existing methods trained on such noisy datasets could be easily biased by the noisy labels, which hinder them to achieve better performance.
To learn from data with noisy labels, it is intuitive to adopt a self-training framework [65], i.e., train a network
ing out inaccurate predictions. Thirdly, we collect a set of zero-labeled non-shadow images with dark objects to train the network to better identify non-shadow regions. Using the above techniques, we can effectively train a simple U-Net [42] in SILT to iteratively refine the noisy labels in the original datasets. Examples demonstrating the effectiveness of the proposed approach are shown in Fig 1 (c).
For quantitative evaluation, we relabel the test set of
SBU [55] to obtain high-quality and accurate shadow masks, due to the existing issue of noisy labels. With this carefully relabeled test set, we conduct various experiments and demonstrate the superiority of our approach in produc-ing more precise shadow detection results compared to ex-isting state-of-the-art methods. Furthermore, we find that our refined training set can significantly improve the per-formance of these state-of-the-art methods. The code, pre-trained model, and dataset are publicly available at https:
//github.com/Cralence/SILT. 2.