Abstract
We propose NEMTO, the first end-to-end neural render-ing pipeline to model 3D transparent objects with complex geometry and unknown indices of refraction. Commonly used appearance modeling such as the Disney BSDF model cannot accurately address this challenging problem due to the complex light paths bending through refractions and the strong dependency of surface appearance on illumina-tion. With 2D images of the transparent object as input, our method is capable of high-quality novel view and re-lighting synthesis. We leverage implicit Signed Distance
Functions (SDF) to model the object geometry and pro-pose a refraction-aware ray bending network to model the effects of light refraction within the object. Our ray bend-ing network is more tolerant to geometric inaccuracies than traditional physically-based methods for rendering trans-parent objects. We provide extensive evaluations on both synthetic and real-world datasets to demonstrate our high-quality synthesis and the applicability of our method. 1.

Introduction
Modeling transparent objects is important for VR/AR applications as the former are abundant in the real world.
Unlike opaque objects with close-to-zero light transmission, transparent objects allow light to pass through. Such refrac-tion and reflection create complex light paths and give trans-parent objects highly environment-dependent appearances.
Consequently, the appearance and geometry of transparent objects are much more entangled than those of opaque ob-jects [31]. A slight error in object geometry can lead to a global change in appearance [42], as the light path for each ray may thus vary substantially. For these reasons, deriving material and object geometry from images of a transparent object is a highly ill-posed and challenging problem.
Existing work for modeling transparent objects can be classified into two categories. One assumes known indices of refraction (IOR) and reconstructs the complex geometry of transparent objects through either physical devices and structured backlights [9, 24, 37, 38, 40, 42] or neural net-Figure 1. Given as input multi-view images captured under natural illumination, NEMTO is capable of high-quality novel view syn-thesis and relighting through optimizing an end-to-end neural rep-resentation for a transparent object. NEMTO disentangles geome-try and illumination-dependent appearance, which previous neural rendering methods, such as PhySG [45], cannot. works that model geometry with analytical refraction [23].
The other [3] focuses on optimizing the refractive ray path in the scene without modeling the object surface geome-try. However, neither approach is optimal for synthesizing novel views and relighting for transparent objects with com-plex geometry. In this work, we propose a new framework that combines recent advances in Neural Inverse Render-ing [5, 6, 29, 45, 47, 48] to overcome these limitations.
Traditionally, physically-based rendering follows Snell’s
Law to render transparent objects. However, object appear-ance highly depends on geometry estimation, and jointly optimizing both is highly ill-posed. Therefore, our key con-tribution is incorporating a physically-guided Ray Bending
Network (RBN) to disentangle object geometry and light re-fraction. RBN takes the learned geometry [44] as prior, and models light refraction by mapping the incoming ray direc-tion directly to the refracted ray direction exiting the object.
Our method does not assume a homogeneous refractive in-1
Methods
A B C D E F G Task
✗ ✓ ✓ ✗
✗ ✓ ✗
✓ ✓ ✗
✗ ✓ ✓ ✗
✗ ✓ ✗ ✓ ✓ ✓ ✗
✗ ✓ ✓ ✓ ✓ ✗ ✓
NeRF [26]
Eikonal [3]
IDR [44]
PhySG, ... [45, 48]
NEMTO (Ours) ✓ ✓ ✓ ✓ ✓ ✓ ✗
✗
✗
✗ ✓ ✗
✗
✗ ✓ ✓ ✗
✓ ✗
✓ ✗
[40, 24, 42]
TLG [23] d e s a
B
-g m
. o e
G
. t s
E s i s e h t n y
S
I
Table 1. Comparison of relevent methods. The first group fo-cuses on image-based novel view synthesis and relighting, while the second estimates transparent object geometry. (A) can model light refraction for non-opaque objects, (B) allows direct novel view synthesis w/ unknown IOR, (C) allows direct scene relighting w/ unknown IOR, (D) can model object surface, (E) does not re-quire complex setup for image capture, i.e no patterned backlight, turntables, etc., (F) can model transparent materials w/ unknown
IOR, (G) allows estimation of illumination during training. dex or a fixed number of bounces [3, 31], and models the object’s surface with the zero-level set of the Signed Dis-tance Function (SDF). NEMTO thus has the potential to handle a wider range of complex geometry and better adapt to various refractive media than existing transparent object modeling [3, 23]. Furthermore, our RBN can improve the estimated geometry by better disentangling it from the ap-pearance of the object than other neural rendering meth-ods [44, 45]. NEMTO thus makes it practical to model transparent objects in various scenarios, by working with unknown refractive indices and natural environment illumi-nation. Tab. 1 lists the pros and cons of image-based models on novel view and relight synthesis, along with methods fo-cusing on geometry estimation for transparent objects. We identify the first group as our baseline because the second cannot synthesize views without knowing the object IOR.
Experiments show that NEMTO can synthesize higher qual-ity novel views and relighting through our representation of transparent objects than all of our baseline methods.
To summarize, our contributions are as follows:
• We propose NEMTO, the first end-to-end method for novel view synthesis and scene relighting for transpar-ent objects, shown in Fig. 1. Our method can disentan-gle transparent object geometry and appearance.
• We design a physically-guided Ray Bending Network (RBN) for predicting ray paths traversing through the transparent object. The network prediction has better error tolerance for the estimated geometry than analyti-cally calculated refraction.
• NEMTO can easily be adapted to real-world transparent objects and achieve high-quality image-based synthesis. 2.