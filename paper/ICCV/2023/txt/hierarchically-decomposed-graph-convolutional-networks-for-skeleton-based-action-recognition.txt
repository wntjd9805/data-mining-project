Abstract
Edge Set
Graph convolutional networks (GCNs) are the most commonly used methods for skeleton-based action recog-nition and have achieved remarkable performance. Gen-erating adjacency matrices with semantically meaningful edges is particularly important for this task, but extract-ing such edges is challenging problem. To solve this, we propose a hierarchically decomposed graph convolu-tional network (HD-GCN) architecture with a novel hier-archically decomposed graph (HD-Graph). The proposed
HD-GCN effectively decomposes every joint node into sev-eral sets to extract major structurally adjacent and distant edges, and uses them to construct an HD-Graph contain-ing those edges in the same semantic spaces of a human skeleton. In addition, we introduce an attention-guided hi-erarchy aggregation (A-HA) module to highlight the dom-inant hierarchical edge sets of the HD-Graph. Further-more, we apply a new six-way ensemble method, which uses only joint and bone stream without any motion stream.
The proposed model is evaluated and achieves state-of-the-art performance on four large, popular datasets. Fi-nally, we demonstrate the effectiveness of our model with various comparative experiments. Code is available at https://github.com/Jho-Yonsei/HD-GCN. 1.

Introduction
Human action recognition (HAR) is a task that catego-rizes action classes by receiving video data as input. HAR is used in many applications, such as human–computer inter-action and virtual reality. Recently, several RGB-based and skeleton-based HAR methods have been proposed with the development of deep learning technology. However, RGB-based methods [31, 29] cannot robustly recognize human actions because they are strongly influenced by environ-mental noises such as background color, brightness of light,
Set 1
Set 2
Set 3
Set 4
Attention Map
Squat Down
Set 1
Set 2
Set 3
Set 4
Figure 1. The framework of HD-GCN. The input skeleton is ap-plied with various edge sets through a hierarchically decomposed graph (HD-Graph). The red lines are the edges included in the corresponding hierarchy edge set. The network highlights the ma-jor edge sets through the attention map. The darker the color of red line, the more highlighted the edge set, and dotted lines denote unconnected edges. and clothing. Therefore, methods using skeleton modal-ity [35, 24, 36, 26, 5, 4, 18, 2, 15] have attracted attention because they are not affected by these noises. These meth-ods recognize action by receiving 2D or 3D coordinates of major human joints as time-series inputs.
Recent approaches [24, 18, 4, 2] have adopted graph convolutional networks (GCNs) to apply human-skeleton graphs to convolutional layers. However, existing GCN-based methods [35, 24, 25, 4, 2] have the following lim-itations. (1) With the widely used handcrafted graph, the relationships between distant joint nodes are not identified since they use only the relationships of PC edges in the hu-man skeleton. Although the graph with PC edges has a se-mantic significance, the graph with only PC edges suffers from long-range dependency problem as they are heuris-tically fixed. However, for humans to recognize actions, relationships between structurally distant joints as well as between adjacent joints are strongly correlated. Although several methods [24, 2] have attempted to solve such limita-tion by training attention-guided learnable graphs, they still use [35]’s handcrafted graph with their learnable graphs.
Moreover, as the element values of [35]’s graph are more dominant than those of the learnable graphs, they do not ad-equately highlight the relationships between distant nodes. (2) Some recent methods [35, 24, 4, 18] risk falling into suboptimality by simply aggregating the edge features and ignoring the contribution of each edge, thus incompletely recognizing which edges are significant for each skeleton sample. For example, in the case of a ‘squat down’ action, the interactions between the legs and arms should be high-lighted.
Motivated by these limitations, we propose a hierarchi-cally decomposed graph convolutional network (HD-GCN) with a hierarchically decomposed graph (HD-Graph) and attention-guided hierarchy aggregation (A-HA) module. In addition, we present a six-way ensemble method to effec-tively utilize our HD-Graph. The framework of our pro-posed methods is shown in Fig. 1 for ‘squat down’ action.
The HD-GCN incorporates GCNs with our HD-Graph, which identifies the relationships between distant joint nodes in the same semantic spaces (e.g. right and left hands, right and left feet). The same semantic spaces are formed by moving out step by step from the Center of Mass (CoM) node of the graph. For example, if belly is a CoM node, the first semantic space includes the belly node, the next space includes the chest and hip nodes, and the subsequent space includes the left and right shoulder and the left and right hip nodes. The nodes in the same semantic space are defined as hierarchy node set. To detect the relationships between distant joint nodes, network should have large re-ceptive field. The proposed HD-Graph contains both mean-ingful adjacent and distant joint nodes by connecting all the nodes in neighboring hierarchy node sets and identi-fies the connectivity between those nodes for large receptive field. We adopt rooted tree-like structure to effectively rep-resent every edges. We apply a spatial edge convolution (S-EdgeConv) layer to consider semantically close edges which cannot be captured by the HD-Graph for each sam-ple. To create the S-EdgeConv layer, we borrow the struc-ture of [33], which is widely used in 3D point clouds.
To consider the contribution of each edge set, the process of selecting the dominant hierarchical information should depend on the action data sample to give proper attention to the most dominant edge sets. For example, in order to rec-ognize the “clapping” action, a hierarchy edge set that in-cludes both hands must be emphasized. To tackle this issue, we propose an attention-guided hierarchy aggregation (A-HA) module, which consists of two submodules: represen-tative spatial average pooling (RSAP) and hierarchical edge convolution (H-EdgeConv). A scaling bias problem occurs if we use the spatial average pooling module without any node extraction process because each node has a different number of adjacent nodes. To prevent this, we apply RSAP, which includes a representative node extraction process that triggers features after the pooling layer to represent each node. To effectively manage hierarchical features obtained by RSAP, we apply a hierarchical edge convolution (H-EdgeConv) layer. The H-EdgeConv treats each hierarchi-cal feature as a graph node and identifies which hierarchical features should be highlighted via the Euclidean distance in feature space. With the RSAP and the H-EdgeConv, our model successfully determines which hierarchy edge sets and joints should be emphasized among the input features.
The existing ensemble method uses four-stream data composed of the joint, bone, joint motion, and bone mo-tion streams, which are the original skeletal coordinates, spatial differential between joint coordinates, and temporal differential of joint, and temporal differential of the bone, respectively. Most existing ensemble methods [25, 2] use additional motion data, but models that solely utilize mo-tion data exhibit relatively inferior performance. To address this problem, we present a new method, a six-way ensem-ble. We apply this ensemble method by setting three HD-Graphs with joint and bone stream data. Each graph has different CoM nodes to extract features of different seman-tic spaces (see Appendix).
We conduct extensive experiments on four bench-mark action recognition datasets: NTU-RGB+D 60 [22],
NTU-RGB+D 120 [16], Kinetics-Skeleton [11], and
Northwestern-UCLA [30].
Our main contributions are summarized as follows:
•
•
•
We propose a hierarchically decomposed graph (HD-Graph) to thoroughly identify the significant distant edges between the same hierarchy node sets.
We propose an attention-guided hierarchy aggregation (A-HA) module to highlight the key edge sets with rep-resentative spatial average pooling (RSAP) and hierar-chical edge convolution (H-EdgeConv).
We use a new six-way ensemble method for skeleton-based action recognition with HD-Graphs that have different center of mass (CoM), which outperforms regular ensemble without any motion data.
•
Our HD-GCN outperforms the state-of-the-arts on four benchmarks for skeleton-based action recognition. 2.