Abstract
Diffusion Probabilistic Models (DPMs) have recently been employed for image deblurring, formulated as an image-conditioned generation process that maps Gaussian noise to the high-quality image, conditioned on the blurry
Image-conditioned DPMs (icDPMs) have shown input. more realistic results than regression-based methods when trained on pairwise in-domain data. However, their robust-ness in restoring images is unclear when presented with out-of-domain images as they do not impose speciﬁc degrada-tion models or intermediate constraints. To this end, we in-troduce a simple yet effective multiscale structure guidance as an implicit bias that informs the icDPM about the coarse structure of the sharp image at the intermediate layers. This guided formulation leads to a signiﬁcant improvement of the deblurring results, particularly on unseen domain. The guidance is extracted from the latent space of a regression network trained to predict the clean-sharp target at mul-tiple lower resolutions, thus maintaining the most salient sharp structures. With both the blurry input and multiscale guidance, the icDPM model can better understand the blur and recover the clean image. We evaluate a single-dataset trained model on diverse datasets and demonstrate more robust deblurring results with fewer artifacts on unseen data. Our method outperforms existing baselines, achiev-ing state-of-the-art perceptual quality while keeping com-petitive distortion metrics. 1.

Introduction
Image deblurring is a fundamentally ill-posed inverse problem that aims to estimate one (or several) high-quality image(s) given a blurry observation. Deep networks allow for end-to-end image deblurring with pairwise supervised learning. While deep regression-based methods [81, 90, 97, 79, 6, 88, 7, 83, 78, 41, 23, 52] optimize distortion metrics such as PSNR, they often produce over-smoothed outputs that lack visual ﬁdelity [39, 5, 13, 4]. Therefore, perceptual-driven methods [43, 26] aim to produce sharp and visually 1Work done during an internship at Google Research. (cid:65)(cid:265)(cid:296)(cid:315)(cid:310) (cid:87)(cid:119)(cid:122)(cid:88)(cid:213)(cid:310) (cid:137)(cid:56)(cid:271)(cid:299)(cid:264)(cid:213)(cid:299) (cid:34)(cid:213)(cid:202)(cid:259)(cid:315)(cid:299)(cid:57)(cid:177)(cid:265)(cid:156)(cid:939) (cid:241)(cid:203)(cid:34)(cid:119)(cid:87) (cid:241)(cid:203)(cid:34)(cid:119)(cid:87)(cid:1109)(cid:335)(cid:1065)(cid:1109)(cid:233)(cid:315)(cid:241)(cid:209)(cid:177)(cid:265)(cid:203)(cid:213)
Figure 1. Deblurring example on Realblur-J dataset [60] with models only trained on synthetic GoPro data [51], from recent regression-based [88, 82] (MPRNet, UFormer), GAN-based [37] (DeblurGANV2) and image-conditioned diffusion probabilistic methods (icDPM). We introduce a guidance module onto the icDPM formulation, and improves its robustness on unseen image. pleasing images that are still faithful to the sharp reference image, typically with a slight compromise on distortion per-formance, i.e., a less than 3dB drop on PSNR [4, 55] allows for signiﬁcantly better visual quality while still being close to the target image. GANs [16] are leveraged for improved deblurring perception [36, 37]. However, GAN training suffers from instability, mode-collapse and artifacts [47], which may hamper the plausibility of the generated images.
Recently, DPMs [18] further improved the photo-realism in a variety of imaging inverse problems [67, 42, 83, 65, 12], formulated as an image-conditioned generation process, where the DPM takes the degraded estimation as an aux-iliary input. Image-conditioned DPMs (icDPMs) do not es-timate the degradation kernel nor impose any intermediate constraints. These models are trained using a standard de-noising loss [18] with pairwise training data in a supervised fashion. In image restoration, such pairwise training dataset is typically artiﬁcially curated by applying known degrada-tion models on a group of clean images, which inevitably introduces a domain gap between the synthetic training dataset and real-world blurry images. When presented with unseen data, the robustness of icDPMs are rather unclear as the intermediate restoration process is intractable. E.g., we observe a noticeable performance drop when we ap-ply the synthetically trained icDPM to out-of-domain data,
including failure to deblur the input (Fig. 1) and injec-tion of artifacts (Fig. 4 ‘icDPM’ and Fig. 7 ‘DvSR’). We empirically established a connection between domain sen-sitivity and image-conditioning in the existing deblurring icDPMs [65, 67, 83], where the observed poor generaliza-tion is attributed to the naive input-level concatenation and the lack of intermediate constraints during the deblurring process. When optimized on the synthetic training set, over-ﬁtting or memorization [71] may occur, making the model vulnerable to shift of the input distribution. Currently, con-ditioning DPM on blurred or corrupted images is under-explored [61], and we hypothesize that more effective im-age conditioning for icDPM is crucial to make the model more constrained and robust towards unseen domain.
Inspired by traditional blind deblurring algorithms where optimization is made using explicit structural priors (e.g., containing image saliency [56, 85]), we enhance the icDPM backbone (UNet [63]) with a multiscale structure guidance at intermediate layers. These guidance features are obtained through a regression network trained to predict salient sharp features from the input. The guidance, in conjunction with the blurry image, provide more informative cues to the model regarding the speciﬁc degradation in the image. As a result, the model can more accurately recover the clean im-age and generalize more effectively. Our contributions are threefold: (1) we investigate and analyze the domain gen-eralization of conditional diffusion models in motion de-blurring task, and empirically ﬁnd a relationship between model robustness and image-conditioning; (2) we propose an intuitive but effective guidance module that projects the input image to a multiscale structure representation, which is then incorporated as an auxiliary prior to make the diffu-sion model more robust; (3) Compared with existing bench-marks, our single-dataset trained model shows more robust results across different test sets by producing more plausi-ble deblurring and fewer artifacts, quantiﬁed by the state-of-the-art perceptual quality and on par distortion metrics. 2.