Abstract
Anomaly detection (AD) is a crucial machine learn-ing task that aims to learn patterns from a set of normal training samples to identify abnormal samples in test data.
Most existing AD studiesassume that the training and test data are drawn from the same data distribution, but the test data can have large distribution shifts arising in many real-world applications due to different natural variations such as new lighting conditions, object poses, or back-ground appearances, rendering existing AD methods inef-fective in such cases. In this paper, we consider the prob-lem of anomaly detection under distribution shift and es-tablish performance benchmarks on four widely-used AD and out-of-distribution (OOD) generalization datasets. We demonstrate that simple adaptation of state-of-the-art OOD generalization methods to AD settings fails to work effec-tively due to the lack of labeled anomaly data. We further introduce a novel robust AD approach to diverse distribu-tion shifts by minimizing the distribution gap between in-distribution and OOD normal samples in both the training and inference stages in an unsupervised way. Our exten-sive empirical results on the four datasets show that our ap-proach substantially outperforms state-of-the-art AD meth-ods and OOD generalization methods on data with vari-ous distribution shifts, while maintaining the detection ac-curacy on in-distribution data. Code and data are available at https://github.com/mala-lab/ADShift. 1.

Introduction
Anomaly Detection (AD) is a crucial task in machine learning that aims to identify rare and unusual patterns in data. It is an important problem in various domains, such as financial domain [1, 4], cybersecurity [69, 72], industrial inspection [5], and medical diagnosis [66, 68]. Due to the difficulty and/or high cost of collecting labeled anomaly data, current AD studies are focused on unsupervised ap-*Corresponding author: G. Pang (pangguansong@gmail.com).
Figure 1: Illustrative samples for anomaly detection un-der distribution shift. First row: the ‘Wood’ dataset from
MVTec [5]. Second row: the ‘Elephant’ class as normal and the remaining classes as anomaly in PACS [40]. Third row: the ‘0’ class as normal and the remaining classes as anomaly in MNIST [36]/MNIST-M [18]. We aim at distin-guishing anomalies from normal data in both in-distribution test data and out-distribution test data proaches, which aim to learn patterns from a set of normal training samples to identify abnormal samples in test data.
Although existing AD studies have demonstrated promising performance [13, 38, 56, 65], they generally as-sume that the training and test data are drawn from the same data distribution. However, this assumption is often unreal-istic in real-world scenarios as the test data can have large distribution shifts arising in many applications due to dif-ferent natural variations such as new lighting conditions, object poses, or background appearances, rendering the AD methods ineffective in such cases.
Distribution shift is a ubiquitous problem in different real-world applications, which can significantly degrade the performance of models in various tasks such as im-age classification, object detection, and segmentation [18, 34, 40, 85]. Many out-of-distribution (OOD) generaliza-tion methods have been introduced to address this prob-lem [8,19,24, 29,37, 43,48, 55,86]. These OOD generaliza-tion methods rely on large labeled training data from one or multiple relevant domains to learn domain-invariant feature representations. They often require class labels [29, 61, 80], domain labels [9,74,82,88], or the existence of diverse data
[24, 86, 89] in the source domain to learn such robust fea-ture representations. However, the training data in the AD task consists of only one class, and the data is monotonous.
Consequently, it is difficult to adapt existing OOD general-ization techniques to address the AD under distribution shift problem. Trivial adaption of the OOD generalization can fail to learn generalized normality representations, leading to many detection errors, e.g., normal samples with distri-bution shifts cannot be distinguished from anomalous sam-ples and consequently they are detected as anomaly. As shown by the exemplar data in Fig. 1, normal samples in the in-distribution (ID) test data are very similar to the nor-mal training data, and ID anomalies deviate largely from the normal data; however, due to the distribution shift, the nor-mal samples in the OOD test data are substantially different from the ID normal data in terms of foreground and/or back-ground features, and as a result, these normal samples can be falsely detected as anomaly.
In this paper, we tackle the problem of anomaly detec-tion under distribution shift. It is an OOD generalization problem, aiming at learning generalized detection models to accurately detect normal and anomalous samples in test data with distribution shifts, while maintaining the effec-tiveness on in-distribution test data. This is different from the problem of OOD detection [23, 26, 44, 62, 76] that aims to equip supervised learning models with a capability of re-jecting OOD/outlier samples as unknown samples for the sake of model deployment safety. This work makes three main contributions in addressing the OOD generalization problem in the AD task:
• We present an extensive study of the distribution shift problem in AD and establish large performance bench-marks under various distribution shifts using four widely-used datasets adapted from AD and OOD gen-eralization tasks. Our empirical results further reveal that existing state-of-the-art (SOTA) AD and OOD generalization methods fail to work effectively in iden-tifying anomalies under distribution shift.
• We then propose a novel robust AD approach to di-verse distribution shifts, namely generalized normal-ity learning (GNL). GNL minimizes the distribution gap between ID and OOD normal samples in both the training and inference stages in an unsupervised way.
To this end, we introduce a normality-preserved loss function to learn distribution-invariant normality rep-resentations, which enables GNL to learn generalized semantics of the normal training data at different fea-ture levels. GNL also utilizes a test time augmentation method to further reduce the the distribution gap dur-ing the inference stage.
• Extensive experiments show that our approach GNL substantially outperforms state-of-the-art AD methods and OOD generalization methods by over 10% in AU-CROC on data with various distribution shifts, while maintaining the detection accuracy on the ID test data. 2.