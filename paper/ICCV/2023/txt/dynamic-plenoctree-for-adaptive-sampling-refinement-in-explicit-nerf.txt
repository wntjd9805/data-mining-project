Abstract operations octrees
The explicit neural radiance Ô¨Åeld (NeRF) has gained considerable interest for its efÔ¨Åcient training and fast in-ference capabilities, making it a promising direction such as virtual reality and gaming.
In particular, PlenOctree (POT) [43], an explicit hierarchical multi-scale octree rep-resentation, has emerged as a structural and inÔ¨Çuential framework. However, POT‚Äôs Ô¨Åxed structure for direct op-timization is sub-optimal as the scene complexity evolves continuously with updates to cached color and density, ne-cessitating reÔ¨Åning the sampling distribution to capture sig-nal complexity accordingly. To address this issue, we pro-pose the dynamic PlenOctree (DOT), which adaptively re-Ô¨Ånes the sample distribution to adjust to changing scene complexity. SpeciÔ¨Åcally, DOT proposes a concise yet novel hierarchical feature fusion strategy during the iterative ren-dering process. Firstly, it identiÔ¨Åes the regions of inter-est through training signals to ensure adaptive and efÔ¨Å-cient reÔ¨Ånement. Next, rather than directly Ô¨Åltering out valueless nodes, DOT introduces the sampling and prun-ing operations for octrees to aggregate features, enabling rapid parameter learning. Compared with POT, our DOT outperforms it by enhancing visual quality, reducing over 55.15/68.84% parameters, and providing 1.7/1.9 times FPS for NeRF-synthetic and Tanks & Temples, respectively. 1.

Introduction
Rendering photo-realistic scenes and objects is crucial for providing users with an immersive and interactive expe-rience in virtual reality [11, 45] and metaverse [19, 29, 50].
Neural radiance Ô¨Åeld (NeRF) [26] has emerged as a promis-ing solution for modeling 3D scenes and objects with only calibrated multi-view images. Many subsequent ap-proaches [2, 20, 27, 36, 46] have been proposed to further enhance NeRF‚Äôs rendering power in terms of the training time, inference speed, and quality. PlenOctree (POT) [43] nerf sampling fix e d d y n a m i c drop
ùíì < ùõø
Prune
Figure 1: While the POT framework is effective, its Ô¨Åxed octree structure can limit its adaptability to varying scene complexities. We introduce hierarchical feature fusion with sampling/pruning to overcome this limitation, as illustrated by the dashed box below. Varying colors on the grid rep-resent the training signals.
Internal nodes are denoted in orange, while leaf nodes in green. Pruning occurs in re-gions of weak signal, where cached properties in leaf nodes are aggregated, and the averaged value is propagated to in-ternal nodes, which become the new leaves. Complemen-tary sampling takes place in the red regions. The resulting sampling distribution exhibits signiÔ¨Åcant improvement, as highlighted by the red boxes in our Ô¨Ånal octree results. stands out among these approaches. It employs an explicit octree structure with spherical basis functions to accelerate and enhance the rendering quality. Such method achieves high-quality rendering at over 150 FPS on an NVIDIA
V100 GPU, opening up new possibilities for real-time and high-quality rendering, utilizing explicit octrees. Moreover,
POT bridges the implicit and explicit NeRFs. SpeciÔ¨Åcally, it demonstrates that POT can transform the implicit NeRFs into the octree representation, further boosting the NeRF training by Ô¨Åve orders of magnitudes with the early stop.
*L. Wang and Y. Chen are the corresponding authors.
Technically, POT‚Äôs main contributions can be classiÔ¨Åed
into two folds: quality enhancement with non-Lambertian effects and a multi-scale sampling strategy with an oc-tree. Firstly, POT employs spherical harmonics (SH) to model the non-Lambertian view-dependent effects and di-rectly stores them along with the density in POT‚Äôs leaves for fast training and inference. Secondly, POT employs a multi-scale approach that pre-samples density and SH us-ing a multi-level tabulated volume. The resulting octree structure facilitates capturing intricate features with deeper octree sub-divisions and diversiÔ¨Åes the sampling density ac-cording to the distribution of signal complexity, i.e. the ex-pressiveness of cached color and density through the scene.
However, after the octree construction, POT keeps the division Ô¨Åxed for optimization. We argue such a process is sub-optimal, as the signal complexity can vary during train-ing. Therefore, its initial sample distribution may not pro-vide a sufÔ¨Åcient sampling rate, leading to aliasing or over-sampling issues. Our proposed dynamic design addresses emerging questions on how to calibrate the spatial distri-bution and aggregate learned features during its construc-tion.
In addition, there has been growing interest in re-cent research for striking a balance between compactness and expressiveness in NeRF representation, with sampling methods falling into two main categories. The Ô¨Årst cate-gory, known as importance sampling [6, 26], involves pre-dicting the locations of samples and allocating more re-sources to complex regions. Although sampling on regions of interest can effectively capture signal complexity, pre-dicting the locations can be computationally expensive, es-pecially when dealing with millions of rays. The second category [21, 44, 7], such as POT, relies on stratiÔ¨Åed dense sampling, followed by rejecting samples below a certain threshold. While Ô¨Åltering saves computational resources by discarding valueless samples, the heuristic rejection process may accidentally drop valuable samples, potentially low-ering performance. Moreover, this process can break the global view consistency as the volume rendering strives to build a consistent 3D representation across all views.
In this paper, we propose a concise yet novel hierarchical feature fusion approach that combines the beneÔ¨Åts of im-portance sampling and rejection methods. SpeciÔ¨Åcally, we exploit the evolving signal complexity during training by utilizing the ray weight or density values as training signals through importance sampling, which incurs no additional cost. With these guided signals, we employ a rejection method to prune valueless regions and selectively sample the most promising regions to capture Ô¨Åne details, striking a balance between accuracy and efÔ¨Åciency. We temporarily
Ô¨Åx the octree and optimize the cached properties to adapt to recent modiÔ¨Åcation. The entire process is iterative, al-lowing us to progressively calibrate the octree structure to increase its compactness and capture more details as train-ing progresses.
Notably, we do not directly drop out voxels but instead, fuse learned features while modifying the octree division.
As depicted in Fig. 1, our novel hierarchical feature fusion approach facilitates adaptive reÔ¨Ånement and enables rapid parameter learning through octree sampling and pruning operations. We demonstrate its effectiveness by showing that it can save around 60% parameters while enhancing rendering quality across different scenes.
Our extensive experiments demonstrate the beneÔ¨Åts of
DOT over POT. Our method enriches rendering views, re-duces the number of required parameters by around 60%, and nearly doubles the rendering speed. Furthermore, we offer more control over sampling and pruning strength, which enhances Ô¨Çexibility when working with scenes of varying complexity. SpeciÔ¨Åcally, DOT achieves excellent performance, allowing for rendering an 800x800 image at 452 FPS on an RTX 3090 GPU, achieving 1.8 times the
FPS of the POT model.
In summary, this paper makes three major contributions:
‚Ä¢ We improve the Ô¨Åxed octree design in POT, allowing for iterative reÔ¨Ånement of the octree structure based on training signals iteratively without introducing ad-ditional cost.
‚Ä¢ We introduce the hierarchical feature fusion strategy to support the adaptive reÔ¨Ånement of the octree division, enabling rapid parameter learning by aggregating fea-tures via octree sampling/pruning operations.
‚Ä¢ Experiments on two benchmark datasets show that
DOT can dramatically slim POT and accelerate the rendering speed while improving rendering quality. 2.