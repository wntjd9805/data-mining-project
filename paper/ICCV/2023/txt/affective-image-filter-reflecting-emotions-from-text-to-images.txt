Abstract
Understanding the emotions in text and presenting them visually is a very challenging problem that requires a deep understanding of natural language and high-quality image synthesis simultaneously. In this work, we propose Affective
Image Filter (AIF), a novel model that is able to understand the visually-abstract emotions from the text and reﬂect them to visually-concrete images with appropriate colors and tex-tures. We build our model based on the multi-modal trans-former architecture, which uniﬁes both images and texts into tokens and encodes the emotional prior knowledge.
Various loss functions are proposed to understand complex emotions and produce appropriate visualization. In addi-tion, we collect and contribute a new dataset with abundant aesthetic images and emotional texts for training and eval-uating the AIF model. We carefully design four quantitative metrics and conduct a user study to comprehensively eval-# Equal contributions. * Corresponding author. uate the performance, which demonstrates our AIF model outperforms state-of-the-art methods and could evoke spe-ciﬁc emotional responses from human observers. 1.

Introduction
When people share their experiences about events and subjects on social networks (e.g., Twitter), the text is a direct medium to express their opinions and establish emotional connections with other users [22, 43]. Since social media is a highly active platform with a vast amount of content being produced every day, inﬂuencers strive to personalize their content to evoke emotional responses from their followers.
It is well known that “a picture tells a thousand words”.
Images have powerful descriptive abilities, and they could also become affective stimuli that enable people from var-ious backgrounds to understand emotional intention [66].
This motivates us to think that, given written texts that reﬂect personal thoughts and feelings, how we can re-ﬂect visually-abstract emotions from user-provided texts to
visually-concrete images to further enhance the visual ap-peal of their social media posts.
In this work, we propose Affective Image Filter (AIF), a novel task that enables users to create unique and emo-tionally compelling images that “stand out from the crowd”.
The desired properties of a well-qualiﬁed AIF algorithm are outlined in Fig. 1, which demonstrates AIF’s advantages if the following three objectives are met: (i) Emotional ﬁdelity – The AIF model should accurately understand emotions from the text and reﬂect them in an arbitrary image provided by the user (Fig. 1 (a)). (ii) Content consistency – Since the
AIF model acts as an image ﬁlter, it is required to preserve the overall structure and visual content of the content image provided by the user (Fig. 1 (b)). (iii) Controllable synthe-sis – Complementing to the above objectives (i) and (ii), the
AIF model should be capable of synthesizing results using a variety of emotional texts (Fig. 1 (c)).
To achieve these three objectives, we build the AIF model with the multi-modal transformer architecture which uniﬁes both images as well as texts into tokens and encodes the prior knowledge of emotional words by utilizing the va-lence, arousal, and dominance (VAD) dictionary [40]. This prior knowledge assists our AIF model to have an in-depth understanding of the inherent properties behind the emo-tional words. Considering that low-level features (i.e., col-ors and textures) of the visual content could well represent the evoked emotion [37, 65], we train the AIF model to learn the aesthetic style representations from famous paint-ings. The sentiment metric loss is designed to learn rela-tionships between emotions; anchor-based sentiment loss and emotional distribution loss are designed to learn high-dimensional emotional cues; and other visualization losses are adopted to produce aesthetically pleasing images with appropriate colors and textures.
For training and evaluating the AIF model, we col-lect and contribute a new dataset with abundant im-ages and corresponding text descriptions, where each text description could be categorized into one of Mikel’s eight emotions1 [38]. We further provide multiple quan-titative metrics for evaluating whether the AIF model could achieve emotion-speciﬁc concrete visualizations of visually-abstract emotions in user-provided content images.
Our contribution could be summarized as follows:
• For the ﬁrst time, we propose the AIF task to reﬂect visually-abstract emotions from text to images pro-vided by the user and further provide metrics for com-prehensive evaluation of performance.
• We introduce the prior knowledge of visual emotion analysis to develop the AIF model with transformer ar-1Mikel’s eight emotions are: amusement, contentment, awe, excite-ment, fear, sadness, disgust, and anger. chitecture and design novel losses to comprehensively visualize ambiguous and subjective emotions.
• An AIF dataset has been newly collected and pro-cessed. It includes numerous aesthetic images along with multiple emotional text descriptions associated with the closest emotional category. 2.