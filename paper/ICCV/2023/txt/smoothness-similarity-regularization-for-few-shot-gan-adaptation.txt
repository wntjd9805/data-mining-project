Abstract
The task of few-shot GAN adaptation aims to adapt a pre-trained GAN model to a small dataset with very few training images. While existing methods perform well when the dataset for pre-training is structurally similar to the tar-get dataset, the approaches suffer from training instabili-ties or memorization issues when the objects in the two do-mains have a very different structure. To mitigate this limi-tation, we propose a new smoothness similarity regulariza-tion that transfers the inherently learned smoothness of the pre-trained GAN to the few-shot target domain even if the two domains are very different. We evaluate our approach by adapting an unconditional and a class-conditional GAN to diverse few-shot target domains. Our proposed method significantly outperforms prior few-shot GAN adaptation methods in the challenging case of structurally dissimilar source-target domains, while performing on par with the state of the art for similar source-target domains. 1.

Introduction
Generative adversarial networks (GANs) have been shown to be powerful at various image synthesis tasks
[4, 28, 3, 13, 27, 26]. The success of these models is in large part enabled by the availability of large datasets for train-ing, typically consisting of thousands of images. However, there are many applications and computer vision tasks such as one-shot or few-shot learning [1, 33], out-of-distribution detection [24], or long-tailed recognition tasks [8] where the number of available training images is very low.
Since training a GAN from scratch on very few samples does not perform well as shown in Fig. 1, a common strat-egy is to fine-tune a pre-trained GAN model on the few-shot dataset, typically employing additional regularization losses to penalize the degradation of the diversity [23, 37]. This approach, referred to as few-shot GAN adaptation, performs well when the target domain is structurally very similar to the dataset that has been used for pre-training, e.g., pho-tographs vs. sketches of human faces. However, the perfor-mance drastically degrades in case of large dissimilarities between the source and target domain as shown in Fig. 1.
Figure 1. Training a GAN model G on a few-shot dataset (row 1) from scratch fails due to training instabilities (row 2). We thus aim to adapt a GAN Gs that has been pre-trained on a large dataset like
LSUN-Church (row 3) to the target few-shot dataset (Gt). While fine-tuning [23] does not perform well either if source and target are dissimilar (row 4), our approach generates diverse and realistic images (row 5) by transferring the smoothness properties of Gs.
Such dissimilarities are a major bottleneck of using GANs in other disciplines like medicine, production, or crop sci-ence, where there is a lack of large datasets due to privacy, confidentiality, or simply lack of data. Motivated by this fact, we extend the protocol for few-shot GAN adaptation by investigating also pairs of datasets that are very different like churches and shells as shown in Fig. 1.
To improve few-shot GAN adaptation in the case of structurally dissimilar pairs, we propose a new GAN adap-tation strategy. Firstly, we propose a new smoothness simi-larity regularization for the generator. Our key observation is that pre-trained GAN generators, regardless of the exact structure of objects in the pre-training dataset, learn well-structured and smooth latent spaces. For example, prior works demonstrated that various local shifts in the latent space can lead to interpretable and smooth transitions of
output images, such as translation of objects in the scene or changing their size [34, 9, 30]. As we show in our ex-periments, the proposed smoothness similarity regulariza-tion enables the transfer of this desirable property to other few-shot image domains without compromising the synthe-sis quality. Secondly, to overcome overfitting issues, we revisit the adversarial loss function of the discriminator and propose a simple yet efficient modification by computing the loss at different layers of the discriminator. This leads to the mitigation of overfitting and a more stabilized adap-tation of the model to diverse target domains.
We evaluate our approach by adapting an unconditional
[15] and a class-conditional GAN [2] to diverse few-shot target domains. Our model significantly outperforms previ-ous state-of-the-art methods in image quality and diversity in the challenging case of dissimilar source and target do-mains, while performing on par with the state of the art on structurally similar dataset pairs. In summary, our contribu-tions are as follows: (i) We extend the evaluation protocol for few-shot GAN adaptation by including new dataset pairs that are structurally much less similar than was considered in prior work. (ii) We propose a new smoothness similarity regularization, which enables diverse synthesis in the tar-get domain by transferring the learned smoothness of a pre-trained GAN. (iii) We revisit the adversarial loss function of the discriminator to stabilize few-shot GAN adaptation across diverse target domains. (iv) Our proposed model en-ables high-quality synthesis in the challenging case of dis-similar source and target domains, significantly outperform-ing prior methods. In addition, we show that our method can be applied to different classes of GAN architectures, in-cluding unconditional and class-conditional GAN models. 2.