Abstract
Unsupervised semantic segmentation is a long-standing challenge in computer vision with great significance. Spec-tral clustering is a theoretically grounded solution to it where the spectral embeddings for pixels are computed to construct distinct clusters. Despite recent progress in en-hancing spectral clustering with powerful pre-trained mod-els, current approaches still suffer from inefficiencies in spectral decomposition and inflexibility in applying them to the test data. This work addresses these issues by casting spectral clustering as a parametric approach that employs neural network-based eigenfunctions to produce spectral embeddings. The outputs of the neural eigenfunctions are further restricted to discrete vectors that indicate clustering assignments directly. As a result, an end-to-end NN-based paradigm of spectral clustering emerges. In practice, the neural eigenfunctions are lightweight and take the features from pre-trained models as inputs, improving training effi-ciency and unleashing the potential of pre-trained models for dense prediction. We conduct extensive empirical stud-ies to validate the effectiveness of our approach and observe significant performance gains over competitive baselines on
Pascal Context, Cityscapes, and ADE20K benchmarks. The code is available at https://github.com/thudzj/
NeuralEigenfunctionSegmentor. 1.

Introduction
Semantic segmentation is essential in understanding the inherent structure and fine-grained information of images.
However, current approaches often hinge on a vast amount of manual annotations to train neural networks (NNs) effec-tively in an end-to-end manner [5, 40]. This is problematic, as obtaining these annotations can be both time-consuming and costly, particularly in fields such as autonomous driving and medical image processing, where annotations are usu-ally collected from domain experts. Thus, finding a way to perform semantic segmentation without manual annotation remains a crucial unresolved problem.
Unsupervised semantic segmentation has recently at-tracted a great deal of attention. A number of methods at-tempt to tackle it by learning fine-grained image features using self-supervised objectives and then applying cluster-ing or grouping techniques [46, 41]. They tend to recog-nize single objects or single semantic categories and strug-gle with complex images. Other approaches have tried to use vision-language cross-modal models (e.g., CLIP [35]) to achieve zero-shot semantic segmentation [48, 39], but they heavily rely on carefully-tuned text prompts and self-training. Compared to the recent approaches, the classic spectral clustering [38], which has stood the test of time, remains an appealing option. In particular, it enjoys solid foundations in spectral graph theoryâ€”it finds the minimum cut of the connectivity graph over pixels.
However, traditional spectral clustering exhibits limita-tions in three aspects: (i) it operates on raw image pix-els, thus is sensitive to color transformations and unable to recognize semantic similarities; (ii) it is computation-ally inefficient due to the involved spectral decomposition; (iii) unlike NN-based methods, it is nontrivial and costly to extend to non-training samples because of its transductive manner. Thus it cannot be performed end-to-end in the test phase. Recent work reveals that pre-trained models such as
ViTs [14] can mitigate the first limitation, significantly im-proving the applicability and effectiveness of spectral clus-tering [30]. Its core contribution is to build the connectivity graph over image patches based on an affinity matrix com-puted with the dense features from pre-trained models. Still, the limitations regarding efficiency and flexibility remain.
The present paper aims to overcome the remaining lim-itations, rendering spectral clustering a simple yet effec-tive baseline for unsupervised semantic segmentation. To tackle the inefficiency issue, we propose to cast the involved spectral decomposition problem as an NN-based optimiza-tion one using the recently developed neural eigenfunction (NeuralEF) technique [12]. Concretely, we first measure the similarities between image patches using both the features extracted from pre-trained models and raw pixels. Treat-ing the similarity matrix (or its variants) as the output of a
kernel function, we then optimize NNs to approximate its principal eigenfunctions. Consequently, our method consti-tutes an NN-based counterpart of spectral embedding. We eliminate the need for an additional grouping step, which is required in prior work [30], by constraining the NN out-put to one-hot vectors that indicate clustering assignments directly. To accomplish this, we use the Gumbel-Softmax estimator [20] for gradient-based optimization during train-ing. These strategies transform spectral clustering from a non-parametric approach to a parametric one, enabling easy and reliable out-of-sample generalization and avoiding solving complex matrix eigenvalue problems during testing.
We perform extensive studies to evaluate the effective-ness of our approach for unsupervised semantic segmenta-tion. We first experiment on the popularly used benchmarks
Pascal Context [31] and Cityscapes [9] based on pre-trained
ViTs, and report superior results compared to leading meth-ods MaskCLIP [48] and ReCo [39]. We further consider the sliding-window-based evaluation protocol [40] and experi-ment on the challenging ADE20K dataset [47] to system-atically study the behavior of our method. In addition, we conduct thorough ablation studies to gain insights into the specification of several core hyper-parameters. 2.