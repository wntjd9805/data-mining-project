Abstract
Neural rendering of implicit surfaces performs well in 3D vision applications. However, it requires dense in-put views as supervision. When only sparse input images are available, output quality drops significantly due to the shape-radiance ambiguity problem. We note that this am-biguity can be constrained when a 3D point is visible in multiple views, as is the case in multi-view stereo (MVS).
We thus propose to regularize neural rendering optimization with an MVS solution. The use of an MVS probability vol-ume and a generalized cross entropy loss leads to a noise-tolerant optimization process. In addition, neural rendering provides global consistency constraints that guide the MVS depth hypothesis sampling and thus improves MVS perfor-mance. Given only three sparse input views, experiments show that our method not only outperforms generic neural rendering models by a large margin but also significantly increases the reconstruction quality of MVS models. 1.

Introduction
Neural surface reconstruction techniques, coupled with coordinate-based neural network models, have become in-creasingly popular in the field of 3D vision [74, 61, 75]. Al-though these methods perform very well, they require dense input views as supervision. This is limiting for many real-world applications where sparse input images are the only source of information, such as robotics, augmented reality, autonomous driving, and scene reconstruction in-the-wild.
As shown in Fig. 1, the reconstruction quality of a scene using VolSDF [74] (a state-of-the-art technique) drops sig-nificantly when only 3 views are used. This is due to the shape-radiance ambiguity problem [82].
The shape-radiance ambiguity [82] means that there is a high probability an incorrect geometry reconstruction sat-isfies the photometric constraint when it is visible from a single view only, as is in the case of sparse views. In that scenario, the photometric loss alone can not guide the model toward a correct solution. To regularize this, we need to constrain surface points to be visible from multiple views,
In the last two rows, we
Figure 1. Shape-Radiance Ambiguity. compare the novel view synthesis results from VolSDF [74] and our model: RGB renderings (left), predicted normal maps (mid-dle), and expected depth maps (right). hence, we need correspondences, as in multi-view stereo (MVS) [7, 38, 68, 71, 72, 9, 77, 21, 70, 80, 66, 69, 63, 84, 86, 16]. Thus, we propose to guide neural rendering op-timization with information from MVS. The challenge is how to effectively incorporate the noisy MVS predictions into the neural rendering pipeline.
Many modern MVS methods [71, 21, 16, 9] integrate the evidence for each possible 3D point into a probability volume and regress depth from it. In order to avoid possi-ble errors in MVS 3D point reconstruction, we do not use point estimates, but the whole probability volume. We also note that the rendering weights in neural rendering methods and the probability volume in MVS actually have the same meaning: the probability that a point at a particular location is visible by multiple views. Based on recent MVS litera-ture [46], we can think of all possible 3D points on a ray as interior or exterior to the object (i.e. a binary classifi-cation problem). Thus, we can treat the MVS probability
volume as a set of noisy labels for the rendering weights (i.e. occupancy values). Posing neural rendering as a clas-sification problem allows the use of cross entropy loss to optimize neural rendering methods. However, as shown by the classification literature [85, 54], the cross entropy loss is sensitive to noisy labels. Instead, we adopt a generalized cross entropy loss [85] to reduce the penalty on false pos-itive MVS predictions and thus increase the optimization’s tolerance to noise.
In order to produce our final geometry, we want to take advantage of global consistency constraints including pho-tometric consistency and surface smoothness imposed by neural rendering. Thus, we propose to incorporate neu-ral surface reconstruction into coarse-to-fine MVS models.
Specifically, we use the coarse stage MVS predictions to regularize neural surface optimization. Then, we use the rendered depth maps to guide the next stage’s depth hy-pothesis sampling in MVS. Moreover, neural surface op-timization only requires 10-15 minutes in current hardware to obtain good results because of strong geometry cues from
MVS. As a result, we obtain much better surface recon-struction than either MVS or neural rendering alone, at a relatively fast speed.
In this paper, we propose S-VolSDF, a novel approach that leverages multi-view stereo priors to optimize neural surface reconstruction with sparse input views. Our main contributions are as follows:
• We propose a simple but effective noise-tolerant cost function that combines multi-view stereo with neu-ral volumetric surface reconstruction methods, so their optimization is regularized by the probability volumes of MVS methods.
• We integrate neural surface reconstruction into multi-ple coarse-to-fine MVS models. Our method consis-tently improves depth estimation for better MVS per-formance at a faster speed.
• We evaluate our method on surface reconstruction and novel view synthesis on the DTU [1] and BlendedMVS
[73] datasets. Our reconstruction is significantly better than both neural rendering and MVS models. 2.