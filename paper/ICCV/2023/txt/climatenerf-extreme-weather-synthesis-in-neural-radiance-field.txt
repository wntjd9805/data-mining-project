Abstract 1.

Introduction
Physical simulations produce excellent predictions of weather effects. Neural radiance ﬁelds produce SOTA scene models. We describe a novel NeRF-editing procedure that can fuse physical simulations with NeRF models of scenes, producing realistic movies of physical phenomena in those scenes. Our application – Climate NeRF – allows people to visualize what climate change outcomes will do to them.
ClimateNeRF allows us to render realistic weather ef-fects, including smog, snow, and ﬂood. Results can be con-trolled with physically meaningful variables like water level.
Qualitative and quantitative studies show that our simulated results are signiﬁcantly more realistic than those from SOTA 2D image editing and SOTA 3D NeRF stylization.
* Both authors contributed equally to this research.
This paper describes a novel procedure that fuses graphic simulations with NeRF models [50, 51] of scenes to pro-duce realistic movies of physical phenomena in those scenes.
We apply our method to produce compelling simulations of possible extreme weather outcomes – what would the playground look like after a minor ﬂood? a major ﬂood? a blizzard?
Our application is aimed at an important problem. Cu-mulative small changes are hard to reason about, and most people ﬁnd it difﬁcult to visualize what climate change out-comes will do to them [9, 23, 26, 37]. Steps to slow CO2 emissions (say, reducing fossil fuel use) or to moderate out-comes (say, building ﬂood control measures) come with immediate costs and distant beneﬁts. It is hard to support such steps if one can’t visualize their effects.
Traditional graphic simulations can produce realistic
Multi-view Input Images 3D Scene Modeling
Sect. 3.1
Neural Scene Stylization
Sect. 3.2
Physically-Inspired Simulation
Sect. 3.3, 3.4
Figure 2: Method overview. Our method takes multiple posed images, the targeted climate event simulation (e.g., snow), and optionally a user-selected style image as inputs. First, we reconstruct the 3D scene using instant NGP [51] (a variant of
NeRF) (Sect. 3.1). The reconstructed radiance ﬁelds allow us to synthesize high-quality novel view imagery of the scene efﬁciently. Second, we optionally ﬁnetune the learned instant-NGP model so that it captures the styles of the provided style image (Sect. 3.2). Such 3D consistent stylization is particularly useful for modeling weather effects that are hard to capture via physical simulation. Third, we simulate the climate events by integrating the relevant physical entities (snow, water, smog) to the scene and rendering physically plausible images. weather effects for 3D scenes in a conventional simulation pipeline [62, 19, 27, 85, 15, 17, 24]. But these methods op-erate on conventional polygon models. Building polygon models that produce compelling renderings from a few im-ages of a scene remains challenging. Neural radiance ﬁelds (NeRFs) produce photorealistic 3D scene models from few images [50, 4, 51, 10, 64, 72, 41] but (as far as we know) have rarely been investigated together with graphics sim-ulations. Our method draws from an extensive literature, reviewed below, that explores editing these models.
Although there are numerous variants of NeRF, most are primarily focused on the task of novel-view synthesis.
Integrating existing NeRF models for graphics simulation yields unsatisfactory results (Fig. 4). Speciﬁcally, we found the geometry of current NeRF models is not sufﬁciently accurate to enable physics-inspired interactions, and they cannot provide a realistic and complete illumination ﬁeld to relight the inserted physics entities, such as water and snow. To address this challenge, we have systematically investigated various techniques to improve NeRF models, focusing on answering the critical research question of “what constitutes a good simulatable NeRF representation?”. Our resulting NeRF variant, ClimateNeRF, boasts high-quality geometry, a complete illumination ﬁeld, and rich semantics, making it particularly well-suited for complex downstream editing and simulation tasks (Sec. 3.1).
ClimateNeRF allows us to render realistic weather ef-fects, including smog, snow, and ﬂood. These effects are consistent over frames so that compelling movies result. At a high level, we: adjust scene images to reﬂect the global effects of physics; build a NeRF model of a scene from those adjusted images; recover an approximate geometric repre-sentation; apply the physical simulation in that geometry; then render using a novel ray tracer. Adjusting the images is essential. For example, trees tend to have less saturated images in winter. We use a novel style transfer approach in an NGP framework to obtain these global effects without changing scene geometry (Sec. 3.2). Our ray tracer merges the physical and NeRF models by carefully accounting for ray effects during rendering (Sec. 3.3). An eye ray could, for example, ﬁrst encounter a high NeRF density (and so return the usual result); or it could strike an inserted water surface (and so be reﬂected to query the model again).
We demonstrate the effectiveness of ClimateNeRF in various 3D scenes from the Tanks and Temple, MipNeRF360, and KITTI-360 datasets [4, 33, 40]. We compared to the state-of-the-art 2D image editing methods, such as stable diffusion inpainting [55], ClimateGAN [60]; state-of-the-art 3D NeRF stylization [78]. Both qualitative and quantitative studies show that our simulated results are signiﬁcantly more realistic than the other competing methods. Furthermore, we also demonstrate the controllability of our physically-inspired approaches, such as changing the water level, wind strength and direction, and thickness of snow and smog.
Our approach results in view consistency (so we can make movies, which is difﬁcult to do with frame-by-frame synthesis); compelling photorealism (because the scene is a
NeRF representation); and is controllable (because we can adjust physically meaningful parameters in the simulation).
As Fig. 1 illustrates, results are photo-realistic, physically
plausible, and temporally consistent.
Our contributions are three-fold: 1. We investigate the challenging problem of repurpos-ing NeRF for realistic simulation and develop a novel framework that can effectively reduce NeRF modeling errors and facilitate graphical simulation. 2. We propose ClimateNeRF, a novel solution that can render realistic weather effects, including smog, snow, and ﬂood, over real-world images. 3. We demonstrate that our proposed approach can pro-duce compelling, photorealistic, geometrically consis-tent, and controllable free-viewpoint movies. 2.