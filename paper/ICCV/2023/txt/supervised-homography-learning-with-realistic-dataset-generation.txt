Abstract
In this paper, we propose an iterative framework, which consists of two phases: a generation phase and a train-ing phase, to generate realistic training data and yield a supervised homography network. In the generation phase, given an unlabeled image pair, we utilize the pre-estimated dominant plane masks and homography of the pair, along with another sampled homography that serves as ground truth to generate a new labeled training pair with realis-tic motion.
In the training phase, the generated data is used to train the supervised homography network, in which the training data is refined via a content consistency mod-ule and a quality assessment module. Once an iteration is finished, the trained network is used in the next data generation phase to update the pre-estimated homography.
Through such an iterative strategy, the quality of the dataset and the performance of the network can be gradually and simultaneously improved. Experimental results show that our method achieves state-of-the-art performance and ex-isting supervised methods can be also improved based on the generated dataset. Code and dataset are available at https://github.com/JianghaiSCU/RealSH. 1.

Introduction
Homography estimation is a fundamental task in com-puter vision that has been widely used for high-dynamic range imaging [40, 24, 25], image stitching [32, 31], and video stabilization [23, 43]. Traditional methods typically use feature extraction and matching methods [26, 3] with outlier suppression [9, 2] to obtain feature matches of two images and subsequently solve direct linear transforma-tion (DLT) [11] to obtain the homography matrix. How-ever, these methods highly rely on the extracted matching keypoints and may crash in challenging scenes that lack
*Equal contribution
†Corresponding authors
Figure 1. The first row shows the target images generated by the previous strategy [6] and our proposed method, visualized by su-perimposing the source image warped by GT homography on the generated target image, where the misaligned pixels are repre-sented as colored ghosts. As highlighted in yellow boxes, the dominant plane is fully aligned by the GT homography, proving that both our method and the previous strategy can satisfy the la-bel criteria. In contrast, only our method can maintain realistic motion between the two images thus satisfying the realism cri-teria, as shown in the red boxes, the car is a moving object that cannot be aligned by a homography. sufficient high-quality feature matches. With the rise of deep learning, such problems have been partially solved, learning-based methods [22, 20, 13] take a pair of images as input and directly output the corresponding homogra-phy, thus are more robust than traditional methods due to their keypoint-free estimation strategy. The learning-based methods can be divided into two categories: supervised and unsupervised. At the moment, benefiting from the label-free characteristic, unsupervised methods can be trained on enormous amounts of real-world data, delivering better performance and generalization capability than supervised ones. We find that the lack of qualified training data is one of the main barriers to the development of supervised meth-ods. Previously supervised dataset generation strategy [6] synthesizes an image pair by using pre-defined ground truth (GT) homography to warp a single image, such strategy considers the whole image as a single plane, neglecting par-allax and foreground motion in the real world. As shown in Fig. 1(a), the two images are fully aligned using the GT homography, but the car in the red box should be a moving object that cannot be aligned by a homography.
In this work, we propose an iterative framework, which is designed to generate image pairs that satisfy both label and realism criteria [10] for supervised homography learn-ing and learns a state-of-the-art homography estimation net-work with the generated dataset. Specifically, given an un-labeled source and target image (Is and It) captured in real-world scenes, we use the homography and dominant plane masks of the two images estimated by the homography esti-mation network and a pre-trained dominant plane detection network, respectively, along with a sampled GT homogra-phy to generate a new target image I t. Then, we use the
Is and I t, together with the sampled GT homography, to compose a training sample of our supervised dataset. The
′ dominant planes of Is and I t can be fully aligned by the
GT homography while the rest remain in realistic motion, making the two images satisfy both label criteria and real-ism criteria. As shown in Fig. 1(b), the dominant plane of the generated image pair can be fully aligned by the GT ho-mography, while the scene parallax and dynamic objects are maintained in the foreground.
′
′
In addition, few artifacts could exist in the generated tar-get image in early iterations, we, therefore, propose a con-tent consistency module and a quality assessment module to eliminate the unexpected content and select high-quality image pairs for training, respectively. The selected image pairs are used to update the homography estimation network which is utilized to estimate homographies for image gen-eration in the next iteration. During the iterative learning steps, the capability of the network is gradually improved, as well as the quality of the synthesized dataset. With our framework, any unlabeled image pairs can be used to gen-erate training samples, thus addressing the lack of quali-fied datasets in supervised homography learning, which im-proves the performance of supervised methods and enables them to be better generalized to real-world scenes. In sum-mary, our main contributions are threefold:
• We propose an iterative deep framework to generate a realistic dataset from unlabeled real-world image pairs for supervised homography learning and simultane-ously obtain a high-precision network based on the generated dataset.
• We propose a content consistency module and a quality assessment module, achieving the elimination of unex-pected content and the selection of qualified data for training.
• Experimental results show that our method brings no-ticeable image realism improvement compared to the prior dataset generation strategy and achieves state-of-the-art performance on public benchmarks. 2.