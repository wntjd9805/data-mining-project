Abstract
This paper proposes a shape anchor guided learning strategy (AncLearn) for robust holistic indoor scene under-standing. We observe that the search space constructed by current methods for proposal feature grouping and in-stance point sampling often introduces massive noise to in-stance detection and mesh reconstruction. Accordingly, we develop AncLearn to generate anchors that dynamically fit instance surfaces to (i) unmix noise and target-related fea-tures for offering reliable proposals at the detection stage, and (ii) reduce outliers in object point sampling for directly providing well-structured geometry priors without segmen-tation during reconstruction. We embed AncLearn into a reconstruction-from-detection learning system (AncRec) to generate high-quality semantic scene models in a purely instance-oriented manner. Experiments conducted on the challenging ScanNetv2 dataset demonstrate that our shape anchor-based method consistently achieves state-of-the-art performance in terms of 3D object detection, layout estima-tion, and shape reconstruction. The code will be available at https://github.com/Geo-Tell/AncRec. 1.

Introduction
Holistic indoor scene understanding from partial obser-vations (e.g., single-view images or 3D scans) is a compre-hensive task that provides 3D semantic scene models for indoor applications. Early works studied this task with a reconstruction-from-detection framework that recovers the geometries of room structures and objects from the cor-responding detection in a separate way. Later, end-to-end learning methods were proposed to simultaneously per-form layout estimation, object detection, and shape predic-tion in one forward pass for semantic scene reconstruction
[27, 37, 23]. With the recent success of point-based 3D detection and instance reconstruction, surging interest has been witnessed in detecting and modeling objects directly
*Corresponding author.
Figure 1. Comparison between different feature grouping strate-gies. (a) the original scene model. (b)-(e) The different feature grouping operations all suffer from the issue of confusing non-target noise with useful features. (f) The proposed shape anchor guided grouper directly generates anchors at the instance surface to merge instance-related features, which largely alleviates noise interference. from sparse point clouds [28, 33].
Benefiting from the use of rich geometry information, current scan-based deep methods have improved the per-formance of semantic scene reconstruction. However, they still left two issues that bottleneck high-quality semantic re-construction: (1) the noisy instance feature learning at the detection phase, and (2) the difficulty in retrieving instances from sparse point clouds for reconstruction.
At the detection phase, it is required to group features for instance representation learning. The ball query [30, 31] and 3D convolution[39, 20] are two basic operations for point feature grouping, but they often mix massive noise with informative features due to the fixed grouping range,
as shown in Fig. 1 (b) and (c). To compensate for the defi-ciency caused by the fixed range, VoteNet [14] and its vari-ants [34, 29, 38, 35] adopt a voting strategy to cluster object features by moving surface points towards object centers.
Albeit more flexible than the basic operations, the voting-based strategy often generates an unconstrained grouping area that brings quantities of outliers as illustrated in Fig. 1 (d). BRNet [10] hence restricts the grouping space by sam-pling around representative points given by coarse box pro-posals. Nevertheless, limited by box-like grouping area, the sampling points can still fall far beyond targets when the objects are irregularly shaped, as depicted in Fig. 1 (e).
At the reconstruction stage, the retrieval of outlier-free object points is a prerequisite for object recovery. Due to the noise introduced by feature grouping in the previous de-tection phase, the points grouped for localizing objects can hardly serve as ideal reconstruction priors as indicated by
Fig. 1. Consequently, the current methods are forced to employ an additional foreground classifier [28] or replace the detector with a complex instance segmentation back-bone to sample object points from the raw scans [33]. How-ever, the existence of numerous non-target outliers in the search space challenges instance segmentation, resulting in increased risks of gluing different instances and misclassi-fying background points.
Based on the discussion above, the two noise interfer-ence issues during detection and reconstruction are actu-ally highly coupled and can be resolved together as long as outliers are excluded during feature grouping. To this end, we are motivated to propose a shape anchor-guided learn-ing strategy (AncLearn) that generates surface anchors to fit the feature grouping areas to object shape distributions, as displayed in Fig. 1 (f). With the geometry constraint pro-vided by surface anchors, it is able to merge local target-focused features for predicting reliable object proposals and construct a shape-aware search space for robustly sampling instance points without segmentation during reconstruction.
The proposed anchor-guided learning strategy can be easily embedded into an end-to-end learning system to accomplish object detection, layout estimation, and instance reconstruc-tion for holistic scene understanding. The main contribu-tions are summarized as follows:
- We present a shape anchor guided learning strategy to simultaneously address the issues of noisy feature learning in detection and instance point retrieval dur-ing reconstruction.
- We embed the proposed anchor-guided learning strat-egy into an end-to-end learning system to accom-plish object detection, layout estimation, and instance reconstruction for holistic scene understanding in a purely instance-oriented way.
- Extensive experiments demonstrate that our AncRec achieves high-quality semantic scene reconstruction with state-of-the-art performance in instance detec-tion and mesh prediction on the challenging Scan-Netv2 dataset [12] (some ground truths provided by
Scan2CAD [1] and SceneCAD [3]). 2.