Abstract
Recovering missing modality is popular in incomplete multimodal learning because it usually benefits downstream tasks. However, the existing methods often directly estimate missing modalities from the observed ones by deep neural networks, lacking consideration of the distribution gap be-tween modalities, resulting in the inconsistency of distri-butions between the recovered and the true data. To mit-igate this issue, in this work, we propose a novel recov-ery paradigm, Distribution-Consistent Modal Recovering (DiCMoR), to transfer the distributions from available modalities to missing modalities, which thus maintains the distribution consistency of recovered data.
In particular, we design a class-specific flow based modality recovery method to transform cross-modal distributions on the condi-tion of sample class, which could well predict a distribution-consistent space for missing modality by virtue of the invert-ibility and exact density estimation of normalizing flow. The generated data from the predicted distribution is integrated with available modalities for the task of classification. Ex-periments show that DiCMoR gains superior performances and is more robust than existing state-of-the-art methods under various missing patterns. Visualization results show that the distribution gaps between recovered modalities and missing modalities are mitigated. Codes are released at https://github.com/mdswyz/DiCMoR. 1.

Introduction
Multimodal machine learning dedicates to designing a strong model for understanding, reasoning, and learning by fusing multimodal data, such as language, acoustic, image, et al [15, 24]. Researchers have extensively ex-ploited how to effectively encode the discriminative repre-sentations from different modalities [22, 33, 3, 28]. How-* The corresponding authors.
Figure 1. Two paradigms for missing modality recovery. (a) Typ-ical paradigm usually exploits a well-crafted encoder and decoder modality recovery. (b) Our method transfers the distribution from the available to the missing modality, aiming to guarantee the dis-(c) Recovered and ground truth modality tribution consistency. distribution visualization comparison between MCTN [20] (top) and our DiCMoR (bottom). DiCMoR exhibits a higher degree of proximity to the ground truth. More results can be found in Fig. 3. ever, in real world scenarios, the well-trained model may be deployed when certain modalities are not available, e.g., language may be unavailable due to speech recognition er-rors; acoustic modality may be lost due to background noise or sensor sensing limitations; visual data may be unavail-able due to lighting, occlusion, or social privacy security.
In practice, the problem of missing modality inevitably de-grades the multimodal understanding performance.
To address this problem, a straightforward way is to con-duct data recovery and then perform downstream tasks on the recovered data. As shown in Fig. 1 (a), this is a typical recovery paradigm that has been extensively studied by re-searchers [23, 20, 34, 16]. The core of this paradigm aims to design a well-crafted encoder and decoder, and then take as input the available modality so as to recover the miss-ing modality. Tran et al. [23] proposed a cascaded residual autoencoder architecture to reconstruct the missing modal-ities; Lian et al. [16] leveraged graph neural networks to estimate the missing modalities from partially observed in-put. However, this paradigm fails to fully consider the dis-tribution gap caused the inherent modality heterogeneity, resulting in the inconsistent distribution between the vanilla available and the corresponding recovered modality.
In this work, we propose a novel framework to mitigate the above issues. As shown in Fig. 1 (b), different from the previous paradigm, we transfer the distribution from the available modalities to the missing modalities before decod-ing the missing data. The missing modality is then recov-ered under the estimated distribution. Thus, the key is to construct and learn a model that has the ability to perform transformations between cross-modal distributions.
To this end, we propose a distribution-consistent modal recovering (DiCMoR) method to complete those missing modalities for robust multimodal understanding. To trans-form cross-modal distributions, we introduce the modality-related flows and bridge different modalities within the em-bedded distribution space. To facilitate the distribution transfer, the invertible modality-specific normalizing flow is used for each modality to map the features of different modalities into the latent spaces with gaussian distributions, which reduces the distribution gap between the modalities.
In the latent distribution space, the latent states of the miss-ing modality could be sampled to feed into the inverse flow to faithfully estimate the original missing data. To increase the discriminability, the modality-related flows are built on condition of class labels to avoid the common collapse of different-class samples.
In other words, we constrain the latent spaces from the same class but different modalities share the same class-specific Gaussian distribution, aim-ing to enhance the discriminative ability of the recovered modality. Owing to the favorable attributes inherent to flow-based models, such as their invertibility and capacity for precise density estimation, an assurance of distributional congruence emerges between the inferred data and the ac-tual ground truth. Finally, the recovered modalities together with the available modalities could be jointly fed into mul-timodal fusion network for the downstream tasks. The con-tributions of this work are summarized as:
• We propose a novel missing modality recovery frame-work by transferring the distributions from the avail-able modalities to the missing modalities, which re-duces the distribution gap between the recovered data and the vanilla available data.
• We propose a cross-modal distribution transformation method by designing class-specific multimodal flows, which not only ensures the congruence of the distribu-tions but also enhances the discriminative capacity.
• We experimentally verify the superiority of the method in various modality-missing patterns. Visualization re-sults demonstrate that distribution gaps between recov-ered and missing modalities are obviously reduced. 2.