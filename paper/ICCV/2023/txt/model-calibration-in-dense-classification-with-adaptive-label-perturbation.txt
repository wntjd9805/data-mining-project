Abstract
For safety-related applications, it is crucial to pro-duce trustworthy deep neural networks whose prediction is associated with confidence that can represent the like-lihood of correctness for subsequent decision-making. Ex-isting dense binary classification models are prone to be-ing over-confident. To improve model calibration, we pro-pose Adaptive Stochastic Label Perturbation (ASLP) which learns a unique label perturbation level for each training image. ASLP employs our proposed Self-Calibrating Bi-nary Cross Entropy (SC-BCE) loss, which unifies label per-turbation processes including stochastic approaches (like
DisturbLabel), and label smoothing, to correct calibra-tion while maintaining classification rates. ASLP follows
Maximum Entropy Inference of classic statistical mechan-ics to maximise prediction entropy with respect to missing information.
It performs this while: (1) preserving clas-sification accuracy on known data as a conservative so-lution, or (2) specifically improves model calibration de-gree by minimising the gap between the prediction accu-racy and expected confidence of the target training label.
Extensive results demonstrate that ASLP can significantly improve calibration degrees of dense binary classifica-tion models on both in-distribution and out-of-distribution data. The code is available on https://github.com/
Carlisle-Liu/ASLP. 1.

Introduction
Binary segmentation aims to differentiate foreground ar-eas from the background in images. Its tasks include Salient
Object Detection [86], Camouflaged Object Detection [13],
Smoke Detection [79], etc. Performance in these tasks has been significantly advanced using the strong representation powers of Deep Neural Networks (DNNs). However, with complex structures and a tremendous number of parame-ters, DNNs are prone to over-fitting to training data and producing over-confident predictions in the real world [18].
Such issues can render the model predictions unreliable in decision making or utilisation in downstream tasks.
Recently, a growing body of literature has been pro-Figure 1: Applying Adaptive Label Perturbation during training can effectively moderate predictions at incorrect areas, highlighting them with high entropy values (red).
Zt(x, y) is a sample-wise Bernoulli variable, parameterized by α, at the tth iteration. After k iterations, update α using
Eq. (5) to adjust the likelihood (or level) of label pertur-bation to increase entropy for incorrect predictions and so correct model calibration. The Perturbed Label (shown in-verted) replaces the Groundtruth Label with probability α. posed to address model mis-calibration problems in DNNs.
They can be roughly categorised as: (1) post-hoc opera-tions, such as temperature scaling [18], Platt scaling [54], etc., (2) training objective approaches [27], like MMCE
[30], soft calibration objective [27], focal loss [45, 17], and (3) data/label augmentation techniques, e.g. label smooth-ing [46] and mixup [85]. We propose an Adaptive Label
Perturbation which learns a unique label perturbation level for each training image. As illustrated in Fig. 1, train-ing with Adaptive Stochastic Label Perturbation, a form of ALP, can effectively moderate incorrect predictions and highlight them with high entropy values.
Adaptive Label Perturbation employs our proposed Self-Calibrating Binary Cross Entropy (SC-BCE) loss, which unifies label perturbation processes including stochastic ap-proaches (like DisturbLabel [75]), and label smoothing [60] to correct calibration while maintaining classification accu-racy. SC-BCE loss is equivalent to a factored combination of (i) a BCE loss w.r.t. groundtruth label, and (ii) a BCE loss w.r.t. a uniform binary categorical distribution. The former enhances dense binary classification performance and the latter improves the model calibration degree. Our method can be connected to Maximum Entropy Inference
[23] of classic statistical mechanics, to maximise prediction
entropy with respect to missing information while preserv-ing the classification accuracy on known data.
The proposed Adaptive Label Perturbation (ALP) can approximate Maximum Entropy Inference [23] to maximise prediction entropy while preserving the ideal dense classifi-cation performance on known data. This represents a con-servative solution that adopts classification accuracy as a proxy for known data and assumes maximum disorder on unknown data. We also present an alternative ALP solution that, instead, takes model calibration degree as a proxy for known data, using a calibration regulariser which constrains the expected confidence of individual supervision signal to not drop below the ideal accuracy on the validation set. This effectively minimises the gap between the distributions of prediction confidence and prediction accuracy, which is the source of model mis-calibration.
Our contributions can be summarised as: (i) We pro-pose Adaptive Stochastic Label Perturbation that learns a sample-wise label perturbation level to improve model cali-bration; (ii) We present a Self-Calibrating Binary Cross En-tropy loss that unifies label perturbation processes including stochastic approaches and label smoothing; (iii) Following
Maximum Entropy Inference [23] we show that Adaptive
Stochastic Label Perturbation (ASLPMEI), can maximise the prediction entropy while preserving the ideal dense classifi-cation accuracy, and (iv) We present an alternative Adaptive
Stochastic Label Perturbation (ASLPMC) solution to max-imise model calibration degree, which achieves state-of-the-art performance in terms of model calibration degree on both in-distribution and out-of-distribution data. We thor-oughly evaluate our method on Salient Object Detection and demonstrate its effectiveness for Camouflaged Object
Detection, Smoke Detection and Semantic Segmentation. 2.