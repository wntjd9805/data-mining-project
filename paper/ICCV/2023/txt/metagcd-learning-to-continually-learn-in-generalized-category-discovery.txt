Abstract
In this paper, we consider a real-world scenario where a model that is trained on pre-defined classes continually en-counters unlabeled data that contains both known and novel classes. The goal is to continually discover novel classes while maintaining the performance in known classes. We name the setting Continual Generalized Category Discov-ery (C-GCD). Existing methods for novel class discovery cannot directly handle the C-GCD setting due to some un-realistic assumptions, such as the unlabeled data only con-taining novel classes. Furthermore, they fail to discover
In this work, we novel classes in a continual fashion. lift all these assumptions and propose an approach, called
MetaGCD, to learn how to incrementally discover with less forgetting. Our proposed method uses a meta-learning framework and leverages the offline labeled data to simulate the testing incremental learning process. A meta-objective is defined to revolve around two conflicting learning objec-tives to achieve novel class discovery without forgetting.
Furthermore, a soft neighborhood-based contrastive net-work is proposed to discriminate uncorrelated images while attracting correlated images. We build strong baselines and conduct extensive experiments on three widely used bench-marks to demonstrate the superiority of our method. 1.

Introduction
Object categories in real-world environments are dynam-ically evolving and expanding over time. However, conven-tional deep learning-based visual recognition methods nor-mally focus on closed-world scenarios with pre-defined cat-egories [19, 37]. Such systems are brittle when deployed to
*The authors contributed equally to this work.
†Corresponding Author
Figure 1: Illustration of our C-GCD setting. During the offline training, we learn an initial model based on training samples of the labeled set. During each subsequent online incremental learning, we are given some unlabeled images belonging to both known and novel classes. Our goal is to update the model in each incremental session so that the model can maintain the performance on old classes while discovering novel classes. an ever-changing realistic open-world setting, where object instances may come from new categories. In contrast, rec-ognizing the known categories and utilizing them to discern the unknowns are intrinsic to human perception.
Recently, discovering the novel classes among unlabeled data has been an active area of research [15, 11, 40, 35, 45].
However, most prior works make several assumptions that are unrealistic in practice. For example, the works in
[15, 11, 40] assume the co-existence of both labeled data (with known classes) and unlabeled data (contains potential unknown classes to be discovered) at the training phase and
the models are learned from scratch. This leads to repet-itive large-scale training every time when new classes are expected to be discovered. The works in [15, 11, 35, 45] as-sume the newly encountered unlabeled data only belongs to the novel classes. This is unrealistic in practice. To meet such conditions, a rigorous filtering method is needed to precisely filter out known class data to avoid degenerate so-lutions. Due to these limitations, none of these works can be used to build recognition systems that can deal with evolv-ing object categories sequentially over a long time horizon.
In this paper, we consider a more flexible setting for real-world applications. Let us consider the application of home robots. The robots are equipped with an offline trained object recognition model on pre-defined categories during manufacturing. After deployment, the robots are expected to operate in diverse environments. While operating, they continually receive data that belongs to known and possibly unknown classes. Ideally, we would like the robots to con-tinually discover and learn novel classes from such data.
We dub such a setting as Continuous Generalized Class
Discovery (C-GCD). As shown in Fig. 1, C-GCD has two phases: 1) an offline training phase that allows the model to be trained on large-scale labeled data with pre-defined classes; 2) when the model is deployed, it continually en-counters unlabeled data that comes from both known and novel classes on a longer horizon. At each incremental ses-sion, the data from the previous sessions is inaccessible.
The model needs to precisely classify the known classes and discover novel ones to expand its knowledge base. Obvi-ously, the main challenge of C-GCD is to discover the novel classes among unlabeled images that contain both known and unknown categories while maintaining the performance on old classes. However, learning novel knowledge nor-mally leads to notorious catastrophic forgetting [7], which further exacerbates the model performance.
There are some initial attempts on C-GCD [21, 45].
However, they only consider C-GCD at the deployment stage mentioned above. The offline training stage is not fully exploited in these works. Concretely, the labeled data during offline training is only used for pre-training model representations. Therefore, the model at the of-fline stage is unaware of its subsequent learning duty (dis-cover novel classes and retain the performance of known classes) [8] and is also prone to overfit to the labeled set [40]. Such learning objective misalignment leads to cumbersome heuristic strategies to facilitate the new learn-ing task while keeping the previous knowledge. For exam-ple, to learn the novel classes, [21] requires a self-labeling method, which may cause error propagation. A routing strategy is also required to determine the known and novel classifier heads. [45] relies on a thresholding method to fil-ter novel instances. However, the overall robustness of the method can be sensitive to the threshold. To alleviate the forgetting issues, [21, 45] propose to distill the knowledge from the pre-trained base models. Data replay is also uti-lized to either directly select representative labeled exam-plars [45] or generate pseudo-latent representations from them [21]. Consequently, the base models and the replay buffers have to be stored locally which may cause storage problems, especially in a resource-constraint environment.
In this work, we propose a fully learning-based solution, named MetaGCD, to minimize the hand-engineered heuris-tics in prior works. Concretely, at the offline training phase, instead of pre-training a model representation, we directly train an initialization that is learned to discover novel cate-gories with less forgetting when deployed. It is realized by meta-learning-based bi-level optimization [12] to couple the offline training and downstream learning objectives. Dur-ing the offline training, we simulate the testing scenario and construct pseudo incremental novel class discovery sessions using the labeled data. At each incremental session, we dis-cover novel classes by updating the model using an unsuper-vised contrastive loss. The meta-objective is then defined by validating the updated model on all classes encountered on a labeled pseudo test set. Therefore, the meta-objective of the offline training is aligned with the evaluation protocol at deployment.
It enforces the model to learn to balance two conflicting objectives, namely discovering new objects and not-forgetting old objects. The meta-objective also re-inforces the unsupervised updated model to be supervised by the true labels to ensure valid novel class discovery.
MetaGCD uses unsupervised contrastive learning to ex-plore the relationship among instances for novel class dis-covery. Therefore, it is less prone to label overfitting [40].
However, we observe that the negative pairs in contrastive learning normally dominate the loss function. So we fur-ther propose soft neighborhood contrastive learning to mine more positiveness. Concretely, for each image instance, we select the nearest candidate neighbors within the batch to treat them as soft positive samples to contribute to the dis-criminative feature learning. Overall, our contributions are summarised as follows:
• We consider a realistic setting C-GCD for applications in real-world scenarios. It allows the model trained on pre-defined classes to continually explore novel classes through incoming unlabeled data while simultaneously keeping the performance of known classes.
• We propose a meta-learning approach where the learn-ing objective is well aligned with the evaluation proto-col during testing. It directly optimizes the model to achieve novel object discovery without forgetting.
• A soft neighborhood contrastive learning method is also proposed to mine more soft positive pairs to el-evate the discovery capability.
• We establish strong baselines and show that our method achieves superior performance with less hand-engineered design through extensive experiments. 2.