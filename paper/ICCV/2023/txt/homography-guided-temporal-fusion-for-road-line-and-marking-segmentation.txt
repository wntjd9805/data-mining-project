Abstract
Reliable segmentation of road lines and markings is crit-ical to autonomous driving. Our work is motivated by the observations that road lines and markings are (1) frequently occluded in the presence of moving vehicles, shadow, and glare and (2) highly structured with low intra-class shape variance and overall high appearance consistency. To solve these issues, we propose a Homography Guided Fusion (HomoFusion) module to exploit temporally-adjacent video frames for complementary cues facilitating the correct clas-sification of the partially occluded road lines or markings.
To reduce computational complexity, a novel surface nor-mal estimator is proposed to establish spatial correspon-dences between the sampled frames, allowing the Homo-Fusion module to perform a pixel-to-pixel attention mech-anism in updating the representation of the occluded road lines or markings. Experiments on ApolloScape, a large-scale lane mark segmentation dataset, and ApolloScape
Night with artificial simulated night-time road conditions, demonstrate that our method outperforms other existing
SOTA lane mark segmentation models with less than 9% of their parameters and computational complexity. We show that exploiting available camera intrinsic data and ground plane assumption for cross-frame correspondence can lead to a light-weight network with significantly improved per-formances in speed and accuracy. We also prove the ver-satility of our HomoFusion approach by applying it to the problem of water puddle segmentation and achieving SOTA performance 1. 1.

Introduction
Lane mark segmentation aims to achieve pixel-wise classification of road lines and markings simultaneously.
Known for its quintessential importance in autonomous driving, lane mark segmentation is also an effective tool for constructing accurate High Definition (HD) maps. Existing works solve individual sub-tasks, e.g. drivable area segmen-Figure 1: Illustration of the effect of the proposed HomoFu-sion module that explores the adjacent frames for cues, fa-cilitating the correct classification of (1) a “Straight Arrow”, which, with its bottom half occluded by a vehicle, is mis-takenly classified as a “Right Turn & Straight Arrow” with-out the HomoFusion module, and (2) a partially occluded
“Dotted Line”, which is incorrectly classified as a “Solid
Line” without the HomoFusion module. The fused frame in the 4th row and the 2nd column demonstrates the recov-ered road lines and markings after projecting the previous frames onto the current frame with the estimated homogra-phy matrices. The yellow box enlarges the area where mis-take classifications are corrected. The red box indicates the spatially corresponding area across the frames. Best viewed in color. tation [33, 9] and lane detection [19, 35], while few address the lane mark segmentation in its entirety [53, 16].
Despite the tremendous progresses in semantic/scene segmentation [52, 42, 26], little attention has been paid to the lane mark segmentation task [53, 16]. Yin et al. [53] leverages additional LiDAR information, merging the seg-mented visual information with the point clouds, to achieve lane mark segmentation. IntRA-KD [16] applies the knowl-edge distillation technique to improve the efficiency of the lane mark segmentation model. 1Code is available at https://github.com/ShanWang-Shan/HomoFusion.
A major challenge in the lane mark segmentation task is
partial occlusion of the road lines and markings caused by the vehicle and surrounding environment leading to false classifications. For example, a partially occluded straight arrow can be easily mistaken as a right turn & straight ar-row, as depicted in Fig. 1. However, existing lane mark segmentation methods have not yet made use of the follow-ing observations: (1) occlusion of the road lines and mark-ings (due to nearby moving vehicles, shadow, and glare) can be reduced by cross-frame consistency; (2) road lines and markings are highly structured, maintaining high con-sistency in intra-class shapes as well as in overall appear-ance, alleviating the requirements on learning complicated features to distinguish different classes with high intra-class variance as in semantic/scene segmentation.
To find complementary information from adjacent frames, we use the ground plane assumption for the road region immediately in front of the camera. Our Homogra-phy Guided Fusion (HomoFusion) module achieves tempo-rally consistent representation, recovers partially occluded road lines or markings, and leads to correct classification.
The module’s success depends on accurate cross-frame spa-tial correspondence, which we achieve using a homography transformation matrix estimated with available intrinsic and extrinsic parameters of the on-vehicle camera, and the road surface normal estimated by our novel optimization method called Road Surface Normal Estimator (RSNE).
Using the highly structured nature of road lines and markings could reduce the complexity of the detection problem and make it suitable to run on edge devices. To this end, we employ (1) a lightweight encoder to represent the visual information in feature spaces, and (2) a cross-frame pixel-to-pixel attention mechanism in our HomoFu-sion module, instead of a more computationally expensive global attention mechanism employed by other methods.
These design decisions allow the proposed model to out-perform the existing lane mark segmentation models with less than 9% of their parameters and Giga Floating Point
Operations (GFLOPs) We summarize our contributions as follows:
• We propose a HomoFusion module that uses ground plane assumption and the adjacent frames for tempo-rally consistent representations for accurate classifica-tion of partially occluded road lines and markings.
• We design a novel estimator RSNE for road sur-face normal, which, combined with camera intrinsic and extrinsic parameters readily available on an au-tonomous vehicle, yields accurate homography matrix between frame pairs. RSNE simplifies the 8 degrees of freedom (DoF) of homography problem to a 2 DoF of normal vector problem.
• We present a lightweight lane mark segmentation model that achieves better performance than the state-of-the-art (SOTA) methods with significantly reduced model complexity and computation requirements. 2.