Abstract
Deep metric learning is crucial for finding an embedding function that can generalize to training and testing data, including unknown test classes. However, limited training samples restrict the model’s generalization to downstream tasks. While adding new training samples is a promis-ing solution, determining their labels remains a significant challenge. Here, we introduce Hybrid Species Embedding (HSE), which employs mixed sample data augmentations to generate hybrid species and provide additional training sig-nals. We demonstrate that HSE outperforms multiple state-of-the-art methods in improving the metric Recall@K on the CUB-200 , CAR-196 and SOP datasets, thus offering a novel solution to deep metric learning’s limitations. 1.

Introduction
Image retrieval heavily depends on deep metric learning to grasp visual similarities. In its early stages, methods like pair-based loss [8, 13, 19, 37] and proxy-based loss [25, 15] were proposed to train models. Nevertheless, the true goal of image retrieval is to adapt to the unknown, and the chal-lenge lies in selecting a metric that can effectively han-dle differences between classes in deep metric learning. A promising approach involves exploring both intra-class and inter-class variations within the image itself, rather than re-lying solely on label information [33, 43, 40, 23, 51, 30].
Hard negative samples, often termed false positives, re-fer to images that resemble anchor images but carry dif-ferent labels. The reason behind these hard samples lies in their potential for sharing remarkably similar or even identi-cal features with the anchor samples. Approaches like hard sample mining and generation have been proposed to aid network convergence by introducing a substantial gradient
[1, 41, 12, 34, 49, 48, 17, 18]. Recently, an advancement in generating appropriate hard samples involves creating sup-plementary training data [17, 38, 5, 21]. This is primarily
∗Corresponding to:csong@zjsu.edu.cn (a) Linear interpolation (b) Our HSE
Figure 1: (a) Deep metric learning methods struggle with linear interpo-lation for generating new training samples with labels when new samples fall between anchors of different classes. The manifold structure lacking clear boundaries makes it challenging to assign a label, even when new samples are between anchors of the same class. (b) Samples with multiple simultaneous features may not lie on a linear interpolation path, and their location may be unknown. They can be classified as an unknown class situated inside or outside a manifold boundary. To tackle this challenge, we propose using the HSE method to allocate the sample to an appropriate embedding space location based on its feature information. achieved through linear interpolation, a prevalent method for generating synthetic samples. However, assigning ab-solute labels to these synthesized samples is intricate due to the manifold structures and cluster boundaries present in the embedded space [17]. Even when the new samples are formed by linear interpolation between samples of the same label, accurately determining absolute labels remains a challenge. Synthetic sample labels have emerged as a po-tential solution, with [38] corroborating their similarity to mixup data augmentation and highlighting the label’s repre-sentation through linear interpolation. Nonetheless, this ap-proach is constrained to mixup data augmentation, as mixup uniformly blends features and labels from different images, which might not hold true for other techniques.
We introduce a novel Hybrid Species Embedding (HSE) that leverages mixed sample data augmentations to generate additional training samples [35, 47, 45, 2, 20]. HSE creates hybrid species by combining features from multiple classes and embedding them into spatial positions. During training, different classes are randomly chosen for data augmentation
in each batch. The labels of hybrid species are disregarded, and their placement near the category with the most simi-lar features simulates human categorization behavior, as de-picted in Figure 1(b). This strategy positions hybrid species close to the samples they are synthesized from, ensuring similarity while avoiding unrelated samples. By synthesiz-ing samples using various mixed sample data augmentation techniques, each incorporating multiple features of a known class, our approach naturally imparts similar characteristics to the hard sample for the model without requiring explicit mining. Additionally, we dynamically adjust the position of each batch of hybrid species embedding to bypass the need for considering label information of these hybrid instances.
Our contributions encompass:
• Introducing a novel metric learning strategy embed-ding challenging and unseen classes (Hybrid species), dur-ing training. These hybrid species offer supplementary training signals, enhancing the generalization capacity of downstream tasks, as validated through experiments.
• Adapting mixed sample data augmentation techniques for our Hybrid Species Embedding (HSE) to address con-straints associated with pair-based metric learning losses, which typically demand explicit class labels.
• Demonstrating through experiments our efficacy in en-hancing performance across state-of-the-art metric learning tasks on CUB-200, CAR-196, and SOP datasets. 2.