Abstract
Recently, multi-expert methods have led to significant improvements in long-tail recognition (LTR). We summarize two aspects that need further enhancement to contribute to
LTR boosting: (1) More diverse experts; (2) Lower model variance. However, the previous methods didn’t handle them well. To this end, we propose More Diverse experts with Consistency Self-distillation (MDCS) to bridge the gap left by earlier methods. Our MDCS approach consists of two core components: Diversity Loss (DL) and Consis-tency Self-distillation (CS). In detail, DL promotes diversity among experts by controlling their focus on different cate-gories. To reduce the model variance, we employ KL diver-gence to distill the richer knowledge of weakly augmented
In particular, instances for the experts’ self-distillation. we design Confident Instance Sampling (CIS) to select the correctly classified instances for CS to avoid biased/noisy knowledge. In the analysis and ablation study, we demon-strate that our method compared with previous work can effectively increase the diversity of experts, significantly re-duce the variance of the model, and improve recognition accuracy. Moreover, the roles of our DL and CS are mutu-ally reinforcing and coupled: the diversity of experts bene-fits from the CS, and the CS cannot achieve remarkable re-sults without the DL. Experiments show our MDCS outper-forms the state-of-the-art by 1% ∼ 2% on five popular long-tailed benchmarks, including CIFAR10-LT, CIFAR100-LT,
ImageNet-LT, Places-LT, and iNaturalist 2018. The code is available at https://github.com/fistyee/MDCS 1.

Introduction
Figure 1. We evaluate a ResNet-32 model based on Balanced
Softmax [41, 35] with weakly/strongly augmentation. All exper-iments were performed with an Imbalanced Factor (IF) of 100 on the CIFAR100-LT dataset. Top: model variance [51]. The model trained with weakly augmented instances has a higher vari-ance, whereas the model trained with strongly augmented in-stances is better than weak augmentation. Bottom: Test accuracy.
In the case of training on weakly/strongly augmented instances, the model supervised with one-hot labels presents lower accuracy.
In contrast, our CS transfers richer knowledge from weakly aug-mented instances, preventing the model from overfitting instances as well as reducing the model variance and improving recognition accuracy. It indicates that the prediction of the weakly augmented model could provide richer supervision knowledge to the strongly augmented instances better than its one-hot label.
Deep learning has achieved remarkable progress in a range of computer vision (CV) tasks, such as image recog-*The Corresponding author is with the College of Information Science and Technology and the Interdisciplinary Research Center for Artificial
Intelligence, Beijing University of Chemical Technology, China nition [17, 14, 64, 30, 63], object detection [45, 12], and action recognition [46]. Despite advances in deep tech-nologies and computational capability, great success is also highly dependent on well-designed large datasets such as
ImageNet [13] and Places [67], where each category has
sufficient and roughly balanced training samples. However, real-world data tends to be long-tailed over semantic cate-gories [60]: a few categories contain many instances (called head categories), while most categories contain only a few instances (called tail categories). Long-tailed recognition (LTR) is challenging because it needs to deal not only with the numerous small data learning problems of the tail cate-gories but also with the extremely unbalanced classification of all categories. Deep models trained with such long-tailed data are usually biased toward head categories on balanced testing data and perform poorly on tail categories.
To address this challenge, many approaches have explored long-tail recognition in order to learn well-performing models from long-tailed data, such as class re-balancing/re-weighting [3, 4, 24, 29, 11, 6, 54, 35], de-coupling learning [23] and contrastive learning [56, 22, 49, 68, 10]. Recently, long-tailed recognition methods employ-ing multi-expert ensemble learning [53, 51, 5, 59, 27] have achieved state-of-the-art (SOTA) performance. We summa-rize two key aspects of these approaches that need further improvement for boosting LTR. (1) Diverse experts experts focus on different aspects, maximizing the expertise of each
[5, 51]. More diversity can support experts in improving
LTR. (2) There is a heavy model variance in the prediction of the model, especially for the tail category. So, reducing model variance is essential for LTR. Previous multi-expert methods [53, 51, 5, 59, 27] focused on the above two as-pects but did not handle them well. RIDE [51] utilizes a loss to moderate diversity, yet individual experts focus pri-marily on head categories. ACE and SADE [5, 51, 59] fo-cus on the diverse experts, which learn classification knowl-edge from sub-categories or dominant categories. However,
The ”tail category experts” of these methods can greatly suppress head category performance while focusing on the tail categories. Furthermore, these multi-expert methods all employ an ensemble method to reduce the final variance while ignoring the variance of each expert. Among them,
NCL [27] introduces strong data augmentation [8] that pro-vides a better generalization of the model. However, there is still a high risk of model variance in its one-hot label su-pervision for strongly augmented instances. To this end, we design a novel method, namely More Diverse experts with Consistency Self-distillation (MDCS), for long-tailed recognition.
Our proposed MDCS contains two key components, Di-versity Loss (DL) and Consistency Self-distillation (CS).
Our DL contains an adjustable distribution weight, to cater to the diversity of each expert. By adjusting the distribution weight, each expert tends to recognize different categories, such as Many-shot categories, Medium-shot categories, and
It is a simple yet effective method
Few-shot categories. for increasing diversity and significantly improving recog-nition accuracy over previous methods (discussed in Sec. 4). To reduce the model variance and avoid model over-fitting instances, we look forward to providing each expert with a richer form of supervision when learning strongly augmented samples. The label-smoothing regularization
[47, 37] is a straightforward way, and further MiSLAS [65] proposes label-aware smoothing for long-tailed recognition.
However, the proportion of label-smoothing assignments of these methods is still instance-agnostic, and more reason-able label assignment principles remain to be explored. To this end, we design CS for each expert, which distills richer instance knowledge from predictions of weakly augmented data to regularize strongly augmented instances. Especially for a mini-batch instance, we propose Confident Instance
Sampling (CIS) to select the correctly classified instances for consistency self-distillation. In this way, our proposed
CIS can prevent CS from introducing biased/noisy knowl-edge. As illustrated in Fig. 1, the model trained with strong augmentation method [8] could reduce the model variance
[51] compared with the model trained with weakly aug-mented instances (e.g., flipped, cropped). However, our
CS trains the model on strongly augmented instances and is supervised by ”soft labels” from the predictions of weakly augmented instances, leading to lower model variance and higher recognition accuracy. These ”soft labels”, produced by prediction on weakly augmented representation, contain more knowledge than their one-hot labels. In addition, the roles of our DL and CS are mutually reinforcing and cou-pled: (1) Our CS is designed for each expert, which in-creases the diversity and recognition accuracy of a single (2) expert, and ultimately benefits the ensemble model.
Without the DL, the CS cannot achieve remarkable results as the model is biased towards head categories (discussed in
Sec. 6).
In the experiments, our proposed MDCS model outper-forms state-of-the-art (SOTA) methods by a significant mar-gin on five commonly used benchmark datasets. For in-stance, on CIFAR-100-LT with an imbalance factor of 100, our approach achieves an accuracy of 56.1%. Similarly, on
ImageNet-LT with ResNeXt-50, our model achieves an ac-curacy of 61.8%, while on iNaturalist 2018 with ResNet-50, we achieve an accuracy of 75.6%. 2.