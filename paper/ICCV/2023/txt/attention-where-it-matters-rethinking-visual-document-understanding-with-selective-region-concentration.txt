Abstract
We propose a novel end-to-end document understand-ing model called SeRum (SElective Region Understanding
Model) for extracting meaningful information from docu-ment images, including document analysis, retrieval, and office automation. Unlike state-of-the-art approaches that rely on multi-stage technical schemes and are computa-tionally expensive, SeRum converts document image under-standing and recognition tasks into a local decoding pro-cess of the visual tokens of interest, using a content-aware token merge module. This mechanism enables the model to pay more attention to regions of interest generated by the query decoder, improving the model’s effectiveness and speeding up the decoding speed of the generative scheme.
We also designed several pre-training tasks to enhance the understanding and local awareness of the model. Exper-imental results demonstrate that SeRum achieves state-of-the-art performance on document understanding tasks and competitive results on text spotting tasks. SeRum represents a substantial advancement towards enabling efficient and effective end-to-end document understanding. 1.

Introduction
Understanding document images is a fundamental task that involves extracting meaningful information from them, such as document information extraction [51] or answering visual questions related to the document [34]. In today’s world, where the volume of digital documents is increasing exponentially, this task has become even more critical in various applications, including document analysis [6], doc-ument retrieval [33], and office robotic process automation (RPA) [1].
Current state-of-the-art approaches [15] rely on multi-stage technical schemes involving optical character recogni-*Equal contribution. †Work done during internship at YouTu Lab.
Figure 1. Comparison of multi-stage and SeRum end-to-end pro-cessing flows for visual document understanding. SeRum’s ap-proach simplifies the pipeline by directly generating text output for key visual tokens from the image, eliminating the need for OCR and delivering highly efficient and effective document analysis.
Best viewed in color. tion (OCR) [42] and other modules [37] to extract key infor-mation, as shown in Figure 1. However, these approaches are suboptimal and computationally expensive, relying too much on prefacing modules such as accurate OCR recogni-tion and document content ordering [18].
To address these challenges, we propose a novel end-to-end document understanding model with selective re-gion concentration called SeRum (SElective Region Un-derstanding Model). As shown in Figure 1, SeRum con-verts document image understanding and recognition tasks into a local decoding process of the visual tokens of inter-est, which includes a vision encoder, a query-text decoder, and a content-aware token merge module.
For document understanding tasks, the content to be ex-tracted often takes up a small proportion of the whole doc-ument area but may change greatly in scale. Therefore, it is crucial to accurately identify the key area of interest first.
SeRum extracts document image features using a vision
Transformer-based encoder. We use a self-encoding Trans-form query decoder inspired by MaskFormer [5], which de-code the input query (question for tasks) and carries out
cross-attention mechanism with image features to form the embeddings of queries. Then, we obtain the area of inter-est mask through dot product with the up-sampled image features. Since the number of queries is greater than the number of text locations required, we use binary matching for pairing, following DETR [4].
The final sequence output is automatically generated by the text decoder through cross-attention with the encoded visual token. However, the presence of noise in long vi-sual token sequence could adversely affect the decoding process. To address this issue, we propose a content-aware token merge mechanism that selects visual tokens associ-ated with the query while merges the rest. This mechanism constrains attention to regions of interest generated by the query decoder, while simultaneously preserving global in-formation and enhancing regional information of interest.
The multi-query mechanism employed in our approach en-ables local generation of text, thereby resulting in shorter and more precise text content.
To further enhance the understanding and local aware-ness of the model, we design three pre-training tasks, in-cluding query to segmentation, text to segmentation and segmentation to text.
In summary, we propose a novel end-to-end document understanding model called SeRum that improves the recognition ability of end-to-end mod-els while achieving competitive results in word recognition.
Our content-aware token merge mechanism limits the de-coder’s attention to the local details of interest, improving the model’s effect and speeding up the decoding speed of the generative scheme. We believe that the SeRum model offers a valuable step towards efficient and effective end-to-end document understanding, with potential applications in various fields such as automatic document analysis, infor-mation extraction, text recognition and etc. Conclusively, our contributions are summarized into the three folds:
• We propose a novel end-to-end document understand-ing model called SeRum, which converts document image understanding and recognition tasks into a lo-cal decoding process of the interested visual tokens.
• We introduce a content-aware token merge mechanism that improves the model’s perception of image details and speeds up the decoding speed of the generative scheme.
• Experimental results on multiple public datasets show that our approach achieves state-of-the-art perfor-mance on document understanding tasks and competi-tive results on text spotting tasks. 2.