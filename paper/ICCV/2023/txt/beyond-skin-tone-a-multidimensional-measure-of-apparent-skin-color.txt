Abstract
This paper strives to measure apparent skin color in computer vision, beyond a unidimensional scale on skin tone. In their seminal paper Gender Shades, Buolamwini and Gebru have shown how gender classification sys-tems can be biased against women with darker skin tones.
Subsequently, fairness researchers and practitioners have adopted the Fitzpatick skin type classification as a common measure to assess skin color bias in computer vision sys-tems. While effective, the Fitzpatick scale only focuses on the skin tone ranging from light to dark. Towards a more comprehensive measure of skin color, we introduce the hue angle ranging from red to yellow. When applied to images, the hue dimension reveals additional biases related to skin color in both computer vision datasets and models. We then recommend multidimensional skin color scales, relying on both skin tone and hue, for fairness assessments. 1.

Introduction
This paper focuses on measuring apparent skin color in images for fairness benchmarking, and moves toward a mul-tidimensional score beyond the skin tone depth. Adverse decisions can arise in common computer vision models, as strikingly identified by Buolamwini and Gebru [8]. This has an impact on real-life applications, as models can pro-duce wrong skin lesion diagnostics [15] or incorrect heart rate measurements [5, 27, 62] for individuals with darker skin tones.
It is therefore critical to identify to what ex-tent visual datasets and models are affected by changes in skin color. To achieve this, it becomes necessary to develop comprehensive skin color scores to characterize images of individuals, otherwise a fairness evaluation based on skin color would not be feasible.
Describing the apparent skin color remains an open chal-lenge, as the final visual color perception results from a complex physical and biological phenomenon [34]. The skin is a multilayered structure, which varies among indi-viduals: not every individual will have the same amount and
*Corresponding author: william.thong@sony.com
†Work done while an intern at Sony AI
Figure 1: Apparent skin color in images results from a complex phenomenon, where it varies in tone from light to dark (vertical axis) and hue from red to yellow (horizontal axis). This figure depicts examples from CelebAMask-HQ.
In this paper, we introduce a measure of the skin hue, be-sides the commonly used skin tone, to quantify apparent skin color variations. distribution of carotene, hemoglobin, or melanin throughout the different layers [6, 10]. Hence, modeling the intrinsic skin color through the amount of reflected, scattered, or ab-sorbed light for every individual is a difficult and complex task in images [67]. Additionally, color perception from the human visual system adds more complexity to the problem, as colors can be differently perceived depending on their context or people’s cultures [26]. Instead, it is simpler and more appropriate to develop representative color scales to capture the variations in apparent skin color.
The commonly accepted standard for skin color scale is the Fitzpatrick skin type classification [24], which catego-rizes skin color into six different types based on skin tone, ranging from light to dark. It has unsurprisingly become a useful tool for fairness analysis [8,57] because skin tone an-notations may serve as a proxy for race or ethnicity annota-tions. Indeed, such sensitive attributes are subject to signifi-cant data privacy protections [22], and are often unavailable or inferred in visual datasets [2, 36], making the measure of
skin tone an alternative fairness tool. Yet, while practical and effective, reducing the skin color to its tone is limit-ing given the skin constitutive complexity. As illustrated in
Figure 1, apparent skin color also varies along other axis, such as the skin hue. For example, when aging, Asian skin becomes darker and more yellow while Caucasian skin be-comes darker and redder [17]. Focusing on skin tone would not capture such change in hue as it only assesses the skin lightness or darkness. In this paper, we therefore promote a multidimensional scale to better represent apparent skin color variations among individuals in images.
Akin to previous works on fairness analysis in computer vision (e.g., [8, 57, 75, 78]), we are interested in characteriz-ing apparent skin color rather than true skin color. The ap-parent skin color is the one depicted in images, and the one that a computer vision model would see, while the true skin color characterizes the constitutive skin color without the influence of external factors such as illumination or color cast. Assessing the true skin color is more important for dermatology [41,60] or cosmetics [6,46] applications as the constitutive color leads to more specific diagnostics or treat-ments and requires an active involvement with practitioners to avoid any misusage or mistrust [28]. In this paper, we rather focus on the assessment of computer vision models, which are fed images in the wild, and thus only consider the apparent skin color in images.
Our main contribution is to demonstrate the relevance and benefits of a multidimensional skin color scale for fair-ness assessments in computer vision. First, we introduce a step towards more comprehensive apparent skin color scores. Rather than classifying skin color in types, as done with the Fitzpatrick scale, we measure automatically and quantitatively skin color in a multidimensional manner in images. We propose to focus on the perceptual light L∗, as a measure of skin tone, and the hue angle h∗, as a measure of skin hue; which results in a multidimensional measure for every image. Second, we showcase the benefits of a multidimensional measure of skin color by (i) quantifying to what extent common image datasets are skewed towards light-red skin color and under-represent dark-yellow skin color, and how generative models trained on these datasets reproduce a similar bias; (ii) revealing multidimensional skin color biases in saliency-based image cropping and face verification models; and (iii) measuring the causal effect of skin color in attribute prediction in multiple commercial and non-commercial models. Overall, our contributions to as-sessing skin color in a multidimensional manner offer novel insights, previously invisible, to better understand biases in the fairness assessment of both datasets and models. 2.