Abstract
Cross-View Geo-Localisation is still a challenging task where additional modules, specific pre-processing or zoom-ing strategies are necessary to determine accurate posi-tions of images. Since different views have different ge-ometries, pre-processing like polar transformation helps to merge them. However, this results in distorted images which then have to be rectified. Adding hard negatives to the training batch could improve the overall performance but with the default loss functions in geo-localisation it is dif-ficult to include them. In this work, we present a simpli-fied but effective architecture based on contrastive learn-ing with symmetric InfoNCE loss that outperforms current state-of-the-art results. Our framework consists of a nar-row training pipeline that eliminates the need of using ag-gregation modules, avoids further pre-processing steps and even increases the capacity of generalisation of the model to unknown regions. We introduce two types of sampling strategies for hard negatives. The first explicitly exploits ge-ographically neighboring locations to provide a good start-ing point. The second leverages the visual similarity be-tween the image embeddings in order to mine hard negative samples. Our work shows excellent performance on com-mon cross-view datasets like CVUSA, CVACT, University-1652 and VIGOR. A comparison between cross-area and same-area settings demonstrate the good generalisation ca-pability of our model.
Figure 1: Our two sampling strategies. The first is based on the geographical distance between the satellite images. The second uses the cosine similarity between the street-view and satellite view embeddings to find hard negatives within a margin. 1.

Introduction
Determining a geo-location from images without meta-data is one of the puzzles yet to be solved in the computer vision community. Solving this problem can help in areas such as agriculture and automotive. For example, a robotic agent in agriculture for spraying fertiliser requires a high precision location. This can be achieved with a real-time kinematic (RTK) GPS, but these sensors are expensive and short-time signal outages can obstruct workflows. There-fore aerial image based localisation in these highly repeti-tive environments can further enhance positioning [4]. An-other challenge in cities is the so-called urban canyon effect, which blocks signals such as GPS or reduces their accuracy.
Especially in large cities, GPS signals are noisy due to tall buildings. The evaluation of 250,000 driving hours in New
York City traffic by Brosh et al. showed an error of 10 me-ters in 40% of GPS signals. Therefore a computer vision solution based on image retrieval was proposed [2] to cor-rect these signals.
While classic approaches sought to do this with vi-sual clues such as sun position and the resulting shad-ows [7, 19, 17] or weather [16, 15], current approaches are increasingly focusing on image retrieval based on deep learning [1, 20, 21]. In cross-view image retrieval [37, 38, 44, 47], different views of an image, e.g. a ground im-age and a satellite image, have to match to determine the searched position. The ground image queries are compared with a database of satellite images with known geographical positions.
Previous approaches mostly used CNN based meth-ods [38, 13, 3, 30, 36, 35, 28, 29], while present research is mainly focused on the Transformer or MLP Mixer archi-tecture as a backbone for geo-localisation [40, 43, 46, 48].
In the latter case, reasonable performance can only be achieved if the weights between the two view-specific en-coders are not shared, resulting in larger models. Further-more, the polar transformation is often utilised to bridge the geometrical gap between the views [28]. Triplet loss as a standard loss in cross-view geo-localisation uses only one negative example per batch and is prone to model collaps-ing when hard negatives are used [39].
In this paper, we present a weight-sharing Siamese CNN that learns class-agnostic embeddings based on the In-foNCE loss [25, 11, 5] and demonstrate the advantage of the CNN architecture for our approach. We use a technique from multimodal pre-training [26] to calculate the loss sym-metrically to further aid the understanding of the different domains in the viewpoints. Hard negative examples, i.e. ex-amples that are hard to distinguish for the model from posi-tives examples, in deep metric learning are a key ingredient to achieve superior performance, thus we present two sam-pling methods. In the early epochs, we leverage GPS coor-dinates to contrast close geographic neighbours as a good initialisation for our second sampling. In later epochs based on a similarity metric, such as cosine similarity, we collect visually similar samples for the batch construction, to focus on hard negatives examples. To summarise our contribution in this work:
• We show the superior performance of our contrastive training with the symmetric InfoNCE loss whilst using a single encoder for both views.
• We propose GPS-Sampling as a task-specific sampling technique for hard negatives at the beginning of the training.
• We present Dynamic Similarity Sampling (DSS) to se-lect hard negatives during training based on the cosine similarity between street and satellite views.
• Our framework consists of a simple training pipeline that eliminates the need of special aggregation mod-ules or complex pre-processing steps, whilst outper-forming current approaches in performance and gener-alisation ability. 2.