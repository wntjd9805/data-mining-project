Abstract 3D single object tracking has been a crucial problem for decades with numerous applications such as autonomous driving. Despite its wide-ranging use, this task remains challenging due to the significant appearance variation caused by occlusion and size differences among tracked tar-gets. To address these issues, we present MBPTrack, which adopts a Memory mechanism to utilize past information and formulates localization in a coarse-to-fine scheme using
Box Priors given in the first frame. Specifically, past frames with targetness masks serve as an external memory, and a transformer-based module propagates tracked target cues from the memory to the current frame. To precisely localize objects of all sizes, MBPTrack first predicts the target cen-ter via Hough voting. By leveraging box priors given in the first frame, we adaptively sample reference points around the target center that roughly cover the target of different sizes. Then, we obtain dense feature maps by aggregating point features into the reference points, where localization can be performed more effectively. Extensive experiments demonstrate that MBPTrack achieves state-of-the-art per-formance on KITTI, nuScenes and Waymo Open Dataset, while running at 50 FPS on a single RTX3090 GPU. 1.

Introduction
The ability to track objects in 3D space is essential for numerous applications, including robotics [2, 12], au-tonomous driving [33, 15], and surveillance systems [27].
Given the initial state of a specific object, the aim of 3D single object tracking (SOT) is to estimate the pose and position of the tracked target in each frame. Early ap-proaches [25, 18, 21] rely heavily on RGB information, which often struggle to handle changing lighting conditions.
Therefore, recent research works [8, 23, 10, 11, 35, 31] have focused on using point clouds to solve 3D object tracking for their unique advantages, such as accurate spatial infor-*corresponding author
Figure 1: An illustration of our proposed MBPTrack for 3D SOT task. MBPTrack employs a memory mechanism to propagate target cues from historical frames and then utilizes a localization head, named BPLocNet, for coarse-to-fine bounding box prediction. BPLocNet first samples reference points around each predicted target center using a bounding box prior, which adaptively covers the tracked targets of all sizes. Then, BPLocNet aggregates local fea-tures from reference points for further refinement. mation and robustness to illumination changes.
Existing methods [23, 30, 34, 24, 5, 10, 36, 11] for the 3D SOT task predominantly follow the Siamese paradigm, which takes the target template cropped from the previous frame and search area in the current frame as input, and then localizes the target in an end-to-end manner using a lo-calization network such as Region Proposal Network [22] (RPN). Different from previous methods, M2-Track [35] explicitly models the target’s motion between two succes-sive frames and CXTrack [31] proposes to exploit the spa-tial contextual information across adjacent frames. Despite achieving promising results on popular datasets, the afore-mentioned methods propagate target cues solely from the
latest frame to the current frame, thereby neglecting rich in-formation contained in other past frames. This limitation renders 3D SOT a challenging task, especially in cases of large appearance variation or target disappearance caused by occlusion. To this end, TAT [16] exploits temporal in-formation by sampling a set of high-quality target templates cropped from historic frames for reliable target-specific fea-ture propagation. However, neglecting information in the latest frame could result in the network failing to capture lasting appearance changes, such as the gradual sparsifi-cation of point clouds as the tracked target moves further away. TAT also ignores the contextual information around the target, which is essential for 3D SOT [31], thereby lead-ing to limited tracking performance.
In addition, the substantial differences in size and ge-ometry across the various categories of tracked targets also pose challenges for 3D SOT, which has been overlooked by previous works. The localization networks adopted in existing methods can be categorized into two paradigms, namely point-based [36, 31, 23] and voxel-based [10]. For voxel-based localization heads like V2B [10], tracked tar-gets with simple shapes and large sizes such as vehicles, can fit well in voxels, leading to more precise localization than point-based heads such as X-RPN [31]. However, for categories such as pedestrians, which have complex geome-tries and small sizes, voxelization leads to considerable in-formation loss, thereby degrading tracking performance. As mentioned in V2B [10], the choice of different voxel sizes can significantly impact tracking performance.
To address the above issues, we present MBPTrack, a memory-based network for the 3D SOT task. Our approach relies on a memory mechanism to leverage rich spatial and temporal contextual information in historical frames and utilizes bounding box priors to address the challenge of size differences among tracked targets. Specifically, past frames with targetness masks serve as an external memory, and we draw inspiration from DeAOT [32], which has achieved great success in video object segmentation, to design a transformer-based module that propagates information from this memory to the current frame. It further decouples ge-ometric features and targetness features into two process-ing branches with shared attention maps to enable effective learning of geometric information. Unlike TAT [16], MBP-Track fully utilizes both spatial and temporal contextual in-formation around the target without cropping or sampling, thereby handling appearance variation and target disappear-ance/reappearance better than previous works. To achieve accurate localization of targets of different sizes, we intro-duce BPLocNet, a coarse-to-fine localization network that captures size information by leveraging the bounding box given in the first frame. BPLocNet first predicts the po-tential target centers as well as the targetness mask used to update the memory mechanism. We adopt a box-prior sampling method to sample reference points around the pre-dicted target centers, adaptively covering the tracked target.
Then, we aggregate point-wise features into the reference points, to obtain a dense feature map with spatial informa-tion, which is fed into a 3D CNN to predict precise bound-ing boxes. Extensive experiments demonstrate that MBP-Track outperforms existing methods by a large margin on three benchmark datasets, while running at 50 FPS on a single NVIDIA RTX3090 GPU. Furthermore, we demon-strate that using our proposed localization network in exist-ing frameworks can consistently improve tracking accuracy.
In summary, our main contributions are as follows:
• To the best of our knowledge, we are the first to exploit both spatial and temporal contextual information in the 3D SOT task using a memory mechanism.
• We propose a localization network that utilizes box pri-ors to localize targets of different sizes in a coarse-to-fine manner, which is shown to be effective in various 3D SOT frameworks.
• Experimental results demonstrate that MBPTrack out-performs existing methods, achieving state-of-the-art online tracking performance. 2.