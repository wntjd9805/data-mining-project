Abstract
SR (single image)
SR (4 images)
SR (8 images)
Despite substantial advances, single-image super-resolution (SISR) is always in a dilemma to reconstruct high-quality images with limited information from one in-put image, especially in realistic scenarios. In this paper, we establish a large-scale real-world burst super-resolution dataset, i.e., RealBSR, to explore the faithful reconstruction of image details from multiple frames. Furthermore, we in-troduce a Federated Burst Afﬁnity network (FBAnet) to inves-tigate non-trivial pixel-wise displacements among images un-der real-world image degradation. Speciﬁcally, rather than using pixel-wise alignment, our FBAnet employs a simple homography alignment from a structural geometry aspect and a Federated Afﬁnity Fusion (FAF) strategy to aggre-gate the complementary information among frames. Those fused informative representations are fed to a Transformer-based module of burst representation decoding. Besides, we have conducted extensive experiments on two versions of our datasets, i.e., RealBSR-RAW and RealBSR-RGB. Exper-imental results demonstrate that our FBAnet outperforms existing state-of-the-art burst SR methods and also achieves visually-pleasant SR image predictions with model details.
Our dataset, codes, and models are publicly available at https://github.com/yjsunnn/FBANet. 1.

Introduction
As a fundamental research topic, Super-Resolution (SR) attracts long-standing substantial interest, which targets high-resolution (HR) image reconstruction from a single or a sequence of low-resolution (LR) observations. In recent years, we have witnessed the prosperity of Single Image
Super-Resolution (SISR), e.g., SRCNN [7], EDSR [19], SR-GAN [16], RDN [33] and ESRGAN [28]. Nevertheless,
*Corresponding author: Liang Lin, Jie Chen
SR (10 images)
SR (14 images)
HR
Figure 1: SR predictions with different numbers of burst im-age inputs in our RealBSR dataset, where more burst inputs facilitate more accurate reconstruction of image details.
SISR intrinsically suffers from a limited capacity of restor-ing details from only one LR image, typically yielding over-smooth LR predictions, especially for large-scale factors.
With real detailed sub-pixel displacement information, Multi-Frame Super-Resolution (MFSR) [31, 1, 2, 21, 20] provides a promising potential to reconstruct the high-quality image from multiple LR counterparts, which is valuable for many sensitive realistic applications, e.g., medical imaging, and remote satellite sensing.
After the pioneering work [25] of Tsai and Huang in 1984, the research on MFSR has not achieved as tremendous progress as SISR. Typically, they are overwhelmed by two challenges: 1) the difﬁculty of fusing multiple LR inputs, which especially is aggravated for real-world data; 2) the lim-itation of artiﬁcially-synthesized data, accounting for a poor generalization for real-world scenarios; To address those challenges, a recent work [1] has made seminal contributions to the ﬁrst real-world burst SR dataset benchmark, BurstSR, and a novel architecture, DBSR. Subsequently, MFIR pro-poses a deep reparametrization to reformulate the classical
MAP objective in a deep feature space [2]. BIPNet [8] introduces a set of pseudo-burst features for information ex-change among multiple burst frames. BSRT [20] employs a 1
pyramid flow-guided deformable convolution network in a
Transformer architecture.
Despite great progress achieved, two aspects still need to be revisited. 1) Method: Align-fusion-reconstruction paradigm-based methods usually fuse multiple burst images according to their similarity to a reference image, following their alignment via the optical ﬂow or deformable convo-lution. However, this fusion strategy largely relies on the reference image and is limited to exploring more information among burst images. 2) Dataset: BurstSR captures multiple
LR images with a smartphone in burst mode and a corre-sponding HR image with a DSLR camera. Thus, several unexpected issues are nontrivial: a) data misalignment (even distortion) among burst LRs and their HR counterparts; b) cross-device gap between LRs and HR captured by different cameras; and c) unfair model evaluation on warped SR pre-dictions by introducing GT HR. Moreover, BurstSR can be cast as a coupled task of burst image SR and enhancement.
To address these issues, we propose the Federated Burst
Afﬁnity Network (FBAnet), and make an attempt to build a new real-world burst image SR dataset, named RealBSR.
Our RealBSR dataset is captured in quick succession a se-quence of LR images and one HR image under a contin-uous shooting mode with the optical zoom strategy, like
RealSR [3]. It provides a real-world benchmark for image detail reconstruction of real-world burst SR applications, avoiding the color style change in terms of the original LR data, especially, burst RAW inputs have no ISP process and often, for faithful high-resolution image predictions, espe-cially for sensitive applications, e.g., medical imaging.
Our FBAnet employs a simple-yet-effective alignment algorithm via a homography matrix from a structural and global aspect. Then, a Federated Afﬁnity Fusion (FAF) module is introduced to aggregate inter- and intra-frame in-formation through afﬁnity difference maps, aiming to not only focus on pixels consistent with the reference frame for global content reconstruction but also highlight the distinc-tion among frames to absorb complementary information.
The fused representations pass through the burst represen-tation decoding module to integrate local features extracted by convolutions with the global long-range dependencies of self-attentions for HR image reconstruction.
In a nutshell, our contributions are summarized below:
• We make an effort to establish a Real-world Burst Super-Resolution benchmark, i.e., RealBSR, which has two versions consisting of RAW and RGB images. Re-alBSR has a great potential to inspire further researches for realistic burst SR applications.
• We propose a Federated Burst Afﬁnity network to ad-dress real-world burst image super-resolution, which derives the afﬁnity difference maps of burst images to federate inter- and intra-frame complementary informa-tion for reconstructing more image details.
• We have conducted extensive experiments on RAW and RGB versions of RealBSR to benchmark existing state-of-the-art methods. Empirically, the efﬁcacy of our FBAnet has been justiﬁed with superior SR perfor-mances from quantitative and qualitative aspects. 2.