Abstract 1.

Introduction
This work presents an easy-to-use regularizer for GAN training, which helps explicitly link some axes of the latent space to a set of pixels in the synthesized image. Es-tablishing such a connection facilitates a more convenient local control of GAN generation, where users can alter the image content only within a spatial area simply by partially resampling the latent code. Experimental results confirm four appealing properties of our regularizer, which we call
LinkGAN. (1) The latent-pixel linkage is applicable to either a fixed region (i.e., same for all instances) or a particular semantic category (i.e., varying across instances), like the sky. (2) Two or multiple regions can be independently linked to different latent axes, which further supports joint control. (3) Our regularizer can improve the spatial controllability of both 2D and 3D-aware GAN models, barely sacrificing the synthesis performance. (4) The models trained with our regularizer are compatible with GAN inversion techniques and maintain editability on real images. Project page can be found here.
Generative adversarial networks (GANs) [12] have been shown to produce photo-realistic and highly diverse images, facilitating a wide range of real world applications [21, 36, 11, 41, 42]. The generator in a GAN is formulated to take a randomly sampled latent code as the input and output an image with a feed forward network. Given a well-learned GAN model, it is generally accepted that a variety of semantics and visual concepts automatically emerge in the latent space [57, 43, 14, 22, 64], which naturally support image manipulation. Some recent work also reveals the potential of GANs in local editing by steering the latent code along a plausible trajectory in the latent space [30, 63].
However, most studies on the relationship between the latent codes and their corresponding images depend on a posterior discovery, which usually suffers from three major drawbacks. (1) Instability: The identification of emerging latent semantics is very sensitive to the samples used for analysis, such that different samples may lead to
â€  indicates equal contribution.
* This work was done during an internship at Ant Group.
different results [14, 42]. (2) Inaccuracy: Given the high-dimensional latent space (e.g., 512d in the popular Style-GAN family [26, 27]), finding a semantically meaningful subspace can be challenging. (3) Inflexibility: Existing manipulation models are usually linear (i.e., based on vector arithmetic [42, 22]), limiting the editing diversity.
This work offers a new perspective on learning control-lable image synthesis. Instead of discovering the semantics from pre-trained GAN models, we introduce an efficient regularizer into the training of GANs, which is able to explicitly link some latent axes with a set of image pixels.
In this way, the selected axes and the remaining axes are related to the in-region pixels and out-region pixels, respectively, with little cross-influence (see Fig. 1). Such a design, termed as LinkGAN, enables a more accurate and more convenient control of the generation, where we can alter the image content within the linked region simply by resampling on the corresponding axes.
We conduct experiments on various datasets to evaluate the efficacy of LinkGAN and demonstrate its four appealing properties. (1) It is possible to link an arbitrary image region to the latent axes, no matter the region is pre-selected before training and fixed for all instances, or refers to a semantic category and varies across instances (see Sec. 4.2.1). (2)
Our regularizer is capable of linking multiple regions to different sets of latent axes independently, and allows joint manipulation of these regions (see Sec. 4.2.2). (3) Our approach lends itself well to both 2D image synthesis models [27] and 3D-aware image synthesis models [5], appearing as sufficiently improving the controllability yet barely harming the synthesis performance. (4) The models trained with our regularizer are compatible with GAN inversion techniques [65] and maintain the editability on real images (see Sec. 4.3). We believe that this work makes a big step towards the spatial controllability of GANs as well as the explicit disentanglement of GAN latent space. It can be expected that the new characteristic (i.e., the latent-pixel linkage) of generative models could open up more possibilities and inspire more applications in the future. 2.