Abstract
The whole slide image (WSI) classification is often for-mulated as a multiple instance learning (MIL) problem.
Since the positive tissue is only a small fraction of the gi-gapixel WSI, existing MIL methods intuitively focus on iden-tifying salient instances via attention mechanisms. How-ever, this leads to a bias towards easy-to-classify instances while neglecting hard-to-classify instances. Some litera-ture has revealed that hard examples are beneficial for modeling a discriminative boundary accurately. By ap-plying such an idea at the instance level, we elaborate a novel MIL framework with masked hard instance mining (MHIM-MIL), which uses a Siamese structure (Teacher-Student) with a consistency constraint to explore the poten-tial hard instances. With several instance masking strate-gies based on attention scores, MHIM-MIL employs a mo-mentum teacher to implicitly mine hard instances for train-ing the student model, which can be any attention-based
MIL model. This counter-intuitive strategy essentially en-ables the student to learn a better discriminating boundary.
Moreover, the student is used to update the teacher with an exponential moving average (EMA), which in turn identi-fies new hard instances for subsequent training iterations and stabilizes the optimization. Experimental results on the
CAMELYON-16 and TCGA Lung Cancer datasets demon-strate that MHIM-MIL outperforms other latest methods in terms of performance and training cost. The code is avail-able at: https://github.com/DearCaat/MHIM-MIL. 1.

Introduction
Histopathological image analysis plays a crucial role in modern medicine, particularly in the treatment of cancer, where it serves as the gold standard for diagnosis [18, 20, 24,45]. Digitalizating pathological images into Whole Slide
*Corresponding Author.
Figure 1: Left: Previous MIL models focus on the more salient instances. Right: MHIM-MIL mines an amount of hard-to-classify instances to learn a better boundary.
Images (WSIs) through digital slide scanner has opened new avenues for computer-aided analysis [9, 26]. Due to the huge size of a WSI and the lack of pixel-level annota-tions, histopathological image analysis is commonly formu-lated as a multiple instance learning (MIL) task [10, 23, 31].
In MIL, each WSI (or slide) is a bag containing thousands of unlabeled instances (patches) cropped from the slide.
With at least one instance being disease positive, the bag is deemed positive, otherwise negative.
However, the number of slides is limited and each slide contains a mass of instances with a low positive propor-tion. This imbalance would hinder the inference of bag la-bels [16, 43]. To alleviate this issue, several WSI classifica-tion methods [6, 16–18, 26] employ an attention mechanism to aggregate salient instance features into a bag-level fea-ture for WSI classification. Furthermore, some MIL frame-works [17, 21, 40, 43] focus on the more salient instances in the bag and leverage them to facilitate WSI classification.
For instance, existing frameworks [40, 43] propose to only select the instances that correspond to the top K highest or lowest attention scores [17, 40] or patch probabilities [43] for yielding high-quality bag embedding for both training and testing.
These salient instances are actually “easy-to-classify” in-stances, which are not optimal for training a discriminative
WSI classification model. In conventional machine learn-ing, such as Support Vector Machines (SVM) [13], samples near the category distribution boundary are more challeng-ing to classify, but are more useful for depicting the clas-sification boundary, as illustrated in Figure 1. Moreover, other deep learning works [25, 28, 33, 34] also reveal that mining hard samples for training can improve the general-ization abilities of models. By applying such an idea at the instance level, we can better highlight the “hard-to-classify” instances that facilitate MIL model training, and benefit the final WSI classification. However, the lack of instance la-bels poses a challenge to the direct application of traditional hard sample mining strategies at the instance level.
To address this issue, we present a novel MIL framework based on masked hard instance mining strategies (MHIM) named MHIM-MIL. The main idea of MHIM is to mask out the instances with high attention scores to highlight the hard instances for model training. Based on this, we incorpo-rate two other instance masking strategies to enhance train-ing efficiency and mitigate the over-fitting risk. Another key design of MHIM-MIL is an instance attention genera-tor based on a Siamese structure (Teacher-Student) [3, 8].
In MHIM-MIL, the MIL-based WSI classification model is the student network, which aggregates hard instances mined by a momentum teacher with different instance masking strategies. The momentum teacher is updated using an exponential moving average (EMA) of the student model.
Moreover, the framework is optimized by inducing a con-sistency constraint that explores more supervised informa-tion beyond the limited slide label. Unlike the conventional
MIL frameworks [40, 43], which adopt complex cascade gradient-updating structures, our method is more simple and does not require additional parameters. It not only im-proves efficiency but also provides improved performance stability. The contribution of this paper is summarized as follows,
• We propose a simple and efficient MIL framework with masked hard instance mining named MHIM-MIL. It implicitly mines hard instances with in-stance attention for training a more discriminative MIL model. Extensive experiments on two WSI datasets validate that MHIM boosts different MIL models and outperforms other latest methods in terms of perfor-mance and training cost.
• We propose several hybrid instance masking strate-gies for indirectly mining hard instances in MIL. These strategies not only address the reliance problem of con-ventional methods on instance-level supervision but also enhance the training efficiency of the model and mitigate the over-fitting risk.
• With the Siamese structure, we introduce a parameter-free momentum teacher to obtain instance attention scores more efficiently and stably. Moreover, we em-ploy a consistency-based iterative optimization to im-prove the discriminability of both models progres-sively. 2.