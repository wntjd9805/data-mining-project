Abstract
Implicit Neural Representations (INR) or neural fields have emerged as a popular framework to encode multime-dia signals such as images and radiance fields while retain-ing high-quality. Recently, learnable feature grids proposed by M¨uller et al. [1] have allowed significant speed-up in the training as well as the sampling of INRs by replacing a large neural network with a multi-resolution look-up ta-ble of feature vectors and a much smaller neural network.
However, these feature grids come at the expense of large memory consumption which can be a bottleneck for stor-age and streaming applications. In this work, we propose
SHACIRA, a simple yet effective task-agnostic framework for compressing such feature grids with no additional post-hoc pruning/quantization stages. We reparameterize feature grids with quantized latent weights and apply entropy regu-larization in the latent space to achieve high levels of com-pression across various domains. Quantitative and qualita-tive results on diverse datasets consisting of images, videos, and radiance fields, show that our approach outperforms existing INR approaches without the need for any large datasets or domain-specific heuristics. Our project page is available at https://shacira.github.io. 1.

Introduction
In today’s digital age, large quantities of data in different modalities (images, audio, video, 3D) is created and trans-mitted every day. Compressing this data with minimal loss of information is hence an important problem and a number of techniques have been developed in the last few decades to address this challenging problem. While the conven-tional methods such as JPEG [5] for images, HEVC [6] for videos excel at encoding signals in their respective domains, coordinate-based implicit neural representations (INR) or
Neural Fields [7] have emerged as a popular alternative for representing complex signals because of their ability to capture high frequency details, and adaptability for di-verse domains. INRs are typically multi layer perceptrons (MLPs) optimized to learn a scalar or vector field. They
Figure 1: We demonstrate the effectiveness of SHACIRA for two tasks. The left column shows a gigapixel image at 21450 × 56718 resolution (cropped for visualization) encoded using Instant-NGP [1], JPEG2000 [2], and SHACIRA (ours). The right column reconstructs NeRF [3] from 2D images and their camera poses using Instant-NGP [1], VQAD [4], and SHACIRA. For each ex-ample, we zoom into two crops to compare different methods. We show overall PSNR and size required by each method. SHACIRA can capture high-resolution details with a smaller storage size in a task-agnostic way (only 2D/3D examples shown here).
take a coordinate (location and/or time) as input and pre-dict a continuous signal value(s) as output (such as pixel color/occupancy). Recently, various works have adapted
INRs to represent a variety of signals such as audio [8], im-ages [9–12], videos [13, 14], shapes [15, 16], and radiance fields [3, 17]. Unsurprisingly, several methods have been proposed to compress INRs using quantization [10, 14, 18], pruning, or a combination of both [13]. The focus of these works is to compress the weights of the MLP, which often leads to either a big drop in the reconstruction quality, or slow convergence for high resolution signals.
In this work, we consider a different class of INR approaches that employ learnable multi-resolution feature grids [1, 19]. These feature grids store feature vectors at different coordinate locations with varying Level-Of-Detail (LOD). The features from different levels (or resolutions) are concatenated and passed through a tiny MLP to recon-struct the required signal. This shifts the burden of repre-senting the signal to the feature grid instead of the MLP.
Such methods have shown to be effective in approximating complex signals such as 3D scenes and gigapixel images with high fidelity [1] and fast training time (since the cost of lookup is very small). However, the size of the feature grids can be very large which is not memory efficient and impractical for many real-world applications with network bandwidth or storage constraints.
We propose an end-to-end learning framework for com-pressing such feature grids without any loss in reconstruc-tion performance. Our feature grid consists of quantized feature vectors and parameterized decoders which trans-form the feature vectors into continuous values before pass-ing them to MLP. We use an entropy regularization loss on the latent features to reduce the size of the discrete la-tents without significantly affecting the reconstruction per-formance. To address the discretization gap inherent to this discrete optimization problem, we employ an annealing ap-proach to the discrete latents which improves the training stability of the latents, converging to better minima. Both entropy regularization and reconsutruction objective can be trained jointly in an end-to-end manner without requiring post-hoc quantization, pruning or finetuning stages. Fur-ther, the hierarchical nature of feature grids allows scaling to high dimensional signals unlike pure MLP-based implicit methods.
As seen in Figure 1, the proposed approach is able to compress feature-grid methods such as Instant-NGP [1] with almost an order of magnitude while retaining the per-formance in terms of PSNR for gigapixel images and 3D scenes from the RTMV dataset [20]. We also conduct ex-tensive quantitative experiments and show results on stan-dard image compression benchmarks such as the Kodak dataset outperforming the classic JPEG codec as well as other implicit methods in the high compression regime. Our approach can even be trivially extend to videos, perform-ing competitively with video-specific INR methods such as
NeRV [13], without explicitly exploiting the inherent tem-poral redundancy present in videos. The key contribution of our work is to directly compress the learnable feature grid with proposed entropy regularization loss and highlight its adaptibility to diverse signals. We summarize our contribu-tions below:
• We introduce an end-to-end trainable compression frame-work for implicit feature grids by maintaining discrete la-tent representations and parameterized decoders.
• We provide extensive experiments on compression bench-marks for a variety of domains such as images, videos, and 3D scenes showing the generalizability of our ap-proach outperforming a variety of INR works. 2.