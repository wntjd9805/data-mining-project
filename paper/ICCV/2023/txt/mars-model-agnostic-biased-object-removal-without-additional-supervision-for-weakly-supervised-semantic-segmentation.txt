Abstract
Weakly-supervised semantic segmentation aims to re-duce labeling costs by training semantic segmentation mod-els using weak supervision, such as image-level class la-bels. However, most approaches struggle to produce ac-curate localization maps and suffer from false predictions in class-related backgrounds (i.e., biased objects), such as detecting a railroad with the train class. Recent methods that remove biased objects require additional supervision for manually identifying biased objects for each problem-atic class and collecting their datasets by reviewing predic-tions, limiting their applicability to the real-world dataset with multiple labels and complex relationships for bias-ing. Following the first observation that biased features can be separated and eliminated by matching biased ob-jects with backgrounds in the same dataset, we propose a fully-automatic/model-agnostic biased removal framework called MARS (Model-Agnostic biased object Removal with-out additional Supervision), which utilizes semantically consistent features of an unsupervised technique to elimi-nate biased objects in pseudo labels. Surprisingly, we show that MARS achieves new state-of-the-art results on two pop-ular benchmarks, PASCAL VOC 2012 (val: 77.7%, test: 77.2%) and MS COCO 2014 (val: 49.4%), by consistently improving the performance of various WSSS models by at least 30% without additional supervision. Code is avail-able at https://github.com/shjo-april/MARS. 1.

Introduction
Fully-supervised semantic segmentation (FSSS) [7, 8], which aims to classify each pixel of an image, requires time-consuming tasks and significant domain expertise in some applications [54] to prepare pixel-wise annotations. By con-trast, weakly-supervised semantic segmentation (WSSS) with image-level supervision, which is the most economi-cal among weak supervision, such as bounding boxes [12], scribbles [35], and points [4], reduces the labeling cost by
*Correspondence to
Figure 1. (a) Comparison with existing WSSS studies [49, 21] and
FSSS. (b) Per-class FP analysis. (c) Examples of biased objects in boat and train classes. (d) Quantitative analysis of biased objects on the PASCAL VOC 2012 dataset. Red dotted circles illustrate the false activation of biased objects such as railroad and sea. more than 20× [4]. The multi-stage learning framework is the dominant approach for training WSSS models with image-level labels. Since this framework heavily relies on the quality of initial class activation maps (CAMs), numer-ous researchers [2, 49, 28, 10, 51, 21] moderate the well-known drawback of CAMs, highlighting the most discrimi-native part of an object to reduce the false negative (FN).
However, the false positive (FP) is the most crucial bot-tleneck to narrow the performance gap between WSSS and
FSSS in Fig. 1(a). According to per-class FP analysis in
Fig. 1(b), predicting target classes (e.g., boat) with class-related objects (e.g., sea) are factored into increasing FP in Fig. 1(c), besides incorrect annotations in the bicycle class. Moreover, 35% of classes in the PASCAL VOC 2012 dataset have biased objects in Fig. 1(d). These results show that the performance degradation of previous approaches depends on the presence or absence of problematic classes in the dataset. We call this issue a biased problem. We also add examples of all classes in the Appendix.
Table 1.
Comparison with public datasets for WSSS. Since
Open Images [24] does not provide pixel-wise annotations for all classes, existing methods employ PASCAL VOC 2012 [14] and
MS COCO 2014 [36] for fair comparison and evaluation.
Dataset
PASCAL VOC 2012 [14]
MS COCO 2014 [36]
Open Images [24]
Training images 10,582 80,783 9,011,219
Classes 20 80 19,794
GT
✓
✓
✗
Figure 2. Integration with WSSS and USS. (a): The USS method fails to detect biased objects without the WSSS output. (b): The
WSSS method cannot find biased objects due to using biased fea-tures. (c): Thanks to the WSSS guidance, the USS method identi-fies biased objects on a limited area of the WSSS output.
Although two studies [51, 29] alleviate the biased prob-lem, their requirements hinder WSSS applications in the real world having complex relationships between classes.
For example, to apply them to train the Open Images dataset
[24], which includes most real-world categories (19,794 classes) in Table 1, they need to not only analyze pairs of the WSSS prediction and image to find biased objects in 6,927 classes (35% of 19,794 classes) as referred to Fig. 1(d) but also confirm the correlation of biased objects and non-problematic classes to prevent decreasing performance of non-problematic classes, impeding the practical WSSS usage. Therefore, without reporting performance on MS
COCO 2014 dataset, current debiasing methods [51, 29] have only shared results on the PASCAL VOC 2012 dataset.
To address the biased problem without additional dataset and supervision, we propose a novel fully-automatic bi-ased removal called MARS (Model-Agnostic biased object
Removal without additional Supervision), which first uti-lizes unsupervised semantic segmentation (USS) in WSSS.
In particular, our method follows a model-agnostic manner by newly connecting existing WSSS and USS methods for biased removal, which have been only independently stud-ied [21, 15]. Specifically, our method is based on two key observations related to the integration with USS and WSSS:
• (The first USS application to separate biased and tar-get objects in WSSS) As the bias issue is intrinsically linked to image-level supervision, USS has fewer bi-ased features than WSSS. In Fig. 2(a), without WSSS, the USS method must tune an optimal K per image
Figure 3.
Correspondence between biased objects and back-grounds. We measure the distance between each separated object (crosses in the left image) and the background regions of other im-ages (middle and right) within the same dataset. As a result, the long and short distances reflect target and biased objects, respec-tively. Therefore, the distance of USS features can be used as a criterion to remove biased objects after clustering features. to separate biased and target objects. Despite using the same ViT-B backbone, WSSS cannot find biased objects in Fig. 2(b). USS clustering successfully dis-entangles biased and target objects on a limited area of the WSSS output, as shown in Fig. 2(c).
• (The first USS-based distance metric to single out the biased object) As shown in Fig. 3, the shorter dis-tance reflects the biased object among distances be-tween two separated regions (pink and orange) and background regions of other images distinguished by the USS method (blue) because the minimum dis-tance between the target and all background sample sets is greater than the minimum distance between the bias and all background sample sets. Accordingly, we show the biased object can exist in the background set, which is a set of classes excluding foreground classes.
Therefore, MARS produces debiased labels using the
USS-based distance metric after separating biased and tar-get objects in all training images. To prevent increasing FN of non-problematic classes, MARS then complements debi-ased labels with online predictions in the training time. Our main contributions are summarized as follows.
• We first introduce two observations of applying USS in
WSSS to find biased objects automatically: the USS-based feature clustering for separating biased and tar-get objects and a new distance metric to select the bi-ased object among two isolated objects.
• We propose a novel fully-automatic/model-agnostic method, MARS, which leverages semantically consis-tent features learned through USS to eliminate biased objects without additional supervision and dataset.
• Unlike current debiasing methods [51, 29] that vali-dated only in the PASCAL VOC 2012 dataset with fewer labels, we have also verified the validity of
MARS in the more practical case with larger and com-plex labels such as MS COCO 2014; MARS achieves new state-of-the-art results on two benchmarks (VOC: 77.7%, COCO: 49.4%) and consistently improves rep-resentative WSSS methods [1, 49, 28, 21] by at least 3.4%, newly validating USS grafting on WSSS.
Figure 4. Conceptual comparison of three WSSS requirements. (a): Using the CLIP’s knowledge trained on image-text pairs dataset (b): Human annotators manually collect alleviates the biased problem by finding problematic classes and identifying biased objects. problematic images from the Open Images dataset [24] to train biased objects directly. (c): The proposed MARS first applies an existing
USS approach to remove biased objects without additional supervision, achieving the fully-automatic biased removal.
Table 2. Comparison with our method and its related works. With the CLIP model trained on a 400M image-and-text dataset, CLIMS
[51] removes biased objects after finding problematic classes and identifying biased objects for each class (i.e., a railroad for the train class). W-OoD [29] requires human annotators manually col-lect problematic images (i.e., only including railroad in an image).
Unlike previous approaches, our method removes biased objects without additional datasets and human supervision.
Properties
For removing biased objects
Use model-agnostic manner
Need to require additional dataset
Need to find problematic classes
Need to identify biased objects
Need to collect problematic images
CLIMS [51] W-OoD [29]
✓
✗
✓
✓
✓
✗
✓
✓
✓
✓
✗
✓
Ours
✓
✓
✗
✗
✗
✗ 2.