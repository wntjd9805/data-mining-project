Abstract
As recent advances in Neural Radiance Fields (NeRF) have enabled high-ﬁdelity 3D face reconstruction and novel view synthesis, its manipulation also became an essential task in 3D vision. However, existing manipulation meth-ods require extensive human labor, such as a user-provided semantic mask and manual attribute search unsuitable for non-expert users. Instead, our approach is designed to re-quire a single text to manipulate a face reconstructed with
NeRF. To do so, we ﬁrst train a scene manipulator, a latent code-conditional deformable NeRF, over a dynamic scene to control a face deformation using the latent code. How-ever, representing a scene deformation with a single latent code is unfavorable for compositing local deformations ob-served in different instances. As so, our proposed Position-conditional Anchor Compositor (PAC) learns to represent a manipulated scene with spatially varying latent codes.
Their renderings with the scene manipulator are then op-timized to yield high cosine similarity to a target text in
CLIP embedding space for text-driven manipulation. To the best of our knowledge, our approach is the ﬁrst to address the text-driven manipulation of a face reconstructed with
NeRF. Extensive results, comparisons, and ablation studies demonstrate the effectiveness of our approach. 1.

Introduction
Easy manipulation of 3D face representation is an essential aspect of advancements in 3D digital human contents[33]. Though Neural Radiance Field[21] (NeRF) made a big step forward in a 3D scene reconstruction, many of its manipulative methods targets color[4, 35] or rigid ge-ometry [46, 16, 42, 15] manipulations, which are inappro-priate for detailed facial expression editing tasks. While a recent work proposed a regionally controllable face editing method [13], it requires an exhaustive process of collect-ing user-annotated masks of face parts from curated train-ing frames, followed by manual attribute control to achieve a desired manipulation. Face-speciﬁc implicit representa-tion methods [6, 48] utilize parameters of morphable face models [37] as priors to encode observed facial expressions with high ﬁdelity. However, their manipulations are not only done manually but also require extensive training sets of approximately 6000 frames that cover various facial ex-pressions, which are laborious in both data collection and manipulation phases. On the contrary, our approach only uses a single text to conduct facial manipulations in NeRF, and trains over a dynamic portrait video with approximately 300 training frames that include a few types of facial defor-mation examples as in Fig. 1a.
In order to control a face deformation, our method ﬁrst learns and separates observed deformations from a canon-ical space leveraging HyperNeRF[24]. Speciﬁcally, per-frame deformation latent codes and a shared latent code-conditional implicit scene network are trained over the training frames. Our key insight is to represent the defor-mations of a scene with multiple, spatially-varying latent codes for manipulation tasks. The insight originates from the shortcomings of na¨ıvely adopting the formulations of
HyperNeRF to manipulation tasks, which is to search for a single latent code that represents a desired face deformation.
For instance, a facial expression that requires a combination of local deformations observed in different instances is not expressible with a single latent code. In this work, we de-ﬁne such a problem as “linked local attribute problem” and address this issue by representing a manipulated scene with spatially varying latent codes. As a result, our manipulation could express a combination of locally observed deforma-tions as seen from the image rendering highlighted with red boundary in Fig. 2a.
To this end, we ﬁrst summarize all observed deforma-tions as a set of anchor codes and let MLP learn to compose the anchor codes to yield multiple, position-conditional la-tent codes. The reﬂectivity of the latent codes on visual attributes of a target text is then achieved by optimizing the rendered images of the latent codes to be close to a target text in CLIP[28] embedding space. In summary, our work makes the following contributions:
• Proposal of a text-driven manipulation pipeline of a face reconstructed with NeRF.
• Design of a manipulation network that learns to repre-sent a scene with spatially varying latent codes.
• First to conduct text-driven manipulation of a face re-constructed with NeRF to the best of our knowledge. (cid:5)(cid:18)(cid:23)(cid:11)(cid:21)(cid:20)(cid:19)(cid:16)(cid:8)(cid:23)(cid:15)(cid:25)(cid:11)(cid:1)(cid:22)(cid:16)(cid:15)(cid:9)(cid:15)(cid:18)(cid:13)(cid:1)(cid:25)(cid:19)(cid:16)(cid:24)(cid:17)(cid:11) (cid:7)(cid:16)(cid:15)(cid:9)(cid:15)(cid:18)(cid:13)(cid:1)(cid:22)(cid:24)(cid:21)(cid:12)(cid:8)(cid:9)(cid:11)(cid:22)(cid:1)(cid:12)(cid:21)(cid:19)(cid:17)(cid:1)(cid:16)(cid:11)(cid:8)(cid:21)(cid:18)(cid:11)(cid:10)(cid:1)(cid:9)(cid:19)(cid:10)(cid:11)(cid:22) (cid:5)(cid:18)(cid:23)(cid:11)(cid:21)(cid:20)(cid:19)(cid:16)(cid:8)(cid:23)(cid:15)(cid:25)(cid:11)(cid:1)(cid:22)(cid:16)(cid:15)(cid:9)(cid:15)(cid:18)(cid:13)(cid:1)(cid:22)(cid:24)(cid:21)(cid:12)(cid:8)(cid:9)(cid:11)(cid:22) (cid:6)(cid:19)(cid:18)(cid:4)(cid:15)(cid:18)(cid:23)(cid:11)(cid:21)(cid:20)(cid:19)(cid:16)(cid:8)(cid:23)(cid:15)(cid:25)(cid:11)(cid:1)(cid:22)(cid:16)(cid:15)(cid:9)(cid:15)(cid:18)(cid:13)(cid:1)(cid:22)(cid:24)(cid:21)(cid:12)(cid:8)(cid:9)(cid:11) (cid:4)(cid:7)(cid:3)(cid:7) (cid:11) (cid:1) (cid:2)(cid:9)(cid:8)(cid:8) (cid:5)(cid:7)(cid:3)(cid:11)(cid:1) (cid:6)(cid:8)(cid:8) (cid:3) (cid:6) (cid:5) (cid:4) (cid:8) (cid:10) (cid:1) (cid:9) (cid:6) (cid:8) (cid:11) (cid:7) (cid:2) (cid:2) (cid:4)(cid:7)(cid:3)(cid:6) (cid:11) (cid:1) (cid:2)(cid:8)(cid:9)(cid:8) (cid:5)(cid:7)(cid:3)(cid:11)(cid:1) (cid:6)(cid:9)(cid:8) (cid:4)(cid:7)(cid:3)(cid:6) (cid:3) (cid:1)(cid:1) (cid:11) (cid:1) (cid:2)(cid:8)(cid:8)(cid:8) (cid:2)(cid:17)(cid:19)(cid:24)(cid:23)(cid:14)(cid:3) (cid:4)(cid:7)(cid:3)(cid:7) (cid:11) (cid:1) (cid:2)(cid:9)(cid:9)(cid:8) (cid:3) (cid:1)(cid:2) (a) (cid:1)(cid:3) (cid:2)(cid:11)(cid:26)(cid:11)(cid:22)(cid:3) (cid:2)(cid:9)(cid:8)(cid:18)(cid:19)(cid:18)(cid:15)(cid:9)(cid:8)(cid:16)(cid:1)(cid:22)(cid:20)(cid:8)(cid:9)(cid:11)(cid:3) (cid:1) (cid:2)(cid:2)(cid:3) (cid:10) (cid:4)(cid:12)(cid:3)(cid:2) (cid:4)(cid:1) (cid:5)(cid:3)(cid:13) (b) (c)
Figure 2: (a) Illustration of linked local attribute problem in hyper space. Expressing scene deformation with per-scene latent code cannot compose local facial deformation observed in different instances. (b) Types of facial defor-mations observed during scene manipulator training. (c)
Renderings of interpolated latent codes with a scene ma-nipulator. 2.