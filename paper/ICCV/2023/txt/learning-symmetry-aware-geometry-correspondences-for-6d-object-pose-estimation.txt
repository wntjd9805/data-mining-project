Abstract
Current 6D pose estimation methods focus on handling objects that are previously trained, which limits their ap-plications in real dynamic world. To this end, we pro-pose a geometry correspondence-based framework, termed
GCPose, to estimate 6D pose of arbitrary unseen objects without any re-training. Specifically, the proposed method draws the idea from point cloud registration and resorts to object-agnostic geometry features to establish the 3D-3D correspondences between the object-scene point cloud and object-model point cloud. Then the 6D pose param-eters are solved by a least-squares fitting algorithm. Tak-ing the symmetry properties of objects into consideration, we design a symmetry-aware matching loss to facilitate the learning of dense point-wise geometry features and im-prove the performance considerably. Moreover, we intro-duce an online training data generation with special data augmentation and normalization to empower the network to learn diverse geometry prior. With training on syn-thetic objects from ShapeNet, our method outperforms pre-vious approaches for unseen object pose estimation by a large margin on T-LESS, LINEMOD, Occluded-LINEMOD, and TUD-L datasets. Code is available at https:// github.com/hikvision-research/GCPose. 1.

Introduction
The 6D pose of an object represents a geometry trans-formation between the object coordinate system and cam-era coordinate system, which consists of 3D rotation and 3D translation. Estimating object pose plays an important role in many real-world applications, such as robotic grasp-ing [8] and augmented reality [38].
*Corresponding author. (a) Category-Level (b) Template-Based (c) Correspondence-Based
Figure 1: Comparison of different open-set pose estima-tion frameworks. Unlike previous methods that rely on category-specific network training (a) or struggle to esti-mate precise poses (b), our GCPose can perform well on arbitrary unseen objects (c).
Driven by the recent developments in deep learning, var-ious methods have been proposed to explore the instance-level 6D pose estimation problem. Some existing works
[43, 15] employ CNNs to detect a set of keypoints pre-defined on the 3D object model. Then the 6D pose can be solved by Perspective-n-Points (PnP) [31] or least-squares fitting algorithm. Since the detected keypoints serve as sparse correspondences, these methods often struggle when objects have view-point changes, occlusions, or lack of tex-ture. Another alternative is to predict pixel-wise 3D co-ordinates for building dense 2D-3D correspondence maps
[42, 59, 51, 36, 22]. They allow for significantly better treatment of occlusions and lead to more precise poses. Al-though instance-level methods can obtain impressive results on existing benchmarks, they are still under the close-set as-sumption that the object space is identical in both training and testing phases. As a result, laborious data collection and re-training are required when unseen objects appear, which does not adhere to application in the real dynamic world.
To loosen the restriction with generalizability to unseen objects, category-level pose estimation paradigm [60, 33, 7, 35, 62] is proposed, as shown in Figure 1a. These ap-proaches predict the object pose for previously seen or un-seen objects from a known set of categories, but can not generalize to new instances having significantly different appearances or shapes [17, 53]. Another way to address the open-set problem is to resort to the template-based mecha-nism [55, 40, 5, 49, 30], which matches the input image to a series of templates generated from their 3D object models, as shown in Figure 1b. Obviously, these methods strug-gle to estimate precise poses due to occlusions and the lim-ited number of viewpoints. To remedy this disadvantage,
OVE6D [5] presents an in-plane orientation regression net-work and OSOP [49] introduces an extra network estimat-ing dense 2D-2D correspondences between the input image and the matched template for pose refinement. In general, these methods have cascade pipelines and result in less ac-curate pose estimation for unseen objects.
As is known, point cloud registration methods have demonstrated excellent generalization to previously unseen point clouds as the geometry features of the point cloud are generic and object-agnostic. Inspired by this idea, we present an unseen object 6D pose estimation framework based on dense geometry correspondences, termed GCPose.
Specifically, given the object-scene point cloud and object-model point cloud as input, GCPose can establish dense 3D-3D correspondences between them through the geom-etry features. Finding correspondences across two scene-level point clouds is well-studied in point cloud registra-tion [1, 23, 65, 64, 45] field. However, it is challenging to learn 3D-3D matching for object-level point clouds due to ambiguous correspondences caused by symmetric proper-ties in many object models. For instance, a 3D location in the object-scene point cloud may correspond to multiple 3D locations on the surface of the symmetric object, and vice versa. Therefore, exploiting the off-the-shelf point cloud registration method is sub-optimal to building correspon-dences for object pose estimation. To this end, we design a symmetry-aware matching loss to let the network learn the object symmetries explicitly.
Following the practice in OVE6D [5], we train the net-work using a large number of synthetic 3D object models from the ShapeNet [6] dataset. Specifically, we introduce a simple yet effective online training data generation with special data augmentation and normalization to empower the network to learn diverse geometry prior. After train-ing on synthetic objects with varied shapes, our method is capable of generalizing to an arbitrary unseen object with-out any re-training. At inference time, the proposed method requires a depth image with a target object mask and the as-sociated object CAD model, which are utilized to generate object-scene and object-model point clouds.
Our contribution can be summarized as follows: 1) We employ the point cloud registration framework and adapt it to work well for unseen object pose estimation. 2) A symmetry-aware matching loss is proposed for building unambiguous and robust 3D-3D correspon-dences, which improves the performance significantly. 3) GCPose achieves state-of-the-art performance on T-LESS, LineMOD, Occluded-LineMOD, and TUD-L datasets under an open-set pose estimation setting. Be-sides, the performance of GCPose can be further im-proved by scaling up the training data. 2.