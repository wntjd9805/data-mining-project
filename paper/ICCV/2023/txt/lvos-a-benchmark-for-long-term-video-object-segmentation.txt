Abstract
Existing video object segmentation (VOS) benchmarks focus on short-term videos which just last about 3-5 sec-onds and where objects are visible most of the time. These videos are poorly representative of practical applications, and the absence of long-term datasets restricts further in-vestigation of VOS on the application in realistic scenar-ios. So, in this paper, we present a new benchmark dataset named LVOS, which consists of 220 videos with a total du-ration of 421 minutes. To the best of our knowledge, LVOS is the first densely annotated long-term VOS dataset. The videos in our LVOS last 1.59 minutes on average, which is 20 times longer than videos in existing VOS datasets. Each video includes various attributes, especially challenges de-riving from the wild, such as long-term reappearing and cross-temporal similar objeccts. Based on LVOS, we assess
*Corresponding author. existing video object segmentation algorithms and propose a Diverse Dynamic Memory network (DDMemory) that consists of three complementary memory banks to exploit temporal information adequately. The experimental results demonstrate the strength and weaknesses of prior meth-ods, pointing promising directions for further study. Data and code are available at https://lingyihongfd. github.io/lvos.github.io/. 1.

Introduction
Given a specific object mask at the first frame, video ob-ject segmentation (VOS) aims to highlight target in a video.
VOS plays a significant role in video understanding and has many potential downstream applications, such as video editing [45], augmented reality [43], robotics [11, 14], self-driving cars [78, 54, 55]. For most practical applications, objects may experience frequent disappearing and videos
Dataset
FBMS [44]
DAVIS [50]
YouTube-VOS [72]
YouTube-VIS [73]
OVIS [52]
UVO [67]
VOT-ST 2021 [28]
VOT-LT 2019 [29]
UAV20L [42]
LaSOT [15]
YouTube-VIS 2022 Long [72]
YouTube-VOS 2022 Long [73]
Long-time Video [33]
LVOS
Videos
Mean
Frames
Total
Frames
Mean
Duration
Total
Duration
Frame
Rate
Object
Classes
Objects Annotations
Annotations
Type 59 90 3,252 2,883 901 1,200 60 50 20 1,400 121 116 3 220 235 69 27 28 90 28 324 13,860 6,298 107,181 78,000
∼68,650
∼108,000 19,447 4,305 2,934 2,506 ∼3,520,000 215,298
∼59,000 75 67 2,470 574 9,014 7,873 7,411 126,280 0.13 0.04 0.06 0.06 0.21 0.05 0.18 2.39 1.63 1.39 0.8 0.74 1.3 1.59 7.7 5.17 217.2 216.7 190.7 511 10.8 119 32.6 1,950 100 87 4 421 30 24 6 6 6 30 30 30 30 30 1.5 1.5 30 6 16
-78 40 25
---5 70
---27 1,465 139 13,543 205 133,886 6,048
∼131,000 4,883
∼296,000 5,223 14,748 ∼1,327,000 60 50 20 17,248 215,298
∼59,000 1,400 ∼3,520,000
-116 3 282
--60 156,432
M
M
M
M
M
M
M
B
B
B
N
N
M
M
Table 1: Comparison of LVOS with the most popular video segmentation and tracking benchmarks. The top part is existing short-term video datasets and the bottom part is long-term video datasets. Duration denotes the total duration (in minutes) of the annotated videos. Annotations type means the type of groundtruth annotations. M and B denote mask and box annotations. N means that the groundtruth annotations are unavailable. The largest value is in bold, and the second and third largest values are underlined. always last more than 1 minute. It is crucial for VOS model to precisely re-detect and segment target objects in videos of arbitrary length.
However, existing VOS models are specifically designed for short-term situation, which struggle to tackle unfore-seen challenges in long-term videos. They are vulner-able to long-term disappearance and error accumulation over time [63, 75, 76]. [46, 8, 20, 70, 57] may suffer from the poor efficiency and out-of-memory crash due to the ever-expanding memory bank, especially in a long video. However, the lack of the densely annotated long-term VOS datasets restricts the development of VOS in practice. To date, almost all VOS benchmark datasets, such as DAVIS [50] and YouTube-VOS [72], just focus on short-term videos, which are a poor reflection of practitioners’ de-mands. The average video length is less than 6 seconds and target objects are always visible, while the average duration is much more longer (i.e.,1-2 minutes) and target objects disappear and reappear frequently in real-world scenarios.
To this end, we propose the first long-term video object segmentation benchmark dataset, named Long-term Video
Object Segmentation (LVOS). LVOS contains 220 videos with an average duration of 1.59 minutes. The emphasized properties of LVOS are summarised as follows. (1) Long-term. Videos in LVOS last 1.59 minutes on average (vs 6 seconds in short-term videos), which is much closer to real applications (Table 1). These videos cover multiple challenges, especially attributes specific in long-term videos such as frequent reappearance and long-term similar ob-ject confusion. Figure 1 shows some sample videos. (2)
Dense and high-quality annotations. All frames in LVOS are manually and precisely annotated at 6 FPS. To annotate the target object accurately and efficiently, we build a semi-automatic annotation pipeline. There are 156K annotated objects in LVOS, about 18% times more annotations than the largest VOS dataset [72]. (3) Comprehensive labeling.
Videos in LVOS feature 27 categories to represent the daily scenarios. Among the 27 categories, there are 7 unseen cat-egories to better assess the generalization ability of models.
Extensive experiments on LVOS are conducted to assess existing VOS models. To capture the different temporal context in long-term videos adequately, we propose Diverse
Dynamic Memory (DDMemory). DDMemory consists of three complementary memory banks: reference mem-ory, global memory, and local memory to encode histori-cal information into fixed-size features. Due to the diverse and dynamic memory mechanism, DDMemory can handle videos of any length with constant memory cost and high efficiency. Oracle experiment demonstrates that error accu-mulation and complex motion are the primary cause for the unsatisfactory performance.
Our contributions are summarized as follows: (1) We construct a new long-term, densely and high-quality an-notated, and comprehensively labeled VOS dataset named
LVOS with 220 videos whose average duration is 1.59 min-utes. (2) We propose the DDMemory to handle long-term (3) We assess existing VOS models and videos better.
DDMemory on LVOS and analyze the cause of errors to discover cues for the development of robust VOS methods. 2.