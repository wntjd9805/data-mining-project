Abstract
Large-scale visual localization systems continue to rely on 3D point clouds built from image collections using structure-from-motion. While the 3D points in these models are represented using local image features, directly match-ing a query image’s local features against the point cloud is challenging due to the scale of the nearest-neighbor search problem. Many recent approaches to visual localization have thus proposed a hybrid method, where first a global (per im-age) embedding is used to retrieve a small subset of database images, and local features of the query are matched only against those. It seems to have become common belief that global embeddings are critical for said image-retrieval in visual localization, despite the significant downside of hav-ing to compute two feature types for each query image. In this paper, we take a step back from this assumption and pro-pose Constrained Approximate Nearest Neighbors (CANN), a joint solution of k-nearest-neighbors across both the ge-ometry and appearance space using only local features. We first derive the theoretical foundation for k-nearest-neighbor retrieval across multiple metrics and then showcase how
CANN improves visual localization. Our experiments on public localization benchmarks demonstrate that our method significantly outperforms both state-of-the-art global feature-based retrieval and approaches using local feature aggrega-tion schemes. Moreover, it is an order of magnitude faster in both index and query time than feature aggregation schemes for these datasets. Code will be released. 1.

Introduction
In this paper we focus on the problem of image retrieval for visual localization. Modern visual localization approaches are predominantly based on 3D point clouds that repre-sent the geometry and appearance of large scale scenes
[30, 19, 43, 31]. These 3D points are estimated from image collections using Structure-from-Motion (SfM), where each 3D point has an associated descriptor derived from pixels.
Figure 1: The proposed Constrained Approximate Nearest Neigh-bor algorithm allows to find the best subset of 3D points that are both close to query features in appearance space and that are con-sistently seen by the same camera, leading to high overlap with the initially unknown query camera pose (shaded area). Jointly solving for these two metrics in a single search algorithm is a long-known open question in the community and CANN provides to the best of our knowledge the first practical solution. Red points in the figure show neighbors retrieved by an unconstrained search using the fea-tures from the query image (bottom right). Using CANN it’s more likely to retrieve points that are inliers to geometric verification (green) and less likely to fetch unrelated outlier points (yellow).
To localize a query image against such 3D models, a set of local features is extracted from it and 2D-3D cor-respondences are estimated based on descriptor similarity.
In practice, this data association problem suffers from var-ious challenges: visual aliasing, scene change, noise, etc.
Because the final localization solution is computed using geometric inference from these 2D-3D correspondences, not finding enough correct matches can lead the entire localiza-tion process to fail.
Simply establishing many more matches per query key-point (red points in Fig. 1) however causes long runtime in geometric verification [3]. It is thus important to find 1
a small 2D-3D set which has high probability to contain
“good” matches (yellow/green points in Fig. 1): In fact we know that the 3D points of “good” matches should all lie inside one (unknown) camera frustum which is the one of the query image (shaded area in Fig. 1).
There exist several approximations to this problem, rang-ing from clustering nearest-neighbor matches in the 3D model’s covisibility graph [42] to using image retrieval meth-ods to obtain a small set of candidate images for which local features are matched subsequently [41]. The latter approach, leveraging recent advances in global (per image) embed-dings, has gained substantial traction recently [18, 42, 41, 8], to a degree that it appears the community has abandoned the idea of finding a solution that jointly solves for appearance and geometry using local features only. For example, the benchmark we evaluate on [18] didn’t even consider local feature based retrieval approach at publication time.
We don’t consider the case of using local features closed and therefore propose an approach to obtain matches that are close in appearance space while obtaining geometric consistency at the same time – which is a long-known open question in the community.
Contributions. In this paper we make three contributions: (1) Our first and main contribution is a new method, re-ferred to as Constrained Approximate Nearest Neighbors (CANN), that efficiently obtains a high quality, small set of 2D-3D correspondences. CANN performs nearest neigh-bor search in descriptor space in a constrained manner, so that matches are compact in 3D space. We provide both a brute-force solution as well as an efficient implementation and associated complexity analysis of this colored nearest neighbor search algorithm. (2) Our second contribution is to make the connection of colored nearest neighbor search to the problem space of image retrieval and localization, proposing a metric to rank cameras, which can serve as a way to evaluate future work in this area. (3) Lastly we provide an extensive evaluation of both global and local feature based methods on four large scale datasets from [18]: “Baidu-Mall”,“Gangnam Sta-tion”,“RobotCar Seasons” and “Aachen Day-Night v1.1”.
We demonstrate that local feature based methods are not only competitive, but in fact strongly outperform global embedding based approaches; which goes contrary to the trend in the community. We hope to provide new impulse to techniques that aim for jointly searching in appearance and geometry space, which is more efficient and elegant than previously proposed two-step approaches. 2.