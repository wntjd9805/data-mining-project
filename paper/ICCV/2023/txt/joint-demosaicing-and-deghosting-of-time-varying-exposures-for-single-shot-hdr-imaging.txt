Abstract
The quad-Bayer patterned image sensor has made signifi-cant improvements in spatial resolution over recent years due to advancements in image sensor technology. This has enabled single-shot high-dynamic-range (HDR) imag-ing using spatially varying multiple exposures. Popular methods for multi-exposure array sensors involve varying the gain of each exposure, but this does not effectively change the photoelectronic energy in each exposure. Con-sequently, HDR images produced using gain-based expo-sure variation may suffer from noise and details being sat-urated. To address this problem, we intend to use time-varying exposures in quad-Bayer patterned sensors. This approach allows long-exposure pixels to receive more pho-ton energy than short- or middle-exposure pixels, resulting in higher-quality HDR images. However, time-varying ex-posures are not ideal for dynamic scenes and require an ad-ditional deghosting method. To tackle this issue, we propose a single-shot HDR demosaicing method that takes time-varying multiple exposures as input and jointly solves both the demosaicing and deghosting problems. Our method uses a feature-extraction module to handle mosaiced multi-ple exposures and a multiscale transformer module to regis-ter spatial displacements of multiple exposures and colors.
We also created a dataset of quad-Bayer sensor input with time-varying exposures and trained our network using this dataset. Results demonstrate that our method outperforms baseline HDR reconstruction methods with both synthetic and real datasets. With our method, we can achieve high-quality HDR images in challenging lighting conditions. 1.

Introduction
Recent advancements in image sensor technology, such as interlaced and quad-Bayer patterned image sensors, have fa-cilitated the development of multi-exposure color filter ar-rays, which enable single-shot high-dynamic-range (HDR) imaging. Single-shot HDR imaging takes only one image to generate an HDR image as input. This imaging tech-nology has successfully expanded the dynamic range of
Figure 1. (a) Input quad-Bayer patterned RAW image with differ-ent exposure times and colors. (b) Three multi-exposure images. (c) Our method result. We jointly solve demosaicing and deblur-ring problems to achieve a high-quality single-shot HDR image from the quad-Bayer pattern. captured images beyond conventional low-dynamic-range (LDR) images. However, multi-exposure color filter array sensors must share pixel budgets to capture not only differ-ent colors but also different exposures, which can result in severe degradation of spatial resolution. The reconstructed
HDR images may experience a reduction in spatial reso-lution by half due to the use of color filters and multiple exposures. Current single-shot methods have focused on enhancing spatial resolution by addressing multi-exposure sampling artifacts, such as mosaicing [1, 17, 37] or inter-lacing artifacts [12, 10, 35, 4].
Current single-shot HDR imaging techniques use gain-based exposure variation to capture different levels of ex-posures simultaneously, but this approach provides only a minor improvement in dynamic range compared to tradi-tional static HDR imaging. Gain-based exposure variation does not capture different amounts of photo energy, even with a long exposure input, which limits the dynamic range of reconstructed HDR images. Traditional HDR imaging captures time-varying multi-exposures, which allows for a wider range of photon energy and high signal-to-noise ra-tio in reconstructed HDR images. However, this approach is not applicable to single-shot HDR imaging of dynamic scenes or camera motions due to motion blur. Recent HDR
deghosting methods [18, 40, 42, 43, 32, 28, 25] have ad-dressed the motion blur problem in HDR video input, but they rarely consider the varying amounts of motion blur with time-varying multiple exposures.
Two main challenges must be addressed to achieve high-quality demosaicing of time-varying multiple exposures in single-shot HDR imaging. The first challenge is the dou-ble mosaicing architecture of multiple exposure times and color filters, which results in sparse input pixel observations that severely degrade the spatial resolution in reconstructed
HDR images. The second challenge arises from spatially-varying motion blur, which is particularly prevalent in long-exposure pixels on the array. This leads to spatially incon-sistent ghost artifacts that degrade the edge details of mov-ing objects or scenes in the resulting images.
In this work, we propose a novel single-shot HDR imag-ing technique that tackles the demosaicing and deghost-ing challenges of time-varying multiple exposures captured by quad-Bayer patterned sensors (Figure 1). To accom-plish this, we created a dataset of time-varying quad-Bayer patterned HDR sensor inputs from existing HDR video datasets. Our demosaicing network comprises feature-extraction and U-net style multi-scale transformer modules.
For each exposure level observation, we use a residual ar-chitecture to convert them into channel-wise attention fea-tures with a doubled spatial resolution. We also address spatial misalignment and motion blur in longer exposure channels through the transformer architecture by acquiring query, key, and value vectors from various sources in the transformer block. In contrast to gain-based single-shot ap-proaches, our method takes into account the physical dif-ferences in exposure times in the quad-Bayer array, which helps mitigate the varying degrees of motion blur in in-put images. Our approach learns the spatial relationship among differently-blurred multiple exposures and registers them with high precision to prevent ghosting artifacts. We also design the transformer block to be configured coarse-to-fine, taking into account pixel displacement that ranges from the nearest neighboring pixels to further ones.
The proposed method overcomes the degradation of spatial resolution caused by the mosaiced exposure and color Bayer patterns and successfully reconstructs high-resolution HDR images from time-varying multiple expo-sure inputs in single-shot HDR imaging. Results from vari-ous real and synthetic scenes demonstrate the superiority of our method over baseline HDR reconstruction methods. 2.