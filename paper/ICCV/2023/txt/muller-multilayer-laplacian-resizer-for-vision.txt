Abstract
Image resizing operation is a fundamental preprocess-ing module in modern computer vision. Throughout the deep learning revolution, researchers have overlooked the potential of alternative resizing methods beyond the commonly used resizers that are readily available, such as nearest-neighbors, bilinear, and bicubic. The key question of our interest is whether the front-end resizer affects the performance of deep vision models? In this paper, we present an extremely lightweight multilayer Laplacian resizer with only a handful of trainable parameters, dubbed
MULLER resizer. MULLER has a bandpass nature in that it learns to boost details in certain frequency subbands that beneﬁt the downstream recognition models. We show that MULLER can be easily plugged into various training pipelines, and it effectively boosts the performance of the underlying vision task with little to no extra cost.
Speciﬁcally, we select a state-of-the-art vision Transformer,
MaxViT [50], as the baseline, and show that, if trained with MULLER, MaxViT gains up to 0.6% top-1 accu-racy, and meanwhile enjoys 36% inference cost saving to achieve similar top-1 accuracy on ImageNet-1k, as compared to the standard training scheme.
Notably,
MULLER’s performance also scales with model size and training data size such as ImageNet-21k and JFT, and it including is widely applicable to multiple vision tasks, image classiﬁcation, object detection and segmentation, as well as image quality assessment. The code is available https://github.com/google-research/ at google-research/tree/master/muller. 1.

Introduction
Most computer vision problems such as image classiﬁ-cation, object detection, video recognition, and image/video generation have seen groundbreaking advancement by deep neural networks-based models that are trained on web-scale, human-curated datasets [11, 12, 15, 15, 24, 33, 35, 40, 41, 46, 53, 58]. In any of the underlining training infrastruc-tures like Tensorﬂow [1] and PyTorch [30], image resizing
Figure 1. Top: our proposed learned resizer can push for-ward a strong vision Transformer MaxViT [50] by up to 0.6% top-1 accuracy on ImageNet-1K with no extra in-ference cost. Results for other backbones are shown in
Sec. 4.2. Bottom: demonstratation of the learned resizer -with detail-boosted input image, the classiﬁcation accuracy of the examplar image has improved. is an essential preprocessing step which enables efﬁcient gradient-based training of networks with millions of train-able parameters. Moreover, the factor of image size can sometimes signiﬁcantly impact the performance of various tasks, particularly those requiring high-resolution predic-tion. Although neural architectures have been revolution-ized by CNNs and Transformers, surprisingly limited atten-tion has been paid to the role of image resizing operations.
Resizing or rescaling refers to the process of chang-ing the resolution of an image, while largely preserving its content for human or machine perception. There are sev-eral major reasons for using resizing: (1) The mini-batch gradient-based training scheme requires the same image resolution in a batch, (2) Resizing can help to reduce com-putational complexity, making it easier and faster to train
and inference neural networks, (3) Smaller images consume lower memory footprint, enabling stable training of large models like Transformers with larger batch-size, (4) Resiz-ing contributes to improving model generalization and ro-bustness by reducing overﬁtting to speciﬁc image size and scales, making the models more ﬂexible and applicable to real-world scenarios.
Moreover, resizing is an integral component of remote inference frameworks. Typically, to maintain the bandwidth efﬁciency of the communication network, before sending an image to the inference server, a thumbnail generator down-scales the image to a ﬁxed resolution (e.g. 480p). The thumbnail generator can be located on the client side (e.g. smart phone), or it can be part of a cloud storage system.
This means that in most cases the inference server does not have access to the original image.
Basic resizing functions such as nearest-neighbor or bi-linear interpolation have long been the go-to options with little to no deliberate consideration in most training soft-ware. While these simple methods offer greater simplicity and efﬁciency, they are not optimized for speciﬁc computer vision tasks and may lead to the loss of important visual features or details, which can, sometimes, result in signif-icant performance degradation [29, 45]. To overcome this limitation, researchers have proposed learned resizers (or downsamplers) [3, 45] that leverage the deep neural net-works to learn image resizing directly from data, yielding improved performance on several tasks. However, one of the main challenges with these learned resizers is that they often require a large number of parameters, and high com-putational overhead during training and inference. Note that this is speciﬁcally a bottleneck in remote inference where the resizer (a.k.a thumbnail generator) is not in the infer-ence server, and may have limited computational resources to run a heavy neural net resizer. Additionally, less-bounded resizers can sometimes be difﬁcult to transfer to new tasks or datasets due to their excessive model capability.
In this paper, we introduce an incredibly lightweight learned resizer, which we call MULLER, that operates on multilayer Laplacian decomposition of images (see Fig. 2).
Our method requires very few parameters and FLOPs, and does not incur any extra training cost, outperforming exist-ing methods in terms of computational efﬁciency, parameter efﬁciency, and transferability. We show that it is the ability-to-learn that makes a better resizer, but not the capacity of the resizer – our MULLER resizer only learns four parame-ters and is more effective than previous complex ones using deep residual blocks [45]. We also demonstrate that our method can be used as a drop-in replacement for off-the-shelf resizing functions on several vision tasks, including classiﬁcation, object detection and segmentation, and im-age quality assessment, resulting in signiﬁcant performance improvements without any extra cost. As shown in Fig. 1, for example, training with the MULLER resizer achieves up to 0.6% performance gain, using a state-of-the-art backbone
MaxViT [50] as the testbed. Our contributions are:
• We propose a surprisingly simple and lightweight resizer, that can be used as a drop-in replacement for off-the-shelf resizing functions like bilinear resizing.
• We demonstrate its applications to multiple computer vi-sion tasks, including image classiﬁcation, object detec-tion and segmentation, and image quality assessment, showing superior performance over existing approaches.
• Extensive ablation studies, analysis, and visualization re-sults are provided to show the robustness and general-ization of the proposed resizer for various model scales, benchmarks, and tasks. 2.