Abstract 1.

Introduction
Few-shot learning has made impressive strides in ad-dressing the crucial challenges of recognizing unknown samples from novel classes in target query sets and manag-ing visual shifts between domains. However, existing tech-niques fall short when it comes to identifying target outliers under domain shifts by learning to reject pseudo-outliers from the source domain, resulting in an incomplete solution to both problems. To address these challenges comprehen-sively, we propose a novel approach called Domain Adap-tive Few-Shot Open Set Recognition (DA-FSOS) and intro-duce a meta-learning-based architecture named DAFOS-NET. During training, our model learns a shared and discriminative embedding space while creating a pseudo-open-space decision boundary, given a fully-supervised source domain and a label-disjoint few-shot target domain.
To enhance data density, we use a pair of conditional ad-versarial networks with tunable noise variances to aug-ment both domainsâ€™ closed and pseudo-open spaces. Fur-thermore, we propose a domain-specific batch-normalized class prototypes alignment strategy to align both domains globally while ensuring class-discriminativeness through novel metric objectives. Our training approach ensures that
DAFOS-NET can generalize well to new scenarios in the target domain. We present three benchmarks for DA-FSOS based on the Office-Home, mini-ImageNet/CUB, and Do-mainNet datasets and demonstrate the efficacy of DAFOS-Net through extensive experimentation.
The development of deep learning techniques has led to significant advancements in visual recognition tasks by leveraging their ability to learn data-driven features from a vast amount of training examples [14, 21]. However, la-beling is a laborious and costly task, which is why few-shot learning (FSL) [33, 22] aims to recognize target classes with limited supervision by learning transferable features from a label-disjoint source domain that has sufficient supervision.
Despite progress [40], FSL models encounter difficulties in two critical scenarios: i) when the under-represented tar-get domain classes are drawn from a different distribution than the source domain. One solution to this is Domain
Adaptive Few-Shot Learning (DA-FSL), which adapts dis-joint classes from the fully-supervised source and sparsely-supervised target domains during training [41, 34, 10], and ii) Few-Shot Open-Set Learning (FSOS) [25], which as-sumes no domain gap between source and target but com-bines FSL with Open-Set Recognition (OSR) [12, 1] to de-tect novel class samples as outliers during testing. However, it is desirable for a generic FSL system to handle domain discrepancy and reject outliers during inference in a unified manner for practical applications. To this end, we introduce a novel scenario, called Domain Adaptive Few-Shot Open-Set Learning (DA-FSOS), which is illustrated in Fig 1.
DA-FSOS is a method that addresses a challenging prob-lem: how to learn from supervision in one domain while adapting to a different domain with non-overlapping known
classes and potential test-time outliers under a few-shot set-ting. During training, the method uses supervision from the source domain and a few-shot training set from a disjoint set of classes of the target domain. However, during testing, the method is expected to handle unlabelled samples from a new set of known and open-set classes from the target domain, adding an extra challenge. DA-FSOS can be ap-plied to self-driving cars, where learning to identify known classes and reject outliers from abundant gaming data, the real-world objects of interest (known and unknown) on the road can be identified. Also, to detect novel animal species, unknown land cover objects, unknown viruses in medical imaging, etc., DA-FSOS can become instrumental.
DA-FSOS combines several techniques to tackle these challenges, including domain adaptation, few-shot learning, and open-set recognition. The setting is designed to handle unconstrained domain differences, extremely limited super-vision in the target domain, and the absence of prior knowl-edge regarding the target open space in test time.
While DA-FSL and FSOS techniques can be combined, they may not be sufficient to effectively solve the DA-FSOS problem as they rely on different assumptions individually (see Section 4). Similarly, combining an FSL technique with open-set DA [29] or a DA-FSL model with the OSR approach may not be suitable since DA variants assume la-bel space consistency between domains, which is not the case for DA-FSOS. Therefore, it is necessary to develop a model specifically designed to solve DA-FSOS.
Our proposed DAFOS-NET: In this paper, we present a novel model called DAFOS-NET that addresses the DA-FSOS problem by integrating three crucial considerations.
Our approach aims to learn a prototype-based classifier that can reject target outliers during testing, and we propose a meta-training method that simulates the test scenario by di-viding the available training classes from both domains into known and pseudo-unknown categories in each episode.
To address the issue of overfitting caused by limited target supervision, we propose a data augmentation tech-nique in DAFOS-NET. Unlike previous FSOS methods that only augment known classes from the source domain
[27], our approach involves augmenting both known and pseudo-unknown classes from both source and target do-mains using a pair of class and domain conditional adver-sarial networks (cGANs). To maintain feature consistency when generating known samples, we apply a low noise vari-ance for the respective cGAN. However, to increase the scatter when generating pseudo-unknown samples, we use a high noise variance. To prevent mode collapse during train-ing, we introduce a regularizer that ensures the outputs of the two cGANs are consistently different.
We also introduce Global Cross-Domain Prototype
Alignment (GCDPA) strategy by exploiting domain-specific batch-norm statistics to bring the domains closer for the smooth transfer of source knowledge into the tar-get. However, we must ensure that the adaptation does not cause misalignments between the domains. To main-tain class discriminativeness, we introduce a class compact-ness loss for the known class samples. Simultaneously, a novel prototype diversification loss objective is introduced to maximize the gap between the known-class prototypes and a combination of in-domain pseudo-unknown samples with the across-domain class prototypes.
Finally, we propose a learning-based approach to auto-matically predict the domain and inlier/outlier class labels for the test samples. This approach eliminates the need for manual threshold selection [25] and improves the ability to solve generalized DA-FSOS by selectively considering ei-ther source or target prototypes based on the predicted do-main labels for classifying the test queries.
In summary, our novel contributions are as follows: 1. We introduce DA-FSOS, a practical problem setting that generalizes FSOS and DA-FSL, and to solve that, we pro-pose an end-to-end solution called DAFOS-NET. 2. DAFOS-NET integrates four novel ideas: i) An episodic training strategy to develop a domain-agnostic open-set ii) A generative feature augmentation scheme classifier. that produces diversified known and pseudo-unknown class samples for both domains from few-shot training samples. iii) A metric objective that ensures class compactness and iv) A prototypical discriminativeness for both domains. batch-norm alignment-based global domain adaptation. 3. We present the standard and generalized DA-FSOS training and evaluation protocols. Accordingly, we evalu-ate our approach on DomainNet[31], miniImageNet-CUB
[39, 38], and Office-Home [37] datasets and achieve an av-erage gain of 15% closed accuracy and 17% AUROC. 2.