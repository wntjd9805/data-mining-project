Abstract
Deep neural networks have achieved remarkable progress in enhancing low-light images by improving their brightness and eliminating noise. However, most existing methods construct end-to-end mapping networks heuristi-cally, neglecting the intrinsic prior of image enhancement task and lacking transparency and interpretability. Al-though some unfolding solutions have been proposed to re-lieve these issues, they rely on proximal operator networks that deliver ambiguous and implicit priors. In this work, we propose a paradigm for low-light image enhancement that explores the potential of customized learnable priors to improve the transparency of the deep unfolding paradigm.
Motivated by the powerful feature representation capability of Masked Autoencoder (MAE), we customize MAE-based illumination and noise priors and redevelop them from two perspectives: 1) structure flow: we train the MAE from a normal-light image to its illumination properties and then embed it into the proximal operator design of the unfold-ing architecture; and 2) optimization flow: we train MAE from a normal-light image to its gradient representation and then employ it as a regularization term to constrain noise in the model output. These designs improve the inter-pretability and representation capability of the model. Ex-tensive experiments on multiple low-light image enhance-ment datasets demonstrate the superiority of our proposed paradigm over state-of-the-art methods. Code is available at https://github.com/zheng980629/CUE. 1.

Introduction
Low-light conditions often result in images with lim-ited visibility and noise, which can negatively affect down-stream computer vision tasks. To recover details buried in low-light images and remove noise effects, the field of low-*Both authors contributed equally to this research.
†Corresponding author.
Figure 1. Comparison between previous deep unfolding low-light enhancement methods and our proposed paradigm. (a) Previous works deliver the ambiguous and implicit priors by the heuris-tically proximal networks in a “black box” manner; and (b) our
CUE explores the potential of customized learnable priors on low-light image enhancement to improve the transparency of the deep unfolding paradigm. light image enhancement has received significant attention.
Existing approaches can be classified into two categories: traditional methods and deep learning-based methods.
Traditional methods for low-light image enhancement involve formulating the problem as an optimization task and using image priors as regularization terms to constrain the solution space. One such representative method is based on the Retinex theory[23], which assumes that an image can be decomposed into reflectance and illumination compo-nents where the former keeps consistency under any light-ing conditions and the latter reflects variations in bright-ness. Nonetheless, estimating illumination and reflectance terms simultaneously is challenging. To overcome this is-sue, based on the Retinex theory, well-designed priors of the illumination and reflectance terms are proposed. For example, an ℓ2 norm on illumination gradients is proposed by [12, 11] to ensure smoothness but generate blurred bor-ders around areas where the illumination suddenly changes.
[28] further introduces a noise term and develops a ℓ1 prior to constrain illumination gradients, maintaining the overall structure of the illumination map. However, hand-crafted priors are difficult to design and have limited representative ability in complex scenes, hindering their practical usage.
Inspired by the powerful learning capability of deep learning, explosive learning-driven methods have undeni-ably ushered in a new era for low-light image enhance-ment [18, 17, 20, 57, 19, 16, 63, 64, 31, 39, 33, 38, 42, 22, 53, 37, 41, 30]. For example, RetinexNet [50] and
KinD [60] are two popular methods that use deep learning to enhance low-light images. RetinexNet integrates Retinex decomposition and illumination adjustment into an end-to-end trainable network, while KinD separately trains layer illumination adjustment, and reflectance decomposition, restoration subnetworks. Despite their success, these meth-ods often construct black-box networks without considering the intrinsic priors of illumination and reflectance compo-nents, leading to a lack of transparency and interpretability.
To improve the interpretability, a model-driven deep un-folding paradigm, URetinexNet [52], has been proposed. It formulates the Retinex decomposition as an implicit prior regularized model but neglects the effects of noise pollu-tion. Moreover, this method delivers the illumination and reflectance priors in a vague and ambiguous manner through empirically constructed proximal operator networks. Thus, the inherent properties of these two components are not con-sidered, leading to an ambiguous and implicit prior princi-ple (see Fig. 1). We therefore wonder, “Can we customize learnable priors for illumination and noise terms that lever-age their intrinsic properties?”.
To answer this question, we first analyze the character-istics of the illumination and noise components: 1) illumi-nation prior: Based on the Retinex theory, the illumina-tion component should be smooth and preserve the struc-ture while adapting to different lighting conditions; 2) noise prior: In low-light images, noise is inherent and cannot be removed simply by adjusting brightness, i.e., irrelevant to enhanced lightness.
Motivated by the above analysis, we aim at exploring the potential of customized learnable priors for low-light image enhancement to improve the transparency of the deep unfolding paradigm. Our proposed method is called
Customized Unfolding Enhancer (CUE). To achieve this, we utilize the innate feature representation capability of
Masked Autoencoder (MAE) to customize MAE-based il-lumination and noise priors with a masked image model-ing strategy. Specifically, the illumination prior is trained from a normal-light image to its illumination map filtered by a bilateral filter, reducing noise without altering the in-trinsic structure [6]. The noise prior aims to learn the histograms of oriented gradients of a normal-light image, which presents the gradient variation while being irrelevant to enhanced lightness [8]. To integrate the customized pri-ors into the low-light image enhancement process, we re-develop the two learned priors from two perspectives: 1) structure flow: embedding the learned illumination prior into the design of the proximal operator in the Retinex de-composition unfolding process; and 2) optimization flow: redeveloping the learned noise prior as a regularization term to eliminate noise by minimizing the gradient presentation difference between the enhanced and normal-light images.
Extensive experimental results demonstrate the superiority of our paradigm over state-of-the-art methods. Addition-ally, we also verify the effectiveness of the proposed learn-able noise prior for image denoising.
Our contributions are summarized as follows:
• We activate the potential of customized learnable il-lumination and noise priors via a new deep unfolding paradigm for low-light image enhancement.
• From the structure flow, we embed the MAE-based customized illumination prior into the unfolding archi-tecture to improve the transparency and interpretability of the unfolding structure.
• From the optimization flow, we redevelop the MAE-based customized noise prior as a regularization term to constrain the gradient representation consistency.
• Our experiments on multiple low-light image bench-marks show that the proposed paradigm outperforms state-of-the-art methods, and our customized noise prior is effective for image denoising. 2.