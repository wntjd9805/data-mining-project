Abstract
Denoising diffusion probabilistic models that were ini-tially proposed for realistic image generation have recently shown success in various perception tasks (e.g., object de-tection and image segmentation) and are increasingly gain-ing attention in computer vision. However, extending such models to multi-frame human pose estimation is non-trivial due to the presence of the additional temporal dimension in videos. More importantly, learning representations that focus on keypoint regions is crucial for accurate localiza-tion of human joints. Nevertheless, the adaptation of the diffusion-based methods remains unclear on how to achieve such objective. In this paper, we present DiffPose, a novel diffusion architecture that formulates video-based human pose estimation as a conditional heatmap generation prob-lem. First, to better leverage temporal information, we pro-pose SpatioTemporal Representation Learner which aggre-gates visual evidences across frames and uses the resulting
In addi-features in each denoising step as a condition. tion, we present a mechanism called Lookup-based Multi-Scale Feature Interaction that determines the correlations between local joints and global contexts across multiple scales. This mechanism generates delicate representations that focus on keypoint regions. Altogether, by extending diffusion models, we show two unique characteristics from
DiffPose on pose estimation task: (i) the ability to combine multiple sets of pose estimates to improve prediction accu-racy, particularly for challenging joints, and (ii) the ability to adjust the number of iterative steps for feature refinement without retraining the model. DiffPose sets new state-of-the-art results on three benchmarks: PoseTrack2017, Pose-Track2018, and PoseTrack21. 1.

Introduction
Human pose estimation has been extensively studied in computer vision, with the aim of detecting all instances of
*Corresponding Author (a) Illustration of the original diffusion model where q
Figure 1. and pÎ¸ refer to the diffusion and denoising process, respectively. (b) In this work, we propose a novel framework named DiffPose which formulates video-based human pose estimation as a gener-ative process of keypoint heatmaps. people from images and localizing anatomical keypoints for each individual [20, 57, 63, 68]. It finds numerous appli-cations ranging from human-computer interaction and aug-mented reality [21, 22] to behavior analysis and surveil-lance tracking [36, 40, 56, 64, 65, 66]. Conventional approaches [55, 69, 82] mainly employ the probabilistic graphical model or the pictorial structure model. Fueled by the explosion of deep learning, Convolutional Neural Net-works [8, 39, 40, 63] and Vision Transformers [38, 75, 80] have witnessed significant progress in this task.
Until recently, denoising diffusion probabilistic models
[30, 58], which are a type of generative models, have re-ceived much research attention for surpassing other meth-ods such as GANs and achieving state-of-the-art generative results [6, 14]. The superior performance of the diffusion model has facilitated its expansion in diverse applications, such as super-resolution [54], inpainting [42], and image deblurring [52]. Following the demonstration of the effec-tiveness of diffusion models as representation learners for discriminative computer vision problems [6], several con-temporary approaches have successfully employed the dif-fusion model for perception tasks, including object detec-tion [10] and image segmentation [1, 6, 26].
Despite the considerable attention that diffusion mod-els have gained following their achievements, their adap-tation for video-based human pose estimation has signifi-cantly trailed that of other vision tasks, such as segmenta-tion and object detection. We conjecture two primary rea-sons that underlie this disparity: (i) Effectively leveraging temporal information is crucial for video-based human pose estimation [39]. However, despite the success of various diffusion architectures in perception tasks, they are primar-ily designed for static images and incapable to capture tem-poral dependencies across frames. (ii) Real world images typically contain many task-irrelevant cues and accurately estimating human poses requires focusing on specific body joint regions [23]. However, it is still an open question on how to guide the diffusion model to filter out the unneces-sary details and only attend to the keypoint regions.
In this paper, we present a novel architecture, termed
SpatioTemporal Diffusion Model for Pose Estimation (Diff-Pose). By extending the framework of diffusion model,
DiffPose presents a new approach to video-based human pose estimation. Specifically, it reformulates this problem as a conditional generative task of keypoint-wise heatmaps, as illustrated in Fig. 1. DiffPose consists of two primary stages: a forward diffusion stage that gradually introduces
Gaussian noise to the ground truth heatmaps, and a reverse denoising stage that utilizes a Pose-Decoder to recover the original heatmap from the noisy input progressively.
Unlike the vanilla diffusion model [30], which simply uses U-Net [53] for denoising, we propose two novel de-signs that enhance the capabilities of the Pose-Decoder.
These modifications enable the Pose-Decoder to better uti-lize temporal information and focus on joint regions. (i) We design a SpatioTemporal Representation Learner (STRL) which sequentially performs spatial information extraction within each frame and integrates cross-frame knowledge through cascaded Transformers. The resulting features, which contain rich temporal priors, are subsequently uti-lized as a fixed condition at each denoising step by the (ii) In addition, we propose a Lookup-Pose-Decoder. based MultiScale Feature Interaction mechanism (LMSFI), which guides the Pose-Decoder to learn intricate represen-tations for pose prediction by inductively leveraging infor-mation from both noisy heatmaps and spatiotemporal fea-tures. To be specific, we first construct probabilistic joint fields based on the noisy heatmaps, and perform lookups over spatiotemporal features accordingly to activate key-point region features. Then, we model fine-grained corre-lations between the retrieved local joint features and origi-nal global contexts over multiple scales to produce the final representations. By conducting feature interaction through
LMSFI, we can explicitly reason about the relationships be-tween joints and global contexts. As shown in Figure 4, our proposed method is able to learn representations that con-verge around keypoint regions consistently.
An important feature of the diffusion-based framework is the separation of model training and evaluation. To pro-vide more context, DiffPose is trained to reverse the forward diffusion process (i.e., predict ground truth heatmaps from noises) and performs multi-step denoising to generate pre-dictions based on randomly generated noisy heatmaps at in-ference. Benefiting from such framework, we demonstrate two distinct properties that appeal to human pose estimation task. (i) As DiffPose can generate multiple plausible pose estimates by sampling random noises, they can be com-bined to improve the prediction robustness, especially for challenging joints such as wrists and ankles. (ii) In contrast to existing methods that adopt a fixed iterative refinement structure [9, 71, 45], DiffPose can adaptively vary the num-ber of denoising steps without retraining the model. From extensive experiments, we show that DiffPose consistently outperforms existing well-established approaches on three benchmark datasets. Furthermore, each of our proposed de-sign choices is verified through ablation studies.
The key contributions of this work are summarized as follows: (1) To our best knowledge, we are the first to in-vestigate video-based human pose estimation from the lens of generative modeling. In particular, we propose DiffPose, the first model that applies diffusion model to multi-frame human pose estimation. (2) We demonstrate two properties of DiffPose that are effective on pose estimation: the ability to enhance performance by aggregating multiple pose esti-mations and to perform flexible iterative refinement without model retraining. (3) We show that our DiffPose delivers state-of-the-art results on three benchmark datasets, Pose-Track2017, PoseTrack2018, and PoseTrack21. 2.