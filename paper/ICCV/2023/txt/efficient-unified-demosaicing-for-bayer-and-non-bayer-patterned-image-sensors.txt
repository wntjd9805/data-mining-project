Abstract
As the physical size of recent CMOS image sensors (CIS) gets smaller, the latest mobile cameras adopt unique non-Bayer color filter array (CFA) patterns (e.g., Quad, Nona,
Q×Q), which consist of homogeneous color units with ad-jacent pixels. These non-Bayer CFAs are superior to con-ventional Bayer CFA thanks to their changeable pixel-bin sizes for different light conditions, but may introduce visual artifacts during demosaicing due to their inherent pixel pat-tern structures and sensor hardware characteristics. Previ-ous demosaicing methods have primarily focused on Bayer
CFA, necessitating distinct reconstruction methods for non-Bayer CIS with various CFA modes under different lighting conditions. In this work, we propose an efficient unified de-mosaicing method that can be applied to both conventional
Bayer RAW and various non-Bayer CFAs’ RAW data in dif-ferent operation modes. Our Knowledge Learning-based demosaicing model for Adaptive Patterns, namely KLAP, utilizes CFA-adaptive filters for only 1% key filters in the network for each CFA, but still manages to effectively de-mosaic all the CFAs, yielding comparable performance to the large-scale models. Furthermore, by employing meta-learning during inference (KLAP-M), our model is able to eliminate unknown sensor-generic artifacts in real RAW data, effectively bridging the gap between synthetic images and real sensor RAW. Our KLAP and KLAP-M methods achieved state-of-the-art demosaicing performance in both synthetic and real RAW data of Bayer and non-Bayer CFAs. 1.

Introduction
Demosaicing (DM) is the process of interpolating single-channel input images into RGB output images within an embedded Image Signal Processor (ISP). With the grow-ing demand for high-quality mobile camera images, CMOS image sensor (CIS) resolution has increased dramatically, even reaching 200 million pixels in the latest smartphones.
∗ Equal contribution, † Corresponding author.
However, as image sensors cannot infinitely increase in size, pixel size has been reduced to enhance resolution. Smaller
CISs are more vulnerable to noise and degradation in im-age restoration capabilities because they are more sensi-tive to variations in light reception, especially in low-light condition [13, 23, 38, 39]. As a result, modern high-end smartphones have started using image sensors that group adjacent homogeneous pixels, resulting in non-Bayer Quad,
Nona, and Quad-by-Quad (Q×Q) sensors [19, 38, 41], while still retaining some of the properties of the standard
Bayer CFA [5] pattern. Quad, Nona, and Q×Q sensors combine the same color pixel arrays of 2×2, 3×3, and 4×4 respectively, resulting in homogeneous pixel units (i.e., Gr,
R, B, and Gb) for each sensor, as shown in Fig. 1(a).
Demosaicing for modern non-Bayer CFAs is more com-plex and computationally demanding than for standard
Bayer CFAs. This is because as the number of pixel ar-rays within each unit increases, the distance between the units becomes greater, requiring interpolation with inaccu-rate pixel values from distant locations. Therefore, there is growing interest in using deep learning for demosaicing methods, leading to active research on both Bayer pattern demosaicing [64, 42, 12, 7, 56, 1, 34, 62, 45, 18, 26, 17] and non-Bayer pattern demosaicing [28, 27, 20, 3, 46, 10].
However, the aforementioned methods focus on a sin-gle CFA DM task and do not cover DM tasks for multiple
CFA patterns. Modern mobile phones with non-Bayer pat-terned CIS adapt their CFA modes dynamically based on lighting conditions, controlled by the CIS’s ISP. Using inde-pendent models (IMs) for each pattern, tailored to different
CFA modes, would demand loading and operating multi-ple models within the limited circuit space of the CIS. This would result in excessive memory and power consumption if the models were kept standby on the mobile application processor (AP) and switched accordingly. Moreover, the task of tuning models for each CFA would be laborious.
Currently, no existing method can handle dynamically changing CFA modes in a non-Bayer patterned CIS as a uni-fied model (UM). Several recent studies have explored the
Figure 1: (a) Overview of our unified model (UM) for demosaicing all the Bayer and non-Bayer CFAs, called the Knowledge
Learning-based demosaicing model for Adaptive Patterns using Meta-test learning (KLAP-M), even when ground truth is unavailable and unknown artifacts are present. (b) Comparing CIS RAW demosaicing results of KLAP (KLAP-M without meta-test learning) and KLAP-M (KLAP with meta-test learning). concept of all-in-one image restoration, which deals with multiple types of unknown degradation [31, 9, 30]. How-ever, these existing methods do not fully account for real
‘unknown’ artifacts in real ‘CIS RAW’ restoration process.
To address this limitation, where ground truth (GT) may be missing or largely unavailable, we will conduct a com-prehensive investigation of these methods. Since such un-known artifacts may fail to yield high-quality photos, we are motivated to propose a UM with robust meta-learning-based DM methods that can handle these obstacles.
In this work, we propose efficient unified demosaicing methods that bridge the gap between synthetic and real CIS
RAW images, enabling various non-Bayer CISs through a new pipeline. Our proposed Knowledge Learning-based demosaicing model for Adaptive Patterns (KLAP) is ca-pable of simultaneously handling multiple CFAs’ demo-saicing, which consists of two following steps. Firstly, we train a baseline UM using the two-stage knowledge learning (TKL) [9], making it more efficient to find Adap-tive Discriminative filters for each specific CFA Pattern (ADP). Secondly, after TKL, we further fine-tune the UM model using ADP, which is a method to identify a small set of discriminative filters in CNN filters, serving as in-dependent key parameters for each specific CFA demo-saicing task. Lastly, we propose KLAP-M, which com-bines KLAP (TKL+ADP) with Meta-test learning, integrat-ing self-supervised learning to handle domain gaps between synthetic RAW and real CIS RAW caused by unknown arti-facts in real-life scenarios. Our proposed meta-test learning consists of pixel binning loss based on CIS domain knowl-edge and self-supervised denoising techniques. Fig. 1(a) provides an overview of our KLAP-M approach, which handles both Bayer and Non-Bayer patterns. Additionally,
Fig. 1(b) shows the results of our meta-test learning tech-nique, addressing the domain gap in real RAW images.
Our contributions are summarized as follows: (1) Our ef-ficient unified network, KLAP, effectively performs demo-saicing for multiple CFAs, (2) KLAP-M, a version of KLAP that incorporates a meta-learning approach, effectively re-duces unknown visual artifacts in genuine CIS RAW images that are caused by diverse sensor characteristics and shoot-ing environments, (3) KLAP and KLAP-M achieve state-of-the-art performance on the synthetic benchmark dataset and real CIS RAW samples captured by CIS chips. 2.