Abstract
Deep Image Manipulation Localization (IML) models suffer from training data insufficiency and thus heavily rely on pre-training. We argue that contrastive learning is more suitable to tackle the data insufficiency problem for IML.
Crafting mutually exclusive positives and negatives is the prerequisite for contrastive learning. However, when adopt-ing contrastive learning in IML, we encounter three cate-gories of image patches: tampered, authentic, and contour patches. Tampered and authentic patches are naturally mu-tually exclusive, but contour patches containing both tam-pered and authentic pixels are non-mutually exclusive to them. Simply abnegating these contour patches results in a drastic performance loss since contour patches are deci-sive to the learning outcomes. Hence, we propose the Non-mutually exclusive Contrastive Learning (NCL) framework to rescue conventional contrastive learning from the above dilemma. In NCL, to cope with the non-mutually exclusiv-ity, we first establish a pivot structure with dual branches to constantly switch the role of contour patches between positives and negatives while training. Then, we devise a pivot-consistent loss to avoid spatial corruption caused by the role-switching process. In this manner, NCL both in-herits the self-supervised merits to address the data insuf-ficiency and retains a high manipulation localization accu-racy. Extensive experiments verify that our NCL achieves state-of-the-art performance on all five benchmarks with-out any pre-training and is more robust on unseen real-life samples. https://github.com/Knightzjz/NCL-IML. 1.

Introduction
Thrilling advances in media techniques grant us easier and easier access to manipulate images. Image Manipula-*Wentao Feng is the corresponding author, contact through mail ad-dress: Wtfeng2021@scu.edu.cn
Figure 1. Three categories of patches in a manipulated image and the non-mutually exclusive relations among them. There are three categories of patches in a manipulated image: tampered, authen-tic, and contour patches. In the middle picture, we depict them accordingly with red, blue, and purple squares. Only tampered and authentic patches are mutually exclusive. When the decisive contour patches are involved, non-mutually exclusivity occurs in contrastive learning. Best viewed in color. tion Localization (IML) is then indispensable for defensive information forensics and is heavily invested by the infor-mation security industry. Today, data insufficiency is the most prominent issue in building deep IML models. As dense annotations and expertise for tamper identification are exorbitant, public datasets for IML are all tiny-sized (with a few hundred to a few thousand images) and severely insuf-ficient for training deep CNNs. Consequently, major deep
IML methods carry out pre-training on additional large-scale datasets.
In general, pre-training of IML models relies on syn-thesized datasets. On the one hand, synthesized datasets vanish the high labeling costs and pre-training on synthe-sized datasets refrains from overfitting. On the other hand, employing synthesized datasets to conduct pre-training im-pedes fair comparisons among models and even jeopardizes the model generalizability. Pre-training is crucial to the model performance, and for fair comparisons, models of the same task commonly practice their pre-training on the same dataset. However, synthesized pre-training datasets for IML models are strikingly different in annotation quan-tity and quality. For instance, ManTra-Net [34] grounds on a self-collected, pixel-wise labeled dataset of 102,028
images and 385 manipulation types for pre-training; RGB-N [38] employs a randomly synthesized dataset of more than 42,000 images; BusterNet [33] entails a synthesized dataset of 100,000 copy-moved images for pre-training;
MVSS [9] adopts a synthesized dataset of 8,4000 images.
Faithful evaluations for models pre-trained on different syn-thesized datasets become impossible. Moreover, unlike real tampered images, these naively synthesized images severely lack elaborate post-processing to cover their manipulation traces or artifacts [5, 29, 9]. In other words, the sampling process of synthesized datasets is biased from the sam-pling process of manual build datasets [36, 37]. A model learned on such a dataset with sampling bias is short in gen-eralizability, and measuring this mode on tiny-sized, non-homologous benchmarks cannot fully disclose its poor per-formance under real cases.
To address the insufficient data problem without intro-ducing such a tricky pre-training strategy, we advocate adopting contrastive learning in IML. On the one hand, self-supervised contrastive learning can yield massive con-trastive pairs from real tampered images. These contrastive pairs boost the training sample number by at least one or two orders of magnitude without causing sampling bias or unfaithful evaluations. On the other hand, manipulation leaves artifacts in images, and artifacts cause feature dis-crepancies between tampered and authentic regions. This is the essential clue for identifying tampered areas by hu-man experts. The contrastive learning objective explicitly follows this clue and reveals the vital feature discrepancies by encouraging the compactness between positive pairs and the margin between negative pairs.
Although recent researches suggest pixel-level con-trastive learning for pixel predictions [35], patch-wise con-trastive learning is still more suitable for IML. Because manipulations rarely happen pixel-by-pixel, the patch-level features are proven to be outstanding in characterizing ma-nipulation traces or artifacts [22]. Thus, in our method, pos-itives and negatives are naturally the tampered and authentic image patches of pure tampered or authentic pixels. Image patches are in a fixed size, but the manipulated regions are arbitrarily shaped and sized. As shown in the middle picture of Figure 1, when sampling along the contour of manipu-lated regions, tampered and authentic pixels are inevitably mingled within one image patch. Then, we have the third patch, contour patches. Apparently, contour patches are nei-ther mutually exclusive to tampered patches nor authentic patches. Conventional contrastive learning designed to han-dle the mutually exclusive relation between binary sets will then malfunction under such a trilateral, non-mutually ex-clusive circumstance. However, simply discarding the con-tour patches and merely employing the tampered and au-thentic patches to conduct contrastive learning is not fea-sible. Previous studies [23, 28, 21, 22] show that artifacts assemble along the borders of tampered areas. Therefore, discarding contour patches means throwing away samples with the richest artifacts’ information. Besides, contour patches are the hard positives or negatives in contrastive learning since they contain both tampered and authentic pixels at the same time. Hard samples are decisive to the contrastive learning outcomes. Discarding contour patches also eliminates most of the hard samples in contrastive learning. In short, we are facing such a dilemma: the ex-isting contrastive learning paradigm is incompatible with the non-mutually exclusive contour patches, but learning without contour patches results in a significant performance gap, and learning without the contrastive paradigm leads to model generalization and evaluation issues. Therefore, a brand-new learning framework that follows the contrastive learning paradigm and copes with non-mutual exclusivity is the key to saving IML models from this dilemma.
Hence, we propose the Non-mutually exclusive Con-trastive Learning (NCL) framework. Every contour patch is partial-tampered and partial-authentic. Therefore, we can regard a contour patch as a hard positive in contrastive learning if we only count its tampered part. Likewise, this counter patch can be simultaneously regarded as a hard neg-ative if only its authentic parts are counted. That is, a con-tour patch can be transferred into a hard positive or a hard negative referring to its partial information. Following this role-switching characteristic, we constructed a pivot struc-ture with dual branches on the shallow layers of the back-bone to squeeze the positive and negative parts accordingly from the contour patches. The name of the pivot indicates that it switches contour patches between the role of hard positives and hard negatives to constitute contrastive pairs.
Thus, the trilateral, non-mutually exclusive contrast among tampered patches (positives), authentic patches (negatives), and the contour patches is then disentangled into three bi-nary, mutually exclusive, contrastive pairs of {positive, neg-ative}, {positive, hard negative}, {negative, hard positive}.
The NCL loss is the sum of the three pair-wise contrastive losses. In addition, the pivot structure corrupts the spatial correlation among contour patches. Therefore, on the de-coder side, we devise the pivot-consistent loss with auxil-iary classifiers to ensure the pixel-wise spatial relations are captured and preserved by the deeper layers of the encoder.
We train our NCL-based method from scratch without additional datasets or pre-training stages. With only 5-10% of the total training data compared with pre-training-based methods, our model outperforms current pre-training-based approaches on all five public IML benchmarks. De-spite this, deep CNNs are prone to overfitting on such small public benchmarks. Therefore, we further use non-homogeneous training and testing datasets to examine model generalization ability. The results verify that NCL endows our IML model with better localization accuracy
and robustness. Last but not least, similar to contrastive learning, NCL also holds the plug-in merit. Regardless of backbone architecture, NCL functions well.
In summary, our main contributions are quad-folded:
• Free of Additional Data. To the best of our knowl-edge, we are the first work bringing contrastive learn-ing in IML to address the insufficiency of training data and drawbacks caused by pre-training.
• Non-Mutually Exclusive Contrast. As far as we know, we are also the first to handle non-mutual ex-clusive, trilateral relations through contrastive learn-ing. Our Non-mutually exclusive Contrastive Learning (NCL) framework can serve other tasks like semantic segmentation or fine-grained object detection.
• Top Benchmark Performance. Our method uses less and inferior training data but achieves state-of-the-art performances as well as the top model generalization ability on all five public benchmarks.
• Plug-in Merit. Our method functions under both CNN and Transformer-styled backbones. Backbone selec-tion will not break the integrity of NCL. 2.