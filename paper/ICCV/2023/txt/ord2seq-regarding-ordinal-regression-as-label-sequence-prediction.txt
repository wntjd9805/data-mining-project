Abstract
Ordinal regression refers to classifying object instances into ordinal categories. It has been widely studied in many scenarios, such as medical disease grading and movie rat-ing. Known methods focused only on learning inter-class ordinal relationships, but still incur limitations in distin-guishing adjacent categories thus far.
In this paper, we propose a simple sequence prediction framework for or-dinal regression called Ord2Seq, which, for the first time, transforms each ordinal category label into a special la-bel sequence and thus regards an ordinal regression task
In this way, we de-as a sequence prediction process. compose an ordinal regression task into a series of re-cursive binary classification steps, so as to subtly dis-tinguish adjacent categories. Comprehensive experiments show the effectiveness of distinguishing adjacent categories for performance improvement and our new approach ex-ceeds state-of-the-art performances in four different sce-narios. Codes are available at https://github.com/ wjh892521292/Ord2Seq. 1.

Introduction
Ordinal regression, a.k.a. ordinal classification, aims to classify object instances into ordinal categories. Since such categories follow a natural order, an ordinal regression task is typically treated as a classification problem with a few regression properties. Common applications are medical image grading [9, 23] (e.g., cataract can be graded from 0 to 6, representing normal to severe states), age estima-tion [29, 32, 21, 44], historical image dating [30, 28], and image aesthetic grading [15, 16, 31].
Unlike general classification tasks, it is challenging to distinguish the adjacent categories due to their confusing data patterns and blurred boundaries in ordinal regression tasks. Previous works often highlighted the ordering re-*Equal contribution.
†Corresponding authors.
Figure 1. Our motivation. The dichotomic search (binary search) aims to repeatedly divide the half portion of a sorted array to find the target item. It can be utilized in ordinal regression tasks since the ordinal candidate labels can be regarded as a finite sorted ar-ray. Thus, an ordinal regression task is decomposed into multiple recursive dichotomic classification sub-problems. For example, when scoring an aesthetic image (e.g., from 1 to 5, the ground truth is 4), we can first estimate whether the score is above or be-low average (i.e., 3⃝). Next, if it is above average, then we can further determine the score to be 4⃝ or 5⃝. lations by introducing K-rank algorithms [12, 19, 29, 6], ordinal distribution constraint assumptions [22, 26, 17, 20], soft labels [13, 10], or multi-instance comparing ap-proaches [24, 25, 20, 38]. However, these methods failed to specifically tackle the “adjacent categories distinction” and hinder the model performances.
In this paper, we argue and validate the importance of the “adjacent categories distinction” in ordinal regression tasks. To this end, we propose to distinguish the adjacent categories gradually in processing. Motivated by the di-chotomic search (binary search) [45], which repeatedly di-vides the half portion of a sorted array to gradually find the target item, we decompose an ordinal regression problem into a series of dichotomic classification steps. In each step, we can only focus on dealing with a boundary of a pair of adjacent categories. An example is given in Fig. 1. The aesthetics score of an image is gradually distinguished via
In this way, an ordi-recursive dichotomic classification.
nal regression problem can be transformed into a sequence prediction problem that sequentially conducts dichotomic classification to finally obtain the ordinal category label.
Evolved from our motivation, we propose a simple se-quence prediction framework for ordinal regression, called
Ord2Seq. In our approach, ordinal regression is regarded as a sequence prediction task where the predicting goal is changed from a category label to a binary label sequence.
That is, the prediction task is decomposed into a series of recursive binary classification steps to better distinguish ad-jacent categories in a process of progressive elaboration.
Specifically, Ord2Seq performs two main steps. First, in pre-processing, we transform ordinal regression labels into label sequences by a tree-structured label mapping approach (we call the tree structure dichotomic tree in this paper).
Thus, for each input data, the prediction objective turns to a sequence of binary labels. Next, it predicts this label sequence progressively via an encoder-decoder structured
Transformer architecture. The Transformer is allowed to in-tegrate context information by delivering the earlier image features and prediction results for the next token prediction.
Also, the Transformer adapts to any sequence prediction length, so that our model has strong scalability on different tasks with various numbers of categories. Further, to enable our model to focus on each binary decision when distin-guishing the remaining categories, the Transformer decoder is designed with a masked decision strategy to suppress the loss interference of the eliminated categories. Comprehen-sive experiments validate the superiority of our proposed
Ord2Seq that carefully distinguishes adjacent categories.
Our main contributions are summarized as follows:
• For the first time, we propose to transform ordinal cate-gory labels as label sequences using a dichotomic tree, so as to tackle an ordinal regression task as a sequence prediction task.
• We propose a new sequence prediction framework for ordinal classification, called Ord2Seq, which effec-tively distinguishes adjacent categories with a process of progressive elaboration.
• We design a novel decoder with a masked decision strategy to suppress the loss interference of the elim-inated categories in order to focus on distinguishing the remaining categories.
• Extensive experiments show the effectiveness of each component and that Ord2Seq performs better in distin-guishing adjacent categories and achieves state-of-the-art performances on various image datasets. 2.