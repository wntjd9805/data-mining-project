Abstract
Multi-task learning faces two challenging issues: (1) the high cost of annotating labels for all tasks and (2) balanc-ing the training progress of various tasks with different na-tures. To resolve the label annotation issue, we construct a large-scale ”partially annotated” multi-task dataset by combining task-specific datasets. However, the numbers of annotations for individual tasks are imbalanced, which may escalate an imbalance in training progress. To bal-ance the training progress, we propose an achievement-based multi-task loss to modulate training speed based on the ”achievement,” defined as the ratio of current accu-racy to single-task accuracy. Then, we formulate the multi-task loss as a weighted geometric mean of individual task losses instead of a weighted sum to prevent any task from dominating the loss. In experiments, we evaluated the ac-curacy and training speed of the proposed multi-task loss on the large-scale multi-task dataset against recent multi-task losses. The proposed loss achieved the best multi-task accuracy without incurring training time overhead. Com-pared to single-task models, the proposed one achieved 1.28%, 1.65%, and 1.18% accuracy improvement in ob-ject detection, semantic segmentation, and depth estima-tion, respectively, while reducing computations to 33.73%.
Source code is available at https://github.com/ samsung/Achievement-based-MTL. 1.

Introduction
Cooperation of various vision tasks is often required for high-level vision applications for autonomous driving and surveillance cameras [6, 16, 41, 8, 12, 38]. The vision task models typically consist of two parts: a feature ex-tractor and a prediction head, and most computations are concentrated on the feature extractor. Hence, sharing the feature extractor among different tasks, multi-task learn-ing, can significantly expedite inference and enhance the
*Corresponding author feature extractor to produce more general representations
[25, 18, 3, 12, 38]. However, multi-task learning faces two major challenges: balancing the training progress of vari-ous tasks with different natures and the cost of annotating the labels of all tasks for plenty of images.
There are two major approaches to balancing the training progress: loss scale-based [25, 5, 20] and gradients-based
[4, 31, 40, 24]. Primitive multi-task losses [25, 5] address the difference in loss scale among individual tasks due to their distinct loss functions (e.g., cross entropy for classifi-cation and L1 loss for regression). However, simply match-ing the loss scales is insufficient to balance the gradients because the derivatives of distinct functions can differ.
Recent multi-task losses have directly adjusted back-propagated gradients [4, 31, 40, 24, 23]. The gradient-based methods seek to equalize the task gradients at the last shared layer [4, 24]. However, achieving balance in task gradients does not guarantee balance in the training progress because the difficulty of tasks may differ. Easy tasks quickly con-verge, while difficult ones are trained slowly [13]. Hence, it is insufficient to consider only gradients to balance the train-ing progress, but task difficulty should also be regarded.
Annotating labels for all tasks on plenty of images is expensive and time-consuming. Thus, multi-task datasets
[33, 7, 10] suffer from a lack of annotations, while task-specific datasets have become larger and larger [29, 22, 32].
Some previous works [18, 38] construct a union dataset composed of task-specific datasets to resolve this issue. Im-ages of the union dataset are partially annotated. Because task losses are only produced for existing labels, multi-task models can be easily biased toward the dominant task if the numbers of labels for individual tasks differ significantly.
Moreover, the gradient of each task is also heavily influ-enced by the number of task labels presented in a batch, and thus gradient-based multi-task losses are significantly disturbed on a partially annotated dataset.
In this paper, we propose a novel multi-task loss that can balance the training progress of different tasks effectively, without using task gradients. The proposed loss controls the training progress based on accuracy achievement, de-fined as the ratio of current accuracy to single-task accuracy.
Figure 1. Achievement and task weight curves for (a) multi-task, (b) object detection, (c) semantic segmentation, and (d) depth estimation on the PASCAL VOC [9] + NYU v2 [33] dataset. The blue and orange lines are the proposed method and IMTL-G [24], respectively. The solid lines mean achievements (left y-axis), and the dotted lines denote task weights (right y-axis). Delivering the same amount of task gradients to the shared feature extractor, IMTL-G learned easy tasks (segmentation and depth) quickly while the difficult one (detection) suffered from under-fitting. The proposed method much focused on the challenging task (detection) having lower achievement than others, and as a result, demonstrated better multi-task accuracy than IMTL-G.
Furthermore, refraining from using a general weighted sum based loss, the proposed loss is composed of a weighted geometric mean to exploit its scale-invariant property.
The main contributions of this paper are as follows: 1. We propose an achievement-based multi-task loss that employs a weighted geometric mean in multi-task learning. The proposed loss effectively balances the training progress and prevents any task from domi-nating the loss. Moreover, the proposed weights and weighted geometric mean also dramatically improve the accuracy of other multi-task losses, respectively. 2. We conduct a robust evaluation for multi-task losses on a large-scale partially annotated multi-task dataset. 3. We empirically validate that multi-task learning on a partially annotated dataset can achieve better accuracy than filling in absent labels using single-task models. 2.