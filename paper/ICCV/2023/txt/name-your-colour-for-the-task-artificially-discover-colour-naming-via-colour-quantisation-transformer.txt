Abstract
The long-standing theory that a colour-naming system evolves under dual pressure of efficient communication and perceptual mechanism is supported by more and more linguistic studies, including analysing four decades of di-achronic data from the Nafaanra language. This inspires us to explore whether machine learning could evolve and dis-cover a similar colour-naming system via optimising the com-munication efficiency represented by high-level recognition performance. Here, we propose a novel colour quantisation transformer, CQFormer, that quantises colour space while maintaining the accuracy of machine recognition on the quantised images. Given an RGB image, Annotation Branch maps it into an index map before generating the quantised image with a colour palette; meanwhile the Palette Branch utilises a key-point detection way to find proper colours in the palette among the whole colour space. By interacting with colour annotation, CQFormer is able to balance both the machine vision accuracy and colour perceptual structure
*Corresponding author. such as distinct and stable colour distribution for discovered colour system. Very interestingly, we even observe the con-sistent evolution pattern between our artificial colour system and basic colour terms across human languages. Besides, our colour quantisation method also offers an efficient quan-tisation method that effectively compresses the image storage while maintaining high performance in high-level recogni-tion tasks such as classification and detection. Extensive experiments demonstrate the superior performance of our method with extremely low bit-rate colours, showing poten-tial to integrate into quantisation network to quantities from image to network activation. The source code is available at https://github.com/ryeocthiv/CQFormer 1.

Introduction
Hath not a Jew eyes? Hath not a Jew hands, organs, dimensions, senses, affections, passions?
William Shakespeare “The Merchant of Venice”
Does artificial intelligence share the same perceptual mechanism for colours as human beings? We aim to explore
this intriguing problem from machine learning perspective.
Colour involves the visual reception and neural register-ing of light stimulants when the spectrum of light interacts with cone cells in the eyes. Physical specifications of colour also include the reflective properties of the physical objects, geometry incident illumination, etc. By defining a colour space [18], people could identify colours directly according to these quantifiable coordinates.
Compared to the pure physiological nature of hue cate-gorisation, the complex phenomenon of colour naming or colour categorisation spans multiple disciplines, from cogni-tive science to anthropology. Solid diachronic research [2] also suggests that human languages constantly evolve to acquire new colour names, resulting in an increasingly fine-grained colour naming system. This evolutionary process is hypothesised to be under the pressure of communication ef-ficiency and perceptual structure. Communication efficiency requires shared colour partitioning to be communicated ac-curately with a lexicon as simple and economical as possible.
Colour perceptual structure is relevant to human perception in nature. For example, the colour space distance between nearby colours should correspond to their perceptual dis-similarity. This structure of perceptual colour space has long been used to explain colour naming patterns across lan-guages. A recent analysis of human colour naming systems, especially in Nafaanra, contributes very direct evidence to support this hypothesis through the employment of Shan-non’s communication model [41]. Interestingly, this echos the research on colour quantisation, which quantises colour space to reduce the number of distinct colours in an image.
Traditional colour quantisation methods [23, 19, 17] are perception-centred and generate a new image that is as vi-sually perceptually similar as possible to the original im-age. These methods group similar colours in the colour space and represent each group with a new colour, thus naturally preserving the perceptual structure. Instead of pri-oritising the perceptual quality, Hou et al. [25] proposed a task-centred/machine-centred colour quantisation method,
ColorCNN, focusing on maintaining network classification accuracy in the restricted colour spaces. While achieving an impressive classification accuracy on even a few-bit image,
ColorCNN only identifies and preserves machine-centred structure without directly clustering similar colours in the colour space. Therefore, this pure machine-centred strategy sacrifices perceptual structure and often associates nearby colours with different quantised indices.
Zaslavsky et al. [49] measure the communication effi-ciency in colour naming by analysing the informational com-plexity based on the information bottleneck (IB) principle.
Here, we argue that the network recognition accuracy also reflects the communication efficiency when the number of colours is restricted. Since the human colour naming is shaped by both perception structure and communication effi-ciency [51], we integrate the need for both perception and machine to propose a novel end-to-end colour quantisation transformer, CQFormer, to discover the artificial colour nam-ing systems.
As illustrated in Fig. 1 (b), the recognition accuracy in-creases with the number of colours in our discovered colour naming system. Surprisingly, the complexity-accuracy trade-offs are similar to the numerical results (Fig. 1 (a)) inde-pendently derived from linguistic research [49]. What is more, after embedding 1978 Nafaanra three-colour system (Nafaanra-1978) into the latent representation of CQFormer (Fig. 1 (d)), our method automatically evolves the fourth colour closed to yellow-green, matching the basic colour terms theory [2] summarised in different languages. Berlin and Kay found universal restrictions on colour naming across cultures and claimed languages acquire new basic colour cat-egories in a strict chronological sequence. For example, if a culture has three colours (light (‘fiNge’), dark (‘wOO’), and warm or red-like (‘nyiE’) in Nafaanra), the fourth colour it evolves should be yellow or green, exactly the one (Fig. 1 (e)) discovered by our CQFormer.
The pipeline of CQFormer, shown in Fig. 2, comprises two branches: Annotation Branch and Palette Branch. Anno-tation Branch annotates each pixel of the input RGB image with the proper quantised colour index before painting the in-dex map with the corresponding colour in the colour palette.
We localise the colour palette in the whole RGB colour space with a novel Palette Branch, which detects the key-point with explicit attention queries of transformer. During the training stage, as illustrated in the red line and black line of Fig. 2 (a),
Palette Branch interacts with an input image and Reference
Palette Queries to maintain the perceptual structure by re-ducing the perceptual structure loss. This perception-centred design groups similar colours and ensures the colour palette sufficiently represents the colour naming system defined by the World Color Survey (WCS) colour naming stimulus grids. As shown in Fig. 2 (b), each item in the colour palette (noted by an asteroid) lies in the middle of the corresponding colour distribution in the WCS colour naming probability map. Finally, the quantised image is passed to a high-level recognition module for machine accuracy tasks such as clas-sification and detection. Through the joint optimisation of
CQFormer and consequent high-level module, we can bal-ance both perception and machine. Besides automatically discovering the colour naming system, our CQFormer also offers an effective solution to extremely compress image storage while maintaining high performance in high-level recognition tasks. For example, the CQFormer achieves 50.6% top-1 accuracy on the CIFAR100 [28] dataset with only a 1-bit colour space (i.e., two colours). The extremely low-bit quantisation of our also demonstrates the potential to integrate into quantisation network research [40, 47], allow-ing the end-to-end optimisation from image to weight and
activation.
Our contributions could be summarised as follows:
• We propose a novel end-to-end colour quantisation transformer, CQFormer, to artificially discover a colour naming system by counting both perception and ma-chine. The discovered colour naming system shows a similar pattern to human language on colour.
• We propose a novel colour quantisation method taking palette generation as an attention-based key-point de-tection task. With the input of independent attention queries, it automatically generates 3D coordinates as the selected colour in the whole colour space.
• Our colour quantisation achieves superior classification and object detection performance with extremely low bit-rate colours. 2.