Abstract
The paradigm of large-scale pre-training followed by downstream fine-tuning has been widely employed in var-In this paper, we re-ious object detection algorithms. veal discrepancies in data, model, and task between the pre-training and fine-tuning procedure in existing practices, which implicitly limit the detector’s performance, general-ization ability, and convergence speed. To this end, we pro-pose AlignDet, a unified pre-training framework that can be adapted to various existing detectors to alleviate the discrepancies. AlignDet decouples the pre-training pro-cess into two stages, i.e., image-domain and box-domain pre-training. The image-domain pre-training optimizes the detection backbone to capture holistic visual abstraction, and box-domain pre-training learns instance-level seman-tics and task-aware concepts to initialize the parts out of the backbone. By incorporating the self-supervised pre-trained backbones, we can pre-train all modules for various detectors in an unsupervised paradigm. As depicted in Fig-ure 1, extensive experiments demonstrate that AlignDet can achieve significant improvements across diverse protocols,
⋆Equal contribution. †Corresponding author. such as detection algorithm, model backbone, data setting, and training schedule. For example, AlignDet improves
FCOS by 5.3 mAP, RetinaNet by 2.1 mAP, Faster R-CNN by 3.3 mAP, and DETR by 2.3 mAP under fewer epochs. 1.

Introduction
In recent years, there has been significant progress in large-scale pre-training and fine-tuning optimization paradigms in computer vision. A series of pre-training al-gorithms have been designed to learn domain-sensitive or task-aware concepts to boost downstream performance [17, 22, 1]. As for object detection, current approaches gener-ally leverage ImageNet [14] to pre-train the backbone with classification-oriented supervision. However, compared to the detection-oriented fine-tuning process, this pre-training paradigm exhibits three discrepancies, as shown in Figure 1:
• Data: most pre-training methods are conducted on single object-centric datasets, like ImageNet. However, the de-tection datasets, e.g., COCO [34], usually consist of mul-tiple objects with different scales and locations. The dif-ferences in data characteristics and domain can cause the pre-training to deviate from the downstream task.
Method
Data
Discrepancy
Model
Task
Object-centric Multi-object Backbone Neck Head Classification Regression
Generalization
Anchor-based
Point-based Query-based
Supervised Backbone
MoCo [22], SwAV [6]
DenseCL [52], SelfEMD [35]
PixPro [58], InsLoc [61], SoCo [53]
UP-DETR [12], DETReg [2]
Ours
✓
✓
✓
✓
✓
✓
✗
✗
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✗
✗
✗
✓
✓
✓
✗
✗
✗
✗
✓
✓
✓
✓
✓
✓
✗
✓
✗
✗
✗
✗
✓
✓
✓
✓
✓
✓
✗
✓
✓
✓
✓
✓
✗
✓
✓
✓
✓
✗
✓
✓
Table 1. We compare with other unsupervised pre-training algorithms in terms of solving the discrepancies and the generalization ability.
Taking task discrepancy as an example, previous methods can only introduce the pretext task of classification or regression in the pre-training stage, while AlignDet can build both tasks to learn the semantic and positional information of the objects.
• Model: current pre-training algorithms mainly focus on partial modules (such as the backbone) within the model due to the diversity and complexity of detectors. Some key detection components (such as the RPN and regres-sion head) remain random initialization.
• Task: existing pre-training approaches only regard the classification task as the pretext task, failing to capture object-aware positional context, including proposal gen-eration, target assignment, and box regression.
These discrepancies potentially bring limited results, poor generalization, and slow convergence speed [43, 47].
As summarized in Table 1, a series of works are pro-posed to bridge the gap between pre-training and fine-tuning processes in object detection. The initial exploration is to construct dense-level contrastive learning to capture task-sensitive context for dense predictions [52, 35, 58, 61, 53, 54]. Some researchers attempt to pre-train other de-tection modules, such as FPN [32, 58] and classification head [53]. However, these approaches require hundreds of epochs of pre-training on object-centric datasets and per-form poorly when pre-training on COCO. In addition, they neither pre-train all modules, such as the regression head in RetinaNet [33] nor construct appropriate regression pre-training tasks, thus failing to resolve the model and task discrepancies, as illustrated in Figure 2. UP-DETR [12] and DETReg [2] pre-train the entire DETR-like detectors by introducing DETR-sensitive pretext tasks. However, these tasks cannot be applied to other detectors since they rely heavily on the transformer-based decoder. Although the above approaches can alleviate the gap to varying degrees, they cannot comprehensively solve the three discrepancies simultaneously or be generalized to various detectors. This leads us to ask: how to design a pre-training framework that can address the discrepancies in data, model, and task, and is applicable to all detection algorithms?
To answer the above question, we propose AlignDet, a universal and pre-training framework for object detec-tion. AlignDet decouples the pre-training process into two stages, image-domain pre-training and box-domain pre-training. The image-domain pre-training optimizes the de-tection backbone to capture holistic visual abstraction, and the box-domain counterpart learns object-level concepts to
Figure 2. Compared with other box-level pre-training methods (e.g., InsLoc [61] and SoCo [53]), our advantages are: 1) Data:
AlignDet works well on COCO with only 12 epochs pre-training; 2) Model: All the modules can be efficiently and fully pre-trained. 3) Task: Both classification and regression knowledge are learned. initialize the parts out of the backbone. The detector is op-timized via box-level contrastive learning and coordinate-related regression losses. It contributes to fully adapting to various detectors, further boosting the performance in the following fine-tuning process, as illustrated in Figure 1. The contributions of this work are summarized in four aspects:
• New Insight: We point out that existing detection algo-rithms are constrained by the data, model, and task dis-crepancies between pre-training and fine-tuning.
• Novel Method: We propose AlignDet to address this is-sue, which constructs detection-oriented pre-training by learning classification and regression knowledge. It de-couples the pre-training into the image domain for the backbone and the box domain for other modules.
• Efficiency and Pioneering: The module-based decouple takes full advantage of the existing pre-trained backbones to efficiently pre-train other modules. By incorporating self-supervised pre-trained backbones, we make the first attempt to fully pre-train various detectors using a com-pletely unsupervised paradigm.
• High Effectiveness:
The comprehensive experiments demonstrate that AlignDet achieves significant perfor-mance improvements under various settings, including different detectors, backbones, data settings, and fine-tuning schedules.
2.