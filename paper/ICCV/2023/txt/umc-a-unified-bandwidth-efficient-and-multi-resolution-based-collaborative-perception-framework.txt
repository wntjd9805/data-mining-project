Abstract
Multi-agent collaborative perception (MCP) has re-cently attracted much attention. It includes three key pro-cesses: communication for sharing, collaboration for inte-gration, and reconstruction for different downstream tasks.
Existing methods pursue designing the collaboration pro-ignoring their intrinsic interactions and re-cess alone, sulting in suboptimal performance.
In contrast, we aim to propose a Unified Collaborative perception framework named UMC, optimizing the communication, collabora-tion, and reconstruction processes with the Multi-resolution technique. The communication introduces a novel train-able multi-resolution and selective-region (MRSR) mecha-nism, achieving higher quality and lower bandwidth. Then, a graph-based collaboration is proposed, conducting on each resolution to adapt the MRSR. Finally, the reconstruc-tion integrates the multi-resolution collaborative features for downstream tasks. Since the general metric can not re-flect the performance enhancement brought by MCP sys-tematically, we introduce a brand-new evaluation metric that evaluates the MCP from different perspectives. To ver-ify our algorithm, we conducted experiments on the V2X-Sim and OPV2V datasets. Our quantitative and qualitative experiments prove that the proposed UMC outperforms the state-of-the-art collaborative perception approaches. 1.

Introduction
Single-vehicle perception has made remarkable achieve-ments in object detection[20, 30, 31], segmentation[28, 32], and other tasks with the advent of deep learning. However, single-vehicle perception often suffers from environmental conditions such as occlusion[38, 49] and severe weather[4, 16, 52], making accurate recognition challenging. To over-come these issues, several appealing studies have been de-*Corresponding author: guangchen@tongji.edu.cn. Our code is avail-able at:https://github.com/ispc-lab/UMC.
Figure 1. The SRAR versus the proposed MRSR mechanism. (a) The existing single-resolution and all-region (SRAR) method utilizes the coarse-grained feature with bandwidth inefficient all-region transmission. (b) The proposed MRSR mechanism incor-porates bandwidth-efficient entropy-based selection with multi-resolution features. voted to collaborative perception[1, 2, 7, 41, 48], which take advantage of sharing the multiple-viewpoint of the same scene with the Vehicle-to-Vehicle(V2V) communication[3].
To design a collaborative perception algorithm, current approaches[39, 23, 44, 18, 43] mainly focus on the collab-oration process alone, aiming to design a high-performance collaboration strategy. Nevertheless, such a strategy ig-nores intrinsic interactions with two critical processes: communication[22, 12] and reconstruction[9]. This kind of collaboration strategy will inherently cause suboptimal performance because the quality of communication directly determines the performance of collaboration[18], and the reconstruction influences the quality of feature maps for downstream tasks. Meanwhile, the collaboration can also affect the design of communication and reconstruction.
Hence, failing to optimize these three processes will de-grade the system.
In this paper, to the best of our knowledge, we are the first to propose a unified collaborative perception frame-work that optimizes the communication, collaboration, and reconstruction processes with multi-resolution technique.
As for communication, as shown in Figure 1, we propose a novel multi-resolution and selective-region (MRSR) mech-anism, which is different from the single-resolution and all-region (SRAR) mechanism that is used by existing collab-orative algorithms[18, 44, 39]. In MRSR, we replace the coarse-grained feature in SRAR with multi-grain features, which reflect the scene from a global to a local perspective.
The multi-grain features will have the complementary ad-vantages of global structure information and local texture details. Meanwhile, to reduce the burden of bandwidth, unlike SRAR, which blindly transmits all regions, we im-plement a trainable and region-wise entropy-based commu-nication selection (Entropy-CS) module that highlights the informative regions and selects appropriate regions for each level of resolution. The proposed MRSR is adaptive to real-time communication, reflecting dynamic connections among agents.
We propose a graph-based collaborative GRU(G-CGRU) module for MRSR’s each level resolution feature in collab-oration. Compared to the existing collaboration strategies that only focus on the present shared information without considering the previous state, we redesign the GRU-cell[5] to adapt the time series of collaborative perception, which models the continuity of vehicle movement. In G-CGRU, the collaboration depends not only on collaborators but also on the last moment information of the ego agent. Mean-while, we propose matrix-valued gates in G-CGRU to en-sure collaboration at a high spatial resolution and allow the agents to adaptively weight the informative regions.
To adapt the proposed multi-resolution collaboration mechanism for reconstruction, we propose a multi-grain feature enhancement (MGFE) module to strengthen the fea-ture reconstruction process.
In MGFE, the fine-grained collaborative feature maps will give direct guidance to the agents’ feature maps via a global pooling operation, and the coarse-grained collaborative feature maps will again en-hance the agents’ feature maps from a global perspective.
This design allows the agents to comprehensively recon-struct the feature maps from local and global viewpoints.
The general evaluation metric (e.g., average precision) can reflect the overall performance of multi-agent collab-orative perception (MCP). However, the performance en-hancement brought by the collaboration concept that MCP introduced cannot be reflected directly. To address this is-sue, we introduce a brand new evaluation metric that sys-tematically evaluates the MCP from four aspects.
To validate the proposed framework, we conducted com-prehensive experiments in 3D object detection on V2X-Sim[17] and OPV2V[45] datasets. Our proposed uni-fied, bandwidth-efficient and multi-resolution based col-laborative perception framework (UMC) achieves a better performance-bandwidth trade-off than the state-of-the-art
SRAR-based collaboration methods. Our contributions are listed as follows:
• We present a unified, bandwidth-efficient framework (UMC) for collaborative perception, which optimizes the communication, collaboration, and reconstruction processes with the multi-resolution technique.
• We propose a novel multi-resolution and selective-region mechanism for communication and the graph-based collaborative GRU for each resolution collabo-ration and multi-grain feature enhancement module for reconstruction.
• We present a brand new evaluation metric for 3D ob-ject collaborative perception, which can evaluate the performance from different perspectives. 2.