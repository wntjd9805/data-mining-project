Abstract
A recent trend in deep learning algorithms has been to-wards training large scale models, having high parameter count and trained on big dataset. However, robustness of such large scale models towards real-world settings is still a less-explored topic. In this work, we first benchmark the performance of these models under different perturbations and datasets thereby representing real-world shifts, and highlight their degrading performance under these shifts.
We then discuss on how complete model fine-tuning based existing robustification schemes might not be a scalable op-tion given very large scale networks and can also lead them to forget some of the desired characterstics. Finally, we propose a simple and cost-effective method to solve this problem, inspired by knowledge transfer literature. It in-volves robustifying smaller models, at a lower computation cost, and then use them as teachers to tune a fraction of these large scale networks, reducing the overall computa-tional overhead. We evaluate our proposed method under various vision perturbations including ImageNet-C,R,S,A datasets and also for transfer learning, zero-shot evalua-tion setups on different datasets. Benchmark results show that our method is able to induce robustness to these large scale models efficiently, requiring significantly lower time and also preserves the transfer learning, zero-shot proper-ties of the original model which none of the existing methods are able to achieve. 1.

Introduction
Large scale deep neural networks trained on large scale data have revolutionized the modern AI era. They are sig-nificantly effective in solving practical problems of high im-portance. These include object detection, zero-shot classi-fication, image segmentation, image generation, and many other applications [18, 25, 27, 39, 5, 29, 35, 9].
Though the large models have shown impressive re-sults on many vision problems [27, 29], their reliability un-*Correspondence to Nishant Jain at njain@cs.iitr.ac.in.
Figure 1. ImageNet-C accuracy v/s training time comparison. Our method is on the pareto-front (achieves better robust accuracy in much lesser time) compared to the state-of-the-art methods Aug-mix based Complete fine-tuning and WISE-complete fine-tuning.
The data points labelled with suffix ”C” correspond to CLIP mod-els. der distribution shift e.g., under illumination changes, ge-ographical variations, camera properties etc., is still under-explored. In this paper, we fist investigate the behavior of large models under distribution shifts. We analyse popular models under synthetic perturbations to images [11], nat-ural distribution shifts [10, 13], differently styled images
[31] and dataset shift [2]. Our analysis of models of vari-ous sizes, architecture families (transformers or CNNs) and training modalities (uni or multi-modal) establishes their brittleness under distribution shifts.
This analysis begs the question: can we induce robust-ness to large vision models without sacrificing their original properties? It is critical to simultaneously maintain clean accuracy on the original datasets, improve robust accuracy on the shifted data and preserve the transfer learning capa-bilities of the large models. Further, computation efficiency during both training and inference is beneficial.
While several prior works can be used to make large-scale models robust, they do not possess the desired prop-erties discussed above. One direction involves fine-tuning the model [33, 16]. This generally suffers from either poor performance under synthetic perturbations or requires sig-nificant training time. Another line of work could be to use advanced augmentation techniques (e.g., aug-mix, pix-mix)
[14, 12, 10, 4]. They are effective under synthetic perturba-tions and natural shifts in the data. However, they require significantly larger compute time and lead to the large mod-els forgetting their original and transfer learning properties.
Figure 1 shows this analysis in a pareto-front plot for two of the recently proposed robustness methods.
To this end, we propose a knowledge transfer method to induce robustness to large models that possesses all the desired properties discussed above. It makes large models robust efficiently (refer Fig.1). We take a plug-and-play ap-proach: insert an additional small robust module and update only a very small portion of the existing large models. To achieve robustness, we explore a new direction: a relatively much smaller but robust model inducing robust knowledge to a large model. Though this provides a novel look at the knowledge distillation approach, a straight-forward ap-plication leads to the large models forgetting their original properties. For this challenging task of ensuring that clean accuracy is preserved in the clean module, robustness in-duced into the robust module and correct module selected at test time, we propose a novel uncertainty-aware knowledge distillation technique. This allows us to fulfil all our re-quired objectives. Since our method involves updating only a small chunk of the large network, it achieves low training latency (refer section 5). To the best of our knowledge, this is the first time such a setup has been used involving knowl-edge transfer from a smaller to a large model. Further, it should be noted that smaller models can be made robust by using prior works like advance augmentation methods
[12, 10, 14].
We evaluate our method under various distribution shift on ImageNet data [28] in section 5. It includes ImageNet-C
[11], ImageNet-R [10], ImageNet-A [13], ImageNet-sketch
[31], ImageNet-V2. We also evaluate on ObjectNet [2] and its perturbed variations ObjectNet-C. We show results for both multi-modal (various CLIP models) and unimodal (various architectures including both ResNets and Vision
Transformers). Alongside this, we also test our method on other datasets in the transfer learning setup, to analyze fur-ther if the desired properties of the model are restored. In all these cases, our method outperforms prior approaches on robust accuracy while still performing at par on clean accu-racy. At the same time, possessing desired characteristics like transfer learning capabilities (refer section 5) and being efficient during training and inference. 2.