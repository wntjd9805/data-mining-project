Abstract
Natural image compression has been greatly improved in the deep learning era. However, the compression per-formance will be heavily degraded if the pretrained en-coder is directly applied on screen content image compres-sion. Meanwhile, we observe that parameter-efficient trans-fer learning (PETL) methods have shown great adaptation ability in high-level vision tasks. Therefore, we propose a
Dec-Adapter, a pioneering entropy-efficient transfer learn-ing module for the decoder to bridge natural image and screen content compression. The adapter’s parameters are learned during encoding and transmitted to the decoder for image-adaptive decoding. Our Dec-Adapter is lightweight, domain-transferable, and architecture-agnostic with gener-alized performance in bridging the two domains. Experi-ments demonstrate that our method outperforms all exist-ing methods by a large margin in terms of BD-rate per-formance on screen content image compression. Specifi-cally, our method achieves over 2 dB gain compared with the baseline when transferred to screen content image com-pression. 1.

Introduction
With the growing demand for high-resolution images and videos online, efficient and more versatile image com-pression methods are essential for storage and transmission.
In recent years, learning-based image compression (LIC) approaches [2, 3, 29, 8, 47] have been emerging and quickly surpassed traditional codecs, such as JPEG [36], BPG [4] and VVC [11]. These methods learn optimal non-linear transforms and probabilities for entropy coding by training end-to-end networks.
However, the model that minimizes the expected rate and distortion (RD) cost on a specified dataset may not be ideal
*Corresponding authors. This work was supported in part by the Na-tional Natural Science Foundation of China under Grant 62231018 and
Grant 62072331.
Figure 1. Comparison of our Dec-Adapter against other transfer learning methods on screen content dataset SIQAD [39] in terms of BD-rate. All the methods are based on the same LIC compres-sion model, i.e., Cheng2020 [8] (namely the baseline). for every test case due to the difference between the prop-erties of a specific image and the statistic properties of a dataset.
It is especially challenging when the test image comes from a different domain. For example, applying a model trained on natural images to screen content images will lead to worse performance. An intuitive approach to solve this problem is fine-tuning the model on a screen con-tent dataset. However, this approach has two drawbacks: it will reduce the model’s generalization to its original data domain and consume considerable resources for fine-tuning a large model. Therefore, it is essential to explore alterna-tive solutions to address these problems.
There are some works exploring content-adaptive image compression. One approach is adjusting the parameters of the encoder neural network [35], but this has shown lim-ited improvement, as shown in Figure 1. Another approach is to adapt the the parameters of the decoder [23, 34, 46], which needs to transmit the adapted parameters to the de-coder side. Therefore, a large adapter will cause a heavy bitrate overhead. The third approach is to modify the la-tent tensor produced by the encoder[24, 13]. Although this process introduces zero parameter, its adaptation ability is limited. The main reason is that it assumes the hyper la-tent representation follows a Gaussian distribution, which is required for the bit-back [41] coding process.
Meanwhile, we observe that the Parameter-Efficient
Transfer Learning (PETL) is utilized in vision and language tasks [17, 25, 40, 7].
It makes a pre-trained model on a large-scale dataset adapt to a new task by fine-tuning a small number of parameters, which is more efficient than fine-tuning the whole network. Different from it, image com-pression is a self-encoding and decoding structure. There-fore, a more effective fine-tuning method is fine-tuning for each image other than a new dataset. From this perspec-tive, fine-tuning based cross domain image compression task is actually a one-shot task. The training and testing processes only utilize one image, which can avoid the do-main shift between training and testing. In addition, differ-ent from PETL, the adapter for image compression should be entropy-efficient since the bitrate overhead depends on the entropy of the adapter.
Based on the above observations, we propose an entropy-efficient adapter to bridge screen content and natural image compression. At the encoding side, we adopt a latent refin-ing strategy to enhance the model’s adaptability. At the de-coding side, instead of updating all parameters, we propose to insert a lightweight adapter into the decoder. The entropy of the adapter is optimized during the encoding process and the adapter parameters will be transmitted to the decoder for image adaptive decoding. The main contributions of this work is summarized as follows.
• To the best of our knowledge, we are the first to sys-tematically investigate feasible solutions for entropy-efficient transfer learning (EETL) for screen content image compression.
• We propose an efficient decoder-side adapter for image adaptive compression. We give a comprehensive anal-ysis on the design of the adapter structure, the decoder structure, and the insertion position.
• Experiments demonstrate that our Dec-Adapter achieves the best BD rate on both the natural image (in-domain) compression and screen content image (out-domain) compression.
Compared with the baseline, our approach achieves an improvement of over 2 dB when transferred to the images with a large domain gap. 2.