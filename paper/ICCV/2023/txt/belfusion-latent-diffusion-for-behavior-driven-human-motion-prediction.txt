Abstract 1.

Introduction
Stochastic human motion prediction (HMP) has gener-ally been tackled with generative adversarial networks and variational autoencoders. Most prior works aim at predict-ing highly diverse motion in terms of the skeleton joints’ dispersion. This has led to methods predicting fast and di-vergent movements, which are often unrealistic and inco-herent with past motion. Such methods also neglect scenar-ios where anticipating diverse short-range behaviors with subtle joint displacements is important. To address these issues, we present BeLFusion, a model that, for the first time, leverages latent diffusion models in HMP to sample from a behavioral latent space where behavior is disentan-gled from pose and motion. Thanks to our behavior coupler, which is able to transfer sampled behavior to ongoing mo-tion, BeLFusion’s predictions display a variety of behaviors that are significantly more realistic, and coherent with past motion than the state of the art. To support it, we introduce two metrics, the Area of the Cumulative Motion Distribu-tion, and the Average Pairwise Distance Error, which are correlated to realism according to a qualitative study (126 participants). Finally, we prove BeLFusion’s generalization power in a new cross-dataset scenario for stochastic HMP.
Humans excel at inattentively predicting others’ ac-tions and movements. This is key to effectively engaging in social interactions, driving a car, or walking across a crowd. Replicating this ability is imperative in many appli-cations like assistive robots, virtual avatars, or autonomous cars [3, 56]. Many prior works conceive Human Motion
Prediction (HMP) from a deterministic point of view, fore-casting a single sequence of body poses, or motion, given past poses, usually represented with skeleton joints [41].
However, humans are spontaneous and unpredictable crea-tures by nature, and this deterministic interpretation does not fit contexts where anticipating all possible outcomes is crucial. Accordingly, recent works have attempted to pre-dict the whole distribution of possible future motions (i.e., a multimodal distribution) given a short observed motion se-quence. We refer to this reformulation as stochastic HMP.
Most prior stochastic works focus on predicting a highly diverse distribution of motions. Such diversity has been tra-ditionally defined and evaluated in the coordinate space [70, 18, 45, 58, 42]. This definition biases research toward mod-els that generate fast transitions into very different poses coordinate-wise (see Fig. 1). Although there are scenar-ios where predicting low-speed diverse motion is impor-tant, this is discouraged by prior techniques. For exam-ple, in assistive robotics, anticipating behaviors (i.e., ac-tions) like whether the interlocutor is about to shake your hand or scratch their head might be crucial for preparing the robot’s actuators on time [5, 51]. In a surveillance sce-nario, a foreseen harmful behavior might not differ much from a well-meaning one when considering only the poses along the motion sequence. We argue that this behavioral perspective is paramount to build next-generation stochastic
HMP models. Moreover, results from prior diversity-centric works [45, 18] often suffer from a trade-off that has been persistently overlooked: predicted motion does not look coherent with respect to the latest observed motion. The strong diversity regularization techniques employed often produce abrupt speed changes or direction discontinuities.
We argue that consistency with the immediate past is a re-quirement for prediction plausibility.
To tackle these issues, we present BeLFusion (Fig. 1).
By constructing a latent space that disentangles behavior from poses and motion, diversity is no longer limited to the traditional coordinate-based perspective. Instead, diversity is viewed through a behavioral lens, allowing both short-(e.g., hand-waving or smoking) and long-range motions (e.g., standing up or sitting down) to be equally encouraged and represented in the space. Our behavior coupler ensures the predicted behavior is decoded into a smooth and plau-sible continuation of any ongoing motion. Thus, our pre-dicted motions look more realistic and coherent with the near past than alternatives, which we assess through quan-titative and qualitative analyses. In addition, BeLFusion is the first approach that exploits conditional latent diffusion models (LDM) [63, 55] for stochastic HMP, achieving state-of-the-art performance. By combining the exceptional ca-pabilities of LDMs to model conditional distributions with the convenient inductive biases of recurrent neural networks (RNNs) for motion modeling [41], BeLFusion represents a powerful method for stochastic HMP.
To summarize, our main contributions are: (1) We pro-pose BeLFusion, a method that generates predictions that are significantly more realistic and coherent with the near past than prior works, while achieving state-of-the-art ac-curacy on Human 3.6M [32] and AMASS [43] datasets. (2) We improve and extend the usual evaluation pipeline for stochastic HMP. For the first time in this task, a cross-dataset evaluation is conducted to assess the robustness against domain shifts, where the superior generalization ca-pabilities of our method are clearly depicted. This setup, built with AMASS [43] dataset, showcases a broad range of actions performed by more than 400 subjects. (3) We pro-pose two new metrics that provide complementary insights on the statistical similarities between a) the predicted and the dataset averaged absolute motion, and b) the predicted and the intrinsic dataset diversity. We show that they are significantly correlated to our definition of realism. 2.