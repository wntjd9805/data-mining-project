Abstract
Single-photon 3D cameras can record the time-of-arrival of billions of photons per second with picosecond accuracy. One common approach to summarize the pho-ton data stream is to build a per-pixel timestamp histogram, resulting in a 3D histogram tensor that encodes distances along the time axis. As the spatio-temporal resolution of the histogram tensor increases, the in-pixel memory require-ments and output data rates can quickly become impracti-cal. To overcome this limitation, we propose a family of lin-ear compressive representations of histogram tensors that can be computed efficiently, in an online fashion, as a ma-trix operation. We design practical lightweight compres-sive representations that are amenable to an in-pixel imple-mentation and consider the spatio-temporal information of each timestamp. Furthermore, we implement our proposed framework as the first layer of a neural network, which en-ables the joint end-to-end optimization of the compressive representations and a downstream SPAD data processing model. We find that a well-designed compressive repre-sentation can reduce in-sensor memory and data rates up to 2 orders of magnitude without significantly reducing 3D imaging quality. Finally, we analyze the power consump-tion implications through an on-chip implementation. 1.

Introduction 3D cameras based on single-photon avalanche diode technology (SPAD) are becoming increasingly popular for a wide range of applications that require high-resolution and low-power depth sensing, ranging from autonomous vehi-cles [1] to consumer smartphones [2]. Kilo-to-megapixel resolution SPAD pixel arrays [27, 28] have the capability of capturing the time-of-arrival of billions of individual pho-tons per frame with extremely high (picosecond) time reso-lution [31]. Unfortunately, this extreme sensitivity and high speed comes at a cost — the raw timestamp data causes a severe bottleneck between the image sensor and the image signal processor (ISP) that processes this data (Fig. 1(a)).
This data bottleneck severely limits the wider use of high-‡Email: fgutierrez3@wisc.edu
Figure 1. Resolving SPAD data bottleneck with learned com-pression. (a) Conventional SPAD-based 3D cameras stream raw photon timestamps or summary histograms off the image sensor which causes a data bottleneck between the image sensor and the on-camera image and signal processing (ISP) module. (b)
Our method applies a lightweight, on-sensor compressive coding scheme to the photon timestamp data which is later decoded at the
ISP, resolving the data bandwidth limitation. resolution SPAD arrays in 3D sensing applications.
One common approach to avoid transferring individual photon timestamps is to build a histogram in each pixel.
This results in a 3D histogram tensor that is transferred off-sensor for processing. Although this may be practical at low spatio-temporal resolutions (e.g., 64x32 pixels with 16 time bins [15]), it requires higher in-sensor memory. Moreover, the data rates of this histogram tensor representation also scale rapidly with the spatio-temporal resolution and max-imum depth range. For example, a megapixel SPAD-based 3D camera operating at 30 fps that outputs a histogram ten-sor with a thousand 8-bit bins per pixel would require an unmanageable data transfer rate of 240 Gbps.
To overcome the above limitations, we seek to design compressive representations of 3D histogram tensors.
In order to reduce the data rates output by the SPAD cam-era, the compact representation needs to be built in-pixel or inside the focal plane array (FPA). This is illustrated in
Fig. 1(b). Due to the limited in-pixel memory and compute, the compressive representation needs to be built in a stream-ing manner, with minimal computations per photon. Photon
histogram tensors are very different from conventional RGB images/video data. Therefore, traditional compression al-gorithms such as MPEG are not directly applicable.
We propose a family of compressive representations for 3D histogram tensors that can be computed in an online fashion with limited memory and compute. They are based on the linear spatio-temporal projection of each photon timestamp, which can be expressed as a simple matrix op-eration.
Instead of constructing per-pixel timestamp his-tograms, a compressive encoding maps its spatio-temporal information into a compressive histogram. To exploit lo-cal spatio-temporal correlations, a single compressive his-togram is built for a local 3D histogram block as illus-Instead of building and storing the full trated in Fig. 2. 3D histogram tensor in-sensor, multiple compressive his-tograms are built and transferred off-sensor for processing, effectively reducing the required in-sensor memory and data rates. Recent works proposed a similar compression frame-work based on compressive histograms [13] or sketches
[36].
In Sec. 4, we show that these prior works can be viewed as special cases of our proposed framework.
In this paper, we explore the design space of spatio-temporal compressive encodings and analyze the trade-offs between different design choices. Furthermore, we present a method to integrate our compression framework with data-driven SPAD data processing methods using convolu-tional neural networks (CNNs), which enables end-to-end optimization of the compressive encoding and a SPAD data processing CNN. We demonstrate the feasibility of com-pressive histograms through an on-chip implementation.
For our experimental evaluation, we integrate the compressive histograms framework with a state-of-the-art learning-based denoising model for SPAD-based 3D imag-ing [32]. Our results show that the jointly optimized com-pressive encoding and CNN can consistently reduce data rates up to 2 orders of magnitude in a wide range of sig-nal and noise levels. Moreover, for a given compression level, it can increase 3D imaging accuracy over previous hand-designed compressive histograms that only exploit temporal information [13, 36], especially in low signal-to-background ratio (SBR) scenarios and at higher compres-sion rates. Furthermore, we show that learned compres-sive histograms can perform comparably and sometimes even outperform a theoretical SPAD sensor design where the full 3D histogram tensor is stored in-sensor and only per-pixel depths are transferred off-sensor. Finally, we an-alyze the power consumption of a compressive histogram implemented on the UltraPhase SPAD processing chip [4]. 2.