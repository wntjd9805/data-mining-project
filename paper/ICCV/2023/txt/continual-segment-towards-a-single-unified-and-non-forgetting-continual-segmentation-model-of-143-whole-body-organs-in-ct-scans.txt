Abstract
Deep learning empowers the mainstream medical im-age segmentation methods. Nevertheless, current deep seg-mentation approaches are not capable of efficiently and ef-fectively adapting and updating the trained models when new segmentation classes are incrementally added. In the real clinical environment, it can be preferred that segmenta-tion models could be dynamically extended to segment new organs/tumors without the (re-)access to previous training datasets due to obstacles of patient privacy and data stor-age. This process can be viewed as a continual semantic segmentation (CSS) problem, being understudied for multi-organ segmentation. In this work, we propose a new archi-tectural CSS learning framework to learn a single deep seg-mentation model for segmenting a total of 143 whole-body organs. Using the encoder/decoder network structure, we demonstrate that a continually trained then frozen encoder coupled with incrementally-added decoders can extract suf-ficiently representative image features for new classes to be subsequently and validly segmented, while avoiding the catastrophic forgetting in CSS. To maintain a single network model complexity, each decoder is progressively pruned us-ing neural architecture search and teacher-student based knowledge distillation. Finally, we propose a body-part and anomaly-aware output merging module to combine organ predictions originating from different decoders and incor-porate both healthy and pathological organs appearing in different datasets. Trained and validated on 3D CT scans of 2500+ patients from four datasets, our single network can segment a total of 143 whole-body organs with very high accuracy, closely reaching the upper bound performance level by training four separate segmentation models (i.e., one model per dataset/task).
† ZJ and DG contribute equally. ∗ For correspondence, please contact
XY (hye1982@zju.edu.cn) and DJ (dakai.jin@alibaba-inc.com).
Figure 1. Illustration of the continual multi-organ segmentation.
At each continual learning step, only the previously trained model is available (green arrow). Previous datasets are not accessible. We allow organs from different datasets to have overlaps, and these datasets may also contain diseased organs (with tumors). 1.

Introduction
Multi-organ segmentation has been extensively studied in medical imaging because of its core importance for many downstream tasks, such as quantitative disease anal-ysis [27, 17], computer-aided diagnosis [51, 7], and can-cer radiotherapy planning [31, 67, 29]. With the emer-gence of many dedicated labeled organ datasets [2] and the fast developments in deep learning segmentation tech-niques [26], deep segmentation networks trained on spe-cific datasets achieve comparable performance with human observers [59, 67, 56]. However, this setup can have se-rious limitations in practical deployment for clinical appli-cations. These trained models are pre-trained to segment a fixed number of organs, while in real clinical practice, it is desirable that segmentation models can be dynami-cally extended to enable segmenting new organs without the (re-)access to previous training datasets or without training from scratch. In this way, patient privacy and data storage issues can be solved, and model development and deploy-ment can be much more efficient. This clinically preferred
process can be viewed as continual semantic segmentation (CSS), which is emerging very recently in the natural image domain [42, 6, 13, 71, 43, 65, 5] but has been only scarcely studied for medical imaging [45, 37]. Notably, if all labeled datasets are simultaneously accessible, it simplifies to a fed-erated learning [50, 55] or partial label learning [16, 57] problem. However, labeled datasets are always sequentially built over time by annotating different organs of interest ac-cording to various clinical tasks.
Multi-organ CSS faces several major challenges. First, since old datasets are not accessible when training on the new dataset, deep networks may easily forget the previously learned knowledge if no additional constraints are added, which is the most prominent issue (known as catastrophic forgetting [60, 32]) in continual learning. Second, in con-trast to natural image datasets that are often completely labeled [15, 73], fully annotated medical image datasets are rare, especially for comprehensive multi-organ datasets.
For example, concerning both necessity and cost, labeling 143 organs for all datasets is simply infeasible or impos-sible. These partially labeled datasets bring up the label conflict issue (semantic shift of the background class [6]), meaning a labeled organ in dataset-1 may become unlabeled background in dataset-2. Third, domain incremental learn-ing is common in multi-organ CSS, since different datasets may contain overlapped yet “style-different” organs. Ap-propriately tackling these domain gaps is non-trivial. E.g., dataset-1 is made up of healthy subjects with normal esoph-agus annotated, while dataset-2 is a dedicated esophageal cancer dataset where esophagus with tumor is labeled.
There are several recent CSS work in computer vi-sion [42, 6, 13, 71, 43]. MiB loss is often applied to handle the background-label conflicting issue [6, 13].
Regularization-based methods are mostly adopted to re-duce the forgetting of old knowledge while learning new classes. However, since network parameters are updated on the training of new classes, it is extremely difficult to achieve high performance on both old and new classes.
There are few previous works of CSS in medical imag-ing [45, 37]. Ozdemir et al. employed only 9 patients with 2 labels to develop a regularization-based CSS preliminary model [45]. The most recent work [37] used MiB loss and prototype matching to continually segment a small num-ber of 5 abdominal organs focusing only on the abdomen
CT. When involving a large number of organs (e.g., ≥ 100 classes) affiliated with a variety of body parts, such as in whole-body CT scans for practical considerations, this strat-egy becomes non-scalable and suffers severe performance degradation (as demonstrated in our experiments later).
A most recent continual classification work [64] has em-pirically shown that a base classification model trained with a sufficiently large number of classes (e.g., 800) is capable of extracting representative features even for new classes.
Hence, freezing most part of its parameters and incremen-tally fine-tuning the newly added last convolutional block for each new task leads to an almost non-forgetting contin-ual classification model, whose performance is close to the joint learning upper bound for both old and new classes.
Motivated by the observation in continual classification, in this work, we propose a novel architecture-based contin-ual multi-organ segmentation framework. On the basis of the common encoder + decoder architecture of segmenta-tion networks, we demonstrate that its encoder is capable of extracting representative deep features (non-specific to or-gan or body part) for the new data. Hence, we can freeze the encoder and incrementally add a separate decoder for each new learning task. Under this scheme, when adding a new task, organs learned in previous tasks will never be for-gotten because the encoder is frozen, and previous decoders are independent of the new task. In addition, the new de-coder is trained separately to segment a fixed number of foreground organs using only the new dataset. Hence, it avoids the background-label conflict with previous datasets during training. Yet, this scheme can lead to a swelling model as tasks expand. To make it scalable, a progressive trimming method using neural architectural search (NAS) and teacher-student-based knowledge distillation (KD) is exploited to maintain the overall model complexity and in-ference time comparable to the original single network. Fi-nally, to merge organ predictions originating from differ-ent decoders and incorporate both healthy and pathological organs appearing in different datasets, we propose a body-part and anomaly-aware output merging scheme using au-tomated body part and tumor predictions.
In summary, the main contributions are as follows:
• We are the first to comprehensively study the multi-organ continual semantic segmentation (CSS) problem with a clinically desirable number of organs (143 or-gans) across different body parts (head & neck, chest, abdomen) to more sufficiently and efficiently support medical diagnosis and treatment planning purposes.
• We propose the first (pure) architecture-based multi-organ continual segmentation framework. Consisting of a general encoder, continually expanded and pruned decoders, and a body-part and anomaly-aware out-put merging module, the proposed network avoids the notorious catastrophic forgetting in CSS while being scalable (maintaining the model complexity similar to other types of CSS approaches).
• Continually trained and validated on 3D CT scans of 2500+ patients compiled from four different datasets, our scalable unified model can segment total of 143 whole-body organs with very high accuracy, closely reaching the upper bound performance level of four well-trained individual models (i.e., nnUNet [26]).
Figure 2. Overall framework of the proposed continual multi-organ segmentation, which is composed of a General Encoder, multiple optimized and pruned decoders (one for each learning step), and a body-part and anomaly-ware output merging module. After training the base encoding/decoding segmentation network using D1, the General Encoder is frozen afterward, and separate trainable decoders are incrementally added to continually learn new datasets, which leads to a non-forgetting architecture. Decoder optimization and pruning are applied at each learning step to maintain a reasonable model complexity. Finally, the merging module is designed to combine organs from all decoders. 2.