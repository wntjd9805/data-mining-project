Abstract
Image harmonization aims to solve the visual inconsis-tency problem in composited images by adaptively adjust-ing the foreground pixels with the background as references.
Existing methods employ local color transformation or re-gion matching between foreground and background, which neglects powerful proximity prior and independently distin-guishes fore-/back-ground as a whole part for harmoniza-tion. As a result, they still show a limited performance across varied foreground objects and scenes. To address this issue, we propose a novel Global-aware Kernel Net-work (GKNet) to harmonize local regions with comprehen-sive consideration of long-distance background references.
Specifically, GKNet includes two parts, i.e., harmony ker-nel prediction and harmony kernel modulation branches.
The former includes a Long-distance Reference Extractor (LRE) to obtain long-distance context and Kernel Predic-tion Blocks (KPB) to predict multi-level harmony kernels by fusing global information with local features. To achieve this goal, a novel Selective Correlation Fusion (SCF) mod-ule is proposed to better select relevant long-distance back-ground references for local harmonization. The latter em-ploys the predicted kernels to harmonize foreground re-gions with local and global awareness. Abundant experi-ments demonstrate the superiority of our method for image harmonization over state-of-the-art methods, e.g., achiev-ing 39.53dB PSNR that surpasses the best counterpart by
+0.78dB ↑; decreasing fMSE/MSE by 11.5%↓/6.7%↓ com-pared with the SoTA method. Code will be available at here. 1.

Introduction
Image composition aims to synthesize foreground ob-jects from one image into another, which is a common task in image editing. However, human eyes could clearly dis-*Equal contribution.
†Corresponding author. (a) Local-translation (b) Region-matching (c) Ours
Figure 1. Comparison of background reference methods in har-monization. Blue/Red region represent foreground/background, respectively, and white/red arrows refer to interaction/injection, respectively. (a) Local-translation methods reference nearby pix-els. (b) Region-matching methods transfer reference with a unified view of fore-/back-ground region. (c) Our method interacts long-distance reference and injects it with short-distance consideration. tinguish synthetic images due to the visual inconsistency between foreground and background in composited images.
In attempting to solve the photo-unrealistic problem, image harmonization is proposed to adjust the foreground objects based on the illumination and color tone in background en-vironment, which plays an important role in image editing.
Traditional image harmonization approaches are mainly based on low-level feature matching, which is only effec-tive for specific scenes. Recently, numerous learning-based methods have achieved remarkable progress by address-ing image harmonization as a generation task. Existing learning-based methods could be categorized from two an-gles, i.e., local-translation and region-matching. 1) The former employs a convolutional encoder-decoder to learn a foreground pixel-to-pixel translation [41, 8]. But a shallow
CNN only captures limited surrounding background. As shown in Figure 1a, these approaches harmonize the current pixel with local references, which is insufficient for harmo-nization as inner foreground pixels could not attach back-ground reference. Besides, related long-distance references are effective in some cases. 2) The latter region matching methods [29, 7] distinguish foreground and background re-gions as two styles or domains. As shown in Figure 1b, they tackle harmonization as a matching problem with a
Mask
Input
RainNet[7] iS2AM[38]
Ours
Real(GT)
Figure 2. Left: Two challenging samples in image harmonization. Mask in column one and Red boxes represents the foreground. Right:
Performance comparison with SOTA methods in terms of PSNR and model size. The circle size represents the floating-point number. unified view of these two regions by statistics components or discriminators. Though these approaches harmonize im-ages with a broader reference range, they totally neglect the spatial variations in two regions. Hang et al. [17] begin to notice this problem and add attention-based references in region matching method [29]. But they still separate two regions independently and harmonize foreground by unified matching without considering foreground spatial variations.
To further illustrate existing problems, we provide two common harmonization cases in Figure 2. In the first case, a small foreground object appears in the background with obvious color changes. The region-matching method Rain-Net [7] provides a poor color correction result while the lo-cal method iS2AM [38] could tackle this case well, which indicates that the unified view of background will blend the overall complex color conditions. In the second case, related long-distance references exist in the background, while the local method could only attach insufficient adja-cent information. Region-matching method RainNet could obtain whole background blue tone by matching, but it still excessively harmonizes the house due to the unified view. These two cases indicate that local reference is insuf-ficient, but region-matching methods could not model long-distance reference well and will cause unbalanced harmo-nization problems by rough matching.
To solve this problem, we rethink essential proximity priors in image harmonization, i.e., when we paste an ob-ject into background, the color or light is related to loca-tion and will be influenced by its neighboring first. More-over, the effective long-distance information in background changes with pasted locations, which requires us to learn adaptive references for each part.
Inspired by this obser-vation, we propose a novel Global-aware Kernel Network (GKNet) to integrate local harmony modulation and long-distance background references, including harmony kernel prediction and harmony kernel modulation. For harmony kernel prediction, we propose a novel global-aware kernel prediction method including Long-distance Reference Ex-tractor (LRE) to obtain long-distance references and Ker-nel Prediction Blocks (KPB) to predict multi-level adaptive kernels with selected long-distance references by Selective
Correlation Fusion (SCF). For kernel modulation, we pro-pose to model local harmony operation by predicted global-aware kernels and multi-level features. Focusing on features in kernel region, kernel modulation is significant in alleviat-ing unbalanced region-matching errors in complex scenes.
To summarize, we make following contributions:
• With the observation of proximity prior and long-distance references in image harmonization task, we design
GKNet to model global-local interaction by learning global-aware harmony kernel, including harmony kernel prediction and harmony kernel modulation.
• For harmony kernel prediction, we propose a kernel pre-diction branch combined with LRE to model global in-formation and multiple KPB to learn adaptive harmony kernels. For better global references, we design SCF to select relevant long-distance references for local harmo-nization. For harmony kernel modulation, we propose the method to harmonize local regions in multi-level decoder layers with predicted kernels.
• Extensive experiments demonstrate the superior perfor-mance of our methods in both quantitative and qualitative results, noting that our method achieves state-of-the-art results on iHarmony4 datasets. 2.