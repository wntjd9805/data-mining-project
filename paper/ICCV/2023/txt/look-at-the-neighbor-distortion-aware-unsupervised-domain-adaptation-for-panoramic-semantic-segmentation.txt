Abstract
Endeavors have been recently made to transfer knowl-edge from the labeled pinhole image domain to the unla-beled panoramic image domain via Unsupervised Domain
Adaptation (UDA). The aim is to tackle the domain gaps caused by the style disparities and distortion problem from the non-uniformly distributed pixels of equirectangular pro-jection (ERP). Previous works typically focus on transfer-ring knowledge based on geometric priors with specially designed multi-branch network architectures. As a result, considerable computational costs are induced, and mean-while, their generalization abilities are profoundly hindered by the variation of distortion among pixels.
In this pa-per, we ﬁnd that the pixels’ neighborhood regions of the
ERP indeed introduce less distortion. Intuitively, we pro-pose a novel UDA framework that can effectively address the distortion problems for panoramic semantic segmenta-∗Corresponding author. tion. In comparison, our method is simpler, easier to im-plement, and more computationally efﬁcient. Speciﬁcally, we propose distortion-aware attention (DA) capturing the neighboring pixel distribution without using any geomet-ric constraints. Moreover, we propose a class-wise feature aggregation (CFA) module to iteratively update the feature representations with a memory bank. As such, the fea-ture similarity between two domains can be consistently optimized. Extensive experiments show that our method achieves new state-of-the-art performance while remark-ably reducing 80% parameters. 1.

Introduction
The burgeoning demand for omnidirectional and dense scene understanding has stimulated the popularity of 360◦ cameras, which pose much wider ﬁeld-of-view (FoV) in the range of 360◦ × 180◦ than the 2D images captured by pin-1
hole cameras [1]. 360◦ cameras deliver complete scene details either in the outdoor or indoor environment; there-fore, research has been actively focused on panoramic se-mantic segmentation for the pixel-wise scene understand-ing of the intelligent systems, such as self-driving and aug-mented/virtual reality [26, 36, 39].
Generally, 360◦ images are projected into the 2D pla-nar representations while preserving the omnidirectional information [40, 14, 50], to be aligned with the existing pipelines [31, 49]. Equirectangular projection (ERP) is the most commonly used projection type. However, ERP im-ages often suffer from the image distortion and object defor-mation [46], caused by the non-uniformly distributed pixels.
Also, the lack of precisely annotated datasets heavily im-pedes training effective panoramic semantic segmentation models.
For these reasons, research endeavors have been made to transfer knowledge from the labeled pinhole image domain to the unlabeled panoramic image domain via Unsupervised
Domain Adaptation (UDA). It aims to tackle the domain gaps caused by intrinsic style disparities and inevitable dis-tortion problems. Typically, [43, 44, 20, 9, 46, 45, 28] leverage the spatial geometric priors (e.g., convolution vari-ants [28] and attention-augmented components [45, 46]) to address the distortion problems. However, these priors are essentially inadequate for the panoramic semantic segmen-tation; therefore, cumbersome, i.e., multi-branch network architectures [38] are designed to reinforce the learning abilities. Consequently, considerable computation costs are induced, and their generalization abilities are profoundly plagued by the variation of distortion among the pixels.
In this paper, we ﬁnd that the pixels’ neighboring regions in the ERP indeed introduce less distortion. As the ERP shufﬂes the equidistribution of spherical pixels, the distance (Fig. 2 (b)) between any two pixels for a speciﬁc latitude of a 360◦ image is different from that (Fig. 2 (c)) of the
ERP image (sphere-to-plane projection). As a result, it is easier to capture the positional distribution among the pixels by reducing the receptive ﬁeld, which is more efﬁcient in addressing distortion problems. Therefore, controlling the neighboring region size is crucial in balancing the trade-off between receptive ﬁeld and distortion problems.
In light of this, we propose a novel UDA framework that can efﬁciently address the distortion problems for panoramic semantic segmentation. Compared with the state-of-the-art UDA methods [13, 45, 46, 41, 44], our method is simpler, easier to implement, and more compu-tationally efﬁcient. Our method enjoys two key contribu-tions. Firstly, we propose a novel distortion-aware atten-tion (DA) module to capture the neighboring pixel distri-butions between domains (See Fig. 1 (a)). This is but-tressed by a trainable relative positional encoding (RPE), which provides unique neighboring positional information.
We then build a hierarchically structured DA-based trans-former (DATR) that aggregates the feature information from all layers. In addition, we propose a class-wise feature ag-gregation (CFA) module that transfers knowledge of the ex-tracted features between domains. It updates the class-wise feature centers with a memory bank and consistently opti-mizes the cross-domain feature similarity by iteratively up-dating class centers.
We conduct extensive experiments for both the syn-thetic and real-world scenarios, including Cityscapes-to-DensePASS and Synthetic-to-DensePASS datasets. The re-sults show that our framework surpasses the SOTA meth-ods by +8.76% and +1.59% on the Synthetic-to-Real and
Pinhole-to-Panoramic scenarios, respectively while taking only 20% parameters (See Fig. 1 (b)). In summary, our ma-jor contributions are three-fold: (I) Our work serves as the
ﬁrst attempt to address the distortion problems by captur-ing the neighboring pixel distributions. (II) We propose a
DA module to capture the neighboring pixel distributions. (III) We propose a CFA module to iteratively transfer the cross-domain knowledge. 2.