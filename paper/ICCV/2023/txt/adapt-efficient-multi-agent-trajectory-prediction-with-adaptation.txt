Abstract
Forecasting future trajectories of agents in complex traf-fic scenes requires reliable and efficient predictions for all agents in the scene. However, existing methods for trajec-tory prediction are either inefficient or sacrifice accuracy.
To address this challenge, we propose ADAPT, a novel ap-proach for jointly predicting the trajectories of all agents in the scene with dynamic weight learning. Our approach outperforms state-of-the-art methods in both single-agent and multi-agent settings on the Argoverse and Interaction datasets, with a fraction of their computational overhead.
We attribute the improvement in our performance: first, to the adaptive head augmenting the model capacity without increasing the model size; second, to our design choices in the endpoint-conditioned prediction, reinforced by gradient stopping. Our analyses show that ADAPT can focus on each agent with adaptive prediction, allowing for accurate pre-dictions efficiently. https:// KUIS-AI.github.io/ adapt 1.

Introduction
A self-driving agent needs to be able to anticipate the future behavior of other agents around it to plan its trajec-tory. This problem, known as trajectory forecasting, is an important requirement for safe navigation. There are mul-tiple challenges to solving this problem. First of all, traf-fic scenes are highly dynamic. The behavior of an agent depends not only on the scene properties, such as configu-rations of lanes but also on other agents, such as yielding to another vehicle that has priority. Second, multiple fu-tures need to be predicted due to the inherent uncertainty in future predictions. While these two challenges are studied in the literature, one challenge remains mostly unresolved:
The future is shaped according to all agents in the scene acting together. Therefore, trajectories of all agents need to be predicted as opposed to the current practice of predicting only the trajectory of a selected agent [11, 6].
The progress in trajectory forecasting has focused mainly on scene representations for predicting the tra-jectory of a single agent. Typically, the existing meth-(a) (b)
Figure 1: Accuracy vs. Efficiency. We plot the ac-the number curacy in terms of error (brier-mFDE) vs. of parameters (a) and inference time (b) on the test set of Argoverse dataset [11]. Our method achieves one of the lowest reported errors with a small number of pa-rameters, leading to highly efficient inference time com-pared to methods AutoBot [22], LaneGCN [32], mm-Transformer [33], DenseTNT [23], SceneTransformer [37],
LTP [48], PAGA [13], and HiVT [53]. ods [32, 49, 21] follow an agent-centric reference frame where the scene is centered around the agent of interest, and everything else is positioned relative to it. This way, the prediction network is provided with the same initial state regardless of the agent’s location or orientation, providing pose-invariance. In other words, the scene is observed from the viewpoint of the agent of interest. In multi-agent setting, each agent has a different view of the world, and one cannot be prioritized over another as in the case of the agent-centric approach. A straightforward extension of an agent-centric approach to multi-agent is iterating the process for each agent in its own reference frame (Fig. 2). This is achieved by transforming the scene according to each agent to ob-tain pose-invariant features. However, this solution scales linearly with the number of agents and causes a variable in-ference time that cannot be afforded in the real-time setting of driving. As a solution, SceneTransformer [37] introduces a global frame that is shared across agents. In their scene-centric approach, all agents are positioned with respect to
the same reference point but at the cost of pose-invariance.
Ideally, the pose-invariance is a desirable property but for multi-agent prediction, a scene-centric approach can be preferred in real world due to efficiency concerns [37].
Then the question is how do we avoid the problems of a scene-centric approach without sacrificing efficiency? In this paper, we propose a solution to adapt to the situation of each agent with dynamic weight learning [28, 45, 43].
Dynamic networks can adjust the model structure based on input by adapting network weights according to the changes in the input states [25]. Therefore, they are well-suited for the multi-agent prediction task where each agent has a dif-ferent initial state. Additionally, dynamic networks are ca-pable of expanding the parameter space without increasing computation cost, therefore meeting the real-time require-ments of our task. We learn the weights of the network that predicts the endpoints so that they can change and adapt to each agent’s reference frame. With dynamic weights, we can efficiently adapt the prediction head to each agent in a scene-centric approach without iterating over agents.
Our method is not only the first to achieve multi-agent prediction accurately and efficiently in a scene-centric ap-proach but also one of the smallest and fastest among all tra-jectory prediction models including single-agent prediction.
Using a goal-conditioning approach, we can easily switch between single and multi-agent prediction settings. To fur-ther enhance the performance of our model, we employ gra-dient stopping to stabilize the training of trajectory and end-point prediction. This technique enables us to achieve good performance by fully leveraging the capacity of a small de-coder with simple MLP layers rather than a complex one.
We show that our method outperforms the state-of-the-art methods with a fraction of their parameters in both single-agent setting of the Argoverse [11] and multi-agent setting of the Interaction [51]. On Interaction, specifically designed for evaluating multi-agent predictions, our method achieves a 1% miss rate in comparison to 5% which was the lowest achieved so far [21]. Our contributions can be sum-marized as follows:
• We propose a novel approach for predicting the trajec-tories of all agents in the scene. Our adaptive head can predict accurate trajectories by dynamically adapting to various initial states of multiple agents.
• We achieve state-of-the-art results efficiently with one of the smallest and fastest models including the ones in single-agent setting. We validate our design choices in endpoint prediction and trajectory prediction with gradient stopping for stabilized training.
• We have created a unified prediction process that can be used for both single and multi-agent settings with the same backbone by utilizing endpoint conditioning.
Our method allows for easy switching between scene-centric and agent-centric reference frames, achieving (a) Scene-Centric (b) Agent-Centric
Figure 2: Scene-Centric vs. Agent-Centric Representa-tion. In scene-centric representation (a), all elements are encoded according to the same reference point. In agent-centric representation (b), each agent is encoded in its own reference frame, leading to a complexity linear in the num-ber of agents in multi-agent prediction. state-of-the-art in both settings. 2.