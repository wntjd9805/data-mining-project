Abstract
Despite significant research efforts, deep neural net-works remain vulnerable to biases: this raises concerns about their fairness and limits their generalization. In this paper, we propose a bias-agnostic approach to mitigate the impact of biases in deep neural networks. Unlike traditional debiasing approaches, we rely on a metric to quantify “bias alignment/misalignment” on target classes and use this information to discourage the propagation of bias-target alignment information through the network. We conduct ex-periments on several commonly used datasets for debiasing and compare our method with supervised and bias-specific approaches. Our results indicate that the proposed method achieves comparable performance to state-of-the-art super-vised approaches, despite being bias-agnostic, even in the presence of multiple biases in the same sample. 1.

Introduction
Today, deep Neural Networks (DNNs) are renowned for their high performance and resilience in many areas of com-puter vision, such as image classification, semantic segmen-tation, and object detection, used in fields ranging from self-driving vehicles to face recognition or surgical guidance.
However, it is well known that their tendency to rely heav-ily on any type of correlation present in the training data exposes them to potential pitfalls [3, 16, 40]: some “spuri-ous correlations” may be erroneously learned by the DNN.
These can act as biases [35].
Learned biases can reduce the generalization of the DNN [3, 5, 8, 16, 24, 30]. For example, if a DNN has learned to distinguish airplanes flying in the sky from boats sailing in the ocean, the model will probably use the background as a base for its classification: detecting it instead of learning the vehicle shape is a much simpler task. However, the model does not generalize to scenarios such as a landing seaplane.
Differently from domain adaptation [9, 29, 36], where the objective is to learn general features that compensate for the domain shift or to adapt extracted features to different domains, the goal of debiasing is to discourage the learning
Figure 1. Our proposed approach to agnostically remove the bias. of spurious correlations.
Many current debiasing approaches rely on prior informa-tion about the bias, such as the existence of an auxiliary label indicating some side information, the presence of bias(es) or their quality [5, 6, 8, 11, 34, 37]. However, obtaining these labels or information on the nature of the bias can be either very costly (due to annotation costs) or very noisy: this is what motivates the development of bias-agnostic approaches. Recent works have shown that bias features are learned “early” [26, 30]; there are bias-target aligned samples, for which the bias is learned, and the per-formance on the train set increases, and some misaligned ones, for which the prediction is wrong. Since bias-agnostic approaches delve into the biased information from the train-ing set, it is common to amplify the first features learned using Generalized Cross-Entropy [41] and then discourage their learning in an “unbiased” model. However, there is no guarantee that the very first features learned are the biased ones: detecting them agnostically and effectively remains an open question.
In this work, we propose a method that identifies the best time to extract bias-target alignment information by ob-serving the relative distance of misclassified samples to the
Voronoi boundary of the correct target class. We use this in-formation to train an unbiased model, where we give higher weight to bias-misaligned samples, and remove the bias-alignment information from the bottleneck layer (Fig. 1).
At a glance, our contributions are the following:
• we propose a bias-agnostic approach that indicates,
during the training of a vanilla model, when to extract bias-target alignment information. More precisely, we extract it when the distance of misclassified samples to the Voronoi boundary of the target class is maximal (Sec. 3.3);
• we use the bias alignment information to weight the loss contribution of every single sample: this will favor the learning of misaligned samples (Sec. 3.4.1);
• we propose an approach to eliminate bias information: specifically, we minimize the extractability of bias alignment information at the bottleneck of the DNN, conditioned to bias-target misalignment (Sec. 3.4.2);
• we study the behavior on several datasets typically used for debiasing and compare both supervised and bias-agnostic approaches: although our proposed tech-nique is bias-agnostic, its performance is comparable to that of supervised approaches (Sec. 4.3). 2.