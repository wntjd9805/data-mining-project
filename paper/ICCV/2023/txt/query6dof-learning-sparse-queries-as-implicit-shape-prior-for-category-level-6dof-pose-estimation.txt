Abstract
Category-level 6DoF object pose estimation intends to estimate the rotation, translation, and size of unseen ob-jects. Many previous works use point clouds as a pre-learned shape prior to overcome intra-category variabil-ity. The shape prior is deformed to reconstruct instances’ point clouds in canonical space and to build dense 3D-3D correspondences between the observed and reconstructed point clouds. However, the pre-learned shape prior is not jointly optimized with estimation networks, and they are trained with a surrogate objective. We propose a novel 6D pose estimation network, named Query6DoF, based on a series of category-specific sparse queries that represent the prior shape. Each query represents a shape compo-nent, and these queries are learnable embeddings that can be optimized together with the estimation network accord-ing to the point cloud reconstruction loss, the normalized object coordinate loss, and the 6d pose estimation loss.
Query6DoF adopts a deformation-and-matching paradigm with attention, where the queries dynamically extract fea-tures from regions of interest using the attention mechanism and then directly regress results. Furthermore, Query6DoF reduces computation overhead through the sparseness of the queries and the incorporation of a lightweight global in-formation injection block. With the aforementioned design,
Query6DoF achieves state-of-the-art (SOTA) pose estima-tion performance on the NOCS datasets. The source code and models are available at https://github.com/ hustvl/Query6DoF.
†Corresponding authors: Wenyu Liu (liuwy@hust.edu.cn), (lite@zhejianglab.com) and Minhong Wan (wanmh@
Te Li zhejianglab.com).
Figure 1: Comparisons with conventional works. a) Con-ventional methods adopt pre-learned shape prior and have a two-stage pipeline, i.e., deforming the prior and build-ing correspondences between points. b) Our method uses sparse learnable queries as the shape prior and conducts query/feature-based deformation and matching. 1.

Introduction
Category-level object pose estimation is aimed at esti-mating an object’s rotation, translation, and size from an
RGB-D scene within a given set of categories. This task has attracted increasing attention due to its vital role in robotics [5], 3D understanding [4, 22], and augmented real-ity [29]. Compared with instance-level object pose estima-tion, category-level object pose estimation doesn’t require obtaining the object’s CAD model in advance, making it more generally applicable.
Many existing methods [2, 7, 16, 30, 41, 38, 20, 35] solve this problem as shown in Figure 1(a). First, they attempt to reconstruct the input object point cloud in the Normal-ized Object Coordinate Space [34] (NOCS). Then they es-timate the 3D-3D correspondences between the input ob-served point cloud and the reconstructed object point cloud.
Finally, they determine object poses and sizes by applying the Umeyama algorithm [31] to these correspondences. To handle intra-category variability, a shape prior, which repre-sents a basic shape for objects in the same category, is intro-duced in [30] to this task. This shape prior is a set of point clouds pre-learned in NOCS for each category. Objects are reconstructed by deforming the shape prior. However, this approach has its drawbacks: 1) the shape prior is a dense representation of objects in a specific category, which is not only redundant but also makes the network computationally expensive. 2) the shape prior is pre-learned in advance and remains static during model training. Additionally, these methods are trained to predict the deformation field D and a correspondence matrix A, which is a surrogate task. 3)
Conventional model architectures [30, 3, 2] typically rely on either pooling operations in the PointNet [26] style or 3D graph convolution (3DGC) [19] to explore geometry features. However, the pooling operation can result in the loss of local geometry features, and these operations are not adaptive to extract the feature information.
To address these issues, we propose a novel method called Query6DoF (illustrated in Figure 1(b)). Instead of re-lying on dense and static point clouds as the shape prior, we introduce a series of sparse and learnable category-specific queries. Each query in this series is designed to encode a specific component of an object’s shape with implicitly shared semantics and is optimized concurrently with the whole model parameters. Due to intra-category variabil-ity, the queries only need to capture the most representa-tive components of objects and disregard unrepresentative shape details. Consequently, the queries can be sparse.
Moreover, due to the sparseness of queries, the sparseness of the queries reduces computational overhead. Therefore, there is no need to use techniques such as Low-Rank trans-former [36] mentioned in SGPA [2]. To eliminate the need for surrogate training objectives, we employ a direct pre-diction framework. However, unlike previous direct re-gression methods, e.g., [3, 20], we choose to perform the core deformation-and-matching paradigm in feature space.
The deformation process is accomplished based on an at-tention mechanism, which adaptively extracts information from instance features to queries. This transforms queries from category-specific into instance-specific shape repre-sentations. Then, correspondences between instance fea-tures and deformed queries are established by computing their similarity. Using these correspondences, the instance features are paired with deformed queries. Finally, these pairs are used to determine the pose and size through a neural network. Since the shape prior already consists of implicit queries, it is reasonable to also execute the entire pipeline implicitly in the feature space to better leverage these queries. Without pre-learned prior and surrogate train-ing objectives, our model is trained entirely and directly.
As a result, the prior can be more suitable for the model, enabling us to achieve state-of-the-art performance on the task.
Conventionally, the self-attention mechanism is used in transformers to inject global information. Unfortunately, adding self-attention layers significantly increases compu-tational load. Therefore, we propose an efficient global en-hancement layer to balance efficiency and performance.
The main contributions of this work can be summarized as:
• We propose to use sparse and learnable queries as shape prior rather than dense and static point clouds.
In this way, the queries are optimized at the same time as the whole model to discover the optimal set of pri-ors, and the sparseness design reduces the computation overhead.
• We adapt existing architectures to fit the novel shape prior representation with the help of attention mecha-nisms. We design a lightweight self-attention module in this to balance accuracy and speed.
• The overall 6DoF pose estimation accuracy of our method is better than previous state-of-the-art meth-ods on the CAMERA25 and REAL275 datasets, espe-cially, on the strict 5◦2cm metric our results are signif-icantly better than previous methods. 2.