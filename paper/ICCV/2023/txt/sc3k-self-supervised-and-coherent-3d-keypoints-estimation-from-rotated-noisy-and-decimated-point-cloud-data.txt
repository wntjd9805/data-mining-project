Abstract
This paper proposes a new method to infer keypoints from arbitrary object categories in practical scenarios where point cloud data (PCD) are noisy, down-sampled and arbitrarily rotated. Our proposed model adheres i) keypoints inference is to the following principles: fully unsupervised (no annotation given), ii) keypoints position error should be low and resilient to PCD per-turbations (robustness), iii) keypoints should not change their indexes for the intra-class objects (semantic coher-ence), iv) keypoints should be close to or proximal to
PCD surface (compactness). We achieve these desider-ata by proposing a new self-supervised training strategy for keypoints estimation that does not assume any a priori knowledge of the object class, and a model ar-chitecture with coupled auxiliary losses that promotes the desired keypoints properties. We compare the key-points estimated by the proposed approach with those of the state-of-the-art unsupervised approaches. The experiments show that our approach outperforms by es-timating keypoints with improved coverage (+9.41%) while being semantically consistent (+4.66%) that best characterize the object’s 3D shape for downstream tasks.
Code and data are available at: https://github.com/IIT-PAVIS/SC3K 1.

Introduction
Representing 3D objects using a set of keypoints [2, 10, 28] is a common and fundamental step for several geometrical reasoning tasks, including pose estimation, action recognition, object tracking, shape registration, deformation, retrieval and reconstruction [23, 35, 30, 42, 9]. As being a first processing step, it is crucial that the keypoints (see Fig. 1) are extracted reliably from point cloud data (PCD) of object shapes, as any error may negatively impact further higher-level tasks.
Figure 1: Self/un-supervised keypoints estimation from
PCD has to be robust to perturbations such as rotations, intra-class shape variations, noisy data and an arbitrary number of input 3D points. The keypoint localization needs to be not only accurate and pertain to the object surface, but also preserve semantic coherence, as the green keypoint is always associated with a specific object region despite arbitrary variations in the PCD.
The solution to this problem was initially cast as a supervised learning task: given a dataset of manu-ally annotated PCDs with keypoints, a computational model infers the keypoints position given a PCD as in-put [32, 45, 44, 13, 8, 36]. While these methods provided impressive results on the dataset they were trained on, they also highlighted the limitations of supervised ap-proaches. The basic issue is the requirement of having large enough datasets containing well-defined ground truth annotations for every object. Annotating such datasets is difficult as finding 3D keypoints manually is a hard and time consuming activity. Similarly, noise or missing data on the PCD can compromise quality, and highly symmetric/smooth objects might confuse the annotator in finding the correct keypoints.
Considering such limitations, recent methods have fo-cused on not-supervised approaches to bypass the need
for human annotations. Self-supervision methods define proxy tasks for which a large number of annotations can be obtained during training [31, 18, 35, 1, 39], e.g., geometrical transformations, canonical mapping, recon-struction to learn the prototype of intra-class object, etc. [22, 41, 21, 25, 27]. Unsupervised approaches dif-ferently promotes keypoints that are implicitly given by reasoning on the object geometry, e.g. point-level clus-tering, object’s skeleton, consistency between object’s symmetry, part contrasting, etc. [15, 33, 24, 9, 37].
The shift towards these learning paradigms clearly allows generalizing keypoint extraction but not without drawbacks. Without human annotations, it is difficult to identify a specific keypoint in a particular seman-tic 3D region when intra-class variations are present (airplane example in Fig. 1). Moreover, for several ap-plications such as shape registration, it is paramount to maintain the semantic consistency of keypoints, i.e., their vector ordering. Despite these considerations, key-points extraction has to be robust against common perturbations of PCDs, and the accuracy in localizing the keypoints should be preserved even if PCDs are rotated, noisy and decimated as shown in Fig. 1.
To this end, we propose an approach that reduces the requirement of ground truth labels by utilizing the input PCDs to learn to produce 3D keypoints on the object’s surface. It generates two versions of an object by applying a random rotation (as done on images in the methods presented in [7, 14]) and estimates the corresponding keypoints set.
Initially, the network optimizes the keypoints of the individual objects to promote non-overlapping, proxi-mal to the input PCD, and covering the complete object.
To ensure consistency in the semantic coherence (order) and positions of the estimated keypoints, the network compares the keypoints of both versions of the input
PCD. First, both sets are transformed to the canonical pose and are compared one-to-one between the corre-sponding keypoints of the sets. Second, as a proxy task, the relative pose between the two sets of keypoints is estimated and minimized against the known relative pose of the PCDs pair. Such learning strategy and network architecture promote the inference of keypoints that are semantically coherent, robust to perturbations, and with better accuracy.
The main contributions of this work are as follows:
• The proposed approach estimates 3D keypoints (from a single PCD), without the need to pre-align a PCD to a canonical pose;
• The presented mutual learning procedure allows to estimate keypoints that are semantically consistent for intra-class objects regardless of perturbations, such as rotation, noise, or down-sampling;
• On an average, the presented approach outperforms the state-of-the-art (SOTA) approaches (coverage:
+9.41%, semantic consistency: +4.66%) and is able to generalize to novel object poses.
The rest of the paper is organized as follows; Section 2 presents recent keypoints estimation approaches along with their positive features and limitations, Section 3 describes the proposed approach which is evaluated in Section 4, Section 5 reports the ablations, finally conclusions are given in Section 6. 2.