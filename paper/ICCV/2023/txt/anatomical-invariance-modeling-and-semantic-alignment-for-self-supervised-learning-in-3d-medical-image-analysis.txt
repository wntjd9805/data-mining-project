Abstract 1.

Introduction
Self-supervised learning (SSL) has recently achieved promising performance for 3D medical image analysis tasks. Most current methods follow existing SSL paradigm originally designed for photographic or natural images, which cannot explicitly and thoroughly exploit the intrin-sic similar anatomical structures across varying medical images. This may in fact degrade the quality of learned deep representations by maximizing the similarity among features containing spatial misalignment information and different anatomical semantics. In this work, we propose a new self-supervised learning framework, namely Alice, that explicitly fulfills Anatomical invariance modeling and semantic alignment via elaborately combining discrimina-tive and generative objectives. Alice introduces a new con-trastive learning strategy which encourages the similar-ity between views that are diversely mined but with con-sistent high-level semantics, in order to learn invariant anatomical features. Moreover, we design a conditional anatomical feature alignment module to complement cor-rupted embeddings with globally matched semantics and inter-patch topology information, conditioned by the dis-tribution of local image content, which permits to create better contrastive pairs. Our extensive quantitative exper-iments on three 3D medical image analysis tasks demon-strate and validate the performance superiority of Alice, surpassing the previous best SSL counterpart methods and showing promising ability for united representation learn-ing. Codes are available at https://github.com/alibaba-damo-academy/alice.
*Equal contribution. This work was done when Yankai Jiang and
Mingze Sun were interns at DAMO Academy, Alibaba Group.
Since the advent of deep learning, the lack of high-quality annotated data has long been a thorny challenge in medical image analysis, especially for 3D tasks. Recent re-search efforts based on self-supervised learning (SSL) shed light on acquiring strong visual representations in an unsu-pervised manner [7, 8, 16, 21, 26, 42].
Nowadays, contrastive learning (CL) [3, 11, 35, 50] and masked image modeling (MIM) [2, 20, 48], together with
Vision Transformers (ViTs) [15, 29], have revolutionized the field of SSL in computer vision and medical imaging, which achieve the state-of-the-art (SOTA) performance for a variety of tasks [3, 20, 40, 47, 56]. There is also a growing trend to combine CL and MIM in a self-distillation way to design more powerful SSL frameworks [23, 40, 41, 56]. De-spite popularity and success, these methods still follow the self-supervised paradigm designed for specific computer vi-sion scenarios, e.g., ImageNet (ILSVRC-2012) [36], which can be less suitable or irrational when applied to medical images. Now we analyze the drawbacks and irrationalities of existing hybrid SSL approaches, which combine CL with
MIM, from the following aspects: (i) Neglecting the intrinsic similar anatomical structure across varying medical image volumes. Commonly-used computed tomography (CT) and magnetic resonance (MR) images render human anatomies with intrinsic structures.
As shown in Fig. 1a, the definition of positive and nega-tive pairs in existing siamese SSL frameworks [3, 23, 40, 41, 56] ignore the semantically consistent anatomical fea-tures across different volumes and force an incorrect con-straint of instance invariance. Intuitively, utilizing the in-trinsic anatomical structure across different image volumes to model the class-specific invariance can help the learned representations more robust to the size, shape, and texture
Figure 1. The motivation of our proposed method Alice. (a) Existing SSL methods [3, 11, 23, 40, 41, 56] simply treat image patch samples which may depict totally different anatomical information from the same CT volume as positive pairs while considering samples sharing the same semantic content class but from another volume as negatives. Alice leverages the consistent anatomical structures across different volumes and addresses the false positive and false negative pairs. (b) shows the defect of existing hybrid SSL [23, 41, 56] methods, which ignore the large semantic gap between masked views and augmented views. Differently, Alice performs anatomical information alignment and thus crafts better contrastive pairs. variances of body parts. (ii) Lack of anatomical semantic alignment for views ex-tracted or sampled from the same image volume. As shown in Fig. 1b, the widely used siamese architecture in hybrid
SSL approaches [12, 23, 41, 56] maximize the similarity be-tween the representations of masked view and intact view.
However, a random crop of a body part may contain dif-ferent organs and human tissues (some of which are small in scale). A large masking ratio would already erase these contents and make the masked view quite distinct from the intact one. Thus, maximizing the similarity between views which incorporate totally different semantics can be harm-ful to the learned representations. To learn good repre-sentations for downstream tasks, SSL methods for medical images should align the anatomical features of the views which form a positive pair.
Driven by the aforementioned limitations, we present a simple, effective, and dedicated self-supervised learning framework for 3D medical segmentation tasks, Alice, by explicitly fulfilling Anatomical invariance modeling and se-mantic alignment through elaborately combined contrastive learning and MIM. From Fig. 1, Alice leverages the struc-tural similarity across different volumetric images to explic-itly learn universal consistent features from intrinsic body structures and model the anatomical invariance which is ro-bust to the size, shape, intensity, and texture diversity of body parts caused by inter-subject variation, organ defor-mation, and pathological changes.
Moreover, we design a conditional anatomical feature alignment module which complements masked views with the globally matched anatomical semantics and inter-patch topology to craft better contrastive pairs, enforcing that the positive pairs encoded to semantically consistent feature representations. This process explicitly realizes anatomical semantic alignment to further strengthen the representation with spatial sensitivity and semantic discriminability. employ 3D medical image segmentation and classifica-tion as downstream tasks. We fine-tune these widely used
ViT-based medical image segmentation frameworks follow-ing [19, 40, 53] with our pre-trained weights on two pub-licly available benchmarks: Fast and Low-resource semi-supervised Abdominal oRgan sEgmentation in CT (FLARE 2022)*, and Beyond the Cranial Vault (BTCV) [27]. Our method achieves the current SOTA results, with 86.87%
Dice on FLARE 2022 and 86.76% Dice on BTCV, surpass-ing previous best results by 2.22% and 1.77% respectively.
We also evaluate transfer learning on a public COVID-19 classification benchmark [31]. Alice outperforms state-of-the-art counterpart methods by 2.52% in AUC.
Our main contributions can be summarized as:
• We investigate the irrationalities of commonly used siamese SSL frameworks applied to medical images.
We propose Alice that is customized to leverage the anatomical similarity across volumetric medical im-ages to model class-specific invariance.
• In Alice, a conditional anatomical semantic alignment module is proposed to match the most related high-level semantics between the crafted contrastive views.
• Alice consistently outperforms popular SSL methods on three public downstream benchmarks, showing its effectiveness and generality. 2.