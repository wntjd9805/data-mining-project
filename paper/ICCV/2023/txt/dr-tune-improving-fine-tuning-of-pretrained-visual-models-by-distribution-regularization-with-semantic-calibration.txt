Abstract
The visual models pretrained on large-scale benchmarks encode general knowledge and prove effective in building more powerful representations for downstream tasks. Most existing approaches follow the fine-tuning paradigm, either by initializing or regularizing the downstream model based on the pretrained one. The former fails to retain the knowl-edge in the successive fine-tuning phase, thereby prone to be over-fitting, and the latter imposes strong constraints to the weights or feature maps of the downstream model without considering semantic drift, often incurring insufficient op-timization. To deal with these issues, we propose a novel fine-tuning framework, namely distribution regularization with semantic calibration (DR-Tune). It employs distribu-tion regularization by enforcing the downstream task head to decrease its classification error on the pretrained fea-ture distribution, which prevents it from over-fitting while enabling sufficient training of downstream encoders. Fur-thermore, to alleviate the interference by semantic drift, we develop the semantic calibration (SC) module to align the global shape and class centers of the pretrained and downstream feature distributions. Extensive experiments on widely used image classification datasets show that DR-Tune consistently improves the performance when combing with various backbones under different pretraining strate-gies. Code is available at: https://github.com/ weeknan/DR-Tune. 1.

Introduction
Nowadays, it has become a prevailing paradigm to pre-train deep models for common use on large-scale datasets and fine-tune them in multiple diverse downstream tasks in the community of computer vision [20, 7]. Due to the
*Corresponding author.
Figure 1. Comparison of distinct regularization-based approaches. (a) (or (b)) performs regularization by reducing the ad-hoc discrep-ancy between the weights (or the intermediate feature maps) of the downstream encoder and the pretrained one. In contrast, DR-Tune (c) performs regularization on the task-specific head by minimiz-ing the classification error with the pretrained feature distribution. data and semantic relevance between pretraining and down-stream tasks, the pretrained model implicitly encodes useful prior knowledge, and compared with the ones by training from scratch, it substantially promotes the accuracy of the downstream task and accelerates its training convergence in a variety of applications [21, 45], e.g. image classification, object detection, and semantic segmentation. In particular, when labeled data are quite limited in the downstream task, the issue of over-fitting can be effectively alleviated by us-ing the pretrained model as a training prior.
To facilitate training downstream models with the pre-trained ones, many efforts have recently been made. One of the typical ways is to directly take the pretrained model for initialization and fine-tune [24, 58] its weights by elab-orately designing task-specific learning objectives [10, 35, 17, 65, 64]. Nevertheless, these methods neglect retaining
Figure 2. Illustration on the motivation of DR-Tune. (a) Vanilla fine-tuning only uses downstream features for training, which is prone to be over-fitting. (b) Distribution Regularization employs the pretrained feature distribution to constrain the task head, enforcing it to learn a smooth classification boundary. (c) t-SNE [51] visualization on the features extracted by the pretrained/downstream encoders on CIFAR10
[33], showing the semantic drift issue. (d) Semantic Calibration clearly alleviates this semantic drift. the pretrained prior in the fine-tuning phase and tend to in-cur the “catastrophic forgetting” problem [40, 6, 16], mak-ing the learned model prone to over-fit.
In contrast, another alternative focuses on utilizing the prior knowledge encoded in the pretrained model to regu-larize the training of downstream models [56, 16]. By in-troducing extra regularization terms based on a pretrained model either on the weights [56] (see Fig. 1 (a)) or the inter-mediate feature maps [30, 36] (see Fig. 1 (b)), these meth-ods prevent the downstream model from over-fitting and significantly boost the overall performance; however, they often impose explicit ad-hoc constraints by reducing the discrepancy between the weights or the sample-wise feature maps generated by the pretrained and downstream models, without considering the semantic drift of the pretrained fea-tures. As a consequence, they are inclined to suffer from the non-negligible bias caused by the pretrained model, de-teriorating the final result which may be even worse than vanilla fine-tuning in specific scenarios as claimed in [10], and leave much room for improvement.
To address the issues above, this paper proposes a novel regularization-based framework for fine-tuning, namely distribution regularization (DR) with semantic calibration (DR-Tune). As Fig. 1 (c) illustrates, different from the ex-isting methods, DR-Tune conducts distribution regulariza-tion on the downstream classification head, instead of the encoder. The basic idea behind is to minimize the clas-sification error of the downstream task head according to the pretrained feature distribution in addition to the nor-mally used downstream feature distribution. Unfortunately, the discrepancy between the dynamically updated down-stream model and the frozen pretrained model incurs se-mantic drift between the two distributions as shown in Fig. 2 (c), which hinders the task head from learning correct clas-sification boundaries. To alleviate this drift, we develop the semantic calibration (SC) module to align the pretrained and downstream feature distributions via a holistic rotation matrix as well as a group of class-level translation vectors, which are efficiently estimated by establishing two mem-ory banks. The rotation matrix performs global distance-preserving alignment, while the translation vectors offer the alignment of class center pairs, significantly removing the semantic drift as depicted in Fig. 2 (d).
Intuitively, the proposed DR-Tune framework has two underlying advantages: 1) DR does not impose explicit con-straints neither on the weights nor on the intermediate fea-ture maps, largely facilitating optimizing the downstream encoder towards the downstream task; 2) SC greatly re-duces the semantic drift and the classification bias is thus alleviated when employing the pretrained feature distribu-tion as regularization, leading to improved fine-tuning re-sults; and 3) as in Fig. 2 (b), by leveraging the extra support from the pretrained feature distribution and the downstream features, the task head benefits generating smoother classi-fication boundaries, restricting the over-fitting risk.
The main contributions are summarized as follows: 1) We propose a novel fine-tuning framework (DR-Tune), which handles over-fitting by regularizing the task-specific head with the pretrained feature distribution. 2) We design the SC module to address the semantic drift between the pretrained and downstream feature distri-butions, effectively decreasing the bias introduced by the regularization from the pretrained models. 3) We conduct extensive evaluation on popular classifi-cation datasets and demonstrate that DR-Tune consistently improves the performance as combined with various net-work structures under different pretraining schemes. 2.