Abstract
Recently, neural implicit surfaces have become popular for multi-view reconstruction. To facilitate practical appli-cations like scene editing and manipulation, some works extend the framework with semantic masks input for the object-compositional reconstruction rather than the holis-tic perspective. Though achieving plausible disentangle-ment, the performance drops significantly when process-ing the indoor scenes where objects are usually partially observed. We propose RICO to address this by regular-izing the unobservable regions for indoor compositional reconstruction. Our key idea is to first regularize the smoothness of the occluded background, which then in turn guides the foreground object reconstruction in unob-servable regions based on the object-background relation-ship. Particularly, we regularize the geometry smooth-ness of occluded background patches. With the improved background surface, the signed distance function and the reversedly rendered depth of objects can be optimized to bound them within the background range. Extensive experi-ments show our method outperforms other methods on syn-thetic and real-world indoor scenes and prove the effective-ness of proposed regularizations. The code is available at https://github.com/kyleleey/RICO 1.

Introduction
Reconstructing 3D geometry from images is a funda-mental problem in computer vision and has many down-stream applications like VR/AR and game assets creation.
With the advance of neural implicit representations [20], re-cent reconstruction methods [25, 36, 41, 43] can recover ac-curate geometry from multi-view images. However, exist-ing methods typically regard the whole scene as an entirety and reconstruct everything altogether, thus preventing ap-plications like scene editing. In indoor scenes with plenty of reconfigurable objects, a disentangled object-compositional reconstruction, i.e. decomposing the geometry into different instantiated objects and background, can be more suitable
*Corresponding authors.
Figure 1. Comparison of [37] (Top) and ours (Bottom). Different objects are visualized in different colors. Previous reconstructions are connected with large artifacts. Taking the partially observed cubic object’s front and back views (in red and green rectangles respectively) as an example, [37] can only get the visible surface, while ours can complement the complete body. for further applications like moving the sofa in the scene.
In this paper, we aim to recover the room-level indoor scenes with decomposed geometry of individual objects and background. We assume that multi-view posed images and semantic masks that assign different labels to each instan-tiated object and the background are given as input. Ex-isting object-compositional methods [9, 45, 40] concentrate more on the rendering performance rather than the under-lying geometry, and thus can not be directly used for re-construction. The most recent work ObjSDF [37] learns an object-compositional signed distance function (SDF) field by proposing a transform function between SDF values and semantic logits. Specifically speaking, ObjSDF predicts multiple SDF values at each 3D point for different seman-tic classes, and converts them to semantic logits, allowing for separating object SDF values from the background when supervised by semantic masks. Although achieving plausi-ble shape disentanglement, it suffers from a common prob-lem in indoor scenes: objects and background can only be partially observed due to occlusions. When the object is partially observed, e.g. a cubic object against the wall, Ob-jSDF can not properly reconstruct the geometry between them (see Fig. 1 top-right). The reason is that the exist-ing works [45, 37] can only effectively regularize semantic labels and geometry of observed regions, and have little im-pact on the unobserved regions. When processing the in-door scenes where a large portion of objects are partially observed, the reconstruction results of these objects will be visible surface connected with the unconstrained struc-tures (as shown in Fig. 1, see Section 3.3 for a detailed anal-ysis). Fig. 2 shows that even with reasonable reconstruction when composing all the objects together, each object’s re-sult in the unobserved region is far from satisfactory and can hinder further applications like manipulating the object.
We propose RICO, which realizes the proper geometry disentanglement for indoor scenes (see Fig. 1 bottom) by explicitly regularizing the unobserved regions. To be more specific, when the object is partially observed, recovering its geometry is an ill-posed problem even with correspond-ing masks. Thus, introducing prior regularization for unob-served regions is necessary. We exploit two types of prior knowledge for indoor scenes in this work: 1) background smoothness and 2) object-background relations. First, when one ray hits the object surface, the existing method [37] can properly regularize the geometry and appearance on the hit-ting point, but can not account for the background surface behind this object. This drawback leads to artifacts and holes on the unobserved background surface (see Fig. 2).
We propose a patch-based smoothness loss to regularize the
SDF values of unobserved background regions. Then, since the background reconstruction is improved, we can leverage another strong prior: the objects are all within the room, i.e. using the background surface to regularize the SDF field of objects. We design two regularization terms: an object point-SDF loss for sampled points behind the background surface and a reversed depth loss to regularize the SDF dis-tribution of the entire ray. Both terms aim to bound the ob-ject within the background surface’s range, thus preventing the aforementioned unmeaning structure, making the object reconstruction a watertight and plausible shape instead of an open surface with severe artifacts.
In summary, we propose RICO to realize compositional reconstruction in indoor scenes where a large portion of ob-jects are partially observed. Our main contributions are: i) A patch-based background smoothness regularizer for unobserved background surface geometry. ii) Guided by the improved background surface, we exploit the object-Figure 2. ObjSDF results. Interested objects are dyed in blue. De-spite of the plausible composition, the disentangled backgrounds have artifacts and sunk holes, and partially observed objects can only get the visible surface (illustrated in ‘Object Backward’). background relation as prior knowledge and design ob-jectives that effectively regularize objects’ unobserved re-gions. iii) Extensive experiments on both real-world and synthetic datasets prove our superior reconstruction perfor-mance compared to previous works, especially for the par-tially observed objects. 2.