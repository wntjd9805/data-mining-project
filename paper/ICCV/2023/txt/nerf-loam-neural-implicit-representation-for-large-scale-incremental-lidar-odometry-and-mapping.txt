Abstract
Simultaneously odometry and mapping using LiDAR data is an important task for mobile systems to achieve full autonomy in large-scale environments. However, most existing LiDAR-based methods prioritize tracking quality over reconstruction quality. Although the recently devel-oped neural radiance ﬁelds (NeRF) have shown promis-ing advances in implicit reconstruction for indoor environ-ments, the problem of simultaneous odometry and mapping for large-scale scenarios using incremental LiDAR data re-mains unexplored. To bridge this gap, in this paper, we pro-pose a novel NeRF-based LiDAR odometry and mapping approach, NeRF-LOAM, consisting of three modules neural odometry, neural mapping, and mesh reconstruction. All these modules utilize our proposed neural signed distance function, which separates LiDAR points into ground and non-ground points to reduce Z-axis drift, optimizes odome-try and voxel embeddings concurrently, and in the end gen-erates dense smooth mesh maps of the environment. More-over, this joint optimization allows our NeRF-LOAM to be pre-trained free and exhibit strong generalization abilities when applied to different environments. Extensive eval-uations on three publicly available datasets demonstrate that our approach achieves state-of-the-art odometry and mapping performance, as well as a strong generalization in large-scale environments utilizing LiDAR data. Fur-thermore, we perform multiple ablation studies to validate the effectiveness of our network design. The implementa-tion of our approach will be made available at https:
//github.com/JunyuanDeng/NeRF-LOAM . 1.

Introduction
Simultaneous odometry and mapping is an important component for autonomous mobile systems to achieve full autonomy in large-scale environments. It estimates the 6-degree-of-freedom poses of the vehicle and simultaneously
*Equal contribution
†Corresponding authors (cid:20)(cid:17)(cid:25)(cid:27)(cid:23) (cid:20)(cid:17)(cid:20)(cid:19)(cid:25) (cid:36)(cid:55)(cid:40)(cid:587)(cid:48)(cid:588) (cid:19)(cid:17)(cid:24)(cid:21)(cid:26)
Figure 1. Simultaneously odometry and dense mapping results on
KITTI07. We present the reconstruction and the odometry result.
The odometry results are colored by the absolute trajectory errors (ATE). Our proposed novel NeRF-LOAM accurately estimates the poses of a mobile system and reconstructs the dense mesh map of the outdoor large-scale environment. builds a map of the environment, which are fundamen-tal prerequisites for downstream tasks like path planning and collision avoidance. LiDAR sensors have been widely adopted for odometry and mapping due to their ability to provide precise range measurements and robustness to illu-mination changes. However, it can be argued that the cur-rent LiDAR odometry and mapping algorithms prioritize tracking quality over dense reconstruction quality, which may overlook the potential beneﬁts of accurately capturing environmental geometry and generating high-ﬁdelity recon-structions. Despite the popularity of LiDAR-based incre-mental pose estimation [15, 41, 26, 39], research on high-level dense map reconstruction, especially deep-learning-based algorithms remains scarce.
Recently, neural radiance ﬁelds (NeRF) [32] has shown promising potentials in representing 3D scenes implicitly using a neural network and parallelly pose tracking meth-ods [33, 51, 45]. Although such representation can achieve seminal reconstruction with accurate poses, they concen-trate on indoor pose tracking and scene representation with
RGB-D sensors. The sparsity of LiDAR data and the lack of RGB information present signiﬁcant challenges for ap-plying previous algorithms to LiDAR data in outdoor en-vironments. Developing practical LiDAR-based algorithms to address these issues is currently a critical task.
To this end, we propose a novel NeRF-based LiDAR odometry and mapping method, dubbed NeRF-LOAM. It employs sparse octree-based voxels combined with neural implicit embeddings, decoded into a continuous signed dis-tance function (SDF) by a neural implicit decoder. The embeddings, decoder, and poses are optimized simultane-ously by minimizing the SDF errors. NeRF-LOAM targets the outdoor driving environments and separates the LiDAR points into ground and non-ground points, and a precise
SDF for ground points can be obtained with the help of nor-mals. Such an operation depresses Z-axis drift and smooths our dense 3D map. To tackle the incremental odometry and mapping under the unknown large-scale outdoor envi-ronment, a dynamic voxel embedding generation strategy without any pre-allocation or time-consuming loop is de-signed. Finally, we use key-scans to not only jointly reﬁne the pose and the map but also relieve the catastrophic for-getting or pre-training process. Extensive experiments were conducted on three publicly available datasets. The exper-imental results demonstrate that our method attains state-of-the-art odometry and mapping performance in outdoor large-scale environments using LiDAR data.
To sum up, the contributions of our work are threefold: 1. To the best of our knowledge, our NeRF-LOAM is the
ﬁrst neural implicit odometry and mapping method for large-scale environments using LiDAR data. 2. We propose a novel neural SDF module combined with dynamic generation and key-scans reﬁne strategy, which realizes a fast allocation of voxel embeddings in the octree and a high-ﬁdelity 3D representation. 3. Based on the proposed online joint optimization, our method is pre-training free and generalizes well in dif-ferent environments. 2.