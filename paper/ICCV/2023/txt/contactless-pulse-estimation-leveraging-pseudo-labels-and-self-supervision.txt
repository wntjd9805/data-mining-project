Abstract
Remote photoplethysmography (rPPG) is a promising research area involving non-invasive monitoring of vital signs using cameras. While several supervised meth-ods have been proposed, recent research has focused on contrastive-based self-supervised methods. However, these methods often collapse to learning irrelevant periodicities when dealing with interferences such as head motions, fa-cial dynamics, and video compression. To address this limi-tation, firstly, we enhance the current self-supervised learn-ing by introducing more reliable and explicit contrastive constraints. Secondly, we propose an innovative learn-ing strategy that seamlessly integrates self-supervised con-straints with pseudo-supervisory signals derived from tra-ditional unsupervised methods. This is followed by a co-rectification technique designed to mitigate the adverse ef-fects of noisy pseudo-labels. Experimental results demon-strate the superiority of our methodology over representa-tive models when applied to small, high-quality datasets such as PURE and UBFC-rPPG. Importantly, on large-scale challenging datasets such as VIPL-HR and V4V, our method, with zero annotation cost, not only significantly surpasses prevailing self-supervised techniques but also showcases remarkable alignment with state-of-the-art su-pervised methods. 1.

Introduction
Remote photoplethysmography (rPPG) is a non-contact method for monitoring human cardiac activity by detect-ing subtle facial color variations induced by changes in blood volume in skin tissue [16, 26]. Although these cyclic changes are not perceptible to the human eye, they can be captured by video cameras and extracted using com-putational algorithms [18, 45]. The deployment of rPPG technology has led to various applications, including home health monitoring, fitness training, and face anti-spoofing.
Remarkably, consumer cameras that are integrated into smartphones can be used for these applications, making rPPG technology widely accessible [11, 36].
The development of rPPG methods has evolved from hand-crafted features [9, 35, 51] to deep learning methods
[22, 32, 56], resulting in significantly improved accuracy due to the powerful feature extraction and representation ca-pabilities of the latter. However, this transition has also led to an increase in the cost of data collection and annotation.
Collecting sufficient data for rPPG can be a challeng-ing task [8], prompting researchers to develop fully self-supervised learning-based methods that can predict pulse signals without annotations. For example, Gideon et al.
[13] derived multiple-views contrastive learning utilizing the resampled and recovered videos. Similarly, Contrast-Phys [44] enforced the power spectral density (PSD) of the estimated pulse signal to be as similar as possible for tem-porally nearby segments and enlarged the distances of PSDs of different videos. Although they opened the door to train-ing with unlabeled data, there exist limitations.
The temporal stability assumption used to acquire posi-tive pairs does not hold if the pulse rate changes instanta-neously due to physical or mental activities. Besides, the current contrastive learning [13, 44] enforced the distance between the anchor and the negatives to be further than the positives, which are coarse-grained and unable to provide explicit regularization to the distances. This allows for any videos that are distant from the anchor but not necessar-ily identical to the corresponding negative samples to sat-isfy the constraints. The easily breakable assumption of temporal stability and the quite open-ended negative con-straints can render the network collapse to learning pulse-irrelevant features, particularly in the absence of supervised constraints.
While some of these methods [13, 44] have shown promising results on small datasets with high-quality and high signal-to-noise ratio (SNR) videos (e.g., videos in
PURE [43] and UBFC-rPPG [3]), where the pulse signal is clear enough to be detected using contrastive periodical constraints, their performance can be compromised when dealing with more challenging videos (e.g., VIPL-HR [32]
In particular, when head motion, vary-and V4V [39]). ing lighting, and video compression are present, the subtle periodical facial chrominance changes that are crucial for
rPPG estimation may be obscured by other types of facial dynamics that conform to the spectral restrictions of self-supervised learning. Therefore, current methods may strug-gle to converge to learning pulse dynamics solely based on the vulnerable self-supervised contrastive learning, without additional pulse-related supervision. To address the limita-tions, we propose a spectral ranking loss that imposes more refined constraints on negative pairs to narrow the search space. Our method involves randomly resampling the an-chor video at varying frequency ratios to generate negatives and then ranking the frequency peaks of the predicted sig-nals based on their corresponding resampling ratios.
Furthermore, in the context of videos characterized by low SNR, encompassing head motion, variations in lighting, and video compression artifacts, prevalent methodologies frequently encounter a susceptibility to local minima. To alleviate this concern, our devised approach involves con-straining the exploration space through the integration of pseudo labels, derived from traditional unsupervised meth-ods [51, 50]. Using these pseudo labels alongside self-supervised learning helps prevent getting stuck in local min-ima and, as a result, prevents the acquisition of features that are unrelated to the underlying pulse-related dynamics.
However, the use of noisy pseudo annotations is a double-edged sword. Although they can help the network avoid superficial local minima and converge to a better solution.
Inversely, it causes the network to overfit to misleading in-formation [27, 41]. To mitigate the negative effects of noisy supervision, we proposed to guide self-supervised learning progressively leveraging pseudo labels produced from tra-ditional unsupervised methods. Additionally, inspired by multi-network learning [25, 19, 15], a label rectification technique is invented which involves training two predictors and selectively using the output of one network to supervise the other.
Figure 1 illustrates the rectification process.
It begins by generating a decision boundary using a combination of pseudo-supervision and self-supervised learning. Then, we employ a large-deviation trick to select instances that are likely to be wrongly labeled and replace their pseudo-labels with the outputs of a peer network. This corrected subset of instances is then used for supervised training. By it-erating this process, our model enters a virtuous circle of self-correction and self-supervision, gradually converging towards the global minimum. We summarize our contribu-tions as follows:
• We develop more reliable and finer-grained self-supervised contrastive constraints.
• We propose a novel strategy for learning rPPG without annotations, using a joint training strategy of pseudo-label supervision and self-supervised learning.
• A label rectification method is proposed to combat the negative effect of incorrect pseudo annotations.
Figure 1. A classification example to illustrate our pseudo-label rectification. (1): draw a decision boundary from all pseudo-labels with weak- and self-supervision; (2): selectively rectify pseudo-labels by confidence scores; (3): draw a new decision boundary using corrected labels. (4): repeat (1)-(3) until convergence.
• In comparison to the state-of-the-art approaches, our annotation-free method consistently attains superior performance across large-scale challenging datasets and compressed videos. 2.