Abstract
Illumination planning in photometric stereo aims to find a balance between surface normal estimation accuracy and image capturing efficiency by selecting optimal light config-urations. It depends on factors such as the unknown shape and general reflectance of the target object, global illumina-tion, and the choice of photometric stereo backbones, which are too complex to be handled by existing methods based on handcrafted illumination planning rules. This paper pro-poses a learning-based illumination planning method that jointly considers these factors via integrating a neural net-work and a generalized image formation model. As it is impractical to supervise illumination planning due to the enormous search space for ground truth light configura-tions, we formulate illumination planning using reinforce-ment learning, which explores the light space in a photomet-ric stereo-aware and reward-driven manner. Experiments on synthetic and real-world datasets demonstrate that pho-tometric stereo under the 20-light configurations from our method is comparable to, or even surpasses that of using lights from all available directions. 1.

Introduction
Photometric stereo estimates the surface normal of an object from images taken in a fixed camera viewpoint under different light directions. From the early work of Woodham
[24], photometric stereo can be solved with at least three calibrated lights under the ideal Lambertian reflectance as-sumption. However, shape recovery in the real-world scene is more complex. For brevity, we denote generalized pho-Project page: https://jhchan0805.github.io/ReLeaPS
† Equal contributions.
‡ Corresponding author.
Figure 1. (Left) Our online illumination planning validation setup (Top with the light direction being controlled by a robot arm. right) Normal estimation error under light distributions from dif-ferent illumination planning methods. Photometric stereo using 20 lights from our illumination planning outperforms existing meth-ods (DC05 [3] and TK22 [21]), and can even obtain comparable results that use 100 light candidates (All). (Bottom right) Illumi-nation planning results for a sphere object based on our ReLeaPS, where the light directions are updated iteratively from the Q-value map, driven by the reward of surface normal estimation errors. tometric stereo as recovering surface normal from image observations with consideration of general non-Lambertian reflectances and global illumination effects such as shad-ows and inter-reflections. To achieve generalized photomet-ric stereo, more lights with uniform distribution are gener-ally preferred in existing methods [17], which can be time-consuming and impractical. To overcome this limitation, it is desirable to develop appropriate illumination planning strategies that can achieve similar or better accuracy with a limited number of light directions.
Despite the importance of illumination planning, few methods have been proposed. An optimal offline light source placement for Lambertian photometric stereo [3] has
been achieved by minimizing the normal uncertainty. On top of this, the illumination planning method for shadow-robust photometric stereo [21] is further designed by opti-mizing the light source direction adaptively based on previ-ously captured images of an object. Both methods assume
Lambertian reflectance, limiting their effectiveness to cap-ture complex properties of real-world material and illumi-nation on non-Lambertian surfaces.
In the context of photometric stereo, achieving optimal illumination planning involves addressing two primary con-cerns: 1) determining an appropriate learning strategy for illumination planning, and 2) integrating the image for-mation model of generalized photometric stereo into the pipeline. Illumination planning is a complex task that heav-ily depends on the object’s shape, reflectance properties, and global illumination effects. Existing methods [3, 21] rely on heuristic rules, making it hard to handle online illu-mination planning under real-world reflectance, global illu-minations, and adaptively fitting to generalized photometric stereo backbones. How to integrate a generalized image for-mation model with a deep neural network for illumination planning should also be considered.
Learning-based methods have demonstrated notable achievements in handling non-Lambertian reflectance prop-erties in generalized photometric stereo in recent years [2, 4]. These methods have significantly boosted the accuracy of surface normal estimation. The success of learning-based techniques motivates us to integrate illumination planning into photometric stereo using a learning-based approach.
However, the illumination planning problem is character-ized by an enormous search space, which makes it difficult to obtain the ground truth light distribution. Consequently, applying supervised learning techniques to learn illumina-tion planning becomes prohibitively difficult.
In this paper, we propose ReLeaPS, a Reinforcement
Learning-based illumination planning for generalized
Photometric Stereo as shown in Fig. 1. Reinforcement learning (RL) is a learning method that trains an agent through trial-and-error, which enables the agent to effi-ciently explore the enormous search space in a reward-driven manner. To formulate the illumination planning with generalized photometric stereo into the RL frame-work, we employ a dueling deep Q-network (DQN) [22] to learn the optimal action based on input images and light directions. We propose a brute-force exploration strategy for the agent to explore the light direction and iteratively optimize its actions via Q-learning based on accumulated observations to maximize the reward. We further trans-form the sparse reward into a dense reward to facilitate the learning process in RL. In summary, ReLeaPS hopes to make Remarkable LeaPS towards more time-efficient and accuracy-aware photometric stereo in practical application, via the following contribution:
• proposing the first RL approach for online illumination planning in a reward-driven manner;
• designing a dueling DQN specially tailored to general-ized photometric stereo;
• enhancing the performance of different photometric stereo backbones with a smaller number of inputs by appropriate illumination planning; and
• evaluating RL-based illumination planning by building a real data validation setup.
Results using ReLeaPS indicate that the accuracy of the recovered normal benefitted from RL-based illumination planning surpasses existing methods [3, 21] (Fig. 1 right). 2.