Abstract 1.

Introduction
Precise crop yield prediction provides valuable infor-mation for agricultural planning and decision-making pro-cesses. However, timely predicting crop yields remains challenging as crop growth is sensitive to growing season weather variation and climate change. In this work, we de-velop a deep learning-based solution, namely Multi-Modal
Spatial-Temporal Vision Transformer (MMST-ViT), for pre-dicting crop yields at the county level across the United
States, by considering the effects of short-term meteoro-logical variations during the growing season and the long-term climate change on crops. Specifically, our MMST-ViT consists of a Multi-Modal Transformer, a Spatial Trans-former, and a Temporal Transformer. The Multi-Modal
Transformer leverages both visual remote sensing data and short-term meteorological data for modeling the effect of growing season weather variations on crop growth. The
Spatial Transformer learns the high-resolution spatial de-pendency among counties for accurate agricultural track-ing. The Temporal Transformer captures the long-range temporal dependency for learning the impact of long-term climate change on crops. Meanwhile, we also devise a novel multi-modal contrastive learning technique to pre-train our model without extensive human supervision. Hence, our
MMST-ViT captures the impacts of both short-term weather variations and long-term climate change on crops by lever-aging both satellite images and meteorological data. We have conducted extensive experiments on over 200 counties in the United States, with the experimental results exhibit-ing that our MMST-ViT outperforms its counterparts under three performance metrics of interest. Our dataset and code are available at https://github.com/fudong03/
MMST-ViT.
*Corresponding author: Dr. Xu Yuan (xyuan@udel.edu)
Accurate crop yield prediction is essential for agricul-tural planning and advisory processes [26], informed eco-nomic decisions [2], and global food security [36]. How-ever, predicting crop yields precisely is challenging as it requires to consider the effects of i) short-term weather variations, governed by the meteorological data during the growing season, and ii) long-term climate change, governed by historical meteorological factors, on crops simultane-ously. Meanwhile, precise crop tracking relies on high-resolution remote sensing data. While process-based pre-diction approaches [44, 11, 25, 54] exist, they often suf-fer from high inaccuracies due to their strong assump-tions on management practices [15]. On the other hand, motivated by the recent success of deep neural networks
[29, 19, 50, 12, 20, 56, 37, 32, 18, 30, 8], deep learning (DL)-based methods have been widely adopted for crop yield predictions, due to their effectiveness in accurate agri-cultural tracking [27, 26] and their potent capabilities in capturing the spatial and temporal variation of meteorolog-ical data [28, 15].
So far, DL-based solutions for crop yield predictions can be roughly grouped into two categories, i.e., remote sens-ing data-based and meteorological data-based approaches.
The former [27, 26, 53, 13, 17, 47, 10] employs such re-mote sensing data as satellite images, unmanned aerial ve-hicle (UAV)-based imagery data, or vegetation indices to es-timate the annual crop yield, while the latter [16, 1, 36, 42, 48] predicts the crop yield by using meteorological param-eter data, including temperature, precipitation, vapor pres-sure deficit, etc. However, the former overlooks the direct impact of meteorological parameters on crop growth, while the latter lacks high-resolution remote sensing data for ac-curate agricultural tracking.
A recent study [39] has reported that the long-term climate change would gradually decrease the crop yield.
Driven by this discovery, follow-up pursuits have attempted to explore the effect of long-term climate change on crops.
For example, the CNN-RNN model [28] demonstrates that the crop yield prediction can benefit from historical mete-orological data, which is essential for measuring the im-pacts of climate change. Later, GNN-RNN [15] extends
CNN-RNN by framing the crop yield prediction as the
Spatial-Temporal forecasting problem.
It employs Graph
Neural Networks (GNN) and Long Short-Term Mem-ory (LSTM) [22] respectively for learning spatial depen-dency among neighborhood counties and for capturing the impact of long-term meteorological data on crops. How-ever, both of them only take into account the meteorological data for predictions, failing to leverage the remote sensing data for accurate agricultural tracking.
In this work, we aim to develop a new DL-based solu-tion for predicting crop yields at the county level across the United States, by using both visual remote sensing data (from the Sentinel-2 satellite imagery [41]) and nu-merical meteorological data (from the HRRR model [24]).
Our solution has two main goals. First, it captures the impacts of both short-term growing season weather varia-tions and long-term climate change on crops. Second, it aims to leverage high-resolution remote sensing data for accurate agricultural tracking. To achieve our goals, we propose the Multi-Modal Spatial-Temporal Vision Trans-former (MMST-ViT), motivated by the recent success of Vi-sion Transformers (ViT) [12]. To the best of our knowledge,
MMST-ViT is the first ViT-based model for real-world
It advances previous CNN/GNN-crop yield prediction. based and RNN-based counterparts respectively with bet-ter generalization to the multi-model data and with more powerful abilities in capturing long-term temporal depen-dency. Its three components of a Multi-Modal Transformer, a Spatial Transformer, and a Temporal Transformer are each equipped with one novel Multi-Head Attention (MHA) mechanism [50]. the Multi-Modal Trans-former leverages satellite images and meteorological data during the growing season for capturing the direct impact of short-term weather variations on crop growth. The Spa-tial Transformer learns high-resolution spatial dependency among counties for precise crop tracking. The Tempo-ral Transformer captures the effects of long-term climate change on crops. Since ViT-based models are prone to overfitting [12], we also develop a novel multi-modal con-trastive learning technique that pre-trains our Multi-Modal
Transformer without requiring human supervision. We have conducted experiments on over 200 counties in the United
States. The experimental results exhibit that our MMST-ViT outperforms its state-of-the-art counterparts under three performance metrics of interest. For example, on the soy-bean prediction, our MMST-ViT achieves the lowest Root
Mean Square Error (RMSE) value of 3.9, the highest R-Specifically, squared (R2) value of 0.843, and the best Pearson Correla-tion Coefficient (Corr) value of 0.918. 2.