Abstract
Deep learning based methods have become the de-facto standard for various computer vision tasks. Nevertheless, they have repeatedly shown their vulnerability to various form of input perturbations such as pixels modification, re-gion anonymization, etc. which are closely related to the adversarial attacks. This research particularly addresses the case of image anonymization, which is significantly im-portant to preserve privacy and hence to secure digitized form of personal information from being exposed and po-tentially misused by different services that have captured it for various purposes. However, applying anonymization causes the classifier to provide different class decisions be-fore and after applying it and therefore reduces the classi-fier’s reliability and usability. In order to achieve a robust solution to this problem we propose a novel anonymiza-tion procedure that allows the existing classifiers to become class decision invariant on the anonymized images with-out any modification requires to apply on the classification models. We conduct numerous experiments on the popular
ImageNet benchmark as well as on a large scale industrial toll classification problem’s dataset. Obtained results con-firm the efficiency and effectiveness of the proposed method as it obtained 0% rate of class decision change for both datasets compared to 15.95% on ImageNet and 0.18% on toll dataset obtained by applying the na¨ıve anonymization approaches. Moreover, it has shown a great potential to be applied to similar problems from different domains. 1.

Introduction
Deep learning models require, in general case, a vast load of data for training, control of performance and analy-sis of the models. For various reasons such as cost of label-ing or necessity to do historic analysis, it might be necessary to keep the data for a longer period of time. For numerous
*Corresponding author automatic system based service providers such as surveil-lance, security, toll classification, these data often concerns personal information including identity via face, location with car license plates, etc. Then, saving these information certainly raises the concern on personal privacy and hence on securing the digitized form of personal information from being exposed and potentially misused. As a consequence, multiple privacy protection laws such as General Data Pro-tection Regulation (GDPR) [19] in European Union, Cali-fornia Consumer Privacy Act (CCPA) in California, USA,
China Cybersecurity Law (CSL) in China, amended Act on the Protection of Personal Information (APPI) in Japan etc. impose severe limitations on data operations in order to pro-tect private data of the end customer. Indeed, one potential solution of the data saving necessity for the services vs the restrictions imposed by the privacy preservation laws is to remove the sensitive information (e.g., face, license plate) from the data via anonymization. Particularly, for the im-age related tasks anonymization means removing sensitive information from the image by modifying its corresponding part (for example, by blurring). This research considers the problem within the context of large scale image classifica-tion.
Recent research demonstrates that na¨ıvely applying anonymization effects the performance of the deep convo-lutional neural network (CNN) based classifiers [10]. Par-ticularly, anonymization causes the classifier to provide dif-ferent class decisions before and after applying it and hence reduces the classifier’s reliability and usability. This creates dual inference pipeline: classifier vs. anonymizer + clas-sifier, where the invariance of the predicted class is not a priori guaranteed. Fig. 1 illustrates this problem on an im-age from ImageNet, where the classifier predicts a different class once the image region is anonymized.
Intuitively, the dual inference pipeline has various im-mediate solutions such as: (1st) developing the classifiers directly with the anonymized data and (2nd) improve the classifier by training it with both original and anonymized
Indeed, for any offline (non real-time) or time-data.
• there is no dependency on the specific neural network architecture, or even specific task, although in our work we discuss only image classification;
• proposed method has low number of parameters;
• it can work directly “out-of-the-box” as we show in the experiment section where we apply it with different
CNN architectures without specific tuning of method parameters.
In order to validate the effectiveness of the proposed ap-proach, we conduct experiments with two different datasets
ImageNet and associated image classification problems: and a proprietary toll vehicle classification dataset. The first set of experiments on the open dataset aims to provide re-producible results and simulates a rather difficult problem in order to explore method limits. The second set of ex-periments illustrates the method’s performance on a real-world application (from which this work originated). Ob-tained results from both datasets confirm the effectiveness of the proposed method as it obtained 0% rate of class de-cision change for both compared to 15.95% on ImageNet and 0.18% on toll dataset obtained by applying the na¨ıve anonymization approaches. Our contributions in this re-search can be summarized as follows:
• we propose a novel solution for an important and con-temporary problem, introduced as the dual inference pipeline;
• we provide a novel view of the problem to be experi-mented with the publicly available popular ImageNet dataset.
• we achieved the desire and optimal performance, which is 0% rate of decision change.
The paper is organized as follows: section 2 discusses related work, in section 3 we set the problem, describe the proposed method and give more details on experiments set-tings. Section 4 contains the experiments results and obser-vations made throughout conducting those. Finally, section 5 concludes the paper. 2.