Abstract 3D shape modeling is labor-intensive, time-consuming, and requires years of expertise. To facilitate 3D shape mod-eling, we propose a 3D shape generation network that takes a 3D VR sketch as a condition. We assume that sketches are created by novices without art training and aim to re-construct geometrically realistic 3D shapes of a given cat-egory. To handle potential sketch ambiguity, our method creates multiple 3D shapes that align with the original sketch’s structure. We carefully design our method, train-ing the model step-by-step and leveraging multi-modal 3D shape representation to support training with limited train-ing data. To guarantee the realism of generated 3D shapes we leverage the normalizing flow that models the distribu-tion of the latent space of 3D shapes. To encourage the fidelity of the generated 3D shapes to an input sketch, we propose a dedicated loss that we deploy at different stages of the training process. The code is available at https:
//github.com/Rowl1ng/3Dsketch2shape. 1.

Introduction
The demand for convenient tools for 3D content cre-ation constantly grows as the creation of virtual worlds be-comes an integral part of various fields such as architecture and cinematography. Recently, several works have demon-strated how text and image priors can be used to create 3D shapes [43, 28, 27, 16, 26]. However, it is univer-sally accepted that text is much less expressive or precise than a 2D freehand sketch in conveying spatial or geomet-ric information [53, 12, 44]. Therefore, many works fo-cus on sketch-based modeling from 2D sketches [38, 5, 4, 6, 31, 25, 13, 46, 58, 57, 55, 17, 21] as a convenient tool for creating virtual 3D content. Yet, 2D sketches are am-biguous, and depicting a complex 3D shape in 2D requires substantial sketching expertise. As Virtual Reality (VR)
Figure 1. Given a VR (Virtual Reality) sketch input, we gener-ate 3D shape samples that satisfy three requirements: (1 - fidelity) reconstructed shapes follow the overall structure of a quick VR sketch; (2 - diversity) reconstructed shapes contain some diversity in shape details: such as a hollow or solid backrest, and (3 - real-ism) reconstructions favor geometrically realistic 3D shapes of a given category. headsets and associated technologies progress [20, 19, 35], more and more works consider 3D VR sketch as an in-put modality in the context of 3D modeling [52, 54, 42] and retrieval [23, 24, 22, 51, 33, 34, 32]. Firstly, 3D VR sketches are drawn directly in 3D and therefore provide a more immersive and intuitive design experience. Secondly, 3D VR sketches offer a natural way to convey volumet-ric shapes and spatial relationships. Moreover, the use of 3D VR sketches aligns with advancements in virtual reality technology, making the process of sketching and designing more future-proof and adaptable to emerging technologies.
Existing works on 3D shape modeling assume carefully created inputs and focus primarily on the interface and lo-gistics of the sketching process. In this paper, we introduce a novel method for 3D shape modeling that utilizes 3D VR sketching. Our method does not require professional sketch training or detailed sketches and is trained and tested on a dataset of sketches created by participants without art expe-rience. This approach ensures that our model can accom-modate a diverse range of users and handle sketches that might be less polished or precise, making it more accessi-ble and practical for real-world applications. Considering the sparsity of VR sketches, a single 3D shape model may
not match the user’s intention. Therefore, we advocate for generating multiple shape variations that closely resemble the input sketch, as demonstrated in Fig. 1. The user can then either directly pick one of the models, or refine the de-sign given the visualized 3D shapes, or multiple shapes can be used in some physical simulation process to select the optimal shape within the constraints of the VR sketch.
Working with freehand VR sketches presents several challenges due to the lack of datasets. We are aware of only one fine-grained dataset of VR sketches by Luo et al. [34], which we use in this work. The challenge of working with this data comes from its limited size and the misalignment between sketches and 3D shapes. Luo et al. [34] let par-ticipants sketch in an area different from the one where the reference 3D shape is displayed. This allows to model the scenario of sketching from memory or imagination, how-ever, results in a lack of alignment between 3D shapes and sketches, as shown in Fig. 2. Considering the misalignment of sketches and shapes in the dataset, and the ambiguity of the VR sketches, we aim to generate shapes with good fi-delity to an input sketch, rather than the reference shape.
We represent our sketches as point clouds, and regress
Signed Distance Fields (SDFs) values [39] representing 3D shapes. Despite the seemingly simple nature of the prob-lem, we found that training an auto-encoder in an end-to-end manner results in poor performance due to a dataset’s limited size and sketch-shape misalignments as discussed above. We, therefore, start by training an SDF auto-decoder, similar to the one proposed by Park et al. [39]. We then propose several losses that allow us to efficiently train our sketch encoder.
In particular, we design a sketch fidelity loss, exploiting the fact that sketch strokes represent 3D shape surface points. Leveraging the properties of SDF, this implies that the regressed SDF values in the points sam-pled from sketch strokes should be close to zero. To be able to sample multiple 3D shapes for a given input sketch, we adopt a conditional normalizing flow (CNF) model [14], trained to model the distribution of the latent space of 3D shapes. During the training of CNF, we again leverage the introduced sketch fidelity loss, improving the fidelity of re-construction to the input sketch.
In summary, our contributions are the following:
• We, for the first time, study the problem of condi-tional 3D shape generation from rapid and sparse 3D
VR sketches and carefully design our method to tackle the problem of (1) limited data, (2) misalignments be-tween sketches and 3D shapes and (3) abstract nature of freehand sketches.
Figure 2. Example of misalignment and ambiguity of 3D sketch.
Misalignment: the collected sketches and reference shapes have deviations in terms of the position and proportion of their parts.
Ambiguity: due to the sparsity and abstract nature of sketches, strokes can be interpreted differently. For example, the strokes of a cube can represent either slender bars or a closed solid shape. 2.