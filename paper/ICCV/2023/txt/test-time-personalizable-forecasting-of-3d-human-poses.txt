Abstract
Current motion forecasting approaches typically train a deep end-to-end model from the source domain data, and then apply it directly to target subjects. Despite promis-ing results, they remain non-optimal, due to privacy con-siderations, the test person and his/her natural properties (e.g., behavioral trait) are typically unseen in training. In this case, the source pre-trained model has a low ability to adapt to these out-of-source characteristics, resulting in an unreliable prediction. To tackle this issue, we propose a novel helper-predictor test-time personalization approach (H/P-TTP), which allows for a generalizable representa-tion of out-of-source subjects to gain more realistic predic-tions. Concretely, the helper is preceded by explicit and im-plicit augmenters, where the former yields noisy sequences to improve robustness, while the latter is to generate novel-domain data with an adversarial learning paradigm. Then, the domain-generalizable learning is achieved where the helper can extract cross-subject invariant-knowledge to up-date the predictor. At test time, given a new person, the predictor is able to be further optimized to empower per-sonalized capabilities to the specific properties. Extensive experiments show that with H/P-TTP, the existing models are significantly improved for various unseen subjects. The project page is available at https://sites.google. com/view/hp-ttp. 1.

Introduction
Forecasting the high-fidelity future human poses, condi-tioned on a given historical sequence, has attracted increas-ing attention in recent years. In a variety of 3D vision-based applications, such as autonomous driving and robot naviga-tion, it offers tremendous potential, especially for tasks that call for seamless interaction with humans [11, 9, 29].
Recent years have witnessed a proliferation in the ex-*Corresponding author
Figure 1. Starting from off-the-shelf networks, we first train a baseline model [26] on the source data, which is further optimized and personalized to the target person during the test phase. Here, we present an illustration of the pose sequence of various sub-jects, in which each 3D feature embedding is created by t-SNE.
We notice that the motion patterns of test subjects fail to match the source one. Moreover, our prediction skeleton (blue) is closer to the ground truth (red) against the vanilla baseline [26]. ploration of this emerging field [16, 5, 2].
In particu-lar, ongoing efforts are being devoted to deep learning ap-proaches, which typically train a generic model from large-scale datasets, and then apply it to new test subjects and samples during the deployment phase. We notice that these methods have become mainstream and are now rapidly evolving [49, 58, 24, 32, 3, 33].
Despite notable successes, the existing approaches are sub-optimal, because the generic model cannot be adapted to unseen personalized subjects [48, 21, 52]. To be precise, due to data limitations or privacy concerns, unseen test per-sons, as well as their individual properties (e.g., age, gender, or behavioral trait), are typically disjointed with the train-ing. It may lead to a large distribution gap between the tar-get and source domain [19, 42, 50], as shown in Figure 1.
For example, for the H3.6M dataset [22], a widely-adopted data splitting strategy takes subject-5 (S5) as the test and
the rest as the training [10, 34, 25]. Here, the inherent prop-erties (height, and body proportion) of S5 are significantly different from the other subjects; hence, the pre-trained pa-rameters may not be specific or personalized for the S5. We also note that, out-of-source persons are inevitable in the deployment, which poses a major bottleneck to current pre-dictive algorithms [3].
To solve it, a novel helper-predictor test-time personal-ization framework (H/P-TTP) is proposed. Starting with ready-to-use networks, our approach can attain tailored pa-rameters according to the characteristics of various unseen subjects. Concretely, the H/P-TTP advances the recent suc-cess of knowledge distillation into test-time adaptation by augmenting source instances to out-of-source distributions, enabling domain-generalizable learning. The helper in-volves an identical architecture with the predictor, except for the explicit and implicit augmenters. To improve the ro-bustness, by adding noise to the samples, the explicit aug-menter extracts task-relevant information and ignores irrel-evant ones. In contrast, the implicit augmenter is a train-able motion-style transformer to achieve the augmentations with new properties, which follows the adversarial training paradigm, with the goal of maximizing the discrepancy with the source subject, while ensuring semantic proximity. With the max-min optimization, the helper would be able to ob-serve and cope with the novel-styled samples to gain the cross-subject invariant context, and distill the knowledge to update the predictor.
During testing, the model can be further updated to adapt to an unseen test person. We also observe that due to psy-chological or environmental factors, even for the same per-son, his/her motion characteristics may vary. More intu-itively, for test data with large domain gaps, the predictor needs greater updates, and conversely, a mild personaliza-tion is expected. For this purpose, an adaptive learning rate strategy is proposed to dynamically consider the demand for test-time personalization. Owing to the adaptive test-time learning rate, our T/P-TTP can adapt to the intrinsic attributes of an unseen test subject, as well as to his/her spe-cific motion dynamics, as shown in Figure 2.
Our contributions are as follows: 1) We notice the issue: the existing approaches are ill-adapted to the out-of-source subjects, and propose a novel H/P-TTP model to address it. 2) We also propose an adaptive learning rate strategy to further consider the extent to which the model needs to be personalized. 3) Our H/P-TTP is integrated into many existing motion forecasting approaches, and substantially boosts the performance on unseen subjects. 2.