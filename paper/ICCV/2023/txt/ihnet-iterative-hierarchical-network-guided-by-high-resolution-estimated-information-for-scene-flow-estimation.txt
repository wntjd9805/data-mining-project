Abstract
Scene flow estimation, which predicts the 3D displace-ments of point clouds, is a fundamental task in autonomous driving. Most methods have adopted a coarse-to-fine struc-ture to balance computational efficiency with accuracy, par-ticularly when handling large displacements. However, in-accuracies in the initial coarse layer’s scene flow estimates may accumulate, leading to incorrect final estimates. To al-leviate this, we introduce a novel Iterative Hierarchical Net-work——IHNet. This approach circulates high-resolution estimated information (scene flow and feature) from the pre-ceding iteration back to the low-resolution layer of the cur-rent iteration. Serving as a guide, the high-resolution es-timated scene flow, instead of initializing the scene flow from zero, provides a more precise center for low-resolution layer to identify matches. Meanwhile, the decoder’s fea-ture at the high-resolution layer can contribute essential movement information. Furthermore, based on the recur-rent structure, we design a resampling scheme to enhance the correspondence between points across two consecutive frames. By employing the previous estimated scene flow to fine-tune the target frame’s coordinates, we can sig-nificantly reduce the correspondence discrepancy between two frame points, a problem often caused by point spar-sity. Following this adjustment, we continue to estimate the scene flow using the newly updated coordinates, along with the reencoded feature. Our approach outperforms the recent state-of-the-art method WSAFlowNet by 20.1% on
FlyingThings3D and 56.0% on KITTI scene flow datasets according to EPE3D metric. The code is available at https://github.com/wangyunlhr/IHNet. 1.

Introduction
Scene flow estimation on point clouds, which predicts point-wise 3D motions from two consecutive point clouds,
∗ Equal contribution. (cid:66) Corresponding author. is a fundamental task in autonomous driving applications and robotics. It supplies spatiotemporal motion and match-ing information for a range of high-level tasks such as multi-object tracking [36, 30], pose estimation [2], mo-tion segmentation [20, 5, 4], etc.
In recent years, due to advancements in deep learning, neural networks have emerged as a popular method for processing point clouds.
FlowNet3D [16] proposed an end-to-end scene flow esti-mation approach that leveraged PointNet++ [22] and intro-duced two new learnable layers, namely flow embedding layer and set upconv layer. However, the capacity of the flow embedding layer (cost volume) is determined by the matching search region, which is constrained to a single res-olution level due to the computational cost.
To strike a balance between accuracy and computational efficiency while accounting for large displacements, numer-ous methods employed a coarse-to-fine structure for the scene flow estimation task, such as PointPWC-Net [35] and
HALFlow [29]. The coarse-to-fine structure is a classical
“encoder-decoder” architecture, consisting of multiple lay-ers. The pipeline first constructs feature pyramid by en-coding the input and estimates at the coarsest resolution to capture large displacements. Layer-by-layer refinement is then performed from the coarser to finer level. During the refinement stage, once the scene flow has been estimated at a coarser level, it is up-sampled and then passed to the finer level by warping. That is, the search center for matching is determined based on the previous estimated results. What’s more, the estimated information from coarser level will be used to estimate scene flow for finer level.
However, early estimation can lead to errors and result in the search area missing the true matching point, yielding in-accurate scene flow estimation. To address this, we propose an Iterative Hierarchical Network (IHNet) based on the ob-servation that the accuracy of downsampled estimation re-sults from finer to coarser level is significantly higher than that of original coarser level results (initialized from zero),
This is shown in Fig. 1. IHNet aims to mitigate the error caused by mismatching in coarser resolution by propagating
the high-resolution estimated information from the previous iteration to low-resolution levels of the current iteration. In this way, IHNet leverages higher accuracy results from the finer level at the previous iteration, improving performance through each iteration.
Another significant challenge in scene flow estimation task is the issue of poor correspondence between two con-secutive frames, stemming from the inherent sparsity of point clouds. Due to the absence of an exact point-to-point correspondence, matching errors arise, ultimately resulting in inaccurate scene flow estimation. To address this issue, some methods [3, 1] designed novel cost volumes, such as point-to-patch, patch-to-patch cost volume. By matching larger regions (i.e. patches) instead of individual points, the influence of this challenge can be mitigated to a certain ex-tent. Focusing on the irregular data structure, RCP [9] de-signed a two-stage recurrent network. They first utilized a point-wise optimization to extract the regular information.
Subsequently, the information was input into a recurrent network based on GRU [23] for further regularization.
To address poor correspondence problem, we adopt an-other solution, which is to adjust the point coordinates.
Based on the iterative hierarchical structure, we propose a novel resampling scheme to modify the coordinates of the points applied to the second iteration and beyond. We first use the estimated scene flow to warp the source frame points, and then find the nearest neighbor of warped points in the target frame to regard as the new target frame point coordinates. Subsequent processing is performed based on the features encoded from the new points. The resampling scheme is effective because it eliminates the points in the target frame that are not particularly relevant to the source frame.
In summary, the main contributions as follows:
• We design an iterative hierarchical network guided by high-resolution estimated information based on a coarse-to-fine structure WSAFlowNet [32].
It lever-ages the high accuracy estimated information and im-proves the performance during each iteration.
• To address the problem of poor correspondence be-tween two adjacent frames, we propose a resampling scheme to adjust point clouds’ coordinates and recode the features as the input.
• Our proposed network achieves state-of-the-art per-formance on the FlyingThings3D and KITTI bench-marks. 2.