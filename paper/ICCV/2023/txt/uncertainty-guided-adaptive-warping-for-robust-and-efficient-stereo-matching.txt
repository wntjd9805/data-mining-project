Abstract
Correlation based stereo matching has achieved out-standing performance, which pursues cost volume between two feature maps. Unfortunately, current methods with a ﬁxed model do not work uniformly well across various datasets, greatly limiting their real-world applicability.
To tackle this issue, this paper proposes a new perspec-tive to dynamically calculate correlation for robust stereo matching. A novel Uncertainty Guided Adaptive Correla-tion (UGAC) module is introduced to robustly adapt the same model for different scenarios. Speciﬁcally, a variance-based uncertainty estimation is employed to adaptively ad-just the sampling area during warping operation. Addition-ally, we improve the traditional non-parametric warping
*Work was done while interning at Megvii. † Corresponding authors. with learnable parameters, such that the position-speciﬁc weights can be learned. We show that by empowering the recurrent network with the UGAC module, stereo matching can be exploited more robustly and effectively. Extensive experiments demonstrate that our method achieves state-of-the-art performance over the ETH3D, KITTI, and Middle-bury datasets when employing the same ﬁxed model over these datasets without any retraining procedure. To tar-get real-time applications, we further design a lightweight model based on UGAC, which also outperforms other meth-ods over KITTI benchmarks with only 0.6 M parameters. 1.

Introduction
Stereo matching is a fundamental computer vision task
[31] that aims to estimate the disparity between two rec-tiﬁed stereo images.
In the past decade, stereo matching has become increasingly popular due to the development of deep learning and the support of large synthetic datasets
[26, 4]. As a result, it has a breadth of applications spanning autonomous driving [6] to 3D reconstruction [13].
Since there are signiﬁcant domain differences between stereo matching datasets, existing state-of-the-art methods generally fail to achieve robust stereo matching, when ap-plied to different datasets with a single trained model with
ﬁxed parameters. As shown in Fig. 1(a), the Middlebury dataset [32] focuses on indoor scenes with high resolution and large disparity, while ETH3D [33] contains gray-scale images at low resolution, and KITTI [12] concentrates on outdoor driving scenarios. Consequently, the leading meth-ods [45, 24] on one dataset cannot consistently perform well across different datasets without retraining (Fig. 1(c,d)), which fails to meet the generalization requirement of real-world applications.
Large scene differences and unbalanced disparity distri-bution are the key reasons resulting in noisy and distorted feature maps [50], thus reducing the robustness. In addi-tion, the limited receptive ﬁeld of convolutions makes it difﬁcult for the network to capture the global features, lead-ing to domain sensitivity to different datasets [25]. To this end, CFNet [35] adopted an adaptive disparity range to en-large the receptive ﬁeld and alleviate the poor robustness caused by the ﬁxed disparity range. However, it still in-curs the issue of robust matching (shown in Fig. 1 (e)) be-cause blurred textures and unclear edges in features still ex-ist when constructing cost volume, which is generated by non-parametric warping and cannot be solved by adjusting the disparity range. Here, features are warped by the corre-sponding disparities and ﬁxed sampling points in the neigh-borhood. Because this process utilizes constant weights, it is inherently position-agnostic and cannot capture different feature details, leading to low robustness.
In this paper, we propose an uncertainty guided adap-tive correlation module to tackle the above problem, and further develop an advanced cascaded recurrent framework based on CREStereo [21], namely CREStereo++, to achieve robust stereo matching. Speciﬁcally, towards the problem caused by a ﬁxed sampling area and limited receptive ﬁeld, we employ a variance-based uncertainty estimation module to adaptively adjust the sampling range in the warping pro-cess. Moreover, we improve the traditional non-parametric warping operation with content-adaptive weights.
In this way, for those areas with high uncertainty, such as texture-less and occluded parts, the network adopts a wide sampling range. For parts that have achieved accurate matching, a small range of sampling area is suitable enough. Experi-mentally, as shown in Fig. 1 (b), our method achieves SOTA performances on all three datasets simultaneously without adaptation. To beneﬁt real-time applications, we further propose a lightweight version, namely Lite-CREStereo++, to enable real-time performance. Our Lite-CREStereo++ outperforms all the published real-time methods with less than 60ms inference time on KITTI2012 benchmarks with only 0.6 M parameters.
The main contributions of this paper are as follows:
• We introduce a new perspective to calculate correlation dynamically for robust stereo matching that can adapt to various datasets.
• We develop an uncertainty guided adaptive warping module that enhances the robustness of the network for different scenarios, which is also valuable in general matching tasks.
• We conduct extensive experiments on commonly used benchmarks and achieve SOTA results in terms of both robustness and efﬁciency, making the proposed ap-proach universal.
• Our method obtains the championship on the stereo task of Robust Vision Challenge 2022. 2.