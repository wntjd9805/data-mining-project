Abstract 3D human pose estimation has been researched for decades with promising fruits. 3D human pose lifting is one of the promising research directions toward the task where both estimated pose and ground truth pose data are used for training. Existing pose lifting works mainly focus on improving the performance of estimated pose, but they usu-ally underperform when testing on the ground truth pose data. We observe that the performance of the estimated pose can be easily improved by preparing good quality 2D pose, such as fine-tuning the 2D pose or using advanced 2D pose detectors. As such, we concentrate on improving the 3D human pose lifting via ground truth data for the fu-ture improvement of more quality estimated pose data. To-wards this goal, a simple yet effective model called Global-local Adaptive Graph Convolutional Network (GLA-GCN) is proposed in this work. Our GLA-GCN globally mod-els the spatiotemporal structure via a graph representation and backtraces local joint features for 3D human pose es-timation via individually connected layers. To validate our model design, we conduct extensive experiments on three benchmark datasets: Human3.6M, HumanEva-I, and MPI-INF-3DHP. Experimental results show that our GLA-GCN1 implemented with ground truth 2D poses significantly out-performs state-of-the-art methods (e.g., up to 3%, 17%, and 14% error reductions on Human3.6M, HumanEva-I, and
MPI-INF-3DHP, respectively). 1.

Introduction 3D Human Pose Estimation (HPE) in videos aims to predict the pose joint locations of the human body in 3D space, which can facilitate plenty of applications such as video surveillance, human-robot interaction, and physio-1Code is available: https://github.com/bruceyo/GLA-GCN
‡Corresponding author. therapy [53]. 3D human poses can be directly retrieved from advanced motion sensors such as motion capture sys-tems, depth sensors, or stereotype cameras [51, 73]. The 3D HPE task can be performed under either multi-view or monocular view settings. Although state-of-the-art multi-view methods [30, 52, 78, 26] generally show superior performance than monocular ones [28, 77], ordinary RGB monocular cameras are much cheaper than these off-the-shelf motion sensors and more widely applied in real-world surveillance scenarios. Hence, 3D HPE from a monocular video is an important and challenging task, which has been attracting increasing research interest. Recent monocular view works can be grouped into model-based and model-free methods [13]. Model-based methods [15, 23] incorpo-rate parametric body models such as kinematic [67], pla-nar [60], and volumetric models [2] for 3D HPE. Model-free methods can be further grouped into single-stage and 2D to 3D lifting methods. Single-stage methods estimate the 3D pose directly from images in an end-to-end manner
[36, 46, 12, 65, 43, 81]. 2D to 3D lifting methods have an intermediate 2D pose estimation layer [44, 50, 41, 61].
Among these methods, 2D to 3D lifting methods imple-mented with ground truth 2D poses achieved better perfor-mance.
The advantages of 2D to 3D lifting methods can be sum-marized as two main points: allowing make use of advances in 2D human pose detection and exploiting temporal infor-mation along multiple 2D pose frames [50, 31]. For the 2D human pose detection, it has achieved remarkable progress via detectors such as Mask R-CNN (MRCNN) [24], Cas-caded Pyramid Network (CPN) [14], Stacked Hourglass (SH) detector [47], and HR-Net [58]. The intermediate 2D pose estimation stage via these 2D pose detectors signifi-cantly reduces the data volume and complexity of the 3D
HPE task. For the temporal information, existing main-stream methods [50, 41, 61, 28, 37, 77] gained notice-able improvements by feeding a long sequence of 2D pose
frames to their models, among which [77] achieved the state-of-the-art performance via ground truth 2D poses. Re-cent methods [77, 84] simply fine-tuned these 2D pose de-tectors on the target datasets and achieved great improve-ments in the performance of estimated 2D pose data but re-main far behind the results of using ground truth 2D pose, which motivates us to concentrate on improving the 3D
HPE via ground truth 2D pose data for potential improve-ments via future more quality estimated 2D pose data.
Given the promising performance and advantages of 2D to 3D lifting methods, our work contributes to the literature in this direction. For 2D to 3D lifting approaches, since
[44] proposed Fully Connected Network (FCN), recent ad-vanced models have three main groups: Temporal Convolu-tional Network (TCN)-based [50, 41], Graph Convolutional
Network (GCN)-based [79, 61, 28], and Transformer-based ones [38, 37, 77]. On the one hand, we observe that exist-ing TCN- and Transformer-based methods can receive large receptive fields (i.e., a long 2D pose sequence) with strided convolutions. However, it can be difficult to make further intuitive designs to backtrace local joint features based on the pose structure, since the 2D pose sequence is flattened and fed to the model. Meanwhile, the estimation of dif-ferent pose joints relies on the same fully connected layer, which lacks considering the independent characteristic of different pose joints. On the other hand, GCN-based mod-els can explicitly reserve the structure of 2D and 3D human pose during convolutional propagation. However, this ad-vantage of GCN remains under-explored. Existing GCN-based methods [79, 61] also utilized a fully connected layer for the estimation of different 3D pose joints, which does not consider the structural features of GCN representations.
To this end, we propose Global-local Adaptive GCN (GLA-GCN) for 2D to 3D human pose lifting. Our GLA-GCN contains two modules: global representation and lo-cal 3D pose estimation.
In the global representation, we use an adaptive Graph Convolutional Network (GCN) to re-construct the global representation of an intermediate 3D human pose sequence from its corresponding 2D sequence.
For the local 3D pose joint estimation, we temporally shrink the global representation optimized by the reconstructed 3D pose sequence with a strided design. Then, an individual connected layer is proposed to locally estimate the 3D hu-man pose joints from the shrunken global representation.
Our contributions can be threefold as follows:
• We propose a global-local learning architecture that leverages the global spatiotemporal representation and local joint representation in the GCN-based model for 3D human pose estimation.
• We are the first to introduce an individually connected layer that has two components to divide joint nodes and in-put the joint node representation for 3D pose joint estima-tion instead of based on pooled features.
• Our GLA-GCN model performs better than corre-sponding state-of-the-art methods [37, 77] with consider-able margins e.g., up to 3% and 17% error reductions on
Human3.6M [29] and HumanEva-I [57], respectively. 2.