Abstract
Meta-learning-based few-shot detectors use one K-average-pooled prototype (averaging along K-shot dimen-sion) in both Region Proposal Network (RPN) and Detec-tion head (DH) for query detection. Such plain operation would harm the FSOD performance in two aspects: 1) the poor quality of the prototype, and 2) the equivocal guidance due to the contradictions between RPN and DH. In this pa-per, we look closely into those critical issues and propose the σ-Adaptive Decoupled Prototype (σ-ADP) as a solution.
To generate the high-quality prototype, we prioritize salient representations and deemphasize trivial variations by ac-cessing both angle distance and magnitude dispersion (σ) across K-support samples. To provide precise information for the query image, the prototype is decoupled into task-specific ones, which provide tailored guidance for ‘where to look’ and ‘what to look for’, respectively.
Beyond that, we find our σ-ADP can gradually strengthen the generalization power of encoding network during meta-training. So it can robustly deal with intra-class variations and a simple K- average pooling is enough to generate a high-quality prototype at meta-testing. We provide theoretical analysis to support its rationality. Ex-tensive experiments on Pascal VOC, MS-COCO and FSOD datasets demonstrate that the proposed method achieves new state-of-the-art performance. Notably, our method sur-passes the baseline model by a large margin – up to around 5.0% AP50 and 8.0% AP75 on novel classes. 1.

Introduction
In recent years, object detectors based on deep learning have achieved impressive performance [36, 37, 14] due to a large amount of human-annotated data. However, humans can observe novel objects with limited instances. Thus,
*Equal contribution. Author ordering determined by coin flip.
†Corresponding author.
Figure 1: The visualization of attention maps for a novel class of ‘walking shoe’. The attention maps are generated by common practice (average-pooling along K-shot dimension) vs. weighted pooling (weights deriving from either angle distance or a com-bination with magnitude deviation), depicted as (b), (c) and (d), respectively. Compared to other operations, σ-ADP (d) is able to active salient regions and suppress trivial features among K sup-port samples, resulting in the robust class representation. We have only shown the two most representative samples for comparison, as the activation map is the same for K samples. few-shot object detection (FSOD) comes to rescue.
In general, there are two main categories of FSOD approaches : fine-tuning and meta-learning based meth-ods. The fine-tuning approaches [46, 41, 48, 50], with-out considering the class-level representations, may pro-duce negative transfer when the differences among cate-gories are obvious. Other meta-learning-based methods
[18, 19, 49, 8, 54, 56, 55] are designed to acquire class-level meta-knowledge and improve model generalization to novel classes through feature re-weighting. Currently,
FSOD meta-detectors use episodic training with inputs of
K-support images and a query image. A class-level pro-totype, generated from K-support images, re-weights the query image and guides the learner for final detection re-sults. Therefore, two main factors directly affect FSOD per-formance: 1) the quality of prototype and 2) the precision of guidance information.
For the first one, most meta-learning-based methods em-ploy some form of class prototypes (globally semantic-rich or locally spatially-aware) from a set of support samples.
For example, methods [8, 54, 56, 29] form vectorial proto-types via global average-pooled features, bilinearly-pooled second-order representations, kernelized descriptors and condition-coupled information respectively. Other works
[15, 55, 53] delve into the spatially-aware prototypes. They treat different support samples equally (averaging along K-shot dimension). Such plain operation struggles to capture the salient regions, overwhelming by the non-target objects 1 and the intra-class variations, as shown in Figure 1 (b).
Generally, assigning weights for K-support features based on the angle distance (measured by cosine similarity) helps to reduce the intra-class variance [46], e.g., the co-sine similarity between per sample to their average-pooled points. This way, the refined prototype can target the rel-evant objects, while discarding the most irrelevant regions across K-shot support images. We observe that accounting for cosine similarity alone is insufficient(Figure 1(c)). As a vector is represented by its angle and magnitude (or length), it makes sense to re-evaluate K support features based on the magnitude deviation. And this deviation can be captured by σ, which is a statistical measurement for measuring the dispersion of a set of points.
In short, we first propose a novel σ-Adaptive Prototype (σ-AP) to provide a high-quality class-level representation.
Specifically, the σ is power normalized [22] to properly up-date the cosine-similarity-refined prototype, enhancing the significance of descriptors that are similar to intrinsic rep-resentations. The activations produced by our method high-light salient features across support samples, leading to im-proved class-level representation, as shown in Figure 1 (d).
For the second one, as analysed by the DeFRCN [33], there are potential contradictions between the Region Pro-posal Network (RPN) and the Detection Head (DH), which may lead to reduced FOSD power. DeFRCN, a fine-turning based method, alleviates conflicts through a gradient de-coupled layer. For our meta-learning-based detector, we decouple the prototype into task-specific ones in the spirit of divide-and-conquer. The task-agnostic prototype is di-vided, and each one plays a specific role in conquering the where to look and what to look for. This allows our proto-type learning to purposefully target inconsistent goals, re-sulting in precise guidance information.
Beyond satisfying those two requirements, we find our model gradually allows the encoding network (EN) to fo-cus on generic features and factor out outliers across a set of support samples during the training stage. So, the gener-alization power of EN is strengthened and we can directly utilize the basic average-pooled prototype at the inference stage. We theoretically analyse prioritizing the samples with small σ can speed up the process of prototype learn-ing. And the EN’s generalization power is strengthened by raising the lower bound of the optimal prototype. Extensive experiments demonstrate that our model achieves state-of-the-art results, especially on the FSOD dataset without meta fine-tuning on novel classes, which conforms to our model’s generalization ability.
In summary, we propose the σ-Adaptive Decoupled Pro-totype, which includes (i) a novel σ-Adaptive Prototype for robust class-level representations, and (ii) the decou-pled task-specific prototypes to provide precise guidance for query detection. We call our approach σ-ADP and its resultant network σ-ADP Net. 2.