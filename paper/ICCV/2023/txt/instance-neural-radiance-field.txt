Abstract
This paper presents one of the ﬁrst learning-based NeRF 3D instance segmentation pipelines, dubbed as Instance
Neural Radiance Field, or Instance-NeRF. Taking a NeRF pretrained from multi-view RGB images as input, Instance-NeRF can learn 3D instance segmentation of a given scene, represented as an instance ﬁeld component of the NeRF model. To this end, we adopt a 3D proposal-based mask prediction network on the sampled volumetric features from
NeRF, which generates discrete 3D instance masks. The coarse 3D mask prediction is then projected to image space to match 2D segmentation masks from different views gen-erated by existing panoptic segmentation models, which are used to supervise the training of the instance ﬁeld. No-tably, beyond generating consistent 2D segmentation maps from novel views, Instance-NeRF can query instance infor-mation at any 3D point, which greatly enhances NeRF ob-ject segmentation and manipulation. Our method is also one of the ﬁrst to achieve such results in pure inference.
Experimented on synthetic and real-world NeRF datasets with complex indoor scenes, Instance-NeRF surpasses pre-vious NeRF segmentation works and competitive 2D seg-mentation methods in segmentation performance on un-seen views. Code and data are available at https:// github.com/lyclyc52/Instance_NeRF. 1.

Introduction
Neural Radiance Field (NeRF) [32] has become the mainstream approach to novel view synthesis nowadays.
Given multi-view images with camera poses only, NeRF encodes the underlying scene in a multi-layer perceptron (MLP) by radiance propagation and generates very impres-sive results. Thus, subsequent to NeRF’s debut in [32] lot of works have made great progress in improving the qual-ity [10, 45], efﬁciency [33, 53, 3] and generality [55, 49].
*Equal contribution.
†This research is supported in part by the Research Grant Council of the Hong Kong SAR under grant no. 16201420.
Input NeRF
Extracted RGB
Density
Instance Field 2D Segmentation
Matching
Figure 1: Pipeline of Instance-NeRF, demonstrated on the 3D-FRONT dataset. Instance-NeRF takes a pre-trained NeRF as input to detect objects within the scene and utilizes existing 2D panoptic segmentation to generate 2D segmentation maps, which are then matched and used to supervise the instance ﬁeld training.
This excellent approach to associate 2D with 3D through radiance ﬁeld leads us to rethink the 3D instance segmenta-tion problem. Unlike the 2D counterpart operating on plenty of training images, 3D instance segmentation is limited by both the quantity and quality of the available data. Previ-ously, 3D segmentation still relies on RGB-D images [21] or point clouds [36, 37, 46, 50, 41] captured by depth sen-sors or custom equipment as input, which are inconvenient to obtain and contain a variety of noises. To mitigate the dependence on explicit 3D geometry, there have been sev-eral investigations on embedding NeRF for addressing fun-damental problems such as 3D semantic segmentation [56] and scene manipulation [26]. Existing unsupervised meth-ods such as [30, 54, 39] also involve 3D scene decomposi-tion and instance segmentation, but it is hard to apply them on complex and large scenes akin to real world cases.
In this paper, inspired by NeRF-RPN [22] and Mask-RCNN [17], we propose Instance-NeRF for 3D instance segmentation in NeRF. Unlike semantic segmentation, where a single object in different views should be labeled as the same class consistently, most instance segmenta-tion methods do not enforce consistency over instance IDs in different views, making direct supervision of instance
ID less applicable. To address this issue, we propose a 2D mask matching procedure that links each 2D instance mask to its 3D instance to resolve inconsistency. More speciﬁcally, we incorporate NeRF-RPN with a mask head to predict 3D coarse segmentation. After projecting the attained 3D masks back to 2D, Instance-NeRF leverages
Mask2Former [6] and CascadePSP [7] to match the same instance in 2D segmentation from different views and reﬁne the resultant masks. The reﬁned 2D segmentation of multi-view images will be used to train an instance ﬁeld which encode 3D instance information in a continuous manner as a neural ﬁeld.
Our major contributions are:
• One of the ﬁrst signiﬁcant attempts to perform 3D in-stance segmentation in NeRF without using ground-truth segmentation as input.
• Propose the architecture and training approach of an
Neural Instance Field, which can produce multi-view consistent 2D segmentation as well as continuous 3D segmentation using NeRF representation.
• Perform experiments and ablation studies on a syn-thetic indoor NeRF dataset to demonstrate the ef-fectiveness of our method, which surpasses competi-tive 2D segmentation methods and previous works in
NeRF segmentation. 2.