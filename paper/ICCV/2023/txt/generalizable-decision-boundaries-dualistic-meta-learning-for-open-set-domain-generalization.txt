Abstract
Domain generalization (DG) is proposed to deal with the issue of domain shift, which occurs when statistical differ-ences exist between source and target domains. However, most current methods do not account for a common realistic scenario where the source and target domains have different classes. To overcome this deficiency, open set domain gener-alization (OSDG) then emerges as a more practical setting to recognize unseen classes in unseen domains. An intuitive approach is to use multiple one-vs-all classifiers to define decision boundaries for each class and reject the outliers as unknown. However, the significant class imbalance between positive and negative samples often causes the boundaries biased towards positive ones, resulting in misclassification for known samples in the unseen target domain. In this paper, we propose a novel meta-learning-based framework called dualistic MEta-learning with joint DomaIn-Class match-ing (MEDIC), which considers gradient matching towards inter-domain and inter-class splits simultaneously to find a generalizable boundary balanced for all tasks. Experimen-tal results demonstrate that MEDIC not only outperforms previous methods in open set scenarios, but also maintains competitive close set generalization ability at the same time.
Our code is available at https://github.com/zzwdx/MEDIC. 1.

Introduction
Deep neural networks have achieved enormous success in a wide range of computer vision tasks, usually assuming that the training and test samples are drawn from the same data distribution and label space. However, due to the un-*Corresponding author: Yinghuan Shi. Xiran Wang, Jian Zhang and
Yinghuan Shi are with the State Key Laboratory for Novel Software Tech-nology and National Institute of Healthcare Data Science, Nanjing Univer-sity, China. Lei Qi is with the School of Computer Science and Engineering,
Southeast University, China. This work is supported by NSFC Program (62222604, 62206052, 62192783), China Postdoctoral Science Founda-tion Project (2023T160100), Jiangsu Natural Science Foundation Project (BK20210224), and CCF-Lenovo Bule Ocean Research Fund.
Figure 1. An example for the variation of decision boundaries of a one-vs-all classifier in open set domain generalization. predictability of real-world application scenarios, the model faces the risk of performance degradation when the above constraints are not satisfied [26]. Domain generalization (DG) [46] is then motivated as a more realistic setting to deal with data distribution shift, which refers to using multiple source domains via data augmentation [29,53], feature align-ment [10, 27], meta-learning [23, 25] and so on, to obtain a model with the generalization ability that can be directly applied to arbitrary unseen target domains.
Most current domain generalization researches are based on the assumption of close set recognition, i.e., the classes in the source domains are consistent with that of the target domains. However, in practice, the deployed model is often exposed to some new classes that have never been encoun-tered in the training phase [40]. For example, in self-driving tasks, thousands of objects are fed into the model that the known label space cannot guarantee complete coverage of them; in medical image processing tasks, some diseases are extremely rare that it is unrealistic to acquire their samples for training. According to the logic of close set classifica-tion, these potential objects are forced to be identified into a known class, which lays hidden dangers for the modelâ€™s ro-bustness and security. To address this problem, it is necessary to investigate a more practical setting of open set domain gen-eralization (OSDG), which focuses on recognizing unknown classes without losing the original classification accuracy.
In open set domain generalization [21, 43], the key is to concurrently deal with the problems of domain shift and category shift. We now turn our attention to a simple yet elegant learning paradigm, meta-learning [19], which has
shown its effectiveness in addressing domain shift. Previous research on meta-learning-based DG [23] and OSDG [43] aims to find an optimal balance between different domains through implicit gradient matching between tasks sampled from them. This domain-wise meta-learning helps prevent the model from becoming overly biased towards individual ones. The rest issue is how to effectively model the category shift. A natural idea is to use a multi-binary classifier [30,39], which comprises multiple one-vs-all binary classifiers, to de-fine a decision boundary for each known class. If a given sample is classified as negative by all sub-classifiers, it is considered to have a high probability of belonging to the unknown classes. However, we found this issue is non-trivial because the one-vs-all classifier in multi-classification tasks can generate biased predictions. As shown in Fig. 1, due to the limited data distribution of positive samples (i.e., from the corresponding class) and the diverse data distribution of negative samples (i.e., from all of the other classes), the classifier may asymmetrically focus on the negative ones which are easier to optimize. This can cause the decision boundary to cling to the positive samples, leading to inac-curate identification of known class samples in the unseen target domain. Conversely, if the decision boundary is too far away from the positive samples, the model can be prone to predicting an excessive quantity of target samples as known, hindering the recognition performance of unknown classes.
To establish a well-balanced decision boundary between classes, we attempt to fully exploit the gradient matching property of meta-learning. In contrast to the domain-wise strategy, we additionally sample tasks by classes to make the decision boundary rationally lying at the middle zone of each class. As a result, unknown samples are more likely to be distributed near the decision boundary, making them easier to be recognized. Concretely, we mitigate the limitation in previous works that merely select tasks by domains [38, 42] and propose a novel meta-learning strategy called dualistic
MEta-learning with joint DomaIn-Class matching (MEDIC).
For tasks selected from different domains, we further divide them at category level. By matching the gradients of these di-vided tasks, we expect the model not only to generalize well across domains, but also to grasp the class-wise relationship more precisely. Furthermore, with the help of an auxiliary multi-binary classifier [30, 39], the model can automatically learn decision boundaries for each individual class. 2.