Abstract
Skeleton-based action recognition has attracted consid-erable attention due to its compact representation of the human body’s skeletal sructure. Many recent methods have achieved remarkable performance using graph con-volutional networks (GCNs) and convolutional neural net-works (CNNs), which extract spatial and temporal fea-tures, respectively. Although spatial and temporal depen-dencies in the human skeleton have been explored sep-arately, spatio-temporal dependency is rarely considered.
In this paper, we propose the Spatio-Temporal Curve Net-work (STC-Net) to effectively leverage the spatio-temporal dependency of the human skeleton. Our proposed net-work consists of two novel elements: 1) The Spatio-Temporal Curve (STC) module; and 2) Dilated Kernels for Graph Convolution (DK-GC). The STC module dynam-ically adjusts the receptive field by identifying meaning-ful node connections between every adjacent frame and generating spatio-temporal curves based on the identified node connections, providing an adaptive spatio-temporal coverage.
In addition, we propose DK-GC to consider long-range dependencies, which results in a large recep-tive field without any additional parameters by applying an extended kernel to the given adjacency matrices of the graph. Our STC-Net combines these two modules and achieves state-of-the-art performance on four skeleton-based action recognition benchmarks. Code is available at https://github.com/Jho-Yonsei/STC-Net. 1.

Introduction
Action recognition is one of the most important video understanding tasks used in various applications such as virtual reality and human–computer interaction. Recent studies on action recognition are divided into two methods,
RGB-based [33, 31] and skeleton-based methods [36, 26, 27, 2, 4, 16]. Action recognition using the skeleton modality (a) Spatio-Temporal GCN (b) Spatio-Temporal Curve Network
Figure 1. Comparison of temporal flows of spatio-temporal GCN (a) and STC module of our model (b). (b)’s curves have adaptive spatio-temporal receptive field by aggregating different nodes for different frames, whereas (a) treats the temporal features of each node independently. receives a video sequence with the three-dimensional coor-dinates of major human joints as its input. Skeleton-based action recognition has the advantage of being able to cre-ate a lightweight model with low computational complexity by compactly compressing the structure of the human body.
In addition, it has the benefit of robustness in that it is not affected by background noise, weather, and lighting condi-tions unlike RGB-based methods.
Earlier approaches [7, 8, 38, 14, 23] extract features by dealing with every joint independently, which means that they do not consider information between structurally cor-related human joints. However, the connections between human joints are identified as a graph structure after Yan et al. [36] has proposed spatio-temporal graph convolutional networks (GCNs) for the skeleton modality. Recent ap-proaches [27, 4, 2, 6] adopt the GCNs as their baseline and attempt to enlarge the receptive field on the spatial domain.
However, methods based on Yan et al.’s GCNs have sev-eral limitations. (1) When a person performs an action, the movement of their body parts occurs in both space and time, and these two aspects of the movement are inherently in-terconnected. While incorporating both spatial and tem-poral components can provide a more complete and accu-rate representation of human actions, it is not feasible to directly utilize this spatio-temporal interconnectivity as the spatial and temporal modules exist independently of each other. (2) As they use graphs that include only the connec-tivity of physically adjacent joints, their networks with such graphs have small spatial receptive fields. Although several self-attention methodologies [27, 2] have been proposed to increase the spatial receptive field, they still rely on using physically adjacent graphs, which can lead to biased results towards those physically adjacent graphs and highlight a potential limitation in their effectiveness. To handle this problem, Liu et al. [21] has proposed a multi-scale graph that identifies the relationship between structurally distant nodes. However, as stated by Yan et al. [36], although it is crucial to differentiate human motion into concentric and eccentric patterns, Liu et al.’s method does not account for such patterns. Additionally, Liu et al.’s model suffers from the limitation of having high model complexity, as there are too many operations parallelly existing in a single layer.
To solve limitation (1), we propose a Spatio-Temporal
Curve (STC) module to reflect direct spatio-temporal de-pendencies in a skeleton sequence.
In addition to apply-ing temporal convolution to aggregate node-wise sequential features, we construct curves that consider the sequential spatio-temporal features for every node and aggregate them with input feature map. To create the curves, we choose the most highly correlated nodes in feature space between all adjacent frames and connect them. Therefore, a more se-mantically effective graph structure can be adaptively gen-erated by giving autonomy to the temporal connections be-tween nodes. Fig. 1 compares the temporal flows of the spatio-temporal GCN for existing methods [36, 27, 2] and our proposed method. Fig. 1 (a) shows that the model re-flects only the features of the same nodes in every frame, while Fig. 1 (b) shows that the model considers the spatio-temporal correlations through the generated curves that take account of features of different nodes in adjacent frames.
Inspired by [35], we use an aggregation module to effec-tively combine all the curve features and apply them to the input feature map.
To handle limitation (2), we propose Dilated Kernels for
Graph Convolution (DK-GC) to have large spatial receptive field for skeletal modality without any additional parame-ters. The GCNs for the human skeleton aggregate inward-facing (centripetal), identity, and outward-facing (centrifu-gal) features, unlike convolutional neural networks (CNNs), which aggregate left, identity, and right pixels features. To apply the dilated kernel to such GCNs, we create adja-cency matrices to identify structurally distant relationships by modifying centripetal and centrifugal matrices. To incor-porate spatial receptive fields from low-level to high-level, we divide the spatial module into several branch operations with different dilated windows. Meanwhile, dilated graph convolution has already been introduced by Li et al. [17] for 3D point clouds analysis task. However, Li et al.’s di-lated graph convolution is completely different from what we propose and is not suitable for human skeletal modality.
Firstly, this method does not utilize the given adjacency ma-trices, but instead uses dynamic graph via k-nearest neigh-borhood (k-NN) algorithm. The inability to utilize the given adjacency matrices reduces the robustness for the action recognition model as Shi et al. [27] experimentally has proven that not using those matrices leads to inferior per-formance. Moreover, the k-NN alone cannot identify all the physically adjacent nodes. The second reason is that Li et al.’s method requires a lot of GPU resources. It causes very high GPU memory consumption and low inference speed since the dynamic graphs are constructed by computing all pairwise distances between all the nodes for every GCN layer.
To verify the superiority of our STC-Net, exten-sive experiments are conducted on four skeleton-based action recognition benchmark datasets: NTU-RGB+D 60 [25], NTU-RGB+D 120 [18], Kinetics-Skeleton [12], and Northwestern-UCLA [32].
Our main contributions are summarized as follows:
•
•
•
We propose the Spatio-Temporal Curve (STC) module to leverage the direct spatio-temporal correlation be-tween different nodes of different frames.
We propose the Dilated Kernels for Graph Convolu-tion (DK-GC) that makes the model have a large spa-tial receptive field without any additional parameters by modifying the given skeletal adjacency matrices.
Our proposed STC-Net outperforms existing state-of-the-arts methods on four benchmarks for skeleton-based action recognition. 2.