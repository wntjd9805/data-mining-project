Abstract
Aiming at crafting a single universal adversarial pertur-bation (UAP) to fool CNN models for various data sam-ples, universal attack enables a more efficient and accu-rate evaluation for the robustness of CNN models. Early universal attacks craft UAPs depending on data priors.
For more practical applications, the data-free universal at-tacks that make UAPs from random noises have aroused much attention recently. However, existing data-free UAP methods perturb all the CNN feature layers equally via the maximization of the CNN activation, leading to poor transferability.
In this paper, we propose a novel data-free universal attack without depending on any real data samples through truncated ratio maximization, which we term as TRM-UAP. Specifically, different from the maxi-mization of the positive activation in convolution layers, we propose to optimize the UAP generation from the ra-tio of positive and negative activations. To further en-hance the transferability of universal attack, TRM-UAP not only performs the ratio maximization merely on low-level generic features via the truncation strategy, but also in-corporates a curriculum optimization algorithm that can effectively learn the diversity of artificial images. Exten-sive experiments on the ImageNet dataset verify that TRM-UAP achieves a state-of-the-art average fooling rate and excellent transferability on different CNN models as com-pared to other data-free UAP methods. Code is available at https://github.com/RandolphCarter0/TRMUAP. 1.

Introduction
Early research [26] shows that tiny and imperceptible perturbations can seriously disturb the prediction results of deep neural networks (DNNs), especially for image recog-nition tasks [3]. Adversarial Examples (AEs), crafted by adding tiny perturbations deliberately to benign samples,
*Corresponding Author: Di Ming are not only imperceptible in computer vision tasks but also prone to transfer among the DNN models. Therefore, AEs have been regarded as a serious threat to DNN models since the development of deep learning [1].
To explore the impact of AEs, many methods are pro-posed to craft the adversarial perturbation that is highly transferable to various DNN models (i.e., with a high fool-ing rate on other DNN models). However, the AEs gener-ated by these works are explicitly designed for some spe-cific samples and often fail to perturb other samples that are even from the same dataset. Different from the afore-mentioned image-specific attack, the universal attack that generates image-agnostic universal adversarial perturbation (UAP) was proposed in [16]. The UAP in a universal attack setting is trained from prior knowledge, such as substitute data, surrogate model, etc. By adding the UAP to benign samples, universal attacks can generate numerous AEs all together in a very short period. Furthermore, the universal attack can fool most DNN models that are trained from sim-ilar datasets, and can greatly reduce the computational cost of crafting AEs, making adversaries more applicable to real scenarios than the image-specific attacks [4, 6, 34].
Whereas, no matter the image-specific attacks or the uni-versal attacks, well-annotated training data (e.g., [21, 9, 7]) or substitute data (e.g., [16, 12, 22, 19]) is required to gen-erate AEs. In practice, obtaining a well-labeled large-scale dataset is challenging and costly, especially for some ap-plications with critical security demand, where less prior knowledge is available. Recently, researchers have inves-tigated data-free universal attack methods [18, 17, 14, 20, 33], where AEs are generated directly from random noises rather than data priors. Compared with previous methods that disturb the gradient or maximize the classification loss in data-dependent scenarios, current data-free UAP meth-ods explore the feature-based perturbation, which tries to maximize the activation (e.g., ReLU) of convolutional neu-ral network (CNN) features. It is shown that feature-based
UAP methods achieved highly efficient and applicable uni-versal attack without using any data priors [4, 6, 34]. How-ever, current data-free UAP methods only consider the pos-itive activation [18, 17] and perturb all layers of CNN fea-tures equally [20, 14]. As a result, UAPs crafted by surro-gate models are hard to transfer to target models [6, 34].
Towards enhancing the transferability of data-free UAPs, we propose a novel data-free universal attack method called
TRM-UAP, which formulates the UAP generation as a trun-cated ratio maximization problem. In particular, TRM-UAP attempts to over-fire positive neurons so that extracted fea-tures from multiple CNN layers can be fully disrupted. Be-sides the maximization of positive neurons, the proper ac-tivation on negative neurons may also be helpful. Hence,
TRM-UAP performs a ratio maximization of positive and negative activations, which facilitates some negative neu-rons transiting to be positive. Moreover, some feature-based adversarial attacks [29, 35] reveal that multiple layers of CNN features are not equally important for disturbing the image classification [11, 28]. To further improve the transferability of universal attack, TRM-UAP performs ra-tio maximization only on parts of CNN activation layers.
Specifically, a truncation strategy is proposed to truncate the activation of high-level convolutions and retain the ac-tivation of shallow convolutions to train perturbations. The intuition is that low-level CNN features are shown to pro-vide more generic (data-independent) feature representa-tions than high-level semantic features [30]. Thus the dis-turbed low-level features are expected to be able to trans-fer attacks across different CNN models, leading to highly transferable UAPs. Furthermore, a curriculum learning [2] based optimization algorithm is introduced to utilize artifi-cial images and explore the diversity of input.
In general, the main contributions of our work can be summarized as follows:
• We propose a novel data-free universal attack method to craft image-agnostic adversarial perturbations with-out utilizing any real data samples during training.
• To the best of our knowledge, we are the first to for-mulate the data-free universal attack as a truncated ra-tio maximization problem. The proposed TRM-UAP enhances the transferability of UAPs from three per-spectives: (i) the maximization on CNN features for crafting UAPs is enhanced by both maximization of positive activation and minimization of negative acti-vation. (ii) the ratio maximization on truncated fea-ture layers improves the generalizability of universal attacks to CNN models. (iii) artificial images are in-corporated into curriculum optimization algorithm to strengthen the UAP dominance on feature activations.
• Extensive experiments on the ImageNet dataset show that TRM-UAP obtains the highest average fooling rate compared with other data-free UAP methods, in-dicating that truncated ratio maximization can greatly improve the transferability of universal attack. 2.