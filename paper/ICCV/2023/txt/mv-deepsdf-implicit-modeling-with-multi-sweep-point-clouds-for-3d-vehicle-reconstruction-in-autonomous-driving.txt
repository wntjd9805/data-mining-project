Abstract
Reconstructing 3D vehicles from noisy and sparse par-tial point clouds is of great significance to autonomous driving. Most existing 3D reconstruction methods can-not be directly applied to this problem because they are elaborately designed to deal with dense inputs with triv-ial noise.
In this work, we propose a novel framework, dubbed MV-DeepSDF, which estimates the optimal Signed
Distance Function (SDF) shape representation from multi-sweep point clouds to reconstruct vehicles in the wild. Al-though there have been some SDF-based implicit model-ing methods, they only focus on single-view-based recon-struction, resulting in low fidelity. In contrast, we first an-alyze multi-sweep consistency and complementarity in the latent feature space and propose to transform the implicit space shape estimation problem into an element-to-set fea-ture extraction problem. Then, we devise a new architecture to extract individual element-level representations and ag-gregate them to generate a set-level predicted latent code.
This set-level latent code is an expression of the optimal 3D shape in the implicit space, and can be subsequently de-coded to a continuous SDF of the vehicle. In this way, our approach learns consistent and complementary information among multi-sweeps for 3D vehicle reconstruction. We con-duct thorough experiments on two real-world autonomous driving datasets (Waymo and KITTI) to demonstrate the su-periority of our approach over state-of-the-art alternative methods both qualitatively and quantitatively. 1.

Introduction 3D vehicle reconstruction from sparse and partial point clouds is a fundamental need in the autonomous driving industry [12, 17].
It aims to infer the 3D structure of vehicles at arbitrary resolutions in the wild, which is of great significance to many downstream tasks in autonomous driving. Despite the many 3D reconstruction methods
Figure 1. An illustration of the motivation of the proposed ap-proach. Our approach takes multi-sweep point clouds as input and simplifies 3D vehicle reconstruction from multi-sweeps into an element-to-set feature extraction problem. In this way, we infer an optimal estimation of the 3D shape described in the abstract im-plicit space for 3D vehicle reconstruction in autonomous driving.
[28, 35, 26, 39, 41, 1, 19, 4], most of them focus on image-based inputs [28, 35, 26, 39, 41], dense point cloud inputs
[19, 31, 11], or their combination [1, 4, 9] and thus, cannot be directly applied to this problem.
Recently, [12] has shown promising performance in ap-plying implicit modeling to tackle this problem. Contrary to explicit modeling methods [32, 33, 47, 49, 43, 42, 10, 2, 38] that directly represent 3D object shape structure with points, voxels, or meshes, implicit modeling maps the 3D shape to a low-dimensional latent space and learns the projection from the latent space to a continuous function that describes the 3D shape. This presents two significant advantages: 1) the 3D shape can be stored as a low-dimensional memory-saving latent code [31, 11, 12, 6]; 2) the trained network outputs a continuous function in the 3D space which sup-ports mesh extraction at any resolution [31]. To this end, we also choose to employ implicit modeling in our approach.
However, previous point cloud-based implicit model-ing methods [31, 11, 12] mainly focus on recovering 3D shapes from a single-view partial point cloud and fail to leverage the multi-sweep information of vehicles. As a re-sult, when noise or annotation errors exist in an individual sweep, single-view methods usually produce low fidelity re-In real-world datasets (e.g., [36, 15]), multi-sweep sults.
Figure 2. The framework of the proposed MV-DeepSDF. Farthest Point Sampling (FPS) [33] is applied to the raw point clouds for pre-processing and DeepSDF [31] is employed to generate a latent code for each observation. We then extract global features from the standardized point clouds (refer to yellow block) and concatenate the global features with the latent codes as element-level representations.
Next, the element-level representations are transformed into a set-level predicted latent code (refer to red block). Finally, we employ a pre-trained DeepSDF decoder [31] to project the predicted latent code to the SDF of the vehicle in 3D space and recover the 3D mesh.
Note that the decoder used in the final step (refer to white trapezoid) is identical to that of DeepSDF (refer to green block). point clouds are usually available and contain richer shape information because of the various viewing angles offered by multiple observations [17]. Although there are some existing 3D reconstruction methods from multi-view point clouds [17, 19, 3, 34], implicit modeling with multi-sweep point clouds remains an unsolved problem.
In this work, we propose a novel framework, dubbed
MV-DeepSDF, to exploit multi-sweep point clouds and im-plicitly generate high-fidelity 3D reconstructions of vehi-cles for autonomous driving. An illustration of the moti-vation for our proposed approach is depicted in Figure 1.
Specifically, to shed light on the importance of exploring multi-sweep point clouds for 3D vehicle reconstruction, we first analyze multi-sweep consistency and complementarity in the latent feature space. We then propose to consider the problem of shape estimation in the implicit space as an element-to-set feature extraction problem, where a set rep-resents a collection of multi-sweeps and an element repre-sents a sparse and partial point cloud. Next, we devise a new architecture to simultaneously extract a global feature and latent code for each element in the multi-sweep and concatenate them as element-level representations. These element-level representations are then transformed into a set-level predicted latent code with the aid of average pool-ing and mapping. This set-level latent code is an optimal estimation of the 3D shape described in the abstract implicit space, which we subsequently decode to a continuous SDF of the vehicle with a pre-trained DeepSDF decoder [31] and recover the 3D mesh from the SDF. The contributions of this work are threefold:
• We analyze multi-sweep consistency and complemen-tarity in the latent feature space and transform the problem of shape estimation in the implicit space into an element-to-set feature extraction problem. This simplifies 3D vehicle reconstruction from multi-sweep point clouds into an optimal estimation of the 3D shape described in the abstract implicit space.
• We propose a novel MV-DeepSDF framework (see
Figure 2) for implicit modeling with multi-sweep point clouds. A new architecture is constructed to extract the element-level representations and generate the set-level predicted latent code.
• We qualitatively and quantitatively demonstrate the su-perior performance of our approach over the state-of-the-art alternative methods through extensive experi-ments on real-world datasets [36, 15]. 2.