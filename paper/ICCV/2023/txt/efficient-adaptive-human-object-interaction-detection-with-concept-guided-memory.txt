Abstract
Human Object Interaction (HOI) detection aims to lo-calize and infer the relationships between a human and an object. Arguably, training supervised models for this task from scratch presents challenges due to the perfor-mance drop over rare classes and the high computational cost and time required to handle long-tailed distributions of HOIs in complex HOI scenes in realistic settings. This observation motivates us to design an HOI detector that can be trained even with long-tailed labeled data and can leverage existing knowledge from pre-trained models. In-spired by the powerful generalization ability of the large
Vision-Language Models (VLM) on classification and re-trieval tasks, we propose an efficient Adaptive HOI De-tector with Concept-guided Memory (ADA-CM). ADA-CM has two operating modes. The first mode makes it tun-able without learning new parameters in a training-free paradigm. Its second mode incorporates an instance-aware adapter mechanism that can further efficiently boost per-formance if updating a lightweight set of parameters can be afforded. Our proposed method achieves competitive re-sults with state-of-the-art on the HICO-DET and V-COCO datasets with much less training time. Code can be found at https://github.com/ltttpku/ADA-CM . 1.

Introduction
Human-object interaction (HOI) detection is essential for comprehending human-centric scenes at a high level.
Given an image, HOI detection aims to localize human and object pairs and recognize their interactions, i.e. a set of <human, object, action> triplets. Recently, vision
Transformers [41], especially the DEtection TRansformer (DETR) [1], have started to revolutionize the HOI detection task. Two-stage methods use an off-the-shelf detector, e.g.
*Corresponding author
DETR, to localize humans and objects concurrently, fol-lowed by predicting interaction classes using the localized region features. One-stage methods usually leverage the pre-trained or fine-tuned weights and architecture of DETR to predict HOI triplets from a global image context in an end-to-end manner.
Despite the progress, most previous methods still face two major challenges in solving the HOI detection task.
First, annotating HOI pairs requires considerable human effort. Therefore, the model may experience data scarcity when encountering a new domain. Even with the availabil-ity of ample data, the combinatorial nature of HOIs exacer-bates challenging scenarios such as recognizing HOI classes from long-tailed distributions. While people can efficiently learn to recognize seen and even unseen HOI from limited samples, most previous methods [19, 39, 28] suffer a sig-nificant performance drop on rare classes as shown in Fig-ure 1(a). Second, training or fine-tuning an HOI detector can contribute to high computational cost and time as shown in Figure 1(b)1. Training two-stage methods involves ex-haustively combining instance-level features to predict pair-wise relationships. In constast, training one-stage HOI de-tectors that adopt the architecture of DETR model can be challenging due to the heavy reliance on transformers [31].
According to the challenges mentioned above, our goal is to build an efficient adaptive HOI detector resilient to im-balanced data, which can not only adapt to a target dataset without training but also quickly converge when fine-tuning.
To deal with the problem of lacking labeled data in a target HOI visual domain, we propose a training-free ap-proach with a concept-guided memory module that pro-vides a balanced memory mechanism for all HOI classes.
The concept-guided memory module leverages not only the domain-specific visual knowledge, but also the domain-1We exclude the training time for pre-training or fine-tuning the object detector since all methods follow the same protocal to pre-train or fine-tune the object detector.
can work well in a training-free manner and can effectively detect rare HOI classes.
Moreover, to quickly adapt to new domains, we pro-pose to unfreeze the properly initialized concept-guided cache memory and inject lightweight residual instance-aware adapters at spatial sensitive feature maps during training. Specifically, unfreezing the cache memory enables the model to select which knowledge is highlighted or sup-pressed dynamically for the HOI task. Since many valuable cues for the HOI detection task may appear from the early spatial-aware and fine-grained feature maps, we propose to early inject prior knowledge into low-level feature maps to capture the local geometric spatial structures required for pair-wise relationship detection. During fine-tuning, while the instance-aware adapters are tailored to facilitate HOI un-derstanding given instance-level prior knowledge, the ex-plicit concept-guided memory mechanism can help alle-viate forgetfulness of rare HOI classes as shown in Fig-ure 1(a). Furthermore, Figure 1(b) demonstrates that our network can achieve the best performance by training for a few epochs with fast convergence speed.
Contributions. Our key idea is to design a HOI detector that leverages knowledge from pre-trained vision-language models and can be adapted to new domains via training-free or fine-tuning. Our work brings three contributions: (1) To the best of our knowledge, we are the first to pro-pose a training-free human-object interaction detection ap-proach, by constructing a balanced concept-guided mem-ory that leverages domain-specific visual knowledge and domain-agnostic semantic knowledge. (2) We demonstrate that unfreezing the properly initialized cache memory and injecting lightweight residual instance-aware adapters at spatial sensitive feature maps during train-ing further boost the performance. (3) Our approach achieves competitive results on VCOCO
[10] and state-of-the-art on HICO-DET [2] dataset by train-ing for a few epochs with fast convergence speed. 2.