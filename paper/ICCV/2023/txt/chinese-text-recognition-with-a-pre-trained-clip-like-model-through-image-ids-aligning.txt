Abstract
Scene text recognition has been studied for decades due to its broad applications. However, despite Chinese characters possessing different characteristics from Latin characters, such as complex inner structures and large categories, few methods have been proposed for Chinese
Text Recognition (CTR). Particularly, the characteristic of large categories poses challenges in dealing with zero-shot and few-shot Chinese characters.
In this paper, inspired by the way humans recognize Chinese texts, we propose a two-stage framework for CTR. Firstly, we pre-train a CLIP-like model through aligning printed character images and Ideographic Description Sequences (IDS). This pre-training stage simulates humans recognizing Chinese characters and obtains the canonical representation of each character. Subsequently, the learned representations are employed to supervise the CTR model, such that traditional single-character recognition can be improved to text-line recognition through image-IDS matching. To evaluate the effectiveness of the proposed method, we conduct extensive experiments on both Chinese character recognition (CCR) and CTR. The experimental results demonstrate that the proposed method performs best in CCR and outperforms previous methods in most scenarios of the CTR bench-It is worth noting that the proposed method can mark. recognize zero-shot Chinese characters in text images without fine-tuning, whereas previous methods require fine-tuning when new classes appear. The code is available at https://github.com/FudanVI/FudanOCR/tree/main/image-ids-CTR. 1.

Introduction
In recent decades, most researchers have focused on ex-ploring Chinese character recognition (CCR) [13, 25, 40, 37, 41], few methods are dedicated to tackle Chinese Text
*Corresponding Author
Figure 1. Comparison between the framework of previous methods (a) and that of the proposed method (b). The data flow of the pre-training stage is in red.
Recognition (CTR). Unlike Latin characters, Chinese char-acters have a large number of categories and complex in-ternal structures, which lead to zero-shot (i.e., characters in test sets are unseen in training sets) and few-shot problems in practical applications. The conventional framework for
CTR should be fine-tuned with the updated alphabet when a new Chinese character appears. However, humans are able to easily match unseen character images with the cor-responding characters in their stsndard (e.g. printed) forms.
Thus, the question is – Can a model recognize Chinese texts like humans?
To tackle the zero-shot problem, existing CCR meth-ods rely on predicting radical or stroke sequences to rec-ognize characters. For example, some radical-based meth-ods [32, 31] are proposed to decompose Chinese characters at the radical level and predict corresponding radical se-quences to determine final predicted characters. Recently, a stroke-based method [5] has been proposed to decompose
Chinese characters into stroke sequences, offering a funda-mental solution to the zero-shot problem in CCR. These methods are based on relatively complex networks so that
they are not suitable for adoption in CTR models to solve zero-shot and few-shot problems. In addition, most scene text recognition models [15, 21] adopt an encoder-decoder framework, which utilizes a fully connected layer to clas-sify characters (as shown in Figure 1(a)). However, these methods require to be fine-tuned when a new character ap-pears, which is inconvenient in practical applications. Fur-thermore, these methods fail to account for the aforemen-tioned unique characteristic of Chinese characters.
For native Chinese speakers, their initial learning is to recognize individual Chinese characters. In this stage, they also learn how to decompose each Chinese character into the corresponding radical sequence. When reading a text line, they first locate the position of each character and then compare it with the standard characters they have learned to determine its category. For unseen characters, people can use their knowledge of radicals and structures to deduce their categories.
Inspired by the way humans recognize Chinese texts, we propose a two-stage framework (as shown in Figure 1(b)) to address the challenge of CTR. The proposed framework consists of a CCR-CLIP pre-training stage and a CTR stage.
In the first stage, we introduce a CLIP-like model, named
CCR-CLIP, to learn the canonical representations of Chi-nese characters through aligning printed character images and their corresponding Ideographic Description Sequences (i.e., radical sequences) in an embedding space. Simi-lar to CLIP [24], the CCR-CLIP model comprises an im-age encoder and a text encoder, and is trained with a con-trastive loss between embeddings of character images and embeddings of radical sequences. To ensure that the im-age encoder extracts features that are independent of font styles, we also introduce a contrastive loss between input images having the same label in a training batch. After pre-training, the text encoder can output the canonical repre-sentations of given radical sequences.
In the CTR stage, the learned canonical representations are employed to su-pervise the CTR model, which is a conventional encoder-decoder framework without a fully connected layer after the decoder. During inference, the model predicts each charac-ter in a text image by calculating the similarity between the learned canonical representations and the extracted charac-ter embedding. Thus, it is able to recognize zero-shot Chi-nese characters without fine-tuning. We conduct extensive experiments to validate the effectiveness of the proposed method. Specifically, we train the CCR-CLIP model on several Chinese character recognition benchmarks to evalu-ate its performance on CCR. The experimental results show that the CCR-CLIP model can robustly recognize Chinese characters in zero-shot settings. Furthermore, our experi-ments on a CTR benchmark demonstrate that the proposed method outperforms previous methods in most cases.
In summary, our contributions are as follows:
Figure 2. Twelve basic structures represented in blue lines (left) and an example of decomposition at the radical level (right).
Figure 3. Five categories of strokes for Chinese characters (left) and some examples of decomposition at the stroke level (right).
• Drawing inspiration from how humans recognize Chi-nese texts, we propose a two-stage framework for
CTR, which comprises a CCR-CLIP pre-training stage and a CTR stage.
• We adopt the CLIP architecture to establish a CCR-CLIP pre-trained model to learn the canonical repre-sentations of Chinese characters.
• Benefiting from the learned canonical representations, the proposed method can recognize zero-shot charac-ters in Chinese text images without fine-tuning.
• Extensive experiments validate that the CCR-CLIP model outperforms previous CCR methods by a clear margin. Furthermore, the proposed two-stage frame-work for CTR achieves better performance than previ-ous methods, particularly when training data is scarce. 2. Preliminaries 2.1.