Abstract
In this paper, we study the problem of end-to-end multi-person pose estimation. State-of-the-art solutions adopt the
DETR-like framework, and mainly develop the complex de-coder, e.g., regarding pose estimation as keypoint box detec-tion and combining with human detection in ED-Pose [38], hierarchically predicting with pose decoder and joint (key-point) decoder in PETR [27].
We present a simple yet effective transformer approach, named Group Pose. We simply regard K-keypoint pose es-timation as predicting a set of N × K keypoint positions, each from a keypoint query, as well as representing each pose with an instance query for scoring N pose predictions.
Motivated by the intuition that the interaction, among across-instance queries of different types, is not directly helpful, we make a simple modification to decoder self-attention. We replace single self-attention over all the
N × (K + 1) queries with two subsequent group self-attentions: (i) N within-instance self-attention, with each over K keypoint queries and one instance query, and (ii) (K +1) same-type across-instance self-attention, each over
N queries of the same type. The resulting decoder re-moves the interaction among across-instance type-different queries, easing the optimization and thus improving the per-formance. Experimental results on MS COCO and Crowd-Pose show that our approach without human box supervi-sion is superior to previous methods with complex decoders, and even is slightly better than ED-Pose that uses human box supervision. Paddle 1 and PyTorch 2 codes are avail-able. 1.

Introduction
Multi-person pose estimation aims to detect the corre-sponding human keypoints for all human instances in an
*Equal Contribution. Work done when H. Liu is an intern at Baidu.
†Corresponding author. Email: yzhao@bjtu.edu.cn 1Code of Paddle: https://github.com/Michel-liu/GroupPose-Paddle 2Code of PyTorch: https://github.com/Michel-liu/GroupPose
Figure 1: Comparison of transformer decoders. Here we mainly illustrate the overview of the decoder part of PETR [27], ED-Pose [38], and our Group Pose. The three end-to-end frameworks differ in query design and decoder architecture. Group Pose only uses a simple transformer decoder rather than developing complex decoders. ‘inst’ and ‘kpt’ represent for instance and keypoint. image. Previous frameworks include top-down [25, 6, 35, 4, 29, 33] and bottom-up methods [1, 24, 12, 5] that di-vide the task into two sequential sub-tasks: human detec-tion with single-person pose estimation or human-agnostic keypoint detection with human instance grouping [24].
Another line in previous frameworks is one-stage meth-ods [22, 26, 31, 34], which directly predict instance-aware keypoints. These frameworks rely on non-differentiable hand-crafted post-processes [10, 24], which complicate the pipelines and challenge the optimizations. Inspired by the success of DETR [2] in object detection, building an end-to-end framework for multi-person pose estimation has seen significant interest.
Recent approaches follow the DETR framework [2, 41, 39], with the transformer encoder-decoder architecture for multi-person pose estimation, as shown in Figure 1.
PETR [27] hierarchically predicts the keypoint positions and uses two subsequent decoders, pose decoder and joint decoder, with two different queries, pose query (a person has one pose query) for pose decoder, and keypoint queries for joint decoder. ED-Pose [38] transfers pose estimation to a keypoint box detection problem, and learns a content query and a box query for each keypoint position prediction
with using the box size to process the query. 2.