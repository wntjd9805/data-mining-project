Abstract
CNN’s limited receptive ﬁeld restricts its ability to capture long-range spatial-temporal dependencies, lead-ing to unsatisfactory performance in video super-resolution (VSR). To tackle this challenge, this paper presents a novel multi-frequency representation enhancement module (MFE) that performs spatial-temporal information aggre-gation in the frequency domain. Speciﬁcally, MFE mainly includes a spatial-frequency representation enhancement branch which captures the long-range dependency in the spatial dimension, and an energy frequency representation enhancement branch to obtain the inter-channel feature re-lationship. Moreover, a novel model training method named privilege training is proposed to encode the privilege infor-mation from high-resolution videos to facilitate model train-ing. With these two methods, we introduce a new VSR model named MFPI, which outperforms state-of-the-art methods by a large margin while maintaining good efﬁciency on var-ious datasets, including REDS4, Vimeo, Vid4, and UDM10. 1.

Introduction
Video super-resolution (VSR), which restores high-resolution (HR) video frames from their highly related but unaligned low-resolution (LR) video frames, is well-desired in various real-world applications [11, 2]. Compared with single image super-resolution (SISR), VSR is much more challenging as it aggregates information from multiple re-lated but misaligned frames in the input video. Hence, an ideal VSR model is expected to leverage the spatial infor-mation from single images but also integrate the temporal
* The ﬁrst two authors contribute equally. This work is done during the internship of F. Li in Samsung. (cid:2) Z. Li is the corresponding author.
Figure 1: VSR performance comparison on UDM10 [65] in terms of PSNR (dB), runtime (ms), and parameters (M).
MFPI outperforms SOTA methods with high efﬁciency. semantic features from multiple frames [45, 50, 18, 3].
CNN-based models have become the standard choice for VSR due to their simplicity and efﬁciency. While re-cent advances in CNN-based VSR, such as residual learn-ing [2, 73], dense connections[59], hierarchical structures
[20], and multi-scale frameworks [63, 34, 48], have shown impressive performance, some potential problems still ex-ist. Firstly, CNN’s limited receptive ﬁeld hinders it from modeling long-range spatial dependencies, making it un-able to capture complex semantic information. Secondly, convolutional ﬁlters have ﬁxed scales and weights, limit-ing their performance on large motions and adaptability to diverse inputs.
In comparison, with the advantages of self-attention layers, ViTs are effective in processing inputs with long-term spatial dependencies. However, the stack
of self-attention layers is accompanied with a large compu-tation budget, which results in inferior inference efﬁciency on edge devices [29]; A natural question arises: can CNNs capture long-range dependencies like ViTs?
In this paper, we propose to answer this question from a frequency perspective. Thanks to their ability to capture global representation, frequency-based models have been widely utilized in single image processing [72, 41, 71].
Unfortunately, their performance in video super-resolution (VSR) is usually limited due to several reasons. (1) Com-pared with single images, videos are composed of multiple related but misaligned images, which contain both spatial and temporal information. However, traditional frequency methods have ﬁxed paradigms and coefﬁcients [56, 66, 40], making them not able to capture the complex information in videos. (2) Traditional frequency methods are sensitive to the noise in images [64, 14]. This disadvantage becomes more fatal in videos where the noise of different frames can be accumulated.
To address these challenges, we propose a novel mod-ule named multi-frequency representation enhancement (MFE), which aggregates information in the frequency do-main. Unlike convolutional and self-attention layers that operate in the feature space, MFE directly manipulates the energy feature map in the frequency domain through three branches: 1) a spatial-frequency representation enhance-ment branch (SFE) that utilizes a Fast Fourier Transform (FFT) and large kernel convolution layer to capture arbitrary interactions among spatial and long-range dependent fea-tures, 2) an energy-frequency representation enhancement branch (EFE) that employs a novel energy discrete cosine transform (DCT) to improve representation and explore po-tentially useful frequency components, and 3) a pair of con-volution layers that leverage large kernels to obtain global range-interact features with stronger shape bias. Compared with the previous frequency methods, the learnable ﬁlter in SFE enables FFT to capture both spatial and temporal information, and the energy function in EFE can alleviate the noise accumulated in multiple video frames. Moreover,
MFE only contains 0.02M parameters, making it affordable for edge devices.
Besides MFE, we further propose a novel model train-ing method named privilege training (PT) to facilitate the training of VSR models. Motivated by previous research in learning using privilege information (LUPI) [53], we propose to apply a trainable encoding module to encode the privilege information from HR videos and then employ them to obtain a good initialization for VSR models. Sufﬁ-cient experiments demonstrate the effectiveness of privilege training on both our model and the other VSR models.
With MFE and privilege training, we introduce a novel
VSR model referred to as MFPI. Extensive experimental results have demonstrated that MFPI outperforms eighteen previous methods by a clear margin in six VSR benchmarks.
For instance, on UDM10, compared with BasicVSR++ [4], which has similar parameters and runtime with MFPI, MFPI achieves 0.36 dB higher PSNR improvements on UDM10
BD degradation, as shown in Figure 1. To sum up, the main contributions in this paper can be summarized as follows:
• We propose multi-frequency representation enhance-ment (MFE), a module that effectively aggregates in-formation in the frequency domain by operating the spatial- and energy-frequency components.
• We propose privilege training, which encodes the priv-ilege information from the HR videos to boost the per-formance of VSR models.
• Abundant experiments demonstrate the effectiveness of MFPI on four datasets, including REDS4, Vimeo,
Vid4, and UDM10 in both BI and BD degradation. 2.