Abstract
Federated learning has gained recognitions as a secure approach for safeguarding local private data in collabo-rative learning. But the advent of gradient inversion re-search has posed significant challenges to this premise by enabling a third-party to recover groundtruth images via gradients. While prior research has predominantly focused on low-resolution images and small batch sizes, this study highlights the feasibility of reconstructing complex images with high resolutions and large batch sizes. The success of the proposed method is contingent on constructing an over-parameterized convolutional network, so that images are generated before fitting to the gradient matching require-ment. Practical experiments demonstrate that the proposed algorithm achieves high-fidelity image recovery, surpassing state-of-the-art competitors that commonly fail in more in-tricate scenarios. Consequently, our study shows that local participants in a federated learning system are vulnerable to potential data leakage issues. Source code is available at https://github.com/czhang024/CI-Net. 1.

Introduction
Federated learning (FL) [16, 17, 20] provides a dis-tributed paradigm that enables multiple parties to coopera-tively learn a shared model. The primary premise of such a learning scheme is to tackle apprehensions concerning data privacy and security, by permitting users to upload their lo-cal gradients instead of the raw data.
But yet, this purported property of data privacy pro-tection has recently come under scrutiny, as evidenced by several works [37, 35, 32] that question the possibility of recovering hidden data from uploaded gradients. Stud-*Corresponding author: Liangli Zhen (zhenll@ihpc.a-star.edu.sg). ies [7, 11] provided affirmative evidence to this question by demonstrating the feasibility of reconstructing training im-ages through a process known as “gradient inversion”. Such a process involves the use of some randomly generated im-ages, and iteratively computes the discrepancy between the gradients of the generated image and the true values. It then adjusts the pixel values in the direction of minimizing such a discrepancy, until the generated image gradients match the target gradients to a satisfactory degree.
The success of these inversion works is often contin-gent upon certain stringent assumptions: the underlying groundtruth images should possess low image resolutions and small batch sizes. A compelling counterexample to this is that attempting gradient inversion for batch sizes larger than 4 on datasets like CIFAR-10 turns out to be ardu-ous [35]. For more complex datasets like ImageNet, images recovery for large batch sizes would be even more challeng-ing [31]. But real-world participants of federated learning systems typically employ significantly larger batch sizes, for instance, 64 on CIFAR-10 and 16 on ImageNet, dur-ing local model training. As consequences, the inversion of gradients in such scenarios poses a significant challenge for these algorithms.
Lying ahead is the issue of nested gradients. Typically, local clients in an FL system only transmit an averaged gra-dient to the server, rather than the gradient of each individ-ual image. Decoupling these averaged gradients presents an arduous task since random decomposition may only lead to a set of noisy gradients. An ideal algorithm would be capa-ble of properly decoupling the averaged gradient in a correct way such that each gradient would act as a proxy for some natural image as expected.
The conventional approach to address the gradient cou-pling issue involves incorporating some image priors. For example, a study in [7] introduced a total variation term to penalize images with high variations, while the work [31]
employed multiple fidelity regularizations. But in this pa-per, we shall highlight that the inclusion of these additional regularization terms may alter the fundamental properties of the original problem, thereby raising concerns about whether the groundtruth images indeed trigger the minimal loss.
The goal of this research is to present an alternative ap-proach to gradient inversion that does not rely on image pri-ors. Drawing inspiration from a recent study [11, 33], we propose an over-parameterized generative algorithm specif-ically designed for gradient inversion. The proposed algo-rithm takes into account three crucial factors in the gradient inversion problem: (i) an over-parameterized network to en-sure that image generation and gradient matching have an non-empty intersection, (ii) a convolutional network to mit-igate gradient matching to noise and (iii) a well-designed architecture to facilitate pixel-level intimacy. Leveraging these factors, we introduce the Convolutional Inversion Net-work (CI-Net), an over-parameterized network that offers a novel method for gradient matching without requiring prior information.
Numerical experiments demonstrate that the proposed algorithm exhibits superior performance in broader scenar-ios, including those involving large batch sizes and high-resolution images. Our proposed network, denoted as
“CI-Net”, outperforms state-of-the-art (SOTA) competitors, which generally struggle under such conditions. For exam-ple, when evaluated on the CIFAR 10 dataset with a batch size of 128 images, our proposed CI-Net achieves a mean peak signal-to-noise ratio (PSNR) of 31.40, surpassing its closest competitor, which only attains a mean PSNR value of 11.05. Moreover, the proposed algorithm has minimal pre-requisites for pre-training or prior knowledge concern-ing the data distribution, thereby enabling its use in a “plug and play” manner. Such a property renders the proposed method more practical for gradient inversion cases in which we have limited knowledge on the local data. 2.