Abstract
Learning semantic segmentation requires pixel-wise an-notations, which can be time-consuming and expensive. To reduce the annotation cost, we propose a superpixel-based active learning (AL) framework, which collects a dominant label per superpixel instead. To be specific, it consists of adaptive superpixel and sieving mechanisms, fully ded-icated to AL. At each round of AL, we adaptively merge neighboring pixels of similar learned features into super-pixels. We then query a selected subset of these super-pixels using an acquisition function assuming no uniform superpixel size. This approach is more efficient than ex-isting methods, which rely only on innate features such as
RGB color and assume uniform superpixel sizes. Obtain-ing a dominant label per superpixel drastically reduces an-notators’ burden as it requires fewer clicks. However, it inevitably introduces noisy annotations due to mismatches between superpixel and ground truth segmentation. To ad-dress this issue, we further devise a sieving mechanism that identifies and excludes potentially noisy annotations from learning. Our experiments on both Cityscapes and PAS-CAL VOC datasets demonstrate the efficacy of adaptive su-perpixel and sieving mechanisms. 1.

Introduction
With the advent of deep learning, many computer vi-sion tasks including semantic segmentation have dramati-cally evolved in recent years. Such advances are thanks to complex deep network models that can learn huge datasets.
However, labeling such large datasets is prohibitively time-consuming and labor-intensive, in particular, for semantic segmentation tasks that demand a dense annotation on each pixel [8, 11]. Active learning (AL) offers an approach to al-leviate the annotation cost by selectively querying only the most informative samples to annotators.
Designing an effective form of annotation query is crit-*Corresponding author. (a) Over-segmented (t = 0) (b) Adaptive merged (t = 2) (c) Adaptive merged (t = 4) (d) Oracle
Figure 1: Examples of adaptive superpixels. (a) We begin active learning with over-segmented superpixels. (b, c) In each round t, we merge superpixels in an adaptive manner using the model from the previous round. (d) As the round progresses, adaptive superpixels look similar to oracle ones. ical in practice as it determines the actual annotation cost such as the number of clicks required and the informative-ness per annotation query. For semantic segmentation, an image-wise query can be asked for a complete annotation on the semantic of every pixel in an image [9, 10, 34, 38, 40].
This is a daunting task requiring an enormous amount of clicks to indicate boundaries (using polygons or contours) for each semantic segment or to annotate semantic pixel-wisely, while the diversity of contexts which we can observe in a single image is restricted. Alternatively, one can design a region-based query enquiring only about the dominant la-bel of a small region such as rectangle patch [5, 27, 37] or superpixel [4, 33]. This is known to be simple yet effective as it requires only a single click per query while enabling
AL to put more focus on significant regions and to avoid annotation wastes.
AL with the region-based query needs a delicate genera-tion of candidate regions to be queried. A small region size dilutes the budget efficiency, whereas the dominant label-ing even by a perfect annotator is prone to give noisy labels
Figure 2: An overview of the proposed framework. In each round t, we merge superpixels with a graph using the latest model, and obtain dominant labels for selected superpixels. The dominant labels are selectively propagated to pixels with confidence above the detected knee point, resulting in the creation of a sieved dataset. Finally, we train a model with the sieved one. when regions are too large to be consisting of pixels with a single class. However, the previous works [5, 27, 33] rely on a fixed candidate set of regions of uniform size, while we could adjust the size and shape of candidate regions as we train the semantic segmentation model over rounds of AL.
This limitation remains even in recent work [4] with super-pixel candidates providing less risk of noisy labels than rect-angle ones since the superpixels are produced, only at the beginning, by a conventional superpixel algorithm, where conventional superpixel algorithms [1, 32, 35] cluster ad-jacent pixels of similar innate features (e.g., color) with implicit or explicit regularization to make similar sizes or shapes of superpixels, i.e., limited freedom of query region.
In this paper, to fully enjoy the benefit in terms of anno-tation cost while suppressing the risk of noisy labels, we de-vise an AL framework, illustrated in Figure 2, consisting of adaptive merging and sieving methods. The adaptive merg-ing method repeatedly evolves the candidate superpixels for dominant labeling at every round with the latest model and no explicit regularization on the size and shape of superpix-els. This indeed enables the continual improvement of the superpixels’ ability to accurately capture the boundaries of semantic objects (Figure 1b and 1c), and a proper variation in the sizes and shapes of superpixels, i.e., larger superpix-els being attached to larger semantic objects (e.g., road and building) and smaller ones to smaller objects (e.g., human and vehicle) as shown in the ideal ones (Figure 1d).
Given the adaptive superpixels, we establish a corre-sponding acquisition function being aware of irregular su-perpixel sizes.
It prioritizes uncertain superpixels of rare classes in order to query the most informative superpixels while balancing class distributions in the entire annotations.
In addition, to alleviate the inevitable noise in the dominant labeling, we propose a sieving technique that excludes la-beled pixels of high potential risks of being different classes than the dominant one. To be specific, we identify such pix-els of potentially noisy labels by per-superpixel sieving with distinct thresholds over superpixels. This provides stabler denoising than uniform sieving with a constant threshold, which might aggravate class imbalance in the sieved anno-tations.
Through the integration of adaptive merging and siev-ing into an AL framework, we achieve improved accuracy and budget-efficiency over a baseline method. Notably, the merging demonstrates effectiveness under small-sized su-perpixels, while the sieving plays a critical role given large-sized superpixels. Moreover, we show a consistent im-provement over existing methods in various settings. We provide a thorough justification of the proposed method using various quantitative measures, where we introduce a new evaluation metric for superpixel algorithms that as-sesses both (achievable) accuracy and recall, where the re-call is overlooked in the existing one, the achievable seg-mentation accuracy (ASA) [22] but important in the context of AL. This may give new insights into developing super-pixel algorithms.
Our main contributions are summarized as follows:
• We propose an adaptive merging algorithm where su-perpixels are updated at each round (Section 3.2), and show the effectiveness of adaptive merging rather than only merging once (Section 4.2).
• We alleviate the side effect of noisy labels via a sieving technique (Section 3.3), and demonstrate especially ef-ficient under large superpixels (Section 4.2).
• In various realistic experiments, we demonstrate the consistent improvement of the proposed AL frame-work, consisting of the adaptive merging and sieving methods with the dedicated acquisition function, over existing ones (Section 4.2).
• We provide an insightful analysis on proper superpix-els for AL with the new evaluation metric of superpixel algorithms being aware of usage in AL (Section 5.1).
2.