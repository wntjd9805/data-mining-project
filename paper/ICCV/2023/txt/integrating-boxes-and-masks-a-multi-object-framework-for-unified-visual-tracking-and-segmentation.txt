Abstract
Tracking any given object(s) spatially and temporally is a common purpose in Visual Object Tracking (VOT) and
Video Object Segmentation (VOS). Joint tracking and seg-mentation have been attempted in some studies but they of-ten lack full compatibility of both box and mask in initial-ization and prediction, and mainly focus on single-object scenarios. To address these limitations, this paper pro-poses a Multi-object Mask-box Integrated framework for unified Tracking and Segmentation, dubbed MITS. Firstly, the unified identification module is proposed to support both box and mask reference for initialization, where de-tailed object information is inferred from boxes or directly retained from masks. Additionally, a novel pinpoint box predictor is proposed for accurate multi-object box pre-diction, facilitating target-oriented representation learning.
All target objects are processed simultaneously from encod-ing to propagation and decoding, as a unified pipeline for
VOT and VOS. Experimental results show MITS achieves state-of-the-art performance on both VOT and VOS bench-marks. Notably, MITS surpasses the best prior VOT com-petitor by around 6% on the GOT-10k test set, and sig-nificantly improves the performance of box initialization on VOS benchmarks. The code is available at https:
//github.com/yoxu515/MITS. 1.

Introduction
Visual object tracking (VOT) [57, 23, 32, 33] and video object segmentation (VOS) [63, 84, 79, 37] are two critical tasks in computer vision. Visual object tracking involves identifying and tracking specific object(s) in a video stream over time. Video object segmentation aims to segment given object(s) in a video sequence and separate it from the back-ground. Both tasks are essential for applications such as video surveillance and autonomous driving.
†Yuanyou Xu worked on this at his Baidu Research internship.
‡Yi Yang is the corresponding author.
Figure 1. We propose a Multi-object Mask-box Integrated frame-work for unified Tracking and Segmentation (MITS). Compared with VOT or VOS methods, our framework integrates both boxes and masks for initialization and prediction in a unified manner, without any extra model for box-to-mask conversion, and supports processing multiple objects simultaneously for VOT and VOS.
In VOT, object sizes and positions are indicated with boxes as box representation, while in VOS object shapes and contours are marked with pixel-level masks as mask representation. Despite their differences, VOT and VOS share similarities. Both tasks require the ability to identify and locate the target object in a video stream accurately in spatial dimension, and to be robust against challenges such as occlusion and fast motion in temporal dimension.
In view of the similarity, tracking and segmentation may have unified multi-knowledge representations [90] and have been explored jointly in some works. 1) Unification. A straightforward solution is to perform conversion between boxes and masks to utilize VOT methods on VOS or VOS methods on VOT. A mask can be converted to a box easily, but generating a mask from a box is hard. Some methods were proposed to address the box-to-mask estimation prob-lem [47, 88, 101]. However, separate but not unified models hinder end-to-end training and are inconvenient to manage in practical applications. 2) Compatibility. Several studies have attempted to unify these two tasks into a single frame-work. However, some of them [78, 75, 62] still lack compat-ibility and flexibility in box/mask input/output and resort to extra models. 3) Multi-Object. Despite that some methods
[48, 81, 86] possess strong compatibility across VOT and
VOS, they mainly focus on the single object scenario and use an ensemble strategy to aggregate the separate result of each object in the multiple object scenario.
Therefore, this paper aims to unify VOS and VOT and improve above shortcomings by integrating boxes and masks in a multi-object framework as Multi-object Inte-grated Tracking and Segmentation (MITS), as shown in Fig-ure 1. For compatibility problem, a unified identification module is proposed to take both reference boxes in VOT and masks in VOS for initialization. The unified identifi-cation module encodes the reference boxes or masks into the unified identification embedding by assigning identi-ties to objects. The coarse identification embedding from boxes is further refined to mitigate the gap between mask and box initialization. The unified identification module is more convenient than borrowing an extra model because it is trained with the whole model in an end-to-end manner.
Besides, the novel pinpoint box predictor is proposed for joint training and prediction with the mask decoder. Previ-ous corner head or center head estimates a box by corners or a center point, which are not have to be inside the object.
Emphasizing exterior points may distract learning target-oriented features and affect the mask prediction. To address this problem, we estimate the box by localizing pinpoints, which are always on the edge of the object. However, di-rectly supervise the learning of pinpoints is infeasible due to the lack of annotation. Therefore we perform decoupled aggregation on the pinpoint maps and determine the box only by side-aligned pinpoint coordinates.
All the modules in our framework are not only compat-ible with two tasks, but also able to process multiple ob-jects simultaneously. The multi-object training and predic-tion make our framework efficient and robust under com-plex scenes with multiple objects. Extensive experiments are conducted to demonstrate the strong compatibility and capacity of our framework. Experimental results show that our framework achieves SOTA performance on VOT bench-marks including LaSOT [23], TrackingNet [57] and GOT-10k [32], and VOS benchmark YouTube-VOS [84]. Our method improves 6% over previous SOTA VOT method on
GOT-10k, and significantly improves the performance of box initialization on VOS benchmarks.
In summary, our contributions are:
• We present a multi-object framework integrating boxes and masks for unified tracking and segmentation.
• The unified identification module is proposed to accept both masks and boxes for initialization.
• A novel pinpoint box predictor is proposed for accurate box prediction together with the mask decoder. 2.