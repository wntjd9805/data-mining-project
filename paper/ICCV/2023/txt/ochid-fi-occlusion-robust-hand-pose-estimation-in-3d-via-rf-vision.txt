Abstract
Hand Pose Estimation (HPE) is crucial to many appli-cations, but conventional cameras-based CM-HPE meth-ods are completely subject to Line-of-Sight (LoS), as cam-eras cannot capture occluded objects.
In this paper, we propose to exploit Radio-Frequency-Vision (RF-vision) ca-pable of bypassing obstacles for achieving occluded HPE, and we introduce OCHID-Fi as the first RF-HPE method with 3D pose estimation capability. OCHID-Fi employs wideband RF sensors widely available on smart devices (e.g., iPhones) to probe 3D human hand pose and extract their skeletons behind obstacles. To overcome the chal-lenge in labeling RF imaging given its human incompre-hensible nature, OCHID-Fi employs a cross-modality and cross-domain training process. It uses a pre-trained CM-HPE network and a synchronized CM/RF dataset, to guide the training of its complex-valued RF-HPE network under
LoS conditions. It further transfers knowledge learned from labeled LoS domain to unlabeled occluded domain via ad-versarial learning, enabling OCHID-Fi to generalize to un-seen occluded scenarios. Experimental results demonstrate the superiority of OCHID-Fi: it achieves comparable accu-racy to CM-HPE under normal conditions while maintain-ing such accuracy even in occluded scenarios, with empiri-cal evidence for its generalizability to new domains. 1.

Introduction
We have witnessed tremendous efforts put into Com-puter Vision (CV) research in the past decade, driven by applications such as facial recognition [37, 45], hand pose estimation [24, 38], object detection [14, 57], and aug-mented/virtual reality [16, 53]. Among various sensing technologies behind CV, Optical Vision (OV) has so far been the dominant path, fuelled by the widely available OV devices (i.e., cameras, lidars) and large-scale datasets [10, 18]. However, OV often suffers from a few major limiting
*Equal contribution. https://github.com/DeepWiSe888/OCHID-Fi
Figure 1. Unlike CM-HPE models, OCHID-Fi can extract 3D hand keypoints behind occlusions (b-d). Note that the wrist and the position of the hand are shown here only as an example. In the actual experiment, the hand can be fully occluded and its position can vary. Drawn outlines here are for illustration purposes only. factors: it requires Line-of-Sight (LoS) [10, 18] and certain lighting conditions [4, 46], it is prone to background clut-ter [17, 40], and is challenged by privacy concerns [1, 3].
Motivated by these shortcomings, non-optical vision technologies have also been explored in the CV commu-nity [7,11,28–30,43,47,48,52,54,55], among which Radio-Frequency-vision (RF-vision) stands out in many aspects including low complexity (thus real-time responsiveness), energy efficiency, and ready deployability [8, 29]. These strengths have motivated the use of RF-vision for problems previously tackled by OV [30, 43, 52]. However, one of the biggest strengths of RF-vision, i.e., occlusion robustness, has only been lightly touched by RF-Pose [52], for coarse-grained human pose estimation trained only in LoS domain and used directly in obstructed scenarios without account-ing for the impact of the obstacles that create occlusion.
In this paper, we focus on utilizing RF-vision to per-form fine-grained 3D Hand Pose Estimation (HPE) for oc-cluded scenes. It is important to distinguish RF-HPE from
RF-enabled Hand Gesture Recognition (RF-HGR) [42, 56]:
While the former requires a more detailed understanding of hand keypoints [24, 39, 49], the latter only performs ba-sic classification tasks. As a result, RF-HPE is highly non-trivial and we summarize three major challenges:
• Non-Euclidean Mapping of Keypoints: RF data does not enjoy a direct Euclidean mapping from signal space to keypoint locations. It is hence difficult for a deep learning model to uncover the intrinsic relations.
• We perform extensive experiments to validate that, in occluded scenes where OV fails completely, OCHID-Fi achieves similar accuracy to that of CM-HPE in LoS conditions. Our empirical results also demonstrate that
OCHID-Fi generalizes to unseen occluded scenes.
• Model Design for Low-resolution, Complex-valued
RF data: CM-HPE models cannot process low-resolution complex-valued RF data, while RF-HGR models are designed exclusively for classification while RF-HPE is inherently a regression task.
• Model Training for Occluded Scenes: RF data in oc-cluded scenes are significantly affected by reflection and refraction caused by the obstacles. It is highly non-trivial to design a training mechanism for an RF-HPE model in such scenarios.
To address these challenges, we propose OCHID-Fi, the first 3D RF-HPE model capable of extracting 3D hand key-points behind full occlusion. To provide a taste of what
OCHID-Fi can achieve, we plot the outputs of OCHID-Fi and a state-of-the-art CM-HPE solution (Google MediaPipe
Hands [49]) for a clear comparison in Figure 1. Trained in cross-modality and cross-domain manner, OCHID-Fi ex-ploits RF-vision to tackle the occlusion issue where CM-HPE fails. OCHID-Fi translates RF signals to hand key-points through cross-modality training aided by a pre-trained CM-HPE model. Specifically, OCHID-Fi employs a synchronized pair of camera and RF sensor during data collection in LoS scenarios. The CM-HPE network is first trained with pseudo ground truth collected by the Opti-Track [25] system, and then we transfer its learned knowl-edge to OCH-Net by supervising OCH-Net together with the RF ground truth data. To handle the complex-valued
RF data, a deep complex-valued network is specifically de-signed to perform feature extraction. While completing the first training stage allows the deep complex-valued network
OCH-Net (OCcluded Hand-Net) to work independently un-der LoS situation, the second stage training OCH-AL (OC-cluded Hand-Adversarial Learning) is performed to further transfer knowledge across domains (from LoS to occluded), for which we leverage adversarial learning in an unsuper-vised manner. In summary, our major contributions are:
• To the best of our knowledge, OCHID-Fi is the first occlusion-robust 3D RF-HPE model.
• OCHID-Fi transfers the knowledge from the OV to the
RF, effectively bridging the gap between complex RF-vision data and hand keypoints.
• OCH-Net is proposed as the complex-valued RF-HPE model to fit RF signals, making it possible to fully ex-ploit the intrinsic RF features.
• OCH-AL leverages adversarial learning in an unsuper-vised manner, so as to further transfer knowledge from the LoS domain into the occluded one. 2.