Abstract
Time
Time
Time
High-speed cameras are an indispensable tool used for the slow-motion analysis of scenes. However, the fixed bandwidth of any imaging system quickly becomes a bot-tleneck, resulting in a fundamental trade-off between the camera’s spatial and temporal resolutions. In recent years, compressive high-speed imaging systems have been pro-posed to circumvent these issues by optically encoding the signal and using a reconstruction procedure to recover a video. Our work proposes a novel approach for com-pressive high-speed imaging based on temporally coding the camera’s point-spread function (PSF). By mechanically spinning a diffraction grating in front of a camera, the sen-sor integrates an image blurred by a PSF that continuously rotates over time. We also propose a deconvolution-based reconstruction algorithm to reconstruct videos from these measurements. Our method achieves superior light effi-ciency and handles a wider scene class than prior meth-ods. Also, our mechanical design yields flexible temporal resolution that can be easily increased, potentially allow-ing capture at 192 kHz—far higher than prior works. We demonstrate a prototype for various applications, including motion capture and particle image velocimetry (PIV). 1.

Introduction
The world is full of high-speed events that are imper-ceptible to both the human eye and most conventional cam-eras (e.g., the flicker of electric lights or the motion of fast-moving objects). The traditional approach to capturing such events is using slow-motion photography, i.e., use a camera to shoot images at a high frame rate and display the results at a lower frame rate. Slow-motion photography is often used for artistic effects in film and as a measurement tool in scientific applications. However, despite significant ad-vancements in sensor technology, conventional high-speed cameras tend to be expensive, bulky, and have high through-put requirements for recording visual content at both high frame rates and high spatial resolutions. These hardware limitations set an upper limit to the cameras’ capture rates.
Capture long exposure frame with rotating PSF
Long exposure
R e c o n s t r u c t i o n
Time
Time
Time
Recover high-speed video
Figure 1. Principle of high-speed imaging with a rotating diffraction grating. A camera captures a long exposure image of a moving scene. During the camera’s exposure period, the diffrac-tion grating placed in front of the camera continuously rotates to generate a time-varying point-spread function (PSF) that encodes scene dynamics into a single frame. Solving a deconvolution prob-lem yields a high-speed video from the captured frame.
Compressed sensing provides a framework to circum-vent such issues. Since videos are highly compressible, it is possible to recover a video from a single snapshot by (i) compressively recording spatiotemporal visual information onto a sensor and (ii) solving a reconstruction problem to re-cover the video using priors on the visual content. Among the large body of work in compressive high-speed imag-ing, most techniques temporally modulate the light incident on sensor pixels [48, 12, 20, 22, 9, 34, 32, 35, 14, 16, 19,
13, 49], either through the use of a spatial light modula-tor (SLM) or novel sensors capable of turning pixels on or off. Alternatively, by using spatial-multiplexing optics (e.g., diffusers, diffraction gratings) to distribute light from any scene point to many camera pixels, it is possible to perform high-speed imaging by using a rolling shutter [2, 50, 26], a reduced region-of-interest (ROI) [39], or a line sensor [40].
Our work proposes a fundamentally different approach to compressive high-speed imaging. Similar to past works that make use of spatial-multiplexing optics, we propose to distribute light across a sensor by using a dual-axis diffrac-tion grating, which diffracts light horizontally and vertically (see Fig. 1). Unlike prior work, however, we opt to change the point-spread function (PSF) during the camera’s expo-sure period. Specifically, we use a motor to mechanically rotate the PSF at high speeds, record a single global-shutter frame, and solve a simple deconvolution-based reconstruc-tion procedure to reconstruct scene dynamics. Please refer to Fig. 1 for an overview of the process.
Our approach, like past work using spatial-multiplexing optics [2, 50, 40, 39], is primarily targeted towards spa-This imaging regime in-tiotemporally sparse scenes. cludes motion capture and particle-image velocimetry (PIV), which see broad application in domains like biome-chanics [29], sports science [31], animation and film-making [38], virtual and augmented reality [5], aerody-namics [47], fluid mechanics [36], biomedical engineer-ing [18], oceanography [7], and combustion and engine re-search [28]. We demonstrate our approach for motion cap-ture and PIV in Sec. 6. Other potential applications for spatiotemporally sparse video include high-speed 3D scan-ning [24] and capturing the fast flicker of electric bulbs [41].
Our approach combines four key advantages over exist-ing methods targeting spatiotemporally sparse scenes: (I) Superior light efficiency.
In many prior methods, the scene light is dispersed using specialized optics to reach many camera pixels, but only a small subset of camera pix-els collect light at each timestamp [2, 40, 39, 50]. Thus, most light is lost by falling outside the ‘active’ pixels. Con-versely, in our work, the signal from different timestamps is encoded by different temporal PSFs, and the entire sensor is left exposed, yielding far superior light efficiency. We show this advantage in simulated experiments in Sec. 3. (II) Easily increasable temporal resolution.
In most prior works, temporal resolution (i.e., FPS) is fundamen-tally limited by the speed of the respective technology (e.g., the modulation speed of a SLM/sensor [12, 22, 34, 32, 14, 49], or the read-out speed of a camera [2, 40, 39, 50, 9]).
In contrast, the temporal resolution of our approach is de-termined by the mechanical rotation speed and thus can be easily increased by rotating the PSF faster. Thus, we show that our approach can resolve a LED flickering at 96 kHz. (III) A wider class of supported scenes. Prior works using spatial-multiplexing optics allocate a fixed amount of pixels for each timestamp (e.g., a single rolling shutter row) [2, 40, 39, 50]. This limits the amount of informa-tion recoverable per frame, imposing a spatial sparsity con-straint on each high-speed frame individually. Instead, our solution multiplexes the signals from different timestamps together, yielding a sparsity constraint over the entire video.
Our method can thus handle temporally sparse but spatially dense scenes, verified in simulated and real experiments. (IV) Simple hardware. While many prior works require specialized optics (e.g., SLMs [12, 34, 49], piezoelectric stages [20, 16, 19]) or specialized sensors (e.g., coded ex-posure pixels [22, 14, 32]), our setup can work with any global-shutter camera combined with simple low-cost hard-ware that is readily available at your local hobby store. We include a DIY guide as part of our supplementary materials. 2.