Abstract 1.

Introduction
While impressive progress has recently been made in image-oriented facial attribute translation, shape-oriented 3D facial attribute translation remains an unsolved issue.
This is primarily limited by the lack of 3D generative mod-els and ineffective usage of 3D facial data. We propose a learning framework for 3D facial attribute translation to relieve these limitations. Firstly, we customize a novel geometric map for 3D shape representation and embed it in an end-to-end generative adversarial network. The geometric map represents 3D shapes symmetrically on a square image grid, while preserving the neighboring rela-tionship of 3D vertices in a local least-square sense. This enables effective learning for the latent representation of data with different attributes. Secondly, we employ a uni-ﬁed and unpaired learning framework for multi-domain at-tribute translation.
It not only makes effective usage of data correlation from multiple domains, but also mitigates the constraint for hardly accessible paired data. Finally, we propose a hierarchical architecture for the discrimina-tor to guarantee robust results against both global and lo-cal artifacts. We conduct extensive experiments to demon-strate the advantage of the proposed framework over the state-of-the-art in generating high-ﬁdelity facial shapes.
Given an input 3D facial shape, the proposed framework is able to synthesize novel shapes of different attributes, which covers some downstream applications, such as ex-pression transfer, gender translation, and aging. Code at https://github.com/NaughtyZZ/3D facial shape attribute tr anslation ssgmap.
∗The corresponding author
Figure 1. Translation of 3D shape attributes to multiple domains that correspond to expressions, genders, and ages.
The advancement of generative adversarial networks (GANs) has recently activated a lot of studies on face-related tasks, such as face synthesis [34, 7], facial im-age super-resolution [38, 32], and facial attribute transla-tion [13, 1]. The rationale of these studies is to use an auxil-iary discriminator network to regularize the output face with the learned distribution of facial data towards a speciﬁc cat-egory. The task of facial attribute translation is referred to as changing the particular aspect of a facial image, e.g. chang-ing the expression [19] or the age [61] of a face, resulting in desired appearances. This task has many downstream ap-plications in the media and ﬁlm industry.
In the past, most methods in the ﬁeld of facial attribute translation dealt with 2D facial images [11, 51, 55]. This is partly because 2D facial images are easily accessible and partly because deep learning based methods commonly work on image data with a regular grid. Nowadays, re-searchers are paying more attention to 3D faces [18, 57, 50, 17, 21, 67, 49] for wider applications and more real-istic rendering, due to advances in 3D imaging sensors and 3D applications. Editing 3D facial shape has attracted much interest in both the computer graphics and computer vision communities. Translation of 3D facial shapes provides ge-ometric ﬂexibility in addition to textures, thus resulting in vividness for facial rigging and animation [23, 40, 53, 25].
The 3D shape is also considered as a vital commodity of face to overcome pose and illumination challenges in exist-ing face recognition literature [42, 65, 43].
In this work, we study the problem of 3D facial shape attribute translation. An example is shown in Figure 1. We denote attributes as inherent features of a 3D face, such as expression, age, and gender that correlate to shape varia-tions. We also refer to some GAN-based domain adaptation works [13, 31], and deﬁne “domain” as a set of data with certain attribute values, e.g. 30-year-old males with neu-tral expression. We cast 3D facial attribute translation as a domain adaptation problem, which is naturally linked with
GAN by its data-driven nature.
Applying state-of-the-art deep GANs on 3D geometry data is challenging, and the difﬁculties are mainly two-fold.
Firstly, unlike facial images on a square Euclidean grid, 3D geometric data, in the case of facial surfaces, are on a Rie-mannian manifold. This hinders the application of state-of-the-art deep convolutional neural networks (CNNs) on 3D facial attribute translation. We refer to this as a prob-lem of network compatibility. Secondly, unlike facial image data that are abundant for image translation tasks, there is a shortage of 3D facial data. This is limited by the popularity of 3D scanning devices. Moreover, most deep CNN based methods rely heavily on paired and labeled data. We refer to this as a problem of data scarcity.
For network compatibility, we design a geometric map that encodes 3D coordinates onto regular image grids. The adjacency information for 3D vertices is preserved in a local least-square manner while being constrained by symmetric property. This enables us to leverage symmetry, an impor-tant character of face in the learning process. In addition, the learning networks are end-to-end with a differentiable 3D-to-2D forward geometric mapping layer and a 2D-to-3D backward grid sampling layer.
For data scarcity, we employ a uniﬁed and unpaired
GAN for multi-domain attribute translation. Firstly, we as-sume that the latent encodings of different domains should be cross-correlated to each other. Rather than learning the translation between every two domains separately, we learn a single generator for all domains, i.e. for expression, age, and gender translation tasks together. Secondly, we employ an unpaired framework, assuming that exactly paired data, i.e. different ages of a person are difﬁcult to collect and dif-ferent genders for the same identity are almost impossible in the real world. This mitigates the exact constraint for hardly accessible paired data. We also conduct data augmentation in training by adding random perturbations of scales and rotations of 3D facial shapes.
In summary, the main contributions of this paper are:
• We ﬁrst propose a general and uniﬁed framework for multi-domain 3D facial attribute translation, which covers some shape-oriented applications including ex-pression transfer, aging, and gender translation.
• We construct a novel geometric map for 3D face repre-sentation on a canonical 2D grid. The geometric map leverages symmetry of face and maintains the adja-cency of 3D vertices in a local least-square manner.
• We make unpaired training of 3D facial shape data available on a geometric map with a hierarchical GAN architecture to suppress both global and local artifacts. 2.