Abstract
In this paper, we introduce a set of simple yet effec-tive TOken REduction (TORE) strategies for Transformer-based Human Mesh Recovery from monocular images. Cur-rent SOTA performance is achieved by Transformer-based structures. However, they suffer from high model complex-ity and computation cost caused by redundant tokens. We propose token reduction strategies based on two important aspects, i.e., the 3D geometry structure and 2D image fea-ture, where we hierarchically recover the mesh geometry with priors from body structure and conduct token cluster-ing to pass fewer but more discriminative image feature to-kens to the Transformer. Our method massively reduces the number of tokens involved in high-complexity interactions in the Transformer. This leads to a significantly reduced computational cost while still achieving competitive or even higher accuracy in shape recovery. Extensive experiments across a wide range of benchmarks validate the superior ef-fectiveness of the proposed method. We further demonstrate the generalizability of our method on hand mesh recovery.
Visit our project page at https://frank-zy-dou. github.io/projects/Tore/index.html. 1.

Introduction
Human Mesh Recovery (HMR) has been extensively re-searched in recent years, given its wide real-world applica-tions [15, 81, 11, 62, 69, 17, 42, 84]. This task becomes more challenging when the input is a monocular 2D image, due to the large pose and shape variation, large appearance variation, partial observation, and self-occlusion.
There has been steady progress in 3D human mesh re-covery [30, 50, 36, 24, 60, 39, 40, 8, 5]. Recently, Trans-former [67] has shown state-of-the-art (SOTA) results on a wide variety of tasks due to its strong capability of cap-turing long-range dependency for more accurate predic-tions [3, 67, 76, 74]. Using tokens constructed from lo-cal features extracted by a convolutional neural network
†, ‡ denote equal contributions.
Figure 1. Throughput v.s. Accuracy and GFLOPs v.s. Accuracy on Human3.6M [23]. Our method dramatically saves GFLOPs and improves throughput while maintaining highly competitive accu-racy. The x-axis of the bottom GFLOPs figure is reversed for demonstration. Eb0 and R50 represent EfficientNet-b0 [65] and
ResNet-50 [20] backbones, respectively. (CNN) [20, 70] to query the joint and mesh vertex positions,
Transformer-based methods [39, 40, 8] achieved SOTA per-formance.
However, improved performance comes with costs: the increased expressivity of Transformers comes with quadrat-ically increasing computational costs since all pairwise in-teractions are taken into account [14]. The space and time complexity of a QKV-attention operation is known to be
O(M 2), where M is the number of tokens. The token number thus plays a vital role in time efficiency: a large number of tokens inevitably leads to a heavy computation burden. Unfortunately, almost all the existing Transformer-based SOTA methods for HMR [39, 40, 8] are suffering from redundant tokens. This incurs a high model com-plexity and computational costs, which prevents the current
Transformer-based HMR methods from achieving their full potential in real-world applications.
In this paper, we make key observations from two im-portant aspects: the 3D geometry structure and 2D image
feature, to reveal the problem of token redundancy. First, to recover the 3D geometry, all existing methods use both mesh vertices and skeleton joints as tokens for the feature interaction between input and body shape. Whereas a body mesh contains numerous vertices, they can be abstracted by a small number of joints on the skeleton. For instance, when animating a SMPL [44] avatar, the skeleton joints, together with a blend shape binding the joints and corresponding mesh vertices of the local body part, are able to describe various body meshes. Therefore, the joints can already be viewed as an underlying structure of a body shape, which intrinsically encodes the human mesh geometry. Second, for image-based input, most existing methods indiscrimi-nately use all the feature patches to capture pose, shape and appearance variance. However, although the human body exhibits large variance, the important features for shape in-ference are dominantly clustered within the body area in an
RGB image. Most features, e.g., image background, are not informative, thus bringing about redundancy.
Given the aforementioned insights, we argue that the
Pareto-front of accuracy and efficiency for Transformer-based HMR could be further improved by reducing the number of tokens [59, 47, 56]. To this end, we introduce a set of simple yet effective token reduction strategies mainly from two aspects corresponding to our observations. First, for 3D mesh recovery, instead of querying both vertices and joints with input features simultaneously, we consider learning a small set of body tokens at the skeleton level for each body part. To recover corresponding mesh vertices, we use an efficient Neural Shape Regressor (NSR) to infer the mesh from the body features encoded by these tokens.
This query process can also be interpreted as an attention matrix decomposition, by which we effectively leverage the geometric insights encoded at the skeleton level to infer the mesh structure hierarchically. Second, for the input image feature, we introduce a learnable token pruner to prune the tokens of patch-based features extracted by a CNN. We em-ploy a clustering-based strategy to identify discriminative features, which results in two appealing properties: 1) the end-to-end learning of the pruner is unsupervised, avoiding the need for additional data labeling; 2) it learns semanti-cally consistent features across various images, thus further benefiting the geometry reasoning and enhancing the capa-bility of generalizability. These token reduction strategies substantially reduce the number of query tokens involved in the computation without sacrificing the important informa-tion. An overview is shown in Figure 2.
We conduct extensive experiments across wide bench-marks [23, 68, 85], including both the human body and hand mesh recovery, to validate the proposed method. Com-pared to SOTA methods, our framework faithfully recov-ers body meshes with fewer tokens, which considerably re-duces memory and computation overhead while maintain-ing competitive geometric accuracy.
In summary, our contribution is three-fold:
• We reveal the issues of token redundancy in the exist-ing Transformer-based methods for HMR.
• We propose effective strategies for token reduction by incorporating the insights from the 3D geometry struc-ture and 2D image feature into the Transformer design.
• Our method achieves SOTA performance on vari-ous benchmarks with less computation cost. For in-stance, for the Transformer Encoder structure [39] and the Transformer Encoder-Decoder structure [8] with
ResNet-50 [20] backbone, our method maintains com-petitive accuracy while saving 82.9%, 50.5% GFLOPs and improving 139.1%, 39.8% throughput, respec-tively; see Figure 1 for an overview. 2.