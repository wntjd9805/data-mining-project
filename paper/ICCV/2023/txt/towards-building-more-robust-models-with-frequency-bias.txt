Abstract
The vulnerability of deep neural networks to adversarial samples has been a major impediment to their broad appli-cations, despite their success in various fields. Recently, some works suggested that adversarially-trained models emphasize the importance of low-frequency information to achieve higher robustness. While several attempts have been made to leverage this frequency characteristic, they have all faced the issue that applying low-pass filters di-rectly to input images leads to irreversible loss of discrim-inative information and poor generalizability to datasets with distinct frequency features. This paper presents a plug-and-play module called the Frequency Preference Control
Module that adaptively reconfigures the low- and high-frequency components of intermediate feature representa-tions, providing better utilization of frequency in robust learning. Empirical studies show that our proposed mod-ule can be easily incorporated into any adversarial train-ing framework, further improving model robustness across different architectures and datasets. Additionally, experi-ments were conducted to examine how the frequency bias of robust models impacts the adversarial training process and its final robustness, revealing interesting insights. 1.

Introduction
As deep learning methods are making a splash in various fields, their security and robustness are drawing more and more attention from both academia and industry. DNNs for image classification have been proven to be easily fooled by adversarial examples, with imperceptible perturbations added to natural images. The vulnerability is also uncov-ered in many other safety-critical fields like medical diag-nosis [10] and autonomous driving [8]. Adversarial training is regarded as a trustworthy approach for producing robust models, and considerable subsequent effort has been done to increase its efficiency [28, 33] and efficacy [40, 41]. De-*Corresponding author. spite continuously advanced robust learning methods, the relationship between some intrinsic characteristics of the model structure, such as frequency characteristics, and the robustness it exhibits seems to be rarely discussed.
The emergence of vision transformers (ViTs) revealed a novel architecture that performs on par or even better than convolutional networks (CNNs) in many vision tasks. As more and more in-depth work unfolds, some of ViT’s fun-damentals and characteristics are exposed. Several recent works try to improve the performance of ViTs with a fre-quency lens. [29] proposed naturally trained ViTs are more robust to adversarial attack, especially for high-frequency
It is also noticed that ViTs reduce high-perturbations. frequency signals while CNNs amplify them [25]. [31] suc-cessfully enhances ViT performance by deliberately retain-ing high-frequency information. The complementarity of
CNNs and ViTs exhibited in the frequency domain is an in-triguing starting point for studying and further improving the robustness of the model. But the relations between ro-bustness and the frequency bias of models have not been fully studied and utilized in the context of robust learning.
Research [11] has suggested that deep neural networks, when trained on image classification data sets, tend to ex-hibit bias towards texture information, which is the high-frequency element present in images. By contrast, mod-els that are adversarially trained primarily emphasize the importance of low-frequency information, leading to im-proved robustness [42]. To delve further into this phe-nomenon, several studies have experimented with adjusting the constraints placed on either low or high-frequency sig-nals in the loss regularization term [2], or incorporating per-turbations of variable frequencies during adversarial train-ing [23]. There are also several attempts [43, 16] aimed at exploiting the above mentioned frequency properties to build more robust models. However, they have primarily been limited to applying low-pass filtering directly to clean or adversarial inputs. Regrettably, this methodology is as-sociated with an irreversible loss of high-frequency infor-mation within the image and thus causes a marked decrease in accuracy across clean samples (e.g., 4-5% clean accuracy
drop compared to standard AT methods) [16]. Furthermore, it is imperative to adapt the parameters of the low-pass fil-ter to better suit different datasets that embody distinct fre-quency characteristics.
In order to solve the aforementioned problems and to adopt a new perspective to study the frequency character-istics of robust models, we propose a plug-and-play mod-ule called Frequency Preference Control Module (FPCM) to reconfigure the low-frequency and high-frequency compo-nents of the intermediate features learned within the model, which can be simply cooperated with any adversarial train-ing framework and further boost model’s robustness. While previous methods require special tuning of their introduced hyperparameters to adapt to datasets with various frequency characteristics, our module can be co-optimized with the model in adversarial training with no need for any fine-grained hyperparameter adjustments, which also allows it to adapt and then utilize frequency features exhibited in different stages (i.e., layers) of a model. Our empirical study reveals that our approach demonstrates adaptability across different model architectures and datasets and con-tinuously drives robust accuracy improvement. Moreover, with FPCM, we can pioneer the study of the frequency char-acteristics of intermediate-level feature representations and take a closer look at how the frequency bias of a robust model would impact its robustness.
In a nutshell, our contribution can be folded into follow-ing aspects: 1. We proposed the Frequency Preference Control Mod-ule that can be effortlessly incorporated into any AT approach and further improve the model robustness. 2. Leveraging our proposed module, we show how the frequency of feature representation would impact the final robustness and adversarial training process. 2.