Abstract
Dense depth and surface normal predictors should pos-sess the equivariant property to cropping-and-resizing – cropping the input image should result in cropping the same output image. However, we find that state-of-the-art depth and normal predictors, despite having strong performances, surprisingly do not respect equivariance. The problem ex-ists even when crop-and-resize data augmentation is em-ployed during training. To remedy this, we propose an equivariant regularization technique, consisting of an av-eraging procedure and a self-consistency loss, to explicitly promote cropping-and-resizing equivariance in depth and normal networks. Our approach can be applied to both
CNN and Transformer architectures, does not incur extra cost during testing, and notably improves the supervised and semi-supervised learning performance of dense pre-dictors on Taskonomy tasks. Finally, finetuning with our loss on unlabeled images improves not only equivariance but also accuracy of state-of-the-art depth and normal pre-dictors when evaluated on NYU-v2. 1.

Introduction
Depth regression [2, 14, 24, 29, 38, 40, 42, 43, 69, 71, 72] and surface normal regression [1, 12, 22, 57] are image-to-image dense prediction tasks that involve predicting an out-put image of the same size as the input image. This con-trasts with image classification, where only one or a few category labels are predicted per image. A shared feature among depth and normal prediction tasks is that they natu-rally require equivariance, such that a geometric transform (e.g., random cropping) applied to the input image results in the same transform to the output image [8, 15, 28, 30], when the effect (scale of the depth prediction) of camera intrinsic change due to cropping is accounted for. This is because the relative depths and normals are derived from the underlying geometrical and physical properties of the scene that are not affected by viewport changes. Consequently, a good depth
Figure 1. State-of-the-art depth and surface normal predictors fail to capture equivariance, while we know equivariance needs to hold for an ideal depth/normal predictor (when adjusted for prediction scale and offset). We crop and resize two patches (red & blue) from the same scene, then extract depths/normals with pre-trained models from [42] (MiDaS-v3) and [1]. We notice clear discrep-ancies between the predictions of the two crops, as highlighted by the yellow boxes. The same issue exists in other depth predictors (Figure 2) and dense prediction tasks as well (supplementary). or normal predictor must have the equivariant property.
To our surprise, we find state-of-the-art well-engineered depth and normal predictors often fail at equivariance. We the MiDaS CNN-based investigate two recent models: (v2.1) and Transformer-based (v3.0) depth predictors from
[42,43] and the uncertainty-guided CNN-based surface nor-mal predictor from [1]. We generate a pair of resized crops of the same test image from NYU-v2 [49], extract predic-tions with the networks, and measure equivariance by com-paring and computing the mean errors between the predic-tions of the two crops. A more equivariant network would produce smaller errors from this procedure. We discover that the examined depth and surface normal predictors do not handle equivariance to cropping very well, as shown in
Figure 1. There are prominent, sometimes structural, in-consistencies in the predictions of the two crops. For this particular scene, the mean error induced by cropping is sig-nificant – as large as 12.6% absolute relative error (AbsRel) between crops for depth prediction, making it compara-ble to the overall AbsRel error to ground truths (13.7%).
Given the widespread use of such dense predictors, for ex-ample, MiDaS-v3 for the depth-guided inference in Stable
Diffusion-v2 [45], it is imperative to solve such an issue.
Data augmentation is a widely-used strategy to promote the equivariance of models during training. In each mini-batch, instead of seeing the original images, the network sees random resized crops of them. The network is implic-itly trained to cope with the variations caused by random crops in a straightforward data-driven manner. However, the problem persists even when randomly resized cropping augmentation is used during training. In fact, the state-of-the-art models we tested, for example, the MiDaS depth net-works [42, 43], are already trained on random crops. This suggests that augmentation alone is not a sufficient solu-tion to the equivariance issue. Other methods to enforce equivariance include invariant inputs and equivariant archi-tectures, but they involve a nontrivial additional effort to construct and do not apply to the cropping transform we are concerned about. Therefore, we compare our approach to the data augmentation strategy as our primary baseline.
In this paper, we propose an equivariant regularization approach built on top of data augmentation to improve equivariance in dense depth and normal prediction net-works. Our approach consists of two parts: an equivariant averaging step of the outputs of random crops, and an equiv-ariant loss between the crop outputs and the average output.
The averaging step is based on the key observation that the full output average of all possible transforms of a transfor-mation group guarantees equivariance to that group. Our sampling version is effectively an unbiased estimate of the full average. The equivariant loss enforces self-consistency and promotes equivariance explicitly rather than implicitly as in data augmentation. Thanks to the flexible formulation, our approach can be applied to any layer of popular net-work architectures (e.g., CNN or Vision Transformer [13]), and with unlabeled images – both are beyond what data aug-mentation can do. Meanwhile, our approach retains the ben-efit of data augmentation, as it imposes no extra cost during testing because the network architecture and the inference procedure are not changed in any way.
Empirically, we demonstrate the effectiveness of our equivariant regularization approach in supervised, semi-supervised and unsupervised learning settings. In the super-vised setting, we benchmark our approach against the no-augmentation and augmentation baselines on edge detec-tion, depth prediction, and surface normal prediction tasks of the Taskonomy dataset [75]. We find that our approach overcomes the ineffectiveness of using data augmentation alone.
In the semi-supervised setting, we show our ap-proach benefits from unlabeled data, improving the sam-ple efficiency further. Finally, in the unsupervised setting, we demonstrate the capability to adapt the state-of-the-art depth and surface normal models to the NYU-v2 dataset
[49] (which these models are not trained on), and improve their accuracy and equivariance, without using any ground truth labels.
To summarize, our contributions are the following:
• We point out an obvious but overlooked issue: The state-of-the-art depth and normal prediction networks fail at equivariance to cropping.
• We propose an equivariant regularization approach to learn more equivariant networks effectively.
• We show empirical successes of our approach in a range of settings, and improve the equivariance and ac-curacy of the state-of-the-art depth and normal models. 2.