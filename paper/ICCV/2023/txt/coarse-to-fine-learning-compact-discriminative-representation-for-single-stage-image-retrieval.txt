Abstract
Image retrieval targets to find images from a database that are visually similar to the query image.
Two-stage methods following retrieve-and-rerank paradigm have achieved excellent performance, but their separate lo-cal and global modules are inefficient to real-world appli-cations. To better trade-off retrieval efficiency and accu-racy, some approaches fuse global and local feature into a joint representation to perform single-stage image retrieval.
However, they are still challenging due to various situations to tackle, e.g., background, occlusion and viewpoint.
In this work, we design a Coarse-to-Fine framework to learn
Compact Discriminative representation (CFCD) for end-to-end single-stage image retrieval-requiring only image-level labels. Specifically, we first design a novel adaptive softmax-based loss which dynamically tunes its scale and margin within each mini-batch and increases them progres-sively to strengthen supervision during training and intra-class compactness. Furthermore, we propose a mechanism which attentively selects prominent local descriptors and infuse fine-grained semantic relations into the global rep-resentation by a hard negative sampling strategy to opti-mize inter-class distinctiveness at a global scale. Exten-sive experimental results have demonstrated the effective-ness of our method, which achieves state-of-the-art single-stage image retrieval performance on benchmarks such as
Revisited Oxford and Revisited Paris. Code is available at https://github.com/bassyess/CFCD. 1.

Introduction
Image retrieval is a fundamental task in computer vision, which aims to efficiently retrieve images similar to a given query from a large-scale database. With the development of deep learning, image retrieval has made great progress [24, 33, 41, 9, 5]. The state-of-the-art methods generally work in a two-stage paradigm [4, 21], where they first obtain coarse
*Equal contribution.
Figure 1. (a) Distribution of [cos(θyi +m)−argmax(cosθj̸=yi )] after training with ArcFace, where yi is target label. In the red box, due to large variations in background, occlusion and viewpoint, these images in Google Landmarks Dataset V2 are far away from their class centers and misclassified. (b) Geometrical interpreta-tion of our methods from the feature perspective. By designing an adaptive margin penalty strategy, we can introduce appropriate supervision intensity for different batch during training. As for the outliers with partial match, we design a mechanism to select prominent local descriptors and minimize their pairwise distances, which makes the unified representation more discriminative. candidates via global features, and then re-rank them with local features to achieve better performance. However, two-stage methods are required to rank images twice and use the expensive RANSAC [12] or AMSK [35] for geometric verification, leading to high memory usage and increased latency.
To alleviate the efficiency issues, many studies [13, 23, 20, 11] recently attempt to explore a unified single-stage image retrieval solution. They design complicated atten-tion modules to fuse global and local features, and adopt the ArcFace [8] loss to train the model in an end-to-end fashion. They have shown excellent performance on single-stage image retrieval benchmarks.
In spite of their suc-cesses, extracting multi-scale local features is still an ex-tremely expensive process. More importantly, these stud-ies do not consider the challenges of large-scale landmark dataset from the perspective of data distribution, which have large variations in background, occlusion and viewpoint.
Fig1(a) displays the cosine logits distribution of land-mark samples after convergence, where more than 20% of the samples are far away from their class centers as their
target cosine logits are smaller than their non-target cosine logits. One can observe the various conditions in these sam-ples such as background, occlusion, viewpoint, etc. More-over, true positives lingering at the classification boundary receive weaker supervision due to the fixed margin penalty.
Therefore, we propose an adaptive margin penalty strat-egy that tunes hyper-parameters to progressively strengthen supervision for intra-class compactness. Besides, inspired by geometric verification, in order to retrieve target images with partial match, we design a mechanism to select promi-nent local descriptors and minimize their pairwise distances for learning inter-class distinctiveness more effectively, is shown in Fig1(b).
We propose a Coarse-to-Fine framework to learn
Compact and Discriminative representation (CFCD) for single-stage image retrieval. Specifically, we first propose a novel adaptive loss which uses the median of cosine log-its in a batch to dynamically tune the scale and margin of the loss function, namely MadaCos. MadaCos increases its scale and margin progressively to strengthen supervision during training, consequently increasing the learned intra-class compactness. We also design the local descriptors matching constraints and hard negative sampling strategy to construct triplets, and introduce the triplet loss[3] to lever-age fine-grained semantic relations, which embed the global feature with more information of inter-class distinctiveness.
We jointly train the model as a whole with MadaCos and triplet losses to produce the final compact and discrimi-native representation and improve the overall performance.
This framework consists of two training phases: global fea-ture learning with MadaCos and later added local feature matching with triplet loss. During the testing stage, global features are extracted from the the end-to-end framework and ranked once without additional computation overhead.
Our main contributions are summarized as follows:
• We propose a coarse-to-fine framework to learn com-pact and discriminative representation for single-stage image retrieval without additional re-ranking compu-tation overhead, which is more efficient.
• To enhance intra-class compactness, we design an adaptive softmax loss named MadaCos, which uses the median of cosine logits within each mini-batch to tune its hyperparameters to strengthen supervision.
• To enhance inter-class distinctiveness, we select local descriptors and design an image-prominent level hard negative sampling strategy to leverage fine-grained semantic relations.
• Through systematic experiments, the proposed method achieves stage-of-the-art single-stage image retrieval performance on benchmarks: ROxf (+1M), RPar (+1M). 2.