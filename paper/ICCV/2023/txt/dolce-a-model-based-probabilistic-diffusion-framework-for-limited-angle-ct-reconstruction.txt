Abstract
Limited-Angle Computed Tomography (LACT) is a non-destructive 3D imaging technique used in a variety of appli-cations ranging from security to medicine. The limited angle coverage in LACT is often a dominant source of severe arti-facts in the reconstructed images, making it a challenging imaging inverse problem. Diffusion models are a recent class of deep generative models for synthesizing realistic images using image denoisers. In this work, we present DOLCE as the first framework for integrating conditionally-trained diffusion models and explicit physical measurement mod-els for solving imaging inverse problems. DOLCE achieves the SOTA performance in highly ill-posed LACT by alter-nating between the data-fidelity and sampling updates of a diffusion model conditioned on the transformed sinogram.
We show through extensive experimentation that unlike ex-isting methods, DOLCE can synthesize high-quality and structurally coherent 3D volumes by using only 2D condi-tionally pre-trained diffusion models. We further show on several challenging real LACT datasets that the same pre-trained DOLCE model achieves the SOTA performance on drastically different types of images. 1.

Introduction
Computed Tomography (CT) is one of the most widely-used imaging modalities with applications in medical diag-nosis, industrial non-destructive testing, and security [76, 17, 77, 80]. In a typical parallel-beam CT imaging system, the x-ray measurements obtained from all viewing angles are combined to reconstruct a cross-sectional image of a 3D object [39]. Conventional reconstruction methods such as
Filtered Back Projection (FBP) can produce high-quality CT images given a complete set of projection data, but com-pletely fail under more ill-posed scenarios such as Limited-Angle CT (LACT), where projections from only a limited
*Work done during an internship at LLNL.
†Corresponding authors.
Figure 1. We show that the same pre-trained DOLCE model can reconstruct distinct CT images such as checked-in luggage [55] and human body [50]. Top: 3D rendering of a luggage from its 2D slices reconstructed using DOLCE on the limited-angle data con-taining just one-third of the views (0-60◦). Note how our method preserves the 3D edges, enabling a successful recovery of the object geometries. Bottom: Comparison of DOLCE on a medical dataset with DPS, which is a SOTA method for solving imaging inverse problems using unconditional diffusion models [13]. See Section 5 for the complete set of experimental results.
θ
≤
≤ range of angles can be acquired (i.e., 0
θmax with
θmax < π) [3, 56, 37, 11, 52]. A typical solution to this in-verse problem is model-based optimization that integrates a forward model characterizing the imaging system and a reg-ularizer imposing priors on the unknown image. While there has been significant progress in algorithms that leverage so-phisticated image priors (e.g., transform-domain sparsity, self-similarity, and learned dictionaries) [20, 19, 43, 16], the focus in the area has recently shifted to deep learning (DL).
Deep Learning for CT: A traditional DL reconstruction involves training a convolutional neural network (CNN) ar-chitecture, such as U-Net [58], to directly perform a regu-larized inversion of the forward model by exploiting redun-dancies in the training data [38, 35, 25, 27, 88, 2, 92, 91].
Model-based DL (MBDL) is another popular reconstruc-tion strategy that seeks to explicitly use the knowledge of the forward model by integrating a CNN into a model-based algorithm. Popular MBDL frameworks include Plug-and-Play Priors (PnP) [73, 57], which use pre-trained deep denoisers as image priors [68, 51, 90], and Deep Unfold-ing [24, 1, 46, 23, 94, 33], which interpret the iterations of a model-based algorithm as layers of a CNN to perform end-to-end supervised training. Other DL strategies used in
CT reconstruction include dual-domain learning [84, 71, 93], deep internal learning [89, 59, 72], and measurement syn-thesis learning [44, 45, 70]. Despite the rich literature on tomographic imaging, the reconstruction of high-quality im-ages with sharp edges remains a well-known challenge, par-ticularly when the acquired data is missing a large-range of angles (i.e., θmax 90◦). Furthermore, most prior work in the area has focused on methods that can only produce point estimates without any quantification of the reconstruction uncertainty, which can be essential in critical applications such as healthcare or security.
≤
Proposed Work: We present Diffusion Probabilistic
Limited-Angle CT Reconstruction (DOLCE), a conditional generative model for LACT, which can generate multiple di-verse, yet high-quality, reconstructions from a given limited-angle data. Inspired by the recent successes of Denoising
Diffusion Probabilistic Models (DDPM) [62, 18] and de-noising score matching [64, 65], we design DOLCE as a
“repeated-refinement” conditional diffusion model. Specif-ically, DOLCE trains a stochastic sampler conditioned on noisy seed reconstructions obtained using transformed limited-angle sinograms. To boost the imaging quality fur-ther, DOLCE imposes an additional data-consistency step at every iteration after the sampling-update step. DOLCE can thus be viewed as a method for transforming a standard nor-mal distribution into an empirical data distribution through a sequence of refinement steps, while integrating physical forward models and learned stochastic samplers (see Fig. 2).
We demonstrate several unique features of DOLCE com-pared to the prior work through extensive experimentation on two real-world LACT datasets. We first show that, on both applications, DOLCE achieves the state-of-the-art (SOTA) performance by directly producing high-resolution 512 512
× images across a range of limited-angle scenarios (θmax
∈
). Next,we make an interesting finding that 60◦, 90◦, 120◦
{ the same pre-trained DOLCE model can be effective on
LACT from significantly different data distributions, such as images of human body and of checked-in luggage, enabling highly generalizable CT reconstruction networks for the first time. Finally, we show how the diverse realizations produced by DOLCE (from a given sinogram) can enable meaningful uncertainty quantification [41]. Notably, we find the vari-ances estimated by DOLCE to be well calibrated, i.e., con-sistent with the true reconstruction errors. In short, DOLCE is the first model-based probabilistic diffusion framework for LACT that achieves SOTA performance and enables sys-tematic uncertainty characterization. Our code is available
} at https://github.com/wustl-cig/DOLCE.
Our main contributions can be summarized as follows: 1. We propose DOLCE as the first conditional diffusion model for the recovery of high-quality CT images from limited-angle sinograms. 2. We show that DOLCE is effective across two real-world datasets: checked-in luggage and medical-image datasets. DOLCE achieves a PSNR improvement of at least 3 dB over ILVR [12] and DPS [13], two SOTA diffusion models for inverse problems. 3. We use DOLCE to provide uncertainty maps for the reconstructed LACT images. The uncertainty estimates are reflective of the true reconstruction errors. 4. Using a 3D segmentation experiment, we show the effectiveness of DOLCE in recovering the geometric structure and sharp edges in high-resolution images, even in severely ill-posed settings. 2.