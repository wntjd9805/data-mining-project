Abstract
We propose a method to estimate 3D human poses from substantially blurred images. The key idea is to tackle the inverse problem of image deblurring by modeling the for-ward problem with a 3D human model, a texture map, and a sequence of poses to describe human motion. The blur-ring process is then modeled by a temporal image aggre-gation step. Using a differentiable renderer, we can solve the inverse problem by backpropagating the pixel-wise re-projection error to recover the best human motion repre-sentation that explains a single or multiple input images.
Since the image reconstruction loss alone is insufﬁcient, we present additional regularization terms. To the best of our knowledge, we present the ﬁrst method to tackle this prob-lem. Our method consistently outperforms other methods on signiﬁcantly blurry inputs since they lack one or mul-tiple key functionalities that our method uniﬁes, i.e. image deblurring with sub-frame accuracy and explicit 3D model-ing of non-rigid human motion. 1.

Introduction
Accurate tracking of human motion is often crucial for understanding dynamic scenes from images. Human mo-tion estimation has a wide ﬁeld of applications such as im-proving human-robot collaboration [2], human-machine in-teraction in general [12], better safety for autonomous driv-ing [20], markerless human motion capture [36, 35, 27], sports analysis, and the movie and entertainment indus-try. A particular difﬁculty occurs when the human motion is fast, or low light conditions demand longer camera ex-posure times, which can both lead to blurry images from which it is signiﬁcantly harder to estimate the human pose.
The main goal of our method is accurate 3D human pose tracking from substantially blurred images or videos.
Hence, it is related to both human pose estimation and im-age deblurring methods. On the one hand, while there is a variety of methods that address 3D human pose estimation from RGB or RGB-D images, there is no method that is de-G
T
F r a m e s
R e n d e r e d
N o v e l
V i e w
} r u l
B d n u o r g k c a
B
] 8 2
[ g n i t t a
M
|
{z
Inputs
} |
{z
Outputs (Estimated sub-frame pose)
Figure 1. Human from Blur (HfB) on a real-world sequence.
Given a blurry image with human motion and the corresponding background, HfB recovers the human shape and sub-frame mo-tion. We visualize sub-frame human pose and show the recon-structed mesh from a novel view. signed to handle substantially blurred images. Moreover, none of the human pose estimation methods is able to esti-mate human pose at sub-frame accuracy. On the other hand, there is a large amount of methods that aim at deblurring images and videos, but they mostly only assume simpliﬁed scenarios, e.g. without out-of-image-plane object rotations, or only for rigidly moving objects [45, 46]. So far, human pose estimation and image deblurring has not been studied jointly. Also, there is no public dataset to evaluate such task since none of standard datasets for human pose estimation include signiﬁcant amounts of motion blur.
We propose the ﬁrst method that recovers human pose at sub-frame accuracy from blurry inputs, even from a single blurry image (Fig. 1). We make the following contributions: (1) We present the ﬁrst method for human pose estimation from substantially blurred images that recovers sub-frame accurate poses as well as texture and body shape. (2) We generate a synthetic dataset and collected real-world motion-blurred data of humans for evaluation purposes. We further propose corresponding evaluation metrics to assess and compare to future methods. (3) The proposed method only relies on test-time optimiza-tion and is learning-free, apart from the initialization
Figure 2. Method overview. The input to our method are a single or multiple blurry frames of a human (left), and the output is a 3D repre-sentation of a human and its sub-frame motion over time (right). From Right to Left: Starting from the human motion representation, our model can be seen as generative model. For a desired set of frames and sub-frames, we can render sub-frame appearances and correspond-ing silhouettes. Then, the sub-frames are averaged to generate blurry frames and blurry silhouettes (alpha channel), which are composed with the known background to generate the input image according to (2). The central part of our method is the image reconstruction loss which compares the generated images with the actual input images. In order to solve for the human motion estimation, the reconstruction loss is backpropagated through the entire differentiable pipeline. The human pose estimation uses a traditional method [27] to initialize the optimization, and the image matting is precomputated [28] for the matting loss. and the motion prior, which is only needed for the single-frame case. Hence, our method does not require large amounts of annotated training data. 2.