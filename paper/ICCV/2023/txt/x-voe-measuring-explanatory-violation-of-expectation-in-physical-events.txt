Abstract
Intuitive physics is pivotal for human understanding of the physical world, enabling prediction and interpretation of events even in infancy. Nonetheless, replicating this level of intuitive physics in artificial intelligence (AI) remains a formidable challenge. This study introduces X-VoE, a com-prehensive benchmark dataset, to assess AI agents’ grasp of intuitive physics. Built on the developmental psychology-rooted Violation of Expectation (VoE) paradigm, X-VoE establishes a higher bar for the explanatory capacities of intuitive physics models. Each VoE scenario within X-VoE encompasses three distinct settings, probing models’ compre-hension of events and their underlying explanations. Beyond model evaluation, we present an explanation-based learning system that captures physics dynamics and infers occluded object states solely from visual sequences, without explicit oc-clusion labels. Experimental outcomes highlight our model’s alignment with human commonsense when tested against
X-VoE. A remarkable feature is our model’s ability to visu-ally expound VoE events by reconstructing concealed scenes.
Concluding, we discuss the findings’ implications and out-line future research directions. Through X-VoE, we catalyze the advancement of AI endowed with human-like intuitive physics capabilities. 1.

Introduction
Humans possess a profound understanding of the physical world, enabling them to predict the outcomes of physical in-teractions and events [6]. From infancy, humans demonstrate intuitive physics, comprehending actions and consequences even in unfamiliar scenarios. For the machine learning com-munity, the challenge lies in emulating this level of intuitive physics understanding. This study introduces X-VoE, a com-prehensive benchmark dataset designed to assess and push the limits of AI agents’ intuitive physics comprehension.
The notion of intuitive physics, observed even in young in-fants, has been foundational in cognitive science and develop-Figure 1: Evaluation settings in the ball blocking exemplar sce-nario of X-VoE. The explanation video illustrates potential hidden dynamics. Circles denote no surprise, and exclamation marks in-dicate surprise. In the predictive setup (S1), a solvable pair is pre-sented without requiring explanation: predicting observed entities’ dynamics suffices to reason about the outcome. In the hypothetical setup (S2), perceiving the direction of outgoing balls might lead to surprise, yet alternate explanations exist—e.g., a hidden blocker behind the wall causing ball rebound. However, a random agent’s scores show negligible disparity, necessitating the explicative setup (S3) to discern surprises, demanding explanatory ability absent in predictive-only or random agents. mental psychology [36]. Infants show surprise when physical events violate their expectations, indicating an understanding of fundamental physical principles [5]. Explanation-based learning has been proposed as a mechanism contributing to the development and refinement of intuitive physics under-standing [4]. However, recent advances in this field have primarily resulted in predictive models, lacking the explana-tory capacity and falling short of capturing even infant-level intuitive physics comprehension [30, 35].
Central to our work is the Violation of Expectation (VoE) paradigm, widely employed in psychological studies to eval-uate infants’ intuitive physics understanding [3, 5]. In this paradigm, participants exhibit surprise, indicated by pro-longed attention, when exposed to events that either follow or violate intuitive physics laws. Inspired by the effective-ness of this paradigm, we adopt it to evaluate AI agents’ intuitive physics comprehension. In each trial, models en-counter experiments adhering to or contravening intuitive physics laws. Models succeed in the VoE test if they display high surprise scores for physics-violating experiments and lower scores for compliant ones.
Existing works within the machine learning and computer vision community have embraced the VoE paradigm [10, 30, 32, 35, 43]. However, most of these efforts primarily focus on predictive abilities, disregarding the explanatory compo-nent [1, 29, 30, 32, 35, 37]. This perspective neglects the fundamental aspect of VoE—the act of explaining observed events. In psychological studies, human participants express surprise not at the moment a physics-violating event occurs, but upon learning of its outcome. This observation under-scores the significance of explanation within VoE.
Motivated by these insights, we introduce X-VoE, an intuitive physics evaluation dataset designed specifically to incorporate explanation within VoE. Distinct from previous efforts that concentrated on predictive scenarios, our dataset encompasses setups that require explaining observed events in diverse VoE situations. We establish three VoE settings for each of the four scenarios: ball collision, blocking, object per-manence, and continuity (see Fig. 2). Each scenario features predictive, hypothetical, and explicative setups. Notably, the three setups within the ball-blocking scenario distinguish explanatory agents from predictive and random ones.
Furthermore, we propose the eXplanation-based Physics
Learner (XPL) model to emulate the explanation-based VoE process, inspired by findings in human studies [3, 4]. While
XPL is adaptable to diverse deep architectures, we specifi-cally build it upon PLATO [30] due to its robust performance.
Our model incorporates three self-supervised modules: per-ception for image encoding, Transformer reasoning for oc-cluded object prediction, and dynamic reasoning for simu-lating physical dynamics. Importantly, our model introduces a reasoning sub-component to update representations of oc-cluded objects, akin to infants’ explanation-based learning when confronted with unexpected outcomes [3].
In summary, our work makes three significant contribu-tions:
• Introduction of X-VoE, a comprehensive intuitive physics evaluation dataset that challenges AI agents not only in predictive capabilities but also in their capacity to explain.
The dataset covers four distinct scenarios, each with pre-dictive, hypothetical, and explicative setups. This allows for a more comprehensive assessment of intuitive physics understanding within VoE.
• Proposition of the XPL model, enhancing existing ap-proaches with an explanatory module that improves
VoE evaluation. Our model comprises three modules— perception, reasoning, and dynamics learning—for holistic comprehension and simulation of physical dynamics.
• Experimental demonstration of XPL’s enhanced perfor-mance in alignment with human commonsense compared to other baselines in X-VoE. Additionally, XPL offers insights into hidden factors, as depicted in Fig. 1. 2.