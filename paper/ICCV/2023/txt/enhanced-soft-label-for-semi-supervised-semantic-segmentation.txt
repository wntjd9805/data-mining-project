Abstract
As a mainstream framework in the field of semi-supervised learning (SSL), self-training via pseudo labeling and its variants have witnessed impressive progress in semi-supervised semantic segmentation with the recent advance of deep neural networks. However, modern self-training based SSL algorithms use a pre-defined constant thresh-old to select unlabeled pixel samples that contribute to the training, thus failing to be compatible with different learn-ing difficulties of variant categories and different learning status of the model. To address these issues, we propose En-hanced Soft Label (ESL), a curriculum learning approach to fully leverage the high-value supervisory signals implicit in the untrustworthy pseudo label. ESL believes that pix-els with unconfident predictions can be pretty sure about their belonging to a subset of dominant classes though be-ing arduous to determine the exact one. It thus contains a
Dynamic Soft Label (DSL) module to dynamically maintain the high probability classes, keeping the label “soft” so as to make full use of the high entropy prediction. However, the DSL itself will inevitably introduce ambiguity between dominant classes, thus blurring the classification boundary.
Therefore, we further propose a pixel-to-part contrastive learning method cooperated with an unsupervised object part grouping mechanism to improve its ability to distin-guish between different classes. Extensive experimental re-sults on Pascal VOC 2012 and Cityscapes show that our approach achieves remarkable improvements over existing state-of-the-art approaches. 1.

Introduction
In recent years, the powerful feature representation ca-pability of deep learning has allowed us to witness tremen-dous progress in visual understanding tasks represented by semantic segmentation [5, 6, 13, 28, 34, 48, 50]. How-*Corresponding author
Figure 1. (a) An unlabeled image with entropy map, where warm color means high entropy. (b) The prediction of a high entropy pixel marked in the white cross in (a). As seen, despite the diffi-culty to distinguish this pixel between dominant classes (person, background and boat), the model is pretty sure that it belongs to one of the dominant classes. ever, as a notorious “data hungry” model, deep learning’s powerful feature representation relies on a large amount of high-quality annotated data. For semantic segmentation, the acquisition of pixel-level data annotations is unbear-ably time-consuming and labor-intensive. Therefore, with the development of semantic segmentation, the need for data-efficient semantic segmentation methods is extremely urgent. With the development of semi-supervised learn-ing [3, 29, 32, 39, 42, 47], semi-supervised semantic seg-mentation [7, 24, 27, 30, 43] which focuses on the study of using massive unlabeled images to assist a small amount of labeled data to improve the performance of semantic seg-mentation, has thus emerged as promising approaches to reduce the need for annotations and has gained extensive research attention.
The core challenge of semi-supervised semantic segmen-tation is to make full use of unlabeled images. Self-training via pseudo labeling [15, 25, 43, 44, 45] and its variants have developed into a mainstream learning paradigm in this field.
These methods usually leverage all labeled images to train a model in a fully-supervised manner and generate pseudo labels for all unlabeled images based on the trained model.
Then, they re-train the model from scratch using all labeled images with ground-truth labels and unlabeled images with
pseudo labels. Since pseudo-labels inevitably contain noise, simply applying them to model training is bound to trigger the confirmation bias problem [2], i.e. overfitting to the in-correct pseudo labels. To mitigate such issues, existing ap-proaches usually just preserve high-confidence predictions, while low-confidence predictions are discarded. However, the selection of the involved training pixels depends on the appropriate threshold setting, which is hard to be compat-ible with various learning difficulties of variant categories and different learning status of the model.
In this paper, we argue that simply discarding these low-confidence pseudo labels falls into a suboptimal trap, as there are usually hard samples with high-value supervisory signals that are crucial for model training. For the sake of convenience, we first introduce the concept of dominant classes, which generally refer to the categories with higher probability in the prediction of a pixel, and the details are described in Section. 3.2. The dominant classes of a pixel contain the categories that are usually semantic similar or spatial closer. For example, the pixel exemplified in Fig. 1 is a hard sample located in the object boundary, which is cru-cial for the training of the model, and its dominant classes include person, background, and boat. While the model is arduous to determine its exact class, it is pretty sure that the pixel belongs to the set of the dominant classes. Simply dis-carding such low-confidence pixel samples during training will result in unavoidable information loss thereby leading to inferior performance. Therefore, to fully explore the po-tential of high entropy predictions, we design a Dynamic
Soft Label (DSL) method to dynamically maintain the high probability classes by keeping the label as a “soft” version.
Concretely, we assign dominant classes for each pixel based on its probability prediction and normalize its probability score of dominant classes as a soft pseudo label, i.e. each class in the set of dominant classes will make contributions to the model training.
Though our proposed DSL can effectively utilize high entropy predictions, it brings ambiguity among dominant classes and thus blurs the classification boundary. To alle-viate such issues, we adopt the typical contrastive learning method [17] to boost the power of distinguishing different classes, thereby Enhancing our dynamic Soft Label (ESL).
Some prior works [1, 41, 49] extend the popular InfoNCE contrastive loss [17] to fully/semi-supervised semantic seg-mentation and make significant modifications for its use in a pixel-to-pixel paradigm or pixel-to-region paradigm.
Unfortunately, in semi-supervised semantic segmentation, such pixel-to-pixel contrastive learning paradigm faces the unique technical challenge of sampling error as the pseudo labels for unlabeled images unavoidably contain noise. Al-though the pixel-to-region contrastive learning paradigm can alleviate this issue by averaging the class region fea-tures, this paradigm is so coarse that it ignores intra-class diversity and gives unfaithful sample allocation, such as forcing a pixel of cat-eye to be similar to the whole cat.
Based on this concern, to fully explore the potential of intra-class diversity, we dive into the object part and further pro-pose a pixel-to-part contrastive learning method cooper-ated with an unsupervised object-part grouping mechanism.
Concretely, we maintain several prototypes for each class and each prototype represents a specific pattern. Then, the whole object in an image can be grouped into several mean-ingful parts by identifying the nearest prototype to each pixel. The candidate positive and negative samples can be obtained by the average pooling of the part feature. With the proposed pixel-to-part contrastive learning method, our
DSL can be further enhanced by alleviating the ambiguity problem between dominant classes. To sum up, our contri-butions can be summarized in three-fold:
• We believe that simply neglecting pixels with the low-confidence pseudo label during semi-supervised train-ing falls into a suboptimal trap, and propose Enhanced
Soft Label (ESL), a curriculum learning approach to fully leverage the high-value supervisory signals im-plicitly in the untrustworthy pseudo label.
• To alleviate the ambiguity issue between dominant classes caused by soft label, we further propose a novel pixel-to-part contrastive learning cooperated with an unsupervised object-part grouping mechanism to facil-itate the learning of class boundaries.
• We evaluate our ESL on both Pascal VOC [10] and
Cityscapes [8] under different partition protocols and demonstrate its superior performance. 2.