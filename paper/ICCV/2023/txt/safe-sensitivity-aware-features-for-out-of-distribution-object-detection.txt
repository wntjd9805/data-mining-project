Abstract
We address the problem of out-of-distribution (OOD) detection for the task of object detection. We show that residual convolutional layers with batch normalisation pro-duce Sensitivity-Aware FEatures (SAFE) that are consis-tently powerful for distinguishing in-distribution from out-of-distribution detections. We extract SAFE vectors for ev-ery detected object, and train a multilayer perceptron on the surrogate task of distinguishing adversarially perturbed from clean in-distribution examples. This circumvents the need for realistic OOD training data, computationally ex-pensive generative models, or retraining of the base ob-ject detector. SAFE outperforms the state-of-the-art OOD object detectors on multiple benchmarks by large margins, e.g. reducing the FPR95 by an absolute 30.6% from 48.3% to 17.7% on the OpenImages dataset. 1.

Introduction
Across a variety of tasks, deep neural networks (DNNs) produce state-of-the-art performance when tested on data that closely matches the training data distribution [19, 54].
However, when deployed into the real world, out-of-distri-bution (OOD) samples that do not belong to the training dis-tribution are likely encountered. Upon encountering OOD samples, DNNs tend to fail silently and produce overconfi-dent erroneous predictions [51, 40, 21, 3, 5, 16]. Especially in safety-critical applications, such as self-driving vehicles or medical robotics, such silent failures present a severe safety risk that must be addressed before the widespread adoption of these systems [59, 2].
OOD detection, where OOD samples are distinguished from in-distribution (ID) samples, is thus an important task.
OOD detection has been addressed widely in the image classification setting [31, 35, 22, 53, 66, 6, 57, 68].
In this paper, we expand upon the limited body of work in
OOD object detection [9, 8, 7], leveraging recent theoret-Figure 1. Overview of our proposed SAFE OOD object de-tector. Feature maps are extracted from sensitivity-aware layers in the backbone of a pretrained object detector. Object-specific
SAFE vectors are extracted for the predicted bounding boxes. Pre-deployment, an auxiliary MLP is trained to distinguish the fea-ture vectors of normal ID detections (blue) from adversarially-perturbed ID samples (orange). At test time, the pipeline for the training samples is repeated (blue) for all test samples, with the auxiliary MLP producing OOD detection scores for each ob-ject in a test image.
Illustrative input images are drawn from
BDD100K [70]. ical insights on the behaviour of the feature space of DNNs.
Specifically, recent theory [34, 43, 61, 55] has highlighted the importance of ensuring that the feature space of a DNN is distance-preserving through the constraints of sensitivity and smoothness. In particular, sensitivity, i.e. the preserva-tion of input distances in the output, has been shown to play a crucial role in learning a robust feature set that avoids mapping ID and OOD data to similar feature representa-tions [61].
Furthermore, prior work established the role of adversar-ial attacks in OOD generalisation [69], increasing the sep-arability of ID samples from OOD [32, 23] and perturbing feature representations [15, 49, 36]. We thus leverage the most sensitive layers in a pretrained object detector back-bone through targeted input-level adversarial perturbations.
This paper introduces SAFE, a new approach to vi-sual OOD object detection that utilises object-specific
Sensitivity-Aware Features (Figure 1). Our approach has three core components, each offering advantages over ex-isting works in this area: 1. We identify a critical subset of layers that are sensi-tive to OOD input variations, i.e. these layers preserve differences from the input in their feature space, and trigger abnormally high activations. SAFE layers are residual convolutional layers with batch normalisation within the backbone of an object detector. We empir-ically validate their superiority for OOD detection in our results. In contrast, previous work only uses fea-tures from the classification head of the object detector and do not consider the characteristics of different lay-ers for OOD detection [9, 53, 31]. 2. We extract object-specific SAFE vectors and use a multi-layer perceptron (MLP) to classify every de-tected object as ID or OOD. This allows OOD samples to be detected in a posthoc manner, i.e. it does not re-quire retraining of the base network [68] and can be applied to any pre-trained object detector with a back-bone containing SAFE layers (e.g. ResNet [19] and
RegNetX [44]). 3. We train this MLP on the surrogate task of distin-guishing the SAFE vectors of adversarially-perturbed samples and clean ID training samples. This avoids the necessity of access to real outlier training data
[31, 25, 71, 35, 22, 47, 4, 1] or a complex generative process to synthesise such data [30, 64, 56, 52].
SAFE achieves new state-of-the-art results across multiple established benchmarks. We release a publicly available code repository to replicate our experiments at: https:
//github.com/SamWilso/SAFE_Official 2.