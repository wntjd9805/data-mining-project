Abstract
Zero-shot object detection aims to localize and recog-nize objects of unseen classes. Most of existing works face two problems: the low recall of RPN in unseen classes and the confusion of unseen classes with background.
In this paper, we present the first method that combines DETR and meta-learning to perform zero-shot object detection, named Meta-ZSDETR, where model training is formalized as an individual episode based meta-learning task. Differ-ent from Faster R-CNN based methods that firstly gener-ate class-agnostic proposals, and then classify them with visual-semantic alignment module, Meta-ZSDETR directly predict class-specific boxes with class-specific queries and further filter them with the predicted accuracy from classifi-cation head. The model is optimized with meta-contrastive learning, which contains a regression head to generate the coordinates of class-specific boxes, a classification head to predict the accuracy of generated boxes, and a contrastive head that utilizes the proposed contrastive-reconstruction loss to further separate different classes in visual space. We conduct extensive experiments on two benchmark datasets
MS COCO and PASCAL VOC. Experimental results show that our method outperforms the existing ZSD methods by a large margin. 1.

Introduction
Object detection [34] is one of the most fundamental tasks in computer vision. Most existing object detection methods require huge amounts of annotated training data, which is expensive and time-consuming to acquire. Mean-while, in reality novel categories constantly emerge, and there is seriously lack or even nonexistent of visual data of
*correspondence author
Figure 1. Zero-shot object detection: Faster R-CNN based meth-ods vs. Meta-ZSDETR. (a): Faster R-CNN based methods firstly generate class-agnostic proposals, and then classify them with dif-ferent visual-semantic alignment modules. (b): Meta-ZSDETR di-rectly predict class-specific boxes with class-specific queries and further filter them with classification head. those novel categories for model training, such as endan-gered species in the wild. The above issues motivates the investigation of zero-shot object detection, which aims to localize and recognize objects of unseen classes.
A mainstream framework of the existing works that are based on Faster R-CNN, is illustrated in Fig. 1(a), where the
RPN remains unchanged and the RoI classification head is replaced with different visual-semantic alignment modules, such as mapping to the same embedding space to calculate similarity between proposals and semantic vectors [2, 40, 41, 32, 44, 12, 25, 18, 7], synthesizing visual features from semantic vectors [17, 14, 42, 47, 27] etc.
However, we observe that the existing methods are sub-optimal, due to their obvious inherent shortcomings: i) The proposals from RPN are often not reliable enough to cover all unseen classes objects in an image because of lacking training data, which has also been identified by a recent study [19]. ii) The confusion between background and un-seen classes is an intractable problem. Although many pre-vious works have tried to tackle it [46, 14, 2], the results are still unsatisfactory.
Recently, object detection frameworks based on the
Transformer have gained widespread popularity, such as
DETR [5], Deformable DETR [48], etc. Such architectures are RPN-free and background-free, i.e., they do not involve
RPN and background class, which are naturally conducive to building zero-shot object detection methods. However, how to build a ZSD method based on DETR detectors poses new challenges. An intuitive idea is to replace DETR’s classification head with a zero-shot classifier based on co-sine similarity [43]. However, such a method simply treats
DETR as a large RPN for proposals generation, the overall framework is essentially the same as previous works.
In this paper, we present the first method that fully ex-plores DETR detectors and meta-learning to perform zero-shot object detection, named Meta-ZSDETR, which can solve the two problems mentioned above that have plagued the field of ZSD for many years, and achieves the state-of-the-art performance. The comparison of Meta-ZSDETR with previous methods is shown in Fig. 1. Different from the previous works that firstly generate class-agnostic pro-posals and then classify them with visual-semantic align-ment module, our method utilizes semantic vectors to guide both proposal generation and classification, which greatly improves the recall of unseen classes. Meanwhile, there is no background class in DETR detectors, which means the confusion between background and unseen classes is no more existent.
In order to detect unseen classes, we formalize the train-ing process as an individual episode based meta-learning task. In each episode, we randomly sample an image I and a set of classes Cπ, which contains the positive classes that ap-pear in I and negative classes that do not appear. The meta-learning task is to make the model learn to detect all positive classes of Cπ on image I. Through the meta-learning task, the training and testing can be unified, i.e., in the model testing, we need only to employ the unseen classes as the set Cπ. To enable the model to detect an arbitrary class set, we firstly fuse each object query with a projected semantic vector from the class set Cπ, which transfers the query from class-agnostic to class-specific. Then, the decoder takes the class-specific query as input and predicts the locations of class-specific boxes, together with the probabilities that the boxes belong to the fused class. To achieve the above goal, we propose meta-contrastive learning, where all predictions are split into three different types and different combina-tions of them are chosen to optimize three different heads, i.e., the regression head to generate the locations of class-specific boxes, the classification head to predict the accu-racy of generated boxes, and the contrastive head to separate different classes in visual space for performance improving with a contrastive-reconstruction loss. The bipartite match-ing and loss calculation are performed in a class-by-class manner, and the final loss is averaged over all classes in the sampled class set Cπ.
In summary, our major contributions are as follows:
• We present the first method that explores DETR and meta-learning to perform zero-shot object detection, which formalizes the training as an individual episode based meta-learning task and ingeniously tackles the two problems that plague ZSD for years.
• We propose to train the decoder to directly predict class-specific boxes with class-specific queries as in-put, under the supervision of our meta-contrastive learning that contains three different heads.
• We conduct extensive experiments on two benchmark datasets MSCOCO and PASCAL VOC to evaluate the proposed method Meta-ZSDETR. Experimental re-sults show that our method outperforms the existing
ZSD methods. 2.