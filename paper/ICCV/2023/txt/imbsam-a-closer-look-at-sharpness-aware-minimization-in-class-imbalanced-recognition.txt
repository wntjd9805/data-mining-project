Abstract
Class imbalance is a common challenge in real-world recognition tasks, where the majority of classes have few samples, also known as tail classes. We address this chal-lenge with the perspective of generalization and empiri-cally find that the promising Sharpness-Aware Minimiza-tion (SAM) fails to address generalization issues under the class-imbalanced setting. Through investigating this spe-cific type of task, we identify that its generalization bottle-neck primarily lies in the severe overfitting for tail classes with limited training data. To overcome this bottleneck, we leverage class priors to restrict the generalization scope of the class-agnostic SAM and propose a class-aware smooth-ness optimization algorithm named Imbalanced-SAM (Imb-SAM). With the guidance of class priors, our ImbSAM specifically improves generalization targeting tail classes.
We also verify the efficacy of ImbSAM on two prototyp-ical applications of class-imbalanced recognition: long-tailed classification and semi-supervised anomaly detec-tion, where our ImbSAM demonstrates remarkable perfor-mance improvements for tail classes and anomaly. Our code implementation is available at https://github. com/cool-xuan/Imbalanced_SAM . 1.

Introduction
Over the course of decades, deep neural networks have achieved remarkable success in various already-intensely-studied tasks, including classification [14, 24], segmenta-tion [40, 50], and object detection [49, 56]. These im-pressive achievements are largely attributed to large-scale datasets [13, 36], which strive for a uniform distribution of categories, contrary to the data distribution in the real open world. The real-world data is usually class-imbalanced
[7, 23, 32, 39, 57], following a long-tailed distribution: a
*Corresponding author.
Figure 1: The visualization of separate loss landscape for head and tail classes in class-imbalanced recognition, op-timized by SGD [6], SAM [17] and our ImbSAM respec-tively. small number of dominant classes (head classes) have nu-merous samples, while the majority of classes (tail classes) contain only a few samples. Directly applying SOTA meth-ods [14, 24] built under balanced data distribution to the class-imbalanced setting suffers from dramatic performance degradation [39]. This critical performance reduction is primarily caused by the overwhelming presence of head classes during training, which in turn results in inadequate learning for tail classes [23, 28, 61]. This limitation moti-vates the theoretical research on class-imbalanced recogni-tion, which drives lots of practical applications such as long-tailed classification [2, 31, 39, 57] and semi-supervised anomaly detection [20, 44, 51].
Many excellent methods [9, 11, 12, 15, 19, 35, 61] have been proposed to tackle the issue of class-imbalanced data, where plenty of methods re-balance the long-tailed data by re-sampling [15, 16] or assign large loss weights to the tail classes. While these methods alleviate the dominant pres-ence of head classes over tail classes, they overexpose the limited tail class samples, increasing the risk of overfitting for these tail classes [22].
Recent methods [2, 31] fine-tune the regularization to penalize the large parameters in turn avoiding overfitting.
Compared with the empirical regularization, Sharpness-Aware Minimization (SAM) [17], an effective optimization algorithm, is supported by a solid theoretical foundation.
SAM connects the smooth geometry of the loss landscape with generalization and captures the sharpness of the loss landscape. By simultaneously minimizing the loss value and sharpness, SAM converges the model weights to reach a smooth minimum (neighborhoods having uniformly low loss).
However, the SAM is proposed and effective in the ideal data setting (balanced distribution [13, 32]), ignoring the class imbalance in the real world. As the loss landscape visualization of SAM shown in Figure 1, SAM tends to pri-oritize generalization on the head classes since the heav-ily imbalanced data, while overlooking the tail classes in class-imbalanced recognition. Nevertheless, even without
SAM, the abundant training data of head classes also pre-vents them from suffering overfitting.
To address this issue, we first investigate the class-imbalanced recognition and identify its generalization bot-tleneck primarily lying in tail classes. As for such specific tasks with long-tailed distribution, the head classes, bene-fiting from sufficient training samples, are less affected by generalization problems [22]. On the other hand, the tail classes, with only a few data instances (sometimes even less than 10), are highly susceptible to severe overfitting. Based on these insights, we propose a class-aware smoothness op-timization algorithm named Imbalanced-SAM (ImbSAM) to tackle the overfitting problem with respect to (w.r.t.) tail classes.
In contrast to the class-agnostic SAM, our Imb-SAM introduces class priors to restrict the smoothness op-timization scope to the tail classes as illustrated in Figure 1, thereby alleviating severe overfitting of inadequate training samples of tail classes.
Our ImbSAM is compatible with existing methods, demonstrating remarkable performance promotion in proto-typical applications of class-imbalanced recognition: long-tailed classification (LTC) [2, 24, 31] and semi-supervised anomaly detection (SSAD) [20, 44, 51]. Notably, our Imb-SAM impressively improves recognition accuracy for tail classes as illustrated in Figure 2, which firmly verifies the efficacy of ImbSAM in focusing generalization scope on classes with limited training data. Our main contributions are summarized as follows:
• We approach the challenge of class-imbalanced recog-nition from a generalization perspective and identify severe overfitting on tail classes as the main general-ization bottleneck. A theoretical analysis is provided to reveal why the promising SAM fails to address the generalization issues in class-imbalanced recognition.
Figure 2: Accuracy gains (%) of each classes on
CIFAR100-LT derived from the standard SAM [17] and our class-aware ImbSAM. With the guidance of class priors (dividing data into two splits by η), our ImbSAM success-fully performs generalization targeting tail classes, which are neglected by SAM.
• To overcome the limitation of SAM, we propose the
Imbalanced SAM (ImbSAM), which incorporates class priors into the class-agnostic SAM to specifically ad-dress the overfitting problem on tail classes.
• We evaluate the efficacy of ImbSAM on two proto-typical applications of class-imbalanced recognition: long-tailed classification and semi-supervised anomaly detection, where it demonstrates remarkable perfor-mance improvements for the classes with inadequate training samples. 2.