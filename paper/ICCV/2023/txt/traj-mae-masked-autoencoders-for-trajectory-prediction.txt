Abstract
Trajectory prediction has been a crucial task in build-ing a reliable autonomous driving system by anticipat-ing possible dangers. One key issue is to generate con-sistent trajectory predictions without colliding. To over-come the challenge, we propose an efficient masked au-toencoder for trajectory prediction (Traj-MAE) that better represents the complicated behaviors of agents in the driv-ing environment. Specifically, our Traj-MAE employs di-verse masking strategies to pre-train the trajectory encoder and map encoder, allowing for the capture of social and temporal information among agents while leveraging the effect of environment from multiple granularities. To ad-dress the catastrophic forgetting problem that arises when pre-training the network with multiple masking strategies, we introduce a continual pre-training framework, which can help Traj-MAE learn valuable and diverse information from various strategies efficiently. Our experimental results in both multi-agent and single-agent settings demonstrate that Traj-MAE achieves competitive results with state-of-the-art methods and significantly outperforms our base-line model. Project page: https://jiazewang.com/ projects/trajmae.html. 1.

Introduction
The goal of trajectory prediction is to predict the future trajectories of moving agents (e.g., pedestrians and vehi-cles), which is a crucial problem for building a safe, com-fortable, and reliable autonomous driving system [32, 66, 37, 12, 51]. Many promising works [21, 7, 49, 26, 70, 60] have been proposed with great interest and demand from academia and industry. It has been demonstrated that mod-eling complex interactions between agents [47, 44, 46, 6, 27] is of great importance in trajectory prediction. On this
*Equal contribution
† Corresponding author: gychen@zhejianglab.com
Figure 1: An example of our masking and reconstruc-tion strategy for trajectory prediction. A portion of the historical trajectory and HD map is masked, the trajectory autoencoder and the map autoencoder are separately trained to recover the masked parts from the corrupted input. The green curve denotes the ego agent, the blue curves denote the surrounding agents, the same in the following figures in this paper. basis, to address the colliding prediction problem and gener-ate consistent trajectory predictions, it is essential to model social and temporal relations between agents and to have a global understanding of maps [2]. In this paper, we investi-gate this issue using self-supervised learning.
Self-supervised learning aims to learn latent seman-tics from unlabeled data rather than building representa-tions based on human annotations. Recent years have witnessed noteworthy advancements in the application of language processing self-supervised learning to natural
[14, 62] and computer vision [57, 38, 4]. One of the most promising self-supervised methods is the masked au-toencoders (MAE) [23] which achieve success in various tasks [39, 53, 73, 72, 22]. Furthermore, pre-train and fine-tune on the same small-scale datasets are also essential to learn a good representation [15]. Inspired by these works, we aim to explore the complex interactions between agents and the multiple granularities of maps using masked autoen-coders. How to design an efficient masked autoencoder to generate consistent trajectory predictions? We attempt to answer the question from the following perspectives: (i) The information density of trajectory and high defi-nition (HD) maps differs significantly from that of images.
While images are natural signals with high spatial redun-dancy, trajectories represent continuous temporal sequential signals with complex social interactions between agents, and HD maps contain highly structured information. Given the differences, models aimed at trajectory prediction re-quire corresponding adjustments to capture informative fea-tures. Therefore, we investigate various masking strategies and suitable masking ratios for trajectories and HD maps.
We develop both social and temporal masking to enable the trajectory encoder to capture information from diverse per-spectives. We also study multiple granularities masking to enforce the map encoder to capture structural information from HD maps. Furthermore, we find that regardless of the masking strategy adopted, a high masking ratio (50% ∼ 60%) yields favorable results, which demands the encoders to acquire a holistic understanding of historical trajectories and HD maps. (ii) The absence of an efficient framework for pre-training multiple strategies poses a challenge for effective multimodal trajectory prediction. While traditional multi-task learning from scratch [74] may struggle to converge due to the complex nature of this task, traditional contin-ual learning methods [11, 40] are limited by their inability to train the network with multiple tasks without forgetting previously learned knowledge. To address this issue, we propose a novel approach that trains the new strategy simul-taneously with the original strategies, utilizing previously learned parameters to initialize the network. Therefore, we ensure that our network can acquire new knowledge while retaining previously obtained knowledge.
Driven by the analysis, we present Masked Trajectory
Autoencoder (Traj-MAE), an efficient and practical frame-work for self-supervised trajectory prediction. As depicted in Figure 1, Traj-MAE leverages partial masking of the in-put trajectory and HD map, utilizing the trajectory encoder and map encoder to reconstruct the masked segments, re-spectively. Through employing diverse masking strategies to reconstruct missing parts of the input trajectory and HD map, the trajectory encoder and map encoder can acquire a comprehensive understanding of the latent semantics of the inputs from various perspectives. Moreover, we intro-duce a novel continual pre-training framework, which is a highly-efficient learning approach that trains the model with multiple strategies simultaneously, mitigating the issue of catastrophic forgetting.
Our core contributions are as follows:
• To our best knowledge, we are the first to present a neat and efficient masked trajectory autoencoder for self-supervised trajectory prediction.
• We explore different masking strategies which fully utilize MAE to exploit the latent semantics of histor-ical trajectory and HD map. Meanwhile, a continual pre-training framework is proposed to efficiently train the model with multiple strategies.
• We conduct extensive experiments on the Argoverse, and INTERACTION for autonomous driving trajec-tory prediction, and the synthetic partition of Tra-jNet++ for pedestrian trajectory prediction. Our Traj-MAE achieves competitive results on these bench-marks and outperforms our baseline model by a no-table margin. 2.