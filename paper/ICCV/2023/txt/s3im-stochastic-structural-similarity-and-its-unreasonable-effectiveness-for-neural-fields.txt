Abstract
Ground Truth
Standard
Multiplex (Ours)
Recently, Neural Radiance Field (NeRF) has shown great success in rendering novel-view images of a given scene by learning an implicit representation with only posed RGB images. NeRF and relevant neural field methods (e.g., neu-ral surface representation) typically optimize a point-wise loss and make point-wise predictions, where one data point corresponds to one pixel. Unfortunately, this line of research failed to use the collective supervision of distant pixels, al-though it is known that pixels in an image or scene can provide rich structural information. To the best of our knowl-edge, we are the first to design a nonlocal multiplex training paradigm for NeRF and relevant neural field methods via a novel Stochastic Structural SIMilarity (S3IM) loss that pro-cesses multiple data points as a whole set instead of process multiple inputs independently. Our extensive experiments demonstrate the unreasonable effectiveness of S3IM in im-proving NeRF and neural surface representation for nearly free. The improvements of quality metrics can be particu-larly significant for those relatively difficult tasks: e.g., the test MSE loss unexpectedly drops by 90% for TensoRF and
DVGO over eight novel view synthesis tasks; a 198% F-score gain and a 64% Chamfer L1 distance reduction for NeuS over eight surface reconstruction tasks. Moreover, S3IM is consistently robust even with sparse inputs, corrupted images, and dynamic scenes. 1.

Introduction a c i l p e
R
-O
G
V
D
T
&
T
-O
G
V
D
T
&
T
-F
R e
N
T
&
T
-F
R o s n e
T
Figure 1. Qualitative comparison of standard training and multiplex training for neural radiance field on Replica Dataset [30] and T&T-Advanced Dataset [10]. Model: DVGO, TensoRF, and NeRF.
Synthesizing novel-view images of a 3D scene from a group of images is a long-standing task in computer vision and computer graphics [4, 5, 12, 8, 28]. This long-standing task has recently made significant progress due to advances in learning-based neural rendering methods [22, 13, 15].
Learning-based neural field methods can represent 3D scenes
*Equal Contributions. {xiezeke,yangxindi}@baidu.com. and even the corresponding surfaces from posed images toward photorealistic novel-view synthesis.
Particularly, benefited from strong representations of deep neural networks (DNNs), Neural Radiance Field (NeRF)
[15] has shown impressive success in synthesizing novel view synthesis of a given scene by implicitly encoding vol-umetric density and color through a fully connected neu-ral network (often referred to as a multilayer perceptron or MLP). NeRF regresses from a single 5D representation (x, y, z, θ, ϕ)- 3D coordinates x = (x, y, z) plus 2D view-ing directions d = (θ, ϕ)- a single volume density σ and a view-dependent RGB color c = (r, g, b), computed by fitting the model to a group of pixels (from training images).
NeRF approximates this continuous 5D scene representation with an MLP network fΘ : (x; d) → (c; σ) and optimizes its weights Θ to map each input 5D coordinate to the corre-sponding volume density and directional emitted color.
Without loss of generality, we focus on the learning mod-ule of NeRF and write the loss optimized by NeRF as
L(Θ) = 1
∥R∥ (cid:88) r∈R lMSE(Θ, r), (1) where lMSE is the point-wise Mean Squared Error (MSE) loss for each pixel/ray r = (xr, dr, cr) in the training data or data minibatch R. Obviously, the MLP of NeRF learns and makes inference point-wisely, because one data point of the MLP corresponds to one pixel’s information.
NeRF and neural surface representation are two of the most representative neural field methods [38], which are also called implicit neural representation methods [29] in com-puter vision. Neural surface representation [14, 18, 41, 32] is another important and long-standing problem orthogonal to NeRF. The point-wise MSE loss not only measures the accuracy of predictions in NeRF, but is also widely used in other relevant neural field methods. However, only optimiz-ing point-wise loss can be a serious but overlooked pitfall of training NeRF and relevant methods.
In image quality assessment, the point-wise MSE-based metric Peak Signal-to-Noise Ratio (PSNR) [6] is widely used but do not correlate well with perceived image quality
[21, 34], since point-wise metrics do not reflect structural information [11, 35, 36, 27] that is rich in the physical world.
The Structural Similarity (SSIM) index not only reflects the structure of a group of pixels, but also correlates with human visual systems significantly better than PSNR/MSE
[35, 9]. SSIM is an important performance metric for eval-uating NeRF models, but it is not used for training NeRF models. The conventional training paradigm of NeRF has un-fortunately overlooked the structural information, as it only optimizes the point-wise MSE loss but not using the col-lective supervision of the structural information of multiple pixels. This is not surprising. The conventional point-wise paradigm is also common in other machine learning models.
Can we propose a novel training paradigm that can cap-ture the structural information of a group of inputs in ways other than the MSE loss of individual pixels? Yes, we for-mulate a multiplex loss associated with the novel training paradigm as
LM(Θ) = 1
∥R∥ (cid:88) r∈R lMSE(Θ, r) + λLS3IM(Θ, R), (2) where LS3IM(Θ, R) is computed over a group of nonlo-cal pixels and the hyperparameter λ adjusts the impor-tance of S3IM. Unlike LS3IM(θ, R), the conventional loss lMSE(θ, (x, d, c, σ)) is computed pixel-wisely. We empha-size that LS3IM(Θ, R) cannot be expressed as the sum of any other loss computed over individual pixels from R. We call the proposed LS3IM a multiplex loss because it allows a model to process multiple nonlocal inputs as a whole multi-plex input. We will formally define S3IM in Section 3.
Main Contributions. We summarize main contributions as follows. (1) We propose the novel Stochastic Structural
SIMilarity (S3IM) index, which measures the similarity be-tween two groups of pixels and captures nonlocal structural similarity information from stochastically sampled pixels.
To the best of our knowledge, we are the first to formulate a multiplex loss that can process multiple inputs collectively by capturing nonlocal information rather than processing multiple inputs independently by capturing individual-pixel information in neural fields. (2) S3IM is model-agnostic and can be generally applied to all types of neural field meth-ods, such as NeRF and neural surface representation, with limited coding costs and computational costs. Our exten-sive experiments demonstrate the unreasonable effectiveness of the nonlocal multiplex training paradigm in improving
NeRF and neural surface representation. Particularly, the improvement in quality metrics can be especially significant for those difficult tasks (e.g., Tables 1 and 6 and Figure 1) and is robust even with sparse inputs, corrupted images, and dynamic scenes. 2.