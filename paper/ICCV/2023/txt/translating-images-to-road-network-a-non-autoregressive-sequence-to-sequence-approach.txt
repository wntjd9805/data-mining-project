Abstract
The extraction of road network is essential for the gen-eration of high-definition maps since it enables the pre-cise localization of road landmarks and their interconnec-tions. However, generating road network poses a signif-icant challenge due to the conflicting underlying combi-nation of Euclidean (e.g., road landmarks location) and non-Euclidean (e.g., road topological connectivity) struc-tures. Existing methods struggle to merge the two types of data domains effectively, but few of them address it properly.
Instead, our work establishes a unified repre-sentation of both types of data domain by projecting both
Euclidean and non-Euclidean data into an integer series called RoadNet Sequence. Further than modeling an auto-regressive sequence-to-sequence Transformer model to un-derstand RoadNet Sequence, we decouple the dependency of RoadNet Sequence into a mixture of auto-regressive and non-autoregressive dependency. Building on this, our pro-posed non-autoregressive sequence-to-sequence approach leverages non-autoregressive dependencies while fixing the gap towards auto-regressive dependencies, resulting in suc-cess on both efficiency and accuracy. Extensive experiments on nuScenes dataset demonstrate the superiority of Road-Net Sequence representation and the non-autoregressive approach compared to existing state-of-the-art alternatives. 1.

Introduction
With the rising prevalence of self-driving cars, a deep knowledge of the road structure is indispensable for au-*Equal contribution
†Li Zhang (lizhangfd@fudan.edu.cn) is the corresponding author with
School of Data Science, Fudan University.
Figure 1. High-definition Road Network Topology contains Eu-clidean data: locations of landmarks and shapes of curves and non-Euclidean data: road topology. A special sequence, Road-Net Sequence, is proposed as a unified representation of both do-mains. Then we use a Non-Autoregressive sequence-to-sequence approach to extract RoadNet Sequence from multi-camera input efficiently and accurately. tonomous vehicle navigation [16, 26, 44, 13]. Road net-work [12, 38, 42] extraction is required to estimate highly accurate road landmark locations, centerline curve shapes and road topological connection for self-driving vehicles.
However, the ability to understand road network in real-time using onboard sensors is highly challenging.
In the literature, road network is differentiated from methods that focus solely on grid-like Euclidean data [6, 5] such as lane detection [60, 36, 61] or BEV semantic under-standing [39, 50, 34, 37]. Instead, road network emphasizes a more comprehensive understanding of both Euclidean do-main and non-Euclidean domain. As shown in Figure 1, accurate road landmark locations such as crossroads, stop-lines, fork-roads, and the shape of centerline curves pertain to the Euclidean domain, whereas road topology belongs to
the non-Euclidean domain. In mathematical terms [5, 6],
Euclidean data is defined in R2. On the other hand, non-Euclidean data, such as graphs that indicate connectivity among nodes, will lose crucial information if projected to
Rn, such as edge curve information.
Unfortunately, existing attempts [9, 10] to extract road network using onboard sensors have not been able to achieve a harmonious integration between Euclidean and non-Euclidean data. STSU [9] divides the road network construction into two stages: center-lines detection and center-line connectivity reasoning—which ignores the co-operation between Euclidean and non-Euclidean domains.
TPLR [10] uses a Transformer or Polygon-RNN [1] to com-bine topology reasoning with center-line localization, but the embedded conflicts between Euclidean data representa-tions and connectivity representation undermine the model performance.
In this work, we propose that the dilemma in existing works arises due to the absence of a unified representa-tion of both Euclidean and non-Euclidean data.
Instead, we introduce a Euclidean-nonEuclidean unified representa-tion with merits of losslessness, efficiency and interaction.
The unified representation, named as RoadNet Sequence, projects both Euclidean and non-Euclidean aspects of road network to integer series domain Zn. The “losslessness” aspect is ensured by establishing a bijection from road net-work to RoadNet Sequence. “Efficiency” is achieved by limiting RoadNet Sequence length to the shortest O(|E|) (where E is the set of all centerlines), through a specially designed topological sorting rule. “Interaction” reveals the interdependence between Euclidean and non-Euclidean in-formation within a single sequence.
Based on the auto-regressive dependency of topologi-cal sorting, we leverage the sequence-to-sequence genera-tion power of Transformer [53, 7, 15] to understand Road-Net Sequence from onboard round-view cameras, called
RoadNetworkTRansformer (RNTR).
However, in practice, the auto-regressive dependency in sequence-to-sequence generation can significantly slow down the inference speed. Our observation is that the de-pendency of road network can be decoupled into a semi-autoregressive format, that retains auto-regressive function-ality within local contexts while simultaneously conducting multiple generations in parallel. This semi-autoregressive model is called Semi-Autoregressive RoadNetTransformer (SAR-RNTR). This approach not only accelerates the in-ference speed by 6 times, but it also significantly boosts the accuracy to a new level based on the better depen-dency modeling. Going beyond SAR-RNTR, we employ a masked training technique on SAR-RNTR to mimic the re-maining auto-regressive dependency through iterative pre-diction [32]. This gives rise to our Non-Autoregressive
RoadNetTransformer (NAR-RNTR) model, which achieves real-time inference speed (47× faster) while maintaining the high performance.
To evaluate road network extraction quality, apart from inheriting the former metrics [9] based on lane detection, we instead design a family of metrics directly based on def-inition of road network – Landmark Precision-Recall and
Reachability-Precision-Recall – to evaluate (i) road land-marks localization accuracy, and (ii) path accuracy between any reachable landmarks.
We make the following contributions: (i) we introduce
RoadNet Sequence, a lossless, efficient and unified repre-sentation of both Euclidean and non-Euclidean information from road network. (ii) We propose a Transformer-based
RoadNetTransformer which can decode RoadNet Sequence from multiple onboard cameras. (iii) By decoupling auto-regressive dependency of RoadNet Sequence, our proposed
Non-autoregressive RoadNetTransformer accelerate the in-ference speed to real-time while boost the accuracy with a significant step from the auto-regressive model. (iv) Exten-sive experiments on nuScenes [8] dataset validate the supe-riority of RoadNet Sequence representation and RoadNet-Transformer over the alternative methods with a consider-able margin. 2.