Abstract
Not all camouflages are equally effective, as even a par-tially visible contour or a slight color difference can make the animal stand out and break its camouflage. In this paper, we address the question of what makes a camouflage suc-cessful, by proposing three scores for automatically assess-ing its effectiveness. In particular, we show that camouflage can be measured by the similarity between background and foreground features and boundary visibility. We use these camouflage scores to assess and compare all available cam-ouflage datasets. We also incorporate the proposed cam-ouflage score into a generative model as an auxiliary loss and show that effective camouflage images or videos can be synthesised in a scalable manner. The generated syn-thetic dataset is used to train a transformer-based model for segmenting camouflaged animals in videos. Experimen-tally, we demonstrate state-of-the-art camouflage breaking performance on the public MoCA-Mask benchmark. 1.

Introduction
Camouflage has long been a subject of interest and fas-cination for the scientific community, especially evolution-ary biologists who consider it as an excellent example of species adaptation. In order to confuse predators or to hide from prey, and increase their chances of survival in their natural habitat, animals have developed numerous cam-ouflage mechanisms, e.g., disruptive coloration and back-ground matching. Some species have even evolved to de-velop an adaptive camouflage, e.g., an arctic fox loses its white fur to better match the brown grey of the new season’s landscape. Perhaps the most dramatic camouflage adapta-tion is the cuttlefish; it changes its patterns dynamically and rapidly as it moves from one spot to the other, constantly adapting and improving its camouflage.
This search for optimal camouflage has inspired nu-merous works in the computer vision community, such as [12, 27], that tackled camouflage as a problem of optimal texture synthesis, making 3D objects non-detectable in a given scene. Others have addressed camouflage as a highly
Figure 1: The three images depict the same animal, an Arc-tic fox, as it adapts its appearance to better blend with the changing landscape of the new season. While images a and c exhibit better background similarity than image b, the fox boundary is more visible in image a than image c. We assess the effectiveness of camouflage by measuring the degree of ambiguity it creates with respect to its background. challenging object segmentation task in [9, 15, 20, 23]. Ef-forts have been made in collecting large scale camouflage datasets [9, 20] with costly annotation. In fact, camouflaged animals often exhibit complex shapes and thin structures that add to the boundary ambiguity and make the annota-tion highly time-consuming. Fan et al. report up to 60min per image to provide accurate pixel-level annotations for their dataset COD10K [9]. While another line of research turned to camouflage breaking in sequences by taking ad-vantage of motion cues [1, 5, 18, 19, 40], the camouflage data scarcity is even more extreme for videos. Recently,
Sim2Real [18, 39] training has shown to be very effective for motion segmentation. By training on the optical flows of synthetic videos, these models can generalise to real videos without suffering from the domain gaps.
In this paper, we start by asking the question: ªwhat are the properties of a successful camouflage ?º To an-swer this question, we investigate three scoring functions for quantifying the effectiveness of camouflage, namely, reconstruction fidelity score (SRf ), boundary score (Sb) and intra-image FrÂechet score (dF ). These scores are later adopted for two critical roles, (i) they are used to assess the relevance of existing camouflage datasets and act as quality-indicator in collecting new camouflage data; (ii) 1
they can be used as a proxy loss for image and video in-painting/generation, where we establish a synthetic camou-flage data generation pipeline with a Generative Adversar-ial Network (GAN), that can simultaneously generate high-quality camouflage examples and masks of the camouflaged animals. We further train a Transformer-based architecture on the generated camouflage video sequences, and demon-strate a performance boost over training on only the (small scale) real data.
In summary, we make the following contributions: First, we introduce three scoring functions to measure the effec-tiveness of a given camouflage in still images and videos.
We use these camouflage scores to rank the images in exist-ing datasets in terms of camouflage success, and also show that the rankings are largely in accordance with human-produced rankings. Second, we incorporate the camou-flage score into a generative model, establishing a scalable pipeline for generating high-quality camouflage images or videos, along with the pixelwise segmentation mask of the camouflaged animals; Third, we show that a Transformer-based model trained on the synthetically generated data can achieve state-of-the-art performance on the MoCA-Mask video camouflaged animal segmentation benchmark. 2.