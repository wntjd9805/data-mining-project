Abstract
In this paper, we focus on a general yet important learning problem, pairwise similarity learning (PSL). PSL subsumes a wide range of important applications, such as open-set face recognition, speaker verification, image retrieval and person re-identification. The goal of PSL is to learn a pair-wise similarity function assigning a higher similarity score to positive pairs (i.e., a pair of samples with the same label) than to negative pairs (i.e., a pair of samples with differ-ent label). We start by identifying a key desideratum for
PSL, and then discuss how existing methods can achieve this desideratum. We then propose a surprisingly simple proxy-free method, called SimPLE, which requires neither feature/proxy normalization nor angular margin and yet is able to generalize well in open-set recognition. We apply the proposed method to three challenging PSL tasks: open-set face recognition, image retrieval and speaker verification.
Comprehensive experimental results on large-scale bench-marks show that our method performs significantly better than current state-of-the-art methods. Our project page is available at simple.is.tue.mpg.de. 1.

Introduction
How to learn discriminative representations is arguably one of the most fundamental and important problems in com-puter vision, speech processing and natural language process-ing. For closed-set classification (e.g., image recognition), it is sufficient to learn class-separable representations as the goal is to infer the label of the input sample. However, for open-set recognition problems such as face recognition [14], speaker verification [1], person re-identification [80] and image retrieval [11], learning class-separable representations is not enough, because the goal becomes learning a similar-ity function that separates positive and negative pairs well.
We study a general problem that is abstracted from these applications – pairwise similarity learning (PSL).
PSL aims to learn a pairwise similarity function such that minimal intra-class similarity is larger than maximal inter-class similarity (or in other words, maximal intra-class
Figure 1: Comparison between classification and PSL. distance is smaller than minimal inter-class distance). When this criterion is satisfied, one can easily find a universal threshold that perfectly separates arbitrary positive and neg-ative sample pairs. This property suggests that (i) perfect verification can be achieved and (ii) labels can be fully recov-ered by simple hierarchical clustering. Compared to classifi-cation, PSL presents a more challenging problem of learning large-margin representations, as illustrated by Figure 1.
PSL can be viewed as a generalization of deep metric learning (DML). While DML requires the dissimilarity func-tion to be a distance metric that satisfies non-negativity and the triangle inequality, PSL does not necessarily need to follow these criteria. For example, [13, 37, 67, 68] learn a cosine similarity that separates positive and negative pairs. 1.1. Desideratum for Pairwise Similarity Learning
We start by formally describing the desideratum of PSL.
PSL seeks to learn a pairwise similarity function S(x1, x2) that is typically symmetric (i.e., S(x1, x2) = S(x2, x1)).
The desired pairwise similarity function needs to always satisfy the following inequality: S(xi, xj) > S(xp, xq) where xi, xj denote an arbitrary pair of samples with the same label, and xp, xq denote an arbitrary pair with different labels. This inequality implies that no negative pair has a larger similarity score than positive pairs. With a labeled dataset, we can further interpret the criterion as min k,i̸=j (cid:124)
S(x[k] i
, x[k] j ) (cid:125)
> max m̸=n,p,q (cid:124) (cid:123)(cid:122)
Minimal intra-class similarity score (cid:123)(cid:122)
Maximal inter-class similarity score (cid:125)
S(x[m] p , x[n] q ) (1) where x[k] i denotes the i-th sample in the k-th class. Nor-mally, there are two ways to parameterize the similarity
function. A naive way is to directly parameterize the similar-ity function as a neural network θ, resulting in Sθ(xi, xj).
However, this parameterization is not scalable for inference, since obtaining all the pairwise similarity scores for N sam-ples requires network inference with complexity O(N 2). A more sensible way is to, instead, parameterize the similarity score as S(fθ(xi), fθ(xj)), where S is usually a simple and efficient similarity measure (e.g., cosine similarity) and fθ is a neural feature encoder parameterized by θ. Such a param-eterization only requires O(N ) time for network inference and O(N 2) time for simple pairwise similarity function eval-uation. Current PSL methods really boil down to learning a feature encoder that can achieve Eq. 1.
The criterion of Eq. 1 essentially suggests that simple clustering of features leads to perfect classification. Unlike classification problems seeking separable feature representa-tions, PSL aims at large-margin features such that the labels can be recovered by hierarchical clustering. Bearing the desideratum in mind, we first examine how existing PSL methods approach this goal, and then propose a PSL frame-work that is surprisingly simple yet effective to achieve this. 1.2. Taxonomy of Pairwise Similarity Learning
Towards such a desideratum, there are currently two main types of method: proxy-based PSL (e.g., [13, 37, 67, 69]) and proxy-free PSL (e.g., [17, 57, 63]). Proxy-based PSL uti-lizes an intermediate parametric sample to serve as a proxy for a group of samples (typically one proxy for one class), which has been shown to benefit convergence and training stability. However, these advantages also come at a price in the sense that it is more difficult for proxy-based PSL to achieve the desideratum. How to achieve Eq. 1 with the presence of proxies is highly nontrivial and usually requires additional design to the loss function [37, 38]. Typical ex-amples of proxy-free PSL include contrastive loss [8, 17] and triplet loss [73], where no proxies are used during train-ing. Although proxy-free PSL can easily use Eq. 1 as the training target, how to construct pairs or triplets becomes especially crucial for convergence and generalization. Hard sample mining matters significantly for performance [77].
Because Eq. 1 is generally intractable to achieve for large training sets, the key difference between proxy-based PSL and proxy-free PSL originates from how they approximate this criterion. Proxy-based PSL achieves Eq. 1 by crafting a relationship between samples and proxies. Proxy-free PSL implements Eq. 1 by sampling a few representative intra-class and inter-class sample pairs, rather than enumerating all the possible pairs. Therefore, how these representative pairs are selected plays a crucial role in determining whether
Eq. 1 can be effectively achieved.
Categorization of PSL can also be made from the per-spective of how the similarity scores between different pairs interact with each other during optimization [74]. Specif-Proxy-based
Proxy-free
Angular
VGGFace [52]
Triplet [45]
SphereFace [37]
NormFace [68]
CosFace [67, 69]
ArcFace [13]
SoftTriple [55]
Circle Loss [61]
HUG [39]
Triplet
Non-angular
Angular
Non-angular
DeepID [62]
DeepFace [63]
DeepID2* [60]
L-Softmax [38]
Center Loss* [75]
Proxy NCA [47]
Proxy-Anchor [27]
FaceNet [57]
Angular Loss [70]
Tuplet [81]
SupCon [25]
Smooth-AP [2]
HUG [39]
Triplet Loss [73]
N-pair [58]
LiftedStruct [59]
InfoNCE [51]
Log-ratio [28]
Ranked List [72]
SNR [82]
Pair SphereFace2 [74]
BCE [24, 30]
Center Loss* [75]
AMC-Loss [7]
RBM [49]
Siamese [8, 17]
DeepID2* [60]
Multi-sim [71]
SNR [82]
SimPLE
Table 1: Taxonomy of some representative PSL methods. * indi-cates that the method has hybrid components. ically, if the training involves comparing the similarity scores between different pairs, then we call it triplet-based learning. Typical examples include triplet loss [57, 73] and almost all the margin-based softmax cross-entropy losses [13, 26, 37, 43, 67, 69]. In contrast, if the training directly compares the pair similarity scores to a universal value, then we call it pair-based learning. Examples include contrastive loss [8] and binary cross-entropy [74]. For down-stream tasks that focus on comparing pairs of samples, pair-based learning can be preferable since its training objective is more aligned with the testing scenario.
There are also several similarity functions that are widely adopted in PSL: angular similarity [13, 37, 57, 67, 69, 70], inner product [60, 62] and Euclidean distance [8, 17]. An-gular similarity has become a de facto choice in open-set recognition, since it can effectively avoid degenerate solutions in triplet-based learning [36, 57] and also help to incorporate angular margin for softmax cross-entropy losses [13, 36, 37, 67, 69, 74]. We summarize a taxonomy for some representative PSL methods in Table 1. 1.3. Motivation and Contribution
Looking into Eq. 1 for PSL, we can observe a few char-acteristics: (1) similarity is only computed between sam-ples and no proxies are involved; (2) there exists a univer-sal threshold that separates intra-class similarity score and inter-class similarity score. The two observations suggest that pair-based proxy-free learning is best aligned with the desideratum. Despite the perfect alignment between the training target of pair-based proxy-free learning and the desideratum, this category remains largely unexplored and existing methods from it are not particularly competitive.
Some natural questions arise: Why don’t pair-based proxy-free PSL methods work as well as expected? Can we realize the full potential for this type of method? Driven by these questions, our paper studies pair-based proxy-free learning and develops a working algorithm for this approach.
To this end, we first challenge the necessity of a few de facto components in state-of-the-art PSL methods, such as angular similarity [37, 40, 57, 68] and angular margin [37], and then propose a surprisingly simple yet effective pair-based proxy-free PSL framework, dubbed SimPLE, where neither angular similarity nor margin is needed. Our major contributions can be summarized as follows:
• We rethink the desideratum of pairwise similarity learning, which effectively subsumes many important applications.
We identify that pair-based proxy-free learning is most aligned with such a desideratum.
• We challenge a few dominating components in current PSL methods (e.g., angular similarity and margin), and find that they are not necessary in the pair-based proxy-free regime.
• We propose SimPLE, a surprisingly simple yet effective pair-base proxy-free learning framework that is designed directly based on the desideratum of PSL.
• Most importantly, we show that SimPLE can easily achieve state-of-the-art performance on open-set face recognition, image retrieval, and speaker verification. We note that this is the first time that a PSL method achieves state-of-the-art performance without the help of angular similarity and margin in open-set face recognition. 2. Rethinking Pairwise Similarity Learning
We start by examining how different types of PSL meth-ods achieve Eq. 1. Since proxy-based PSL models the rela-tionship between samples and proxies, it approximates Eq. 1 through the constraint embedded in the similarity function.
Specifically, we consider a two-class scenario. We have sam-ples xi and xj from the first class constitute the minimal intra-class similarity. xk (class 1) and zk (class 2) yield the maximal inter-class similarity. Then PSL’s desideratum requires us to have S( ˜xi, ˜xj) > S( ˜xk, ˜zk) where we de-fine ˜x = fθ(x) for notation convenience. For proxy-based
PSL to achieve this inequality, we first consider a triangular inequality for the similarity score function:
S(v1, v3) − S(v2, v3) ≥ S(v1, v2) ≥ S(v1, v3) + S(v2, v3) which is also satisfied by the prominent angular similarity, i.e., S(v1, v2) = 1 − 1
∥v1∥·∥v2∥ ). Then we have
π arccos( 1 v2 v⊤
S( ˜xi, w1) − S( ˜xj, w1) ≥ S( ˜xi, ˜xj)
S( ˜xk, ˜zk) ≥ S( ˜xk, w2) + S( ˜zk, w2) (2) which leads to the following sufficient condition for
S( ˜xi, ˜xj) > S( ˜xk, ˜zk) to hold:
S( ˜xi, w1) (cid:125) (cid:123)(cid:122) (cid:124)
Intra-class similarity
− (cid:0)S( ˜xj, w1) + S( ˜xk, w2)(cid:1) (cid:125) (cid:123)(cid:122)
Margin between similarity scores (cid:124)
> S( ˜xk, w2) (cid:125) (cid:123)(cid:122)
Inter-class similarity (cid:124) where w1 and w2 denote the proxy for class 1 and 2, re-spectively. For proxy-based PSL to achieve the desideratum,
Figure 2: Comparison of different types of PSL. we have to introduce a margin between intra-class and inter-class similarity score. Without the margin, S( ˜xi, w1) >
S( ˜xk, w2) is the criterion for standard classification and only implies separable features. The triangular inequality indicates that with a proper distance metric being the dis-similarity function, it will be easier for proxy-based PSL to achieve the desideratum in Eq. 1. Therefore, margin is actually indispensable for proxy-based PSL.
Then we discuss why angular similarity is widely adopted in PSL. We consider the softmax cross-entropy loss:
LCE = log (cid:0)1 + (cid:88) i̸=y exp(w⊤ i ˜x − w⊤ y ˜x)(cid:1) (3) where wi denotes the i-th class proxy (i.e., last-layer classi-fier) and ˜x is the feature (y is the label). We have that lim
∥x∥→∞
LCE = (cid:26) 0 if ∀i ̸= y, w⊤
+∞ if ∃i ̸= y, w⊤ y ˜x > w⊤ y ˜x < w⊤ i ˜x i ˜x (4) which implies that as long as the feature can be classified to the correct class (i.e., features are separable), then the softmax cross-entropy loss can be trivially minimized by
In order to eliminate these increasing the feature norm. degenerate solutions, common practice [13, 34, 37, 67–69] resorts to normalizing both proxy weights and features to a fixed length, leading to the popular angular similarity. One may notice an obvious caveat here – both angular margin and angular similarity are especially designed for proxy-based learning. Neither is necessary for proxy-free learning.
Now we discuss how proxy-free learning approximates the desideratum in Eq. 1. Contrastive loss [8, 17] and triplet loss [57, 73] are arguably the most representative proxy-free PSL methods. Since it is computationally intractable to enumerate all the possible sample pairs or triplets, both
contrastive and triplet losses heavily rely on hard sample mining which essentially seeks representative samples to approximate the minimal intra-class and maximal inter-class similarity. Moreover, triplet loss also has similar degenerate solutions as the softmax cross-entropy loss, so it is usually used together with feature normalization [57]. One signifi-cant difference between triplet-based learning and pair-based learning is the use of a universal threshold. For example, a triplet loss enforces the similarity between an anchor and a positive sample to be larger than the similarity between the anchor and a negative sample. In contrast, pair-based learn-ing (e.g., contrastive loss and SphereFace2 [74]) compares both positive and negative pairs to a universal threshold, which inherently draws a consistent decision boundary be-tween positive pairs and negative pairs and is more aligned with PSL’s desideratum.
We give an intuitive comparison of different types of PSL in Figure 2. The target of pair-based proxy-free PSL is per-fectly aligned with the desideratum that minimal intra-class similarity score is larger than maximal inter-class similarity score. Surprisingly, we find that neither angular similarity (i.e., feature/proxy normalization) nor angular margin is nec-essary. Further, we identify two important aspects that are essential for pair-based proxy-free PSL: (1) pair sampling, which affects how accurately it can approximate the desidera-tum in Eq. 1; (2) similarity score, which should be consistent across training and testing. In Section 3, we discuss how we use a simple design to address these issues. 3. An Embarrassingly Simple PSL Framework
We aim for SimPLE to be as simple as possible without introducing additional assumptions or priors. We formulate pair-based proxy-free PSL as a pair classification problem, which yields the following naive loss formulation:
Ln =E{ ˜x1, ˜x2}∼D (cid:26) yp · log (cid:0)1 + exp(−S( ˜x1, ˜x2) − b)(cid:1)+ (1 − yp) · log (cid:0)1 + exp(S( ˜x1, ˜x2) + b)(cid:1) (cid:27) (5) where yp = 1 if ˜x1 and ˜x2 are from the same class, and yp = 0 otherwise. This is essentially a binary logistic regression without classifiers (i.e., binary cross entropy). The advantage of such a formulation can be better understood from its decision boundary S( ˜x1, ˜x2) + b = 0. When S( ˜x1, ˜x2) is larger than −b, then ˜x1 and ˜x2 are predicted to the same class. Otherwise, they are predicted as a negative pair.
Similarity score. Cosine similarity (or angular similarity) has been the de facto standard in open-set face recogni-tion [13, 37, 67–69], speaker verification [9, 41, 66] and image retrieval [48]. Despite its popularity, angular similar-ity introduces an assumption that features are supposed to be discriminative on the unit hypersphere. However, Eq. 1 does
Figure 3: Illustration of SimPLE’s pair construction. not necessitate angular similarity. As long as the similarity score is consistent across training and testing, then we can expect it to generalize well. We start with the simplest case without any assumption – the inner product as the similarity score: S( ˜x1, ˜x2) = ⟨ ˜x1, ˜x2⟩ = ∥ ˜x1∥ · ∥ ˜x2∥ · cos(θ ˜x1, ˜x2 ).
However, the sign of the inner product completely depends on the angle between two features. When the angle is smaller than π 2 , then increasing the similarity can trivially become increasing the feature magnitude. When the angle is larger than π 2 , then decreasing the similarity can also trivially be-come decreasing the feature magnitude. We find it to be a strong assumption to use π 2 as the sign boundary. Therefore, we remove such an assumption by adding an angular bias:
S( ˜x1, ˜x2) = ∥ ˜x1∥ · ∥ ˜x2∥ · (cid:0) cos(θ ˜x1, ˜x2 ) − bθ (6) (cid:1) where bθ is learned directly from data and stays constant during inference. How does this angular bias term differ from the bias term in Eq. 5? We write down the decision boundary for the new similarity functions:
∥ ˜x1∥ · ∥ ˜x2∥ · cos(θ ˜x1, ˜x2 ) (cid:125) (cid:123)(cid:122) (cid:124)
Inner product similarity
− ∥ ˜x1∥ · ∥ ˜x2∥ · bθ (cid:125) (cid:123)(cid:122)
Data-dependent bias (cid:124)
+ b (cid:124)(cid:123)(cid:122)(cid:125)
Constant bias
= 0 which is not equivalent to the decision boundary induced by the inner product similarity. The data-dependent bias serves a different role to the constant bias, and also removes a prescribed assumption in inner product. Our experiments show that removing this assumption is important and leads to consistently better performance. One delicate difference to the angular similarity is that the angular bias is redundant since ∥ ˜x1∥ · ∥ ˜x2∥ · bθ also becomes some fixed constant and can be trivially merged to b with ∥ ˜x1∥ = ∥ ˜x2∥ = 1.
Pair sampling. How to construct pairs is arguably one of the most important factors in determining the performance of proxy-free learning [77]. We consider two aspects of pair sampling: pair coverage and pair importance.
Because it is impossible to enumerate all the pair combi-nations for a large dataset, we seek to enlarge the coverage of pairs. The size of mini-batches also limits the pair coverage.
To address this, we maintain a queue of samples encoded by a moving-averaged encoder [18] and then form pairs from samples in the queue. Specifically, we use a first-in-first-out queue where the oldest mini-batch is dequeued as the
the mining directions are reversed for positive and negative pairs, then their effect will no longer cancel out each other.
To this end, we multiply 1 r to the similarity score in the loss of positive pairs (instead of r), and simultaneously multiply r by the similarity score in the loss of negative pairs. We arrive at the final form of the loss function below:
Figure 4: The effect of r for hard pair mining.
+ (1−α) · (1−yp) · log
Lf = E{ ˜x1, ˜x2}∼D (cid:26)
α·yp ·log (cid:19) (S( ˜x1, ˜x2)+b)(cid:1) (cid:18) 1+exp (cid:0)− 1 r 1 + exp (cid:0)r(S( ˜x1, ˜x2) + b)(cid:1) (cid:18) (cid:19)(cid:27) (8) current mini-batch is enqueued. We denote the size of the mini-batch as m and the size of the queue as q. We can form m · q pairs in total. We note that the samples in the queue are encoded by a moving-averaged encoder instead of the original encoder. The moving-averaged encoder is updated by θq ← ηθq + (1 − η)θ where η is the moving average parameter, θq are the parameters of the moving-averaged encoder and θ are the parameters of the current encoder that is trained with back-propagation.
With a sufficient number of pairs, we now consider how to weight them based on their importance. We implement the pair reweighting in the loss function. The way we construct pairs will inevitably result in a highly imbalanced number of positive and negative pairs. To address this problem, we first introduce a weighting hyperparameter to balance the importance of positive and negative pairs, yielding
Lb = E{ ˜x1, ˜x2}∼D (cid:26)
α · yp · log (cid:0)1 + exp(−S( ˜x1, ˜x2) + b)(cid:1)
+ (1 − α) · (1 − yp) · log (cid:0)1 + exp(S( ˜x1, ˜x2) + b)(cid:1) (cid:27) (7) where α is a hyperparameter for balancing positive and neg-ative pairs. Then we consider the final problem of hard pair mining. We note that hard pair mining is highly nontrivial without angular similarity (i.e., feature and proxy normal-ization). For example, if we multiply the similarity score by a scaling parameter (i.e., simply replace S( ˜x1, ˜x2) with r · S( ˜x1, ˜x2) in Eq. 7), this parameter will not have the same effect of hard pair mining as SphereFace2 [74]. This is because the network can trivially learn to decrease the fea-ture magnitude and r will be compensated by the decreased magnitude, whereas features are normalized in [74]. This phenomenon suggests that the effect of hard pair mining within positive and negative pairs tends to cancel out each other in our formulation (without angular similarity).
To address this critical problem, we propose a simple yet novel remedy – perform hard pair mining in a reverse direction for positive and negative pairs. Specifically, we seek a hyperparameter that simultaneously controls the hard pair mining for both positive and negative pairs. As it gets larger, the loss function focuses more on easy pairs within positive pairs, and at the same time, focuses more on hard pairs within negative pairs. The core idea is that as long as where r is a hyperparameter that scales the loss curve with respect to the similarity score. Specifically, larger r corre-sponds to more importance on easy positive pairs and hard negative pairs. We define Q1(t) = log(1 + exp(−t/r)) and
Q2(t) = log(1 + exp(r · t)), and then plot their curves to illustrate how they achieve hard pair mining of reverse direc-tions. For the function Q1(t), the loss focuses more on easy pairs as r gets larger. For the function Q2, the loss focuses more on hard samples as r gets larger.
Simplicity and significance of SimPLE. With similarity score, pair coverage and pair importance taken into account, we end up with a surprisingly simple formulation in Eq. 8 which only requires simple modifications from standard bi-nary cross-entropy. Most importantly, SimPLE completely drops the dependency on angular similarity and margin while still achieving state-of-the-art performance on almost all open-set recognition problems. We believe this method is significant since it opens up new possibilities for PSL and also demonstrates that angular similarity and margin are no longer requisite to achieve state-of-the-art performance. 4. Discussions and Insights
SimPLE closes the gap between training and testing. One of the most challenging problems in open-set recognition is the gap between training and testing. Almost all previous innovations were made towards bridging this gap. For exam-ple, angular margin [13, 36, 37, 67, 69, 74] is widely adopted in proxy-based learning such that the training target can be closer to the testing scenario. Recently, SphereFace2 [74] was proposed to further bridge this gap by switching from triplet-based learning to pair-based learning, because only pair comparison is performed during testing. However, the use of proxies still prevents SphereFace2 from closing this gap, and moreover, SphereFace2 remains heavily dependent on angular similarity and margin. Our work can actually be viewed as a novel proxy-free generalization of SphereFace2.
By dropping the use of class proxies, angular similarity and margin, SimPLE takes one step further towards closing the gap between training and testing in open-set recognition.
SimPLE as a general framework. SimPLE gives a simple yet working variant for pair-based proxy-free learning, but
more importantly, SimPLE identifies a few critical design as-pects (e.g., similarity score, pair coverage, pair importance) to achieve PSL’s desideratum and opens new possibilities.
For example, the optimal similarity score is yet to be de-signed and how to effectively incorporate hard pair mining without the use of angular similarity remains an open prob-lem. Solving any of these open problems might easily lead to better loss functions in pair-based proxy-free learning. 5. Experiments and Results
We evaluate SimPLE with multiple open-set recognition problems, including face recognition, image retrieval, and speaker verification. We adopt the standard training and testing protocols, network configurations, and optimization strategy, so that our results can be transparently and fairly compared to previous methods. The detailed experimental settings are given in the corresponding subsections. 5.1. Open-set Face Recognition
Experimental setup. We generally follow the data process-ing and augmentation strategy from [26]. Specifically, the face images are cropped based on the 5 face landmarks de-tected by MTCNN [83] or RetinaFace [12] using similarity transformation. The cropped image is resized to 112×112, and RGB pixels are normalized to [-1, 1]. In training mode, random cropping, rescaling, and photometric jittering are applied to the face images with a probability of 0.2, while horizontally flipping is applied with the probability of 0.5.
We first evaluate the design of SimPLE by performing ablation studies. SFNet-64 [37] and MS1MV2 [13, 16] are adopted as the backbone and training set, respectively.
The validation set is constructed by combining LFW [20],
AgeDB-30 [46], CALFW [85], and CPLFW [84], containing 12,000 positive and 12,000 negative pairs. SimPLE models are trained with different r and α. The equal error rates (EER) and the true positive rates at different false positive rates (TPR@FAR) on the validation set are reported.
Ablation: hyperparameter r, α, and bθ. Hyperparameter r is used to control the strength of sample mining. When r = 1, SimPLE is equivalent to vanilla binary cross-entropy.
As r increases, SimPLE focuses more on the hard negative pairs. Table 2 shows that SimPLE yields large performance gains when r > 1 is used. With r = 3 and α = 0.001,
SimPLE yields 3.23% EER, which outperforms the best result with r = 1 (3.72%) by a considerable margin.
We also perform a similar ablation study with different bθ, and the results are given in the Appendix. In general, bθ = 0.3 or 0.4 works well for all the experiments. We also observe that higher α is usually paired with higher r for the best performance. With optimal r and α pairs, SimPLE performs equally well. Therefore, we fix r = 3, α = 0.001, and bθ = 0.3 in the following experiments. r
α
EER (↓) TPR@FAR=1e-4 TPR@FAR=1e-3 TPR@FAR=1e-2 1 0.0002 1 0.0005 0.001 1 1 0.002 2 0.0005 0.001 2 2 0.002 3 0.0005 0.001 3 0.002 3 3.98 3.72 3.85 4.2 3.35 3.38 3.34 3.38 3.28 3.23 87.88 89.23 88.43 85.45 90.5 88.84 90.36 89.80 91.07 89.62 90.56 92.20 90.91 89.89 92.38 92.10 92.25 92.00 92.45 92.27 93.78 94.49 94.11 93.46 94.93 94.55 94.61 94.81 94.80 94.84
Table 2: Ablation study of r and α for SimPLE (%).
Ablation: score functions. To investigate the importance of score functions, we run experiments for SimPLE using cosine similarity or generalized inner product (i.e., Eq. 6) as the score function. Experimental results show that the generalized inner product leads to a significantly lower EER over cosine similarity (with optimal hyperparameters), i.e. 3.23% vs. 4.81%. The results suggest that a proper score function plays a key role in the success of SimPLE.
In our early experimentation, we also attempted to in-corporate generalized inner product into the proxy-based framework. However, we did not manage to obtain meaning-ful results (as shown in the Appendix). This further shows that our SimPLE framework is promising in the sense that it can easily adopt various score functions.
Comparison with previous methods. For a comprehen-sive comparison, we conduct experiments under three differ-ent settings: (A) SFNet-20 trained with VGGFace2 dataset
[4] (8.6K subjects), (B) SFNet-64 trained with MS1MV2 dataset (85.7K subjects), and (C) IResNet-100 trained with
MS1MV2 dataset. The goal is to explore SimPLE under different network capacities and data scales. The evaluations are performed on IARPA Janus Benchmark (IJB) [42, 76].
This is a challenging dataset since it contains mixed-quality samples, e.g. low-quality video frames from surveillance cameras and high-quality images. For setting A and B, we train the face models of different methods using their re-leased code, which ensures all methods use the same training recipes except loss functions. For setting C, we directly use the released models or results reported in their published papers, since they represent the current best performance.
Setting A: small model and training set. We first explore
SimPLE in a relatively lightweight setting. As can be seen from Table 3, SimPLE outperforms all competitors by large margins in both verification and identification tasks. In par-ticular, SimPLE respectively outperforms SphereFace2 by 7.38% and 8.30% in TAR@FAR=1e-5 and TPIR@FPIR=1e-2 on IJB-B dataset. Similar performance gains can also be observed on the IJB-C dataset, and it shows that SimPLE is effective for low-capacity architectures and small-scale train-ing sets. Using cosine similarity as score function, SimPLE yields inferior results, which is consistent with the perfor-Method
NormFace [68]
SphereFace [36, 37]
CosFace [67, 69]
ArcFace [13]
Circle Loss [61]
CurricularFace [21]
SphereFace2 [74]
SimPLE (cosine)
SimPLE
IJB-B
IJB-C 1:1 Verification TAR @ FAR 1e-4 1e-5 1e-6 1:N Identification TPIR @ FPIR top 1 1e-1 1e-2 32.53 40.11 40.77 40.15 36.56 22.16 40.19 40.90 47.00 68.20 75.44 73.66 76.52 72.81 63.35 77.13 63.09 84.51 82.24 87.43 85.51 87.50 86.51 88.23 87.95 80.86 90.72 91.17 92.97 91.96 92.26 91.41 92.66 92.36 91.02 93.19 58.85 67.70 67.97 70.25 65.58 47.59 72.14 58.06 80.44 78.99 84.87 82.77 85.02 83.73 84.93 87.32 76.94 89.18 1:1 Verification TAR @ FAR 1e-4 1e-5 1e-6 65.64 73.79 70.43 74.32 69.69 35.54 75.38 51.72 82.34 76.31 83.02 80.21 82.49 80.66 76.49 83.38 69.49 88.62 86.15 90.37 88.75 90.17 89.67 91.10 90.82 84.40 92.92 1:N Identification TPIR @ FPIR top 1 1e-2 1e-1 92.09 94.19 93.09 93.79 92.96 93.73 93.24 92.22 94.51 70.60 78.18 75.36 78.22 75.41 54.13 80.03 62.10 85.66 81.43 86.90 84.90 86.71 85.63 85.77 87.54 77.92 90.84
Table 3: Comparison on IJB-B and IJB-C. We use SFNet-20 as the backbone architecture and VGGFace2 as the training set. Results are in
% and higher number indicates better performance.
IJB-B
IJB-C
Method
NormFace [68]
SphereFace [36, 37]
CosFace [67, 69]
ArcFace [13]
Circle Loss [61]
CurricularFace [21]
SphereFace2 [74]
SimPLE 1:1 Verification TAR @ FAR 1e-4 1e-5 1e-6 40.56 48.83 37.82 41.02 41.65 43.76 40.31 46.67 75.30 86.66 82.99 86.16 82.76 85.55 85.89 90.34 90.22 94.36 94.20 94.82 94.09 94.61 94.04 94.49 1:N Identification TPIR @ FPIR top 1 1e-2 1e-1 92.49 94.84 94.69 94.88 94.64 94.82 94.59 95.15 64.62 76.35 70.61 77.92 74.63 76.01 78.05 83.56 88.19 93.20 93.03 93.79 92.83 93.37 93.02 93.62 1:1 Verification TAR @ FAR 1e-4 1e-5 1e-6 70.17 83.57 78.01 84.47 81.18 83.35 84.60 88.49 85.88 92.79 92.29 93.25 91.59 92.95 92.37 93.48 92.69 95.82 95.87 96.25 95.83 96.11 95.74 95.91 1:N Identification TPIR @ FPIR top 1 1e-1 1e-2 93.70 96.07 95.91 96.12 95.77 96.04 95.81 96.36 77.97 87.74 84.59 88.80 84.56 87.88 88.87 91.88 89.81 94.47 94.53 95.08 94.15 94.76 94.52 94.76
Table 4: Comparison on IJB-B and IJB-C. We use SFNet-64 as the backbone architecture and MS1MV2 as the training set.
IJB-B
IJB-C
Method
SphereFace [36, 37]
CosFace [67, 69]
ArcFace [13]
CurricularFace† [21]
BroadFace† [29]
SCF-ArcFace† [31]
SphereFace2 [74]
MagFace+ [43]
AdaFace [26]
SimPLE 1:1 Verification TAR @ FAR 1e-4 1e-5 1e-6 1:N Identification TPIR @ FPIR top 1 1e-2 1e-1 47.33 43.67 43.43
-40.92
-41.53 42.32 46.78 49.87 90.14 88.83 90.40
-89.97 90.68 89.92 90.36 90.04 91.13 94.87 95.23 95.02 94.86 94.97 94.74 95.02 94.51 95.67 94.78 95.13 95.35 95.14
---95.24 94.81 95.54 95.54 82.57 80.50 81.36
---83.46 83.65 80.73 85.92 94.30 94.49 94.26
---94.36 93.87 95.07 94.28 1:1 Verification TAR @ FAR 1e-4 1e-5 1e-6 87.86 85.29 86.00
-85.96
-87.63 90.24 89.74 90.30 94.36 94.33 94.49
-94.59 94.04 94.49 94.08 94.87 94.34 96.25 96.62 96.39 96.15 96.38 96.09 96.42 95.97 96.89 96.27 1:N Identification TPIR @ FPIR top 1 1e-2 1e-1 96.45 96.53 96.47
---96.41 96.02 96.75 96.81 91.68 90.69 91.91
---92.08 91.95 92.12 92.88 95.36 95.61 95.51
---95.47 95.06 96.20 95.49
Table 5: Comparison on IJB-B and IJB-C. We use IResNet-100 as the backbone architecture and MS1MV2 as the training set. ’-’ indicates that neither the model is released nor the result is reported in their paper. † Results are obtained from their papers. mance on the validation set. The results indicate that a lot more small insights (e.g. margin) are required before it can achieve competitive performance.
Setting B and C: larger model and training set. These ex-periments are designed to investigate if SimPLE can benefit from larger models and training sets. Again, the compar-ison is conducted on the IJB datasets and the results are given in Table 4 and Table 5. We observe that SimPLE achieves competitive results on IJB datasets under both set-tings. Compared to other methods, SimPLE improves more at low accept rates, e.g. FPR=1e-6, 1e-5, and FPIR=1e-2.
The results validate that SimPLE can benefit from a stronger backbone and more training data.
Proxy-based vs Proxy-free. Both SphereFace2 and Sim-PLE are pair-wise learning frameworks, while SimPLE re-moves the proxy, angular assumption, and margin term. As shown in Tables 4 and 5, the improvement of SimPLE over
SphereFace2 suggests that these dominating components might not be necessary in the open-set recognition prob-lem. We hope this observation will encourage researchers to rethink the use of each component in the PSL framework.
We further evaluate our SimPLE model trained with set-ting C on several high-quality datasets, as given in Table 6. SimPLE achieves the highest accuracies on cross-age and cross-pose datasets, i.e. 96.25% on CALFW, 94.00% on
CPLFW, and 98.77% on CFP-FP, showing the robustness
Method
LFW AgeDB
CALFW CPLFW CFP-FP
Method
VoxCeleb1
VoxCeleb1-E
VoxCeleb1-H
SphereFace [36, 37]
CosFace [67, 69]
ArcFace [13]
CurricularFace [21]
BroadFace [29]
SCF-ArcFace [31]
SphereFace2 [74]
MagFace [43]
AdaFace [26]
SimPLE 99.78 98.81 98.83 99.80 99.85 99.82 99.80 99.83 99.82 99.78 98.02 98.11 98.28 98.32 98.38 98.30 98.07 98.17 98.05 98.28 95.56 95.76 95.45 96.20 96.20 96.12 95.38 96.15 96.08 96.25 92.11 92.28 92.08 93.13 93.17 93.16 92.20 92.87 93.53 94.00 98.08 98.12 98.27 98.37 98.63 98.40 98.15 98.46 98.49 98.77
Table 6: Comparison on multiple high-quality face datasets. Results are in % and higher number indicates better performance.
Method
Precision@1
R-Precision
MAP@R
Contrastive [17]
Triplet [73]
NT-Xent [5, 51, 58]
ProxyNCA [47]
Margin [77]
Margin/class [77]
N. Softmax [68, 86]
CosFace [67, 69]
ArcFace [13]
FastAP [3]
SNR [82]
MS [71]
MS+Miner [71]
SoftTriple [55]
SimPLE 68.13 64.24 66.61 65.69 63.60 64.37 65.65 67.32 67.50 63.17 66.44 65.04 67.73 67.27 68.58 37.24 34.55 35.96 35.14 33.94 34.59 35.99 37.49 37.31 34.20 36.56 35.40 37.37 37.34 37.62 26.53 23.69 25.09 24.21 23.09 23.71 25.25 26.70 26.45 23.53 25.75 24.70 26.52 26.51 26.84
Table 7: Performance of Image Retrieval on CUB-200-2011. of SimPLE to varying age and pose. The best performance on the LFW and AgeDB datasets (99.85% and 98.38%) is obtained by BroadFace, which is a hybrid method that com-bines proxy-based and proxy-free PSL. Our results suggest that the proxy-free PSL paradigm is still worth exploring and should not be ignored for open-set recognition. 5.2. Image Retrieval and Speaker Verification
We evaluate SimPLE on two more open-set recognition problems: image retrieval and speaker verification.
Image Retrieval. We use the codebase in [48], which is a well-known benchmarking toolkit for image retrieval and metric learning. For all the methods, the data processing, training recipes, and testing protocols are nearly the same, except the loss functions. This ensures a fair comparison of different methods. As suggested in [48], we use BN-Inception as the backbone [22] with ImageNet pretraining.
The precision at 1 (also known as top-1 / rank-1 accuracy),
R-precision, and Mean Average Precision at R (MAP@R) on CUB-200-2011 dataset [65] are reported in Table 7.
Speaker Verification. We adopt the standard train/val/test split given by VoxCeleb2 [10]. The speech recordings are randomly cropped to 3-8 seconds in each mini-batch as data
Softmax
A-Softmax [36, 37]
AM-Softmax [67, 69]
AAM-Softmax [13]
SimPLE 2.11 2.11 2.17 2.22 1.85 2.05 2.11 2.16 2.21 1.80 3.76 3.47 3.49 3.55 3.23
Table 8: Performance of Speaker Verification on VoxCeleb1. augmentation. The mini-batch size is set to 512. We use
ResNet-34 as the backbone architecture. To learn the net-works from scratch, the SGD optimizer is used and the learn-ing rate is initialized at 0.1 and divided by 10 after 30K, 50K, and 60K iterations. The training is completed at 70K itera-tions. We report the EER on VoxCeleb1, VoxCeleb1-easy,
VoxCeleb1-hard in Table 8.
Unsurprisingly, SimPLE achieves consistently competi-tive results on CUB-200-2011 and VoxCeleb1 datasets (Ta-ble 7 and 8). The pipeline of different methods is the same, so the gains can only be attributed to the better PSL loss function. This shows that the applications of SimPLE are not limited to any particular object (face) or data modal (im-age). It appears to perform well on a variety of open-set recognition problems, e.g. generic object or speech data. 6.