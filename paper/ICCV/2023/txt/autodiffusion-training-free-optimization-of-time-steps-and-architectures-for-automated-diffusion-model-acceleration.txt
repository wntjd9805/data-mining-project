Abstract 1.

Introduction
Diffusion models are emerging expressive generative models, in which a large number of time steps (inference steps) are required for a single image generation. To accel-erate such tedious process, reducing steps uniformly is con-sidered as an undisputed principle of diffusion models. We consider that such a uniform assumption is not the optimal solution in practice; i.e., we can find different optimal time steps for different models. Therefore, we propose to search the optimal time steps sequence and compressed model ar-chitecture in a unified framework to achieve effective image generation for diffusion models without any further train-ing. Specifically, we first design a unified search space that consists of all possible time steps and various architectures.
Then, a two stage evolutionary algorithm is introduced to find the optimal solution in the designed search space. To further accelerate the search process, we employ FID score between generated and real samples to estimate the perfor-mance of the sampled examples. As a result, the proposed method is (i).training-free, obtaining the optimal time steps and model architecture without any training process; (ii). orthogonal to most advanced diffusion samplers and can be integrated to gain better sample quality. (iii). general-ized, where the searched time steps and architectures can be directly applied on different diffusion models with the same guidance scale. Experimental results show that our method achieves excellent performance by using only a few time steps, e.g. 17.86 FID score on ImageNet 64 × 64 with only four steps, compared to 138.66 with DDIM.
*Corresponding author: fchao@xmu.edu.cn
Diffusion models are a class of generative models that exhibit remarkable performance across a broad range of tasks, including but not limited to image generation [14, 24, 8, 2, 29, 4, 15, 38], super-resolution [33, 39, 6], inpaint-ing [22, 31], and text-to-image generation [25, 32, 27, 10].
These models utilize the diffusion process to gradually in-troduce noise into the input data until it conforms to a Gaus-sian distribution. They then learn the reversal of this process to restore the data from sampled noise. Consequently, they achieve exact likelihood computation and excellent sample quality. However, one major drawback of diffusion models is their slow generation process. For instance, on a V100
GPU, generating a 256 × 256 image with StyleGAN [16] only takes 0.015s, whereas the ADM model requires multi-ple time steps for denoising during generation, leading to a significantly longer generation time of 14.75s.
Extensive studies have focused on reducing the number of time steps to improve the generation process of diffu-sion models. Some of these studies represent the generation process as either stochastic differential equations (SDEs) or ordinary differential equations (ODEs), and then utilize nu-merical methods to solve these equations [36, 20, 6, 21].
The samplers obtained by these numerical methods can typ-ically be applied to pre-trained diffusion models in a plug-and-play manner without re-training. The other studies pro-posed to utilize knowledge distillation to reduce the num-ber of time steps [34, 23]. These methods decrease the time steps required for the generation process and then allow the noise prediction network to learn from the network of the original generation process. Although these methods are effective in improving the sampling speed of diffusion mod-Figure 1. Left: We propose to search the optimal time steps sequence and corresponding compressed network architecture in a unified framework. Right: Samples by ADM-G [8] pre-trained on ImageNet 64 × 64 with and without our methods (AutoDiffusion), varying the number of time steps. els, we observe that they have paid little attention to the se-lection of time step sequences. When reducing the number of time steps, most of these methods sample the new time steps uniformly or according to a specific procedure [36].
We argue that there exists an optimal time steps sequence with any given length for the given diffusion model. And the optimal time steps sequence varies depending on the specific task and the super-parameters of diffusion models.
We believe that the generation quality of diffusion models can be improved by replacing the original time steps with the optimal time steps.
Therefore, we introduce AutoDiffusion, a novel frame-work that simultaneously searches optimal time step se-quences and the architectures for pre-trained diffusion mod-els without additional training. Fig. 1 (Left) shows the schematic of AutoDiffusion. Our approach is inspired by Neural Architecture Search (NAS) techniques that are widely used for compressing large-scale neural networks
[28, 42, 26, 18, 1]. In our method, we begin with a pre-trained diffusion model and a desired number of time steps.
Next, we construct a unified search space comprising all possible time step sequences and diverse noise prediction network architectures. To explore the search space effec-tively, we use the distance between generated and real sam-ples as the evaluation metric to estimate performance for candidate time steps and architectures. Our method pro-vides three main advantages. First, we demonstrate through experiments that the optimal time steps sequence obtained through our approach leads to significantly better image quality than uniform time steps, especially in a few-step regime, as illustrated in Fig. 1 (Right). Second, we show that the searched result of the diffusion model can be ap-plied to another model using the same guidance scale with-out repeating the search process. Furthermore, our approach can be combined with existing advanced samplers to further improve sample quality.
Our main contributions are summarized as follows:
• Our study reveals that uniform sampling or using a fixed function to sample time steps is suboptimal for diffusion models. Instead, we propose that there ex-ist an optimal time steps sequence and corresponding noise prediction network architecture for each diffu-sion model. To facilitate this, we propose a search space that encompasses both time steps and network architectures. Employing the optimal candidate of this search space can effectively improve sampling speed for diffusion models and complement the most ad-vanced samplers to enhance sample quality.
• We propose a unified training-free framework, AutoD-iffusion, to search both time steps and architectures in the search space for any given diffusion model. We utilize a two-stage evolutionary algorithm as a search strategy and the FID score as the performance estima-tion for candidates in the search space, enabling an ef-ficient and effective search process.
• Extensive experiments show that our method is training-free, orthogonal to most advanced diffusion samplers, and generalized, where the searched time steps and architectures can be directly applied to dif-ferent diffusion models with the same guidance scale.
Our method achieves excellent performance by us-ing only a few time steps, e.g., 17.86 FID score on
ImageNet 64 × 64 with only four steps, compared to 138.66 with DDIM. Furthermore, by implement-ing our method, the samplers exhibit a noteworthy enhancement in generation speed, achieving a 2× speedup compared to the samplers lacking our method. 2.