Abstract
Despite recent advancements in deep learning, deep neu-ral networks continue to suffer from performance degra-dation when applied to new data that differs from train-ing data. Test-time adaptation (TTA) aims to address this challenge by adapting a model to unlabeled data at test time. TTA can be applied to pretrained networks without modifying their training procedures, enabling them to uti-lize a well-formed source distribution for adaptation. One possible approach is to align the representation space of test samples to the source distribution (i.e., feature align-ment). However, performing feature alignment in TTA is especially challenging in that access to labeled source data is restricted during adaptation. That is, a model does not have a chance to learn test data in a class-discriminative manner, which was feasible in other adaptation tasks (e.g., unsupervised domain adaptation) via supervised losses on the source data. Based on this observation, we propose a simple yet effective feature alignment loss, termed as Class-Aware Feature Alignment (CAFA), which simultaneously 1) encourages a model to learn target representations in a class-discriminative manner and 2) effectively mitigates the distribution shifts at test time. Our method does not require any hyper-parameters or additional losses, which are re-quired in previous approaches. We conduct extensive ex-periments on 6 different datasets and show our proposed method consistently outperforms existing baselines. 1.

Introduction
Recent advancements [17, 51, 11, 10] in machine learn-ing are effective in solving diverse problems, achiev-ing remarkable performance enhancements on benchmark datasets. However, these methods can suffer from signif-icant performance degradation when applied to test data with different properties from the training data (i.e., source data), such as corruption [18], changing lighting condi-tions [8], or adverse weather [53, 6]. Sensitivity to distri-bution shifts [41] hampers deep networks from performing well in practical scenarios where test samples may differ from training data [26]. Thus, adapting deep models to the test samples is crucial when distribution shifts exist.
Various adaptation methods [3, 15, 36, 14, 48, 13, 55, 21] have been proposed to alleviate this problem. However, most of these methods require either access to the source data during adaptation [48, 14, 19] or modification of the training procedure [33, 32, 49], which limits their applica-bility. Therefore, we seek to design an adaptation method that 1) is applicable to existing deep networks without mod-ification and 2) does not require access to the source data during adaptation. Satisfying such conditions, previous studies perform adaptation at test time while making predic-tions simultaneously, which is referred to as test-time adap-tation (TTA).
One widely adopted approach to address distribution shifts is to align the source (i.e., training data) and target (i.e., test data) distributions [14, 48, 34, 47, 13, 50]. For ex-ample, DANN [14] directly reduces the H-divergence be-tween the source and target distributions, and CORAL [48] minimizes the difference in the second-order statistics be-tween the source and target data. Despite their demon-strated effectiveness in the unsupervised domain adapta-tion (UDA) task, applying those alignments to TTA has the following limitation. Alignments are generally per-formed along with supervised losses on the source data, which encourages a model to learn target distributions in a class-discriminative manner [48]. However, access to the source data is prohibited during adaptation in TTA, preclud-ing learning class discriminability.
With this issue in mind, we conduct an analysis of the effects of feature alignments in TTA by using two distances in the representation space: intra-class distance and inter-class distance. As shown in Fig. 1 (c), intra-class distance (dotted arrow) is defined as the distance between a sam-ple and its ground-truth source class distribution, and inter-class distance (solid arrow) denotes the averaged distance between the sample and the other source class distribu-tions. Achieving low intra-class distance and high inter-class distance is crucial for improving classification accu-racy [30, 4, 31, 42, 56].
For analysis, we first adopt a feature alignment that re-duces the domain-level discrepancy between source and tar-get domains, which is a commonly adopted paradigm in
UDA studies [14, 48, 47]. One straightforward approach to achieve this is to align the mean and covariance of the
Figure 1. A motivating example of our paper. (a) shows the change of the intra-class distance (dotted lines) and the inter-class distance (solid lines) of ours (blue line) and global feature alignment (red line). (b) shows the accuracy changes as adaptation proceeds. (c) illustrates how our method CAFA aligns the test features to the source distribution in a class-discriminative manner. We obtain the plots by adapting a model to corrupted images of the CIFAR10-C dataset. Please refer to Section 4 for further details. source and target distributions, i.e., global feature alignment (Global FA).1 The result of applying this feature alignment in TTA is depicted in Fig. 1 (a) (red line). The intra-class distance is reduced, which is desirable but is also accom-panied by a decrease in inter-class distance. Such effects can degrade the image classification accuracy in Fig. 1 (b) (red line). This is mainly due to the lack of class infor-mation in the global feature alignment. A model does not have a chance to learn the test data in a class-discriminative manner since a supervised loss is not available on both the source and target data.
Motivated by such observations, we propose Class-Aware Feature Alignment (CAFA) that aligns the target features to the pre-calculated source feature distributions by considering both intra- and inter-class distances. To be more specific, we pre-calculate the statistics (i.e., mean and covariance) of the source distribution to estimate class-conditional Gaussian distributions from a pretrained net-work. At test time, we use the Mahalanobis distance [37] to 1) align each sample to its predicted class-conditional Gaus-sian distribution (i.e., reduce intra-class distance) and 2) en-force samples to be distinct from the other class-conditional
Gaussian distributions (i.e., increase inter-class distance).
Applying CAFA successfully enhances class discriminabil-ity as shown in Fig. 1 (a) (blue line) and significantly im-proves the classification accuracy as adaptation proceeds (Fig. 1 (b) (blue line)). We empirically show that reducing intra-class distance alone is not sufficient as it could also reduce the inter-class distance and result in performance degradation.
Aligning feature distributions at test time requires ac-cess to the source data before adaptation to pre-calculate the source statistics, as similarly done in previous meth-ods [12, 33, 7]. However, we empirically show that CAFA only requires a small number of training samples (e.g., 5% of the training samples in the ImageNet/CIFAR10 datasets 1We will explain the global feature alignment in more detail in Sec-tion 3.2 (Fig. 3)) to obtain robust source statistics that outperform the existing methods. In addition, CAFA does not require any hyper-parameters or modifications on pretraining pro-cedures for adaptation.
The main contributions of our work are as follows:
• We propose a novel Class-Aware Feature Alignment (CAFA) that effectively mitigates distribution shifts and encourages a model to learn discriminative target representations simultaneously.
• Our proposed approach is simple yet effective, not re-quiring hyper-parameters or additional modifications of the training procedure.
• We conduct extensive experiments on 6 different datasets along with in-depth analyses and show that
CAFA consistently outperforms the existing methods on test-time adaptation. 2.