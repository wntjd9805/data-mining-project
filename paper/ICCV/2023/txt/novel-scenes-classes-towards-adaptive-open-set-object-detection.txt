Abstract
Domain Adaptive Object Detection (DAOD) transfers an object detector to a novel domain free of labels. How-ever, in the real world, besides encountering novel scenes, novel domains always contain novel-class objects de facto, which are ignored in existing research. Thus, we formu-late and study a more practical setting, Adaptive Open-set
Object Detection (AOOD), considering both novel scenes and classes. Directly combing off-the-shelled cross-domain and open-set approaches is sub-optimal since their low-order dependence, e.g., the confidence score, is insuffi-cient for the AOOD with two dimensions of novel infor-mation. To address this, we propose a novel Structured
Motif Matching (SOMA) framework for AOOD, which mod-els the high-order relation with motifs, i.e., statistically sig-nificant subgraphs, and formulates AOOD solution as motif matching to learn with high-order patterns. In a nutshell,
SOMA consists of Structure-aware Novel-class Learning (SNL) and Structure-aware Transfer Learning (STL). As for SNL, we establish an instance-oriented graph to cap-ture the class-independent object feature hidden in dif-ferent base classes. Then, a high-order metric is pro-posed to match the most significant motif as high-order patterns, serving for motif-guided novel-class learning. In
STL, we set up a semantic-oriented graph to model the class-dependent relation across domains, and match un-labelled objects with high-order motifs to align the cross-domain distribution with structural awareness. Exten-sive experiments demonstrate that the proposed SOMA achieves state-of-the-art performance. Codes are available at https://github.com/CityU-AIM-Group/SOMA. 1.

Introduction
Domain Adaptive Object Detection (DAOD) studies ro-bust object detection in cross-domain scenarios, where the
*Corresponding author.
This work was supported by Hong Kong Research Grants Council Gen-eral Research Fund 11211221, 14204321, 14220622, and Innovation and
Technology Commission-Innovation and Technology Fund ITS/100/20.
Figure 1. Illustration of (a) existing DAOD assumption and (b) the proposed AOOD setting. independent and identically distributed constraint [17] is no longer applicable due to the domain shift [7]. With tailor-designed techniques [7, 22, 5], the object detector trained in a labeled domain can be generalized to a novel one free of labels (Figure 1(a)), pushing forward its real-world ground-ing, e.g., self-driving with novel weather and street scenes.
While achieving great success, existing DAOD works strongly assume a shared class space between the two do-mains (see Figure 1(a)), leading to a vast gap between the transferred domain and real-world [24]. Since natu-ral scenes are diverse and always contain objects beyond pre-defined classes, this gap severely limits the scene un-derstanding for industrial usage [19], e.g., confusing the au-tonomous driving system with wrong judgments. Hence, to overcome this limitation, we relax the assumption and for-mulate a more practical setting, called Adaptive Open-set
Object Detection (AOOD), by allowing the target domain with novel-class objects. As shown in Figure 1(b), in the target domain, besides detecting the base-class car and per-son shared with the source domain, we also aim to identify novel-class objects, e.g., dustbin and door sign, etc. Specif-ically, the object detector uses the base-class labels in the source domain for training, and aims to detect base-class objects and identify novel-class objects as unknown [19] in the target domain. The proposed AOOD1 is a practical set-1See Appendix for comparing with other related task settings.
ting in the real world that considers two dimensions of novel information, namely novel scenes and classes.
Aiming to improve the novel-scene robustness, recent
DAOD advances delve into semantic-level cues, e.g., clas-sification scores [50, 30, 22, 29] and prototype-based dis-tance [44, 58], to guide the adversarial alignment [44, 29, 22], metric learning [55, 50, 30], and self-training [26, 25, 56], which achieve cross-domain adaptation at the category level. To improve the novel-class discriminability, existing works rely on classification scores [24, 19, 12, 21, 16, 24] to discover informative background objects, and conduct a novel-class synthesis with base-class sample pairs [59, 14] to achieve open-set learning [12]. The two streams use low-order [35] cues, e.g., the pair-wise distance and relation, to achieve reliable learning with novel information.
However, directly combining cross-domain and open-set approaches may lead to a sub-optimal AOOD. The reason is that the novel-class objects out of distribution and the novel-scene objects attacked by the domain shift are both embedded outside of the labeled feature space with low confidence [19, 7, 21], which are difficult to distinguish with low-order cues. Going beyond the low-order cues, the motif [2, 36, 42], i.e., a statistically significant subgraph, has been studied to model the high-order patterns within a graph. Hence, we aim to use motifs to break through
Instead of modeling the pair-wise this low-order barrier. relation between two entities, a motif assumes the high-order relation among several entities (see Figure 2), which can be used to solve AOOD from the following two as-pects. Firstly, we observe that novel-class objects inher-ently contain class-independent features to distinguish from non-informative backgrounds, e.g., relatively complete con-tours. These features are shared among different classes and should not be overwhelmed by class-specific seman-tics. Thus, our critical insight is discovering this shared feature among several class centers with motifs, achieving motif-guided novel-class learning2. Secondly, for the novel scene, the high-order cues of class-dependent distribution, e.g., within-class variance, are crucial for the cross-domain robustness [1, 30]. These observations motivate us to model the high-order patterns among several class extreme points with motifs and achieve motif-guided transfer learning.
To address the critical yet unexplored AOOD issue, we propose a novel Structured Motif Matching (SOMA) frame-work, which models the high-order patterns with motifs to learn in the real world. Specifically, we propose Structure-aware Novel-class Learning (SNL) to empower novel-class detection in the source domain. SNL estimates class cen-ters and extremes with a semantic bank, which is used to construct an instance-oriented graph to capture class-independent object features. Then, with a newly proposed high-order metric, each candidate object is matched with a 2See Sec. 5 for a high-level clarification of the core idea. graph motif to model significant high-order patterns, serv-ing for motif-guided novel-class learning. Moreover, we design a Structure-aware Transfer Learning (STL) in the target domain for cross-domain transfer. STL constructs a semantic-oriented graph with class extremes, in which the motif is obtained as class-dependent high-order patterns.
Then, we use motifs to fulfill motif-guided transfer learn-ing with structural awareness. The proposed motif-based learning paradigm explores the high-order structural pat-terns well-suited for diverse real-world situations [35]. To be summarized, our main contributions are as follows,
• This paper formulates a real-world friendly setting,
Adaptive Open-set Object Detection (AOOD), con-sidering both novel scenes and classes. To address
AOOD, we propose a novel Structured Motif Matching (SOMA) framework, which models the high-order pat-terns with graph motifs for reliable learning.
• We propose a Structure-aware Novel-class Learning (SNL) module, which models the shared object fea-tures through motif matching for novel-class learning.
• We design Structure-aware Transfer Learning (STL) for novel scenes. STL models the high-order relation with graph motifs, adapting the cross-domain distribu-tion with structural awareness.
• Three AOOD benchmarks are carefully developed, thoroughly considering different base-novel splitting protocols with practical groundings in the real world.
Extensive experiments show that our method achieves state-of-the-art performance in various scenarios. 2.