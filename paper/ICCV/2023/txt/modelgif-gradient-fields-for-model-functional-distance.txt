Abstract
The last decade has witnessed the success of deep learn-ing and the surge of publicly released trained models, which necessitates the quantification of the model functional dis-tance for various purposes. However, quantifying the model functional distance is always challenging due to the opacity in inner workings and the heterogeneity in architectures or tasks. Inspired by the concept of “field” in physics, in this work we introduce Model Gradient Field (abbr. ModelGiF) to extract homogeneous representations from the heteroge-neous pre-trained models. Our main assumption underlying
ModelGiF is that each pre-trained deep model uniquely de-termines a ModelGiF over the input space. The distance between models can thus be measured by the similarity be-tween their ModelGiFs. We validate the effectiveness of the proposed ModelGiF with a suite of testbeds, includ-ing task relatedness estimation, intellectual property pro-tection, and model unlearning verification. Experimental results demonstrate the versatility of the proposed Model-GiF on these tasks, with significantly superiority perfor-mance to state-of-the-art competitors. Codes are available at https://github.com/zju-vipa/modelgif. 1.

Introduction
The last decade has witnessed the great progress of deep learning in various fields, and a plethora of deep neu-ral networks are developed and released publicly, with ei-ther their architectures and trained parameters (e.g., Tensor-flow Hub1, Pytorch Hub2) for research, or the prediction
API (e.g., BigML, Amazon Machine Learning) as ML-as-a-Service (MLaaS) for commercial purposes. These off-the-shelf pre-trained models become extremely important resources for not only practitioners to solve their own prob-lems, but also researchers to explore and exploit the huge potential underlying these pre-trained models.
*Corresponding author 1https://www.tensorflow.org/hub 2https://pytorch.org/hub/
Figure 1. An illustrative diagram of the magnetic field and the pro-posed model gradient field (ModelGiF) defined on the input space.
With the surge of pre-trained models released, quantify-ing the model relationship emerges as an important ques-tion. The large-scale open-sourced deep models, heteroge-neous in architectures and tasks and trained isolatedly or dependently, are related to each other in various manners.
For example, a student model trained by knowledge distil-lation [19] should behave more similarly with the teacher than an independently trained identical model. Likewise, a fine-tuned model should be more closely related to its pre-trained model than the one trained from scratch. More gen-erally, models trained in isolation on heterogeneous tasks should inherit the intrinsic task relatedness [53] as task-specific features are extracted by these models. Broadly speaking, there exists a model metric space where models with similar functional behaviors are clustered together and dissimilar ones are far apart. The model functional distance between models, if left unresolved, leaves existing model repositories still simple unstructured collections of many isolated open-sourced models, hindering the exploitation of their great value as a whole.
Despite the ever-increasing number of publicly available pre-trained models, the study on the model functional dis-tance, i.e., structure of the model metric space, lags far be-hind. This phenomenon can be largely attributed to the great challenge of computing the functional distance between any deep models, where the barriers are three-folds: (1) Hetero-geneity: deep models usually differ significantly in architec-tures. Even with the same architecture, models trained on different datasets or tasks can also behave quite differently; (2) Opacity: the opaque inner workings of deep models ren-der computing the model similarity extremely difficult; (3)
Efficiency: as the cost of computing pairwise distance grows quadratically with the number of models, the computation of the functional distance should be efficient.
A few prior works have been devoted to computing model distance, in either weight space [1, 24] or represen-tation space [28, 12]. For example, Task2Vec [1] com-putes task or model representations based on estimates of the Fisher information matrix associated with the probe net-work parameters, which provides a fixed-dimensional em-bedding of the model agnostic to the task variations. How-ever, Task2Vec assumes all probe models share the same ar-chitecture, which is highly restrictive in practice. ModelD-iff [28] and representation similarity analysis (RSA) [12], on the other hand, adopt the similarity of representations on a small set of reference inputs as the model represen-tations, and the model distance is thus calculated resort-ing to these model representations, which is shown effec-tive for model reuse detection and transferability estimation.
However, these methods only capture the point-wise behav-ior of the models at a small number of chosen reference points, which is limited in representation capacity and fails at harder tasks such as detecting model extraction [28]. Re-cently, DEPARA [43, 44] and ZEST [22] are proposed as pilot studies by applying explanation methods for comput-ing model distance. However, they are validated on disjoint downstream tasks, and the performance on comprehensive tasks remains unclear. Moreover, these methods also use a small number of chosen reference points to extract the model representations, which makes them suffer from low representation capacity.
In this work, inspired by the concept of “field” in physics, we propose Model Gradient Field (as shown in
Figure 1), abbreviated as ModelGiF, as the proxy to ex-tract homogeneous representations from pre-trained hetero-geneous models to derive their functionality distance. Spe-cially, the proposed ModelGiF is defined on the input space, i.e., every point in the ModelGiF denotes the gradient vector of the model output w.r.t. the input on the same point. The main assumption underlying ModelGiF is that each pre-trained deep model uniquely determines a ModelGiF over the input space. The functional distance between any two models can thus be measured by the similarity between their
ModelGiFs. Unlike prior methods where the point-wise features are adopted for representing the model, Model-GiFs represents these models by their gradient on the whole input space, which makes it more capable of differentiat-ing highly related models (i.e., model extraction detection).
Moreover, we provide theoretical insights into the proposed
ModelGiFs for model functional distance, and make exten-sive discussions on different implementation details. We validate the effectiveness of the proposed ModelGiF with a suite of testbeds, including transferability estimation, in-tellectual property protection, and model unlearning verifi-cation. Experimental results demonstrate the versatility of the proposed ModelGiF on these tasks, with significantly superiority to state-of-the-art (SOTA) methods.
To sum up, we make the following contributions: (1) we propose the concept of “model gradient field”, a novel method for quantifying the functionality similarity between pre-trained deep models; (2) we provide theoretical insights into the proposed ModelGiFs for model functional distance, and make extensive discussions on different implementa-tion details; (3) extensive experiments demonstrate the ef-fectiveness and the superiority of ModelGiF on various tasks, including transferability estimation, intellectual prop-erty protection, and model unlearning verification. 2.