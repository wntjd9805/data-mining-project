Abstract
Despite the success of StyleGAN in image synthesis, the images it synthesizes are not always perfect and the well-known truncation trick has become a standard post-processing technique for StyleGAN to synthesize high qual-ity images. Although effective, it has long been noted that the truncation trick tends to reduce the diversity of synthe-sized images and unnecessarily sacrifices many distinct im-age features. To address this issue, in this paper, we first delve into the StyleGAN image synthesis mechanism and discover an important phenomenon, namely Feature Pro-liferation, which demonstrates how specific features repro-duce with forward propagation. Then, we show how the occurrence of Feature Proliferation results in StyleGAN im-age artifacts. As an analogy, we refer to it as the “cancer” in StyleGAN from its proliferating and malignant nature.
Finally, we propose a novel feature rescaling method that identifies and modulates risky features to mitigate feature proliferation. Thanks to our discovery of Feature Prolif-eration, the proposed feature rescaling method is less de-structive and retains more useful image features than the truncation trick, as it is more fine-grained and works in a lower-level feature space rather than a high-level la-tent space. Experimental results justify the validity of our claims and the effectiveness of the proposed feature rescal-ing method. Our code is available at https:// github.com/ songc42/ Feature-proliferation. 1.

Introduction
Deep learning has entered the era of large models. For instance, the GPT-3 [7] developed by OpenAI has 175 bil-lion parameters and can easily cost around 15 million dol-lars to train for a single run, let alone the GPT-3.5 under-pinning the recently hyped ChatGPT1; Stability.ai trained their Stable-diffusion-v1-42 using 256 Nvidia A100 GPUs for 150,000 GPU hours; Nvidia spent 92 GPU years and
*Corresponding author: Yipeng Qin 1https://openai.com/blog/chatgpt 2https://huggingface.co/CompVis/stable-diffusion-v1-4 225 MWh of electricity with an in-house cluster of NVIDIA
V100 GPUs to develop StyleGAN3 [15] and 4 weeks on 64
NVIDIA A100s for a “constrained” training of their recent
StyleGAN-T [27]. As a result, although the performance of large models is impressive, their high costs have become a critical concern, e.g., OpenAI admitted that there was a bug in their GPT-3 model but cannot afford to retrain it due to the high cost [7]. This motivates us to do our best to avoid retraining large neural network models. In this work, we focus on the StyleGAN family [16, 17, 15, 27] as they are inherently more efficient (i.e., generating images with a single pass), allow for excellent semantic interpolation in their latent spaces, and are comparable to the quality of diffusion models [27]. For the StyleGAN series, although there were no obvious bugs in the training, the synthesized images are not always perfect. While instead of attempt-ing to solve this problem by improving the model design which requires multiple retraining, StyleGAN follows the
“no retraining” philosophy and resorts to a post-processing technique called truncation trick [20, 6]. In short, the trun-cation trick improves the quality of StyleGAN synthesized images by normalizing their corresponding latent codes to-wards their mean in the latent space. However, despite its popularity, it has long been noted that the truncation trick tends to reduce the diversity of synthesized images and un-necessarily sacrifices many distinct image features [16].
In this paper, we address the low-quality images syn-thesized by StyleGAN from a different perspective, i.e., its mechanism for image synthesis in the feature space. Specif-ically, we delved into the architectural details of the Style-GAN generator and discovered an important phenomenon, namely Feature Proliferation, which demonstrates how spe-cific features reproduce with forward propagation. In short,
Feature Proliferation denotes the phenomenon where the ratio of the occurrence of a certain type of feature (those with abnormally large values) in a layer increases with for-ward propagation. Our analysis points out that such a phe-nomenon is a by-product of the weight modulation and de-modulation techniques used in StyleGAN2/3 [17, 15] and the latest StyleGAN-T [27].
Interestingly, we observed that Feature Proliferation usually leads to artifacts in Style-Figure 1. Top: StyleGAN synthesized images with artifacts. Bottom: images “cured” by our method.
GAN synthesized images and these artifacts can be easily removed by a simple feature rescaling method. To minimize the unnecessary interference with useful image features, we propose a novel method to identify the risky features prone to proliferation in the earliest layers, thereby removing the least amount of them. As a result, our method significantly outperforms the truncation trick in terms of retaining useful image features while improving the quality of StyleGAN synthesized images. Experimental results justify the valid-ity of our claims and the effectiveness of the proposed fea-ture rescaling method. Our contributions include:
• We discover an important phenomenon, namely Fea-ture Proliferation, which shows how specific features reproduce with forward propagation. We also show that it is a by-product of the weight modulation and demodulation techniques used in modern StyleGANs.
• We discover a strong causal relationship between the occurrence of Feature Proliferation and StyleGAN im-age artifacts.
• We propose a novel feature rescaling method that iden-tifies and modulates risky features to mitigate feature proliferation, thereby achieving a better trade-off be-tween quality and diversity of StyleGAN synthesized images than the popular truncation trick. 2.