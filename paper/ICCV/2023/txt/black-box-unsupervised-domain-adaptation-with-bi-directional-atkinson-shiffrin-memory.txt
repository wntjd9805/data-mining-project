Abstract
Black-box unsupervised domain adaptation (UDA) learns with source predictions of target data without ac-cessing either source data or source models during train-ing, and it has clear superiority in data privacy and flexibil-ity in target network selection. However, the source predic-tions of target data are often noisy and training with them is prone to learning collapses. We propose BiMem, a bi-directional memorization mechanism that learns to remem-ber useful and representative information to correct noisy pseudo labels on the fly, leading to robust black-box UDA that can generalize across different visual recognition tasks.
BiMem constructs three types of memory, including sensory memory, short-term memory, and long-term memory, which interact in a bi-directional manner for comprehensive and robust memorization of learnt features. It includes a for-ward memorization flow that identifies and stores useful fea-tures and a backward calibration flow that rectifies features’ pseudo labels progressively. Extensive experiments show that BiMem achieves superior domain adaptation perfor-mance consistently across various visual recognition tasks such as image classification, semantic segmentation and ob-ject detection. 1.

Introduction
Unsupervised domain adaptation (UDA) has been stud-ied extensively in recent years, aiming to alleviate data collection and annotation constraint in deep network train-ing [8, 67, 25, 57, 75, 88, 12, 58, 52, 56, 93]. However, most existing UDA methods could impair data privacy and confidentiality [43] as they require to access source data or source-trained models during training. In addition, most ex-isting UDA imposes the same network architecture (i.e., the source model architecture) in adaptation which lim-its the flexibility of selecting different target networks in
UDA [43]. Black-box UDA only requires the initial pre-*Corresponding author
Figure 1: Self-training including Vanilla self-training [34], and advanced CBST [92] and CRST [93] tends to ‘for-get’ learnt useful features due to the accumulation of noisy pseudo labels along the training process in black-box UDA – it learns well at the early adaptation stage but collapses with the adaptation moving on and the finally adapted mod-els in [34, 92] cannot even compare with the Source only.
We introduce bi-directional memory to remember useful and representative features learnt during adaptation, which helps calibrate noisy pseudo labels on the fly and leads to stabler black-box UDA without collapse. The experiments were conducted over domain adaptive semantic segmenta-tion task GTA5 → Cityscapes and the evaluations were per-formed over the Cityscapes validation data. dictions of target data provided by black-box source mod-els [43] (i.e., only the model predictions of target data are available [43]) for domain adaptation, as shown in Table 1.
It has attracted increasing attention in recent years [43, 44] due to its advantages in data privacy and flexibility of al-lowing different target networks regardless of the source-trained black-box models.
However, the black-box predictions of the target data are prone to errors due to the cross-domain discrepancy, lead-Comparisons of Different UDA Setups
Adaptation Setups
Source Data
Source-Trained Model
Source-Predicted Target Labels
Target Data
Privacy Risk
Conventional UDA
Source-free UDA
Black-box UDA
✓
✗
✗
✓
✓
✗
✓
✓
✓
✓
✓
✓
High
Medium
Low
Table 1: Comparison of different UDA setups: Black-box UDA better preserves data privacy, requiring neither source data nor source-trained models but just source-predicted labels of target data during domain adaptation. It also allows different target networks regardless of source networks. ing to a fair amount of false pseudo labels. As a result, self-training [34, 92, 93] with the pseudo-labelled target data is often susceptible to collapse as illustrated in Fig. 1. We argue that the learning collapse is largely attributed to cer-tain ‘forgetting’ in network training. Specifically, the self-training with noisy pseudo labels learns well at the early stage and the trained model outperforms the Source only over the test data as shown in Fig. 1. However, the perfor-mance deteriorates gradually and drops even lower than that of the Source only as the training moves on. This shows that the self-training learns useful target information and adapts well towards the target data at the early training stage, but then gradually forgets the learnt useful target knowledge and collapses with the accumulation of pseudo-label noises along the training process.
Inspired by Atkinson-Shiffrin memory [3], we propose
BiMem, a bi-directional memorization mechanism that con-structs three types of memories to address the ‘forgetting’ problem in black-box UDA. The three types of memory in-teract in a bi-directional manner including a forward mem-orization flow and a backward calibration flow as illustrated in Fig. 2. In the forward memorization flow, the short-term memory actively identifies and stores hard samples (i.e., samples with high prediction uncertainty) from the sen-sory memory which buffers fresh features from the current training batch. Meanwhile, the long-term memory accu-mulates features from the sensory and short-term memory, leading to comprehensive memorization that captures fresh yet representative features.
In backward calibration flow, we calibrate the pseudo labels of memorized features pro-gressively where the short-term memory is calibrated by the long-term memory while the sensory memory is corrected by both short-term and long-term memory, leading to robust memorization via a progressive calibration process. Hence,
BiMem builds comprehensive and robust memory that al-lows to learn with more accurate pseudo labels and produce better adapted target model as illustrated in Fig. 1.
The contributions of this work can be summarized in three aspects. First, we design BiMem, a general black-box UDA framework that works well on different visual recognition tasks. To the best of our knowledge, this is the first work that explores and benchmarks black-box UDA over different visual recognition tasks. Second, we design three types of memory that interact in a bi-directional man-ner, leading to less ‘forgetting’ of useful and representa-tive features, more accurate pseudo labeling of target data on the fly, and better adaptation in black-box UDA. Third, extensive experiments over multiple benchmarks show that
BiMem achieves superior performance consistently across different computer vision tasks including image classifica-tion, semantic segmentation, and object detection. 2.