Abstract 1.

Introduction
Generalized Category Discovery (GCD) aims to dis-cover novel categories in unlabelled datasets using knowl-edge learned from labelled samples. Previous studies ar-gued that parametric classifiers are prone to overfitting to seen categories, and endorsed using a non-parametric clas-sifier formed with semi-supervised k-means. However, in this study, we investigate the failure of parametric clas-sifiers, verify the effectiveness of previous design choices when high-quality supervision is available, and identify un-reliable pseudo-labels as a key problem. We demonstrate that two prediction biases exist: the classifier tends to pre-dict seen classes more often, and produces an imbalanced distribution across seen and novel categories. Based on these findings, we propose a simple yet effective paramet-ric classification method that benefits from entropy regular-isation, achieves state-of-the-art performance on multiple
GCD benchmarks and shows strong robustness to unknown class numbers. We hope the investigation and proposed simple framework can serve as a strong baseline to facil-itate future studies in this field. Our code is available at: https://github.com/CVMI-Lab/SimGCD.
*Equal contribution.
With large-scale labelled datasets, deep learning meth-ods can surpass humans in recognising images [23]. How-ever, it is not always possible to collect large-scale human annotations for training deep learning models. Therefore, there is a rich body of recognition models that focus on learning with a large number of unlabelled data. Among them, semi-supervised learning (SSL) [29, 4, 33] is re-garded as a promising approach, yet with the assumption that labelled instances are provided for each of the cate-gories the model needs to classify. Generalized category discovery (GCD) [39] is recently formalised to relax this assumption by assuming the unlabelled data can also con-tain similar yet distinct categories from the labelled data.
The goal of GCD is to learn a model that is able to classify the already-seen categories in the labelled data, and more importantly, jointly discover the new categories in the unla-belled data and make correct classifications. Developing a strong method for this problem could help us better utilise the easily available large-scale unlabelled datasets.
Previous works [39, 20, 16, 5] approach this problem from two perspectives: learning generic feature representa-tions to facilitate the discovery of novel categories, and gen-erating pseudo clusters/labels for unlabelled data to guide the learning of a classifier. The former is often achieved by using self-supervised learning methods [20, 46, 17, 22, 8, 48] to improve the generalization ability of features to novel categories. For constructing the classifier, earlier works [20, 46, 51, 5, 16] adopt a parametric approach that builds a learnable classifier on top of the extracted features.
The classifier is jointly optimised with the backbone using labelled data and pseudo-labelled data.
However, recent research shows [39, 15] that parametric classifiers are prone to overfit to seen categories (see Fig. 2) and thus promote using a non-parametric classifier such as k-means clustering. Albeit obtaining promising results, the non-parametric classifiers suffer from heavy computation costs on large-scale datasets due to quadratic complexity of the clustering algorithm. Besides, unlike a learnable para-metric classifier, the non-parametric method loses the abil-ity to jointly optimise the separating hyperplane of all cate-gories in a learnable manner, potentially being sub-optimal.
This motivates us to revisit the reason that makes previ-ous parametric classifiers fail to recognise novel classes. In a series of investigations (Sec. 3) from the view of super-vision quality, we verify the effectiveness of prior design choices in feature representations and training paradigms when strong supervision is available, and conclude that the key to previous parametric classifiers’ degraded per-formance is unreliable pseudo labels. By diagnosing the statistics of its predictions, we identify severe prediction bi-ases within the model, i.e., the bias towards predicting more
‘Old’ classes than ‘New’ classes (Fig. 5) and the bias of pro-ducing imbalanced pseudo-labels across all classes (Fig. 6).
Based on these findings, we thus present a simple para-metric classification baseline for generalized category dis-covery (see Figs. 1 and 7). The representation learning objective follows GCD [39], and the classification objec-tive is simply cross-entropy for labelled samples and self-distillation [8, 2] for unlabelled samples. Besides, an en-tropy regularisation term is also adopted to overcome bi-ased predictions by enforcing the model to predict more uniformly distributed labels across all possible categories.
Empirically, we indeed observe that our method produces more balanced pseudo-labels (Figs. 9 and 10) and achieves a large performance gain on multiple GCD benchmarks (Tabs. 2 to 4), indicating that the two types of biases we identified are the core reason why the parametric-classifier-based approach performs poorly for GCD. Additionally, we observe that the entropy regulariser could also be used to en-force robustness towards an unknown number of categories (Figs. 11 and 12), this could further ease the deployment of parametric classifiers for GCD in real-world scenarios.
Our contributions are summarised as follows: (1) We re-visit the design choices of parametric classification and con-clude the key factors that make it fail for GCD. (2) Based on
Performance overview. Prior parametric classi-Figure 2. fication method (UNO+ [16]) shows highly degraded perfor-mance in ‘New’ classes. The non-parametric classification work (GCD [39]) performs better, but at the sacrifice of ‘Old’ class and high inference cost. Our method shows that parametric classifica-tion can work well on both metrics. the analysis, we propose a simple yet effective parametric classification method. (3) Our method achieves SOTA on multiple popular GCD benchmarks, challenging the recent promotion of non-parametric classification for this task. 2.