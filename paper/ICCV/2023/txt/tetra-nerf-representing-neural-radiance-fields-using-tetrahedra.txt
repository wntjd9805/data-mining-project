Abstract
Neural Radiance Fields (NeRFs) are a very recent and very popular approach for the problems of novel view syn-thesis and 3D reconstruction. A popular scene representa-tion used by NeRFs is to combine a uniform, voxel-based subdivision of the scene with an MLP. Based on the ob-servation that a (sparse) point cloud of the scene is often available, this paper proposes to use an adaptive represen-tation based on tetrahedra obtained by Delaunay triangula-tion instead of uniform subdivision or point-based represen-tations. We show that such a representation enables efficient training and leads to state-of-the-art results. Our approach elegantly combines concepts from 3D geometry process-ing, triangle-based rendering, and modern neural radiance fields. Compared to voxel-based representations, ours pro-vides more detail around parts of the scene likely to be close to the surface. Compared to point-based representations, our approach achieves better performance. The source code is publicly available at: https://jkulhanek.com/tetra-nerf. 1.

Introduction
Reconstructing 3D scenes from images and rendering photo-realistic novel views is a key problem in computer vision. Recently, NeRFs [3, 4, 39] became dominant in the field for their superior photo-realistic results. Originally,
NeRFs used MLPs to represent the 3D scene as an im-plicit function. Given a set of posed images, NeRF ran-domly samples a batch of pixels, casts rays from the pix-els into the 3D space, queries the implicit function at ran-domly sampled distances along the rays, and aggregates the sampled values using volumetric rendering [37, 39]. While the visual results of such methods are of high quality, the problem is that querying large MLPs at millions of points is costly. Also, once the network is trained, it is difficult to make any changes to the represented radiance field as every-thing is baked into the MLPs parameters, and any change has a non-local effect. Since then, there have been a lot of proposed alternatives to the large MLP field representa-tion [9, 17, 32, 41, 57, 70, 74]. These methods combine an
MLP with a voxel feature grid [41, 57], or in some cases represent the radiance field directly as a tensor [9, 10, 17].
When querying these representations, first, the containing voxel is found, and the features stored at the eight corner points of the voxel are trilinearly interpolated. The result is either passed through a shallow MLP [9, 10, 41, 57] or is used directly as the density and colour [17, 32, 57].
Having a dense tensor represent the entire scene is very inefficient, as we only need to represent a small space around surfaces. Therefore, different methods propose dif-ferent ways of tackling the issue. Instant-NGP [41], for ex-ample, uses a hash grid instead of a dense tensor, where it relies on optimisation to resolve the hash collisions. How-ever, similarly to MLPs, any change to the stored hashmap influences the field in many places. A more common di-rection to addressing the issue is by directly using a sparse tensor representation [9, 17]. These methods start with a low-resolution grid and, at predefined steps, subsample the representation, increasing the resolution. These approaches tend to require a careful setting of hyperparameters, such as the scene bounding box and the subdivision steps, in order for the methods to work well.
Because many of these methods use traditional structure from motion (SfM) [54, 55] methods to generate the initial poses for the captured images, we can reuse the original reconstruction in the scene representation. Inspired by clas-sical surface reconstruction methods [22,23,29,30], we rep-resent the scene as a dense triangulation of the input point cloud, where the scene is a set of non-overlapping tetra-hedra whose union is the convex hull of the original point cloud [14]. When querying such a representation, we find to which tetrahedron the query point belongs and perform barycentric linear interpolation of the features stored in the vertices of the tetrahedron. This very simple representa-tion can be thought of as the direct extension of the classi-cal triangle-rendering pipelines used in graphics [40,43,45].
The representation avoids problems with the sparsity of the input point cloud as the tetrahedra fully cover the scene, re-sulting in a continuous rather than discrete representation.
This paper makes the following contributions: (1) We propose a novel radiance field representation which is ini-tialised from a sparse or dense point cloud. This represen-tation is naturally denser in the proximity of surfaces and, therefore, provides a higher resolution in these regions. (2)
The proposed representation is evaluated on multiple syn-thetic and real-world datasets and is compared with a state-of-the-art point-cloud-based representation â€“ Point-NeRF
[70]. The presented results show that our method clearly outperforms this baseline. We further demonstrate the ef-fectiveness of our adaptive representation by comparing it with a voxel-based representation that uses the same num-ber of trainable parameters. (3) We make the source code and model checkpoints publicly available.1 2.