Abstract
As a video task, Multiple Object Tracking (MOT) is ex-pected to capture temporal information of targets effec-tively. Unfortunately, most existing methods only explicitly exploit the object features between adjacent frames, while lacking the capacity to model long-term temporal infor-mation. In this paper, we propose MeMOTR, a long-term memory-augmented Transformer for multi-object tracking.
Our method is able to make the same objectâ€™s track embed-ding more stable and distinguishable by leveraging long-term memory injection with a customized memory-attention layer. This significantly improves the target association ability of our model. Experimental results on DanceTrack show that MeMOTR impressively surpasses the state-of-the-art method by 7.9% and 13.0% on HOTA and AssA met-rics, respectively. Furthermore, our model also outperforms other Transformer-based methods on association perfor-mance on MOT17 and generalizes well on BDD100K. Code is available at https://github.com/MCG-NJU/MeMOTR. 1.

Introduction
Multi-Object Tracking (MOT) [8, 23, 29] aims to de-tect multiple objects and maintain their identities in a video stream. MOT can be applied to numerous downstream tasks, such as action recognition [7], behavior analysis [16], and so on. It is also an important technique for real-world applications, e.g., autonomous driving and surveillance.
According to the definition of MOT, this task can be formally divided into two parts: object detection and as-sociation. For a long time, pedestrian tracking datasets (like MOT17 [23]) have had mainstream domination in the community. However, these datasets have insufficient chal-lenges in target association because of their almost lin-ear motion pattern. Therefore, tracking-by-detection meth-ods [5, 32, 43] achieve the state-of-the-art performance of
MOT for several years. They first adopt a robust object de-(cid:66) : Corresponding author (lmwang@nju.edu.cn). tector (e.g., YOLOX [12]) to independently localize the ob-jects in each frame and associate them with IoU [3, 40] or
ReID features [26]. However, associating targets becomes a critical challenge in some complex scenarios, like group dancers [29] and sports players [8, 13]. These similar ap-pearances and erratic movements may cause existing meth-ods to fail. Recently, Transformer-based tracking meth-ods [22, 42] have introduced a new fully-end-to-end MOT paradigm. Through the interaction and progressive decod-ing of detect and track queries in Transformer, they simul-taneously complete detection and tracking. This paradigm is expected to have greater potential for object association due to the flexibility of Transformer, especially in the above complex scenes.
Although these Transformer-based methods achieve ex-cellent performance, they still struggle with some compli-cated issues, such as analogous appearances, irregular mo-tion patterns, and long-term occlusions. We hypothesize that more intelligent leverage of temporal information can provide the tracker a more effective and robust representa-tion for each tracked target, thereby relieving the above is-sues and boosting the tracking performance. Unfortunately, most previous methods [22, 42] only exploit the image or object features between two adjacent frames, which lacking the utilization of long-term temporal information.
Based on the analysis above, in this paper, we focus on leveraging temporal information by proposing a long-term
Memory-augmented Multi-Object Tracking method with
TRansformer, coined as MeMOTR. We exploit detect and track embeddings to localize newborn and tracked objects via a Transformer Decoder, respectively. Our model main-tains a long-term memory with the exponential recursion update algorithm [28] for each tracked object. Afterward, we inject this memory into the track embedding, reducing its abrupt changes and thus improving the model association ability. As multiple tracked targets exist in a video stream, we apply a memory-attention layer to produce a more dis-tinguishable representation. Besides, we present an adap-tive aggregation to fuse the object feature from two adjacent frames to improve tracking robustness.
In addition, we argue that the learnable detection query
in DETR [6] has no semantic information about specific objects. However, the track query in Transformer-based
MOT methods like MOTR [42] carries information about a tracked object. This difference will cause a semantic infor-mation gap and thus degrade the final tracking performance.
Therefore, to overcome this issue, we use a light decoder to perform preliminary object detection, which outputs the de-tect embedding with specific semantics. Then we jointly input detect and track embeddings into the subsequent de-coder to make MeMOTR tracking results more precise.
We mainly evaluate our method on the DanceTrack dataset [29] because of its serious association challenge.
Experimental results show that our method achieves the state-of-the-art performance on this challenging Dance-Track dataset, especially on association metrics (e.g., AssA,
IDF1). We also evaluate our model on the traditional pedestrian tracking dataset of MOT17 [23] and the multi-categories tracking dataset of BDD100K [41]. In addition, we perform extensive ablation studies further demonstrate the effectiveness of our designs. 2.