Abstract
End-to-end autonomous driving aims to build a fully dif-ferentiable system that takes raw sensor data as inputs and directly outputs the planned trajectory or control signals of the ego vehicle. State-of-the-art methods usually follow the ‘Teacher-Student’ paradigm. The Teacher model uses privileged information (ground-truth states of surrounding agents and map elements) to learn the driving strategy. The student model only has access to raw sensor data and con-ducts behavior cloning on the data collected by the teacher model. By eliminating the noise of the perception part dur-1
ing planning learning, state-of-the-art works could achieve better performance with significantly less data compared to those coupled ones.
However, under the current Teacher-Student paradigm, the student model still needs to learn a planning head from scratch, which could be challenging due to the redundant and noisy nature of raw sensor inputs and the casual con-fusion issue of behavior cloning.
In this work, we aim to explore the possibility of directly adopting the strong teacher model to conduct planning while letting the student model focus more on the perception part. We find that even equipped with a SOTA perception model, directly letting the student model learn the required inputs of the teacher model leads to poor driving performance, which comes from the large distribution gap between predicted privileged inputs and the ground-truth.
To this end, we propose DriveAdapter, which employs adapters with the feature alignment objective function be-tween the student (perception) and teacher (planning) mod-ules. Additionally, since the pure learning-based teacher model itself is imperfect and occasionally breaks safety rules, we propose a method of action-guided feature learn-ing with a mask for those imperfect teacher features to fur-ther inject the priors of hand-crafted rules into the learning process. DriveAdapter achieves SOTA performance on mul-tiple closed-loop simulation-based benchmarks of CARLA. 1.

Introduction
In recent years, autonomous driving has become an ac-tive research topic due to the enormous progress of deep learning. A traditional pipeline of an autonomous driving system is usually composed of object detection [23], motion prediction [18, 17], trajectory planning [32], etc. To fully unleash the power of deep learning and big data and avoid cumulative errors, the concept of end-to-end autonomous driving is proposed [29, 26, 15, 5] which aims to build a fully differentiable model directly mapping the raw sensor data into planned trajectories or control signals.
One difficulty of end-to-end autonomous driving is that the noisy and redundant raw sensor inputs make it hard to directly learn a good policy. For example, raw sensor in-puts based reinforcement learning (RL) agent MaRLn [35] requires 20 million steps (around 20 days) to converge even equipped with their pretraining techniques. To this end, in
Roach [45], they decouple the learning process into two steps: (i) conduct the RL algorithm based on privileged in-puts - rasterizing the ground-truth location of surrounding agents and traffic signs into 2D bird’s-eye-view (BEV) ten-sors. The trained RL model is called the teacher model as it uses privileged inputs and thus performs well. (ii) conduct behavior cloning with raw sensor inputs on the data col-lected by the teacher model. This model only with access to raw sensor data is called the student model since they are supervised by the teacher model. By decoupling the percep-tion noise from the driving strategy learning process, Roach could achieve much better performance on more challeng-ing benchmarks in 10 million steps. Besides the benefits of efficient RL training, in LBC [4] and PlanT [32], they demonstrate that training a teacher model from rule-based expert and then using the teacher model to provide extra su-pervision for the student model could bring significant per-formance gains as well. Due to the aforementioned advan-tages of the decoupled planning and perception learning, the teacher-student paradigm has been widely adopted by the state-of-the-art (SOTA) works [4, 3, 39, 32, 14].
However, issues under there are still the existing paradigm. The student model still needs to train a planning head from scratch by behavior cloning, which could result in the causal confusion issue [37]. Specifically, the causal confusion issue here refers to the phenomenon that the stu-dent model learns the visual clue of the results instead of the cause of the desired actions. For example, the well-known inertia problem [37] is that the agent sometimes keeps still forever at the intersection. It is because, during behavior cloning, the student model might learn the improper causal correlation that the ego vehicle should copy behaviors of its surrounding vehicles at the intersection. In fact, the behav-iors are determined by the traffic light. However, since the traffic light is smaller in images compared to vehicles, the student tends to find the shortcut [37]. As a result, during evaluation, if there are no vehicles nearby or all vehicles are behind the ego vehicle, it might get stuck. The causal confu-sion issues could be solved by techniques such as reweight-ing the distribution of training data [33, 30, 37] or a causal prior structure/network [38, 9].
Inspired by the fact that we already have a strong teacher model trained by RL without any causal confusion issue, in this work, we aim to explore the way to utilize the teacher model to conduct planning directly instead of train-ing a planning head for the student model from scratch.
In this way, the learning process of perception and plan-ning is completely decoupled and thus the disadvantage of behavior cloning could be avoided, as demonstrated in
Fig. 1. As a result, we could directly benefit from the driving knowledge inside the teacher model learned by RL.
One intuitive implementation of this idea is to train a stu-dent model to generate the required privileged inputs for the frozen teacher model, e.g., a BEV segmentation student model for the Roach teacher model. However, we find that even equipped with the SOTA perception model: BEVFu-sion [24] + Mask2former [6], its final driving performance is still unsatisfying. The issue comes from the large dis-tribution gap between the predicted BEV segmentation and ground-truth. It could be formulated as a domain transfer
problem since the teacher model has only seen the ground-truth BEV segmentation during the training process.
Inspired by the usage of adapters in the natural language processing (NLP) [13] and computer vision [12] field to adopt huge foundation models for downstream tasks, we propose DriveAdapter, which connects the output of the student model (perception) and the input of the teacher model (planning). Specifically, we add a learnable adapter module after each part of the teacher model and apply fea-ture alignment objective functions on each adapter. In this way, the adapter could learn to transfer the imperfect feature from the student model’s domain to the teacher model’s do-main in a layer-by-layer supervised way.
Additionally, we observe that the pure learning-based teacher model itself is imperfect and it is a common prac-tice to add extra hand-crafted rules during the final deci-sion process [40, 43, 14]. Thus, even if the student with adapters could losslessly generate the required inputs for the teacher model, it is still upper-bounded by the imperfect performance of the teacher. To this end, we propose to back-propagate an action loss to all adapters and mask all feature alignment loss if the teacher model is overridden by the rule.
In this way, we force adapters to directly learn the feature required to generate good actions instead of just mimicking the teacher. By combining the two proposed techniques,
DriveAdapter achieves state-of-the-art performance on two closed-loop evaluation benchmarks of the CARLA simula-tor. Moreover, we conduct thorough ablation studies and give results of other related attempts such as directly gener-ating intermediate features of the teacher.
In summary, this work has the following contributions:
• To the best of our knowledge, we are the first to thor-oughly explore the paradigm of directly utilizing the teacher head to conduct planning for the end-to-end au-tonomous driving task. Under such decoupled paradigm, the disadvantages of behavior cloning such as causal con-fusion could be avoided.
• The intermediate output form of BEV segmentation be-tween the perception and planning modules has strong interpretability, shedding insights into the typically black-box pipeline of end-to-end autonomous driving. The de-coupled perception model could enjoy the recent rapid progress of BEV perception and semantic segmentation.
• To deal with the imperfect perception issue as well as the imperfect teacher model issue, we propose DriveAdapter along with a masked feature distillation strategy. By com-bining the two techniques, it could achieve state-of-the-art performance on two public benchmarks.
• We give thorough ablation studies and other related at-tempts to provide more insights and understanding re-garding the new decoupled paradigm.
We believe that the rich driving knowledge within an RL expert model learned by millions of steps of exploration should be utilized more extensively instead of only for be-havior cloning. We hope the proposed decoupled paradigm, our failing attempts, and our working techniques could all provide useful insights for this line of study. 2.