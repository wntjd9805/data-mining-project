Abstract
Frequency analysis is useful for understanding the mech-anisms of representation learning in neural networks (NNs).
Most research in this area focuses on the learning dynam-ics of NNs for regression tasks, while little for classifi-cation. This study empirically investigates the latter and expands the understanding of frequency shortcuts. First, we perform experiments on synthetic datasets, designed to have a bias in different frequency bands. Our re-sults demonstrate that NNs tend to find simple solutions for classification, and what they learn first during train-ing depends on the most distinctive frequency character-istics, which can be either low- or high-frequencies. Sec-ond, we confirm this phenomenon on natural images. We propose a metric to measure class-wise frequency char-acteristics and a method to identify frequency shortcuts.
The results show that frequency shortcuts can be texture-based or shape-based, depending on what best simpli-fies the objective. Third, we validate the transferability of frequency shortcuts on out-of-distribution (OOD) test sets. Our results suggest that frequency shortcuts can be transferred across datasets and cannot be fully avoided by larger model capacity and data augmentation. We recom-mend that future research should focus on effective train-ing schemes mitigating frequency shortcut learning. Codes and data are available at https://github.com/ nis-research/nn-frequency-shortcuts. 1.

Introduction
Deep neural networks (DNNs) have been widely used to tackle problems in many fields, e.g. medical data analysis, self-driving vehicles, robotics, and surveillance. However, the underlying predictive processes of DNNs are not com-pletely understood due to the black-box nature of their non-linear multilayer structure [3]. While a DNN can approx-imate any function [23], its (hundreds of) millions of pa-rameters limit the understanding of function approximation process. Analyzing the learned features is a viable way to understand what triggers the predictions, although explain-Figure 1: Images of ‘container ship’ and ’siamese cat’ and their DFM-filtered versions with only top-5% dominant fre-quencies (the white dots in the central figures) retained can both be recognized correctly by NNs. ing how DNNs process data needs further exploration [28].
Researchers worked on explaining the predictions of
NNs in terms of their input, using Saliency [27], Gradient-weighted Class Activation Mapping [25] and Layer-wise
Relevance Propagation [2]. These techniques highlight the area of an image that contributes to prediction but do not explain why the performance of NNs degrades on OOD data. Recently, an interest in understanding the learning dynamics of NNs from a frequency perspective has grown.
NNs are found to learn lower frequencies first in regres-sion tasks [23], as they carry most of the needed informa-tion to reconstruct signals [35]. Thus NNs tend to fit low-frequency functions first to data [17]. This biased learning behavior is known as simplicity bias [26], which induces the NNs to learn simple but effective patterns, i.e. shortcuts solutions that disregard semantics related to the problem at hand but are simpler for solving the optimization task. For instance, the frequency shortcuts proposed in [31] are sets of frequencies used specifically to classify certain classes.
In this work, we empirically analyze the learning dy-namics of NNs for image classification and relate it to simplicity-bias and shortcut learning from a frequency per-spective. Our results indicate that simplicity-biased learn-ing in NNs leads to frequency-biased learning, where the
NNs exploit specific frequency sets, namely frequency shortcuts, to facilitate predictions. These frequency short-cuts are data-dependent and can be either texture-based or shape-based, depending on what best simplifies the objec-tive function (e.g. a unique color, texture, or shape associ-ated with a particular class in a dataset, without necessar-ily other meaningful semantics). This may impact general-ization. We demonstrate this phenomenon through texture-based and shape-based frequency shortcuts in Fig. 1. When we retain only specific subsets of frequencies (identified us-ing a method proposed in this paper) from images of ‘con-tainer ship’ and ‘siamese cat’, the classifier can recognize
Interestingly, when the same sets of fre-them correctly. quencies are retained from images of other classes, the pre-dictions are biased towards these two classes, indicating that the frequency sets are specific for their classification.
Different from previous work on regression tasks [23], we investigate the learning dynamics and frequency short-cuts in NNs for image classification. Compared to the work uncovering frequency shortcuts [31], we expand the understanding of them and demonstrate that they can be texture, shape, or color, depending on data characteristics.
We propose a metric to compare the frequency character-istics of data and investigate systematically the impact of present/absent shortcut features on OOD generalization. In summary, our contributions are: 1. We that complement existing studies showed
NNs for regression tasks are biased towards low-frequency [23]. For classification, we find that NNs can exhibit different frequency biases, tending to adopt frequency shortcuts based on data characteris-tics because of simplicity-bias learning. Our analysis provides valuable insights into the learning dynamics of NNs and the factors influencing their behavior. 2. We propose a method to identify frequency short-cuts, based on culling frequencies that contribute less to classification. These shortcuts are composed of specific frequency subsets that correspond to tex-tures, shapes, or colors, providing further insight into the texture-bias identified by Geirhos et al. [12] and background-dependency found in [33]. 3. We systematically examine the influence of frequency shortcuts on the generalization of NNs and find that the presence of frequency shortcut features in an OOD test set may give an illusion of improved generaliza-tion. Furthermore, we find that larger model capacity and common data augmentation techniques like Au-toAugment [5], AugMix [14], and SIN [11] cannot fully avoid shortcut learning. We recommend further research targeting frequency information to avoid fre-quency shortcut learning. 2.