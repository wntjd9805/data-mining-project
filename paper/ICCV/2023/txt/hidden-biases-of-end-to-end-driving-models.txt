Abstract
End-to-end driving systems have recently made rapid progress, in particular on CARLA. Independent of their ma-jor contribution, they introduce changes to minor system components. Consequently, the source of improvements is unclear. We identify two biases that recur in nearly all state-of-the-art methods and are critical for the observed progress on CARLA: (1) lateral recovery via a strong in-ductive bias towards target point following, and (2) longi-tudinal averaging of multimodal waypoint predictions for slowing down. We investigate the drawbacks of these bi-ases and identify principled alternatives. By incorporating our insights, we develop TF++, a simple end-to-end method that ranks first on the Longest6 and LAV benchmarks, gain-ing 11 driving score over the best prior work on Longest6. 1.

Introduction
End-to-end driving approaches have rapidly improved in performance on the CARLA leaderboard [1], the de-facto standard for fair online evaluation. Driving scores have in-creased from under 20 [9, 22] to over 70 [26, 31] in just two years. However, why recent systems work so well is not fully understood, as both methods and training sets differ largely between submissions. Rigorous ablations are expen-sive due to the large design space of driving systems and the need to simulate large amounts of driving for evaluation.
In particular, recent methods trained with Imitation
Learning (IL) have shown strong performance [6, 8, 11, 26, 31]. They are trained using offline datasets, yet they can sur-prisingly recover from the classic compounding error prob-lem of IL [21, 24], as indicated by their high route comple-tions [8, 11, 26, 31]. While they do not utilize HD maps as input, they are provided with map-based GNSS locations in the center of the lane (spaced 30 m apart on average) called target points (TPs) that describe the route the car should follow. TPs were introduced as an alternative form of conditioning signals to convey driver intent [9, 22]. Prior work [13, 14] used discrete navigation commands or NCs (i.e. follow lane, turn right, ...) instead.
In this paper, we show that TP conditioned models re-(a) Target point shortcut (b) Waypoint ambiguity
Figure 1: Hidden biases. (a) When outside their train-ing distribution, current methods extrapolate waypoint pre-dictions to the nearest target point, helping them recover. (b) The future velocity is multi-modal, but current methods commit to a single plan, which leads to interpolation. cover from the compounding error problem because they use geometric information contained in the TP to reset steer-ing errors periodically (at every TP). This makes them im-plicitly rely on accurate map information, even though they are otherwise HD map free. Steering directly towards a
TP is a shortcut [16] that these IL methods learn to ex-ploit. When methods accumulate enough steering error to be out of distribution during deployment, we observe that they steer towards the nearest TP. When the TP is close, this has the effect of driving back to the lane center, where it is in distribution again. This is illustrated in Fig. 1a. However, when the TP is far away, this shortcut can lead to catas-trophic steering errors (e.g. cutting a turn). We show ex-amples of this behavior for various SotA architectures in
Section 3.1. We demonstrate that the shortcut problem is intrinsically related to the decoder architecture and that a transformer decoder [29] can mitigate it.
Another common aspect of the current SotA is that they use waypoints (future positions of an expert driver) as out-put representations [8, 11, 31]. We point out that this is an ambiguous representation as the future velocity is multi-modal, yet the model commits to a point estimate. This is il-lustrated in Fig. 1b. We show that this ambiguity can some-times be helpful due to the continuous nature of waypoints: the network can continuously interpolate between modes.
We propose an alternative that explicitly predicts the un-certainty of the network via target speed classification, and show that interpolating between target speeds weighted by the uncertainty reduces collisions. Our controlled experi-ments also cover important but sometimes neglected details in the training of end-to-end driving systems, such as aug-mentation, training schedules, and dataset size. In particu-lar, we revisit the idea of shift and rotation augmentations to aid recovery [2,5]. These were common in early IL methods for CARLA with control outputs [14], but are harder to im-plement with waypoint outputs and not used by the current
SotA. We find that they yield significant improvements.
Using these insights, we develop TransFuser++ (TF++), which sets a new SotA on the Longest6 [11] and LAV [8] benchmarks. Two of the ideas we apply, transformer de-coder pooling and path-based outputs instead of waypoints, have been used in Interfuser [26]. However, these are pre-sented as minor details, and their impact is not studied in isolation as in our work. TF++ is significantly simpler than
Interfuser, yet outperforms it by a large margin on Longest6, as we show in Section 4. We use ∼4× less data, 1 camera instead of 4, and do not require complex heuristics to extract throttle and brake commands for our path output.
Contributions:
• We show that target point conditioned models learn a shortcut that helps them recover from steering errors.
• We point out that the waypoint output representation is ambiguous, but its continuous nature helps models collide less by interpolating to slow down.
• Using the insights gained from controlled experiments, we propose TransFuser++ which places first on the
Longest6 and LAV benchmarks.
Code, data, and models are available at https://github.com/ autonomousvision/carla garage. 2.