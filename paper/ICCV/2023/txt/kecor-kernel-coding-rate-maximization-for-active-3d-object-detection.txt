Abstract
Achieving a reliable LiDAR-based object detector in au-tonomous driving is paramount, but its success hinges on obtaining large amounts of precise 3D annotations. Ac-tive learning (AL) seeks to mitigate the annotation burden through algorithms that use fewer labels and can attain performance comparable to fully supervised learning. Al-though AL has shown promise, current approaches priori-tize the selection of unlabeled point clouds with high uncer-tainty and/or diversity, leading to the selection of more in-stances for labeling and reduced computational efficiency.
In this paper, we resort to a novel kernel coding rate maxi-mization (KECOR) strategy which aims to identify the most informative point clouds to acquire labels through the lens of information theory. Greedy search is applied to seek desired point clouds that can maximize the minimal num-ber of bits required to encode the latent features. To de-termine the uniqueness and informativeness of the selected samples from the model perspective, we construct a proxy network of the 3D detector head and compute the outer product of Jacobians from all proxy layers to form the em-pirical neural tangent kernel (NTK) matrix. To accommo-date both one-stage (i.e., SECOND) and two-stage detectors (i.e., PV-RCNN), we further incorporate the classification entropy maximization and well trade-off between detection performance and the total number of bounding boxes se-lected for annotation. Extensive experiments conducted on two 3D benchmarks and a 2D detection dataset evidence the superiority and versatility of the proposed approach. Our results show that approximately 44% box-level annotation costs and 26% computational time are reduced compared to the state-of-the-art AL method, without compromising de-tection performance. Source code: https://github. com/Luoyadan/KECOR-active-3Ddet. 1.

Introduction
Being a crucial component in the realm of scene under-standing, LiDAR-based 3D object detection [35, 59, 60, 64] identifies and accurately localizes objects in a 3D scene with the oriented bounding boxes and semantic labels. This technology has facilitated a wide range of applications in environmental perceptions, including robotics, autonomous driving, and augmented reality. With the recent advance-ments in 3D detection models [14, 25, 54], highly accurate recognition of objects can be achieved through point cloud projection [65], point feature extraction [35, 58, 60, 67, 68] or voxelization [13, 59, 64]. However, achieving such per-formance often comes at the expense of requiring a large volume of labeled point cloud data, which can be costly and time-consuming.
To mitigate the labeling costs and optimize the value of annotations, active learning (AL) [38, 50] has emerged as a promising solution. Active learning involves iteratively selecting the most beneficial samples for label acquisition from a large pool of unlabeled data until the labeling budget is exhausted. This selection process is guided by the se-lection criteria based on sample uncertainty [30, 37, 49, 51] and/or diversity [16, 22, 56, 66]. Both measures are used to assess the informativeness of the unlabeled samples.
Aleatoric uncertainty-driven approaches search for samples that the model is least confident of by using metrics like maximum entropy [63] or estimated model changes [45,69].
On the other hand, epistemic uncertainty based methods at-tempt to find the most representative samples to avoid sam-ple redundancy by using greedy coreset algorithms [56] or clustering based approaches [5].
While active learning has proven to be effective in re-ducing labeling costs for recognition tasks, its application in
LiDAR-based object detection has been limited [18,31,55].
This is largely due to its high computational costs and in-volvement of both detection and regression tasks, which pose significant challenges to the design of the selection criteria. A very recent work CRB [42] manually designed three heuristics that allow the acquisition of labels by hier-archically filtering out concise, representative, and geomet-rically balanced unlabelled point clouds. While effective, it remains unclear how to characterize the sample informa-tiveness for both classification and regression tasks with one unified measurement.
In this paper, we propose a novel AL strategy called ker-nel coding rate maximization (KECOR) for efficient and ef-fective active 3D detection. To endow the model with the ability to reason about the trade-off between information and performance autonomously, we resort to the coding rate theory and modify the formula from feature selection to sample selection, by replacing the covariance estimate with the empirical neural tangent kernel (NTK). The pro-posed KECOR strategy allows us to pick the most informa-tive point clouds from the unlabeled pool such that their la-tent features require the maximal coding length for encod-ing. To characterize the non-linear relationships between the latent features and the corresponding box predictions spending the least computational costs, we train a proxy network of the 3D detector head with labeled samples and extract the outer product of Jacobians from all proxy layers to form the NTK matrix of all unlabeled samples. Empiri-cal studies evidence that the NTK kernel not only captures non-linearity but takes the aleatoric and epistemic uncer-tainties into joint consideration, assisting detectors to rec-ognize challenging objects that are of sparse structure. To accommodate both one-stage (i.e., SECOND) and two-stage detectors (i.e., PV-RCNN), we further incorporate the clas-sification entropy maximization into the selection criteria.
Our contributions are summarized as below: 1. We propose a novel information-theoretic based crite-rion KECOR for cost-effective 3D box annotations that allows for the greedy search of informative point clouds by maximizing the kernel coding rate. 2. Our framework is flexible to accommodate different choices of kernels and 3D detector architectures. Empir-ical NTK kernel used in KECOR demonstrates a strong capacity to unify both aleatoric and epistemic uncertain-ties from the model perspective, which helps detectors learn a variety of challenging objects. 3. Extensive experiments have been conducted on both 3D benchmarks (i.e., KITTI and Waymo Open) and 2D ob-ject detection dataset (i.e., PASCAL VOC07), verify-ing the effectiveness and versatility of the proposed ap-proach. Experimental results show that the proposed ap-proach achieves a 44.4% reduction of annotations and up to 26.4% less running time compared to the state-of-the-art active 3D detection methods. 2.