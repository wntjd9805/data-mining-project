Abstract
Compressive autoencoders (CAEs) play an important role in deep learning-based image compression, but large-scale CAEs are computationally expensive. We propose a framework with three techniques to enable efficient CAE-based image coding: 1) Spatially-adaptive convolution and normalization operators enable block-wise nonlinear transform to spend FLOPs unevenly across the image to be compressed, according to a transform capacity map. 2) Just-unpenalized model capacity (JUMC) optimizes the transform capacity of each CAE block via rate-distortion-complexity optimization, finding the optimal capacity for the source image content. 3) A lightweight routing agent model predicts the transform capacity map for the CAEs by approximating JUMC targets. By activating the best-sized sub-CAE inside the slimmable supernet, our approach achieves up to 40% computational speed-up with minimal
BD-Rate increase, validating its ability to save computa-tional resources in a content-aware manner. 1.

Introduction
In recent years, neural image compression (NIC) is be-ing actively investigated, which reveals its great potential in terms of compression efficiency and capacity for per-ceptual optimization [2, 3, 6, 24]. After initial attempts, the specific variants of autoencoders, namely compressive autoencoders (CAEs), have become a popular architecture choice in follow-up studies. The adoption of CAE for learning compact nonlinear representation of image signals
*The majority of the work was done when L. Tao was studying at
SECE, PKUSZ. His current affiliation is with Tencent AI Lab.
†Corresponding Author: Wei Gao. This work was supported by
Natural Science Foundation of China (62271013, 62031013), Shen-zhen Fundamental Research Program (GXWD20201231165807007-20200806163656003), Shenzhen Science and Technology Plan Basic Re-search Project (JCYJ20190808161805519), and was sponsored by CAAI-Huawei MindSpore Open Fund (CAAIXSJLJJ-2022-002C). leads to great success, yielding comparable or superior rate-distortion trade-offs when compared with the existing state-of-the-art codecs. Due to the learning-based nature of NIC, the number of incurred floating-point operations (FLOPs) is higher than those of legacy algorithms by orders of magni-tude. By replacing traditional linear transforms (i.e., DCT,
DST) with neural network-based nonlinear transforms, the inference computational costs will be huge although with much better representation capacity. Such a dilemma hin-ders the practical deployment of NIC codecs, which calls for an efficient way to reduce the computational overhead of CAEs without harming their performance advantages.
Early works have demonstrated that the scale of CAEs is highly related to the image quality or bitrate [3]. The more radical quality objective in loss function will de-mand more latent channels allocated. Therefore, the con-verged model with inadequate channels will suffer from rate-distortion degradation. A larger redundant model car-ries no penalty or reward in terms of rate-distortion crite-In this case, the well-studied channel pruning meth-ria. ods may fit the needs for complexity-mitigation. However, since neural image codecs are originally trained with di-versified picture and block content and involve distortion-sensitive reconstruction, the contribution of each channel takes effect on individual inputs. Henceforth, when chan-nel pruning approaches are applied to remove unimpor-tant channels [12, 23, 41], excessive channel elimination can lead to severely-degraded rate-distortion performance.
Therefore, the static way of one-shot channel pruning may not be suitable for further rate-distortion-complexity opti-mization, which can be crucial to the coding performance.
Conversely, we would like to investigate the dynamic rout-ing solution to benefit the underexplored rate-distortion-complexity (RDC) trade-off-oriented optimization.
In this paper, we emphasize the importance of employ-ing content-adaptive optimization at run-time. The overall framework of AdaNIC is illustrated in Figure 1. By de-signing and training a lightweight adaptive routing agent under the rate-distortion lossless objective, and proposing
Figure 1. Illustration of the proposed AdaNIC framework. Lower middle: SA-CAE, a slimmable CAE supernet powered by spatially-adaptive operators. SlimE&SlimD: slimmable encoder&decoder for neural-based transform. AE&AD: arithmetic encoder&decoder.
Upper middle: transform routing agent (RA) sub-system, including teacher and student routing agents and their learning pipeline. D: knowledge distillation loss as devised by Hinton et al. in [13]. A: action loss, we use cross-entropy loss between the output action of the agent and the optimal JUMC choice. S: surrogate loss, we adopt mean-squared error (MSE) as the criterion for ∆ routing cost regression.
∆Cost: transform capacity downgrade cost defined in Section 3.4. JUMC: just-unpenalized model capacity determined by a threshold ϵ.
Upper sides: (a) examples of patch-level routing costs. (b) details of the lightweight routing agent (student model). the spatially-adaptive signal transform operators for fine-grained transform-capacity allocation, the optimal sub-CAE with minimal redundant parameters and computations can serve the corresponding input patches. In this way, the max-imal system throughput can be achieved. grained capacity allocation. The proposed solution utilizes a novel action space, which is content-adaptive (in image level or patch level), so additional optimization techniques (for example, model pruning / AutoML methods) shall be compatible with the trade-offs discussed in this work.
Since the action space of dynamic routing is devised as sample or region-adaptive, it can be seamlessly integrated into other feasible solutions for accelerating neural nonlin-ear transform that results in a static lightweight model and improves their performance by joint optimization. The ra-tionale behind this is that the speed-up effects of AdaNIC come from exploiting the differences of required transform capacity among uncompressed content, which is not con-flicting with efforts of acquiring a computationally-efficient model. The interesting side of the proposed “routing” ap-proach is that it makes coding decisions at run-time, which is similar to the traditional RDO process or fast algorithms that are commonly adopted by modern image/video coding standards. Such kind of run-time trade-offs can bring about more flexibility when a codec system is responsible for the processing of a wide variety of content, enabling better rate-distortion or complexity tradeoffs through customized be-haviors.
The contributions of our work can be summarized as fol-low: (1) a novel way of accelerating neural image codecs with content-adaptive transform routing (2) definition of unpenalized rate-distortion objective (3) network design of lightweight routing agent and its learning mechanism (4) an original spatially-adaptive convolution operator for fine-2.