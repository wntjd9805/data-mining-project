Abstract
This paper studies the fundamental problem of multi-layer generator models in learning hierarchical represen-tations. The multi-layer generator model that consists of multiple layers of latent variables organized in a top-down architecture tends to learn multiple levels of data abstrac-tion. However, such multi-layer latent variables are typi-cally parameterized to be Gaussian, which can be less in-formative in capturing complex abstractions, resulting in limited success in hierarchical representation learning. On the other hand, the energy-based (EBM) prior is known to be expressive in capturing the data regularities, but it often lacks the hierarchical structure to capture different levels of hierarchical representations. In this paper, we propose a joint latent space EBM prior model with multi-layer latent variables for effective hierarchical representation learning.
We develop a variational joint learning scheme that seam-lessly integrates an inference model for efficient inference.
Our experiments demonstrate that the proposed joint EBM prior is effective and expressive in capturing hierarchical representations and modelling data distribution. 1.

Introduction
In recent years, deep generative models have achieved remarkable success in generating high-quality images [36, 31], texts [40, 13], and videos [28, 35]. However, learn-ing generative models that incorporate hierarchical struc-tures still remains a challenge. Such hierarchical generative models can play a critical role in enabling explainable ar-tificial intelligence, thus representing an important area of ongoing research.
To tackle this challenge, various methods of learning hi-erarchical representations have been explored [30, 42, 21, 3, 30]. These methods learn generative models with mul-tiple layers of latent variables organized in a top-down ar-Our project page is available at https://jcui1224.github. io/hierarchical-representation-ebm-proj/. chitecture, which have shown the capability of learning in-creasingly abstract representations (e.g., general structures, classes) at the top layers while capturing low-level data fea-tures (e.g., colors, background) at the bottom layers. In gen-eral, one could categorize these methods into two classes: (i) conditional hierarchy and (ii) architectural hierarchy.
The conditional hierarchies [30, 12, 25, 21, 3] employ stacked generative models layered on top of one another and assume conditional Gaussian distributions at different layers, while the architectural hierarchies [42, 20] instead leverage network architecture to place high-level represen-tations at the top layers of latent variables and low-level rep-resentations at the bottom layers. However, they typically assume conditional Gaussian distribution or isotropic Gaus-sian as the prior, which could have limited expressivity [26].
Learning a more expressive and informative prior model for multiple layers of latent variables is thus needed.
The energy-based models (EBMs) [19, 39, 7, 24, 26, 4], on the other hand, are shown to be expressive and proved to be powerful in capturing data regularities. Notably, [26] studies the EBM in the latent space, where the energy func-tion is considered as a correction of the non-informative prior and tilts the non-informative prior to a more expres-sive prior distribution. The low dimensionality of the latent space makes EBM more effective in capturing regularities in the data. However, prior methods often rely on expen-sive MCMC methods for posterior sampling of the latent variables, and more importantly, the latent variables are not hierarchically organized, making it difficult to capture data variations at different levels.
In this paper, we propose to combine the strengths of latent space EBM and the multi-layer generator model for effective hierarchical representation learning. In particular, we build the EBM on the latent variables across different layers of the generator model, where the latent variables at different layers are concatenated and modelled jointly. The latent variables at different layers capture different levels of information from the data via the hierarchy of the generative model, and their inter-relations are further tightened up and better captured through EBM in joint latent space.
Learning the EBM in the latent space can be challeng-ing since it usually requires MCMC sampling for both the prior and posterior distributions of the latent variables. The prior sampling is efficient with the low dimensionality of the latent space and the lightweight network of the energy function, while the MCMC sampling of posterior distribu-tion requires the backward propagation of generation net-work, which is usually heavy and thus renders inefficient inference. To ensure efficient inference, we introduce an inference model and develop a joint training scheme to ef-ficiently and effectively learn the latent space EBM and multi-layer generator model.
In particular, the inference model aims to approximate the exact posterior of the multi-layer latent variables while also serving to extract levels of data variations through the deep feed-forward inference net-work to facilitate hierarchical learning.
Contributions: 1) We propose the joint EBM prior model for hierarchical generator models with multiple layers of la-tent variables; 2) We develop a variational training scheme for efficient learning and inference; 3) We provide strong empirical results on hierarchical learning and image model-ing, as well as various ablation studies to illustrate the ef-fectiveness of the proposed model. 2.