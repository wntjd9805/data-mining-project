Abstract
High dynamic range (HDR) images capture much more intensity levels than standard ones. Current methods pre-dominantly generate HDR images from 8-bit low dynamic range (LDR) sRGB images that have been degraded by the camera processing pipeline. However, it becomes a formidable task to retrieve extremely high dynamic range scenes from such limited bit-depth data. Unlike existing methods, the core idea of this work is to incorporate more informative Raw sensor data to generate HDR images, aim-ing to recover scene information in hard regions (the dark-est and brightest areas of an HDR scene). To this end, we propose a model tailor-made for Raw images, harnessing the unique features of Raw data to facilitate the Raw-to-HDR mapping. Specifically, we learn exposure masks to separate the hard and easy regions of a high dynamic scene.
Then, we introduce two important guidances, dual inten-sity guidance, which guides less informative channels with more informative ones, and global spatial guidance, which extrapolates scene specifics over an extended spatial do-main. To verify our Raw-to-HDR approach, we collect a large Raw/HDR paired dataset for both training and test-ing. Our empirical evaluations validate the superiority of the proposed Raw-to-HDR reconstruction model, as well as our newly captured dataset in the experiments. 1.

Introduction
The dynamic range of real-world scenes often surpasses the recording capability of standard consumer camera sen-sors, leading images to lose details in both over- and under-exposed regions [6]. To endow today’s digital photos with the capacity to contain more scene information, the tech-nique called high dynamic range (HDR) that records data with a wide range of intensity levels has been extensively explored in the computational imaging community [45].
Compared with conventional low dynamic range (LDR) im-ages, HDR retains more details in over- and under-exposure
*Corresponding Author: fuying@bit.edu.cn
Dark (RGB)
Dark (Raw)
Dark (HDR)
Bright (RGB)
Bright (Raw)
Bright (HDR)
Figure 1: The RGB/Raw/HDR images of the darkest (first row) and brightest (second row) regions in a high dynamic scene. This paper is motivated by two observations: (1)
HDR scenes contain both extremely dark and bright re-gions, which are very challenging to reconstruct from a sin-gle image; (2) Raw images contain much more information in these hard regions, compared to low-bit RGB images. regions. Thus, HDR benefits downstream vision tasks including segmentation [33], object detection [36], and also provide more aesthetically appealing pictures [19, 25], which computer vision researchers have longly pursued.
Methods to obtain HDR data broadly fall into three cat-egories, i.e., reconstruction from multi-exposure, single-exposure images, and novel camera sensors. Among new sensors, some noteworthy examples include HDR cam-eras [34, 41], event cameras [18, 40, 44, 58], and infrared sensors [29]. Since these sensors are all specialized de-vices, more works focus on the reconstruction from multi-/single-exposures captured by commercial cameras, which are more practical and commercially friendly.
Historically, considering that single exposure cannot record the intensity information of a scene that covers a large dynamic range, researchers often combined multi-exposure images to generate HDR content [10,14,19,23,52, 53]. The quality of these images greatly depend on align-ing different exposures, and may suffer from ghosting effect caused by imperfect alignment.
To avoid the potential risk of alignment failure, more re-cent works incorporate only a single LDR image to recon-struct an HDR image [9, 13, 30, 50]. Nonetheless, single-image HDR reconstruction is more challenging due to the physical limitation of consumer camera’s dynamic range.
Consequently, under-exposed regions are often noisy [7, 8, 16, 54], while over-exposed regions are difficult to re-cover [2, 22]. Most previous works utilize low-bit sRGB images for HDR reconstruction. However, sRGB images have been degraded by lossy in-camera operations, which is not enough to record details in an HDR scene. Even as innovative and interpretable deep models emerge [13, 30], the HDR reconstructions from single LDR images often fal-ter in highly dynamic scenes due to the inherent paucity of low-bit sRGB input.
In this work, we aim to relieve the information limita-tion for single-exposure setting with a specialized recon-struction model and high-quality dataset. Using a single image, the challenge comes down to the recovery of the darkest and brightest regions (hard regions) in high dy-namic scenes. The visualization in Figure 1 shows that commonly used sRGB images contain limited information in hard regions. Raw images retain more details than sRGB, but are still far from HDR. Therefore, we propose using un-processed Raw sensor data, which has higher available bit-depth and better intensity tolerance, thus can circumvent the long-standing drawback of insufficient scene information.
To perform specific operations on hard regions, we learn an exposure mask to adaptively separate the over-/under-and well-illuminated regions for each scene. We also de-vise a deep neural network specially designed for Raw in-put images to exploit the information in hard regions. Cru-cially, we propose a dual intensity guidance based on the channel-variant attribute of Raw images to guide less infor-mative image channels and global spatial guidance to well exploit longer-range information. Finally, we collect a high-quality Raw/HDR paired dataset for both training and test-ing. The quality of our Raw-to-HDR reconstruction meth-ods and dataset are verified in the experiments.
Our main contributions can be summarized as follows: 1. We focus on the essential issue of HDR imaging — the challenge in recovering the dark and bright regions, for which we propose to learn an exposure mask to separate the image into hard and easy regions. 2. We propose a deep network to deal with the hard re-gions, including a dual intensity guidance built on the channel-variant attribute of Raw images and a global spatial guidance built on transformer with spatial at-tention that exploits information from a longer range. 3. We directly reconstruct HDR from a single Raw im-age, which is endowed with higher bit-depth to handle high dynamic scenes and can be potentially integrated into modern camera processing pipelines. In addition, we collect a high-quality paired Raw/HDR dataset for training and evaluation. 2.