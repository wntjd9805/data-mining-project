Abstract
We propose DiffusionDet, a new framework that for-mulates object detection as a denoising diffusion process from noisy boxes to object boxes. During the training stage, object boxes diffuse from ground-truth boxes to ran-dom distribution, and the model learns to reverse this nois-ing process.
In inference, the model refines a set of ran-domly generated boxes to the output results in a progressive way. Our work possesses an appealing property of flexibil-ity, which enables the dynamic number of boxes and itera-tive evaluation. The extensive experiments on the standard benchmarks show that DiffusionDet achieves favorable per-formance compared to previous well-established detectors.
For example, DiffusionDet achieves 5.3 AP and 4.8 AP gains when evaluated with more boxes and iteration steps, under a zero-shot transfer setting from COCO to CrowdHu-man. Our code is available at https://github.com/
ShoufaChen/DiffusionDet. 1.

Introduction
Object detection aims to predict a set of bounding boxes and associated category labels for targeted objects in one image. As a fundamental visual recognition task, it has become the cornerstone of many related recognition sce-narios, such as instance segmentation [36, 53], pose esti-mation [9, 22], action recognition [32, 81], object track-ing [46, 65], and visual relationship detection [45, 62].
Modern object detection approaches have been evolv-ing with the development of object candidates, i.e., from empirical object priors [27, 59, 72, 74] to learnable object queries [10,90,114]). Specifically, the majority of detectors solve detection tasks by defining surrogate regression and classification on empirically designed object candidates, such as sliding windows [28, 79], region proposals [27, 74], anchor boxes [56, 72] and reference points [19, 105, 112].
Recently, DETR [10] proposes learnable object queries to eliminate the hand-designed components and set up an end-to-end detection pipeline, attracting great attention on
Figure 1. Diffusion model for object detection. (a) A diffusion model where q is the diffusion process and pθ is the reverse pro-cess. (b) Diffusion model for image generation task. (c) We pro-pose to formulate object detection as a denoising diffusion process from noisy boxes to object boxes. query-based detection paradigm [23, 51, 90, 114].
While these works achieve a simple and effective de-sign, they still have a dependency on a fixed set of learnable queries. A natural question is: is there a simpler approach that does not even need the surrogate of learnable queries?
We answer this question by designing a novel framework that directly detects objects from a set of random boxes.
Starting from purely random boxes, which do not contain learnable parameters that need to be optimized in the train-ing stage, we expect to gradually refine the positions and sizes of these boxes until they perfectly cover the targeted objects. This noise-to-box approach requires neither heuris-tic object priors nor learnable queries, further simplifying the object candidates and pushing the development of the detection pipeline forward.
Our motivation is illustrated in Figure 1. We think of the philosophy of noise-to-box paradigm is analogous to noise-to-image process in the denoising diffusion mod-els [16, 38, 88], which are a class of likelihood-based mod-els to generate the image by gradually removing noise from an image via the learned denoising model. Diffu-sion models have achieved great success in many generation tasks [3, 4, 40, 71, 94] and start to be explored in perception tasks like image segmentation [1, 5, 6, 13, 31, 47, 97]. How-# Boxes 300 500 1000 2000
DETR [10]
Sparse R-CNN [90] 66.6 66.5 (-0.1)
DiffusionDet 61.3 61.3 (+0.0) 61.3 (+0.0) 61.3 (+0.0) 66.5 (-0.1) 66.6 69.0 (+2.4) 71.0 (+4.4) 71.9 (+5.3) 66.5 (-0.1) (a) Dynamic number of evaluation boxes.
# Steps 1 2 3 4
DETR [10] 62.7 (+1.4)
Sparse R-CNN [90] 66.6 60.6 (-6.0) 55.5 (-11.1) 52.6 (-14.0) 71.4 (+4.8)
DiffusionDet 66.6 69.7 (+3.1) 61.3 62.5 (+1.2) 70.8 (+4.2) 62.7 (+1.4) (b) Dynamic number of evaluation steps.
Table 1. Zero-shot transfer from COCO to CrowdHuman vis-ible box detection. All models are trained with 300 boxes and tested with different number of boxes and steps. ever, to the best of our knowledge, there is no prior art that successfully adopts it to object detection.
In this work, we propose DiffusionDet, which tackles the object detection task with a diffusion model by casting detection as a generative task over the space of the posi-tions (center coordinates) and sizes (widths and heights) of bounding boxes in the image. At the training stage, Gaus-sian noise controlled by a variance schedule [38] is added to ground truth boxes to obtain noisy boxes. Then these noisy boxes are used to crop [36, 74] features of Region of
Interest (RoI) from the output feature map of the backbone encoder, e.g., ResNet [37], Swin Transformer [60]. Finally, these RoI features are sent to the detection decoder, which is trained to predict the ground-truth boxes without noise.
With this training objective, DiffusionDet is able to predict the ground truth boxes from random boxes. At the inference stage, DiffusionDet generates bounding boxes by reversing the learned diffusion process, which adjusts a noisy prior distribution to the learned distribution over bounding boxes.
As a probabilistic model, DiffusionDet has an attractive superiority of flexibility, i.e., we can train the network once and use the same network parameters under diverse settings in the inference stage, mainly including: (1) Dynamic num-ber of boxes. Leveraging random boxes as object candi-dates, we decouple the training and evaluation stage of Dif-fusionDet, i.e., we can train DiffusionDet with Ntrain ran-dom boxes while evaluating it with Neval random boxes, where the Neval is arbitrary and does not need to be equal to Ntrain. (2) Iterative evaluation. Benefited by the iter-ative denoising property of diffusion models, DiffusionDet can reuse the whole detection head in an iterative way, fur-ther improving its performance.
The flexibility of DiffusionDet makes it a great advan-tage in detecting objects across different scenarios, e.g., sparse or crowded, without additional fine-tuning. Specifi-cally, Table 1 shows that when directly evaluating COCO-pretraiend models on CrowdHuman [80] dataset, which covers more crowed scenes, DiffusionDet achieves signif-icant gains by adjusting the number of evaluation boxes and iteration steps. In contrast, previous methods only obtain marginal gains or even degraded performance. More de-tailed discussions are left in Section 4.
Besides, we evaluate DiffusionDet on COCO [57] dataset. With ResNet-50 [37] backbone, DiffusionDet achieves 45.8 AP using a single sampling step and 300 random boxes, which significantly outperforms Faster R-CNN [74] (40.2 AP), DETR [10] (42.0 AP) and on par with
Sparse R-CNN [90] (45.0 AP). Besides, we can further im-prove DiffusionDet up to 46.8 AP by increasing the number of sampling steps and random boxes.
Our contributions are summarized as follows:
• We formulate object detection as a generative denoising process, which is the first study to apply the diffusion model to object detection to the best of our knowledge.
• Our noise-to-box detection paradigm has several appeal-ing properties, such as decoupling training and evaluation stage for dynamic boxes and iterative evaluation.
• We conduct extensive experiments on COCO, Crowd-Human, and LVIS benchmarks. DiffusionDet achieves favorable performance against previous well-established detectors, especially zero-shot transferring across differ-ent scenarios. 2.