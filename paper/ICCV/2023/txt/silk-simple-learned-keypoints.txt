Abstract
Keypoint detection & descriptors are foundational tech-nologies for computer vision tasks like image matching, 3D reconstruction and visual odometry. Hand-engineered methods like Harris corners, SIFT, and HOG descriptors have been used for decades; more recently, there has been a trend to introduce learning in an attempt to improve key-point detectors. On inspection however, the results are dif-ficult to interpret; recent learning-based methods employ a vast diversity of experimental setups and design choices: empirical results are often reported using different back-bones, protocols, datasets, types of supervisions or tasks.
Since these differences are often coupled together, it raises a natural question on what makes a good learned keypoint de-tector. In this work, we revisit the design of existing keypoint detectors by deconstructing their methodologies and iden-tifying the key components. We re-design each component from first-principle and propose Simple Learned Keypoints (SiLK) that is fully-differentiable, lightweight, and flexi-ble. Despite its simplicity, SiLK advances new state-of-the-art on Detection Repeatability and Homography Estimation tasks on HPatches and 3D Point-Cloud Registration task on
ScanNet, and achieves competitive performance to state-of-the-art on camera pose estimation in 2022 Image Matching
Challenge and ScanNet. 1.

Introduction
Keypoint detection and matching is a foundational com-puter vision technique to obtain a sparse yet informa-tive representation of an image.
Image stitching [7, 1], track-SLAM [14, 34], SfM [44], camera calibrations, ing [37], and object detection [30] are important tasks built on keypoint correspondences [32]. A good keypoint model should be able to select a subset of points useful and infor-mative to a specific task. One typically also wants robust-ness of the descriptor to some set of transformations (e.g. scale, viewpoint, or lighting variation).
Figure 1. The top image is an example of keypoint matching un-der viewpoint change; correct matches are green, incorrect ones are red. The bottom image shows keypoints which are cycle-consistent by SiLK. As can be observed, SiLK has learned to find distinctive geometric features (corners, curves, intersections,..); from single non-annotated images.
Existing keypoint methods come in multiple forms and flavors (Tab. 1). However, those differences are often cou-pled together and not controlled for, which make it chal-lenging to identify the source of gain. Our quest to find-ing the key-components of good keypoint detectors led to an in-depth review of alternative approaches, as well as the design, from first principle, of SiLK (Simple Learned
Keypoints) : A simple self-supervised approach to learn
distinctive and robust keypoints from arbitrary image data in a traditional “detect-and-describe” framework. Despite its simplicity, SiLK is competitive or surpasses SOTA in most settings.
Additionally, leveraging SiLK’s simple one-stage train-ing protocol and modular architecture, we are able to ab-late various dimensions of detector performance for differ-ent tasks. In particular, with an eye toward real-time per-formance, we identify tasks where extremely lightweight backbone architectures are sufficient. 2.