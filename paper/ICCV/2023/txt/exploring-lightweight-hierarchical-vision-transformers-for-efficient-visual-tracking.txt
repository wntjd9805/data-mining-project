Abstract
Transformer-based visual trackers have demonstrated signiﬁcant progress owing to their superior modeling ca-pabilities. However, existing trackers are hampered by low speed, limiting their applicability on devices with limited computational power. To alleviate this problem, we propose
HiT, a new family of efﬁcient tracking models that can run at high speed on different devices while retaining high per-formance. The central idea of HiT is the Bridge Module, which bridges the gap between modern lightweight trans-formers and the tracking framework. The Bridge Module in-corporates the high-level information of deep features into the shallow large-resolution features. In this way, it pro-duces better features for the tracking head. We also pro-pose a novel dual-image position encoding technique that simultaneously encodes the position information of both the search region and template images. The HiT model achieves promising speed with competitive performance.
For instance, it runs at 61 frames per second (fps) on the
Nvidia Jetson AGX edge device. Furthermore, HiT attains 64.6% AUC on the LaSOT benchmark, surpassing all pre-vious efﬁcient trackers. Code and models are available at https://github.com/kangben258/HiT. 1.

Introduction
Visual object tracking is a fundamental task in com-puter vision, which aims to track an arbitrary object given its initial state in a video sequence. In recent years, with the development of deep neural networks [25, 20, 39, 42],
In particular, the tracking has made signiﬁcant progress. utilization of transformers [42] has played a pivotal role in the development of several high-performance track-ers [8, 50, 43, 53, 10, 52, 7]. Unfortunately, much of the research [27, 2, 8] has concentrated solely on achiev-ing high performance without considering tracking speed.
∗ Equal contribution.
† Corresponding authors: Dong Wang (wdice@dlut.edu.cn), Houwen
Peng (houwen.peng@microsoft.com). 4.7(cid:28772) faster
Non-real-time
Real-time
Figure 1: Comparison of our HiT with other trackers on La-SOT in terms of speed (horizontal axis) on the edge AI plat-form of Nvidia Jetson AGX Xavier and success rate (AUC) (vertical axis). Following the VOT real-time setting [23], we set the real-time line at 20 fps. Our HiT achieves the best real-time result, surpassing other efﬁcient trackers.
While these trackers may achieve real-time speed on pow-erful GPUs, they lack competitiveness and advantages on resource-limited devices. For instance, TransT [8], which is a high-performance tracker, only achieves a speed of 5 frames per second (fps) on the Intel Core i9-9900K CPU and 13 fps on the Nvidia Jetson AGX. Consequently, a high-performance tracker with fast speed is critical.
The one-stream structure has gained popularity in track-ing applications [52, 5, 48, 10]. This structure performs feature extraction and feature fusion jointly, leveraging the capabilities of the backbone network [14] that has been pre-trained for image classiﬁcation. In our work, we also adopt the one-stream architecture, leveraging a pre-trained lightweight transformer backbone network. However, there exists a substantial gap between the tracking ﬁeld and the image classiﬁcation ﬁeld. In the image classiﬁcation ﬁeld, lightweight networks [18, 33, 47] frequently incorporate a hierarchical architecture with high-stride downsampling to decrease computational expenses. However, large-stride downsampling often leads to a loss of critical information,
which is crucial for accurate tracking. This naturally raises the question of how to reconcile the need for detailed infor-mation in tracking with the large-stride downsampling in the hierarchical backbone network.
To tackle this problem, we introduce the Bridge Module, which integrates features from different levels of the hier-archical backbone. The Bridge Module fuses deep seman-tic information with shallow detail information, mitigating the information loss resulting from large-stride downsam-pling. By combining the proposed Bridge Module with lightweight hierarchical backbone LeViT [18], we develop
HiT, a new family of efﬁcient tracking models. Moreover, we proposed a novel relative position encoding technique, called dual-image position encoding, to improve the posi-tion information. This method encodes the position infor-mation of the template and search region jointly, enhancing the interaction between them.
Our extensive experiments validate the effectiveness and efﬁciency of HiT. Speciﬁcally, compared to the high-speed tracker FEAR [28], HiT-Base achieves an 11.1% higher
AUC score on the LaSOT benchmark while being 1.6 times faster than FEAR on Nvidia Jetson AGX Xavier. In com-parison to the high-performance tracker STARK-ST50 [50],
HiT-Base delivers similar performance while being 4.7 times faster on AGX, representing a signiﬁcant improve-ment over previous real-time trackers. Our main contribu-tions are summarized as follows:
• We propose the Bridge Module, which incorporates the high-level information of deep features into the shallow large-resolution features, thereby mitigating the infor-mation loss caused by the large-stride downsampling.
This approach enables the use of large-stride downsam-pling hierarchical backbones for tracking purposes.
• To improve position accuracy, we introduce a dual-image position encoding approach that jointly encodes position information from both the template and the search region.
• Building upon these components, we introduce HiT, a family of efﬁcient tracking models. HiT exhibits promising performance while maintaining exceptionally fast processing speeds. Empirical evaluations demon-strate that HiT outperforms state-of-the-art efﬁcient tracking algorithms. 2.