Abstract
The accuracy of learning-based optical flow estimation models heavily relies on the realism of the training datasets.
Current approaches for generating such datasets either em-ploy synthetic data or generate images with limited real-ism. However, the domain gap of these data with real-world scenes constrains the generalization of the trained model to real-world applications. To address this issue, we inves-tigate generating realistic optical flow datasets from real-world images. Firstly, to generate highly realistic new im-ages, we construct a layered depth representation, known as multiplane images (MPI), from single-view images. This allows us to generate novel view images that are highly re-alistic. To generate optical flow maps that correspond ac-curately to the new image, we calculate the optical flows of each plane using the camera matrix and plane depths. We then project these layered optical flows into the output op-tical flow map with volume rendering. Secondly, to ensure the realism of motion, we present an independent object mo-tion module that can separate the camera and dynamic ob-ject motion in MPI. This module addresses the deficiency in MPI-based single-view methods, where optical flow is generated only by camera motion and does not account for any object movement. We additionally devise a depth-aware inpainting module to merge new images with dy-namic objects and address unnatural motion occlusions. We show the superior performance of our method through ex-tensive experiments on real-world datasets. Moreover, our approach achieves state-of-the-art performance in both un-supervised and supervised training of learning-based mod-els. The code will be made publicly available at: https:
//github.com/Sharpiless/MPI-Flow. 1.

Introduction
Optical flow refers to the precise calculation of per-pixel motion between consecutive video frames.
Its applica-tions span a wide range of fields, including object tracking
[10, 51], robot navigation [23, 41], three-dimensional (3D)
*Corresponding Author: fuying@bit.edu.cn (a) Depthstill. [1] (b) RealFlow [12] (c) Ours (d) Source image and details of generated flows from our method
Figure 1: Visual comparison of images reveals that our method, when compared with those based on real-world images [1, 12], demonstrates superior image realism. Our method also achieves fine optical flows by employing vol-ume rendering in MPI and separate motions of the camera and object with the independent object motion module. reconstruction [24, 14], and visual simultaneous localiza-tion and mapping (SLAM) [52, 8, 29]. In recent years, with the rapid development of neural networks, learning-based methods [44, 45] have demonstrated significant advances compared to traditional model-based algorithms [3, 49, 50].
Conventional practices primarily rely on synthetic data, as demonstrated by [9, 18, 4]. Synthetic data contains exact optical flow labels and animated images. However, the do-main gap between synthetic and real data hinders its further improvements in real-world applications.
Recent studies have aimed to extract optical flow from real-world data by employing hand-made special hardware
[2, 11, 34]. However, the rigidly controlled and inefficient collection procedure limits their applicability. To address this issue, Depthstillation [1], and RealFlow [12] have been proposed, which project each pixel in the real-world image onto the novel view frame with the help of random motions
of virtual cameras or estimated flows. Nonetheless, both methods are limited by the lack of image realism, leading to issues such as collisions, holes, and artifacts, as illustrated in Figure 1. These limitations constrain the real-world per-formance of learning-based optical flow models [44, 45].
To achieve higher image realism, we turn our atten-tion to the use of single-view Multiplane Images (MPI)
[53, 47, 54, 6, 13]. This line of work demonstrates re-markable single-view image rendering capabilities and ef-fectively reduces collisions, holes, and artifacts commonly found in previous methods [1, 12]. These advancements contribute to higher image realism, prompting a natural question: Can high-realistic MPI methods be adapted to generate high-quality optical flow datasets for training pur-poses?
To this end, we propose MPI-Flow, aiming to gener-ate realistic optical flow datasets from real-world images.
Specifically, we first review the image synthesis pipeline of
MPI and devise an optical flow generation pipeline along with image synthesis.
In this step, we build an MPI by warping single-view image features onto each layered plane with the predicted color and density. The color and density then be mapped into a realistic new image via volume ren-dering. With the layered planes, we extract optical flows with virtual camera motions from the rendered image and the real image. Second, as the MPI can only be applied in static scenes, which yield limited motion realism, we propose an independent object motion module and a depth-aware inpainting module to tackle this issue. The indepen-dent object motion module decouples dynamic objects from static scenes and applies different virtual camera matrices to calculate the motion of both dynamic and static parts. The depth-aware inpainting module is introduced to remove the object occlusion in the synthesized new image.
With MPI-Flow, a large number of single-view images can be used to generate large-scale training datasets with realistic images and motions. This enables learning-based optical flow models better generalization to a wide range of real-world scenes. Extensive experiments on real datasets demonstrate the effectiveness of our approach. In summary, our main contributions are as follows:
• We are the first to present a novel MPI-based optical flow dataset generation framework, namely MPI-Flow, which can significantly improve the realism of the gen-erated images and motion.
• We present a novel independent object motion mod-ule for modeling dynamic objects in MPI, which can model realistic optical flow from camera motion and object motion simultaneously.
• We design a depth-aware inpainting module for realis-tic image inpainting, which can remove unnatural mo-tion occlusions in generated images. 2.