Abstract
Weather degraded conditions such as rain, haze, snow, etc. may degrade the performance of most computer vi-sion systems. Therefore, effective restoration of multi-weather degraded images is an essential prerequisite for successful functioning of such systems. The current multi-weather image restoration approaches utilize a model that is trained on a combined dataset consisting of individ-ual images for rainy, snowy, and hazy weather degrada-tions. These methods may face challenges when deal-ing with real-world situations where the images may have multiple, more intricate weather conditions. To address this issue, we propose a domain translation-based uni-In this fied method for multi-weather image restoration. approach, the proposed network learns multiple weather degradations simultaneously, making it immune for real-world conditions. Specifically, we first propose an instance-level domain (weather) translation with multi-attentive fea-ture learning approach to get different weather-degraded variants of the same scenario. Next, the original and translated images are used as input to the proposed novel multi-weather restoration network which utilizes a progres-sive multi-domain deformable alignment (PMDA) with cas-caded multi-head attention (CMA). The proposed PMDA fa-cilitates the restoration network to learn weather-invariant clues effectively. Further, PMDA and respective decoder features are merged via proposed CMA module for restora-tion. Extensive experimental results on synthetic and real-world hazy, rainy, and snowy image databases clearly demonstrate that our model outperforms the state-of-the-art multi-weather image restoration methods. Code is avail-able at https://github.com/pwp1208/Domain_
Translation_Multi-weather_Restoration. 1.

Introduction
Fog, snow, rain, haze or their combintations often de-grade the quality of images recorded for computer vision applications such as surveillance, traffic monitoring, and autonomous driving. These applications routinely involve sub-tasks such as optical flow estimation [36], object detec-Figure 1. Upper-part: Thumbnail of the proposed domain transla-tion based multi-weather image restoration approach. Lower-part:
Sample restoration results: (a) de-hazing, (b) de-raining with veil-ing effect, and (c) de-snowing with veiling effect. tion [8], depth estimation [27], etc., which use algorithms or models expecting clean image as their input. Therefore, restoration of images degraded by one or many weather conditions is an important problem.
Although remarkable success has been achieved in restoration of particular domain such as image de-hazing, image de-raining, and image de-snowing, multi-weather de-graded image restoration is still an open problem. Existing works handle multiple weather degradations via separate weather specific encoders [15], or separate training for each weather [1]. To handle multiple degradations with sepa-rate training-based models, typically these weather-specific models are put in a cascade, e.g., haze removal followed by rain removal. But, such an approach may produce un-desirable results as the erroneous output of any one of the earlier stages affects the overall result in an unpredictable manner. Also, in order to select the appropriate restora-tion model, prior information about the degradation must be available. To overcome these limitations, researchers intro-duced various unified (single trainable parameters) models based on knowledge distillation [4], transformer [33], con-trastive degradation guidance [12] and degradation removel with feature corrector [11] for multi-weather image restora-tion. These models are trained using a combined dataset that contains individual degraded images representing rainy, snowy, and hazy weather, etc. As real-world scenario may have more intricate weather conditions, which limits the performance of [4], [33], [11], [12] methods. Therefore, the restoration architecture should be able to perform sig-nificantly for any weather degradation.
To address the above challenges, we propose multi-weather image restoration framework where we first cre-ate different weather degradations of a degraded image and use them to learn a set of features that jointly represent all the degraded images. Since the common part across di-verse weather degraded images is the clean image (i.e., ev-erything except weather degradations), our feature extrac-tor learns to suppress the weather specific information and thus learns weather-invariant features. A practical advan-tage of this learning scheme is that our feature extractor can be also used for real data even though it is trained using synthetic data. This is because the synthetic and real-world images mainly differ in the weather-degradations, and since our feature extractor learns to suppress it, it can close the domain gap between synthetic and real-world data.
Following this idea, we propose a domain translation based unified approach for multi-weather image restoration.
In order to achieve this, we first used a domain transla-tion approach, where any of the degraded image can be translated to specific domain (e.g., hazy, rain with veil, snow with veil). We then propose a restoration architecture which takes domain translated and original degraded im-ages as input to generate degradation free output. The pro-posed restoration network comprises of two components: namely a progressive multi-domain deformable alignment (PMDA) and cascaded multi-head attention (CMA) blocks.
PMDA module perform inter domain offset feature align-ment which facilitates the restoration network to learn weather-invariant representation effectively. Further, the
CMA block is proposed to aggregate the respective PMDA and decoder features for effective restoration. Our main contributions are:
• A novel unified architecture for multi-weather image restoration. It utilizes a single trainable model to re-store all weather degradations.
• A domain-translation with multi-attentive feature learning to achieve unified model’s generalizability.
• A progressive multi-domain deformable alignment and cascaded multi-head attention modules for multi-weather image restoration.
Extensive experimental analysis on various weather-degraded synthetic and real-world datasets demonstrate that the proposed multi-weather restoration framework outper-forms the existing state-of-the-art (SOTA) methods. An overview and sample results of the proposed method for real-world images are given in Figure 1. 2.