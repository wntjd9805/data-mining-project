Abstract
In this paper, we present a Hybrid Spectral Denois-ing Transformer (HSDT) for hyperspectral image denois-ing. Challenges in adapting transformer for HSI arise from the capabilities to tackle existing limitations of CNN-based methods in capturing the global and local spatial-spectral correlations while maintaining efficiency and flexibility. To address these issues, we introduce a hybrid approach that combines the advantages of both models with a Spatial-Spectral Separable Convolution (S3Conv), Guided Spectral
Self-Attention (GSSA), and Self-Modulated Feed-Forward
Network (SM-FFN). Our S3Conv works as a lightweight al-ternative to 3D convolution, which extracts more spatial-spectral correlated features while keeping the flexibility to tackle HSIs with an arbitrary number of bands. These fea-tures are then adaptively processed by GSSA which per-forms 3D self-attention across the spectral bands, guided by a set of learnable queries that encode the spectral sig-natures. This not only enriches our model with power-ful capabilities for identifying global spectral correlations but also maintains linear complexity. Moreover, our SM-FFN proposes the self-modulation that intensifies the acti-vations of more informative regions, which further strength-ens the aggregated features. Extensive experiments are con-ducted on various datasets under both simulated and real-world noise, and it shows that our HSDT significantly out-performs the existing state-of-the-art methods while main-taining low computational overhead. Code is at https:
//github.com/Zeqiang-Lai/HSDT. 1.

Introduction
Hyperspectral image (HSI) provides substantially more abundant spectral information than the ordinary color im-age, which makes it especially utilitarian in the field of re-mote sensing [3, 4], biometric authentication [54], detection
[41], and geological science [17, 51]. Nevertheless, lim-† Corresponding Author.
Figure 1: Our method achieves state-of-the-art performance while maintaining low computational overhead. ited by imaging techniques, most existing HSI cameras still suffer from various types of noise that might degrade the performance of their applications, which urges the develop-ment of robust HSI denoising algorithms.
Motivated by the intrinsic properties of HSI, traditional
HSI denoising approaches [63, 20] often exploit the opti-mization schemes with priors, e.g., low rankness [67, 58], non-local similarities [40, 42], spatial-spectral correlation
[47], and global correlation along the spectrum [59]. Whilst the efficacy of these offering appreciable performance, methods is largely dependent on the degree of similarity between the handcrafted priors and the real-world noise model, and these methods are often challenging to acceler-ate with modern hardwares due to the complex processing pipelines. Recent HSI denoising methods based on Convo-lutional Neural Network (CNN) [64, 32, 5] get rid of hand-crafted regularizations with learning-based prior and often run faster with graphic accelerators and machine-learning frameworks [45]. However, these methods are still insuf-ficient for exploring the characteristics of HSI, e.g., global and local spectral-spatial correlations. For example, HSID-CNN [64] only considers the correlations between several adjacent spectral bands. QRNN3D [59] and GRUNet [32] model the global spectral correlations with quasi-recurrent units [6] but suffer from the problem of vanished corre-lations for long-range separate bands due to the recurrent multiplications of merging weights. Besides, recent meth-ods [59, 66] tend to use 3D convolution to explore the local spectral-spatial correlations while maintaining the flexibil-ity to handle different HSIs. This strategy, however, intro-duces substantially unwanted computation and parameters.
Starting from natural language processing [55], trans-former architectures [16, 2] have recently been applied to various vision tasks including color image restoration
[37, 65] and HSI processing [34, 7, 44]. With the multi-head self-attention of transformer, these methods enjoy stronger capabilities of capturing non-local similarity and long-range dependency over aforementioned CNN-based methods. De-spite of that, they are still suboptimal and inflexible for di-verse HSIs. On the one hand, existing attentions for HSIs apply along either spatial [34, 44] or 2D feature channel
[34, 7] dimensions, which could introduce quadratic com-plexities or break down the structured spectral dependency.
On the other hand, their 2D architectural designs also make their models specifically bound to one type of HSI, e.g., HSI with 31 bands, and separate models have to be trained for other types, e.g., HSI with 210 bands. This can be problem-atic since the amount of available datasets is unevenly dis-tributed for different HSIs. Finally, HSIs often exhibit ben-eficial fixed structures, e.g., relative intensity correlations of different bands for objects. Direct transfer of existing trans-former blocks without considering this fact might lead to suboptimal performance for HSI denoising.
In this paper, we propose a novel Hybrid Spectral De-noising Transformer (HSDT) that effectively integrates the local spectral-spatial inductive bias of the convolution and the long-range spectral dependency modeling ability of the transformer. Unlike previous HSI transformers [34, 7, 44],
HSDT is designed to be effective and flexible for handling diverse HSIs in a single model, which results in a vari-ety of benefits, e.g., the ability to jointly utilize HSIs with different numbers of bands for more sufficient training in data-insufficiency scenarios. To achieve it, (a) we first in-troduce a parallel Spectral-Spatial Separable Convolution (S3Conv) unit that efficiently extracts more spatial-spectral meaningful features than previous 3D [59] and separable (b) With the stronger local spectral-convolutions [15]. spatial inductive bias, the extracted features are then pro-cessed by a newly proposed Guided Spectral Self-Attention (GSSA) that performs the global self-attention along the 3D spectral rather than spatial [44] or 2D spectral/channel di-mensions [34, 7] to selectively aggregate the information across different bands. This not only enriches our model with powerful capabilities for identifying long-range spec-tral correlations but also makes our model free of inflex-ibility of 2D spectral SA for dealing with different HSIs, quadratic complexity of spatial SA [16], and the issue of vanished long-range dependency of QRNN [59]. (c) Be-sides, inspired the relatively stationary global patterns and statistics of features of different HSI bands, as shown in
Fig. 2, we propose to enhance our GSSA with a set of learn-able queries that encode the global spectral statistics for
Figure 2: Visualization of feature maps of different bands by performing global average pooling on spatial locations.
It can be observed that despite the difference of images, the pooled feature maps of clean and noisy images share differ-ent common patterns, which might be helpful for identify-ing, e.g., cleaner bands, for denoising noisy bands. each band. We alternatively switch between self-attention among spectral bands and cross-attention between spec-tral bands and learnable queries during the training, so that we can guide the GSSA to pay attention to features that are more discriminative and beneficial for denoising while keeping the flexibility. (d) Moreover, we propose a Self-Modulated Feed-Forward Network (SM-FFN) with a novel
SM-branch to further strengthen the aggregated features of more informative regions. Extensive experiments on vari-ous datasets under different noise show that our HSDT con-sistently outperforms the existing state-of-the-art (SOTA) methods while maintaining low computational overhead, as shown in Fig. 1.
In summary, our contributions are that,
• We present HSDT, a 3D hybrid spectral denoising trans-former that effectively captures the local spatial-spectral features and long-range global spectral correlations.
• We introduce GSSA guided by a set of learnable queries that encode the global statistics of HSIs, which models long-range spectral correlations along 3D spectrum in-stead of previous 2D spectral/channel dimensions.
• We propose SM-FFN with a novel self-modulated branch for driving the model to pay attention to more informa-tive regions, along with a S3Conv for extracting spatial-spectral meaningful features. 2.