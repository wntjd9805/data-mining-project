Abstract
Whole slide image (WSI) analysis has become increas-ingly important in the medical imaging community, en-abling automated and objective diagnosis, prognosis, and therapeutic-response prediction. However, in clinical prac-tice, the ever-evolving environment hamper the utility of
WSI analysis models. In this paper, we propose the FIRST continual learning framework for WSI analysis, named
ConSlide, to tackle the challenges of enormous image size, utilization of hierarchical structure, and catastrophic for-getting by progressive model updating on multiple sequen-tial datasets. Our framework contains three key compo-nents. The Hierarchical Interaction Transformer (HIT) is proposed to model and utilize the hierarchical structural knowledge of WSI. The Breakup-Reorganize (BuRo) re-hearsal method is developed for WSI data replay with ef-ficient region storing buffer and WSI reorganizing opera-tion. The asynchronous updating mechanism is devised to encourage the network to learn generic and specific knowl-edge respectively during the replay stage, based on a nested cross-scale similarity learning (CSSL) module. We eval-uated the proposed ConSlide on four public WSI datasets from TCGA projects. It performs best over other state-of-the-art methods with a fair WSI-based continual learning setting and achieves a better trade-off of the overall perfor-mance and forgetting on previous tasks. 1.

Introduction
Whole slide images (WSIs) contain rich histopatholog-ical information of the tissue sections and are routinely
*These authors contributed equally to this work.
â€ Corresponding Author.
Figure 1. Illustration of concept and challenges of continual WSI analysis. (a) Continual WSI learning aims to alleviate catastrophic forgetting while exploiting knowledge from sequentially incom-ing datasets from the different tasks/domains. (b) The hierarchical structure of WSIs raises challenges for network architecture and learning strategy design. used for clinical practice. With recent advances in deep learning, computational WSI have attracted widespread at-tention in the medical image analysis community, which can provide automated and objective diagnosis, prognosis, and therapeutic-response prediction [18, 46, 57, 60]. How-ever, the huge size and expensive pixel-level annotations of
WSI bring computational challenges in deep model archi-tecture design [47, 28, 31]. Therefore, multiple instance learning (MIL)-based approaches are proposed for weakly-supervised WSI analysis [13, 46, 59], where they first divide
WSI into a set of patches, conduct analysis for each patch, and then aggregate them together for slide-level prediction.
Although encouraging results are achieved, these ap-proaches typically adopt the static model learning set-ting [40, 57, 65, 17, 66, 26]. However, the WSI imaging technology and staining protocols are not static [58], which constrains the model performance in new data, and they are subject to an ever-evolving environment in which WSI analysis methods have to adapt in order to remain effec-tiveness [37, 53, 61, 21, 32]. Although retrain the model every time new data are available is a intuitive solution, but this process can incur high computational and storage costs, especially for WSIs with huge size, while the num-ber of WSIs for different tasks is growing fast [6]. An-other candidate solution is to train a new model for each new dataset. However, it may be difficult to collect enough data to train a model for each domain (e.g., different stain of
WSIs). Fine-tuning the pre-trained model on the newly ar-rived datasets is also a candidate solution. However, during the fine-tuning process, the network is prone to concentrate too much on adapting to the feature domain of the current dataset and disrupting the knowledge acquired from previ-ous datasets, which leads to bad performance on previous datasets. This phenomenon is referred as catastrophic for-getting [9, 19, 39].
Continual Learning (CL) was recently proposed [45, 19] to overcome the limitations of static model learning and alleviate catastrophic forgetting. The aim of CL is to train models with adaptability when meeting datasets from new tasks without catastrophically forgetting the knowledge learned from previous tasks, which can make deep learn-ing models much more versatile to the constant growth of medical datasets. CL has received much attention in recent years, and it can be achieved either by parameter regulariza-tion [34, 56, 36], knowledge distillation [42, 24, 8], apposite architecture design [44, 54, 23], or by data rehearsal-based strategies [55, 11, 14]. Among these strategies, rehearsal-based methods achieved good performance by replaying a subset of the training data stored in a memory buffer. How-ever, the characteristics of WSI pose unique challenges for designing continual WSI analysis frameworks and we are not aware of such frameworks in the existing literature.
WSIs are usually stored at different resolutions, resulting in a hierarchical structure with containing different patho-logical information, as shown in Figure 1 (b). For exam-ple, patch-level images encompass find-grained cells and tumor cellularity information [25, 51, 3]. Region-level images mainly characterize the tissue information, such as the extent of tumor-immune localization [1, 17, 10], while slide-level images depict the overall intra-tumoral features [5, 30, 48]. Modeling and utilizing this hierarchi-cal characteristic of WSI is critical for accurate WSI anal-ysis [27, 52], while it is quite challenging to handle this hierarchical structure when designing a continual WSI anal-ysis framework. Our preliminary experiments revealed that directly adapting the current CL approaches to hierarchi-cal WSI models will lead to drastic knowledge forgetting of previous datasets (see Section 5.4). Moreover, WSIs are gi-gapixel images with only slide-level labels, which brings storage and computational challenges for rehearsal-based
CL, as it is impractical to store and replay the representa-tive WSI in the limited memory buffer.
To tackle these challenges, we develop a novel WSI con-tinual analysis framework, named ConSlide to enable pro-gressive update of a hierarchical WSI analysis architecture by sequentially utilizing the heterogeneous WSI datasets.
To achieve that, we store a representative region set of past datasets, and then regularly reorganize and replay them dur-ing the current model update with an asynchronous updat-ing mechanism. Specifically, we first design a novel Hi-erarchical Interaction Transformer (HIT) as the backbone to efficiently model and utilize the hierarchical characteris-tic of WSI. HIT is possible to aggregate both fine-grained and coarse-grained WSI features for more comprehensive
WSI analysis via its bidirectional interaction within the hi-erarchical structure. Further, to enable the continual update of the designed hierarchical architecture, we follow the re-hearsal strategy but develop a novel Breakup-Reorganize (BuRo) rehearsal module to tackle the unique challenges of WSI data replay. Particularly, the BuRo rehearsal mod-ule utilizes a random sampling strategy to select and store
WSI regions of old tasks in an efficient manner, and then reorganize augmented WSIs of old tasks to improve the knowledge fidelity of old tasks in the replay step. Based on the augmented old task WSI data, we devise a new asyn-chronous updating mechanism with the inspiration of Com-plementary Learning System (CLS) theory [35], to encour-age the patch-level and region-level blocks to learn generic and task-specific knowledge, respectively, by conducting a nested Cross-Scale Similarity Learning (CSSL) task from both old and current WSI data.
With the above careful designs, our framework can pre-serve the knowledge of previous WSI datasets to mitigate catastrophic forgetting and improve the generalization of the WSI model for more accurate analysis. We evaluated our framework on four public WSI datasets from TCGA projects. The extensive ablation analysis shows the ef-fectiveness of each proposed module.
Importantly, our
Conslide achieves more improvement than other compared methods and better trade-off of the overall performance and forgetting on previous datasets under a fair WSI CL setting. Our code is available at https://github.com/HKU-MedAI/ConSlide. 2.