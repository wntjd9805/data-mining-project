Abstract
We present a novel method for weakly-supervised action segmentation and unseen error detection in anomalous in-structional videos. In the absence of an appropriate dataset for this task, we introduce the Anomalous Toy Assembly (ATA) dataset1, which comprises 1152 untrimmed videos of 32 participants assembling three different toys, recorded from four different viewpoints. The training set comprises 27 participants who assemble toys in an expected and con-sistent manner, while the test and validation sets comprise 5 participants who display sequential anomalies in their task. We introduce a weakly labeled segmentation algo-rithm that is a generalization of the constrained Viterbi al-gorithm and identifies potential anomalous moments based on the difference between future anticipation and current recognition results. The proposed method is not restricted by the training transcripts during testing, allowing for the inference of anomalous action sequences while maintain-ing real-time performance. Based on these segmentation results, we also introduce a baseline to detect pre-defined human errors, and benchmark results on the ATA dataset.
Experiments were conducted on the ATA and CSV datasets, outperforming the state-of-the-art in segmenting anomalous videos under both online and offline conditions. 1.

Introduction
One of the challenges in human machine interaction is the automatic vision-based understanding of human actions in instructional videos. These videos depict a series of low-level actions that collectively accomplish a top-level task, such as preparing a meal or assembling an object. How-ever, labeling each frame of these videos can be arduous and necessitate a significant amount of manual effort to note the start and end times of each action segment. Conse-quently, there has been a surge of research interest in devel-oping weakly-supervised methods to learn the actions. In 1https://usa.honda-ri.com/ata
Figure 1. A toy example of different assembly sequences. Given a fixed set of non-anomalous training transcripts, our method ex-plores and infers unseen anomalous sequences at test time. The anomalous sequences may or may not entail assembly errors. particular, such methods aim to overcome the challenge of weakly-labeled instructional videos, where only the ordered sequence of action labels (transcript) is provided without any information on the duration of each action.
Specifically, detection of fine errors and anomalies in tasks performed by human operators is critical for enhanc-ing quality of work, safety, and efficiency. Anomalies can take different forms, but in this paper, we focus on the de-tection of fine-grained sequential anomalies in instructional videos. We define sequential anomalies as unseen action sequences that arise due to unexpected permutations of the action sequences seen in the training set. Such permutations may include unexpected changes in the order of actions, or the omission or addition of one or multiple actions at any point in the video. We also define an “error” as a sequential anomaly that leads to an undesired outcome. This means that not all sequential anomalies indicate faulty procedures (Fig.1). In the context of assembly, some examples of these unseen variations at test time include scenarios where an as-sembly worker skips fastening a screw or spends too much time idling between actions. AI systems can be trained on limited data collected from the optimal work of profes-sionals, yet they must still be capable of detecting out-of-sequence actions in situations where inexperienced workers make mistakes or follow sub-optimal sequences.
Existing weakly-supervised segmentation methods di-vide a video into its constituent atomic actions. These meth-ods are either explicitly [8, 15, 21] or implicitly [33] limited by the training transcripts, so they cannot identify anomalies and out-of-sequence actions effectively in videos. More-over, the absence of datasets with anomalous instructional videos has prevented such methods from being thoroughly tested under circumstances, where there are significant vari-ations between the training and test transcripts.
This paper presents the Anomalous Toy Assembly (ATA) dataset, which is the first instructional video dataset that contains anomalies. The ATA dataset comprises 1152 untrimmed videos of 32 participants assembling three dif-ferent toys, which were recorded from four different view-points. Each toy assembly constitutes a task. The distin-guishing feature of this dataset is the disparity between the training and test action sequences, enabling the investiga-tion of unseen error detection in instructional videos.
In particular, the training set comprises 27 participants who assemble toys in an expected and consistent manner.
On the other hand, the test and validation sets entail 5 par-ticipants who display anomalies in their assembly of toys, including sequence variations, defects, or redundancies. Al-though the test and training sets involve the same set of ac-tions, the action sequences of the test set are distinct and previously unseen in the training set. Our dataset includes annotations of human errors, atomic actions, human pose, and bounding boxes of interactive objects for each video.
As a second contribution, we propose a novel method for weakly-supervised action segmentation, and unseen error detection in anomalous instructional videos. Unlike previ-ous work, the proposed real-time action segmentation algo-rithm is not restricted by training transcripts during testing.
Our inference method is a generalized version of the Viterbi algorithm [37] used in [14, 27]. It segments videos into un-seen transcripts and identifies potential anomalous moments based on the difference between future anticipation and cur-rent recognition results. This method enables the inference of anomalous action sequences while maintaining real-time performance. Finally, based on these segmentation results, the paper introduces a mechanism to detect predefined hu-man errors that occur during assembly, with baseline error detection results presented on the ATA dataset.
To summarize, the contributions of this paper are: 1) We introduce the ATA dataset, the first anomalous in-structional video dataset, containing sequential anomalies and human errors made during toy assembly. All videos are annotated with various spatial and temporal labels. 2) We propose our unconstrained Viterbi algorithm that al-lows real-time segmentation of videos into unseen action sequences. 3) Experiments were conducted on the ATA and CSV [25] datasets, demonstrating that our proposed method outper-forms the state-of-the-art (SoTA) in segmenting anomalous videos under both online and offline conditions. Here, on-line refers to the causal inference of the current action in streaming videos, while offline refers to the full segmenta-tion of the video after observing the entire video. 2.