Abstract
Modeling and designing urban building layouts is of sig-nificant interest in computer vision, computer graphics, and urban applications. A building layout consists of a set of buildings in city blocks defined by a network of roads. We observe that building layouts are discrete structures, con-sisting of multiple rows of buildings of various shapes, and are amenable to skeletonization for mapping arbitrary city block shapes to a canonical form. Hence, we propose a fully automatic approach to building layout generation us-ing graph attention networks. Our method generates real-istic urban layouts given arbitrary road networks, and en-ables conditional generation based on learned priors. Our results, including user study, demonstrate superior perfor-mance as compared to prior layout generation networks, support arbitrary city block and varying building shapes as demonstrated by generating layouts for 28 large cities. 1.

Introduction
Layout generation is of significant interest today in com-puter vision, computer graphics, and related fields. In par-ticular, an urban building layout consists of a set of build-ings arranged into arbitrarily shaped city blocks as defined by a network of interconnected roads. Such layouts are needed in order to provide urban configurations for enter-tainment, simulation, and scientific applications such as de-signing and evolving cities to address urban weather fore-casting (Fig. 5), urban heat island modeling, and sky view factor analysis, etc.
The capture and modeling of complex urban building layouts has been pursued from several directions. 1) Com-puter vision and photogrammetry works seek to metrically reconstruct building layouts over large areas from satellite and/or aerial imagery [11, 40, 12, 21, 64, 70, 34, 36, 15].
Nonetheless, these approaches are constrained by image resolution, occlusion, and segmentation accuracy. 2) Urban procedural modeling has made significant strides in gen-erating the hierarchical components of a city such as road networks, city blocks, parcels, buildings, and more (e.g., buildings [39, 67, 5], roads [42, 10], trees [22, 24, 31, 69], parcels [35, 57] and even entire cities [56, 4]). Unfortu-nately, the generation process requires time consuming and expert knowledge in developing custom procedural rules to create or update the content. 3) Inverse urban procedural modeling attempts to remove the need of explicit rule spec-ification by encoding heuristics specific to cities [6, 68].
Recently, some solutions have addressed inverse mod-eling for layout generation; e.g., using graph-based meth-Figure 2: Framework. Our method is trained in a VAE framework conditioned on arbitrary block shapes (e.g., from a road network). The block shape is a binary mask encoded to latent space by a CNN-based encoder. Building layouts are represented by a grid topology graph and its positional, geometrical, and shape information is encoded by a spatial transform into a canonical representation. By using a graph attention network we codify the graph into a latent space. During decoding, the block shape latent is utilized as condition for decoder to produce building layouts. Our method is able to conditionally generate large urban layouts for arbitrary block shapes and building arrangements (i.e., we have processed 28 cities). ods for structured object creation (StructureNet [38]), in-terior layout design (HouseGAN [41]), land lot generation (BlockPlanner [63]), and building generation (Building-GAN [8]). However, none of these works focus on gen-erating urban layouts containing arbitrary city block shapes and varying building footprints such as those appearing in cities worldwide.
Our work builds on three key observations.
• First, following the organization defined by proce-dural modeling arbitrarily-shaped buildings within an arbitrarily-shaped city block can be organized as a dis-crete spatial data structure of non-overlapping objects arranged into a few rows of buildings (e.g., one row for large buildings, two rows for dense smaller struc-tures, and multiple rows for sparser areas having main buildings and auxiliary building structures).
• Second, capturing the aforementioned building layout configuration can be performed with at least a 2D mes-sage passing setup as afforded by a stubby grid graph (i.e., one row of connected nodes/buildings, two rows forming a ladder graph, or a few rows interconnected as a shallow regular grid, as in Fig. 3.
• Third, by using skeletonization we can perform a spatial transform to the aforementioned stubby graph topology to support diverse urban block shapes.
Altogether, our fully automatic approach for building layout generation uses a variational auto-encoder frame-work using graph neural networks. First, we define a graph-based representation of a block and building layouts that is able to capture the inherent styles of multiple cities glob-ally. Second, the encoder makes use of multi-pass aggrega-tion and combination message passing as well as a spatial transform to codify varying building shapes and layouts for arbitrary city block shapes (Fig. 1). Third, the decoder gen-erates varying building shapes and layouts from the latent space conditioned on block shape (i.e., the distribution of building layouts depends on the block shape). Unlike most prior graph-based method, our scheme is able to accurately capture block shape, building shape type, positional data, and alignment as well. Finally, our synthesis process gen-erates arbitrary maps based on the generated graph, poten-tially spanning a large continuous area (e.g. a entire city).
To the best of our knowledge, our method is the first to generate building layouts in arbitrary city blocks, and is able to span diverse styles of 28 large cities across North
America (e.g., Chicago, Los Angeles, New York City... full list in Sec. 4.1). In Fig. 1, our method generates realistic urban layouts given arbitrary shaped road networks, and it provides controllable generation given building layout pri-ors. We provide comparisons to several prior related meth-ods [2, 17, 26, 63, 25, 20] and show that none of them sup-ports arbitrary block shapes, various building shapes and layouts, nor have any been demonstrated at the scale of our method. In addition, we show examples of conditioned gen-eration, manipulation, interpolation, and ablation study.
Our main contributions include:
• Graph-based Representation for arbitrarily shaped city blocks and building layouts amenable to deep learning.
• Canonical Spatial Transformation to encode building layouts into a shape-independent canonical representa-tion,
• Controllable Generation of realistic urban layouts for arbitrary road networks (e.g. random, or conditioned on a learned prior). 2.