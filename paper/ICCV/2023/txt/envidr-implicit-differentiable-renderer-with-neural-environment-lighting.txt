Abstract
Recent advances in neural rendering have shown great potential for reconstructing scenes from multiview images.
However, accurately representing objects with glossy sur-In this faces remains a challenge for existing methods. work, we introduce ENVIDR, a rendering and modeling framework for high-quality rendering and reconstruction of surfaces with challenging specular reflections. To achieve this, we first propose a novel neural renderer with decom-posed rendering components to learn the interaction be-tween surface and environment lighting. This renderer is trained using existing physically based renderers and is de-coupled from actual scene representations. We then pro-pose an SDF-based neural surface model that leverages this learned neural renderer to represent general scenes.
Our model additionally synthesizes indirect illuminations caused by inter-reflections from shiny surfaces by marching surface-reflected rays. We demonstrate that our method out-performs state-of-art methods on challenging shiny scenes, providing high-quality rendering of specular reflections while also enabling material editing and scene relighting. 1.

Introduction
Neural Radiance Fields (NeRF) [24] has emerged as a promising approach to many important 3D computer vision and graphics tasks. By integrating deep learning with tra-ditional volume rendering techniques, NeRF enables high-quality 3D scene modeling and reconstruction with photo-realistic rendering quality with significant recent research that has achieved impressive results [25, 26, 28, 20]. While
NeRF can synthesize novel views with photo-realistic qual-ity, they often struggle to accurately represent surfaces with high specular reflectance. Instead of learning a solid, smooth surface for these regions, NeRF models tend to in-terpret the view-dependent specular reflections as virtual lights or images underneath the actual surfaces (Figure 2).
This leads to learning inaccurate surface geometry in the shiny regions. These virtual lights can also interfere with normal directions and negatively affect performance in in-verse rendering tasks such as relighting and environment estimation. This challenge has also been observed and ana-lyzed by prior work, Verbin et al. [35], but is yet to be fully addressed.
Prior work largely takes one of two major approaches to address the challenge of learning reflection in neural render-ing. The first approach involves explicitly representing vir-tual lights or images underneath the surface to account for complex view-dependent appearance [13, 42, 17, 34]. The original NeRF [24] and its extensions such as [21, 2, 45] also synthesize complex reflections in this way (Figure 2).
Although this approach at large can improve rendering qual-ity, it often sacrifices the accuracy of the reconstructed sur-face and limits the ability to edit scenes, such as relight-ing. Alternatively, the second approach incorporates knowl-edge of inverse rendering to model the interaction between light and surface [47, 49, 6, 26]. By decomposing render-ing parameters, these methods can achieve material editing
Figure 2: Artifacts in rendering surfaces with specular reflections due to the inaccurate interpretation of virtual lights underneath ob-ject surfaces (results from mip-NeRF [2]). and scene relighting. However, these methods often suf-fer from relatively low rendering quality compared to top-performing NeRF models without full decomposition. This is because the simplified or approximated rendering equa-tion [16] used in these models cannot account for all com-plex rendering effects. Ref-NeRF [35] improves the render-ing of glossy objects with some decomposition; however its editability (e.g., relighting) is still limited as it does not fully decompose surface material and environment illumination.
In this work, we aim to further improve the quality of neu-ral rendering for glossy surfaces, while retaining accurate surface geometry and the ability to edit scenes.
In this work, we introduce ENVIDR, a new rendering and modeling framework for high-quality reconstructing and rendering of 3D objects with challenging specular re-It comprises two major parts: 1) a novel neu-flections. ral renderer and 2) an SDF-based neural surface model that represents the scene and interacts with the neural renderer.
Our neural renderer is different from prior works [47, 49, 6, 26] that incorporate the rendering equations for in-verse rendering as we do not use an explicit form of the rendering equation. Instead, our neural renderer learns an approximation of physically based rendering (PBR) using 3 decomposed MLPs accounting for environment lighting, diffuse rendering, and specular rendering, respectively (Fig-ure 3). This neural renderer is trained using images with various materials and environments synthesized by existing
PBR renderers. In our renderer, the environment MLP is a decoupled component that is trained to represent the pre-integrated lighting of a specific environment with neural features as output (different from prior methods [6, 10, 19] that outputs RGB). Thus, our neural renderer can be used for scene relighting and material editing by simply swap-ping out the environment MLP with the one that is trained to represent the desired environment map.
To interact with this neural renderer, we present a new neural surface model that employs an SDF-based neural representation (similar to [43]). We, however, use the dif-fuse/specular MLPs from the neural renderer in place of the commonly used directional color MLP. During training, we only train this SDF model and a new environment MLP without changing the pre-trained diffuse/specular MLPs in the neural renderer.
Finally, shiny surfaces may have inter-reflections that cause apparent view-dependent indirect illumination. To model this, we approximate the incoming radiance from inter-reflections by marching rays along the surface-reflected view directions. We additionally propose a color blending model that converts the approximated incoming radiance into indirect illumination and blends it into EN-VIDRâ€™s final rendered color.
We demonstrate the effectiveness of our proposed method on several challenging shiny scenes, and our results show that it is quantitatively and qualitatively on par with or superior to previous methods. Our method achieves this while preserving high-quality decomposed rendering com-ponents, including diffuse color, specular color, material roughness, and environment light, which enables physically based scene editing. 2.