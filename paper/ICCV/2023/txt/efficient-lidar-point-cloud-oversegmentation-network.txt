Abstract
Point cloud oversegmentation is a challenging task since it needs to produce perceptually meaningful partitions (i.e., superpoints) of a point cloud. Most existing overseg-mentation methods cannot efﬁciently generate superpoints from large-scale LiDAR point clouds due to complex and inefﬁcient procedures. In this paper, we propose a simple yet efﬁcient end-to-end LiDAR oversegmentation network, which segments superpoints from the LiDAR point cloud by grouping points based on low-level point embeddings.
Speciﬁcally, we ﬁrst learn the similarity of points from the constructed local neighborhoods to obtain low-level point embeddings through the local discriminative loss.
Then, to generate homogeneous superpoints from the sparse
LiDAR point cloud, we propose a LiDAR point grouping algorithm that simultaneously considers the similarity of point embeddings and the Euclidean distance of points in 3D space. Finally, we design a superpoint reﬁnement module for accurately assigning the hard boundary points to the corresponding superpoints. Extensive results on two large-scale outdoor datasets, SemanticKITTI and nuScenes, show that our method achieves a new state-of-the-art in
LiDAR oversegmentation. Notably, the inference time of our method is 100× faster than that of other methods. Fur-thermore, we apply the learned superpoints to the LiDAR semantic segmentation task and the results show that using superpoints can signiﬁcantly improve the LiDAR semantic segmentation of the baseline network. Code is available at https://github.com/fpthink/SuperLiDAR. 1.

Introduction
In modern self-driving cars, 3D LiDAR sensor acquires precise distance measurements of surrounding objects and
∗Corresponding authors.
Le Hui and Yuchao Dai are with Shaanxi Key Laboratory of
Information Acquisition and Processing, China. Linghua Tang, Jin Xie and Jian Yang are with Key Lab of Intelligent Perception and Systems for
High-Dimensional Information of Ministry of Education, and Jiangsu Key
Lab of Image and Video Understanding for Social Security, China. their surface characteristics for large-scale outdoor scene
In recent years, LiDAR semantic seg-understanding. mentation [21] has been widely studied, and a variety of approaches have emerged with impressive results. How-ever, LiDAR oversegmentation is rarely explored in 3D computer vision. Unlike LiDAR semantic segmentation,
LiDAR oversegmentation outputs the perceptually mean-ingful tessellation of point cloud. The resulting superpoint is a set of points, which are semantically and geometrically homogeneous in the local regions of the objects. The super-point representation can adaptively and ﬂexibly represent local geometric structures of objects. Therefore, studying
LiDAR oversegmentation is very meaningful for LiDAR the sparsity, point cloud based applications. However, noise, and irregularity of LiDAR point clouds bring great challenges to LiDAR oversegmentation.
Early point cloud oversegmentation methods are usu-ally optimization based methods. Lin et al. [17] cast-ed superpoint segmentation problem as a subset selection problem, and developed a heuristic algorithm that utilizes handcrafted local information of the point cloud to segment superpoints by minimizing the energy function. Guinard et al. [8] formulated point cloud oversegmentation as a struc-tured optimization problem and used handcrafted local descriptors to produce geometrically simple superpoints through a greedy graph-cut algorithm [14]. However, due to sparse LiDAR point clouds, the computed handcrafted features are less discriminative, so the resulting superpoints cannot produce clear boundaries between similar objects.
Landrieu et al. [13] introduced a deep network to extract point embeddings, which are used to replace handcrafted features in [14] for segmenting superpoints. Since it is a two-stage method, the processing procedure of superpoint segmentation is complex and time-consuming. Recently,
Hui et al. [11] proposed an end-to-end superpoint network that iteratively learns the point-superpoint association map for clustering superpoints. Nonetheless, it requires post-processing to ﬁlter the noise points.
In short, due to the above methods complex and inefﬁcient procedures, cannot efﬁciently generate superpoints from large-scale
LiDAR point clouds.
In this paper, we propose a simple yet efﬁcient LiDAR oversegmentation network called SuperLiDAR, which di-rectly outputs superpoint from LiDAR point clouds without any additional processing procedures. The key idea of seg-menting superpoints is to group points based on low-level point embeddings. Speciﬁcally, to learn low-level point embeddings, we ﬁrst formulate it as a deep metric learning problem structured by a local neighborhood deﬁned on the point cloud. We introduce the local discriminative loss to embed 3D points within the local neighborhoods of the same object, thereby ensuring the point embed-dings are similar to each other. After obtaining low-level point embeddings, we then propose a LiDAR point grouping algorithm, which groups the points to generate superpoints via the breadth-ﬁrst search (BFS). By using the similarity of point embeddings and Euclidean distance of 3D point coordinates, we apply the BFS algorithm to produce compact superpoints. Finally, we propose a superpoint reﬁnement module, which learns the afﬁnity between the hard boundary point and its k-nearest candidate superpoints. By assigning the hard boundary point with the corresponding superpoint with the highest similarity, we can obtain high-quality superpoints. Notably, our Li-DAR oversegmentation network can ﬂexibly integrate with downstream tasks, such as semantic segmentation. In order to evaluate the effectiveness of the learned superpoints, we introduce a simple multi-scale superpoint aggregation module for LiDAR semantic segmentation. We conduct experiments on two large-scale benchmarks, SemanticKIT-TI and nuScenes, to demonstrate the effectiveness of our method. LIDAR oversegmentation experiments show that the proposed method not only achieves state-of-the-art performance, but also is 100× faster than other methods.
Furthermore, LiDAR semantic segmentation experiments demonstrate that using superpoint can signiﬁcantly improve the performance of the baseline network.
The contributions of this paper are as follows:
• We propose an efﬁcient LiDAR oversegmentation net-work for learning superpoint segmentation from large-scale LiDAR point clouds.
• Our method achieves state-of-the-art performance in
LiDAR oversegmentation while being 100× faster than current oversegmentation methods.
• We demonstrate that the proposed LiDAR overseg-mentation network can be integrated into LiDAR se-mantic segmentation network in an end-to-end man-ner and further improve the performance of LiDAR semantic segmentation. 2.