Abstract 1.

Introduction
While most state-of-the-art instance segmentation meth-ods produce pixel-wise segmentation masks, numerous ap-plications demand precise vector polygons of detected ob-jects instead of rasterized output. This paper proposes
Re:PolyWorld as a remastered and improved version of
PolyWorld, a neural network that extracts object vertices from an image and connects them optimally to generate pre-cise polygons. The objective of this work was to overcome weaknesses and shortcomings of the original model, as well as introducing an improved polygonal representation to ob-tain a general-purpose method for polygon extraction in im-ages. The architecture has been redesigned to not only ex-ploit vertex features, but to also make use of the visual ap-pearance of edges. To this end, an edge-aware Graph Neu-ral Network predicts the connection strength between each pair of vertices, which is further used to compute the assign-ment by solving a differentiable optimal transport problem.
The proposed redefinition of the polygonal scene turns the method into a powerful generalized approach that can be applied to a large variety of tasks and problem settings, such as building extraction, floorplan reconstruction and even wireframe parsing. Re:PolyWorld not only outper-forms the original model on building extraction in aerial images, thanks to the proposed joint analysis of vertices and edges, but also beats the state-of-the-art in multiple other domains.
The detection of polygonal objects and the generation of vector annotations is an important topic in numerous com-puter vision applications, such as building extraction in air-borne imagery, floorplan reconstruction, scene understand-ing, as well as wireframe parsing. In all these applications, the visual quality of the final polygonization is a highly de-sired feature that modern machine learning approaches aim to achieve. On one hand, vector annotations with redun-dant vertices often appear irregular, and exhibit artifacts or curved corners. On the other hand, oversimplified polygons are often not able to capture geometric details of the object.
In this paper, we propose Re:PolyWorld (Figure 1) as a remastered version of PolyWorld [30], a neural network for building detection and polygonization in airborne imagery.
The original model extracts positions and visual descriptors of building corners using a Convolutional Neural Network (CNN) and generates polygons by evaluating which con-nections between vertices are valid. This procedure iden-tifies the optimal pairing of detected vertex descriptors, re-quiring each corner to be linked with its respective subse-quent vertex in the polygon. Connections between poly-gon vertices can be represented by a permutation matrix obtained as the solution of a linear sum assignment prob-lem. PolyWorld is fast, accurate, end-to-end trained, and generates high quality building polygons ready to be used in cartographic applications. However, the permutational representation of the scene is not applicable to other prob-lem settings and applications, and the model only reasons
based on local visual descriptors of vertices.
Motivated by these drawbacks of PolyWorld, our remas-tered model makes the following contributions:
• We propose a novel generalized representation of the polygonal scene, that can be applied to numerous tasks and problem settings with diverse image data sets.
• We modify the PolyWorld architecture in order to not only rely on local vertex information, but also exploit visual edge features by introducing a novel edge-aware attention mechanism.
• We evaluate our model on a variety of data sets and different tasks; including building extraction, floorplan reconstruction, and even wireframe parsing. ate line segment proposals based on predicted junctions, and a line segment verification module to classify them.
However, L-CNN incurs high computational costs due to the large number of proposals it generates. Moreover, ig-noring line segment information in the proposal stage may not fully leverage the deep learning pipeline for better per-formance. Even though not fully end-to-end trainable, at-traction field map (AFM) based approaches [22, 23] reach outstanding performance in line segment detection without exploiting junction information during learning. More re-cently, HAWP [24, 25], similarly to L-CNN, performs line and junctions proposal generation and proposal verification.
It achieves state-of-the-art performance by introducing a novel line segment prediction approach for more accurate parsing. 2.