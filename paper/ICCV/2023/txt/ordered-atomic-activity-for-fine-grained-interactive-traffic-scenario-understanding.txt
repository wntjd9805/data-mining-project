Abstract
We introduce a novel representation called Ordered
Atomic Activity for interactive scenario understanding. The representation decomposes each scenario into a set of or-dered atomic activities, where each activity consists of an action and the corresponding actors involved and the order denotes the temporal development of the scenario. This de-sign also helps in identifying important interactive relation-ships, such as yielding. The action is a high-level seman-tic motion pattern that is grounded in the surrounding road topology, which we decompose into zones and corners with unique IDs. For example, a group of pedestrians crossing in front is denoted as C1 → C4: P+, as depicted in Fig-ure 1. We collect a new large-scale dataset called OATS1 (Ordered Atomic Activities in interactive Traffic Scenarios), comprising 1026 video clips (∼ 20s) captured at intersec-tions in San Francisco Bay Area. Each clip is labeled with the proposed language, resulting in 59 activity categories and 6512 annotated activity instances. We propose three fine-grained scenario understanding tasks, i.e., multilabel atomic activity recognition, activity order prediction, and interactive scenario retrieval. We also propose a Graph
Convolutional Network based framework that models both appearance and motion of traffic participants to tackle the above tasks, that performs favorably against state-of-the-art methods. However, we find that the methods cannot achieve satisfactory performance, indicating rising oppor-tunities for the community to develop new algorithms for these tasks towards better interactive scenario understand-ing. 1.

Introduction
Intelligent transportation systems (ITS) have made sig-nificant progress in addressing traffic fatalities, with ad-vancements in perception [20, 55, 70, 26, 19], predic-tion [90, 48, 16], hazard identification [54, 71, 39, 31], and 1https://usa.honda-ri.com/oats
Figure 1. Ordered Atomic Activity.
Instead of using natu-ral language to describe a scenario which is verbose and time-consuming, Ordered Atomic Activity decomposes each interactive scenario into a set of ordered atomic activities, where each ac-tivity consists of an action and the corresponding actors involved and the order represents the temporal development of the scenario.
The activity of ”a group of pedestrians crossing in front” is repre-sented as C1 → C4: P+, where C1 and C4 are the two corners, → denotes the moving direction and the actors P+ (a group of pedes-trians) perform the action. We denote the temporal development in a scenario by tagging the order of activities based on their oc-currence. Ordered Atomic Activity also enables efficient scenario retrieval for applications such as scenario-based assessment. planning [5, 1]. To deploy ITS at scale, extensive research has been conducted on scenario-based simulation assess-ment [15, 5, 85, 1] to validate ITS in challenging scenarios and identify the causes of failure. Effective scenario under-standing and retrieval of real-world data, therefore, can en-hance scenario-based assessment [65, 21] and help improve
ITS deployment.
In this work, we focus on intersection scenarios, which involve the highest number of interactions among traf-fic participants and account for approximately 40% of all crashes [53]. We specifically examine scenarios where traf-fic participants are crossing at the intersections, rather than
static participants who do not directly interact with the ego car. This design choice is motivated by the practice of scenario-based safety assessment [77, 63, 21, 13], which fo-cuses on activities relevant to the ego vehicle. Our primary research objective is to identify an effective way to describe an interactive scenario involving traffic participants, in or-der to achieve a better scenario understanding and retrieval.
According to [77, 13], an interactive scenario representa-tion should include information about the activities of road users (including their location, moving direction, and goal), the static environment, and the temporal evolution of these activities. We can use natural language [43, 34, 33], road scene graphs [89, 74], and attributes [58, 42, 48, 65] to rep-resent interactive scenarios. While it is intuitive and ex-plainable for humans using natural language, it often lacks explicit information about the motion directions and goals of road users, leading to verbose descriptions that are diffi-cult to label and control for quality, as shown in Figure 1.
Additionally, it is challenging to retrieve videos efficiently with lengthy natural language descriptions. Road scene graphs have also become a popular representation of traffic scenes. Each road user is represented as a node with low-level states such as location, speed, and direction, whereas edges capture pair-wise relationships between pairs of road users such as ”following.” However, these approaches do not represent the high-level semantics between actors’ ac-tions and the underlying road topology, which enables effi-cient tagging for scenario-based assessment [21]. Attribute-based representations are promising options. However, ex-isting works have not explored bridging the gap between activity and underlying road scene structures. Moreover, both road scene graphs and attribute-based approaches have not tackled the temporal development of a scenario and also lack activity order information.
To this end, we propose a novel representation of an in-teractive scenario called Ordered Atomic Activity. In Fig-ure 1, we see an ego vehicle turning right and yielding to a group of crossing pedestrians in the front and a crossing ve-hicle from the left side, while another car in front is crossing in the opposite direction of the ego vehicle. We represent this detailed description in a concise yet interpretable man-ner using our proposed representation, where each activity comprises an action and the corresponding actors, such as a group of pedestrians or the ego vehicle. The action is a high-level semantic motion pattern grounded in the surrounding road topology. Specifically, we decompose a road scene, such as a 4-way intersection, into a set of regions that rep-resent corners and zones. For example, a right-turn action is denoted as Z1 → Z2, representing a motion pattern from an initial position to the destination. ”A group of pedestri-ans crossing in front” is denoted as C1 → C4: P+, where
C1 and C4 are the two corners, → is the motion direction and P+ are the group of pedestrians performing the action.
Moreover, we denote temporal development in a scenario by tagging the order in which the activities occur. This also helps in representing yielding relationships.
In Figure 1, the order of the group of pedestrians, crossing vehicle in the same direction as ego vehicle, and ego vehicle activities represent yielding. Ordered Atomic Activity is designed at a video level, making it highly scalable and easing the burden of annotation.
We collect a large-scale dataset OATS and annotate monocular videos with Ordered Atomic Activity. The OATS dataset comprises 1026 clips, each approximately 20 sec-onds long, of real human driving in the San Francisco Bay
Area captured using an instrumented vehicle. We pro-pose three new and challenging fine-grained scenario under-standing tasks, including multilabel atomic activity recog-nition, activity order prediction, and interactive scenario re-trieval. We design a graph convolutional network-based al-gorithm that models both appearance and motion of traffic participants for the above tasks. We also implement multi-ple baselines (including recent state-of-the-art video under-standing algorithms [6, 79, 87, 18, 76, 2, 83]) and evaluate them on the proposed dataset.
Our extensive experiments demonstrate that the methods perform inadequately on the proposed three tasks. Specifi-cally, the best-performing algorithms for multilabel activity recognition, activity order prediction, and interactive sce-nario retrieval achieve 26.7% mAP, 16.1% matching score, and 16.6% Recall@top50. To successfully recognize mul-tiple Atomic Activities in a scenario, a model should detect and track moving road users, associate their spatio-temporal action with respect to the underlying road topology, and capture the concept of groups. We believe the proposed Or-dered Atomic Activity and the dataset introduce new chal-lenges to the video scene understanding community. We hope to encourage the research community to work collec-tively on this important and challenging area.
This paper makes the following contributions. First, we introduce a novel representation called Ordered Atomic
Activity for interactive scenario understanding. Second, we construct a large-scale dataset and propose three essen-tial fine-grained scenario understanding tasks: multilabel atomic activity recognition, activity order prediction, and interactive scenario retrieval. Third, we propose a graph convolutional based network that models both appearance and motion of traffic participants and performs favorably against state-of-the-art methods on the above tasks. We also conduct extensive experiments on the three tasks and estab-lish a comprehensive benchmark suite for future research. 2.