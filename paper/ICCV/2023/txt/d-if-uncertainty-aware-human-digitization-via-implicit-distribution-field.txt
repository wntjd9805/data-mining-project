Abstract
Realistic virtual humans play a crucial role in numerous industries, such as metaverse, intelligent healthcare, and self-driving simulation. But creating them on a large scale with high levels of realism remains a challenge. The utiliza-tion of deep implicit function sparks a new era of image-based 3D clothed human reconstruction, enabling pixel-aligned shape recovery with fine details. Subsequently, the vast majority of works locate the surface by regressing the deterministic implicit value for each point. However, should all points be treated equally regardless of their proximity to the surface? In this paper, we propose replacing the implicit value with an adaptive uncertainty distribution, to differentiate between points based on their distance to the surface. This simple “value ⇒ distribution” transi-tion yields significant improvements on nearly all the base-lines. Furthermore, qualitative results demonstrate that the models trained using our uncertainty distribution loss, can capture more intricate wrinkles, and realistic limbs.
Code and models are available for research purposes at github.com/psyai-net/D-IF release. 1.

Introduction
The creation of realistic digital avatars with intricate clothing details holds significant importance in various intelligent health-applications, such as metaverse [40], care [45], teleportation [19], and self-driving simula-tion [44]. However, conventional methods require substan-tial human resources and considerable costs for designing or capturing high-fidelity 3D digital avatars. To simplify this process while maintaining quality, both the academic community and industry have shifted their focus and efforts toward data-driven approaches [20, 37, 43], to accurately reconstruct 3D humans from images or monocular videos.
†These authors contributed equally to this work.
*represents the corresponding author.
Figure 1. Comparison with mainstream SOTAs.
Unlike
PaMIR [47], PIFu [37], and ICON [43], which frequently pro-duce 3D humans with distorted or non-human shape limbs, miss-ing details, and high-frequency noise, our method overcomes these issues and achieves superior geometric details in reconstruction.
Explicit-shape-based approaches [1–3, 18, 41, 48] typi-cally fit and deform the parametric body model, like SMPL-(X) [23, 33], to align with the visual observations. While these approaches could recover 3D humans wearing tight clothing, they face limitations when it comes to recon-structing loose-fitting garments that largely deviate from the body. Alternatively, implicit-function-based approaches [4, 13–15, 21, 38, 42, 43, 47] utilize implicit function parame-Figure 2. The framework of D-IF (Sec. 3.1). A. For queried points p ∈ R3, which are uniformly sampled from the entire 3D space, 7D pointwise local feature F7D is extracted. B. F7D is then fed into distribution predictor Pφ (p), to estimate the per-point distribution (µ, σ), and the coarse occupancy Os(p) is sampled from it. C. Given all above features and outputs (9D), Occupancy Rectifier, an additional MLP, is to predict the residual offset ∆Os(p). Finally, the fine occupancy (cid:102)Os(p) is obtained via (cid:102)Os(p) = Os(p) + ∆Os(p). The bottom half of this illustration demonstrates the design of uncertainty-aware supervised learning (Sec. 3.4). During training, we formulate the “pseudo” ground-truth distribution ˆP (p) as follows: ground-truth smooth occupancy value Ogt(p) as the expectation µ (Eq. (5)), and σ is gradually reducing as the point-to-mesh distance increases (Eq. (6)). Finally, KL-divergence loss is introduced to minimize the difference between predicted and pseudo distributions, see Eq. (7). terized by MLPs to regress occupancy fields [28] or signed distance fields (SDF) [32]. Detailed meshes can then be extracted using Marching Cubes [24] from the iso-surface of a certain implicit value. Implicit methods have demon-strated their superiority in capturing geometric details and accommodating various topological structures. However, they may generate non-human shapes for unseen poses or garments, due to the absence of shape regularization.
Despite the impressive results of prior implicit-based methods, they have not fully taken into account the presence of “uncertainty” in the geometric deformation that arises during the reconstruction procedure. For example, in the case of points that significantly deviate from the body, a practical shortcut would be to categorize them as “outside points”, while even a minor estimation disturbance near the surface can lead to a completely wrong occupancy result.
To account for such uncertainty, this paper introduces implicit distribution fields, called D-IF. Instead of directly estimating the implicit value at each point, we opt to sam-ple the implicit value from an estimated distribution. This enables us to effectively capture the uncertainty associated with the distance from the surface. The overview of our method is shown in Fig. 2. Inspired by ICON [43], we firstly extract 7D local features from the input image and estimated
SMPL body. These features are then utilized to estimate the point-wise occupancy distribution. Sampling from the pro-jected distribution of grid points across the entire 3D space produces a coarse occupancy field. To enhance the level of detail, we introduce an additional MLP called “Occupancy
Rectifier”, which refines the coarse occupancy field further, to obtain the fine occupancy field, the final clothed mesh is extracted using Marching Cubes [24] at 0.5 level-set.
Upon delving deeper into D-IF, it becomes apparent that there exists a dilemma for the learned distribution to be simultaneously accurate and uncertain. This necessitates finding a balance in terms of distribution sharpness. To ad-dress this dilemma, we introduce an explicit supervision mechanism known as the uncertainty distribution loss to learn the distribution, which is illustrated in Fig. 2. The in-sight behind the loss is based on the assumption that point-wise distribution is highly relevant to point-to-mesh dis-tance. We elaborate this in Sec. 3.4, where we introduce the
KL-divergence [22] between the predicted distribution and a designed distribution (pseudo GT). Moreover, the Occu-pancy Rectifier module aims to correct any erroneous occu-pancy while simultaneously refining intricate shape details. 2
Quantitative experiments on CAPE [26] confirm that our method achieves SOTA performance, see Tab. 1. And as a “plug-and-play” module, it significantly improves the re-construction accuracy on nearly all the mainstream base-lines. As depicted in Fig. 1, D-IF excels at recovering intri-cate geometric features, while mitigating common artifacts found in other works [37, 43, 47], including non-human parts, missing details, and high-frequency noise. 2.