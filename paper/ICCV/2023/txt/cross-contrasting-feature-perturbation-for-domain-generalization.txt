Abstract
Domain generalization (DG) aims to learn a robust model from source domains that generalize well on un-seen target domains. Recent studies focus on generating novel domain samples or features to diversify distributions complementary to source domains. Yet, these approaches can hardly deal with the restriction that the samples syn-thesized from various domains can cause semantic distor-tion. In this paper, we propose an online one-stage Cross
Contrasting Feature Perturbation (CCFP) framework to simulate domain shift by generating perturbed features in the latent space while regularizing the model prediction against domain shift. Different from the previous fixed syn-thesizing strategy, we design modules with learnable fea-ture perturbations and semantic consistency constraints.
In contrast to prior work, our method does not use any generative-based models or domain labels. We conduct extensive experiments on a standard DomainBed bench-mark with a strict evaluation protocol for a fair compar-ison. Comprehensive experiments show that our method outperforms the previous state-of-the-art, and quantitative analyses illustrate that our approach can alleviate the do-main shift problem in out-of-distribution (OOD) scenarios. https://github.com/hackmebroo/CCFP 1.

Introduction
Deep Neural Networks have achieved remarkable suc-cess on a number of computer vision tasks[27, 65]. These models rely on the i.i.d assumption[52], i.e., the training data and testing data are identically and independently dis-tributed. However, in real-world scenarios, the assumption does not always hold due to the domain shif t problem[5].
For instance, it is hard for a model trained on photographs to adapt to sketches.
Domain adaptation (DA) methods[13, 50, 61] can be em-*Corresponding author. ployed to handle the out-of-distribution (OOD) issue in the settings where unlabeled target data is available. Although
DA can perform well on known target domains, it still fails in practical situations where target domains are not accessi-ble during training. Domain generalization (DG) [59] aims to deal with such problems. The goal of domain general-ization is to learn a generalized model from multiple differ-ent but related source domains (i.e. diverse training datasets with the same label space) that can perform well on arbi-trary unseen target domains. To realize this goal, most deep learning models are trained to minimize the average loss over the training set, which is known as the Empirical Risk
Minimization (ERM) principle[53]. However, ERM-based network provably fails to OOD scenarios[38, 11, 21, 64].
One line of work[49, 45, 46] improves the generaliza-tion capability of a model by optimizing the worst-domain risk over the set of possible domains, which are created by perturbing samples in the image level or using generative-based model (i.e. VAE[25] or GAN[17]) to generate ficti-tious samples. Despite the performance promoted by creat-ing samples in the image level on an offline basis to approx-imate the worst case over the entire family of domains, it is hard to generate ”fictitious” samples in the input space with-out losing semantic discriminative information[43]. More-over, the offline two-stage data perturbation training pro-cedure is nontrivial since both training a generative-based model and inferring them to obtain perturbed samples are challenging tasks.
Another line of work perturbs features in the latent space[55, 70] by tuning the scaling and shifting parameters after instance normalization. Another study[32] extends it and leverages the uncertainty associated with feature statis-tics perturbation. However, these methods all rely on a fixed perturbation strategy (linear interpolation or random pertur-bation) which limits the domain transportation from synthe-sized features to original features. Besides, although the in-stance normalization-based feature perturbation can change the information of intermediate features which is specific to domains, they still fail to preserve the semantic invari-ant, as the instance normalization may dilute discriminative information that is relevant to task objectives[39]. The per-formance of feature synthesis methods can be undetermined on account of semantic inconsistency[35].
As is mentioned above, the data perturbation based methods can hardly generate the fictitious samples in the in-put space, and the feature perturbation based methods lim-its the diversity of the synthesized features and fail to pre-serve the semantic consistency. To address both of these issues, we propose to enforce a domain-aware adaptive fea-ture perturbation in the latent space following the worst-case optimization objective and explicitly constrain the se-mantic consistency to preserve the class discriminative in-formation.
Practically, the desideratum for the worst-case DG prob-lem is to simulate the realistic domain shift by maximiz-ing the domain discrepancy and minimizing the class dis-criminative characteristics between the source domain dis-tribution and the fictitious target domain distribution. To this end, we design an adaptive online one-stage Cross
Contrasting F eature P erturbation (CCFP) framework.
An illustration of CCFP is shown in Figure 1. Our CCFP consists of two sub-network, one is used to extract the original features which represent the online estimate of the source distribution, and the other is used to perturb features in the latent space to create semantic invariant fictitious tar-get distribution. In order to preserve the class discriminative information of the perturbed features, we regularize the pre-dictions between the two sub-networks.
A key component of our framework is the feature per-turbation. As pointed out in the research field of style transfer[10, 22], the feature statistics carry the informa-tion primarily referring to domain-specific but are less rel-evant to class discriminative. Based on this, we design a learnable domain perturbation (LDP) module which can generate learnable perturbation of features to enlarge the domain transportation from the original ones. Note that the
LDP only adds learnable scaling and shifting parameters on feature statistics without adopting domain labels or addi-tional generative models.
Another critical point of CCFP is the measurement of domain discrepancy. Different from existing study measure the domain discrepancy in the last layer[58, 51], we pro-pose to measure the domain discrepancy from the interme-diate features to align with the observation that the shallow layers of the network learn low-level features (such as color and edges) which are more domain aware but less semantic relevant[60]. Additionally, Gatys et al.[15] show that Gram matrices of latent features can be used to encode stylistic attributes like textures and patterns. Motivated by this, we develop a novel Gram-matrices-based metric to represent the domain-specific information from the intermediate ac-tivations. We maximize the dissimilarity between the in-termediate features’ Gram matrices to simulate the domain shift.
We validate the effectiveness of CCFP on a standard DG benchmark called Domainbed[18]. Comprehensive experi-ment results show that our method surpasses previous meth-ods and achieves state-of-the-art.
In summary, our contributions are three-fold:
• We propose a novel online one-stage cross contrast-ing feature perturbation framework (CCFP) for worst-case domain generalization problem, which can gener-ate perturbed features while regularizing semantic con-sistency.
• We develop a learnable domain perturbation (LDP) module and an effective domain-aware Gram-matrices-based metric to measure domain discrepancy, which are useful for DG and integrated into the above
CCFP framework. Additionally, our algorithm does not use any generative-based models and domain labels.
• Comprehensive experiments show that our method achieves state-of-the-art performance on diverse DG benchmarks under strict evaluation protocols of
DomainBed[18]. 2.