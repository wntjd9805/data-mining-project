Abstract
Training a generative model with limited number of sam-ples is a challenging task. Current methods primarily rely on few-shot model adaption to train the network. How-ever, in scenarios where data is extremely limited (less than 10), the generative network tends to overfit and suf-fers from content degradation. To address these problems, we propose a novel phasic content fusing few-shot diffu-sion model with directional distribution consistency loss, which targets different learning objectives at distinct train-ing stages of the diffusion model. Specifically, we design a phasic training strategy with phasic content fusion to help our model learn content and style information when t is large, and learn local details of target domain when t is small, leading to an improvement in the capture of con-tent, style and local details. Furthermore, we introduce a novel directional distribution consistency loss that en-sures the consistency between the generated and source distributions more efficiently and stably than the prior methods, preventing our model from overfitting. Finally, we propose a cross-domain structure guidance strategy that enhances structure consistency during domain adap-tation. Theoretical analysis, qualitative and quantitative experiments demonstrate the superiority of our approach in few-shot generative model adaption tasks compared to state-of-the-art methods. The source code is available at: https://github.com/sjtuplayer/few-shot-diffusion. 1.

Introduction
Deep generative models [8, 9] have achieved significant success in image generation tasks in recent years [39, 33].
However, when the number of samples is limited, i.e., they still suffer from under few-shot image generation,
*Equal contributions.
†Corresponding author.
Figure 1. Comparison with the diffusion model [43] directly trained with IDC loss [20], which captures an inaccurate style due to the failed style transfer when t is small. the problem of overfitting. Most of the few-shot genera-tive models are based on Generative Adversarial Networks (GANs) [8, 2, 5, 15, 30] using few-shot model adaption.
Some existing works have attempted to mitigate the over-fitting problem through regularization or data augmenta-tion [14, 36, 26, 41, 42], but still face difficulties when the samples are extremely limited (less than 10). Recently,
IDC [20] and RSSA [31] propose new cross-domain consis-tency loss functions to maintain similarity between the gen-erated and original distributions and demonstrate promising results. However, due to the inherent limitations of GAN’s architecture and generation process, there is still room for improvement for these methods in terms of preserving con-tent information and enhancing image quality.
Over the last few years, diffusion models [9] have shown great success in image generation and have surpassed GAN model in sub-tasks like text-to-image synthesis and image inpainting [23]. Especially, the flexible controlling process and good generation quality of diffusion models can help enhance the content information and structure consistency during domain adaption and are suitable for few-shot im-age generation task, which inspires us to study few-shot diffusion generation. However, training few-shot diffusion
model faces the following problems: (1) diffusion model tends to overfit with limited number of samples as GANs do; (2) simply training diffusion model with the few-shot loss functions in GAN [20, 31] leads to failed style transfer at the detail learning stage (t small), causing unsuccessful style capture as Fig. 1 shows; (3) the existing loss in few-shot GAN adaptation only constrains the pairwise distances of generated samples in target and source domains to be similar, leading to distribution rotation during training pro-cess, which may cause unstable and ineffective training.
To solve these problems, we propose a novel few-shot diffusion model that incorporates a phasic content fus-ing module and a directional distribution consistency loss to prevent overfitting and maintain content consistency.
Specifically, we first design a phasic training strategy with phasic content fusion module, which integrates content in-formation into the network and explicitly decomposes the model training into two stages: learn content and style infor-mation when t is large, and learn local details in the target domain when t is small, preventing our model from con-fusion between content and target-domain local details ef-fectively. Then, with a deep analysis on existing few-shot losses [20, 31], we propose a novel directional distribution consistency loss which can avoid the distribution rotation problem during training and better keep the structure of generated distribution, improving the training stability, ef-ficiency and solving the overfitting problem. Finally, we design a cross-domain structure guidance strategy to fur-ther integrate structural information during inference time, resulting in improved performance in both structure preser-vation and domain adaptation.
Extensive qualitative and quantitative experiments show that our model outperforms the state-of-the-art few-shot generative models in both content preservation and domain adaptation. Moreover, through theoretical analysis, we also prove the effectiveness of our directional distribution con-sistency loss and the cross-domain structure guidance strat-egy in terms of distribution and structure maintenance.
Our contributions can be summarized into three aspects:
• We propose a novel phasic content fusing few-shot dif-fusion model, which learns content and style informa-tion when t is large, and learns local details when t is small. By incorporating the phasic content fusion module, our model excels in both content preservation and domain adaptation.
• We design a novel directional distribution consistency loss, which can effectively avoid the distribution rota-tion problem during training and better keep the struc-ture of generated distribution. It has been theoretically and experimentally proved that the directional distri-bution consistency loss can maintain the structure of generated distribution in a more effective and stable way than the state-of-the-art methods.
• An iterative cross-domain structure guidance strategy is proposed to further integrate structural information during inference time, and has been demonstrated to achieve superior structure preserving performance in domain translation. 2.