Abstract
Point cloud registration is essential for many applica-tions. However, existing real datasets require extremely tedious and costly annotations, yet may not provide accu-rate camera poses. For the synthetic datasets, they are mainly object- level, so the trained models may not gen-eralize well to real scenes. We design SIRA- PCR, a new approach to 3D point cloud registration. First, we build a synthetic scene- level 3D registration dataset, specifically designed with physically- based and random strategies to arrange diverse objects. Second, we account for varia-tions in different sensing mechanisms and layout place-ments, then formulate a sim- to- real adaptation framework with an adaptive re- sample module to simulate patterns in real point clouds. To our best knowledge, this is the first work that explores sim- to- real adaptation for point cloud registration. Extensive experiments show the SOTA per-formance of SIRA- PCR on widely- used indoor and out-door datasets. The code and dataset will be released on https://github.com/Chen- Suyi/SIRA_Pytorch. 1.

Introduction 3D point cloud registration is a fundamental task, re-ceiving incredible attention from both the industry and academia, due to its wide applications in robotics [19, 42, 39], graphics [85], computer vision [14, 27], etc. Given a partially overlapping point cloud pair, the algorithm is re-quired to predict a 3D rigid transformation to align them.
Recent data-driven deep-learning-based methods have attained remarkable success in indoor scenarios [6, 12, 13, 29, 80, 79]. To support the training, commonly-used datasets can be divided into two categories: (i) object level, e.g., ModelNet40 [70] and ShapeNet [10], and (ii) indoor-scene level, e.g., 3DMatch [81]. However, the model
*Equal contribution.
†Corresponding authors. 2Department of Computer Science and Engineering; Institute of Medi-cal Intelligence and XR (IMIXR).
Figure 1. We construct the first large-scale scene-level synthetic dataset for point cloud registration, called FlyingShapes, by in-serting objects into simple indoor scenes through physically-based and random strategies. Then, a generative-based pipeline, named
SIRA, is designed for sim-to-real adaptation. Qualitative results show the performance improvement of our approach. trained on the synthetic object-level dataset can hardly gen-eralize to real-world indoor scenarios, since the object data has strong shape priors while the geometric structures in in-door scenes are much more complex and diverse. Though directly adopting real-captured datasets can produce sat-isfying performance, collecting a large amount of data is highly time-consuming. Also, obtaining accurate ground-truth labels is expensive, since the estimated camera poses are prone to errors, so human annotations are needed.
A straightforward avenue to overcome such data scarcity is to utilize simulation data, in which both the data collec-tion and annotation can be done automatically. To leverage existing synthetic 3D indoor scene-level datasets to form the training data for point cloud registration, there are mul-tiple options, e.g., SUNCG [60], OpenRooms [40], Struc-tured3D [84], and 3D-FRONT [21]. Specifically, SUNCG has left an apparent void in the community. OpenRooms and Structured3D mainly aim to provide photo-realistic
scene images, without providing CAD models. Though 3D-FRONT provides CAD models of rooms and a portion of the furniture, its layouts are relatively simple and more reg-ular than the real ones. To sum up, using existing synthetic data to train a model for point cloud registration has two main challenges: (i) simulated scenes lack complicated ge-ometric structures, since they only contain limited varieties of furniture. A robust feature descriptor and precise fea-ture matching heavily rely on diverse structures in data; and (ii) the point pattern gap, owing to different sensing mech-anisms. Simulated scenes tend to contain smooth surfaces with regularly-distributed points, while real scenes exhibit noise and more irregular patterns. Particularly, the feature descriptor is sensitive to the low-level point distribution.
To address challenge (i), inspired by FlowNet [17], we build the first large-scale indoor synthetic dataset named
FlyingShapes, on the simulated dataset 3D-FRONT. Specif-ically, we enrich the local geometric structures by utilizing the object-level ShapeNet dataset as an additional source.
We design strategies to randomly arrange objects from
ShapeNet on the surfaces of some furniture and in the mid-air of the 3D-FRONT rooms. For challenge (ii), we develop a generative sim-to-real adaptation pipeline, named SIRA.
In particular, we design an Adaptive Re-sample Module (ARM) and insert it after different layers of the generator to adaptively adjust point positions in multiple ranges. Lastly, we take the generated point clouds to train the point cloud registration network.
Our main contributions are three-fold: the first
• We construct large-scale indoor synthetic dataset, named FlyingShapes, on the simulated dataset 3D-FRONT for 3D point cloud registration.
• We design a generative sim-to-real adaptation pipeline named SIRA, with an adaptive re-sample module for-mulated to mitigate the low-level point cloud distribu-tion domain gap. To our best knowledge, this is the first work that exploits domain adaptation strategies to enhance the 3D point cloud registration task.
• Extensive qualitative and quantitative comparisons on both indoor and outdoor datasets show the state-of-the-art performance of our method. 2.