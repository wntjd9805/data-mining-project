Abstract
Understanding point clouds captured from the real-world is challenging due to shifts in data distribution caused by varying object scales, sensor angles, and self-occlusion. Prior works have addressed this issue by com-bining recent learning principles such as self-supervised learning, self-training, and adversarial training, which leads to significant computational overhead. Toward suc-cinct yet powerful domain adaptation for point clouds, we revisit the unique challenges of point cloud data under do-main shift scenarios and discover the importance of the global geometry of source data and trends of target pseudo-labels biased to the source label distribution. Motivated by our observations, we propose an adapter-guided do-main adaptation method, PC-Adapter, that preserves the global shape information of the source domain using an attention-based adapter, while learning the local charac-teristics of the target domain via another adapter equipped with graph convolution. Additionally, we propose a novel pseudo-labeling strategy resilient to the classifier bias by adjusting confidence scores using their class-wise confi-dence distributions to consider relative confidences. Our method demonstrates superiority over baselines on vari-ous domain shift settings in benchmark datasets - PointDA,
GraspNetPC, and PointSegDA. 1.

Introduction 3D vision has gained considerable attention as an im-mense amount of 3D data is collected by LiDAR sensors or depth-sensing cameras in real-world applications such as autonomous vehicles, surveillance systems, and drones.
In recent years, deep neural networks [15, 16, 22, 28, 17] have become a de facto approach for understanding un-ordered 3D point sets (i.e. point cloud data). However, for the case of point clouds in the wild, deep models inevitably encounter distributional shift - also known as domain shift
- due to the different object scales, point density, angle of sensor, object occlusion, etc. This problem makes the mod-els perform poorly outside the laboratory.
Unsupervised domain adaptation (UDA) is a represen-tative solution to tackle the domain shift problem, which targets to transfer the knowledge from a labeled source do-main to an unlabeled target domain [24, 8, 10]. UDA meth-ods generally endeavor to reduce the discrepancy of two do-mains in representation space, so that a classifier trained on the label-rich source domain generalizes well on the target domain. Such standard UDA strategies would be attractive options even for point cloud data, since collecting synthetic point clouds can be simply done by sampling points from the 3D CAD models whereas annotating the enormous real 3D data is cumbersome and time-consuming. Hence, if a
UDA method can successfully transfer the knowledge from synthetic point clouds (source domain) to real point clouds (target domain), it will enable the models to significantly boost performances over a broad range of 3D vision tasks.
Therefore, numerous studies considering the innate char-acteristic of point cloud data have recently been proposed for domain adaptation [18, 1, 29, 5, 20, 12, 19]. Most of them jointly exploit components such as self-supervised learning, adversarial training, data augmentation, and self-training to squeeze the best adaptation performances. Es-pecially, recent works [29, 5, 12] focus on designing at least two self-supervised learning tasks by deforming point clouds; for example, reconstructing the deformed parts or predicting the extent of specific distortion. Although these methods have shown successful results, due to their exces-sive computations and memory access, these frameworks are difficult to deploy in real-world systems where we do not have sufficient computing resources. These situations raise questions regarding the race of performance-oriented design and call for a pivot towards a succinct yet effective strategy toward a practical domain adaptation framework.
Toward this, we reconsider the individual efficacy of dif-ferent types of knowledge for domain adaptation, especially focusing on which knowledge of the source benefits to be transferred, and suggest two design philosophies for a point cloud-specific domain adaptation framework. We first com-pare the value of knowledge in terms of global geometry and local structure to determine which knowledge would be more beneficial under domain shift scenarios. Drawing on our observations, we argue the necessity of transferring the shape information of the source domain during the adap-tation phase. Secondly, we observe that pseudo-labels are highly dependent on the label distribution of the source. To obtain unbiased pseudo-labels for target data, we suggest that the label bias induced from the knowledge of source label distribution should be considered in selecting pseudo-labels as there is no guarantee that the label distribution of the source domain would match that of the target domain.
Inspired by the prior insights, we introduce Point Cloud
Adapter (PC-Adapter), an adapter-based domain adapta-tion framework that can efficiently learn feature transfor-mation to adapt local spatial structures of the target do-main while preserving the knowledge of global geometry acquired from the source domain. Our method exploits two adapters, a global shape-aware adapter and a locality-aware adapter, both of which consist of one simple block. Our global shape-aware adapter learns implicit shape informa-tion of the source domain using a proposed relative posi-tional encoding and then transfers this knowledge to tar-get point clouds. To preserve the source geometry infor-mation during the adaptation process, the parameters are weakly updated when training target point clouds. Mean-while, the locality-aware adapter actively learns the target domain-specific local structures using graph neural network operations, which is only updated by target point clouds.
In other words, the local structure adapter solely provides room for feature transformation to adapt to the target do-main. After passing the entire path of the model including adapters, target point clouds are trained via pseudo-labels.
To avoid pseudo-labels being selected relying on the label distribution of the source domain, we propose a simple yet novel pseudo-label correction strategy. Our approach recti-fies pseudo-labels based on their percentile ranks from ap-proximated class-wise confidence distributions, taking into account their relative confidences.
In summary, our contribution is threefold:
• We present design philosophies to promote succinct yet effective domain adaptation on point cloud data, concentrated on which knowledge from the source do-main has to be transferred.
• We propose a tailored framework for these design prin-ciples that preserves global shape knowledge of the source via an attention-based adapter while providing room for target-specific feature transformation through a graph convolution-based adapter. We also devise a reliable pseudo-labeling method that adjusts class-wise confidence with the guidance of its percentile on confidence distribution. Note that our method does not resort to any extra sub-tasks or adversarial training.
• Extensive experiments show that our PC-Adapter brings significant performance gain over self-training and adversarial domain alignment baselines, and even achieves state-of-the-art performances when combined with auxiliary self-supervised learning tasks. 2.