Abstract
Domain adaptation (DA) aims to transfer knowledge from a label-rich source domain to a related but label-scarce target domain. Recently, increasing research has focused on exploring data structure of the target domain.
In light of the recent success of Instance Discrimination
Contrastive (IDCo) loss in self-supervised learning, we try directly applying it to domain adaptation tasks. However, the improvement is very limited, which motivates us to re-think its underlying limitations for domain adaptation tasks.
An intuitive limitation is that a pair of samples belonging to the same class could be treated as negatives. Here we argue that using low-confidence samples to construct positive and negative pairs can alleviate this issue and is more suitable for IDCo loss. Another limitation is that IDCo loss cannot capture enough semantic information. We address this by introducing domain-invariant and accurate semantic infor-mation from classifier weights and input data. Specifically, we propose a class relationship enhanced features. It uses probability weighted class prototpyes as the input features of IDCo loss, which can implicitly transfer the domain-invariant class relationship. We further propose a target-dominated cross-domain mixup that can incorporate accu-rate semantic information from the source domain. We eval-uate the proposed method in unsupervised DA and other
DA settings, and extensive experimental results reveal that our method can make IDCo loss more effective and achieve state-of-the-art performance.1 1.

Introduction
Deep neural networks have shown considerable effec-tiveness in a variety of machine learning challenges [29, 5, 56]. However, the impressive performance gain heavily
*Corresponding author 1Code is available at https://github.com/zhyx12/EIDCo
Figure 1. Illustration of our proposed method. The bottom left rep-resents the target-domain feature distribution during training. The bottom right is the feature distribution obtained by our method.
The upper part is our proposed effective instance discrimination contrastive loss, which contains three key designs. Best viewed in color. relies on massive well-labeled training data. Additionally, manually annotating sufficient training data is often time and expense prohibitive in reality. Besides, another disad-vantage of traditional deep learning is its inability to gener-alize to new datasets due to the domain shift problem [2, 1].
Domain Adaptation (DA) addresses this issue by utilizing the knowledge of a label-rich source domain to assist the learning in a related but label-scarce target domain.
The most popular way to deal with domain shift is to learn domain-invariant representations. We can roughly classify these DA approaches as either discrepancy metric-based methods [45, 83] or adversarial-based methods [72, 42, 9]. Recently, there have been more methods exploring the inherent structures of unlabeled target domains, such as self-training through pseudo labels [15, 101, 27, 43] and aligning prototypes across domains [25, 95]. The majority of them rely on trustworthy samples selected by some crite-ria, such as probability [52, 3] and sample ratio [101]. This can create reliable pseudo labels or prototypes, leading to better discriminability on the target domain. However, this
would lead to a suboptimal transferability since the trust-worthy samples are more biased to source domain samples and meanwhile less confident samples are not well learned.
Recently, Instance Discrimination Contrastive (IDCo) loss [19, 6] has achieved great success in self-supervised learning. It regards different views of the same image as positive pairs and pulls them togher. All other images are negative samples and are pushed away from the query sam-ple. Inspired by this, a natural idea is to introduce IDCo loss into the unlabeled target domain, considering no class labels are needed. However, when directly applying IDCo loss in feature space, we observed that only a slight improve-ment was gained. We conjecture that it is caused by two main factors. Firstly, there exists category collision in IDCo loss [91, 26]. That is, two instances, even belonging to the same category, are considered negative pairs if they origi-nate from different samples, and their similarity will be re-duced. Secondly, with little category priors, the traditional
IDCo loss learn rich low-level features without encoding enough high-level semantic informantion [61, 71, 21]. This is suboptimal for many visual recognition tasks that require discriminative semantic features.
Existing work improves IDCo loss by selecting more informative positive and negative samples, i.e., integrating category information [21] or resorting to the nearest neigh-bors [14, 90]. Although the limitations can be partially al-leviated, the selection of informative samples are compli-cated. Differently, we focus on exploring a pure and effec-tive IDCo loss for domain adaptation tasks.
For the first limitation, we argue that category collision cannot be completely avoided due to lack of accurate la-bels. However, considering the push away process between the query sample and negative samples, the contributions of different negative samples are not equal [74]. The closer negative sample contributes more to the push away pro-cess. Based on this, we find that low-confidence samples are more suitable for IDCo loss. Specifically, if we draw both positive and negative samples from low-confidence ones as in Figure 1 upper middle, the closer negative sam-ples will more likely belong to different classes with the query sample. With this simple design, category collision can be greatly alleviated. More importantly, low-confidence sample based IDCo loss is complementary to existing self-training or category contrastive methods, which rely more on high-confidence samples.
For the second limitation, it is necessary to explicitly in-volve semantic information into IDCo loss. We solve this by introducing domain-invariant and accurate semantic in-formation using classifier weights and input data. On the one hand, the classifier weights can be regarded as class pro-totypes. Instead of using original features, we propose class relationship enhanced features where the classifier proto-types is weighted by predicted probability. Through this re-represented features, the domain-invariant class relation-ship can be implicitly embedded when computing the sim-ilarity of two samples. Specifically, the class relationship is represented by cosine similarities matrix A of the classi-fier weights, and the similarity of two samples can be rep-resented as the sum of A weighted outer product of two probabilities. In this way, the class relationship can be bet-ter maintained. On the other hand, the source images con-tain accurate semantic information. We propose to combine
Mixup [93] with IDCo loss. The model is encouraged to behave linearly across the source and target domains during the instance discrimination process. In such a case, it is still crucial to guarantee the low-confidence of mixed samples according to the above analysis. To this end, we propose a target-dominated mixup where the low-confidence target samples are given a higher weight than the source samples.
By combining all three designs, the IDCo loss can work well, and features of low-confidence target samples are bet-ter learned.
Our contributions are summarized as follows:
• We propose a pure and effective IDCo loss in domain adaptation for image classification. Here two main limitations are considered and can be greatly allevi-ated.
• We propose to use only low-confidence samples in
IDCo loss to alleviate category collision. Further-more, we propose class relationship enhanced features and target-dominated cross-domain mixup to encode domain-invariant and accurate semantic information.
• We conducted extensive experiments on multiple DA benchmarks, and the results reveal that our proposed method achieves the state-of-the-art performance. 2.