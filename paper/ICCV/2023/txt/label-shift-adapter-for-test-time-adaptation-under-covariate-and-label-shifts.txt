Abstract
Test-time adaptation (TTA) aims to adapt a pre-trained model to the target domain in a batch-by-batch manner dur-ing inference. While label distributions often exhibit im-balances in real-world scenarios, most previous TTA ap-proaches typically assume that both source and target do-main datasets have balanced label distribution. Due to the fact that certain classes appear more frequently in certain domains (e.g., buildings in cities, trees in forests), it is natu-ral that the label distribution shifts as the domain changes.
However, we discover that the majority of existing TTA methods fail to address the coexistence of covariate and la-bel shifts. To tackle this challenge, we propose a novel label shift adapter that can be incorporated into existing TTA ap-proaches to deal with label shifts during the TTA process effectively. Specifically, we estimate the label distribution of the target domain to feed it into the label shift adapter.
Subsequently, the label shift adapter produces optimal pa-rameters for target label distribution. By predicting only the parameters for a part of the pre-trained source model, our approach is computationally efficient and can be eas-ily applied, regardless of the model architectures. Through extensive experiments, we demonstrate that integrating our strategy with TTA approaches leads to substantial perfor-mance improvements under the joint presence of label and covariate shifts. 1.

Introduction
Despite the recent remarkable improvement of deep neu-ral networks in various applications, the models still suffer from distribution shifts between source distribution and tar-get distribution. One type of distribution shift, known as covariate shift, occurs when the target distribution pt(x) differs from the source distribution ps(x). In autonomous driving, for instance, models may degrade significantly dur-ing testing due to ambient factors such as weather and lo-cation. To design the models robust to covariate shifts, un-*Qualcomm AI Research is an initiative of Qualcomm Technologies,
Inc.
Figure 1. We consider the test-time adaptation scenario, when co-variate and label shifts occur simultaneously. After deploying the pre-trained model, the model is adapted to the target domain.
However, existing methods often suffer from the coexistence of covariate and label shifts. Employing our method enables online adaptation under shifted target label distributions. supervised domain adaptation literature [9, 10, 23, 19] has explored the transfer of knowledge learned from labeled source data to unlabeled target data.
To be more practical in real-world scenarios, test-time adaptation (TTA) algorithms [46] have emerged to enhance practicality in real-world scenarios by adapting deep neu-ral networks to the target domain during inference. Specif-ically, TTA approaches optimize the model parameters batch-by-batch using unlabeled test data, avoiding addi-tional labeling costs. Previous TTA studies have mitigated the performance degradation caused by covariate shift by enhancing normalization statistics [41, 11, 24], optimizing model parameters with entropy minimization [46, 35], or utilizing pseudo labels [20].
Although the natural data encountered in practice often exhibits long-tailed label distribution, most previous TTA methods assume that the model is trained on class-balanced data. This assumption overlooks another type of distribu-tion shift, known as label shift, in which label distribu-tion varies between source ps(y) and target pt(y). Label shift has been studied extensively in the long-tailed recog-nition literature [18, 6, 8, 15]. Considering only one type
input into the label shift adapter during inference. More-over, our proposed method can be easily integrated with
TTA methods such as TENT [46] and IABN [11] to adapt the model to the target domain. Combining TTA approaches with the proposed label shift adapter enables robust model adaptation to the target domain, even in the presence of co-variate and label shifts simultaneously. Through extensive experiments, we demonstrate that our method outperforms the existing TTA methods when both source and target do-main datasets have class-imbalanced label distributions.
In summary, the main contributions are as follows:
• We introduce a novel label shift adapter that produces the optimal parameters according to the label distribu-tion. By utilizing the label shift adapter, we can de-velop a robust TTA algorithm that can handle both co-variate and label shifts simultaneously.
• Our approach is easily applicable to any model regard-less of the model architecture and pre-training process.
It can be simply integrated with other TTA algorithms.
• Through extensive experiments on six benchmarks, we demonstrate that our method enhances the perfor-mance significantly when source and target domain datasets have class-imbalanced label distributions. 2.