Abstract
Understanding and analyzing animal behavior is in-creasingly essential to protect endangered animal species.
However, the application of advanced computer vision tech-niques in this regard is minimal, which boils down to lack-ing large and diverse datasets for training deep models. To break the deadlock, we present LoTE-Animal, a large-scale endangered animal dataset collected over 12 years, to fos-ter the application of deep learning in rare species conser-vation. The collected data contains vast variations such as ecological seasons, weather conditions, periods, view-points, and habitat scenes. So far, we retrieved at least 500K videos and 1.2 million images. Specifically, we se-lected and annotated 11 endangered animals for behavior understanding, including 10K video sequences for the ac-tion recognition task, 28K images for object detection, in-stance segmentation, and pose estimation tasks.
In addi-tion, we gathered 7K web images of the same species as source domain data for the domain adaptation task. We provide evaluation results of representative vision under-standing approaches and cross-domain experiments. LoTE-Animal dataset would facilitate the community to research more advanced machine learning models and explore new tasks to aid endangered animal conservation. Our dataset will be released with the paper. Our dataset can be found at https://LoTE-Animal.github.io 1.

Introduction
Protecting endangered wildlife is becoming increasingly challenging as global biodiversity declines [16]. Accu-rate information about wild animals is crucial for imple-menting effective conservation measures [9, 68]. Vari-ous techniques have been developed to monitor wildlife
*These authors contribute equally to this work.
â€ Corresponding authors: Bochuan Zheng, Jifeng Ning, Jindong Zhang.
[62, 38, 31, 52, 4, 60, 34], but gathering reliable informa-tion remains difficult [3]. Endangered animals are scarce and wary, making it hard to track their movements [68].
And wildlife is often aggressive, making it impossible to implant sensors [71, 61]. Additionally, human interference could disturb animal behavior, causing data collection to de-viate from natural conditions [71, 61].
Camera trapping is an effective solution to these prob-lems, allowing for the collection of wildlife image data while ensuring animal welfare [38, 56]. However, camera trap data is vast and contains a significant amount of irrele-vant information. Manual sorting and analysis are not only inefficient but also imprecise [38, 26, 62, 66].
Computer vision technology can automatically extract and analyze image information, relying on robust deep learning models for accurate and efficient results [14, 70, 54]. For this reason, it is essential to establish comprehen-sive large-scale datasets to provide deep learning algorithms with training and testing data [14, 70, 54]. However, exist-ing datasets for animal protection are limited in the follow-ing ways: (1) Shortage of wildlife data. Current datasets focus on common domestic or zoo animals [42, 2, 11, 14, 7, 50, 76], whose behaviors are influenced by human interaction, and they may not exhibit natural behavior in the wild. Because wildlife data is scarce, these datasets lack the potential to develop cross-domain models. (2) Short time span and discontinuous space. Some datasets are collected from scattered network images [79], short-term monitoring data [54], or even synthetic images
[54]. These data cannot reflect the long-term living status of wild animals. Continuous spatiotemporal data is required to study the specific habits and migration patterns of endan-gered animals, while discontinuous data is also inadequate for developing complex models related to wildlife growth patterns [80, 48, 37]. (3) Limited tasks for testing. Most datasets have only
one or two data annotations which limit their usefulness for multitask training. Furthermore, they lack environmental information, such as day and night, weather, and location.
This makes it difficult to develop accurate ecological pre-diction models using these datasets [19, 74, 69].
To address these issues, we present LoTE-animal, a long-term and continuous dataset for endangered animal be-havior understanding. LoTE-animal has the following three features: (1) Abundant wildlife data in natural habitats. We cu-rated data of 11 endangered wildlife species from the Wo-long National Nature Reserve, all of which were captured by trap cameras with minimal human interference. The dataset consists of 10k video sequences and 28k images.
We also created a subset of 7k web images that can be used to enhance the generalization performance of deep learning models. (2) Long temporal span and spatial continuity. We collected the raw data of LoTE-animal dataset by monitor-ing with infrared-triggered trap cameras for 12 years, during which the cameras were fixed at specific locations with clear geographic information. The recorded data includes videos and images of the same population at different stages in the same location, providing valuable information for wildlife research. It is worth noting that the monitoring is still on-going. (3) Rich scene and annotation information. LoTE-animal dataset provides annotated information on different weather conditions, seasons, and habitat environments, and records images of wildlife in different growth stages under these conditions. We annotated the images with bounding boxes, segmentation masks, skeletal keypoints, and action labels, making them suitable for various computer vision tasks.
In this paper, we trained and tested representative com-puter vision models based on the wild and web subsets. We also evaluated the generalization performance of the mod-els trained on the web subset. Our results can serve as a reference for the development of deep learning algorithms. 2.