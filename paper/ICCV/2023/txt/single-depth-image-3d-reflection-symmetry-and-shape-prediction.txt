Abstract
In this paper, we present Iterative Symmetry Comple-tion Network (ISCNet), a single depth-image shape comple-tion method that exploits reflective symmetry cues to obtain more detailed shapes. The efficacy of single depth-image shape completion methods is often sensitive to the accuracy of the symmetry plane. ISCNet therefore jointly estimates the symmetry plane and shape completion iteratively; more complete shapes contribute to more robust symmetry plane estimates and vice versa. Furthermore, our shape comple-tion method operates in the image domain, enabling more efficient high-resolution, detailed geometry reconstruction.
We perform the shape completion from pairs of viewpoints, reflected across the symmetry plane, predicted by a rein-forcement learning agent to improve robustness and to si-multaneously explicitly leverage symmetry. We demonstrate the effectiveness of ISCNet on a variety of object categories on both synthetic and real-scanned datasets. 1.

Introduction
Symmetry is an intrinsic geometric property present in the vast majority of man-made and natural objects [12, 17], and which has been exploited to improve the efficacy of ap-plications such as shape matching [12], segmentation [13], object retrieval [8], and robotic grasping [34].
In this paper, we aim to leverage symmetry as an aid for the completion of shapes from partial observations [23, 24, 28]. Recently, Yao et al. [39] presented Front2Back, a framework for 3D shape reconstruction from a single RGB image. A key observation in Front2Back is that a (nearly) complete 3D model can be effectively described by a pair of 2.5D visible surface images taken from opposite views (i.e., front and back views). Based on this observation,
Front2Back completes a shape by synthesizing a back view using a global 3D reflective symmetry plane from a given front view. However, the reconstruction quality is signifi-cantly affected by the input front view angle (Figure 1(d)).
Moreover, Front2Back assumes the availability of a ‘per-fect’ symmetry plane, which in practice is challenging to obtain from partial observations [21, 22, 45].
*Co-corresponding authors. (a) Input Depth Map &
Observed Surface (b) PoinTr [40] (c) IF-Net [3] (d) Front2Back [39] (e) Ours (f) Ground Truth
Figure 1. ISCNet more efficiently leverages symmetry cues for robust shape completion from a single depth image compared to prior methods.
We present ISCNet (Iterative Shape Completion Net-work), a single depth-image shape completion method that explicitly leverages symmetry cues. Our key insight is that symmetry detection and symmetry-based shape completion are complementary tasks that can provide constructive cues to the other task. Symmetry detection can help shape com-pletion by providing object-centric information about miss-ing geometrical features, and shape completion can provide more robust symmetry cues by filling in missing geometry.
Departing from existing work [33] that assumes an ideal prediction of the symmetry plane, ISCNet iteratively refines the symmetry plane and the reconstructed shape jointly.
Furthermore, unlike Front2Back [39], ISCNet does not rely on the initial input viewpoint to a-priori fix the synthetic back view camera position but instead leverages a trained reinforcement learning (RL) policy to select optimal pairs of reflection viewpoints at each iteration. We empirically found that predetermining the viewpoints is less effective than RL-based viewpoint selection which can more effec-tively deal with the dynamic shape of a partial point cloud during the refinement process.
Specifically, ISCNet takes as input a single depth im-age and reprojects it to an incomplete point cloud. Instead of explicitly detecting a symmetry plane, we estimate the pose [30] that aligns the symmetry plane to the X-Y plane.
Based on the current estimate of the point cloud and sym-metry aligning pose, an RL agent determines a pair of re-flection viewpoints, reflected across the symmetry plane, for extracting a pair of partial depth and normal maps that are subsequently repaired using a novel 2D inpainting module.
By directly working on depth image pairs, our method is independent of the size of the point cloud, and it can lever-age geometry information from the symmetric counter view.
However, because the virtual depth images are reprojections that differ from the input view, not all reprojected points are valid (e.g., the backside of points visible through a ‘hole’).
Therefore, we first identify reliable pixels before perform-ing depth inpainting in the projected image domain. Fi-nally, we reproject the inpainted maps back to 3D and up-date the point cloud. We progressively refine the point cloud by alternating between estimating reflection viewpoints and completing the point cloud for 20 iterations, updating the symmetry plane every 4th iteration, to balance efficiency versus efficacy. When updating the symmetry plane, we
‘reset’ the point cloud to its initial state to mitigate the im-pact of prior inaccurate symmetry plane estimations on the shape completion.
We validate that ISCNet produces more accurate shape completions than existing methods (Figure 1) and confirm the contribution of each component in our model via a thor-ough ablation study. In summary, our contributions are: 1) a novel robust joint symmetry-detection / shape completion method; 2) a symmetric viewpoint-based 3D shape comple-tion method for detailed high-resolution shape reconstruc-tion; and 3) a reinforcement learning-based optimal reflec-tion viewpoint selection solution for progressive shape com-pletion. 2.