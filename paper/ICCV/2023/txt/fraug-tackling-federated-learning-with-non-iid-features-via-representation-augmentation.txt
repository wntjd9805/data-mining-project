Abstract
Federated Learning (FL) is a decentralized machine learning paradigm, in which multiple clients collabora-tively train neural networks without centralizing their lo-cal data, and hence preserve data privacy. However, real-world FL applications usually encounter challenges aris-ing from distribution shifts across the local datasets of in-dividual clients. These shifts may drift the global model aggregation or result in convergence to deflected local op-timum. While existing efforts have addressed distribution shifts in the label space, an equally important challenge re-mains relatively unexplored. This challenge involves situa-tions where the local data of different clients indicate iden-tical label distributions but exhibit divergent feature dis-tributions. This issue can significantly impact the global model performance in the FL framework. In this work, we propose Federated Representation Augmentation (FRAug) to resolve this practical and challenging problem. FRAug optimizes a shared embedding generator to capture client consensus. Its output synthetic embeddings are transformed into client-specific by a locally optimized RTNet to augment the training space of each client. Our empirical evalua-tion on three public benchmarks and a real-world medi-cal dataset demonstrates the effectiveness of the proposed method, which substantially outperforms the current state-of-the-art FL methods for feature distribution shifts, includ-ing PartialFed and FedBN. 1.

Introduction
Federated Learning (FL) is a machine learning paradigm in which a shared model is collaboratively trained using de-centralized data sources. In the classical FL approach, e.g.,
FedAvg [49], the central server obtains the model by it-eratively averaging the optimized model weights uploaded
*Corresponding author from the active clients. FL has the benefit that it does not require direct access to the client local datasets, resulting in improved client-server communication efficiency and en-hanced data confidentiality.
Despite these promising prospects, real-world FL appli-cations encounter practical challenges arising from data het-erogeneity, in which the client local datasets are not inde-pendent and identically distributed (non-IID). Non-IID data from different clients may cause local model drifts during the client update and overfitting to its local objective, mak-ing it challenging to obtain a stable and optimal conver-gence of the aggregated server model [41, 50].
As discussed in [28], data heterogeneity in FL can be cat-egorized into label space heterogeneity and feature space heterogeneity. A variety of methods were developed to tackle problem settings where the client datasets are non-IID in the label space [75, 66]. However, the under-explored problem of feature distribution shift is also prevalent in real-world applications, e.g., in the data collected from differ-ent scanners in clinical centers [10], as well as gathered by different machines in industrial manufacturing plants [39].
Most importantly, although these entities may diagnose the same types of cancers or detect the same types of anomalies, i.e., having the same label distribution, they are not will-ing to share their original data to prevent competitive disad-vantage or reverse engineering. Therefore, we propose an effective and privacy-preserving FL algorithm, i.e., Feder-ated Representation Augmentation (FRAug), to address this practical problem of feature space heterogeneity.
Unlike previous works that generate synthetic samples in the input space [69, 68] or acquire additional public datasets
[44, 17], FRAug applies data augmentation in the low-dimensional feature embedding space, which is more effi-cient and confronts fewer confidentiality threats. Moreover, the proposed augmentation algorithm is especially suitable for FL applications, where collaborative training is often conducted by multiple edge devices (clients) with limited
computational powers and data quantities [49]. Specifically, we first aggregate the consensual knowledge from different clients in the embedding space by training a shared rep-resentation generator, which produces client-agnostic em-beddings. However, solely optimizing the generator might be challenging, given its training representations follow-ing different local client feature distributions. Therefore, a
Representation Transformation Network (RTNet) is locally trained at each client to transform the client-agnostic syn-thetic embeddings into client-specific. Hereby, we aim at aligning the client-agnostic embeddings with the local fea-ture distribution. Finally, the local dataset of each client will be augmented by its client-specific synthetic embeddings.
The proposed method FRAug achieves state-of-the-art results on three benchmark datasets with feature distribution shift, surpassing the concurrent FL methods addressing the same problem, including PartialFed [55] and FedBN [43].
Moreover, the superior performance of FRAug on a medi-cal dataset illustrates its applicability in complex real-world
FL applications. Our contributions can be summarized as follows:
• We propose a novel representation augmentation algo-rithm (FRAug) to address FL with non-IID features.
• We conduct comprehensive experiments on three pub-lic benchmark datasets with feature distribution shifts, in which FRAug achieves SOTA results.
• We verify the maturity and scalability of FRAug on a real-world medical dataset, and further analyze the convergence rate and robustness of FRAug. 2.