Abstract
Unsupervised learning is a challenging task due to the lack of labels. Multiple Object Tracking (MOT), which inevitably suffers from mutual object interference, occlu-sion, etc., is even more difficult without label supervision.
In this paper, we explore the latent consistency of sam-ple features across video frames and propose an Unsu-pervised Contrastive Similarity Learning method, named
UCSL, including three contrast modules: self-contrast, cross-contrast, and ambiguity contrast. Specifically, i) self-contrast uses intra-frame direct and inter-frame indirect contrast to obtain discriminative representations by maxi-mizing self-similarity. ii) Cross-contrast aligns cross- and continuous-frame matching results, mitigating the persis-tent negative effect caused by object occlusion. And iii) am-biguity contrast matches ambiguous objects with each other to further increase the certainty of subsequent object associ-ation through an implicit manner. On existing benchmarks, our method outperforms the existing unsupervised methods using only limited help from ReID head, and even provides higher accuracy than lots of fully supervised methods. 1.

Introduction
As a basic task in computer vision, Multiple Object
Tracking (MOT) is widely applied in a variety of fields, in-cluding robot navigation, intelligent surveillance, and other aspects [36, 33]. Currently, one of the most popular track-ing paradigms is joint detection and re-identification (ReID) embeddings. In the case of supervision, ReID is regarded as a classification task. To keep track of objects, many works
[39, 45] utilize appearance features for object association, where the representation ability of the ReID head will di-rectly affect the accuracy of the object association.
However, due to limitations in various conditions such as labeled datasets, to meet the needs of researchers, there has been a growing requirement to annotate tracking datasets,
*Equal Contribution. †Corresponding Author
Figure 1. Supervised and Unsupervised MOT. In the joint detec-tion and ReID embeddings framework, to obtain discriminative embeddings for tracking, the left branch is a usual method of su-pervised MOT training, i.e., given labels, it is trained as an object classification task. The middle branch is a common method of unsupervised training, i.e., it is processed by clustering, and tar-gets with high similarity are regarded as the same class. The right branch is the proposed method with contrast similarity learning to improve the similarity of the same objects without label informa-tion. which is costly and time-consuming. Therefore, unsuper-vised learning of visual representation has attracted great at-tention in tracking. Some works [35, 30] have demonstrated that training the network in the real direction can also be done even without ground truth. Some works [5, 6] directly use ReID features to cluster objects with high similarity
into the same class, then generate pseudo-labels to train the network, as shown in the middle branch of Figure 1. But these cluster-based methods are easy to accumulate errors during the training process. In contrast, we consider using an Unsupervised Contrastive Similarity Learning (UCSL) to train the ReID branch without generating pseudo-labels, as shown in the right branch of Figure 1.
As a video task, the objects in MOT are always chang-ing over time, which leads to inevitable problems of mutual occlusion between objects and objects, and between objects and non-objects, as well as the disappearance of old objects and the appearance of new ones. Occluded objects are not represented consistently from frame to frame due to addi-tional interference features. Lost and emerging objects the-oretically cannot be matched with other objects, and they are almost always negative for the current association stage.
Thus, it is difficult for the model to determine whether arbi-trary two objects are the same or not. In supervised cases,
ID labels can be used to make the training more explicitly directed, while in the unsupervised case, the dual limitation of unlabeling and inherent problems makes unsupervised
MOT even more challenging. So we manage to find poten-tial connections between objects to determine if the objects are identical.
In this paper, we propose an Unsupervised Contrastive
Similarity Learning (UCSL) method to solve the inherent object association problems of unsupervised MOT. Specifi-cally, UCSL consists of three modules, self-contrast, cross-contrast and ambiguity contrast, designed to address differ-ent issues respectively. For the self-contrast, we first match between objects within frames and between objects in ad-jacent frames. Correspondingly, we get the direct and in-direct matching results of the intra-frame objects. Then we maximize the matching probability of self-to-self to maxi-mize the similarity of the same objects. For cross-contrast, considering theoretically the cross-frame matching results should be consistent with the final results of continuous matching, we improve the similarity of the occluded objects by making these two matching results as close as possible.
For ambiguity contrast, we match between ambiguous ob-jects, mainly containing occluded, lost, and emerging ob-jects whose final similarity is generally low, to further de-termine the object identity. Our proposed method is sim-ple but effective, which achieves outstanding performance by utilizing only the ReID embeddings without adding any additional branch such as the occlusion handling or optical-flow based cue to the detection branch.
We implement the method on the basis of FairMOT [45] using the pre-trained model on the COCO dataset [19]. Our experiments on the MOT15 [15], MOT17 [24] and MOT20
[7] datasets are conducted to evaluate the effectiveness of the proposed method. The performance of our unsupervised approach is comparable with, or outperforms, that of some supervised methods using expensive annotations.
Overall, our contributions are summarized as follows:
• We propose a contrastive similarity learning method for unsupervised MOT task, which pursues latent ob-ject consistency based only on the sample features in the ReID module given without the ID information.
• We design three useful modules to model associa-tions between objects in different cases. To elab-orate, self-contrast module matches intra-frame ob-jects, cross-contrast module associates cross-frame ob-jects, and ambiguity contrast module deals with those hard/corner cases (e.g., occluded objects, lost objects, etc.)
• Experiments on MOT15[15], MOT17[24] and MOT20
[7] demonstrate the effectiveness of the proposed
UCSL method. As an unsupervised method, UCSL outperforms state-of-the-art unsupervised MOT meth-ods and even achieves similar performance as the fully supervised MOT methods. 2.