Abstract
The challenge in sourcing attribution for forgery faces has gained widespread attention due to the rapid develop-ment of generative techniques. While many recent works have taken essential steps on GAN-generated faces, more threatening attacks related to identity swapping or expres-sion transferring are still overlooked. And the forgery traces hidden in unknown attacks from the open-world unla-beled faces still remain under-explored. To push the related frontier research, we introduce a new benchmark called
Open-World DeepFake Attribution (OW-DFA), which aims to evaluate attribution performance against various types of fake faces under open-world scenarios. Meanwhile, we pro-pose a novel framework named Contrastive Pseudo Learn-ing (CPL) for the OW-DFA task through 1) introducing a
Global-Local Voting module to guide the feature alignment of forged faces with different manipulated regions, 2) de-signing a Confidence-based Soft Pseudo-label strategy to mitigate the pseudo-noise caused by similar methods in un-labeled set. In addition, we extend the CPL framework with a multi-stage paradigm that leverages pre-train technique and iterative learning to further enhance traceability per-formance. Extensive experiments verify the superiority of our proposed method on the OW-DFA and also demonstrate the interpretability of deepfake attribution task and its im-pact on improving the security of deepfake detection area. 1.

Introduction
With the rapid development of generative technologies such as Deepfakes [2], the malicious usage of fake content on social media has raised public concerns about face se-curity and privacy. Dedicated research efforts [26, 48, 56] have been made in the real/fake detection task in recent years. Nonetheless, with its distinctive merits, DeepFake
Attribution (DFA), known as identifying the source model
*Equal contribution. This work was done when Zhimin Sun was a re-search intern at Tencent YouTu Lab.
†Corresponding authors.
Figure 1. In the OW-DFA setting, the unlabeled dataset may con-tain attacks that have never been encountered in the labeled set.
A feasible model should attribute the known attacks (images with blue border) and assign the unknown attacks (images with red bor-der) to novel classes simultaneously. of fake faces, has also significantly drawn widespread at-tentions [59, 61, 24]. On the one hand, DFA can be used for legal proceedings and provide interpretability to human beings, i.e.“why the face is fake.” On the other hand, with the nature of learning enhanced representation for different attacking types, DFA is also effective to boost the deepfake detection performance [29, 17].
Early approaches of sourcing attribution [59, 61, 24] mostly focus on the GAN-generated images rather than the more realistic and threatening attacks related to iden-tity swapping or expression transferring. Meanwhile, most of them assume a closed scenario where the training set and test set share the same category distributions, which is not applicable to open-world scenarios since new types of forgery attacks emerge immensely. To this end, we intro-duce a new benchmark, Open-World DeepFake Attribution (OW-DFA), as shown in Figure 1. The OW-DFA bench-mark consists of a labeled training dataset and an unlabeled dataset. The labeled dataset contains samples from known classes, while the unlabeled dataset includes samples from both known and unknown classes. More importantly, OW-DFA considers nearly 20 challenging and realistic forgery methods, including 4 widely-used forgery types, namely identity swap [1, 2], expression transfer [5, 49], attribute manipulation [12, 13] and entire face synthesis [32, 34].
The main challenge of OW-DFA is how to utilize unlabeled data in open-world scenes to improve the attribution perfor-mance for both known and unknown forged faces.
The OW-DFA is fundamentally different but closely re-lated to Open-World Semi-Supervised Learning (OW-SSL), where some OW-SSL methods [27, 8, 25] demonstrate ef-fectiveness in learning unknown categories through con-trastive learning or pseudo-labeling strategies. However, since all classes of OW-DFA are face data whose disparity information relies on fine-grained forgery traces [10, 65], these OW-SSL methods that only focus on global informa-tion will be limited in attributing unknown forged faces.
Moreover, Open-world GAN [18] discovers and refines un-seen GANs with iterative algorithms. However, the fin-gerprint assumption relied on may not hold in the fake faces generated by non-GAN methods. Without a semi-supervised learning strategy, the features extracted by this model for different unknown attacks lack distinguishability.
In this paper, we propose a novel framework named Con-trastive Pseudo Learning (CPL), which addresses the above issues from two perspectives: 1) We introduce a Global-Local Voting (GLV) module that guides inter-sample fea-ture alignment by extracting both global and local informa-tion and adaptively highlights different manipulated regions through a spatially enhancing mechanism. By combining global and local similarity, we can filter and group together samples of the same attack type. 2) Besides the inter-sample relation, we also leverage the intra-sample information to enhance the class compactness using the pseudo-labeling technique. A Confidence-based Soft Pseudo-labeling (CSP) mechanism is proposed to mitigate the pseudo-noise in-duced by similar novel attack methods. Moreover, previ-ous research [27, 55] has demonstrated the efficacy of pre-training techniques and iterative learning, so we extend the
CPL framework with a multi-stage paradigm to further im-prove the attribution performance. Finally, extensive ex-perimental results verify the superiority of our method on the OW-DFA benchmark. We also demonstrate the inter-pretability of the deepfake attribution task and its impact on improving the security of the deepfake detection area.
We summarize our contributions as follows: (1) We present a new benchmark called Open-World
DeepFake Attribution (OW-DFA), which aims to evaluate attribution performance against various types of fake faces under open-world scenarios. (2) We propose a novel Contrastive Pseudo Learn-ing (CPL) framework for OW-DFA task through 1) a
Global-Local Voting module to guide the feature alignment of forged faces with different manipulated regions, 2) a
Confidence-based Soft Pseudo-labeling strategy to mitigate pseudo-noise caused by similar methods in unlabeled set. (3) Comprehensive experiments and visualization results demonstrate that our method achieves SOTA performance on OW-DFA. We also show that combining the deepfake at-tribution task with the deepfake detection task leads to bet-ter interpretability and face security. 2.