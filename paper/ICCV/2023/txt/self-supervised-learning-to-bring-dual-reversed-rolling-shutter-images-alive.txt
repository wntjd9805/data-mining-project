Abstract
Modern consumer cameras usually employ the rolling shutter (RS) mechanism, where images are captured by scanning scenes row-by-row, yielding RS distortions for dy-namic scenes. To correct RS distortions, existing meth-ods adopt a fully supervised learning manner, where high framerate global shutter (GS) images should be collected as ground-truth supervision.
In this paper, we propose a
Self-supervised learning framework for Dual reversed RS distortions Correction (SelfDRSC), where a DRSC network can be learned to generate a high framerate GS video only based on dual RS images with reversed distortions. In par-ticular, a bidirectional distortion warping module is pro-posed for reconstructing dual reversed RS images, and then a self-supervised loss can be deployed to train DRSC net-work by enhancing the cycle consistency between input and reconstructed dual reversed RS images. Besides start and end RS scanning time, GS images at arbitrary interme-diate scanning time can also be supervised in SelfDRSC, thus enabling the learned DRSC network to generate a high framerate GS video. Moreover, a simple yet effective self-distillation strategy is introduced in self-supervised loss for mitigating boundary artifacts in generated GS images. On synthetic dataset, SelfDRSC achieves better or compara-ble quantitative metrics in comparison to state-of-the-art methods trained in the full supervision manner. On real-world RS cases, our SelfDRSC can produce high framer-ate GS videos with finer correction textures and better tem-porary consistency. The source code and trained models are made publicly available at https://github.com/ shangwei5/SelfDRSC. 1.

Introduction
Recent years have witnessed an increasing demand for imaging sensors, due to the widespread applications of digital cameras and smartphones. Although the Charge-Coupled Device (CCD) has been the dominant technol-*Corresponding author: rendongweihit@gmail.com. ogy for imaging sensors, it is recently popular that mod-ern consumer cameras choose the Complementary Metal-Oxide Semiconductor (CMOS) as an alternative due to its many merits, e.g., easy integration with image processing pipeline and communication circuits, and low power con-sumption [14]. In CMOS sensors, rolling shutter (RS) scan-ning mechanism is generally deployed to capture images, i.e., each row of CMOS array is exposed in the sequential time, which is different from CCD with global shutter (GS) scanning at one instant. Therefore, RS images suffer from distortions when capturing dynamic scenes, which not only affect human visual perception but also yield performance degradation or even failure in computer vision tasks [2, 13].
To correct RS distortions, pioneering works usually re-construct GS images from a single RS image [20, 32] or multiple consecutive RS images [15, 6], where the latter ones usually have better performance. But consecutive RS images setting is ambiguous [30], e.g., two RS cameras, moving horizontally at the same speed but with different readout time, can produce the same RS images. Most re-cently, a new RS acquisition setting, i.e., dual RS images with reversed scanning directions (see Fig. 1), is proposed in [1, 30] to address this ambiguity. In [1], one GS image is reconstructed from dual RS images with reversed distor-tions, while in [30], Zhong et al. devote efforts to recon-struct high framerate GS videos. Nevertheless, both of them adopt a fully supervised learning manner, i.e., ground-truth
GS supervision is required to learn RS correction networks.
Especially in [30], high framerate GS videos should be col-lected to serve as ground-truth. In the supervised learning manner, it is not easy to collect real-world training samples, while synthetic training samples would yield poor general-ization ability when handling real-world RS cases.
In this paper, we aim ambitiously for the more challeng-ing and practical task, i.e., self-supervised learning to in-vert dual reversed RS images to a high framerate GS video, dubbed SelfDRSC, which to the best of our knowledge is studied for the first time. The primary design philosophy of our SelfDRSC is that latent GS images predicted by the
DRSC network can be used to reconstruct dual RS images with reversed distortions, and then the DRSC network can
Illustration of capturing dual RS images with reversed scanning directions, i.e., top-to-bottom (It2b) and bottom-to-top (Ib2t).
Figure 1.
In this work, we propose the first self-supervised learning method SelfDRSC to correct RS distortions. In comparison to state-of-the-art supervised RS correction methods CVR [7] and IFED [30], our SelfDRSC can generate high framerate GS videos with finer textures and better temporary consistency. The result can be displayed in an animated figure in the arXiv version. be learned by enforcing the cycle consistency between in-put and reconstructed RS images. As shown in Fig. 2, a novel bidirectional warping (BDWarping) module is pro-posed, by which dual reversed RS images can be recon-structed, and then a self-supervised loss can be deployed to train the DRSC network. During training, an intermediate
GS image at arbitrary RS scanning time is predicted, and in our BDWarping module, it can also be used to reconstruct another set of dual RS images, which serve as the extra self-supervision in SelfDRSC. In this way, the predicted GS im-ages at intermediate scanning time can also be supervised, making the learned DRSC network be able to generate high framerate GS videos. Moreover, the DRSC network trained by individual self-supervised loss would yield undesirable boundary artifacts as shown in Fig. 3, and we introduce a self-distillation strategy into self-supervised loss to alleviate this issue, as shown in Fig. 4.
Extensive experiments on synthetic and real-world RS images have been conducted to evaluate our SelfDRSC. Al-though any ground-truth GS supervision is not exploited in our SelfDRSC, it still achieves comparable quantitative metrics on synthetic dataset, in comparison to state-of-the-art supervised RS correction methods. On real-world RS cases, our SelfDRSC can produce high framerate GS videos with finer textures and better temporary consistency. 2.