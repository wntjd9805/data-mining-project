Abstract
Self-supervised learning (SSL) methods targeting scene images have seen a rapid growth recently, and they mostly rely on either a dedicated dense matching mechanism or a costly unsupervised object discovery module. This pa-per shows that instead of hinging on these strenuous opera-tions, quality image representations can be learned by treat-ing scene/multi-label image SSL simply as a multi-label classification problem, which greatly simplifies the learn-ing framework. Specifically, multiple binary pseudo-labels are assigned for each input image by comparing its em-beddings with those in two dictionaries, and the network is optimized using the binary cross entropy loss. The pro-posed method is named Multi-Label Self-supervised learn-ing (MLS). Visualizations qualitatively show that clearly the pseudo-labels by MLS can automatically find semantically similar pseudo-positive pairs across different images to fa-cilitate contrastive learning. MLS learns high quality rep-resentations on MS-COCO and achieves state-of-the-art re-sults on classification, detection and segmentation bench-marks. At the same time, MLS is much simpler than existing methods, making it easier to deploy and for further explo-ration. 1.

Introduction
Self-supervised learning (SSL) methods based on con-trastive learning [4, 3] have facilitated numerous down-stream tasks. Those [16, 6, 14, 13] that target object-centric images (e.g., ImageNet) are already relatively ma-ture, but inventing SSL methods for scene images (e.g.,
MS-COCO [23]) gains popularity recently. Since unlabeled scene images (or multi-label images) are more natural [46] and richer in semantics, various SSL methods [39, 45, 19, 40, 20, 44] have successively emerged.
SSL methods focusing on scene/multi-label images can
*J. Wu is the corresponding author. This paper was partly supported by the National Natural Science Foundation of China under Grant 62276123 and Grant 61921006.
Figure 1. Illustrating our motivation. An image patch cropped from a multi-label image comprises multiple objects. Each object can find similar (‘pos’) and dissimilar (‘neg’) images from a large dictionary. The whole image patch is pulled closer to those posi-tive ones and pushed away from the negatives using a BCE loss.
See Fig. 4 for positives and negatives chosen by our algorithm. be summarized into two categories. One is dense matching, such as DenseCL [39], MaskCo [51] and Self-EMD [24].
They take the features’ locations into account to improve the performance on dense prediction tasks. They mostly differ in how the heuristic matching metric is designed. Another branch of work like SoCo [41] and ORL [46] resort to unsu-pervised object discovery to find local object contents, and learn quality representation with both object- and scene-level semantics. However, they usually involve multi-stage
SSL pretraining on top of expensive box generation [35].
These scene image SSL methods are generally based on the contrastive loss (e.g., InfoNCE [27]), where two ran-domly augmented views of the same image are forced to be close to each other, and optionally push away views from different images. The loss assumes single-label im-ages [27], but the input are in fact multi-label: hence there is a mismatch between the loss and the data. On one hand, it can be difficult for two views randomly cropped from the same scene image to be exactly matched [39, 47]. On the other hand, there is only one matched positive pair in In-foNCE, while more positive pairs are naturally preferred: a view cropped from a multi-label image likely contains mul-tiple semantic concepts or objects.
Therefore, this paper proposes a simple yet direct ap-proach towards scene image SSL, named as Multi-Label
Self-supervised learning (MLS). We treat each image (or randomly cropped patch) as a semantic bag with multiple objects, then retrieve images sharing similar semantics with any object in the bag from a large image dictionary. Note that an object in a bag is not necessarily within the set of human-annotated categories. As illustrated in Fig. 1, the cropped patch contains person, horse, road and bus, which will be pulled closer to similar images containing any of these objects and be pushed away from those dissimilar ones. Specifically, the patch’s embedding produced by a backbone network will select top k similar embeddings as k (pseudo) positive images from a dictionary, and the rest will be negatives. In another dictionary containing images in the same order as the first one, the BCE (binary cross en-tropy) loss plus these binary pseudo-labels will classify the patch’s embedding after an MLP projector using all the im-ages in this second dictionary as classifiers, and generates gradients that optimize the backbone network. This frame-work is illustrated in Fig. 2.
Our framework has two benefits. First, the large dictio-nary has diverse positive samples for any given input, hence provides many quality positive pairs with deformations or intra-class variations [11]. Second, unlike InfoNCE, the
BCE loss is not mutually exclusive among classes, hence allows the co-occurrence of multiple classes in one scene image. By applying our SSL method to scene images (e.g.,
MS-COCO), we achieve state-of-the-art results on object detection, instance segmentation and various classification benchmarks. Our contributions are summarized as follows: 1. For the first time, we formulate scene image SSL as a multi-label classification, and propose our Multi-Label
Self-supervised (MLS) learning approach. 2. Unlike previous methods that adopt dense matching or unsupervised object discovery, MLS is simple in con-cept, and enjoys intuitive visualizations (c.f . Fig. 4) which clearly verifies our motivation. 3. Extensive experiments of object detection, instance segmentation and classification on various benchmark datasets, together with ablation studies, clearly demon-strate the effectiveness of our method. 2.