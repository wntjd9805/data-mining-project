Abstract
Contemporary LiDAR-based 3D object detection meth-ods mostly focus on single-domain learning or cross-domain adaptive learning. However, for autonomous driv-ing systems, optimizing a specific LiDAR-based 3D object detector for each domain is costly and lacks of scalabil-ity in real-world deployment. It is desirable to train a uni-versal LiDAR-based 3D object detector from multiple do-mains. In this work, we propose the first attempt to explore multi-domain learning and generalization for LiDAR-based 3D object detection. We show that jointly optimizing a 3D object detector from multiple domains achieves better gen-eralization capability compared to the conventional single-domain learning model. To explore informative knowledge across domains towards a universal 3D object detector, we propose a multi-domain knowledge transfer framework with universal feature transformation. This approach leverages spatial-wise and channel-wise knowledge across domains to learn universal feature representations, so it facilitates to optimize a universal 3D object detector for deployment at different domains. Extensive experiments on four bench-mark datasets (Waymo, KITTI, NuScenes and ONCE) show the superiority of our approach over the state-of-the-art ap-proaches for multi-domain learning and generalization in
LiDAR-based 3D object detection. 1.

Introduction
LiDAR-based 3D object detection aims to localize and recognize objects of interests from LiDAR point clouds. It has been used in a wide range of applications, such as au-tonomous driving and robotics. Although incredible suc-cess has been achieved in the past few years, most LiDAR-based 3D object detection methods focus on optimizing a specific model for a single domain [38, 42, 21, 34, 7, 23, 11], which usually shows poor generalization to other do-mains. To address this problem, some researchers resort to
*Bingbing Liu is the corresponding author.
Figure 1. Comparisons of LiDAR-based 3D object detection by single-domain learning and multi-domain learning. (a) Conven-tional methods mainly train a specific model for each domain. (b) We propose to jointly optimize a universal model for all do-mains. (c) Comparison between oracle models and a joint-training model. Results are evaluated using CenterPoint [38] with KITTI metric [2] of APBEV and IoU0.7 of the car category. cross-domain adaptation [31, 16, 37, 36] to transfer knowl-edge from a source domain to a target domain, which im-proves generalization of a target model. However, domain adaptive 3D object detection methods usually ignore the im-portance of preserving generalization to the source domain, resulting in poor performance on the source domain.
For automated driving systems, optimizing a specific
LiDAR-based 3D object detection model for each domain (e.g., locations, LiDAR sensors, etc.) is costly and lacks of scalability for real-world deployment. More importantly, optimizing each domain independently cannot make full use of knowledge of each domain to facilitate learning a uni-versal detector. We summarize some domain gap infor-Dataset
Waymo
KITTI
Location
USA
Germany
NuScenes USA/Singapore
ONCE
China
Night/rain
Yes
No
Yes
Yes
LiDAR beam Points per scene Car average size (L,W,H) 64-beam 64-beam 32-beam 40-beam 160k 118k 25k 70k (4.80, 2.11, 1.79) (3.89, 1.62, 1.53) (4.64, 1.96, 1.73) (4.36, 1.81, 1.56)
VFOV
[-17.6◦, 2.4◦]
[-23.6◦, 3.2◦]
[-30.0◦, 10.0◦]
[-25.0◦, 15.0◦]
Table 1. Domain gap information of four autonomous driving datasets, namely Waymo [24], KITTI [2], NuScenes [1] and ONCE [17]. We resolve domain gaps by transferring knowledge across multiple domains to learn universal feature representations in a universal detector. mation of four widely used autonomous driving datasets (Waymo [24], KITTI [2], NuScenes [1] and ONCE [17]) in Table 1 and show the performance of each oracle model (single-domain learning) on all domains in Fig. 1(c). Due to the significant domain gaps (e.g., LiDAR beams, locations, weather, object sizes, etc.), these single-domain learning models usually perform poorly on other domains. Thus, for real-world application, it is desirable to optimize a universal model with good generalization on all domains. However, there is no existing work proposed to address this problem.
In this work, we propose multi-domain learning and gen-eralization for learning a universal LiDAR-based 3D ob-ject detector. First, we construct a joint-training baseline model using data from multiple domains. We validate the advantage of learning a variety of point clouds from dif-ferent domains and show the superior performance of the joint-training model over the conventional single-domain learning model (see Fig. 1(c)). Then, to further explore in-formative knowledge across domains, we propose a multi-domain knowledge transfer (MDKT) framework with uni-versal feature transformation for LiDAR-based 3D object detection. An overview of the proposed approach is de-picted in Fig. 2. Specifically, we aim to learn universal feature representations in a universal detector by transfer-ring informative knowledge across multiple domains. To this end, we employ multiple specific detectors trained on each domain and transfer knowledge from these specific de-tectors to a universal detector so that the universal detector can aggregate informative spatial-wise knowledge across domains. Meanwhile, to aggregate informative channel-wise knowledge across domains, we modulate channel in-formation of feature representations in the universal detec-tor. Together with spatial-wise and channel-wise knowl-edge transfer across domains, the universal feature transfor-mation module facilitates to optimize a universal detector.
Besides, we observe that learning to normalize intermediate
BEV (Bird’s Eye View) features can also facilitate model optimization when training data are from multiple domains.
To some extent, this strategy is compatible with our MDKT approach by removing some noises in statistics across mul-tiple domains. In summary, our contributions are:
• We propose multi-domain learning and generalization for LiDAR-based 3D object detection. To the best of our knowledge, this is the first work exploring multi-domain data for optimizing a universal LiDAR-based 3D object detector.
• We propose a multi-domain knowledge transfer frame-work with universal feature transformation for LiDAR-based 3D object detection. Our approach learns uni-versal feature representations for LiDAR-based 3D ob-ject detection by aggregating informative spatial-wise and channel-wise knowledge across domains.
• We provide thorough experimental analyses on four autonomous driving benchmark datasets and demon-strate the superiority of our approach over the state-of-the-art approaches for multi-domain learning and gen-eralization in LiDAR-based 3D object detection. 2.