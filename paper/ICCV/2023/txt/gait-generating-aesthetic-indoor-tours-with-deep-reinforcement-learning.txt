Abstract
Placing and orienting a camera to compose aesthetically meaningful shots of a scene is not only a key objective in real-world photography and cinematography but also for virtual content creation. The framing of a camera often sig-nificantly contributes to the story telling in movies, games, and mixed reality applications. Generating single camera poses or even contiguous trajectories either requires a sig-nificant amount of manual labor or requires solving high-dimensional optimization problems, which can be computa-tionally demanding and error-prone. In this paper, we intro-duce GAIT, a framework for training a Deep Reinforcement
Learning (DRL) agent, that learns to automatically control a camera to generate a sequence of aesthetically meaning-ful views for synthetic 3D indoor scenes. To generate se-quences of frames with high aesthetic value, GAIT relies on a neural aesthetics estimator, which is trained on a crowed-sourced dataset. Additionally, we introduce regularization techniques for diversity and smoothness to generate visu-ally interesting trajectories for a 3D environment, and to constrain agent acceleration in the reward function to gen-erate a smooth sequence of camera frames. We validated our method by comparing it to baseline algorithms, based on a perceptual user study, and through ablation studies.
Code and visual results are available on the project web-site: https://desaixie.github.io/gait-rl 1.

Introduction
Composing a shot by framing a scene with a camera plays an integral part in photography and cinematography.
A carefully composed frame does not only provide the in-formation of a scene, but also serves to define the visual style, to instill a desired emotion in the viewer, and to carry forward the story the artist wants to convey [39]. Photog-raphers and movie directors commonly spend a significant amount of time to perfect the camera framing, which – con-sequently – often leads to extensive cost footprints. While framing scenes in virtual setups, such as games or mixed reality applications, is arguably less involved, defining aes-Figure 1: Our novel DRL agent, GAIT, automatically gen-erates camera poses so as to obtain aesthetic views of 3D indoor scenes. Left: Views of three camera poses from a generated sequence. Right: the 3D indoor environment with three highlighted camera poses. Red, yellow, orange cor-responds to the three frames on the left respectively, where the red dot is the initial pose. GAIT maintains high aesthetic views throughout the sequence, while satisfying the initial pose, diversity, smoothness, and boundary constraints. thetically valuable camera poses and trajectories still re-quires a considerable amount of manual work. An artist has to position key frames in space, define the orientation of the camera, and specify the temporal profile for the interpola-tion between keyframes. While this provides a high degree of control, for many applications, it would be desirable to frame a scene automatically by computing camera poses.
Existing methods for automatically computing single camera poses or camera trajectories either rely on hand-crafted methods with heuristics, which commonly do not generalize [40], are limited to specific applications, such as a trip between two cities [19], or specifically focus on mov-ing targets [36]. Recently, it has been recognized that neural aesthetics estimators can serve as more generic solution for generating camera poses for the purpose of obtaining aes-thetically meaningful camera frames [32] – a 2D image is mapped to a score that quantifies the aesthetics. An aesthet-ics estimator can be used to compare any two images with different contents or styles, which makes them applicable for finding views in lower dimensional spaces such as im-ages and videos [49], or in constrained robotics settings [1].
In a 3D environment, finding a desired camera pose requires searching in a continuous R6 space (i.e., position R3 and orientation in R3) while also considering obstacles or even dynamically moving objects. Computing camera paths in a flexible and versatile manner therefore is a challenging and open problem.
In this paper, we propose a novel method for automati-cally generating trajectories to aesthetically frame synthetic 3D indoor scenes. We introduce GAIT, a framework for training a Deep Reinforcement Learning (DRL) network that learns to move the camera so as to generate trajecto-ries that show the most aesthetic views while also satisfying smoothness constraints. Our method is able to robustly gen-erate diverse trajectories with varying start and end camera poses. Camera poses are optimized with a neural aesthetic metric [49] without any pre-determined targets in the view.
GAIT computes camera transformations – the translation in 3D Euclidean space and the rotation (defined as yaw and pitch) – in a continuous 5D space for each step of the se-quence. We define diversity regularization to provide con-trol for either generating diverse sets of trajectories with varying start and end poses or to generate more uniform trajectories that always converge to the same final pose. To constrain the agent from taking actions that would create discontinuities in camera pose, we define smoothness reg-ularization. Smooth trajectories tend to be more pleasing visually, which is important when the generated trajectories are used for video tours. To obtain a GAIT agent, we intro-duce a flexible framework to leverage existing RL methods for policy training, such as DrQ-v2 [50] and CURL [27].
Based on a number of experiments we show that our method is able to generate trajectories of camera poses that frame scenes in an aesthetically meaningful manner. We show that our method is able to generate camera trajecto-ries for a variety of complex 3D indoor scenes, which can be used to automatically create aesthetic video tours. More-over, we show that the learned policies are robust against random initial camera poses – independent of the starting pose of the agent, it can converge to the same target pose.
In summary, our contributions are: (1) We propose
GAIT, the first DRL-based framework for generating se-quences of camera poses with constrained globally opti-mal aesthetics in 3D synthetic indoor scenes; (2) We allow for user control based on diversity regularization and use smoothness regularization to constrain the agent to generate smooth and visually pleasing camera poses; (3) We show that employing image augmentation techniques facilitates learning representation of 3D scene aesthetics from a high-dimensional pixel-space, which is commonly considered challenging for DRL algorithms; (4) We implemented our algorithm to efficiently utilizes multiple GPUs: on a 8-GPU compute node, it can finish training in 3.5 hours; (5) We show that the generated camera poses can be interpolated to generate high-quality video tours of a scene; (6) Finally, we perform an extensive set of experiments and carefully vali-date our method based on quantitative and qualitative visual evaluations, via comparison with baseline method in a user study, and ablation studies to validate our algorithm design. 2.