Abstract
Recent deep learning methods have achieved superior results in shadow removal. However, most of these su-pervised methods rely on training over a huge amount of shadow and shadow-free image pairs, which require labo-rious annotations and may end up with poor model gen-eralization. Shadows, in fact, only form partial degrada-tion in images, while their non-shadow regions provide rich structural information potentially for unsupervised learn-ing.
In this paper, we propose a novel diffusion-based solution for unsupervised shadow removal, which sepa-rately modeling the shadow, non-shadow, and their bound-ary regions. We employ a pretrained unconditional diffu-sion model fused with non-corrupted information to gen-erate the natural shadow-free image. While the diffusion model can restore the clear structure in the boundary re-gion by utilizing its adjacent non-corrupted contextual in-formation, it fails to address the inner shadow area due to the isolation of the non-corrupted contexts. Thus we further propose a Shadow-Invariant Intrinsic Decomposition mod-ule to exploit the underlying reflectance in the shadow re-gion to maintain structural consistency during the diffusive sampling. Extensive experiments on the publicly available shadow removal datasets show that the proposed method achieves a significant improvement compared to existing unsupervised methods, and even is comparable with some existing supervised methods. 1.

Introduction
Shadow is a ubiquitous phenomenon resulting from par-tial occlusion of light by occluders. It is critical to remove these shadows because their detrimental impacts on vision models, such as object detection and tracking [23, 35, 46].
Unfortunately, in general, it is still an open problem to re-move shadows from a single image due to the large va-riety of shadow shapes and background structures, mak-*Corresponding author: Bihan Wen.
Figure 1: Shadow removal results on the ISTD [37] dataset.
From (a) to (f): (a) input shadow image, supervised learn-ing results of (b) SP+M-Net [25], (c) corresponding ground truth shadow-free image, as well as unsupervised learning results of (d) DC-ShadowNet [20], (e) G2R [29], and (f)
Ours, respectively. ing it challenging to obtain a generalized solution. Con-ventional shadow removal methods [9, 45] mainly rely on carefully designed hand-crafted statistical features, e.g., il-lumination, gradient, and region consistency, to construct the optimization function for shadow region removal. How-ever, they totally ignore the natural image prior and the op-timization function’s underlying assumptions are frequently excessively idealistic, leading to unnatural results with arti-facts, particularly in real-world scenarios.
Recently, deep-learning based image shadow removal methods [12, 25, 4, 7, 16, 28, 20] have achieved remark-able progress by learning the pixel-wise mapping between the shadow images and ground-truth shadow-free ones in a fully-supervised manner. However, such solutions require laborious annotations and can easily result in overfitting the training dataset with poor generalization. More importantly, shadow removal is a region-wise corrupted problem with abundant context and structure priors. This information ac-tually provides rich clues to infer the shadow regions solely based on the single input, demonstrating strong potential to address the problem using unsupervised learning meth-ods. Some works [16, 28, 20] have started to explore un-supervised methods for shadow removal mainly relying on
GAN using unpaired shadow and shadow-free images. Un-fortunately, due to the absence of the training pair with the pixel-wise ground truth, the discriminator relies solely on unpaired non-shadow images, which can cause the genera-tor to produce inauthentic outputs. Namely, the generator’s learning faces dispersed space and is very easy to halluci-nate new content and artifacts.
In this paper, we propose a novel unsupervised diffusion-based solution using only the shadow images without any reference. According to our analysis, the corrupted re-gions in shadow images can be categorized into two distinct types: 1) shadow regions, with subtle structural informa-tion obscured by the low illumination; 2) boundary regions, which contain noisy structures and exhibit rich adjacent non-corrupted contexts. Our work unifies the restoration of both shadow and boundary regions in a comprehensive manner, by integrating the generative power of the diffusion model and the detail preservation power of the intrinsic de-composition, resulting in mutual benefits for both regions.
More in detail, we employ a pre-trained unconditional diffusion model, injected with the guidance of the non-corrupted region information as the baseline to generate natural shadow-free images and suppress artifacts. While the diffusion model can effectively restore the clear struc-ture and standard illumination in the boundary region by utilizing its adjacent non-corrupted contextual information, it falls short in addressing the inner shadow region, which is isolated from such contexts. To address this limitation, we propose a Shadow-Invariant Intrinsic Decomposition model, which ensures consistency among the reflectance of all intermediate results during diffusive sampling. By do-ing so, we are able to unveil the structural detail present in these inner shadow regions. Experimental results re-veal that the proposed method consistently attains superior performance across existing widely-used shadow removal datasets. It markedly surpasses the capabilities of existing unsupervised methods, and in certain instances, achieves comparable performance to certain supervised methods.
The main contributions of this work are as follows:
• We propose a novel diffusion-based unsupervised method for shadow removal, in which we divide the corrupted regions into shadow and boundary regions.
Inspired by the partition category, our work unifies shadow and boundary region restoration by integrating diffusion and intrinsic decomposition for their mutual benefits.
• We further present a Shadow-Invariant Intrinsic De-composition model that guarantees coherence among reflectance values at each stage of diffusive sampling.
This approach allows us to effectively uncover struc-tural details present within the inner shadow regions.
• We conduct extensive experiments on public datasets and show that the proposed method achieves signifi-cant improvement among existing SOTA unsupervised methods and even comparable performance with some supervised methods. 2.