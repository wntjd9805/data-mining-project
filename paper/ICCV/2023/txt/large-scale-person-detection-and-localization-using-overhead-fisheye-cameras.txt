Abstract
Location determination finds wide applications in daily life. Instead of existing efforts devoted to localizing tourist photos captured by perspective cameras, in this article, we focus on devising person positioning solutions using over-head fisheye cameras. Such solutions are advantageous in large field of view (FOV), low cost, anti-occlusion, and un-aggressive work mode (without the necessity of cameras car-ried by persons). However, related studies are quite scarce, due to the paucity of data. To stimulate research in this ex-citing area, we present LOAF, the first large-scale overhead fisheye dataset for person detection and localization. LOAF is built with many essential features, e.g., i) the data cover abundant diversities in scenes, human pose, density, and location; ii) it contains currently the largest number of an-notated pedestrian, i.e., 457K bounding boxes with ground-truth location information; iii) the body-boxes are labeled as radius-aligned so as to fully address the positioning chal-lenge. To approach localization, we build a fisheye person detection network, which exploits the fisheye distortions by a rotation-equivariant training strategy and predict radius-aligned human boxes end-to-end. Then, the actual locations of the detected persons are calculated by a numerical solu-tion on the fisheye model and camera altitude data. Exten-sive experiments on LOAF validate the superiority of our fisheye detector w.r.t. previous methods, and show that our whole fisheye positioning solution is able to locate all per-sons in FOV with an accuracy of 0.5 m, within 0.1 s. 1.

Introduction
Accurate position finding of persons attracts growing in-terest from both research and industrial communities, since it plays a crucial role in numerous location-sensitive applica-tion scenarios (e.g., surveillance, smart home, public health).
Nevertheless, due to the line-of-sight (LOS) issue, GPS is unreliable in interior spaces and urban canyon. To overcome 1The first two authors contribute equally to this work. 2Corresponding author: Wenguan Wang.
Figure 1: Person positioning using overhead fisheye camera: We detect humans on omnidirectional images and then project detects onto the real world coordinates to obtain physical locations. Com-pared with using perspective cameras, our fisheye camera based solution is favored in low cost, high accuracy, and fast speed. such limitation, various alternative solutions are investigated.
Signal based solutions, including Bluetooth [13] and Wi-Fi [74], are popular, but they are easily interfered by chang-ing environments and nearby human bodies [73]. A com-plementary stream of work is vision based; they typically make use of traditional cameras, RGBD cameras, or in-built smartphone cameras, and enjoy the advantage of reliable services. To get location information, visual positioning so-lutions usually refer to a pre-acquired 3D map or a geo-tagged database as the scene representation [63], or directly utilize the captured image to estimate the camera pose [39].
Although visual localization has been a hotspot issue for many years, existing efforts are mainly dedicated to urban place recognition or indoor camera localization, based on perspective cameras [63, 39, 62, 43]. None of them ad-dresses person positioning by using overhead fisheye cam-eras, even though fisheye cameras are widely used in visual surveillance applications. One possible reason is the lack of accessible datasets, compounded by considerable costs in-volved in data collection. In this article, we provide a large-scale overhead fisheye dataset, LOAF, for person detection and localization in both indoor and outdoor scenes.
Compared with perspective cameras, overhead (top-view) fisheye cameras are promoted due to less occlusion among people and larger field of view (FOV) – allowing the coverage of a large space using a single, low-cost camera. Only few public datasets [21, 42, 24] provide top-view fisheye data.
Unfortunately, they only cover quite few scenes and their people-box annotations do not adequately address the po-sitioning challenge, negatively affecting location approxi-mation (see §3.2 for detailed analysis). Differently, LOAF specifically targets at person localization in surveillance ap-plications, and has the following appealing characteristics:
• Large-scale: LOAF is the largest in the filed, to our best knowledge. It consists of over 70 videos, with more than 43K frame images, 457K person-detection annotations as well as corresponding location information.
• High diversity: LOAF contains a wide variety of surveil-lance scenarios; it includes a total of 11 indoor and 40 out-door scenes, and the data are captured at different times of day and cover different illumination conditions.
• Positioning-aware person-box annotation: LOAF offers radius-aligned human-box annotations. Compared with other person representations, i.e., head center [21], axis-aligned [60] or body-aligned box [42, 24], used in previ-ous fisheye datasets, the radius-aligned box is promoted, as it fits well radially-oriented bodies [42], and, more im-portantly, it is better aware of the positioning problem.
Moreover, we devise a person positioning system that first detects persons from raw fisheye images, and then calcula-tes physical locations based on fisheye visual model and al-titude information (see Fig. 1). Clearly, high-quality person detection is the crucial premise for precise localization us-ing overhead fisheye cameras. Fisheye lenses provide large
FOV, at the cost of strong radial distortion. This makes pe-destrian detection in top-view fisheye images a much harder task, compared with using perspective cameras. Studies on overhead fisheye pedestrian detection are very scarce [60, 42, 51, 24, 64]; they rarely concern the link with person po-sitioning, and many of them [60, 42] are even not trainable due to the lack of fisheye data. With our LOAF dataset, we develop a novel query based fisheye human detector. It expli-citly exploits fisheye geometry by accommodating rotation equivariance into the matching between queries and human instances during network training. The insight here is intui-tive: for a robust fisheye detector, rotation of a fisheye im-age should result in correspondingly rotated detections. In addition, our detection algorithm learns to predict radius-aligned person boxes, facilitating localization estimation.
We test our fisheye person detection algorithm as well as our whole positioning system over LOAF. We find that our detector significantly outperforms previous methods, and our full system delivers precise localization results. We also empirically show that our algorithm generalizes well on pre-vious top-view fisheye person detection datasets [24, 65]. 2.