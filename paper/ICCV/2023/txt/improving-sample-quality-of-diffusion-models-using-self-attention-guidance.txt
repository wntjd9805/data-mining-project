Abstract
Denoising diffusion models (DDMs) have attracted at-tention for their exceptional generation quality and diver-sity. This success is largely attributed to the use of class- or text-conditional diffusion guidance methods, such as classi-fier and classifier-free guidance. In this paper, we present a more comprehensive perspective that goes beyond the tra-ditional guidance methods. From this generalized perspec-tive, we introduce novel condition- and training-free strate-gies to enhance the quality of generated images. As a sim-ple solution, blur guidance improves the suitability of inter-mediate samples for their fine-scale information and struc-tures, enabling diffusion models to generate higher quality samples with a moderate guidance scale. Improving upon this, Self-Attention Guidance (SAG) uses the intermediate self-attention maps of diffusion models to enhance their sta-bility and efficacy. Specifically, SAG adversarially blurs only the regions that diffusion models attend to at each it-eration and guides them accordingly. Our experimental re-sults show that our SAG improves the performance of vari-ous diffusion models, including ADM, IDDPM, Stable Dif-fusion, and DiT. Moreover, combining SAG with conven-tional guidance methods leads to further improvement. 1.

Introduction
Recently, denoising diffusion models (DDMs) [31, 33, 12, 7, 13, 27], which synthesize images from noise through an iterative denoising process, have been actively re-searched and attracted attention due to their exceptional per-formance in synthesizing high-quality and diverse images.
Behind this remarkable success lies the introduction of diffusion guidance methods [7, 20, 14]. Several studies have revealed that to improve the quality of image samples generated by diffusion models, guidance techniques using
The project page and code can be accessed at: https://ku-cvlab.github.io/Self-Attention-Guidance/
class labels [7, 14] or captions [20] are essential. How-ever, despite the significant improvement provided by these guidance methods, they are bounded within the limits of using external conditions. For example, classifier guidance (CG) [7] requires the training of an additional classifier, and classifier-free guidance (CFG) [14] adds complexity to the training process through label-dropping. In addition, both methods are limited by their need for hard-earned external conditions, which binds them to conditional settings.
In light of the limitations mentioned above, in this work, we present a more general formulation of diffusion guid-ance that can make use of information within the intermedi-ate samples of diffusion models. This formulation detaches the necessary condition of traditional approaches [14, 7, 20], i.e., the requirement for external information, from dif-fusion guidance, and facilitates a flexible and condition-free approach to guide diffusion models. This broadens the ap-plicability of diffusion guidance to cases with or without external conditions.
Based on the generalized formulation and the intuition that any internal information within intermediate samples can also serve as guidance, we firstly propose blur guid-ance as a straightforward solution to improve sample qual-ity. Blur guidance uses the eliminated information resulting from Gaussian blur to guide intermediate samples, exploit-ing the benign property of Gaussian blur that it naturally removes fine-scale details [15, 18, 26]. While our results show that this method improves sample quality with a mod-erate guidance scale, it becomes problematic with a large guidance scale, since it may introduce structural ambiguity in entire regions, which makes it difficult to align the pre-diction of the degraded input with that of the original one.
To improve the effectiveness and stability of blur guid-ance with a larger guidance scale, we explore the self-attention mechanism of diffusion models. Generally, recent diffusion models [12, 7, 21, 27, 13, 23] are equipped with a self-attention module [36, 8] within their architecture.
Claiming that the self-attention is a key to capture salient information during generation process [16, 41, 42, 10], we present Self-Attention Guidance (SAG), which adversari-ally blurs the region that contains salient information using the self-attention map of diffusion models and guides diffu-sion models with the residual information. Leveraging the attention maps during the reverse process of diffusion mod-els, it can encouragingly boost the quality and reduce the artifacts through self-conditioning without requiring exter-nal information nor additional training, as shown in Fig. 1.
The pseudocode and pipeline are provided in Alg. 1 and
Fig. 2(b), respectively.
In experiments, we evaluate the effectiveness of the pro-posed approach by plugging it into various diffusion mod-els including ADM [7], IDDPM [21], Stable Diffusion [27], and DiT [23], which demonstrates our method’s broad ap-plicability. We also show that in addition to the increased sample quality when using SAG alone, performance fur-ther improves when using it on top of existing guidance schemes, i.e., classifier [7] or classifier-free [14] guidance, demonstrating the orthogonality with the existing methods.
Finally, we present ablation studies to validate our choices.
To sum up, our work has the following contributions:
• Generalizing conditional guidance methods [7, 14, 20] into a condition-free method that can be applied to any diffusion model without external conditions, expand-ing the applicability of guidance.
• Introducing novel guidance, dubbed Self-Attention
Guidance (SAG), that uses the internal self-attention maps of diffusion models, improving sample quality without external conditions or additional fine-tuning.
• Demonstrating the orthogonality of SAG to existing conditional models and methods, enabling its flexi-ble combination with others to achieve higher perfor-mance.
• Presenting extensive ablation studies to justify the de-sign choices and demonstrate the effectiveness of the proposed method. 2.