Abstract
Explaining the predictions of deep neural nets has been a topic of great interest in the computer vision literature.
While several gradient-based interpretation schemes have been proposed to reveal the inﬂuential variables in a neu-ral net’s prediction, standard gradient-based interpretation frameworks have been commonly observed to lack robust-ness to input perturbations and ﬂexibility for incorporating prior knowledge of sparsity and group-sparsity structures.
In this work, we propose MoreauGrad as an interpretation scheme based on the classiﬁer neural net’s Moreau enve-lope. We demonstrate that MoreauGrad results in a smooth and robust interpretation of a multi-layer neural network and can be efﬁciently computed through ﬁrst-order opti-mization methods. Furthermore, we show that Moreau-Grad can be naturally combined with L1-norm regulariza-tion techniques to output a sparse or group-sparse explana-tion which are prior conditions applicable to a wide range of deep learning applications. We empirically evaluate the proposed MoreauGrad scheme on standard computer vision datasets, showing the qualitative and quantitative success of the MoreauGrad approach in comparison to standard gradient-based interpretation methods 1. 1.

Introduction
Deep neural networks (DNNs) have achieved state-of-the-art performance in many computer vision problems in-cluding image classiﬁcation [11], object detection [29], and medical image analysis [19]. While they manage to attain super-human scores on standard image and speech recogni-tion tasks, a reliable application of deep learning models to real-world problems requires an interpretation of their pre-dictions to help domain experts understand and investigate the basis of their predictions. Over the past few years, de-veloping and analyzing interpretation schemes that reveal 1The paper’s code is available at https://github.com/ buyeah1109/MoreauGrad.
Figure 1. Interpretation of Sparse MoreauGrad (ours) vs. standard gradient-based baselines on an ImageNet sample before and after adding a norm-bounded interpretation adversarial attack. the inﬂuential features in a neural network’s prediction have attracted great interest in the computer vision community.
A standard approach for interpreting neural nets’ pre-dictions is to analyze the gradient of their prediction score function at or around an input data point. Such gradient-based interpretation mechanisms result in a feature saliency map revealing the inﬂuential variables that locally affect the neural net’s assigned prediction score. Three well-known examples of gradient-based interpretation schemes are the simple gradient [21], integrated gradients [24], and
DeepLIFT [20] methods. While the mentioned methods have found many applications in explaining neural nets’ predictions, they have been observed to lack robustness to input perturbations and to output a dense noisy saliency map in their application to computer vision datasets [6, 8]. Con-sequently, these gradient-based explanations can be consid-erably altered by minor random or adversarial input noise.
A widely-used approach to improve the robustness and sharpness of gradient-based interpretations is SmoothGrad
[22] which applies Gaussian smoothing to the mentioned gradient-based interpretation methods. As shown by [22],
SmoothGrad can signiﬁcantly boost the visual quality of a neural net’s gradient-based saliency map. On the other hand, SmoothGrad typically leads to a dense interpretation vector and remains inﬂexible to incorporate prior knowl-edge of sparsity and group-sparsity structures. Since a sparse saliency map is an applicable assumption to sev-eral image classiﬁcation problems where a relatively small group of input variables can completely determine the im-age label, a counterpart of SmoothGrad which can simulta-neously achieve sparse and robust interpretation will be of signiﬁcant use in computer vision problems.
In this paper, we propose a novel approach, which we call MoreauGrad, to achieve a provably smooth gradient-based interpretation with potential sparsity or group-sparsity properties. The proposed MoreauGrad outputs the gradient of a classiﬁer’s Moreau envelope which is a use-ful optimization tool for enforcing smoothness in a tar-get function. We leverage convex analysis to show that
MoreauGrad behaves smoothly around an input sample and therefore provides an alternative optimization-based ap-proach to SmoothGrad for achieving a smoothly-changing saliency map. As a result, we demonstrate that similar to
SmoothGrad, MoreauGrad offers robustness to input pertur-bations, since a norm-bounded perturbation will only lead to a bounded change to the MoreauGrad interpretation.
Next, we show that MoreauGrad can be ﬂexibly com-bined with L1-norm-based regularization penalties to out-put sparse and group-sparse interpretations. Our pro-posed combinations, Sparse MoreauGrad and Group-Sparse
MoreauGrad, take advantage of elastic-net [31] and group-norm [16] penalty terms to enforce sparse and group-sparse saliency maps, respectively. We show that these exten-sions of MoreauGrad preserve the smoothness and robust-ness properties of the original MoreauGrad scheme. There-fore, our discussion demonstrates the adaptable nature of
MoreauGrad for incorporating prior knowledge of sparsity structures in the output interpretation.
Finally, we present the empirical results of our numer-ical experiments applying MoreauGrad to standard image recognition datasets and neural net architectures. We com-pare the numerical performance of MoreauGrad with stan-dard gradient-based interpretation baselines. Our numeri-cal results indicate the satisfactory performance of vanilla and L1-norm-based MoreauGrad in terms of visual quality and robustness. Figure 1 shows the robustness and spar-sity of the Sparse MoreauGrad interpretation applied to an
ImageNet sample in comparison to standard gradient-based saliency maps. As this and our other empirical ﬁndings suggest, MoreauGrad can outperform standard baselines in terms of the sparsity and robustness properties of the out-put interpretation. In the following, we summarize the main contributions of this paper:
• Proposing MoreauGrad as an interpretation scheme based on a classiﬁer function’s Moreau envelope
• Analyzing the smoothness and robustness properties of
MoreauGrad by leveraging convex analysis
• Introducing L1-regularized Sparse MoreauGrad to obtain an interpretation satisfying prior sparsity conditions
• Providing numerical results supporting MoreauGrad over standard image recognition datasets 2.