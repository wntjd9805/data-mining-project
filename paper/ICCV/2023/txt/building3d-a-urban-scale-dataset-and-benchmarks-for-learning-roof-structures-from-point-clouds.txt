Abstract
Urban modeling from LiDAR point clouds is an im-portant topic in computer vision, computer graphics, pho-togrammetry and remote sensing. 3D city models have found a wide range of applications in smart cities, au-tonomous navigation, urban planning and mapping etc.
However, existing datasets for 3D modeling mainly focus on common objects such as furniture or cars. Lack of build-ing datasets has become a major obstacle for applying deep learning technology to specific domains such as urban mod-eling. In this paper, we present an urban-scale dataset con-sisting of more than 160 thousands buildings along with corresponding point clouds, mesh and wireframe models, covering 16 cities in Estonia about 998 Km2. We exten-sively evaluate performance of state-of-the-art algorithms including handcrafted and deep feature based methods. Ex-perimental results indicate that Building3D has challenges of high intra-class variance, data imbalance and large-scale noises. The Building3D is the first and largest urban-scale building modeling benchmark, allowing a comparison of supervised and self-supervised learning methods. We be-lieve that our Building3D will facilitate future research on urban modeling, aerial path planning, mesh simplification, and semantic/part segmentation etc. 1.

Introduction
Deep learning has achieved tremendous success on com-puter vision applications such as image classification and object detection [12, 20, 26, 47], semantic segmentation
[5, 11, 43] and human pose estimation [2, 55], to name a few. With the increased availability of 3D point clouds that found a wide range of applications in robotics, autonomous driving and urban modeling, a recent research focus has been shifted to deal with such massive 3D point clouds
[29, 39, 40, 48]. The majority of current work on 3D point cloud processing are focused on 3D shape classification
[39,42,48,49], 3D object detection and tracking [18,29,41], 3D semantic and instance segmentation [16,22,40,49]. Cor-respondingly, a large number of datasets including synthetic and real-world ones have been established to train and eval-uate deep learning algorithms with respect to above men-tioned applications [1, 3, 6, 8, 10, 15, 44, 50]. The widely available datasets are prerequisite for rapid algorithm ad-vancement in supervised learning based on neural networks.
Supervised learning methods heavily rely on labeled data, which have been intensively studied. Due to the expensive cost of labeled data, self-supervised learning methods learn-ing representations from unlabeled data, are receiving more and more attention. Started from self-supervised learning on 2D images, SimCLR [7] and CPC [13, 51] have reached top performance on image classification benchmarks. The methods of self-supervised learning in 2D are being quickly adapted for 3D point clouds, such as the jigsaw puzzle pre-text task [46], estimating rotations [19], contrastive learn-ing [45], point cloud completion [54].
Current deep learning methods on urban modeling have been restricted to small datasets or synthetic ones. How-ever, urban modeling is different from existing object mod-eling work where small objects are collected under a well-controlled lab environment. Specifically, urban modeling deal with large-scale LiDAR scans containing more noisy and incomplete point clouds that represent complex real-world scenes. To advance urban modeling research in com-puter vision, we introduce an urban-scale dataset for 3D roof modeling from point clouds collected from the air. The dataset covering 16 cities in Estonian consist of 875.39 mil-lions of aerial LiDAR point clouds and 161.91 thousands of 3D building models in both mesh and wireframe for-mats. A mesh model is a 3D model that is made up of small discrete cells. The commonly used 2D cell shapes are the triangle and the quadrilateral, which the triangular mesh is the one referred in this paper. A wireframe model is a 3D model that the polygonal faces have been removed to retain only the outlines of its component polygons. It is the least complex representation, namely a skeletal descrip-tion of a 3D object consisting of vector points connected by lines. Man-made objects such as buildings are mostly poly-hedral which can be represented by corners, edges and/or planar surfaces [28]. Therefore, wireframes are particularly suitable for representing polyhedral objects such as build-ings or furniture. Besides benefit of efficient storage and transmit, wireframe models are easy to edit and manipulate in CAD software which can help create CAD models for various applications such as quality inspection, metrology, rendering and animation [28].
We convert mesh models into wireframe models. There is no wireframe models provided in current building mod-eling datasets [3, 15, 17, 25, 56]. To our knowledge, we are the first to provide both mesh and wireframe building models along with corresponding LiDAR point clouds at urban scale. Fig.1a shows the aerial LiDAR point clouds of
Tallinn, one out of 16 cities in Building3D dataset. It con-tains 361.95 million points and 47.05 thousands of build-ings, covering an area around 195 km2. Figure 1b, 1c 1d 1e shows building and roof point clouds, as well as correspond-ing mesh and wireframe models, respectively. Besides a urban-scale dataset, we also provide two new baselines of supervised and self-supervised learning, adopted and eval-uated various supervised and self-supervised pipelines for 3D roof modeling. To our knowledge, we are the first to use and evaluate self-supervised learning method for 3D object reconstruction. Overall, our main contributions are in the following.
• We present the first and largest urban-scale building modeling dataset consisting of aerial LiDAR point clouds, mesh and wireframe models. Besides urban modeling, the proposed dataset can be extended to support various downstream applications. The whole dataset is made available to the research community.
• We evaluate representative deep and handcrafted feature based methods including mainstream self-supervised learning methods, and establish new base-lines and evaluation metric for future research. The new baselines achieve state-of-the-art performance compared with deep learning based methods. To our knowledge, we are the first to propose and adopt self-supervised pre-training methods for 3D building re-construction. 2.