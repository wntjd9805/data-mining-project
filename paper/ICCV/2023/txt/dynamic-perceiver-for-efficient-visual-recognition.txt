Abstract
Early exiting has become a promising approach to im-proving the inference efficiency of deep networks. By struc-turing models with multiple classifiers (exits), predictions for “easy” samples can be generated at earlier exits, negat-ing the need for executing deeper layers. Current multi-exit networks typically implement linear classifiers at interme-diate layers, compelling low-level features to encapsulate high-level semantics. This sub-optimal design invariably undermines the performance of later exits. In this paper, we propose Dynamic Perceiver (Dyn-Perceiver) to decou-ple the feature extraction procedure and the early classifi-cation task with a novel dual-branch architecture. A fea-ture branch serves to extract image features, while a classi-fication branch processes a latent code assigned for clas-sification tasks. Bi-directional cross-attention layers are established to progressively fuse the information of both branches. Early exits are placed exclusively within the classification branch, thus eliminating the need for linear separability in low-level features. Dyn-Perceiver consti-tutes a versatile and adaptable framework that can be built upon various architectures. Experiments on image classi-fication, action recognition, and object detection demon-strate that our method significantly improves the inference efficiency of different backbones, outperforming numerous competitive approaches across a broad range of computa-tional budgets. Evaluation on both CPU and GPU plat-forms substantiate the superior practical efficiency of Dyn-Perceiver. Code is available at https://www.github. com/LeapLabTHU/Dynamic_Perceiver. 1.

Introduction
Convolutional neural networks (CNNs) [19, 25, 67, 49, 40, 34] and vision Transformers [11, 54, 72, 39, 59, 41] have
*Equal contribution.
†Corresponding Author.
Figure 1: Comparison of Dyn-Perceiver with the previous early-exiting scheme. (a) Conventional methods build clas-sifiers on intermediate features, degrading the performance of the last exit; (b) Dyn-Perceiver decouples feature extrac-tion and early classification with a two-branch structure. precipitated substantial advancements in visual recognition.
Despite concerted efforts towards scaling up vision mod-els for superior accuracy [75, 38, 51], the high computa-tional demands have acted as a deterrent to their deployment in resource-constrained scenarios. Research endeavours to-wards improving the inference efficiency of deep networks span a multitude of directions, including lightweight archi-tecture design [23, 77, 22], pruning [15, 20, 70], quantiza-tion [30, 73], etc. In contrast to traditional models, which adhere to a static computational graph during testing, dy-namic networks [16, 3, 35, 61, 18, 64, 65, 79, 78] can adapt their computation with varying input complexities, leading to promising results in efficient visual recognition.
In the field of dynamic networks, dynamic early-exiting
networks [3, 14, 12, 24, 69, 71] construct multiple classi-fiers along the depth dimension, allowing samples that yield high classification confidence at early classifiers, referred to as “easy” samples, to be rapidly predicted without activat-ing deeper layers. Existing implementations mostly build early classifiers on intermediate features [3, 24, 69] (Fig. 1 (a)). However, it has been observed [24] that classifiers will interfere with each other and significantly degrade the per-formance of the final exit. A widely held belief is that deep models generally extract features from a low level to a high level, and it is more appropriate to feed the high-level fea-tures at the end of a network to a linear classifier. Early classifiers in previous literature force intermediate low-level features to encapsulate high-level semantics and be linearly separable. This essentially means that feature extraction and early classification are intricately intertwined. This sub-optimal design invariably undermines the performance of dynamic early-exiting networks.
Ideally, it is expected that 1) there is a latent code which consistently embeds semantic information for direct use in classification tasks; 2) early classification and feature ex-traction should be decoupled, i.e., the acquisition of seman-tic information should be managed by a separate branch, thereby avoiding the necessity of sharing shallow layers in a feature extractor. Under these circumstances, the latent code needs to achieve linear separability, not the low-level image features, preserving the performance of late exits.
The concept of incorporating a latent code is inspired by the general-purpose architecture, Perceiver [29]. This model leverages asymmetric attention to iteratively distill inputs into a latent code, which is then employed for specific tasks.
Despite its impressive ability to process various modalities,
Perceiver’s application in visual recognition encounters a significant challenge in terms of computational cost, partic-ularly when the pixel count in images is substantial.
In this paper, we propose a novel two-branch structure (Fig. 1 (b)), named Dynamic Perceiver (Dyn-Perceiver),
Specifically, a feature for efficient visual recognition. branch extracts image features from a low level to a high level. Concurrently, a trainable latent code, engineered to encapsulate the semantics pertinent to classification, is processed by a classification branch. These two branches progressively exchange information via symmetric cross-attention layers, and the token number of image features is significantly reduced compared to the original Perceiver.
Critically, multiple classifiers are situated solely in the clas-sification branch, enabling early predictions without hinder-ing feature extraction. The outputs from both branches are ultimately fused before being supplied to the final classifier.
Our design boasts three key advantages: 1) feature ex-traction and early classification are explicitly decoupled, and the experiment results in Sec. 4.2 demonstrate that the early classifier in our method even improves the perfor-mance of the last exit; 2) the Dyn-Perceiver framework is simple and versatile. It does away with the need for meticu-lously handcrafted structures as seen in previous approaches
[24, 69, 62]. In essence, we can construct the classification branch on any advanced vision backbones to attain top-tier performance. Such universality also allows Dyn-Perceiver to seamlessly serve as a backbone for downstream tasks such as object detection; 3) the theoretical efficiency of early exiting in Dyn-Perceiver can effectively translate into practical speedup on different hardware devices.
We evaluate the performance of Dyn-Perceiver with mul-tiple visual backbones including ResNet [19], RegNet-Y [49], and MobileNet-v3 [22]. Experiments show that
Dyn-Perceiver significantly outperforms various competing models in terms of the accuracy-efficiency trade-off in Im-ageNet [10] classification. Notably, the inference efficiency of RegNet-Y experiences a remarkable increase of 1.9-4.8× without any compromise in accuracy. The practical la-tency of Dyn-Perceiver is also validated on CPU and GPU platforms. Additionally, our method effectively enhances the performance-efficiency trade-off in action recognition (Something-Something V1 [13]) and object detection tasks.
For instance, Dyn-Perceiver boosts the mean average pre-cision (mAP) of RegNet-Y by 0.9% while diminishing its computation by 43% on the COCO [37] dataset. 2.