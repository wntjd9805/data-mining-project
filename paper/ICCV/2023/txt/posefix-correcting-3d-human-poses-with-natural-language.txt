Abstract
Automatically producing instructions to modify one’s posture could open the door to endless applications, such as personalized coaching and in-home physical therapy. Tack-ling the reverse problem (i.e., refining a 3D pose based on some natural language feedback) could help for as-sisted 3D character animation or robot teaching, for in-stance. Although a few recent works explore the connec-tions between natural language and 3D human pose, none focus on describing 3D body pose differences. In this pa-per, we tackle the problem of correcting 3D human poses with natural language. To this end, we introduce the Pose-Fix dataset, which consists of several thousand paired 3D poses and their corresponding text feedback, that describe how the source pose needs to be modified to obtain the tar-get pose. We demonstrate the potential of this dataset on two tasks: (1) text-based pose editing, that aims at gener-ating corrected 3D body poses given a query pose and a text modifier; and (2) correctional text generation, where instructions are generated based on the differences be-tween two body poses. The dataset and the code are avail-able at https://europe.naverlabs.com/research/ computer-vision/posefix/. 1.

Introduction
How many puzzles could you solve with two human body poses and a description of their differences? Call this description a feedback. It could be automatically generated by a fitness application based on the comparison between the gold standard fitness pose and the pose of John Doe, exercising in front of their smartphone camera in their liv-ing room (“straighten your back”). In another context, the feedback can be considered a modifying instruction, pro-vided by a digital animation artist to automatically modify the pose of a character, without having to redesign every-thing by hand. This feedback could be some kind of con-Figure 1: Illustration of the tasks addressed with the new
PoseFix dataset, which consists of textual descriptions of the difference between two 3D body poses. straint, to be applied to a whole sequence of poses (make them run, but “with hands on the hips!”). It could also be a hint, to guide pose estimation from images in failure cases: start from an initial 3D body pose fit, and give step-by-step instructions for the model to improve its pose estimation (“the left elbow should be bent to the back”).
In this paper, we focus on free-form feedback describing the change between two static 3D human poses (which can be extracted from actual pose sequences). Why so static?
There exist many settings that require the semantic under-standing of fine-grained changes of static body poses. For instance, yoga poses are extremely challenging and specific (with a lot of subtle variations), and they are static. Some sport motions require almost-perfect postures at every mo-ment: for better efficiency, to avoid any pain or injury, or just for better rendering e.g. in classical dance, yoga, karate, etc. What is more, the realization of complex motions some-times calls for precise step-to-step instructions, in order to assimilate the gesture or to perform it correctly.
Natural language can help in all these scenarios, in that it is highly semantic and unconstrained, in addition of being a very intuitive way to convey ideas. While 3D poses can be manually edited within a design framework [38], language is particularly efficient for non-experts or when direct ma-nipulation is not possible. The pose semantic we propose
Figure 2: Examples of pose pairs and their annotated modifier in PoseFix. The source pose is shown in gray and the target pose in purple. Poses from in-sequence (IS) pairs are from the same motion clip; unlike out-of-sequence (OOS) pairs. to learn here can be leveraged for other modalities (e.g. im-ages) or in other settings (e.g. robot teaching).
While the link between language and images has been extensively studied in tasks like image captioning [32, 21] or image editing [64], the research on leveraging natu-ral language for 3D human modeling is still in its in-fancy. A few works use textual descriptions to generate motion [18, 54], to describe the difference in poses from synthetic 2D renderings [25] or to describe a single static pose [12]. Nevertheless, there currently exists no dataset that associates pairs of 3D poses with textual instructions to move from one source pose to one target pose. In this work, we thus introduce the PoseFix dataset, which contains over 6,000 textual modifiers written by human annotators for this scenario. In addition, we design a pipeline similar to [12], to generate modifiers automatically and increase the size of the data, see Figure 2 for some examples.
Leveraging the PoseFix dataset, we tackle two tasks: text-based pose editing, where the goal is to generate new poses from an initial pose and modification instructions, and correctional text generation where the objective is to pro-duce a textual description of the difference between a pair of poses (see Figure 1). For the first task, we use a base-line consisting in a conditional Variational Auto-Encoder (cVAE). For the second, we consider a baseline built from an auto-regressive transformer model. We provide a de-tailed evaluation of both baselines, and show promising re-sults.
In summary, our contributions are threefold:
◦ We introduce the PoseFix dataset (Section 3) that as-sociates pairs of 3D human poses and human-written textual descriptions of their differences.
◦ We introduce the task of text-based pose editing (Sec-tion 4), that can be tackled with a cVAE baseline.
◦ We study the task of correctional text generation with a conditioned auto-regressive model (Section 5). 2.