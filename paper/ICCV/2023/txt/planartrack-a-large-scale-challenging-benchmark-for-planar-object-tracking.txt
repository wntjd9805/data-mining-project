Abstract
Planar object tracking is a critical computer vision prob-lem and has drawn increasing interest owing to its key roles in robotics, augmented reality, etc. Despite rapid progress, its further development, especially in the deep learning era, is largely hindered due to the lack of large-scale challenging benchmarks. Addressing this, we introduce PlanarTrack, a large-scale challenging planar tracking benchmark. Specif-ically, PlanarTrack consists of 1,000 videos with more than 490K images. All these sequences are collected in complex unconstrained scenarios from the wild, which makes Pla-narTrack, compared with existing benchmarks, more chal-lenging but realistic for real-world applications. To ensure the high-quality annotation, each frame in PlanarTrack is manually labeled using four corners with multiple-round careful inspection and refinement. To our best knowledge,
PlanarTrack, to date, is the largest and the most challeng-ing dataset dedicated to planar object tracking. In order to analyze the proposed PlanarTrack, we evaluate 10 planar trackers and conduct comprehensive comparisons and in-depth analysis. Our results, not surprisingly, demonstrate that current top-performing planar trackers degenerate sig-nificantly on the challenging PlanarTrack and more efforts are needed to improve planar tracking in the future. In ad-dition, we further derive a variant named PlanarTrackBB for generic object tracking from our PlanarTrack. Our eval-uation of 10 excellent generic trackers on PlanarTrackBB manifests that, surprisingly, PlanarTrackBB is even more challenging than several popular generic tracking bench-marks and more attention should be paid to handle such planar objects, though they are rigid. All benchmarks and evaluations are released at https://hengfan2010. github.io/projects/PlanarTrack/.
∗The authors make equal contributions and are co-first authors.
†Corresponding author: Libo Zhang (libo@iscas.ac.cn).
Figure 1. Generic object tracking (a) and planar object tracking (b).
The former estimates axis-aligned rectangular bounding boxes for the target object, while the latter (our focus in this work) calculates 2D transformations of the target object to obtain the corresponding corner points for localization. All figures throughout this paper are best viewed in color and by zooming in. 1.

Introduction
Planar tracking is an important problem in computer vi-sion. Different than generic tracking which represents ob-ject with an axis-aligned bounding box, planar tracking rep-resents target with four corners. Besides, the goal of generic tracking is to locate the target with axis-aligned rectangular bounding boxes [10, 38], while planar object tracking aims to estimate 2D transformations (e.g., homograph) of the tar-get and locate it with corner points (see Fig. 1). Owing to its importance in robotics and augmented reality (AR), planar object tracking has attracted increasing attentions in recent years. In particular, several benchmarks (e.g., [20, 31, 19]) have been specially developed for evaluating and comparing different planar trackers, which greatly facilitates related re-search and progress on this topic. Despite this, they are lim-ited in further pushing the frontier of planar tracking.
One of the major issues with existing benchmarks is their
datasets are not suitable for planar tracking. To further fa-cilitate research on deep planar tracking, a dedicated large-scale benchmark is desired, which motivates our work. 1.1. Contributions
In this paper, we propose a novel large-scale benchmark, dubbed PlanarTrack, dedicated for planar object tracking.
Specifically, PlanarTrack consists of 1,000 video sequences.
All these videos are directly collected in complicated uncon-strained scenarios from the wild, which makes PlanarTrack, compared to existing datasets (e.g., [13, 21, 5, 31, 20, 19]), much more challenging yet realistic for real applications.
In order to diversify our PlanarTrack, each planar object ap-pears exclusively in one video, which is different than other datasets. In total, there are over 490K frames in our Planar-Track, and each one is manually labeled using four corner points1 with cautious inspections and refinements to ensure high-qualify annotations. Besides, we offer challenge factor information for each video as in generic tracking [38] to en-able in-depth analysis. To our best knowledge, PlanarTrack, to date, is the largest and most challenging planar tracking dataset. By releasing PlanarTrack, we aim to provide a ded-icated platform for facilitating planar trackers.
In order to analyze PlanarTrack and provide comparisons for future research, we evaluate 10 representative planar ob-ject trackers. Our evaluation exhibits that, not surprisingly, existing top-performing planar trackers severely degrade on more challenging PlanarTrack. For example, the precision (PRE) score (as described later) of WOFT [32] on POT-210 is 0.805 but drops to 0.433 on PlanarTrack, and the score of
HDN [41] drops from 0.612 on POT-210 to 0.263 on Planar-Track. This consistently reveals the difficulties for planar tracking brought by realistic complicated scenes, and more efforts are required for improvements. To provide guidance for future research, we further conduct comprehensive anal-ysis to analyze challenges in planar tracking and discuss po-tential directions to facilitate related research. Besides, our re-training experiments show the usefulness and effective-ness of our benchmark in performance enhancement.
Furthermore, as a by-product of PlanarTrack, we develop a new variant, PlanarTrackBB, which is suitable for generic box tracking. We aim at large-scale learning and evaluation of generic object trackers on localizing rigid targets, which is rarely investigated before. Our experiments on assessing 10 recent Transformer-based generic trackers reveals heavy performance degeneration on PlanarTrackBB compared with their performance on large-scale generic tracking datasets (e.g., LaSOT [10] and TrackingNet [27]) and more attention is needed in handling planar objects, though they are rigid.
In summary, our main contributions are as follows:
⋄ We introduce a novel benchmark termed PlanarTrack 1Four points are the least number of points to determine the homograph of two planar objects, which is the reason to use four points for annotation.
Figure 2. Summary of planar object tracking datasets, containing
POT-280 [19], POT-210 [20], TMT [31], UCSB [13], Metiao [21],
POIC [5], and PlanarTrack. The circle diameter is in proportion to the number of frames of a dataset. Our PlanarTrack is the largest. relatively small scales. Especially, in the deep learning era, to unleash the potential of deep planar tracking, it is desired to have a large-scale platform. Nevertheless, as displayed in Fig. 2, currently all planar tracking benchmarks consist of less than 300 sequences, which is insufficient for large-scale learning of deep planar tracking. As a consequence, researchers are forced to leverage synthetic data generated from images (e.g., [23]) for transformation learning in deep planar tracking, which may result in inferior performance due to domain gap between different tasks.
Besides the small-scale issue, another problem is the less challenging scenarios for planar object tracking. Early pla-nar tracking datasets (e.g., [21, 31, 13, 5]) are constructed from the indoor laboratories with simple background, which cannot reflect the diverse and complicated scenarios of real world in performance evaluation. To deal with this, recent datasets (e.g., [20, 19]) directly collect videos in the wild.
However, most of these videos are mainly involved with one challenge factor (or attribute in generic tracking), and very few (e.g., 30 in [20] and 40 in [19]) contain multiple chal-lenges (i.e., the unconstrained condition). This may weaken the difficulties of planar tracking in the wild where arbitrary challenges could exist, and thus restricts datasets in assess-ing generalization of planar tracking in natural scenarios.
Furthermore, the diversity of current benchmarks is lim-ited. In particular, the same planar target object is usually employed in multiple videos, which significantly decreases the diversity in target appearance. Even for current largest benchmark [19] (one target used in 7 videos), the number of planar targets does not exceed 40 (see Tab. 1). Such lack of diversity makes it difficult to use current datasets for faithful assessment of planar trackers in practice.
We are aware that there exist several large-scale datasets (e.g., [27, 10, 16]) for generic tracking. Nevertheless, due to different setting and goal (see Fig. 1 again), these generic
Table 1. Detailed comparison of the proposed PlanarTrack with other existing planar object tracking benchmarks.
Unconstrain-ed Videos
Annotated frames
Targets Videos
Mean frames
Total frames
Max frames
Min frames
Year
Benchmark
Metaio [21]
UCSB [13]
TMT [31]
POIC [5]
POT-210 [20]
POT-280 [19]
PlanarTrack (ours) 2009 2011 2015 2017 2018 2021 2023 8 6 12 20 30 40 1,000 40 96 109 20 210 280 1,000 1,200 13 191 283 501 501 317 1,200 72 648 1,149 501 501 490 1,200 500 2,518 2,666 501 501 549 48K 7K 71K 23K 105K 140K 490K 48K 7K 71K 23K 53K 70K 490K n/a n/a n/a n/a 30 40 1,000
In the wild
✗
✗
✗
✗
✓
✓
✓ for planar tracking. To the best of our knowledge, Pla-narTrack is to date the largest as well as the most chal-lenging planar tracking benchmark in the wild.
⋄ We conduct comprehensive evaluations to analyze Pla-narTrack and provide comparison for future research.
⋄ We conduct retraining experiments to validate the ef-fectiveness of the proposed PlanarTrack in improving deep planar tracking performance.
⋄ Based on PlanarTrack, we develop PlanarTrackBB for generic tracking on planar-like targets and conduct ex-tensive evaluation and analysis. 2.