Abstract
For homography estimation, we propose Geometrized
Transformer (GeoFormer), a new detector-free feature matching method. Current detector-free methods, e.g.
LoFTR, lack an effective mean to accurately localize small and thus computationally feasible regions for cross-attention diffusion. We resolve the challenge with an ex-tremely simple idea: using the classical RANSAC geome-try for attentive region search. Given coarse matches by
LoFTR, a homography is obtained with ease. Such a ho-mography allows us to compute cross-attention in a fo-cused manner, where key/value sets required by Transform-ers can be reduced to small fix-sized regions rather than an entire image. Local features can thus be enhanced by standard Transformers. We integrate GeoFormer into the LoFTR framework. By minimizing a multi-scale cross-entropy based matching loss on auto-generated training data, the network is trained in a fully self-supervised man-ner. Extensive experiments are conducted on multiple real-world datasets covering natural images, heavily manipu-lated pictures and retinal images. The proposed method compares favorably against the state-of-the-art. 1.

Introduction
Homography estimation, also known as perspective transformation or planar projection, is a fundamental prob-lem in computer vision and robotics. It involves estimat-ing a 3 × 3 matrix that maps corresponding points in two images taken from different viewpoints, assuming that the scene is planar. Homography estimation has various appli-cations including image/video stitching [32, 7], camera cali-bration [33], object recognition [17], and 3D reconstruction
[19, 34], etc. The problem is challenging due to various fac-tors such as occlusions, noise, and perspective distortions.
*Corresponding author.
Various techniques have been developed to estimate ho-mography efficiently and accurately. These include match-ing based methods [18, 4, 22] and unsupervised deep ho-mography methods [10, 16, 31]. Matching based methods detect distinctive features such as keypoints or corners from given images and then match the features for homography estimation. SuperGlue [24], for instance, employs Super-Point [4] for feature detection and description, and then uses
Transformers [29] to enhance the features by self-attention and cross-attention. The method however suffers from the lack of discriminative features when dealing with texture-less or blurry images [23]. Deep homography methods, on the other hand, directly minimize the photometric or feature differences between two images. As such, they can be sen-sitive to errors or ambiguities in the data, making them diffi-cult to handle image pairs with a large baseline [16, 31, 10].
A novel trend is to develop detector-free feature match-ing methods, see NCNet [23], LoFTR [26], ASpanFormer
[3] and DKM [6]. These methods find matches by dense pixel-to-pixel matching, with no need for keypoint detec-tion. Conceptually, LoFTR can be viewed as a detector-free variant of SuperGlue. Being detector-free means the num-ber of features to be updated by Transformers is equal to the number of pixels.
In order to update high-resolution feature maps at affordable computational cost, LoFTR has to replace the normal Transformers with linear Transform-ers [11]. However, the latter tends to diffuse among large areas instead of focusing sharply on corresponding regions
[3, 27]. Consequently, noise can be introduced during fea-ture updating, resulting in incorrect matches.
In order to localize attention regions that are computationally feasible for the normal Transformers, ASpanFormer regresses flow maps in each cross-attention phase. However, flow map re-gression can be error-prone, see Fig. 1a.
In order to support local feature interaction and enhance-ment with standard Transformers, we propose in this pa-per Geometrized Transformer (GeoFormer). Our idea is ex-tremely simple. Instead of flow map regression, we propose
(a) ASpanFormer (b) GeoFormer (this paper)
Figure 1: Visualizing cross-attention diffusion regions of (a) ASpanFormer [3] and (b) the proposed GeoFormer. Per image pair, a specific query point is shown in green dot on the left-hand image, while its cross-attention region (i.e. the key / value set) is shown in green dots on the right-hand image. ASpanFormer uses flow map regression, which appears to be inaccurate.
By contrast, GeoFormer exploits the RANSAC geometry to identify small yet geometrically verified regions. to use the classical RANSAC geometry for attentive region search. As shown in Fig. 1b, the geometry allows us to compute cross-attention in a focused manner such that the key / value set required by the Transformers can be reduced to small fix-sized regions on the feature maps. Viewing these geometrically localized regions as keypoints detected at a coarse level, the proposed method essentially refines lo-cal features in a detector-based manner, whilst matching the refined features in a detector-free manner.
In sum, our main contributions are as follows:
• We propose GeoFormer, a new detector-free feature matching method for homography estimation. With the proposed sparse self-attention and focused cross-attention blocks, local feature updates are achieved with standard
Transformers, which have more accurate attention diffusion regions than linear Transformers.
• GeoFormer is integrated with ease into LoFTR, see Fig. 2. By minimizing a multi-scale cross-entropy based match-ing loss on auto-generated training data, the entire network is end-to-end trained in a fully self-supervised manner.
• Experiments on natural images [2], heavily edited pictures
[5] and retinal images [9] show that GeoFormer compares favorably against the state-of-the-art. Code is released. 2.