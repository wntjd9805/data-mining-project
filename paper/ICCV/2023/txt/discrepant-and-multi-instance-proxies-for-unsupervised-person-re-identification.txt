Abstract
Most recent unsupervised person re-identification meth-ods maintain a cluster uni-proxy for contrastive learning.
However, due to the intra-class variance and inter-class similarity, the cluster uni-proxy is prone to be biased and confused with similar classes, resulting in the learned fea-tures lacking intra-class compactness and inter-class sep-aration in the embedding space. To completely and ac-curately represent the information contained in a cluster and learn discriminative features, we propose to maintain discrepant cluster proxies and multi-instance proxies for a cluster. Each cluster proxy focuses on representing a part of the information, and several discrepant proxies collabo-rate to represent the entire cluster completely. As a com-plement to the overall representation, multi-instance prox-ies are used to accurately represent the fine-grained infor-mation contained in the instances of the cluster. Based on the proposed discrepant cluster proxies, we construct clus-ter contrastive loss to use the proxies as hard positive sam-ples to pull instances of a cluster closer and reduce intra-class variance. Meanwhile, instance contrastive loss is con-structed by global hard negative sample mining in multi-instance proxies to push away the truly indistinguishable classes and decrease inter-class similarity. Extensive exper-iments on Market-1501 and MSMT17 demonstrate that the proposed method outperforms state-of-the-art approaches. 1.

Introduction
Unsupervised person re-identification (Re-ID) aims to retrieve images of a particular person across camera views and scenes without annotations [35, 48]. Most unsupervised methods adopt a two-step alternating training scheme: 1) generating pseudo labels by k-nearest neighbor search [34, 42] or clustering [15, 13, 27, 43, 8]; 2) training the model based on a uni-proxy (i.e., cluster centroid [9] or learnable weight [13]) of each cluster. However, due to the intra-class
*Corresponding author
Figure 1. An illustration demonstrating that global hard negatives are more effective than batch hard in promoting inter-class sepa-ration. Different shapes represent different classes. (a) The batch hard negatives are the ones easy to distinguish. b) Our global hard negatives are the truly hardest and most informative samples of in-distinguishable classes. variance and inter-class similarity caused by the changeable human pose, illumination, and camera views [54], a uni-proxy /is often biased and confused, failing to fully and accurately describe the information of a cluster. As a re-sult, the features learned based on the uni-proxy are not compact and have unclear cluster boundaries in the embed-ding space, which in turn affects the quality of clustering.
In order to learn discriminative features, CAP [36] subdi-vides each cluster to obtain multiple camera-aware prox-ies, pulling an instance (i.e., sample) closer to all proxies in the cluster to alleviate intra-class variance. The later works
ICE [2] and PPLR [7] adopt the same strategy. Although these methods improve the compactness of clusters, they depend on extra labels and ignore the intra-class variance caused by factors other than camera views. On the other hand, several works [46, 14, 7] focus on reducing inter-class similarity to learn discriminative features. They consider performing batch hard negative sample mining [20] to pro-mote inter-class separation. However, as shown in Figure 1, due to the randomness of sampling, the negative samples selected for a query from the mini-batch may not be true hard negatives in the global embedding space, and therefore cannot enlarge the inter-class separation of actual indistin-guishable classes.
To reduce intra-class variance without relying on addi-tional annotations, we propose to use several discrepant cluster proxies to complementarily represent a cluster. Each
2.