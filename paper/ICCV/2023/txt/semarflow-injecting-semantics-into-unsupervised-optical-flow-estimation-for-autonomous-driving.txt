Abstract
Unsupervised optical flow estimation is especially hard near occlusions and motion boundaries and in low-texture regions. We show that additional information such as semantics and domain knowledge can help better con-strain this problem. We introduce SemARFlow, an un-supervised optical flow network designed for autonomous driving data that takes estimated semantic segmentation masks as additional inputs. This additional information is injected into the encoder and into a learned upsam-pler that refines the flow output.
In addition, a simple yet effective semantic augmentation module provides self-supervision when learning flow and its boundaries for ve-hicles, poles, and sky. Together, these injections of se-mantic information improve the KITTI-2015 optical flow test error rate from 11.80% to 8.38%. We also show vis-ible improvements around object boundaries as well as a greater ability to generalize across datasets. Code is available at https://github.com/duke-vision/ semantic-unsup-flow-release. 1.

Introduction
Optical flow estimation, i.e., pixel-level motion tracking across video frames, has broad applications in many com-puter vision tasks that include object tracking [61], video editing [14, 31], and autonomous driving [6, 58].
Thanks to the success of deep convolutional neural net-works [34, 17, 36] and transformer networks [33, 69, 88, 28] in computer vision, many top-performing supervised opti-cal flow networks have been proposed in recent years [10, 65, 22, 68, 85], in which ground-truth labels supervise train-ing. However, real optical flow is hard to label, so most supervised methods train (or at least pre-train) on synthetic datasets [10, 44, 4, 56] which makes them hard to adapt to real applications due to the significant gap between syn-thetic and real data [70, 29].
Figure 1. An example on KITTI-2015 test set (sample #63). Only one input frame is shown for conciseness. Our SemARFlow takes additional semantic segmentation inputs (estimated by an off-the-shelf model) and outputs much sharper flow around seman-tic boundaries. flow estimators [81] instead uses loss terms based on the assumptions of constant brightness and smooth flow [45, 27, 42]. Some self-supervision techniques have also been studied to enhance model performance [38, 39, 37]. Unsu-pervised training makes it possible to train flow networks directly on large real datasets from the target domain.
Even so, unsupervised optical flow estimation is a poorly constrained problem. Brightness is not constant in re-gions with occlusions [72] or on shiny surfaces [43], nor is it smooth across motion boundaries [30, 82]. Moreover, points in regions with poor texture content [59] or in dark shadows [58] are difficult to track as they are easily con-fused with neighboring points (the so-called aperture prob-lem). This dearth of reliable constraints makes the unsuper-vised training of flow networks especially challenging.
A natural way to address this issue is to inject additional constraints in the form of semantics and domain knowledge.
For example, in autonomous driving applications [84, 6], we have clear expectations about object types and layouts of the scene, as well as prior knowledge of how each type of object typically moves. We focus on this application do-main and show that this additional information helps the network achieve better flow results.
Due to label scarcity, unsupervised training of optical
To make an autonomous driving system work well in
reality, it is best to train it on real data. However, anno-tating real driving video with optical flow labels is expen-sive [83], as it requires careful synchronization and cali-bration of diverse sensors including cameras, LiDAR, and
GPS/IMU [16], aided by some manual annotation and cura-tion based on CAD models of moving objects [46].
In contrast, annotating semantic labels seems much more feasible, and indeed semantic labels are available in most (if not all) existing driving datasets. We consider semantic seg-mentation because it provides semantics at the pixel level, the same level as optical flow. As one of the most popular and well-studied tasks in modern computer vision, semantic segmentation [40, 47, 87] has been extensively adopted for autonomous driving systems. In this paper, we show that adding semantic segmentation inputs helps improve unsu-pervised optical flow performance significantly.
Specifically, we first infer semantic segmentation maps using an off-the-shelf model [89], which of course is trained with semantic labels. An encoder with semantic map input is used to aggregate image and semantic features (Sec. 3.1), and a learned upsampler is added into the iterative decoder to refine flow around object boundaries given semantic in-puts (Sec. 3.2). We also propose a simple yet effective semantic augmentation module for self-supervision, which provides realistic augmentations specific to the vehicles, poles, and sky classes based on domain knowledge and seg-mentation maps (Sec. 3.3). An occluder cache is imple-mented to improve efficiency (Sec. 3.4). Semantic augmen-tation provides challenging samples for self-supervision, which help train flow better in occluded regions and around foreground object boundaries.
Overall, by injecting semantic segmentation inputs, our
SemARFlow network achieves significantly better unsuper-vised flow results both quantitatively (Sec. 4.3) and qualita-tively (Sec. 4.4). Adapted from ARFlow [37], SemARFlow reduces KITTI-2015 [46] test error from 11.80% to 8.38% and out-performs the current unsupervised state-of-the-art
UPFlow [42] (9.38%) by a clear margin. The example in
Fig. 1 also demonstrates visible improvements around ob-ject boundaries. The effectiveness of each module is justi-fied through an extensive ablation study (Sec. 4.5) and im-provement analysis (Sec. 4.6). In addition to performance boost, unsupervised flow networks with additional semantic inputs generalize better across different datasets (Sec. 4.7).
Our research is essentially novel compared to previous approaches. Some early work incorporates semantics in tra-ditional energy-minimization methods [41, 18] for optical flow through geometric constraints such as piece-wise rigid motion and planar surface motion [57, 21, 1, 75]. In com-parison, to the best of our knowledge, we are the first to inject semantics into the unsupervised training of recent op-tical flow networks. Some research also trains a network for segmentation and optical flow jointly [9]. In contrast, we leverage existing, separately trained segmentation systems both because they are available and because modularity— separating segmentation from flow estimation—is impor-tant for the development of large real-application systems such as autonomous driving.
In summary, our contributions are as follows.
• To the best of our knowledge, we are the first to ex-plore adding semantic inputs to assist the unsupervised training of deep optical flow networks.
• We propose a simple yet effective network called Se-mARFlow that achieves state-of-the-art results both quantitatively and qualitatively. Our model works well on real-life occlusions and yields sharp motion bound-aries around objects.
• We provide full training and inference code as well as trained models to encourage follow-up research. 2.