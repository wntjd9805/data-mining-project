Abstract
Given monocular videos, we build 3D models of artic-ulated objects and environments whose 3D configurations satisfy dynamics and contact constraints. At its core, our method leverages differentiable physics simulation to aid visual reconstructions. We couple differentiable physics simulation with differentiable rendering via coordinate de-scent, which enables end-to-end optimization of, not only 3D reconstructions, but also physical system parameters from videos. We demonstrate the effectiveness of physics-informed reconstruction on monocular videos of quadruped animals and humans.
It reduces reconstruction artifacts (e.g., scale ambiguity, unbalanced poses, and foot swap-ping) that are challenging to address by visual cues alone, and produces better foot contact estimation. 1.

Introduction
Given casually-captured monocular RGB videos, we aim to build 3D models of articulated objects and the environ-ment, whose configurations (geometry, motion trajectory, force, and mass distribution) satisfy physics constraints, and can be replayed in a physics simulator.
Reconstructing dynamic 3D structures from monocu-lar videos is challenging due to the under-constrained na-ture of the problem. Prior works often leverage first order constraints. For instance, Nonrigid-SfM explores temporal smoothness and low-rank priors [4] to constrain the prob-lem. Recent works on differentiable rendering and dynamic
NeRF utilize divergence-free motion fields [42] or as-rigid-as-possible priors [20]. Although those methods are able to obtain visually appealing reconstruction results from the reference viewpoint, physically-implausible configurations, such as foot sliding, statically-unstable poses, etc., are often observed from a novel viewpoint. An illustrative example is shown in Fig. 2.
Physics as a prior. We seek a more principled way to model the time-varying behavior of an object and its interaction with the environment using physics constraints. Physical priors tend to be relatively unexplored as a tool for aiding reconstruction, though important exceptions exist in the do-main of monocular human motion capture [8, 50, 53]. One reason that such methods are not more widespread is that they often make strong assumptions about the target and the scene, for instance, accurate 2D/3D keypoint tracking, known ground plane, and contact state annotations. More-over, operationalizing such constraints requires the use of
2.