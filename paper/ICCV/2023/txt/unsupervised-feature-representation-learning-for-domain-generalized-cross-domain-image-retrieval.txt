Abstract
Cross-domain image retrieval has been extensively stud-In recently proposed ied due to its high practical value. unsupervised cross-domain image retrieval methods, efforts are taken to break the data annotation barrier. However, applicability of the model is still confined to domains seen during training. This limitation motivates us to present the first attempt at domain-generalized unsupervised cross-domain image retrieval (DG-UCDIR) aiming at facilitat-ing image retrieval between any two unseen domains in an unsupervised way. To improve domain generalizability of the model, we thus propose a new two-stage domain aug-mentation technique for diversified training data genera-tion. DG-UCDIR also shares all the challenges present in the unsupervised cross-domain image retrieval, where domain-agnostic and semantic-aware feature representa-tions are supposed to be learned without external super-vision. To accomplish this, we introduce a novel cross-domain contrastive learning strategy by utilizing phase image as a proxy to mitigate the domain gap. Exten-sive experiments are carried out using PACS and Domain-Net dataset, and consistently illustrate the superior per-formance of our framework compared to existing state-of-the-art methods. Our source code is available at https:
//github.com/conghui1002/DG-UCDIR. 1.

Introduction
Cross-domain image retrieval finds a variety of applica-tions in online shopping [15, 31], law enforcement [18, 20], etc. Most existing cross-domain image retrieval algorithms
[27, 32] heavily rely on category and pair annotations to drive explicit semantic-aware and domain-invariant feature learning for retrieval. One emerging research direction for reducing data labeling cost is unsupervised cross-domain image retrieval (UCDIR) [9, 10], where human annotation is no longer necessary for model training and the trained model can be employed to conduct retrieval between seen
Figure 1. Illustration of DG-UCDIR. Given only unlabeled train-ing domain data, the objective of DG-UCDIR is to facilitate re-trieval between unseen domains. domains. However, even the raw image can be labor-intensive to acquire for some domains such as sketch. As reported in [6], the median drawing time for one non-expert sketch in the TU-Berlin dataset is 86 seconds. This largely motivates us to investigate the domain-generalized unsu-pervised cross-domain image retrieval (DG-UCDIR) that sidesteps both data labeling and collection barriers, as il-lustrated in Fig. 1. Specifically, our ultimate goal is to leverage only unlabeled data from a pair of seen domains, e.g., art painting and real photo, to train a feature extractor which is capable of projecting imagery input from any un-seen domain, e.g., sketch and cartoon, into a domain invari-ant shared feature space. Images from one unseen domain, e.g., sketch, can then be used as queries to conduct retrieval of the same category data from another unseen domain, e.g., cartoon. Consequently, DG-UCDIR is particularly valuable for those domains with data scarcity bottleneck.
Nevertheless, DG-UCDIR is an extremely challenging task due to the requirements of: 1) Novel domain gener-alizability. Given data from only the seen domain, we aim to facilitate image retrieval across to unseen domains, i.e., endow trained model with domain generalizability. Both existing supervised [32] and unsupervised [9] cross-domain image retrieval methods are not suited for direct testing on the novel domains since they are designed for spe-cific domain pairs and thus is highly susceptible to fail-ure on unseen novel domains. 2) Domain-agnostic un-supervised feature learning. The absence of category label or pairwise supervision for the seen domains dur-ing training, makes it extremely difficult for the model to learn semantically meaningful and domain-invariant fea-tures for effective category-level retrieval. The task then boils down to domain-agnostic unsupervised feature rep-resentation learning. Although contrastive learning [2, 3] has shown great promise in the context of unsupervised learning, the vanilla contrastive learning algorithm neglects influence of domain-specific knowledge and thus still suf-fers from the inability to mitigate domain shift and features alignment from different domains.
In this paper, we introduce a novel deep learning frame-work that simultaneously performs unseen domain gener-alization and domain-agnostic feature learning in an unsu-pervised paradigm. To address the first challenge of DG-UCDIR, we propose a new domain augmentation strategy by exploiting inherent characteristics of frequency domain data. More concretely, Fourier transform is employed to convert the RGB image into the disentangled phase and amplitude component in the frequency domain. According to [29] and [30], class-discriminative knowledge is mainly contained in the high-frequency portion of the phase part.
We thus design a two-stage domain augmentation technique by first augmenting the low-frequency phase component, followed by the amplitude component distortion of the orig-inal image, while keeping the semantic information use-ful for image retrieval unchanged. As a result, our frame-work can be more resilient to the overfitting on seen do-mains during training compared to existing cross-domain image retrieval methods. For domain-agnostic unsuper-vised feature learning, we devise a set of phase-enhanced contrastive losses to: 1) remedy shifts in the seen domains that would hinder the effective training of feature extrac-tor; 2) further bridge the gap between seen and unseen do-mains for better generalization; 3) mitigate the discrepancy between unseen domains for more effective cross-domain image retrieval. Intuitively, we leverage the smaller domain gap between phase images compared to their RGB counter-parts (c.f . Fig. 2) to conduct unsupervised feature learning.
Specifically, we formulate: 1) a phase-enhanced instance-instance contrastive loss by regarding the phase image as the positive pair of the corresponding RGB input, i.e., the phase image is adopted as a proxy to ameliorate the domain discrepancy and align features from various domains; 2) a phase-enhanced instance-centroid contrastive loss, where centroids shared by different domains are measured based on the phase image features to help pull semantically simi-lar instance closer across domains.
Our main contributions are summarized as follows: 1. We introduce a new research direction of domain-generalized unsupervised cross-domain image retrieval
Figure 2. Smaller domain gaps are seen in the phase images com-pared to the RGB guitar images from four domains in Figure 1. (DG-UCDIR) which aims at advancing the practical ap-plication of image retrieval. 2. A two-stage domain augmentation strategy is proposed to increase the data diversity for superior novel domain generalizability. 3. We design the phase-enhanced instance-instance and instance-centroid contrastive losses to effectively facil-itate the unsupervised domain-invariant and semantic-aware feature learning. 4. Extensive experiments on PACS and DomainNet vali-date the efficacy of our proposed framework on DG-UCDIR. 2.