Abstract
Phase I: Self-supervised learning on  state-action interactions from  diverse episodes 
We introduce DualMind, a generalist agent designed to tackle various decision-making tasks that addresses chal-lenges posed by current methods, such as overﬁtting behav-iors and dependence on task-speciﬁc ﬁne-tuning. DualMind uses a novel “Dual-phase” training strategy that emulates how humans learn to act in the world. The model ﬁrst learns fundamental common knowledge through a self-supervised objective tailored for control tasks and then learns how to make decisions based on different contexts through imitat-ing behaviors conditioned on given prompts. DualMind can handle tasks across domains, scenes, and embodiments using just a single set of model weights and can execute zero-shot prompting without requiring task-speciﬁc ﬁne-tuning. We evaluate DualMind on MetaWorld [40] and
Habitat [31] through extensive experiments and demon-strate its superior generalizability compared to previous techniques, outperforming other generalist agents by over 50% and 70% on Habitat and MetaWorld, respectively. On the 45 tasks in MetaWorld, DualMind achieves over 30 tasks at a 90% success rate. Our source code is available at https://github.com/yunyikristy/DualMind. 1.

Introduction
Transformer-based models, combined with large-scale data, have shown success in generalizing across various tasks in both language and vision. Notable examples in-clude BERT [11], GPT [28], MAE [16], CLIP [27] and
Flamingo [1], etc. Recently, there has been a signiﬁcant fo-cus on developing such general-purpose models for sequen-tial decision-making and control tasks, such as GATO [32].
The prominent approach is to train a decoder-only Trans-former with Imitation Learning (IL) on massive datasets from all targeted tasks. By training with prompts, the model can perform zero-shot inference with just task prompts.
DualMind
Task 1
Task 2
Task 3
Task 4
Task N
Phase II: Imitation Learning from  prompts conditions
Navigate to: 
Navigate to: 
Navigate to the <sofa> 
“open the door” 
Figure 1: A high-level overview of DualMind’s Dual-phase training scheme.
However, such IL-based approaches to general-purpose models face limitations when it comes to sequential con-trol tasks, as highlighted below: (1) Memorizing behav-iors hinders generalization to diverse tasks: Imitating ex-pert behaviors can lead to memorization and over-ﬁtting of speciﬁc behaviors that may not be applicable to new situa-tions or variations of tasks, thus limiting the model’s abil-ity to generalize. This limitation is particularly challenging when dealing with a wide range of decision-making tasks that have vastly different conﬁgurations, transition func-tions, and state and action spaces. (2) Dependence on high-quality data impedes practical application: IL methods rely heavily on the availability of high-quality expert demonstra-tions, which can be difﬁcult and expensive to obtain. When the available data is of low quality or not representative of the target task, the performance of the model may suffer.
In light of the aforementioned limitations, self-supervised pretraining has emerged as a viable solution.
By focusing on learning common underlying information, a pretrained model can be better equipped to handle diverse tasks. Recently, a study known as SMART [36] has demon-strated the potential of self-supervised pretraining for multi-task decision-making. 2.