Abstract
We address the problem of aligning real-world 3D data of garments, which benefits many applications such as tex-ture learning, physical parameter estimation, generative modeling of garments, etc. Existing extrinsic methods typi-cally perform non-rigid iterative closest point and struggle to align details due to incorrect closest matches and rigid-ity constraints. While intrinsic methods based on functional maps can produce high-quality correspondences, they work under isometric assumptions and become unreliable for garment deformations which are highly non-isometric. To achieve wrinkle-level as well as texture-level alignment, we present a novel coarse-to-fine two-stage method that lever-ages intrinsic manifold properties with two neural defor-mation fields, in the 3D space and the intrinsic space, re-spectively. The coarse stage performs a 3D fitting, where we leverage intrinsic manifold properties to define a man-ifold deformation field. The coarse fitting then induces a functional map that produces an alignment of intrin-sic embeddings. We further refine the intrinsic alignment with a second neural deformation field for higher accu-racy. We evaluate our method with our captured garment dataset, GarmCap. The method achieves accurate wrinkle-level and texture-level alignment and works for difficult garment types such as long coats. Our project page is https://jsnln.github.io/iccv2023 intrinsic/index.html. 1.

Introduction
The research into building realistic animatable human avatars has drawn increasing attention in the past few years.
Recent developments have demonstrated that compared with full-body avatars [8, 24, 26, 29, 31, 43, 63, 64], meth-ods utilizing accurately aligned garment scans to explicitly model garments produce much more realistic geometric de-formations and/or rendering results [15, 18, 55, 56], and enable or improve a number of downstream tasks such as retargeting [38], texture learning [55, 56], pose-driving gar-Figure 1. Our method can align deformed versions of a garment to the extent that both texture patterns and geometric details are accurately matched. Various types of garments can be handled, including difficult ones such as coats. ment animation [18] and virtual try-on [9, 32].
In this paper, we focus on the problem of aligning gar-ments. Existing methods for aligning garments are mostly extrinsic [6, 30, 38, 52, 55, 56, 61]. These methods directly operate in the extrinsic space, i.e., the 3D space, typically by fitting a template shape to target shapes in a non-rigid iterative closest point (ICP) manner. Extrinsic methods eas-ily suffer from incorrect point matches, making it difficult to align details and even the overall shape. This problem becomes more severe for garments, due to their complex deformations as well as articulated motions.
On the other hand, intrinsic methods [2, 12, 19, 27, 33, 37, 42] leverage intrinsic manifold properties, most com-monly the eigenfunctions of the Laplace-Beltrami operator (LBO) [35], which are independent of the extrinsic shape and therefore also free from incorrect matches in the ex-trinsic space. These high-dimensional intrinsic embeddings are also smoother than their extrinsic counterparts, and
are easier to align. Current mainstream methods for this purpose are mostly based on the Functional Maps frame-work [37], where one estimates a linear functional map be-tween two intrinsic embeddings. Unfortunately, directly applying the Functional Maps framework [37] for intrinsic garment alignment still poses challenges. Since a functional map typically needs to be computed using shape descriptor constraints [3, 44, 51], they are more suitable for as-rigid-as-possible deformations. Garments, on the other hand, can stretch, shear and bend, rendering shape descriptors unreli-able for functional map estimation. Moreover, the linear as-sumption of a functional map becomes insufficient for gar-ments due to their non-isometric deformations.
In this work, we resolve these challenges by proposing two neural deformation fields to align the intrinsic embed-dings of garments in a coarse-to-fine manner. Our method works in two stages.
In the first stage, we use a neural deformation field to obtain a coarse 3D alignment of the source and the target, which induces a functional map to align their intrinsic embeddings. This bypasses the need for descriptors to estimate functional maps as in previous work [2, 12, 27, 37]. Furthermore, we use an intrinsic neu-ral field [21] to implement this deformation. Leveraging intrinsic features makes this deformation field robust to de-fects such as self-contact or self-intersections of the base template, allowing us to handle difficult garment types, e.g., long coats.
In the second stage, the intrinsic alignment is further refined with a second neural deformation field.
This differs from traditional (linear) functional maps by in-troducing non-linearity to the Functional Maps framework.
We remark that the necessity of introducing non-linearity for garments is rooted in their highly non-rigid and non-isometric deformations. An analysis of the necessity of non-linearity will be provided in the supplementary mate-rials. We demonstrate that our two-stage pipeline can align garment to the extent that both geometry and texture are ac-curately matched (Fig. 1). To summarize, our contributions include:
• We propose a two-stage pipeline for aligning highly non-rigid 3D garment data, leveraging intrinsic man-ifold properties and neural deformation fields to achieve high-accuracy results.
• In the first stage, we propose an intrinsic neural de-formation field that leverages intrinsic manifold prop-erties. Such intrinsic fields do not suffer from self-contact or self-intersections of the base template. To the best of our knowledge, we are the first to use in-trinsic neural fields for modeling deformations.
• In the second stage, we propose another neural defor-mation field that introduces non-linearity to the Func-tional Maps framework. This allows us to achieve texture-level high-accuracy alignment. We also pro-vide a theoretical analysis why this is necessary in the supplementary material.
• We collect a dataset of high-quality 3D garment data, including difficult garment types such as long coats. 2.