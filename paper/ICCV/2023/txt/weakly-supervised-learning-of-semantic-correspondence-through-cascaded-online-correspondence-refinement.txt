Abstract
Caltech-UCSD Birds [Technical Report 2010]
CUB describes fine-grained bird species.
PF-PASCAL & PF-WILLOW [TPAMI 2017]
PFs describe 20 classes of common object.
In this paper, we develop a weakly supervised learning algorithm to learn robust semantic correspondences from large-scale datasets with only image-level labels. Following the spirit of multiple instance learning (MIL), we decom-pose the weakly supervised correspondence learning prob-lem into three stages: image-level matching, region-level matching, and pixel-level matching. We propose a novel cascaded online correspondence reﬁnement algorithm to integrate MIL and the correspondence ﬁltering and reﬁne-ment procedure into a single deep network and train this network end-to-end with only image-level supervision, i.e., without point-to-point matching information. During the correspondence learning process, pixel-to-pixel matching pairs inferred from weak supervision are propagated, ﬁl-tered, and enhanced through masked correspondence vot-ing and calibration. Besides, we design a correspondence consistency check algorithm to select images with discrim-inative key points to generate pseudo-labels for classical matching algorithms. Finally, we ﬁlter out about 110,000 images from the ImageNet ILSVRC training set to for-mulate a new dataset, called SC-ImageNet. Experiments on several popular benchmarks indicate that pre-training on SC-ImageNet can improve the performance of state-of-the-art algorithms efﬁciently. Our project is available on https://github.com/21210240056/SC-ImageNet. 1.

Introduction
Learning semantic correspondence between object in-stances of the same category has become a fundamental problem in computer vision [9, 13]. Semantic matching methods have various applications in few shot learning [22,
∗: Equal Contribution
†: Corresponding Author
Image number: 5,794  
Image Pairs: 10,000(Randomly sampled)
Object category: 200
Key points per image: 15
Image number: 1,345 & 100  
Image Pairs: 1,345 & 900 
Object category: 20 & 10
Key points per image: 4 ~ 17
Spair-71k [ICCV 2019]
Spair describes 18 categories of common  object with challenging context.
SC-ImageNet [Ours]
SC-ImageNet contains a much larger number  of general object or scene categories.
Image number: 1,800  
Image Pairs: 70,958
Object category: 18
Key points per image: 3 ~ 30
Image number: 113,516
Image Pairs: 794,612 (Auto Labeled)
Object category: 679
Key points per image: 32
Figure 1. Annotation statistics of three popular semantic matching datasets and our SC-ImageNet. Green circles and lines demon-strate key-point and semantic correspondence relationship anno-tated by humans. Yellow circles and lines are our automatically generated pseudo-labels. 14], multi-object tracking [25], image editing [19, 31] and etc. With the breakthrough of deep learning, state-of-the-art algorithms have achieved impressive achievements [9, 44, 14]. However, current popular semantic correspon-dence datasets, such as FG3DCar [37], PF-PASCAL [13],
SPair71k [28] and Caltech-UCSD Birds [39], only contain limited annotated samples and thus weaken the generaliza-tion ability of existing algorithms.
Different from other visual recognition tasks [7, 45, 21, 46, 15], building dense semantic correspondence datasets needs to identify important object parts or salient feature points, which is much more complex and labor-expensive.
Figure 1 illustrates the annotation statistics of three popu-lar semantic matching datasets. As listed above, Caltech-UCSD Birds [39] has 200 ﬁne-greind bird species and 5,794 annotated images, PF-PASCAL [13] contains 20 dif-ferent object categories and 1,345 annotated images, and
Figure 2. Visual comparison of semantic correspondences generated by different matching levels. All images are selected from ImageNet
[7]. Rows from top to bottom demonstrate pseudo-labels generated by the image-level, region-level, and pixel-level matching stages and the last row stands for correspondences annotated by humans.
SPair71k [28] contains 18 different object categories and 1,800 annotated images. The number of key points in each image varies from 3 to 30, and the average number is 7. Compared with other large-scale datasets, such as Im-ageNet [7] and MS COCO [21], the annotated images in the semantic correspondence datasets are far from enough.
This paper aims to solve the problem of training deep neural networks for semantic matching tasks with insufﬁ-cient training data. Our motivation is to investigate whether we can learn accurate semantic correspondence from large-scale datasets with only image-level annotations. We adopt the weakly supervised learning scheme [36, 11, 3, 12, 42] to learn semantic correspondences from the ImageNet
ILSVRC training set since it has a massive amount of la-beled data and various object categories. Given an image pair from ImageNet, our core idea is to follow multiple in-stance learning (MIL [10, 2, 5, 43, 40]) pipelines to treat im-ages as bags and point-to-point matching pairs as instances to train binary matching classiﬁers. We select ImageNet
ILSVRC training set as our database and incorporate the
MIL pipeline in OICR [36] and MEFF [11] to decompose the problem into the image-level matching stage, region-level stage, and pixel-level stage. Now the problem be-comes two folds: 1) How to gradually reﬁne the correspon-dences during the learning process? 2) How to select and
ﬁlter out images with salient feature points from ImageNet?
To learn reliable correspondences from the ImageNet dataset, we propose a novel cascaded online correspon-dence reﬁnement algorithm to integrate the image-level, region-level, and pixel-level matching modules into a sin-gle network and train it in an end-to-end manner. As shown in Figure 2, in the image-level matching module, image la-bels are used to judge whether appropriate semantic corre-spondence exists in image pairs, and correspondences with high conﬁdence in positive image pairs are identiﬁed as re-liable correspondences. The region-level matching module accepts supervision from the previous stage and conducts robust region-matching to improve the matching accuracy further. Finally, the pixel-level matching module gets better supervision from the previous stage and trains the seman-tic matching head as previous methods [44, 18]. To ensure learning efﬁciency, different from state-of-the-art semantic matching algorithms [34, 29, 44, 6], we design a match-ing pipeline consisting of a transformer feature backbone, a gated cross attention module, and a correlation aggrega-tion module, which is proven to be very powerful. Another critical point in our multiple-instance learning pipeline is to design a correspondence ﬁltering and reﬁnement module to improve correspondences in different stages. We incor-porate a saliency detector, SelfReformer [41], to segment foreground objects and employ regularized Hough match-ing (RHM) [27] to ensure further matching consistency.
After learning correspondences from image-level an-notations, we generated a new dataset with high-quality pseudo-labels for semantic correspondence and called it se-mantic correspondence ImageNet (SC-ImageNet). In Ima-geNet, some image categories are not object-centric, lack salient and unique feature points, or contain too complex
background clutters, which are unsuitable for semantic cor-respondence learning. We remove these object categories and ﬁlter out 679 image categories manually. To further im-prove the dataset quality, we compute the matching quality of each image and select images that contain more high-quality salient feature points to formulate our new dataset.
The matching quality is measured by the matching consis-tency index, which is introduced with details in subsequent sections. We select the top 30% images to formulate the
SC-ImageNet and use it as a pre-training set for several popular semantic matching methods. Experiments demon-strate that our cascaded online correspondence reﬁnement network trained in a weakly supervised manner can achieve competitive results with their supervised counterpart on PF-PASCAL and PF-WILLOW benchmarks. And if we pre-train state-of-the-art algorithms on SC-ImageNet and ﬁne-tune them in the common fully supervised setting, we get impressive improvements on various datasets.
In summary, our contribution can be written as follows:
• We introduce a new weakly supervised semantic corre-spondence scheme, which can learn pixel-level match-ing relationships in image pairs. It provides a new per-spective for semantic matching methods to learn reli-able correspondences from large-scale, weakly anno-tated datasets.
• We propose a novel cascaded online correspondence reﬁnement pipeline that integrates multiple instance learning and correspondence ﬁltering and reﬁnement into a single neural network that can be trained end-to-end.
• We build a new dataset based on ImageNet for seman-tic correspondence, called SC-ImageNet. It contains 679 object categories, 113,516 images, and 794,612 semantic correspondence pairs, and is much larger than existing benchmarks. Experiments with state-of-the-art algorithms indicate that SC-ImageNet pre-trained models show strong generalization ability and can beneﬁt the subsequent ﬁne-tuning process. 2.