Abstract https://github.com/SysCV/cascade-detr.
Object localization in general environments is a fun-damental part of vision systems. While dominating on the COCO benchmark, recent Transformer-based detection methods are not competitive in diverse domains. Moreover, these methods still struggle to very accurately estimate the object bounding boxes in complex environments.
We introduce Cascade-DETR for high-quality universal object detection. We jointly tackle the generalization to di-verse domains and localization accuracy by proposing the
Cascade Attention layer, which explicitly integrates object-centric information into the detection decoder by limiting the attention to the previous box prediction. To further enhance accuracy, we also revisit the scoring of queries.
Instead of relying on classification scores, we predict the expected IoU of the query, leading to substantially more well-calibrated confidences. Lastly, we introduce a uni-versal object detection benchmark, UDB10, that contains 10 datasets from diverse domains. While also advanc-ing the state-of-the-art on COCO, Cascade-DETR substan-tially improves DETR-based detectors on all datasets in
UDB10, even by over 10 mAP in some cases. The im-provements under stringent quality requirements are even more pronounced. Our code and pretrained models are at
*Equal contribution. 1.

Introduction
Object detection is a fundamental computer vision task with a wide range of real-life applications, such as self-driving and medical imaging. With remarkable progress since the emergence of DETR [5], Transformer-based de-tectors [55, 13, 38] have achieved ever increasing perfor-mance. The recent DETR-based methods [24, 52, 29] out-perform CNN-based detectors [34, 18, 35, 41] on the de facto COCO challenge by a substantial margin.
Despite the notable progress of DETR-based detectors, there are still significant limitations that need to be ad-dressed. Figure 1 shows that DETR-based methods severely struggle when applied outside of the conventional COCO benchmarks. This can be attributed to the limited number of training samples and diverse styles encountered in more task-specific domains, resulting in a drop in performance even below their CNN-based predecessors.
In particular, we find that on e.g., Cityscapes [12] and Brain tumor [17] benchmarks, the performance of DN-DETR [24] is substan-tially poorer than Faster R-CNN despite its superior perfor-mance on COCO. Moreover, the prediction of highly accu-rate bounding boxes remains challenging. In Figure 2, given
Figure 2. Detection results comparison between DN-DETR [24] and our Cascade-DN-DETR, DAB-DETR [29] and our Cascade-DAB-DETR on COCO [27] (Left) and UVO [43] (Right), using
IoU thresholds ranging from loose to strict. All comparisons are with the same training setting and schedule. stricter IoU thresholds, existing DETR-based methods still have substantial room for improvement.
We partially attribute these two problems, namely, poor generalization to other datasets and limited bounding box accuracy, to a lack of a local object-centric prior. Following the general philosophy of transformers [15], DETR-based methods replace convolutions with global cross-attention layers in the detection head, thus removing the object-centric inductive bias. We argue that without such bias makes it difficult to accurately identify local object regions, thus limiting the bounding box accuracy. Additionally, the reliance on a purely data-driven approach to learn such bias places a heavy reliance on large annotated datasets, which are often unavailable in diverse real-world applica-tions. Many detection tasks have distinct image domains, such as medical imaging or document analysis (as shown in
Figure 1), which differ significantly from those in COCO or
ImageNet, making pretraining on large annotated datasets even less effective.
The other attributing factor is the scoring of bounding box predictions which further exacerbates the high accuracy of DETR-based detectors. The query scoring in DETR de-coder is purely based on the final classification confidence.
However, these scores are largely oblivious of the quality of the predicted bounding box. Instead, we argue that cor-rectly classified box proposals that better overlaps with the ground-truth should be assigned higher scores.
To address these two issues, this paper presents Cascade-DETR to promote high-quality universal detection perfor-mance for DETR-based models. To tackle the lack of lo-cal object-centric prior, we introduce cascade attention in the DETR decoder, which constrains the spatial cross atten-tion layers to only inside the previously predicted bound-ing box of each query. Since DETR decoder has multiple decoder layers, the cascade structure iteratively refines the cross-attention region for each query, using a more accurate box prediction after every layer. To improve the scoring of box predictions, we propose an IoU-aware Query Recali-Table 1. Datasets components in UDB10 benchmark for evalu-ating high-quality universal object detection. The UniAP met-ric computes the mean of AP for each individual dataset compo-nent. Training is done individually on each dataset. All compar-ing methods use ResNet50 as backbone. Our Cascade-DN-DETR is built on DN-DETR [24]. FR-CNN: Faster R-CNN; Paintings:
People in paintings dataset [33]; Document: Document parts [31].
COCO [27]
UVO [43]
Cityscapes [12]
BDD100K [48]
Brain tumor [17]
Document [31]
Smoke [32]
EgoHands [1]
PlantDoc [37]
Paintings [33]
UniAP
Domain
Natural
Open World
Traffic
Traffic
Medical
Office
Natural
Egoview
Natural
Art
# Images 118k 15k 3k 70k 7k 1k 0.5k 11k 2k 0.6k
FR-CNN [35] DN-DETR [24] 37.9 24.7 30.1 31.0 43.5 48.0 67.1 74.9 38.9 17.0 41.3 43.4 22.3 19.0 28.2 38.9 44.7 66.5 74.4 45.0 2.2 38.5
Ours 45.5↑2.1 28.4↑6.1 29.0↑10.0 30.2↑2.0 46.5↑7.6 50.9↑6.2 71.8↑5.3 77.6↑3.2 49.1↑4.1 13.4↑11.2 44.2↑5.7 bration, by adding an IoU prediction branch to re-calibrate query scores. In parallel to the query classification and re-gression branches, the IoU prediction branch computes the box proposal IoU to the corresponding GT object. This en-ables each matched learnable query to be aware of its qual-ity more accurately. During inference, we recalibrate the classification scores by the predicted localization scores as the final ones to rank proposals.
We further compose a new detection benchmark UDB10 and corresponding evaluation metric UniAP to support high-quality universal detection. We hope to facilitate the detection community not only focusing detection results on
COCO but also in more wide real-life applications. As in
Table 1, UDB10 consists of 10 datasets from various real-life domains. We compare the UniAP among Faster R-CNN [35], DN-DETR [24] and Cascade-DN-DETR, where our approach achieves the best 44.2 UniAP. With negligible model parameters increase, our method significantly pro-motes the detection quality of DETR-based models for 5.7
UniAP, especially on the domain-specific datasets. This is also validated by our large performance gain in Figure 2.
On the large-scale COCO benchmark, Cascade-DN-DETR achieves significant 2.1 and 2.4 AP improvement over DN-DETR using R50 and R101 backbone respectively. 2.