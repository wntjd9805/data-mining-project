Abstract
FSS (Few-shot segmentation) aims to segment a target class using a small number of labeled images (support set).
To extract information relevant to the target class, a dom-inant approach in best performing FSS methods removes background features using a support mask. We observe that this feature excision through a limiting support mask in-troduces an information bottleneck in several challenging
FSS cases, e.g., for small targets and/or inaccurate target boundaries. To this end, we present a novel method (MSI), which maximizes the support-set information by exploit-ing two complementary sources of features to generate su-per correlation maps. We validate the effectiveness of our approach by instantiating it into three recent and strong
FSS methods. Experimental results on several publicly available FSS benchmarks show that our proposed method consistently improves performance by visible margins and leads to faster convergence. Our code and trained mod-els are available at: https://github.com/moonsh/
MSI-Maximize-Support-Set-Information 1.

Introduction
Deep convolutional neural networks (DCNNs) have achieved state-of-the-art results across several mainstream computer vision (CV) problems, including object detection
[26, 27] and semantic segmentation [18, 2, 38]. An im-portant factor underlying the success of DCNNs is large-scale annotated datasets, which are costly and cumbersome to acquire in many dense prediction tasks, such as seman-tic segmentation. Moreover, these models struggle to seg-ment novel objects when only a few annotated examples are
Figure 1. Recent FSS baseline (VAT[9]) struggles to accurately segment the target object in several challenging scenarios in PAS-CAL [5] and COCOi [15]: (a) the same instance of the target class is not masked, e.g., the sofa on the right, (b) the support mask is very small compared to the entire image, e.g., flowers in the pot, (c) support mask is missing some target boundary informa-tion, e.g., the front and chimney of the train, and (d) the back-ground contains some important contextual information, unavail-able in the support mask, e.g., shoes and grass. Our method (MSI) is capable of accurately segmenting target objects. It maximizes the support set information to compensate for the limited support mask information and can exploit relevant contextual information from the background. available. Many existing few-shot segmentation (FSS) ap-proaches [25, 30, 34, 23, 31, 33, 35, 13, 32, 16, 37, 19, 21, 11, 12, 9, 22] aim to address this shortcoming. The problem settings in FSS require accurate segmentation of a target ob-small, carrying limited object information; and (d) The background contains some important contextual informa-tion, unavailable in the support mask, for accurately seg-menting the target object. We conjecture that this happens because many current SOTA methods rely on support masks to completely remove the background (Fig. 2), which limits the useful information in several challenging FSS cases.
In this paper, we propose a new method to overcome the limited information bottleneck from the support mask. It is based on the intuition that upon maximizing the information from the masked support set images (MSI), it is possible to compensate for the limited support mask information by utilizing the important contextual information available in the typically discarded background (Fig. 2). MSI jointly exploits two complementary sources of features. The first set of features is obtained by using masked support images, which only activate the target-related features in the query image. The second set of features is generated from the full support images, which activate the features of all similar objects shared between the support and query images. The former features act as an anchor for the latter in localizing a certain target class while supplementing it with the target boundary information. We summarize our key contributions as follows:
• We propose MSI, an efficient and effective plug-and-play module for FSS methods. MSI harnesses masked support images to capture the delineated target infor-mation and exploits the entire support image for com-plete target information.
• We perform extensive experiments and analysis on three challenging FSS benchmarks: PASCAL-5i [5],
COCO-20i [15], and FSS-1000 [14]. Results show that
MSI consistently improves mIoU in the one-shot set-ting over all strong baselines, including HSNet [21],
ASNet [11], and VAT [9].
• MSI improves the training speed of recent baseline models on PASCAL-5i [5], with 3.3x average speed-up on VAT [8] and 4.5x on HSNet [21]. 2.