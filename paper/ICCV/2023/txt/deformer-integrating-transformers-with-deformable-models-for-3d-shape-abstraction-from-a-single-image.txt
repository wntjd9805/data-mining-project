Abstraction from a Single Image
Di Liu1, Xiang Yu2, Meng Ye1, Qilong Zhangli1, Zhuowei Li1, Zhixing Zhang1, Dimitris N. Metaxas1 1Rutgers University 2Amazon Prime Video
Abstract
Accurate 3D shape abstraction from a single 2D image is a long-standing problem in computer vision and graph-ics. By leveraging a set of primitives to represent the tar-get shape, recent methods have achieved promising results.
However, these methods either use a relatively large number of primitives or lack geometric flexibility due to the limited expressibility of the primitives. In this paper, we propose a novel bi-channel Transformer architecture, integrated with parameterized deformable models, termed DeFormer, to si-multaneously estimate the global and local deformations of primitives.
In this way, DeFormer can abstract com-plex object shapes while using a small number of primi-tives which offer a broader geometry coverage and finer de-tails. Then, we introduce a force-driven dynamic fitting and a cycle-consistent re-projection loss to optimize the primi-tive parameters. Extensive experiments on ShapeNet across various settings show that DeFormer achieves better recon-struction accuracy over the state-of-the-art, and visualizes with consistent semantic correspondences for improved in-terpretability. 1.

Introduction
Accurate 3D shape abstraction with semantically mean-ingful parts is an active research field in computer vision for decades. It can be applied to many downstream tasks, such as shape reconstruction [47, 9, 53, 58, 68, 49, 50, 56, 43], object segmentation [31, 51, 37, 21, 73, 39, 41, 27, 38, 7, 71, 20, 42, 40, 16, 28, 45, 19], shape editing [69, 24] and re-targeting [15, 23, 70]. Due to the large success of deep neural networks (DNNs), a series of learning-based works [56, 54, 64, 55, 14] propose to decompose an ob-ject shape into primitives and use the deformed primitives to represent the target shape. The primitive-based methods usually interpret a shape as a union of simple parts (e.g., cuboids, spheres, or superquadrics), offering interpretable abstraction of a shape target.
To achieve high accuracy of shape reconstruction, exist-ing methods require joint optimization of a number of prim-Figure 1: DeFormer uses a small number of primitives to abstract a 3D shape from a 2D image with better accuracy and part correspondence. Taking “lamp” and “chair” as ex-amples, we compare to Suq [56], CvxNets [14], and Neural
Parts (NP) [55] with ∼20, 25, and 5 primitives, respectively, while ours applies 2 primitives for lamps (1 for shade and 1 for body) and 6 primitives for chairs (4 for legs, 1 for seat and 1 for back). itives, which sometimes do not accurately correspond to the object parts and therefore limit the interpretability of the re-constructions [56, 14, 55] (see Fig. 1). To this end, using a small number of primitives to abstract complex shapes becomes a trend in recent research [55]. However, the dilemma lies in that using fewer primitives usually results in sub-optimal reconstruction accuracy due to their reduced representation power, while using more primitives lowers the interpretability and requires higher computational costs.
Physics-based deformable models (DMs) [48, 62] are well known for their strong abstraction ability in shape representation, and have been successfully applied to var-ious complex shape modeling applications. DMs leverage a physical modeling framework to predict global and local deformations of primitives, in which force-driven dynamic
fitting across the data and the generalized latent space are used to jointly minimize the divergence between the de-formed primitives and the target shapes. Although DMs can offer strong representation power for shape abstraction, a main concern is that they require handcrafted parametric initialization for each specific shape abstraction, which lim-its their usage to general and automated shape modeling.
To address the aforementioned limitations, we propose a bi-channel Transformer combined with deformable models, termed DeFormer, to leverage the superior interpretability from DMs and overcome the parametric initialization lim-itation by taking advantage of the universal approximation capabilities [29, 30] of deep neural networks. Moreover, we leverage general superquadric primitives with global defor-mations as our primitive formulation, which offer a broader shape coverage and improve abstraction accuracy. To fur-ther enhance the shape coverage of the proposed DeFormer, we employ a diffeomorphic mapping that preserves shape topology to predict local deformations for finer details be-yond the coverage of global deformations.
To improve the primitive parameter optimization, we to minimize introduce “external force” during training, the divergence between the deformed primitives and target shapes. This allows us to further use kinematic modeling for more flexible transformations across the data space, the generalized latent space, and the projected image space for improved robust training. To guarantee the training con-vergence, we leverage a cycle-consistent re-projection loss to achieve consistency between the reconstructed shapes, with the projected image and the original image as the in-put, respectively. Extensive experiments across several set-tings show that DeFormer outperforms the state-of-the-art (SOTA) with fewer primitives on the core thirteen shape categories of ShapeNet.
Our main contributions are summarized as follows:
• To the best of our knowledge, DeFormer is the first work that integrates Transformers with deformable models for ac-curate shape abstraction. We show that our novel learning formulation achieves better abstraction ability using a small number of primitives with a broader shape coverage.
• A force-driven dynamic fitting loss combined with a cycle-consistent re-projection regularization is introduced for effective and robust model training.
• Extensive experiments show that our method achieves bet-ter reconstruction accuracy and improved semantic consis-tency compared to the state-of-the-art. 2.