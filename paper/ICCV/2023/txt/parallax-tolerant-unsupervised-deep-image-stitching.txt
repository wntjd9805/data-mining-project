Abstract
Traditional image stitching approaches tend to lever-age increasingly complex geometric features (e.g., point, line, edge, etc.) for better performance. However, these hand-crafted features are only suitable for speciﬁc natu-In con-ral scenes with adequate geometric structures. trast, deep stitching schemes overcome adverse conditions by adaptively learning robust semantic features, but they cannot handle large-parallax cases.
To solve these issues, we propose a parallax-tolerant un-supervised deep image stitching technique. First, we pro-pose a robust and ﬂexible warp to model the image regis-tration from global homography to local thin-plate spline motion. It provides accurate alignment for overlapping re-gions and shape preservation for non-overlapping regions by joint optimization concerning alignment and distortion.
*Corresponding author.
Subsequently, to improve the generalization capability, we design a simple but effective iterative strategy to enhance the warp adaption in cross-dataset and cross-resolution ap-plications. Finally, to further eliminate the parallax arti-facts, we propose to composite the stitched image seam-lessly by unsupervised learning for seam-driven composi-tion masks. Compared with existing methods, our solution is parallax-tolerant and free from laborious designs of com-plicated geometric features for speciﬁc scenes. Extensive experiments show our superiority over the SoTA methods, both quantitatively and qualitatively. The code is available at https://github.com/nie-lang/UDIS2. 1.

Introduction
Image stitching is a practical technology that aims to construct a scene with a wide ﬁeld-of-view (FoV) from dif-ferent images with limited FoV. It is useful in a wide range
of ﬁelds, such as autonomous driving, medical imaging, surveillance videos, virtual reality, etc.
Over the past decades, traditional stitching approaches tend to adopt increasingly complicated geometric features to achieve better content alignment and shape preservation.
In the beginning, SIFT [38] is widely used in various im-age stitching algorithms [4, 13, 50, 5, 34, 25] to extract dis-criminative key points and calculate adaptive warps. Then, the line segment is proved to be another unique feature to achieve better stitching quality and preserve linear struc-tures [31, 49, 32, 19]. Recently, the large-scale edge is also introduced in [10] to preserve the contour structures. Be-sides, there is a great variety of other geometric features that are leveraged to improve the stitching quality, such as depth maps [33], semantic planar regions [26], etc.
Having calculated the warps, seam cutting is usually used to remove parallax artifacts. To explore an invisible seam, various energy functions are designed using colors
[22], edges [35, 8], salient maps [30], depth [6], etc.
From the broad usage of geometric features, a clear de-veloping trend has been discovered: increasingly sophisti-cated features are leveraged. We ask: are these complex designs practical in real applications? We attempt to an-swer this question from two perspectives. 1) These elabo-rate algorithms with complicated geometric features poorly adapt to scenes without sufﬁcient geometric structures, such as medical images, industrial images, and other natural im-ages with low texture (Fig.1b), low light or low resolution. 2) When there exist abundant geometric structures, the run-ning speed is intolerant (please refer to Table 2,3 for detail).
Such a trend seems to violate the “practical” original intent.
Recently, deep stitching technologies using convolu-tional neural networks (CNNs) have aroused widespread attention in the community. They abandon geometric fea-tures and head for high-level semantic features that can be adaptively learned in a data-driven pattern in a supervised
[24, 40, 44, 47, 23], weakly-supervised [46], or unsuper-vised [41] manner. Although they are robust to various nat-ural or unnatural conditions, they cannot handle large paral-lax and demonstrate unsatisfactory generalization in cross-dataset and cross-resolution conditions. A large-parallax case is shown in Fig.1a, where the tree is in the middle of the car in the reference image while it is on the left in the target image. To deal with parallax, UDIS [41] reconstructs stitched images from feature to pixel. However, the parallax is so large that undesired blurs are produced as a side effect.
In this paper, we propose a parallax-tolerant unsuper-vised deep image stitching technique, addressing the robust-ness issue in traditional stitching and the large-parallax is-sue in deep stitching simultaneously. Actually, the proposed deep learning-based solution is naturally robust to various scenes due to effective semantic feature extraction. Then, it overcomes the large parallax via two stages: warp and composition.
In the ﬁrst stage, we propose a robust and
ﬂexible warp to model the image registration. Particularly, we simultaneously parameterize homography transforma-tion and thin-plate spline (TPS) transformation as uniﬁed representations in a compact framework. The former offers a global linear transformation, while the latter produces lo-cal nonlinear deformation, allowing our warp to align im-ages with parallax. Besides, this warp contributes to both content alignment and shape preservation simultaneously via combined optimization of alignment and distortion. In the second stage, the existing reconstruction-based method
[41] treats artifact elimination as a reconstruction process from feature to pixel, leading to inevitable blurs around the parallax regions. To overcome this drawback, we cooper-ate the motivation of seam-cutting into deep composition and implicitly ﬁnd a “seam” through unsupervised learn-ing for seam-driven composition masks. To this end, we design boundary and smoothness constraints to restrict the endpoints and route of a “seam”, compositing the stitched
In addition to the two stages, we de-image seamlessly. sign a simple iterative strategy to enhance the generaliza-tion, rapidly improving the registration performance of our warp in different datasets and resolutions.
Furthermore, we conduct extensive experiments about the warp and composition, demonstrating our superiority to other SoTA solutions. The contributions center around:
• We propose a robust and ﬂexible warp by parameteriz-ing the homography and thin-plate spline into uniﬁed representations, realizing unsupervised content align-ment and shape preservation in various scenes.
• A new composition approach is proposed to generate seamless stitched images via unsupervised learning for composition masks. Compared with the reconstruc-tion [41], our composition eliminates parallax artifacts without introducing undesirable blurs.
• We design a simple iterative strategy to enhance warp adaption in different datasets and resolutions. 2.