Abstract
Exploring good generalization ability is essential in deep metric learning (DML). Most existing DML methods focus on improving the model robustness against category shift to keep the performance on unseen categories. However, in addition to category shift, domain shift also widely exists in real-world scenarios. Therefore, learning better gener-alization ability for the DML model is still a challenging yet realistic problem. In this paper, we propose a new self-expanded equalization (SEE) method to effectively general-ize the DML model to both unseen categories and domains.
Specifically, we take a ‘min-max’ strategy combined with a proxy-based loss to adaptively augment diverse out-of-distribution samples that vastly expand the span of original training data. To take full advantage of the implicit cross-domain relations between source and augmented samples, we introduce a domain-aware equalization module to in-duce the domain-invariant distance metric by regularizing the feature distribution in the metric space. Extensive exper-iments on two benchmarks and a large-scale multi-domain dataset demonstrate the superiority of our SEE over the ex-isting DML methods. 1.

Introduction
Learning an effective metric to measure the visual simi-larities among examples is a fundamental problem in many computer vision tasks, such as image retrieval [15, 24], face recognition [10, 32] and person re-identification [54, 55, 22]. Metric learning aims to automatically learn a task-specific distance metric under which samples from the same class are encouraged to be closer than those from different classes. Taking advantage of deep learning tech-nique [8, 14], deep metric learning (DML) methods employ deep neural networks (DNNs) [8, 52, 51] to extract more
*Corresponding Author
Figure 1. Comparisons of the single-domain generalized DML task with the conventional DML and single-domain generaliza-tion. The better generalization ability of the learned DML model is needed to adapt both unseen categories and domains. representative feature embeddings and demonstrate supe-rior performance.
In standard DML settings[23, 25, 33], we hope the trained metric model can better generalize to unseen classes in the testing phase, which aligns more with the scenar-ios in practical applications. To this end, many methods, such as XBM [41], DRML [59], and DCML [2], have been proposed to alleviate the impact of such category shift and learn discriminative metric that generalizes well to unseen classes. However, in many real-world applications, there exists not only category shift but also domain shift between the training data and testing data as shown in Figure 1. For example, the retrieval gallery in image retrieval includes im-ages with different styles, but we can only use real images for training, as usual. Therefore, these DML methods suffer from poor generalization due to the impact of domain shift.
Simultaneously ensuring better generalization ability to un-seen categories and unseen domains for the metric model is a more challenging problem.
To further explore improving the generalization ability of
DML, we propose a practical yet challenging task, namely
Figure 2. The simple illustration of our self-expanded equalization. We adopt the adaptive domain expansion module to augment out-of-distribution samples while utilizing the domain-aware equalization module to learn a more robust domain-invariant distance metric against domain shift. single-domain generalized DML. As shown in Figure 1, giving a training dataset with seen categories and domains, we aim to train a metric model and generalize it to differ-ent unseen categories and domains. Different from domain generalization methods [45, 18, 53], we cannot obtain and use extra domain-related annotations, which are usually not accessible in practical applications. Therefore, domain gen-eralization methods cannot be directly adopted in our task.
Learning adversarial augmentations is a general idea to improve the model’s generalization ability, and some re-lated methods [30, 42, 58] have been proposed for single-domain generalization. However, the generated samples should instead be considered adversarial perturbations that cannot effectively mimic the domain shift with diversity.
Moreover, simply treating adversarial augmentations as the same training samples as the original training data will harm learning discriminative distance metric since the dis-carded domain-specific variations may be helpful to extract domain-invariant representations.
In this paper, we propose a self-expanded equalization (SEE) method for single-domain generalized DML, which consists of two main modules, i.e., adaptive domain expan-sion (ADE) and domain-aware equalization (DAE). In the
ADE module, we employ a ‘min-max’ strategy to modify the source data and adaptively conduct diverse domain ex-pansion. We hope the generated augmentations keep consis-tency with the source data at pixel level while having a large margin with the proxy of this class learned by our proxy-based metric loss shown in Figure 2. To further improve the generalization ability, we utilize the DAE module to exca-vate the implicit semantic relations across different domain shifts and induce the domain-invariant distance metric that is more discriminative for unseen domains. Meanwhile, the generated augmentations will be regarded as hard samples to learn the discriminative metric for unseen classes. Dur-ing training, the data distribution expansion and the model optimization are conducted alternatively in each iteration.
The contributions are summarized as follows:
• We discuss and propose a more realistic yet challeng-ing task, i.e., single-domain generalized DML, which aims to generalize the metric model to unseen cate-gories and domains.
• To handle this difficult task, we provide a new self-expanded equalization method to adaptively expand domain distribution with diversity and learn the con-sistent distance metric across different domain shifts.
• We perform experiments on multiple datasets and compare our method with state-of-the-art DML meth-ods. Our SEE substantially outperforms all baselines across all benchmarks. 2.