Abstract
We present a deep homography mixture motion model for single image rolling shutter correction. Rolling shutter (RS) effects are often caused by row-wise exposure delay in the widely adopted CMOS sensor. Previous methods of-ten require more than one frame for the correction, leading to data quality requirements. Few approaches address the more challenging task of single image RS correction, which often adopt designs like trajectory estimation or long rect-angular kernels, to learn the camera motion parameters of an RS image, to restore the global shutter (GS) image. In this work, we adopt a more straightforward method to learn deep homography mixture motion between an RS image and its corresponding GS image, without large solution space or strict restrictions on image features. We show that divid-ing an image into blocks with a Gaussian weight of block scanlines fits well for the RS setting. Moreover, instead of directly learning the motion mapping, we learn coefficients that assemble several motion bases to produce the correc-tion motion, where these bases are learned from the con-secutive frames of natural videos beforehand. Experiments show that our method outperforms existing single RS meth-ods statistically and visually, in both synthesized and real
RS images. Our code and dataset are available at https:
//github.com/DavidYan2001/Deep_HM . 1.

Introduction
Rolling shutter (RS) refers to the effects caused by differ-ent row exposures that has been widely adopted in CMOS sensors. Such a row-wise exposure often introduces arti-facts, such as blending of straight lines and skewing of im-age contents, which are not only visually unpleasant but also harmful for downstream tasks [9, 26, 1, 25]
Existing RS rectification methods can be categorized into: multi-frame [3, 13, 2, 15, 31] and single-frame [22, 21, 20, 38, 10]. Correcting RS from a single image is more
*Corresponding author
Figure 1. Rectification result on real examples. Column 1: real RS images. Column 2: results by [37]. Column 3: our results. challenging but important under data-starved situations.
Most existing single RS methods are non-learning methods (e.g., [22, 20, 12, 19]), only few works are learning-based ones (e.g., [21, 10]). Non-learning methods rely on prior assumptions for the correction, such as “straight lines re-main straight”. However, they often fail when such salient priors are not available in an image. In contrast, many deep learning methods have been proposed but they are based on multi-frame approaches. Only few methods target on single
RS correction, which is inherently an ill-posed problem.
Existing deep-learning single RS methods learn the row-wise camera motion between RS and global shutter (GS) pairs (e.g., [21]). However, row-wise motion introduces a large solution space that increases the learning difficulty. To facilitate the learning, [38] requires an additional depth as the input, where the depth can be estimated by an off-the-shelf method. Unfortunately, the quality of the correction is affected by the quality of the estimated depth, and estimat-ing depth from a single image is still an open problem.
In this paper, we present a novel method that learns a deep homography mixture (HM) motion model for single
RS correction. HM [6] is originally proposed to align adja-cent frames for the task of joint video RS removal and stabi-lization. An HM divides a frame into several equally spaced 1
horizontal blocks. Each block follows a homography trans-formation with Gaussian smoothing of neighboring blocks for the spatial smoothness. The model holds when 1) depth of the scene is plane or at infinity, 2) camera motion across rows maintains piece-wise smoothness. Previously, the
HM [6] is estimated by detecting [24] and tracking [28] im-age feature points between consecutive frames, and solve multiple smoothed homographies with a DLT [7]. Unlike these methods, we use the model as the motion correction model under our single RS rectify scenarios. Directly learn-ing the homography mixture between RS and GS cannot produce satisfactory results. Recently, BasisHomo [34] pro-poses a method to learn deep homography by combining 8 pre-defined homography flow bases, each of which is a flow map created by modifying one of a homography matrix el-ement. In this way, the learning of a homography is con-verted to the learning of coefficients corresponding to each flow basis, which demonstrates superior performances com-pared to directly regressing homography matrix elements, or the 4pt motion vector representation [4]. Here, we adopt flow basis representation, not for the frame registration [34], but for the estimation of rectifying motion as HM between
GS and RS. Moreover, we notice that pre-defined bases are not optimal. We propose to learn these bases from natu-ral videos. PCA-Flow [32] shows that optical flow can be estimated by first learning several optical flow bases from a movie and then combine them for the flow estimation.
These bases are extracted by the PCA [8]. In this work, in-stead of learning the complex basis with object-level motion details as in optical flow [32], we learn global homography flow basis that reflects camera motions.
On the other hand, many of the rolling shutter datasets are designed for multi-frame cases. We follow the single RS method [21] to synthesize RS and GS pairs. We notice that many of the existing datasets contain rich textures, full of salient lines, such as urban scenes [33]. A potential reason is that rich salient lines are more friendly for the RS correc-tion. Here, we move a step further by creating a new dataset named as RS-Homo, based on the CA-Homo dataset [35], which is designed for homography estimation of two im-ages, and contains many adverse scenarios, such as poor texture and low light. Trained on RS-Homo, we show that our method can work well not only for synthesized images in many scenarios but also for real RS captures.
In summary, our main contributions are:
• We propose deep homography mixture motion model for the task of single image rolling shutter correction, which neither requires camera intrinsics nor the addi-tional IMU hardware.
• We introduce a pipeline that learns the motion map-ping between GS and RS by combining motion bases, which are learned from natural videos. We train our network on the proposed RS-Homo dataset, delivering high quality results even under adverse cases.
• Our method achieves state-of-the-art performances when compared to previous single-frame approaches, with 2.7% higher SSIM and 56% lower motion
RMSE (per pixel). The ablation study verifies the ef-fectiveness of each component. 2.