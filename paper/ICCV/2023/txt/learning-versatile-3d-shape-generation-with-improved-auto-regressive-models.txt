Abstract
Auto-Regressive (AR) models have achieved impressive results in 2D image generation by modeling joint distribu-tions in the grid space. While this approach has been ex-tended to the 3D domain for powerful shape generation, it still has two limitations: expensive computations on vol-umetric grids and ambiguous auto-regressive order along grid dimensions. To overcome these limitations, we propose the Improved Auto-regressive Model (ImAM) for 3D shape generation, which applies discrete representation learning
*Equal contribution
â€ Corresponding author based on a latent vector instead of volumetric grids. Our approach not only reduces computational costs but also pre-serves essential geometric details by learning the joint dis-tribution in a more tractable order. Moreover, thanks to the simplicity of our model architecture, we can naturally extend it from unconditional to conditional generation by concatenating various conditioning inputs, such as point clouds, categories, images, and texts. Extensive experi-ments demonstrate that ImAM can synthesize diverse and faithful shapes of multiple categories, achieving state-of-the-art performance.
1.

Introduction 3D shape generation has garnered increasing interest in both academia and industry for its extensive applications in robotics [20], autonomous driving [47, 28], augmented reality [35] and virtual reality [34]. Based on whether user prerequisites are provided, shape generation is typically cat-egorized as unconditional or conditional. To be an effective generative model, it is crucial for the synthesized shapes to be both diverse and faithful to the universal cognition of humans or given conditions. These qualities serve as the foundation for other deterministic tasks, such as shape com-pletion, single-view reconstruction, and more. Previous ap-proaches [8, 14, 25] usually utilize an AutoEncoder (AE) to learn latent features by shape reconstruction. Then, a GAN is trained to fit the distributions of the latent features, allow-ing for the generation of 3D shapes through sampling the latent codes learned in AE. While achieving convincing re-sults, a single embedding for one shape easily encounters the problem of poor scalability and difficulty in training.
Recently, Auto-Regressive (AR) models have shown re-markable performance in the generation of 2D images [11, 50, 5] and 3D shape [23, 45]. Instead of learning a contin-uous latent space, these model leverage discrete represen-tation learning to encode each 2D/3D input into grid-based discrete codes. Subsequently, a transformer-based network is employed to jointly model the distribution of all codes, which essentially reflects the underlying prior of objects, facilitating high-quality generation and tractable training.
However, applying AR models to 3D still suffers from two limitations. First, as the number of discrete codes increases from squared to cubed, the computational burden of the transformer grows dramatically, making it difficult to con-verge. Second, discrete codes in the grid space are highly coupled. It is ambiguous to simply flatten them for auto-regression (e.g., a top-down row-major order). This may lead to poor quality or even collapse of generated shapes (see Sec. 3.1 and the Supplementary for more details).
In this paper, we propose an improved auto-regressive model (ImAM), to enhance the efficient learning of 3D shape generation. Our key idea is to apply discrete rep-resentation learning in a one-dimensional space instead of 3D volumetric space. Specifically, we first project volumet-ric grids encoded from 3D shapes onto three axis-aligned orthogonal planes. This process significantly reduces the computational costs from cubed to squared while main-taining the essential information about the input geometry.
Next, we present a coupling network to further encode three planes into a compact and tractable latent space, on which discrete representation learning is performed.
Our ImAM is straightforward and effective, simply tack-ling the aforementioned limitations by two projections.
Thus, a vanilla decoder-only transformer can be attached to model the joint distributions of codes from the latent spaces.
Furthermore, the simplicity of the transformer structure al-lows us to switch freely between unconditional and con-ditional generation by concatenating various conditioning inputs, such as point clouds, categories, images and texts.
Figure 1 showcases the ability of our ImAM to generate di-verse and accurate shapes across multiple categories, both with and without the given condition on the top-left corner.
In summary, the contributions of this paper are listed as follows. (1) We propose an improved AR Model (ImAM) for 3D shape generation. By applying discrete representa-tion learning in a latent vector instead of volumetric grids, our ImAM enjoys the advantages of lightweight and flex-ibility. (2) Our proposed ImAM model provides a more unified framework for switching between unconditional and conditional generation for a variety of conditioning in-puts, including point clouds, categories, images, and texts. (3) Extensive experiments are conducted on four tasks to demonstrate that our ImAM can generate more faithful and diverse shapes, achieving state-of-the-art results for uncon-ditional and conditional shape generation. Overall, our con-tributions advance the field of 3D shape generation, provid-ing a powerful tool for researchers and practitioners alike. 2.