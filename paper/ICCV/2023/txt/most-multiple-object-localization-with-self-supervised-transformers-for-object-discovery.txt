Abstract
We tackle the challenging task of unsupervised object lo-calization in this work. Recently, transformers trained with self-supervised learning have been shown to exhibit object localization properties without being trained for this task.
In this work, we present Multiple Object localization with
Self-supervised Transformers (MOST) that uses features of transformers trained using self-supervised learning to lo-calize multiple objects in real world images. MOST ana-lyzes the similarity maps of the features using box counting; a fractal analysis tool to identify tokens lying on foreground patches. The identified tokens are then clustered together, and tokens of each cluster are used to generate bounding boxes on foreground regions. Unlike recent state-of-the-art object localization methods, MOST can localize mul-tiple objects per image and outperforms SOTA algorithms on several object localization and discovery benchmarks on
PASCAL-VOC 07, 12 and COCO20k datasets. Additionally, we show that MOST can be used for self-supervised pre-training of object detectors, and yields consistent improve-ments on fully, semi-supervised object detection and unsu-pervised region proposal generation.Our project is publicly available at rssaketh.github.io/most. 1.

Introduction
Object detectors are important components of several computer vision systems such as visual relationship detec-tion [21, 29], human-object interaction detection [1, 13, 45, 52], scene graph generation [57] and object track-ing [54, 56] etc. Performance of object detectors is heavily reliant on the availability of training data. However, an-notating large object detection datasets can be expensive and time consuming [14, 27]. Additionally, the vocabu-lary of object detectors is limited by the training datasets and such detectors often fail to generalize to new cate-Work done while at UMD.
Figure 1: Top: Methods like LOST [41] (shown in figure),
TokenCut [53] identify and localize the most salient fore-ground object and hence can detect only one object per im-age. Bottom: MOST is a simple, yet effective method that localizes multiple objects per image without training. gories [7]. This strategy is not scalable and a more effec-tive approach is warranted. Object discovery is one such task that has the potential to address these concerns. Ob-ject discovery is the problem of identifying and grouping objects/parts in a large collection of images without human intervention [23, 24, 36, 43]. The first step in object discov-ery is to obtain region proposals and subsequently group them semantically. Previous works on discovery used Se-lective Search [46], randomized Prim’s [30] or a region pro-posal network (RPN) [35] to get object proposals. [48–50] used inter-image similarity to construct a graph and per-formed optimization or ranking, to localize objects without any supervision. Such methods are computationally expen-sive and often fail to scale to datasets larger than 20000 im-ages. [34] used region proposals from an RPN and proposed a never ending learning approach and is the first method shown to scale to ∼100000 images. However, these region proposal methods are often of low quality, and therefore reduce the performance of discovery systems. Recently,
LOST [41] and TokenCut [53] leveraged the object seg-mentation properties of transformers [47] trained using self-supervised learning (DINO [3]) to obtain high quality object proposals. They demonstrate significant improvements over
state-of-the-art on object discovery, salient object detection and weakly supervised object localization benchmarks.
However, both LOST [41] and TokenCut [53] assume the presence of a single salient object per image and hence, can localize only one object as shown in Fig 1 (top). This assumption may hold for object centric datasets like Im-ageNet [37] but is not true for scene-centric real world datasets like PASCAL-VOC [12] and COCO [27]. In this work, we address the problem of localizing multiple ob-jects per image and demonstrate the effectiveness of our ap-proach for the task of unsupervised object localization and discovery on several standard benchmarks.
We propose a new object localization method called
“Multiple Object localization with Self-supervised Trans-formers” (MOST) which is capable of localizing multiple objects per image without using any labels. We use the features extracted from a transformer [47] network trained with DINO [3]. Our method is based on two empirical observations; 1) Patches within foreground objects have higher correlation with each other than the ones on the back-ground [41] and 2) The similarity map computed using the features of a foreground object with all the features in the image is usually more localized and less noisier than the one computed using the feature of a background. Our algorithm analyzes the similarities between patches exhaustively us-ing a fractal analysis tool called box counting [28]. This analysis picks a set of patches that most likely lie on fore-ground objects. Next, we perform clustering on the patch locations to group patches belonging to a foreground object together. Each of these clusters is called pools. A binary mask is then computed for each pool and a bounding box is extracted. This capability enables the algorithm to ex-tract multiple bounding boxes per image as shown in Fig.1 (bottom). We demonstrate that without any training, our method can outperform state-of-the-art object localization methods that train class agnostic detectors to detect multiple objects. To prove the effectiveness of MOST, we demon-strate results on several object localization and discovery benchmarks. On self-supervised pre-training for object de-tectors, using MOST yields consistent improvement across multiple downstream tasks using 6× fewer boxes. When compared against other self-supervised transformer-based localization methods, MOST achieves higher recall with and without additional training. We summarize the contri-butions of our work below.
• We propose MOST, an effective method to localize and discover multiple objects per image without supervi-sion using transformers trained with DINO.
• We perform exhaustive experiments to assess the per-formance of MOST on several localization and discov-ery benchmarks and show significant improvements over the baselines.
The paper is organized as follows. In Section 2 we discuss related works on object localization and discovery. We de-scribe our approach in detail in Section 3. We describe our experimental setup and present results in Section 4 and con-clude in Section 5. 2.