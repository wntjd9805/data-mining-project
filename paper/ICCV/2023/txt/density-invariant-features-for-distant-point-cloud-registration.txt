Abstract
Registration of distant outdoor LiDAR point clouds is crucial to extending the 3D vision of collaborative au-tonomous vehicles, and yet is challenging due to small overlapping area and a huge disparity between observed point densities. In this paper, we propose Group-wise Con-trastive Learning (GCL) scheme to extract density-invariant geometric features to register distant outdoor LiDAR point clouds. We mark through theoretical analysis and exper-iments that, contrastive positives should be independent and identically distributed (i.i.d.), in order to train density-invariant feature extractors. We propose upon the conclu-sion a simple yet effective training scheme to force the fea-ture of multiple point clouds in the same spatial location (referred to as positive groups) to be similar, which natu-rally avoids the sampling bias introduced by a pair of point
* Corresponding author clouds to conform with the i.i.d. principle. The resulting fully-convolutional feature extractor is more powerful and density-invariant than state-of-the-art methods, improving the registration recall of distant scenarios on KITTI and nuScenes benchmarks by 40.9% and 26.9%, respectively.
Code is available at https://github.com/liuQuan98/GCL. 1.

Introduction
Point cloud registration is the cornerstone technique for various computer vision tasks such as SLAM [29, 30], scene flow estimation [26, 27], and early/late fusion in 3D scene understanding [55, 53, 22, 56]. Due to the complex scenar-ios and the large scale of outdoor point clouds, point cloud registration in driving scenarios is a more challenging and rewarding task than indoor scenes, which can help expand the perceptual field of collaborative vehicles for enhancing the driving safety. In such scenarios, point cloud registra-tion should be accurate enough even when dealing with ex-tremely low-overlap point clouds (e.g., two LiDARs of in-terest may be over 50 meters apart) to secure downstream tasks such as object detection [56, 22], segmentation [49], and tracking [45, 38].
As depicted in Figure 1(a), as a pair of overlapping point clouds drift apart, they scan the same location with increas-ingly different densities because point cloud local density reduces quadratically with the distance from the LiDAR.
This is referred to as the density-mismatch problem exclu-sively found on distant outdoor point clouds. As generally discovered by literature [47, 40, 50, 20, 35], deep learn-ing features are sensitive to point density so that density-mismatch results in low feature similarity and harms regis-tration performance.
In recent years, there has been a boom in learning-based outdoor point cloud registration methods [10, 15, 32, 1, 50, 9, 5, 20, 51], all of which train feature extractors based on a pair of point clouds, referred to as the pair-wise con-trastive learning (PCL) technique [10]. As stated by Arora et al. [3], a prerequisite for PCL network convergence is that data samples in a positive pair, which represents scans of a location made by two LiDARs, have to be independently and identically distributed (i.i.d.). However, severe density-mismatch leads to violation of the i.i.d. principle. More specifically, given a pair of distant point clouds S, T , it is highly likely that a high-density location in point cloud S corresponds to a low-density location in point cloud T and vise versa, i.e., their densities are correlated, as depicted in
Figure 1(c). Despite adopting several density-related tech-niques such as voxelization [15, 28, 52, 35, 50, 9, 20, 51] or density-adaptive calculation [5, 47], existing methods still fail when handling distant outdoor point clouds, as depicted in Figure 1 (b), where state-of-the-art method Predator [20] fails to register two point clouds of 50 meters apart.
Based on the analysis above, we remark that i.i.d. posi-tive features w.r.t. density are essential for training density-invatiant feature extractors to solve the distant point cloud registration problem.
In this paper, we propose group-wise contrastive learn-ing (GCL) scheme for density-invariant feature extraction in order to register distant point clouds. The core idea of GCL is to utilize groups of highly-overlapped point clouds, continuously collected by moving vehicles of public datasets, to break the density correlation between positive examples. As illustrated in Figure 1(d), GCL aligns such point clouds, and collects all point correspondences and their features at one location, referred to as a positive group.
A large enough positive group can better approximate the underlying feature distribution. Furthermore, given a posi-tive group and a specific positive sample in the group, the density of its possible correspondence is unknown since we do not know which point cloud the other sample belongs to. As a result, GCL positive samples are approximately i.i.d. and can be used for designing compelling group-wise loss to train the density-invariant feature extractor.
How to engage the extractor to derive consistent features over inconsistent densities in positive groups is non-trivial.
One straightforward solution is to minimize the variance of all features, which is not sufficient to set the optimal conver-gence target. In contrast, we additionally ask the mean of a positive group to be close to its finest feature, which is de-fined as the feature derived from the point with the highest point density in the group. By doing this, we force fea-tures extracted with low point densities to be similar with the most descriptive one in a positive group, facilitating fea-tures in a positive group to converge towards a better con-sensus.
We implement GCL on both sparse voxel convolution and KPConv, and conduct extensive experiments on KITTI
[14] and nuScenes [6]. Results demonstrate that GCL can achieve above 40.9% and 26.9% registration recall gains over SOTA point cloud registration methods when han-dling far point cloud pairs in KITTI and nuScenes, respec-tively, without performance loss on near point cloud regis-tration benchmarks. In addition, GCL is lightweight, mak-ing it preferable for online distant point cloud registration on smart vehicles.
We highlight our main contributions as follows:
• We theoretically analyze the difficulty of registering distant point clouds, and mark that constructing more i.i.d. positive samples is the key to train a density-invariant feature extractor for this challenging task.
• We propose an effective density-invariant feature ex-traction scheme based on group-wise contrastive learn-ing, where i.i.d. positive groups are neatly constructed and new contrastive learning loss are particularly de-signed.
• We conduct extensive trace-driven experiments on
KITTI and nuScenes. Results demonstrate superior density-invariance along with +40.9% and +26.9% registration recall improvements on distant scenarios in KITTI and nuScenes, respectively. 2.