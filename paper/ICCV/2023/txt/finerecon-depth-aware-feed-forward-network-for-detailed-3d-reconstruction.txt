Abstract
Recent works on 3D reconstruction from posed im-ages [17, 23, 24] have demonstrated that direct inference of scene-level 3D geometry without test-time optimization is feasible using deep neural networks, showing remarkable promise and high efficiency. However, the reconstructed ge-ometry, typically represented as a 3D truncated signed dis-tance function (TSDF), is often coarse without fine geomet-ric details. To address this problem, we propose three effec-tive solutions for improving the fidelity of inference-based 3D reconstructions. We first present a resolution-agnostic
TSDF supervision strategy to provide the network with a more accurate learning signal during training, avoiding the pitfalls of TSDF interpolation seen in previous work.
We then introduce a depth guidance strategy using multi-view depth estimates to enhance the scene representation and recover more accurate surfaces. Finally, we develop a novel architecture for the final layers of the network, con-ditioning the output TSDF prediction on high-resolution image features in addition to coarse voxel features, en-abling sharper reconstruction of fine details. Our method,
FineRecon1, produces smooth and highly accurate recon-structions, showing significant improvements across multi-ple depth and 3D reconstruction metrics. 1.

Introduction
Reconstruction of 3D scenes from posed images is a long-standing problem in computer vision, with many ap-plications such as autonomous driving, robotic navigation, and digital 3D asset creation. The traditional approach is to estimate depth maps over the input images using multi-view stereo (MVS), and then fuse them together to form a unified 3D model [9, 10, 22]. However, the fusion process commonly results in missing geometry or artifacts in areas where the depth maps do not agree, due to effects such as occlusion, specularity, and transparent or low-texture sur-1https://github.com/apple/ml-finerecon
Figure 1. Our method, FineRecon, recovers highly detailed and coherent geometry relative to state-of-the-art methods. Our contri-butions of lossless ground truth sampling, depth-aware feature vol-ume, and point backprojection result in smooth surfaces that pre-serve high-frequency structures without creating strong artifacts. faces. Recently, an alternative method has been proposed to address this issue in Atlas [17], which back-projects learned image features onto a voxel grid and directly predicts the scene’s truncated signed distance function (TSDF) using a 3D convolutional neural network (CNN). The main advan-tage is that the CNN can learn to produce smooth, consistent surfaces, and to fill in holes that would otherwise result from low-texture regions and occlusion. Several methods have proposed improvements to this framework [1, 2, 23, 24], consistently pushing the state of the art in reconstruction accuracy. However, despite these efforts, the reconstruc-tions produced by these methods remain coarse. We iden-tify three key factors restricting the accuracy and level of detail in prior works, and we introduce solutions to address them, demonstrating their effectiveness within a new sys-tem: FineRecon.
First, existing works use tri-linear interpolation to re-sample the ground-truth TSDF to align with the model’s voxel grid during training [17, 23, 24]. This allows su-pervision of the model’s TSDF predictions at each voxel center, even when the voxel centers do not coincide with the pre-computed ground-truth TSDF points. However, re-sampling via tri-linear interpolation corrupts detail in the training data, because distance fields are not linear when non-planar geometry such a corner is present, as shown in
Fig. 3. We avoid this issue by making supervised predic-tions only at the exact points where the ground-truth TSDF is known. This supervision change comes at no extra cost, and it results in greatly improved visual detail as well as a relative reduction in average chamfer distance between re-construction and ground truth of over 10%.
Second, prior work [1, 2, 17, 23, 24] uses dense back-projection, sampling a feature from each input image in each voxel. This causes blurring in the back-projection vol-ume, which increases the difficulty of extracting accurate surface locations. To address this, our method uses an ini-tial multi-view stereo depth estimation step, after which the depth estimates are used to enhance the feature volume and guide the 3D CNN toward areas of high surface likelihood.
We show that this step significantly increases the quality of the reconstructions produced by our system.
Third, because of the high computational cost of 3D
CNNs, it is expensive to increase the voxel resolution. Ex-isting works use voxel sizes of 4cm or larger [1, 2, 17, 23, 24], which is not enough to resolve the level of geometric detail visible in natural images at ranges of a few meters. To remedy this, we propose a new method to query the TSDF prediction at any point in R3, conditioned on the CNN grid features and image features projected directly to the query point. This reduces aliasing and allows our model to resolve sub-voxel detail. Furthermore, this enables reconstruction at arbitrary resolution without re-training.
FineRecon achieves state-of-the-art performance on the challenging ScanNet dataset, as measured by 3D mesh met-rics and rendered 2D depth metrics. We further show that it produces substantially improved visual detail with reduced artifacts relative to prior work.
Contributions. The main contributions of this paper are:
• We increase the accuracy of the training data us-ing resolution-agnostic TSDF supervision, allowing
FineRecon to reconstruct details with higher fidelity.
• We improve reconstruction accuracy using a novel
MVS depth-guidance strategy, augmenting the back-projection volume with an estimated TSDF fusion channel.
• We enable the reconstruction of sub-voxel detail with a novel TSDF prediction architecture that can be queried at any 3D point, using point back-projected fine-grained image features. 2.