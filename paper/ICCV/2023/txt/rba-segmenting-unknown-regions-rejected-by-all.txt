Abstract
Standard semantic segmentation models owe their success to curated datasets with a fixed set of semantic categories, without contemplating the possibility of identifying unknown objects from novel categories. Existing methods in outlier detection suffer from a lack of smoothness and objectness in their predictions, due to limitations of the per-pixel clas-sification paradigm. Furthermore, additional training for detecting outliers harms the performance of known classes.
In this paper, we explore another paradigm with region-level classification to better segment unknown objects. We show that the object queries in mask classification tend to behave like one vs. all classifiers. Based on this finding, we propose a novel outlier scoring function called RbA by defining the event of being an outlier as being rejected by all known classes. Our extensive experiments show that mask clas-sification improves the performance of the existing outlier detection methods, and the best results are achieved with the proposed RbA. We also propose an objective to optimize
RbA using minimal outlier supervision. Further fine-tuning with outliers improves the unknown performance, and unlike previous methods, it does not degrade the inlier performance.
Project page: https://kuis-ai.github.io/RbA 1.

Introduction
We address the problem of semantic segmentation of un-known categories. Detecting novel objects, for example, in front of a self-driving vehicle, is crucial for safety yet very challenging. The distribution of potential objects on the road has a long tail of unknowns such as wild animals, vehicle debris, litter, etc., manifesting in small quantities on the exist-ing datasets [73, 7, 18]. The diversity of unknowns in terms of appearance, size, and location adds to the difficulty. In addition to the challenges of data, deep learning has evolved around the closed-set assumption. Most existing models for category prediction owe their success to curated datasets with a fixed set of semantic categories. These models fail in the open-set case by over-confidently assigning the labels of known classes to unknowns [33, 58].
Figure 1: Preserving objectness and eliminating noise.
While state-of-the-art methods PEBAL [65] and DenseHy-brid [25] suffer from a lack of smoothness and objectness with high false positive rates, our method RbA clearly seg-ments the unknown objects and reduces false positives by eliminating uncertainty at semantic boundaries and in am-biguous background regions.
The existing approaches to segmenting unknowns can be divided into two depending on whether they use supervi-sion for unknown objects or not. In either case, the model has access to known classes during training, i.e. inlier or in-distribution, and the goal is to identify the pixels belong-ing to an unknown class, i.e. anomalous, outlier, or out-of-distribution (OoD). Earlier approaches resort to an ensemble of models [41] or Monte Carlo dropout [23] which require multiple forward passes, therefore costly in practice. More recent approaches use the maximum class probability [35] predicted by the model as a measure of its confidence. How-ever, this approach requires the probability predictions to be calibrated, which is not guaranteed [64, 58, 26, 54, 39].
In the supervised case, the model can utilize outlier data to learn a discriminative representation, however, outlier data is limited. Typically, another dataset from a different domain is used for this purpose [12], or outlier objects are artificially added to driving images [25, 65].
The existing methods in outlier detection suffer from a lack of smoothness and objectness in the OoD predictions as shown in Fig. 1. This is mainly due to the limitations
closed-set performance. Unfortunately, this unintended con-sequence is not desirable since the primary objective of unknown segmentation is to identify unknowns while still accurately recognizing known classes without compromising the inlier performance.
We propose an objective to optimize the proposed out-lier scoring function using a limited amount of outlier data.
By fine-tuning a very small portion of the model with this objective, our method outperforms the state-of-the-art on challenging datasets with high distribution shifts such as
Road Anomaly [49] and SMIYC [11]. Notably, we achieve this without affecting the closed-set performance. Our con-tributions can be summarized as follows:
• We postulate and study the inherent ability of mask classification models to express uncertainty, and use this strength to boost the performance of several existing
OoD segmentation methods.
• Based on our finding that object queries behave approx-imately as one vs. all classifiers, we propose a novel outlier scoring function that represents the probabil-ity of being an outlier as not being any of the known classes. The proposed scoring function helps to elim-inate uncertainty in ambiguous inlier regions such as semantic boundaries.
• We propose a loss function that directly optimizes our proposed scoring function using minimal outlier data.
The proposed objective exceeds the state-of-the-art by only fine-tuning a very small portion of the model with-out affecting the closed-set performance. 2.