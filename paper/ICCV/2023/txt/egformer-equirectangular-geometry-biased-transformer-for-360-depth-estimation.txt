Abstract
Estimating the depths of equirectangular (i.e., 360◦) im-ages (EIs) is challenging given the distorted 180◦ × 360◦
ﬁeld-of-view, which is hard to be addressed via convolu-tional neural network (CNN). Although a transformer with global attention achieves signiﬁcant improvements over
CNN for EI depth estimation task, it is computationally inefﬁcient, which raises the need for transformer with lo-cal attention. However, to apply local attention success-fully for EIs, a speciﬁc strategy, which addresses distorted equirectangular geometry and limited receptive ﬁeld simul-taneously, is required. Prior works have only cared either of them, resulting in unsatisfactory depths occasionally.
In this paper, we propose an equirectangular geometry-biased transformer termed EGformer. While limiting the computational cost and the number of network parame-ters, EGformer enables the extraction of the equirectangu-lar geometry-aware local attention with a large receptive
ﬁeld. To achieve this, we actively utilize the equirectangular geometry as the bias for the local attention instead of strug-gling to reduce the distortion of EIs. As compared to the most recent EI depth estimation studies, the proposed ap-proach yields the best depth outcomes overall with the low-est computational cost and the fewest parameters, demon-strating the effectiveness of the proposed methods. 1.

Introduction
Estimating the depths of equirectangular (i.e., 360◦) im-ages (EIs) can be challenging because such images have a 180◦ × 360◦ wide ﬁeld-of-view (FoV) with distortion. Im-ages with distorted wide FoV often requires a global view for proper image processing [20, 26, 53]. Such circum-stances strongly require a large receptive ﬁeld for accurate depth estimations of EIs, which is hard to be achieved via (a) Input [55] (b) Ground truth [55] (c) Panoformer [32] (77.7GFlops, 20.4M params) (d) EGformer (73.9GFlops,15.4M params)
Figure 1: By utilizing the equirectangular geometry as the bias, EGformer efﬁciently enables the extraction of the equirectangular geometry-aware local attention with a large receptive ﬁeld, yielding much more accurate depths with the lowest computational cost and the fewest parameters as compared to the results in the most recent studies. convolutional neural network (CNN).
Considering the receptive ﬁeld, the vision transformer (ViT) [14] may be the best option for equirectangular depth estimations. ViT has advantages over a CNN in that the at-tention is extracted in a global manner. A wide FoV can be addressed through global attention, and the effective-ness of this approach has been demonstrated [53]. However, in terms of the computational cost, this global mechanism makes ViT inappropriate for application to EIs. The com-putational cost of global attention is quadratic with respect to the input resolutions [23] which raises the need for local attention [23, 22, 13, 18, 19].
Unfortunately, applying local attention to EIs is a non-trivial problem because the distorted geometry and local re-ceptive ﬁeld should be addressed at the same time. Due to the non-uniform geometry of EIs, each local atten-tion should be extracted differently while considering the equirectangular geometry. Therefore, local attention for general vision tasks cannot yield satisfactory performance
outcomes for EIs, which demands speciﬁc strategies. How-ever, even if the distortion of EIs can be addressed via proper strategies as proposed recently by Panoformer [32], there still remains a fundamental limitation of local atten-tion: the limited receptive ﬁeld. To enlarge the receptive
ﬁeld, various hand-crafted or data-adaptive sparse patterns have been proposed for local windows with a hierarchical type of network architecture [42, 43, 23, 13, 45, 32]. How-ever, such repeated local operations cannot fundamentally substitute for a global operator [44], increasing both the computational cost and the number of network parameters required for a plausible quality of the depth.
As described above, dealing efﬁciently with equirectan-gular geometry and a limited receptive ﬁeld via local atten-tion appears to be challenging, yet one important fact has been overlooked: the equirectangular geometry is known beforehand. For various vision tasks, it has been shown that a structural prior can boost the performances efﬁciently
[20, 46, 9, 16, 50, 48]. For example, based on the prior knowledge that cars cannot ﬂy up in the sky in urban scenes,
HA-Net [9] improves segmentation performance outcomes at a negligible computational overhead by imposing differ-ent importance levels on the encoded features according to their vertical positions. Inspired by those studies, we come up with the idea of offsetting the limitations of local atten-tion via a structural prior of EIs.
In this paper, we propose an equirectangular geometry-biased transformer, termed EGformer, which actively uti-lizes the equirectangular geometry as the bias for inter-and intra-local windows. Through this, while limiting the computational cost and the number of network parame-ters, EGformer enables the extraction of the equirectangular geometry-aware local attention with a large receptive ﬁeld.
EGformer consists of three main proposals: equirectangu-lar relative position embedding (ERPE), distance-based at-tention score (DAS) and equirectangular-aware attention re-arrangement (EaAR). Speciﬁcally, ERPE and DAS impose geometry bias onto the elements within the local window, allowing for consideration of the equirectangular geometry when extracting the local attention. Meanwhile, EaAR im-poses the geometry bias on the local window. This enables each local window to interact with other local windows in-directly, thereby enlarging the receptive ﬁeld. Compared to the most recent studies of EI depth estimations, EGformer yields the best depth outcomes overall with the lowest com-putational cost and the fewest parameters, demonstrating the effectiveness of the proposed method. 2.