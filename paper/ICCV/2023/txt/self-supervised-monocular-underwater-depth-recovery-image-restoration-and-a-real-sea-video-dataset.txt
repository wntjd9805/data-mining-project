Abstract
Underwater (UW) depth estimation and image restora-tion is a challenging task due to its fundamental ill-posedness and the unavailability of real large-scale UW-paired datasets. UW depth estimation has been attempted before by utilizing either the haze information present or the geometry cue from stereo images or the adjacent frames in a video. To obtain improved estimates of depth from a single
UW image, we propose a deep learning (DL) method that utilizes both haze and geometry during training. By har-nessing the physical model for UW image formation in con-junction with the view-synthesis constraint on neighboring frames in monocular videos, we perform disentanglement of the input image to also get an estimate of the scene ra-diance. The proposed method is completely self-supervised and simultaneously outputs the depth map and the restored image in real-time (55 fps). We call this first-ever Under-water Self-supervised deep learning network for simultane-ous Recovery of Depth and Image as USe-ReDI-Net. To fa-cilitate monocular self-supervision, we collected a Dataset of Real-world Underwater Videos of Artifacts (DRUVA) in shallow sea waters. DRUVA is the first UW video dataset that contains video sequences of 20 different submerged artifacts with almost full azimuthal coverage of each ar-tifact. Extensive experiments on our DRUVA dataset and other UW datasets establish the superiority of our proposed
USe-ReDI-Net over prior art for both UW depth and im-age recovery. The dataset DRUVA is available at https:
//github.com/nishavarghese15/DRUVA. 1.

Introduction
Underwater (UW) depth recovery and image restoration is very important in ocean exploration applications such as marine biology [40], marine archaeology [38], UW robotics
[54], etc. 3D reconstruction of UW structures warrants depth as a fundamental requirement. Current UW depth estimation methods can be divided into active and passive
[54]. Active methods, which include different kinds of sonar [42, 23, 8], UW laser line-scanning [45, 16], range-(a) Input from DRUVA (b) Depth map
Figure 1: (a) An example image from our DRUVA dataset. (b) Depth map, and (c) enhanced image obtained using our USe-ReDI-Net. (c) Enhanced image gated imaging systems [39], and LiDAR [46] are usually bulky. Also, their performance is limited by the scatter-ing of light in water [51]. On the other hand, passive methods use images captured from a camera. These in-clude traditional [5, 44, 11, 4] as well as deep-learning (DL) based approaches [25, 53, 26]. Traditional UW depth estimation methods find depth from haze by utilizing the
UW image formation model. These methods return er-roneous estimates when there is a mismatch between the adopted prior and actual scene conditions, and are time-consuming too. Supervised deep networks for UW depth estimation are cumbersome to design due to the unavail-ability of paired large-scale UW depth datasets. Unpaired-learning based [25] and Generative Adversarial Network (GAN)-based [26] methods exist for depth. But they use either terrestrial RGBD datasets or synthetically generated datasets for training. As a result, there is a domain gap with real UW images.
Self-supervised depth estimation networks for terrestrial images [21, 19, 22, 57, 59] utilize geometry cues between adjacent frames of a monocular video or stereo pairs where a target view is synthesized from a source view using the relative pose and the estimated depth. These methods can-not be directly applied to UW images due to the presence of haze. A recent method [53] estimates depth from UW im-ages using the geometry cue. Because [53] performs self-supervision based on the depth and pose derived directly from hazy UW images, the depth map lacks details.
Since light is absorbed/scattered in water, UW images suffer from color distortions and poor contrast. Restora-[44, tion of UW images has attracted a lot of attention. 43, 1, 35, 56] estimate the parameters of the UW imag-ing model using image priors. Due to the inconsistency
between the prior and actual image conditions, the results are not always satisfactory [37]. DL-based methods in-clude supervised [34, 33, 31] and unsupervised approaches
[6, 15] for UW image enhancement. Supervised methods rely largely on either synthetic UW datasets generated from
RGBD datasets like NYU Depth v2 [47] or real underwater datasets like UIEB [33] with (subjective) pseudo-ground-truth. The unavailability of real UW datasets with actual ground truth continues to pose challenges for supervised
UW image restoration. Inspired by an unsupervised method for image dehazing [30], the works [15, 6] leverage UW im-age formation model for self-supervision by disentangling the input image.
In this paper, we propose a unified learning frame-work for joint monocular UW depth estimation and image restoration based on self-supervision that runs in real-time.
We refer to it as Underwater Self-supervised network for si-multaneous Recovery of Depth and Image (USe-ReDI-Net).
This is the first UW work to use both haze and geometry as cues for depth. We harness the UW image formation model [1] to disentangle the input hazy image to get an esti-mate of the clean image and the transmission map. We find depth analytically from the transmission map and invoke an additional view-consistency constraint from a neighbor-ing frame to facilitate proper disentanglement. When we perform self-supervision by view-synthesis, the warped lo-cation is governed by the estimated depth while the photo-metric value at the warped location comes from the restored input. Joint estimation of depth and image is mutually ben-eficial in the sense that a refined depth map aids the image restoration process, and an improved image estimate in turn helps to recover a better estimate of depth. The strength of our method lies in encapsulating this strong coupling be-tween the two tasks. In our method, we cannot estimate one without estimating the other. To the best of our knowledge, this is the first DL-based work to estimate depth as well as restored image jointly in an end-to-end manner from an underwater image. We perform extensive experiments on several real-world UW image datasets to establish the ef-fectiveness of our USe-ReDI-Net for both UW depth esti-mation and image restoration.
In order to advance the state-of-the-art, UW datasets are essential but these are quite difficult to capture. Consider-ing the critical need for real UW video sequences with cam-era intrinsics, we collected our own Dataset of Real-world
Underwater Videos of Artifacts (DRUVA) using a GoPro
Hero 10 camera. This dataset contains video sequences of 20 different artifacts in shallow waters where the diver goes around the artifacts to acquire an almost 360â—¦ azimuthal view. Details of the dataset are given in Sec. 4. An ex-ample image from DRUVA is given in Fig. 1 along with the depth map and the enhanced output obtained using USe-ReDI-Net.
Our main contributions are as follows. 1. We propose a self-supervised deep network (Use-ReDI-Net) for monocular underwater depth estimation and image restoration that runs in real-time (55 fps). 2. USe-ReDI-Net is the first end-to-end DL method to si-multaneously recover depth and latent image from an underwater observation. By jointly solving for image and depth, we judiciously invoke relevant losses gov-erning the scene radiance as well as the depth map to better constrain the problem. 3. Our work is the first attempt to utilize cues from both haze and geometry to recover depth in UW images. 4. USe-ReDI-Net is a fully self-supervised approach that outperforms state-of-the-art methods both in terms of output quality as well as computational speed. 5. We have collected a unique dataset (DRUVA) which, to the best of our knowledge, is the first-ever UW video dataset containing real underwater image sequences of submerged artifacts. We shall release this dataset for the research community to harness it in a multitude of ways. 2.