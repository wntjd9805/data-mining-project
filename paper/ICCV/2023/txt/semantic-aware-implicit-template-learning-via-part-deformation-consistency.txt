Abstract
Learning implicit templates as neural fields has recently shown impressive performance in unsupervised shape cor-respondence. Despite the success, we observe current ap-proaches, which solely rely on geometric information, often learn suboptimal deformation across generic object shapes,
In this paper, we which have high structural variability. highlight the importance of part deformation consistency and propose a semantic-aware implicit template learning framework to enable semantically plausible deformation.
By leveraging semantic prior from a self-supervised fea-ture extractor, we suggest local conditioning with novel semantic-aware deformation code and deformation consis-tency regularizations regarding part deformation, global deformation, and global scaling. Our extensive experi-ments demonstrate the superiority of the proposed method over baselines in various tasks: keypoint transfer, part la-bel transfer, and texture transfer. More interestingly, our framework shows a larger performance gain under more challenging settings. We also provide qualitative analyses to validate the effectiveness of semantic-aware deformation.
The code is available at https://github.com/mlvlab/PDC. 1.

Introduction
Template learning is essential for shape analysis since the template, which is a compact representation of arbitrary shapes, provides a good prior for shape fitting so that we can establish dense correspondence and transfer key attributes such as texture or keypoints between shapes. Traditionally, handcrafted templates such as meshes, part elements with primitive shapes (e.g., sphere, cylinder, cone), or parametric models have been widely used for human/animal body [3, 4, 5, 6, 7, 8, 9], human face [10, 11], human hand [12, 13, 14], and generic objects [15, 16, 17]. Defining templates for less complex shapes with consistent topologies and similar structures is relatively straightforward. However, for shapes like generic object shapes with high structural variability or
*Corresponding author.
Figure 1. Importance of part deformation consistency. Given input shapes with high structural variability, only considering low-level geometry during template learning [1, 2] can lead to subop-timal deformation (e.g., cannot distinguish between seat and arm where two parts are geometrically close while semantically dis-tant: low seat-low arm, high seat-high arm). Ours succeeds in transferring shape attributes by encouraging part deformation con-sistency with semantic information. non-rigid shapes with large-scale deformations, manually defining suitable templates becomes challenging.
To address this challenge, recent works [1, 2, 18, 19] have focused on learning implicit templates based on neu-ral fields [20]. Neural fields, which are known for strong representation power, efficiency, and flexibility, have been successful in multiple 3D vision tasks, e.g., shape/scene re-construction [21, 22, 23, 24], neural rendering [25, 26, 27], and human digitization [28, 29, 30]. Likewise, neural fields-based template learning have shown superior perfor-mance on dense correspondence between complex shapes.
Both [1] and [2] suggest decomposing the implicit repre-sentation of shapes into a deformation field and a template field. Here, the template is learned as a continuous func-tion, which is expected to capture shared structures among the given shapes within a category (e.g., airplane, chair), while the deformation depends solely on the conditioned geometry of each shape (i.e., SDF value and surface nor-mal). We observe current approaches often learn subopti-mal deformation especially when a shape category has high structural variability like diverse local deformation scales and unseen/missing part structures; see Figure 1. That is, incorporating extra knowledge of part semantics is neces-sary to handle such cases.
In this paper, we propose a novel framework to learn semantically plausible deformation by distilling the knowl-edge of self-supervised feature extractor [31] and employ-ing it as a semantic prior to satisfy part deformation con-sistency during the template learning process. Part defor-mation consistency is our inductive bias that the deforma-tion result within the same part should be consistent. By leveraging semantic prior to understand part arrangements of shapes, we suggest local conditioning with semantic-aware deformation code and carefully designed regulariza-tions to encourage semantically corresponding deformation.
Semantic-aware deformation code is a point-wise soft as-signment of part deformation priors, where part deforma-tion priors are multiple latent codes to encode information on corresponding part deformation. We calculate assigned
In weights considering the part semantics of each point. addition, we propose input space regularization and latent space regularization to encourage part-level distances to be close, providing an explicit way to control the deformation field so that the model can learn flexible deformation and successfully learn common structures under diverse shapes.
Lastly, we suggest global scale consistency regularization to preserve the volume of the template against large-scale deformations. To validate the effectiveness of our frame-work, we conduct extensive surrogate experiments reflect-ing different levels of correspondence such as keypoint transfer, part label transfer, and texture transfer, and demon-strate competitive performance over baselines with qualita-tive analyses.
Our contributions are summarized as follows: 1⃝ We propose a new framework that learns global implicit tem-plate fields founded on part deformation consistency while understanding part semantics to enable semantically plau-sible deformation, 2⃝ We impose hybrid conditioning by combining global conditioning of geometry and local con-ditioning of part semantics for flexible deformation, 3⃝ We design novel regularizations to successfully manipulate the template fields, 4⃝ We show the effectiveness of our frame-work with both qualitative and quantitative experiments. 2.