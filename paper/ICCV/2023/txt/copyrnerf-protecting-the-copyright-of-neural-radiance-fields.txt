Abstract
Secret message 00100110…
Novel views
Extracted message 00100110…
Neural Radiance Fields (NeRF) have the potential to be a major representation of media. Since training a NeRF has never been an easy task, the protection of its model
In this paper, by analyz-copyright should be a priority. ing the pros and cons of possible copyright protection solu-tions, we propose to protect the copyright of NeRF models by replacing the original color representation in NeRF with a watermarked color representation. Then, a distortion-resistant rendering scheme is designed to guarantee robust message extraction in 2D renderings of NeRF. Our pro-posed method can directly protect the copyright of NeRF models while maintaining high rendering quality and bit ac-curacy when compared among optional solutions. Project page: https://luo-ziyuan.github.io/copyrnerf. 1.

Introduction
Though Neural Radiance Fields (NeRF) [23] have the potential to be the mainstream for the representation of dig-ital media, training a NeRF model has never been an easy task. If a NeRF model is stolen by malicious users, how can we identify its intellectual property?
As with any digital asset (e.g., 3D model, video, or im-age), copyright can be secured by embedding copyright messages into asset, aka digital watermarking, and NeRF models are no exception. An intuitive solution is to directly watermark rendered samples using an off-the-shelf water-marking approach (e.g., HiDDeN [50] and MBRS [14]).
However, this only protects the copyright of rendered sam-ples, leaving the core model unprotected. If the core model has been stolen, malicious users may render new samples
*Corresponding author. This work was carried out at Renjie’s Research
Group at the Department of Computer Science of Hong Kong Baptist Uni-versity. j k 00100110… 00100110…
Reconstruction quality under different settings
Ground truth
PSNR/Bit Acc.
Our CopyRNeRF 32.69/100%
HiDDeN + NeRF 27.71/51%
NeRF with message 22.83/69%
Figure 1: When NeRF models are stolen ( 1 ) by macli-cious users, CopyRNeRF can help to claim model owner-ship by transmitting copyright messages embedded in mod-els to rendering samples ( 2 ). We show some comparisons with HiDDeN [50] + NeRF [23], and NeRF [23] with mes-sages. PSNR/Bit Accuracy is shown below each example. using different rendering strategies, leaving no room for external watermarking expected by model creators. Be-sides, without considering factors necessary for rendering during watermarking, directly watermarking rendered sam-ples may leave easily detectable trace on areas with low ge-ometry values.
The copyright messages are usually embedded into 3D structure (e.g., meshes) for explicit 3D models [43]. Since such structures are all implicitly encoded into the weights of multilayer perceptron (MLP) for NeRF, its copyright protection should be conducted by watermarking model weights. As the information encoded by NeRF can only be accessed via 2D renderings of protected models, two com-mon standards should be considered during the watermark extraction on rendered samples [1, 15, 41, 45]: 1) invisi-bility, which requires that no serious visual distortion are
caused by embedded messages, and 2) robustness, which ensures robust message extraction even when various dis-tortions are encountered.
One option is to create a NeRF model using watermarked images, while the popular invisible watermarks on 2D im-ages cannot be effectively transmitted into NeRF mod-els. As outlined in Figure 1 (HiDDeN [50] + NeRF [23]), though the rendered results are of high quality, the secret messages cannot be robustly extracted. We can also directly concatenate secret messages with input coordinates, which produces higher bit accuracy (NeRF with message in Fig-ure 1). However, the lower PSNR values of rendered sam-ples indicate that there is an obvious visual distortion, which violates the standard for invisibility.
Though invisibility is important for a watermarking sys-tem, the higher demand for robustness makes watermarking unique [50]. Thus, in addition to invisibility, we focus on a more robust protection of NeRF models. As opposed to embedding messages into the entire models as in the above settings, we create a watermarked color representation for rendering based on a subset of models, as displayed in Fig-ure 2. By keeping the base representation unchanged, this approach can produce rendering samples with invisible wa-termarks. By incorporating spatial information into the wa-termarked color representation, the embedded messages can remain consistent across different viewpoints rendered from
NeRF models. We further strengthen the robustness of wa-termark extraction by using distortion-resistant rendering during model optimization. A distortion layer is designed to ensure robust watermark extraction even when the rendered samples are severely distorted (e.g., blurring, noise, and ro-tation). A random sampling strategy is further considered to make the protected model robust to different sampling strategy during rendering.
Distortion-resistant rendering is only needed during the optimization of core models. If the core model is stolen, even with different rendering schemes and sampling strate-gies, the copyright message can still be robustly extracted.
Our contribution can be summarized as follows:
• a method to produce copyright-embedded NeRF mod-els.
• a watermarked color representation to ensure invisibil-ity and high rendering quality.
• distortion-resistant rendering to ensure robustness across different rendering strategies or 2D distortions. 2.