Abstract
To deliver the artistic expression of the target style, re-cent studies exploit the attention mechanism owing to its ability to map the local patches of the style image to the corresponding patches of the content image. However, be-cause of the low semantic correspondence between arbi-trary content and artworks, the attention module repeatedly abuses speciﬁc local patches from the style image, result-ing in disharmonious and evident repetitive artifacts. To overcome this limitation and accomplish impeccable artis-tic style transfer, we focus on enhancing the attention mech-anism and capturing the rhythm of patterns that organize the style. In this paper, we introduce a novel metric, namely pattern repeatability, that quantiﬁes the repetition of pat-terns in the style image. Based on the pattern repeatabil-ity, we propose Aesthetic Pattern-Aware style transfer Net-works (AesPA-Net) that discover the sweet spot of local and global style expressions. In addition, we propose a novel self-supervisory task to encourage the attention mechanism
* Corresponding author (cid:2) First author email to learn precise and meaningful semantic correspondence.
Lastly, we introduce the patch-wise style loss to transfer the elaborate rhythm of local patterns. Through qualita-tive and quantitative evaluations, we verify the reliability of the proposed pattern repeatability that aligns with human perception, and demonstrate the superiority of the proposed framework. All codes and pre-trained weights are available at Kibeom-Hong/AesPA-Net. 1.

Introduction
Style transfer aims to render the content of a source im-age using the elements of a style image. Although the concepts of content and style cannot be rigorously deﬁned, the research community has been building agreeable ideas, considering repeating elements such as brush strokes, color maps, patterns, and certain dominant shapes to be style [11].
Since Gatys et al. [11] pioneered the Neural Style Trans-fer by using the Gram matrix of deep feature activations as the style representation, previous works have shown sur-prising performance in Artistic Style Transfer (AST) by em-ploying the global transformation methods [22, 15, 2] and patch-wise swapping approaches [5, 33, 17] that leverage 1      
the similarity between patches in the content and style in-puts. However, a major challenge for these methods is the lack of semantic information on the content images, which often leads to distortion artifacts (Fig. 1 (g-h)).
To handle this, recent advances in AST methods [28, 10, 24, 25, 9, 40] have incorporated the attention mechanism which aggregates elements from a style image to render the content of a source image according to semantic correspon-dence between local patches of the images. While the prin-ciple of attention networks has shown the great potential in guiding detailed expression and maintaining content in-formation, they often produce abnormal patterns or evident artifacts, e.g., smudges or ﬂoating eyes (Fig. 1 (d-f)). Al-though several works [9, 4, 37] have attempted to alleviate this problem by employing transformer or external learning strategies, achieving detailed textures such as pointillism or brush strokes remains challenging (Fig. 1 (b-c)).
In order to overcome above issues, we conjecture pit-falls of the attention mechanism for AST. Firstly, we point out that the low semantic correspondence between arbitrary content and style images induces attention mechanisms to focus on limited regions of the style image. This can hin-der attention-based methods from accurately capturing and expressing the entire style of the reference images. Conse-quently, this obstacle leads to disharmonious artifacts since they heavily rely on few style patches such as eyes instead of a representative style e.g., a pencil sketch in a portrait (2nd row of Fig. 1). Furthermore, attention mechanisms utilize only small patches from the style image where large patches would be more suitable. This leads to overly repet-itive patterns, even with less-repetitive styles. For instance, despite a simple stripe style, global regions such as the sky are prone to contain artifacts and objects can be painted with excessively repetitive stripes (1st row of Fig. 1).
To this end, we introduce remedies for more delicate artistic expression and improving the attention mechanism.
First, we revisit the deﬁnition of style considering its unique repeatability. As shown in Fig. 2, our motivation is based on the observation that every style can be expressed as a repetition of appropriate patches which could describe the entire style. To this end, we propose a novel metric pat-tern repeatability which quantiﬁes the frequency of repeat-ing patches in a style image. Then it indicates whether we should bring more effects from attention-based stylization whose advantage lies in details, or global statistic-based stylization whose advantage lies in the smooth reﬂection of entire styles. Accordingly, we introduce the Aesthetic
Pattern-Aware style transfer Networks (AesPA-Net) which calibrate the stylized features from the two approaches upon the pattern repeatability.
In addition, we propose the self-supervisory task for en-couraging the attention module to capture the broader cor-responding regions of style images even for arbitrary pairs.
Can each patch represent the whole style ? (cid:56) (cid:56) (cid:57) (cid:56) (cid:57) (cid:57) (cid:57) (cid:57) (cid:57)
Pattern Repeatability ((cid:2009)(cid:3046)(cid:3047)(cid:3052)(cid:3039)(cid:3032)) (cid:1371)
Figure 2. Illustration of our motivation. We show whether each local pattern with various scale could represent the entire style im-ages or not. Motivated by this, we introduce a new metric to quan-tify the repetition of local patches, i.e., pattern repeatability.
This auxiliary task amounts to maximizing the similarity between the augmented input and its original at the feature level. As a result, it effectively reinforces the attention mod-ules to conduct the artistic stylization. Last but not least, we modify the style loss to be computed between patches with the proper size. Our patch-wise style loss induces the styl-ized results to reﬂect the rhythm of local patterns according to the proposed pattern repeatability.
In experiments, we qualitatively show that our networks are capable of articulate artistic stylization with various pat-terns of style. Besides, through quantitative proxy metrics and the user study, we demonstrate that our framework,
AesPA-Net, outperforms the state-of-the-art AST studies:
ﬁve attention-based methods [28, 10, 24, 4, 9] and two global statistics-based methods [22, 15]. Furthermore, we verify that the reliability of pattern repeatability closely aligns with human perception, and provide ablation studies to validate the effect of individual components. 2.