Abstract
Despite tremendous advancements in bird’s-eye view (BEV) perception, existing models fall short in generating realistic and coherent semantic map layouts, and they fail to account for uncertainties arising from partial sensor infor-mation (such as occlusion or limited coverage). In this work, we introduce MapPrior, a novel BEV perception framework that combines a traditional discriminative BEV perception model with a learned generative model for semantic map layouts. Our MapPrior delivers predictions with better accu-racy, realism and uncertainty awareness. We evaluate our model on the large-scale nuScenes benchmark. At the time of submission, MapPrior outperforms the strongest competing method, with significantly improved MMD and ECE scores in camera- and LiDAR-based BEV perception. Furthermore, our method can be used to perpetually generate layouts with unconditional sampling. 1.

Introduction
Accurately understanding the surrounding environment of autonomous vehicles is crucial to guarantee the safety of riders and other traffic participants. Among various per-ception approaches, Bird’s-Eye View (BEV) perception has drawn significant attention in recent years thanks to its ca-pacity to densely model scene layouts and its tight coupling with downstream planning [80, 56, 49].
Existing perception models encounter two challenges.
The first challenge pertains to the limitations of observa-tions, particularly in distant or occluded regions, resulting in inaccurate predictions. This may manifest in choppy, out-of-distribution, or missing map elements. The second challenge is that most existing models do not consider uncertainty and diversity in possible road layouts. Taking Fig. 1 as an exam-ple, the state-of-the-art LiDAR perception model [80] gener-ates incoherent lane markings and sidewalks with massive gaps and cannot quantify the uncertainty and multi-modality as it only produces a single prediction per input.
This paper presents MapPrior, a novel BEV perception
Figure 1: Existing predictive BEV perception models do not provide realistic scene structures (e.g., the lane and sidewalks have gaps and are not straight). In contrast, our MapPrior is able to accurately recover the layout with a learned prior.
These results are validated with a quantitative comparison, showing our method’s superior accuracy, realism and uncer-tainty awareness. method that is accurate, realistic, and uncertainty-aware. At the heart of our method is a novel combination of the stan-dard discriminative BEV perception model with a learned deep generative traffic layout prior. Incorporating genera-tive modeling in this predictive task attempts to address the two aforementioned challenges – modeling the data distribu-tion improves realism, and using a sampling process allows generating multiple realistic predictions. Combining our generative model with a discriminative perception model ensures that our method retains a strong predictive ability.
Our approach comprises two steps, namely the predic-tion and generative steps. In the prediction step, we use an off-the-shelf BEV perception model [49] to make an initial layout estimate of the traffic scene from sensory input. In the generative step, we use our MapPrior model and initial esti-mate to sample one or multiple refined layouts. We perform sampling in a learned discrete latent space using a condi-tional transformer that is provided with the initial prediction.
Finally, the generated tokens are passed into a decoder to output the final layout prediction, which is diverse, realistic, and coherent with the input. The encoder, decoder, and code-book of the MapPrior are trained from real-world map data in an unsupervised way.
We benchmark our method on the nuScenes dataset against various state-of-the-art BEV perception methods with varying modalities. Our results show that MapPrior out-performs existing methods in terms of accuracy (as reflected by mean intersection-over-union), realism (as reflected by maximum-mean discrepancy), and uncertainty awareness (as reflected by expected calibration error). Furthermore, we demonstrate the unconditional generation capabilities of
MapPrior by generating a realistic and consistent HD map of a 30 km-long road. 2.