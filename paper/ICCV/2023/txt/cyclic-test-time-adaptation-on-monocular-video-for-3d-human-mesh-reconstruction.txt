Abstract
Despite recent advances in 3D human mesh reconstruc-tion, domain gap between training and test data is still a major challenge. Several prior works tackle the domain gap problem via test-time adaptation that fine-tunes a net-work relying on 2D evidence (e.g., 2D human keypoints) from test images. However, the high reliance on 2D evi-dence during adaptation causes two major issues. First, 2D evidence induces depth ambiguity, preventing the learning of accurate 3D human geometry. Second, 2D evidence is noisy or partially non-existent during test time, and such imperfect 2D evidence leads to erroneous adaptation. To overcome the above issues, we introduce CycleAdapt, which cyclically adapts two networks: a human mesh reconstruc-tion network (HMRNet) and a human motion denoising net-work (MDNet), given a test video.
In our framework, to alleviate high reliance on 2D evidence, we fully supervise
HMRNet with generated 3D supervision targets by MDNet.
Our cyclic adaptation scheme progressively elaborates the 3D supervision targets, which compensate for imperfect 2D evidence. As a result, our CycleAdapt achieves state-of-the-art performance compared to previous test-time adaptation methods. The codes are available in here. 1.

Introduction 3D human mesh reconstruction (HMR) has gained popu-larity in many applications, such as AR/VR gaming, fitness tracking, and virtual try-on. Despite recent advances, one of the major bottlenecks is the prohibitive cost of collect-ing 3D training data on in-the-wild images, which are taken in our daily environments. Due to the challenge, most of
HMR methods are commonly trained on Motion Capture (MoCap) [10, 29] datasets. While such datasets provide ac-curate 3D annotations obtained from sophisticated captur-ing devices, they contain limited human poses with less di-verse image appearances compared to in-the-wild datasets.
Figure 1. (a) We propose CycleAdapt that iteratively adapts the human mesh reconstruction network (HMRNet) and the human motion denoising network (MDNet) in a cyclic fashion. (b) As the cycle repeats, MDNet produces progressively accurate 3D human meshes as reliable 3D supervision targets for HMRNet, which in turn results in improved outputs of HMRNet.
Accordingly, a domain gap arises in which performance in the test environment severely drops. In this work, we tackle the challenging domain gap problem via a test-time adap-tation scheme that adapts a pre-trained HMR network to a given test in-the-wild video.
Most of the previous test-time adaptation methods [32, 7, 6, 40] fine-tune an HMR network via weak supervision with 2D evidence from test images, such as 2D human key-points or silhouettes. They mainly rely on 2D reprojection loss that enforces the projection of reconstructed mesh to be close to the 2D evidence. However, the 2D reprojection loss causes two critical issues. First, the depth ambiguity of 2D evidence hinders learning accurate 3D geometry since innumerable points in 3D space correspond to the same 2D point of the 2D evidence. Second, 2D evidence for comput-ing the 2D reprojection loss is often imperfect at test time, which results in erroneous adaptation. While several previ-ous methods [7, 6] assume that ground-truths (GTs) of 2D evidence are available at test time, it is far from the practical scenario. During the test time, since we cannot acquire GT 2D evidence, the 2D evidence should be estimated from test images for the adaptation. Accordingly, the 2D evidence contains estimation error and is even partially non-existent, especially under human truncations and occlusions. Such imperfect 2D evidence leads to erroneous adaptation, mak-ing the HMR network to produce inadequate reconstruc-tions, as shown in Figure 2.
To overcome the above limitations, we propose Cy-cleAdapt, a novel test-time adaptation framework for 3D human mesh reconstruction. Our framework consists of two networks: a human mesh reconstruction network (HMR-Net) and a human motion denoising network (MDNet), as shown in Figure 1(a). Given a test video, these two net-works are adapted on the test video in two stages: 1) HM-RNet adaptation stage and 2) MDNet adaptation stage. In the HMRNet adaptation stage, HMRNet is fully supervised with 3D supervision targets generated from the MDNet as well as the 2D evidence.
Initially, HMRNet reconstructs a human mesh sequence from an image sequence of the test video. Then, the reconstructed human meshes are for-warded into MDNet, where the human meshes are refined via human motion denoising. The motion denoising effec-tively complements ambiguous parts (e.g., occluded human part) that the HMRNet cannot infer from the image context.
The refined meshes from MDNet act as 3D supervision tar-gets during adaptation of HMRNet. Thus, the HMRNet is fully supervised with the generated 3D supervision targets, which alleviates the high reliance on 2D evidence in learn-ing accurate 3D geometry of test images.
In the MDNet adaptation stage, MDNet is updated in a self-supervised manner with only noisy human meshes re-constructed from HMRNet. Adaptation for MDNet is cru-cial as the MDNet is pre-trained based on 3D labels of a
MoCap dataset. Due to the restricted environment of the
MoCap dataset, human motion distribution in the MoCap dataset is far from the distribution of test video, resulting
Figure 2. Given imperfect 2D evidence (keypoints) estimated from a test image, the previous test-time adaptation method [6] fails while our CycleAdapt produces accurate reconstruction results. in the degraded performance of MDNet.
In this regard, we also perform adaptation for MDNet to improve the mo-tion denoising performance in the test video. Since 3D human mesh GTs are unavailable during test time, we de-sign the MDNet to be trainable in a self-supervised man-ner. In our design, random parts of noisy human meshes are masked, then the MDNet learns to reconstruct the masked parts of noisy human meshes. This self-supervised learning enhances denoising performance on the test video, despite only using noisy human meshes from HMRNet.
As shown in Figure 1 (a), the two adaptation stages it-erate in a cyclic fashion. As the cycle repeats, the MDNet produces progressively reliable 3D supervision targets for
HMRNet, as shown in Figure 1 (b). The progressively elab-orated 3D supervision complements the imperfect 2D ev-idence of test images, preventing erroneous adaptation of
HMRNet. As a result, our CycleAdapt produces far more accurate and natural human mesh reconstructions than pre-vious methods, by resolving the major problems with the 2D evidence. We present an extensive evaluation of the pro-posed framework under various scenarios.
Our contributions can be summarized as follows.
• We present CycleAdapt, a novel test-time adaptation framework for 3D human mesh reconstruction to miti-gate the domain gap between training and test data.
• We propose human motion denoising network, which generates 3D supervision targets to fully supervise the human mesh reconstruction network. Our cyclic adap-tation strategy progressively elaborates the 3D super-vision targets to prevent erroneous adaptation.
• We show that our CycleAdapt outperforms the previ-ous state-of-the-art methods in various scenarios. 2.