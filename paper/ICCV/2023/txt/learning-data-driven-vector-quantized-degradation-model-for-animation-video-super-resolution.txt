Abstract
Existing real-world video super-resolution (VSR) meth-ods focus on designing a general degradation pipeline for open-domain videos while ignoring data intrinsic charac-teristics which strongly limit their performance when ap-plying to some specific domains (e.g., animation videos). In this paper, we thoroughly explore the characteristics of an-imation videos and leverage the rich priors in real-world animation data for a more practical animation VSR model.
In particular, we propose a multi-scale Vector-Quantized
Degradation model for animation video Super-Resolution (VQD-SR) to decompose the local details from global struc-tures and transfer the degradation priors in real-world animation videos to a learned vector-quantized codebook for degradation modeling. A rich-content Real Animation
Low-quality (RAL) video dataset is collected for extracting the priors. We further propose a data enhancement strat-egy for high-resolution (HR) training videos based on our observation that existing HR videos are mostly collected from the Web which contains conspicuous compression arti-facts. The proposed strategy is valid to lift the upper bound of animation VSR performance, regardless of the specific
VSR model. Experimental results demonstrate the superi-ority of the proposed VQD-SR over state-of-the-art meth-ods, through extensive quantitative and qualitative evalua-tions of the latest animation video super-resolution bench-mark. The code and pre-trained models can be downloaded at https://github.com/researchmm/VQD-SR. 1.

Introduction
Animation video super-resolution (VSR) [35], which is a subdiscipline of video super-resolution (VSR) [1, 2, 3, 19, 28, 37], aims to restore high-resolution (HR) videos from their low-resolution (LR) counterparts in animation domain.
As a special type of visual art, animation video shows great
*This work was done while Zixi Tuo was a research intern at Microsoft
Research Asia.
†Corresponding author.
Figure 1. A comparison between our proposed VQD-SR and other SOTA VSR methods in real scenario. As indicated by the red dotted circles, our VQD-SR could restore more appeal-ing details by considering the degradation priors in real animation videos. (‘∗’ denotes fine-tune on animation videos). entertainment, cultural, educational and commercial values.
However, most of them available on the Web are in lim-ited resolutions and have visually unappealing artifacts due to the passing ages, lossy compression and transmission.
Dedicated to real applications, animation VSR is a blind
SR [21, 32, 46, 40, 43] task which is more challenging than conventional VSR tasks [1, 2, 14, 19, 28, 36], because of the complicated and agnostic real-world degradations. Thus, practical VSR methods for improving real-world LR ani-mation videos are in highly demanded.
Blind SR model for open-domain has long been the fo-cus. As it’s hard to collect LR-HR pairs in real scenar-ios, recent learning-based approaches try to model the real-world degradations from HR to LR, thus generating pseudo
LR-HR pairs to train SR models. These approaches can
be roughly divided into two categories, explicit modeling and implicit modeling, with regard to the degradation pro-cedures. Explicit modeling [9, 20, 32, 46] methods try to combine basic degradation operators like noise, blur and rescaling to imitate the real-world degradation pipeline. In-stead, implicit modeling methods employ a neural network, which is usually in the manner of generative adversarial net-works (GAN) [7], as an alternative to the combination of basic degradation operators. However, these general degra-dation methods designed for open-domain videos are not quite suitable for the animation domain as they ignore the intrinsic characteristics of the data. Directly adopting exist-ing degradation models for open-domain to animation VSR would lead to unpleasant results (as shown in Fig. 1 a), even though they are fine-tuned on the animation videos.
Specific to animation VSR, AnimeSR [35] moves one step further to propose a learnable basic operator (LBO) with an “input-rescaling” strategy that considers the data characteristics and demonstrates their advantages over open-domain VSR methods. However, the proposed “input-rescaling” strategy of constructing pseudo HR-LR pairs for the LBO training requires human annotations, which prevents their method from scaling up to modeling vari-ous real-world degradations. In AnimeSR [35], only three
LBOs are trained with three human-annotated videos re-leading to unappealing results (as shown in spectively,
Fig. 1 b). Thus, how to effectively leverage large-scale real-world animation videos based on their data characteristics is still an open problem.
In this paper, we propose a multi-scale Vector-Quantized
Degradation model for animation video Super-Resolution (VQD-SR), which leverages the data characteristics of ani-mation videos. We observe that different from open-domain videos with complex textures and irregular illumination conditions, animation videos are roughly composed of ba-sic visual patterns like smooth color patches and clear lines which can be easily captured with high fidelity by vector-quantization (VQ) [5, 25, 29]. Such data characteristics could also be used for encoding and transferring degra-dation priors from low-quality animation videos and re-sults in a degradation codebook. Given any clean LR an-imation frame, the degraded LR counterpart can be easily obtained by looking up the pre-trained degradation code-book. Specifically, a novel multi-scale VQGAN for degra-dation modeling is proposed to learn and transfer real-world degradation priors from a large-scale Real Animation Low-quality (RAL) video dataset collected from the Web. To im-prove the generalization ability of VQD-SR, we propose a two-stage training pipeline and a stochastic top-k VQ strat-egy to match up with the multi-scale VQGAN, yielding vi-sually appealing results (as shown in Fig. 1 c).
To further lift the upper bound of existing animation
VSR methods, we propose an HR-SR strategy to enhance the quality of HR training videos for more ideal ground truths. This is motivated by our observations that existing
HR animation videos are mostly collected from the Web which contains conspicuous compression artifacts and such artifacts could be easily reduced by existing SR methods.
Our contributions are summarized as follows:
• We collect a large-scale real LR animation dataset, and conduct a comprehensive study on real animation data to thoroughly explore the challenges and data charac-teristics in animation VSR task.
• We propose a novel multi-scale VQ degradation model to transfer real-world degradation priors for synthesiz-ing pseudo LR-HR training pairs. We further propose an HR-SR data enhancement strategy to improve the performance of existing VSR methods for animation.
• Extensive experiments demonstrate the effectiveness of our proposed methods which significantly improve the recent SOTA animation VSR method in both quan-titative and qualitative comparisons. 2.