Abstract
Frame I1
Frame I2
Optical flow
Current adversarial attacks on motion estimation, or op-tical flow, optimize small per-pixel perturbations, which are unlikely to appear in the real world. In contrast, adverse weather conditions constitute a much more realistic threat scenario. Hence, in this work, we present a novel attack on motion estimation that exploits adversarially optimized par-ticles to mimic weather effects like snowflakes, rain streaks or fog clouds. At the core of our attack framework is a differentiable particle rendering system that integrates par-ticles (i) consistently over multiple time steps (ii) into the 3D space (iii) with a photo-realistic appearance. Through optimization, we obtain adversarial weather that signifi-cantly impacts the motion estimation. Surprisingly, meth-ods that previously showed good robustness towards small per-pixel perturbations are particularly vulnerable to ad-versarial weather. At the same time, augmenting the train-ing with non-optimized weather increases a method’s ro-bustness towards weather effects and improves generaliz-ability at almost no additional cost. Our code is available at https://github.com/cv-stuttgart/DistractingDownpour. 1.

Introduction
Adversarial attacks that pose a severe threat to neural networks have recently been introduced in the context of optical flow. There, the goal is to compute the pixel-wise 2D motion f between two consecutive frames I1 and I2 of an image sequence over time. Current attacks on optical flow [1, 17, 31, 36, 37] modify these two frames in the 2D space and consequently ignore the actual 3D geometry of the scene as well as the objects moving within. Moreover, when modifying pixels, they impose bounds on the pertur-bation’s Lp norm rather than imposing visual constraints, which yields attacked images that lack naturalism. There-fore, robustness analyses with these attacks might not nec-essarily reflect the robustness of optical flow methods in the
Original
Adversarial fog
Adversarial snow
Adversarial rain
Adversarial sparks
Figure 1. Weather attacks with adversarial fog, snow, rain and sparks to perturb optical flow estimation with GMA [15]. Our weather attacks obey the 3D geometry and camera motion, which is visible in the dynamic motion blur. real world – where perturbations are more likely to appear in the form of weather phenomena.
This work investigates whether naturally occurring weather effects like snow, rain or fog can be manipulated to serve as adversarial samples for motion estimation. How-ever, simulating weather in this context requires special care: First, the motion of weather elements should be con-sistent with the 3D geometry of the scene. Snowflakes should disappear behind objects and their falling distance should appear larger when closer to the camera. Second, their motion should be coherent in time. A raindrop should fall from top to bottom over the first and second frame, and a fog cloud between two objects should remain there – even if the camera moved or rotated.
Taking all this into account, we propose an adversar-ial attack framework that augments images with particle-based weather effects that feature a high degree of realism:
We create weather particles with a view-consistent 3D mo-tion over time, insert them into the 3D scene in a depth-aware manner, and ensure photo-realism through visual ef-fects. This enables us to generate adversarially manipulated weather that significantly deteriorates optical flow predic-tions, while still satisfying the spatiotemporal and visual constraints of naturalistic weather. Our proposed augmenta-tion and attack procedure can generate a wide range of par-ticle effects, where single particles or super-particles move independently of the remaining scene content. Fig. 1 shows examples of adversarial snowflakes, rain streaks, fire sparks and fog clouds, that differ in size, speed or motion blur, color and transparency.
Contributions. Our contributions are three-fold: (i) We present a differentiable particle-to-scene rendering framework that generates realistically moving particles in the 3D scene over multiple time steps. It supports a multitude of particle effects ranging from rain and snow over sparks to mist and fog. (ii) Based on this differentiable rendering framework, we devise the first adversarial weather attacks for optical flow. They optimize 3D spatial positions and color properties of particles in the scene rather than 2D per-pixel perturbations, resulting in highly realistic images with regard to particle motion and appearance. (iii) While being visually indistinguishable from benign weather augmentations, our adversarial weather a-chieves significant degradations of optical flow predic-tions. Interestingly, this particularly holds for methods with high robustness towards small Lp perturbations. 2.