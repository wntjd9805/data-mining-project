Abstract
While analyzing scanned documents, handwritten text can overlap with printed text. This overlap causes diffi-culties during the optical character recognition (OCR) and digitization process of documents, and subsequently, hurts downstream NLP tasks. Prior research either focuses solely on the binary classification of handwritten text or performs a three-class segmentation of the document, i.e., recogni-tion of handwritten, printed, and background pixels. This approach results in the assignment of overlapping hand-written and printed pixels to only one of the classes, and thus, they are not accounted for in the other class. Thus, in this research, we develop novel approaches to address the challenges of handwritten and printed text segmenta-tion. Our objective is to recover text from different classes in their entirety, especially enhancing the segmentation per-formance on overlapping sections. To support this task, we introduce a new dataset, SignaTR6K, collected from real legal documents, as well as a new model architecture for the handwritten and printed text segmentation task. Our best configuration outperforms prior work on two different datasets by 17.9% and 7.3% on IoU scores. The SignaTR6K dataset is accessible for download via the following link: https://forms.office.com/r/2a5RDg7cAY. 1.

Introduction
For various purposes, the digitization of hard-copy documents and associated challenges are an active area of research in both academia [25, 11, 27, 10, 6, 20] and industry [18]. This digital transformation involves scanning paper documents through an OCR process, making their text accessible for downstream natural language processing (NLP) tasks, such as named entity recognition (NER).
The documents of interest can originate from a variety of domains, including historical documents [27], legal and court-issued documents [18], business contracts [25], and medical records and prescriptions [5]. Although various studies, as cited above, have been conducted, there is yet a considerable gap between current approaches and
Figure 1: Court documents are first printed and then signed or annotated by various parties. This results in handwritten text overlapping the underlying printed information, leading to performance degradation in downstream tasks, such as named entity recognition (NER). This is a fabricated example, however to protect personally very similar to the original documents, identifiable information (PII). human-level performance in mixed-text scenarios (i.e., when handwritten and printed text overlap). For instance, attorneys frequently sign legal documents, resulting in their signatures overlapping with their information. This overlap hampers the performance of OCR tools in character recognition, subsequently making it challenging for down-stream tasks to accurately identify information linked to the attorneys and their associated law firms. Figure 1 provides an illustration of handwritten text (HT) overlapping with printed text (PT) in court documents. Extracting parties names is a crucial step in the named-entity recognition (NER) task for legal and court documents [24]. When attorneys and other involved parties sign these documents, which are later scanned using OCR tools, their signa-tures often obscure the details of names and law firms.
Consequently, the semantic segmentation of handwritten elements, such as lawyers’ signatures and accompanying handwritten notes, and printed text detailing the lawyer and the law firm’s information, becomes vital.
In this research, we aim to address the challenges of HT and PT segmentation, as there is still a large gap between human-level performance and the existing approaches
for this task. Our focus in this effort is to improve the segmentation performance in overlapping regions for scanned legal documents, and to aid in this endeavor, we also introduce a new dataset.
In summary, our research makes the following contributions:
• We introduce a new dataset, SignaTR6K (pronounce as
Signature 6K)1 derived from 200 pixel-level manually annotated crops of images from genuine legal documents.
The dataset comprises signatures, handwritten text, and printed text, which frequently overlap. With data augmen-tation, we have created a dataset of sizes 5169, 530, 558, for training, validation, and testing, respectively, that we release to the public, to facilitate dataset availability for future research and to aid in the training and evaluation of deep-learning segmentation models.
• We propose a novel architecture that integrates both seman-tic segmentation features and fine features, enhancing the performance of text segmentation over previous methods.
Moreover, we introduce a new loss function termed Fusion loss, that, comparatively, is stable and converges to optimal loss values and Intersection over Union (IoU) scores.
• Lastly, we conduct an extensive quantitative and visual evaluation of different variations of our approach against prior work on two distinct datasets, and illustrate our ap-proach’s superior performance in the text segmentation task, especially in challenging scenarios where printed and handwritten text overlap. 2.