Abstract
Learning-based image deraining methods have made great progress. However, the lack of large-scale high-quality paired training samples is the main bottleneck to hamper the real image deraining (RID). To address this dilemma and advance RID, we construct a Large-scale High-quality
Paired real rain benchmark (LHP-Rain), including 3000 video sequences with 1 million high-resolution (1920*1080) frame pairs. The advantages of the proposed dataset over the existing ones are three-fold: rain with higher-diversity and larger-scale, image with higher-resolution and higher-quality ground-truth. Speciﬁcally, the real rains in LHP-Rain not only contain the classical rain streak/veiling/occlusion in the sky, but also the splashing on the ground overlooked by deraining community. Moreover, we propose a novel ro-bust low-rank tensor recovery model to generate the GT with better separating the static background from the dynamic rain. In addition, we design a simple transformer-based sin-gle image deraining baseline, which simultaneously utilize
†These authors contributed equally to this work.
∗Corresponding author. the self-attention and cross-layer attention within the image and rain layer with discriminative feature representation.
Extensive experiments verify the superiority of the proposed dataset and deraining method over state-of-the-art. 1.

Introduction
Single image deraining is to improve the imaging qual-ity by separating rain from image background. In recent years, signiﬁcant progress has been made in learning-based single image deraining by various sophisticated CNN archi-tectures [14, 36, 53, 10] and powerful Transformer models
[35, 44]. Although these state-of-the-art supervised methods have achieved impressive results on simulated datasets, a fact cannot be ignored that those competitive methods perform unsatisfactory on diverse real rainy scenes. The core reason is the domain shift issue between the simpliﬁed synthetic rain and complex real rain [50, 32, 41, 51].
To solve this problem, an intuitive idea is to try the best to make rain degradation model as real as possible [11].
The researchers formulate the rain imaging procedure into a comprehensive rain simulation model [9, 48, 12, 24, 18], 1
Datasets
RID/RIS[19]
NR-IQA[43]
Real3000[25]
FCRealRain[51]
SPA-Data[37]
RainDS[32]
GT-Rain[1]
RealRain-1K[20]
LHP-Rain
Source
Internet
Internet
Camera
Year 2019 Cam/Internet 2020 2021 2022 2019 Cam/Internet 2021 2022 2022 Cam/Internet 2023
Cam
Internet
Camera
Table 1: Summary of existing real rain datasets.
Sequence
None
None
None
None 170
None 202 1120 3000
Resolution
Frame 640*368 4.5K 1000*680 0.2K 942*654 3.0K 4240*2400 4.0K 256*256 29.5K 1296*728 1.0K 666*339 31.5K 1512*973 1.1K 1.0M 1920*1080
Rain Categories streak, raindrop streak, veiling streak, veiling streak, veiling streak streak, raindrop streak, veiling streak, veiling, occlusion
Annotation
Object detection
None
None
Object detection
None
None
None
None
Paired
----(cid:88) (cid:88) (cid:88) (cid:88) (cid:88) streak, veiling, occlusion, splashing Object detection/Lane in which different visual appearance of rain streaks[9], ac-cumulation veiling [48], haze [12, 18], and occlusion [24] factors are taken into consideration. Unfortunately, these linear simulation models still cannot well accommodate the distribution of realistic rains. For example, in Fig. 1, real-istic rain streak is usually not exactly a regular line-pattern streak but possesses irregular non-uniform in terms of the intensity and width. Apart from the rain streaks, the existing rain simulation models could not handle the complicated rain splashing on the ground, which presents as dense point-shape texture, droplets or water waves, ruining visibility of trafﬁc signs, such as lane lines, and also causes enormous negative effects for the high-level vision.
Another research line obtains the ‘clean’ counterpart from the realistic rainy videos [37, 20], which leverages the mo-tion discrepancy between static image background and dy-namic rain. Unfortunately, they simply employ naive ﬁl-tering strategies such as percentile ﬁlter [37] and median
ﬁlter [20], resulting in unsatisfactory GT with residual rain or over-smoothing phenomenon. Moreover, the number and diversity of the existing real paired rain datasets are still limited. Few datasets have considered the rain splash on the ground, which is commonly observed in the real world but still rarely mentioned in deraining community. And the number of existing video sequences and image frames are not sufﬁcient to cover diverse rains in terms of the varied rain angle, intensity, density, length, width and so on. Last but not least, the existing realistic rainy images are mostly downloaded from the Internet with low-quality: compres-sion, watermark, low-resolution, without annotation and so on. As such, constructing a large-scale high-quality paired realistic rain dataset is highly necessary.
In this work, we construct a new large-scale high-quality paired real rain benchmark. The strength of our benchmark is threefold. First, the LHP-Rain contains diverse rain cate-gories with very large-scale, including 3000 video sequences with over 1 million frame pairs. Second, apart from the conventional streak and veiling, our benchmark is capable of removing the representative challenging ground splash-ing rain in the real world. Third, the LHP-Rain is collected by the smartphone with high-resolution (1920*1080 pixels) and abundant objects under self-driving and surveillance scenes are captured for comprehensive evaluation. More-over, we propose a novel robust low-rank tensor recovery method (RLRTR) for video deraining, which can generate higher-quality GT with better rain removal from sky to the ground and image structure preserving. We summary the main contributions as follows:
• We construct a large-scale high-quality paired real rain benchmark for real single image deraining. To our best knowledge, LHP-Rain is the largest paired real rain dataset (3000 video sequences, 1 million frames) with high image resolution (1920*1080), and the ﬁrst benchmark to claim and tackle the problem of ground splashing rain removal.
• We design a novel robust low-rank tensor recovery model for video deraining to better acquire paired GT. We pro-vide detailed analysis to show RLRTR can better differ the rain from static background than previous datasets.
• We propose a new transformer-based single image de-raining baseline, which exploits both self-attention and cross-layer attention between the rain and image layer for better representation. Extensive experiments on different real datasets verify the superiority of proposed method. 2.