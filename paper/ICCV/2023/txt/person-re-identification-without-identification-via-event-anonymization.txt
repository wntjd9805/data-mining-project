Abstract
Wide-scale use of visual surveillance in public spaces puts individual privacy at stake while increasing resource consumption (energy, bandwidth, and computation). Neu-romorphic vision sensors (event-cameras) have been re-cently considered a valid solution to the privacy issue be-cause they do not capture detailed RGB visual information of the subjects in the scene. However, recent deep learn-ing architectures have been able to reconstruct images from event cameras with high fidelity, reintroducing a potential threat to privacy for event-based vision applications.
In this paper, we aim to anonymize event-streams to protect the identity of human subjects against such image recon-struction attacks. To achieve this, we propose an end-to-end network architecture jointly optimized for the twofold ob-jective of preserving privacy and performing a downstream task such as person ReId. Our network learns to scramble events, enforcing the degradation of images recovered from the privacy attacker. In this work, we also bring to the com-munity the first ever event-based person ReId dataset gath-ered to evaluate the performance of our approach. We val-idate our approach with extensive experiments and report results on the synthetic event data simulated from the pub-licly available SoftBio dataset and our proposed Event-ReId dataset. The code is available at https://github. com/IIT-PAVIS/ReId_without_Id 1.

Introduction
For security and monitoring purposes, intelligent surveil-lance systems are installed in our personal spaces (e.g., home surveillance) and all over urban areas (hospitals, banks, shopping malls, airports and streets, etc.). However, collecting images and videos with always-connected vision sensors raises new issues: i) ethical discussions over the bal-ance between safety/security needs and individual privacy; ii) unauthorized access to sensory data that may threaten users’ privacy; iii) extensive resource consumption of large-scale sensor networks, e.g., energy, bandwidth, and comput-ing power. Neuromorphic vision sensors (event cameras)
Figure 1. Event-to-image [32] can be regarded as a privacy at-tack, which reconstructs the appearance of a person from an event stream (a). We propose a learnable Event Anonymization network architecture (b), which deals with such attack by scrambling the event stream so that reconstruction deteriorates while preserving the performance of an event-based downstream task (e.g., person
ReId (c)). We also consider a possible Inversion Attack (d), where the attacker tries to reverse the effect of the proposed anonymiza-tion in order to attain image reconstruction (e). are a disruptive technology as they only capture scene dy-namics and do not record visual detail of humans, which enforces privacy-by-design (to some extent); their ultra-low resource consumption makes them ideal for always-on vi-sual sensors. Besides, their high dynamic range enables them to work under challenging illumination conditions while, alike RGB cameras, event-cameras are able to solve various vision tasks, such as object recognition [26], human pose estimation [33], detection and tracking [27, 15, 21], and person re-identification (ReId) [1].
Event cameras output asynchronous events that are trig-gered with extremely low latency when an intensity change at pixel level is over a given threshold. Due to their asyn-chronous nature, event streams do not form images but rather a data-stream containing pixel position activation
(i.e., (u, v) coordinates) and a polarity. These event streams were considered privacy-preserving, as they do not con-tain detailed visual features that can let a human or al-gorithm recognize individual traits such as faces. How-ever, event streams encode the entire visual signal in an ex-tremely compressed form and could, in principle, be decom-pressed to recover a high-quality video stream. Currently, deep neural network-based image reconstruction models
[32, 30, 37, 43] have demonstrated impressive abilities in recovering grayscale images from event streams, represent-ing a potential threat to the privacy of event-based vision applications as shown in Fig. 1 (a).
Recently, Du et al. [11] proposed a hand-crafted encryp-tion framework to prevent privacy attacks on event-streams.
Their approach incorporates a spatial chaotic mapping to scramble the positions of events and flip their polarities.
The spatial information in the encrypted event-stream is thus deformed due to 2D position scrambling and, as a re-sult, event-to-image methods fail to reconstruct high-quality images. The main drawback of this encryption technique is that downstream computer vision tasks cannot be performed directly with the encrypted event-stream, which is only use-ful to protect data during transmission or storage and must be decrypted before being utilized.
In this paper, we propose a learning-based approach called Event-Stream Anonymization which prevents pri-vacy attacks on event data (see Fig. 1 b), while at the same time allowing the execution of downstream tasks. The pro-posed method enforces the degradation of images recov-ered from the privacy attacker (i.e., event-to-image module) while jointly optimizing a downstream task in an end-to-end fashion. In other words, it helps protect subjects’ identity while preserving the information needed to achieve other tasks, such as person ReId as shown in Fig. 1 (c). The two tasks, anonymization and ReId, seem to have contrasting objectives. This represents the actual challenge of our work.
However, ReId only aims at associating images of a person in a camera network, while anonymity refers to protecting a person’s identity or other biometric traits. A practical use case is when an attacker has a person’s name and photo and aims at identifying that person by maliciously accessing a camera network. The proposed anonymization pipeline pre-vents this attack while allowing ReId by the surveillance system.
We verify that our approach can successfully anonymize the event-stream with only a small drop in performance in person ReId by performing extensive experiments on sim-ulated event data and on a newly introduced real event-based person ReId dataset called Event-ReId. More specif-ically, to evaluate the robustness of our method against event-to-image reconstruction techniques, not only do we measure the (poor) quality of the recovered images, but we also verify that classic full-body human identification or face identification tasks are hardly possible using such anonymized data. In addition, we validate the robustness of our anonymization technique against an inversion at-tack, where an attacker tries to reverse the effect of the anonymization network (see Fig. 1 d).
The main contributions of this work are summarised as follows:
• We propose an event-stream anonymization network to protect the identity information against event-to-image attacks in event-based vision applications. We also propose a joint optimization framework that preserves anonymization with a small drop in performance while testing on downstream tasks (e.g., ReId).
• We contribute a first-ever person ReId dataset captured with event camera, namely the Event-ReId dataset.
• We performed extensive experiments to verify the robustness of event stream anonymization network against privacy attacks (event-to-image approaches) using synthetic and the proposed real event dataset. 2.