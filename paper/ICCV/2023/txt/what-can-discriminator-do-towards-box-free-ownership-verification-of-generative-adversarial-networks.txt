Abstract
In recent decades, Generative Adversarial Network (GAN) and its variants have achieved unprecedented success in image synthesis. However, well-trained GANs are under the threat of illegal steal or leakage. The prior studies on remote ownership verification assume a black-box setting where the defender can query the suspicious model with specific inputs, which we identify is not enough for genera-tion tasks. To this end, in this paper, we propose a novel IP protection scheme for GANs where ownership verification can be done by checking outputs only, without choosing the inputs (i.e., box-free setting). Specifically, we make use of the unexploited potential of the discriminator to learn a hypersphere that captures the unique distribution learned by the paired generator. Extensive evaluations on two popular
GAN tasks and more than 10 GAN architectures demonstrate our proposed scheme to effectively verify the ownership.
Our proposed scheme shown to be immune to popu-lar input-based removal attacks and robust against other existing attacks. The source code and models are available at https://github.com/AbstractTeen/gan_ownership_verification. 1.

Introduction
With the rapid development of GANs, we have witnessed fruitful applications of GAN in many fields, such as realistic facial images synthesis [45], fine-grained attribute editing
[55], etc. Unlike the classification model with specified label prediction, the GANs learn a data distribution and output the synthesized data sample within a certain distribution.
In GANs, the discriminator and generator are two essential components, where the discriminator works as a judger to discriminate whether the sample is produced by the genera-Figure 1: Comparison of the verification process between previous black-box watermark-based verification paradigm [37] and our box-free method.
In the black-box setting, carefully-crafted verification samples should be fed to the suspicious model to activate a hidden backdoor in the model (the red circle) and generate watermarked outputs. However, in box-free setting, querying the model with deterministic inputs is not allowed. Ownership verification should be done with only output images. tor, the generator learns to generate more realistic samples to confuse the discriminator [16, 7]. Usually, the discriminator is discarded after training since the generator is the core asset for synthesizing high-quality images.
Training a decent GAN requires a huge investment of resources, such as computing resources, labeled/unlabeled training dataset, time, and human labors [47, 31]. However, well-trained generators are under the threat of unintentional leakage and theft. The adversary may deploy the stolen model on the Internet for profit and the owner (also the defender) is only able to verify the ownership remotely by querying the suspicious model [35, 37, 23, 14].
Most existing works on IP protection of DNN models as-1
sume the owner can query the suspicious model with specific inputs (i.e., black-box setting). Based on this fundamental assumption, two schools of solutions have been proposed: model watermark [64, 37, 29] and model fingerprint [39, 34].
They either proactively embed or passively extract a hidden functionality in the model, where outlier outputs can be acti-vated by a specific query set (known as the verification set).
For verification, the defender queries the model with this set and observes whether the outputs match the source model.
Since it is improbable for any other model to perform the same abnormal behavior, the owner can judge whether the suspicious model is a stolen copy.
However, the black-box assumption is challenged in gen-eration tasks. For example, the whole-image synthesis task takes a randomized latent representation as input. In reality, this representation is usually sampled from a pre-defined distribution, such as normal distribution. Therefore, the adversaries can prohibit the verification by sampling the latent representation themselves. The black-box methods are also shown to be vulnerable to input transformation-based removal attacks [19, 53]. Moreover, recent literature has shown the outlier verification samples can be detected, inspected, or reverse-engineered [18, 56]. Note that the verification set plays a similar role to private keys in cryp-tography [22, 30]. Once it is disclosed, the adversaries are capable to launch ambiguity attacks, or invalidate the wa-termark/fingerprint via methods such as adversarial training.
These limitations inspire us to raise an important question: can ownership verification be done via checking outputs only, without choosing the inputs (i.e., box-free setting)?
This setting is more challenging because queries made by the defender are totally equivalent to those of normal users.
There is no chance to activate a hidden functionality.
In this paper, we make the first attempt to box-free own-ership verification of GANs. Based on the fact that GAN suffers from unstable training, we reveal the unexploited potential of the discriminator to capture the model-specific distribution learned by the paired generator. We utilize the discriminator’s representations to learn a network featuring a hypersphere that encloses the distribution learned by the generator. Our proposed scheme does not require specify-ing any input nor training additional detection networks, the ownership verification can be done effectively via feeding a batch of suspicious images to the learned network. However, due to the gradual degradation issue, it is challenging for the discriminator to extract meaningful feature representa-tions without sacrificing the performance of the generator.
To tackle this problem, we leverage the pearson correlation coefficient [38] to quantify the implicit reconstruction ability of the discriminator, and prevent the degradation via adding the term into the loss function of the discriminator.
To comprehensively evaluate the effectiveness and robust-ness of our proposed method, we conduct experiments on two popular GAN tasks (i.e., entire image synthesis, image-to-image translation) and 10 state-of-the-art GAN architec-tures to demonstrate the effectiveness of our scheme in veri-fying the ownership of generator. We also show qualitatively and quantitatively that our scheme is immune to popular and powerful removal attacks (e.g., input transformation-based and reverse engineering-based attacks) and robust to other existing attacks.
Our main contributions are summarized as follows:
• We identify a fundamental limitation of black-box setting-based ownership verification schemes on generation tasks, i.e., choosing deterministic inputs is not allowed for appli-cations like unconditioned image synthesis.
• We reveal the unexploited potential of the well-trained discriminator for capturing the unique distribution learned by the paired generator. Based on this finding, we make the first attempt towards box-free verification scheme of
GANs, which does not require specifying the input and does not rely on additional models.
• Extensive evaluations on two popular GAN applications and more than 10 GAN architectures demonstrate our pro-posed scheme to effectively verify the ownership. Through qualitative and quantitative analysis, we show that our pro-posed scheme is immune to popular removal attacks and robust to other existing attacks. 2.