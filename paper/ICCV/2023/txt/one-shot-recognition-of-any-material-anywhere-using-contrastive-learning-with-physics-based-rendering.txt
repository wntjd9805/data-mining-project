Abstract
Visual recognition of materials and their states is essen-tial for understanding the world, from determining whether food is cooked, metal is rusted, or a chemical reaction has occurred. However, current image recognition methods are limited to specific classes and properties and can’t handle the vast number of material states in the world. To ad-dress this, we present MatSim: the first dataset and bench-mark for computer vision-based recognition of similarities and transitions between materials and textures, focusing on identifying any material under any conditions using one or a few examples. The dataset contains synthetic and nat-ural images. Synthetic images were rendered using giant collections of textures, objects, and environments gener-ated by computer graphics artists. We use mixtures and gradual transitions between materials to allow the system to learn cases with smooth transitions between states (like gradually cooked food). We also render images with ma-terials inside transparent containers to support beverage and chemistry lab use cases. We use this dataset to train a Siamese net that identifies the same material in different objects, mixtures, and environments. The descriptor gener-ated by this net can be used to identify the states of materials and their subclasses using a single image. We also present the first few-shot material recognition benchmark with nat-ural images from a wide range of fields, including the state of foods and beverages, types of grounds, and many other use cases. We show that a net trained on the MatSim syn-thetic dataset outperforms state-of-the-art models like Clip on the benchmark and also achieves good results on other unsupervised material classification tasks. Dataset, gener-ation code and trained models have been made available at: https://github.com/ZuseZ4/MatSim-Dataset-Generator-Scripts-And-Neural-net 1Vector institute, 2University of Toronto, 3Karlsruhe Institute of Technology, 4Innoviz
* Equal Contributions, # Corresponding authors alan@aspuru.com, manuel@drehwald.info, sagieppel@gmail.com
Figure 1. The MatSim benchmark for identifying materials from every aspect of the world using one or a few natural images (few-shot learning). Top-1 results of ConvNeXt trained on the MatSim dataset and pretrained Clip H14, on materials classes unseen dur-ing training. Only selected samples are shown. 1.

Introduction
The ability to visually identify materials is critical for a wide range of applications, from material science and
Figure 2. Selected examples from the MatSim synthetic dataset. The upper line contains random materials on random objects. The bottom row contains random materials inside transparent vessels. chemical research to cooking, construction, and industry (Figure 1) [31, 38, 22, 39, 14, 15]. Recognition of mate-rials and their states is essential for handling and inspect-ing materials in the chemistry lab, evaluating whether the ground is wet, determining whether a fruit is ripe, detecting rust on metal surfaces, and distinguishing between different types of rocks or fabrics. There are several major challenges that make this problem difficult for computer vision meth-ods. First, there are almost infinite material states and tex-tures, and each can look very different in different settings.
The second challenge is that transitions between material states tend to be gradual and have a continuous intermedi-ate state, which makes it hard to use discrete categories to describe the material (like cooked food). Another challenge is that liquids and materials in environments such as labo-ratories, hospitals, and kitchens are usually handled inside transparent vessels that distort the view of the materials.
Previous studies on image recognition for materials have focused on distinguishing between material classes, such as metal, plastic, and wood, or determining properties like tur-bidity or glossiness. The limitation of these approaches is that they can only work on the classes and properties they were trained on [13, 8, 16, 29, 36, 14, 7]. To our knowl-edge, the problem of identifying unseen materials in any environment using one example (one-shot learning) has not been addressed by any benchmark or dataset. In this work, we propose the first general dataset and benchmark for one-shot recognition of any material state in any environment using only one or a few examples. 1.1. The MatSim Dataset
The MatSim dataset includes large-scale collections of synthetic images (Figure 2) for material self-similarity and a diverse natural image benchmark to test the ability of the net to identify material states and subclasses using one or a few examples (Figure 1). This dataset is designed to ad-dress the general issue of one-shot material retrieval without restrictions on material types, settings, and environments.
The main focus is on distinguishing between states of ma-terials and identifying fine-grained categories such as rot-ten vs. ripe or coffee vs. cocoa. Additionally, we created a second adversarial benchmark to test the net’s ability to recognize materials without association with objects or en-vironments. This benchmark involves covering objects with random materials to create uncorrelated material-object as-sociations. 1.2. Synthetic Dataset and Training
Our hypothesis is that training a Siamese net to iden-tify the same material texture on different objects and en-vironments will allow the net to recognize materials in any setting. While material types are not always matched to a single texture, we assume that a diverse enough training set will force the net to learn a general representation of mate-rials and their properties. The main advantage of this self-similarity approach is that when applied to synthetic data, it can be used to generate an unlimited amount of data with no human effort. In addition, it can be easily expanded to materials mixtures and gradual transitions. The main chal-lenge is the need for a large and highly diverse dataset to prevent the net from overfitting to specific materials or en-vironments. 1.3. Evaluation and Results
The net trained on the MatSim dataset achieves good results in recognizing and matching materials of the same states and subclasses, outperforming state-of-the-art nets like CLIP and nets trained on human-annotated similarity metrics. We also demonstrate that the net performs well in matching images of the same general class in standard clas-sification datasets such as OpenSurface[7] and DMS[32], without using the semantic class labels, suggesting that it learned robust descriptors that generalize beyond its origi-nal task. 1.4. Contribution 1) This work introduces the first general dataset and benchmark for low-shot material recognition. The base-lines tested in the experimental section demonstrate that the dataset achieves this, allowing the net to identify subclasses, gradual transitions, and materials states, and even allow-ing the net to generalize to different tasks, such as mate-rial classification. 2) Demonstrating that a net trained only on synthetic data and self-similarity, using a single GPU,
can outperform large-scale foundation models like Clip on a general low-shot problem. 3) Show how large-scale CGI assets repositories can be combined to create highly diverse synthetic training data with diversity far exceeding existing materials data sets (hundreds of thousands of different ob-jects and textures) and can be scaled indefinitely using AI textures/objects generating techniques. 2.