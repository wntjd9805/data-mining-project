Abstract
The great advancements of generative adversarial net-works and face recognition models in computer vision have made it possible to swap identities on images from sin-gle sources. Although a lot of studies seems to have proposed almost satisfactory solutions, we notice previ-ous methods still suffer from an identity-attribute entan-glement that causes undesired attributes swapping because widely used identity encoders, e.g., ArcFace, have some crucial attribute biases owing to their pretraining on face recognition tasks. To address this issue, we design Blend-Face, a novel identity encoder for face-swapping. The key idea behind BlendFace is training face recognition models on blended images whose attributes are replaced with those of another mitigates inter-personal biases such as hairsyles. BlendFace feeds disentangled identity fea-tures into generators and guides generators properly as an identity loss function. Extensive experiments demonstrate that BlendFace improves the identity-attribute disentangle-ment in face-swapping models, maintaining a comparable quantitative performance to previous methods. The code and models are available at https://github.com/ mapooon/BlendFace. 1.

Introduction
Face-swapping aims to replace target identities with source identities in images while preserving the target at-tributes, e.g., facial expression, hair, pose, and background.
This task is receiving considerable attention because of its potential applications in various fields, such as films and metaverses. Recent advances in generative adversarial net-works (GANs) [7, 25, 34, 36, 51, 58, 89] have enabled the photo-realistic image generation in various conditions, e.g., attribute [29], identity [9], and expression [83], as well as unconditional image generation. Moreover, the advance-ment in face recognition models provides powerful iden-tity encoders for face-swapping, which boosts the trans-*Work done during an internship at CyberAgent AI Lab
Figure 1: Examples of attribute leakages. The direct use of face recognition models, i.e., ArcFace [17] as an identity guidance causes attribute leakages, especially on head shapes and hairstyles due to attribute biases inherent in the face recognition models whereas our identity encoder
BlendFace address these problems. Best viewed in zoom. ferability of identities from source inputs to generated im-ages and leads to successful one-shot face-swapping mod-els [9, 14, 22, 45, 50, 72, 74â€“76, 90] with reasonable quality.
However, despite these impressive efforts, a critical is-sue still remains. Previous state-of-the-art methods suf-fer from identity-attribute entanglements because of biased guidance from face recognition models used as identity en-coders. Fig. 1 presents the failure cases of a traditional face recognition model ArcFace [17]. As shown in the figure,
ArcFace-based face-swapping models tend to swap unde-sired attributes, e.g., hairstyles and head shapes. This is because images of the same identity have strong correla-tions for some attributes; therefore, face recognition models accidentally learn to recognize the attributes as identities, which causes misguidances in training face-swapping mod-els. Though certain studies in the field of face recognition propose effective approaches to mitigate biases between individuals, they cannot be solutions for biases in face-swapping models as they do not consider intra-personal bi-ases.
In this paper, we propose BlendFace, a novel identity en-coder that provides well-disentangled identity features for
2.