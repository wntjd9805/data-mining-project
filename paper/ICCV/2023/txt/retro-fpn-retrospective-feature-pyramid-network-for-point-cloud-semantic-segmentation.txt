Abstract
Learning per-point semantic features from the hierar-chical feature pyramid is essential for point cloud seman-tic segmentation. However, most previous methods suf-fered from ambiguous region features or failed to reﬁne per-point features effectively, which leads to information loss and ambiguous semantic identiﬁcation. To resolve this, we propose Retro-FPN to model the per-point feature pre-diction as an explicit and retrospective reﬁning process, which goes through all the pyramid layers to extract se-mantic features explicitly for each point.
Its key novelty is a retro-transformer for summarizing semantic contexts from the previous layer and accordingly reﬁning the fea-*Equal contribution.
†Corresponding authors. This work was supported by National Key
R&D Program of China (2022YFC3800600), the National Natural Sci-ence Foundation of China (62272263, 62072268), and in part by Tsinghua-Kuaishou Institute of Future Media Data. tures in the current stage.
In this way, the categoriza-tion of each point is conditioned on its local semantic pat-tern. Speciﬁcally, the retro-transformer consists of a local cross-attention block and a semantic gate unit. The cross-attention serves to summarize the semantic pattern retro-spectively from the previous layer. And the gate unit care-fully incorporates the summarized contexts and reﬁnes the current semantic features. Retro-FPN is a pluggable neural network that applies to hierarchical decoders. By integrat-ing Retro-FPN with three representative backbones, includ-ing both point-based and voxel-based methods, we show that Retro-FPN can signiﬁcantly improve performance over state-of-the-art backbones. Comprehensive experiments on widely used benchmarks can justify the effectiveness of our design. The source is available at https://github. com/AllenXiangX/Retro-FPN . 1.

Introduction 3D point cloud semantic segmentation [27, 5, 80, 32, 9, 55, 84, 63, 75], which aims to predict a unique category la-Input (a)
GT
Point Transformer
Retro-FPN (b) (c) (d) 4(cid:817)
Y  2(cid:817)
Y  5(cid:817)
Y  3(cid:817)
Y 
Figure 2. Visualization of segmentation process of Retro-FPN. (a) and (c) show the visual comparison with the backbone (Point
Transformer [87]) network. In (a), the backbone loses the infor-mation of the column. In (c), the backbone struggles to distinguish between chair and sofa. In (b) and (d), we show the retrospective reﬁning process by Retro-FPN over the improved areas. 1(cid:817)
Y  bel for each point, is a critical task towards the 3D visual un-derstanding of large-scale scenes. A typical solution to pre-dict per-point semantic labels is the widely used encoder-decoder framework [21]. The encoder aims to learn contex-tual region features by gradually enlarging receptive ﬁelds.
The decoder propagates the local region features from the larger receptive ﬁelds into the smaller ones, which inher-ently forms a feature pyramid [37] (see Figure 1 (a)).
Learning per-point feature prediction from the pyramidal region features is the target of point cloud semantic segmen-tation. However, most existing encoder-decoder-based net-works merely reveal per-point features explicitly at the ﬁnal layer (denoted as red box in Figure 1 (a)), leaving abun-dant semantic information stuck in the intermediate region features (black box in Figure 1 (a)), which cannot directly facilitate the ﬁnal prediction. This may lead to the loss of semantic information and ambiguous semantic identiﬁca-tion, as demonstrated in Figure 2 (a) and (c). Since each pyramid layer may contain useful and erroneous informa-tion simultaneously, the per-point semantic features should be carefully reﬁned through all stages.
To resolve this, some prior works [16, 28] adopt hierar-chical supervision to reﬁne intermediate predictions explic-itly. In 2D vision, PointRend [28] proposed to reﬁne high-frequency points with hierarchical supervision, but each point is reﬁned based on the features interpolated at a single location, which suffered to capture the local semantic pat-tern and may fail to obtain informative per-point features for 3D point clouds. RFCR [16] ﬁrst introduced multi-scale supervision to point cloud semantic segmentation, but the supervision was on region-level and it’s still difﬁcult to ob-tain accurate per-point prediction from the region features.
Therefore, we propose Retro-FPN to improve per-point semantic feature prediction by fully utilizing the feature pyramid, which is achieved by an explicit and retrospective reﬁning process (see Figure 1 (b)). Speciﬁcally, by predict-ing per-point labels for all the middle layers, Retro-FPN al-lows region information to ﬂow into points and obtains the point-level semantic features at each stage. Then, the fea-tures are carefully reﬁned by retrospectively summarizing the semantic pattern from the previous layer and adaptively rearranging the current semantic information.
To conduct retrospective reﬁnement, we introduce a novel retro-transformer in each layer to extract per-point semantic features, which consist of two stages. The ﬁrst stage aims to “retrospect” useful information from the pre-vious layer. Since the category of each point is similar to its surrounding local region, we use a local cross-attention block to conduct retrospection, which takes the features of the current layer as queries to summarize semantic contexts from the previous layer. Different from the region-level in-formation in the backbone features, such contextual infor-mation are built upon the per-point semantic features of the nearby points, which can fully facilitate the reﬁnement of each point by selectively revisiting its neighbor points. The second stage serves to “reﬁne” the current semantic features by combining them with the summarized contexts. Instead of merging the features with simple adding or concatena-tion, we use a lightweight semantic gate to adaptively pre-serve and forget the previous semantic information. The retro-transformer can establish a cross-level semantic rela-tionship between different decoding stages, this enables the network to explicitly preserve useful information and dis-card erroneous information in each stage, as illustrated in
Figure 2 (b) and (d).
Retro-FPN is a pluggable neural network that can extract and reﬁne per-point semantic features for prevailing back-bones, including both point-based and voxel-based meth-ods. Speciﬁcally, we embed Retro-FPN into KPConv [65],
MinkowskiNet [7], and Point Transformer [87]. Non-trivial improvements on the S3DIS [1] Area 5 benchmark (Figure 1 (c)) can verify the effectiveness of our network design. In summary, our contributions are threefold:
• We propose Retro-FPN to improve per-point seman-tic feature prediction for 3D point clouds. Retro-FPN models the feature propagation as an explicit and ret-rospective reﬁning process on point-level semantic in-formation, which is a plug-and-play network that can improve the performance of prevailing backbones.
• We propose a novel retro-transformer to establish a cross-level semantic relationship between different de-coding stages. It utilizes a local cross-attention to ret-rospect the previous semantic pattern and leverages a lightweight semantic gate unit to reﬁne the current se-mantic features.
• We integrate Retro-FPN with both point-based and voxel-based backbones and evaluate our method on the S3DIS [1], ScanNet [10] and SemanticKITTI [2] benchmarks. Experimental results demonstrate that our method can signiﬁcantly improve performance over state-of-the-art methods. 2.