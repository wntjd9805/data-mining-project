Abstract
Deep learning algorithms require large amounts of la-beled data for effective performance, but the presence of noisy labels often significantly degrade their performance.
Although recent studies on designing a robust objective function to label noise, known as the robust loss method, have shown promising results for learning with noisy la-bels, they suffer from the issue of underfitting not only noisy samples but also clean ones, leading to suboptimal model performance. To address this issue, we propose a novel learning framework that selectively suppresses noisy sam-ples while avoiding underfitting clean data. Our frame-work incorporates label confidence as a measure of label noise, enabling the network model to prioritize the training of samples deemed to be noise-free. The label confidence is based on the robust loss methods, and we provide theoreti-cal evidence that our method can reach the optimal point of the robust loss, subject to certain conditions. Furthermore, the proposed method is generalizable and can be combined with existing robust loss methods, making it suitable for a wide range of applications of learning with noisy labels.
We evaluate our approach on both synthetic and real-world datasets, and the experimental results demonstrate its ef-fectiveness in achieving outstanding classification perfor-mance compared to state-of-the-art methods. 1.

Introduction
Recent advances in deep learning have led to remarkable image classification performance that surpasses human abil-ity [8, 9]. However, the challenge is that deep learning mod-els require a substantial amount of labeled data to maintain their desired performance. Image classification benchmark datasets often contain tens of thousands [14] to millions [24] of labeled data. Despite extensive efforts to curate these datasets, mislabeling is inevitable due to the complexity of samples and errors made by experts [1]. This issue is par-ticularly problematic given the capacity of deep networks to
*Corresponding author
Figure 1. Comparison with robust loss functions against to label noise. (a) Cross-entropy loss cannot prevent the learning of mislabeled samples, as it imposes a stronger penalty on predictions that are more misaligned. (b) Noise-robust loss prevents the model from learning mislabeled samples by suppressing strong penalties, but it carries the risk of underfitting. (c) Ours adjusts the penalty based on the confidence of each sample, imposing a strong penalty only on samples with high confidence in their labels. overfit data samples [35]. Consequently, preventing overfit-ting on mislabeled data is a critical challenge.
To tackle this challenge, researchers have focused on de-veloping methods for learning with noisy labels in deep learning frameworks. These methods can be categorized into three topics: noise estimation, sample selection, and robust loss. While noise estimation methods [6, 10, 22, 25] assume the availability of prior knowledge about the noise model, obtaining this information in real-world practice can be challenging. Sample selection methods [7, 12, 31, 34, 13] aim to eliminate noisy labels in the dataset and train the network model on the refined set. However, the success of these methods heavily depends on the quality of noise elim-ination, and the human-designed criteria for configuring the refined set may not generalize well across various datasets
[33]. Robust loss methods [4, 5, 30, 37], on the other hand, aim to design loss functions that are theoretically less af-fected by label noise. However, these methods can also en-courage underfitting, resulting in lower performance.
This paper presents a novel training strategy aimed at addressing the underfitting problem commonly encountered
by robust loss methods. Cross-entropy loss, a widely-used objective function for image classification tasks, is highly responsive to incorrect predictions. This is because both the loss value and gradient magnitude increase when the pre-dicted probability for a given label decreases. Conversely, robust loss methods reduce the penalty for erroneous pre-dictions to prevent the model from learning mislabeled sam-ples. However, batch-based stochastic gradient descent can often impede convergence to the optimal point of the robust loss function, leading to underfitting issues. To alleviate this challenge, we propose a sample-wise label confidence in-corporation into our method. This incorporation leads to re-duced penalties for inaccurate predictions of noisy samples with lower confidence levels. The proposed approach in-volves training using a weighted cross-entropy loss, where the weight is determined based the label confidence. A vi-sual representation of this methodology is in Figure 1.
Furthermore, we also offer theoretical evidence that our proposed training strategy is capable of attaining the op-timal point of the robust loss method, subject to certain conditions being satisfied regarding the sample-wise label confidence. Specifically, the calculation of the label confi-dence is based on the existing robust loss method, and our proposed method approximates the optimal point of the se-lected robust loss method.
Importantly, it’s worth noting that our method does not introduce a novel loss function that inherently accounts for label noise robustness. Instead, it provides a training strategy to mitigate the underfitting is-sue of existing robust loss methods like MAE [5], GCE [37], and JS [4]. Thus, our strategy holds the potential for univer-sal applicability. Additionally, in contrast to sample selec-tion methods that often require the hard-tuning of hyper-parameters based on human-designed criteria, our method computes the label confidence by simply selecting the ap-propriate robust loss.
Our research derives label confidence for a dataset con-sisting primarily of normal samples, inspired by an appli-cation of the robust loss [21]. While the previous appli-cation employed a robust loss model to identify unbiased images by learning features that counteract bias, our pro-posed method employs a robust loss model that effectively learns the majority of normal samples. This approach pre-vents the imposition of excessive penalties on mislabeled samples. The determination of label confidence plays a piv-otal role in achieving this objective. In order for the theo-retical framework to hold, the label confidence must satisfy two critical conditions: (1) a strict negative correlation be-tween the label confidence and the robust loss value exists, and (2) samples with a robust loss value surpassing a spe-cific threshold must converge towards a label confidence of 0. These conditions are intuitive and align with our assump-tion that samples with low robust loss values are less likely to be noisy samples.
In summary, the proposed approach offers a novel learn-ing strategy to address the underfitting problem of robust loss methods, which can be combined with existing robust loss methods in a versatile manner. Moreover, our theo-retical findings emphasize the potential for designing label confidence to adhere to two crucial conditions. This insight can serve as valuable guidance for future research endeav-ors aimed at calculating label confidence through alterna-tive approaches. Finally, we evaluate the performance of the proposed method on synthetic datasets and real-world datasets. On synthetic datasets, our method significantly outperforms existing robust loss methods, particularly as the noise ratio increases.
In addition, our method shows consistent performance across different hyperparameters, which is a significant advantage over existing learning with noisy label methods that require hard-tuning. On real-world datasets, our method also achieves state-of-the-art perfor-mance, demonstrating its effectiveness in real-world scenar-ios. Our contributions are three-fold:
• The proposed approach reduces underfitting issues of robust loss methods by incorporating sample-wise la-bel confidence, leading to improved convergence to the optimal point of the robust loss function.
• The proposed method is generally applicable to robust loss methods, and label confidence can be simply com-puted by selecting the appropriate robust loss.
• Theoretical evidence supports the proposed method by providing guidelines for designing label confidence that approximates the optimal point of the selected ro-bust loss method, subject to certain conditions being satisfied regarding sample-wise label confidence. 2.