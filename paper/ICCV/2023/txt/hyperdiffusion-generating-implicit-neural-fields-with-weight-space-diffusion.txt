Abstract 1.

Introduction
Implicit neural fields, typically encoded by a multilayer perceptron (MLP) that maps from coordinates (e.g., xyz) to signals (e.g., signed distances), have shown remark-able promise as a high-fidelity and compact representation.
However, the lack of a regular and explicit grid structure also makes it challenging to apply generative modeling di-rectly on implicit neural fields in order to synthesize new data. To this end, we propose HyperDiffusion, a novel ap-proach for unconditional generative modeling of implicit neural fields. HyperDiffusion operates directly on MLP weights and generates new neural implicit fields encoded by synthesized MLP parameters. Specifically, a collection of MLPs is first optimized to faithfully represent individual data samples. Subsequently, a diffusion process is trained in this MLP weight space to model the underlying distribu-tion of neural implicit fields. HyperDiffusion enables diffu-sion modeling over a implicit, compact, and yet high-fidelity representation of complex signals across 3D shapes and 4D mesh animations within one single unified framework.
Recent years have seen profound development in im-plicit neural field models, demonstrating powerful repre-sentations, particularly 3D shape geometry [34, 6], neu-ral radiance fields (NeRF) [31], and complex signals with higher-order derivative constraints [46]. Typically, an im-plicit neural field1 maps an input coordinate location in n-dimensional space to the target signal domain. For example, an implicit surface representation
{x ∈ Rn|f (x, θ) = 0}, where f : Rn → R is typically characterized by a mul-tilayer perceptron (MLP). Notably, such neural fields ef-ficiently represent sparse high-dimensional data in a rela-tively low-dimensional MLP weight space. This contin-uous mapping enables sampling at arbitrary-resolution for surface representations, eliminating explicit resolution con-straints inherent to classical point, mesh, or voxel represen-tations. One can then easily reconstruct the mesh underly-1Implicit neural fields are also referred to as coordinate fields or coordinate-based networks. We use these terms interchangeably.
ing this compact representation through methods such as
Marching Cubes [28].
It has enabled faithful 3D recon-struction where an MLP is optimized to fit a set of point observations [34], as well as preliminary results in higher-dimensional 4D reconstruction and tracking [27]. have been optimized to represent individual instances from a dataset. We then employ a transformer-based network to model the diffusion process directly on the optimized
MLP weights. This enables generative modeling on a low-dimensional space, and we demonstrate its high-fidelity and diverse generative modeling capabilities, achieving state-of-the-art 3D and 4D surface synthesis.
Our contributions can be summarized as follows:
• We present the first approach to model the space of neural field MLP weights by diffusion modeling, en-abling a new paradigm for high-dimensional genera-tive modeling.
• Our MLP optimization of surface occupancy provides a low-dimensional weight space for effective uncondi-tional diffusion modeling with a transformer-based ar-chitecture for both 3D and 4D surfaces at high fidelity. (a) Generated 3D shapes. 2.