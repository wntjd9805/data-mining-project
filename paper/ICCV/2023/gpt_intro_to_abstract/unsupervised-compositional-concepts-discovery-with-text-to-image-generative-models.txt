This paper introduces a scalable approach to discovering unsupervised compositional concepts in realistic images using existing generative models. The authors demonstrate how their method achieves state-of-the-art performance on concept discovery across different domains, including automating the discovery of painting styles and decomposing scenes into lighting and objects. The discovered generative concepts can be used for various tasks, such as generating novel creative images or effective representations for downstream classification tasks. The approach is illustrated with examples across different domains, including art, ImageNet images, and kitchen scenes. The authors contribute a method that leverages the rich semantic information in large text-to-image generative models to discover diverse compositional generative concepts from unlabeled natural images. Overall, this work advances the understanding of computer vision systems' ability to understand, recombine, and imagine the visual world.