Visual similarity is a crucial factor in various computer vision applications such as search and recommendations. Existing methods for visual similarity discovery (VSD) often rely on identification retrieval tasks, where images of the same object are retrieved under different conditions. However, identification and visual similarity tasks are distinct, as illustrated by examples in Fig. 1. Additionally, the scarcity and inconsistency of multiple images of the same product pose challenges for learning visual similarity. To overcome these limitations, auxiliary information can be used, but it may not always be a reliable proxy for perceived similarities. The most accurate evaluation of visual perceptual similarity requires annotations from human domain experts, but this approach is time-consuming and costly. In this paper, we propose the Efficient Discovery of Similarities (EDS) method for efficiently collecting feedback from experts. We release a large-scale benchmark dataset of over 110K labeled image pairs for evaluating VSD models. Our contributions include highlighting the evaluation challenge in VSD, proposing an efficient procedure with appropriate metrics, curating a benchmark dataset, and providing an extensive evaluation of pretrained and finetuned models. Additionally, we discuss the limitations of supervised methods for VSD.