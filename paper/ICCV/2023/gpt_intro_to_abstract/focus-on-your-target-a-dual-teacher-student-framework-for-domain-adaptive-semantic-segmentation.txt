Deep neural networks have shown effectiveness in learning from labeled visual data, but their ability to adapt to unlabeled data or unknown domains is not always guaranteed. In this paper, we focus on the unsupervised domain adaptation problem for semantic segmentation, where pixel-wise labeled data is available for the source domain but only unlabeled images are provided for the target domain. This setting is valuable in real-world applications where annotating new domains is burdensome. The current state-of-the-art approaches for unsupervised domain adaptation in semantic segmentation are based on a self-training framework. This framework first learns semantics from labeled data in the source domain and then generates pseudo labels in the target domain to adapt the model. However, the two abilities of learning knowledge from the source domain and adapting it to the target domain can conflict with each other. To address this conflict, we propose a dual teacher-student (DTS) framework. The key idea is to train two individual models with different network weights to alleviate the conflict. DTS can be built upon existing self-training approaches by creating two copies of the original teacher-student model, increasing the training data proportion from the target domain in the second group, and applying a bidirectional learning strategy where the two models supervise each other via pseudo labels. This framework allows for stronger adapting ability while mostly preserving the learning ability. Experiments conducted on the standard unsupervised domain adaptation setting using synthetic and real datasets demonstrate the effectiveness of the DTS framework. When integrated with existing baselines, DTS achieves improved segmentation accuracy and sets new records on benchmark datasets.