Human pose estimation is an important task in computer vision with various applications in virtual/augmented reality, healthcare, and security surveillance. Real-time pose estimation on resource-constrained devices is challenging due to the computational burden of deep learning models. Keyframe-based pose estimation frameworks have shown promise in reducing computational costs by reconstructing poses in remaining frames from keyframe poses. However, existing pipelines for keyframe selection and refinement modules are repetitive and unnecessary. To address this, we propose a simplified recover-refine pipeline that selects keyframes using a sampler and recovers the pose sequence using an interpolator, followed by a single refinement module. We introduce a novel framework called MixSynthFormer, utilizing a lightweight transformer encoder-like structure for sampling-based pose estimation. We use a synthetic self-attention module to generate attention weights and capture inter-joint and inter-frame relationships. Our model outperforms existing frameworks in terms of accuracy and efficiency for 2D and 3D pose estimation and body recovery tasks. It also shows competitive performance in short-term motion prediction tasks.