This paper introduces the concept of distribution drift in deep neural networks (DNNs) used for computer vision tasks and the need for robustness research in object detection. The authors argue that most current robustness research focuses on image classification and lacks benchmarks for object detection. They propose COCO-O, a novel test dataset consisting of online-collected images from various domains, to evaluate the robustness of object detectors under natural distribution shifts. COCO-O is compared to existing benchmarks and shown to be more comprehensive and challenging. The authors conduct extensive experiments on over 100 modern object detectors, analyzing factors that influence robustness such as detector architecture and pre-training. The findings suggest that improving backbone models and utilizing advanced backbone designs can enhance detector robustness, although detection transformers are found to be more vulnerable under distribution shifts. The authors hope that COCO-O will provide a valuable testbed for robustness studies in object detection and encourage future algorithms to evaluate their out-of-distribution generalization ability. The contributions of this paper include the proposal of COCO-O, the benchmarking of modern detectors for robustness, and the analysis of factors impacting detector robustness.