This paper introduces a novel approach to self-supervised representation learning using a data-agnostic augmentation technique called channel-wise randomized quantization. The authors draw a connection between the sequential masking operation and quantization, exploring quantization as a form of masking along the channel dimension. The data in each channel is dynamically quantized through a non-uniform quantizer, with the quantization value randomly sampled from randomly sampled quantization bins. This allows information within each quantization bin to be masked out while retaining information across bins. The authors systematically study various quantization configurations and their effects as data augmentation, including the number of bins, uniform or non-uniform bins, and methods to select quantization values. They apply this randomized quantizer as the sole augmentation or in combination with augmentations along the sequential dimension on state-of-the-art Siamese representation learning methods. Their approach achieves state-of-the-art results on various modalities such as vision, audio, 3D point clouds, and the DABS benchmark, outperforming domain-agnostic and domain-specific augmentations. The contributions of this paper include the proposal of a simple and effective data-agnostic augmentation technique, the design of a randomization technique to enhance data augmentation, and the demonstration of the generality and strong performance of channel-wise randomized quantization in a data-agnostic manner.