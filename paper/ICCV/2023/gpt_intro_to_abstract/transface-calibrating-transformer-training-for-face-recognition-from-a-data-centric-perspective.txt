Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs) have been successful in computer vision tasks, but ViTs lack certain biases, leading to challenges in training. While ViTs perform well on visual tasks with large-scale training data, their performance is similar to CNNs in Face Recognition (FR). This paper investigates the training process of ViTs in FR and identifies the drawbacks in instance-level data augmentation and hard sample mining strategies. To address these issues, the paper proposes a patch-level data augmentation strategy called Dominant Patch Amplitude Perturbation (DPAP) that preserves face structural information. It also introduces an entropy-guided hard sample mining strategy (EHSM) to better mine hard samples and enhance the stability of FR model prediction. Experimental results on face benchmarks demonstrate the superiority of the proposed methods.