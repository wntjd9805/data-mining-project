Change captioning is an emerging task in computer vision and natural language processing, wherein the goal is to not only understand the contents of two similar images but also describe their differences using natural language. This task has various real-world applications, including generating detailed reports on monitored facilities and pathological changes. However, change captioning presents additional challenges compared to single-image captioning. These challenges include locating subtle differences in images and dealing with pseudo changes caused by different viewpoints or object scale and location variations. Traditional methods for locating changes involve subtracting two images or matching object features between the images. However, current match-based methods struggle to learn stable difference features under pseudo changes, as shifting features of corresponding objects can overpower local feature changes. To address these challenges, this paper proposes a novel Self-supervised CrOss-view REpresentation Reconstruction (SCORER) network. SCORER uses a multi-head token-wise matching (MTM) approach to model relationships between cross-view features from similar/dissimilar images. It maximizes cross-view contrastive alignment to learn view-invariant image representations and reconstruct the representations of unchanged objects. SCORER also employs cross-modal backward reasoning (CBR) to improve the quality of generated captions by ensuring that they are informative about the differences between the two images. Experimental results show that SCORER outperforms existing methods on four public datasets with different change scenarios.