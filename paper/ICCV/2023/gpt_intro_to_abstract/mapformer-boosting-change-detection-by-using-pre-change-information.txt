In recent years, there has been a significant increase in the availability of Earth observation data, which has provided valuable insights in various fields such as climate research, disaster management, and urban planning. Efforts have been made to create rich semantic maps of the Earth, including manual annotations provided by platforms like OpenStreetMap and the use of deep learning techniques for large-scale semantic mapping. However, the Earth's surface is constantly changing due to both natural and human influences. This has resulted in the need for monitoring and detecting changes in the Earth's surface using up-to-date Earth observation data. Change detection, which involves comparing bi-temporal images to identify semantically changed pixels, is typically done using deep learning methods. However, the research community has largely overlooked the potential of utilizing existing semantic information, such as maps, for change detection tasks. In this paper, we introduce the novel tasks of Conditional Change Detection and Cross-modal Change Detection, where semantic information is used in the form of pixelwise maps to improve change detection performance. We propose the MapFormer architecture, which combines bi-temporal image features and map features through a multi-modal feature fusion module. We also apply a supervised contrastive loss to guide the image encoder during training. Our experiments on publicly available datasets demonstrate the effectiveness and robustness of our approach. Overall, our contributions include introducing new change detection tasks, proposing the MapFormer architecture, and providing experimental evidence of its performance gains and practicality.