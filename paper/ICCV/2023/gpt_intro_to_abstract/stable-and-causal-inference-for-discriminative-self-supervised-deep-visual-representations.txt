Learning generalized representation with unlabeled data is a challenging task, but Self-Supervised Learning (SSL) has shown promising results in learning semantic invariant representations without labels. There are two main types of SSL: generative SSL, which reconstructs altered data, and discriminative SSL, which predicts task-specific representations. However, discriminative SSL can result in unstable representations when one subtle factor of the data changes. To address this issue, we propose learning targeted transformations that restore performance on unseen data shifts. Our contributions include showcasing the benefits of aligning positive pairs, demonstrating the orthogonality of augmentations applied during training, proposing causal interpretations of data changes, and validating our solutions through experiments.