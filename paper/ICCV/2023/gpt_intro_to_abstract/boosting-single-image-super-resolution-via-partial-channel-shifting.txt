Single image super-resolution (SISR) is a challenging problem in computer vision, aiming to reconstruct a high-resolution (HR) image from a low-resolution (LR) image. Convolutional neural networks (CNNs) have shown significant progress in SISR by learning non-linear mappings from LR to HR image pairs. However, existing models heavily rely on increasing the scale of the model, including network parameters and depth, to achieve high-quality results. This approach has limitations in performance improvement and utilization efficiency. In this paper, we propose a method called partial channel shifting (PCS) to improve the effectiveness of intermediate features in SR models without increasing computational overhead. PCS strategically displaces a portion of feature channels in the spatial dimensions, enhancing feature diversity and enlarging the receptive field. We analyze different technical constraints to simplify the application of PCS and demonstrate its effectiveness through benchmark experiments. The results show that PCS improves SR performance without additional parameters and computational costs. Our contributions include the proposal of PCS, the identification of technical constraints, and experimental evidence of its effectiveness in enhancing feature representation and promoting SR performance.