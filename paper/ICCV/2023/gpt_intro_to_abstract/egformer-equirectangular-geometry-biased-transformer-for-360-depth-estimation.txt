Estimating depths in equirectangular (360Â°) images is challenging due to their wide field-of-view and distortion. Global view and large receptive field are crucial for accurate depth estimation. Vision transformer (ViT) is promising for equirectangular depth estimation but has high computational cost. Local attention is necessary, but the distortion and limited receptive field of equirectangular images make it difficult. Existing strategies like Panoformer have limitations in addressing the receptive field. This paper proposes EGformer, an equirectangular geometry-biased transformer, that utilizes equirectangular geometry as a bias for inter- and intra-local windows. It includes equirectangular relative position embedding (ERPE), distance-based attention score (DAS), and equirectangular-aware attention rearrangement (EaAR) to consider geometry bias and enlarge the receptive field. EGformer achieves accurate depth estimation with the lowest computational cost and parameters, outperforming existing studies.