This paper addresses the problem of restoring images degraded by various weather conditions, such as fog, snow, rain, and haze. While there have been successful techniques for restoring images degraded by a single weather condition, restoration of images degraded by multiple weather conditions remains an open problem. Existing approaches handle multiple degradations separately, but this can lead to undesirable results and require prior knowledge of the specific degradation. To overcome these limitations, the authors propose a novel multi-weather image restoration framework. They use a domain translation approach to create different weather degradations of a degraded image and train a feature extractor to learn weather-invariant features. This feature extractor can be used on both synthetic and real-world data. The proposed restoration network comprises a progressive multi-domain deformable alignment module and cascaded multi-head attention blocks, which effectively restore the images. Experimental analysis on synthetic and real-world datasets demonstrates that the proposed framework outperforms existing state-of-the-art methods. Overall, this paper presents a unified architecture for multi-weather image restoration and introduces novel modules for achieving better restoration results.