This paper introduces a framework for a geometric adversarial attack on 3D meshes, with a focus on autoencoders (AEs) as the deep-learning tool to process the geometry of the mesh. The study aims to uncover vulnerabilities in networks that process geometric attributes and examine the credibility and robustness of AEs. The proposed attack, called SAGA, involves perturbing a clean source mesh to reconstruct the geometry of a specific target mesh. The attack is conducted in a white-box setting where access to the AE is available, and a black-box setting where the adversarial examples are transferred to other unseen AEs. To address the topological constraints of the mesh, perturbations are applied in the spectral domain using low-frequency perturbations and additional mesh-related regularizations. The effectiveness of the attack is evaluated on datasets of human faces and animals using geometric and semantic metrics. The results demonstrate the ability of SAGA to craft adversarial examples that change the output geometry of an AE. This work contributes to the understanding of adversarial attacks on 3D meshes and provides insights into the vulnerabilities and limitations of AEs in processing geometric attributes.