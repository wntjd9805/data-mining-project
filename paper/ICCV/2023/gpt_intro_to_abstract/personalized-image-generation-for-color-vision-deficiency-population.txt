This paper introduces the problem of neglecting underrepresented populations, such as color-impairment populations, in image generation algorithms. It highlights the need for an inclusive image generation model that takes into account the needs of all viewers, including those with color vision deficiency (CVD). The paper also discusses the limitations of existing recoloring algorithms in addressing the specific requirements of CVD populations. To bridge these gaps, the authors propose a CVD-oriented personalized image generation framework based on an adversarial network structure. The framework aims to generate CVD-aligned images and allows for varying degrees of CVD by decoupling and controlling the color representation using a novel triple-latent structure. The authors also introduce a differential CVD simulator and propose CVD loss functions to achieve CVD-oriented generation. The proposed method evaluates the friendliness of generated images based on contrast decay, color information, and high-level perception across various types and degrees of CVD. Experimental results demonstrate that the proposed method outperforms existing image generation models and combination baselines on multiple datasets. The contributions of this paper include the proposed CVD-oriented image generation framework, the novel triple-latent structure for personalized generation, and extensive experiments demonstrating the effectiveness of the proposed method for generating CVD-friendly images for different types and severity of CVD populations.