This paper introduces the concept of avatars, which are digital representations used in virtual platforms and communities. The task is to generate a new representation that conveys a given style and content while preserving the person's identity. Avatars are typically created either by skilled artists or through automatic image generation methods. However, image-based avatars have limitations for animations and virtual environments. To overcome this, the paper proposes using parametric vector graphics to depict avatars, which allows for animations and compositing without losing quality. A weakly-supervised cross-modal alignment framework is presented to translate rich representations from portraits to parametric avatars. This framework matches latent representations from both domains, preserving facial identity and style features. The goal is to propose an approach for converting images into parametric avatar representations that accurately preserve the individual's identity. The contributions of the paper are a flexible parametric representation for facial attributes and a novel cross-modal framework that generates higher quality avatars with better preservation of identity compared to previous methods.