The amodal instance segmentation (AIS) task aims to determine the entire shape of an object, including its visible and occluded components. This task is more challenging than visible instance segmentation as it lacks information about the occluded region. The AIS task has significant implications for various industrial applications that encounter occlusion problems. However, current AIS datasets and methods rely on a single-view approach, which is ill-posed due to the presence of multiple potential candidates for the occluded object. In this paper, we propose a task called Multi-view Amodal Instance Segmentation (MAIS) that predicts amodal segmentations through multiple viewpoints. To study the MAIS task, we create a synthetic dataset called MUVA that comprises high-quality 3D models and sufficient occlusion. MUVA is the first and only multi-view AIS dataset currently available and provides precise annotations in the occluded region. We also introduce a novel method called MASFormer that effectively utilizes multi-view information for amodal instance segmentation. Our experiments show that MASFormer outperforms existing single-view methods and accurately predicts severely occluded objects. The contributions of this paper include the proposal of the MAIS task, the creation of the MUVA dataset, and the introduction of the MASFormer method for solving the ill-posed problem in the AIS task.