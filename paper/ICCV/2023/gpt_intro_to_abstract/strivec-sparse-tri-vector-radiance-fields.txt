Representing 3D scenes as radiance fields has become a popular choice in 3D vision and graphics applications for achieving photo-realistic rendering quality. While many methods use MLPs to represent neural fields, recent works have demonstrated the advantages of using shared global feature encoding for radiance field modeling in terms of speed, compactness, and quality. However, these methods assume uniform feature assignment throughout the scene, which can be inefficient for accurately modeling intricate local scene details. In this paper, we propose Strivec, a novel neural scene representation that utilizes sparsely distributed and factorized local tensor grids to model a volumetric radiance field. Unlike previous methods, our approach accurately captures complex scene structures and local details with fewer model parameters. We build upon the TensoRF approach, which leverages tensor factorization techniques for radiance field modeling. However, instead of using a single global tensor, we distribute multiple small local tensors around the scene surface to exploit local spatial commonalities. Our local tensors, compactly modeled with factorized triple vectors, lead to superior rendering quality and compactness compared to TensoRF's global tensor model. By adopting local tensors, we can allocate neural features according to the actual scene distribution, enabling more efficient scene modeling and better usage of model parameters. We pre-acquire coarse scene geometry to distribute local tensors around the actual scene surface, resulting in a sparse representation that avoids modeling the empty scene space. Our model correlates a group of local features inside a local box and expresses them with triple vectors, leveraging local spatial coherence and imposing local low-rank priors via tensor factorization. We also distribute multi-scale local tensors to effectively model scene geometry and appearance at multiple scales in a hierarchical manner. Our approach combines the advantages of both local and global radiance field representations, outperforming previous methods in terms of rendering quality while using significantly fewer model parameters. Experimental results on synthetic and real datasets demonstrate the superior representational power of our model.