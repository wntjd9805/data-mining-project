High dynamic range (HDR) imaging is a technique that records data with a wide range of intensity levels to capture more scene information in digital photos. However, current methods for obtaining HDR data face challenges in reconstructing extremely dark and bright regions. This paper proposes a specialized reconstruction model and high-quality dataset to address this limitation. By leveraging unprocessed Raw sensor data, which has higher bit-depth and better intensity tolerance, the proposed model aims to recover details in hard regions. Additionally, an exposure mask is learned to adaptively separate over- and under-exposed regions in the scene, and a deep neural network is designed to exploit the information in these hard regions. Experimental results demonstrate the quality of the proposed methods, and a high-quality paired Raw/HDR dataset is collected for training and evaluation. The contributions of this work include addressing the challenge of recovering dark and bright regions in HDR imaging, proposing a deep network with dual intensity guidance and global spatial guidance, and directly reconstructing HDR from a single Raw image. The proposed methods have the potential to be integrated into modern camera processing pipelines.