Despite the impressive performance of large deep learning networks in various tasks, the training and deployment of such models remain expensive due to the lack of parameter efficiency. Sparse Mixture of Experts (MoE) is a technique that aims to divide and conquer model parameters based on their optimal responses to specific inputs, leading to reduced inference costs. In this paper, we focus on sparse MoE for convolutional neural networks (CNNs) and investigate its impact on adversarial robustness, which refers to the ability of a model to withstand adversarial attacks. While adversarial training (AT) has been extensively studied for CNNs, it is unclear how the improved inference efficiency of sparse MoE affects adversarial robustness and whether alternative AT mechanisms are needed. Our main research question is: What are the insights and suitable AT mechanisms for adversarial robustness in sparse MoE-integrated CNNs? To address this question, we propose a new adversarial training framework called ADVMOE for MoE-CNN. We dissect the robustness of sparse MoE into routers' robustness and experts' robustness and use this insight to improve overall robustness. We conduct extensive experiments on four CNN architectures and four datasets, demonstrating the effectiveness of ADVMOE in improving adversarial robustness without sacrificing inference efficiency. Our results show significant improvements in both robustness and inference overhead reduction compared to traditional AT.