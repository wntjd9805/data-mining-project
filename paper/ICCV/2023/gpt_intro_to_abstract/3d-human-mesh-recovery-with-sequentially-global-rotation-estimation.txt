3D human mesh recovery from monocular RGB images is a crucial task with applications in various domains such as human-object interaction, action recognition, and virtual/augmented reality. Parametric human body models have simplified this task by generating realistic 3D human body meshes using shape parameters and joint rotations. Existing model-based methods for 3D human mesh recovery can be categorized into optimization-based approaches and regression-based approaches. Optimization-based approaches iteratively estimate body pose and shape parameters by minimizing the error between the model's 2D projection and 2D evidence, while regression-based approaches directly regress model parameters using neural networks. However, existing regression-based methods regress the relative rotation matrix for each joint with respect to their parent joints, which can lead to error accumulation. To address this issue, the proposed SGRE (Spatial Global Rotation Estimation) presents a direct rotation prediction pipeline. SGRE is a general approach that can be integrated into existing regression-based methods by replacing their relative rotation estimation branches. Experimental results show that integrating SGRE with baseline regression models and 3DCrowdNet improves both 3D and 2D human pose and shape estimation performance on various benchmarks. Compared to previous methods, SGRE effectively alleviates the error accumulation issue and produces better results. SGRE is a promising method for improving 3D human mesh recovery and can be applied to enhance the performance of recent regression-based methods.