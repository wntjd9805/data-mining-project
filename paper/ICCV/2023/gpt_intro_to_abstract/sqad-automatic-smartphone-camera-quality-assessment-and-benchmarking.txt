The quality of images in computer vision algorithms plays a crucial role in understanding the natural world. Quantifying and estimating perceived image quality by human viewers is important, and three main categories of objective assessment methods are used: no-reference, reduced-reference, and full-reference. No-reference methods, which estimate image quality without requiring undistorted counterparts, are more convenient in realistic scenarios. Common quality metrics include image statistical differences and learning-based approaches. However, gaps still exist between perceivable image quality and predicted quantitative results. New algorithms inspired by GANs and perceptual-oriented optimization are being proposed to further reduce this gap. Another direction in assessing image quality is considering the device used to capture the images, which requires the recorded imagery, corresponding camera devices, and photometric settings. Optical patterns are widely applied to make measurements more objective and meaningful. Various methods have been proposed for image quality assessment, but they often have limitations and are not comprehensive. To address these limitations, the authors propose the Smartphone Camera Sensor Quality Assessment Dataset (SQAD), which combines device-based lab measurement approaches with Deep Learning to accurately quantify smartphone camera quality. The dataset covers critical quality factors such as resolution, color accuracy, noise level, dynamic range, aliasing, and Point Spread Function (PSF). The evaluations are conducted in real-world conditions, reflecting practical scenarios where access to individual camera components is limited. The authors also introduce the task of automatically assessing smartphone camera quality, eliminating the need for manual measurements.