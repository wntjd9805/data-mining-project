Semantic segmentation is a computer vision task that classifies each pixel in an image into specific visual classes. While closed-set segmentation models have been successful on benchmark datasets, real-world applications often require the ability to handle open-world scenarios, where the models may mistakenly identify out-of-distribution objects as in-distribution classes. This can be particularly problematic in critical applications like autonomous driving. To address this risk, pixel-wise out-of-distribution (OoD) detection methods have been developed to work alongside closed-set segmentation models and produce an OoD map. However, existing approaches tend to produce low uncertainty for difficult OoD pixels that share similarities with in-distribution objects, leading to unsatisfactory performance in complex scenes. In contrast, state-of-the-art OoD pixel detectors re-train the segmentation models with OoD data, but this can negatively impact the in-distribution segmentation accuracy. Additionally, these methods often lack context reliability, as they do not consider the relationships between OoD pixels and their surrounding context. To address these issues, we propose a new pixel-wise OoD detection module called Residual Pattern Learning (RPL), which learns the residual pattern of anomalies and induces the segmentation model to produce high uncertainty for potentially anomalous regions. We also introduce a novel positive energy loss function and context-robust contrastive learning to improve the detection accuracy and context robustness of OoD pixels. Our approach achieves the highest accuracy and stability in various scene contexts compared to state-of-the-art methods on multiple datasets.