The ability to establish correspondences in temporal inputs is a fundamental aspect of the human visual system and is crucial for object perception. Computer vision research has also focused on establishing correspondences from image sequences, known as optical flow, dating back to the inception of the field. Keypoints have emerged as a preferred representation in various vision tasks such as recognition, pose estimation, reconstruction, and robotic manipulation. However, existing methods have limitations in identifying temporally consistent keypoints, particularly for movable or deformable objects. In this paper, we propose a novel 3D Implicit Transporter that extracts temporally consistent keypoints and reconstructs the underlying shape of objects from point cloud inputs. We introduce three core components: hybrid 3D representation architectures, cross-attention for keypoint discovery, and an implicit geometry decoder. Our method achieves improved perception performance in terms of spatiotemporal consistency of keypoints compared to state-of-the-art methods. Additionally, we explore the use of our self-supervised mid-level representation in articulated object manipulation and demonstrate its advantages over existing object-agnostic methods. Our contributions include the formulation of the 3D Implicit Transporter, the development of a closed-loop manipulation strategy, and the achievement of state-of-the-art results in perception and manipulation tasks.