Reconstructing a 3D scene from multi-view images is a crucial problem in computer vision with applications in animation, gaming, and VR/AR. Current methods use implicit neural network representations, but struggle with poor surface reconstructions and ambiguous visual cues. This paper aims to bridge these gaps by proposing an improved feature rendering scheme and a hybrid representation that combines signed distance functions (SDF) with occupancy. Experimental results show that the proposed approach produces higher-fidelity representations, especially in small and dark objects.