The development of deep neural networks (DNNs) requires a large amount of accurately labeled data, but collecting such data is time-consuming and laborious. Partial-label learning (PLL) has emerged as a solution, allowing non-expert annotators to assign a candidate label set. However, existing PLL methods assume that candidate labels are instance-independent (II), which is unrealistic in real-world scenarios. In this paper, we focus on instance-dependent (ID) PLL and conduct an empirical study on label disambiguation (LD) dynamics in II-PLL and ID-PLL. We observe that ID-PLL suffers from a high proportion of under-disambiguated (UD) examples, leading to performance degradation. To address this challenge, we propose a two-stage PLL framework that selectively disambiguates well-labeled examples and dynamically determines thresholds for WD and UD examples. Our extensive experiments demonstrate the superiority and effectiveness of our proposed framework in both II-PLL and ID-PLL.