Abstract:The proliferation of computing devices has led to an abundance of proprietary user data, raising concerns about data privacy. Federated learning (FL) addresses this challenge by enabling machine learning on decentralized devices without exchanging locally stored data. However, FL frameworks are vulnerable to poisoning attacks, where malicious clients submit fraudulent model updates. Existing defense strategies are ineffective in non-IID data settings, where data distributions vary among clients. This paper presents FedCPA, an attack-tolerant aggregation method for FL under non-IID data settings. FedCPA assesses the importance of model parameters in each client's update and proposes a defense strategy to measure model similarity beyond Euclidean-based similarity. FedCPA consists of two steps: computing the normality score of each client's model and aggregating local updates via a weighted average to remove likely-malicious updates. Evaluation results demonstrate that FedCPA outperforms existing methods in protecting against both untargeted and targeted attacks. This proposed model provides a more robust and attack-tolerant decentralized computing framework for federated learning.