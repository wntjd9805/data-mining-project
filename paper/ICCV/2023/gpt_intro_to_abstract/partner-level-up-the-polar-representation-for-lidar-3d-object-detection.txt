3D object detection is crucial for autonomous driving and relies heavily on accurate localization provided by LiDAR sensors. However, LiDAR point clouds have their own unique characteristics, including being unordered, unstructured, and sparse. As a result, effective representation methods are needed for 3D object detection algorithms to perform well in real-world scenarios.Previous studies have explored different representations for point clouds. Point-based approaches process raw points directly using methods like PointNet, but they can be time-consuming. Range-based methods represent LiDAR points in a 2.5D manifold structure, offering compactness and faster neighbor queries. However, their performance lags behind other representations. Grid-based methods transform irregular point clouds into 2D pillars or 3D voxels and generate 3D boxes in bird's-eye-view. These methods have dominated the 3D detection benchmark but face challenges due to non-uniform density distribution and misalignment of global feature maps.To address these issues, we propose PARTNER (PolAr RepresenTatioN detEctoR), a novel LiDAR-based 3D object detector that learns effective representation in polar coordinates. PARTNER consists of two key components: a global representation re-alignment module and a geometry-aware adaptive module. The global representation re-alignment module employs an attention mechanism to re-align features between objects, while the geometry-aware adaptive module introduces geometric and instance information for more accurate box prediction. By leveraging these designs, our polar 3D detector outperforms Cartesian-based methods.In summary, our contributions include: (i) the exploration of the feature distortion problem in polar representation and the development of PARTNER, a LiDAR-based 3D object detector in the polar coordinate system, (ii) the introduction of two polar-tailored designs to address feature distortion and improve box prediction accuracy, and (iii) extensive validation on the Waymo and ONCE datasets, demonstrating the competitiveness of our approach and its advantages in streaming and low-resolution scenarios.