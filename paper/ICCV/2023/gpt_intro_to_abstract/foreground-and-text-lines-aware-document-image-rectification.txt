This paper addresses the problem of distortions in document images and the challenges they pose for information extraction and document intelligence. Previous methods for rectification relied on traditional techniques such as regression and boundary segmentation, while some newer methods utilized deep learning techniques like Convolutional Neural Networks (CNN) and Transformers. However, these methods have limitations in capturing long-distance dependencies and effectively focusing on text-line areas. To address these limitations, the authors propose a novel distortion image rectification model based on a cross-attention mechanism that combines features from the foreground and text-line regions. By incorporating both global and local information, the proposed model reduces background interference and improves the readability of document images. Extensive experiments demonstrate the effectiveness of the proposed model in achieving state-of-the-art results on existing benchmarks.