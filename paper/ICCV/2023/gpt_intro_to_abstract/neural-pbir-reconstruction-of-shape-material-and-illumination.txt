Reconstructing geometry, material reflectance, and lighting from images, also known as inverse rendering, is a challenging task in computer vision and graphics. Traditionally, the acquisition of these intrinsic components has been studied independently. Recent advancements have enabled joint reconstruction of shape, material, and lighting from 2D images of an object. These techniques can be classified into two categories: neural reconstruction methods and physics-based inverse rendering (PBIR). Neural reconstruction methods use multi-layer perceptrons (MLPs) to encode the appearance of objects and optimize the network using volume ray tracing. PBIR, on the other hand, optimizes shape, material, and lighting by computing unbiased gradients of image appearance. However, both methods have limitations, such as high computational cost and overfitting. In this paper, we propose a highly efficient and accurate inverse rendering pipeline that combines the advantages of both neural reconstruction and PBIR methods. Our pipeline consists of three stages: hybrid neural volume-based reconstruction for geometry, an efficient optimization method for material and lighting estimation, and an advanced PBIR framework for joint refinement of geometry, materials, and lighting. Our contributions include a hybrid volume representation for fast and accurate geometry reconstruction, an efficient optimization scheme for initial material and lighting estimation, an advanced PBIR framework, and a complete pipeline for state-of-the-art geometry, material, and lighting estimation.