Distance metric learning (DML) aims to find an embedding function that places semantically similar samples close together while keeping dissimilar samples further apart in Euclidean space. Convolutional neural networks (CNNs) followed by global pooling layers, often global average pooling (GAP), are commonly used in DML methods. However, it is unclear why averaging over all features is the best choice, and whether some classes should be given more importance. In this paper, we propose a learnable and generalized version of GAP that determines which semantic entities to use and assigns weights for averaging. We redefine GAP as an optimization problem with the ability to choose a subset of features and regularize it to avoid degenerate solutions. We show that the original GAP is a specific case of our proposed optimization problem. Additionally, we introduce a zero-shot prediction loss to handle unseen classes. Through synthetic experiments, we demonstrate that our pooling method selects better feature subsets and improves generalization. Our method can be applied with any DML loss, and we observe consistent improvements compared to direct application of GAP and other pooling alternatives on different datasets.