Depth recovery from sparse depth maps is crucial for various computer vision applications. Accurate depth maps provide necessary 3D information for tasks such as scene reconstruction and autonomous driving. While high-quality texture information is easily captured, acquiring reliable depth information remains a challenge. Traditional model-based methods and data-driven methods have been explored for estimating missing depth information in sparse depth maps. Deep learning models, particularly convolutional neural networks (CNNs), have shown promise in depth recovery tasks. However, they often overlook the specific characteristics of depth images. Conversely, model-driven approaches heavily rely on manual parameter design, which may not guarantee optimal solutions. In this paper, we propose a deep unfolding model that combines traditional mathematical models with CNNs to learn more generalized prior information about depth images. We introduce a non-local auto-regressive regularization term to enhance global understanding, leveraging similarities among depth patches. We derive an alternate optimization algorithm and unfold it into a deep network. Experimental results on NYU-Depth V2 and SUN RGB-D datasets demonstrate the effectiveness and availability of our method for depth recovery tasks, achieving comparable performance with deep learning-based methods.