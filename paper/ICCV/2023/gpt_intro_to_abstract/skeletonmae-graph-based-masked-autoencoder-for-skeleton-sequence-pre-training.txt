Human action recognition is a significant research area in video understanding due to its wide applications in computer interaction, intelligent surveillance security, and virtual reality. Skeleton sequences, which contain only the coordinate information of key joints of the human body, have emerged as a suitable representation for action recognition tasks. The development of human pose estimation algorithms has made it feasible to obtain accurate skeleton sequences, and the high-level and lightweight nature of skeletons make them robust against complex backgrounds and various conditions. However, most existing skeleton-based action recognition methods require large amounts of labeled data for training elaborate models, which is time-consuming and labor-intensive. To address this limitation, self-supervised skeleton-based action recognition methods have gained attention in recent years. However, these methods often overlook the fine-grained dependencies among different skeleton joints, restricting their generalization capability. In this paper, we propose a novel self-supervised learning framework, called Skeleton Sequence Learning (SSL), that incorporates a graph-based encoder-decoder pre-training architecture named SkeletonMAE. SkeletonMAE uses prior human topology knowledge to reconstruct masked skeleton joints and edges, enabling a comprehensive perception of the joints, topology, and action. To capture comprehensive spatial-temporal dependencies, the pre-trained SkeletonMAE encoder is integrated with the Spatial-Temporal Representation Learning (STRL) module. Experimental results on multiple datasets demonstrate that SSL outperforms state-of-the-art self-supervised and fully supervised methods, indicating its effectiveness in skeleton-based action recognition.