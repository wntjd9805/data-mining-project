Sign languages are visual-spatial signals used by deaf communities for communication. Sign language recognition can be divided into isolated sign language recognition (ISLR), which recognizes and classifies isolated signs, and continuous sign language recognition (CSLR), which recognizes continuous signs without prior knowledge of sign boundaries. However, the lack of large-scale training data has hindered the progress of CSLR. This paper aims to develop a CSLR framework using an ISLR model and a multilingual corpus. The authors propose using cross-lingual signs, which have similar visual signals but may convey different meanings in different sign languages, as auxiliary training data. They present a three-step solution that involves building sign language dictionaries, identifying the cross-lingual mappings, and training the CSLR model. The authors emphasize the significance of using multilingual sign language corpora to enrich training data and discuss the contributions of their work in improving CSLR performance.