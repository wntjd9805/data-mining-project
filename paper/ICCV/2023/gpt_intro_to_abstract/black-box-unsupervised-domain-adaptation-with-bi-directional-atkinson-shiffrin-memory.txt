Unsupervised domain adaptation (UDA) methods have been extensively studied in recent years to address limitations in data collection and annotation for deep network training. However, existing UDA methods can compromise data privacy and lack flexibility in selecting different target networks. This paper introduces a bi-directional memory mechanism called BiMem to address these issues in black-box UDA. BiMem helps calibrate noisy pseudo labels on the fly, leading to more stable and accurate black-box UDA. Experimental results demonstrate the effectiveness of BiMem across various computer vision tasks, including image classification, semantic segmentation, and object detection. This work contributes a general framework for black-box UDA and advances the understanding of the role of memory in UDA tasks.