The ability to track objects in 3D space plays a crucial role in robotics, autonomous driving, and surveillance systems. 3D single object tracking (SOT) aims to estimate the pose and position of a tracked target in each frame. Previous approaches heavily rely on RGB information, which struggles with changing lighting conditions. Recent research has focused on using point clouds for 3D object tracking due to their accurate spatial information and robustness to illumination changes. However, existing methods for 3D SOT have limitations in capturing rich temporal information and considering contextual information. Additionally, the size and geometry variations among different tracked targets pose challenges for accurate localization. To address these issues, this paper proposes MBPTrack, a memory-based network for 3D SOT. MBPTrack leverages a memory mechanism to incorporate spatial and temporal contextual information from historical frames and utilizes bounding box priors to handle size differences among tracked targets. A transformer-based module is designed to propagate information from the memory to the current frame, effectively capturing geometric features and targetness features. MBPTrack also introduces BPLocNet, a coarse-to-fine localization network that considers size information using a bounding box prior. Experimental results demonstrate that MBPTrack outperforms existing methods on benchmark datasets and improves tracking accuracy when integrated into existing frameworks. Overall, this paper contributes to the exploration of spatial and temporal contextual information in 3D SOT and introduces a localization network that addresses size variations for more accurate tracking.