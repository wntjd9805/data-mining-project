The success of Graph Neural Networks (GNNs) has led to a surge in graph-based representation learning. GNNs provide an efficient framework for learning from graph-structured data and have been effectively applied in various tasks. However, a fundamental limitation of GNNs is the assumption that the underlying graph is provided, which may not be optimal for certain tasks. One common practice is to generate a k-nearest neighbor (k-NN) graph, but fixing k is overly restrictive. To address this, we propose a differentiable graph-generator (DGG) module that learns graph topology with an adaptive neighborhood size. This module can be integrated into any graph convolutional network and is jointly optimized with the rest of the network's parameters. Our contributions include the ability to learn neighborhood sizes, the integrability of the DGG module into existing pipelines, and improvements in model accuracy across different datasets and tasks.