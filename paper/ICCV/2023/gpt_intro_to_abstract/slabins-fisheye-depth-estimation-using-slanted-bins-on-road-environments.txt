With the rise of autonomous driving, the need for accurate 3D perception has become increasingly important for safety. While existing advanced driver-assistance systems (ADAS) rely on various sensor modalities for 3D perception, they primarily focus on the frontal view. However, statistics show that a significant number of fatal car accidents occur due to T-bone crashes, emphasizing the importance of side-view 3D perception. To address this, fisheye cameras have gained attention for their ability to provide a wider field of view (FoV) and cost-effectiveness. However, monocular fisheye camera-based side-view depth estimation is challenging due to severe distortion. In this paper, we propose a novel fisheye depth estimation framework called SlaBins that leverages the geometric property of road environments. Through the use of a slanted multi-cylindrical image (MCI) representation, we estimate adaptive bins and the per-pixel probability of slanted cylindrical layers, preserving the geometric property of the road environments and improving depth quality near object boundaries. Additionally, we independently estimate the slanted angle of the camera's viewing direction, which, when combined with the estimated depth information in the slanted MCI domain, allows us to compute a dense and accurate depth map for fisheye cameras. Experimental results on the SynWoodScape dataset and a modified KITTI-360 depth dataset demonstrate the superiority of SlaBins compared to baseline methods and its potential for downstream tasks. Our contributions include the introduction of the SlaBins framework, the slanted MCI representation, and a slanted-aware regression method for fisheye depth estimation.