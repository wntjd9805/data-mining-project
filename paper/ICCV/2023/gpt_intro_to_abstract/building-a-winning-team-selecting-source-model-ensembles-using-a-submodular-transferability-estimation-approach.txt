In computer vision, transfer learning is widely used to train Deep Neural Networks (DNNs) on new domains and datasets. This is achieved by fine-tuning pre-trained models, which leads to faster convergence and better performance compared to training from scratch. However, the selection of the optimal combination of dataset and architecture for fine-tuning remains a challenge. Transferability estimation (TE) metrics have been proposed to address this problem, but most existing methods only consider a single source model, limiting their use in ensemble learning settings. In this paper, we introduce a novel TE metric called OSBORN, specifically designed for ensemble selection. OSBORN incorporates measures of the latent space mismatch between the source and target datasets, as well as the interaction between models in the ensemble. We demonstrate the effectiveness of OSBORN through extensive experiments on various tasks and model architectures. Our metric outperforms existing methods in terms of correlation coefficients. Overall, our contributions include the introduction of OSBORN, its application as a submodular set function, and its evaluation in different scenarios.