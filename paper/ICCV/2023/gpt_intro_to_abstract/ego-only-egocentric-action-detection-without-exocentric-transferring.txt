This paper addresses the problem of action detection from egocentric videos captured by head-mounted devices. While action detection in third-person videos has been extensively researched in the computer vision community, the formulation of this task in the first-person setting is underexplored. One major challenge is the lack of data, making it difficult to train large-capacity models to achieve competitive results. Existing methods have attempted to train egocentric models using only egocentric data, but have failed to obtain satisfactory results. Therefore, current egocentric action detection methods rely on large-scale third-person videos or images, assuming that pretraining with proper transferring techniques can mitigate the domain gap between egocentric and exocentric videos. However, the dramatically different viewpoint of first-person videos poses unique challenges that cannot be addressed solely by scaling exocentric data or improving transferring techniques. This paper argues for training with in-domain egocentric data only, leveraging recent data-efficient training methods and the availability of extensive egocentric datasets. The proposed Ego-Only approach consists of three stages: (1) masked autoencoder pretraining on egocentric data, (2) temporal semantic segmentation finetuning, and (3) action detection using an off-the-shelf temporal action detector. Empirical evaluation on three large-scale egocentric datasets shows that Ego-Only outperforms previous results based on exocentric transferring, setting new state-of-the-art performance without additional data. The paper also identifies critical factors for the effectiveness of the Ego-Only approach and highlights the importance of in-domain pretraining and long-term modeling. Overall, this paper contributes the first Ego-Only method for effective egocentric action representation learning, advances state-of-the-art results on both action detection and action recognition, and provides insights into the key factors influencing the effectiveness of the Ego-Only approach.