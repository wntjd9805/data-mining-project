Mirrors play a significant role in our daily lives, but their inconsistent appearance makes it challenging to separate them from their surroundings, affecting various computer vision tasks. Existing mirror detection methods rely on costly supervised ImageNet pre-training, which may lead to failures in detecting mirrors that reflect real objects. We question the necessity of this pre-training approach for mirror detection, as it involves expensive labeling costs and causes feature redundancy. We observe that humans recognize mirrors implicitly, suggesting the suitability of self-supervised learning (SSL). Inspired by this, we propose a new SSL pre-training framework specifically for mirror detection, considering mirror reflection in the pre-training process. Our framework consists of three stages: image-level, patch-level, and pixel-level pre-training, progressively learning the representation of mirror reflection. Through comprehensive experiments, we demonstrate the effectiveness of our SSL pre-training framework, which significantly improves the performances of existing mirror detection methods. Furthermore, our framework outperforms other CNN-based SSL pre-training frameworks on the mirror detection task. This paper contributes by investigating SSL pre-training frameworks for mirror detection, proposing a new SSL pre-training framework, and showcasing its superiority over supervised ImageNet pre-training and other SSL methods.