Template learning is important for shape analysis in computer science, as it allows for the establishment of dense correspondence and the transfer of key attributes between shapes. Traditional methods have used handcrafted templates, but defining templates for complex shapes with high structural variability is challenging. Recent works have focused on learning implicit templates based on neural fields, which have shown superior performance in dense correspondence between complex shapes. However, current approaches often learn suboptimal deformation, especially for shape categories with high structural variability. In this paper, we propose a novel framework to learn semantically plausible deformation by incorporating part semantics and employing self-supervised feature extraction. We introduce semantic-aware deformation code, which assigns part deformation priors based on the semantics of each point, and we design regularization techniques to encourage part-level distances to be close. We also propose a global scale consistency regularization to preserve the volume of the template. Our framework is validated through experiments on keypoint transfer, part label transfer, and texture transfer, demonstrating competitive performance over baselines. Our contributions include the proposal of a new framework for global implicit template learning, the imposition of hybrid conditioning for flexible deformation, the design of novel regularizations, and the demonstration of the effectiveness through qualitative and quantitative experiments.