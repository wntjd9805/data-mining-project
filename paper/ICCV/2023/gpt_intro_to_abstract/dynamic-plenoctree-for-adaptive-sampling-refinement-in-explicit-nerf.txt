Rendering photo-realistic scenes and objects is crucial for providing users with an immersive and interactive experience in virtual reality and metaverse. The Neural Radiance Field (NeRF) has emerged as a promising solution for modeling 3D scenes and objects using calibrated multi-view images. However, subsequent approaches have been proposed to enhance NeRF's rendering power in terms of training time, inference speed, and quality. PlenOctree (POT) is one such approach that employs an explicit octree structure with spherical basis functions to accelerate and enhance rendering quality. While POT achieves high-quality rendering at high frame rates, its fixed octree structure limits its adaptability to varying scene complexities. This paper introduces a hierarchical feature fusion approach to overcome this limitation. By dynamically sampling and pruning the octree, the proposed method achieves more efficient sampling distribution and improved rendering quality. Additionally, the paper addresses the challenge of striking a balance between compactness and expressiveness in NeRF representation. The proposed approach combines the benefits of importance sampling and rejection methods, allowing for adaptive refinement of the octree and selective sampling of promising regions. Extensive experiments demonstrate that the proposed approach, called Dynamic Octree (DOT), outperforms POT in terms of rendering quality, parameter efficiency, and rendering speed. Furthermore, DOT offers more control over sampling and pruning strength, enhancing flexibility when working with scenes of varying complexity. Overall, this paper contributes an improved octree design, a hierarchical feature fusion strategy, and demonstrates the effectiveness of DOT in slimming down POT, accelerating rendering speed, and improving rendering quality.