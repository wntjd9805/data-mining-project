Video-based 6-DoF object tracking plays a crucial role in various applications such as augmented reality, robotic manipulation, and human-computer interaction. Existing methods for 6-DoF object tracking rely on keypoints, edges, or region-based features, each with its limitations and challenges. In this paper, we propose a novel learning-based active contour model called DeepAC for real-time 6-DoF object tracking. DeepAC combines the advantages of optimization-based and learning-based methods, achieving both robustness and real-time performance. Inspired by the region-based approach RBGT, DeepAC utilizes a network to estimate the directions to update the contours based on the local regions around the contours. The proposed method employs a three-phase pipeline, involving feature extraction, boundary prediction, and pose optimization, all of which are trainable end-to-end with pose supervision. Our experiments on semi-synthetic and real-world datasets demonstrate that DeepAC outperforms other baseline methods in terms of tracking accuracy. Additionally, we showcase the real-time performance of DeepAC on a mobile device. Our contributions include the development of a novel learning-based active contour model, a lightweight network for contour evolution, and an efficient optimization algorithm for end-to-end training with pose supervision.