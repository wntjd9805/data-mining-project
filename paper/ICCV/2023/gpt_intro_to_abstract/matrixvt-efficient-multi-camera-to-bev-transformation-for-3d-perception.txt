This paper introduces the concept of Vision-centric 3D perception in Bird's-Eye-View (BEV) and its application in various downstream tasks in the field of autonomous driving technology. The View Transformation (VT) component, which converts multi-camera features to BEV, is explored, and existing VT methods are categorized into geometry-based and learning-based methods. Lift-Splat, a representative geometry-based VT method, is discussed for its ability to produce high-quality BEV features. However, two issues with Lift-Splat are identified: the inefficiency of the "splat" operation and the large size of the lifted multi-view image features. In response, the authors propose a novel VT method called MatrixVT that addresses these issues. MatrixVT is based on the concept of feature transportation and utilizes a Feature Transporting Matrix (FTM) to transform features to BEV. To reduce sparsity and improve efficiency, the authors introduce Prime Extraction and the Ring & Ray Decomposition techniques. Experimental results demonstrate that MatrixVT is faster and more memory-efficient than existing methods while achieving comparable performance in object detection and map segmentation tasks. The main contributions of this work include the proposal of a new description of multi-camera to BEV transformation, the introduction of Prime Extraction and the Ring & Ray Decomposition techniques, and the demonstration of the efficiency and generality of MatrixVT.