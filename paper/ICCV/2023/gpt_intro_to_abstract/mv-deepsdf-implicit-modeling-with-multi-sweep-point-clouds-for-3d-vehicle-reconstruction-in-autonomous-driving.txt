3D vehicle reconstruction from sparse and partial point clouds is crucial for autonomous driving. Existing methods mainly focus on image-based inputs, dense point cloud inputs, or their combination, and cannot be directly applied to this problem. Implicit modeling has shown promising results in addressing this issue by mapping 3D shapes to a low-dimensional latent space. However, previous point cloud-based implicit modeling methods fail to leverage the multi-sweep information of vehicles. In this paper, we propose a novel framework called MV-DeepSDF that exploits multi-sweep point clouds to generate high-fidelity 3D reconstructions of vehicles. We analyze multi-sweep consistency and complementarity in the latent feature space and transform the problem into an element-to-set feature extraction problem. We devise a new architecture to extract global features and latent codes from multi-sweep point clouds, and generate a set-level predicted latent code. This latent code is then decoded to a continuous signed distance function (SDF) and used to recover the 3D mesh of the vehicle. We evaluate the performance of our approach on real-world datasets and demonstrate its superiority over existing methods.