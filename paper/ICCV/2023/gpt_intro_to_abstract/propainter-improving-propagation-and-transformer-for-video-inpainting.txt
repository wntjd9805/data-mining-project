Video inpainting aims to fill missing regions in a video with visually consistent content. It has various applications such as video completion, object removal, and video restoration. Existing techniques for video inpainting include flow-guided propagation and video Transformer. However, these methods have limitations such as inaccurate flow and restricted propagation range. In this study, we propose dual-domain propagation, combining image and feature-based propagation, to overcome these limitations. We introduce efficient GPU-based propagation, improved feature propagation, and efficient flow completion techniques. Additionally, we present an efficient mask-guided sparse video Transformer for the inpainting task. Our approach achieves superior performance compared to state-of-the-art methods in terms of PSNR while reducing memory consumption.