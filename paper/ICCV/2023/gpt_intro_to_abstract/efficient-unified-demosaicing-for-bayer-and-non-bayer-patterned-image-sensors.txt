Demosaicing is the process of converting single-channel input images into RGB output images in an embedded Image Signal Processor (ISP). As the demand for high-quality mobile camera images increases, CMOS image sensor (CIS) resolution has dramatically increased. However, decreasing pixel sizes in smaller CISs make them more susceptible to noise and degradation, especially in low-light conditions. To address this, modern smartphones use non-Bayer Quad, Nona, and Quad-by-Quad (QÃ—Q) sensors. Demosaicing for non-Bayer CFAs is more complex and computationally demanding than for standard Bayer CFAs. Deep learning methods have been explored for demosaicing, but they mainly focus on a single CFA pattern and do not cover multiple pattern tasks. Mobile phones with non-Bayer patterned CIS adapt their CFA modes dynamically based on lighting conditions, which poses challenges for traditional independent models. Currently, there is no unified model that can handle dynamically changing CFA modes in a non-Bayer patterned CIS. To address this, we propose a Knowledge Learning-based demosaicing model for Adaptive Patterns using Meta-test learning (KLAP-M) that can handle unknown artifacts and missing ground truth. Our approach bridges the gap between synthetic and real CIS RAW images, enabling the simultaneous demosaicing of multiple CFAs. KLAP-M incorporates meta-test learning and self-supervised learning techniques to handle domain gaps and achieve state-of-the-art performance on both synthetic and real CIS RAW samples.