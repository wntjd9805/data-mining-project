Few-shot semantic segmentation methods aim to address the challenge of sparse annotated data, which often hinders traditional semantic segmentation methods. These methods leverage the advantages of few-shot learning to quickly adapt to unseen domains with only a few labeled samples. Most few-shot semantic segmentation methods are built on episode-based meta-learning, where each episode consists of a support set and a query set. The support set contains a few support images with pixel-wise annotations, and the models learn a generic meta-learner using abundant episodic data from base classes. However, current few-shot semantic segmentation methods have limitations in requiring specific novel class annotations corresponding to query images during inference and only being able to segment specific novel classes. Generalized Few-shot Semantic Segmentation (GFSS) was proposed to overcome these limitations by registering novel classes to the base model before inference, enabling simultaneous segmentation of base and novel classes without additional information. However, GFSS still faces challenges related to representation division between base-class and novel-class blocks as well as feature embedding prejudice. In this work, we propose a joint prototypical kernel learning and open-set foreground perception approach to address these challenges. We introduce a base-class kernel update schema to supervise the update of base-class kernels using pixel-assembled features, which allows them to have prototypical representation abilities. We also leverage open-set foreground perception to mitigate feature embedding prejudice and propose a conditional bias based inference for ensemble prediction. Additionally, we expand our method to class incremental few-shot segmentation, which registers novel classes with an incremental stream. Experimental results on GFSS and CIFSS datasets demonstrate that our proposed method achieves higher performance compared to other approaches.