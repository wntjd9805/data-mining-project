This paper addresses the problem of video stabilization in the context of the growing popularity of short videos on social media platforms. While professional equipment can provide stable videos, it is expensive and impractical for everyday use. Software-based solutions, such as video stabilization algorithms, have become an attractive alternative. Existing techniques can be classified into optimization-based and learning-based. Optimization-based algorithms are fast and robust, but they struggle with occlusion and missing regions. Learning-based algorithms achieve higher visual quality but are computationally complex and lack generalization. To overcome these limitations, the authors propose an iterative optimization-based learning approach that is efficient and robust. Their approach includes a probabilistic stabilized network and a full-frame outpainting module. Instead of focusing on explicit noise in pixel intensity values, their approach aims to suppress implicitly embedded noise in video frames. They adopt an expectation-maximization approach and propose a synthetic training dataset to optimize model parameters. The paper introduces two modules: a probabilistic stabilization network for motion trajectory smoothing and a video outpainting network for full-frame video rendering. Experimental results show competitive performance on benchmark datasets. The contributions of this work are the formulation of video stabilization as a fixed-point problem, the construction of a probabilistic stabilization network with a coarse-to-fine strategy, and the proposal of a video outpainting network leveraging spatial coherence.