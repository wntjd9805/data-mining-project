Video matting is a widely studied problem in computer science and has numerous applications in video editing. The goal is to separate a video into multiple layers with associated alpha mattes, allowing for individual processing of each layer before compositing them back together. While current techniques focus on obtaining masks of the main object of interest, there is a need to include associated effects such as shadows and reflections to increase realism and reduce manual segmentation. We propose a method called OmnimatteRF that combines 2D foreground layers with a 3D background model to address this challenge. Our method is able to handle complex scenes with non-rotational camera motions and provides robust results without per-video parameter tuning. We evaluate our method using a new dataset of challenging video sequences and demonstrate its superiority over existing approaches. Our contributions include a novel approach to modeling the static background in 3D, a re-training step for clean static 3D reconstruction, and the release of a new dataset for further research in video matting with associated effects.