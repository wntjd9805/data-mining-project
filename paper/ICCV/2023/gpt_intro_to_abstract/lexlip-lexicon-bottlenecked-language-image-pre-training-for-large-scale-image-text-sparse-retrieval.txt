This paper introduces a novel sparse retrieval paradigm for image-text retrieval (ITR) and proposes a pre-training framework called Lexicon-Bottlenecked Language Image Pre-Training (LexLIP) to learn lexicon-weighting representations. The sparse retrieval paradigm leverages sparse representations in the vocabulary space and employs the Exact Lexicon Matching Search algorithm to find matching pairs, significantly reducing retrieval latency. The LexLIP framework consists of two pre-training phases: lexicon-bottlenecked masked language modeling and momentum lexicon-contrastive learning. Experimental results show that LexLIP achieves state-of-the-art performance on ITR benchmarks and outperforms existing methods in terms of retrieval speed and index storage memory. The contributions of this work include the introduction of the sparse retrieval paradigm, the proposal of the LexLIP framework, and extensive experiments on both small-scale and large-scale ITR datasets.