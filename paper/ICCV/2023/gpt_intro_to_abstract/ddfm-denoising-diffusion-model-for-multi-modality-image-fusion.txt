Image fusion is a technology that combines information from multiple source images to create high-quality fused images. It has various applications such as saliency detection, object detection, and semantic segmentation. In particular, Infrared-Visible image Fusion (IVF) and Medical Image Fusion (MIF) are challenging in Multi-Modality Image Fusion (MMIF) due to the need to model cross-modality features and preserve critical information from all sensors and modalities.Generative Adversarial Networks (GANs) have been widely used for MMIF, but they suffer from issues such as unstable training, lack of interpretability, and mode collapse. To address these challenges, we propose a Denoising Diffusion image Fusion Model (DDFM) based on Denoising Diffusion Probabilistic Models (DDPM). DDPM generates high-quality images by modeling the diffusion process of restoring a noise-corrupted image. Compared to GAN, DDPM does not require a discriminator network and has interpretable generation process.In our proposed DDFM, we formulate the MMIF task as a DDPM-based posterior sampling model, which consists of an unconditional generation module and a conditional likelihood rectification module. The sampling of fused images is achieved solely by a pre-trained DDPM. Likelihood rectification is formulated as a probability inference problem involving latent variables, which can be solved using the EM algorithm. We evaluate DDFM on IVF and MIF tasks and show that it consistently delivers favorable fusion results, preserving structure and detail information from the source images while satisfying visual fidelity requirements.