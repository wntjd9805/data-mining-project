Abstract:The task of learning visual correspondences across space and time is a fundamental problem in computer vision, with applications in 3D reconstruction, physical understanding, and dynamic object modeling. This task is challenging due to factors such as viewpoint change, distractions, and deformations, and can be approached through object-wise, group-wise, or pixel-wise correspondences. In this paper, we focus on learning fine-grained features for pixel-wise video correspondences. We explore the use of synthetic data for feature learning, but find that directly utilizing synthetic supervision as hard labels leads to inferior representations. To address this, we propose using an external pre-trained 2D encoder to derive soft supervision for optimization based on optical flow. Additionally, we incorporate self-supervised feature learning on unlabeled real data to improve generalization in real scenes. We also introduce a coarse-to-fine framework to improve efficiency in obtaining dense matching results between fine-grained features. Our method is evaluated on correspondence-based tasks and consistently outperforms state-of-the-art methods.