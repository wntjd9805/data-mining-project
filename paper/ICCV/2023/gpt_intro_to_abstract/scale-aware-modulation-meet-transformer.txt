This paper introduces the Scale-Aware Modulation Transformer (SMT), a novel architecture that improves upon the limitations of self-attention in shallow networks by integrating convolution blocks with Transformer blocks. The authors propose the use of convolutional modulation, specifically the Scale-Aware Modulation (SAM) technique, which incorporates Multi-Head Mixed Convolution (MHMC) and Scale-Aware Aggregation (SAA) modules to enhance model performance and capture multi-scale features. Additionally, the authors present the Evolutionary Hybrid Network (EHN) architecture, which combines SAM blocks and Transformer blocks in a strategic stacking strategy to better match computational characteristics and improve performance on downstream tasks. Experimental results demonstrate that SMT outperforms state-of-the-art vision Transformers and convolutional networks on classification, object detection, and segmentation tasks, while requiring fewer parameters and incurring lower computational costs. The contributions of this paper include the introduction of SAM and EHN, as well as the evaluation and validation of SMT on various benchmarks.