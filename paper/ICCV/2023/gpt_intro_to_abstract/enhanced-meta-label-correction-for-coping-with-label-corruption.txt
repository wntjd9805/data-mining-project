The success of Deep Neural Networks (DNNs) in visual classification tasks is mainly attributed to the availability of large labeled datasets. However, obtaining sufficient labeled data is often challenging in practical applications. To address this issue, various approaches have been proposed to reduce the amount of labeled data required for classification, such as semi-supervised learning, transfer learning, and self-supervised learning. However, in some cases, the quality of the labeled data can be compromised, as seen in the crawling process of search engines and online websites. Traditional learning methods struggle to handle significant label noise, making it crucial to develop learning frameworks that can cope with label corruption.While traditional methods for learning with noisy labels have limitations in handling real-world noise, obtaining small amounts of clean labeled data is often feasible. Therefore, integrating large amounts of noisy labeled data and small amounts of clean data is essential. Meta-learning, a popular approach in solving various tasks, shows promise in learning with noisy labels using auxiliary clean datasets. Examples include meta-sample weighting, meta-robustification, meta-label correction, and meta-soft label correction.In this work, we introduce EMLC, an enhanced meta-label correction approach for learning from label-corrupted data. We propose improved procedures for computing the meta-gradient used to optimize the teacher. Additionally, we design a unique teacher architecture and a novel training objective to enhance the label correction process. Our teacher architecture is independent of the student, avoiding confirmation bias. Furthermore, we propose an auxiliary adversarial training objective to further enhance the effectiveness of the teacher's label correction mechanism. Our experiments demonstrate the superiority of our teacher in purifying the training labels. Overall, our contributions include deriving efficient procedures for computing the meta-gradient, designing a unique teacher architecture with a novel training objective, and combining these components into the EMLC framework. We validate the effectiveness of EMLC on synthetic and real-world label-corrupted benchmarks.