Monocular 3D human pose estimation is a crucial task in computer science with applications in human-computer interaction, metaverse, and self-driving. This task involves estimating the 3D positions of human body joints from 2D images or videos. The process includes two steps: estimating the 2D locations of human joints using off-the-shelf 2D keypoint detectors, and mapping these 2D locations to their corresponding 3D positions. This paper focuses on the latter step, known as the 2D-to-3D lifting process, and specifically on probabilistic methods that generate multiple pose hypotheses. Existing probabilistic approaches suffer from limitations in network compatibility, inability to specify the number of hypotheses, and the averaging of pose hypotheses without considering joint differences and the prior distribution of 2D keypoints. To address these limitations, this paper introduces a diffusion-based 3D pose estimation (D3DP) method that utilizes Denoising Diffusion Probabilistic Models (DDPMs). The D3DP approach involves adding noise to the ground truth 3D poses during training and sampling pure noise during inference to generate multiple 3D pose hypotheses. The compatibility of the denoiser and the ability to customize the number of hypotheses during inference distinguish this method from previous approaches. To improve the accuracy of the final 3D prediction, this paper proposes a joint-wise reprojection-based multi-hypothesis aggregation (JPMA) method that leverages the 2D prior at the joint level. Comparisons with state-of-the-art deterministic and probabilistic approaches demonstrate the superiority of the D3DP method. The contributions of this paper include the D3DP method, the joint-wise aggregation approach, the JPMA method, and the outperformance of existing methods on 3D human pose estimation benchmarks.