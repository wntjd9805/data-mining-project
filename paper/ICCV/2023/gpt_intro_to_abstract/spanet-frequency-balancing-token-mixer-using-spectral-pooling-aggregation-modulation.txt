In recent years, Vision Transformers (ViTs) have gained significant attention in computer vision and have become a viable alternative to Convolutional Neural Networks (CNNs) in various tasks. While the success of ViTs has been primarily attributed to Multi-Head Self-Attention (MSA) for token mixing, recent studies have challenged this belief by achieving comparable results without utilizing MSAs. Some research lines have explored alternative token mixers and reported encouraging results. In this paper, we propose a novel token-mixer called spectral pooling aggregation modulation (SPAM) module, which utilizes the Discrete Fourier Transform (DFT) to balance high- and low-frequency components of visual features. We introduce SPANet, based on the MetaFormer architecture, and evaluate its performance on image classification, object detection, and segmentation tasks. Our results demonstrate that SPANet outperforms previous state-of-the-art models. Our contributions include solving the balancing problem of frequency components, introducing the SPAM module, and proposing SPANet with improved performance across multiple vision tasks.