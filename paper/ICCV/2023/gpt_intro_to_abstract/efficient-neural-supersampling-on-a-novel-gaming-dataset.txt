Real-time rendering for video games has become increasingly challenging with the demand for higher resolutions, framerates, and photorealism. To address this challenge, a solution has emerged that involves rendering at lower resolution and then using an upscaling technique to achieve the desired resolution. However, developing efficient upscaling solutions that balance speed and accuracy remains a challenge. While commercial solutions, including those based on deep learning (DL) such as Nvidia's DLSS and Intel's XeSS, as well as non-machine learning solutions like AMD's FSR, have been developed for gaming super-resolution, there has been limited research on DL-based super-resolution for gaming.The lack of standard, publicly available datasets for gaming-specific super-resolution is one reason for the limited attention given to DL-based super-resolution in gaming. Researchers and developers who want to study or improve existing methods must create their own datasets, which can be time-consuming and resource-intensive.In this paper, we contribute to the research and development of gaming super-resolution algorithms by releasing a dataset specifically designed for this purpose. We demonstrate that models trained on this dataset can compete with and outperform the quality levels achieved by commercial solutions like DLSS. Additionally, we propose an efficient gaming super-resolution architecture that leverages auxiliary modalities such as sub-pixel accurate motion vectors and depth, as well as graphics rendering features commonly used for temporal anti-aliasing. Our solution is four times more efficient than previously published work for the same level of accuracy.Overall, this work provides a new resource to measure progress in the field of gaming super-resolution and has the potential to advance the state-of-the-art in this area.