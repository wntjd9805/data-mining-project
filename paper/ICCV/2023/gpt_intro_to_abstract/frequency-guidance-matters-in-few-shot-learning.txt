Deep learning has shown great success in image classification tasks, but it heavily relies on large annotated datasets. However, deep models often struggle to generalize when faced with few data or annotations. This problem is known as few-shot classification, where the goal is to classify a query sample using only a few labeled data. Recent research has applied the meta-learning framework to build a discriminative feature space and achieve superior performance for recognizing novel classes. However, existing methods may fail to generalize well to novel classes due to large domain gaps between training and testing sets. Several domain adaptation-based few-shot algorithms have been proposed to address this issue, but they do not consistently improve performance across different few-shot scenarios. Moreover, most domain adaptation-based methods only focus on exploiting spatial features, ignoring the potential benefits of frequency-domain representation. Frequency components provide discriminative and interpretive features for visual understanding, but no work has systematically investigated their role in few-shot learning. In this paper, we propose a novel Frequency-Guided Few-shot Learning (FGFL) framework that adaptively selects important frequency components for effective few-shot classification. Our framework generates a task-specific class-discriminative mask in the frequency domain and converts it back to the spatial domain to generate masked and unmasked images. We construct triplets and additional few-shot tasks using these images and introduce ranking losses to capture task-specific class-discriminative information. Additionally, we enhance the support set by including unmasked images. Our contributions include proposing the FGFL framework, introducing ranking losses at both sample and task levels, investigating the impact of frequency components on few-shot methods under various generalized few-shot settings, and demonstrating improved performance and generalizability through experimental results and visualizations.