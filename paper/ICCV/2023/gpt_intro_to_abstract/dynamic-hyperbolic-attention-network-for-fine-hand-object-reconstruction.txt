3D hand-object reconstruction from monocular RGB images is an important task in computer vision with applications in human-machine interaction, robotic grasping/learning, and augmented reality. Existing methods for this task struggle with two challenges: reconstructing meshes with consistent pose and scale, and fulfilling physiological rules and physical characteristics of hand-object interaction. These methods typically work in Euclidean space, regressing model parameters from image features and manually defining interaction constraints. In this paper, we propose a method called Dynamic Hyperbolic Attention Network (DHANet) that learns geometry-image multi-modal features in hyperbolic space to achieve more accurate hand-object reconstruction. Hyperbolic space has shown potential for learning geometric representations, and our approach leverages this by projecting hand and object meshes into hyperbolic space and employing dynamic hyperbolic graph convolution and image-attention hyperbolic graph convolution to learn rich geometric information and model hand-object interaction. Evaluation on three public hand-object datasets demonstrates that DHANet outperforms state-of-the-art methods. The contributions of our work include introducing hand-object reconstruction in hyperbolic space, devising dynamic hyperbolic and image-attention graph convolutions, and demonstrating the superiority of our design through comprehensive evaluations.