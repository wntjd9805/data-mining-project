The quality of casually captured Neural Radiance Fields (NeRFs) is often lower than that of captures shown in NeRF papers. This is particularly evident when rendering a fly-through path from different viewpoints than the original captures, which results in floater artifacts and bad geometry. Existing approaches to mitigate these artifacts involve extensive capture processes or algorithmic improvements for out-of-distribution NeRF renderings. However, current benchmarks mainly focus on evaluating image quality at held-out frames, which does not reflect the visual quality at novel viewpoints. In this paper, we propose a novel method to clean up casually captured NeRFs and introduce a new evaluation procedure that measures the quality of a NeRF from novel viewpoints. We capture two videos, one for training the NeRF and another for evaluation, and compute metrics based on ground-truth images from the evaluation video. Additionally, we introduce Nerfbusters, a method that improves geometry in everyday NeRF captures by enhancing surface coherence, removing floaters, and eliminating cloudy artifacts. Nerfbusters learns a local 3D geometric prior using synthetic 3D data and employs a diffusion network to encourage plausible geometry during NeRF optimization. We demonstrate that this technique effectively removes floaters and improves scene geometry. Our proposed evaluation procedure and Nerfbusters method are implemented in the open-source Nerfstudio repository. The code and data can be accessed at https://ethanweber.me/nerfbusters.