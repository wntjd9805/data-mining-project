Automated and objective analysis of medical images is a significant research topic in various clinical applications. However, the acquisition of massive annotated data for model development on new domains can be burdensome. To address this issue, unsupervised domain adaptation (UDA) methods have been proposed to mitigate data distribution bias between a richly labeled source domain and a target domain with no explicit supervision. However, these methods assume a closed-set adaptation setting where the source and target domains share the same category label space and definition. In the medical domain, inconsistency in taxonomy across different countries or institutes is common, making cross-domain adaptation challenging. To tackle this problem, the authors propose a generalized adaptation method that addresses both data distribution bias and category gap in clinical practice. They introduce a taxonomy adaptive domain adaptation approach, which allows the target domain to adopt a different label space from the source domain. The method leverages a labeled source dataset, unlabeled samples from the target domain, and annotated samples of target-private categories. The authors propose a unified framework using optimization trajectory distillation to provide external guidance for learning new classes with limited supervision. The framework consists of cross-domain/class distillation and historical self-distillation components. Cross-domain and cross-class distillation utilize the optimization trajectory from the source domain and classes as a "teacher" to calibrate the training dynamics of the target domain and new classes. Historical self-distillation drives the optimization paths to converge towards flat minima, improving model generalization. The proposed method results in a more generalized cross-domain adaptation paradigm for medical image analysis and shows improvements over existing approaches in terms of effectiveness and robustness, as demonstrated through experiments on various benchmarks.