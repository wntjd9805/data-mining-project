Generative Adversarial Networks (GANs) and style-based generative models, such as StyleGANs, have emerged as the leading paradigm of generative modeling in the vision domain. The latent spaces of StyleGANs are known to contain rich and hierarchical semantics, allowing for meaningful variations in the output images by moving the latent code in certain directions. To precisely control the generation process, latent semantics discovery methods have been developed to identify interpretable directions where each variation factor is disentangled. One promising approach is SeFa, which uses the eigenvectors of the projector to discover semantically meaningful concepts. However, this method suffers from the entanglement of semantics in the top eigenvectors due to imbalanced eigenvalue distribution. Enforcing orthogonality constraint to the projector mitigates this issue, but it leads to a shortage of discoverable semantics for large models like StyleGANs. To address these challenges, we propose the Householder Projector, a low-rank orthogonal matrix representation based on Householder transformations, to parameterize the projection matrix. This approach preserves orthogonality and guarantees meaningful output changes by setting the singular values as a low-rank identity matrix. Our method integrates seamlessly with pre-trained GAN models and requires minimal additional fine-tuning steps while improving the latent semantics discovery and attribute control without compromising image quality. Extensive experiments on various benchmarks demonstrate the effectiveness of our approach in large-scale generative models like StyleGANs. Our contributions include the development of the Householder Projector, its integration into pre-trained GAN models, and empirical evidence of its effectiveness in latent semantics discovery and precise attribute control.