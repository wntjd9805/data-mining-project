Semantic segmentation is a crucial task in computer vision for understanding the structure and details of images. However, current approaches heavily rely on manual annotations, which are time-consuming and costly to obtain. Unsupervised semantic segmentation has gained attention as an alternative, but existing methods struggle with complex images and require carefully-tuned text prompts or self-training. Spectral clustering, a classic technique, has potential but faces limitations in terms of sensitivity to color transformations, computational efficiency, and applicability to non-training samples. Recent work has shown that pre-trained models can improve spectral clustering, but efficiency and flexibility issues remain. In this paper, we propose a solution to these limitations by casting the spectral decomposition problem as an optimization one using neural eigenfunctions. Our method leverages pre-trained model features and raw pixels to measure similarities between image patches and uses neural networks to approximate the principal eigenfunctions. We eliminate the need for a separate grouping step by directly assigning clustering assignments with one-hot vectors. This parametric approach enables easy out-of-sample generalization and avoids complex matrix eigenvalue problems during testing. We evaluate our approach on benchmark datasets and demonstrate superior results compared to leading methods. Ablation studies are conducted to analyze the impact of core hyperparameters. Our method offers a simple yet effective baseline for unsupervised semantic segmentation.