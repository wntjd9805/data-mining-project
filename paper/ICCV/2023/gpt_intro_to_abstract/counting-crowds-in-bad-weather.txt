Crowd counting is an important task in computer vision with numerous applications. State-of-the-art approaches for crowd counting are based on convolutional neural networks (CNNs) and transformers. However, these approaches do not perform well under adverse weather conditions, which cause large appearance variations in crowd scenes. In this paper, we propose a two-stage model for crowd counting under adverse weather. We leverage image restoration modules to preprocess images and then apply a crowd counting method. However, this two-stage method has limitations in effectively addressing the problem. Therefore, we propose a transformer-based method called AWCC-Net, which incorporates weather queries to improve robustness in both clear and adverse weather conditions. We introduce a contrastive weather-adaptive module to enhance the learned weather queries, enabling the network to adapt to various weather degradation types. Extensive experimental results demonstrate the effectiveness of our proposed method in robust crowd counting without requiring weather annotations. Our contributions include introducing the AWCC-Net and the weather-adaptive module to improve model performance under adverse weather conditions.