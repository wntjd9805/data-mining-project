Unsupervised person re-identification (Re-ID) is a computer vision task that aims to retrieve images of a particular person across different camera views and scenes without any annotations. Existing unsupervised methods typically use a two-step training scheme, generating pseudo labels for clusters and training the model based on a single representation of each cluster. However, this approach often fails to accurately describe the information of a cluster due to the intra-class variance and inter-class similarity caused by factors like human pose, illumination, and camera views. As a result, the learned features are not compact and have unclear cluster boundaries. To address this issue, some methods subdivide each cluster into multiple camera-aware proxies to reduce intra-class variance. However, these methods rely on additional labels and do not consider other factors affecting intra-class variance. Alternatively, some methods focus on reducing inter-class similarity by performing batch hard negative sample mining. However, due to the random sampling, the selected negative samples may not effectively enlarge the inter-class separation of similar classes. In this paper, we propose a method that uses multiple discrepant cluster proxies to complementarily represent a cluster, thereby reducing intra-class variance without relying on additional annotations.