Researchers have made significant efforts to develop AI learners that can mimic human cognition. One such endeavor is zero-shot learning (ZSL), which aims to identify unseen classes without using their images during training. However, human zero-shot learning abilities improve dynamically over time as individuals acquire more knowledge of seen tasks. To evaluate zero-shot learning in a dynamically changing seen-unseen distribution, the continual zero-shot learning problem (CZSL) has been proposed. CZSL emulates the continuous learning process of a human's life, where the model continually sees more classes from the unseen world and is evaluated on both seen and unseen classes. This has the potential to accelerate research in species discovery as known species continuously grow, but a significant percentage of species remains undiscovered. Generative models, such as GANs, have shown progress in producing photorealistic images by learning high-dimensional probability distributions. This ability has motivated researchers to adapt GANs to ZSL, known as generative-based ZSL, where the classifier is trained on synthetic unseen samples to reduce bias towards seen classes. However, in CZSL, the unseen world changes dynamically and unexpectedly, making it unrealistic to assume prior knowledge about unseen classes. Most existing methods struggle to perform well in this setting, known as inductive continual zero-shot learning. Therefore, there is a need to develop purely inductive continual zero-shot methods and gain a theoretical understanding of how zero-shot learning benefits from synthetic data. In this paper, we propose a purely inductive method called Generative Random Walk (GRW) loss for CZSL, guided only by semantic descriptions of seen classes. We apply a random walk starting from seen classes and moving through generated examples of hallucinated classes, using the GRW loss to encourage realistic and distinguishable samples to represent unseen classes. Our theoretical analysis and experiments show the effectiveness of our approach, achieving state-of-the-art results on standard CZSL benchmarks.