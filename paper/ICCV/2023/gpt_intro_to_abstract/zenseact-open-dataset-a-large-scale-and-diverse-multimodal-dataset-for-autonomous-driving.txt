Automated driving has the potential to improve road safety and reduce traffic accidents. However, the development of autonomous vehicles requires high-quality and diverse data from real-world traffic scenarios to achieve optimal performance. In this paper, we introduce Zenseact Open Dataset (ZOD), Europe's largest and most diverse multimodal autonomous driving dataset. ZOD consists of more than 100k traffic scenes and is carefully curated to cover a wide range of real-world driving scenarios. The dataset is split into three subsets: Frames, Sequences, and Drives, each suited for different perception tasks and learning objectives. ZOD stands out from other datasets by offering a 9Ã— larger geographical coverage and employing high-resolution sensors such as cameras, LiDARs, and GNSS/IMU systems. It also provides comprehensive annotations for various perception tasks, including object detection, lane segmentation, and traffic sign recognition. The dataset is released under a permissive license, allowing for both research and commercial use. We believe that ZOD will contribute to the development of robust algorithms and accelerate the advancement of autonomous driving technology.