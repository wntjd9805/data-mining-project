The task of single image deraining aims to improve the quality of images by separating rain from the image background. While significant progress has been made in learning-based deraining methods using CNN architectures and Transformer models, these supervised methods still underperform when it comes to real rainy scenes due to the domain shift issue between synthetic and real rain. To address this problem, researchers have attempted to create more realistic rain degradation models. Existing rain datasets, such as RID/RIS, NR-IQA, Real3000, FCRealRain, SPA-Data, RainDS, GT-Rain, RealRain-1K, and LHP-Rain, have been used for training and evaluation, but they have limitations in terms of resolution, rain categories, and the ability to handle rain splashing on the ground. In this work, we propose a new large-scale high-quality paired real rain benchmark, called LHP-Rain, which includes diverse rain categories, ground splashing rain, and high-resolution images captured in real-world scenarios. We also present a novel robust low-rank tensor recovery method (RLRTR) for video deraining to generate higher-quality ground truth images. Additionally, we introduce a transformer-based single image deraining baseline that incorporates self-attention and cross-layer attention for better representation. Experimental results demonstrate the effectiveness of our approach on different real datasets. Overall, the contributions of this work include the construction of a large-scale real rain benchmark, the development of a robust deraining method, and the proposal of a transformer-based baseline for single image deraining.