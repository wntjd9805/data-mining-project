Deep learning models are designed to perform well in the closed world scenario, where the inputs during inference are assumed to be from the same distribution as the training data. However, when inputs are sampled from other distributions, these models may make incorrect predictions. To address this issue, the task of out-of-distribution (OOD) detection has been established. Previous approaches have used confidence scores or input features learned by classification models to detect OOD samples, but these methods have limitations such as overconfidence, high cost and time requirements, and the need for additional datasets or input processing.In this paper, we propose a simple and effective approach for OOD detection that does not require hyperparameters, additional datasets, or input processing. We combine the norm and Mahalanobis distances of features to detect OOD samples. We find that models trained with the cosine-based softmax loss are advantageous for OOD detection compared to those trained with the regular softmax loss. We mathematically conjecture that the feature norm from models with the cosine-based softmax loss can serve as a measure for the probability of in-distribution, and we confirm its effectiveness through experiments. We also develop a robust Mahalanobis distance-based measure for models with the cosine-based softmax loss. Our proposed OOD score function combines the feature norm and Mahalanobis distance without any hyperparameters.Our method eliminates the need for input processing, making the additional computation for OOD detection negligible. The feature norms and Mahalanobis distances can be obtained with minimal additional calculations from classification models. Since the cosine-based softmax loss is applicable to various deep models, our OOD detection approach can be easily extended to different structures without sacrificing classification accuracy. Moreover, our method is practical as it does not rely on any additional datasets.We evaluate the OOD detection performance of our method on various image datasets through experiments. We compare our approach with other methods that rely on additional datasets, perform input processing, or tune hyperparameters to maximize performance. The results show that our approach outperforms or is at least comparable to state-of-the-art OOD detection methods.