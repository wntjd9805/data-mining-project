Optical flow is a fundamental topic in event-based vision and has various applications in computer vision, such as ego-motion estimation, image reconstruction, and video frame interpolation. Recent advancements in frame-based optical flow algorithms have dominated the field, but they still have limitations when applied to event-based data due to the differences between event data and conventional images. Event cameras capture visual information in a sparse manner but provide rich motion cues with high temporal resolution. In this paper, we propose a novel Temporal Motion Aggregation (TMA) approach to leverage the temporal continuity of event data for optical flow estimation. TMA incorporates three components, including an event splitting strategy, a linear lookup strategy, and a motion pattern aggregation module. By exploiting temporally fine-grained motion information, TMA overcomes the information scarcity issue in motion features and generates accurate flow predictions early in the process. We evaluate TMA on benchmark datasets and demonstrate its superiority in terms of accuracy and efficiency compared to existing methods. Our contributions include recognizing the importance of temporal continuity in event-based optical flow, proposing the TMA approach with its distinct components, and achieving high accuracy and efficiency in optical flow estimation.