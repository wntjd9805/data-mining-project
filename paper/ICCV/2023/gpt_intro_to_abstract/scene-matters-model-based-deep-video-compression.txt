Videos have become increasingly prevalent in various aspects of life, leading to a significant challenge in efficiently storing and transmitting video data. Multiple video compression standards have been developed, but the performance of existing deep learning-based video compression (DLVC) methods still lags behind traditional methods. To overcome this performance bottleneck, this paper proposes an innovative video coding paradigm that seeks to find a compact subspace for reconstructing video frames. The proposed method introduces a context-related spatial positional embedding (CRSPE) and a frequency domain supervision (FDS) module to handle spatial variations and capture high-frequency details, respectively. Additionally, the paper introduces a scene flow constraint mechanism (SFCM) and a temporal contrastive loss (TCL) to improve temporal correlation modeling. Experimental results demonstrate that the proposed method outperforms the traditional H.266 standard, indicating its potential for enhancing video compression. The framework of the proposed model-based video compression method is illustrated, highlighting the incorporation of spatial context enhancement and temporal correlation capturing. Overall, this paper makes contributions in advancing the field of video compression and inspires further exploration in this area.