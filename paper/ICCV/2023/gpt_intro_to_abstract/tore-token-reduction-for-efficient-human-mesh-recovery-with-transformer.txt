Human Mesh Recovery (HMR) is a widely researched task in computer science due to its various real-world applications. The task becomes particularly challenging when the input is a monocular 2D image, as it involves dealing with large pose and shape variations, appearance variations, partial observation, and self-occlusion. While there has been progress in 3D human mesh recovery, recent studies have shown that Transformer-based methods achieve state-of-the-art performance by capturing long-range dependencies for more accurate predictions. However, the increased expressivity of Transformers comes with higher computational costs, as all pairwise interactions need to be considered. Existing Transformer-based methods for HMR suffer from redundant tokens, which leads to high model complexity and computational costs and hinders their full potential in real-world applications.In this paper, we make key observations about the 3D geometry structure and 2D image features to address the problem of token redundancy. First, we propose using a small number of skeleton joints as tokens to represent the body mesh, as these joints already encode the underlying structure of the body shape. Second, we introduce a learnable token pruner to remove redundant tokens from the input image features, focusing only on the discriminative features within the body area. These token reduction strategies significantly reduce the computational burden without sacrificing important information.We conduct extensive experiments on benchmark datasets to validate the effectiveness of our proposed method. Our framework achieves state-of-the-art performance in terms of accuracy while reducing memory and computation overhead. For example, compared to existing methods, our method saves a significant percentage of GFLOPs and improves throughput while maintaining competitive accuracy. Overall, our contributions include identifying token redundancy issues in existing Transformer-based methods for HMR, proposing effective strategies for token reduction based on insights from 3D geometry structure and 2D image features, and achieving state-of-the-art performance with reduced computational costs.