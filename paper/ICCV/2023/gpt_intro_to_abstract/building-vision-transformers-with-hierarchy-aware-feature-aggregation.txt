The introduction of this computer science paper discusses the success of Transformer in natural language processing (NLP) and the inspiration it has provided for the research of Vision Transformer in the field of computer vision. Vision Transformers have shown new state-of-the-art performance in various vision tasks such as image classification, object detection, and semantic segmentation. Compared to Convolutional Neural Networks (ConvNets), Transformers have better global modeling capabilities due to their attention mechanism. However, to incorporate Transformers into existing frameworks, it is necessary to generate hierarchical feature maps. Currently, most Transformers still generate hierarchical feature maps using the downsampling method of ConvNets, which can lead to inaccurate segmentation. To address this issue, the paper proposes a Hierarchy Aware Feature Aggregation framework (HAFA) which consists of a Semantic Information Aggregation (SIA) module and a Local Adaptive Feature Aggregation (LAA) module. The SIA module clusters patches with similar semantics to ensure accurate modeling of global relationships, while the LAA module enhances the capture of local texture information. The proposed HAFA framework improves performance in various vision tasks and shows notable improvements in small object detection and semantic segmentation.