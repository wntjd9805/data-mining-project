Object detectors play a crucial role in various computer vision systems, but their performance heavily relies on the availability of training data. However, annotating large object detection datasets can be expensive and time-consuming. Additionally, these detectors often struggle to generalize to new categories. Object discovery, the process of identifying and grouping objects in images without human intervention, has the potential to address these challenges. Previous object discovery methods have used different techniques to obtain region proposals and group them semantically, but they have limitations in terms of scalability and quality of proposals. This paper proposes a new object localization method called "Multiple Object localization with Self-supervised Transformers" (MOST), which is capable of localizing multiple objects per image without using any labels. MOST leverages the features extracted from a transformer network trained with DINO and relies on empirical observations regarding the similarity between patches within foreground objects and the background. The proposed algorithm analyzes these similarities using box counting and performs clustering to group patches belonging to foreground objects. This enables the extraction of multiple bounding boxes per image. The effectiveness of MOST is demonstrated through experiments on various object localization and discovery benchmarks, showing significant improvements over baselines. The paper concludes by discussing related works, detailing the methodology, presenting experimental results, and highlighting the contributions of the proposed method.