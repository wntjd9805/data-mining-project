Single image dehazing is a task that aims to restore clear, haze-free images from hazy images. Traditional haze removal strategies have gradually shifted towards deep learning-based methods, particularly convolutional neural networks (CNNs), due to their significant performance improvement. However, the direct application of Transformer, a popular architecture in computer vision tasks, faces challenges in image dehazing. These challenges include the computational complexity of Transformer and the inflexible scales of tokens generated by existing visual Transformer networks. To address these challenges, we propose a variant of Transformer called TaylorFormer, which applies self-attention on the entire feature map and maintains linear computational complexity by using the Taylor expansion on softmax. This approach avoids reducing the receptive field and allows for more fine-grained processing of features. Additionally, we introduce a multi-scale attention refinement module to further improve TaylorFormer's performance. To address the issue of inflexible scales, we propose a multi-branch encoder-decoder backbone for TaylorFormer called MB-TaylorFormer. This backbone uses a multi-scale patch embedding approach, which generates tokens with different scales and dimensions. The multi-branch structure captures more powerful features by processing these tokens simultaneously.Our main contributions are: 1) The proposal of TaylorFormer, a linearized variant of Transformer, and the introduction of an MSAR module to correct errors in self-attention.2) The design of the MB-TaylorFormer architecture, which incorporates multi-scale patch embedding for flexible receptive fields and multi-level semantic information.3) Experimental results on public datasets demonstrate that MB-TaylorFormer achieves state-of-the-art performance with limited parameters and computational complexity.