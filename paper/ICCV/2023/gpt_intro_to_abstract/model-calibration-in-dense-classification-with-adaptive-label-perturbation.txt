Binary segmentation is a crucial task in computer vision, with applications such as salient object detection, camouflaged object detection, and smoke detection. Deep Neural Networks (DNNs) have shown promising results in these tasks, but they often suffer from overfitting and producing over-confident predictions in the real world. This can lead to unreliable model predictions, impacting decision making and downstream tasks. To address this issue, various approaches have been proposed, including post-hoc operations, training objective approaches, and data/label augmentation techniques. In this paper, we propose an Adaptive Label Perturbation (ALP) method, which learns a unique label perturbation level for each training image. ALP incorporates the Self-Calibrating Binary Cross Entropy (SC-BCE) loss, which combines stochastic approaches and label smoothing to improve model calibration while maintaining classification accuracy. ALP can approximate Maximum Entropy Inference to maximize prediction entropy while preserving dense classification performance. We also present an alternative ALP solution that maximizes model calibration degree by minimizing the gap between prediction confidence and accuracy distributions. Our contributions include the Adaptive Stochastic Label Perturbation method, the SC-BCE loss, and the evaluation of our method on various tasks, demonstrating its effectiveness in improving model calibration and performance.