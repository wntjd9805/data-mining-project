We propose a new method called Class-aware Text Prompts (CTP) for fast adaptation of large vision-language models (VLMs) on downstream vision tasks. Our approach generates text prompts based on task-relevant image semantics, improving classification accuracy of unseen classes without introducing learning ambiguities. Additionally, we introduce Text-guided Feature Tuning (TFT), which guides the image branch to focus on task-related regions. Our mutual-learning method achieves state-of-the-art results on four downstream tasks and significantly outperforms existing methods on base-to-new generalization task.