Single-vehicle perception has made significant advancements in object detection and segmentation with the emergence of deep learning. However, challenges such as occlusion and severe weather can hinder accurate recognition in single-vehicle perception. To overcome these issues, collaborative perception studies have been conducted, leveraging the multiple-viewpoint capability of Vehicle-to-Vehicle (V2V) communication. Current collaborative perception algorithms primarily focus on collaboration strategies, neglecting the crucial processes of communication and reconstruction. This oversight can result in suboptimal performance. In this paper, we propose a unified collaborative perception framework that optimizes communication, collaboration, and reconstruction using a multi-resolution technique. Our framework introduces a novel multi-resolution and selective-region mechanism for communication, a graph-based collaborative module for collaboration, and a multi-grain feature enhancement module for reconstruction. We also present a new evaluation metric to assess performance in collaborative perception. Experimental results demonstrate that our framework outperforms existing methods in terms of performance-bandwidth trade-off.