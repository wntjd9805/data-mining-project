This paper introduces Federated Learning (FL), a distributed data parallel machine learning approach, as a solution to privacy concerns regarding uploading biological data to central data servers. FL allows for collaborative training of a shared global model on a mediator server without sharing personal data. The focus of this paper is on FL-based one-class classification (OCC) in computer vision applications, which is useful for fraud detection, defect detection, and detecting unauthorized users. However, FL-based OCC methods face challenges such as high communication costs, limited representation, and unstable learning processes. To address these challenges, the authors propose a novel approach called Prototypical representation distillation based unsupervised Federated Learning (ProtoFL). ProtoFL distills representation from an off-the-shelf model learned using off-the-shelf datasets, without transferring parameters directly to the client. This approach resolves issues related to communication costs and the need for extra data. Additionally, the authors propose a flow-based one-class classifier for estimating the density of a target class in a distributed setting. The experimental findings show that ProtoFL outperforms server-based and client-based methods on both image and tabular datasets and is scalable to accommodate new clients. The authors' contributions include proposing the ProtoFL framework, a prototype-based representation learning method, and new federated and centralized learning methods for one-class classification, all of which achieve superior performance compared to existing approaches.