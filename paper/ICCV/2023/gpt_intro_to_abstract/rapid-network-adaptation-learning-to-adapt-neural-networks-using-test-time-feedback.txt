Neural networks have been found to be unreliable when faced with distribution shifts, such as changes in camera motion, object occlusions, weather conditions, and lighting. Training-time strategies have attempted to address this issue by anticipating shifts and adjusting the network accordingly. However, this approach has limitations due to the unpredictable nature of shifts. Therefore, test-time adaptation methods have emerged, aiming to adapt to shifts as they occur. In this paper, we propose a test-time adaptation framework that aims to efficiently adapt a main network using a feedback signal. We compare this approach to "test-time optimization" (TTO), which uses techniques like fine-tuning with SGD. We demonstrate that our approach, which incorporates a learnable feed-forward controller network, is more efficient and flexible than TTO. It can be engineered to include inductive biases and desired features to counter suboptimalities of the adaptation signal.