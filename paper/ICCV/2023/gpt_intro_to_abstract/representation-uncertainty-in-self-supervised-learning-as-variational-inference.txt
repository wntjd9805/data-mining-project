Self-supervised learning (SSL) is a framework for learning representations of data without substantial manually labeled data. It has been shown to effectively train high-performance models in downstream tasks. One approach to SSL involves training image encoders by maximizing the similarity between representations of different augmented views of an image. Another approach utilizes probabilistic generative models with variational inference to learn latent representations in an unsupervised fashion. However, the connection between SSL and variational inference has not been fully explored. In this study, we incorporate variational inference into SSL to make it uncertainty-aware and analyze representation uncertainty. We clarify the relationship between SSL and variational inference, generalize SSL methods as the variational inference of spherical or categorical latent variables, and propose a novel SSL method called variational inference SimSiam (VI-SimSiam) that predicts representations and their uncertainty. We demonstrate that VI-SimSiam successfully estimates uncertainty without labels while achieving competitive classification performance. Additionally, we show a qualitative evaluation of the estimated uncertainty and its relationship to classification accuracy. Our study provides insights into the theoretical connection between SSL and variational inference and presents a promising approach for uncertainty-aware representation learning.