Video object segmentation (VOS) is a fundamental and challenging computer vision task that aims to segment a specific object throughout an entire video sequence. It plays a crucial role in various practical applications including self-driving vehicles, augmented reality, and video editing. While traditional techniques and deep learning methods have been extensively studied in the past, current state-of-the-art deep-learning-based methods have significantly improved the performance of VOS. However, these methods have primarily been evaluated on datasets with isolated and salient objects, which rarely occur in real-world scenarios. To address this limitation, we introduce a new large-scale challenging video object segmentation benchmark called coMplex video Object SEgmentation (MOSE), which consists of 2,149 videos with complex scenes and incorporates 36 object categories and 431,725 high-quality segmentation masks. MOSE features complex scenarios such as disappearance-reappearance of objects, heavy occlusions, small/inconspicuous objects, and crowded scenes. We retrain and evaluate existing VOS methods on MOSE, and the results demonstrate that current state-of-the-art methods exhibit lower performance in complex scenes, especially in tracking objects that disappear due to occlusions. The challenges presented by MOSE span across different aspects, including occlusions, small objects, crowds, and the temporal domain. Our contributions include the creation of the MOSE dataset, a comprehensive comparison and evaluation of state-of-the-art VOS methods across four different settings, and an analysis of the challenges and potential directions for future research in video object segmentation under complex scenes.