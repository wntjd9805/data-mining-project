With the rise of autonomous driving, there is an increasing interest in 3D vision tasks based on LiDAR technology. One such task is 3D LiDAR single object tracking (SOT), which aims to track a specific object in a 3D video. However, this task faces challenges such as sparsity of LiDAR point clouds, occlusions, and fast motions. Existing methods for 3D SOT predominantly use a Siamese-like backbone with an additional matching network. This approach has limitations in feature interaction and requires extra model parameters and computational overheads. To address these issues, we propose SyncTrack, a single-branch and single-stage framework with a Transformer-based backbone. The Transformer backbone enables simultaneous feature extraction and matching, leveraging its dynamic global reasoning property. Furthermore, we introduce attentive sampling, called APST, to improve the point-wise perception efficiency of the backbone. Our proposed method achieves state-of-the-art performance on KITTI and NuScenes datasets for real-time tracking, with a high-speed of approximately 45fps. SyncTrack also demonstrates good scalability in both width and depth.