This work proposes a solution for continuous space-time video super-resolution (C-STVSR), which aims to increase both spatial resolution and temporal frame-rate of a video using a single model. Unlike fixed-scale space-time video super-resolution (F-STVSR), which focuses on a specific spatiotemporal scale, C-STVSR is more flexible and practical for real-world scenarios with videos of varying resolutions and frame-rates. Previous approaches for C-STVSR have approached the problem by performing separate temporal interpolation and spatial super-resolution tasks, missing the opportunity for improved performance. Inspired by continuous image super-resolution, this work presents an early attempt at C-STVSR using a spatial implicit neural function for super-resoluting frame features and a temporal implicit neural function for generating motion estimates. However, learning backward motion as a function of time poses challenges due to the potential randomness and discontinuities introduced by multiple motion trajectories. To address this, the proposed method learns forward motion trajectories using a space-time implicit neural function and explicit motion modeling. Additionally, a reliability-aware splatting and decoding scheme is introduced to fuse information from multiple reference frames. The proposed C-STVSR framework, MoTIF, achieves state-of-the-art performance and out-of-distribution generalization.