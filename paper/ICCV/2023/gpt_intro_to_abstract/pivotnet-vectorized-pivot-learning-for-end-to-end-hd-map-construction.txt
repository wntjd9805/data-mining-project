High-definition (HD) maps play a crucial role in autonomous driving modules such as simulation, localization, and planning. Traditionally, these maps are constructed through manual annotation on lidar point clouds, which is time-consuming and labor-intensive. Recent research has aimed to reduce the labeling costs by exploring map learning techniques, where local maps are constructed within a predefined bird's-eye-view range using data from onboard sensors. However, most existing methods treat map construction as a semantic learning problem and generate rasterized maps, which have limitations in terms of memory usage, geometric relationships, and post-processing requirements. To address these limitations, there have been proposals for generating vectorized representations in an end-to-end manner. However, these methods have their own drawbacks, including redundant points and information loss. In this paper, we propose PivotNet, a framework for precise and compact HD map construction using a pivot-based vectorization approach. PivotNet consists of four primary modules, including a line-aware point decoder and a pivotal point predictor. We introduce a point-to-line mask module and a pivot dynamic matching module to accurately model map elements, and propose a dynamic vectorized sequence loss to supervise the position and topology of the vectorized point predictions. Our experimental results show that PivotNet outperforms state-of-the-art methods on existing benchmarks, demonstrating the effectiveness of our approach.