The introduction of this computer science paper discusses the success of Vision Transformer (ViT) models in various computer vision tasks. However, the large number of parameters and calculations in these models hinder their applications on portable devices. To address this efficiency issue, the paper explores the binarization of ViTs. The authors highlight the challenges of binarizing Transformers, particularly in accurately binarizing the softmax attention. They also discuss the need to preserve information from pretrained ViTs during binarization. The paper introduces Softmax-aware Binarization (SAB) for self-attention module, Cross-layer Binarization (CLB) for retaining pretrained information, and Parameterized Weight Scales (PWS) for weights binarization. The authors present their contributions as the pioneering work in exploring binary vision Transformers, and they demonstrate the effectiveness of their approach through experiments on image classification and object detection tasks.