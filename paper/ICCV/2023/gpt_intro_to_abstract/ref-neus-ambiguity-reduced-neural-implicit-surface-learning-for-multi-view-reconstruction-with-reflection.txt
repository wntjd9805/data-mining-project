3D reconstruction is a fundamental task in computer vision that finds applications in various fields such as computer-aided design, computer animation, and virtual reality. Image-based 3D reconstruction, in particular, is challenging and often requires a multi-step pipeline with supervision. Recently, neural implicit surface learning has gained attention for its ability to achieve high-quality reconstruction with end-to-end and unsupervised training. However, existing methods struggle with reflective surfaces, producing erroneous results due to the ambiguous surface prediction caused by multi-view inconsistency.To address this issue, some recent works have explored reflection modeling in neural radiance fields by decomposing object appearance into physical components. While this approach can improve 3D geometry estimation by eliminating the influence of reflection, accurate decomposition is often difficult to achieve. In this paper, we propose a simple and effective solution that reduces ambiguity without relying on physical decomposition. Our approach introduces a reflection-aware photometric loss that adapts the weights fitting reflective surfaces based on reflection scores, avoiding multi-view consistency issues. We also improve geometry estimation by substituting radiance dependency with reflection direction. Experimental results demonstrate that our model outperforms existing methods in predicting surface geometry, surface normals, and rendering realism.The key contribution of this work includes the following:- We present the first neural implicit surface learning framework for reconstructing objects with reflective surfaces.- We propose a simple yet effective approach for handling reflective surfaces in neural implicit surface learning, resulting in high-quality surface geometry and normals.- Extensive experiments on multiple datasets demonstrate that our framework significantly outperforms state-of-the-art methods on reflective surfaces.