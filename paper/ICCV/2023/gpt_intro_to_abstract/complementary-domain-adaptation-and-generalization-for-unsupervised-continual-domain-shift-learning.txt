Machine learning algorithms have been widely applied in various fields, but the assumption that training and test data are identically and independently distributed (IID) is often not valid in real-world scenarios. This leads to performance decline when encountering new data from different domains. To address this issue, two approaches have been developed: domain generalization and domain adaptation. Domain generalization aims to enhance a model's ability to generalize to unseen domains, while domain adaptation focuses on enhancing model performance only on the current target domain. However, achieving both objectives simultaneously is challenging. In this paper, we propose Complementary Domain Adaptation and Generalization (CoDAG), a learning framework that combines both approaches in a complementary manner. Our framework involves training two separate models, one for domain adaptation and the other for domain generalization. The domain adaptation model adapts to the target domain, providing more accurate pseudo-labels for training the domain generalization model. Conversely, the domain generalization model learns generalized representations across domains and provides initialization parameters for the domain adaptation model. Our framework achieves improved performance for both domain adaptation and generalization. The main contribution of our framework lies in its complementary structure, leveraging existing methods without requiring tailored models for the problem. Our approach achieves state-of-the-art performance and demonstrates superior robustness. Additionally, our work bridges the gap between domain adaptation and generalization, which were previously studied independently, representing a paradigm shift with practical implications. Our contributions include introducing a novel framework, consistently outperforming state-of-the-art models, and enabling seamless integration with existing algorithms.