Symmetry is a widely present property in both man-made and natural objects, with numerous applications in various fields. This paper focuses on leveraging symmetry for shape completion from partial observations. Previous work, such as Front2Back, has shown that a complete 3D model can be described by a pair of 2.5D visible surface images. However, reconstruction quality is affected by the input view angle, and obtaining a perfect symmetry plane from partial observations is challenging. In this paper, we propose ISCNet, a method that explicitly leverages symmetry cues for shape completion. Our key insight is that symmetry detection and shape completion can provide constructive cues to each other. Unlike existing work, ISCNet iteratively refines the symmetry plane and the reconstructed shape jointly, and it does not rely on an initial viewpoint but instead leverages reinforcement learning for optimal viewpoint selection. ISCNet takes a single depth image and reprojects it to an incomplete point cloud, estimating the alignment of the symmetry plane. An RL agent determines reflection viewpoints, and a 2D inpainting module repairs the depth and normal maps. We validate that ISCNet produces more accurate shape completions compared to existing methods and conduct a thorough ablation study to analyze the contributions of each component. Overall, our contributions include a novel joint symmetry-detection/shape completion method, a symmetric viewpoint-based 3D shape completion method, and a reinforcement learning-based optimal viewpoint selection solution.