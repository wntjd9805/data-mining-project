Generative Adversarial Networks (GANs) have become widely used in low-level vision tasks, such as image super-resolution. Improving the perceptual quality of reconstructed images is a key goal in these tasks. In this paper, we investigate the effectiveness of spectral discriminators in GAN-based super-resolution. Previous studies have shown that GAN-generated images often struggle to match the spectral distribution of real data, especially in the high-frequency range. Spectral discriminators that utilize the Fourier spectrum as input have been proposed as a solution to this problem. However, the superiority of spectral discriminators over spatial discriminators is still unclear. Therefore, we evaluate the behavior of both spatial and spectral discriminators in super-resolution tasks and analyze their robustness under frequency perturbations. Our analysis shows that spectral discriminators perform better in identifying differences in the high-frequency range, while spatial discriminators have an advantage in the low-frequency range. Based on these findings, we propose a Dual Transformer (DualFormer) approach that combines spatial and spectral Transformers to improve the alignment of generated images with real images. Experimental results demonstrate that our method achieves better performance in terms of both spectral alignment and human perception assessment compared to previous baselines.