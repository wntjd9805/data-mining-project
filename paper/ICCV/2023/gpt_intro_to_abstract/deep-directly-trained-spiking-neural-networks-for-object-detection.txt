Object detection is a challenging problem in computer vision with applications in various fields such as autonomous driving, security surveillance, and medical imaging. Most existing frameworks for object detection use artificial neural networks (ANNs), which have high performance but also high computational complexity and energy consumption. Spiking neural networks (SNNs) offer a more efficient and biologically inspired approach to object detection by utilizing binary signals (spikes) for neuron communication and exhibiting asynchronous computation and event-driven communication. However, most SNNs for object detection are converted from ANNs and have limitations in terms of time steps and dynamic capture of spatiotemporal information. Training SNNs directly with surrogate gradients is a promising approach that achieves high performance with few time steps and can process both static images and event data efficiently. Another challenge in object detection is dealing with multi-scale object features and achieving deep structure training. Existing models are limited in terms of depth and may not be suitable for some neuromorphic hardware. To address these challenges, this paper proposes EMS-YOLO, a novel directly trained SNN for object detection based on the YOLO framework. EMS-YOLO uses surrogate gradients to train a deep and large-scale SNN without converting from ANNs. Additionally, a new energy-efficient residual block, EMS-ResNet, is designed to handle multi-scale object features and reduce power consumption. Experimental results demonstrate that EMS-YOLO achieves better performance than advanced ANN-SNN conversion methods, requires only 4 time steps for inference in real-time, and reduces energy consumption by 5.83Ã— compared to ANNs with the same architecture. Overall, this paper offers a novel approach to object detection using directly trained SNNs with improved performance and energy efficiency.