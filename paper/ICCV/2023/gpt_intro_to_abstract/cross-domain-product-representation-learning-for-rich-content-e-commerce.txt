Recently, the increasing popularity of rich-content e-commerce has transformed the way consumers shop online. In this type of e-commerce, products are not only sold through traditional product pages but also through dynamic and interactive media formats such as short videos and live streams. Consumers are increasingly using these formats to make informed purchase decisions, resulting in a more engaging shopping experience. However, rich-content e-commerce presents several technical challenges, including the inconsistency in product presentation across different media domains. To address this challenge, a unified cross-domain product representation is urgently needed in industrial scenarios. Prior research has primarily focused on learning product representations in the product page domain, but such representations are inadequate for rich-content e-commerce. To bridge this gap, the authors have collected a large-scale dataset, called ROPE, which includes product pages, short videos, and live streams from various online shopping platforms. The authors also propose a baseline model, COPE, that maps these different media formats into the same feature space to build a unified product representation. Experimental results show that COPE outperforms existing methods in cross-domain retrieval and few-shot classification tasks. The contributions of this work include being the first to explore a unified product representation across different media formats in rich-content e-commerce, the creation of the ROPE dataset, and the introduction of the COPE model.