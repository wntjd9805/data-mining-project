In this paper, we propose DiffIR, a powerful and efficient image restoration (IR) network based on Diffusion Models (DMs). DMs have shown impressive results in image synthesis and IR tasks, but they require a large number of iteration steps and consume massive computational resources. Unlike image synthesis, IR tasks only require adding accurate details to low-quality images. Therefore, we aim to design a DM-based IR network that can fully and efficiently utilize the distribution mapping abilities of DMs. Our approach, DiffIR, adopts transformer blocks in a Unet shape to extract and aggregate multi-level features. We train DiffIR in two stages: the first stage involves developing a compact IR prior extraction network (CPEN) and a Dynamic IRformer (DIRformer) to guide the restoration process. The second stage focuses on training the DM to estimate the accurate IR prior representation (IPR) directly from low-quality images. We demonstrate the effectiveness of our joint optimization approach and show that DiffIR achieves state-of-the-art performance in IR tasks while consuming significantly fewer computational resources compared to other DM-based methods. Our main contributions include proposing DiffIR as a strong and efficient DM-based baseline for IR, introducing novel techniques (DGTA and DGFN) to fully exploit the IPR, and conducting extensive experiments to validate the effectiveness and efficiency of DiffIR in IR tasks.