This paper introduces the concept of FerKD, a sample-calibration framework for Faster Knowledge Distillation (KD) in computer vision tasks. KD has shown impressive results in various visual domains but is often computationally expensive. FerKD aims to address this issue by improving the efficiency and effectiveness of KD. The proposed framework utilizes soft labels dynamically generated in each iteration and incorporates context information from hard ground-truth labels through recalibration with smoothing. Additionally, FerKD identifies and discards excessively easy or difficult samples to expedite the training process. The paper presents extensive analysis, ablation, and discussion on the impact of hard and easy samples, demonstrating state-of-the-art performance. Overall, FerKD offers a more efficient and precise approach to knowledge distillation in computer vision.