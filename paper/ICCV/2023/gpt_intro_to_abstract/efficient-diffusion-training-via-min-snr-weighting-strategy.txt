In recent years, denoising diffusion models have gained attention as powerful deep generative models due to their ability to model complex distributions. Compared to prior Generative Adversarial Networks (GANs), diffusion models have demonstrated superior performance in various generation tasks. However, a key limitation of denoising diffusion models is their slow convergence rate, which presents a challenge for researchers. In this paper, we identify the slow convergence rate as arising from conflicting optimization directions for different timesteps during training. We propose the Min-SNR-γ loss weighting strategy to address this issue by treating each timestep as an individual task in multi-task learning. This strategy balances the different tasks and allows for faster convergence compared to previous approaches. We compare our strategy with other conventional loss weighting strategies and demonstrate its effectiveness in multiple generation scenarios. Additionally, we establish a new record in FID score on the ImageNet 256×256 benchmark. Our contributions include uncovering the slow convergence issue in diffusion training, proposing a new loss weighting strategy to mitigate conflicting gradients, and achieving improved performance in image generation tasks.