Monocular 3D reconstruction is a crucial task in computer vision with various applications, such as augmented reality, virtual reality, robotics, and autonomous driving. Recently, learning-based methods have shown promising results for this task. These methods predict a Truncated Signed Distance Field (TSDF) volume as the 3D reconstruction using a sequence of posed images. They can be categorized into volumetric-based and depth-based methods.Existing volumetric-based methods suffer from the limitation of duplicating 2D image features along the entire camera ray, including empty spaces and occluded areas. This introduction proposes a novel 3D geometric feature representation called Ray-contextual Compensated Cost Volume (RCCV) to address this issue. Previous works duplicated 2D features in the 3D space, which can complicate feature fusion and TSDF prediction and introduce noise. The RCCV solves this limitation by directly constructing 3D feature representations that encode geometry clues.The cost volume, widely used in depth prediction, is chosen as the 3D geometric feature representation. It consists of multi-view feature matching confidences across pre-defined depth planes. Compared to duplicating 2D image features, the cost volume explicitly encodes the depth probability distribution along the ray. However, existing depth-based methods predict 2D depth maps from the cost volume and then reconstruct the 3D structure through TSDF Fusion. This 3D-2D-3D pipeline lacks global context and frame consistency, leading to loss of structural details or artifacts. In contrast, by retaining and fusing the 3D feature representation of each keyframe, a holistic estimation of the structure can be achieved.This paper proposes the RCCV as a 3D geometric feature representation, which is a multi-view cost volume with two contributions. First, a distribution feature is devised for individual camera rays, integrating the confidence distribution along the ray into each voxel. Second, the original 2D image feature is fused with the cost volume to compensate for non-overlapping regions and low-contrast areas. The proposed RCCV provides comprehensive 3D geometric information and can be inferred from a fusion of RCCVs from multiple keyframes. Extensive experiments demonstrate the effectiveness of RCCV as a generic representation and its agnostic nature with downstream fusion and prediction models.The contributions of this paper are as follows:1. Proposing the usage of multi-view cost volume as a direct 3D geometric feature representation in neural reconstruction.2.