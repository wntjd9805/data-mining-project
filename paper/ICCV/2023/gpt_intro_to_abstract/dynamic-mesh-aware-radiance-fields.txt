Creating photorealistic 3D environments typically requires manual work by skilled artists. Neural Radiance Fields (NeRF) provide a volumetric representation of real-world scenes, allowing for high-quality novel view synthesis and interactive rendering. However, existing methods for complex material and lighting effects are based on surface mesh representations. Integrating NeRF with traditional graphics pipelines has various applications in VR/AR, gaming, virtual tourism, education, and animation. While volume rendering has been successful for participating media, integrating NeRF into this pipeline while maintaining realistic lighting effects remains unexplored. Furthermore, the implicit geometry of NeRF makes it challenging to detect and resolve collisions. Recent works have attempted to enhance the integration between NeRF and meshes for rendering and simulation. We propose a hybrid graphics pipeline that integrates NeRF and meshes, considering lighting effects and contact handling. By unifying NeRF volume rendering and path tracing, we devise update rules for radiance and throughput variables, enabling seamless integration. Additionally, we incorporate shadows onto NeRF using differentiable surface rendering techniques and employ SDFs to represent geometry for collision resolution. Our implementation is efficient and user-friendly, with a high-level Python interface. Overall, our contributions include a two-way coupling between NeRF and surface representations, integration with HDR data, an efficient rendering procedure, and an interactive implementation.