An ideal artificial intelligence system should possess the ability to continually learn and acquire new concepts from a changing environment, a capability referred to as continual or lifelong learning. However, most modern Deep Learning models struggle with achieving continual learning as they tend to overwrite previously learned parameters in order to adapt to new tasks, resulting in a significant drop in performance on past tasks, known as catastrophic forgetting. Current approaches to reducing forgetting in continual learning fall into three categories: memory/experience replay, regularisation-based approaches, and dynamic network architectures. Among these methods, maintaining a fixed-capacity memory buffer that replays past examples to the model along with learning new tasks has proven to be a simple and efficient approach. However, existing memory-based methods assume that the task's identity is known during training, which is rarely the case in real-world scenarios.In this paper, we focus on a more challenging continual learning scenario called Task-Free Continual Learning (TFCL), where the model is trained on a data stream without access to task information. We propose extending memory-based approaches by developing an efficient sample selection strategy that selectively stores and replays samples at each training time. However, these approaches often suffer from interference between the probabilistic representations of old and newly seen samples. To address this issue, we introduce the dynamic expansion model (DEM), which increases the model's capacity to handle incoming samples while preserving prior knowledge. We propose a new approach called the Self-Evolved Dynamic Expansion Model (SEDEM), which evaluates the diversity among experts in the mixture system to control the model's growth and preserve underlying data distributions with a compact structure. Additionally, we propose the Dynamic Expansible Knowledge Mask Mechanism (DEKMM) that incorporates feature representations from all previously learned experts into the currently updated expert to promote knowledge transfer. DEKMM dynamically updates mask values to explore potential knowledge transfer through a gradient optimization mechanism.Furthermore, we introduce a novelty-aware sample selection approach that selectively stores training samples sufficiently different from the knowledge preserved by previously learned experts, encouraging the current expert to learn novel information and improving the diversity among experts. We conducted a series of experiments to validate the effectiveness of our proposed methodology, showing improved performance compared to state-of-the-art methods while employing fewer experts. We summarize our contributions as follows: the introduction of the SEDEM model for TFCL, a novelty-aware sample selection approach, the DEKMM for regulating previously learned representations, theoretical guarantees for SEDEM, and state-of-the-art performance in standard TFCL benchmarks.