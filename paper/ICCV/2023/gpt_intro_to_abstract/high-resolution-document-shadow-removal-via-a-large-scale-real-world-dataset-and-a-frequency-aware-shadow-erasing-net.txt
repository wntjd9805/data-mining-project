Shadows cast on paper by occluders obstructing the light source can reduce readability and hinder document enhancement, optical character recognition (OCR), key information extraction, and semantic entity labeling. There is a long-standing need to remove cast shadows from digital copies, but traditional methods based on physics-based illumination models are often limited by rigid assumptions and may incorrectly compute exposure and reflectance. Recent deep learning methods have shown progress in natural shadow removal, but transferring these methods to the document domain faces challenges due to the need to preserve fine-grained information in high-resolution images and the lack of large-scale and high-resolution datasets for document shadow removal. Weakly-supervised and unsupervised methods alleviate data requirements but make strong assumptions of statistical similarity or produce unstable results. To address these problems, this paper introduces a large-scale real-world shadow dataset called Shadowed Document 7K (SD7K), which includes high-resolution shadow and shadow-free document image pairs with manually annotated shadow masks. The dataset covers various document types and uses three distinct light sources for training diversity. The paper also proposes a robust network called Frequency-aware Shadow Erasing Net (FSENet) for high-resolution image processing. FSENet divides the document image into low-frequency and high-frequency components and incorporates transformer-based network and cascaded aggregations for global illumination alteration and adaptive pixel enhancement. Dilated convolution-based texture recovery modules are used for high-frequency restoration. Experimental results show that FSENet outperforms state-of-the-art methods on small benchmarks and SD7K in terms of qualitative and quantitative evaluations. The contributions of this paper include the introduction of SD7K, the development of FSENet for high-resolution document shadow removal, and the demonstration of its superior performance compared to existing methods.