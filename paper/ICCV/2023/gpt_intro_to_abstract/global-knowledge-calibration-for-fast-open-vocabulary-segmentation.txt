This paper introduces the concept of open-vocabulary semantic segmentation, which aims to segment arbitrary categories given only text inputs. Unlike traditional closed-set segmentation, open-vocabulary segmentation methods have the potential for various applications, such as image editing and human-robot interaction. The existing approaches rely on predefined sets of training categories and cannot recognize categories that were not present during training, limiting their practical applicability. To overcome this limitation, the paper proposes a novel approach called Global Knowledge Calibration. This approach includes a text diversification strategy for prompt augmentation and a text-guided knowledge distillation strategy for calibrating the trained model's representation. The paper also explores open-vocabulary video segmentation, providing a benchmark and a simple baseline for future research in this domain. The experimental results demonstrate that the proposed model offers strong generalization performance with a smaller computational cost compared to existing methods.