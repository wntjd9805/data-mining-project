This paper focuses on the extraction of road network information using onboard sensors for self-driving cars. Existing methods have struggled to integrate both Euclidean (landmark locations and centerline curves) and non-Euclidean (road topology) data effectively. The authors propose a unified representation, called RoadNet Sequence, that projects both Euclidean and non-Euclidean aspects onto an integer series domain. This representation ensures losslessness, efficiency, and interaction between the two domains. To extract RoadNet Sequence from camera input, the authors introduce the RoadNetworkTransformer (RNTR), which leverages the sequence-to-sequence generation power of the Transformer model. However, the auto-regressive dependency of RNTR slows down inference speed. To address this, the authors propose the Semi-Autoregressive RoadNetTransformer (SAR-RNTR), which decouples the dependency into a semi-autoregressive format. By applying a masked training technique, they further improve speed and accuracy, leading to the Non-Autoregressive RoadNetTransformer (NAR-RNTR). The paper introduces new evaluation metrics for road network extraction quality and presents extensive experiments on the nuScenes dataset to validate the superiority of RoadNet Sequence and RoadNetTransformer over alternative methods.