This paper addresses the problem of incomplete shapes in 3D scans and the need for shape completion in practical applications. The authors classify current learning-based shape completion methods into two categories: volumetric representation and point cloud based methods. While volumetric representations provide accurate shapes, they come with high memory expenses. On the other hand, point cloud based methods are memory-efficient but struggle to recover detailed structures. To tackle this limitation, most existing methods adopt a coarse-to-fine approach. However, they overlook the importance of the scanning viewpoint in the completion process.To address this issue, the authors propose unsupervised viewpoint representation learning using a contrastive learning approach. This enables the generation of distinct latent representations for incomplete objects. By learning abstract representations to distinguish between different viewpoints, discriminative viewpoint representations can be obtained. The proposed method does not require supervision with ground-truth viewpoints, making it suitable for real-world applications.The authors introduce the Viewpoint-Aware Point cloud Completion Network (VAPCNet) that incorporates viewpoint information for feature adaptation. This is achieved by predicting convolutional kernels and modulated self-attention for local information aggregation from the viewpoint representation. Experimental results on the MVP and PCN datasets demonstrate the effectiveness of the proposed network.The contributions of this paper include a novel formulation of point cloud completion with unsupervised viewpoint representation learning, an effective viewpoint-aware module for accurate point cloud completion, and state-of-the-art completion results on both MVP and PCN datasets.