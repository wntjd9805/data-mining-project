This paper addresses the limitations of current computer-aided detection (CAD) tools in the field of radiology by proposing a new dataset and a novel computing architecture. The authors curate a large CT image dataset that includes eight major cancers, confirming all tumor types by surgical or biopsy pathology. The tumors are manually segmented in 3D by specialized radiologists. The dataset aims to enable the development of a universal multi-cancer imaging reading AI model that can assist radiologists in precision detection, quantification, and diagnosis. The authors also propose a new computing architecture called Unified Tumor Transformer (CancerUniT) that simultaneously solves the tasks of multi-tumor detection, segmentation, and diagnosis. CancerUniT represents each organ and tumor as an object query in a semantic hierarchy, facilitating the learning of inter-organ and intra-organ relationships. The proposed CancerUniT model shows superior performance compared to existing models, achieving higher sensitivity, specificity, and diagnostic accuracy in tumor detection across all organs. The findings of this study have implications for improving cancer detection and diagnosis in clinical practice.