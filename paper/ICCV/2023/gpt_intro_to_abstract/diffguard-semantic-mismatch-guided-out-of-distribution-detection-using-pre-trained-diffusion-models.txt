The introduction of the paper discusses the importance of out-of-distribution (OOD) detection in deep learning models, as the assumption of independent and identically distributed (i.i.d.) data often does not hold true in real-world scenarios. The paper introduces DIFFGUARD, a semantic mismatch-guided OOD detection framework based on diffusion models. DIFFGUARD utilizes information from the classifier-under-protection to address the problem of lack of consideration for the classifier's output semantics in diffusion models. Several test-time enhancement techniques are proposed to balance the guidance between the input image and the label condition during generation. The effectiveness of the proposed framework is evaluated on the OpenOOD benchmark, showing superiority or comparable performance to existing OOD detection solutions. The contributions of the paper include the diffusion-based framework for detecting OODs, the proposed test-time techniques to enhance conditioning, and achieving state-of-the-art performance on CIFAR-10 and strong differentiation ability on hard OOD samples of IMAGENET. The rest of the paper is organized into sections discussing related OOD detection methods, diffusion models, the proposed framework, experimental results, limitations, and future works.