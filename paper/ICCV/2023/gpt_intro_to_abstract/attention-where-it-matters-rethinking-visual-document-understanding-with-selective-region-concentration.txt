Document image understanding is a crucial task in today's world where the volume of digital documents is increasing rapidly. Current approaches rely on multi-stage technical schemes utilizing optical character recognition (OCR) and other modules. However, these approaches are suboptimal and computationally expensive. To overcome these challenges, we propose SeRum, a selective region understanding model that simplifies the pipeline by directly generating text output for key visual tokens from the image. SeRum utilizes a vision Transformer-based encoder to extract document image features and a self-encoding Transformer query decoder for local decoding of visual tokens. Additionally, a content-aware token merge mechanism is introduced to enhance regional information and constrain attention to regions of interest. Our approach achieves competitive results in word recognition and offers a valuable step towards efficient end-to-end document understanding. Experimental results on public datasets demonstrate state-of-the-art performance on document understanding tasks and competitive results on text spotting tasks. Overall, SeRum has potential applications in automatic document analysis, information extraction, and text recognition.