This paper introduces the problem of referring video object segmentation (R-VOS), which aims to segment a specific object in a video given a linguistic expression. Previous studies have addressed the R-VOS problem with the assumption that the referred object appears in the video, limiting its practical application. This paper proposes a new task, called Robust R-VOS (R2-VOS), which analyzes the semantic consensus between video and language inputs and discriminates between positive and negative pairs. The paper introduces a cyclic structural consensus (CSC) measure to enhance segmentation quality and accommodate linguistic diversity. The authors propose a R2-VOS network that enables end-to-end training of the primary segmentation and dual expression reconstruction task. The proposed method achieves state-of-the-art performance on popular datasets.