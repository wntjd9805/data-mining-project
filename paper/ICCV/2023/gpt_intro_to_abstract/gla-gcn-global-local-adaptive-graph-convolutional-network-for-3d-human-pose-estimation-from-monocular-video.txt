3D Human Pose Estimation (HPE) in videos is an important task with various applications such as video surveillance and human-robot interaction. While 3D HPE can be directly retrieved from advanced motion sensors, it is more cost-effective to perform it using ordinary RGB monocular cameras. Recent works on monocular view 3D HPE can be categorized into model-based and model-free methods, with model-free methods achieving better performance. Among model-free methods, 2D to 3D lifting methods have shown advantages in utilizing 2D human pose detection and temporal information. However, existing methods using ground truth 2D poses still fall behind in performance compared to those using ground truth 3D poses. This motivates our focus on improving 3D HPE using ground truth 2D pose data. In this paper, we propose a Global-local Adaptive GCN (GLA-GCN) model for 2D to 3D human pose lifting. GLA-GCN leverages global spatiotemporal representation and local joint representation in a graph convolutional network-based architecture. Our model outperforms state-of-the-art methods and achieves significant error reductions on benchmark datasets.