Visual Question Answering (VQA) is a challenging task in computer science where a machine needs to understand a question, perceive an image, and produce an answer. However, little attention has been given to the robustness of VQA systems, particularly in handling unanswerable questions (UQs) that cannot be answered by image inspection. This lack of robustness can lead to safety hazards and reduced user trust in VQA models. In this paper, we propose a realistic VQA (RVQA) system that can accurately reject UQs and correctly answer answerable questions (AQs). We curate a new evaluation dataset, RGQA, consisting of both AQs and UQs to measure the performance of RVQA models. To address the limitations of existing formulations, we introduce unsupervised training strategies using pseudo UQs, RoI Mixup, and model ensembling. Our experiments demonstrate the effectiveness of these methods, outperforming prior RVQA models. We also show that our proposed models have room for improvement compared to human performance, which motivates future research in the RVQA problem. Overall, our contributions include a new evaluation dataset, an unsupervised training strategy, and improved RVQA models.