Accurately perceiving 3D structures in urban scenes is essential for safe driving. Semantic occupancy perception, which assigns semantic labels to spatially-occupied regions, is a challenging and promising research direction in autonomous driving. However, most benchmarks in this field focus on indoor scenes, limiting the evaluation and generalization of algorithms. In this paper, we introduce OpenOccupancy, the first benchmark for surrounding semantic occupancy perception in driving scenarios. We extend the large-scale nuScenes dataset with dense semantic occupancy annotation to create nuScenes-Occupancy. To efficiently annotate and densify the labels, we propose the Augmenting And Purifying (AAP) pipeline. We also establish camera-based, LiDAR-based, and multi-modal baselines for the benchmark, showing improved performance on different types of objects and regions. To address the computational burden, we propose the Cascade Occupancy Network (CONet) for efficient occupancy perception. Our contributions include the OpenOccupancy benchmark, the AAP pipeline for annotation, the baselines, and the CONet. We conduct comprehensive experiments on these approaches and modern occupancy perception methods.