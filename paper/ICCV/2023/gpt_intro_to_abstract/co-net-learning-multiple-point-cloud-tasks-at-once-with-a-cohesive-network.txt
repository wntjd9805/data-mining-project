With the advancements in deep neural networks, point cloud analysis has seen significant improvements in tasks such as point classification, segmentation, and detection. However, these methods are inefficient when performing multiple tasks as they are designed for singular tasks. Parallel computing can alleviate this issue, but it introduces additional overheads that can be costly for devices with limited resources. Multi-task learning (MTL) has been introduced in visual tasks to jointly accomplish different tasks from a single image. However, applying MTL to point cloud tasks presents challenges such as finding an optimal backbone for each task and dealing with the discrepancies in gradients under multi-task learning settings. To address these challenges, this paper proposes CO-Net, a unified framework that optimizes multiple point cloud tasks collectively. It introduces a nested layer-wise processing policy that uses NAS technique to find the optimal architecture for each task. Additionally, a sign-based gradient surgery is proposed to eliminate conflicting gradients. Experimental results demonstrate that CO-Net outperforms baselines and can be comparable to state-of-the-art works. Furthermore, CO-Net allows for incremental learning and scaling as the number of tasks increases. The contributions of this work include the proposed CO-Net framework, the nested layer-wise processing policy, the sign-based gradient surgery, and the demonstration of incremental learning with fewer task-specific parameters.