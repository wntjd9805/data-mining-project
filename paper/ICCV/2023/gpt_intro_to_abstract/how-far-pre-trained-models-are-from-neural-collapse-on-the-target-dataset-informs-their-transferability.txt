In recent years, there has been an increase in the availability of pre-trained models in public repositories. These models can be adapted and re-tuned for new tasks, but the challenge is to select the best pre-trained model from a large pool for a downstream task. Traditional methods for ranking these models require fine-tuning each model and comparing test accuracy, which is computationally expensive. Transferability estimation is a line of research that aims to rank pre-trained models on a downstream task without fine-tuning. Current approaches in transferability estimation consider the current status of the models and can be categorized into probabilistic-based and feature distribution-based techniques. This paper introduces a different approach to transferability estimation by measuring the difference between the current status and the hypothetical terminal status of pre-trained models after fine-tuning. The paper proposes a transferability metric based on the observations of neural collapse, which occurs when the training loss approaches zero. The proposed metric analyzes the spectral properties of the class-wise feature matrix, assesses the gap between the pre-trained model features and the geometry of the target features, and calculates the difference between the hypothetical classifier and the nearest neighbor classifier. The paper demonstrates strong correlations between the proposed metric and the transferability of supervised and self-supervised pre-trained models on standard benchmarks. The proposed metric, called the Neural Collapse Transferability Index (NCTI), outperforms existing transferability estimation methods and provides insights for potential unsupervised transferability estimation.