Hand pose estimation, which estimates the 3D positions of hand keypoints, is crucial for various human-computer interaction applications. Deep learning techniques and low-cost depth cameras have improved hand pose estimation, but challenges remain due to hand orientations, self-occlusion, and noisy depth images. Most state-of-the-art approaches use deep convolutional neural networks (CNNs) but struggle to capture the nonlinear mapping from 2D depth images to 3D hand pose. Some approaches use 3D CNNs, but they have high computational overhead. Other approaches use PointNet to convert 2D input images into continuous 3D coordinates. However, these methods have large model architectures and are not suitable for resource-limited devices. In this paper, we propose a novel recurrent architecture, HandR2N2, that dynamically adjusts model capacity for higher accuracy or efficiency. HandR2N2 uses a residual recurrent unit (RRU) with an attentive gate and a channel-wise graph convolutional network (GCN) to iteratively regress accurate 3D hand pose from an input hand point cloud. We evaluate HandR2N2 on benchmark datasets and achieve new state-of-the-art results with lower computational requirements. Our contributions include the novel iterative network architecture, the RRU for refining joint-wise hidden states, and the use of GCN for modeling joint dependencies. Extensive experiments demonstrate the efficiency and effectiveness of our proposed network.