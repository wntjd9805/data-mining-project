Learning from noisy labels is an active research area in deep learning. Noisy labels are common in real-world applications, and trustworthy AI should be robust to mislabeling. Convolutional neural networks (CNNs) have been shown to first learn the actual pattern before overfitting the noise, leading to the development of various training strategies such as early stopping (ES). ES has achieved promising performance in current noisy label models. This paper focuses on investigating the impact of label noise on deep models trained using different image components, specifically the amplitude spectrum (AS) and the phase spectrum (PS). The AS quantifies the presence of sinusoidal components in an image, while the PS reveals the location of each sinusoidal component. Previous studies have shown that human vision relies more on PS for object recognition and that CNNs model the correlation between objects and labels based on the connection between AS and annotations, leading to sensitivity to image perturbation and overconfidence in out-of-distribution detection. The paper presents experimental results using ResNet-18 models trained on CIFAR-10 dataset with raw images, AS, and PS components. The results show that CNNs trained on PS are more robust to label noise compared to those trained on AS, and models trained on raw images perform better than models trained on AS or PS alone. To improve CNNs' robustness to label noise, the paper proposes a solution called Phase-AmplituDe DisentangLed Early Stopping (PADDLES), which disentangles the deep image features into AS and PS at different training steps using Discrete Fourier Transform (DFT) and stops the optimization on AS earlier than on PS. Experimental results show that PADDLES outperforms existing methods in terms of resistance to label noise.