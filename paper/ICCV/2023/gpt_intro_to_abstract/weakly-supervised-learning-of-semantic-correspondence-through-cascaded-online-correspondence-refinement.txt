Learning semantic correspondence between objects in computer vision is a fundamental problem with various applications. However, existing semantic correspondence datasets have limited annotated samples, limiting the generalization ability of algorithms. Building dense semantic correspondence datasets is complex and labor-intensive, requiring the identification of important object parts or salient feature points. In this paper, we propose a weakly supervised learning scheme to learn accurate semantic correspondence from large-scale datasets with only image-level annotations. We introduce a cascaded online correspondence refinement algorithm that integrates image-level, region-level, and pixel-level matching modules in a single network, trained end-to-end. We also create a new dataset called SC-ImageNet, consisting of 679 object categories, 113,516 images, and 794,612 semantic correspondence pairs. Experimental results show that our approach achieves competitive results and strong generalization ability, benefiting subsequent fine-tuning processes.