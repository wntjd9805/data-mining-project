Gait recognition is an important task in the field of human identification, allowing for the capture of long-distance gait features without subject cooperation. Existing studies on gait recognition can be categorized into appearance-based and model-based methods. Although appearance-based methods have been dominant, model-based methods offer robustness to carrying and clothing. However, a crucial problem in these methods is the lack of generalization ability across different environments. In this paper, we propose a framework called Generalized Pose-based Gait Recognition (GPGait) to improve the generalization ability of model-based methods. We introduce a Human-Oriented Transformation (HOT) and a series of Human-Oriented Descriptors (HOD) to obtain a unified and enriched representation of gait sequences captured from different cameras. Additionally, we present a Part-Aware Graph Convolutional Network (PAGCN) to capture fine-grained features and local-global relationships within the gait data. Through extensive experiments, we demonstrate that GPGait achieves state-of-the-art generalization results across different scenarios, outperforming previous methods by a significant margin.