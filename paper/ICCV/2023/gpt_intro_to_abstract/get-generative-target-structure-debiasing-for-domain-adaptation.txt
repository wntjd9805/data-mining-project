Despite the success of deep learning in various domains, most deep learning models assume that the training and test data have similar distributions, which is known as the domain shift problem. To address this issue, many domain adaptation (DA) techniques have been proposed. Unsupervised DA aims to transfer knowledge from labeled source data to unlabeled target data with domain shift. Other variants of DA include partial-set DA and semi-supervised DA. Most DA approaches focus on learning domain-invariant features or utilizing semi-supervised learning techniques. However, these methods often suffer from source domain bias or class distribution bias in the target domain, which affects the performance of pseudo label generation. In this paper, we propose an online target generative classifier called GeT to generate debiased and discriminative pseudo labels for DA tasks. The GeT consists of a Gaussian mixture model (GMM) and a structure similarity regularization. The GMM induces target feature distribution into distinctive Gaussian components, reducing source data bias and enhancing target class discriminability. We also introduce an auxiliary distribution that is controlled with entropy maximization to mitigate class distribution bias and improve pseudo label quality. We jointly optimize the generative classifier and the structure similarity regularization in an iterative classification expectation maximization framework. Our contributions include the proposal of the online target generative classifier, the introduction of the structure similarity regularization, the development of the classification expectation maximization scheme, and the achievement of competitive results on various DA settings and benchmark datasets.