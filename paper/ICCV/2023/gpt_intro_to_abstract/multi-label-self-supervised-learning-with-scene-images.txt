Self-supervised learning (SSL) methods based on contrastive learning have proven successful for downstream tasks, particularly those targeting object-centric images. However, there has been a recent push for SSL methods that focus on scene images, which are more natural and richer in semantics. Various SSL methods for scene images have emerged, falling into two categories: dense matching and unsupervised object discovery. Dense matching methods consider feature locations to improve performance on dense prediction tasks, while unsupervised object discovery methods find local object contents and incorporate scene-level semantics. However, these methods often require expensive pretraining on top of box generation. Most scene image SSL methods are based on the contrastive loss, which assumes single-label images, creating a mismatch with the multi-label input data. This paper proposes a new approach called Multi-Label Self-supervised learning (MLS) for scene image SSL. MLS treats each image or randomly cropped patch as a semantic bag with multiple objects, retrieving similar images from a large dictionary. The patch's embedding is used to select top similar embeddings as positive images and the rest as negatives. The BCE loss and binary pseudo-labels are then used to classify the patch's embedding and optimize the backbone network. The MLS method achieves state-of-the-art results on object detection, instance segmentation, and classification benchmarks for scene images. The contributions of this work include formulating scene image SSL as multi-label classification, proposing the MLS approach, and demonstrating its effectiveness through extensive experiments and ablation studies. MLS is a simple and intuitive method that provides diverse positive samples and allows for the co-occurrence of multiple classes in scene images.