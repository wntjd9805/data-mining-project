Real-world environments often have independently moving objects, which is important for robot navigation and augmented reality. However, traditional and deep learning algorithms for 3D reconstruction assume static scenes and treat moving objects as outliers. This results in suboptimal results when the scene is dynamic. In this paper, we propose a new approach called Multi-Body Structure-from-Motion (MBSfM) to enable consistent 3D reconstruction of scenes with multiple rigidly moving objects. Traditional MBSfM methods segment rigid motions to obtain partial reconstructions of individually moving objects, but they are limited by the relative scale problem and cannot achieve a unified reconstruction of all objects. We address this problem by developing a deep learning framework that includes a robust scale estimation to fix the scale ambiguity and a multi-body plane sweep network to regress refined camera poses and depth maps in multi-body scenes. Our approach outperforms existing methods in depth estimation for multi-body scenes and achieves comparable results in camera pose estimation.