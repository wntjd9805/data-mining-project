Automatic 3D content creation using large language models has gained attention in various industries. Traditional methods of creating 3D assets are labor-intensive and involve multiple stages resulting in imperfections. This paper focuses on automatic 3D content creation from text prompts using a novel method called Fantasia3D. Fantasia3D disentangles the modeling and learning of geometry and appearance, allowing for fine recovery of geometry and photorealistic rendering. The proposed method utilizes a hybrid representation for geometry learning and introduces spatially varying Bidirectional Reflectance Distribution Function (BRDF) for appearance modeling. The effectiveness of Fantasia3D is demonstrated through experiments, showing its superiority in high-quality and diverse 3D content creation. The contributions of this work include the introduction of Fantasia3D, a disentangled framework for text-to-3D content creation, and the incorporation of BRDF modeling for photorealistic rendering.