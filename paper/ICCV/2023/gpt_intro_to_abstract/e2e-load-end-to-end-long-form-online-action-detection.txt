This paper addresses the problem of Online Action Detection (OAD) in computer vision and introduces a novel approach called E2E-LOAD (End-to-End Long-form Transformer for OAD). Existing methods in OAD rely on pre-trained networks and suffer from limitations in balancing performance and computational costs. E2E-LOAD utilizes a "Space-then-Space-time" paradigm, buffering features from raw video frames to reduce computational overhead and enable processing of extended historical sequences. It also employs an asymmetric architecture for efficient long-form feature extraction and introduces a token re-usage strategy for faster spatiotemporal interactions on extended video clips. Experimental results on three public datasets demonstrate that E2E-LOAD achieves superior effectiveness and efficiency compared to other methods. The proposed framework integrates a stream buffer and an efficient online data processing mechanism, leading to significant advancements in accuracy and inference speed.