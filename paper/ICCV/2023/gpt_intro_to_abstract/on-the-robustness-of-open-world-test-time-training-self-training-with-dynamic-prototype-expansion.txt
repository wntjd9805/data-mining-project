The distribution gap between training and testing data in deep learning poses challenges to model generalization. Domain adaptation has been studied to learn domain invariant features but requires access to both source and target domain data. Test-time training (TTT) is a new paradigm that enables adaptation at inference time when target domain data is unavailable during training. TTT has shown success on various scenarios but its capability is not fully explored. In this work, we focus on the open-world scenario where the target domain may contain strong out-of-distribution (OOD) samples. We empirically evaluate existing TTT methods and show that they suffer from strong OOD samples. We propose two techniques to improve the robustness of TTT: a baseline method based on self-training with prototype clustering and a strong OOD detector, and regularization with distribution alignment. We also create an open-world TTT benchmark and our approach achieves state-of-the-art performance. This work highlights the importance of improving TTT in realistic scenarios.