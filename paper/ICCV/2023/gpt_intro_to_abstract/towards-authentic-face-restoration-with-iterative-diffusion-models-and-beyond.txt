Face images play a crucial role in various applications, but real-world scenarios often introduce image degradations. Recent advancements have focused on blind face restoration to transform low-quality photos into high-quality ones. Existing methods utilize pretrained networks and auxiliary information to recover facial features. However, these methods still struggle with preserving delicate identity features, generating artifacts, and maintaining high-frequency details. The limitations may stem from model design choices and the quality of training data. Evaluating restoration models based on noisy ground-truth data can also be problematic. To address these challenges, we propose using conditional denoising diffusion models (DDMs) with iterative learning. DDMs offer intrinsic iterative refinement and extrinsic iterative enhancement, resulting in better degradation removal and detail preservation. Our approach can automatically clean data without extensive annotation and provide authentic restoration and accurate evaluation. Moreover, the proposed model's benefits extend beyond restoration, improving the quality of training data and enhancing generative models. We demonstrate the effectiveness of our approach through empirical results on blind face restoration and image generation benchmarks, showing superior performance compared to state-of-the-art methods.