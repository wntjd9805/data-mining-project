Deep-learning-based methods for data compression have shown superior performance in rate-distortion performance compared to classical codecs. However, their high computational complexity, especially for decoding, hinders their widescale adoption. In this study, we replace deep convolutional decoders with lightweight and shallow (even linear) decoding transforms, inspired by the parallel between nonlinear transform coding and traditional transform coding. We aim to establish the rate-distortion performance of neural image compression at the lower limit of decoding complexity. Our contributions include offering new insights into the image manifold parameterized by learned synthesis transforms in nonlinear transform coding, studying the effect of linear synthesis transform within a hyperprior architecture, providing a theoretical analysis of the rate-distortion cost of neural lossy compression, and equipping our JPEG-like synthesis with powerful encoding methods to achieve state-of-the-art results in the trade-off between rate-distortion performance and decoding complexity. Through our research, we shed light on the role of nonlinearity in the perceptual quality of neural image compression and quantify the performance implications of varying the complexity of encoding and decoding procedures.