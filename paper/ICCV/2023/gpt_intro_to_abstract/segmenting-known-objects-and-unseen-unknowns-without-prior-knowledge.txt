Neural networks have achieved remarkable performance in perception tasks such as object detection and semantic segmentation. In safety-critical applications like autonomous driving and robotics, it is crucial to ensure the robustness and generalization of these networks. However, current datasets do not fully capture the diversity of the real world, leading to difficulties in handling out-of-distribution data. Additionally, state-of-the-art methods tend to be overly confident even on incorrect predictions, which can be problematic in safety-critical scenarios. Estimating uncertainty in model outputs is considered essential for safe applicability. While previous works have addressed these challenges for image classification and object detection, they remain unexplored for dense tasks like semantic and panoptic segmentation. In panoptic segmentation, the problem of assigning unseen objects to known classes is more severe due to the need for predictions for every input unit. Therefore, new methods are being designed to improve robustness against unseen scenarios. This paper proposes a new setting called holistic segmentation, which involves identifying and segmenting unseen unknown object categories without any external or prior knowledge. It introduces the U3HS framework, the first panoptic framework to handle unseen, unknown object categories and provide uncertainty measures for its outputs. The contributions of this paper include the introduction of the holistic segmentation setting, the development of the U3HS framework, and the provision of uncertainty measures for improved safe applicability.