Deep neural networks have shown excellent performance in computer vision tasks when the training and test sets have the same distribution. However, in real-world applications, there are often domain shifts between the training and test sets, which results in reduced performance and hinders confident deployment. This is particularly critical in safety-critical applications like tumor recognition and autonomous driving. Image data consists of various attributes such as shape, color, background, and texture. Some attributes are task-related, referred to as labels, while others are domain-specific and cause distribution shifts, ultimately weakening model generalization. To address this, data augmentation coupled with consistency regularization is commonly used to make models invariant to the domain-specific attributes. By perturbing the data and imposing consistency regularization on the representations before and after perturbation, the model becomes less sensitive to the domain-specific attributes.Existing consistency regularization methods can be categorized into two approaches: representation-based methods and prediction-based methods. Representation-based methods employ ℓ1 or ℓ2 loss to enforce consistency in model output representations, but they can lead to training difficulties and model collapse. Prediction-based methods use cross-entropy loss to regularize maximum classification probabilities. However, these methods ignore the order of other classes, reducing the model's discriminability.To address these challenges, we propose Order-preserving Consistency Regularization (OCR) for cross-domain tasks. OCR enhances model robustness to domain-specific attributes without requiring an asymmetric architecture or stop gradient. By computing the residual component, which represents the variation between augmented and original representations, OCR minimizes task-related information in the residual component. This is achieved by regularizing the classification probabilities of the residual component to be the same for each category. Consequently, OCR preserves the order of classification probabilities before and after augmentation, making the model less sensitive to domain-specific attributes. The contributions of this paper are threefold: First, we propose OCR as a method for enhancing model robustness to domain-specific attributes. Compared to representation-based methods, OCR allows different representations for two views of the same image, relaxing model constraints during training. Compared to prediction-based methods, OCR preserves the order of classification probabilities, improving model sensitivity to domain-specific attributes. Second, we provide a theoretical analysis of OCR, showing that representation-based methods are a special case of OCR and that OCR reduces the mutual information between domain-specific and label attributes. Third, we evaluate OCR on five cross-domain vision tasks, demonstrating its effectiveness in enhancing model robustness, particularly against adversarial attacks.