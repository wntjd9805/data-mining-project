In recent years, deep neural networks have achieved remarkable results in classification, thanks to regularization techniques such as Dropout and Dropblock that reduce overfitting. However, these techniques assume that the training and test data follow similar distributions. In a domain generalization setting, where there is a distribution shift between the train and test set, models with classical regularization techniques often fail to generalize well. In this paper, we aim to build a model that is robust to domain shift and performs equally well on both source and unseen test domains. We propose a dropout strategy based on the Gradient Signal to Noise Ratio (GSNR) to drop parameters with the highest GSNR in each training step. This improves the overall GSNR of the model and enhances generalization performance. Additionally, we use a learning-to-learn technique to dynamically learn the dropout probability for each neural network block, instead of using a fixed and manually chosen value. We conduct extensive experiments on benchmark domain generalization datasets for classification and face recognition tasks, and our approach outperforms existing methods. Our contributions include the introduction of a novel dropout strategy based on GSNR, a meta-learning framework to alleviate the problem of selecting optimal dropout ratios, and empirical validation on various domain generalization benchmark datasets.