Multi-Object Tracking (MOT) is a crucial task in computer vision, with applications in video surveillance, autonomous vehicles, and sports analysis. However, occlusion in crowded scenes often leads to fragmented tracklets and ID switching, posing a significant challenge. One solution is Multi-Camera Multi-Object Tracking (MC-MOT), where information from multiple cameras is leveraged to overcome occlusion. Existing graph-based models for MC-MOT have limitations, relying on single-camera trackers and not fully utilizing spatial and temporal information. To address these issues, we propose a Reconfigurable Spatial-Temporal (ReST) graph model for MC-MOT. Our model divides the problem into Spatial Association and Temporal Association sub-tasks, optimizing spatial and temporal consistency separately. A Graph Reconfiguration module aggregates information from both models, resulting in better tracking results. We demonstrate the effectiveness of our model through experimental evaluation on benchmark datasets. Our contributions include formulating MC-MOT as two sub-tasks, proposing a Graph Reconfiguration module, and achieving state-of-the-art performance on the Wildtrack dataset.