This paper focuses on the problem of image retrieval for visual localization in large-scale scenes. Most modern approaches rely on 3D point clouds derived from image collections using Structure-from-Motion (SfM). To effectively localize a query image, local features are extracted and 2D-3D correspondences are estimated. However, challenges such as visual aliasing and scene change can hinder the data association process, leading to localization failure. The conventional approach of establishing numerous matches per query keypoint causes long runtime in geometric verification. Therefore, it is important to find a small set of 2D-3D correspondences that are likely to contain correct matches. Various approximations have been proposed, but they often rely on global image embeddings and do not jointly solve for appearance and geometry using local features. In this paper, we propose a new method called Constrained Approximate Nearest Neighbors (CANN) that efficiently obtains a high-quality set of 2D-3D correspondences. CANN performs constrained nearest neighbor search in descriptor space, ensuring compact matches in 3D space. We also establish a connection between colored nearest neighbor search and image retrieval and localization, introducing a metric to rank cameras. Furthermore, we evaluate both global and local feature-based methods on four large-scale datasets, demonstrating that local feature-based methods outperform global embedding-based approaches. This challenges the prevailing trend and emphasizes the importance of jointly searching in appearance and geometry space.