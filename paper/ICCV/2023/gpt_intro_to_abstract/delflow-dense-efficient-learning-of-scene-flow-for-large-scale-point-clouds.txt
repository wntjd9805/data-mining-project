Scene flow estimation, which represents the motion between frames in terms of magnitude and direction, is crucial for various autonomous driving tasks. Existing methods for 3D scene flow estimation can be categorized into voxel-based, point-based, and grid-based approaches. However, voxel-based methods are computationally expensive, while point-based methods suffer from memory and time inefficiencies. Grid-based methods, on the other hand, struggle with outliers and lack flexibility. To address these challenges, we propose a projection-based framework for scene flow learning from dense point clouds. We project the 3D point clouds onto a 2D image plane, enabling efficient processing of complete point clouds. We also introduce a Kernel Based Grouping method to capture 3D geometric information on a 2D grid, reducing memory consumption and query complexity. Additionally, we tackle the feature fusion challenge between point clouds and images by utilizing the dense format of projected point clouds, eliminating the density gap between points and pixels. Our approach also incorporates a warping operation in the cost volume module to refine the predicted flow, avoiding information loss caused by point merging. Overall, our contributions include an efficient scene flow learning framework, a novel cost volume module with a warping projection technique, and a pixel-point feature fusion module for improved scene flow estimation accuracy.