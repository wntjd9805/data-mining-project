Creating human avatars for immersive media requires user-friendly solutions that offer intuitive control, immediate application readiness, and high quality. Existing approaches using reference images or text prompts have limitations in terms of ease of use and quality. This paper focuses on text-guided avatar creation using Contrastive Language-Image Pre-Training (CLIP) and diffusion models. By leveraging neural implicit fields and the SMPL model for animation, the proposed method achieves high-quality results in terms of consistency and realism. The multi-scale training strategy and shape regularization method further enhance the overall performance. The contributions of this paper include the development of a text-guided method using diffusion models, the ability to easily animate and reshape avatars using only pose and shape parameters, and the capability to composite avatar radiance fields with real scenes for realistic occlusion-aware view synthesis.