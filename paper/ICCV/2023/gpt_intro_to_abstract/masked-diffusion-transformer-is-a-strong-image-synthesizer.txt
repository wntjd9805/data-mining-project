This paper introduces Diffusion Probabilistic Models (DPMs) as a powerful tool for image-level generative models. DPMs have been shown to outperform previous state-of-the-art generative adversarial networks (GANs) and have been successful in applications such as text-to-image generation and speech generation. However, the training process for DPMs is time-consuming due to the large number of time steps required for convergence. In this paper, the authors propose an effective Masked Diffusion Transformer (MDT) to improve the training efficiency of DPMs. MDT incorporates a mask latent modeling scheme to enhance contextual learning and improve the learning of associated relations among object parts in an image. Experimental results demonstrate that MDT achieves superior performance in image synthesis tasks and significantly reduces training time compared to previous DPM approaches. The proposed method sets a new state-of-the-art in class-conditional image synthesis on the ImageNet dataset. The contributions of this paper include the introduction of the mask latent modeling scheme and the development of the MDT method, which improves DPM training efficiency and enhances contextual learning ability.