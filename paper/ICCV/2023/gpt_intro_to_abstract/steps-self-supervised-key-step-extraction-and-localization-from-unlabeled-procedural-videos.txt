Rapid shifts in technology and business models have created a skills gap between employers and the labor force, resulting in reduced manufacturing output. Efforts to reskill workers have gained attention, but the complexity of tasks and the years of training required pose challenges. Augmented Reality (AR) headsets have shown promise in improving training efficiency and on-the-job performance across diverse industries. In this paper, we propose an approach using AR headsets to automatically extract key steps of complex tasks for content creation. Our approach utilizes a "learning-from-observation" framework, where recordings of expert performance are analyzed to identify key steps. We capture data on a Microsoft HoloLens 2 for the task of changing a printer cartridge, and generate key steps using multiple cues such as hand pose and eye gaze. The key step extraction problem is challenging due to limited expert recordings, subjective nature of key steps, and lack of large-scale datasets. To address these challenges, we propose a two-stage approach that trains a task-specific model to produce context-rich feature vectors for each frame of the recording. We introduce a novel loss called BMC2, which enforces temporally adapted features from different cues to be close in a common latent space. Our approach is suitable for both wearable devices and conventional procedural task videos. We provide quantitative and qualitative results on multiple datasets, demonstrating superior performance compared to prior works. Our contributions include the proposal of an intra-video self-supervised learning approach, the use of multiple synchronized cues, and the development of a low-complexity SSL module for improved performance on various tasks.