Motion prediction is a crucial aspect of autonomous driving systems, as it enables vehicles to understand and plan safe routes in interactive environments. Learning-based approaches have shown promise in improving the accuracy of motion prediction by utilizing large-scale real-world driving datasets. However, most existing studies focus on generating marginal predictions of future trajectories for individual agents, without considering their future interactions. This limitation can lead to unreliable results for downstream planning modules. To address this, recent works propose joint motion prediction models that generate scene-compliant trajectories. However, these models still struggle to capture future interactions effectively. This paper introduces Bi-level Future Fusion (BiFF), a novel model that incorporates High-level Future Intention Fusion (HFIF) and Low-level Future Behavior Fusion (LFBF) mechanisms to generate scene-consistent goals and predict scene-compliant trajectories. The proposed model overcomes the limitations of previous models by designing polyline-based coordinates that provide agent-centric representations without redundant context encoding. Experimental results demonstrate that the proposed approach achieves state-of-the-art performance on the interactive prediction benchmark of the Waymo Open Motion Dataset (WOMD).