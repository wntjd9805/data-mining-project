Real-world datasets often exhibit correlation biases, where an attribute unrelated to the task is correlated with the task label. For example, in the task of distinguishing images of chickens from airplanes, the background of the image may be correlated with the label. A naive classifier trained on such biases may rely heavily on the background rather than the actual task, leading to underperformance on bias-conflicting data. Deep models trained with standard techniques are known to exploit these shortcuts, which can have significant consequences in applications like medicine, face recognition, and autonomous driving.In this paper, we propose a method called FACTS to automatically identify bias-conflicting slices in potentially biased datasets. These slices are subsets of the data where the spurious correlation does not hold. Identifying these slices can inform strategies to mitigate the bias, such as reweighting or annotating underrepresented populations. Our method amplifies correlations to learn a context-aligned decision boundary and then clusters confidently misclassified samples to uncover bias-conflicting slices.Discovering bias-conflicting slices is challenging because annotating and controlling for potentially spurious attributes is difficult and may not scale to larger datasets. Moreover, task labels can be spuriously correlated with latent attributes that may be unknown or not easily interpretable. Previous works have attempted automated solutions, but they have limitations in diagnosing multiple bias-conflicting slices, generalizing to severe correlation bias, or controlling for bias in external models.To address these limitations, FACTS leverages heavily regularized empirical risk minimization to amplify the model's reliance on the spurious correlation. This allows the model to segregate bias-conflicting and bias-aligned samples within each class. The method also uses a novel slicing strategy that fits per-class mixture models in a bias-amplified feature space, ensuring correlation-aware clustering and semantic coherence. FACTS makes limited assumptions and can generalize to challenging evaluation settings not previously considered.The contributions of this paper include studying the problem of automatically discovering coherent and distinct slices in datasets with correlation bias, proposing the FACTS algorithm for slice discovery without additional annotations, and reporting strong results in diverse evaluation settings using multiple datasets.