Temporal action localization (TAL) is the task of localizing the temporal boundaries of action instances and recognizing their categories in videos. While fully supervised methods have achieved great success in TAL, they require manual frame-level annotations, which are expensive and time-consuming. Weakly-supervised TAL (WTAL) has gained attention as it allows for action instance detection using only video-level action labels. Existing WTAL methods use a localization-by-classification pipeline, but foreground and background separation remains a challenge due to the lack of background class cues from video-level labels. Some approaches rely on multiple instance learning to select confident snippets, while others use attention mechanisms to learn foreground weights. However, these methods fail to consider the distribution of all snippets, resulting in inaccurate localization. To address this issue, we propose a clustering-based F&B separation algorithm for WTAL. We use clustering to capture the snippet distribution in a self-supervised manner, which is immune to video classification loss. We argue that clustering multiple clusters of snippets with clear characteristics is easier compared to separate foreground and background clusters. Furthermore, the characteristics of clusters can serve as cues for foreground and background separation. Our proposed Clustering-Assisted F&B SEparation (CASE) network includes snippet clustering and cluster classification components, which are trained using a unified self-labeling mechanism based on optimal transport. Experimental results demonstrate the effectiveness and efficiency of our method compared to existing approaches.