Text images, which are composed of words and characters, often suffer from degraded quality, impairing the readability of the text. To address this issue, scene text image super-resolution (STISR) techniques aim to reconstruct clear and legible text contents. Traditional methods rely on manual design and priors, resulting in limited performance. Deep learning-based STISR approaches utilize convolutional neural networks (CNNs) trained on low-resolution (LR) and high-resolution (HR) text image pairs to learn complex text priors and reconstruct high-quality text images. While synthetic datasets have been widely used, they do not adequately capture real-world degradations, leading to limited performance on real-world LR text images. To overcome this limitation, the TextZoom dataset was introduced, but it is restricted to English texts with simple structures. This poses challenges for STISR on more complex languages like Chinese. Additionally, TextZoom focuses on fixed-size text images, limiting generalization to texts of various resolutions. To address these limitations, this work proposes the Real-CE dataset, a novel real-world Chinese-English benchmark for training and evaluating STISR models on both languages, featuring various resolutions and complex stroke structures. The dataset provides detailed annotations and employs an edge-aware learning method to enhance the reconstruction quality of Chinese texts. Experimental results demonstrate the superior performance of models trained on the Real-CE dataset compared to TextZoom for Chinese text super-resolution. The paper concludes with a description of the organization of the subsequent sections.