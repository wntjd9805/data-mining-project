Semantic segmentation has made significant advancements in recent years with the help of deep neural networks. However, generating a single segmentation output may not be suitable for safety-critical domains like medical diagnostics and autonomous driving, where images often suffer from ambiguity or differences in annotation. In such cases, multiple correct segmentation maps may be necessary to accurately describe the set of correct labels. This requires stochastic semantic segmentation methods to predict conditional distributions of labels given an image, which is challenging due to the multimodal distribution, high-dimensional output space, and limited annotation data. Denoising Diffusion Probabilistic Models (DDPMs) have shown promise in learning complex distributions, and they have been successfully applied to various computer vision tasks. While DDPMs have been used for semantic segmentation, their potential advantages for modeling categorical variables and generating diverse segmentation maps have not been explored. In this paper, we propose a conditional categorical diffusion model (CCDM) based on DDPMs for semantic segmentation. This approach explicitly generates label maps of discrete, unordered variables, allowing for the generation of multiple segmentation samples that consider the uncertainty caused by image ambiguity. Our experiments demonstrate that our approach achieves state-of-the-art performance on the LIDC dataset and competitive results on the Cityscapes dataset. Our contributions include the proposal of a conditional categorical diffusion model, achieving state-of-the-art performance on the LIDC dataset, and reporting competitive results on the Cityscapes dataset using a lightweight model.