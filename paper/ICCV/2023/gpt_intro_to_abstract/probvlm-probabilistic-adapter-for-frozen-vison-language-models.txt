ProbVLM is a post-hoc probabilistic adapter that converts deterministic embeddings from large-scale vision-language models into probabilistic ones. By modeling the inherent ambiguities in different modalities, ProbVLM learns distributions that provide well-calibrated uncertainty estimates. Unlike previous methods, ProbVLM retains the benefits of large-scale pre-training without requiring training from scratch. The method is evaluated on COCO, Flickr, CUB, and Oxford-Flowers datasets, demonstrating calibrated uncertainties and the ability to select optimal models and samples for fine-tuning. Additionally, a pre-trained latent diffusion model is used to visualize the predicted embedding distributions, showing meaningful modes of variation.