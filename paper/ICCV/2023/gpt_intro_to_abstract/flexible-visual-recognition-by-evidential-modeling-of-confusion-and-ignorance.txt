This paper introduces a method for explicitly predicting two sources of uncertainty, confusion and ignorance, in visual classifiers. These uncertainties can greatly benefit various tasks such as autonomous driving and medical diagnosis. Existing methods for uncertainty quantification do not distinguish between confusion and ignorance, making it difficult to perform flexible visual recognition. The proposed method models confusion and ignorance separately for each sample, providing valuable information for visual tasks. The effectiveness of the method is extensively validated through various experiments.