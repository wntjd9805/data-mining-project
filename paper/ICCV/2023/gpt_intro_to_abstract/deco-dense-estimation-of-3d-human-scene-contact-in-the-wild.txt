In this paper, we address the problem of modeling and inferring contact from images or videos, which is crucial for applications in human activity understanding, robotics, biomechanics, and augmented or virtual reality. Existing methods in this area focus on specific types of contact or use limited datasets. However, we propose a novel method and a new dataset that aim to represent detailed scene contacts across the full body and infer them from in-the-wild images. To achieve this, we collect a dataset with 3D contact annotations using an interactive labeling tool and train a 3D contact detector that produces dense contact labels on a 3D body mesh. We emphasize the importance of capturing and understanding contact in 3D, as well as distinguishing between different types of contact that support or do not support the body. Moreover, we highlight the challenges in obtaining appropriate training data and propose a solution using dense annotations for in-the-wild images. We demonstrate the effectiveness of our method through detailed quantitative experiments, showing its superiority over existing contact detectors and its impact on improving 3D human pose and shape estimation. Our contributions include the DAMON dataset with dense 3D contact annotations, the DECO regressor for predicting 3D contact, and the integration of estimated contact into a 3D human pose and shape estimation method. All our data, models, and code are publicly available.