Image retrieval systems are used to search large databases for visual contents similar to a query image. The search process typically involves two stages: sorting database images based on high-level similarity to the query, and then refining the results through a reranking process. In recent years, deep learning-based global features have been widely used in the first stage, while geometric matching of local image features is commonly employed in the reranking stage. However, advanced matching processes in the reranking stage have resulted in significant latency and memory requirements. To address this limitation, this paper proposes SuperGlobal, a method that is fully based on global image features for both stages of image retrieval. The authors introduce improvements to the core global feature representation by enhancing pooling strategies. They also present an efficient and effective reranking process that adapts the representation of the query and top-ranked database images in order to estimate their similarities more accurately. Experimental results demonstrate that SuperGlobal outperforms previous methods, achieving new state-of-the-art results in image retrieval benchmarks. Notably, the proposed reranking mechanism is more than four orders of magnitude faster and requires significantly less memory compared to complex methods, while achieving higher accuracy.