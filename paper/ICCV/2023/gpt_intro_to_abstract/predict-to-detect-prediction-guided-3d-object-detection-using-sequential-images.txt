The task of 3D object detection is crucial for developing reliable self-driving systems. Camera-based 3D object detection has become popular due to its cost-effectiveness and high-resolution capabilities. However, it still has limitations in performance due to scale ambiguity and the absence of motion cues. Recent research has addressed these issues by leveraging temporal information from multiple frames. While previous works have utilized temporal images in feature-level aggregation or used temporal stereo to enhance depth estimation, they have not thoroughly investigated the motion cues of objects, which are important for object detection using sequence images. This study explores the importance of motion cues in detection and proposes a novel sequential image-based 3D object detection model called P2D (Predict to Detect). P2D incorporates a prediction scheme that uses previous frames to predict objects' information for the current frame. In the feature aggregation module, a deformable attention mechanism is employed to create a spatio-temporal feature based on the prediction results. The 3D detection head then takes the aggregated spatio-temporal feature and outputs the final detection results. Experimental results demonstrate the effectiveness of the proposed approach, and it outperforms previous state-of-the-art methods in adapting to moving objects and accurately estimating their velocities. The contributions of this research include identifying motion features as a key factor in sequential image-based 3D object detection, proposing a novel detection model that leverages motion cues, and achieving improved performance compared to existing methods.