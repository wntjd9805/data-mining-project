This paper addresses the challenge of reconstructing the shape of hand-held objects for AI to understand human activities. Previous works have focused on reconstructing objects with known template shapes, but these methods fail on unseen object instances. To address this limitation, the authors propose a deep-learning model called CHORD that leverages shape information from a known template while also generalizing well to unseen instances. CHORD utilizes a categorical object shape prior to reconstruct the surface of unseen objects. The authors also introduce a new dataset, COMIC, for category-level hand-object reconstruction. Extensive evaluations demonstrate that CHORD outperforms state-of-the-art methods and generalizes effectively to unseen instances. The contributions of the paper include the proposal of the CHORD model, the incorporation of appearance, shape, and interacting pose awareness in CHORD, and the introduction of the COMIC dataset.