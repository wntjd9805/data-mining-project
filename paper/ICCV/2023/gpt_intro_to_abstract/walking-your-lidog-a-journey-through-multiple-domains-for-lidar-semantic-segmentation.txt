This paper addresses the challenge of achieving accurate and robust semantic segmentation of LiDAR point clouds. LiDAR semantic segmentation (LSS) is a fundamental problem in mobile robot navigation, with applications in mapping, localization, and situational awareness. Current state-of-the-art LSS methods perform well when trained and evaluated in the same sensor setup and environment, but their performance degrades significantly when faced with domain shifts caused by differences in sensory settings or recording environments. The paper proposes LiDOG (LiDAR DOmain Generalization) as a method specifically designed for domain generalization in LSS. LiDOG encourages the 3D network to learn features that are robust to variations in sensor type or geographic location by projecting features onto a 2D bird's-eye-view plane. Experimental evaluation shows that LiDOG achieves an improvement in mean intersection-over-union on the target domain, demonstrating its effectiveness in addressing the challenge of domain shifts. The paper presents the first study on domain generalization in the context of LiDAR semantic segmentation and provides a test-bed for studying DG-LSS using synthetic and real-world datasets. The proposed LiDOG method achieves state-of-the-art performance in all generalization directions. Overall, this paper contributes to the field of LiDAR semantic segmentation by addressing the challenge of domain shifts and proposing a robust and effective method for domain generalization.