Single image super-resolution (SR) is a prominent research area in computer vision, aiming to restore high-quality images from low-resolution counterparts. CNN-based methods have been the mainstream approach for SR, utilizing techniques such as residual learning, dense connections, and channel attention to construct network architectures. However, recent studies have shown that Transformer-based models, which leverage self-attention for building pairwise relationships, outperform CNN-based models in SR. SwinIR is a notable example of a Transformer-based SR model that achieves state-of-the-art results. A key observation is that enlarging the windows for shifted window self-attention in SwinIR leads to performance gains but also increases computational burden. In this paper, we propose permuted self-attention (PSA) as an efficient method for building pairwise relationships within large windows. PSA reduces the channel dimensions of key and value matrices, conveying spatial information into the channel dimension without sacrificing spatial information or expressive attention maps. We also improve the feed-forward network (FFN) by incorporating a depth-wise convolution between linear layers. We introduce SRFormer, a new SR network based on PSA and the improved FFN. Experimental evaluations on multiple datasets demonstrate that SRFormer consistently outperforms existing methods in various SR tasks, including challenging scenarios and lightweight models. Our contributions include the introduction of PSA for image super-resolution and the development of SRFormer, which achieves state-of-the-art performance in classical, lightweight, and real-world SR tasks.