This paper introduces the problem of 3D pose estimation, which aims to reconstruct the 3D coordinates of a person from a 2D video. The authors focus on the reconstruction of body keypoints to represent human motions. They categorize 3D pose estimation into single-person and multi-person estimation, and primarily tackle the latter. The authors identify three unresolved issues with previous models: robustness to unseen views, occlusion, and jittering in pose sequences. To address these challenges, they propose a novel model called POTR-3D, which leverages a data augmentation strategy to generate training examples and a 2D-to-3D lifting approach to estimate the 3D coordinates. The model also incorporates techniques to handle occlusion and reduce jittering. Overall, the authors demonstrate that POTR-3D outperforms existing methods in robustness, occlusion handling, and producing smoother pose sequences.