Semi-supervised learning (SSL) has shown promise in addressing the shortage of labeled data. However, current SSL methods only work well when the labeled and unlabeled data have similar class distributions. In cases where the class distributions do not match, the accuracy of the pseudo-labels used in SSL can drop significantly, leading to confirmation bias and reduced model performance. This mismatched class distribution scenario is known as Missing Not At Random (MNAR). MNAR is a more realistic setting in SSL, as labeled data is often unevenly distributed and class imbalance is common. In this paper, we propose a novel method called Pseudo-Rectifying Guidance (PRG) to address SSL in MNAR. PRG dynamically tracks class transitions caused by pseudo-rectifying procedures and provides class-level guidance for rectifying pseudo-labels in the next epoch. We model the class transitions using Markov random walk on a graph constructed from the class tracking matrix. By perturbing confident class predictions based on class transition history, PRG improves the quality of pseudo-labels and mitigates the negative effects of MNAR. We evaluate PRG on several SSL benchmarks and demonstrate its effectiveness in coping with SSL in MNAR, outperforming other methods in terms of accuracy. Our approach is computationally efficient and does not require additional network components.