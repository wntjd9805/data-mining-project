Improving the generalization of deep neural networks to out-of-distribution samples is a challenging problem in machine learning and computer vision. Neural networks are typically trained and tested on data samples from the same distribution, but in real-world applications, the distribution of test samples can differ significantly. This creates difficulty in applying semi-supervised learning for domain adaptation. Therefore, there is a need to develop techniques that enable deep neural networks to capture domain-invariant patterns in the data, facilitating improved generalization to out-of-distribution samples.In this paper, we focus on the single-source domain generalization setting, where only one source domain is available for training and no prior knowledge is available about the target domain. Recent work in this area focuses on augmenting the data to simulate the presence of out-of-distribution domains. One approach involves learning-free data augmentation methods, while another approach is based on adversarial perturbations. However, none of the existing work directly augments the data using Bayesian neural networks for domain generalization.To address this gap, we propose a novel approach called Adversarial Bayesian Augmentation (ABA). ABA combines adversarial learning and Bayesian neural networks to generate more diverse data and improve generalization on different domains. Our experimental results demonstrate the superior performance of ABA compared to existing methods. We validate the effectiveness of our proposed method on four datasets, covering three types of domain generalization. Our method outperforms all existing state-of-the-art methods on all four datasets.The key contributions of our paper are: introducing the ABA method, empirically validating its effectiveness on various datasets, and investigating the driving forces behind ABA's ability to generate diverse data. We also conduct a comprehensive ablation study to analyze the impact of model hyperparameters on system performance.