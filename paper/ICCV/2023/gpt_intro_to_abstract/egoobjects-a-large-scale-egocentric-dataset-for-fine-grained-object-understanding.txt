This paper introduces EgoObjects, a large-scale egocentric video dataset for fine-grained object understanding. Unlike existing datasets which are limited in size, domain, and object categories, EgoObjects includes hundreds of object categories commonly found in households and offices worldwide. The dataset consists of over 9,200 videos captured using various wearable devices with different field-of-view, providing representative egocentric visual data formats. Each main object is captured in multiple videos with different variations in nearby secondary objects, background complexity, lighting, viewing distance, and camera motion. The dataset is annotated with bounding boxes, category-level semantic labels, and instance-level object identifiers. EgoObjects is the largest egocentric video dataset in terms of object categories, videos with object annotations, and object instances captured under diverse conditions. The paper also presents four benchmark tasks for both non-continual and continual learning settings, including novel instance-level object detection tasks. A multi-stage federated annotation process is proposed to accompany the continuously growing dataset. The paper concludes by summarizing the contributions of creating the EgoObjects dataset and introducing benchmark tasks, along with evaluating different approaches to these tasks.