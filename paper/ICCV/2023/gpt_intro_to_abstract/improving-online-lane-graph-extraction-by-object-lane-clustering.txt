Accurate road scene understanding is critical for autonomous driving, specifically in the areas of lane graph representation and object detection. Lane graphs define the agent's action environment, while object detection provides information on other traffic agents. While offline generated HD-Maps are commonly used for lane graph representation, online components are required to account for the dynamic nature of traffic scenes. On the other hand, methods such as Bird's-Eye-View occupancy grid representations focus on object detection but lack information on the road network. This paper proposes a network architecture that uses object detection results to improve online lane graph extraction. By utilizing the outputs of object detection methods, the proposed method can adapt to different object detection methods without re-training. The approach includes a novel clustering-based formulation to connect object detections to centerlines, significantly improving performance. Extensive experiments validate the effectiveness of the proposed method compared to state-of-the-art techniques, with superior results on benchmark datasets.