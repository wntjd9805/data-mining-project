Modern cameras are equipped with compound lenses that control the focus of light on the sensor. Adjusting the lens aperture, or f-number, affects the amount of light captured in a photograph, but also induces a depth-dependent blur known as the depth of field (DoF) effect. While some amount of defocus blur is present in images due to non-zero apertures, most computer vision algorithms ignore this effect and assume that the image is entirely in focus. However, this simplifying assumption can result in unwanted effects, particularly in tasks such as virtual 3D object insertion. In this paper, we propose a method for estimating the camera lens parameters that control the DoF effect from a single image, specifically the focus disparity and blur factor. Our approach combines pixel-wise depth and disparity estimation networks with a signed disparity blur model, allowing for the recovery of desired lens parameters via linear least-squares. We also introduce a weighting module to improve accuracy and robustness. Our method produces globally consistent defocus maps and enables applications such as 3D virtual object insertion without relying on post-processing techniques. We conduct a comparative analysis and demonstrate state-of-the-art performance in estimating lens parameters and defocus blur on images with strong DoF effects. The ability to recover lens parameters from a single image enables realistic insertion of 3D objects in shallow DoF images.