In recent years, deep learning has made significant advancements in visual understanding tasks such as semantic segmentation. However, deep learning models require large amounts of high-quality annotated data, which is time-consuming and labor-intensive to acquire. To address this issue, semi-supervised semantic segmentation methods have emerged, aiming to use unlabeled images to improve the performance of segmentation models. Pseudo labeling, a popular semi-supervised learning paradigm, generates pseudo labels for unlabeled images based on a fully supervised model trained on labeled images. However, the use of pseudo labels can lead to overfitting and confirmation bias. Existing approaches tend to discard low-confidence predictions, but this may result in the loss of valuable training samples. In this paper, we propose a Dynamic Soft Label (DSL) method that maintains high-probability classes for each pixel as soft pseudo labels. We argue that low-confidence predictions, which belong to dominant classes, contain valuable supervisory signals for model training. To enhance the DSL, we introduce a pixel-to-part contrastive learning method, along with an unsupervised object-part grouping mechanism, to alleviate ambiguity between dominant classes. Our contributions include the proposal of Enhanced Soft Label (ESL), which leverages the high-value supervisory signals in the pseudo label, and the introduction of pixel-to-part contrastive learning to facilitate learning of class boundaries. We evaluate our method on Pascal VOC and Cityscapes datasets and demonstrate its superior performance.