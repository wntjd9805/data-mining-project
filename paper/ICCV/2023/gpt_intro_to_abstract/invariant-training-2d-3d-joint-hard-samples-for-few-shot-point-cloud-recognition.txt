This paper introduces a solution for the challenging task of few-shot recognition in 3D object point clouds. The traditional approach of projecting point clouds into 2D images for recognition lacks complete geometric information and can suffer from rendering artifacts. Another popular approach involves transferring knowledge from 2D models to 3D models, but this approach does not fully take advantage of the strengths of both domains. The paper proposes a new training strategy called INVJOINT, which focuses on improving collaborative representation across the 2D and 3D domains. The strategy selects joint hard samples, which are samples that are confidently predicted as different wrong labels by each domain, and removes the ambiguous predictions to enhance collaborative recognition. Extensive experiments on synthetic and real-world 3D classification datasets demonstrate the effectiveness of INVJOINT, achieving substantial improvements over existing state-of-the-art approaches. The paper concludes by highlighting the contributions of this work, including the novel approach of combining 2D and 3D for few-shot recognition, addressing the challenge of joint hard samples, and providing a plug-and-play training module with potential for further enhancements.