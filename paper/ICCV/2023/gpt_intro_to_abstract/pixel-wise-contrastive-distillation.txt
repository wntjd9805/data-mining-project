Self-supervised learning (SSL) has shown remarkable progress in computer vision tasks, but this advancement has primarily been observed in larger models. Small models, which are necessary for edge devices and resource-constrained environments, have exhibited inferior performance. In recent years, self-supervised distillation methods have effectively alleviated the performance lag of small models by transferring knowledge from large pre-trained models. These methods have shown competitive performance on classification tasks but have had less pronounced improvement on dense prediction tasks like object detection and semantic segmentation. This study introduces Pixel-Wise Contrastive Distillation (PCD), a pixel-level self-supervised distillation framework that incorporates pixel-level knowledge distillation. PCD allows for more efficient and adequate transfer of knowledge from the teacher to the student by attracting corresponding pixels from the student and teacher feature maps. Additionally, a SpatialAdaptor is introduced to adapt the projection/prediction head used for encoding vectorized features to processing 2D feature maps. The effectiveness of PCD is comprehensively evaluated on various dense prediction tasks, surpassing state-of-the-art results. PCD is also found to be robust to different teacher models and works well with various student backbone architectures. These findings contribute to the future research on self-supervised pre-training with small models.