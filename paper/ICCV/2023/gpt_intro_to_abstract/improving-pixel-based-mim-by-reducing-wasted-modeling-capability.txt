Self-supervised learning (SSL) has shown significant progress in natural language processing and computer vision tasks. In image SSL, Masked Image Modeling (MIM) has emerged as an effective framework, with promising results in downstream tasks. Previous works such as BEiT and MAE have utilized MIM by masking a portion of the input image and training the model to capture the semantics of the masked patches through reconstruction. However, these methods have limitations in effectively capturing both low-frequency semantics and high-frequency detail. In this paper, we propose a new method called Multi-level Feature Fusion (MFF) to address this issue. MFF extends the fusion strategy used in MAE and systematically explores different design choices for incorporating multi-feature fusion. Despite its simplicity, MFF offers several advantages: it improves training efficiency, achieving similar results to the original method in a shorter training period; it consistently enhances performance across various downstream tasks; and it exhibits greater robustness on out-of-distribution datasets compared to the base method. Additionally, we conduct detailed analysis, examining the effect of multi-feature fusion on latent features and optimization. Our findings reveal that the fusion strategy attenuates high-frequency information and flattens the loss landscapes, leading to improved representation learning. In summary, our contributions consist of the development and evaluation of the multi-level feature fusion strategy for isotropic backbones, a comprehensive analysis of its impact on latent features and optimization, and extensive ablation studies that validate the effectiveness of our approach.