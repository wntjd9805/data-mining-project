Cooperation between various vision tasks is necessary for advanced vision applications in autonomous driving and surveillance cameras. These tasks often involve a feature extractor and a prediction head, with most computations focused on the feature extractor. Multi-task learning, which involves sharing the feature extractor among different tasks, can improve inference speed and enhance the general representations produced by the feature extractor. However, multi-task learning faces challenges in balancing the training progress of different tasks with different natures, and in the cost of annotating labels for all tasks.Two major approaches to balancing the training progress are loss scale-based and gradients-based methods. Loss scale-based methods address the difference in loss scales among tasks due to distinct loss functions, but may not balance gradients. Gradient-based methods seek to equalize task gradients at the last shared layer, but task difficulty is not always considered. Annotating labels for all tasks on plenty of images is expensive and time-consuming, leading to a lack of annotations in multi-task datasets.In this paper, we propose a novel multi-task loss that effectively balances the training progress of different tasks without using task gradients. The proposed loss controls training progress based on accuracy achievement, defined as the ratio of current accuracy to single-task accuracy. We also introduce a weighted geometric mean to exploit the scale-invariant property of the loss. Our contributions include the proposal of an achievement-based multi-task loss, the robust evaluation of multi-task losses on a large-scale partially annotated dataset, and the validation of multi-task learning on a partially annotated dataset.Figure 1 illustrates the achievement and task weight curves for different tasks using our proposed method compared to a gradient-based approach. Our proposed method focuses on the challenging task that has lower achievement than others, leading to better multi-task accuracy. We demonstrate that our proposed loss effectively balances the training progress and improves the accuracy of other multi-task losses.