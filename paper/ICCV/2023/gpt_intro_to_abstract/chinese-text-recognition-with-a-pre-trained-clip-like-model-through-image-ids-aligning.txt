Chinese Text Recognition (CTR) faces challenges due to the large number of categories and complex internal structures of Chinese characters. Existing methods for Chinese Character Recognition (CCR) rely on predicting radical or stroke sequences to recognize characters. However, these methods are not suitable for CTR due to their complexity. Moreover, most scene text recognition models require fine-tuning when a new character appears, which is inconvenient. Inspired by how humans recognize Chinese texts, we propose a two-stage framework for CTR. In the first stage, we introduce a CCR-CLIP pre-training model to learn canonical representations of Chinese characters. The model aligns printed character images with their corresponding radical sequences. In the second stage, the learned canonical representations are used to supervise the CTR model. The proposed method achieves superior performance compared to previous methods in both CCR and CTR tasks. Our contributions include the two-stage framework for CTR, the use of CLIP architecture for pre-training, the ability to recognize zero-shot Chinese characters without fine-tuning, and the superior performance of the proposed method in various benchmarks.