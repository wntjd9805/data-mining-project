Diffusion models have become popular in the computer science community due to their impressive performance in image synthesis. These models use a parameterized sampling chain trained with a variational bound to generate images by gradually denoising white noise. While diffusion models have been successful in image synthesis, they have also been utilized in image restoration tasks such as super-resolution, in-painting, and denoising. One notable diffusion-based image restoration framework is DDRM, which has achieved robustness to noise in hyperspectral images (HSIs). However, applying diffusion models to HSI restoration is challenging due to the poor generalization ability of existing methods to various scenarios and the limited availability of training data for HSIs. In this paper, the authors propose a self-supervised Diffusion Spatio-Spectral Model (DDS2M) tailored for HSI restoration. DDS2M reverses the diffusion process using untrained neural networks and a variational inference-based loss function, thus eliminating the need for extra training data. The proposed model leverages the intrinsic structure of HSIs by incorporating untrained spatial and spectral networks. This approach improves the generalization ability of DDS2M to diverse HSI scenarios. The authors conduct extensive experiments on HSI denoising, noisy HSI completion, and super-resolution and demonstrate the superiority of DDS2M in terms of robustness to noise and generalization ability compared to existing state-of-the-art methods in HSI restoration.