The introduction of this computer science paper discusses the success of transformer-based models in natural language processing (NLP) and their extension to computer vision tasks through vision transformers (ViTs). It also highlights the emerging field of machine learning inference as a service (MLaaS) and the privacy concerns associated with it. The paper proposes private inference (PI) methods using techniques such as homomorphic encryption (HE) and secure multi-party computation (MPC) protocols to address these concerns. The focus of the study is on PI for transformers, particularly ViTs. The paper introduces a novel softmax approximation called learnable 2Quad (L2Q) for ViTs, which allows for fine-grained parameter adaptability. It also explores the impact of attention architectures on PI latency and proposes a hybrid approach using external attention (EA) and self-attention (SA) modules with the L2Q approximation to achieve high accuracy and low latency. The paper presents a selective attention search (SAS) method to generate PI-friendly ViT models with a mix of SA and EA modules. The contributions of the paper are summarized as the introduction concludes. Experimental results demonstrate that the proposed method outperforms existing techniques in terms of accuracy and PI latency on various datasets.