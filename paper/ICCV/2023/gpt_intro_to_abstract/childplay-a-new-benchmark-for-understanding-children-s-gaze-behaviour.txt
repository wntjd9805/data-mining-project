Gaze is a non-verbal cue that plays a crucial role in social interactions and human communication, making it a significant focus in human interaction analysis. Gaze extraction and analysis have found applications in various fields such as human-human or human-robot interaction, psychological studies, and medical diagnoses. In particular, understanding children's gaze behaviors is important for their cognitive development, and abnormal gaze patterns have been associated with neuro-developmental disorders like Autism Spectrum Disorder (ASD). However, current methods for analyzing children's gaze are limited by the lack of publicly available datasets that capture their behavior in realistic settings. Existing datasets either focus on adults or are recorded in controlled laboratory settings, making them inadequate for studying the unique gaze behavior of children. To address this gap, we introduce the ChildPlay dataset, which features videos of children interacting in natural environments. The dataset provides high-quality gaze annotations, including a gaze class specifically for 2D gaze following scenarios. We also propose a new model that leverages geometric reasoning and inferred depth maps to predict gaze targets in a more accurate and interpretable way. We introduce the Looking at Head Precision metric to evaluate performance, which captures the accuracy of the model at predicting the category of image regions being looked at. Experimental results on multiple datasets demonstrate that our approach outperforms existing methods, highlighting the need for further research in this area. The ChildPlay dataset and our models are publicly available for future studies.