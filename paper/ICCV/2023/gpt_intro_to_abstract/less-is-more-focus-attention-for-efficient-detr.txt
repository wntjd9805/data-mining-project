Object detection is a crucial task in computer vision that involves predicting the bounding boxes and classes of objects in an image. Recent advancements, such as DETR, have used learnable queries and bipartite graph matching to improve set-based box prediction. However, existing models like DETR suffer from computational burden and inefficiency. In response, Deformable DETR reduces complexity through key sparsification, but still faces challenges in terms of computational burden and latency. Previous works have explored token compression strategies in the transformer encoder, but there is room for improvement in token selection. Sparse DETR, for example, preserves the spatial structure of tokens through query sparsity, but the selected tokens still contain noise and overlook necessary object tokens. Additionally, DAM's supervision in Sparse DETR is inefficient. To address these issues, we propose Focus-DETR, which allocates attention to informative tokens by stacking localization and category semantic information. This approach includes a scoring mechanism for token selection, a foreground token selector, and a multi-category score predictor. By integrating reliable scores and selection from different semantic levels, Focus-DETR enhances foreground tokens and fine-grained object tokens, improving the accuracy of object detection. Our experiments demonstrate that Focus-DETR outperforms existing models, such as Sparse DETR, in terms of accuracy while maintaining computational efficiency. Furthermore, Focus-DETR is compatible with different query construction strategies, making it a versatile solution for DETR-like models.