This paper introduces a Trajectory Memory Retrieval Network (TMRN) for semi-supervised Video Object Segmentation (VOS), which is tasked with pixel-wise classification of class-agnostic objects in video sequences. The paper argues that while memory-based methods have shown promise in this field, they overlook the rich temporal information present in videos and rely heavily on redundant spatial information. To address this, the authors propose TMRN, a generic plugin that consists of a spatial alignment module and a temporal aggregation module. The spatial alignment module utilizes a set of representative reference features to rectify false matches caused by direct pairwise pixel-level correlations. The temporal aggregation module aggregates trajectory features from relevant memory frames to enhance segmentation accuracy. The authors also address the challenge of obtaining appropriate agents for training without supervision signals, utilizing singular value decomposition (SVD) to acquire diverse and complementary agents. Experimental results on benchmark datasets demonstrate the effectiveness of TMRN compared to leading methods.