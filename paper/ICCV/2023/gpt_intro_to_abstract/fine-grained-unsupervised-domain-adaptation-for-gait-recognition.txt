Gait recognition is a biometric technology that identifies individuals based on their unique walking patterns. It has gained significant attention for its ability to recognize people at long distances, regardless of their attire. Advances in deep learning and the availability of labeled data have greatly facilitated the applications of gait recognition. However, accurately annotating large amounts of data remains a challenge, especially under long-distance cameras where critical information such as the human face is often blurred. In this paper, we propose a fine-grained unsupervised domain adaptation (UDA) framework for gait recognition. The framework transfers knowledge from a labeled source domain to an unlabeled target domain. A key prior knowledge in gait recognition is the existence of overlapping angles in adjacent-view sequences. Leveraging this knowledge, our UDA framework gradually learns cross-dressing capabilities in the target domain through knowledge transfer and clustering, without the need for pre-training the network. We address two main aspects: the offline clustering stage, where accurate pseudo-labels are assigned to unlabeled data based on cross-view chaining relationships, and the online training stage, where gait features are continuously learned in both the source and target domains. We propose a simple yet effective UDA framework that transfers knowledge, extracts fine-grained spatio-temporal motion patterns, and achieves superior performance compared to current state-of-the-art methods, particularly under cross-dressing conditions. Experimental results on various datasets demonstrate the efficacy of our proposed UDA framework.