Point cloud registration is a crucial problem in computer vision and robotics. Learning-based methods using neural networks and transformers have shown promising results in registering partially visible point clouds. However, the limited shared characteristics of low-overlap point cloud pairs degrade the performance of these methods. To address this, we propose a novel approach called Masked Reconstruction Auxiliary Network (MRA) that utilizes the invisible parts of each point cloud as inherent masks and treats the aligned point cloud pair as the reconstruction objective. The MRA guides the backbone to capture geometric details and overall structures during training, and the decoder is detached to avoid extra inference time. We also introduce a Deviation Correction module to refine the predicted coordinates of corresponding points. Additionally, we present Masked Reconstruction Transformer (MRT), a transformer-based method that achieves precise and efficient alignment of point clouds. Experimental results on various datasets demonstrate that our method outperforms state-of-the-art methods in terms of registration accuracy while avoiding extra inference time. Our contributions include proposing a new perspective on point cloud registration, developing the MRA for training, introducing the Deviation Correction module, and achieving SOTA performance on multiple datasets.