Intelligent surveillance systems are widely used for security and monitoring purposes in personal spaces and urban areas. However, these systems raise concerns related to privacy, unauthorized access to sensory data, and resource consumption. Neuromorphic vision sensors, also known as event cameras, offer a potential solution as they capture scene dynamics without recording visual detail of humans, ensuring privacy-by-design to some extent. Event cameras have low resource consumption and can perform various vision tasks. However, event streams, which are the output of event cameras, contain compressed visual signals that can potentially be reconstructed to recover high-quality video streams, posing a threat to privacy. Previous encryption frameworks have been proposed to prevent privacy attacks on event streams but hinder downstream computer vision tasks. In this paper, we propose a learning-based approach called Event-Stream Anonymization that prevents privacy attacks while enabling the execution of downstream tasks such as person re-identification (ReId). Our approach degrades images recovered from an event-to-image module while optimizing the ReId task, protecting subjects' identity while preserving the information necessary for other tasks. We validate our approach through extensive experiments on simulated and real event data, demonstrating its robustness against privacy attacks and inversion attacks. Our contributions include proposing an event-stream anonymization network, a joint optimization framework, and introducing the Event-ReId dataset captured with event cameras.