This paper introduces a novel supervised fusion method called SupFusion for LiDAR-Camera 3D object detection in autonomous driving and robotics. Previous fusion approaches have relied on simple concatenation or summation of camera and LiDAR features, while deep learning-based fusion approaches have lacked effective supervision at the feature level. This paper proposes a solution that provides stronger and high-quality fusion features through the use of an assistant model and introduces auxiliary supervision for feature-level extraction. The paper also introduces a data enhancement method called Polar Sampling to improve features quality and proposes a deep fusion module to enhance detection accuracy. Extensive experiments on KITTI benchmark show around 2% mAP improvements compared to previous detectors with different fusion strategies. The source code will be released after the blind review.