Scene flow estimation plays a crucial role in understanding the motion of objects in a dynamic environment, making it valuable for applications like autonomous driving, augmented reality, and robotics. While early approaches focused on estimating motion in 2D space using RGB images, recent developments in LiDAR sensors and point cloud-based learning have allowed for the direct estimation of scene flow in 3D space. This paper introduces a novel architecture, called Multi-Scale Bidirectional Recurrent Network (MSBRN), for optimizing scene flow estimation in a coarse-to-fine manner. The proposed model utilizes a hybrid correspondence grouping technique to collect corresponding points from both the latent feature space and Euclidean space, enhancing the accuracy and efficiency of the estimation. Experimental results on benchmark datasets demonstrate that the MSBRN model achieves state-of-the-art performance in both occluded and non-occluded conditions.