This paper introduces a framework for learning 3D-consistent features from posed images via retrieval. The goal is to train a network to extract features that are identifiable and consistent in 3D space, allowing for reuse of the same representation for different places. The proposed framework uses a ranking-based objective function to select highly-identifiable landmarks and balances distinctiveness with reusability. The resulting Location-Consistent Universal features are semantically-meaningful, 3D-consistent at multiple scales, and can be applied to tasks such as landmark retrieval, localization, semantic segmentation, and instance segmentation. The contributions of this paper include the framework itself, an evaluation of the proposed features on real images of indoor environments, and the demonstration of various applications.