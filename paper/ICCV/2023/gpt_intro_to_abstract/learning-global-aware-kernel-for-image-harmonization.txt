Image composition is a common task in image editing, where foreground objects from one image are synthesized into another. However, existing methods often fail to produce realistic composite images due to the visual inconsistency between foreground and background. To solve this problem, image harmonization is proposed to adjust the foreground objects based on the illumination and color tone in the background environment. Traditional image harmonization approaches rely on low-level feature matching, which has limitations in handling different scenes. Recently, learning-based methods have shown promising results by addressing image harmonization as a generation task. These methods can be categorized into local-translation and region-matching approaches. While local-translation methods capture limited surrounding background, region-matching methods neglect spatial variations in the foreground and background regions. This paper introduces a novel Global-aware Kernel Network (GKNet) that integrates local harmony modulation and long-distance background references for image harmonization. GKNet includes harmony kernel prediction and harmony kernel modulation. The proposed method achieves state-of-the-art results on iHarmony4 datasets, as demonstrated through extensive experiments.