Few-Shot Learning (FSL) refers to the ability to acquire new knowledge from a limited number of samples, a skill that humans possess naturally but machines still lack. Efforts have been made to bridge this gap in fields like computer vision, machine translation, and reinforcement learning. The general formulation of FSL involves two stages: training-time knowledge accumulation and test-time task adaptation. While meta-learning has been the dominant approach for FSL, recent studies have shown that test-time task adaptation methods can be more effective. Additionally, with the advancements in model pre-training techniques, designing efficient task adaptation algorithms that can leverage pre-trained models has become valuable. In this paper, we propose a unified image- and label-denoising framework called DETA for reliable task adaptation. We introduce a free contrastive relevance aggregation (CoRA) module to determine the weights of regions and images in support samples, and two losses to promote intra-class compactness and inter-class dispersion. The proposed DETA framework improves classification accuracy in adapter-based and fine-tuning-based task adaptation approaches, and outperforms existing approaches in tackling image and label noise. Our contributions are the development of the DETA framework, which can be integrated into various task adaptation paradigms, and extensive experiments on the Meta-Dataset that demonstrate the effectiveness and flexibility of DETA.