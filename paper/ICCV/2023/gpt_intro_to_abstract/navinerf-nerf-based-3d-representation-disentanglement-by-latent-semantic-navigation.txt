In this paper, we address the problem of 3D representation disentanglement in the field of 3D reconstruction. While explicit reconstruction technologies have made significant progress, the reconstructed scenes often lack interpretability and controllability. We propose a method called NaviNeRF, which uses Neural Radiance Fields (NeRF) as a differentiable 3D representation and introduces a self-supervised navigation to identify interpretable semantic directions in the generative latent space. NaviNeRF achieves fine-grained 3D disentanglement by bridging 3D reconstruction and latent semantic manipulation. We evaluate NaviNeRF on two popular benchmarks and show that it outperforms other 3D-aware GANs in attribute manipulation and achieves comparable performance to editing-oriented models that rely on priors. In summary, our contributions include the achievement of fine-grained 3D disentanglement without priors or additional supervision, the utilization of both latent semantic navigation and NeRF representation in a complementary way, and the design of a synergistic loss to collaborate the two branches of NaviNeRF.