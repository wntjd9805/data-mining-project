Action localization in video analytics is a challenging task that aims to accurately predict the start and end time stamps of different human actions. While prior research has made significant improvements in weakly-supervised settings, there is still a performance gap compared to fully-supervised settings. Various solutions have been proposed, but most of them overlook the significance of feature variations in action localization. In this paper, we propose a novel Attention-based Hierarchically-structured Latent Model (AHLM) that models spatial and temporal features for weakly-supervised action localization. Our model incorporates a change-point detection mechanism to detect action boundaries by leveraging the temporal variations in feature semantics. Experimental results on popular action detection datasets demonstrate that our AHLM framework outperforms existing methods and achieves state-of-the-art performance.