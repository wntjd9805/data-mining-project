Visual tasks for top-view fisheye cameras are challenging due to the spatial distortion caused by the geometry of fisheye images. Convolutional Neural Networks (CNNs) have been used to tackle this distortion and improve the accuracy of visual tasks. However, existing methods focus on adapting CNNs to the input and output of fisheye images, without considering the appropriateness of the convolution kernel for distorted objects. This paper proposes a novel convolution method called Deformable Convolution in the Poincaré Ball (DCPB) specifically designed for top-view fisheye cameras. The DCPB embeds the features of fisheye images in the Poincaré ball, a geometric model that approximates the projection model of fisheye cameras, and uses Graph Convolution Networks (GCNs) in the hyperbolic space to obtain offsets and modulation scalars for the deformable convolution. The proposed method aims to improve the ability of the convolution kernel to extract distorted features from fisheye images. Experimental results using a synthetic segmentation dataset show that the DCPB improves the performance of CNN semantic segmentation on fisheye distortions. The contributions of this paper include the proposal of the DCPB convolution method, a method to project features from the Poincaré ball back to the Euclidean space, and the exploration of an appropriate network structure for the DCPB in the segmentation networks UNet.