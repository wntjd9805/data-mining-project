Sign language recognition (SLR) is important for society, but it requires more detailed information than general action recognition (AR) tasks. Previous SLR methods have used RGB-based or pose-based approaches, with pose-based methods offering better robustness but having limitations in understanding detailed motion contexts. To address these limitations, we propose a novel framework called P3D, which utilizes part-wise encoding Transformers (PET) and a whole-body encoding Transformer (WET) to capture motion contexts at different levels. By encoding pose sequences of specific body parts with PET and combining them using WET, P3D improves SLR accuracy. We also address the ambiguity issue by incorporating both 2D and 3D poses in our approach. Experimental results show that P3D outperforms previous state-of-the-art methods on the WLASL benchmark and achieves comparable results to RGB-based methods. Our contributions include the development of P3D and the use of pose ensembles to exploit both 2D and 3D pose information, leading to improved SLR performance.