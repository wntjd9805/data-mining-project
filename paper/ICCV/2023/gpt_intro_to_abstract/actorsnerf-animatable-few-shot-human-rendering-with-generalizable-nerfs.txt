Recent advances in Neural Radiance Fields (NeRF) have led to significant progress in free-viewpoint rendering of humans performing complex movements. However, existing approaches require synchronized multi-view videos and instance-level NeRF networks trained on specific human video sequences, limiting their applicability to videos in the wild. To address this challenge, this paper proposes a category-level human actor NeRF model called ActorsNeRF, which can be trained from just a few images. The key insight is to leverage a category-level canonical space derived from a parametric model to coarsely align all humans, and then refine the alignment using an instance-level canonical space. ActorsNeRF incorporates a feature encoder, skinning weight network, deformation network, and rendering network to learn the shape, appearance, and motion of human actors. Experimental results demonstrate that ActorsNeRF outperforms existing approaches in few-shot settings, making it a promising technique for capturing complex human movements with limited data.