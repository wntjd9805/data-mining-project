Abstract:3D object detection is a crucial problem in 3D scene understanding, but its progress has been hindered by the high cost of annotation. Semi-supervised 3D object detection has recently gained attention as a method to improve accuracy using unlabeled data. One widely recognized framework for this is mean teachers (MT). However, while semi-supervised image classification and semantic segmentation using MT pair predictions at the image or pixel level, the question of how to pair predictions between two sets of 3D boxes remains open. Prior methods have only exploited a limited number of box pairs for MT training due to the two-stage architecture they are built upon. We propose a new method called DQS3D that addresses this by using densely matched boxes, which allows for significantly more box pairs and spatially dense training signals. Additionally, we address the issue of point-to-voxel quantization in 3D detection and propose a compensation rule to account for quantization error. Our method achieves notable performance improvements in various settings and outperforms existing methods on public datasets.