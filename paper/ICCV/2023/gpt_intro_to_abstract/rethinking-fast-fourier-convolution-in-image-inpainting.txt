Image inpainting, or image completion, is a task in low-level vision that aims to recover missing or degraded areas of an image by referring to the undegraded parts. Traditional non-learning methods for image inpainting use statistical information from the undegraded area to infer the missing content. However, these methods struggle to recover semantics and are prone to artifacts in the case of large and continuous masks. Learning-based models, on the other hand, can achieve better inpainting results by generating content that does not exist in the degraded image. However, current learning-based methods still face challenges in capturing global semantics and generating clear and sharp complex content. This paper proposes a novel Unbiased Fast Fourier Convolution (UFFC) module to address these challenges in image inpainting. The UFFC module avoids the flaws of existing approaches, such as spectrum shifting, unexpected spatial activation, and limited frequency receptive field. Experimental results demonstrate that the proposed UFFC module outperforms existing methods in terms of inpainting quality and convergence speed.