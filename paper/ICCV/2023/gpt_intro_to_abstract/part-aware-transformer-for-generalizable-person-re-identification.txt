Person Re-Identification (ReID) aims to identify individuals across multiple cameras, and CNNs have shown promising results in supervised and unsupervised ReID. However, domain generalization (DG) ReID, which trains a model on known domains and applies it to unknown domains, still lags behind supervised ReID. To address this, various DG methods have been proposed, such as disentanglement and meta-learning. One promising approach gaining attention is the Transformer network, which incorporates attention mechanisms and exhibits better generalization under distribution shifts. However, the use of Transformer in DG ReID is not well studied. This paper introduces a pure Transformer-based framework for DG ReID and proposes a Cross-ID Similarity Learning module (CSL) to learn generic features. Additionally, a Part-guided Self-Distillation (PSD) method is proposed to further enhance generalization. Experimental results demonstrate that CSL and PSD improve model generalization, achieving state-of-the-art performance in most DG ReID settings, including a 3.2% improvement in Rank1 accuracy and a 4.6% improvement in mAP accuracy under the Marketâ†’CUHK-NP setting. The contributions of this work include the introduction of a pure Transformer-based framework for DG ReID, the CSL module for learning generic features, and the PSD method for further improving generalization.