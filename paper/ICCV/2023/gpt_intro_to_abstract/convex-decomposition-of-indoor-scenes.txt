This paper introduces a method for decomposing indoor scenes into convex primitives that accurately represent the scene. The method utilizes labeled RGBD + semantic segmentation maps for training and can refine the predicted decomposition using depth + segmentation maps from a pretrained network. The approach combines descent and regression methods to select primitives and their parameters. The paper demonstrates the importance of both steps in achieving a good fit. The accuracy, segmentation, and parsimony properties of the primitive representation are assessed, and the method is evaluated on the NYUv2 dataset using standard metrics. The paper also highlights the advantages of the mixed strategy over individual descent or regression methods. Furthermore, the use of segmentation labels to drive primitive generation is introduced.