Temporal action segmentation is a crucial task in understanding and analyzing human activities in complex videos, with various applications in video surveillance, video summarization, and skill assessment. Recent advancements in multi-stage models have significantly improved the performance of temporal action segmentation. These models use an iterative refinement paradigm, where multiple stages adjust the initial prediction to capture the temporal dynamics of actions and reduce over-segmentation errors. In this paper, we propose a new generative approach to action segmentation that incorporates the denoising diffusion model. This model gradually adds and removes noise to generate new samples from the data distribution, aligning with the iterative refinement paradigm. We formulate action segmentation as an action sequence generation problem conditioned on the input video. By adopting the diffusion-based approach, we not only learn the discriminative mapping from video frames to actions but also capture the prior distribution of human actions through generative modeling. We enhance the prior modeling by considering three prominent characteristics of human actions: temporal position prior, boundary prior, and relation prior. To jointly exploit these priors, we devise a condition masking strategy that fits into our proposed framework. Our method, called DiffAct, formulates action segmentation as a conditional generation problem, leveraging the input video as the condition. During training, the model is provided with degraded temporal action segmentation sequences with varying levels of injected noise, and it learns to denoise them to restore the original ground truth. To achieve this, we employ three loss functions and use a reverse diffusion process to generate the action prediction sequence during inference. The condition masking strategy allows the model to consider information beyond visual features, such as time locations, action durations, and temporal context. We evaluate our method on three datasets and demonstrate its effectiveness compared to state-of-the-art methods. Our contributions include formulating temporal action segmentation as a conditional generation task, proposing a new iterative refinement framework based on the denoising diffusion process, and designing a condition masking strategy to exploit the priors of human actions.