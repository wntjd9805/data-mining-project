Face recognition systems have become widely used for person authentication in real-world applications such as access control and electronic payments. However, these systems are susceptible to presentation attacks, such as print attack, video replay, and 3D mask. Face anti-spoofing (FAS) methods have been developed to address this issue, but they often perform poorly in cross-dataset tests due to domain gaps. Domain generalization methods have been introduced to alleviate domain shifts, but they rely heavily on supervised training using labeled source data. This is problematic as labeled data is laborious and costly to obtain, leading to limited data for FAS. On the other hand, large amounts of unlabeled face data can be easily collected in various environments, making unsupervised training a more practical approach. In this paper, we propose an unsupervised domain generalization framework for FAS (UDG-FAS) that leverages unlabeled data to learn discriminative representations that generalize well across domains. We introduce a Split-Rotation-Merge module to generate identity-agnostic local representations for mining intrinsic spoof features and design a contrastive learning method that pulls together images from different persons potentially belonging to the same class. Our method also addresses domain-related bias by searching cross-domain neighbors as positive samples. We evaluate our approach on six diverse UDG-FAS benchmarks and achieve state-of-the-art performance on various challenging cross-domain scenarios. This work is the first attempt to mitigate identity and domain bias and learn generalized task-aware features in a fully unsupervised manner for FAS.