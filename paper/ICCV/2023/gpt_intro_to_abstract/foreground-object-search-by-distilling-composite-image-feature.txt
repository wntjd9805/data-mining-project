Foreground Object Search (FOS) is a fundamental technique in computer vision that aims to find compatible foregrounds for a given background image. These foregrounds should be able to be realistically composited into the image. FOS is widely used in image composition applications, such as object insertion in photo editing and filling regions with new foregrounds.Compatibility between the background and foreground is influenced by various factors, including semantics, style, lighting, and geometry. Previous research on FOS has considered different factors, with some focusing on semantic compatibility and others considering geometry and additional factors like style and lighting.Existing methods typically involve learning an embedding space using encoders for both the background and foreground. Alternatively, some approaches have trained a discriminator to predict background-foreground compatibility. However, these methods are computationally expensive as they require compositing each foreground image with the background and performing forward computation for each composite image.In this paper, we propose a novel FOS framework called Disco-FOS via knowledge distillation. We distill the knowledge of composite images from the discriminator to two encoders, enforcing the interaction output of foreground and background features to match with the composite image features. To strike a balance between performance and computational cost, we perform interaction only on the last feature maps of the encoders.To evaluate our method, we construct two FOS datasets: S-FOSD with synthetic composite images and R-FOSD with real composite images. S-FOSD dataset is used for training and validation, while R-FOSD dataset is used for model evaluation. Our experiments demonstrate the effectiveness of our proposed method over previous approaches.In summary, our contributions include the creation of the S-FOSD and R-FOSD datasets, the introduction of the DiscoFOS method for foreground object search, and extensive experiments showcasing the superiority of our method.