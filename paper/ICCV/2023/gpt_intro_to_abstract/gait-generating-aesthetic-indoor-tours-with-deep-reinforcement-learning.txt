In this paper, we propose a novel method for automatically generating trajectories to aesthetically frame synthetic 3D indoor scenes. We introduce GAIT, a framework for training a Deep Reinforcement Learning (DRL) network that learns to move the camera to generate trajectories that show the most aesthetic views while also satisfying smoothness constraints. Our method is able to robustly generate diverse trajectories with varying start and end camera poses. Camera poses are optimized with a neural aesthetic metric without any pre-determined targets in the view.GAIT computes camera transformations in a continuous 5D space for each step of the sequence. We define diversity regularization to provide control for either generating diverse sets of trajectories with varying start and end poses or to generate more uniform trajectories that always converge to the same final pose. To constrain the agent from taking actions that would create discontinuities in camera pose, we define smoothness regularization. Smooth trajectories tend to be more pleasing visually, which is important when the generated trajectories are used for video tours.Based on a number of experiments, we demonstrate that our method is able to generate trajectories of camera poses that frame scenes in an aesthetically meaningful manner. We show that our method is able to generate camera trajectories for a variety of complex 3D indoor scenes, which can be used to automatically create aesthetic video tours. Additionally, we show that the learned policies are robust against random initial camera poses.In summary, our contributions are: (1) We propose GAIT, the first DRL-based framework for generating sequences of camera poses with constrained globally optimal aesthetics in 3D synthetic indoor scenes. (2) We allow for user control based on diversity regularization and use smoothness regularization to constrain the agent to generate smooth and visually pleasing camera poses. (3) We demonstrate the effectiveness of image augmentation techniques in learning representation of 3D scene aesthetics, which is a challenging task for DRL algorithms. (4) We implement our algorithm to efficiently utilize multiple GPUs. (5) We show that the generated camera poses can be interpolated to generate high-quality video tours of a scene. (6) Finally, we validate our method through quantitative and qualitative evaluations, including comparison with baseline methods in a user study and ablation studies to validate our algorithm design.