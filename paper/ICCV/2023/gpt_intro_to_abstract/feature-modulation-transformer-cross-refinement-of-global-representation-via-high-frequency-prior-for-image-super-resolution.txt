Single image super-resolution (SISR) is an important topic in computer vision, with various practical applications such as surveillance video, medical image enhancement, and old image reconstruction. Despite its practical value, SISR is a challenging problem due to its ill-posed nature and the existence of multiple solutions for a given low-resolution image. Classical approaches to SISR have limitations in their performance due to their constrained model capacities.Deep learning, particularly convolutional neural networks (CNNs) and transformer architectures, has shown remarkable success in SISR. Prior research has introduced techniques such as residual and dense connectives, as well as attention mechanisms, to improve performance. However, these works have mainly focused on capturing global information and there is limited analysis of the impact of high-frequency information on performance.This paper investigates the influence of high-frequency information on the performance of CNN and transformer structures in SISR. The authors conduct experiments by discarding different ratios of high-frequency components from the input image and observing the corresponding changes in performance. The empirical findings reveal that transformers prioritize low-frequency information and have limited capability in constructing high-frequency representations compared to CNNs.To address this issue, the authors propose a novel structure called the Cross-ReÔ¨Ånement Adaptive Feature Modulation Transformer (CRAFT) which combines the strengths of both CNN and transformer structures. CRAFT includes three key components, namely the high-frequency enhancement residual block (HFERB), the shift rectangle window attention block (SRWAB), and the hybrid fusion block (HFB), which work collaboratively to capture high-frequency details, extract long-range dependencies, and refine the output for better representation. Experimental results show that CRAFT outperforms state-of-the-art methods in SISR with fewer parameters.The main contributions of this paper are: 1) the study of the impact of CNN and transformer structures on performance from a frequency perspective, highlighting the effectiveness of transformers in capturing low-frequency information but limited capacity for high-frequency representations compared to CNNs; 2) the design of a parallel structure that explores different frequency features by incorporating the HFERB branch for high-frequency information and the SRWAB branch for global information; 3) the proposal of a fuse strategy that integrates the strengths of CNN and transformer, resulting in improved performance; and 4) extensive experimental results demonstrating the effectiveness of the proposed method compared to existing state-of-the-art SISR methods with fewer parameters.