Learning maps between images or spaces, also known as registration, is a crucial task in fields such as computer vision, medical imaging, and brain mapping. Traditional registration methods have been surpassed by deep learning-based approaches in terms of performance and inference time. However, these deep registration methods often lead to over-optimization of image similarities, resulting in non-smooth mappings. To address this issue, existing remedies enforce diffeomorphism using add-ons or probabilistic formulations, but these methods can be computationally expensive or lead to inferior performance. In this paper, we propose two novel sanity checks, namely self-sanity check and cross-sanity check, to reduce error and ensure inverse consistency in registration models. Our experiments demonstrate that these checks improve the sanity awareness of different models without sacrificing performance. Our findings also highlight the need for smooth transformations and the limitations of over-optimization on image similarities.