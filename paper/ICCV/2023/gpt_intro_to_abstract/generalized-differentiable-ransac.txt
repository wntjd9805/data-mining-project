Robust estimation is a crucial aspect of vision pipelines in computer science, with applications in various areas such as relative pose estimation, wide baseline matching, multi-model fitting, image-based localization, motion segmentation, and pose graph initialization. Randomized hypothesize-and-verify approaches, like RANSAC, have emerged as the most widely used methods due to their robustness, simplicity, and efficiency. However, the integration of RANSAC with neural networks for optimization of evaluation metrics remains a challenging problem, as minimal solvers are often complex and not differentiable. In this paper, we propose a new differentiable RANSAC algorithm, ∇-RANSAC, which enables learning inlier probabilities while optimizing test-time evaluation metrics. We also introduce a re-parametrization strategy based on the Gumbel Softmax sampler, allowing gradient propagation through the entire randomized procedure. We demonstrate the potential of ∇-RANSAC by incorporating it into an end-to-end feature matcher for improved matches and confidence. Our approach has significant implications for the training of learning-based vision systems, enabling the training of pipelines that were previously difficult or impossible to train.