Federated Learning (FL) is a privacy-aware learning paradigm that enables collaboration among multiple entities, where each entity retains data locally and transfers training updates to a central server. However, conventional FL approaches assume static data classes and domains, whereas in reality, new classes could emerge and data domains could change over time. To address this issue, recent research has introduced the concept of Continual Learning (CL) within the FL framework, referred to as Federated Continual Learning (FCL). FCL aims to mitigate catastrophic forgetting by allowing new classes to be dynamically added. However, existing FCCL methods have limitations, such as the reliance on unlabeled surrogate datasets or the need to store previous data, which may violate data privacy regulations.To address these issues, we propose a novel method called TARGET (federated class-continual learning via exemplar-free distillation), which effectively alleviates catastrophic forgetting in FCCL without compromising clients' data privacy. Our approach leverages the previously trained global model to transfer knowledge of old tasks and trains a generator to produce synthetic data that simulates the global distribution on each client. We conducted a systematic analysis and observed that the imbalanced distribution of data among clients exacerbates catastrophic forgetting. Our contributions include: (1) demonstrating that non-independent and identically distributed data exacerbates catastrophic forgetting in FL and proposing a method (TARGET) that alleviates this issue by leveraging global information, (2) not requiring extra datasets or data from previous tasks, making it applicable in data-sensitive scenarios, and (3) conducting extensive experiments that show the efficacy of our proposed method, achieving higher accuracy compared to the best baseline method on the CIFAR-100 dataset.Overall, our work addresses the challenges of continuously emerging data classes in FL and provides a solution that improves the performance of FCCL without violating data privacy regulations.