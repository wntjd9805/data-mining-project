The paper introduces the concept of input attribution in deep learning models and its importance for understanding model decisions and ensuring safety and fairness. The Integrated Gradient (IG) method and its variants are discussed as commonly used approaches for computing input attributions. However, the paper argues that a single path is not reliable enough for interpretation and proposes a novel attribution method that takes the expectation over a distribution of random paths. The Stick-Breaking Process is adopted to sample from the distribution of possible paths efficiently. The main contributions of the paper are addressing the inconsistency of attribution based on path selection, proposing a sampling method inspired by the Stick-Breaking Process, and evaluating the proposed method's reliability on various network architectures. An illustration of the Stick-Breaking Path Integration (SPI) method is provided, showing how it generates multiple attribution samples and obtains the average attribution.