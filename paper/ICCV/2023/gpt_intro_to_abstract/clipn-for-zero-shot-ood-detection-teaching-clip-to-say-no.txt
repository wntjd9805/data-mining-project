Deep learning models have shown excellent performance in closed-world conditions but often struggle with generalization and performance in real-world applications. This is due to the presence of unknown classes that have not been seen during training. Out-of-distribution (OOD) detection methods have been developed to address this issue. These methods aim to distinguish unknown classes by measuring how closely the input data matches the known classes. However, existing methods fail to accurately identify hard-to-distinguish OOD samples that are close to certain known classes. Recent approaches leverage generalizable representations learned by CLIP, a language-vision model, to detect OOD data without training on the known classes. However, these methods still face challenges in dealing with hard-to-distinguish OOD samples. To address these limitations, we propose a new CLIP architecture, called CLIPN, which incorporates a "no" logic. CLIPN is trained using image-text binary-opposite loss and text semantic-opposite loss to teach it to match images with "no" prompts and understand the meaning of "no" prompts. We also design two threshold-free inference algorithms, competing-to-win and agreeing-to-differ, to perform OOD detection using negation semantics. Experimental results on benchmark datasets demonstrate the superior performance of CLIPN compared to existing methods. Our contributions include the proposal of CLIPN, the development of novel loss functions, and the introduction of threshold-free inference algorithms for OOD detection.