Deepfake technology has gained attention for its potential negative use cases, but it also holds significant promise for positive applications. This paper focuses on face swapping, which involves preserving the identity of the source image while transferring other attributes from a target image. Existing approaches have struggled to achieve all three goals of face swapping simultaneously, largely due to the inadequate disentanglement of face identity and non-identity representations. This paper proposes a new framework that eliminates skip connections, which have been found to hinder disentanglement. Instead, the framework includes two separate encoders for capturing pixel-level and semantic-level attributes, respectively. It also incorporates target identity removal and non-identity attribute preservation losses to compensate for the absence of skip connections. The proposed method is evaluated using a new metric and extensive experiments, demonstrating its effectiveness in achieving thorough disentanglement and preserving identity-irrelevant attributes. This paper contributes by identifying the limitations of prior approaches, highlighting the role of skip connections in insufficient disentanglement, introducing new network structures and training strategies, and validating the effectiveness of the proposed method.