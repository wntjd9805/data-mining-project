Video instance segmentation (VIS) is an important task in video understanding, aiming to detect, segment, and track objects across a video. It has various real-world applications, such as video editing, surveillance, augmented reality, and autonomous driving. VIS methods can be categorized into offline and online methods. Offline methods process the entire video at once, while online methods process frames individually and associate the results across frames. Although both offline and online methods have achieved impressive performance, online methods suffer from temporal inconsistency. This is because they rely on instance association techniques that operate on a per-frame basis. Existing association techniques include tracking-by-detection and query propagation-based methods, which generate per-frame instances independently or propagate queries across frames, respectively. However, these methods result in temporal inconsistency due to isolation of frame features or the Local Matching and Propagating (LocPro) scheme. In this paper, we propose TCOVIS, a novel online video instance segmentation method. TCOVIS introduces a global instance assignment strategy that optimizes for global temporal consistency. Additionally, we propose a spatio-temporal enhancement module that captures spatial and semantic features between frames, enhancing temporal consistency. Experimental results on several benchmark datasets demonstrate the effectiveness of our proposed method, achieving state-of-the-art performance.