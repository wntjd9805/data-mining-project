3D place recognition and localization in a city-scale map is a critical challenge for enabling autonomous agents to operate effectively in real-world applications such as autonomous driving and robot navigation. While GPS signals can provide reliable geo-location, they are limited by external satellite information and fail in environments with no direct line-of-sight or signal availability. Therefore, it is important to develop the capability to perform localization using on-board sensors only.Calibrated depth sensors, such as LiDAR, can be used to localize the observed scene by matching it against a pre-built point cloud database. Unlike visual image-based matching, point cloud recognition focuses on the geometry of the scene and can overcome factors such as variations in lighting, weather, and season. Over the past decade, various point-cloud-based solutions have been proposed, including point-based descriptors and voxel-based descriptors.Point-based descriptors aim to improve global context aggregation by processing points individually, while voxel-based descriptors leverage 3D sparse convolutions over a sparse volumetric representation. However, voxel-based descriptors result in a loss of geometric detail during voxelization, and small voxel cells consume significant memory.Another challenge is that most previous descriptors require dense maps as a reference for place recognition, which may not always be available in unfamiliar or changing environments. To address these problems, we propose a novel cross-attention transformer for single-scan-based place recognition called CASSPR. CASSPR aims to compensate for quantization losses and integrate long-range spatial relationships.Our approach utilizes a hierarchical cross-attention transformer to fuse information from both point-wise and sparse voxelized branches. This allows for flexible aggregation of local and global information into sparse voxel features while maintaining geometric detail. Our proposed method outperforms state-of-the-art approaches in challenging point cloud localization tasks.In summary, our contributions include studying the sparsity of single LiDAR scans, proposing a hierarchical cross-attention transformer module, analyzing computation and memory trade-offs, and demonstrating improved performance on benchmark datasets.