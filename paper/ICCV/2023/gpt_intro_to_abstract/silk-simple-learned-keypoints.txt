Keypoint detection and matching is a fundamental aspect of computer vision, providing a concise yet informative representation of an image. Numerous important tasks, such as image stitching, SLAM, SfM, and object detection, rely on keypoint correspondences. An effective keypoint model should be capable of selecting a subset of points that are relevant to a specific task and exhibit robustness to various transformations. Existing keypoint methods exhibit diverse characteristics, but it is challenging to determine the factors contributing to their performance. To address this, we present SiLK (Simple Learned Keypoints), a self-supervised approach for learning distinctive and robust keypoints from arbitrary image data. SiLK achieves competitive or superior performance compared to state-of-the-art methods. Furthermore, SiLK's one-stage training protocol and modular architecture enable us to analyze and optimize detector performance for different tasks, emphasizing the importance of lightweight backbone architectures for real-time applications.