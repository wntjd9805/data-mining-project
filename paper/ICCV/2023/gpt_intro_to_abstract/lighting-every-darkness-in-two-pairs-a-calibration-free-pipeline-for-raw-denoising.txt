Noise in image capturing has been extensively studied in recent years, particularly in relation to RAW images. Compared to standard RGB images, RAW images have two advantages for image denoising: unique noise distribution and higher bit depth. Learning-based methods using real datasets have made significant progress in RAW image denoising. However, collecting real RAW image datasets for each camera model is impractical. As a result, there has been a growing interest in using synthetic datasets for learning-based methods. Calibration-based noise synthesis with physics-based models has proven effective in fitting real noise. These methods involve building a noise model, calibrating parameters for a specific camera, and generating synthetic paired data for training. While these methods have achieved good performance, they are limited by the need for stable illumination environments, difficulties in transferring denoising networks to different cameras, and the inclusion of all noise distributions in the noise model. To address these limitations, this paper proposes a calibration-free pipeline for RAW image denoising called Lighting Every Darkness (LED). The LED framework eliminates the need for calibration data or operations and utilizes a pre-training and fine-tuning framework to decouple the denoising network from the specific camera. A Reparameterized Noise Removal (RepNR) block is introduced to handle the domain gap between virtual and target cameras, as well as out-of-model noise. The main contributions of this work are a calibration-free pipeline for RAW image denoising, a camera-specific alignment (CSA) approach to loosen the coupling between the denoising network and camera model, and an out-of-model noise removal (OMNR) technique for few-shot transfer learning. Experimental results demonstrate the effectiveness of the proposed LED pipeline, which requires only a small number of raw image pairs and iterations compared to state-of-the-art methods.