The ability to visually identify materials is crucial for various applications, ranging from material science and chemical research to cooking, construction, and industry. However, this task poses several challenges for computer vision methods. Firstly, materials can have infinite states and textures, which can appear different in various settings. Secondly, transitions between material states tend to be gradual and continuous, making it difficult to describe them using discrete categories. Additionally, materials in transparent vessels can be visually distorted. Previous studies have mainly focused on classifying material classes or determining specific properties, while the problem of identifying unseen materials using only one example (one-shot learning) remains unaddressed. In this paper, we propose the MatSim dataset, which includes synthetic images to test the network's ability to recognize material states and subclasses using one or a few examples. The dataset aims to address the general issue of one-shot material recognition in any environment and without restrictions on material types. We hypothesize that training a Siamese net on the same material texture across various objects and environments will enable the net to recognize materials in any setting. The net trained on the MatSim dataset achieves good results in material recognition, outperforming state-of-the-art models. Moreover, it demonstrates robust generalization capabilities beyond its original task. This work contributes to the development of a general dataset and benchmark for low-shot material recognition, showcases the effectiveness of training on synthetic data, and highlights the potential of combining CGI assets repositories to create diverse training data for material recognition tasks.