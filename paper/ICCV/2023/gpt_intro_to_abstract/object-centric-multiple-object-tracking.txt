This research work aims to bridge the gap between object-centric learning and fully-supervised multiple object tracking (MOT) pipelines. Existing MOT methods rely on detection labels and object ID labels, making them label intense and ineffective in open-world scenarios. Unsupervised object-centric representation learning offers a potential solution to the MOT problem without additional supervision. However, current approaches suffer from issues such as ID switches and part-whole split, limiting their applicability in downstream MOT tasks. In this work, a video object-centric model, OC-MOT, is proposed to address these challenges. OC-MOT utilizes a memory model to consolidate object representations and improve temporal consistency. The model achieves label-efficient MOT by leveraging unsupervised memory prediction and an index-merge module to handle the part-whole and duplication issues specific to object-centric models. Experimental results demonstrate the effectiveness of OC-MOT in MOT tasks with minimal detection labels and no ID labels. This research contributes to the development of object-centric representations in MOT and provides an alternative to costly fully-supervised MOT pipelines.