Deep neural networks (DNNs) require large amounts of training data and powerful computing resources for successful training. However, acquiring sufficient training samples and dealing with resource limitations can be challenging in practical applications. To address these issues, third-party data and training platforms are often used, but they bring new security risks. Backdoor attacks pose a serious threat to the training process of DNNs, where attackers inject triggers into benign samples to manipulate the models' behavior. Deploying attacked models can have severe consequences, making it necessary to develop a secure training framework when using third-party data or training platforms. Several defenses have been proposed, but distinguishing poisoned samples from benign ones is often challenging. In this paper, we propose a novel secure training framework called The Victim and The Beneficiary (V&B) that directly trains clean models on poisoned data without relying on benign samples. The framework includes a victim network that detects poisoned samples and a beneficiary network that is trained on credible samples filtered by the victim network. We also introduce a data augmentation method called AttentionMix, which has a stronger inhibition effect against stealthy backdoor attacks. Extensive experiments on benchmark datasets demonstrate the effectiveness and robustness of our framework.