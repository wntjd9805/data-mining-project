Humans possess the ability to recognize complex concepts through composition of familiar visual primitives, a skill that deep learning methods lack. Compositional Zero-shot Learning (CZSL) aims to mimic this human ability by learning the compositionality of seen objects and attributes. Conventional CZSL methods operate in closed-world settings, where test images are restricted to a predefined set of attribute-object pairs. However, this limits the generalization ability of CZSL models. In this work, we focus on the more realistic and challenging task of unconstrained Open-World CZSL (OW-CZSL), where arbitrary compositions may appear at test time. Prior approaches for OW-CZSL have relied on similarity-based composition classification, but their performance degrades due to the expanded output space. In this paper, we propose the Distilled Reverse Attention Network (DRANet) for OW-CZSL, which employs attribute/object-specific networks and an attention-based disentangling strategy to extract and untangle visual primitives of attributes and objects. We achieve state-of-the-art performance on benchmark datasets and analyze the limitations and extensibility of our model.