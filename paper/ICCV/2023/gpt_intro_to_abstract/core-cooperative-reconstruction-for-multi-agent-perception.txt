Perception is crucial for intelligent agents to sense their environment, but individual perception is limited by occlusion and safety concerns. Co-operative perception, which involves multiple agents exchanging information, has shown promise in addressing these limitations. However, there is a trade-off between performance and bandwidth in co-operative perception. This paper introduces the CORE framework, which takes a novel approach of cooperative reconstruction. By learning to reconstruct complete scenes from incomplete observations, agents can improve their cooperation and boost perception performance. The CORE framework consists of three modules: compression, collaboration, and reconstruction. Compression efficiently compresses the features of each agent's observation, collaboration encourages knowledge exchange among agents, and reconstruction recovers complete scenes from the enhanced features. CORE is learned in a supervised manner using raw sensor data, and it achieves better trade-offs between perception accuracy and communication bandwidth in autonomous driving scenarios.