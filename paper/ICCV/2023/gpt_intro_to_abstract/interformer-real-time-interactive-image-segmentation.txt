In this paper, we introduce a method called InterFormer, which aims to improve computational efficiency in interactive image segmentation. We address the challenges of deploying computationally-intensive models on low-power devices, as well as the computational redundancy caused by similar model inputs and serial interactions. To overcome these challenges, we propose a pipeline that utilizes a large vision transformer model to preprocess images offline, followed by a lightweight interactive segmentation module for real-time annotation on low-power devices. We also introduce a novel interactive multi-head self attention module, called I-MSA, that efficiently utilizes the preprocessed features from the large model. Our experimental results demonstrate that InterFormer outperforms previous interactive segmentation models in terms of both computational efficiency and segmentation quality. Overall, our contributions include the introduction of InterFormer, the proposal of the I-MSA module, and the demonstration of its effectiveness through extensive experiments on various datasets.