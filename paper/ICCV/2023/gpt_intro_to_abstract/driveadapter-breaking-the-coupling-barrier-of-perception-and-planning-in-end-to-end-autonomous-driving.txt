In recent years, there has been significant progress in autonomous driving systems due to advancements in deep learning. Traditional pipelines involve multiple components such as object detection, motion prediction, and trajectory planning. However, the concept of end-to-end autonomous driving aims to directly map raw sensor data to planned trajectories or control signals using deep learning and big data. One challenge in end-to-end autonomous driving is the difficulty of directly learning a good policy due to noisy and redundant sensor inputs. Previous approaches, such as privileged input-based reinforcement learning (RL) agent MaRLn and the teacher-student paradigm in Roach, have shown promise in improving performance. However, these approaches can still suffer from causal confusion issues, where the student model learns visual clues instead of the cause behind desired actions. To address these challenges, this work proposes DriveAdapter, a technique that connects a student model to a teacher model for planning in a decoupled manner. DriveAdapter utilizes adapter modules to transfer features between the student and teacher models and incorporates a feature alignment objective function. Additionally, the proposed approach includes back-propagating an action loss to the adapters and masking feature alignment loss to account for the imperfect performance of the teacher model and the inclusion of hand-crafted rules. Experimental results demonstrate that DriveAdapter achieves state-of-the-art performance on evaluation benchmarks in the CARLA simulator. Ablation studies and comparisons with alternative approaches further provide insights into the benefits of the decoupled paradigm. This work highlights the importance of leveraging the driving knowledge within RL expert models and provides valuable insights for future research in this area.