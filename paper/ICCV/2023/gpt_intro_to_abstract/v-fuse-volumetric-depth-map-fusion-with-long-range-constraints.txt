This paper introduces V-FUSE, an end-to-end learning-based method for the fusion of depth and confidence maps in Multi-View Stereo (MVS) systems. The current state-of-the-art MVS systems use depth map collections for 3D reconstruction, but depth map fusion is still implemented using heuristic operations. V-FUSE utilizes a 3D convolutional network that considers support, occlusions, and free-space violations constraints to improve the accuracy of depth estimates. Unlike previous methods, V-FUSE operates on a 3D volume and learns all parameters end-to-end. Additionally, the paper proposes a technique for achieving high resolution near the surfaces while reducing storage and computational requirements. The main contributions of this work are the V-FUSE fusion method and the pixel-wise search window estimation sub-network. Extensive evaluations on MVS benchmarks demonstrate the effectiveness of V-FUSE in terms of both 2D and 3D error metrics.