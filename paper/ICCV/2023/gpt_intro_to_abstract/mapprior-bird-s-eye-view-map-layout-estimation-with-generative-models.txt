Abstract:The accurate perception of the environment is crucial for the safety of autonomous vehicles. Bird's-Eye View (BEV) perception, which models scene layouts and is tightly coupled with planning, has gained significant attention. However, existing BEV perception models face challenges in accurately predicting distant or occluded regions and considering uncertainty and diversity in road layouts. This paper presents MapPrior, a novel BEV perception method that addresses these challenges. MapPrior combines a discriminative BEV perception model with a learned deep generative traffic layout prior. The method includes a prediction step using an off-the-shelf BEV perception model and a generative step using the MapPrior model to sample refined layouts. Our approach outperforms existing methods in terms of accuracy, realism, and uncertainty awareness, as demonstrated through benchmarking on the nuScenes dataset. Additionally, MapPrior showcases its unconditional generation capabilities by generating a realistic and consistent HD map of a 30 km-long road.