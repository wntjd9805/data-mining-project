The realm of computer vision and graphics faces the challenge of novel view synthesis. Neural volumetric representations, such as NeRF, have emerged as a breakthrough in reconstructing 3D scenes. However, NeRF faces challenges when training images have varying resolutions, leading to blurred rendering outputs and aliasing artifacts. Mip-NeRF addresses these challenges with a scale representation and a novel rendering strategy. However, Mip-NeRF relies on querying the network with scale-variant encoding, limiting its integration with pre-cache techniques. This paper introduces Mip-VoG, a novel multiscale representation that addresses training on images with varying scales and enables real-time anti-aliasing rendering. Mip-VoG stores scene geometry and color attributes explicitly within a voxel grid framework and uses a compact MLP for decoding view-dependent effects. It maintains one density voxel grid and one feature voxel grid for high-frequency spatial attributes, allowing for progressive down-sampling and LOD calculation. Our approach achieves impressive results in addressing multiscale challenges and accurate anti-aliasing rendering, surpassing state-of-the-art techniques.