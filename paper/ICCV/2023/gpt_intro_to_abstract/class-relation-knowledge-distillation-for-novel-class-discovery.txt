The recent development of deep learning has seen significant success in visual recognition tasks. However, most methods focus on closed-world settings, where all visual classes are predefined. This limits the deployment of learned models in realistic scenarios with potential novel classes. In contrast, humans can acquire new concepts without supervision based on learned knowledge. Inspired by this ability, the task of Novel Class Discovery (NCD) aims to discover novel categories from unlabeled data based on known-class data. Existing NCD methods involve supervised and discovery training stages but are less effective in capturing the relationship between known and novel classes. To address this challenge, we propose a class-relation representation that encodes the similarity between a novel class and known classes. We use the predicted distribution of a well-trained model to encode the inter-class relationship. We introduce a novel class-relation knowledge distillation framework for NCD that utilizes the class relation represented by the supervised-trained model to promote knowledge transfer. Our framework includes a two-head network architecture with an encoder and two classifiers for known and novel classes. We validate the effectiveness of our method on four datasets and demonstrate superior performance compared to previous state-of-the-art approaches. Our contributions include a simple and effective learning framework for knowledge transfer, a regularization strategy to capture class relations, and significant improvement in performance on various benchmarks.