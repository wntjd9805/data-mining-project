Blind image super-resolution (SR) has made significant progress in recent years, thanks to advancements in dataset construction and network design. However, existing methods have limitations in terms of training sets and model generalization. To address these limitations, self-supervised learning and leveraging face regions have been introduced. However, these methods still exhibit inferior performance in SR. This paper introduces MetaF2N, an efficient and effective method for blind image SR. It directly fine-tunes the SR model parameters using low-quality and recovered face pairs, eliminating the need for degradation modeling and low-quality image synthesis. The model adaptation process is stabilized and accelerated using the model-agnostic meta-learning framework. Additionally, a MaskNet is deployed to predict adaptive loss weights for different positions in the recovered face regions, reducing the impact of errors. The effectiveness of MetaF2N is demonstrated through extensive experiments on synthetic and real-world datasets. The contributions of this paper include the proposal of MetaF2N for blind image SR, the introduction of MaskNet for confidence prediction, and the collection of a real-world low-quality image dataset.