The last decade has seen significant advancements in machine learning (ML), resulting in models that surpass human performance in various tasks. However, these models often struggle with distribution shifts, such as adversarial examples, image corruptions, and out-of-distribution samples. Addressing these issues is crucial for the widespread adoption of ML in practical applications, particularly in safety-critical domains where distribution shifts are inevitable. Previous studies have focused on understanding and bridging the gap between ML models and human perception, exploring architecture and training data perspectives. Frequency spectra of training data have been leveraged to improve model robustness, but existing methods either rely on ensemble models or complex augmentation regimes, limiting their effectiveness. Additionally, it is important to preserve or improve the clean accuracy of the models while enhancing their robustness. In this paper, we propose HybridAugment, a simple data augmentation method inspired by frequency spectra-based approaches. By swapping high-frequency and low-frequency components of images, regardless of their class labels, HybridAugment encourages the models to focus on the low-frequency information and reduces reliance on high-frequency components, which are often the cause of robustness issues. With minimal training overhead, HybridAugment improves corruption robustness while preserving or improving clean accuracy, and also enhances adversarial robustness. We further introduce HybridAugment++, which performs hierarchical perturbations in the frequency spectra by swapping amplitude and phase components. By forcing the models to rely on phase and low-frequency information, HybridAugment++ offers additional improvements in adversarial and corruption robustness, as well as clean accuracy. Our main contributions include the proposal and implementation of HybridAugment and HybridAugment++, demonstration of their effectiveness in improving robustness, and comparison with alternative methods on benchmark datasets.