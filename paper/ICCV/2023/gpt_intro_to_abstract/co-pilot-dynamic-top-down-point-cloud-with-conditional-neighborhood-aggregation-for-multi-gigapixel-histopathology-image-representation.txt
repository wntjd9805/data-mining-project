Deep learning models have gained significant interest in the computer vision community for the digital processing of medical images. These models have been applied to various image types and tasks, such as histopathology images and CT scans, for classification, segmentation, and survival prediction. In the field of digitized histopathology, where Whole-Slide Images (WSIs) are used, the high resolution and large size of the images present computational challenges. Multiple Instance Learning (MIL) techniques are often used to address these challenges, but they have limitations in terms of representational capacity, computational power requirements, and the inability to capture high-granular details. This paper introduces a novel approach that utilizes graph neural networks (GNNs) to represent histopathology images through the dynamic and hierarchical processing of cellular graphs extracted from the images. The cellular graphs allow the model to examine cell-level information and interconnections, providing a multi-scaled perspective of the tissue. Compared to MIL models and Visual-Transformer-based methods, the proposed GNN approach offers more efficient processing of WSIs and avoids over-parameterization issues. The paper presents a dynamic top-down GNN called CO-PILOT, which achieves state-of-the-art survival prediction results and enables efficient training on large images. The model demonstrates the ability to stratify high-grade serous ovarian cancer patients into different risk groups based solely on routine tissue slides. Additionally, a large cellular graph dataset, along with survival information, is provided, which is one of the largest datasets in this context. This work advances the fields of MIL, Vision Transformer, and GNNs, and offers new possibilities for analyzing medical images.