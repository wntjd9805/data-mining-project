The success of deep learning in visual recognition tasks, particularly in scene text recognition (STR), heavily relies on large labeled datasets. However, current progress in STR has shown a trend of accuracy saturation on common benchmarks, indicating that the challenges in these benchmarks have been largely solved. This raises questions about the sufficiency of these benchmarks to drive future progress and whether STR can be considered solved. To address these questions, we evaluate the performance of 13 representative STR models on common benchmarks and find that there is limited scope for accuracy improvement. Furthermore, we identify additional challenges that are prevalent in the real world but have received less attention in the STR community. To facilitate more thorough evaluations and encourage research on these challenges, we construct a challenge-driven benchmark comprising both generic and challenge-specific samples. We find that current state-of-the-art models still face numerous challenges in the real world, indicating that STR is far from being solved. To tackle the sub-optimal performance of STR models, particularly in real-world scenarios, we propose utilizing unlabeled data through self-supervised pre-training. Specifically, we investigate a Vision Transformer-based STR model that leverages unlabeled data to achieve state-of-the-art performance on both common benchmarks and the proposed challenge-driven benchmark. Our contributions include highlighting the insufficiency of common benchmarks, establishing a comprehensive and realistic benchmark, and offering a practical solution for STR improvement through the use of unlabeled data.