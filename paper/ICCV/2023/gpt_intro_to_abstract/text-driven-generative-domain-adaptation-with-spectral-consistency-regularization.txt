Generative image modeling has made significant advancements in recent years, allowing for the creation of high-resolution images that are virtually indistinguishable from real images. However, the training of these models requires extensive computational resources and large datasets, limiting their application in certain scenarios, such as collecting paintings by specific artists. To overcome these limitations, text-driven generative domain adaptation is proposed as an alternative approach that leverages text descriptions of visual semantics to guide the generative process instead of relying on a collection of image samples from the target domain. Text has shown success in semantic image generation and manipulation, making it a valuable tool in generative domain adaptation. Traditional methods for adaptation in a few-shot scenario involve training generative models in the target domain using limited samples and adapting pre-trained models from a large-scale source domain that contains high-level semantic knowledge. However, these methods still require additional training samples and an adversarial training process, resulting in decreased image fidelity and diversity as the number of samples decreases. In contrast, text-driven generative domain adaptation eliminates the need for image samples in the target domain and instead relies on text descriptions. One approach to text-driven adaptation encourages visual changes between samples from the target and source generators to align with semantic directions described by text, resulting in generative adaptation for various domains in a short training time. The main challenge in text-driven adaptation is the mode collapse problem, which arises from the entanglement of intra-domain semantics and inter-domain style in text representation. To address this challenge, researchers propose the use of spectral consistency regularization, which analyzes the Hessian matrix of the generator's manifold in the metric space. The eigenvalues of the Hessian matrix decrease during the adaptation process, indicating the occurrence of mode collapse. By introducing spectral consistency regularization, the latent space of the generator can be preserved, allowing for the preservation of intra-domain variations in the source domain without restricting the style effects of the target generator. A stochastic method is developed to regularize the spectrum of the Hessian matrix, reducing computational costs. Additionally, a granularity adaptive regularization is designed to control the balance between diversity and stylization for the target model. Experimental results and ablation studies demonstrate the effectiveness of the proposed spectral consistency regularization in a wide range of target domains, including its applications in image editing and image-to-image translation. In summary, this paper contributes by analyzing the mode collapse problem in GAN adaptation and proposing a spectral consistency regularization for text-driven adaptation, along with a granularity adaptive regularization and empirical evaluations of its effectiveness.