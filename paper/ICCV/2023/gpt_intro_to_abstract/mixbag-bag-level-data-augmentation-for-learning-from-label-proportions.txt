This paper introduces the problem of learning from label proportions (LLP) in computer science. In many classification tasks, instance-level annotations are costly and may not be disclosed for privacy reasons. In LLP, the goal is to train a model using label proportions of a bag instead of instance-level labels. Various methods have been proposed for LLP, most of which are based on the proportion loss. However, these methods face challenges when the number of labeled bags is insufficient. To address this, the paper proposes a bag-level data augmentation technique called MixBag. MixBag generates new bags with different label proportions by sampling instances from original bags and mixing them. The expected label proportion of a mixed bag can be calculated from the original bags. To mitigate the adverse effects of the proportion gap, the paper introduces a confidence interval loss, which is statistically guaranteed. Experiments using eight datasets demonstrate the effectiveness of the proposed method in improving classification accuracy. The main contributions of this paper include examining the impact of the number of labeled bags and bag size on LLP performance, proposing MixBag with a confidence interval loss, and demonstrating the applicability of MixBag to various LLP methods and instance-level augmentation techniques.