Video understanding is a significant research area in computer vision with applications in various domains. However, the challenge of deteriorated video frames due to motion blur, occlusion, and deformation makes it difficult to extract relevant information. Existing methods use complex integration modules tailored for specific tasks, which increases complexity and computational costs. In this paper, we propose a unified framework called Spatio-Temporal Prompting Network (STPN) to address these limitations. STPN introduces spatio-temporal information into the backbone network to directly obtain robust video features without the need for complex integration modules. We introduce a dynamic video prompt predictor to generate video prompts based on support frames, which are then used in the network. STPN can be easily adapted to different video understanding tasks and achieves state-of-the-art performance in video object detection, video instance segmentation, and visual object tracking benchmarks. Our contributions include the development of STPN, the exploration of prompting techniques for video feature extraction, and achieving state-of-the-art performance on multiple video understanding tasks.