Video object segmentation (VOS) plays a crucial role in video understanding and has various applications, such as video editing, augmented reality, robotics, and self-driving cars. However, existing VOS models are primarily designed for short-term videos and struggle with challenges in long-term videos, such as long-term disappearance and error accumulation. Unfortunately, there is a lack of densely annotated long-term VOS datasets. Most benchmark datasets focus on short-term videos, which do not accurately reflect real-world scenarios. In this paper, we propose LVOS, the first long-term video object segmentation benchmark dataset. LVOS consists of 220 videos with an average duration of 1.59 minutes and provides dense and high-quality annotations. It features 27 categories, including 7 unseen categories, to evaluate the generalization ability of VOS models. We conduct extensive experiments on LVOS, introducing Diverse Dynamic Memory (DDMemory), a memory mechanism that effectively handles long-term videos with constant memory cost and high efficiency. Our contributions include the construction of the LVOS dataset, the introduction of DDMemory, and the assessment of existing VOS models on long-term videos.