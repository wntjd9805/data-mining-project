The introduction of this computer science paper discusses the challenge of acquiring extensive labeled data for deep learning in computer vision. It highlights the time-consuming and labor-intensive process of manual annotation and emphasizes the need for data-efficient learning methods. The paper proposes a novel approach, named BorLan, that leverages pretrained language models (PLMs), such as BERT and GPT, to enhance the data-efficiency of visual learning. By aligning the image feature space with the text embedding space of PLMs, the proposed method aims to capture semantic relationships between concepts and domain-invariant knowledge. The paper also compares the framework with existing methods and showcases its flexibility and adaptability in different learning scenarios. The contributions of the work include the introduction of BorLan as a data-efficient visual learning paradigm, the proposal of a text embedding distribution-aware objective, and extensive experiments to validate the method's effectiveness.