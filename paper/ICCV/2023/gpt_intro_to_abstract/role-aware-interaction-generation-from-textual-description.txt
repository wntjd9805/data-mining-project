Modeling human motion for 3D animation, such as game characters and online avatars, is a complex task that has traditionally been done through manual crafting or costly motion capture systems. However, recent advancements in generating human motion from language have shown promise in creating more diverse and faithful animations. In this paper, we propose a role-aware interaction generation model that extends a single motion generation method to handle interactions between two human characters. We differentiate between asymmetric interactions, where there is an initiator and a receiver, and symmetric interactions, where both actors perform the same action. For asymmetric interactions, we assign appropriate textual descriptions, using active and passive voice languages, to capture the relationship between the two motions. To achieve consistency and capture temporal correspondence, we introduce a cross attention module between two Transformer units. Additionally, we propose a method that automatically learns to differentiate the roles by adopting Permutation Invariant Training (PIT). We evaluate our model on the NTU-RGB+D 120 dataset, introducing a novel metric called Mutual Consistency to assess the accuracy of interactions. Our results demonstrate that our proposed method effectively generates realistic interactions between two human characters, with higher mutual consistency and fidelity to the input text compared to existing studies that do not consider roles.