Human-object interaction (HOI) detection is a crucial task in understanding human-centric scenes. It involves localizing human and object pairs in an image and recognizing their interactions. Recent advancements in vision Transformers, especially the DEtection TRansformer (DETR), have revolutionized HOI detection. Two-stage methods utilize DETR to localize humans and objects simultaneously, followed by predicting interaction classes. One-stage methods use DETR's weights and architecture to predict HOI triplets directly from the image context. However, previous methods face challenges in annotating HOI pairs and suffer from data scarcity and imbalanced data distributions. Additionally, training HOI detectors can be computationally expensive, particularly with two-stage methods relying on transformers. To address these challenges, we propose an adaptive and efficient HOI detector that is resilient to imbalanced data. Our approach involves a training-free method with a concept-guided memory module that balances HOI classes. This memory module leverages domain-specific visual knowledge and can effectively detect rare HOI classes. To adapt to new domains quickly, we unfreeze the memory module and inject lightweight residual instance-aware adapters during training. By leveraging pre-trained vision-language models, our approach achieves competitive results on the VCOCO and HICO-DET datasets with fast convergence speed. Our contributions include proposing a training-free approach for HOI detection, demonstrating the effectiveness of the concept-guided memory module, and achieving state-of-the-art results on benchmark datasets.