Semi-supervised learning (SSL) is a machine learning paradigm that aims to improve model performance by incorporating unlabeled data. However, existing SSL methods assume that labeled and unlabeled data share the same class space, which is not always feasible in real-world applications. This gives rise to the problem of Open-Set Semi-Supervised Learning (OSSL), where unlabeled data may contain outliers that do not belong to any of the labeled classes. The negative effects of these unseen-class outliers on SSL methods have been observed, as adding outliers can significantly reduce classification accuracy. One approach to handle outliers is to detect and remove them, but this may also exclude valuable inliers from subsequent training. In this paper, we propose IOMatch, a novel framework that jointly utilizes both inliers and outliers in an open-set SSL setting. Unlike existing methods, IOMatch optimizes all network modules simultaneously, making it easy to use. Experimental results demonstrate the effectiveness of IOMatch, especially in scenarios with scarce labels and severe class mismatch. IOMatch outperforms state-of-the-art methods, achieving significant performance gains even when the proportion of outliers is high and the number of labels per seen class is limited. Overall, our contributions include highlighting the limitations of existing open-set SSL methods, proposing a unified paradigm for inliers and outliers utilization, and demonstrating the superiority of IOMatch in various OSSL settings.