Large neural networks have achieved remarkable success in various domains such as natural language understanding, computer vision, and reinforcement learning. However, training these large models remains challenging in terms of infrastructure and optimization. In this paper, we propose a divide-and-conquer strategy called modular training to improve the effectiveness and efficiency of training large models. We divide the model into smaller sub-modules, train them independently, and then assemble them to obtain the final model. This approach leads to faster and more stable convergence, higher robustness against overfitting, and allows training on different machines without communication. Designing an effective modular training mechanism is non-trivial due to the dilemma between independency and compatibility. We propose a Deep Incubation approach that addresses this dilemma and demonstrates the benefits of the divide-and-conquer paradigm. We introduce a global, shared meta model and a module incubation algorithm to encourage sub-modules to be aware of their role in the target model. This allows for highly compatible sub-modules that collaborate smoothly after assembly. Our approach allows for an extremely shallow meta model with negligible computational overhead, while maintaining the performance of the target model. We validate the effectiveness of Deep Incubation on the DeiT training recipe, outperforming end-to-end training or delivering similar performance at a reduced training cost. The performance gains also transfer to downstream tasks such as object detection and semantic segmentation.