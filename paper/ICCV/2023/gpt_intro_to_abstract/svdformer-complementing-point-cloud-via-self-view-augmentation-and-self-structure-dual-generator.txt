Point cloud completion is a challenging task in 3D vision applications due to the sparsity and large structural incompleteness of captured point clouds. Various learning-based techniques have been proposed but are limited in their ability to produce satisfactory results. Two primary challenges are identified: the absence of crucial semantic parts and the inference of detailed structures. Some methods incorporate additional color images to address the first challenge but obtaining paired images with well-calibrated parameters is difficult. Other methods utilize skip-connections or encoding techniques but fail to generate geometric details for different missing regions. To overcome these challenges, a new neural network called SVDFormer is proposed. SVDFormer leverages self-structure information in a coarse-to-fine paradigm. It incorporates a Self-View Fusion Network (SVFNet) to learn an effective descriptor of the global shape and enhance inter-view relations. It also utilizes a Self-structure Dual-Generator (SDG) with parallel refinement units to analyze and align the structures of generated point clouds. Extensive experiments demonstrate that SVDFormer outperforms existing methods in terms of global shape understanding and detail recovery. The contributions of this work include the design of SVDFormer, the introduction of SVFNet for multi-view feature fusion, and the implementation of SDG for handling various incomplete shapes.