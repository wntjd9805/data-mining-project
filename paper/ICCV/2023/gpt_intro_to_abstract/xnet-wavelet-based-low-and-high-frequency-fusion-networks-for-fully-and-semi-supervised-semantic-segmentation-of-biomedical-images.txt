This paper introduces a novel wavelet-based LF and HF fusion model, called XNet, for semantic segmentation of biomedical images. The goal of semantic segmentation is to assign a class label to each pixel, and convolutional neural networks (CNNs) have been successful in this task. Some studies have extended these methods to 3D and achieved promising results. Recently, the combination of transformers and CNNs has become popular as transformers can capture long-range dependencies. However, most existing methods focus on model architecture rather than exploring the intrinsic LF and HF information of images that may be useful for segmentation.Supervised methods for semantic segmentation require large-scale labeled images, which can be costly and time-consuming to produce. To address this issue, researchers have proposed semi-supervised methods that learn with a small number of labeled images and a substantial number of unlabeled images. Common solutions include adversarial training, pseudo-labeling, and consistency regularization. Among these, consistency regularization is currently the best performing method. However, current perturbation strategies used in consistency regularization are artificially designed and may introduce negative learning bias.To overcome these problems, the authors propose XNet, which simultaneously achieves fully-supervised learning based on LF and HF information fusion, and semi-supervised learning based on consistency of LF and HF outputs. XNet uses wavelet transform to generate LF and HF images and fuses their information to generate dual-branch segmentation predictions. For supervised learning, the predictions absorb the complete LF and HF information. For semi-supervised learning, the dual-output pays different attention to LF and HF information, leading to consistency differences that are used for training on unlabeled images.The motivation for this approach is that LF information represents abstract semantics, while HF information represents image details. By extracting and fusing different frequency information, the model can better focus on LF semantics and HF details to improve performance. Moreover, using wavelet transform to generate LF and HF images for consistency difference-based semi-supervised learning helps alleviate the learning bias caused by artificial perturbations.The contributions of this work include the proposal of XNet, which achieves state-of-the-art results in both fully- and semi-supervised semantic segmentation of biomedical images simultaneously. XNet also utilizes wavelet transform for generating LF and HF images, enabling consistency learning and reducing learning bias. Extensive benchmarking on two 2D and two 3D public biomedical datasets confirms the effectiveness of XNet.