Diffusion models have shown superior performance compared to previous generative models in computer science. This has led to researchers exploring the application of diffusion models in various downstream tasks, with conditional generation being a popular focus area. Conditional diffusion models (CDMs) have been proposed for diverse conditions such as text, class labels, degraded images, segmentation maps, landmarks, hand-drawn sketches, and style images. These CDMs can be categorized as training-required or training-free. Training-required CDMs involve training a time-dependent classifier or a new score estimator to guide the generation process. While these methods yield impressive results, they lack flexibility and require retraining or fine-tuning for new target conditions. On the other hand, training-free CDMs attempt to solve the same problems without additional training. However, these methods struggle to generalize to a wider range of conditions. To address these limitations, this paper proposes a training-free conditional diffusion model, called FreeDoM. FreeDoM emphasizes generalization by using an energy function for sampling and leverages pre-trained time-independent models to construct the energy function, making it training-free. The proposed FreeDoM offers simplicity, effectiveness, low cost, and efficiency, while supporting a wide range of conditions. It is suitable for various applications and different types of diffusion models, as demonstrated through extensive experiments.