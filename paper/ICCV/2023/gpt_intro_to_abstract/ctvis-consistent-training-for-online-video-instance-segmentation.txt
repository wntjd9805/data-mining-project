Video instance segmentation is a critical task in computer vision, with applications in various domains such as video surveillance, video editing, autonomous driving, and augmented reality. Existing methods for video instance segmentation can be categorized into offline and online methods. Online methods, which process videos frame by frame, have achieved state-of-the-art performance by leveraging query-based frameworks and incorporating temporal consistency. However, these methods have not fully explored the discrimination of query embeddings to associate instances accurately. In this paper, we propose a novel online video instance segmentation framework called CTVIS that addresses this limitation. CTVIS incorporates useful tactics from inference, including a memory bank, momentum-averaged embeddings, and noise training, to improve the quality of query embeddings and facilitate accurate instance association. We also propose goal-oriented augmentation methods to generate pseudo-videos for training, which reduces the reliance on expensive and time-consuming annotations. Experimental results on benchmark datasets demonstrate that CTVIS outperforms existing methods by a large margin. Furthermore, CTVIS achieves impressive performance even when trained only with pseudo-videos, surpassing fully supervised methods. Our contributions include the development of a simple yet effective training framework for online video instance segmentation, the proposal of pseudo-data generation methods, and the achievement of state-of-the-art performance on multiple datasets.