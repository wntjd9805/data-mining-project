Object detection is a crucial task in computer vision, and traditional approaches rely on convolution to extract informative features from images. However, recent work, such as DETR, has challenged this paradigm by introducing an end-to-end solution that uses self-attention for feature extraction and eliminates the need for post-processing steps like non-maximum suppression. Despite its advantages, DETR suffers from slow convergence due to the lack of a good positional prior for matching queries to the visual feature map. This paper addresses the issue of misalignment between the classification and localization tasks in DETR by decoupling the decoder's cross-attention block into two branches. The proposed method allows classification and localization to match queries with different regions of the visual feature map and improves performance over existing DETR detectors. Additionally, the study highlights the importance of query initialization in the decoder and introduces a task-aware query generation module to learn task-specific queries based on anchor boxes. An alignment loss is also proposed to ensure consistency between high classification confidence and precise localization. The proposed approach is evaluated on the MSCOCO dataset and demonstrates significant improvements in object detection performance.