This paper introduces a novel weakly-supervised Referring Image Segmentation (RIS) framework that aims to segment a target object from an input image based on linguistic queries. Existing RIS methods rely on time-consuming pixel-level annotations for fully-supervised learning. The proposed framework leverages referring texts as supervision signals, classifying positive and negative texts to locate target objects. Three technical novelties are presented: a bilateral prompt method to harmonize visual and linguistic features, a calibration method to enhance response maps, and a response map selection strategy for high-quality pseudo-labels. The proposed framework achieves promising results compared to fully-supervised RIS methods and outperforms weakly-supervised baselines, without requiring additional annotations.