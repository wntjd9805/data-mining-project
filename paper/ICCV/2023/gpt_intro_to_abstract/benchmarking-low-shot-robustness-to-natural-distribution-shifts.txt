Abstract:Computer Vision has witnessed significant advancements in recent years, driven by advanced architectures like Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs), as well as large datasets and sophisticated training strategies. However, concerns have been raised about the ability of early learning techniques to generalize to distribution shifts beyond the ImageNet dataset. To address this, researchers have proposed various evaluation datasets to measure out-of-distribution (OOD) performance. Recent methods have shown impressive performance by fine-tuning self-supervised or large-scale vision-language pre-trained models on fully labeled in-domain (ID) data. However, fine-tuning requires large amounts of data and compute resources, which may not be accessible to most practitioners. This paper introduces the concept of "low-shot robustness," where pre-trained models are fine-tuned using a small number of ID images and then evaluated on OOD data. The paper aims to study the effectiveness of different pre-training strategies, architectures, and robustness interventions in low-shot regimes with various natural distribution shifts. The key research questions addressed include the most effective pre-training strategies and architectures for low-shot robustness with ImageNet pre-trained models, the performance comparison between models pre-trained on large external datasets like CLIP and ImageNet pre-trained models on different datasets, and the impact of robustness interventions in the full-shot regime versus low-shot regimes. The findings highlight the need for reevaluating conventional wisdom for robustness in low-shot regimes and provide insights for future work in this area.