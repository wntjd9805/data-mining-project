In this paper, we explore the necessity of inhibitory connections in brain function from the perspective of representation capacity. Previous studies have shown that a balanced ratio of excitatory/inhibitory connections is essential for memory and behavioral control, while imbalances can lead to disorders such as epilepsy. However, some organisms, like the Cnidarian jellyfish, exhibit context-dependent behaviors without inhibitory connections, suggesting alternative mechanisms for brain function. To investigate this further, we analyze the representation capacity of non-negative networks, focusing on Deep Neural Networks (DNNs) as a modeling tool. By removing inhibitory connections and setting all weights to be non-negative, we examine the functions that can be represented by these networks. Contrary to the previous theoretical result that DNNs are universal approximators, we prove that DNNs with all non-negative weights are not universal approximators. Furthermore, we establish three geometric properties of the representation space for non-negative DNNs. These findings demonstrate that networks without negative connections not only lose universality but also have a significantly limited representation space. We extend our analysis to convolutional neural networks (CNNs) and other structural variants. Our theoretical results provide a plausible explanation for the evolutionary development of brains with inhibitory and excitatory connections. While simpler systems may be capable of performing certain functions, they have limited representation capacity. Thus, our work concludes that inhibitory connections are necessary for a brain to represent a broader range of functions.