In recent years, there has been a surge of interest in vision-and-language navigation tasks in the computer vision, natural language processing, and robotics communities. These tasks, such as R2R, RxR, REVERIE, Touch-Down, Alfred, and iGibson, have advanced the research in vision and language understanding, cross-modality matching, path planning, and reasoning. However, all these tasks are designed for ground-based agents and overlook the application scenario of navigation in the sky using unmanned aerial vehicles (UAVs). To bridge this research gap and enable navigation in the sky, this paper proposes a city-level UAV-based vision-and-language navigation task called AerialVLN, along with a corresponding dataset. AerialVLN is significantly different from ground-based VLN tasks in several aspects. First, it has a larger action space, requiring agents to consider actions such as "rise up" and "pan down". Moreover, multirotors can move left or right without turning their heads. Second, the outdoor environments in AerialVLN are much larger and more complex, covering a variety of city-level scenes. Agents must be able to distinguish referred buildings and objects based on their spatial relationships from a bird's-eye view. Third, AerialVLN involves longer paths compared to ground-based VLN tasks, requiring agents to navigate through city-level environments. Fourth, agents must learn to avoid obstacles in 3D space, which is more challenging than avoiding obstacles on the ground. The AerialVLN dataset consists of 25 different city-level environments with over 870 different kinds of objects. The dataset includes 8,446 flying paths obtained from experienced human UAV pilots. Each path is paired with three instructions annotated by AMT workers, allowing for fine-grained cross-modality matching learning. The instructions have an average of 83 words and a vocabulary of 4,470 words. The paper also evaluates five baselines, including two standard VLN models and a proposed model.Overall, AerialVLN presents a new and highly challenging task for navigation in the sky using UAVs. The dataset and proposed models provide a foundation for future research in this area.