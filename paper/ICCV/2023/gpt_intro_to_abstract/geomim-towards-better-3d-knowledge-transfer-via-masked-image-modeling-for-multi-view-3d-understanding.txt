Multi-view camera-based 3D detection is a critical problem in computer vision. To improve detection performance, previous works have used a pre-trained LiDAR model as a teacher and transferred its knowledge to a camera-based student network. However, there is a significant domain gap between the LiDAR model's bird's eye view (BEV) features and the camera-based model's features, due to the differences in 3D point clouds and 2D images. In this paper, we propose Geometry Enhanced Masked Image Modeling (GeoMIM) to bridge this domain gap and improve multi-view camera-based 3D detection. GeoMIM integrates a multi-camera vision transformer with Cross-View Attention blocks and enables perspective-view representation pretraining via BEV feature reconstruction. By reconstructing the LiDAR model's BEV features, GeoMIM enhances the camera-based model's capability for joint multi-view inference. Experimental results show that our approach achieves state-of-the-art results on the nuScenes dataset for 3D detection and segmentation. We also demonstrate successful transfer learning to the Waymo Open dataset, improving the performance of an ImageNet-initialized 3D detector.