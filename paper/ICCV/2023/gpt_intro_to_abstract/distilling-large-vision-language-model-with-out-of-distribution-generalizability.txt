Recent advancements in large vision language models (VLMs) have shown great potential in various applications. However, their large sizes and high computational requirements hinder their deployment on edge devices and scenarios that require rapid network inference. To address this limitation, we investigate the principles and techniques for distilling visual representations from large VLMs to smaller models. We focus on out-of-distribution (OOD) generalization and propose techniques to maintain the relationship between the visual and language representation spaces of the teacher models. Our experiments demonstrate the effectiveness of our techniques in improving student models' OOD generalization ability. We also explore the enrichment of teacher language representations to enhance visual space and vision-language alignment. Our thorough experimental analysis provides valuable insights and demonstrates the impact of our techniques on OOD generalization. Our study contributes to the understanding and development of small and compact models with strong generalizability in diverse open-set concepts encountered in the real world.