Abstract: Surface reconstruction from 3D point clouds is a crucial task in computer science and has various downstream applications. Existing methods often rely on learning implicit representations from point clouds and using these representations to reconstruct surfaces using the marching cubes algorithm. However, these methods struggle with generalization to large structure or geometry variations in training samples. Recent approaches have achieved better generalization by directly overfitting neural networks on single unseen point clouds, but they suffer from slow convergence and extensive distance calculations, making them unsuitable for large-scale point cloud reconstruction. In this paper, we present a novel approach called GridPull to address the scalability challenge in surface reconstruction from large-scale point clouds. GridPull does not require learned priors or point normals and infers a distance field directly from the point cloud without using neural components. We achieve faster inference by inferring the distance field on grids near the surface and organizing surface points in a tree structure for efficient nearest neighbor search. Our loss function encourages continuous distances and consistent gradients in the field, compensating for the lack of continuity caused by neural networks. We evaluate the effectiveness of GridPull through numerical and visual comparisons with state-of-the-art methods on widely used benchmarks. Our results demonstrate that GridPull outperforms existing methods in terms of both speed and accuracy in surface reconstruction. In summary, our contributions include: 1. Introducing GridPull, a method for reconstructing surfaces from large-scale point clouds without using neural networks. 2. Proposing a loss function that enables the inference of a discrete distance field with continuous distances and consistent gradients. 3. Demonstrating the superiority of GridPull over state-of-the-art methods in terms of speed and accuracy on benchmark datasets.