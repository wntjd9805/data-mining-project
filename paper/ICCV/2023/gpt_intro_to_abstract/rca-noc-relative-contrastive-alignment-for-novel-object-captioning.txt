This paper introduces a novel approach called Relative Contrastive Alignment (RCA) for learning the relative semantic relevance between images and their corresponding object tags in a loose form. The goal is to achieve vision and language alignment and improve the discriminative ability of the multi-modality representation. The authors utilize CLIP to generate a list of contrastive tags that are closely linked to an image, and divide the list into a relevant part and an irrelevant part based on the relative semantic relevance. They propose a contrastive learning objective that treats tags in the relevant part as positive and tags in the irrelevant part as negative, with the aim of aligning vision and semantics. In addition, the authors propose a method called Uncertainty-Aware Selection and Reweighting (UASR) to estimate and exploit the uncertainty of each contrastive sample, mitigating the negative effect of noisy tags. The proposed RCA method is evaluated on the Nocaps and Held-Out COCO datasets and outperforms other state-of-the-art methods. The contributions of this paper include the introduction of RCA for relative semantic relevance learning, the use of UASR for uncertainty estimation, and the validation of the proposed method on benchmark datasets.