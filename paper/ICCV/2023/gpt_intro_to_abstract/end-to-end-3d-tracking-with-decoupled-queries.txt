Multi-object tracking (MOT) in 3D scenes is crucial for accurate object localization and identification in applications like autonomous driving and robotics. Previous methods have primarily used pre-defined 3D detectors and post-processing to track objects, relying heavily on geometry cues. However, this approach hinders the use of appearance features for better identity distinction in camera-based settings. To address this issue, recent learning-based methods have emerged for end-to-end tracking, such as tracking-with-query approaches that employ queries in the transformer for association. However, balancing detection and tracking performance simultaneously in 3D scenes remains challenging. This paper proposes a novel framework called DQTrack for 3D object tracking, which utilizes decoupled queries to address the task conflict representation and enhance query capability. The framework solves the association and track representation update problems, enabling end-to-end 3D object tracking and detection. Experimental studies demonstrate the effectiveness of DQTrack, surpassing previous learning-based trackers and achieving leading performance on the nuScenes dataset.