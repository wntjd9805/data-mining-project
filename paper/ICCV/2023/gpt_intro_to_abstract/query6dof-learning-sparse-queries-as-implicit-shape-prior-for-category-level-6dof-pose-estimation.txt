Category-level object pose estimation is an important task in robotics, 3D understanding, and augmented reality. Existing methods for solving this problem typically reconstruct the object point cloud and estimate correspondences between the observed and reconstructed point clouds. However, these methods have drawbacks such as the use of dense and static shape priors, which are computationally expensive and not adaptive to intra-category variability. To address these issues, we propose a novel method called Query6DoF that utilizes sparse and learnable category-specific queries as shape priors. These queries encode specific components of an object's shape and are optimized concurrently with the model parameters. The deformation-and-matching paradigm is performed in feature space using an attention mechanism, allowing the queries to transform from category-specific to instance-specific shape representations. Our model is trained entirely and directly, eliminating the need for pre-learned priors and surrogate training objectives. We also introduce an efficient global enhancement layer to balance efficiency and performance. Experimental results show that our method achieves state-of-the-art performance on pose estimation tasks. Our contributions include the use of sparse and learnable queries as shape priors, the adaptation of existing architectures to fit the novel shape prior representation, and improved pose estimation accuracy on benchmark datasets.