3D object detection using LiDAR point clouds is a fundamental task in autonomous driving. LiDAR sensors are commonly used in various 3D applications due to their ability to provide accurate distance information. Existing LiDAR-based 3D object detection methods use either point-based or voxel-based networks to generate bounding boxes for foreground objects. However, the sparsity of LiDAR point clouds poses challenges in detecting distant and occluded objects. To address this, point cloud completion methods have been explored but they fail to capture contextual information and indiscriminately produce dense point clouds for all proposals. In this paper, we propose the Point Generation R-CNN (PG-RCNN), a two-stage 3D object detection method that generates geometrically and semantically rich point clouds for proposal refinement. Our method utilizes a RoI point generation (RPG) module that estimates the shape and displacement of foreground objects using primitive RoI features. Unlike previous completion methods, our method assigns a semantic feature to each generated point, allowing for more informative point clouds. We demonstrate the effectiveness of our approach on the KITTI dataset, achieving competitive performance with state-of-the-art models while reducing computational cost. Our method better serves the purpose of refining false-positive or misaligned proposals compared to previous point cloud completion methods. Overall, our contributions include the introduction of PG-RCNN, a two-stage method for LiDAR-based 3D object detection, a comparison of point generation results with a previous completion method, and achieving competitive performance with fewer parameters and inference time.