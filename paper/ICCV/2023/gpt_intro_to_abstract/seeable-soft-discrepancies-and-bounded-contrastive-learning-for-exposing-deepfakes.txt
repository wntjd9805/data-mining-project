Recent advances in deep generative models have enabled the generation of fake images and videos with unprecedented levels of realism, leading to the creation of deepfakes. Deepfakes pose a serious threat to individuals and society as a whole, and the deep learning community is actively working on countermeasures and detection techniques. To improve the generalization capabilities of deepfake detectors, synthetic data (pseudo deepfakes) and diverse augmentation techniques have been used during training. However, these methods are limited by the discriminative nature of the training procedure. In this paper, we propose a novel deepfake detector called SeeABLE that formulates the detection problem as an out-of-distribution task and generalizes better to unseen deepfakes. SeeABLE is trained using only real face images and utilizes soft discrepancies, local image perturbations, and a novel bounded contrastive regression loss to detect minute inconsistencies and exploit additional localization cues. Experimental results on multiple datasets demonstrate the superior performance and generalization capabilities of SeeABLE compared to existing deepfake detectors. The contributions of this paper include the introduction of SeeABLE, the novel Bounded Contrastive Regression loss, and the demonstration of its superior performance through rigorous experiments.