This paper focuses on the problem of multi-organ semantic segmentation in medical imaging, which is crucial for various medical applications. While deep learning models trained on specific datasets have shown comparable performance with human observers, there are limitations in their practical deployment for clinical applications. Specifically, these models are pre-trained to segment a fixed number of organs, and cannot dynamically extend to include new organs without access to previous training datasets or training from scratch. This paper introduces the concept of continual semantic segmentation (CSS) in the medical imaging domain, where segmentation models can be dynamically extended to enable segmenting new organs without re-accessing previous training datasets. The paper highlights the challenges associated with multi-organ CSS, such as the issue of catastrophic forgetting, limited availability of fully annotated medical image datasets, and domain gaps in incremental learning. The paper proposes a novel architecture-based continual multi-organ segmentation framework that addresses these challenges. The framework includes a general encoder, expanding and pruning decoders, and an output merging module. The proposed framework is trained and validated on 3D CT scans of over 2500 patients from different datasets, achieving high accuracy in segmenting a total of 143 whole-body organs. The paper contributes to the field by comprehensively studying the multi-organ CSS problem and proposing a scalable and non-forgetting segmentation framework.