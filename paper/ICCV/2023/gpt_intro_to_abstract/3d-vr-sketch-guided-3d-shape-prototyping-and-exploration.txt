The demand for convenient tools for 3D content creation is increasing, especially in fields like architecture and cinematography. While text and image priors have been used to create 3D shapes, 2D freehand sketches are considered more expressive and precise. Sketch-based modeling from 2D sketches has gained attention as a convenient tool, but it requires substantial sketching expertise and may result in ambiguous representations. With advancements in virtual reality (VR) technology, 3D VR sketches are gaining popularity as an input modality in 3D modeling and retrieval. However, existing works on 3D shape modeling focus on the interface and logistics, assuming carefully created inputs. In this paper, we propose a novel method for 3D shape modeling using 3D VR sketching that does not require professional training or detailed sketches. Our method is trained and tested on a dataset of sketches created by participants without art experience, making it more accessible and practical for real-world applications. We generate multiple shape variations that resemble the input sketch, allowing the user to select or refine the design. Working with freehand VR sketches poses challenges due to limited datasets and misalignments between sketches and 3D shapes. We address these challenges by representing sketches as point clouds and regressing Signed Distance Fields (SDFs) values. We introduce a sketch fidelity loss to ensure the fidelity of reconstruction to the input sketch. Overall, our method tackles the problem of limited data, misalignments, and the abstract nature of freehand sketches in 3D shape generation from rapid and sparse 3D VR sketches.