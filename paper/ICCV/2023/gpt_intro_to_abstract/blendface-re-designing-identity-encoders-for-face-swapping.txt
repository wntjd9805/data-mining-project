Face-swapping is a popular task in computer vision, with potential applications in various fields such as films and metaverses. Recent advancements in generative adversarial networks (GANs) have enabled the generation of photorealistic images, including attributes like facial expression, hair, pose, and background. Additionally, the improvement in face recognition models has provided powerful identity encoders for face-swapping. However, existing methods suffer from identity-attribute entanglements caused by biased guidance from face recognition models. These models tend to swap undesirable attributes, such as hairstyles and head shapes. In this paper, we propose BlendFace, a novel identity encoder that provides well-disentangled identity features for better face-swapping results. We demonstrate that BlendFace successfully addresses the issue of attribute leakages and improves the quality of one-shot face-swapping models.