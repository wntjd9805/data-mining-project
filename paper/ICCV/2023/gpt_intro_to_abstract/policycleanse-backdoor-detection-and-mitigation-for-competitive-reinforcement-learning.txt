Reinforcement Learning (RL) is a popular method used to train intelligent agents in various applications. However, ensuring the security and robustness of RL agents, particularly in safety-critical applications, is of utmost importance. In this paper, we focus on the security problem of competitive reinforcement learning (CRL) systems, where two agents compete against each other. It has been shown that CRL systems are vulnerable to adversarial attacks, with one of the most representative attacks being the backdoor attack. In this attack, a Trojan agent is embedded with trigger actions that compromise the system when observed by the victim agent. Our work aims to address the backdoor detection problem in CRL, which is challenging due to the high complexity of multi-agent dynamics. We propose an approach called PolicyCleanse that detects potential backdoor triggers by optimizing a separate policy with a reversed reward function. We also propose an unlearning-based mitigation approach to purify the Trojan agent's policy. Our experiments demonstrate the effectiveness and robustness of PolicyCleanse in detecting and mitigating backdoor attacks in various CRL scenarios. Overall, our contributions include the proposal of PolicyCleanse as a backdoor detection approach, the introduction of the RL backdoor defense problem, and the evaluation of PolicyCleanse's performance against different types of attacks.