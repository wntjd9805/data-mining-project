Deep learning has been highly successful in computer vision tasks, but current research focuses mainly on visible patterns and lacks the ability to reason about occluded information. This paper addresses the task of video amodal segmentation, which aims to deduce complete object masks, even in partially obscured situations. Previous studies have relied on prior knowledge, limiting generalization abilities. This paper proposes a novel approach that leverages supervised signals with object-centric representation and integrates information from different views. The approach utilizes front-view features transformed into bird's-eye view features, which capture 3D information. The proposed model achieves outstanding performance on real-world and synthetic benchmarks, demonstrating the effectiveness of the architecture. The contributions of this paper include formulating the video amodal segmentation task using supervised signals, proposing a multi-view fusion layer with object slots, introducing bird's-eye view features, and achieving notable improvements in performance.