Neural radiance field (NeRF) is a 3D representation model that uses a multi-layer perceptron (MLP) to capture geometry and view-dependent appearance for rendering realistic novel views. However, this approach requires computationally expensive reconstruction and rendering processes. Other methods have proposed explicit or hybrid representations for efficient rendering and reconstruction, but they suffer from issues such as blurring and aliasing. In this paper, we present Tri-Mip radiance fields (Tri-MipRF), a novel representation that supports high-fidelity anti-aliased renderings and efficient reconstruction. Tri-MipRF achieves state-of-the-art rendering quality, can be reconstructed quickly, and has a compact model size. We introduce Tri-Mip encoding, which decomposes the 3D space into three planes and represents each plane using a mipmap. We also propose a cone-casting rendering technique that formulates pixels as discs and emits cones for each pixel. Our method effectively connects the Tri-Mip encoding with cone-casting rendering, resulting in renderings that are free of blurring and aliasing. We evaluate our method on benchmarks and real-world images, demonstrating its effectiveness for high-fidelity rendering and fast reconstruction. Our contributions include the Tri-Mip encoding, cone-casting rendering, and a hybrid volume-surface rendering strategy for real-time rendering on consumer-level devices.