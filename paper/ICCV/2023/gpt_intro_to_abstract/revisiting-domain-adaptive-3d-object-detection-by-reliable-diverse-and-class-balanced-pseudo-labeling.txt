LiDAR-based 3D object detection in applications such as robotic systems and self-driving automobiles presents challenges in deploying detectors in real-world scenes due to a domain gap between training and test point cloud data. This domain gap arises from object shift and environmental shift, which can significantly degrade the accuracy of 3D detectors. To address this problem, domain-adaptive 3D detection approaches have been explored, including self-training paradigms and self-supervised techniques. However, prior works have predominantly focused on single-class training settings, and when transitioning to a multi-class scenario, the detection performance decreases. To tackle this issue, this paper proposes the Reliable, Diverse, class-Balanced (REDB) framework for generating pseudo labels in the domain-adaptive 3D detection task. The REDB framework incorporates mechanisms such as cross-domain examination to assess label reliability, OBC-based downsampling to enhance geometric diversity, and class-balanced self-training to address inter-class imbalance. The proposed framework is evaluated on three large-scale testbeds, demonstrating exceptional adaptability and improvements in 3D mean Average Precision (mAP) over state-of-the-art methods.