This paper introduces a novel deep learning-based approach for online video stabilization. Traditional methods for video stabilization involve three main steps: camera motion estimating, camera path smoothing, and steady frame synthesis. However, deep learning-based methods often produce visually inferior results compared to traditional methods because they try to learn all three steps in a unified framework without considering the different characteristics of each step. In this work, the authors argue that it is not necessary to encompass all three steps in the learning pipeline and propose focusing solely on learning to stabilize shaky camera motion using deep motion models. They also address the distinction between offline and online camera path smoothing, where offline methods optimize the path globally after video capture, while online methods aim to stabilize the video during capture. The availability of future frames significantly affects the stability, making online methods less effective in suppressing low-frequency camera shake. To address this, the authors propose a deep online camera path smooth network that takes a pre-estimated 2D camera trajectory as input and outputs the motion compensation warp field for the last frame in real-time. They employ a mesh-based motion model that demonstrates robustness in various scenes to handle depth changes and moving objects. The authors further propose a hybrid loss function to maintain spatial coherence and temporal continuity in the stabilized video. They create a motion dataset, MotionStab, consisting of stable and unstable video pairs, which are used to train the network. The authors demonstrate the effectiveness of their approach through extensive experiments and comparisons with existing state-of-the-art methods.