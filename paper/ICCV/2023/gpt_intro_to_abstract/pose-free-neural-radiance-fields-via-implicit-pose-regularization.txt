Recent advancements in novel view synthesis have been driven by the development of neural radiance fields (NeRF) that can generate high-quality novel views with multi-view consistency. However, existing NeRF methods heavily rely on accurate camera poses, which are often difficult to obtain and not available in many image datasets. To tackle this limitation, some approaches train NeRF with unposed multi-view images using inaccurate camera poses or prior knowledge about camera pose distributions. Another approach avoids using pose information altogether but suffers from biased or inaccurate pose estimation due to the domain gap between rendered and real images. In this paper, we propose IR-NeRF, a novel pose-free NeRF that introduces Implicit Regularization to improve the robustness of pose estimation for real images. Our method constructs a scene codebook to encode scene-specific pose distributions and utilizes a pose-guided view reconstruction scheme to refine the pose estimator with unposed real images. Experimental results demonstrate that IR-NeRF achieves superior novel view synthesis performance compared to existing methods. The contributions of our work are threefold: the introduction of IR-NeRF, a novel pose-free NeRF with implicit pose regularization; the construction of a scene codebook to encode scene-specific pose distributions; and the design of a pose-guided view reconstruction scheme to refine the pose estimator with unposed real images, enhancing its robustness.