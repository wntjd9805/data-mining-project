Deep learning approaches have greatly impacted computer vision and are increasingly being utilized in safety-critical applications like automated driving. However, ensuring that these models perform well across all subgroups within an operational design domain is crucial for their deployment in safety-critical domains. Unfortunately, classifiers trained on data with spurious correlations often result in shortcut decision-making, which can lead to failures on rare subgroups. To address this issue, model auditing becomes necessary to evaluate the behavior of classifiers on various subgroups. This paper proposes PROMPTATTACK, a procedure that uses text-to-image models to synthesize images of subgroups encoded directly in the prompt. By leveraging combinatorial testing, PROMPTATTACK covers a large subset of subgroups in the operational design domain. The paper also introduces a benchmark for systematic error identification and demonstrates the effectiveness of PROMPTATTACK in identifying systematic misclassifications on rare subgroups of ImageNet classifiers.