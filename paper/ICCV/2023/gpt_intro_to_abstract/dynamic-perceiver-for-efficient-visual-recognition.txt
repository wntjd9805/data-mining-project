Convolutional neural networks (CNNs) and vision Transformers have significantly advanced visual recognition. However, the high computational demands of these models hinder their deployment in resource-constrained scenarios. Dynamic networks, which can adapt their computation based on input complexity, offer a potential solution for efficient visual recognition. Dynamic early-exiting networks construct multiple classifiers along the depth dimension, allowing for rapid prediction of "easy" samples. Existing implementations build early classifiers on intermediate features, leading to interference and degradation of the final exit performance. This paper introduces Dynamic Perceiver (Dyn-Perceiver), a novel two-branch structure that decouples feature extraction and early classification. Dyn-Perceiver leverages a latent code to embed semantic information and employs a trainable classification branch to process this code. Information exchange occurs through symmetric cross-attention layers, reducing the token number of image features. Multiple classifiers are situated in the classification branch, enabling early predictions without hindering feature extraction. The proposed design achieves explicit decoupling of feature extraction and early classification, simplifies the framework, and attains top-tier performance with various vision backbones. Dyn-Perceiver demonstrates superior accuracy-efficiency trade-off in ImageNet classification and enhances performance-efficiency in action recognition and object detection tasks. Experimental results show remarkable increase in inference efficiency without compromising accuracy and practical latency on different hardware platforms.