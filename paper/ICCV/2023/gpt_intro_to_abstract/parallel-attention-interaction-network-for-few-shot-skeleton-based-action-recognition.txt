Skeleton-based action recognition has become a prominent topic in various fields due to its action-focused nature and compactness. However, identifying novel actions still remains a challenge. To address this issue, few-shot action recognition has gained attention. These methods utilize unlabeled query and labeled support sets to learn a discriminative feature representation for matching query actions with categories represented by a few support samples. Current approaches focus on either exploiting intra-skeleton or inter-skeleton relations, ignoring the complementarity between the two paradigms. This limits their effectiveness in scenarios with similar spatial appearances or inconsistent temporal dependencies. Some works explore discriminative features within sequences, while others adjust local features across sequences. However, considering either the dependency within sequences or the association between sequences alone is inadequate. In this paper, we propose a novel few-shot skeleton-based action recognition framework called Parallel Attention Interaction Network (PAINet). PAINet aligns the spatial and temporal domains within two parallel branches to enable complementary attention to informative regions in the skeleton sequence. We introduce a topology encoding module and employ spatial cross-attention and spatial self-attention modules for cross-spatial and cross-temporal alignments, respectively. Our experimental results demonstrate that PAINet outperforms state-of-the-art methods in terms of action recognition accuracy.