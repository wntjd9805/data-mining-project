Stereo depth estimation is a fundamental computer vision task that is crucial for numerous applications such as autonomous driving, robotics, and virtual/augmented reality. Traditional methods for depth estimation struggle to handle textureless areas and often produce unreliable results. Recent advancements in deep learning have led to the development of methods that can generate smooth results in textureless regions by learning shape priors. However, these methods still face limitations in handling inherent ambiguities and require controlled environments. In this paper, we propose an end-to-end neural network called DPS-Net that predicts depth from polarimetric stereo images. We address the challenges of combining polarimetric and photometric domains, solving inherent ambiguities in polarization information, and the lack of real polarimetric stereo datasets. Our network integrates polarization constraints and learned shape priors using a cascaded dual-GRU module to achieve accurate depth estimation. We also present synthetic and real polarimetric stereo datasets for training the network. Our contributions include the first learning-based framework for polarimetric stereo depth estimation, a novel cascaded dual-GRU architecture, and the integration of multi-domain similarity measurement and polarization cues to solve inherent ambiguities. Extensive experiments demonstrate the superior performance of our method compared to state-of-the-art learning-based and traditional polarimetric methods.