Speech-driven portrait animation, which involves animating a static face image using an input speech signal, has various applications in computer games, movies, virtual reality, and telecommunications. However, this task is challenging as it requires predicting facial expressions accurately while ensuring natural-looking animation that aligns with the speech content and maintains video quality. In this paper, we propose SPACE, a method for speech-driven portrait animation with controllable expression. SPACE breaks down the task into subtasks to enhance interpretability and fine-grained control. Our method predicts facial landmark motions, applies desired head poses, and transforms the landmarks into a latent keypoint space for better synthesis quality. We introduce emotion conditioning in SPACE for controlling emotion types and intensities in the generated videos. Our approach achieves state-of-the-art quality, provides realistic head poses, and enables manipulation of emotions in the output videos. By utilizing both explicit and latent keypoints, SPACE offers improved interpretability, controllability, and image quality compared to previous methods.