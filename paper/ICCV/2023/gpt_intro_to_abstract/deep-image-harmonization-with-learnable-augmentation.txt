Image composition is a common image editing operation that involves cutting the foreground from one image and pasting it onto another background image to create a realistic composite image. However, inconsistencies in illumination statistics between the foreground and background images can result in unrealistic composites. Image harmonization aims to adjust the illumination statistics of the foreground to make it compatible with the background, resulting in a harmonious composite image. Training data-hungry deep learning models for image harmonization requires abundant pairs of composite images and harmonious images, which are difficult to obtain manually. Recent approaches have focused on adjusting the foreground of real images to generate synthetic composite images paired with ground-truth harmonious real images. Different datasets have been constructed using various foreground adjustment approaches, such as traditional color transfer methods or replacing the foreground with retouched or differently captured foregrounds. Despite similar construction pipelines, these datasets have considerably different data distributions due to factors like image source, capture device, scene type, and foreground adjustment approach. This paper addresses the challenge of limited training data on small-scale datasets by augmenting them with synthetic composite images. An augmentation network called SycoNet is developed to automatically generate synthetic composite images by simulating the original foreground adjustment approach. The generated synthetic composite images are used to enhance the training of an existing image harmonization network. The proposed learnable augmentation method significantly improves the harmonization performance, as demonstrated through experiments on various datasets. Overall, this work contributes a novel approach for enriching the illumination diversity for image harmonization and demonstrates the effectiveness of the proposed learnable augmentation method.