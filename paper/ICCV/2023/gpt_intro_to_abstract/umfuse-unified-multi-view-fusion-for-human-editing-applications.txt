Automating person-image editing is valuable for business applications such as advertisements and individual creativity. Pose-based image editing relies on human poses for editing workflows, but current methods suffer from artifacts due to limited image information. This paper presents a novel pose-guided human image generation method that incorporates multiple images and leverages existing reposing models to improve editing results. The method uses a deep neural network to transform a source image into a target pose, but when the target pose differs significantly from the source pose, the network must infer certain regions from context. To address this, the paper proposes using multiple source images and mapping corresponding parts based on texture matching. The paper introduces UMFuse, a framework that fuses pose and appearance features from different source images for human image editing. It also introduces the multi-view human reposing task and provides a benchmark dataset for evaluating the output quality. Additionally, the paper includes quantitative and qualitative analyses, comparisons, and ablation studies to demonstrate the effectiveness of the proposed method.