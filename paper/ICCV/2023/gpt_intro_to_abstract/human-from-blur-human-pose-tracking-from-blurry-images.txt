Accurate tracking of human motion is crucial for various applications such as human-robot collaboration, human-machine interaction, and autonomous driving. However, fast motion and low light conditions can result in blurry images, making it challenging to estimate human pose accurately. While there are methods for 3D pose estimation and image deblurring, none of them can handle substantially blurred images or estimate poses at sub-frame accuracy. To address this gap, we propose a method that recovers human pose at sub-frame accuracy from blurry inputs. Our contributions include the first method for pose estimation from blurred images, a synthetic dataset and real-world motion-blurred data for evaluation, and a learning-free approach that relies on test-time optimization. We also provide an overview of our method, which involves generating sub-frame appearances and silhouettes, reconstructing blurry frames, and utilizing image reconstruction and matting losses. Our method is efficient and does not require large amounts of annotated training data.