Visual object tracking (VOT) is a crucial research topic in computer vision, with applications in video surveillance, anti-UAV tracking, and automatic driving. However, VOT still faces challenges such as deformation, motion blur, and background interference. Various approaches have been proposed to address these challenges, including CNN-based, hybrid CNN-Transformer, and pure Transformer trackers. While pure Transformer trackers have shown promising results in feature extraction, they can be disrupted by complex backgrounds due to a lack of consideration for fore-background relationships. In this paper, we address this issue by considering two core aspects: (1) effective fore-background information mining for both template and search region, and (2) target-aware feature interaction. We propose a new attention mechanism to achieve better target-aware feature interaction, resulting in improved tracking performance.