This paper addresses the issue of poor generalization in image classification due to the presence of biased features in training data. Previous studies have mainly focused on addressing one known or unknown bias in an image, but in reality, images often contain multiple unknown biases. The authors investigate the coexistence of multiple biases, such as gender, attractiveness, and wearing lipstick, in the CelebA dataset. They discover that a significant percentage of samples exhibit multiple biases. Existing methods fail to effectively capture and remove these multiple biases. Therefore, the authors propose a Partition-and-Debias (PnD) approach that divides the agnostic bias scenario space into multiple subscenario spaces, each handled by a biases-specific expert. The final prediction is obtained through a gating module that considers the consensus of all experts. Experimental results on public and constructed bias datasets demonstrate the effectiveness of the proposed method.