Livestreaming Product Recognition (LPR) is a machine learning application in the e-commerce industry that aims to recognize products presented in a live commerce clip. The real-time and accurate recognition of livestreaming products can improve the online product recommendation and enhance the purchasing efficiency of consumers. The LPR task involves intended product identification and product retrieval from a shop. This task poses challenges in distinguishing intended products from background products, capturing fine-grained features, handling video-to-image and cross-domain problems, and addressing appearance changes due to various factors. Existing datasets for LPR lack crucial text modal and have limited data scale. To address these limitations, LPR4M, a large-scale multi-modal live commerce dataset, is introduced. It includes extensive categories, diverse data modalities, and heterogeneous correspondences. LPR4M offers advantages in terms of data scale, expressivity, and diversity. A proposed approach based on LPR4M uses instance-level contrastive learning and patch-level semantic alignment to achieve fine-grained LPR. Patch Feature Reconstruction loss is introduced for patch-level supervision. The main contributions of this paper include the collection of a large-scale live commerce dataset, the introduction of the RICE model, the proposal of the Patch Feature Reconstruction loss, and the definition of benchmark datasets and evaluation protocols. Experimental results demonstrate the effectiveness of LPR4M and the proposed approach.