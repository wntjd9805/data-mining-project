The number of blind individuals worldwide is increasing, with projections indicating further increases in the future. Visual assistance technology and walking assistants have been developed to aid individuals with visual impairments in navigating outdoor environments. Semantic segmentation methods, such as convolutional neural networks (CNNs) and Vision Transformers (ViTs), have shown promising results in assisting visually impaired individuals to walk on blind roads. However, these methods often rely on visual images, which can be inadequate in low illumination environments. As a solution, thermal infrared semantic segmentation has been proposed. However, existing processing techniques often overlook the influence of thermal imaging characteristics on the segmentation task. In this paper, we address this limitation by incorporating two key factors, atmospheric transmission and the thermal inertia effect, into the thermal infrared image processing pipeline. We propose a thermal blind road segmentation network that effectively leverages these effects, resulting in improved accuracy compared to previous methods. Additionally, we introduce a large-scale thermal infrared blind road segmentation dataset with pixel-level annotations, which is publicly available. Our method achieves state-of-the-art performance on both our dataset and benchmark datasets.