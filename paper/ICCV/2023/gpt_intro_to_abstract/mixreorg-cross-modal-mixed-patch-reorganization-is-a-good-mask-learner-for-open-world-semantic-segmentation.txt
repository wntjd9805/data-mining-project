Image segmentation has various applications in virtual presence, virtual try-on, movie post-production, and autonomous driving. Current state-of-the-art semantic segmentation methods heavily rely on densely annotated data, which limits their performance in closed-set settings. However, in real-world scenarios, where new concepts constantly emerge, learning an open-world segmentation model is more practical but challenging. Early methods address this by using few-shot learning or unsupervised clustering, but they still assume that training and testing classes are in the same feature space. In this paper, we propose MixReorg, a novel approach for open-world segmentation. MixReorg constructs fine-grained patch-text pairs from image-text data, allowing the model to learn mixed image reorganization from high-level semantics. We also introduce a mixing restoration strategy to ensure semantic association between patch tokens and text, suppressing interference from patches of different images. Our experiments demonstrate that MixReorg outperforms existing zero-shot segmentation baselines and achieves high performance on evaluation datasets. We contribute by providing a method to construct patch-text data for open-world segmentation and addressing the challenges of low-level features and irrelevant patches in mixed image segmentation.