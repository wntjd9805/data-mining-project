Deep learning has achieved remarkable success in single task learning on large datasets, but obtaining refined data for real-world applications is often expensive and limited in some domains. Lifelong few-shot learning combines lifelong learning and few-shot learning to overcome catastrophic forgetting and learn from limited data without overfitting. While previous studies have focused on discriminative tasks, little research has been done on lifelong few-shot learning for generative tasks such as image generation. This task involves training a model to generate realistic and diverse images from a small number of training examples while continually learning new tasks and preserving the ability to generate images from previous domains. Two key challenges in this setting are the forgetting of previous task generation abilities and the mode collapse problem due to biased and sparse training distributions. To address these challenges, we propose a framework called Lifelong Few-Shot Generative Adversarial Network (LFS-GAN) which uses a weight modulation technique called Learnable Factorized Tensor (LeFT) to capture task-specific knowledge with low memory costs. We also propose a cluster-wise mode seeking loss and a novel diversity measure called Balanced Inter- and Intra-cluster LPIPS (B-LPIPS) to improve the diversity of generated images and accurately evaluate generation diversity. Our experiments show that LFS-GAN outperforms current state-of-the-art methods in both lifelong few-shot image generation and few-shot image generation tasks.