The fields of 3D human perception and human reconstruction have seen significant advancements, but limited access to real human data has hindered further progress. Synthetic human datasets have emerged as a valuable research avenue to address this challenge. However, existing synthetic datasets have certain limitations, such as a limited number of human models and low-quality annotations. These limitations stem from the reliance on real scans for rendering the synthetic datasets. This paper introduces a new synthetic dataset called SynBody, which overcomes these limitations. The dataset includes 1.2 million frames with ground-truth 3D human body annotations and covers 10,000 human body models, 1,187 motions, and 26,960 video clips. Key to SynBody is the development of the layered parametric human model called SMPL-XL, which enriches the SMPL-X model with features such as hair, garments, accessories, and textures. The SMPL-XL model allows for the automatic generation of a large number of human models with high-quality annotations. The paper also presents a scalable and automatic system to render images and annotations for the dataset. SynBody supports two tracks for human pose and shape estimation and human neural rendering. Experimental results demonstrate the effectiveness of SynBody for these tasks, highlighting the importance of diversity and annotation quality in downstream applications. Overall, SynBody is a comprehensive synthetic dataset for human perception and modeling, offering significant contributions in terms of subject diversity, layered 3D annotations, and improved performance in various tasks.