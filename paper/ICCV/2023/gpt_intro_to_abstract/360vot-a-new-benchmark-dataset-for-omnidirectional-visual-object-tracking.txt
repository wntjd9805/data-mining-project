Visual object tracking is a crucial problem in computer vision, with applications in video analysis, human-machine interaction, and intelligent robots. While most research in this field focuses on perspective visual object tracking, little attention has been paid to omnidirectional visual object tracking. Omnidirectional visual object tracking utilizes a 360-degree camera to track the target object, offering continuous observation and minimizing out-of-view issues. However, omnidirectional tracking presents new challenges, such as image distortion, stitching artifacts, and occlusion by photographers. To address this problem and evaluate the performance of existing tracking algorithms, we propose a benchmark dataset called 360VOT. This dataset is composed of 120 sequences with diverse scenarios and categories. It includes conventional and additional challenges specific to omnidirectional tracking. We introduce new representations for object tracking, such as bounding field-of-view (BFoV), and provide four types of ground truth annotations. Furthermore, we develop new metrics tailored for omnidirectional tracking evaluation. We benchmark 20 state-of-the-art trackers on 360VOT and establish a new baseline for future comparisons. The contributions of this work include the first benchmark dataset for omnidirectional visual object tracking, exploration of new representations, new evaluation metrics, and extensive evaluations of state-of-the-art trackers.