Novel view synthesis (NVS) is a challenging problem in computer vision and graphics, with applications in virtual reality, augmented reality, and image editing. Differentiable neural rendering has recently been introduced to address this problem, particularly through the use of the neural radiance field (NeRF). While NeRF has been successful in modeling static scenes, extending it to dynamic scenes requires addressing the non-smooth and discontinuous nature of the backward flow field. In this paper, we propose using forward flow as a deformation model, warping the canonical radiance field using forward deformation flow to render images at different time steps. We address the challenges associated with forward warping, including the representation of the canonical radiance field using a voxel grid and solving the many-to-one and one-to-many mapping issues. Our experiments demonstrate the effectiveness of our method in dynamic view synthesis and its superiority over existing methods on various datasets.