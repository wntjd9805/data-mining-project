Indoor 3D reconstruction plays a vital role in various applications such as augmented reality/virtual reality, building information modeling, and automatic robot navigation. However, due to the inherent limitations of 3D sensors and occlusion between objects, reconstruction results often contain incomplete surfaces. Recent advancements in deep learning-based scene completion techniques have shown promise in addressing this issue. However, existing methods primarily rely on convolutional neural networks (CNNs), which have limited ability to capture long-range information necessary for scene completion with incomplete inputs. To overcome this limitation, we propose a Dual-Scale Transformer Network (DST-Net) for large-scale scene completion. By leveraging the capabilities of Vision Transformers (ViT) to capture long-range information, our approach achieves precision in completing missing geometric shapes in scenes. The DST-Net consists of transformer modules designed for different-level scene information and incorporates a contrastive attention training strategy to effectively learn similar and distinguishable shape features. We also introduce a structure loss to enhance geometric accuracy and a Cube Intersection over Target (CIoT) loss to ensure complete output voxels. Our experimental results demonstrate the superior performance of DST-Net compared to state-of-the-art methods. In summary, our contributions include the development of DST-Net for indoor scene surface completion, the proposal of a contrastive attention training strategy, and the introduction of structure loss and CIoT loss to enhance completion accuracy and scene completeness.