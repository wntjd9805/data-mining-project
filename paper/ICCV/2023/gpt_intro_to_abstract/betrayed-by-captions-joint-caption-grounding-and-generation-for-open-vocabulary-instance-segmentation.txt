This paper introduces a unified framework called Caption Grounding and Generation (CGG) for open vocabulary instance segmentation. The framework combines caption grounding, which aligns text and region features, with caption generation, which generates captions for imagery input. The proposed framework utilizes object nouns for grounding and incorporates a caption generation loss to capture context information. Experimental results show that the CGG framework achieves significant improvements in performance compared to previous methods.