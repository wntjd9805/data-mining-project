This paper introduces the concept of visual emotion analysis (VEA) as a task in affective computing. The authors highlight the importance of understanding emotions in AI systems in order to mimic human behavior effectively. They discuss the potential applications of affective computing in various fields such as education, healthcare, advertising, and safety. The authors also discuss existing work in VEA, which mainly focuses on feature design and recognition performance. They highlight the limitations of hand-crafted features and the need for a new and rich dataset for further research in VEA. To address these issues, the authors introduce EmoSet, a large-scale visual emotion dataset annotated with rich attributes. They describe the dataset's superiority over existing ones in terms of scale, annotation richness, diversity, and data balance. The authors also explain the process of dataset construction and attribute annotation. They emphasize the importance of understanding the correlations between attributes and emotions. Finally, the authors present an attribute module for visual emotion recognition and validate it using CNN backbones. The contributions of the paper include the introduction of EmoSet dataset, the development of emotion attributes, in-depth analyses on emotion understanding, and the attribute module for visual emotion recognition.