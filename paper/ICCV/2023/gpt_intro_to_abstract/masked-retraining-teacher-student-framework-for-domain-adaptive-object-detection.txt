Object detection is a fundamental task in computer vision with numerous real-world applications. CNN-based and transformer-based detectors have achieved significant success in challenging benchmarks, but they are vulnerable to domain shift. To address this issue, unsupervised domain adaptation (UDA) has been studied, where the model is trained on a labeled source domain and an unlabeled target domain. Among these UDA approaches, teacher-student frameworks have shown promising results by using pseudo labels from the teacher model to supervise the student model. However, the quality of pseudo labels is often low due to limited number and incorrect predictions caused by domain shift. In this paper, we propose a Masked Retraining Teacher-student framework (MRT) for domain adaptive object detection. MRT leverages a masked autoencoder (MAE) and selective retraining mechanism to improve the performance of the student model. MAE is employed as a self-supervised task on target images, allowing the transformer encoder to gain better knowledge of the target domain from limited pseudo boxes. The selective retraining mechanism periodically re-initializes certain parts of the student parameters to overcome local optimums biased towards incorrect pseudo labels. Experimental results show that our proposed approach outperforms existing methods and achieves state-of-the-art performance on three domain adaptive object detection benchmarks.