Visual object tracking is crucial for various robotic applications, but most existing trackers are developed and evaluated offline. However, in real-world scenarios, the latency caused by the trackers' processing time cannot be ignored. This issue is particularly critical in unmanned aerial vehicle (UAV) tracking scenes. The latency in online tracking leads to outdated tracker outputs and the potential skipping of frames. To address this problem, we propose a framework called PVT++, which converts off-the-shelf trackers into predictive trackers by integrating a predictor. We design a lightweight network architecture that leverages both historical motion information and visual cues for efficient and accurate motion prediction. To overcome the training-evaluation domain gap, we introduce a relative motion factor as a training objective. Additionally, we present an extended latency-aware evaluation benchmark (e-LAE) for any-speed trackers. Empirical results demonstrate that PVT++ significantly improves performance under the online setting and achieves comparable or better results compared to the offline setting. This framework is the first end-to-end solution for online visual tracking and works well for latency-aware tracking in various scenarios.