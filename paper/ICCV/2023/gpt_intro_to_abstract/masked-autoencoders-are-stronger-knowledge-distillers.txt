In this computer science paper, the authors address the challenge of improving the performance of lightweight student models in tasks such as object detection and semantic segmentation. They propose a new paradigm called Masked Knowledge Distillation (MKD) to effectively learn the complete knowledge from a high-capacity teacher model. MKD utilizes a masked autoencoding scheme, where random patches of the student model's input image are masked and the corresponding missing features are recovered by imitating the teacher's output. The authors introduce the concepts of masked convolution and adaptive decoder module to facilitate the integration of MKD with different architectures in fine-grained visual tasks. Experimental results demonstrate that MKD significantly improves the performance of feature-based distillation and establishes new state-of-the-art results in various models and tasks.