Deep neural networks have achieved remarkable success in various tasks, but their performance degrades in the presence of class imbalance, where there are few samples for the majority of classes (tail classes) compared to dominant classes (head classes). Existing methods to address class imbalance either overexpose tail class samples or ignore the issue altogether. This paper proposes a class-aware smoothness optimization algorithm called Imbalanced-SAM (ImbSAM) to tackle overfitting in tail classes. ImbSAM incorporates class priors to restrict the optimization scope to tail classes, improving generalization. The efficacy of ImbSAM is evaluated in long-tailed classification and semi-supervised anomaly detection tasks, demonstrating significant performance improvements for classes with limited training samples.