Automated systems that accurately forecast 3D human-object interactions (HOIs) have significant implications for robotics, animation, and computer vision. However, existing work on HOI synthesis does not reflect real-world complexity. To address this, we propose a learning-based method called "InterDiff" that incorporates a diffusion model with intuitive physics. Our approach focuses on the short-term relative motion of an object with respect to the contact point, which follows a simple and deterministic pattern. InterDiff consists of two components: (i) Interaction Diffusion, a generator that models the distribution of future HOIs, and (ii) Interaction Correction, a physics-informed predictor that synthesizes the object's relative motion with respect to regions in contact on the human body. By injecting plausible dynamics back into the diffusion model iteratively, InterDiff generates realistic human motion sequences with vivid interactions. The two components of InterDiff can be trained separately and naturally conform during inference without fine-tuning. Our contributions include being the first to tackle mesh-based 3D HOI prediction, proposing a diffusion framework that leverages past motion and shape information, and introducing a simple yet effective HOI corrector that incorporates physics priors. Extensive experiments validate the effectiveness of our framework, especially for out-of-distribution objects and long-term autoregressive inference. Our improved generalizability is attributed to design strategies such as promoting simple motion patterns and anticipating interactions within a local reference system.