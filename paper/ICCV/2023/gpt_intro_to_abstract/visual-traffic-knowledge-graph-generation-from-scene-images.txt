This paper introduces Visual Traffic Knowledge Graph Generation (VTKGG), a high-level traffic scene understanding task that aims to provide comprehensive and well-formatted traffic scene information for autonomous driving systems. While subtasks such as road segmentation, lane detection, and traffic sign detection have made significant progress, they provide limited low-level output and are insufficient for auto drive.VTKGG extracts traffic information from traffic scene images and organizes this information into a knowledge graph. The graph connects roads, lanes, locations, warnings, and other elements, providing a comprehensive representation of the traffic scene. However, generating such a graph is complicated due to the relationships between traffic signs, their components, and their correspondence to traffic elements.Previous studies have addressed aspects of traffic scene understanding, but they have limitations. This paper proposes a novel architecture called the Hierarchical Graph ATtention network (HGAT) to integrate the reasoning of different relations in the traffic knowledge graph â€“ S-S relations, C-C relations, and A-T relations. A large dataset called CASIA-Tencent Road Scene dataset (RS10K) is collected and annotated to train and evaluate the proposed framework.The overall framework includes a sign component detector, graph construction, feature refining, relation classification, text recognition, and attribute recognition. The HGAT architecture organizes its layers in a top-down manner, with cross-level links facilitating cross-level interaction. The traffic knowledge graph is generated by leveraging the correlation between relations and embedded edges between traffic elements.The RS10K dataset consists of 10,066 high-resolution images, with 42,923 annotated traffic signs of different types. The dataset provides comprehensive annotations, including road masks, road directions, lane masks, lane types, sign components, and relations. RS10K can be used for various tasks in addition to VTKGG, such as road and lane segmentation, and traffic sign detection.The contributions of this paper include the proposal of the VTKGG task, the introduction of the RS10K dataset, and the framework for VTKGG utilizing HGAT. Experimental results on RS10K demonstrate the effectiveness of the framework, achieving state-of-the-art performance compared to other relation reasoning methods.