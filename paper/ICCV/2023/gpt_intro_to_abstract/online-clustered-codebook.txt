Vector Quantisation (VQ) is a widely used technique in machine learning for tasks such as data compression, recognition, and generation. However, VQ has limitations when applied to deep networks, including codebook collapse and low codevector utilization. In this paper, we propose a new alternative quantiser called Clustering VQ-VAE (CVQ-VAE) to address these issues. Inspired by dynamic cluster initialization techniques, CVQ-VAE dynamically initializes unoptimized codebooks by resampling them from learned features. We demonstrate that this approach significantly improves codebook utilization and outperforms previous models on various datasets. We also incorporate CVQ-VAE into large models to showcase its generality and potential in different applications.