The paper introduces the concept of vision-language navigation (VLN) and its relevance in developing intelligent robots that can understand and follow human instructions. The standard VLN setting involves agents navigating in 3D environments with language instructions, but their movement is constrained to a small set of predefined locations. To address the limitations of this setup, the paper proposes a continuous version of VLN (VLN-CE) where agents have the freedom to traverse any unobstructed location. However, VLN-CE poses challenges in strategic planning due to the continuous nature of the environment. In response, the paper presents DREAMWALKER, a VLN-CE agent that uses a world model to abstract the continuous environment into a discrete representation, enabling it to conduct mental planning before taking real actions. The world model consists of an environment graph (EG) that collects temporary knowledge about the surroundings and a learnable scene synthesizer (SS) that predicts future observations. DREAMWALKER synthesizes various navigation trajectories based on the world model, evaluates their progress, and selects the best plan using Monte Carlo Tree Search. Unlike existing VLN-CE solutions, DREAMWALKER uses an explicit, abstract model of the environment and can anticipate the impacts of actions to plan strategically. The paper presents extensive experiments that show promising performance of DREAMWALKER in real-time behavioral interpretation, and highlights the potential for future research in developing more strategic, robust, and interpretable VLN-CE agents.