Indoor 3D object detection using point clouds and deep learning techniques has been extensively studied, but suffers from the high cost of 3D sensors. In contrast, image-based methods are more affordable and can capture rich semantic information. However, monocular image-based methods face challenges such as scale ambiguity, occlusion, and limited field of view. Previous multi-view image-based methods have shown promising results, but neglect the underlying geometric characteristics. To address these limitations, we propose ImGeoNet, a multi-view 3D object detection framework that uses image-induced geometry-aware voxel representation. ImGeoNet learns to induce geometry from multi-view images, reducing the importance of voxels representing free space. Our approach achieves improved detection performance by alleviating confusion from voxels in free space and leveraging a pre-trained 2D feature extractor. We evaluate ImGeoNet on three indoor datasets and outperform state-of-the-art methods in terms of mean average precision. Furthermore, our proposed representation enables image-based methods to outperform point cloud-based methods in scenarios with sparse and noisy point clouds or diverse object classes. The contributions of our work include introducing a geometry-aware voxel representation, achieving state-of-the-art performance, and demonstrating the superiority of our method over point cloud-based methods in practical scenarios.