Anomaly detection (AD) aims to identify instances that exhibit abnormal patterns compared to normal samples. This task is often performed in an unsupervised setting, where only normal samples are available. Humans also recognize anomalies by comparing them with normal visuals based on three discrepancies: patch patterns, image regions, and novel appearances. Existing unsupervised AD methods primarily focus on either patch-wise representation discrepancies or intra- and inter-image correlations to detect anomalies. However, these approaches have limitations in detecting complex anomalies and providing comprehensive spatial context descriptions. In this paper, we propose a novel AD framework called FOcus-the-Discrepancy (FOD) that leverages the modeling capabilities of Transformers to simultaneously capture patch-wise, intra-, and inter-discrepancies. FOD consists of three recognition branches: the patch-wise discrepancy branch, the intra-correlation branch, and the inter-correlation branch. We adapt Transformer to model intra- and inter-image correlations, specifically using self-attention maps to capture spatial context information. To optimize the model, we introduce a two-branch structure, RBF-kernel-based target-correlations as learning targets for self-supervised learning, and an entropy constraint strategy. Experimental results on real-world AD datasets demonstrate that FOD achieves state-of-the-art performance in detecting anomalies by effectively capturing patch-wise, intra-, and inter-discrepancies.