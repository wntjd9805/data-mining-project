Low-light raw denoising is a challenging problem in computational photography. Deep learning algorithms have become the mainstream approach for this task, relying on large-scale datasets of real-world noisy-clean raw image pairs. However, collecting such datasets is labor-intensive. To address this, researchers have explored synthesizing low-light noisy raw images using physics-based and deep neural network (DNN)-based noise models. Physics-based methods analyze the physical process of camera sensor imaging to obtain statistical distributions of noise sources, but they struggle to accurately model all noise sources across different camera sensors. DNN-based methods use deep generative networks to synthesize noise but have been shown to perform poorly on extremely low-light raw images. In this paper, we propose a new perspective on synthesizing realistic low-light raw noise by separating the synthesis process into signal-dependent and signal-independent components. We use a pre-trained denoise network and a multi-scale discriminator to perform image and noise domain alignment, respectively. We also collect a new low-light raw denoising dataset for training and benchmarking. Our experiments demonstrate that our noise model outperforms existing state-of-the-art models on different camera sensors. Overall, our contributions include a general noise model, an effective discriminator framework, and a new benchmark dataset for low-light raw denoising.