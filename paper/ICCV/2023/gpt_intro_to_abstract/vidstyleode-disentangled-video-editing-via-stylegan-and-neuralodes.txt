Semantic image editing has transformed the design industry by allowing users to perform precise edits quickly and intuitively. This is achieved through the use of various inputs, such as text, audio, or scene graphs. However, adapting these capabilities to videos presents challenges, including the lack of large-scale, high-resolution video datasets and the limited capacity of current generative models. Previous attempts have been restricted to low-resolution videos, and image-based methods lack temporal coherency and cross-sequence generalization.To address these limitations, this paper proposes VidStyleODE, a framework for learning spatio-temporal video representations that are suitable for generation and manipulation. The desired properties of these representations include accurate expression of high-resolution videos, robustness to irregular motion patterns, and the ability to control appearance and motion independently. Additionally, the framework aims to learn these representations efficiently from sparse videos.VidStyleODE disentangles video content and dynamics, modeling them as a global code and a latent ordinary differential equation, respectively. This framework explains video frames in the latent space as offsets from the global code, which are determined through solving the latent ODE and applying self- and cross-attention operations. A novel temporal consistency loss based on CLIP is introduced for effective training.The contributions of this paper are as follows: 1) The development of VidStyleODE, a framework that leverages StyleGAN2 and latent ODEs to disentangle content, style, and motion representations. 2) By using latent directions with respect to a global latent code, VidStyleODE enables external conditioning, such as text, making video manipulation more interpretable. 3) The introduction of a non-adversarial video consistency loss that outperforms previous consistency losses at a lower training cost. 4) Demonstration of the framework's capabilities on high-resolution videos, including appearance manipulation, motion transfer, image animation, video interpolation, and extrapolation.