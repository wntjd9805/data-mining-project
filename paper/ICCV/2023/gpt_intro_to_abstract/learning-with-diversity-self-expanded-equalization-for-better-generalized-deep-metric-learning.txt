Learning an effective metric to measure visual similarities among examples is a fundamental problem in computer vision tasks such as image retrieval, face recognition, and person re-identification. Deep metric learning (DML) methods, which employ deep neural networks to extract feature embeddings, have shown superior performance in this area. In standard DML settings, the goal is to train a metric model that generalizes well to unseen classes in the testing phase. To address this challenge, various methods have been proposed to alleviate the impact of category shift and learn a discriminative metric that generalizes well. However, in many real-world applications, there is not only category shift but also domain shift between the training and testing data, leading to poor generalization. To explore the improvement of DML's generalization ability, this paper introduces a practical yet challenging task called single-domain generalized DML. In this task, the metric model is trained on a dataset with seen categories and domains and is expected to generalize to different unseen categories and domains. The paper proposes a self-expanded equalization (SEE) method for single-domain generalized DML, which consists of adaptive domain expansion and domain-aware equalization modules. The adaptive domain expansion module modifies the source data to generate diverse augmentations that mimic domain shift, while the domain-aware equalization module discovers implicit semantic relations across different domain shifts to induce a domain-invariant distance metric. Experimental results on multiple datasets demonstrate that SEE outperforms state-of-the-art DML methods across all benchmarks in terms of performance.