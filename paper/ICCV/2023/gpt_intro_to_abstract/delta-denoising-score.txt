Large-scale language-vision models have transformed the generation and editing of visual content. Text-to-image generative models, particularly Score Distillation Sampling (SDS), have gained attention for their ability to optimize image generation using a 2D diffusion model as a prior. However, SDS tends to result in blurry outputs and convergence towards specific modes. In this paper, we propose a new scoring technique called Delta Denoising Score (DDS) that addresses these limitations. DDS utilizes an additional reference image-text query and calculates the difference between the outputs of the reference and target queries. This technique provides cleaner gradients for modifying the edited portions of an image while leaving the rest unchanged. DDS can be used for prompt-to-prompt editing and training a zero-shot image translation model without paired training datasets. Experimental results demonstrate the effectiveness of DDS compared to existing text-driven editing methods.