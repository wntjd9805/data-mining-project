This paper introduces a method for concept ablation in text-conditioned diffusion models. The goal is to prevent large-scale models from generating copyrighted or personal content without re-training the model from scratch. The method involves modifying generated images for a target concept to match a broader anchor concept. Two different training objectives are proposed, one based on model prediction matching and the other based on modified text-image pairs. The method is evaluated on 16 concept ablation tasks and shown to successfully ablate target concepts while preserving related concepts. An extensive ablation study is performed to explore different design choices, and the limitations of the method are discussed. The full version of the paper and the code, data, and models are available online.