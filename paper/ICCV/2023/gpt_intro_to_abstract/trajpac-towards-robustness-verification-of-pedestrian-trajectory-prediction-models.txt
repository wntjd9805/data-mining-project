This paper introduces the problem of robustness in trajectory prediction models for human behavior comprehension and self-driving systems. While current methods have achieved remarkable results, they are susceptible to adversarial attacks. The paper highlights the shortcomings in previous research and proposes a formal definition of robustness for trajectory prediction tasks. It also presents two novel definitions of robustness: label robustness and pure robustness. Additionally, the paper addresses the issue of stochastic prediction techniques and proposes a method to compare post-attack predictions with the empirical distribution of pre-attack predictions. The paper also introduces a framework called TRAJPAC for robustness verification of trajectory forecasting models and explores the interpretability of adversarial attacks in trajectory prediction models. The main contributions include the formal definition of robustness, the TRAJPAC framework, and the evaluation of robustness on various trajectory forecasting models.