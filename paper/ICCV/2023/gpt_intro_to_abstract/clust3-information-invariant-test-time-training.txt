The domain invariance hypothesis has played a crucial role in the success of deep learning methods for computer vision. However, this hypothesis assumes that the training and testing data are drawn from the same distribution, which is rarely the case in practical settings. Domain Adaptation (DA) addresses this issue by studying how learning algorithms can be adapted to new domains with different types of domain shifts in the test data. Two promising directions in DA are Domain Generalization (DG) and Test-Time Adaptation (TTA). While DG trains a model on a large source dataset with different domains and evaluates its performance on new domains, TTA adapts the model to test data on the fly. TTA does not require supervision from testing samples or access to the source domain, making it a challenging but realistic problem.However, TTA methods heavily rely on the choice of unsupervised loss functions used at test time and can be sensitive to this choice, which may impact performance. Test-Time Training (TTT) is a variant of TTA where an auxiliary task is learned from the training data and used at test time to update the model. Unsupervised and self-supervised tasks are typically used for TTT, allowing for adaptation without the need for any labels. Inspired by the success of Mutual-Information (MI) maximization in various learning tasks, we propose a TTT method called ClusT3 that maximizes the MI between feature maps and discrete latent representations related to clustering. Our method aims to keep the information between features and their corresponding encoding constant across domains. We introduce an auxiliary task that performs information-maximization clustering during source domain training and use the MI between features and cluster assignments as the objective for test-time adaptation. Unlike previous TTT methods, our approach is problem-agnostic and can be added to any model through a low-dimensional linear projection. It also does not require distilled information from the source domain, making it more lightweight and efficient. We evaluate ClusT3 in various TTA scenarios with different types of domain shifts and demonstrate competitive performance compared to previous methods. To the best of our knowledge, our approach is the first Unsupervised Test-Time Training method using a joint training based on MI and linear projectors. The rest of the paper presents related work, details our ClusT3 method, experimental settings, results, and conclusions.