Reconstructing the dynamic 3D world from 2D images is an important task for various computer vision and graphics applications. Traditional stereo algorithms that use computer vision techniques have limitations in terms of speed and quality. Recently, neural implicit representations have emerged as a promising alternative due to their high spatial resolution and detailed reconstructions. However, existing methods such as NeuS and Instant-NGP still have limitations in terms of training speed and surface constraints.In this paper, we propose NeuS2, a new method for fast training of highly-detailed neural implicit surfaces. We achieve this by parameterizing the neural network-encoded Signed Distance Field (SDF) using multi-resolution hash tables of learnable feature vectors. To optimize GPU computing performance, we derive a simple formula for calculating the second-order derivatives tailored to ReLU-based MLPs.Furthermore, we extend our method to multi-view dynamic scene reconstruction by introducing an incremental learning strategy. Instead of training each frame separately, we leverage the similarity between consecutive frames to efficiently learn a neural dynamic representation. However, we address the issue of occluded regions by predicting a global transformation to align the frames before learning the representation of the new frame.Our contributions include the proposal of NeuS2, a method for fast neural surface reconstruction, a formulation for efficient parallelization of GPU computation, a progressive training strategy for better convergence, and an incremental learning method with a global transformation prediction component. Overall, NeuS2 achieves a significant speed-up over existing methods while maintaining high reconstruction quality.