Deep Neural Networks (DNNs) have shown excellent efficacy in computer vision tasks, but recent studies have revealed their vulnerability to adversarial examples. While most research has focused on image models, video models also suffer from this vulnerability, posing security threats in video-related tasks. Patch attacks, which involve adding regional patches to inputs, have been found to be a significant threat to DNNs. However, current patch attack methods for video models have limitations in terms of attack performance and imperceptibility. Additionally, existing attack settings either require white-box access to the model or are not suitable for video models. To address these challenges, we propose a new attack setting called decision-based patch attacks on video models. We introduce a novel attack method called Spatial-Temporal Differential Evolution (STDE) to achieve query-efficient attacks in this new setting. STDE reduces the parameter space by incorporating prior knowledge from target videos and performs binary encoding to select keyframes. We improve the heuristic algorithm and propose a spatial-temporal differential evolution strategy to avoid local optima. Experimental results demonstrate that STDE achieves high fooling rates with smaller patch areas and fewer queries compared to state-of-the-art methods, ensuring potent attack capability and imperceptibility. Our work contributes to bridging the gap in evaluating the robustness of video models and paves the way for developing more secure video models.