Building generative models for synthesizing 3D shapes is a prominent field in computer graphics and 3D vision, with applications in areas such as 3D content creation, autonomous driving, AR/VR, and robotics. Evaluating these models involves considering their quality, diversity, and controllability. While previous models have shown promising quality and diversity using implicit function-based shape representations, controlling and manipulating local structures remains challenging. Existing methods for editing local shapes can be categorized into interpolation-based and optimization-based methods, but they have limitations in producing consistent and desired results. In this paper, we propose a new paradigm called 3D Semantic Subspace Traverser, which leverages learned semantic information in a subspace to enable effective shape control and editing. Our model combines a deep implicit function-based representation, a latent-space GAN, and local linear subspace models to generate diverse and semantically editable 3D shapes. We demonstrate the effectiveness of our approach through quantitative and qualitative results, achieving superior performance in both shape generation and editing. This work contributes a novel semantic generative model for 3D shape editing, a latent-space GAN for implicit-function-based generation, a method for unsupervised discovery of controllable dimensions, and evidence of superior performance in 3D shape generation and editing.