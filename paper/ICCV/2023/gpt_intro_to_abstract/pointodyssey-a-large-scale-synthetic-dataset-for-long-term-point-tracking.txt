In this paper, we present PointOdyssey, a large-scale synthetic dataset for the task of fine-grained long-range tracking in computer vision. While there are existing datasets for fine-grained short-range tracking and coarse-grained long-range tracking, there is a lack of datasets that specifically target fine-grained long-range tracking. Previous works in this area have trained trackers on unrealistic synthetic data and tested them on real-world videos with sparse human-provided annotations, limiting the learning of long-range temporal context and scene-level semantic awareness. We argue that long-range point tracking should not be treated as an extension of optical flow, as it involves modeling factors such as camera shake, object-level motions and deformations, and multi-object relationships. To address these limitations, we propose PointOdyssey, which provides the complexity, diversity, and naturalism of real-world videos through the use of motions, scene layouts, and camera trajectories mined from real-world videos and motion captures. Our dataset incorporates domain randomization on a wider range of scene attributes, resulting in better photorealism. The motion profiles in our data come from large-scale motion-capture datasets of humans and animals, driving realistic long-range trajectories. We also introduce visual diversity through a large set of simulated assets and randomized scene lighting. PointOdyssey unlocks new challenges in leveraging long-range temporal context, and we propose modifications to existing tracking methods to achieve higher accuracy. The main contribution of this paper is the PointOdyssey dataset, which provides a highway for the development of accurate models for fine-grained long-range tracking. The dataset and simulation engine code are publicly available.