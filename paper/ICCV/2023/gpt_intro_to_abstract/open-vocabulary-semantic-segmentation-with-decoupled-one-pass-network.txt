Semantic segmentation is an important task in computer vision that involves grouping image pixels into meaningful regions and assigning class labels. Traditionally, semantic segmentation networks have focused on a fixed set of semantic classes defined by the dataset. However, with the emergence of large-scale pre-trained visual-language models (VLMs) like CLIP and ALIGN, there has been growing interest in open-vocabulary (or zero-shot) semantic segmentation. OpenSeg was one of the early methods for this task, using class-agnostic masks and text embeddings from a pre-trained VLM for region classification. While efficient, OpenSeg's single shared visual encoder breaks the alignment of the pre-trained VLM. Other approaches, like ZegFormer and SimBaseline, decouple the sub-tasks of mask proposal and classification but suffer from high computational overhead. In this work, we aim to develop a framework that maintains zero-shot capability while being computationally efficient. We propose a decoupled one-pass network (DeOP) with Generalized Patch Severance (GPS) and Classification Anchor Learning (CAL) to address the challenges faced by previous methods. GPS reduces interference between patch embeddings, and CAL identifies patches suitable for classification. Our experiments demonstrate that DeOP outperforms previous methods while maintaining efficiency, validating the effectiveness of GPS and CAL.