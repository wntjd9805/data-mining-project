With the increasing number of videos available online, there has been a growing interest in video understanding in computer vision research. One challenging yet fundamental task in this area is temporal action localization (TAL), which involves identifying and localizing human actions in a video clip. TAL has various applications, including sports highlighting, human action analysis, and security monitoring.Existing methods in TAL can be classified into two main approaches: two-stage approaches and one-stage approaches. Two-stage approaches generate action proposals and then perform classification and boundary refinement, while one-stage approaches simultaneously recognize and locate action instances. However, these methods treat each frame equally during training, resulting in sub-optimal performance.In order to address this issue, we propose a lightweight Action Sensitivity Evaluator (ASE) for each sub-task in TAL. ASE measures the importance of each frame based on its action sensitivity to classification and localization. Frames with higher action sensitivity are given more attention during training. We introduce the concept of Action Sensitivity, which is disentangled into class-level and instance-level perspectives. The class-level perspective models the coarse action sensitivity distribution of each action category using gaussian weights, while the instance-level perspective is supervised in a prediction-aware manner. The training weights of each frame are dynamically adjusted based on their action sensitivity, leading to more effective model training.We further develop a novel Action Sensitivity Learning (ASL) framework using ASE to effectively tackle the TAL task. Additionally, we design an Action Sensitive Contrastive Loss (ASCL) to enhance the features and improve the discrimination between actions and backgrounds. ASCL generates various types of action-related and action-irrelevant features and performs contrasting between them, leading to improved performance in TAL.Extensive experiments and ablation studies on six datasets demonstrate that our proposed ASL framework outperforms existing methods in classifying and localizing action instances. Our contributions include the introduction of the ASE component for training enhancement, the design of the ASCL for feature enhancement, and the verification of ASL on various action localization datasets, achieving superior results in multiple types of datasets.