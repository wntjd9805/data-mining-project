Underwater depth recovery and image restoration are vital for various applications in ocean exploration. Current methods for underwater depth estimation can be categorized into active and passive methods. Active methods, such as sonar and LiDAR, are bulky and limited by light scattering in water. Passive methods utilize images captured from a camera, including traditional and deep learning-based approaches. However, traditional methods are time-consuming and prone to errors, while deep learning-based methods lack large-scale underwater depth datasets and suffer from a domain gap with real underwater images. Existing self-supervised depth estimation networks for terrestrial images cannot be directly applied to underwater images due to the presence of haze. Additionally, underwater images suffer from color distortions and poor contrast, leading to the need for image restoration techniques. DL-based methods for underwater image enhancement either rely on synthetic datasets or lack actual ground truth. In this paper, we propose a unified learning framework, called USe-ReDI-Net, for joint monocular underwater depth estimation and image restoration based on self-supervision. Our method leverages both haze and geometry as cues for depth estimation and utilizes the underwater image formation model for disentanglement. The joint estimation of depth and image benefits both tasks, enhancing the accuracy of the depth map and image restoration. We introduce DRUVA, a dataset of real-world underwater videos of artifacts, collected using a GoPro Hero 10 camera, to facilitate advancements in underwater research. Our main contributions include the proposal of USe-ReDI-Net, a real-time self-supervised deep network for simultaneous depth estimation and image restoration, the utilization of cues from both haze and geometry, and the outperformance of state-of-the-art methods in terms of quality and speed. We also release the DRUVA dataset for the research community.