Abstract:Large-scale datasets play a crucial role in the performance of computer vision models. However, existing fairness datasets lack exhaustive and diverse demographic annotations, limiting the ability to perform fine-grained fairness analyses. In this paper, we introduce FACET (Fairness in Computer Vision Evaluation Benchmark), a large-scale evaluation benchmark with comprehensive annotations for 32k images. FACET includes annotations for 13 person attributes and 52 person classes. We ensure high-quality annotations by utilizing trained expert annotators from various geographic regions. FACET enables a more in-depth analysis of fairness concerns and model biases across different demographic axes. We demonstrate the utility of FACET by evaluating state-of-the-art vision models and examining their fairness on demographic attributes. Our contributions include the creation of FACET and its availability as a publicly accessible benchmark. FACET serves as a valuable resource for comparing different models and conducting quantitative and qualitative analyses on existing vision models. It is important to note that FACET is an evaluation-only benchmark, and using its annotations for training purposes is strictly prohibited.