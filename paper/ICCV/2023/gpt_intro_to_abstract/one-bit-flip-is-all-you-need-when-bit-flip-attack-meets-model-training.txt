Deep neural networks (DNNs) have been widely used in various mission-critical applications, making their security issues highly significant. Previous studies have shown that DNNs are vulnerable to attacks such as data poisoning and adversarial attacks. Recently, it has been demonstrated that DNNs can also be vulnerable in the deployment stage to a specific type of attack called the bit-flip attack (BFA). BFAs can achieve different malicious goals, including reducing DNN accuracy, inserting trojans, and manipulating DNN outputs. However, existing BFAs have limitations, as they often require flipping a large number of bits, making them impractical. In this paper, we propose a new BFA paradigm called the training-assisted bit-flip attack (TBA) that addresses these limitations. We formulate the problem as a multi-task learning instance and introduce an effective method to solve it. Our empirical results show that TBA is effective, requiring flipping only one or a few bits to activate malicious behaviors in most cases.Overall, our contributions include revealing the limitations of existing BFAs, introducing TBA as a new paradigm, and providing an effective method to solve the TBA problem.