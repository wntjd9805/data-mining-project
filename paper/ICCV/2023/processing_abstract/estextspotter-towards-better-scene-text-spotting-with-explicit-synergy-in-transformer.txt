In recent years, end-to-end scene text spotting ap-proaches are evolving to the Transformer-based framework.While previous studies have shown the crucial importance of the intrinsic synergy between text detection and recog-nition, recent advances in Transformer-based methods usu-ally adopt an implicit synergy strategy with shared query, which can not fully realize the potential of these two in-teractive tasks.In this paper, we argue that the explicit synergy considering distinct characteristics of text detec-tion and recognition can significantly improve the perfor-mance text spotting. To this end, we introduce a new model named Explicit Synergy-based Text Spotting Trans-former framework (ESTextSpotter), which achieves explicit synergy by modeling discriminative and interactive fea-tures for text detection and recognition within a single de-coder. Specifically, we decompose the conventional shared query into task-aware queries for text polygon and con-tent, respectively. Through the decoder with the proposed vision-language communication module, the queries inter-act with each other in an explicit manner while preserving discriminative patterns of text detection and recognition, thus improving performance significantly. Additionally, we propose a task-aware query initialization scheme to en-sure stable training. Experimental results demonstrate that our model significantly outperforms previous state-of-the-art methods. Code is available at https://github. com/mxin262/ESTextSpotter. 