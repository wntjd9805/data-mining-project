Visual Transformers (ViTs) and Convolutional NeuralNetworks (CNNs) are the two primary backbone struc-tures extensively used in various vision tasks. Generat-ing transferable adversarial examples for ViTs is difﬁcult due to ViTs’ superior robustness, while transferring ad-versarial examples across ViTs and CNNs is even harder, since their structures and mechanisms for processing im-ages are fundamentally distinct. In this work, we propose a novel attack method named Momentum Integrated Gradi-ents (MIG), which not only attacks ViTs with high success rate, but also exhibits impressive transferability across ViTs and CNNs. Speciﬁcally, we use integrated gradients rather than gradients to steer the generation of adversarial per-turbations, inspired by the observation that integrated gra-dients of images demonstrate higher similarity across mod-els in comparison to regular gradients. Then we acquire the accumulated gradients by combining the integrated gra-dients from previous iterations with the current ones in a momentum manner and use their sign to modify the per-turbations iteratively. We conduct extensive experiments to demonstrate that adversarial examples obtained usingMIG show stronger transferability, resulting in signiﬁcant improvements over state-of-the-art methods for both CNN and ViT models. 