Out-of-distribution (OOD) detection is crucial to mod-ern deep learning applications by identifying and alerting about the OOD samples that should not be tested or used for making predictions. Current OOD detection methods have made significant progress when in-distribution (ID) andOOD samples are drawn from static distributions. How-ever, this can be unrealistic when applied to real-world sys-tems which often undergo continuous variations and shifts in ID and OOD distributions over time. Therefore, for an ef-fective application in real-world systems, the development of OOD detection methods that can adapt to these dynamic and evolving distributions is essential. In this paper, we pro-pose a novel and more realistic setting called continuously adaptive out-of-distribution (CAOOD) detection which tar-gets on developing an OOD detection model that enables dynamic and quick adaptation to a new arriving distribu-tion, with insufficient ID samples during deployment time.To address CAOOD, we develop meta OOD learning (MOL) by designing a learning-to-adapt diagram such that a good initialized OOD detection model is learned during the train-ing process. In the testing process, MOL ensures OOD de-tection performance over shifting distributions by quickly adapting to new distributions with a few adaptations. Ex-tensive experiments on several OOD benchmarks endorse the effectiveness of our method in preserving both ID classi-fication accuracy and OOD detection performance on con-tinuously shifting distributions. 