Keypoint detection & descriptors are foundational tech-nologies for computer vision tasks like image matching, 3D reconstruction and visual odometry. Hand-engineered methods like Harris corners, SIFT, and HOG descriptors have been used for decades; more recently, there has been a trend to introduce learning in an attempt to improve key-point detectors. On inspection however, the results are dif-ficult to interpret; recent learning-based methods employ a vast diversity of experimental setups and design choices: empirical results are often reported using different back-bones, protocols, datasets, types of supervisions or tasks.Since these differences are often coupled together, it raises a natural question on what makes a good learned keypoint de-tector. In this work, we revisit the design of existing keypoint detectors by deconstructing their methodologies and iden-tifying the key components. We re-design each component from first-principle and propose Simple Learned Keypoints (SiLK) that is fully-differentiable, lightweight, and flexi-ble. Despite its simplicity, SiLK advances new state-of-the-art on Detection Repeatability and Homography Estimation tasks on HPatches and 3D Point-Cloud Registration task onScanNet, and achieves competitive performance to state-of-the-art on camera pose estimation in 2022 Image MatchingChallenge and ScanNet. 