In contrastive self-supervised learning, the common way to learn discriminative representation is to pull different augmented “views” of the same image closer while pushing all other images further apart, which has been proven to be effective. However, it is unavoidable to construct unde-sirable views containing different semantic concepts during the augmentation procedure. It would damage the semantic consistency of representation to pull these augmentations closer in the feature space indiscriminately. In this study, we introduce feature-level augmentation and propose a novel semantics-consistent feature search (SCFS) method to miti-gate this negative effect. The main idea of SCFS is to adap-tively search semantics-consistent features to enhance the contrast between semantics-consistent regions in different augmentations. Thus, the trained model can learn to fo-cus on meaningful object regions, improving the semantic representation ability. Extensive experiments conducted on different datasets and tasks demonstrate that SCFS effec-tively improves the performance of self-supervised learning and achieves state-of-the-art performance on different down-stream tasks.1 