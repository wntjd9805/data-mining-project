Realistic human-centric rendering plays a key role in both computer vision and computer graphics.Rapid progress has been made in the algorithm aspect over the years, yet existing human-centric rendering datasets and benchmarks are rather impoverished in terms of diversity (e.g., outfit’s fabric/material, body’s interaction with ob-jects, and motion sequences), which are crucial for render-ing effect. Researchers are usually constrained to explore and evaluate a small set of rendering problems on cur-rent datasets, while real-world applications require meth-ods to be robust across different scenarios. In this work, we present DNA-Rendering, a large-scale, high-fidelity repos-itory of human performance data for neural actor render-*Joint-first authors with W. Cheng.†Equal advising. ing. DNA-Rendering presents several appealing attributes.First, our dataset contains over 1500 human subjects, 5000 motion sequences, and 67.5M frames’ data volume. Upon the massive collections, we provide human subjects with grand categories of pose actions, body shapes, clothing, accessories, hairdos, and object intersection, which ranges the geometry and appearance variances from everyday life to professional occasions. Second, we provide rich assets for each subject – 2D/3D human body keypoints, foreground masks, SMPLX models, cloth/accessory materials, multi-view images, and videos. These assets boost the current method’s accuracy on downstream rendering tasks. Third, we construct a professional multi-view system to capture data, which contains 60 synchronous cameras with max 4096 × 3000 resolution, 15 fps speed, and stern camera calibration steps, ensuring high-quality resources for task training and evaluation.DatasetEthnicity AgeAttributeCloth MotionHuman3.6M [19]CMU Panoptic [24]ZJU-MoCap [44]HUMBI [66]AIST++ [56, 28]THuman 4.0 [51]HuMMan [5]GeneBody [10]DNA-Rendering (Ours)✗✓✗✓✗✗✓✓✓✗✓✗✓✗✗✓✓✓✗✗✗✓✗✓✓✓✓✓✓✓✗✗✓✓✓✓Interactivity✓✓✗✗✗✗✗✓✓#ID × #Outfit 11 × 1 97 × 1 10 × 1 772 × 1 30 × 1 3 × 1 1000 × 1 50 × 2 500 × 3Scale#Motions 17 65 10−−− 500 61 1187#View 4 31 + 480∗ 24 107 9 24 10 48 60#Frames 3.6M 15.3M 180K 26M 10.1M 10K 60M 2.95M 67.5MRealismHRes 1000P 1080P 1024P 1080P 1080P 1150P 1080P 2048P 4096PTable 1: Dataset comparison on attributes and scales. We compare the proposed dataset with previous human-centric multiview datasets in terms of attribute coverage, scale, and realism. ‘Ethnicity’ denotes whether the dataset contains actors from multiple ethnic groups.‘Age’ means if there is a wide age range containing elders or infants. ‘Cloth’ separates datasets with only daily costumes or with extra diverse clothing. ‘Attribute-Motion’ denotes whether it has human motion in different scenarios. ‘Interactivity’ tells whether there contains human-object interaction. We mark these attributes with ✓ and ✗. In scale, we list the number of key factors with compared dataset, Note that ‘Scale-#Motions’ means the number of motion categories, and superscript ∗ means low-resolution VGA cameras, we exclude them during ‘#View’ ranking and ‘#Frames’ calculation. We abbreviate resolution at height as ‘HRes’.Along with the dataset, we provide a large-scale and quantitative benchmark in full-scale, with multiple tasks to evaluate the existing progress of novel view synthesis, novel pose animation synthesis, and novel identity render-ing methods.In this manuscript, we describe our DNA-Rendering effort as a revealing of new observations, chal-lenges, and future directions to human-centric rendering.The dataset, code, and benchmarks will be publicly avail-able at https://dna-rendering.github.io/. 