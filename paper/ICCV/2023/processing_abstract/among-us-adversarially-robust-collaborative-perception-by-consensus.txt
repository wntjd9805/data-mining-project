Multiple robots could perceive a scene (e.g., detect ob-jects) collaboratively better than individuals, although eas-ily suffer from adversarial attacks when using deep learn-ing. This could be addressed by the adversarial defense, but its training requires the often-unknown attacking mecha-nism. Differently, we propose ROBOSAC, a novel sampling-based defense strategy generalizable to unseen attackers.Our key idea is that collaborative perception should lead to consensus rather than dissensus in results compared to indi-vidual perception. This leads to our hypothesize-and-verify framework: perception results with and without collabora-tion from a random subset of teammates are compared until reaching a consensus.In such a framework, more team-mates in the sampled subset often entail better perception performance but require longer sampling time to reject po-tential attackers. Thus, we derive how many sampling tri-als are needed to ensure the desired size of an attacker-free subset, or equivalently, the maximum size of such a subset that we can successfully sample within a given number of trials. We validate our method on the task of collaborative 3D object detection in autonomous driving scenarios. 