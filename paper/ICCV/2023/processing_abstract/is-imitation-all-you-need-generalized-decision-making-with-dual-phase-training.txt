Phase I: Self-supervised learning on  state-action interactions from  diverse episodes We introduce DualMind, a generalist agent designed to tackle various decision-making tasks that addresses chal-lenges posed by current methods, such as overﬁtting behav-iors and dependence on task-speciﬁc ﬁne-tuning. DualMind uses a novel “Dual-phase” training strategy that emulates how humans learn to act in the world. The model ﬁrst learns fundamental common knowledge through a self-supervised objective tailored for control tasks and then learns how to make decisions based on different contexts through imitat-ing behaviors conditioned on given prompts. DualMind can handle tasks across domains, scenes, and embodiments using just a single set of model weights and can execute zero-shot prompting without requiring task-speciﬁc ﬁne-tuning. We evaluate DualMind on MetaWorld [40] andHabitat [31] through extensive experiments and demon-strate its superior generalizability compared to previous techniques, outperforming other generalist agents by over 50% and 70% on Habitat and MetaWorld, respectively. On the 45 tasks in MetaWorld, DualMind achieves over 30 tasks at a 90% success rate. Our source code is available at https://github.com/yunyikristy/DualMind. 