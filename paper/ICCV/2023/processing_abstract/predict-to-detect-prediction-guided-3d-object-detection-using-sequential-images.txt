Recent camera-based 3D object detection methods have introduced sequential frames to improve the detection per-formance hoping that multiple frames would mitigate the large depth estimation error. Despite improved detection performance, prior works rely on naive fusion methods (e.g., concatenation) or are limited to static scenes (e.g., temporal stereo), neglecting the importance of the motion cue of objects. These approaches do not fully exploit the potential of sequential images and show limited perfor-mance improvements. To address this limitation, we pro-pose a novel 3D object detection model, P2D (Predict toDetect), that integrates a prediction scheme into a detection framework to explicitly extract and leverage motion fea-tures. P2D predicts object information in the current frame using solely past frames to learn temporal motion features.We then introduce a novel temporal feature aggregation method that attentively exploits Birdâ€™s-Eye-View (BEV) fea-tures based on predicted object information, resulting in ac-curate 3D object detection. Experimental results demon-strate that P2D improves mAP and NDS by 3.0% and 3.7% compared to the sequential image-based baseline, proving that incorporating a prediction scheme can significantly im-prove detection accuracy. 