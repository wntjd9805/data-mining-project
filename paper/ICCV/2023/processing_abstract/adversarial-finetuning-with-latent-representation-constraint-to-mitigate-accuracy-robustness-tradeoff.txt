This paper addresses the tradeoff between standard ac-curacy on clean examples and robustness against adversar-ial examples in deep neural networks (DNNs). Although adversarial training (AT) improves robustness, it degrades the standard accuracy, thus yielding the tradeoff. To mit-igate this tradeoff, we propose a novel AT method calledARREST, which comprises three components: (i) adversar-ial ﬁnetuning (AFT), (ii) representation-guided knowledge distillation (RGKD), and (iii) noisy replay (NR). AFT trains a DNN on adversarial examples by initializing its parame-ters with a DNN that is standardly pretrained on clean ex-amples. RGKD and NR respectively entail a regularization term and an algorithm to preserve latent representations of clean examples during AFT. RGKD penalizes the distance between the representations of the standardly pretrained and AFT DNNs. NR switches input adversarial examples to nonadversarial ones when the representation changes signiﬁcantly during AFT. By combining these components,ARREST achieves both high standard accuracy and robust-ness. Experimental results demonstrate that ARREST mit-igates the tradeoff more effectively than previous AT-based methods do. 