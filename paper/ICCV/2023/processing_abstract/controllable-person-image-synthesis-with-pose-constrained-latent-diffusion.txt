Controllable person image synthesis aims at rendering a source image based on user-speciﬁed changes in body pose or appearance. Prior art approaches leverage pixel-level denoising diffusion models conditioned on the coarse skele-ton via cross-attention. This leads to two limitations: low efﬁciency and inaccurate condition information. To address both issues, a novel Pose-Constrained Latent Diffusion model (PoCoLD) is introduced. Rather than using the skele-ton as a sparse pose representation, we exploit DensePose which offers much richer body structure information. To ef-fectively capitalize DensePose at a low cost, we propose an efﬁcient pose-constrained attention module that is capable of modeling the complex interplay between appearance and pose. Extensive experiments show that our PoCoLD out-performs the state-of-the-art competitors in image synthe-sis ﬁdelity. Critically, it runs 2× smaller memory than the latest diffusion-model-based alter-native during inference. Our code and models are available at https://github.com/BrandonHanx/PoCoLD. faster and consumes 3.6× 