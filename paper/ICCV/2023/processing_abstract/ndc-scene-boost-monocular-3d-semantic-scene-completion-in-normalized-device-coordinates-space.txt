Monocular 3D Semantic Scene Completion (SSC) has garnered significant attention in recent years due to its po-tential to predict complex semantics and geometry shapes from a single image, requiring no 3D inputs.In this pa-per, we identify several critical issues in current state-of-the-art methods, including the Feature Ambiguity of pro-jected 2D features in the ray to the 3D space, the PoseAmbiguity of the 3D convolution, and the ComputationImbalance in the 3D convolution across different depth levels.To address these problems, we devise a novelNormalized Device Coordinates scene completion network (NDC-Scene) that directly extends the 2D feature map to aNormalized Device Coordinates (NDC) space, rather than to the world space directly, through progressive restora-tion of the dimension of depth with deconvolution oper-ations. Experiment results demonstrate that transferring the majority of computation from the target 3D space to the proposed normalized device coordinates space ben-efits monocular SSC tasks. Additionally, we design aDepth-Adaptive Dual Decoder to simultaneously upsam-ple and fuse the 2D and 3D feature maps, further im-proving overall performance. Our extensive experiments confirm that the proposed method consistently outperforms state-of-the-art methods on both outdoor SemanticKITTI and indoor NYUv2 datasets. Our code are available at https://github.com/Jiawei-Yao0812/NDCScene. 