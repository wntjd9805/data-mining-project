Single-photon 3D cameras can record the time-of-arrival of billions of photons per second with picosecond accuracy. One common approach to summarize the pho-ton data stream is to build a per-pixel timestamp histogram, resulting in a 3D histogram tensor that encodes distances along the time axis. As the spatio-temporal resolution of the histogram tensor increases, the in-pixel memory require-ments and output data rates can quickly become impracti-cal. To overcome this limitation, we propose a family of lin-ear compressive representations of histogram tensors that can be computed efficiently, in an online fashion, as a ma-trix operation. We design practical lightweight compres-sive representations that are amenable to an in-pixel imple-mentation and consider the spatio-temporal information of each timestamp. Furthermore, we implement our proposed framework as the first layer of a neural network, which en-ables the joint end-to-end optimization of the compressive representations and a downstream SPAD data processing model. We find that a well-designed compressive repre-sentation can reduce in-sensor memory and data rates up to 2 orders of magnitude without significantly reducing 3D imaging quality. Finally, we analyze the power consump-tion implications through an on-chip implementation. 