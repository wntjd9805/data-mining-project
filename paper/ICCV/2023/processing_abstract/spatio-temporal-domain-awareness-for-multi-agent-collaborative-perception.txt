Multi-agent collaborative perception as a potential ap-plication for vehicle-to-everything communication could significantly improve the perception performance of au-tonomous vehicles over single-agent perception. However, several challenges remain in achieving pragmatic informa-tion sharing in this emerging research. In this paper, we propose SCOPE, a novel collaborative perception frame-work that aggregates the spatio-temporal awareness char-acteristics across on-road agents in an end-to-end man-ner. Specifically, SCOPE has three distinct strengths: i) it considers effective semantic cues of the temporal con-text to enhance current representations of the target agent; ii) it aggregates perceptually critical spatial information from heterogeneous agents and overcomes localization er-rors via multi-scale feature interactions; iii) it integrates multi-source representations of the target agent based on their complementary contributions by an adaptive fusion paradigm. To thoroughly evaluate SCOPE, we consider both real-world and simulated scenarios of collaborative 3D object detection tasks on three datasets. Extensive ex-periments show the superiority of our approach and the necessity of the proposed components. The project link is https://ydk122024.github.io/SCOPE/. 