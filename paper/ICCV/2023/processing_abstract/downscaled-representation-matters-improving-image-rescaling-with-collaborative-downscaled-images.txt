(cid:43)(cid:53)(cid:3)(cid:44)(cid:80)(cid:68)(cid:74)(cid:72) (cid:53)(cid:72)(cid:70)(cid:82)(cid:81)(cid:86)(cid:87)(cid:85)(cid:88)(cid:70)(cid:87)(cid:72)(cid:71)(cid:3)(cid:44)(cid:80)(cid:68)(cid:74)(cid:72) (cid:47)(cid:53)(cid:3)(cid:44)(cid:80)(cid:68)(cid:74)(cid:72)Deep networks have achieved great success in image rescaling (IR) task that seeks to learn the optimal down-scaled representations, i.e., low-resolution (LR) images, to reconstruct the original high-resolution (HR) images. Com-pared with super-resolution methods that consider a ﬁxed downscaling scheme, e.g., bicubic, IR often achieves sig-niﬁcantly better reconstruction performance thanks to the learned downscaled representations. This highlights the importance of a good downscaled representation. Exist-ing IR methods mainly learn the downscaled representation by jointly optimizing the downscaling and upscaling mod-els. Unlike them, we seek to improve the downscaled rep-resentation through a different and more direct way – di-rectly optimizing the downscaled image itself instead of the down-/upscaling models. Consequently, we propose a Hi-erarchical Collaborative Downscaling (HCD) method that performs gradient descent w.r.t. the reconstruction loss in both HR and LR domains to improve the downscaled rep-resentations, so as to boost IR performance. Extensive ex-periments show that our HCD signiﬁcantly improves the re-construction performance both quantitatively and qualita-tively. Particularly, we improve over popular IR methods by>0.57 dB PSNR on Set5. Moreover, we also highlight theﬂexibility of our HCD since it can generalize well across diverse image rescaling models. The code is available at https://github.com/xubingna/HCD. 