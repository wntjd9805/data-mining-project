As a video task, Multiple Object Tracking (MOT) is ex-pected to capture temporal information of targets effec-tively. Unfortunately, most existing methods only explicitly exploit the object features between adjacent frames, while lacking the capacity to model long-term temporal infor-mation. In this paper, we propose MeMOTR, a long-term memory-augmented Transformer for multi-object tracking.Our method is able to make the same objectâ€™s track embed-ding more stable and distinguishable by leveraging long-term memory injection with a customized memory-attention layer. This significantly improves the target association ability of our model. Experimental results on DanceTrack show that MeMOTR impressively surpasses the state-of-the-art method by 7.9% and 13.0% on HOTA and AssA met-rics, respectively. Furthermore, our model also outperforms other Transformer-based methods on association perfor-mance on MOT17 and generalizes well on BDD100K. Code is available at https://github.com/MCG-NJU/MeMOTR. 