This paper addresses data augmentation for action seg-mentation. Our key novelty is that we augment the origi-nal training videos in the deep feature space, not in the vi-sual spatiotemporal domain as done by previous work. For augmentation, we modify original deep features of video frames such that the resulting embeddings fall closer to the class decision boundaries. Also, we edit action sequences transcripts) by in-of the original training videos (a.k.a. serting, deleting, and replacing actions such that the result-ing transcripts are close in edit distance to the ground-truth ones. For our data augmentation we resort to reinforce-ment learning, instead of more common supervised learn-ing, since we do not have access to reliable oracles which would provide supervision about the optimal data modifica-tions in the deep feature space. For modifying frame embed-dings, we use a meta-model formulated as a Markov Game with multiple self-interested agents. Also, new transcripts are generated using a fast, parameter-free Monte Carlo tree search. Our experiments show that the proposed data aug-mentation of the Breakfast, GTEA, and 50Salads datasets leads to significant performance gains of several state of the art action segmenters. 