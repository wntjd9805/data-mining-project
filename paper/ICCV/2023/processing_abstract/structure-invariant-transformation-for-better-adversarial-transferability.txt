Given the severe vulnerability of Deep Neural Networks (DNNs) against adversarial examples, there is an urgent need for an effective adversarial attack to identify the de-ficiencies of DNNs in security-sensitive applications. As one of the prevalent black-box adversarial attacks, the ex-isting transfer-based attacks still cannot achieve compara-ble performance with the white-box attacks. Among these, input transformation based attacks have shown remark-able effectiveness in boosting transferability. In this work, we find that the existing input transformation based at-tacks transform the input image globally, resulting in lim-ited diversity of the transformed images. We postulate that the more diverse transformed images result in better transferability. Thus, we investigate how to locally ap-ply various transformations onto the input image to im-prove such diversity while preserving the structure of im-age. To this end, we propose a novel input transforma-tion based attack, called Structure Invariant Transforma-tion (SIA), which applies a random image transformation onto each image block to craft a set of diverse images for gradient calculation. Extensive experiments on the stan-dard ImageNet dataset demonstrate that SIA exhibits much better transferability than the existing SOTA input transfor-mation based attacks on CNN-based and transformer-based models, showing its generality and superiority in boosting transferability. Code is available at https://github. com/xiaosen-wang/SIT. 