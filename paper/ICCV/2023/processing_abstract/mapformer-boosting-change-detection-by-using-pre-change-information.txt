Change detection in remote sensing imagery is essential for a variety of applications such as urban planning, disas-ter management, and climate research. However, existing methods for identifying semantically changed areas over-look the availability of semantic information in the form of existing maps describing features of the earthâ€™s surface.In this paper, we leverage this information for change de-tection in bi-temporal images. We show that the simple integration of the additional information via concatena-tion of latent representations suffices to significantly out-perform state-of-the-art change detection methods. Mo-tivated by this observation, we propose the new task ofConditional Change Detection, where pre-change seman-tic information is used as input next to bi-temporal im-ages. To fully exploit the extra information, we proposeMapFormer, a novel architecture based on a multi-modal feature fusion module that allows for feature processing conditioned on the available semantic information. We further employ a supervised, cross-modal contrastive loss to guide the learning of visual representations. Our ap-proach outperforms existing change detection methods by an absolute 11.7% and 18.4% in terms of binary changeIoU on DynamicEarthNet and HRSCD, respectively. Fur-thermore, we demonstrate the robustness of our approach to the quality of the pre-change semantic information and the absence pre-change imagery. The code is available at https://github.com/mxbh/mapformer. 