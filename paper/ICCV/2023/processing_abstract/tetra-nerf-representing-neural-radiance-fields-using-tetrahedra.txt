Neural Radiance Fields (NeRFs) are a very recent and very popular approach for the problems of novel view syn-thesis and 3D reconstruction. A popular scene representa-tion used by NeRFs is to combine a uniform, voxel-based subdivision of the scene with an MLP. Based on the ob-servation that a (sparse) point cloud of the scene is often available, this paper proposes to use an adaptive represen-tation based on tetrahedra obtained by Delaunay triangula-tion instead of uniform subdivision or point-based represen-tations. We show that such a representation enables efficient training and leads to state-of-the-art results. Our approach elegantly combines concepts from 3D geometry process-ing, triangle-based rendering, and modern neural radiance fields. Compared to voxel-based representations, ours pro-vides more detail around parts of the scene likely to be close to the surface. Compared to point-based representations, our approach achieves better performance. The source code is publicly available at: https://jkulhanek.com/tetra-nerf. 