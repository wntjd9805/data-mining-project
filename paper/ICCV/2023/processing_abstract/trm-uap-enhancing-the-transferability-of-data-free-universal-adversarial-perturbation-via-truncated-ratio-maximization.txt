Aiming at crafting a single universal adversarial pertur-bation (UAP) to fool CNN models for various data sam-ples, universal attack enables a more efficient and accu-rate evaluation for the robustness of CNN models. Early universal attacks craft UAPs depending on data priors.For more practical applications, the data-free universal at-tacks that make UAPs from random noises have aroused much attention recently. However, existing data-free UAP methods perturb all the CNN feature layers equally via the maximization of the CNN activation, leading to poor transferability.In this paper, we propose a novel data-free universal attack without depending on any real data samples through truncated ratio maximization, which we term as TRM-UAP. Specifically, different from the maxi-mization of the positive activation in convolution layers, we propose to optimize the UAP generation from the ra-tio of positive and negative activations. To further en-hance the transferability of universal attack, TRM-UAP not only performs the ratio maximization merely on low-level generic features via the truncation strategy, but also in-corporates a curriculum optimization algorithm that can effectively learn the diversity of artificial images. Exten-sive experiments on the ImageNet dataset verify that TRM-UAP achieves a state-of-the-art average fooling rate and excellent transferability on different CNN models as com-pared to other data-free UAP methods. Code is available at https://github.com/RandolphCarter0/TRMUAP. 