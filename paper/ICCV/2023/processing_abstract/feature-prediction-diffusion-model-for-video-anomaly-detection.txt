Anomaly detection in the video is an important research area and a challenging task in real applications. Due to the unavailability of large-scale annotated anomaly events, most existing video anomaly detection (VAD) methods focus on learning the distribution of normal samples to detect the substantially deviated samples as anomalies. To well learn the distribution of normal motion and appearance, many auxiliary networks are employed to extract foreground ob-ject or action information. These high-level semantic fea-tures effectively ﬁlter the noise from the background to de-crease its inﬂuence on detection models. However, the ca-pability of these extra semantic models heavily affects the performance of the VAD methods. Motivated by the impres-sive generative and anti-noise capacity of diffusion model (DM), in this work, we introduce a novel DM-based method to predict the features of video frames for anomaly de-tection. We aim to learn the distribution of normal sam-ples without any extra high-level semantic feature extrac-tion models involved. To this end, we build two denoising diffusion implicit modules to predict and reﬁne the features.The ﬁrst module concentrates on feature motion learning, while the last focuses on feature appearance learning. To the best of our knowledge, it is the ﬁrst DM-based method to predict frame features for VAD. The strong capacity ofDMs also enables our method to more accurately predict the normal features than non-DM-based feature prediction-based VAD methods. Extensive experiments show that the proposed approach substantially outperforms state-of-the-art competing methods. The code is available atFPDM. 