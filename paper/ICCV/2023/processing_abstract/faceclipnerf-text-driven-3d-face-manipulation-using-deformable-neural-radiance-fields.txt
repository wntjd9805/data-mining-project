As recent advances in Neural Radiance Fields (NeRF) have enabled high-ﬁdelity 3D face reconstruction and novel view synthesis, its manipulation also became an essential task in 3D vision. However, existing manipulation meth-ods require extensive human labor, such as a user-provided semantic mask and manual attribute search unsuitable for non-expert users. Instead, our approach is designed to re-quire a single text to manipulate a face reconstructed withNeRF. To do so, we ﬁrst train a scene manipulator, a latent code-conditional deformable NeRF, over a dynamic scene to control a face deformation using the latent code. How-ever, representing a scene deformation with a single latent code is unfavorable for compositing local deformations ob-served in different instances. As so, our proposed Position-conditional Anchor Compositor (PAC) learns to represent a manipulated scene with spatially varying latent codes.Their renderings with the scene manipulator are then op-timized to yield high cosine similarity to a target text inCLIP embedding space for text-driven manipulation. To the best of our knowledge, our approach is the ﬁrst to address the text-driven manipulation of a face reconstructed withNeRF. Extensive results, comparisons, and ablation studies demonstrate the effectiveness of our approach. 