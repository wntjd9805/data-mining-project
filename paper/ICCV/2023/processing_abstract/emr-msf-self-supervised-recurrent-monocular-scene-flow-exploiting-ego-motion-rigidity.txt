Self-supervised monocular scene flow estimation, aiming to understand both 3D structures and 3D motions from two temporally consecutive monocular images, has received in-creasing attention for its simple and economical sensor setup. However, the accuracy of current methods suffers from the bottleneck of less-efficient network architecture and lack of motion rigidity for regularization. In this pa-per, we propose a superior model named EMR-MSF by borrowing the advantages of network architecture design under the scope of supervised learning. We further im-pose explicit and robust geometric constraints with an elab-orately constructed ego-motion aggregation module where a rigidity soft mask is proposed to filter out dynamic re-gions for stable ego-motion estimation using static regions.Moreover, we propose a motion consistency loss along with a mask regularization loss to fully exploit static regions.Several efficient training strategies are integrated includ-ing a gradient detachment technique and an enhanced view synthesis process for better performance. Our proposed method outperforms the previous self-supervised works by a large margin and catches up to the performance of su-pervised methods. On the KITTI scene flow benchmark, our approach improves the SF-all metric of the state-of-the-art self-supervised monocular method by 44% and demon-strates superior performance across sub-tasks including depth and visual odometry, amongst other self-supervised single-task or multi-task methods. 