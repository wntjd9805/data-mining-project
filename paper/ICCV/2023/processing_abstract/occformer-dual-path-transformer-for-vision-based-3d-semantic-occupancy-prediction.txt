The vision-based perception for autonomous driving has undergone a transformation from the bird-eye-view (BEV) representations to the 3D semantic occupancy. Compared with the BEV planes, the 3D semantic occupancy further provides structural information along the vertical direction.This paper presents OccFormer, a dual-path transformer network to effectively process the 3D volume for semantic occupancy prediction. OccFormer achieves a long-range, dynamic, and efficient encoding of the camera-generated 3D voxel features. It is obtained by decomposing the heavy 3D processing into the local and global transformer path-ways along the horizontal plane. For the occupancy de-coder, we adapt the vanilla Mask2Former for 3D seman-tic occupancy by proposing preserve-pooling and class-guided sampling, which notably mitigate the sparsity and class imbalance. Experimental results demonstrate that Oc-cFormer significantly outperforms existing methods for se-mantic scene completion on SemanticKITTI dataset and forLiDAR semantic segmentation on nuScenes dataset. Code is available at https://github.com/zhangyp15/OccFormer. 