We introduce Replay, a collection of multi-view, multi-modal videos of humans interacting socially. Each scene is ﬁlmed in high production quality, from different view-points with several static cameras, as well as wearable action cameras, and recorded with a large array of mi-crophones at different positions in the room. Overall, the dataset contains over 4000 minutes of footage and over 7 million timestamped high-resolution frames annotated with camera poses and partially with foreground masks. The Re-play dataset has many potential applications, such as novel-view synthesis, 3D reconstruction, novel-view acoustic syn-thesis, human body and face analysis, and training genera-tive models. We provide a benchmark for training and eval-uating novel-view synthesis, with two scenarios of different difﬁculty. Finally, we evaluate several baseline state-of-the-art methods on the new benchmark. 