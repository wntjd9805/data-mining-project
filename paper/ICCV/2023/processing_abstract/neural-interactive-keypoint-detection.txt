This work proposes an end-to-end neural interactive key-point detection framework named Click-Pose, which can significantly reduce more than 10 times labeling costs of 2D keypoint annotation compared with manual-only anno-tation. Click-Pose explores how user feedback can cooper-ate with a neural keypoint detector to correct the predicted keypoints in an interactive way for a faster and more ef-fective annotation process. Specifically, we design the pose error modeling strategy that inputs the ground truth pose combined with four typical pose errors into the decoder and trains the model to reconstruct the correct poses, which en-hances the self-correction ability of the model. Then, we attach an interactive human-feedback loop that allows re-ceiving users’ clicks to correct one or several predicted keypoints and iteratively utilizes the decoder to update all other keypoints with a minimum number of clicks (NoC) for efficient annotation. We validate Click-Pose in in-domain, out-of-domain scenes, and a new task of keypoint adapta-tion. For annotation, Click-Pose only needs 1.97 and 6.45NoC@95 (at precision 95%) on COCO and Human-Art, re-*Work done during an internship at IDEA.†Corresponding author. ducing 31.4% and 36.3% efforts than the SOTA model (ViT-Pose) with manual correction, respectively. Besides, with-out user clicks, Click-Pose surpasses the previous end-to-end model by 1.4 AP on COCO and 3.0 AP on Human-Art. 