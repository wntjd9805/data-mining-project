Incremental learning aims to overcome catastrophic forgetting when learning deep networks from sequential tasks. With impressive learning efficiency and performance, prompt-based methods adopt a fixed backbone to sequen-tial tasks by learning task-specific prompts. However, ex-isting prompt-based methods heavily rely on strong pre-training (typically trained on ImageNet-21k), and we find that their models could be trapped if the potential gap between the pretraining task and unknown future tasks is large.In this work, we develop a learnable AdaptivePrompt Generator (APG). The key is to unify the prompt retrieval and prompt learning processes into a learnable prompt generator. Hence, the whole prompting process can be optimized to reduce the negative effects of the gap be-tween tasks effectively. To make our APG avoid learning ineffective knowledge, we maintain a knowledge pool to reg-ularize APG with the feature distribution of each class. Ex-tensive experiments show that our method significantly out-performs advanced methods in exemplar-free incremental learning without (strong) pretraining. Besides, under strong pretraining, our method also has comparable performance to existing prompt-based models, showing that our method can still benefit from pretraining. Codes can be found at https://github.com/TOM-tym/APG 