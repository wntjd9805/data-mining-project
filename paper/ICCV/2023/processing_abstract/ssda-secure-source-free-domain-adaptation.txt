Source-free domain adaptation (SFDA) is a popular un-supervised domain adaptation method where a pre-trained model from a source domain is adapted to a target do-main without accessing any source data. Despite rich re-sults in this area, existing literature overlooks the secu-rity challenges of the unsupervised SFDA setting in pres-ence of a malicious source domain owner. This work in-vestigates the effect of a source adversary which may in-ject a hidden malicious behavior (Backdoor/Trojan) during source training and potentially transfer it to the target do-main even after benign training by the victim (target do-main owner). Our investigation of the current SFDA set-ting reveals that because of the unique challenges present in SFDA (e.g., no source data, target label), defending against backdoor attack using existing defenses become practically ineffective in protecting the target model. To address this, we propose a novel target domain protec-tion scheme called secure source-free domain adaptation (SSDA). SSDA adopts a single-shot model compression of a pre-trained source model and a novel knowledge transfer scheme with a spectral-norm-based loss penalty for target training. The proposed static compression and the dynamic training loss penalty are designed to suppress the malicious channels responsive to the backdoor during the adaptation stage. At the same time, the knowledge transfer from an un-compressed auxiliary model helps to recover the benign test accuracy. Our extensive evaluation on multiple dataset and domain tasks against recent backdoor attacks reveal that the proposed SSDA can successfully defend against strong backdoor attacks with little to no degradation in test accu-racy compared to the vulnerable baseline SFDA methods.Our code is available at https://github.com/ML-Security-Research-LAB/SSDA. 