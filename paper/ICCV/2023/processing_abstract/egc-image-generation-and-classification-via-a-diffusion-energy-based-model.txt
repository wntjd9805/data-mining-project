Learning image classification and image generation using the same set of network parameters presents a formidable challenge. Recent advanced approaches per-form well in one task often exhibit poor performance in the other. This work introduces an energy-based classi-fier and generator, namely EGC, which can achieve supe-rior performance in both tasks using a single neural net-work. Unlike conventional classifiers that produce a label given an image (i.e., a conditional distribution p(y|x)), the forward pass in EGC is a classification model that yields a joint distribution p(x, y), enabling a diffusion model in its backward pass by marginalizing out the label y to esti-mate the score function. Furthermore, EGC can be adapted for unsupervised learning by considering the label as la-tent variables. EGC achieves competitive generation results compared with state-of-the-art approaches on ImageNet-1k,CelebA-HQ and LSUN Church, while achieving superior classification accuracy and robustness against adversarial attacks on CIFAR-10. This work marks the inaugural suc-cess in mastering both domains using a unified network pa-rameter set. We believe that EGC bridges the gap between discriminative and generative learning. Code will be re-leased at https://github.com/GuoQiushan/EGC.Figure 2: FID and classification accuracy on ImageNet 256Ã—256 dataset. The scatters plots on the vertical N/A line represent the image generation models, which are not available for classification. The scatter plot on the horizon-tal N/A line represents the classification model, which is not available for image generation. Remarkably, EGC achieves superior performance in both tasks with a single neural net-work, demonstrating its effectiveness in bridging the gap between discriminative and generative learning.