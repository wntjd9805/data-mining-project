1.2. Answer GroundingAnswer grounding is the task of locating relevant visual evidence for the Visual Question Answering task. While a wide variety of attention methods have been introduced for this task, they suffer from the following three prob-lems: designs that do not allow the usage of pre-trained networks and do not benefit from large data pre-training, custom designs that are not based on well-grounded pre-vious designs, therefore limiting the learning power of the network, or complicated designs that make it challeng-ing to re-implement or improve them.In this paper, we propose a novel architectural block, which we term Sen-tence Attention Block, to solve these problems. The pro-posed block re-calibrates channel-wise image feature-maps by explicitly modeling inter-dependencies between the im-age feature-maps and sentence embedding. We visually demonstrate how this block filters out irrelevant feature-maps channels based on sentence embedding. We start our design with a well-known attention method, and by mak-ing minor modifications, we improve the results to achieve state-of-the-art accuracy. The flexibility of our method makes it easy to use different pre-trained backbone net-works, and its simplicity makes it easy to understand and be re-implemented. We demonstrate the effectiveness of our method on the TextVQA-X, VQS, VQA-X, and VizWiz-VQA-Grounding datasets. We perform multiple ablation studies to show the effectiveness of our design choices. 