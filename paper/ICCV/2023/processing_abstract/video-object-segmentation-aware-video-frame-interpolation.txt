Video frame interpolation (VFI) is a very active re-search topic due to its broad applicability to many ap-plications, including video enhancement, video encoding, and slow-motion effects. VFI methods have been advanced by improving the overall image quality for challenging se-quences containing occlusions, large motion, and dynamic texture. This mainstream research direction neglects that foreground and background regions have different impor-tance in perceptual image quality. Moreover, accurate syn-thesis of moving objects can be of utmost importance in computer vision applications.In this paper, we propose a video object segmentation (VOS)-aware training frame-work called VOS-VFI that allows VFI models to interpolate frames with more precise object boundaries. Specifically, we exploit VOS as an auxiliary task to help train VFI mod-els by providing additional loss functions, including seg-mentation loss and bi-directional consistency loss. From extensive experiments, we demonstrate that VOS-VFI can boost the performance of existing VFI models by render-ing clear object boundaries. Moreover, VOS-VFI displays its effectiveness on multiple benchmarks for different appli-cations, including video object segmentation, object pose estimation, and visual tracking. The code is available at https://github.com/junsang7777/VOS-VFI 