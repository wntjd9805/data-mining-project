Removing clutter from scenes is essential in many ap-plications, ranging from privacy-concerned content filter-ing to data augmentation. In this work, we present an au-tomatic system that removes clutter from 3D scenes and inpaints with coherent geometry and texture. We pro-pose techniques for its two key components: 3D segmen-tation based on shared properties and 3D inpainting, both of which are important problems. The definition of 3D scene clutter (frequently-moving objects) is not well cap-tured by commonly-studied object categories in computer vision. To tackle the lack of well-defined clutter anno-tations, we group noisy fine-grained labels, leverage vir-tual rendering, and impose an instance-level area-sensitive loss. Once clutter is removed, we inpaint geometry and texture in the resulting holes by merging inpainted RGB-D images. This requires novel voting and pruning strategies that guarantee multi-view consistency across individually inpainted images for mesh reconstruction. Experiments onScanNet and Matterport3D dataset show that our method outperforms baselines for clutter segmentation and 3D in-painting, both visually and quantitatively. Project page: https://weify627.github.io/clutter/. 