Recent years have witnessed the prevailing progress of Generative Adversarial Networks (GANs) in image-to-image translation. However, the success of these GAN mod-els hinges on ponderous computational costs and labor-expensive training data. Current efficient GAN learning techniques often fall into two orthogonal aspects: i) model ii) data/label-slimming via reduced calculation costs; efficient learning with fewer training data/labels. To com-bine the best of both worlds, we propose a new learning paradigm, Unified GAN Compression (UGC), with a uni-fied optimization objective to seamlessly prompt the syn-ergy of model-efficient and label-efficient learning. UGC sets up semi-supervised-driven network architecture search and adaptive online semi-supervised distillation stages se-quentially, which formulates a heterogeneous mutual learn-ing scheme to obtain an architecture-flexible, label-efficient,⋆Equal contribution. †Corresponding author. and performance-excellent model. Extensive experiments demonstrate that UGC obtains state-of-the-art lightweight models even with less than 50% labels. UGC that com-presses 40× MACs can achieve 21.43 FID on edges→shoes with 25% labels, which even outperforms the original model with 100% labels by 2.75 FID. 