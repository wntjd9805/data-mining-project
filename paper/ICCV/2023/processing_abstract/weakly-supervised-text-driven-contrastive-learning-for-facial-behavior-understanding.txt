Contrastive learning has shown promising potential for learning robust representations by utilizing unlabeled data.However, constructing effective positive-negative pairs for contrastive learning on facial behavior datasets remains challenging. This is because such pairs inevitably en-code the subject-ID information, and the randomly con-structed pairs may push similar facial images away due to the limited number of subjects in facial behavior datasets.To address this issue, we propose to utilize activity de-scriptions, coarse-grained information provided in some datasets, which can provide high-level semantic informa-tion about the image sequences but is often neglected in pre-vious studies. More specifically, we introduce a two-stageContrastive Learning with Text-Embeded framework forFacial behavior understanding (CLEF). The first stage is a weakly-supervised contrastive learning method that learns representations from positive-negative pairs constructed us-ing coarse-grained activity information. The second stage aims to train the recognition of facial expressions or facial action units by maximizing the similarity between the im-age and the corresponding text label names. The proposedCLEF achieves state-of-the-art performance on three in-the-lab datasets for AU recognition and three in-the-wild datasets for facial expression recognition. 