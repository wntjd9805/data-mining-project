Human pose estimation (HPE) is integral to scene un-derstanding in numerous safety-critical domains involving human-machine interaction, such as autonomous driving or semi-automated work environments. Avoiding costly mis-takes is synonymous with anticipating failure in model pre-dictions, which necessitates meta-judgments on the accu-racy of the applied models. Here, we propose a straight-forward human pose regression framework to examine the behavior of two established methods for simultane-ous aleatoric and epistemic uncertainty estimation: maxi-mum a-posteriori (MAP) estimation with Monte-Carlo vari-ational inference and deep evidential regression (DER).First, we evaluate both approaches on the quality of their predicted variances and whether these truly capture the ex-pected model error. The initial assessment indicates that both methods exhibit the overconﬁdence issue common in deep probabilistic models. This observation motivates our implementation of an additional recalibration step to ex-tract reliable conﬁdence intervals. We then take a closer look at deep evidential regression, which, to our knowledge, is applied comprehensively for the ﬁrst time to the HPE problem. Experimental results indicate that DER behaves as expected in challenging and adverse conditions com-monly occurring in HPE and that the predicted uncertain-ties match their purported aleatoric and epistemic sources.Notably, DER achieves smooth uncertainty estimates with-out the need for a costly sampling step, making it an at-tractive candidate for uncertainty estimation on resource-limited platforms. 