Most prior semantic segmentation methods have been developed for day-time scenes, while typically underper-forming in night-time scenes due to insufﬁcient and com-plicated lighting conditions.In this work, we tackle this challenge by proposing a novel night-time semantic seg-mentation paradigm, i.e., disentangle then parse (DTP).DTP explicitly disentangles night-time images into light-invariant reﬂectance and light-speciﬁc illumination compo-nents and then recognizes semantics based on their adaptive fusion. Concretely, the proposed DTP comprises two key components: 1) Instead of processing lighting-entangled features as in prior works, our Semantic-Oriented Disen-tanglement (SOD) framework enables the extraction of re-ﬂectance component without being impeded by lighting, al-lowing the network to consistently recognize the seman-tics under cover of varying and complicated lighting con-ditions. 2) Based on the observation that the illumination component can serve as a cue for some semantically con-fused regions, we further introduce an Illumination-AwareParser (IAParser) to explicitly learn the correlation be-tween semantics and lighting, and aggregate the illumi-nation features to yield more precise predictions. Exten-sive experiments on the night-time segmentation task with various settings demonstrate that DTP signiﬁcantly outper-forms state-of-the-art methods. Furthermore, with negligi-ble additional parameters, DTP can be directly used to ben-eﬁt existing day-time methods for night-time segmentation.Code and dataset are available at https://github. com/w1oves/DTP.git. 