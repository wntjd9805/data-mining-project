Both indoor and outdoor environments are inherently structured and repetitive. Traditional modeling pipelines keep an asset library storing unique object templates, which is both versatile and memory efﬁcient in practice. Inspired by this observation, we propose AssetField, a novel neu-ral scene representation that learns a set of object-aware ground feature planes to represent the scene, where an asset library storing template feature patches can be constructed in an unsupervised manner. Unlike existing methods which require object masks to query spatial points for object edit-ing, our ground feature plane representation offers a natu-ral visualization of the scene in the bird-eye view, allowing a variety of operations (e.g. translation, duplication, defor-mation) on objects to conﬁgure a new scene. With the tem-plate feature patches, group editing is enabled for scenes with many recurring items to avoid repetitive work on ob-ject individuals. We show that AssetField not only achieves competitive performance for novel-view synthesis but also generates realistic renderings for new scene conﬁgurations. 