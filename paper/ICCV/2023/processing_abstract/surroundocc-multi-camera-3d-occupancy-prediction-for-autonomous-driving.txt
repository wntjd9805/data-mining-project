3D scene understanding plays a vital role in vision-based autonomous driving. While most existing meth-ods focus on 3D object detection, they have difficulty de-scribing real-world objects of arbitrary shapes and infi-nite classes. Towards a more comprehensive perception of a 3D scene, in this paper, we propose a SurroundOcc method to predict the 3D occupancy with multi-camera im-ages. We first extract multi-scale features for each image and adopt spatial 2D-3D attention to lift them to the 3D volume space. Then we apply 3D convolutions to progres-sively upsample the volume features and impose supervision on multiple levels. To obtain dense occupancy prediction, we design a pipeline to generate dense occupancy ground truth without expansive occupancy annotations. Specifi-cally, we fuse multi-frame LiDAR scans of dynamic ob-jects and static scenes separately. Then we adopt Pois-son Reconstruction to fill the holes and voxelize the mesh to get dense occupancy labels. Extensive experiments on nuScenes and SemanticKITTI datasets demonstrate the su-periority of our method. Code and dataset are available at https://github.com/weiyithu/SurroundOcc. 