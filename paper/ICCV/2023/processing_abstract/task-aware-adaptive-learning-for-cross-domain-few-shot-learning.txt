Although existing few-shot learning works yield promis-ing results for in-domain queries, they still suffer from weak cross-domain generalization. Limited support data requires effective knowledge transfer, but domain-shift makes this harder. Towards this emerging challenge, researchers im-proved adaptation by introducing task-specific parameters, which are directly optimized and estimated for each task.However, adding a fixed number of additional parameters fails to consider the diverse domain shifts between target tasks and the source domain, limiting efficacy. In this paper, we first observe the dependence of task-specific parameter configuration on the target task. Abundant task-specific pa-rameters may over-fit, and insufficient task-specific param-eters may result in under-adaptation â€“ but the optimal task-specific configuration varies for different test tasks. Based on these findings, we propose the Task-aware Adaptive Net-work (TA2-Net), which is trained by reinforcement learning to adaptively estimate the optimal task-specific parameter configuration for each test task. It learns, for example, that tasks with significant domain-shift usually have a larger need for task-specific parameters for adaptation. We eval-uate our model on Meta-dataset. Empirical results show that our model outperforms existing state-of-the-art meth-ods. Our code is available at https://github.com/PRIS-CV/TA2-Net. 