Neural image compression methods have seen increas-ingly strong performance in recent years. However, they suffer orders of magnitude higher computational complex-ity compared to traditional codecs, which hinders their real-world deployment. This paper takes a step forward in closing this gap in decoding complexity by adopting shallow or even linear decoding transforms. To compen-sate for the resulting drop in compression performance, we exploit the often asymmetrical computation budget be-tween encoding and decoding, by adopting more power-ful encoder networks and iterative encoding. We theoret-ically formalize the intuition behind, and our experimen-tal results establish a new frontier in the trade-off between rate-distortion and decoding complexity for neural image compression. Specifically, we achieve rate-distortion per-formance competitive with the established mean-scale hy-perprior architecture of Minnen et al. (2018) at less than 50K decoding FLOPs/pixel, reducing the baselineâ€™s overall decoding complexity by 80%, or over 90% for the synthe-sis transform alone. Our code can be found at https://github.com/mandt-lab/shallow-ntc. 