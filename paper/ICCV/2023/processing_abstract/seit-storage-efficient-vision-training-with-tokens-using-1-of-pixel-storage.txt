We need billion-scale images to achieve more general-izable and ground-breaking vision models, as well as mas-sive dataset storage to ship the images (e.g., the LAION-5B dataset needs 240TB storage space). However, it has become challenging to deal with unlimited dataset storage with limited storage infrastructure. A number of storage-efﬁcient training methods have been proposed to tackle the problem, but they are rarely scalable or suffer from severe damage to performance.In this paper, we pro-pose a storage-efﬁcient training strategy for vision clas-siﬁers for large-scale datasets (e.g., ImageNet) that only uses 1024 tokens per instance without using the raw level pixels; our token storage only needs <1% of the originalJPEG-compressed raw pixels. We also propose token aug-mentations and a Stem-adaptor module to make our ap-proach able to use the same architecture as pixel-based ap-proaches with only minimal modiﬁcations on the stem layer and the carefully tuned optimization settings. Our exper-imental results on ImageNet-1k show that our method sig-niﬁcantly outperforms other storage-efﬁcient training meth-ods with a large gap. We further show the effectiveness of our method in other practical scenarios, storage-efﬁcient pre-training, and continual learning. Code is available at https://github.com/naver-ai/seit 