We study the problem of estimating optical flow from event cameras. One important issue is how to build a high-quality event-flow dataset with accurate event values and flow labels. Previous datasets are created by either captur-ing real scenes by event cameras or synthesizing from im-ages with pasted foreground objects. The former case can produce real event values but with calculated flow labels, which are sparse and inaccurate. The latter case can gener-ate dense flow labels but the interpolated events are prone to errors. In this work, we propose to render a physically cor-rect event-flow dataset using computer graphics models. In particular, we first create indoor and outdoor 3D scenes byBlender with rich scene content variations. Second, diverse camera motions are included for the virtual capturing, pro-ducing images and accurate flow labels. Third, we render high-framerate videos between images for accurate events.The rendered dataset can adjust the density of events, based on which we further introduce an adaptive density mod-ule (ADM). Experiments show that our proposed dataset can facilitate event-flow learning, whereas previous ap-proaches when trained on our dataset can improve their performances constantly by a relatively large margin.In addition, event-flow pipelines when equipped with our ADM can further improve performances. Our code is available at https://github.com/boomluo02/ADMFlow.Figure 1: (a) the captured dataset from real event cam-era [55, 54]. (b) the synthesized dataset with flying chairs (c) the synthesized dataset by moving foreground [50]. a foreground image [42]. (d) Our synthesized dataset by graphics rendering, which not only reflects the real motions under correct scene geometries, but also produces accurate dense flow labels and events. 