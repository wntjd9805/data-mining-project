Underwater (UW) depth estimation and image restora-tion is a challenging task due to its fundamental ill-posedness and the unavailability of real large-scale UW-paired datasets. UW depth estimation has been attempted before by utilizing either the haze information present or the geometry cue from stereo images or the adjacent frames in a video. To obtain improved estimates of depth from a singleUW image, we propose a deep learning (DL) method that utilizes both haze and geometry during training. By har-nessing the physical model for UW image formation in con-junction with the view-synthesis constraint on neighboring frames in monocular videos, we perform disentanglement of the input image to also get an estimate of the scene ra-diance. The proposed method is completely self-supervised and simultaneously outputs the depth map and the restored image in real-time (55 fps). We call this first-ever Under-water Self-supervised deep learning network for simultane-ous Recovery of Depth and Image as USe-ReDI-Net. To fa-cilitate monocular self-supervision, we collected a Dataset of Real-world Underwater Videos of Artifacts (DRUVA) in shallow sea waters. DRUVA is the first UW video dataset that contains video sequences of 20 different submerged artifacts with almost full azimuthal coverage of each ar-tifact. Extensive experiments on our DRUVA dataset and other UW datasets establish the superiority of our proposedUSe-ReDI-Net over prior art for both UW depth and im-age recovery. The dataset DRUVA is available at https://github.com/nishavarghese15/DRUVA. 