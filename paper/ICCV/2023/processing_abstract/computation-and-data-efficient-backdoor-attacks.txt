image, point cloud, naturalBackdoor attacks against deep neural network (DNN) models have been widely studied. Various attack techniques have been proposed for different domains and paradigms, language processing, e.g., transfer learning, etc. The most widely-used way to em-bed a backdoor into a DNN model is to poison the training data. They usually randomly select samples from the benign training set for poisoning, without considering the distinct contribution of each sample to the backdoor effectiveness, making the attack less optimal.It theoretical proofing.A recent work [40] proposed to use the forgetting score to measure the importance of each poisoned sam-ple and then filter out redundant data for effective back-door training. However, this method is empirically de-signed without is also very time-consuming as it needs to go through several train-ing stages for data selection.To address such lim-itations, we propose a novel confidence-based scoring methodology, which can efficiently measure the contri-bution of each poisoning sample based on the distance posteriors. We further introduce a greedy search algo-rithm to find the most informative samples for backdoor injection more promptly.Experimental evaluations on both 2D image and 3D point cloud classification tasks show that our approach can achieve comparable perfor-mance or even surpass the forgetting score-based search-ing method while requiring only several extra epochsâ€™ com-putation of a standard training process. Our code can be found at https://github.com/WU-YU-TONG/ computational_efficient_backdoor 