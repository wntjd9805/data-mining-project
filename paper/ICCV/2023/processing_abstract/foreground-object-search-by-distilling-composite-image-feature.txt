Foreground object search (FOS) aims to find compati-ble foreground objects for a given background image, pro-ducing realistic composite image. We observe that com-petitive retrieval performance could be achieved by us-ing a discriminator to predict the compatibility of com-posite image, but this approach has unaffordable timeTo this end, we propose a novel FOS method cost. via distilling composite feature (DiscoFOS). Specifically, the abovementioned discriminator serves as teacher net-work. The student network employs two encoders to ex-tract foreground feature and background feature. Their interaction output is enforced to match the composite image feature from the teacher network. Additionally, previous works did not release their datasets, so we contribute two datasets for FOS task: S-FOSD dataset with synthetic composite images and R-FOSD dataset with real composite images. Extensive experiments on our two datasets demonstrate the superiority of the pro-posed method over previous approaches. The dataset and code are available at https://github.com/bcmi/Foreground-Object-Search-Dataset-FOSD. 