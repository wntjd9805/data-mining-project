Generating life-like whole-body human grasping has garnered significant attention in the field of computer graphics. Existing works have demonstrated the effec-tiveness of keyframe-guided motion generation framework, witch focus on modeling the grasping motions of humans in temporal sequence when the target objects are placed in front of them. However, the generated grasping poses of the human body in the key-frames are limited, failing to capture the full range of grasping poses that humans are capable of.To address this issue, we propose a novel framework called COOP (DeCOupling and COupling of Whole-BodyGrasPing Pose Generation) to synthesize life-like whole-body poses that cover the widest range of human grasping capabilities. In this framework, we first decouple the whole-body pose into body pose and hand pose and model them separately, which allows us to pre-train the body model with out-of-domain data easily. Then, we couple these two gen-â€ Corresponding author. erated body parts through a unified optimization algorithm.Furthermore, we design a simple evaluation method to evaluate the generalization ability of models in gener-ating grasping poses for objects placed at different po-sitions.The experimental results demonstrate the effi-cacy and superiority of our method. And COOP holds great potential as a plug-and-play component for other domains in whole-body pose generation. Our models and code are available at https://github.com/ zhengyanzhao1997/COOP. 