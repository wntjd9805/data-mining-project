The last decade has witnessed the success of deep learn-ing and the surge of publicly released trained models, which necessitates the quantification of the model functional dis-tance for various purposes. However, quantifying the model functional distance is always challenging due to the opacity in inner workings and the heterogeneity in architectures or tasks. Inspired by the concept of “field” in physics, in this work we introduce Model Gradient Field (abbr. ModelGiF) to extract homogeneous representations from the heteroge-neous pre-trained models. Our main assumption underlyingModelGiF is that each pre-trained deep model uniquely de-termines a ModelGiF over the input space. The distance between models can thus be measured by the similarity be-tween their ModelGiFs. We validate the effectiveness of the proposed ModelGiF with a suite of testbeds, includ-ing task relatedness estimation, intellectual property pro-tection, and model unlearning verification. Experimental results demonstrate the versatility of the proposed Model-GiF on these tasks, with significantly superiority perfor-mance to state-of-the-art competitors. Codes are available at https://github.com/zju-vipa/modelgif. 