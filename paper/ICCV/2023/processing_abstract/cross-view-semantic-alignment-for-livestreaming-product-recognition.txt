Live commerce is the act of selling products online through live streaming. The customer’s diverse demands for online products introduce more challenges to Livestream-ing Product Recognition. Previous works have primarily focused on fashion clothing data or utilize single-modal in-put, which does not reflect the real-world scenario where multimodal data from various categories are present.In this paper, we present LPR4M, a large-scale multimodal dataset that covers 34 categories, comprises 3 modalities (image, video, and text), and is 50× larger than the largest publicly available dataset. LPR4M contains diverse videos and noise modality pairs while exhibiting a long-tailed dis-tribution, resembling real-world problems. Moreover, a cRoss-vIew semantiC alignmEnt (RICE) model is proposed to learn discriminative instance features from the image and video views of the products. This is achieved through instance-level contrastive learning and cross-view patch-level feature propagation. A novel Patch Feature Recon-struction loss is proposed to penalize the semantic mis-alignment between cross-view patches. Extensive experi-ments demonstrate the effectiveness of RICE and provide insights into the importance of dataset diversity and ex-pressivity. The dataset and code are available at https://github.com/adxcreative/RICE. 