Single hyperspectral image super-resolution (single-HSI-SR) aims to restore a high-resolution hyperspectral im-age from a low-resolution observation. However, the pre-vailing CNN-based approaches have shown limitations in building long-range dependencies and capturing interac-tion information between spectral features. This results in inadequate utilization of spectral information and artifacts after upsampling. To address this issue, we propose ES-SAformer, an ESSA attention-embedded Transformer net-work for single-HSI-SR with an iterative refining struc-ture. Specifically, we first introduce a robust and spectral-friendly similarity metric, i.e., the spectral correlation coef-ficient of the spectrum (SCC), to replace the original atten-tion matrix and incorporates inductive biases into the model to facilitate training. Built upon it, we further utilize the kernelizable attention technique with theoretical support to form a novel efficient SCC-kernel-based self-attention (ESSA) and reduce attention computation to linear com-plexity. ESSA enlarges the receptive field for features after upsampling without bringing much computation and allows the model to effectively utilize spatial-spectral information from different scales, resulting in the generation of more natural high-resolution images. Without the need for pre-training on large-scale datasets, our experiments demon-strate ESSAâ€™s effectiveness in both visual quality and quan-titative results. The code will be released at ESSAformer. 