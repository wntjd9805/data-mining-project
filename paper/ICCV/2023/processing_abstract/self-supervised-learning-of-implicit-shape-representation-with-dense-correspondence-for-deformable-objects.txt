Learning 3D shape representation with dense correspon-dence for deformable objects is a fundamental problem in computer vision. Existing approaches often need addi-tional annotations of specific semantic domain, e.g., skele-ton poses for human bodies or animals, which require extra annotation effort and suffer from error accumulation, and they are limited to specific domain. In this paper, we pro-pose a novel self-supervised approach to learn neural im-plicit shape representation for deformable objects, which can represent shapes with a template shape and dense cor-respondence in 3D. Our method does not require the pri-ors of skeleton and skinning weight, and only requires a collection of shapes represented in signed distance fields.To handle the large deformation, we constrain the learned template shape in the same latent space with the train-ing shapes, design a new formulation of local rigid con-straint that enforces rigid transformation in local region and addresses local reflection issue, and present a new hi-erarchical rigid constraint to reduce the ambiguity due to the joint learning of template shape and correspondences.Extensive experiments show that our model can represent shapes with large deformations. We also show that our shape representation can support two typical applications, such as texture transfer and shape editing, with competi-tive performance. The code and models are available at https://iscas3dv.github.io/deformshape. 