Pre-trained point cloud models have found extensive ap-plications in 3D understanding tasks like object classifica-tion and part segmentation. However, the prevailing strat-egy of full fine-tuning in downstream tasks leads to large per-task storage overhead for model parameters, which limits the efficiency when applying large-scale pre-trained models. Inspired by the recent success of visual prompt tun-ing (VPT), this paper attempts to explore prompt tuning on pre-trained point cloud models, to pursue an elegant bal-ance between performance and parameter efficiency. We find while instance-agnostic static prompting, e.g. VPT, shows some efficacy in downstream transfer, it is vulnera-ble to the distribution diversity caused by various types of noises in real-world point cloud data. To conquer this limi-tation, we propose a novel Instance-aware Dynamic PromptTuning (IDPT) strategy for pre-trained point cloud mod-els. The essence of IDPT is to develop a dynamic prompt generation module to perceive semantic prior features of each point cloud instance and generate adaptive prompt to-kens to enhance the modelâ€™s robustness. Notably, extensive experiments demonstrate that IDPT outperforms full fine-tuning in most tasks with a mere 7% of the trainable param-eters, providing a promising solution to parameter-efficient learning for pre-trained point cloud models. Code is avail-able at https://github.com/zyh16143998882/ICCV23-IDPT. 