Despite being highly performant, deep neural networks might base their decisions on features that spuriously cor-relate with the provided labels, thus hurting generalization.To mitigate this, ‘model guidance’ has recently gained pop-ularity, i.e. the idea of regularizing the models’ explana-tions to ensure that they are “right for the right reasons”[49]. While various techniques to achieve such model guid-ance have been proposed, experimental validation of these approaches has thus far been limited to relatively simple and / or synthetic datasets. To better understand the effec-tiveness of the various design choices that have been ex-plored in the context of model guidance, in this work we conduct an in-depth evaluation across various loss func-tions, attribution methods, models, and ‘guidance depths’ on the PASCAL VOC 2007 and MS COCO 2014 datasets.As annotation costs for model guidance can limit its ap-plicability, we also place a particular focus on efﬁciency.Speciﬁcally, we guide the models via bounding box anno-tations, which are much cheaper to obtain than the com-monly used segmentation masks, and evaluate the robust-ness of model guidance under limited (e.g. with only 1% of annotated images) or overly coarse annotations. Further, we propose using the EPG score as an additional evalua-tion metric and loss function (‘Energy loss’). We show that optimizing for the Energy loss leads to models that exhibit a distinct focus on object-speciﬁc features, despite only us-ing bounding box annotations that also include background regions. Lastly, we show that such model guidance can im-prove generalization under distribution shifts. Code avail-able at: https://github.com/sukrutrao/Model-Guidance 