Online continual learning (CL) studies the problem of learning continuously from a single-pass data stream while adapting to new data and mitigating catastrophic forget-ting. Recently, by storing a small subset of old data, replay-based methods have shown promising performance. Unlike previous methods that focus on sample storage or knowl-edge distillation against catastrophic forgetting, this paper aims to understand why the online learning models fail to generalize well from a new perspective of shortcut learn-ing. We identify shortcut learning as the key limiting fac-tor for online CL, where the learned features may be bi-ased, not generalizable to new tasks, and may have an ad-verse impact on knowledge distillation. To tackle this issue, we present the online prototype learning (OnPro) frame-work for online CL. First, we propose online prototype equilibrium to learn representative features against short-cut learning and discriminative features to avoid class con-fusion, ultimately achieving an equilibrium status that sep-arates all seen classes well while learning new classes. Sec-ond, with the feedback of online prototypes, we devise a novel adaptive prototypical feedback mechanism to sense the classes that are easily misclassified and then enhance their boundaries. Extensive experimental results on widely-used benchmark datasets demonstrate the superior perfor-mance of OnPro over the state-of-the-art baseline meth-ods. Source code is available at https://github. com/weilllllls/OnPro. 