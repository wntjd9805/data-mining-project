Neural Radiance Field (NeRF) has shown impressive performance in novel view synthesis via implicit scene rep-resentation. However, it usually suffers from poor scala-bility as requiring densely sampled images for each new scene.Several studies have attempted to mitigate this problem by integrating Multi-View Stereo (MVS) technique into NeRF while they still entail a cumbersome ﬁne-tuning process for new scenes. Notably, the rendering qual-ity will drop severely without this ﬁne-tuning process and the errors mainly appear around the high-frequency fea-tures. In the light of this observation, we design WaveN-eRF, which integrates wavelet frequency decomposition intoMVS and NeRF to achieve generalizable yet high-quality synthesis without any per-scene optimization.To pre-serve high-frequency information when generating 3D fea-ture volumes, WaveNeRF builds Multi-View Stereo in theWavelet domain by integrating the discrete wavelet trans-form into the classical cascade MVS, which disentangles high-frequency information explicitly. With that, disentan-gled frequency features can be injected into classic NeRF via a novel hybrid neural renderer to yield faithful high-frequency details, and an intuitive frequency-guided sam-pling strategy can be designed to suppress artifacts around high-frequency regions. Extensive experiments over three widely studied benchmarks show that WaveNeRF achieves superior generalizable radiance ﬁeld modeling when only given three images as input. 