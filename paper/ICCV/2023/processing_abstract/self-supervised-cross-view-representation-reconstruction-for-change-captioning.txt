Change captioning aims to describe the difference be-tween a pair of similar images.Its key challenge is how to learn a stable difference representation under pseudo changes caused by viewpoint change.In this paper, we address this by proposing a self-supervised cross-view representation reconstruction (SCORER) network. Con-cretely, we first design a multi-head token-wise matching to model relationships between cross-view features fromThen, by maximizing cross-similar/dissimilar images. view contrastive alignment of two similar images, SCORER learns two view-invariant image representations in a self-supervised way. Based on these, we reconstruct the rep-resentations of unchanged objects by cross-attention, thus learning a stable difference representation for caption gen-eration. Further, we devise a cross-modal backward rea-soning to improve the quality of caption. This module re-versely models a “hallucination” representation with the caption and “before” representation. By pushing it closer to the “after” representation, we enforce the caption to be informative about the difference in a self-supervised man-ner. Extensive experiments show our method achieves the state-of-the-art results on four datasets. The code is avail-able at https://github.com/tuyunbin/SCORER. 