Using deep learning, 3D autonomous driving semantic segmentation has become a well-studied subject, with meth-ods that can reach very high performance. Nonetheless, because of the limited size of the training datasets, these models cannot see every type of object and scene found in real-world applications. The ability to be reliable in these various unknown environments is called domain generaliza-tion.Despite its importance, domain generalization is rela-tively unexplored in the case of 3D autonomous driving se-mantic segmentation. To fill this gap, this paper presents the first benchmark for this application by testing state-of-the-art methods and discussing the difficulty of tackling LaserImaging Detection and Ranging (LiDAR) domain shifts.We also propose the first method designed to address this domain generalization, which we call 3DLabelProp. This method relies on leveraging the geometry and sequential-ity of the LiDAR data to enhance its generalization perfor-mances by working on partially accumulated point clouds.It reaches a mean Intersection over Union (mIoU) of 50.4% on SemanticPOSS and of 55.2% on PandaSet solid-state Li-DAR while being trained only on SemanticKITTI, making it the state-of-the-art method for generalization (+5% and+33% better, respectively, than the second best method).The code for this method is available on GitHub: https://github.com/JulesSanchez/3DLabelProp. 