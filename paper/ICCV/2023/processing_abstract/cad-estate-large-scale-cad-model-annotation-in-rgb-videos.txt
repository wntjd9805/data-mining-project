ular Scan2CAD benchmark. https://github.com/google-research/cad-estate .The dataset is available atWe propose a method for annotating videos of com-plex multi-object scenes with a globally-consistent 3D rep-resentation of the objects. We annotate each object with a CAD model from a database, and place it in the 3D coordinate frame of the scene with a 9-DoF pose trans-formation. Our method is semi-automatic and works on commonly-available RGB videos, without requiring a depth sensor. Many steps are performed automatically, and the tasks performed by humans are simple, well-specified, and require only limited reasoning in 3D. This makes them fea-sible for crowd-sourcing and has allowed us to construct a large-scale dataset by annotating real-estate videos fromYouTube. Our dataset CAD-Estate offers 101k instances of 12k unique CAD models placed in the 3D representations of 20k videos. In comparison to Scan2CAD, the largest ex-isting dataset with CAD model annotations on real scenes,CAD-Estate has 7× more instances and 4× more uniqueCAD models. We showcase the benefits of pre-training aMask2CAD model on CAD-Estate for the task of automatic 3D object reconstruction and pose estimation, demonstrat-ing that it leads to performance improvements on the pop-