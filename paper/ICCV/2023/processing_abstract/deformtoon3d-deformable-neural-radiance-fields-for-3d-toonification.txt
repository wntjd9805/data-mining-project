In this paper, we address the challenging problem of 3D toonification, which involves transferring the style of an artistic domain onto a target 3D face with stylized ge-ometry and texture. Although fine-tuning a pre-trained 3DGAN on the artistic domain can produce reasonable perfor-mance, this strategy has limitations in the 3D domain. In particular, fine-tuning can deteriorate the original GAN la-tent space, which affects subsequent semantic editing, and requires independent optimization and storage for each new style, limiting flexibility and efficient deployment. To over-come these challenges, we propose DEFORMTOON3D, an effective toonification framework tailored for hierarchical 3D GAN. Our approach decomposes 3D toonification into*Equal contribution. subproblems of geometry and texture stylization to better preserve the original latent space. Specifically, we devise a novel StyleField that predicts conditional 3D deformation to align a real-space NeRF to the style space for geome-try stylization. Thanks to the StyleField formulation, which already handles geometry stylization well, texture styliza-tion can be achieved conveniently via adaptive style mixing that injects information of the artistic domain into the de-coder of the pre-trained 3D GAN. Due to the unique design, our method enables flexible style degree control and shape-texture-specific style swap. Furthermore, we achieve effi-cient training without any real-world 2D-3D training pairs but proxy samples synthesized from off-the-shelf 2D tooni-fication models. Code is released at https://github. com/junzhezhang/DeformToon3D.