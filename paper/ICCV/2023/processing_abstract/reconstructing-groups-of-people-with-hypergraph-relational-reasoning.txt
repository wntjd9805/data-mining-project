Due to the mutual occlusion, severe scale variation, and complex spatial distribution, the current multi-person mesh recovery methods cannot produce accurate absolute body poses and shapes in large-scale crowded scenes. To ad-dress the obstacles, we fully exploit crowd features for re-constructing groups of people from a monocular image. A novel hypergraph relational reasoning network is proposed to formulate the complex and high-order relation corre-lations among individuals and groups in the crowd. We first extract compact human features and location infor-mation from the original high-resolution image. By con-ducting the relational reasoning on the extracted individ-ual features, the underlying crowd collectiveness and in-teraction relationship can provide additional group infor-mation for the reconstruction. Finally, the updated indi-vidual features and the localization information are used to regress human meshes in camera coordinates. To facili-tate the network training, we further build pseudo ground-*Corresponding author. E-mail: yangangwang@seu.edu.cn. All the authors from Southeast University are affiliated with the Key Laboratory of Measurement and Control of Complex Systems of Engineering, Min-istry of Education, Nanjing, China. This work was supported in part by the National Natural Science Foundation of China (No. 62076061), theNatural Science Foundation of Jiangsu Province (No. BK20220127). truth on two crowd datasets, which may also promote fu-ture research on pose estimation and human behavior un-derstanding in crowded scenes. The experimental results show that our approach outperforms other baseline meth-ods both in crowded and common scenarios. The code and datasets are publicly available at https://github. com/boycehbz/GroupRec. 