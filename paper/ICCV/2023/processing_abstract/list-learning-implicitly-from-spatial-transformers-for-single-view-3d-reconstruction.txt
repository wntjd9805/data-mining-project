Accurate reconstruction of both the geometric and topo-logical details of a 3D object from a single 2D image em-bodies a fundamental challenge in computer vision. Exist-ing explicit/implicit solutions to this problem struggle to re-cover self-occluded geometry and/or faithfully reconstruct topological shape structures. To resolve this dilemma, we introduce LIST, a novel neural architecture that leverages local and global image features to accurately reconstruct the geometric and topological structure of a 3D object from a single image. We utilize global 2D features to predict a coarse shape of the target object and then use it as a base for higher-resolution reconstruction. By leveraging both local 2D features from the image and 3D features from the coarse prediction, we can predict the signed distance between an arbitrary point and the target surface via an implicit predictor with great accuracy. Furthermore, our model does not require camera estimation or pixel align-ment. It provides an uninfluenced reconstruction from the input-view direction. Through qualitative and quantitative analysis, we show the superiority of our model in recon-structing 3D objects from both synthetic and real-world im-ages against the state of the art. Our source code is publicly available to the research community [13]. 