Recent work on deep reinforcement learning (DRL) has pointed out that algorithmic information about good poli-cies can be extracted from offline data which lack explicit information about executed actions [45, 46, 30]. For exam-ple, videos of humans or robots may convey a lot of im-plicit information about rewarding action sequences, but a DRL machine that wants to profit from watching such videos must first learn by itself to identify and recognize relevant states/actions/rewards. Without relying on ground-truth annotations, our new method called Deep State Iden-tifier learns to predict returns from episodes encoded as videos. Then it uses a kind of mask-based sensitivity analy-sis to extract/identify important critical states. Extensive ex-periments showcase our methodâ€™s potential for understand-ing and improving agent behavior. The source code and the generated datasets are available at https://github.com/AI-Initiative-KAUST/VideoRLCS. 