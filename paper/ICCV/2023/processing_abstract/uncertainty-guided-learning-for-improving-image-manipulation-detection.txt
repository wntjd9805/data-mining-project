Image manipulation detection (IMD) is of vital impor-tance as faking images and spreading misinformation canIMD is the core be malicious and harm our daily life. technique to solve these issues and poses challenges in two main aspects: (1) Data Uncertainty, i.e., the manip-ulated artifacts are often hard for humans to discern and lead to noisy labels, which may disturb model training; (2)Model Uncertainty, i.e., the same object may hold differ-ent categories (tampered or not) due to manipulation oper-ations, which could potentially confuse the model training and result in unreliable outcomes. Previous works mainly focus on solving the model uncertainty issue by designing meticulous features and networks, however, the data uncer-tainty problem is rarely considered. In this paper, we ad-dress both problems by introducing an uncertainty-guided learning framework, which measures data and model uncer-tainties by a novel Uncertainty Estimation Network (UEN).UEN is trained under dynamic supervision, and outputs es-timated uncertainty maps to refine manipulation detection results, which significantly alleviates the learning difficul-ties. To our knowledge, this is the first work to embed uncer-tainty modeling into IMD. Extensive experiments on various datasets demonstrate state-of-the-art performance, validat-ing the effectiveness and generalizability of our method. 