Semantic segmentation is a computer vision task that associates a label with each pixel in an image. Modern approaches tend to introduce class embeddings into se-mantic segmentation for deeply utilizing category seman-tics, and regard supervised class masks as final predictions.In this paper, we explore the mechanism of class embed-dings and have an insight that more explicit and mean-ingful class embeddings can be generated based on class masks purposely. Following this observation, we proposeECENet, a new segmentation paradigm, in which class em-beddings are obtained and enhanced explicitly during in-teracting with multi-stage image features. Based on this, we revisit the traditional decoding process and explore in-verted information flow between segmentation masks and class embeddings. Furthermore, to ensure the discrim-inability and informativity of features from backbone, we propose a Feature Reconstruction module, which combines intrinsic and diverse branches together to ensure the con-currence of diversity and redundancy in features. Ex-periments show that our ECENet outperforms its counter-parts on the ADE20K dataset with much less computational cost and achieves new state-of-the-art results on PASCAL-Context dataset. The code will be released at https://gitee.com/mindspore/models and https:// github.com/Carol-lyh/ECENet. 