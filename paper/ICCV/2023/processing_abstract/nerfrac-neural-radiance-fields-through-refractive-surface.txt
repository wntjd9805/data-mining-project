Neural Radiance Fields (NeRF) is a popular neural rep-resentation for novel view synthesis. By querying spatial points and view directions, a multilayer perceptron (MLP) can be trained to output the volume density and radiance along a ray, which lets us render novel views of the scene.The original NeRF and its recent variants, however, are limited to opaque scenes dominated with diffuse reflec-tion surfaces and cannot handle complex refractive sur-faces well. We introduce NeRFrac to realize neural novel view synthesis of scenes captured through refractive sur-faces, typically water surfaces. For each queried ray, anMLP-based Refractive Field is trained to estimate the dis-tance from the ray origin to the refractive surface. A re-fracted ray at each intersection point is then computed bySnellâ€™s Law, given the input ray and the approximated lo-cal normal. Points of the scene are sampled along the re-fracted ray and are sent to a Radiance Field for further ra-diance estimation. We show that from a sparse set of im-ages, our model achieves accurate novel view synthesis of the scene underneath the refractive surface and simultane-ously reconstructs the refractive surface. We evaluate the effectiveness of our method with synthetic and real scenes seen through water surfaces. Experimental results demon-strate the accuracy of NeRFrac for modeling scenes seen through wavy refractive surfaces. Github page: https://github.com/Yifever20002/NeRFrac. 