Deepfake detection remains a challenging task due to the difficulty of generalizing to new types of forgeries. This problem primarily stems from the overfitting of existing de-tection methods to forgery-irrelevant features and method-specific patterns. The latter has been rarely studied and not well addressed by previous works. This paper presents a novel approach to address the two types of overfitting issues by uncovering common forgery features. Specifically, we first propose a disentanglement framework that decomposes image information into three distinct components: forgery-irrelevant, method-specific forgery, and common forgery features. To ensure the decoupling of method-specific and common forgery features, a multi-task learning strategy is employed, including a multi-class classification that pre-dicts the category of the forgery method and a binary clas-sification that distinguishes the real from the fake. Addi-tionally, a conditional decoder is designed to utilize forgery features as a condition along with forgery-irrelevant fea-tures to generate reconstructed images. Furthermore, a contrastive regularization technique is proposed to encour-age the disentanglement of the common and specific forgery features. Ultimately, we only utilize the common forgery features for the purpose of generalizable deepfake detec-tion. Extensive evaluations demonstrate that our framework can perform superior generalization than current state-of-the-art methods. 