Contrastive learning based vision-language joint pre-training has emerged as a successful representation learn-ing strategy. In this paper, we present a prototype represen-tation learning framework incorporating both global andIn local alignment between medical images and reports. contrast to standard global multi-modality alignment meth-ods, we employ a local alignment module for fine-grained representation. Furthermore, a cross-modality conditional reconstruction module is designed to interchange informa-tion across modalities in the training phase by reconstruct-ing masked images and reports. For reconstructing long reports, a sentence-wise prototype memory bank is con-structed, enabling the network to focus on low-level local-ized visual and high-level clinical linguistic features. Ad-ditionally, a non-auto-regressive generation paradigm is proposed for reconstructing non-sequential reports. Ex-perimental results on five downstream tasks, including su-pervised classification, zero-shot classification, image-to-text retrieval, semantic segmentation, and object detection, show the proposed method outperforms other state-of-the-art methods across multiple datasets and under different dataset size settings. The code is available at https://github.com/QtacierP/PRIOR. 