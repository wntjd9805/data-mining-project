In this paper, we realize automatic visual recognition and direction estimation of pointing. We introduce the ﬁrst neural pointing understanding method based on two key contributions. The ﬁrst is the introduction of a ﬁrst-of-its-kind large-scale dataset for pointing recognition and di-rection estimation, which we refer to as the DP Dataset.DP Dataset consists of more than 2 million frames of 33 people pointing in various styles annotated for each frame with pointing timings and 3D directions. The second isDeePoint, a novel deep network model for joint recogni-tion and 3D direction estimation of pointing. DeePoint is a Transformer-based network which fully leverages the spatio-temporal coordination of the body parts, not just the hands. Through extensive experiments, we demonstrate the accuracy and efﬁciency of DeePoint. We believe DP Dataset and DeePoint will serve as a sound foundation for visual human intention understanding. 