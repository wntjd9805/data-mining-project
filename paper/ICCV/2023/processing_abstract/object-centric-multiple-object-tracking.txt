Unsupervised object-centric learning methods allow the partitioning of scenes into entities without additional lo-calization information and are excellent candidates for re-ducing the annotation burden of multiple-object tracking (MOT) pipelines. Unfortunately, they lack two key prop-erties: objects are often split into parts and are not con-sistently tracked over time. In fact, state-of-the-art models achieve pixel-level accuracy and temporal consistency by relying on supervised object detection with additional ID labels for the association through time. This paper pro-poses a video object-centric model for MOT. It consists of an index-merge module that adapts the object-centric slots into detection outputs and an object memory mod-ule that builds complete object prototypes to handle occlu-sions. Benefited from object-centric learning, we only re-quire sparse detection labels (0%-6.25%) for object local-ization and feature binding. Relying on our self-supervisedExpectation-Maximization-inspired loss for object associ-ation, our approach requires no ID labels. Our exper-iments significantly narrow the gap between the existing object-centric model and the fully supervised state-of-the-art and outperform several unsupervised trackers. Code is available at https://github.com/amazon-science/object-centric-multiple-object-tracking. 