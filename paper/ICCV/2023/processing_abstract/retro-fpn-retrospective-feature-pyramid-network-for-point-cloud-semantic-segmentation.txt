Learning per-point semantic features from the hierar-chical feature pyramid is essential for point cloud seman-tic segmentation. However, most previous methods suf-fered from ambiguous region features or failed to reﬁne per-point features effectively, which leads to information loss and ambiguous semantic identiﬁcation. To resolve this, we propose Retro-FPN to model the per-point feature pre-diction as an explicit and retrospective reﬁning process, which goes through all the pyramid layers to extract se-mantic features explicitly for each point.Its key novelty is a retro-transformer for summarizing semantic contexts from the previous layer and accordingly reﬁning the fea-*Equal contribution.†Corresponding authors. This work was supported by National KeyR&D Program of China (2022YFC3800600), the National Natural Sci-ence Foundation of China (62272263, 62072268), and in part by Tsinghua-Kuaishou Institute of Future Media Data. tures in the current stage.In this way, the categoriza-tion of each point is conditioned on its local semantic pat-tern. Speciﬁcally, the retro-transformer consists of a local cross-attention block and a semantic gate unit. The cross-attention serves to summarize the semantic pattern retro-spectively from the previous layer. And the gate unit care-fully incorporates the summarized contexts and reﬁnes the current semantic features. Retro-FPN is a pluggable neural network that applies to hierarchical decoders. By integrat-ing Retro-FPN with three representative backbones, includ-ing both point-based and voxel-based methods, we show that Retro-FPN can signiﬁcantly improve performance over state-of-the-art backbones. Comprehensive experiments on widely used benchmarks can justify the effectiveness of our design. The source is available at https://github. com/AllenXiangX/Retro-FPN . 