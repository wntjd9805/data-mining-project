DETR-like models have significantly boosted the perfor-mance of detectors and even outperformed classical con-volutional models. However, all tokens are treated equally without discrimination brings a redundant computational burden in the traditional encoder structure. The recent spar-sification strategies exploit a subset of informative tokens to reduce attention complexity maintaining performance through the sparse encoder. But these methods tend to rely on unreliable model statistics. Moreover, simply reducing the token population hinders the detection performance to a large extent, limiting the application of these sparse mod-els. We propose Focus-DETR, which focuses attention on more informative tokens for a better trade-off between com-putation efficiency and model accuracy. Specifically, we re-construct the encoder with dual attention, which includes a token scoring mechanism that considers both localization and category semantic information of the objects from multi-scale feature maps. We efficiently abandon the background queries and enhance the semantic interaction of the fine-grained object queries based on the scores. Compared with the state-of-the-art sparse DETR-like detectors under the same setting, our Focus-DETR gets comparable complex-ity while achieving 50.4AP (+2.2) on COCO. The code is available at torch-version† and mindspore-version‡. 