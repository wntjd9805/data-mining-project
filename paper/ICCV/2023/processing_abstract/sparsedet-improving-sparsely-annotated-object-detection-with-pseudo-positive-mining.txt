Training with sparse annotations is known to reduce the performance of object detectors. Previous methods have focused on proxies for missing ground truth annotations in the form of pseudo-labels for unlabeled boxes. We ob-serve that existing methods suffer at higher levels of spar-sity in the data due to noisy pseudo-labels. To prevent this, we propose an end-to-end system that learns to sep-arate the proposals into labeled and unlabeled regions us-ing Pseudo-positive mining. While the labeled regions are processed as usual, self-supervised learning is used to pro-cess the unlabeled regions thereby preventing the negative effects of noisy pseudo-labels. This novel approach has multiple advantages such as improved robustness to higher sparsity when compared to existing methods. We con-duct exhaustive experiments on five splits on the PASCAL-VOC and COCO datasets achieving state-of-the-art perfor-mance. We also unify various splits used across literature for this task and present a standardized benchmark. On average, we improve by 2.6, 3.9 and 9.6 mAP over pre-vious state-of-the-art methods on three splits of increas-ing sparsity on COCO. Our project is publicly available at cs.umd.edu/~sakshams/SparseDet. 