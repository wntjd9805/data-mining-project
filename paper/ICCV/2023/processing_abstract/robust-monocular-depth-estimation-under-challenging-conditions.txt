While state-of-the-art monocular depth estimation ap-proaches achieve impressive results in ideal settings, they are highly unreliable under challenging illumination and weather conditions, such as at nighttime or in the presence of rain. In this paper, we uncover these safety-critical is-sues and tackle them with md4all: a simple and effective solution that works reliably under both adverse and ideal conditions, as well as for different types of learning super-vision. We achieve this by exploiting the efficacy of existing methods under perfect settings. Therefore, we provide valid training signals independently of what is in the input. First, we generate a set of complex samples corresponding to the normal training ones. Then, we train the model by guiding its self- or full-supervision by feeding the generated sam-ples and computing the standard losses on the correspond-ing original images. Doing so enables a single model to recover information across diverse conditions without mod-ifications at inference time. Extensive experiments on two challenging public datasets, namely nuScenes and OxfordRobotCar, demonstrate the effectiveness of our techniques, outperforming prior works by a large margin in both stan-dard and challenging conditions. Source code and data are available at: https://md4all.github.io. 