CNN’s limited receptive ﬁeld restricts its ability to capture long-range spatial-temporal dependencies, lead-ing to unsatisfactory performance in video super-resolution (VSR). To tackle this challenge, this paper presents a novel multi-frequency representation enhancement module (MFE) that performs spatial-temporal information aggre-gation in the frequency domain. Speciﬁcally, MFE mainly includes a spatial-frequency representation enhancement branch which captures the long-range dependency in the spatial dimension, and an energy frequency representation enhancement branch to obtain the inter-channel feature re-lationship. Moreover, a novel model training method named privilege training is proposed to encode the privilege infor-mation from high-resolution videos to facilitate model train-ing. With these two methods, we introduce a new VSR model named MFPI, which outperforms state-of-the-art methods by a large margin while maintaining good efﬁciency on var-ious datasets, including REDS4, Vimeo, Vid4, and UDM10. 