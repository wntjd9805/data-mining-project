The current interacting hand (IH) datasets are relatively simplistic in terms of background and texture, with hand joints being annotated by a machine annotator, which may result in inaccuracies, and the diversity of pose distribution is limited. However, the variability of background, pose distribution, and texture can greatly influence the gener-alization ability. Therefore, we present a large-scale syn-thetic dataset –RenderIH– for interacting hands with accu-rate and diverse pose annotations. The dataset contains 1M photo-realistic images with varied backgrounds, per-spectives, and hand textures. To generate natural and di-verse interacting poses, we propose a new pose optimiza-tion algorithm. Additionally, for better pose estimation accuracy, we introduce a transformer-based pose estima-tion network, TransHand, to leverage the correlation be-tween interacting hands and verify the effectiveness of Ren-derIH in improving results. Our dataset is model-agnostic and can improve more accuracy of any hand pose esti-mation method in comparison to other real or synthetic datasets. Experiments have shown that pretraining on our synthetic data can significantly decrease the error from 6.76mm to 5.79mm, and our Transhand surpasses contem-porary methods. Our dataset and code are available at https://github.com/adwardlee/RenderIH. 