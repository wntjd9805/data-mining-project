Explaining the predictions of deep neural nets has been a topic of great interest in the computer vision literature.While several gradient-based interpretation schemes have been proposed to reveal the inﬂuential variables in a neu-ral net’s prediction, standard gradient-based interpretation frameworks have been commonly observed to lack robust-ness to input perturbations and ﬂexibility for incorporating prior knowledge of sparsity and group-sparsity structures.In this work, we propose MoreauGrad as an interpretation scheme based on the classiﬁer neural net’s Moreau enve-lope. We demonstrate that MoreauGrad results in a smooth and robust interpretation of a multi-layer neural network and can be efﬁciently computed through ﬁrst-order opti-mization methods. Furthermore, we show that Moreau-Grad can be naturally combined with L1-norm regulariza-tion techniques to output a sparse or group-sparse explana-tion which are prior conditions applicable to a wide range of deep learning applications. We empirically evaluate the proposed MoreauGrad scheme on standard computer vision datasets, showing the qualitative and quantitative success of the MoreauGrad approach in comparison to standard gradient-based interpretation methods 1. 