We present DINAR, an approach for creating realistic rigged fullbody avatars from single RGB images. Simi-larly to previous works, our method uses neural textures combined with the SMPL-X body model to achieve photo-realistic quality of avatars while keeping them easy to an-imate and fast to infer. To restore the texture, we use a latent diffusion model and show how such model can be trained in the neural texture space. The use of the diffu-sion model allows us to realistically reconstruct large un-seen regions such as the back of a person given the frontal view. The models in our pipeline are trained using 2D im-ages and videos only.In the experiments, our approach achieves state-of-the-art rendering quality and good gen-eralization to new poses and viewpoints. In particular, the approach improves state-of-the-art on the SnapshotPeople public benchmark. 