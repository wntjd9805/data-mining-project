Federated Learning (FL) has recently emerged as a promising distributed machine learning framework to pre-serve clients’ privacy, by allowing multiple clients to up-load the gradients calculated from their local data to a cen-tral server. Recent studies ﬁnd that the exchanged gradi-ents also take the risk of privacy leakage, e.g., an attacker can invert the shared gradients and recover sensitive data against an FL system by leveraging pre-trained generative adversarial networks (GAN) as prior knowledge. However, performing gradient inversion attacks in the latent space of the GAN model limits their expression ability and general-izability. To tackle these challenges, we propose GradientInversion over Feature Domains (GIFD), which disassem-bles the GAN model and searches the feature domains of the intermediate layers.Instead of optimizing only over the initial latent code, we progressively change the opti-mized layer, from the initial latent space to intermediate layers closer to the output images. In addition, we design a regularizer to avoid unreal image generation by adding a small l1 ball constraint to the searching range. We also ex-tend GIFD to the out-of-distribution (OOD) setting, which weakens the assumption that the training sets of GANs andFL tasks obey the same data distribution. Extensive experi-ments demonstrate that our method can achieve pixel-level reconstruction and is superior to the existing methods. No-tably, GIFD also shows great generalizability under differ-ent defense strategy settings and batch sizes. 