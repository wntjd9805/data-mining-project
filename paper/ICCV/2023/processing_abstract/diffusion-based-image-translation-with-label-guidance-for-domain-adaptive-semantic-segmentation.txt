Existing MethodsOursSemantic ConsistencyTranslating images from a source domain to a target do-main for learning target models is one of the most com-mon strategies in domain adaptive semantic segmentation (DASS). However, existing methods still struggle to preserve semantically-consistent local details between the original and translated images. In this work, we present an innova-tive approach that addresses this challenge by using source-domain labels as explicit guidance during image transla-tion. Concretely, we formulate cross-domain image transla-tion as a denoising diffusion process and utilize a novel Se-mantic Gradient Guidance (SGG) method to constrain the translation process, conditioning it on the pixel-wise source labels. Additionally, a Progressive Translation Learning (PTL) strategy is devised to enable the SGG method to work reliably across domains with large gaps. Extensive exper-iments demonstrate the superiority of our approach over state-of-the-art methods. 