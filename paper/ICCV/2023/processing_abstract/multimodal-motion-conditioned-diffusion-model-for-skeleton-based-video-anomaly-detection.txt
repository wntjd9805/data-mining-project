Anomalies are rare and anomaly detection is often there-fore framed as One-Class Classification (OCC), i.e. trained solely on normalcy. Leading OCC techniques constrain the latent representations of normal1 motions to limited vol-umes and detect as abnormal anything outside, which ac-counts satisfactorily for the openset’ness of anomalies. But normalcy shares the same openset’ness property since hu-mans can perform the same action in several ways, which the leading techniques neglect.We propose a novel generative model for video anomaly detection (VAD), which assumes that both normality and abnormality are multimodal. We consider skeletal represen-tations and leverage state-of-the-art diffusion probabilistic models to generate multimodal future human poses. We contribute a novel conditioning on the past motion of people and exploit the improved mode coverage capabilities of dif-fusion processes to generate different-but-plausible future motions. Upon the statistical aggregation of future modes, an anomaly is detected when the generated set of motions is not pertinent to the actual future. We validate our model on 4 established benchmarks: UBnormal, HR-UBnormal,HR-STC, and HR-Avenue, with extensive experiments sur-passing state-of-the-art results. 