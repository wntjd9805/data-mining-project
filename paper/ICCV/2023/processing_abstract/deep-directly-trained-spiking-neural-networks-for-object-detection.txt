Spiking neural networks (SNNs) are brain-inspired energy-efficient models that encode information in spa-tiotemporal dynamics. Recently, deep SNNs trained directly have shown great success in achieving high performance on classification tasks with very few time steps. However, how to design a directly-trained SNN for the regression task of object detection still remains a challenging prob-lem. To address this problem, we propose EMS-YOLO, a novel directly-trained SNN framework for object detec-tion, which is the first trial to train a deep SNN with sur-rogate gradients for object detection rather than ANN-SNN conversion strategies. Specifically, we design a full-spike residual block, EMS-ResNet, which can effectively extend the depth of the directly-trained SNN with low power con-sumption. Furthermore, we theoretically analyze and prove the EMS-ResNet could avoid gradient vanishing or explod-ing. The results demonstrate that our approach outper-forms the state-of-the-art ANN-SNN conversion methods (at least 500 time steps) in extremely fewer time steps (only 4 time steps). It is shown that our model could achieve com-parable performance to the ANN with the same architec-ture while consuming 5.83Ã— less energy on the frame-basedCOCO Dataset and the event-based Gen1 Dataset. Our code is available in https://github.com/BICLab/EMS-YOLO. 