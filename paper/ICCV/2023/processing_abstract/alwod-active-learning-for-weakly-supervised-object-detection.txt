Object detection (OD), a crucial vision task, remains challenged by the lack of large training datasets with pre-cise object localization labels.In this work, we pro-pose ALWOD, a new framework that addresses this prob-lem by fusing active learning (AL) with weakly and semi-supervised object detection paradigms. Because the per-formance of AL critically depends on the model initializa-tion, we propose a new auxiliary image generator strat-egy that utilizes an extremely small labeled set, coupled with a large weakly tagged set of images, as a warm-start for AL. We then propose a new AL acquisition function, another critical factor in AL success, that leverages the student-teacher OD pair disagreement and uncertainty to effectively propose the most informative images to anno-tate. Finally, to complete the AL loop, we introduce a new labeling task delegated to human annotators, based on se-lection and correction of model-proposed detections, which is both rapid and effective in labeling the informative im-ages. We demonstrate, across several challenging bench-marks, that ALWOD significantly narrows the gap between the ODs trained on few partially labeled but strategically selected image instances and those that rely on the fully-labeled data. Our code is publicly available on https://github.com/seqam-lab/ALWOD. 