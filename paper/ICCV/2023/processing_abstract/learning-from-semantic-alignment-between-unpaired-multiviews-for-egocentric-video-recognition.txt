We are concerned with a challenging scenario in un-In this case, the model paired multiview video learning. aims to learn comprehensive multiview representations while the cross-view semantic information exhibits varia-tions. We propose Semantics-based Unpaired MultiviewLearning (SUM-L) to tackle this unpaired multiview learn-ing problem. The key idea is to build cross-view pseudo-pairs and do view-invariant alignment by leveraging the semantic information of videos. To facilitate the data effi-ciency of multiview learning, we further perform video-text alignment for first-person and third-person videos, to fully leverage the semantic knowledge to improve video repre-sentations. Extensive experiments on multiple benchmark datasets verify the effectiveness of our framework. Our method also outperforms multiple existing view-alignment methods, under the more challenging scenario than typ-ical paired or unpaired multimodal or multiview learn-ing. Our code is available at https://github.com/ wqtwjt1996/SUM-L. 