Source-free domain adaptive semantic segmentation has gained increasing attention recently. It eases the require-ment of full access to the source domain by transferring knowledge only from a well-trained source model. How-ever, reducing the uncertainty of the target pseudo labels becomes inevitably more challenging without the supervi-sion of the labeled source data. In this work, we propose a novel asymmetric two-stream architecture that learns more robustly from noisy pseudo labels. Our approach simul-taneously conducts dual-head pseudo label denoising and cross-modal consistency regularization. Towards the for-mer, we introduce a multimodal auxiliary network during training (and discard it during inference), which effectively enhances the pseudo labels’ correctness by leveraging the guidance from the depth information. Towards the latter, we enforce a new cross-modal pixel-wise consistency be-tween the predictions of the two streams, encouraging our model to behave smoothly for both modality variance and image perturbations. It serves as an effective regularization to further reduce the impact of the inaccurate pseudo la-bels in source-free unsupervised domain adaptation. Exper-iments on GTA5 → Cityscapes and SYNTHIA → Cityscapes benchmarks demonstrate the superiority of our proposed method, obtaining the new state-of-the-art mIoU of 57.7% and 57.5%, respectively. 