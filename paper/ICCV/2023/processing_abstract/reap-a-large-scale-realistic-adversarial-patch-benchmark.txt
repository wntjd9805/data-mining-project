Machine learning models are known to be susceptible to adversarial perturbation. One famous attack is the adversar-ial patch, a particularly crafted sticker that makes the model mispredict the object it is placed on. This attack presents a critical threat to cyber-physical systems that rely on cam-eras such as autonomous cars. Despite the signiﬁcance of the problem, conducting research in this setting has been difﬁcult; evaluating attacks and defenses in the real world is exceptionally costly while synthetic data are unrealistic.In this work, we propose the REAP (REalistic AdversarialPatch) benchmark, a digital benchmark that enables the eval-uations on real images under real-world conditions. Built on top of the Mapillary Vistas dataset, our benchmark con-tains over 14,000 trafﬁc signs. Each sign is augmented with geometric and lighting transformations for applying a digi-tally generated patch realistically onto the sign. Using our benchmark, we perform the ﬁrst large-scale assessments of adversarial patch attacks under realistic conditions. Our experiments suggest that patch attacks may present a smaller threat than previously believed and that the success rate of an attack on simpler digital simulations is not predictive of its actual effectiveness in practice. Our benchmark is released publicly at https://github.com/wagner-group/ reap-benchmark. 