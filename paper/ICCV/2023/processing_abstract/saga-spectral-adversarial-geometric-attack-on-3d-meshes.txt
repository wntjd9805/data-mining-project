AttaAttack ackA triangular mesh is one of the most popular 3D data representations. As such, the deployment of deep neural networks for mesh processing is widely spread and is in-creasingly attracting more attention. However, neural net-works are prone to adversarial attacks, where carefully crafted inputs impair the model’s functionality. The need to explore these vulnerabilities is a fundamental factor in the future development of 3D-based applications. Recently, mesh attacks were studied on the semantic level, where clas-siﬁers are misled to produce wrong predictions. Neverthe-less, mesh surfaces possess complex geometric attributes beyond their semantic meaning, and their analysis often in-cludes the need to encode and reconstruct the geometry of the shape.We propose a novel framework for a geometric adversar-ial attack on a 3D mesh autoencoder. In this setting, an ad-versarial input mesh deceives the autoencoder by forcing it to reconstruct a different geometric shape at its output. The malicious input is produced by perturbing a clean shape in the spectral domain. Our method leverages the spectral de-composition of the mesh along with additional mesh-related properties to obtain visually credible results that consider the delicacy of surface distortions1. 