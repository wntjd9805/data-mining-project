Model binarization can significantly compress model size, reduce energy consumption, and accelerate inference through efficient bit-wise operations. Although binarizing convolutional neural networks have been extensively stud-ied, there is little work on exploring binarization of visionTransformers which underpin most recent breakthroughs in visual recognition. To this end, we propose to solve two fun-damental challenges to push the horizon of Binary VisionTransformers (BiViT). First, the traditional binary method does not take the long-tailed distribution of softmax atten-tion into consideration, bringing large binarization errors in the attention module. To solve this, we propose Softmax-aware Binarization, which dynamically adapts to the data distribution and reduces the error caused by binarization.Second, to better preserve the information of the pretrained model and restore accuracy, we propose a Cross-layer Bi-narization scheme that decouples the binarization of self-attention and multi-layer perceptrons (MLPs), and Param-eterized Weight Scales which introduce learnable scaling factors for weight binarization. Overall, our method per-forms favorably against state-of-the-arts by 19.8% on theTinyImageNet dataset. On ImageNet, our BiViT achieves a competitive 75.6% Top-1 accuracy over Swin-S model. Ad-ditionally, on COCO object detection, our method achieves an mAP of 40.8 with a Swin-T backbone over Cascade MaskR-CNN framework. 