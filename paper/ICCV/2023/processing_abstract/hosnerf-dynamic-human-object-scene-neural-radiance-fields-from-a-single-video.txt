We introduce HOSNeRF, a novel 360° free-viewpoint rendering method that reconstructs neural radiance fields for dynamic human-object-scene from a single monocular in-the-wild video. Our method enables pausing the video at any frame and rendering all scene details (dynamic hu-mans, objects, and backgrounds) from arbitrary viewpoints.The first challenge in this task is the complex object mo-tions in human-object interactions, which we tackle by in-troducing the new object bones into the conventional human skeleton hierarchy to effectively estimate large object defor-mations in our dynamic human-object model. The second challenge is that humans interact with different objects at different times, for which we introduce two new learnable object state embeddings that can be used as conditions for learning our human-object representation and scene rep-resentation, respectively. Extensive experiments show thatHOSNeRF significantly outperforms SOTA approaches on two challenging datasets by a large margin of 40% ∼ 50% in terms of LPIPS. The code, data, and compelling exam-ples of 360° free-viewpoint renderings from single videos: https://showlab.github.io/HOSNeRF. 