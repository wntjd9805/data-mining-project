Face Anti-Spoofing (FAS) is recently studied under the continual learning setting, where the FAS models are ex-pected to evolve after encountering data from new domains.However, existing methods need extra replay buffers to store previous data for rehearsal, which becomes infeasible when previous data is unavailable because of privacy issues. In this paper, we propose the first rehearsal-free method forDomain Continual Learning (DCL) of FAS, which deals with catastrophic forgetting and unseen domain general-ization problems simultaneously. For better generaliza-tion to unseen domains, we design the Dynamic CentralDifference Convolutional Adapter (DCDCA) to adapt Vi-sion Transformer (ViT) models during the continual learn-ing sessions. To alleviate the forgetting of previous do-mains without using previous data, we propose the ProxyPrototype Contrastive Regularization (PPCR) to constrain the continual learning with previous domain knowledge from the proxy prototypes. Simulating practical DCL sce-narios, we devise two new protocols which evaluate both generalization and anti-forgetting performance. Exten-sive experimental results show that our proposed method can improve the generalization performance in unseen do-mains and alleviate the catastrophic forgetting of previous knowledge. The code and protocol files are released on https://github.com/RizhaoCai/DCL-FAS-ICCV2023. 