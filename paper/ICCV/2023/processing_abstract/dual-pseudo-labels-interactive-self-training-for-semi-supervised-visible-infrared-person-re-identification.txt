Visible-infrared person re-identification (VI-ReID) aims to match a specific person from a gallery of images cap-tured from non-overlapping visible and infrared cameras.Most works focus on fully supervised VI-ReID, which re-quires substantial cross-modality annotation that is more expensive than the annotation in single-modality. To re-duce the extensive cost of annotation, we explore two practi-cal semi-supervised settings: uni-semi-supervised (annotat-ing only visible images) and bi-semi-supervised (annotating partially in both modalities). These two semi-supervised settings face two challenges due to the large cross-modality discrepancies and the lack of correspondence supervision it is diffi-between visible and infrared images. Thus, cult to generate reliable pseudo-labels and learn modality-invariant features from noise pseudo-labels. In this paper, we propose a dual pseudo-label interactive self-training (DPIS) for these two semi-supervised VI-ReID. Our DPIS integrates two pseudo-labels generated by distinct models into a hybrid pseudo-label for unlabeled data. However, the hybrid pseudo-label still inevitably contains noise. To eliminate the negative effect of noise pseudo-labels, we in-troduce three modules: noise label penalty (NLP), noise correspondence calibration (NCC), and unreliable anchor learning (UAL). Specifically, NLP penalizes noise labels,NCC calibrates noisy correspondences, and UAL mines the hard-to-discriminate features. Extensive experimen-tal results on SYSU-MM01 and RegDB demonstrate that our DPIS achieves impressive performance under these two semi-supervised settings.*Equal contribution.â€ Corresponding author.Figure 1. The figure illustrates the differences between fully super-vised, uni-semi-supervised, and bi-semi-supervised learning set-tings, which mainly lie in the availability of labeled data. 