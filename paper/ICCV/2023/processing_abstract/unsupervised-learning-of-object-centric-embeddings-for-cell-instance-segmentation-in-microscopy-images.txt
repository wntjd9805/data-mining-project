Segmentation of objects in microscopy images is re-quired for many biomedical applications. We intro-duce object-centric embeddings (OCEs), which embed im-age patches such that the spatial offsets between patches cropped from the same object are preserved. Those learnt embeddings can be used to delineate individual objects and thus obtain instance segmentations. Here, we show theoretically that, under assumptions commonly found in microscopy images, OCEs can be learnt through a self-supervised task that predicts the spatial offset between im-age patches. Together, this forms an unsupervised cell in-stance segmentation method which we evaluate on nine di-verse large-scale microscopy datasets. Segmentations ob-tained with our method lead to substantially improved re-sults, compared to state-of-the-art baselines on six out of nine datasets, and perform on par on the remaining three datasets.If ground-truth annotations are available, our method serves as an excellent starting point for super-vised training, reducing the required amount of ground-thus substan-truth needed by one order of magnitude, tially increasing the practical applicability of our method.Source code is available at github.com/funkelab/ cellulus. 