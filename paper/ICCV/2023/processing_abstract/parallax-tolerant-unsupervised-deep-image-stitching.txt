Traditional image stitching approaches tend to lever-age increasingly complex geometric features (e.g., point, line, edge, etc.) for better performance. However, these hand-crafted features are only suitable for speciﬁc natu-In con-ral scenes with adequate geometric structures. trast, deep stitching schemes overcome adverse conditions by adaptively learning robust semantic features, but they cannot handle large-parallax cases.To solve these issues, we propose a parallax-tolerant un-supervised deep image stitching technique. First, we pro-pose a robust and ﬂexible warp to model the image regis-tration from global homography to local thin-plate spline motion. It provides accurate alignment for overlapping re-gions and shape preservation for non-overlapping regions by joint optimization concerning alignment and distortion.*Corresponding author.Subsequently, to improve the generalization capability, we design a simple but effective iterative strategy to enhance the warp adaption in cross-dataset and cross-resolution ap-plications. Finally, to further eliminate the parallax arti-facts, we propose to composite the stitched image seam-lessly by unsupervised learning for seam-driven composi-tion masks. Compared with existing methods, our solution is parallax-tolerant and free from laborious designs of com-plicated geometric features for speciﬁc scenes. Extensive experiments show our superiority over the SoTA methods, both quantitatively and qualitatively. The code is available at https://github.com/nie-lang/UDIS2. 