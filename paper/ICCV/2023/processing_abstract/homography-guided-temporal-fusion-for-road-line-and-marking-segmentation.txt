Reliable segmentation of road lines and markings is crit-ical to autonomous driving. Our work is motivated by the observations that road lines and markings are (1) frequently occluded in the presence of moving vehicles, shadow, and glare and (2) highly structured with low intra-class shape variance and overall high appearance consistency. To solve these issues, we propose a Homography Guided Fusion (HomoFusion) module to exploit temporally-adjacent video frames for complementary cues facilitating the correct clas-sification of the partially occluded road lines or markings.To reduce computational complexity, a novel surface nor-mal estimator is proposed to establish spatial correspon-dences between the sampled frames, allowing the Homo-Fusion module to perform a pixel-to-pixel attention mech-anism in updating the representation of the occluded road lines or markings. Experiments on ApolloScape, a large-scale lane mark segmentation dataset, and ApolloScapeNight with artificial simulated night-time road conditions, demonstrate that our method outperforms other existingSOTA lane mark segmentation models with less than 9% of their parameters and computational complexity. We show that exploiting available camera intrinsic data and ground plane assumption for cross-frame correspondence can lead to a light-weight network with significantly improved per-formances in speed and accuracy. We also prove the ver-satility of our HomoFusion approach by applying it to the problem of water puddle segmentation and achieving SOTA performance 1. 