Referring Expression Segmentation (RES) is a widely ex-plored multi-modal task, which endeavors to segment the pre-existing object within a single image with a given lin-guistic expression. However, in broader real-world scenar-ios, it is not always possible to determine if the described object exists in a specific image. Generally, a collection of images is available, some of which potentially contain the target objects. To this end, we propose a more realistic setting, named Group-wise Referring Expression Segmen-tation (GRES), which expands RES to a group of related images, allowing the described objects to exist in a subset of the input image group. To support this new setting, we introduce an elaborately compiled dataset named GroupedReferring Dataset (GRD), containing complete group-wise annotations of the target objects described by given expres-sions. Moreover, we also present a baseline method namedGrouped Referring Segmenter (GRSer), which explicitly captures the language-vision and intra-group vision-vision interactions to achieve state-of-the-art results on the pro-posed GRES setting and related tasks, such as Co-SalientObject Detection and traditional RES. Our dataset and codes are publicly released in https://github.com/shikras/d-cube. 