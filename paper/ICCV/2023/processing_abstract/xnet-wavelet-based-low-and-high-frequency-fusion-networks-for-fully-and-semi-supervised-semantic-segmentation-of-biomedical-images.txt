Fully- and semi-supervised semantic segmentation of biomedical images have been advanced with the devel-opment of deep neural networks (DNNs). So far, how-ever, DNN models are usually designed to support one of these two learning schemes, unified models that support both fully- and semi-supervised segmentation remain lim-ited. Furthermore, few fully-supervised models focus on the intrinsic low frequency (LF) and high frequency (HF) information of images to improve performance. Pertur-bations in consistency-based semi-supervised models are often artificially designed. They may introduce negativeIn this learning bias that are not beneficial for training. study, we propose a wavelet-based LF and HF fusion modelXNet, which supports both fully- and semi-supervised se-mantic segmentation and outperforms state-of-the-art mod-els in both fields. It emphasizes extracting LF and HF in-formation for consistency training to alleviate the learning bias caused by artificial perturbations. Extensive experi-ments on two 2D and two 3D datasets demonstrate the ef-fectiveness of our model. Code is available at https://github.com/Yanfeng-Zhou/XNet. 