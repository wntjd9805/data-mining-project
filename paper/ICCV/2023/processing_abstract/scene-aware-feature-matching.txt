Current feature matching methods focus on point-level matching, pursuing better representation learning of indi-vidual features, but lacking further understanding of the scene. This results in signiﬁcant performance degradation when handling challenging scenes such as scenes with large viewpoint and illumination changes. To tackle this prob-lem, we propose a novel model named SAM, which applies attentional grouping to guide Scene-Aware feature Match-ing. SAM handles multi-level features, i.e., image tokens and group tokens, with attention layers, and groups the im-age tokens with the proposed token grouping module. Our model can be trained by ground-truth matches only and pro-duce reasonable grouping results. With the sense-aware grouping guidance, SAM is not only more accurate and ro-bust but also more interpretable than conventional feature matching models. Sufﬁcient experiments on various appli-cations, including homography estimation, pose estimation, and image matching, demonstrate that our model achieves state-of-the-art performance. 