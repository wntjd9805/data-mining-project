The great advancements of generative adversarial net-works and face recognition models in computer vision have made it possible to swap identities on images from sin-gle sources. Although a lot of studies seems to have proposed almost satisfactory solutions, we notice previ-ous methods still suffer from an identity-attribute entan-glement that causes undesired attributes swapping because widely used identity encoders, e.g., ArcFace, have some crucial attribute biases owing to their pretraining on face recognition tasks. To address this issue, we design Blend-Face, a novel identity encoder for face-swapping. The key idea behind BlendFace is training face recognition models on blended images whose attributes are replaced with those of another mitigates inter-personal biases such as hairsyles. BlendFace feeds disentangled identity fea-tures into generators and guides generators properly as an identity loss function. Extensive experiments demonstrate that BlendFace improves the identity-attribute disentangle-ment in face-swapping models, maintaining a comparable quantitative performance to previous methods. The code and models are available at https://github.com/ mapooon/BlendFace. 