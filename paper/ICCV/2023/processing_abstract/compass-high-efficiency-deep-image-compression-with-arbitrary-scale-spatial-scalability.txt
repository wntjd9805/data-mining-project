Recently, neural network (NN)-based image compres-sion studies have actively been made and has shown im-pressive performance in comparison to traditional methods.However, most of the works have focused on non-scalable image compression (single-layer coding) while spatially scalable image compression has drawn less attention al-though it has many applications. In this paper, we propose a novel NN-based spatially scalable image compression method, called COMPASS, which supports arbitrary-scale spatial scalability. Our proposed COMPASS has a very flex-ible structure where the number of layers and their respec-tive scale factors can be arbitrarily determined during in-*Corresponding author. ference. To reduce the spatial redundancy between adjacent layers for arbitrary scale factors, our COMPASS adopts an inter-layer arbitrary scale prediction method, called LIFF, based on implicit neural representation. We propose a com-bined RD loss function to effectively train multiple lay-ers. Experimental results show that our COMPASS achievesBD-rate gain of -58.33% and -47.17% at maximum com-pared to SHVC and the state-of-the-art NN-based spatially scalable image compression method, respectively, for var-ious combinations of scale factors. Our COMPASS also shows comparable or even better coding efficiency than the single-layer coding for various scale factors.