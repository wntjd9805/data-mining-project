Deep Neural Networks have exhibited considerable suc-cess in various visual tasks. However, when applied to un-seen test datasets, state-of-the-art models often suffer per-In this pa-formance degradation due to domain shifts. per, we introduce a novel approach for domain general-ization from a novel perspective of enhancing the robust-ness of channels in feature maps to domain shifts. We ob-serve that models trained on source domains contain a sub-stantial number of channels that exhibit unstable activa-tions across different domains, which are inclined to cap-ture domain-specific features and behave abnormally when exposed to unseen target domains. To address the issue, we propose a DomainDrop framework to continuously en-hance the channel robustness to domain shifts, where a domain discriminator is used to identify and drop unsta-ble channels in feature maps of each network layer dur-ing forward propagation. We theoretically prove that our framework could effectively lower the generalization bound.Extensive experiments on several benchmarks indicate that our framework achieves state-of-the-art performance com-pared to other competing methods. Our code is available at https://github.com/lingeringlight/DomainDrop. 