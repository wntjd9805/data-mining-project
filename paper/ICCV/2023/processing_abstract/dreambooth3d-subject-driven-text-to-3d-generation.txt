We present DreamBooth3D, an approach to personal-ize text-to-3D generative models from as few as 3-6 ca-sually captured images of a subject. Our approach com-bines recent advances in personalizing text-to-image mod-els (DreamBooth) with text-to-3D generation (DreamFu-sion). We ﬁnd that na¨ıvely combining these methods fails to yield satisfactory subject-speciﬁc 3D assets due to per-sonalized text-to-image models overﬁtting to the input view-points of the subject. We overcome this through a 3-stage optimization strategy where we jointly leverage the 3D con-sistency of neural radiance ﬁelds together with the person-alization capability of text-to-image models. Our method can produce high-quality, subject-speciﬁc 3D assets with text-driven modiﬁcations such as novel poses, colors and attributes that are not seen in any of the input images of the subject. More results are available at our project page: https://dreambooth3d.github.io 