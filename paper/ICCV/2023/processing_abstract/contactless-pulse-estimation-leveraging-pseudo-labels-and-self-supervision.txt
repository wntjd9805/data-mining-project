Remote photoplethysmography (rPPG) is a promising research area involving non-invasive monitoring of vital signs using cameras. While several supervised meth-ods have been proposed, recent research has focused on contrastive-based self-supervised methods. However, these methods often collapse to learning irrelevant periodicities when dealing with interferences such as head motions, fa-cial dynamics, and video compression. To address this limi-tation, firstly, we enhance the current self-supervised learn-ing by introducing more reliable and explicit contrastive constraints. Secondly, we propose an innovative learn-ing strategy that seamlessly integrates self-supervised con-straints with pseudo-supervisory signals derived from tra-ditional unsupervised methods. This is followed by a co-rectification technique designed to mitigate the adverse ef-fects of noisy pseudo-labels. Experimental results demon-strate the superiority of our methodology over representa-tive models when applied to small, high-quality datasets such as PURE and UBFC-rPPG. Importantly, on large-scale challenging datasets such as VIPL-HR and V4V, our method, with zero annotation cost, not only significantly surpasses prevailing self-supervised techniques but also showcases remarkable alignment with state-of-the-art su-pervised methods. 