3D reconstruction from a single 2D image was exten-sively covered in the literature but relies on depth supervi-sion at training time, which limits its applicability. To re-lax the dependence to depth we propose SceneRF, a self-supervised monocular scene reconstruction method using only posed image sequences for training. Fueled by the re-cent progress in neural radiance ﬁelds (NeRF) we optimize a radiance ﬁeld though with explicit depth optimization and a novel probabilistic sampling strategy to efﬁciently han-dle large scenes. At inference, a single input image suf-ﬁces to hallucinate novel depth views which are fused to-gether to obtain 3D scene reconstruction. Thorough ex-periments demonstrate that we outperform all baselines for novel depth views synthesis and scene reconstruction, on indoor BundleFusion and outdoor SemanticKITTI. Code is available at https://astra-vision.github.io/SceneRF . 