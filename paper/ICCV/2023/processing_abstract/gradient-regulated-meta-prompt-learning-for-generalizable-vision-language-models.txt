Prompt tuning, a recently emerging paradigm, enables the powerful vision-language pre-training models to adapt to downstream tasks in a parameter- and data- efficient way, by learning the “soft prompts” to condition frozen pre-training models. Though effective, it is particularly prob-lematic in the few-shot scenario, where prompt tuning per-formance is sensitive to the initialization and requires a time-consuming process to find a good initialization, thus restricting the fast adaptation ability of the pre-trainingIn addition, prompt tuning could undermine the models. generalizability of the pre-training models, because the learnable prompt tokens are easy to overfit to the limited training samples. To address these issues, we introduce a novel Gradient-RegulAted Meta-prompt learning (GRAM) framework that jointly meta-learns an efficient soft prompt initialization for better adaptation and a lightweight gra-dient regulating function for strong cross-domain general-izability in a meta-learning paradigm using only the unla-beled image-text pre-training data. Rather than designing a specific prompt tuning method, our GRAM can be eas-ily incorporated into various prompt tuning methods in a model-agnostic way, and comprehensive experiments show that GRAM brings about consistent improvement for them in several settings (i.e., few-shot learning, cross-domain generalization, cross-dataset generalization, etc.) over 11 datasets. Further, experiments show that GRAM enables the orthogonal methods of textual and visual prompt tuning to work in a mutually-enhanced way, offering better gener-alizability beyond the uni-modal prompt tuning methods.*Equal Contribution.†Work done when interning at Huawei Cloud.‡Corresponding Author.Figure 1: (a) Prompt tuning accuracy varies significantly with different initialization. (b) As the training continues,CoOp’s performance drops severely while our GRAM pre-vents CoOp from overfitting to spurious correlations. 