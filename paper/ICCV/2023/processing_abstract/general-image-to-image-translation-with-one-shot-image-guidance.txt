Large-scale text-to-image models pre-trained on mas-sive text-image pairs show excellent performance in image synthesis recently. However, image can provide more intu-itive visual concepts than plain text. People may ask: how can we integrate the desired visual concept into an existing image, such as our portrait? Current methods are inad-equate in meeting this demand as they lack the ability to preserve content or translate visual concepts effectively. In-spired by this, we propose a novel framework named visual concept translator (VCT) with the ability to preserve con-tent in the source image and translate the visual concepts guided by a single reference image. The proposed VCT contains a content-concept inversion (CCI) process to ex-*The first two authors contributed equally to this work. tract contents and concepts, and a content-concept fusion (CCF) process to gather the extracted information to ob-tain the target image. Given only one reference image, the proposed VCT can complete a wide range of general image-to-image translation tasks with excellent results. Extensive experiments are conducted to prove the superiority and ef-fectiveness of the proposed methods. Codes are available at https://github.com/CrystalNeuro/visual-concept-translator. 