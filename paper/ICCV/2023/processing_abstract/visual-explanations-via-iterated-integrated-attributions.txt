We introduce Iterated Integrated Attributions (IIA) - a generic method for explaining the predictions of vision mod-els. IIA employs iterative integration across the input im-age, the internal representations generated by the model, and their gradients, yielding precise and focused explana-tion maps. We demonstrate the effectiveness of IIA through comprehensive evaluations across various tasks, datasets, and network architectures. Our results showcase that IIA produces accurate explanation maps, outperforming other state-of-the-art explanation techniques. 