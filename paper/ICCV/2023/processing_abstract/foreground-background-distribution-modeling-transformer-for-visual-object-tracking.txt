Visual object tracking is a fundamental research topic with a broad range of applications. Benefiting from the rapid development of Transformer, pure Transformer track-ers have achieved great progress. However, the feature learning of these Transformer-based trackers is easily dis-turbed by complex backgrounds. To address the above lim-itations, we propose a novel foreground-background distri-bution modeling transformer for visual object tracking (F-BDMTrack), including a fore-background agent learning (FBAL) module and a distribution-aware attention (DA2) module in a unified transformer architecture. The proposedF-BDMTrack enjoys several merits. First, the proposedFBAL module can effectively mine fore-background infor-mation with designed fore-background agents. Second, theDA2 module can suppress the incorrect interaction between foreground and background by modeling fore-background distribution similarities. Finally, F-BDMTrack can extract discriminative features under ever-changing tracking sce-narios for more accurate target state estimation. Extensive experiments show that our F-BDMTrack outperforms previ-ous state-of-the-art trackers on eight tracking benchmarks. 