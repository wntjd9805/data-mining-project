Deep Neural Networks (DNNs)-based semantic segmen-tation models trained on a source domain often struggle to generalize to unseen target domains, i.e., a domain gap problem. Texture often contributes to the domain gap, mak-ing DNNs vulnerable to domain shift because they are prone to be texture-biased. Existing Domain Generalized Seman-tic Segmentation (DGSS) methods have alleviated the do-main gap problem by guiding models to prioritize shape over texture. On the other hand, shape and texture are two prominent and complementary cues in semantic segmenta-tion. This paper argues that leveraging texture is crucial for improving performance in DGSS. Speciﬁcally, we pro-pose a novel framework, coined Texture Learning DomainRandomization (TLDR). TLDR includes two novel losses to effectively enhance texture learning in DGSS: (1) a texture regularization loss to prevent overﬁtting to source domain textures by using texture features from an ImageNet pre-trained model and (2) a texture generalization loss that uti-lizes random style images to learn diverse texture represen-tations in a self-supervised manner. Extensive experimental results demonstrate the superiority of the proposed TLDR; e.g., TLDR achieves 46.5 mIoU on GTA→Cityscapes us-ing ResNet-50, which improves the prior state-of-the-art method by 1.9 mIoU. The source code is available at https://github.com/ssssshwan/TLDR. 