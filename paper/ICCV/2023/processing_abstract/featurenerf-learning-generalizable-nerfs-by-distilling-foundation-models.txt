Recent works on generalizable NeRFs have shown promising results on novel view synthesis from single or few images. However, such models have rarely been ap-plied on other downstream tasks beyond synthesis such as semantic understanding and parsing. In this paper, we pro-pose a novel framework named FeatureNeRF to learn gen-eralizable NeRFs by distilling pre-trained vision founda-tion models (e.g., DINO, Latent Diffusion). FeatureNeRF leverages 2D pre-trained foundation models to 3D space via neural rendering, and then extract deep features for 3D query points from NeRF MLPs. Consequently, it al-lows to map 2D images to continuous 3D semantic fea-ture volumes, which can be used for various downstream tasks. We evaluate FeatureNeRF on tasks of 2D/3D se-mantic keypoint transfer and 2D/3D object part segmenta-tion. Our extensive experiments demonstrate the effective-ness of FeatureNeRF as a generalizable 3D semantic fea-ture extractor. Our project page is available at https://jianglongye.com/featurenerf/. 