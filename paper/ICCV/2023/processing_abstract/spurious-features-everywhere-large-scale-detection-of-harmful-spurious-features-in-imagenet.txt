Spurious Features in Training Data bird feeder grafﬁti eucalyptus labelBenchmark performance of deep learning classiﬁers alone is not a reliable predictor for the performance of a deployed model. In particular, if the image classiﬁer has picked up spurious features in the training data, its predic-tions can fail in unexpected ways.In this paper, we de-velop a framework that allows us to systematically iden-tify spurious features in large datasets like ImageNet. It is based on our neural PCA components and their visualiza-tion. Previous work on spurious features often operates in toy settings or requires costly pixel-wise annotations.In contrast, we work with ImageNet and validate our results by showing that presence of the harmful spurious feature of a class alone is sufﬁcient to trigger the prediction of that class. We introduce the novel dataset “Spurious ImageNet” which allows to measure the reliance of any ImageNet clas-siﬁer on harmful spurious features. Moreover, we introduceSpuFix as a simple mitigation method to reduce the depen-dence of any ImageNet classiﬁer on previously identiﬁed harmful spurious features without requiring additional la-bels or retraining of the model. We provide code and data at https:// github.com/ YanNeu/ spurious imagenet. 