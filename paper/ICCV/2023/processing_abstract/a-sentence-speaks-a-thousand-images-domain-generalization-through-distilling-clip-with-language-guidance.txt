Domain generalization studies the problem of training a model with samples from several domains (or distribu-tions) and then testing the model with samples from a new, unseen domain. In this paper, we propose a novel approach for domain generalization that leverages recent advances in large vision-language models, specifically a CLIP teacher model, to train a smaller model that generalizes to unseen domains. The key technical contribution is a new type of regularization that requires the student’s learned image rep-resentations to be close to the teacher’s learned text repre-sentations obtained from encoding the corresponding text descriptions of images. We introduce two designs of the loss function, absolute and relative distance, which provide spe-cific guidance on how the training process of the student model should be regularized. We evaluate our proposed method, dubbed RISE (Regularized Invariance with Seman-tic Embeddings), on various benchmark datasets, and show that it outperforms several state-of-the-art domain gener-alization methods. To our knowledge, our work is the first to leverage knowledge distillation using a large vision-language model for domain generalization. By incorporat-ing text-based information, RISE improves the generaliza-tion capability of machine learning models. 