Real-time rendering for video games has become in-creasingly challenging due to the need for higher resolu-tions, framerates and photorealism. Supersampling has emerged as an effective solution to address this challenge.Our work introduces a novel neural algorithm for super-sampling rendered content that is 4Ã— more efficient than existing methods while maintaining the same level of accu-racy. Additionally, we introduce a new dataset which pro-vides auxiliary modalities such as motion vectors and depth generated using graphics rendering features like viewport jittering and mipmap biasing at different resolutions. We believe that this dataset fills a gap in the current dataset landscape and can serve as a valuable resource to help measure progress in the field and advance the state-of-the-art in super-resolution techniques for gaming content. 