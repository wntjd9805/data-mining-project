Learning multiple pretext tasks is a popular approach to tackle the nonalignment problem in unsupervised video anomaly detection. However, the conventional learning method of simultaneously learning multiple pretext tasks, is prone to sub-optimal solutions, incurring sharp perfor-mance drops. In this paper, we propose to sequentially learn multiple pretext tasks according to their difficulties in an as-cending manner to improve the performance of anomaly de-tection. The core idea is to relax the learning objective by starting with easy pretext tasks in the early stage and grad-ually refine it by involving more challenging pretext tasks later on. In this way, our method is able to reduce the diffi-culties of learning and avoid converging to sub-optimal so-lutions. Specifically, we design a tailored sequential learn-ing order for three widely-used pretext tasks. It starts with frame prediction task, then moves on to frame reconstruc-tion task and last ends with frame-order classification task.We further introduce a new contrastive loss which makes the learned representations of normality more discriminative by pushing normal and pseudo-abnormal samples apart. Ex-tensive experiments on three datasets demonstrate the effec-tiveness of our method. 