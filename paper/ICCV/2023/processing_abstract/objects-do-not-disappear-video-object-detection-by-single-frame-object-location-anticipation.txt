Objects in videos are typically characterized by contin-uous smooth motion. We exploit continuous smooth motion in three ways. 1) Improved accuracy by using object motion as an additional source of supervision, which we obtain by anticipating object locations from a static keyframe. 2) Im-proved efficiency by only doing the expensive feature com-putations on a small subset of all frames. Because neigh-boring video frames are often redundant, we only com-pute features for a single static keyframe and predict ob-ject locations in subsequent frames. 3) Reduced annotation cost, where we only annotate the keyframe and use smooth pseudo-motion between keyframes. We demonstrate com-putational efficiency, annotation efficiency, and improved mean average precision compared to the state-of-the-artImageNet VID, EPIC KITCHENS-55, on four datasets:YouTube-BoundingBoxes and Waymo Open dataset. Our source code is available at https://github.com/L-KID/Video-object-detection-by-location-anticipation. 