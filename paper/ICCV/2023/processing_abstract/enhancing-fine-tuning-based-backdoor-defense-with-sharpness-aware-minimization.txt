Backdoor defense, which aims to detect or mitigate the effect of malicious triggers introduced by attackers, is be-coming increasingly critical for machine learning security and integrity. Fine-tuning based on benign data is a nat-ural defense to erase the backdoor effect in a backdoored model. However, recent studies show that, given limited be-nign data, vanilla fine-tuning has poor defense performance.In this work, we firstly investigate the vanilla fine-tuning process for backdoor mitigation from the neuron weight per-spective, and find that backdoor-related neurons are only slightly perturbed in the vanilla fine-tuning process, which explains its poor backdoor defense performance. To en-hance the fine-tuning based defense, inspired by the obser-vation that the backdoor-related neurons often have larger weight norms, we propose FT-SAM, a novel backdoor de-fense paradigm that aims to shrink the norms of backdoor-related neurons by incorporating sharpness-aware minimiza-tion with fine-tuning. We demonstrate the effectiveness of our method on several benchmark datasets and network architectures, where it achieves state-of-the-art defense per-formance, and provide extensive analysis to reveal the FT-SAMâ€™s mechanism. Overall, our work provides a promising avenue for improving the robustness of machine learning models against backdoor attacks. Codes are available at https://github.com/SCLBD/BackdoorBench. 