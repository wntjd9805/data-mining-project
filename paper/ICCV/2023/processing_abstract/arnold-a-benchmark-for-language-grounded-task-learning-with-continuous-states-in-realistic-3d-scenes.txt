Understanding the continuous states of objects is essen-tial for task learning and planning in the real world. How-ever, most existing task learning benchmarks assume discrete (e.g., binary) object goal states, which poses challenges for the learning of complex tasks and transferring learned policy from simulated environments to the real world. Furthermore, state discretization limits a robotâ€™s ability to follow human instructions based on the grounding of actions and states. To tackle these challenges, we present ARNOLD, a benchmark that evaluates language-grounded task learning with con-tinuous states in realistic 3D scenes. ARNOLD is comprised of 8 language-conditioned tasks that involve understanding object states and learning policies for continuous goals. To promote language-instructed learning, we provide expert* Equal contribution. Corresponding authors: Ran Gong, JiangyongHuang, Baoxiong Jia, and Siyuan Huang. demonstrations with template-generated language descrip-tions. We assess task performance by utilizing the latest language-conditioned policy learning models. Our results indicate that current models for language-conditioned ma-nipulations continue to experience significant challenges in novel goal-state generalizations, scene generalizations, and object generalizations. These findings highlight the need to develop new algorithms that address this gap and under-score the potential for further research in this area.Project website: https://arnold-benchmark.github.io. 