Recently, the pure camera-based Birdâ€™s-Eye-View (BEV) perception provides a feasible solution for economical au-tonomous driving. However, the existing BEV-based multi-view 3D detectors generally transform all image features into BEV features, without considering the problem that the large proportion of background information may sub-merge the object information.In this paper, we proposeSemantic-Aware BEV Pooling (SA-BEVPool), which can fil-ter out background information according to the semantic segmentation of image features and transform image fea-tures into semantic-aware BEV features. Accordingly, we propose BEV-Paste, an effective data augmentation strat-egy that closely matches with semantic-aware BEV feature.In addition, we design a Multi-Scale Cross-Task (MSCT) head, which combines task-specific and cross-task informa-tion to predict depth distribution and semantic segmentation more accurately, further improving the quality of semantic-aware BEV feature. Finally, we integrate the above mod-ules into a novel multi-view 3D object detection framework, namely SA-BEV. Experiments on nuScenes show that SA-BEV achieves state-of-the-art performance. Code has been available at https://github.com/mengtan00/SA-BEV.git. 