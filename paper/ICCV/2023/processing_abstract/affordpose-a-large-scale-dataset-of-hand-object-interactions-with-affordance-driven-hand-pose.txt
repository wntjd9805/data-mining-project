How human interact with objects depends on the func-tional roles of the target objects, which introduces the prob-It re-lem of affordance-aware hand-object interaction. quires a large number of human demonstrations for the learning and understanding of plausible and appropriate hand-object interactions.In this work, we present Af-fordPose, a large-scale dataset of hand-object interactions with affordance-driven hand pose. We first annotate the specific part-level affordance labels for each object, e.g. twist, pull, handle-grasp, etc, instead of the general in-tents such as use or handover, to indicate the purpose and guide the localization of the hand-object interactions. The fine-grained hand-object interactions reveal the influence of hand-centered affordances on the detailed arrangement of the hand poses, yet also exhibit a certain degree of diver-sity. We collect a total of 26.7K hand-object interactions, each including the 3D object shape, the part-level affor-dance label, and the manually adjusted hand poses. The comprehensive data analysis shows the common character-istics and diversity of hand-object interactions per affor-dance via the parameter statistics and contacting compu-tation. We also conduct experiments on the tasks of hand-object affordance understanding and affordance-oriented hand-object interaction generation, to validate the effec-tiveness of our dataset in learning the fine-grained hand-object interactions. Project page: https://github. com/GentlesJan/AffordPose 