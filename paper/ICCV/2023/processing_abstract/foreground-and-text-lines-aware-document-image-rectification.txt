This paper aims at the distorted document image recti-fication problem, the objective to eliminate the geometric distortion in the document images and realize document intelligence.Improving the readability of distorted docu-ments is crucial to effectively extract information from de-formed images. According to our observations, the fore-ground and text-line of the original warped image can rep-resent the deformation tendency. However, previous dis-torted image rectification methods pay little attention to the readability of the warped paper. In this paper, we fo-cus on the foreground and text-line regions of distorted paper and proposes a global and local fusion method to improve the rectification effect of distorted images and enhance the readability of document images. We intro-duce cross attention to capture the features of the fore-ground and text-lines in the warped document and effec-tively fuse them. The proposed method is evaluated quan-titatively and qualitatively on the public DocUNet bench-mark and DIR300 Dataset, which achieve state-of-the-art performances. Experimental analysis shows the proposed method can well perform overall geometric rectification of distorted images and effectively improve document read-ability (using the metrics of Character Error Rate and EditDistance). The code is available at https://github. com/xiaomore/Document-Image-Dewarping. 