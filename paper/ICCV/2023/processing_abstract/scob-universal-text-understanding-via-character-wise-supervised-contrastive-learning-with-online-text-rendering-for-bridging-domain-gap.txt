Inspired by the great success of language model (LM)-based pre-training, recent studies in visual document un-derstanding have explored LM-based pre-training methods for modeling text within document images. Among them, pre-training that reads all text from an image has shown promise, but often exhibits instability and even fails when applied to broader domains, such as those involving both visual documents and scene text images. This is a sub-stantial limitation for real-world scenarios, where the pro-cessing of text image inputs in diverse domains is es-sential. In this paper, we investigate effective pre-training tasks in the broader domains and also propose a novel pre-training method called SCOB that leverages character-wise supervised contrastive learning with online text ren-dering to effectively pre-train document and scene text do-mains by bridging the domain gap. Moreover, SCOB en-ables weakly supervised learning, significantly reducing annotation costs. Extensive benchmarks demonstrate thatSCOB generally improves vanilla pre-training methods and achieves comparable performance to state-of-the-art meth-ods. Our findings suggest that SCOB can be served gener-ally and effectively for read-type pre-training methods. The code will be available at https://github.com/naver-ai/scob. 