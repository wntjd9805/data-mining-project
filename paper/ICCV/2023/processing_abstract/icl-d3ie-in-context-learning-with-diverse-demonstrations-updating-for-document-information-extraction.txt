Large language models (LLMs), such as GPT-3 andChatGPT, have demonstrated remarkable results in various natural language processing (NLP) tasks with in-context learning, which involves inference based on a few demon-stration examples. Despite their successes in NLP tasks, no investigation has been conducted to assess the abil-ity of LLMs to perform document information extraction (DIE) using in-context learning. Applying LLMs to DIE poses two challenges: the modality and task gap. To this end, we propose a simple but effective in-context learning framework called ICL-D3IE, which enables LLMs to per-form DIE with different types of demonstration examples.Specifically, we extract the most difficult and distinct seg-ments from hard training documents as hard demonstra-tions for benefiting all test instances. We design demon-strations describing relationships that enable LLMs to un-derstand positional relationships. We introduce formatting demonstrations for easy answer extraction. Additionally, the framework improves diverse demonstrations by updat-ing them iteratively. Our experiments on three widely used benchmark datasets demonstrate that the ICL-D3IE frame-work enables Davinci-003/ChatGPT to achieve superior performance when compared to previous pre-trained meth-ods fine-tuned with full training in both the in-distribution (ID) setting and in the out-of-distribution (OOD) setting.Code is available at https://github.com/MAEHCM/ICL-D3IE. 