Thanks to the excellent global modeling capability of at-tention mechanisms, the Vision Transformer has achieved better results than ConvNet in many computer tasks. How-ever, in generating hierarchical feature maps, the Trans-former still adopts the ConvNet feature aggregation scheme.This leads to the problem that the semantic information of the grid area of image becomes confused after feature aggregation, making it difficult for attention to accurately model global relationships. To address this, we propose theHierarchy Aware Feature Aggregation framework (HAFA).HAFA enhances the extraction of local features adaptively in shallow layers where semantic information is weak, while is able to aggregate patches with similar semantics in deep layers. The clear semantic information of the aggregated patches, enables the attention mechanism to more accu-rately model global information at the semantic level. Ex-tensive experiments show that after using the HAFA frame-work, significant improvements have been achieved relative to the baseline models in image classification, object detec-tion, and semantic segmentation tasks. 