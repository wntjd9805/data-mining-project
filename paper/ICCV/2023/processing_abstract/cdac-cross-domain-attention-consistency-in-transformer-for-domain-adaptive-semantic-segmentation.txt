While transformers have greatly boosted performance in semantic segmentation, domain adaptive transformers are not yet well explored. We identify that the domain gap can cause discrepancies in self-attention. Due to this gap, the transformer attends to spurious regions or pixels, which deteriorates accuracy on the target domain. We proposeCross-Domain Attention Consistency (CDAC), to perform adaptation on attention maps using cross-domain attention layers that share features between source and target do-mains. Specifically, we impose consistency between predic-tions from cross-domain attention and self-attention mod-ules to encourage similar distributions across domains in both the attention and output of the model, i.e., attention-level and output-level alignment. We also enforce consis-tency in attention maps between different augmented views to further strengthen the attention-based alignment. Com-bining these two components, CDAC mitigates the discrep-ancy in attention maps across domains and further boosts the performance of the transformer under unsupervised do-main adaptation settings. Our method is evaluated on var-ious widely used benchmarks and outperforms the state-of-the-art baselines, including GTAV-to-Cityscapes by 1.3 and 1.5 percent point (pp) and Synthia-to-Cityscapes by 0.6 pp and 2.9 pp when combining with two competi-tive Transformer-based backbones, respectively. Our code will be publicly available at https://github.com/ wangkaihong/CDAC. 