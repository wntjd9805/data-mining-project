Vector-quantized image modeling has shown great po-tential in synthesizing high-quality images. However, gen-erating high-resolution images remains a challenging task due to the quadratic computational overhead of the self-attention process.In this study, we seek to explore a more efficient two-stage framework for high-resolution im-age generation with improvements in the following three aspects. (1) Based on the observation that the first quan-tization stage has solid local property, we employ a local attention-based quantization model instead of the global at-tention mechanism used in previous methods, leading to bet-ter efficiency and reconstruction quality. (2) We emphasize the importance of multi-grained feature interaction during image generation and introduce an efficient attention mech-anism that combines global attention (long-range seman-tic consistency within the whole image) and local attention (fined-grained details). This approach results in faster gen-eration speed, higher generation fidelity, and improved res-olution. (3) We propose a new generation pipeline incorpo-rating autoencoding training and autoregressive generation strategy, demonstrating a better paradigm for image syn-thesis. Extensive experiments demonstrate the superiority of our approach in high-quality and high-resolution image reconstruction and generation. 