We study the problem of 3D-aware full-body human gen-eration, aiming at creating animatable human avatars with high-quality textures and geometries. Generally, two chal-i) existing methods struggle lenges remain in this field: to generate geometries with rich realistic details such as the wrinkles of garments; ii) they typically utilize volu-metric radiance fields and neural renderers in the synthe-sis process, making high-resolution rendering non-trivial.To overcome these problems, we propose GETAvatar, aGenerative model that directly generates Explicit Textured 3D meshes for animatable human Avatar, with photo-realistic appearance and fine geometric details. Specifi-cally, we first design an articulated 3D human represen-tation with explicit surface modeling, and enrich the gener-ated humans with realistic surface details by learning from the 2D normal maps of 3D scan data. Second, with the explicit mesh representation, we can use a rasterization-based renderer to perform surface rendering, allowing us to achieve high-resolution image generation efficiently. Ex-tensive experiments demonstrate that GETAvatar achieves state-of-the-art performance on 3D-aware human genera-*Equal contribution. tion both in appearance and geometry quality. Notably,GETAvatar can generate images at 5122 resolution with 17FPS and 10242 resolution with 14FPS, improving upon previous methods by 2Ã—. Our code and models will be at https://getavatar.github.io/. 