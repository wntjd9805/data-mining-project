We present a simple but effective pixel-level self-supervised distillation framework friendly to dense predic-tion tasks. Our method, called Pixel-Wise Contrastive Dis-tillation (PCD), distills knowledge by attracting the corre-sponding pixels from student’s and teacher’s output feature maps. PCD includes a novel design called SpatialAdaptor which “reshapes” a part of the teacher network while pre-serving the distribution of its output features. Our ablation experiments suggest that this reshaping behavior enables more informative pixel-to-pixel distillation. Moreover, we utilize a plug-in multi-head self-attention module that ex-plicitly relates the pixels of student’s feature maps to en-hance the effective receptive field, leading to a more com-petitive student. PCD outperforms previous self-supervised distillation methods on various dense prediction tasks. A backbone of ResNet-18-FPN distilled by PCD achieves 37.4APbbox and 34.0 APmask on COCO dataset using the detec-tor of Mask R-CNN. We hope our study will inspire future research on how to pre-train a small model friendly to dense prediction tasks in a self-supervised fashion. 