In this study, a novel self-supervised learning (SSL) method is proposed, which considers SSL in terms of vari-ational inference to learn not only representation but also representation uncertainties. SSL is a method of learning representations without labels by maximizing the similar-ity between image representations of different augmented views of an image. Meanwhile, variational autoencoder (VAE) is an unsupervised representation learning method that trains a probabilistic generative model with variational inference. Both VAE and SSL can learn representations with-out labels, but their relationship has not been investigated in the past. Herein, the theoretical relationship betweenSSL and variational inference has been clariﬁed. Further-more, a novel method, namely variational inference SimSiam (VI-SimSiam), has been proposed. VI-SimSiam can predict the representation uncertainty by interpreting SimSiam with variational inference and deﬁning the latent space distribu-tion. The present experiments qualitatively show that VI-SimSiam could learn uncertainty by comparing input images and predicted uncertainties. Additionally, we described a re-lationship between estimated uncertainty and classiﬁcation accuracy. 