We introduce the Aria Digital Twin (ADT) 1 - an egocen-tric dataset captured using Aria glasses with extensive ob-ject, environment, and human level ground truth. This ADT release contains 200 sequences of real-world activities con-ducted by Aria wearers in two real indoor scenes with 398 object instances (344 stationary and 74 dynamic). Each sequence consists of: a) raw data of two monochrome cam-era streams, one RGB camera stream, two IMU streams; b) complete sensor calibration; c) ground truth data including continuous 6-degree-of-freedom (6DoF) poses of the Aria devices, object 6DoF poses, 3D eye gaze vectors, 3D hu-man poses, 2D image segmentations, image depth maps; and d) photo-realistic synthetic renderings. To the best of our knowledge, there is no existing egocentric dataset with a level of accuracy, photo-realism and comprehensiveness comparable to ADT. By contributing ADT to the research community, our mission is to set a new standard for evalu-ation in the egocentric machine perception domain, which includes very challenging research problems such as 3D ob-ject detection and tracking, scene reconstruction and un-derstanding, sim-to-real learning, human pose prediction -while also inspiring new machine perception tasks for aug-mented reality (AR) applications. To kick start exploration of the ADT research use cases, we evaluated several existing state-of-the-art methods for object detection, segmentation and image translation tasks that demonstrate the usefulness of ADT as a benchmarking dataset. 