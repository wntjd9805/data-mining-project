BEV Features (LiDAR)BEV Features (Fusion)By identifying four important components of existingLiDAR-camera 3D object detection methods (LiDAR and camera candidates, transformation, and fusion outputs), we observe that all existing methods either ﬁnd dense candi-dates or yield dense representations of scenes. However, given that objects occupy only a small part of a scene,ﬁnding dense candidates and generating dense represen-tations is noisy and inefﬁcient. We propose SparseFusion, a novel multi-sensor 3D detection method that exclusively uses sparse candidates and sparse representations. Speciﬁ-cally, SparseFusion utilizes the outputs of parallel detectors in the LiDAR and camera modalities as sparse candidates for fusion. We transform the camera candidates into the Li-DAR coordinate space by disentangling the object represen-tations. Then, we can fuse the multi-modality candidates in a uniﬁed 3D space by a lightweight self-attention module.To mitigate negative transfer between modalities, we pro-pose novel semantic and geometric cross-modality trans-fer modules that are applied prior to the modality-speciﬁc detectors. SparseFusion achieves state-of-the-art perfor-mance on the nuScenes benchmark while also running at the fastest speed, even outperforming methods with stronger backbones. We perform extensive experiments to demon-strate the effectiveness and efﬁciency of our modules and overall method pipeline. Our code will be made publicly available at https://github.com/yichen928/SparseFusion. 