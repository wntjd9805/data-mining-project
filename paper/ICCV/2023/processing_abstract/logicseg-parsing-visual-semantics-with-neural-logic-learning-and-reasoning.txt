Current high-performance semantic segmentation models are purely data-driven sub-symbolic approaches and blind to the structured nature of the visual world. This is in stark contrast to human cognition which abstracts visual percep-tions at multiple levels and conducts symbolic reasoning with such structured abstraction. To fill these fundamental gaps, we devise LOGICSEG, a holistic visual semantic parser that integrates neural inductive learning and logic reasoning with both rich data and symbolic knowledge. In particular, the semantic concepts of interest are structured as a hierarchy, from which a set of constraints are derived for describing the symbolic relations and formalized as first-order logic rules.After fuzzy logic-based continuous relaxation, logical formu-lae are grounded onto data and neural computational graphs, hence enabling logic-induced network training. During in-ference, logical constraints are packaged into an iterative process and injected into the network in a form of several matrix multiplications, so as to achieve hierarchy-coherent prediction with logic reasoning. These designs together makeLOGICSEG a general and compact neural-logic machine that is readily integrated into existing segmentation models.Extensive experiments over four datasets with various seg-mentation models and backbones verify the effectiveness and generality of LOGICSEG.We believe this study opens a new avenue for visual semantic parsing. 