The development of face editing has been boosted since the birth of StyleGAN. While previous works have explored different interactive methods, such as sketching and exem-plar photos, they have been limited in terms of expressive-ness and generality.In this paper, we propose a new in-teraction method by guiding the editing with abstract cli-part, composed of a set of simple semantic parts, allow-ing users to control across face photos with simple clicks.However, this is a challenging task given the large domain gap between colorful face photos and abstract clipart with limited data. To solve this problem, we introduce a frame-work called ClipFaceShop 1 built on top of StyleGAN. The key idea is to take advantage of W+ latent code encoded rich and disentangled visual features, and create a new lightweight selective feature adaptor to predict a modiﬁ-able path toward the target output photo. Since no pairwise*Nanxuan Zhao is with Adobe Research.E-mail: nanxu-anzhao@gmail.com.*Shengqi Dang, Hexun Lin, Yang Shi and Nan Cao are with IntelligentBig DataVisualization Lab, Tongji University. Nan Cao is the correspond-ing author. E-mail: dangsq123@tongji.edu.cn, linhexun@pku.edu.cn,{shiyang1230, nan.cao}@gmail.com. 1Code: https://github.com/dangsq/ClipFaceShop labeled data exists for training, we design a set of losses to provide supervision signals for learning the modiﬁable path. Experimental results show that ClipFaceShop gen-erates realistic and faithful face photos, sharing the same facial attributes as the reference clipart. We demonstrate that ClipFaceShop supports clipart in diverse styles, even in form of a free-hand sketch. 