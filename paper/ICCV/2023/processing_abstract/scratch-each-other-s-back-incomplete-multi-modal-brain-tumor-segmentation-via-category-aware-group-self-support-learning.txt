Although Magnetic Resonance Imaging (MRI) is very helpful for brain tumor segmentation and discovery, it of-ten lacks some modalities in clinical practice. As a re-sult, degradation of prediction performance is inevitable.According to current implementations, different modalities are considered to be independent and non-interfering with each other during the training process of modal feature ex-traction, however they are complementary. In this paper, considering the sensitivity of different modalities to diverse tumor regions, we propose a Category Aware Group Self-Support Learning framework, called GSS, to make up for the information deﬁcit among the modalities in the indi-vidual modal feature extraction phase. Precisely, within each prediction category, predictions of all modalities form a group, where the prediction with the most extraordi-nary sensitivity is selected as the group leader. Collab-orative efforts between group leaders and members iden-tify the communal learning target with high consistency and certainty. As our minor contribution, we introduce a random mask to reduce the possible biases. GSS adopts the standard training strategy without speciﬁc architectural choices and thus can be easily plugged into existing in-complete multi-modal brain tumor segmentation. Remark-ably, extensive experiments on BraTS2020, BraTS2018, and BraTS2015 datasets demonstrate that GSS can im-prove the performance of existing SOTA algorithms by 1.27-3.20% in Dice on average. The code is released at https://github.com/qysgithubopen/GSS. 