Missing detectionMissing detectionError detectionInfrared and visible image fusion aims to integrate com-prehensive information from multiple sources to achieve su-perior performances on various practical tasks, such as de-tection, over that of a single modality. However, most ex-isting methods directly combined the texture details and ob-ject contrast of different modalities, ignoring the dynamic changes in reality, which diminishes the visible texture in good lighting conditions and the infrared contrast in low lighting conditions. To Ô¨Åll this gap, we propose a dynamic image fusion framework with a multi-modal gated mixture of local-to-global experts, termed MoE-Fusion, to dynami-cally extract effective and comprehensive information from the respective modalities. Our model consists of a Mixture of Local Experts (MoLE) and a Mixture of Global Experts (MoGE) guided by a multi-modal gate. The MoLE per-forms specialized learning of multi-modal local features, prompting the fused images to retain the local informa-tion in a sample-adaptive manner, while the MoGE focuses on the global information that complements the fused im-age with overall texture detail and contrast. Extensive ex-periments show that our MoE-Fusion outperforms state-of-the-art methods in preserving multi-modal image texture and contrast through the local-to-global dynamic learning paradigm, and also achieves superior performance on de-tection tasks. Our code is available: https://github. com/SunYM2020/MoE-Fusion. 