Recent studies have shown the vulnerability of CNNs un-der perturbation noises, which is partially caused by the reason that the well-trained CNNs are too biased toward the object texture, i.e., they make predictions mainly based on texture cues. To reduce this texture-bias, current stud-ies resort to learning augmented samples with heavily per-turbed texture to make networks be more biased toward rel-atively stable shape cues. However, such methods usually fail to achieve real shape-biased networks due to the insuf-ficient diversity of the shape cues. In this paper, we propose to augment the training dataset by generating semantically meaningful shapes and samples, via a shape deformation-based online augmentation, namely as SDbOA. The sam-ples generated by our SDbOA have two main merits. First, the augmented samples with more diverse shape variations enable networks to learn the shape cues more elaborately, which encourages the network to be shape-biased. Second, semantic-meaningful shape-augmentation samples could be produced by jointly regularizing the generator with ob-ject texture and edge-guidance soft constraint, where the edges are represented more robustly with a self information guided map to better against the noises on them. Extensive experiments under various perturbation noises demonstrate the obvious superiority of our shape-bias-motivated model over the state of the arts in terms of robustness performance.Code is available at https://github.com/C0notSilly/-ICCV-23-Edge-Deformation-based-Online-Augmentation.* Corresponding authorFigure 1. Comparison of different models’ predictions on texture-shape cue conflict samples [11] between Style Augmentation [21] (CVPRW’19), deformation augmentation in [43] and ours. Spe-cific to the testing image (a), the bottom row shows the original (b) and augmented (c)-(e) images for training. 