3D pose estimation is an invaluable task in computer vision with various practical applications. Especially, 3D pose estimation for multi-person from a monocular video (3DMPPE) is particularly challenging and is still largely uncharted, far from applying to in-the-wild scenarios yet.We pose three unresolved issues with the existing meth-ods: lack of robustness on unseen views during training, vulnerability to occlusion, and severe jittering in the out-put. As a remedy, we propose POTR-3D, the ﬁrst realiza-tion of a sequence-to-sequence 2D-to-3D lifting model for 3DMPPE, powered by a novel geometry-aware data aug-mentation strategy, capable of generating unbounded data with a variety of views while caring about the ground plane and occlusions. Through extensive experiments, we verify that the proposed model and data augmentation robustly generalizes to diverse unseen views, robustly recovers the poses against heavy occlusions, and reliably generates more natural and smoother outputs. The effectiveness of our approach is veriﬁed not only by achieving the state-of-the-art performance on public benchmarks, but also by qualita-tive results on more challenging in-the-wild videos. Demo videos are available at https://www.youtube.com/@potr3d. 