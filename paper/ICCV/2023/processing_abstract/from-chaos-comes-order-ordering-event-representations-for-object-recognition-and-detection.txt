Today, state-of-the-art deep neural networks that process events first convert them into dense, grid-like input repre-sentations before using an off-the-shelf network. However, selecting the appropriate representation for the task tradi-tionally requires training a neural network for each repre-sentation and selecting the best one based on the valida-tion score, which is very time-consuming. This work elimi-nates this bottleneck by selecting representations based on the Gromov-Wasserstein Discrepancy (GWD) between raw events and their representation. It is about 200 times faster to compute than training a neural network and preserves the task performance ranking of event representations across multiple representations, network backbones, datasets, and tasks. Thus finding representations with high task scores is equivalent to finding representations with a low GWD. We use this insight to, for the first time, perform a hyperpa-rameter search on a large family of event representations, revealing new and powerful representations that exceed the*Equal contribution state-of-the-art. Our optimized representations outperform existing representations by 1.7 mAP on the 1 Mpx dataset and 0.3 mAP on the Gen1 dataset, two established object detection benchmarks, and reach a 3.8% higher classifica-tion score on the mini N-ImageNet benchmark. Moreover, we outperform state-of-the-art by 2.1 mAP on Gen1 and state-of-the-art feed-forward methods by 6.0 mAP on the 1Mpx datasets. This work opens a new unexplored field of ex-plicit representation optimization for event-based learning.Multimedia MaterialFor open-source code please visit https://github. com/uzh-rpg/event_representation_study. 