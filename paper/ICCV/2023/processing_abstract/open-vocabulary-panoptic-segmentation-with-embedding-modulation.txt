Open-vocabulary image segmentation is attracting in-creasing attention due to its critical applications in the real world. Traditional closed-vocabulary segmentation meth-ods are not able to characterize novel objects, whereas sev-eral recent open-vocabulary attempts obtain unsatisfactory results, i.e., notable performance reduction on the closed-vocabulary and massive demand for extra data. To this end, we propose OPSNet, an omnipotent and data-efficient framework for Open-vocabulary Panoptic Segmentation.Specifically, the exquisitely designed Embedding Modula-tion module, together with several meticulous components, enables adequate embedding enhancement and informa-tion exchange between the segmentation model and the visual-linguistic well-aligned CLIP encoder, resulting in superior segmentation performance under both open- and closed-vocabulary settings with much fewer need of addi-tional data. Extensive experimental evaluations are con-ducted across multiple datasets (e.g., COCO, ADE20K,Cityscapes, and PascalContext) under various circum-stances, where the proposed OPSNet achieves state-of-the-art results, which demonstrates the effectiveness and gen-erality of the proposed approach. The project page is https://opsnet-page.github.io. 