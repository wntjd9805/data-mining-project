ing AVSpeech, HDTF, and LRW, in terms of photo-realism, identity preservation, and Lip-Sync accuracy.Dubbed video generation aims to accurately synchronize mouth movements of a given facial video with driving audio while preserving identity and scene-specific visual dynam-ics, such as head pose and lighting. Despite the accurate lip generation of previous approaches that adopts a pre-trained audio-video synchronization metric as an objective function, called Sync-Loss, extending it to high-resolution videos was challenging due to shift biases in the loss land-scape that inhibit tandem optimization of Sync-Loss and vi-sual quality, leading to a loss of detail.To address this issue, we introduce shift-invariant learn-ing, which generates photo-realistic high-resolution videos with accurate Lip-Sync. Further, we employ a pyramid net-work with coarse-to-fine image generation to improve sta-bility and lip syncronization. Our model outperforms state-of-the-art methods on multiple benchmark datasets, includ-âˆ—Equal contribution. 