Online Action Detection (OAD) is the task of identifying actions in streaming videos without access to future frames.Much effort has been devoted to effectively capturing long-range dependencies, with transformers receiving the spot-light for their ability to capture long-range temporal struc-tures. In contrast, RNNs have received less attention lately, due to their lower performance compared to recent methods that utilize transformers. In this paper, we investigate the underlying reasons for the inferior performance of RNNs compared to transformer-based algorithms. Our findings indicate that the discrepancy between training and infer-ence is the primary hindrance to the effective training ofRNNs. To address this, we propose applying non-uniform weights to the loss computed at each time step, which al-lows the RNN model to learn from the predictions made in an environment that better resembles the inference stage.Extensive experiments on three benchmark datasets, THU-MOS, TVSeries, and FineAction demonstrate that a minimalRNN-based model trained with the proposed methodology performs equally or better than the existing best methods with a significant increase in efficiency. The code is avail-able at https://github.com/jbistanbul/MiniROAD. 