The advent of open-source AI communities has produced a cornucopia of powerful text-guided diffusion models that are trained on various datasets. While few explorations have been conducted on ensembling such models to com-bine their strengths.In this work, we propose a simple yet effective method called Saliency-aware Noise Blend-ing (SNB) that can empower the fused text-guided diffusion models to achieve more controllable generation. Specifi-cally, we experimentally find that the responses of classifier-free guidance are highly related to the saliency of gen-erated images. Thus we propose to trust different mod-*Work done during an internship at JD Explore Academy.â€ Corresponding authors. els in their areas of expertise by blending the predicted noises of two diffusion models in a saliency-aware man-ner. SNB is training-free and can be completed within aDDIM sampling process. Additionally, it can automati-cally align the semantics of two noise spaces without re-quiring additional annotations such as masks. Extensive experiments show the impressive effectiveness of SNB in various applications. The project page is available at https://magicfusion.github.io/. 