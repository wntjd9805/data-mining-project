In this paper, we provide 20,000 non-trivial human an-notations on popular datasets as a first step to bridge gap to studying how natural semantic spurious features affect im-age classification, as prior works often study datasets mix-ing low-level features due to limitations in accessing real-istic datasets. We investigate how natural background col-ors play a role as spurious features by annotating the test sets of CIFAR10 and CIFAR100 into subgroups based on the background color of each image. We name our datasetsCIFAR10-B and CIFAR100-B1 and integrate them withCIFAR-Cs.We find that overall human-level accuracy does not guarantee consistent subgroup performances, and the phe-nomenon remains even on models pre-trained on ImageNet or after data augmentation (DA). To alleviate this issue, we propose FlowAug, a semantic DA that leverages decoupled semantic representations captured by a pre-trained genera-tive flow. Experimental results show that FlowAug achieves more consistent subgroup results than other types of DA methods on CIFAR10/100 and on CIFAR10/100-C. Addi-tionally, it shows better generalization performance.Furthermore, we propose a generic metric, MacroStd, for studying model robustness to spurious correlations, where we take a macro average on the weighted standard deviations across different classes. We show MacroStd be-ing more predictive of better performances; per our met-ric, FlowAug demonstrates improvements on subgroup dis-crepancy. Although this metric is proposed to study our curated datasets, it applies to all datasets that have sub-groups or subclasses. Lastly, we also show superior out-of-distribution results on CIFAR10.1. 