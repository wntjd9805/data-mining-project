Learning-based multi-view stereo (MVS) method heav-ily relies on feature matching, which requires distinctive and descriptive representations. An effective solution is to apply non-local feature aggregation, e.g., Transformer.Albeit useful, these techniques introduce heavy computa-tion overheads for MVS. Each pixel densely attends to theIn contrast, we propose to constrain non-whole image. local feature augmentation within a pair of lines: each point only attends the corresponding pair of epipolar lines.Our idea takes inspiration from the classic epipolar geom-etry, which shows that one point with different depth hy-potheses will be projected to the epipolar line on the other view. This constraint reduces the 2D search space into the epipolar line in stereo matching. Similarly, this sug-gests that the matching of MVS is to distinguish a series of points lying on the same line. Inspired by this point-to-line search, we devise a line-to-point non-local augmenta-tion strategy. We first devise an optimized searching algo-rithm to split the 2D feature maps into epipolar line pairs.Then, an Epipolar Transformer (ET) performs non-local feature augmentation among epipolar line pairs. We incor-porate the ET into a learning-based MVS baseline, namedET-MVSNet. ET-MVSNet achieves state-of-the-art recon-struction performance on both the DTU and Tanks-and-Temples benchmark with high efficiency. Code is available at https://github.com/TQTQliu/ET-MVSNet. 