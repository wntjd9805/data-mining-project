Visual Place Recognition is a task that aims to predict the place of an image (called query) based solely on its visual features. This is typically done through image re-trieval, where the query is matched to the most similar images from a large database of geotagged photos, us-ing learned global descriptors. A major challenge in this task is recognizing places seen from different viewpoints.To overcome this limitation, we propose a new method, called EigenPlaces, to train our neural network on im-ages from different point of views, which embeds viewpoint robustness into the learned global descriptors. The un-derlying idea is to cluster the training data so as to ex-plicitly present the model with different views of the same points of interest. The selection of this points of inter-est is done without the need for extra supervision. We then present experiments on the most comprehensive set of datasets in literature, finding that EigenPlaces is able to outperform previous state of the art on the majority of datasets, while requiring 60% less GPU memory for train-ing and using 50% smaller descriptors. The code and trained models for EigenPlaces are available at https://github.com/gmberton/EigenPlaces, while results with any other baseline can be computed with the codebase at https://github.com/gmberton/auto_VPR. 