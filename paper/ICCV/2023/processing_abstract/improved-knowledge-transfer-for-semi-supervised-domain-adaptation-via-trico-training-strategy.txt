The motivation of the semi-supervised domain adapta-tion (SSDA) is to train a model by leveraging knowledge acquired from the plentiful labeled source combined with extremely scarce labeled target data to achieve the low-est error on the unlabeled target data at the testing time.However, due to inter-domain and intra-domain discrepan-cies, the improvement of classification accuracy is limited.To solve these, we propose the Trico-training method that utilizes a multilayer perceptron (MLP) classifier and two graph convolutional network (GCN) classifiers called inter-view GCN and intra-view GCN classifiers. The first co-training strategy exploits a correlation between MLP and inter-view GCN classifiers to minimize the inter-domain dis-crepancy, in which the inter-view GCN classifier provides its pseudo labels to teach the MLP classifier, which en-courages class representation alignment across domains. In contrast, the MLP classifier gives feedback to the inter-viewGCN classifier by using a new concept, ‘pseudo-edge’, for neighbor’s feature aggregation. Doing this increases the data structure mining ability of the inter-view GCN clas-sifier; thus, the quality of generated pseudo labels is im-proved. The second co-training strategy between MLP and intra-view GCN is conducted in a similar way to reduce the intra-domain discrepancy by enhancing the correlation be-tween labeled and unlabeled target data. Due to an im-balance in classification accuracy between inter-view and intra-view GCN classifiers, we propose the third co-training strategy that encourages them to cooperate to address this problem. We verify the effectiveness of the proposed method on three standard SSDA benchmark datasets: Office-31,Office-Home, and DomainNet. The extended experimental results show that our method surpasses the prior state-of-the-art approaches in SSDA. 