Supervised learning of image classifiers distills human knowledge into a parametric model fÎ¸ through pairs of im-ages and corresponding labels {(Xi, Yi)}N i=1. We argue that this simple and widely used representation of human knowl-edge neglects rich auxiliary information from the annotation procedure, such as the time-series of mouse traces and clicks left after image selection. Our insight is that such anno-tation byproducts Z provide approximate human attention that weakly guides the model to focus on the foreground cues, reducing spurious correlations and discouraging short-cut learning. To verify this, we create ImageNet-AB andCOCO-AB. They are ImageNet and COCO training sets en-riched with sample-wise annotation byproducts, collected by replicating the respective original annotation tasks. We refer to the new paradigm of training models with annota-tion byproducts as learning using annotation byproducts (LUAB). We show that a simple multitask loss for regressingZ together with Y already improves the generalisability and robustness of the learned models. Compared to the original supervised learning, LUAB does not require extra annotation costs. ImageNet-AB and COCO-AB are at github.com/naver-ai/NeglectedFreeLunch. 