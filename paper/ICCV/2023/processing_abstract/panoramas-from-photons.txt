Scene reconstruction in the presence of high-speed mo-tion and low illumination is important in many applica-tions such as augmented and virtual reality, drone naviga-tion, and autonomous robotics. Traditional motion estima-tion techniques fail in such conditions, suffering from too much blur in the presence of high-speed motion and strong noise in low-light conditions. Single-photon cameras have recently emerged as a promising technology capable of cap-turing hundreds of thousands of photon frames per second thanks to their high speed and extreme sensitivity. Unfortu-nately, traditional computer vision techniques are not well suited for dealing with the binary-valued photon data cap-tured by these cameras because these are corrupted by ex-treme Poisson noise. Here we present a method capable of estimating extreme scene motion under challenging con-ditions, such as low light or high dynamic range, from a sequence of high-speed image frames such as those cap-tured by a single-photon camera. Our method relies on it-eratively improving a motion estimate by grouping and ag-gregating frames after-the-fact, in a stratified manner. We demonstrate the creation of high-quality panoramas under fast motion and extremely low light, and super-resolution results using a custom single-photon camera prototype. For code and supplemental material see our project webpage. 