In instance image retrieval, considering local spatial in-formation within an image has proven effective to boost re-trieval performance, as demonstrated by local visual de-scriptor based geometric verification. Nevertheless, it will be highly valuable to make ordinary global image repre-sentations spatial-context-aware because global represen-tation based image retrieval is appealing thanks to its al-gorithmic simplicity, low memory cost, and being friendly to sophisticated data structures. To this end, we propose a novel feature learning framework for instance image re-trieval, which embeds local spatial context information into the learned global feature representations. Specifically, in parallel to the visual feature branch in a CNN backbone, we design a spatial context branch that consists of two modules called online token learning and distance encod-ing. For each local descriptor learned in CNN, the for-mer module is used to indicate the types of its surrounding descriptors, while their spatial distribution information is captured by the latter module. After that, the visual fea-ture branch and the spatial context branch are fused to produce a single global feature representation per image.As experimentally demonstrated, with the spatial-context-aware characteristic, we can well improve the performance of global representation based image retrieval while main-taining all of its appealing properties. Our code is available at https://github.com/Zy-Zhang/SpCa. 