The recent amalgamation of transformer and convolu-tional designs has led to steady improvements in accuracyIn this work, we introduce and efficiency of the models.FastViT, a hybrid vision transformer architecture that ob-tains the state-of-the-art latency-accuracy trade-off. To this end, we introduce a novel token mixing operator, RepMixer, a building block of FastViT, that uses structural reparam-eterization to lower the memory access cost by removing skip-connections in the network. We further apply train-time overparametrization and large kernel convolutions to boost accuracy and empirically show that these choices have minimal effect on latency. We show that – our model faster than CMT, a recent state-of-the-art hybrid is 3.5 transformer architecture, 4.9 faster than EfficientNet, and faster than ConvNeXt on a mobile device for the same 1.9 accuracy on the ImageNet dataset. At similar latency, our model obtains 4.2% better Top-1 accuracy on ImageNet than MobileOne. Our model consistently outperforms com-peting architectures across several tasks – image classifica-tion, detection, segmentation and 3D mesh regression with significant improvement in latency on both a mobile de-vice and a desktop GPU. Furthermore, our model is highly robust to out-of-distribution samples and corruptions, im-proving over competing robust models. Code and mod-els are available at https://github.com/apple/ ml-fastvit××× 