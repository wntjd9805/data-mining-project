Deep neural networks have achieved remarkable results across various tasks. However, they are susceptible to ad-versarial examples, which are generated by adding adver-sarial perturbations to original data. Adversarial training (AT) is the most effective defense mechanism against adver-sarial examples and has received significant attention. Re-cent studies highlight the importance of example exploita-tion, where the modelâ€™s learning intensity is altered for specific examples to extend classic AT approaches. How-ever, the analysis methodologies employed by these stud-ies are varied and contradictory, which may lead to con-fusion in future research. To address this issue, we pro-vide a comprehensive summary of representative strategies focusing on exploiting examples within a unified frame-work. Furthermore, we investigate the role of examples in AT and find that examples which contribute primarily to accuracy or robustness are distinct. Based on this find-ing, we propose a novel example-exploitation idea that can further improve the performance of advanced AT meth-ods. This new idea suggests that critical challenges in AT, such as the accuracy-robustness trade-off, robust overfit-ting, and catastrophic overfitting, can be alleviated simulta-neously from an example-exploitation perspective. The code can be found in https://github.com/geyao1995/advancing-example-exploitation-in-adversarial-training. 