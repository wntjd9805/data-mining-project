Neural Radiance Fields (NeRF) [24] has achieved impres-sive results in single object scene reconstruction and novel view synthesis, as demonstrated on many single modality and single object focused indoor scene datasets like DTU [14],BMVS [42], and NeRF Synthetic [24]. However, the study of NeRF on large-scale outdoor scene reconstruction is still limited, as there is no unified outdoor scene dataset for large-scale NeRF evaluation due to expensive data acquisition and calibration costs. In this work, we propose a large-scale outdoor multi-modal dataset, OMMO dataset, containing complex objects and scenes with calibrated images, point clouds and prompt annotations. A new benchmark for sev-eral outdoor NeRF-based tasks is established, such as novel view synthesis, diverse 3D representation, and multi-modalNeRF. To create the dataset, we capture and collect a large number of real fly-view videos and select high-quality and high-resolution clips from them. Then we design a quality review module to refine images, remove low-quality frames and fail-to-calibrate scenes through a learning-based au-tomatic evaluation plus manual review. Finally, volunteers are employed to label and review the prompt annotation for each scene and keyframe. Compared with existing NeRF datasets, our dataset contains abundant real-world urban and natural scenes with various scales, camera trajectories, and lighting conditions. Experiments show that our dataset can benchmark most state-of-the-art NeRF methods on dif-ferent tasks. The dataset can be found at the following link: https://ommo.luchongshan.com/ .Figure 1. A city scene example from our dataset captured with low illuminance and circle-shaped camera trajectory. We show multi-view calibrated images, the camera track, and text descriptions of the scene. Some details in colored boxes are zoomed in to indicate that our dataset can provide real-world high-fidelity texture details. 