Novel view synthesis aims to render unseen views given a set of calibrated images. In practical applications, the coverage, appearance or geometry of the scene may change over time, with new images continuously being captured.Efﬁciently incorporating such continuous change is an open challenge. Standard NeRF benchmarks only involve scene coverage expansion. To study other practical scene changes, we propose a new dataset, World Across Time (WAT), con-sisting of scenes that change in appearance and geometry over time. We also propose a simple yet effective method,CLNeRF, which introduces continual learning (CL) to Neu-ral Radiance Fields (NeRFs). CLNeRF combines gener-ative replay and the Instant Neural Graphics Primitives (NGP) architecture to effectively prevent catastrophic forget-ting and efﬁciently update the model when new data ar-rives. We also add trainable appearance and geometry embeddings to NGP, allowing a single compact model to handle complex scene changes. Without the need to store historical images, CLNeRF trained sequentially over mul-tiple scans of a changing scene performs on-par with the upper bound model trained on all scans at once. Com-pared to other CL baselines CLNeRF performs much better across standard benchmarks and WAT. The source code, a demo, and the WAT dataset are available at https://github.com/IntelLabs/CLNeRF. 