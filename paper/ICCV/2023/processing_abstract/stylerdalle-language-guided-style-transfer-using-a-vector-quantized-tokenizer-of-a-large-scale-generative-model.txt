Despite the progress made in the style transfer task, most previous work focus on transferring only relatively sim-ple features like color or texture, while missing more ab-stract concepts such as overall art expression or painter-speciﬁc traits. However, these abstract semantics can be captured by models like DALL-E or CLIP, which have been trained using huge datasets of images and textualIn this paper, we propose StylerDALLE, a documents. style transfer method that exploits both of these models and uses natural language to describe abstract art styles.Speciﬁcally, we formulate the language-guided style trans-fer task as a non-autoregressive token sequence transla-tion, i.e., from input content image to output stylized im-age, in the discrete latent space of a large-scale pretrained vector-quantized tokenizer, e.g., the discrete variational auto-encoder (dVAE) of DALL-E. To incorporate style in-formation, we propose a Reinforcement Learning strategy with CLIP-based language supervision that ensures styl-ization and content preservation simultaneously. Experi-mental results demonstrate the superiority of our method, which can effectively transfer art styles using language in-structions at different granularities. Code is available at https://github.com/zipengxuc/StylerDALLE. 