Video stabilization refers to the problem of transform-ing a shaky video into a visually pleasing one. The ques-tion of how to strike a good trade-off between visual qual-ity and computational speed has remained one of the open challenges in video stabilization. Inspired by the analogy between wobbly frames and jigsaw puzzles, we propose an iterative optimization-based learning approach using syn-thetic datasets for video stabilization, which consists of two interacting submodules: motion trajectory smoothing and full-frame outpainting. First, we develop a two-level (coarse-to-ﬁne) stabilizing algorithm based on the proba-bilistic ﬂow ﬁeld. The conﬁdence map associated with the estimated optical ﬂow is exploited to guide the search for shared regions through backpropagation. Second, we take a divide-and-conquer approach and propose a novel multi-frame fusion strategy to render full-frame stabilized views.An important new insight brought about by our iterative optimization approach is that the target video can be in-terpreted as the ﬁxed point of nonlinear mapping for video stabilization. We formulate video stabilization as a problem of minimizing the amount of jerkiness in motion trajecto-ries, which guarantees convergence with the help of ﬁxed-point theory. Extensive experimental results are reported to demonstrate the superiority of the proposed approach in terms of computational speed and visual quality. The code will be available on GitHub. 