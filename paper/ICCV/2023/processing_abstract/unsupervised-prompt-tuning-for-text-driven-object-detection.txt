Grounded language-image pre-trained models have shown strong zero-shot generalization to various down-stream object detection tasks. Despite their promising per-formance, the models rely heavily on the laborious prompt engineering. Existing works typically address this prob-lem by tuning text prompts using downstream training data in a few-shot or fully supervised manner. However, a rarely studied problem is to optimize text prompts with-In this paper, we delve into out using any annotations. this problem and propose an Unsupervised Prompt Tuning framework for text-driven object detection, which is com-posed of two novel mean teaching mechanisms.In con-ventional mean teaching, the quality of pseudo boxes is expected to optimize better as the training goes on, but there is still a risk of overfitting noisy pseudo boxes. To mitigate this problem, 1) we propose Nested Mean Teach-ing, which adopts nested-annotation to supervise teacher-student mutual learning in a bi-level optimization manner; 2) we propose Dual Complementary Teaching, which em-ploys an offline pre-trained teacher and an online mean teacher via data-augmentation-based complementary la-beling so as to ensure learning without accumulating confir-mation bias. By integrating these two mechanisms, the pro-posed unsupervised prompt tuning framework achieves sig-nificant performance improvement on extensive object de-tection datasets. 