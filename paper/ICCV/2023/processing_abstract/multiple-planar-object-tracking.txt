Tracking both location and pose of multiple planar ob-jects (MPOT) is of great significance to numerous real-world applications. The greater degree-of-freedom of pla-nar objects compared with common objects makes MPOT far more challenging than well-studied object tracking, es-pecially when occlusion occurs. To address this challeng-ing task, we are inspired by amodal perception that humans jointly track visible and invisible parts of the target, and propose a tracking framework that unifies appearance per-ception and occlusion reasoning. Specifically, we present a dual-branch network to track the visible part of planar ob-jects, including vertexes and mask. Then, we develop an oc-clusion area localization strategy to infer the invisible part, i.e., the occluded region, followed by a two-stream attention network finally refining the prediction. To alleviate the lack of data in this field, we build the first large-scale benchmark dataset, namely MPOT-3K. It consists of 3,717 planar ob-jects from 356 videos and contains 148,896 frames together with 687,417 annotations. The collected planar objects have 9 motion patterns and the videos are shot in 6 types of indoor and outdoor scenes. Extensive experiments demon-strate the superiority of our proposed method on the newly developed MPOT-3K as well as other two popular single planar object tracking datasets. The code and MPOT-3K dataset are released on https://zzcheng.top/MPOT. 