Recently emerged Vision-and-Language Navigation (VLN) tasks have drawn signiﬁcant attention in both com-puter vision and natural language processing communi-ties. Existing VLN tasks are built for agents that navigate on the ground, either indoors or outdoors. However, many tasks require intelligent agents to carry out in the sky, such as UAV-based goods delivery, trafﬁc/security†These authors contribute equally to this work∗Corresponding Author patrol, and scenery tour, to name a few. Navigating in the sky is more complicated than on the ground be-cause agents need to consider the ﬂying height and more complex spatial relationship reasoning. To ﬁll this gap and facilitate research in this ﬁeld, we pro-pose a new task named AerialVLN, which is UAV-based and towards outdoor environments. We develop a 3D simulator rendered by near-realistic pictures of 25 city-level scenarios. Our simulator supports continuous nav-igation, environment extension and conﬁguration. We also proposed an extended baseline model based on the widely-used cross-modal-alignment (CMA) naviga-tion methods. We ﬁnd that there is still a signiﬁcant gap between the baseline model and human perfor-mance, which suggests AerialVLN is a new challeng-ing task. Dataset and code is available at https://github.com/AirVLN/AirVLN . 