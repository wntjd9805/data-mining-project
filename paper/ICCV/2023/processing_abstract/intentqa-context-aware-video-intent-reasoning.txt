In this paper, we propose a novel task IntentQA, a specialVideoQA task focusing on video intent reasoning, which has become increasingly important for AI with its advantages in equipping AI agents with the capability of reasoning be-yond mere recognition in daily tasks. We also contribute a large-scale VideoQA dataset for this task. We propose aContext-aware Video Intent Reasoning model (CaVIR) con-sisting of i) Video Query Language (VQL) for better cross-modal representation of the situational context, ii) Con-trastive Learning module for utilizing the contrastive con-text, and iii) Commonsense Reasoning module for incor-porating the commonsense context. Comprehensive experi-ments on this challenging task demonstrate the effectiveness of each model component, the superiority of our full model over other baselines, and the generalizability of our model to a new VideoQA task. The dataset and codes are open-sourced at: https://github.com/JoseponLee/IntentQA.git. 