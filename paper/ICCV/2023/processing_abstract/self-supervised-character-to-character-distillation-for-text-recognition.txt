When handling complicated text images (e.g., irregular structures, low resolution, heavy occlusion, and uneven illu-mination), existing supervised text recognition methods are data-hungry. Although these methods employ large-scale synthetic text images to reduce the dependence on anno-tated real images, the domain gap still limits the recog-nition performance. Therefore, exploring the robust text feature representations on unlabeled real images by self-supervised learning is a good solution. However, existing self-supervised text recognition methods conduct sequence-to-sequence representation learning by roughly splitting the visual features along the horizontal axis, which lim-its the flexibility of the augmentations, as large geometric-based augmentations may lead to sequence-to-sequence feature inconsistency. Motivated by this, we propose a novel self-supervised Character-to-Character Distillation method, CCD, which enables versatile augmentations to fa-cilitate general text representation learning. Specifically, we delineate the character structures of unlabeled real im-ages by designing a self-supervised character segmentation module. Following this, CCD easily enriches the diver-sity of local characters while keeping their pairwise align-ment under flexible augmentations, using the transforma-tion matrix between two augmented views from images. Ex-periments demonstrate that CCD achieves state-of-the-art results, with average performance gains of 1.38% in text recognition, 1.7% in text segmentation, 0.24 dB (PSNR) and 0.0321 (SSIM) in text super-resolution. Code is available at https://github.com/TongkunGuan/CCD. 