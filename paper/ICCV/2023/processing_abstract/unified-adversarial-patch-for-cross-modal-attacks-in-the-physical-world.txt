Recently, physical adversarial attacks have been pre-sented to evade DNNs-based object detectors. To ensure the security, many scenarios are simultaneously deployed with visible sensors and infrared sensors, leading to the failures of these single-modal physical attacks. To show the poten-tial risks under such scenes, we propose a unified adversar-ial patch to perform cross-modal physical attacks, i.e., fool-ing visible and infrared object detectors at the same time via a single patch. Considering different imaging mecha-nisms of visible and infrared sensors, our work focuses on modeling the shapes of adversarial patches, which can be captured in different modalities when they change. To this end, we design a novel boundary-limited shape optimiza-tion to achieve the compact and smooth shapes, and thus they can be easily implemented in the physical world. In ad-dition, to balance the fooling degree between visible detec-tor and infrared detector during the optimization process, we propose a score-aware iterative evaluation, which can guide the adversarial patch to iteratively reduce the pre-dicted scores of the multi-modal sensors. We finally test our method against the one-stage detector: YOLOv3 and the two-stage detector: Faster RCNN. Results show that our unified patch achieves an Attack Success Rate (ASR) of 73.33% and 69.17%, respectively. More importantly, we verify the effective attacks in the physical world when visi-ble and infrared sensors shoot the objects under various set-tings like different angles, distances, postures, and scenes. 