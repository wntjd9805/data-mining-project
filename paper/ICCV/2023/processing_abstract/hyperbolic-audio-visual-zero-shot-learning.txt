Audio-visual zero-shot learning aims to classify samples consisting of a pair of corresponding audio and video se-quences from classes that are not present during training.An analysis of the audio-visual data reveals a large de-gree of hyperbolicity, indicating the potential benefit of us-ing a hyperbolic transformation to achieve curvature-aware geometric learning, with the aim of exploring more com-plex hierarchical data structures for this task. The pro-posed approach employs a novel loss function that incor-porates cross-modality alignment between video and audio features in the hyperbolic space. Additionally, we explore the use of multiple adaptive curvatures for hyperbolic pro-jections. The experimental results on this very challenging task demonstrate that our proposed hyperbolic approach for zero-shot learning outperforms the SOTA method on three datasets: VGGSound-GZSL, UCF-GZSL, and ActivityNet-GZSL achieving a harmonic mean (HM) improvement of around 3.0%, 7.0%, and 5.3%, respectively. 