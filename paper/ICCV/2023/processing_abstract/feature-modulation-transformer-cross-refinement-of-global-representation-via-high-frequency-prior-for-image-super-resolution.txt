Transformer-based methods have exhibited remarkable potential in single image super-resolution (SISR) by effec-tively extracting long-range dependencies. However, most of the current research in this area has prioritized the de-sign of transformer blocks to capture global information, while overlooking the importance of incorporating high-frequency priors, which we believe could be beneﬁcial.In our study, we conducted a series of experiments and found that transformer structures are more adept at cap-turing low-frequency information, but have limited capacity in constructing high-frequency representations when com-pared to their convolutional counterparts. Our proposed solution, the cross-reﬁnement adaptive feature modulation transformer (CRAFT), integrates the strengths of both con-volutional and transformer structures. It comprises three key components: the high-frequency enhancement resid-ual block (HFERB) for extracting high-frequency informa-tion, the shift rectangle window attention block (SRWAB) for capturing global information, and the hybrid fusion block (HFB) for reﬁning the global representation. Our experiments on multiple datasets demonstrate that CRAFT outperforms state-of-the-art methods by up to 0.29dB while using fewer parameters. The source code will be made available at: https://github.com/AVC2-UESTC/CRAFT-SR.git. 