Approximately, 350 million people, a proportion of 8%, suffer from color vision deficiency (CVD). While image generation algorithms have been highly successful in syn-thesizing high-quality images, CVD populations are unin-tentionally excluded from target users and have difficul-ties understanding the generated images as normal view-ers do. Although a straightforward baseline can be formed by combining generation models and recolor compensa-tion methods as the post-processing, the CVD friendliness of the result images is still limited since the input image content of recolor methods is not CVD-oriented and will be fixed during the recolor compensation process. Be-sides, the CVD populations can not be fully served since the varying degrees of CVD are often neglected in recol-oring methods. Instead, we propose a personalized CVD-friendly image generation algorithm with two key charac-teristics: (i) generating CVD-oriented images aligned with the needs of CVD populations; (ii) generating continu-ous personalized images for people with various CVD de-grees through disentangling the color representation based on a triple-latent structure. Quantitative and qualita-tive experiments indicate our proposed image generation model can generate practical and compelling results com-pared to the normal generation model and combination baselines on several datasets. The code is available at: https://github.com/Jiangshuyi0V0/CVD-GAN.git 