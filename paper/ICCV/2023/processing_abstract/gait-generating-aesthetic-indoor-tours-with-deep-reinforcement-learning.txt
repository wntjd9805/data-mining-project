Placing and orienting a camera to compose aesthetically meaningful shots of a scene is not only a key objective in real-world photography and cinematography but also for virtual content creation. The framing of a camera often sig-nificantly contributes to the story telling in movies, games, and mixed reality applications. Generating single camera poses or even contiguous trajectories either requires a sig-nificant amount of manual labor or requires solving high-dimensional optimization problems, which can be computa-tionally demanding and error-prone. In this paper, we intro-duce GAIT, a framework for training a Deep ReinforcementLearning (DRL) agent, that learns to automatically control a camera to generate a sequence of aesthetically meaning-ful views for synthetic 3D indoor scenes. To generate se-quences of frames with high aesthetic value, GAIT relies on a neural aesthetics estimator, which is trained on a crowed-sourced dataset. Additionally, we introduce regularization techniques for diversity and smoothness to generate visu-ally interesting trajectories for a 3D environment, and to constrain agent acceleration in the reward function to gen-erate a smooth sequence of camera frames. We validated our method by comparing it to baseline algorithms, based on a perceptual user study, and through ablation studies.Code and visual results are available on the project web-site: https://desaixie.github.io/gait-rl 