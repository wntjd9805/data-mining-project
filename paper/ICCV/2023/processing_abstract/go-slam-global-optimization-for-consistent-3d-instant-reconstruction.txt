Neural implicit representations have recently demon-strated compelling results on dense Simultaneous Localiza-tion And Mapping (SLAM) but suffer from the accumula-tion of errors in camera tracking and distortion in the re-construction. Purposely, we present GO-SLAM, a deep-learning-based dense visual SLAM framework globally op-timizing poses and 3D reconstruction in real-time. Ro-bust pose estimation is at its core, supported by efficient loop closing and online full bundle adjustment, which op-timize per frame by utilizing the learned global geometry of the complete history of input frames. Simultaneously, we update the implicit and continuous surface represen-tation on-the-fly to ensure global consistency of 3D re-construction. Results on various synthetic and real-world datasets demonstrate that GO-SLAM outperforms state-of-the-art approaches at tracking robustness and reconstruc-tion accuracy. Furthermore, GO-SLAM is versatile and can run with monocular, stereo, and RGB-D input. 