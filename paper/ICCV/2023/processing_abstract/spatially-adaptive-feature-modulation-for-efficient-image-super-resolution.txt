Although deep learning-based solutions have achieved impressive reconstruction performance in image super-resolution (SR), these models are generally large, with com-plex architectures, making them incompatible with low-power devices with many computational and memory con-straints.To overcome these challenges, we propose a spatially-adaptive feature modulation (SAFM) mechanism for efficient SR design. In detail, the SAFM layer uses inde-pendent computations to learn multi-scale feature represen-tations and aggregates these features for dynamic spatial modulation. As the SAFM prioritizes exploiting non-local feature dependencies, we further introduce a convolutional channel mixer (CCM) to encode local contextual informa-tion and mix channels simultaneously. Extensive experi-mental results show that the proposed method is 3Ã— smaller than state-of-the-art efficient SR methods, e.g., IMDN, and yields comparable performance with much less memory us-age. Our source codes and pre-trained models are available at: https://github.com/sunny2109/SAFMN . 