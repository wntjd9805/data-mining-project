SPC-basedVisible OccludedQuery PointPartial Coordinate SystemObs. Space LearningLocal Receptive FieldsIn this paper, we focus on the task of generalizable neu-ral human rendering which trains conditional Neural Ra-diance Fields (NeRF) from multi-view videos of different characters. To handle the dynamic human motion, previ-ous methods have primarily used a SparseConvNet (SPC)-based human representation to process the painted SMPL.However, such SPC-based representation i) optimizes un-der the volatile observation space which leads to the pose-misalignment between training and inference stages, and ii) lacks the global relationships among human parts that is critical for handling the incomplete painted SMPL. Tack-ling these issues, we present a brand-new framework namedTransHuman, which learns the painted SMPL under the canonical space and captures the global relationships be-tween human parts with transformers. Speciﬁcally, Tran-sHuman is mainly composed of Transformer-based HumanEncoding (TransHE), Deformable Partial Radiance Fields (DPaRF), and Fine-grained Detail Integration (FDI). Tran-sHE ﬁrst processes the painted SMPL under the canoni-cal space via transformers for capturing the global rela-tionships between human parts. Then, DPaRF binds each output token with a deformable radiance ﬁeld for encoding the query point under the observation space. Finally, theFDI is employed to further integrate ﬁne-grained informa-tion from reference images. Extensive experiments on ZJU-MoCap and H36M show that our TransHuman achieves a signiﬁcantly new state-of-the-art performance with high efﬁciency. Project page: https://pansanity666. github.io/TransHuman/ 