We propose a novel progressive parameter-sharing strat-egy (MPPS) in this paper for effectively training multitask learning models on diverse computer vision tasks simulta-neously. Specifically, we propose to parameterize distribu-tions for different tasks to control the sharings, based on the concept of Exclusive Capacity that we introduce. A schedul-ing mechanism following the concept of curriculum learn-ing is also designed to progressively change the sharing strategy to increase the level of sharing during the learning process. We further propose a novel loss function to reg-ularize the optimization of network parameters as well as the sharing probabilities of each neuron for each task. Our approach can be combined with many state-of-the-art mul-titask learning solutions to achieve better joint task perfor-mance. Comprehensive experiments show that it has com-petitive performance on three challenging datasets (Multi-CIFAR100, NYUv2, and Cityscapes) using various convolu-tion neural network architectures. 