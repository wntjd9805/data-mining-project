While bird’s-eye-view (BEV) perception models can be helpful in building high-definition maps (HD maps) with less human labor, their results are often unreliable and demonstrate noticeable inconsistencies in the predicted HD maps from different viewpoints. This is because BEV per-ception is typically set up in an “onboard” manner, which restricts the computation and prevents algorithms from si-multaneously reasoning multiple views. This paper over-comes these limitations and advocates a more practical“offboard” HD map generation setup that removes the com-putation constraints, based on the fact that HD maps are commonly reusable infrastructures built offline in data cen-ters. To this end, we propose a novel offboard pipeline called MV-Map that capitalizes multi-view consistency and can handle an arbitrary number of frames with the key de-sign of a “region-centric” framework. In MV-Map, the tar-get HD maps are created by aggregating all the frames of onboard predictions, weighted by the confidence scores as-signed by an “uncertainty network.” To further enhance multi-view consistency, we augment the uncertainty net-work with the global 3D structure optimized by a voxelized neural radiance field (Voxel-NeRF). Extensive experiments on nuScenes show that our MV-Map significantly improves the quality of HD maps, further highlighting the importance of offboard methods for HD map generation. Our code and model are available at https : //github.com/ZiYang-xie/MV-Map. 