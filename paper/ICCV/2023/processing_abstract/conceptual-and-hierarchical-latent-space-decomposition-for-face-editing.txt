Generative Adversarial Networks (GANs) can pro-duce photo-realistic results using an unconditional image-generation pipeline. However, the images generated byGANs (e.g., StyleGAN) are entangled in feature spaces, which makes it difficult to interpret and control the con-tents of images.In this paper, we present an encoder-decoder model that decomposes the entangled GAN space into a conceptual and hierarchical latent space in a self-supervised manner. The outputs of 3D morphable face mod-els are leveraged to independently control image synthesis parameters like pose, expression, and illumination. For this purpose, a novel latent space decomposition pipeline is in-troduced using transformer networks and generative mod-els. Later, this new space is used to optimize a transformer-based GAN space controller for face editing. In this work, a StyleGAN2 model for faces is utilized. Since our method manipulates only GAN features, the photo-realism of Style-GAN2 is fully preserved. The results demonstrate that our method qualitatively and quantitatively outperforms base-lines in terms of identity preservation and editing precision. 