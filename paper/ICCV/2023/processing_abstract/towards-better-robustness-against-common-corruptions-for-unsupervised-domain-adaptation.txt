Recent studies have investigated how to achieve robust-ness for unsupervised domain adaptation (UDA). While most efforts focus on adversarial robustness, i.e. how the model performs against unseen malicious adversarial per-turbations, robustness against benign common corruption (RaCC) surprisingly remains under-explored for UDA. To-wards improving RaCC for UDA methods in an unsuper-vised manner, we propose a novel Distributionally and Dis-cretely Adversarial Regularization (DDAR) framework in this paper. Formulated as a min-max optimization with a distribution distance, DDAR1 is theoretically well-founded to ensure generalization over unknown common corrup-tions. Meanwhile, we show that our regularization scheme effectively reduces a surrogate of RaCC, i.e., the perceptual distance between natural data and common corruption. To enable a abetter adversarial regularization, the design of the optimization pipeline relies on an image discretization scheme that can transform ”out-of-distribution” adversar-ial data into “in-distribution” data augmentation. Through extensive experiments, in terms of RaCC, our method is su-perior to conventional unsupervised regularization mech-anisms, widely improves the robustness of existing UDA methods, and achieves state-of-the-art performance. 