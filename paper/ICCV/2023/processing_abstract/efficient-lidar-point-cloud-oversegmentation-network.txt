Point cloud oversegmentation is a challenging task since it needs to produce perceptually meaningful partitions (i.e., superpoints) of a point cloud. Most existing overseg-mentation methods cannot efﬁciently generate superpoints from large-scale LiDAR point clouds due to complex and inefﬁcient procedures. In this paper, we propose a simple yet efﬁcient end-to-end LiDAR oversegmentation network, which segments superpoints from the LiDAR point cloud by grouping points based on low-level point embeddings.Speciﬁcally, we ﬁrst learn the similarity of points from the constructed local neighborhoods to obtain low-level point embeddings through the local discriminative loss.Then, to generate homogeneous superpoints from the sparseLiDAR point cloud, we propose a LiDAR point grouping algorithm that simultaneously considers the similarity of point embeddings and the Euclidean distance of points in 3D space. Finally, we design a superpoint reﬁnement module for accurately assigning the hard boundary points to the corresponding superpoints. Extensive results on two large-scale outdoor datasets, SemanticKITTI and nuScenes, show that our method achieves a new state-of-the-art inLiDAR oversegmentation. Notably, the inference time of our method is 100× faster than that of other methods. Fur-thermore, we apply the learned superpoints to the LiDAR semantic segmentation task and the results show that using superpoints can signiﬁcantly improve the LiDAR semantic segmentation of the baseline network. Code is available at https://github.com/fpthink/SuperLiDAR. 