{}Open-vocabulary models are a promising new paradigm for image classiﬁcation. Unlike traditional classiﬁcation models, open-vocabulary models classify among any arbi-trary set of categories speciﬁed with natural language dur-ing inference. This natural language, called “prompts”, typically consists of a set of hand-written templates (e.g.,“a photo of a”) which are completed with each of the category names. This work introduces a simple method to generate higher accuracy prompts, without relying on any explicit knowledge of the task domain and with far fewer hand-constructed sentences. To achieve this, we com-bine open-vocabulary models with large language models (LLMs) to create Customized Prompts via Language mod-els (CuPL, pronounced “couple”). In particular, we lever-age the knowledge contained in LLMs in order to gener-ate many descriptive sentences that contain important dis-criminating characteristics of the image categories. This allows the model to place a greater importance on these re-gions in the image when making predictions. We ﬁnd that this straightforward and general approach improves accu-racy on a range of zero-shot image classiﬁcation bench-marks, including over one percentage point gain on Ima-geNet. Finally, this simple baseline requires no additional training and remains completely zero-shot. Code available at https://github.com/sarahpratt/CuPL.A photo of a goldﬁshA photo of a platypusA photo of a spatulaImage encoderText encoderWhat does  a platypus  look like? Image encoderA platypus  looks like a  beaver with  a ducks billGoldﬁsh are small orange ﬁsh  with shiny scalesA platypus looks like a beaver  with a ducks billA spatula is a ﬂat rectangular  kitchen utensil with a long  handleText encoder d r a d n a tS t o h s-o r eZ a v i s t p m o rP d e z m o t s uC i)LP uC ( l s e d o m e g a u g n aLFigure 1. Schematic of the method. (Top) The standard method of a zero-shot open-vocabulary image classiﬁcation model (e.g.,CLIP [42]). (Bottom) Our method of CuPL. First, an LLM gener-ates descriptive captions for given class categories. Next, an open-vocabulary model uses these captions as prompts for performing classiﬁcation. 