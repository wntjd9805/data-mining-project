Scene Graph Generation (SGG) aims to detect all the vi-sual relation triplets <sub, pred, obj> in a given image.With the emergence of various advanced techniques for bet-ter utilizing both the intrinsic and extrinsic information in each relation triplet, SGG has achieved great progress over the recent years. However, due to the ubiquitous long-tailed predicate distributions, today’s SGG models are still easily biased to the head predicates. Currently, the most prevalent debiasing solutions for SGG are re-balancing methods, e.g., changing the distributions of original training samples. In this paper, we argue that all existing re-balancing strategies fail to increase the diversity of the relation triplet features of each predicate, which is critical for robust SGG. To this end, we propose a novel Compositional Feature Augmenta-tion (CFA) strategy, which is the ﬁrst unbiased SGG work to mitigate the bias issue from the perspective of increas-ing the diversity of triplet features. Speciﬁcally, we ﬁrst de-compose each relation triplet feature into two components: intrinsic feature and extrinsic feature, which correspond to the intrinsic characteristics and extrinsic contexts of a rela-tion triplet, respectively. Then, we design two different fea-ture augmentation modules to enrich the feature diversity of original relation triplets by replacing or mixing up either their intrinsic or extrinsic features from other samples. Due to its model-agnostic nature, CFA can be seamlessly incor-porated into various SGG frameworks. Extensive ablations have shown that CFA achieves a new state-of-the-art per-formance on the trade-off between different metrics. 