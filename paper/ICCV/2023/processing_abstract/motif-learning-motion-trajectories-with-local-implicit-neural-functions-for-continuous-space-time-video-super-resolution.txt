This work addresses continuous space-time video super-resolution (C-STVSR) that aims to up-scale an input video both spatially and temporally by any scaling factors. One key challenge of C-STVSR is to propagate information tem-porally among the input video frames. To this end, weIt introduce a space-time local implicit neural function. has the striking feature of learning forward motion for a continuum of pixels. We motivate the use of forward mo-tion from the perspective of learning individual motion tra-jectories, as opposed to learning a mixture of motion tra-jectories with backward motion. To ease motion interpo-lation, we encode sparsely sampled forward motion ex-tracted from the input video as the contextual input. Along with a reliability-aware splatting and decoding scheme, our framework, termed MoTIF, achieves the state-of-the-art performance on C-STVSR. The source code of MoTIF is available at https://github.com/sichun233746/MoTIF. 