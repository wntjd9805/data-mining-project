Video snapshot compressive imaging (SCI) aims to cap-ture a sequence of video frames with only a single shot of a 2D detector, whose backbones rest in optical modulation patterns (also known as masks) and a computational recon-struction algorithm. Advanced deep learning algorithms and mature hardware are putting video SCI into practical applications. Yet, there are two clouds in the sunshine ofSCI: i) low dynamic range as a victim of high temporal mul-tiplexing, and ii) existing deep learning algorithms’ degra-dation on real system. To address these challenges, this paper presents a deep optics framework to jointly optimize masks and a reconstruction network. Speciﬁcally, we ﬁrst propose a new type of structural mask to realize motion-aware and full-dynamic-range measurement. Considering the motion awareness property in measurement domain, we develop an efﬁcient network for video SCI reconstruction using Transformer to capture long-term temporal depen-dencies, dubbed Res2former. Moreover, sensor response is introduced into the forward model of video SCI to guaran-tee end-to-end model training close to real system. Finally, we implement the learned structural masks on a digital micro-mirror device. Experimental results on synthetic and real data validate the effectiveness of the proposed frame-work. We believe this is a milestone for real-world videoSCI. The source code and data are available at https://github.com/pwangcs/DeepOpticsSCI. 