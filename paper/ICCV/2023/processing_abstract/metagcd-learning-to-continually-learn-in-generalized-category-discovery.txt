In this paper, we consider a real-world scenario where a model that is trained on pre-defined classes continually en-counters unlabeled data that contains both known and novel classes. The goal is to continually discover novel classes while maintaining the performance in known classes. We name the setting Continual Generalized Category Discov-ery (C-GCD). Existing methods for novel class discovery cannot directly handle the C-GCD setting due to some un-realistic assumptions, such as the unlabeled data only con-taining novel classes. Furthermore, they fail to discoverIn this work, we novel classes in a continual fashion. lift all these assumptions and propose an approach, calledMetaGCD, to learn how to incrementally discover with less forgetting. Our proposed method uses a meta-learning framework and leverages the offline labeled data to simulate the testing incremental learning process. A meta-objective is defined to revolve around two conflicting learning objec-tives to achieve novel class discovery without forgetting.Furthermore, a soft neighborhood-based contrastive net-work is proposed to discriminate uncorrelated images while attracting correlated images. We build strong baselines and conduct extensive experiments on three widely used bench-marks to demonstrate the superiority of our method. 