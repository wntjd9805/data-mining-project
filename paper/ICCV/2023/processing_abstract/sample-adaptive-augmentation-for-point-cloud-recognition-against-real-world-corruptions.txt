Robust 3D perception under corruption has become an essential task for the realm of 3D vision. While current data augmentation techniques usually perform random transfor-mations on all point cloud objects in an ofﬂine way and ignore the structure of the samples, resulting in over-or-under enhancement.In this work, we propose an alter-native to make sample-adaptive transformations based on the structure of the sample to cope with potential corrup-tion via an auto-augmentation framework, named as Adapt-Point. Specially, we leverage a imitator, consisting of aDeformation Controller and a Mask Controller, respec-tively in charge of predicting deformation parameters and producing a per-point mask, based on the intrinsic struc-tural information of the input point cloud, and then con-duct corruption simulations on top. Then a discriminator is utilized to prevent the generation of excessive corrup-In tion that deviates from the original data distribution. addition, a perception-guidance feedback mechanism is in-corporated to guide the generation of samples with appro-priate difﬁculty level. Furthermore, to address the paucity of real-world corrupted point cloud, we also introduce a new dataset ScanObjectNN-C, that exhibits greater simi-larity to actual data in real-world environments, especially when contrasted with preceding CAD datasets. Experi-ments show that our method achieves state-of-the-art results on multiple corruption benchmarks, including ModelNet-C, our ScanObjectNN-C, and ShapeNet-C. 