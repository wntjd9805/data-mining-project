We present a novel method for populating 3D indoor scenes with virtual humans that can navigate in the environ-ment and interact with objects in a realistic manner. Exist-ing approaches rely on high-quality training sequences that contain captured human motions and the 3D scenes they in-teract with. However, such interaction data are costly, diffi-cult to capture, and can hardly cover the full range of plau-sible human-scene interactions in complex indoor environ-ments. To address these challenges, we propose a reinforce-ment learning-based approach that enables virtual humans to navigate in 3D scenes and interact with objects realisti-cally and autonomously, driven by learned motion control policies. The motion control policies employ latent motion action spaces, which correspond to realistic motion primi-tives and are learned from large-scale motion capture data using a powerful generative motion model. For naviga-tion in a 3D environment, we propose a scene-aware policy 1 with novel state and reward designs for collision avoidance.Combined with navigation mesh-based path-finding algo-rithms to generate intermediate waypoints, our approach enables the synthesis of diverse human motions navigat-ing in 3D indoor scenes and avoiding obstacles. To gener-ate fine-grained human-object interactions, we carefully cu-rate interaction goal guidance using a marker-based body representation and leverage features based on the signed distance field (SDF) to encode human-scene proximity re-lations. Our method can synthesize realistic and diverse human-object interactions (e.g., sitting on a chair and then getting up) even for out-of-distribution test scenarios with different object shapes, orientations, starting body posi-tions, and poses. Experimental results demonstrate that our approach outperforms state-of-the-art human-scene inter-action synthesis methods in terms of both motion natural-ness and diversity. Code, models, and demonstrative video results are available at: https://zkf1997.github.io/DIMOS.