This paper aims to develop an accurate 3D geometry representation of satellite images using satellite-ground im-age pairs. Our focus is on the challenging problem of 3D-aware ground-views synthesis from a satellite image.We draw inspiration from the density field representation used in volumetric neural rendering and propose a new ap-proach, called Sat2Density. Our method utilizes the prop-erties of ground-view panoramas for the sky and non-sky regions to learn faithful density fields of 3D scenes in a geometric perspective. Unlike other methods that require extra depth information during training, our Sat2Density can automatically learn accurate and faithful 3D geom-etry via density representation without depth supervision.This advancement significantly improves the ground-view panorama synthesis task. Additionally, our study provides a new geometric perspective to understand the relationship between satellite and ground-view images in 3D space. 