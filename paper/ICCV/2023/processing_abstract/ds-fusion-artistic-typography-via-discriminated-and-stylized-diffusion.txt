We introduce a novel method to automatically generate an artistic typography by stylizing one or more letter fonts to visually convey the semantics of an input word, while ensuring that the output remains readable. To address an assortment of challenges with our task at hand including conflicting goals (artistic stylization vs. legibility), lack of ground truth, and immense search space, our approach uti-lizes large language models to bridge texts and visual im-ages for stylization and build an unsupervised generative model with a diffusion model backbone. Specifically, we employ the denoising generator in Latent Diffusion Model (LDM), with the key addition of a CNN-based discriminator to adapt the input style onto the input text. The discrimina-tor uses rasterized images of a given letter/word font as real samples and the output of the denoising generator as fake samples. Our model is coined DS-Fusion for discriminated and stylized diffusion. We showcase the quality and versa-tility of our method through numerous examples, qualita-tive and quantitative evaluation, and ablation studies. User studies comparing to strong baselines including CLIPDraw,DALL-E 2, Stable Diffusion, as well as artist-crafted ty-pographies, demonstrate strong performance of DS-Fusion.Code is available at https://ds-fusion.github.io/. 