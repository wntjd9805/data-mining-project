Active learning (AL) aims to select the most useful data samples from an unlabeled data pool and annotate them to expand the labeled dataset under a limited budget. Espe-cially, uncertainty-based methods choose the most uncer-tain samples, which are known to be effective in improving model performance. However, previous methods often over-look training dynamics (TD), defined as the ever-changing model behavior during optimization via stochastic gradi-ent descent, even though other research areas have empir-ically shown that TD provides important clues for measur-ing the data uncertainty. In this paper, we first provide the-oretical and empirical evidence to argue the usefulness of utilizing the ever-changing model behavior rather than the fully trained model snapshot. We then propose a novel AL method, Training Dynamics for Active Learning (TiDAL), which efficiently predicts the training dynamics of unla-beled data to estimate their uncertainty. Experimental re-sults show that our TiDAL achieves better or comparable performance on both balanced and imbalanced benchmark datasets compared to state-of-the-art AL methods, which es-timate data uncertainty using only static information after model training. 