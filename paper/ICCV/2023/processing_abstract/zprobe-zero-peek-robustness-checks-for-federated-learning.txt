Privacy-preserving federated learning allows multiple users to jointly train a model with coordination of a central server. The server only learns the ﬁnal aggregation result, thereby preventing leakage of the users’ (private) training data from the individual model updates. However, keep-ing the individual updates private allows malicious users to degrade the model accuracy without being detected, also known as Byzantine attacks. Best existing defenses againstByzantine workers rely on robust rank-based statistics, e.g., setting robust bounds via the median of updates, to ﬁnd ma-licious updates. However, implementing privacy-preserving rank-based statistics, especially median-based, is nontrivial and unscalable in the secure domain, as it requires sorting of all individual updates. We establish the ﬁrst private robust-ness check that uses high break point rank-based statistics on aggregated model updates. By exploiting randomized clustering, we signiﬁcantly improve the scalability of our defense without compromising privacy. We leverage the derived statistical bounds in zero-knowledge proofs to de-tect and remove malicious updates without revealing the private user updates. Our novel framework, zPROBE, en-ables Byzantine resilient and secure federated learning. We show the effectiveness of zPROBE on several computer vi-sion benchmarks. Empirical evaluations demonstrate that zPROBE provides a low overhead solution to defend against state-of-the-art Byzantine attacks while preserving privacy. 