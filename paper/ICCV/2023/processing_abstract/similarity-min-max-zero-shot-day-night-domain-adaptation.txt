Low-light conditions not only hamper human visual ex-perience but also degrade the model’s performance on downstream vision tasks. While existing works make re-markable progress on day-night domain adaptation, they rely heavily on domain knowledge derived from the task-specific nighttime dataset. This paper challenges a more complicated scenario with border applicability, i.e., zero-shot day-night domain adaptation, which eliminates re-liance on any nighttime data. Unlike prior zero-shot adap-tation approaches emphasizing either image-level transla-tion or model-level adaptation, we propose a similarity min-max paradigm that considers them under a unified frame-work. On the image level, we darken images towards mini-mum feature similarity to enlarge the domain gap. Then on the model level, we maximize the feature similarity between the darkened images and their normal-light counterparts for better model adaptation. To the best of our knowledge, this work represents the pioneering effort in jointly optimiz-ing both levels, resulting in a significant improvement of model generalizability. Extensive experiments demonstrate our method’s effectiveness and broad applicability on vari-ous nighttime vision tasks, including classification, seman-tic segmentation, visual place recognition, and video action recognition. Our project page is available at https:// red-fairy.github.io/ZeroShotDayNightDA-Webpage/. 