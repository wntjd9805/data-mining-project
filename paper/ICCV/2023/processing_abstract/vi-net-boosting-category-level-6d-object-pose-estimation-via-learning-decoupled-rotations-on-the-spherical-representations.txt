Rotation estimation of high precision from an RGB-D object observation is a huge challenge in 6D object pose es-timation, due to the difficulty of learning in the non-linear space of SO(3).In this paper, we propose a novel rota-tion estimation network, termed as VI-Net, to make the task easier by decoupling the rotation as the combination of a viewpoint rotation and an in-plane rotation. More specifi-cally, VI-Net bases the feature learning on the sphere with two individual branches for the estimates of two factorized rotations, where a V-Branch is employed to learn the view-point rotation via binary classification on the spherical sig-nals, while another I-Branch is used to estimate the in-plane rotation by transforming the signals to view from the zenith direction. To process the spherical signals, a Spherical Fea-ture Pyramid Network is constructed based on a novel de-sign of SPAtial Spherical Convolution (SPA-SConv), which settles the boundary problem of spherical signals via fea-ture padding and realizes viewpoint-equivariant feature ex-traction by symmetric convolutional operations. We apply the proposed VI-Net to the challenging task of category-level 6D object pose estimation for predicting the poses of unknown objects without available CAD models; exper-iments on the benchmarking datasets confirm the efficacy of our method, which outperforms the existing ones with a large margin in the regime of high precision. 