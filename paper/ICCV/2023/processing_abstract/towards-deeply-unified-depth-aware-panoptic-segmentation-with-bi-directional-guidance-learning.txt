Depth-aware panoptic segmentation is an emerging topic in computer vision which combines semantic and ge-ometric understanding for more robust scene interpreta-tion. Recent works pursue unified frameworks to tackle this challenge but mostly still treat it as two individual learn-ing tasks, which limits their potential for exploring cross-domain information. We propose a deeply unified frame-work for depth-aware panoptic segmentation, which per-forms joint segmentation and depth estimation both in a per-segment manner with identical object queries. To narrow the gap between the two tasks, we further design a geomet-ric query enhancement method, which is able to integrate scene geometry into object queries using latent represen-tations. In addition, we propose a bi-directional guidance learning approach to facilitate cross-task feature learning by taking advantage of their mutual relations. Our method sets the new state of the art for depth-aware panoptic seg-mentation on both Cityscapes-DVPS and SemKITTI-DVPS datasets. Moreover, our guidance learning approach is shown to deliver performance improvement even under in-complete supervision labels. Code and models are avail-able at https://github.com/jwh97nn/DeepDPS. 