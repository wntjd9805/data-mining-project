Multi-class cell nuclei detection is a fundamental pre-It is critical requisite in the diagnosis of histopathology. to efficiently locate and identify cells with diverse morphol-ogy and distributions in digital pathological images. Most existing methods take complex intermediate representations as learning targets and rely on inflexible post-refinements while paying less attention to various cell density and fields of view. In this paper, we propose a novel Affine-ConsistentTransformer (AC-Former), which directly yields a sequence of nucleus positions and is trained collaboratively through two sub-networks, a global and a local network. The lo-cal branch learns to infer distorted input images of smaller scales while the global network outputs the large-scale pre-dictions as extra supervision signals. We further introduce an Adaptive Affine Transformer (AAT) module, which can automatically learn the key spatial transformations to warp original images for local network training. The AAT module works by learning to capture the transformed image regions that are more valuable for training the model. Experimental results demonstrate that the proposed method significantly outperforms existing state-of-the-art algorithms on various benchmarks. 