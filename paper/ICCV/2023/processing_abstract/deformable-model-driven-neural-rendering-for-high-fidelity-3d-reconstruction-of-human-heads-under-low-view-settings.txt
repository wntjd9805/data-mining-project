Reconstructing 3D human heads in low-view settings presents technical challenges, mainly due to the pronounced risk of overﬁtting with limited views and high-frequency sig-nals. To address this, we propose geometry decomposition and adopt a two-stage, coarse-to-ﬁne training strategy, al-lowing for progressively capturing high-frequency geomet-ric details. We represent 3D human heads using the zero level-set of a combined signed distance ﬁeld, comprising a smooth template, a non-rigid deformation, and a high-frequency displacement ﬁeld. The template captures fea-tures that are independent of both identity and expression and is co-trained with the deformation network across mul-tiple individuals with sparse and randomly selected views.The displacement ﬁeld, capturing individual-speciﬁc de-tails, undergoes separate training for each person. Our network training does not require 3D supervision or object masks. Experimental results demonstrate the effectiveness and robustness of our geometry decomposition and two-stage training strategy. Our method outperforms existing neural rendering approaches in terms of reconstruction ac-curacy and novel view synthesis under low-view settings.Moreover, the pre-trained template serves a good initializa-tion for our model when encountering unseen individuals. 