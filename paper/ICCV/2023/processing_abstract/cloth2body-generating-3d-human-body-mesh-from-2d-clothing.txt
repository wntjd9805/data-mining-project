In this paper, we define and study a new Cloth2Body problem which has a goal of generating 3d human body meshes from a 2D clothing image. Unlike the existing human mesh recovery problem, Cloth2Body needs to ad-dress new and emerging challenges raised by the partial observation of the input and the high diversity of the out-put. Indeed, there are three specific challenges. First, how to locate and pose human bodies into the clothes. Sec-ond, how to effectively estimate body shapes out of vari-ous clothing types. Finally, how to generate diverse and plausible results from a 2D clothing image. To this end, we propose an end-to-end framework that can accurately estimate 3D body mesh parameterized by pose and shape from a 2D clothing image. Along this line, we first utilizeKinematics-aware Pose Estimation to estimate body pose parameters. 3D skeleton is employed as a proxy followed*Work partially conducted during an internship at ZMO AI Inc.â€ Corresponding author by an inverse kinematics module to boost the estimation accuracy. We additionally design an adaptive depth trick to align the re-projected 3D mesh better with 2D clothing image by disentangling the effects of object size and cam-era extrinsic. Next, we propose Physics-informed ShapeEstimation to estimate body shape parameters. 3D shape parameters are predicted based on partial body measure-ments estimated from RGB image, which not only improves pixel-wise human-cloth alignment, but also enables flexi-ble user editing. Finally, we design Evolution-based pose generation method, a skeleton transplanting method in-spired by genetic algorithms to generate diverse reasonable poses during inference. As shown by experimental results on both synthetic and real-world data, the proposed frame-work achieves state-of-the-art performance and can effec-tively recover natural and diverse 3D body meshes from 2D images that align well with clothing.