Q: “a woman wearing the cream color dress and cutting cake with a man”Existing Referring Image Segmentation (RIS) methods typically require expensive pixel-level or box-level annota-tions for supervision.In this paper, we observe that the referring texts used in RIS already provide sufficient in-formation to localize the target object. Hence, we pro-pose a novel weakly-supervised RIS framework to formu-late the target localization problem as a classification pro-cess to differentiate between positive and negative text ex-pressions. While the referring text expressions for an image are used as positive expressions, the referring text expres-sions from other images can be used as negative expressions for this image. Our framework has three main novelties.First, we propose a bilateral prompt method to facilitate the classification process, by harmonizing the domain discrep-ancy between visual and linguistic features. Second, we propose a calibration method to reduce noisy background information and improve the correctness of the response maps for target object localization. Third, we propose a positive response map selection strategy to generate high-quality pseudo-labels from the enhanced response maps, for training a segmentation network for RIS inference. For evaluation, we propose a new metric to measure localiza-tion accuracy. Experiments on four benchmarks show that our framework achieves promising performances to existing fully-supervised RIS methods while outperforming state-of-the-art weakly-supervised methods adapted from related ar-eas. Code is available at https://github.com/fawnliu/TRIS. 