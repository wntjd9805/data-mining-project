This paper presents CORE, a conceptually simple, ef-fective and communication-efficient model for multi-agent cooperative perception. It addresses the task from a novel perspective of cooperative reconstruction, based on two key insights: 1) cooperating agents together provide a more holistic observation of the environment, and 2) the holis-tic observation can serve as valuable supervision to explic-itly guide the model learning how to reconstruct the ideal observation based on collaboration. CORE instantiates the idea with three major components: a compressor for each agent to create more compact feature representation for efficient broadcasting, a lightweight attentive collab-oration component for cross-agent message aggregation, and a reconstruction module to reconstruct the observation based on aggregated feature representations. This learning-to-reconstruct idea is task-agnostic, and offers clear and reasonable supervision to inspire more effective collabora-tion, eventually promoting perception tasks. We validateCORE on two large-scale multi-agent percetion dataset,OPV2V and V2X-Sim, in two tasks, i.e., 3D object detec-tion and semantic segmentation. Results demonstrate thatCORE achieves state-of-the-art performance, and is more communication-efficient. 