Planar object tracking is a critical computer vision prob-lem and has drawn increasing interest owing to its key roles in robotics, augmented reality, etc. Despite rapid progress, its further development, especially in the deep learning era, is largely hindered due to the lack of large-scale challenging benchmarks. Addressing this, we introduce PlanarTrack, a large-scale challenging planar tracking benchmark. Specif-ically, PlanarTrack consists of 1,000 videos with more than 490K images. All these sequences are collected in complex unconstrained scenarios from the wild, which makes Pla-narTrack, compared with existing benchmarks, more chal-lenging but realistic for real-world applications. To ensure the high-quality annotation, each frame in PlanarTrack is manually labeled using four corners with multiple-round careful inspection and refinement. To our best knowledge,PlanarTrack, to date, is the largest and the most challeng-ing dataset dedicated to planar object tracking. In order to analyze the proposed PlanarTrack, we evaluate 10 planar trackers and conduct comprehensive comparisons and in-depth analysis. Our results, not surprisingly, demonstrate that current top-performing planar trackers degenerate sig-nificantly on the challenging PlanarTrack and more efforts are needed to improve planar tracking in the future. In ad-dition, we further derive a variant named PlanarTrackBB for generic object tracking from our PlanarTrack. Our eval-uation of 10 excellent generic trackers on PlanarTrackBB manifests that, surprisingly, PlanarTrackBB is even more challenging than several popular generic tracking bench-marks and more attention should be paid to handle such planar objects, though they are rigid. All benchmarks and evaluations are released at https://hengfan2010. github.io/projects/PlanarTrack/.∗The authors make equal contributions and are co-first authors.†Corresponding author: Libo Zhang (libo@iscas.ac.cn).Figure 1. Generic object tracking (a) and planar object tracking (b).The former estimates axis-aligned rectangular bounding boxes for the target object, while the latter (our focus in this work) calculates 2D transformations of the target object to obtain the corresponding corner points for localization. All figures throughout this paper are best viewed in color and by zooming in. 