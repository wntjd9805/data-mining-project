Recent studies show that self-attentions behave like low-pass filters (as opposed to convolutions) and enhancing their high-pass filtering capability improves model per-formance. Contrary to this idea, we investigate existing convolution-based models with spectral analysis and ob-serve that improving the low-pass filtering in convolution operations also leads to performance improvement. To ac-count for this observation, we hypothesize that utilizing op-timal token mixers that capture balanced representations of both high- and low-frequency components can enhance the performance of models. We verify this by decompos-ing visual features into the frequency domain and combin-ing them in a balanced manner. To handle this, we re-place the balancing problem with a mask filtering problem in the frequency domain. Then, we introduce a novel token-mixer named SPAM and leverage it to derive a MetaFormer model termed as SPANet. Experimental results show that the proposed method provides a way to achieve this bal-ance, and the balanced representations of both high- and low-frequency components can improve the performance of models on multiple computer vision tasks. Our code is available at https://doranlyong.github.io/projects/spanet/. 