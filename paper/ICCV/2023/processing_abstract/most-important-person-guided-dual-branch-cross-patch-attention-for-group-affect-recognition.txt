Group affect refers to the subjective emotion that is evoked by an external stimulus in a group, which is an im-portant factor that shapes group behavior and outcomes.Recognizing group affect involves identifying important in-dividuals and salient objects among a crowd that can evoke emotions. However, most existing methods lack attention to affective meaning in group dynamics and fail to ac-count for the contextual relevance of faces and objects in group-level images.In this work, we propose a solution by incorporating the psychological concept of the Most Im-portant Person (MIP), which represents the most notewor-thy face in a crowd and has affective semantic meaning.We present the Dual-branch Cross-Patch Attention Trans-former (DCAT) which uses global image and MIP together as inputs. Specifically, we first learn the informative fa-cial regions produced by the MIP and the global context separately. Then, the Cross-Patch Attention module is pro-posed to fuse the features of MIP and global context to-gether to complement each other. Our proposed method outperforms state-of-the-art methods on GAF 3.0, GroupE-moW, and HECO datasets. Moreover, we demonstrate the potential for broader applications by showing that our pro-posed model can be transferred to another group affect task, group cohesion, and achieve comparable results.Global + All 3Random 3MIPs 1Random MIPAcc (%) 85.01 85.47 87.46 82.30 88.86Table 1. Different face selection strategies. The “3Random” refers to selecting 3 faces randomly from the detected faces in the im-age, while the “3MIPs” strategy selects the top three detected faces based on their importance ranking. The dataset evaluated here is the GroupEmoW [22]. or group-level emotion [2] 1.Figure 1. Feature map comparison between using MIP and all faces. The yellow box in (a) represents the MIP region. 