Self-supervised learning (SSL) methods targeting scene images have seen a rapid growth recently, and they mostly rely on either a dedicated dense matching mechanism or a costly unsupervised object discovery module. This pa-per shows that instead of hinging on these strenuous opera-tions, quality image representations can be learned by treat-ing scene/multi-label image SSL simply as a multi-label classification problem, which greatly simplifies the learn-ing framework. Specifically, multiple binary pseudo-labels are assigned for each input image by comparing its em-beddings with those in two dictionaries, and the network is optimized using the binary cross entropy loss. The pro-posed method is named Multi-Label Self-supervised learn-ing (MLS). Visualizations qualitatively show that clearly the pseudo-labels by MLS can automatically find semantically similar pseudo-positive pairs across different images to fa-cilitate contrastive learning. MLS learns high quality rep-resentations on MS-COCO and achieves state-of-the-art re-sults on classification, detection and segmentation bench-marks. At the same time, MLS is much simpler than existing methods, making it easier to deploy and for further explo-ration. 