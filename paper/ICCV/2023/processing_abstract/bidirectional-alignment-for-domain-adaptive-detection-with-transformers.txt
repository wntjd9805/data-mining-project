We propose a Bidirectional Alignment for domain adap-tive Detection with Transformers (BiADT) to improve cross domain object detection performance. Existing adversarial learning based methods use gradient reverse layer (GRL) to reduce the domain gap between the source and target domains in feature representations. Since different image parts and objects may exhibit various degrees of domain-specific characteristics, directly applying GRL on a global image or object representation may not be suitable. Our proposed BiADT explicitly estimates token-wise domain-invariant and domain-specific features in the image and ob-ject token sequences. BiADT has a novel deformable at-tention and self-attention, aimed at bi-directional domain alignment and mutual information minimization. These two objectives reduce the domain gap in domain-invariant representations, and simultaneously increase the distinc-tiveness of domain-specific features. Our experiments show that BiADT achieves very competitive performance to SOTA consistently on Cityscapes-to-FoggyCityscapes,Sim10K-to-Citiscapes and Cityscapes-to-BDD100K, out-performing the strong baseline, AQT, by 2.0, 2.1, and 2.4 in mAP50, respectively. The implementation is available at https://github.com/helq2612/biADT 