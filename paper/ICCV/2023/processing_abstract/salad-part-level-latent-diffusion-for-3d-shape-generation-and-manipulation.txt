We present a cascaded diffusion model based on a part-level implicit 3D representation. Our model achieves state-of-the-art generation quality and also enables part-level shape editing and manipulation without any addi-tional training in conditional setup. Diffusion models have demonstrated impressive capabilities in data generation as well as zero-shot completion and editing via a guided re-verse process. Recent research on 3D diffusion models has focused on improving their generation capabilities with var-ious data representations, while the absence of structural information has limited their capability in completion and editing tasks. We thus propose our novel diffusion model us-ing a part-level implicit representation. To effectively learn diffusion with high-dimensional embedding vectors of parts, we propose a cascaded framework, learning diffusion first on a low-dimensional subspace encoding extrinsic param-eters of parts and then on the other high-dimensional sub-space encoding intrinsic attributes. In the experiments, we demonstrate the outperformance of our method compared with the previous ones both in generation and part-level completion and manipulation tasks. Our project page is https://salad3d.github.io. 