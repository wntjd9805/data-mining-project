Denoising diffusion models (DDMs) have attracted at-tention for their exceptional generation quality and diver-sity. This success is largely attributed to the use of class- or text-conditional diffusion guidance methods, such as classi-fier and classifier-free guidance. In this paper, we present a more comprehensive perspective that goes beyond the tra-ditional guidance methods. From this generalized perspec-tive, we introduce novel condition- and training-free strate-gies to enhance the quality of generated images. As a sim-ple solution, blur guidance improves the suitability of inter-mediate samples for their fine-scale information and struc-tures, enabling diffusion models to generate higher quality samples with a moderate guidance scale. Improving upon this, Self-Attention Guidance (SAG) uses the intermediate self-attention maps of diffusion models to enhance their sta-bility and efficacy. Specifically, SAG adversarially blurs only the regions that diffusion models attend to at each it-eration and guides them accordingly. Our experimental re-sults show that our SAG improves the performance of vari-ous diffusion models, including ADM, IDDPM, Stable Dif-fusion, and DiT. Moreover, combining SAG with conven-tional guidance methods leads to further improvement. 