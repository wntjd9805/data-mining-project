Semantic segmentation has made significant progress in recent years thanks to deep neural networks, but the com-mon objective of generating a single segmentation output that accurately matches the imageâ€™s content may not be suitable for safety-critical domains such as medical diag-nostics and autonomous driving.Instead, multiple possi-ble correct segmentation maps may be required to reflect the true distribution of annotation maps.In this context, stochastic semantic segmentation methods must learn to predict conditional distributions of labels given the image, but this is challenging due to the typically multimodal distri-butions, high-dimensional output spaces, and limited anno-tation data. To address these challenges, we propose a con-ditional categorical diffusion model (CCDM) for seman-tic segmentation based on Denoising Diffusion Probabilis-tic Models. Our model is conditioned to the input image, enabling it to generate multiple segmentation label maps that account for the aleatoric uncertainty arising from di-vergent ground truth annotations. Our experimental results show that CCDM achieves state-of-the-art performance onLIDC, a stochastic semantic segmentation dataset, and out-performs established baselines on the classical segmenta-tion dataset Cityscapes. 