In this paper, a novel Diffusion-based 3D Pose esti-mation (D3DP) method with Joint-wise reProjection-basedMulti-hypothesis Aggregation (JPMA) is proposed for prob-abilistic 3D human pose estimation. On the one hand,D3DP generates multiple possible 3D pose hypotheses for a single 2D observation. It gradually diffuses the ground truth 3D poses to a random distribution, and learns a de-noiser conditioned on 2D keypoints to recover the uncon-taminated 3D poses. The proposed D3DP is compatible with existing 3D pose estimators and supports users to balance efficiency and accuracy during inference through two customizable parameters. On the other hand, JPMA is proposed to assemble multiple hypotheses generated byD3DP into a single 3D pose for practical use.It repro-jects 3D pose hypotheses to the 2D camera plane, selects the best hypothesis joint-by-joint based on the reprojec-tion errors, and combines the selected joints into the fi-nal pose. The proposed JPMA conducts aggregation at the joint level and makes use of the 2D prior informa-tion, both of which have been overlooked by previous ap-proaches. Extensive experiments on Human3.6M and MPI-INF-3DHP datasets show that our method outperforms the state-of-the-art deterministic and probabilistic approaches by 1.5% and 8.9%, respectively. Code is available at https://github.com/paTRICK-swk/D3DP. 