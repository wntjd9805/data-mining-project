One of the main challenges in LiDAR-based 3D ob-ject detection is that the sensors often fail to capture the complete spatial information about the objects due to long distance and occlusion. Two-stage detectors with point cloud completion approaches tackle this problem by adding more points to the regions of interest (RoIs) with a pre-trained network. However, these methods generate dense point clouds of objects for all region proposals, assum-ing that objects always exist in the RoIs. This leads to the indiscriminate point generation for incorrect propos-als as well. Motivated by this, we propose Point Gen-eration R-CNN (PG-RCNN), a novel end-to-end detector that generates semantic surface points of foreground ob-jects for accurate detection. Our method uses a jointly trained RoI point generation module to process the contex-tual information of RoIs and estimate the complete shape and displacement of foreground objects. For every gen-erated point, PG-RCNN assigns a semantic feature that indicates the estimated foreground probability. Extensive experiments show that the point clouds generated by our method provide geometrically and semantically rich infor-mation for reﬁning false positive and misaligned propos-als. PG-RCNN achieves competitive performance on theKITTI benchmark, with signiﬁcantly fewer parameters than state-of-the-art models. The code is available at https://github.com/quotation2520/PG-RCNN . 