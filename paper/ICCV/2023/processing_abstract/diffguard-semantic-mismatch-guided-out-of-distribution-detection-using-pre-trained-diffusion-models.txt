Given a classifier, the inherent property of semantic Out-of-Distribution (OOD) samples is that their contents differ from all legal classes in terms of semantics, namely seman-tic mismatch. There is a recent work that directly applies it to OOD detection, which employs a conditional GenerativeAdversarial Network (cGAN) to enlarge semantic mismatch in the image space. While achieving remarkable OOD de-tection performance on small datasets, it is not applicable to IMAGENET-scale datasets due to the difficulty in training cGANs with both input images and labels as conditions.As diffusion models are much easier to train and amenable to various conditions compared to cGANs, in this work, we propose to directly use pre-trained diffusion mod-els for semantic mismatch-guided OOD detection, namedDIFFGUARD. Specifically, given an OOD input image and the predicted label from the classifier, we try to enlarge the semantic difference between the reconstructed OOD image under these conditions and the original input im-age. We also present several test-time techniques to further strengthen such differences. Experimental results show thatDIFFGUARD is effective on both CIFAR-10 and hard cases of the large-scale IMAGENET, and it can be easily com-bined with existing OOD detection techniques to achieve state-of-the-art OOD detection results. 