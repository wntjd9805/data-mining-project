Deep neural networks are valuable assets considering their commercial benefits and huge demands for costly an-notation and computation resources. To protect the copy-right of DNNs, backdoor-based ownership verification be-comes popular recently, in which the model owner can watermark the model by embedding a specific backdoor behavior before releasing it. The defenders (usually the model owners) can identify whether a suspicious third-party model is “stolen” from them based on the pres-ence of the behavior. Unfortunately, these watermarks are proven to be vulnerable to removal attacks even like fine-tuning. To further explore this vulnerability, we investigate the parameter space and find there exist many watermark-removed models in the vicinity of the watermarked one, which may be easily used by removal attacks.Inspired by this finding, we propose a mini-max formulation to find these watermark-removed models and recover their water-mark behavior. Extensive experiments demonstrate that our method improves the robustness of the model watermark-ing against parametric changes and numerous watermark-removal attacks.The codes for reproducing our main experiments are available at https://github.com/GuanhaoGan/robust-model-watermarking. 