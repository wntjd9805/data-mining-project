Understanding the visual world from human perspec-tives has been a long-standing challenge in computer vi-sion. Egocentric videos exhibit high scene complexity and irregular motion flows compared to typical video un-derstanding tasks. With the egocentric domain in mind, we address the problem of self-supervised, class-agnostic object detection, aiming to locate all objects in a given view, without any annotations or pre-trained weights. Our method, self-supervised object detection from egocentric videos (DEVI), generalizes appearance-based methods to learn features end-to-end that are category-specific and in-variant to viewing angle and illumination. Our approach leverages natural human behavior in egocentric percep-tion to sample diverse views of objects for our multi-view and scale-regression losses, and our cluster residual mod-ule learns multi-category patches for complex scene under-standing. DEVI results in gains up to 4.11% AP50, 0.11%AR1, 1.32% AR10, and 5.03% AR100 on recent egocen-tric datasets, while significantly reducing model complexity.We also demonstrate competitive performance on out-of-domain datasets without additional training or fine-tuning. 