els are better at recognizing tail entities.Large-scale multi-modal pre-training models such asCLIP [30] and PaLI [8] exhibit strong generalization on various visual domains and tasks. However, existing image classiﬁcation benchmarks often evaluate recognition on a speciﬁc domain (e.g., outdoor images) or a speciﬁc task (e.g., classifying plant species), which falls short of evaluat-ing whether pre-trained foundational models are universal visual recognizers. To address this, we formally present the task of Open-domain Visual Entity recognitioN (OVEN), where a model need to link an image onto a Wikipedia entity with respect to a text query. We construct OVEN-Wiki ‡ by re-purposing 14 existing datasets with all labels grounded onto one single label space: Wikipedia entities. OVEN-Wiki chal-lenges models to select among six million possible Wikipedia entities, making it a general visual recognition benchmark with the largest number of labels. Our study on state-of-the-art pre-trained models reveals large headroom in gen-eralizing to the massive-scale label space. We show that a PaLI-based auto-regressive visual recognition model per-forms surprisingly well, even on Wikipedia entities that have never been seen during ﬁne-tuning. We also ﬁnd existing pre-trained models yield different strengths: while PaLI-based models obtain higher overall performance, CLIP-based mod-