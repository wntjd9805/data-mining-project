We tackle the data scarcity challenge in few-shot point cloud recognition of 3D objects by using a joint prediction from a conventional 3D model and a well-trained 2D model.Surprisingly, such an ensemble, though seems trivial, has hardly been shown effective in recent 2D-3D models. We find out the crux is the less effective training for the “joint hard samples”, which have high confidence prediction on different wrong labels, implying that the 2D and 3D models do not collaborate well. To this end, our proposed invariant training strategy, called INVJOINT, does not only empha-size the training more on the hard samples, but also seeks the invariance between the conflicting 2D and 3D ambigu-ous predictions.INVJOINT can learn more collaborative 2D and 3D representations for better ensemble. Extensive experiments on 3D shape classification with widely adoptedModelNet10/40, ScanObjectNN and Toys4K, and shape re-trieval with ShapeNet-Core validate the superiority of ourINVJOINT. Codes will be publicly Available 1.Figure 1. Comparisons of our framework with existing 2D-3D methods, which can be categorized into (a) Directly projecting point cloud into multi-view images as inputs, and then fine-tuning the 2D models with a frozen backbone. (b) Indirectly leveraging the 2D pretrained knowledge as a constraint or supervision, trans-ferring them via knowledge distillation or contrastive learning, and then only using the optimized 3D pathway for prediction. (c) In contrast, our INVJOINT, based on ensemble paradigm, makes the best of the 2D and 3D worlds by joint prediction in inference. 