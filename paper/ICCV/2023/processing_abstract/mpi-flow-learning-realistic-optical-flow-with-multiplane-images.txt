The accuracy of learning-based optical flow estimation models heavily relies on the realism of the training datasets.Current approaches for generating such datasets either em-ploy synthetic data or generate images with limited real-ism. However, the domain gap of these data with real-world scenes constrains the generalization of the trained model to real-world applications. To address this issue, we inves-tigate generating realistic optical flow datasets from real-world images. Firstly, to generate highly realistic new im-ages, we construct a layered depth representation, known as multiplane images (MPI), from single-view images. This allows us to generate novel view images that are highly re-alistic. To generate optical flow maps that correspond ac-curately to the new image, we calculate the optical flows of each plane using the camera matrix and plane depths. We then project these layered optical flows into the output op-tical flow map with volume rendering. Secondly, to ensure the realism of motion, we present an independent object mo-tion module that can separate the camera and dynamic ob-ject motion in MPI. This module addresses the deficiency in MPI-based single-view methods, where optical flow is generated only by camera motion and does not account for any object movement. We additionally devise a depth-aware inpainting module to merge new images with dy-namic objects and address unnatural motion occlusions. We show the superior performance of our method through ex-tensive experiments on real-world datasets. Moreover, our approach achieves state-of-the-art performance in both un-supervised and supervised training of learning-based mod-els. The code will be made publicly available at: https://github.com/Sharpiless/MPI-Flow. 