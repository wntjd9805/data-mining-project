The growing threats of deepfakes to society and cyberse-curity have raised enormous public concerns, and increas-ing efforts have been devoted to this critical topic of deep-fake video detection. Existing video methods achieve good performance but are computationally intensive. This paper introduces a simple yet effective strategy named Thumb-nail Layout (TALL), which transforms a video clip into a pre-defined layout to realize the preservation of spa-tial and temporal dependencies. Specifically, consecutive frames are masked in a fixed position in each frame to im-prove generalization, then resized to sub-images and rear-ranged into a pre-defined layout as the thumbnail. TALL is model-agnostic and extremely simple by only modify-ing a few lines of code.Inspired by the success of vi-sion transformers, we incorporate TALL into Swin Trans-former, forming an efficient and effective method TALL-Swin. Extensive experiments on intra-dataset and cross-dataset validate the validity and superiority of TALL andSOTA TALL-Swin. TALL-Swin achieves 90.79% AUC on the challenging cross-dataset task, FaceForensics++ â†’ Celeb-DF. The code is available at https://github.com/ rainy-xu/TALL4Deepfake. 