Denoising diffusion probabilistic models that were ini-tially proposed for realistic image generation have recently shown success in various perception tasks (e.g., object de-tection and image segmentation) and are increasingly gain-ing attention in computer vision. However, extending such models to multi-frame human pose estimation is non-trivial due to the presence of the additional temporal dimension in videos. More importantly, learning representations that focus on keypoint regions is crucial for accurate localiza-tion of human joints. Nevertheless, the adaptation of the diffusion-based methods remains unclear on how to achieve such objective. In this paper, we present DiffPose, a novel diffusion architecture that formulates video-based human pose estimation as a conditional heatmap generation prob-lem. First, to better leverage temporal information, we pro-pose SpatioTemporal Representation Learner which aggre-gates visual evidences across frames and uses the resultingIn addi-features in each denoising step as a condition. tion, we present a mechanism called Lookup-based Multi-Scale Feature Interaction that determines the correlations between local joints and global contexts across multiple scales. This mechanism generates delicate representations that focus on keypoint regions. Altogether, by extending diffusion models, we show two unique characteristics fromDiffPose on pose estimation task: (i) the ability to combine multiple sets of pose estimates to improve prediction accu-racy, particularly for challenging joints, and (ii) the ability to adjust the number of iterative steps for feature refinement without retraining the model. DiffPose sets new state-of-the-art results on three benchmarks: PoseTrack2017, Pose-Track2018, and PoseTrack21. 