We propose DiffusionDet, a new framework that for-mulates object detection as a denoising diffusion process from noisy boxes to object boxes. During the training stage, object boxes diffuse from ground-truth boxes to ran-dom distribution, and the model learns to reverse this nois-ing process.In inference, the model refines a set of ran-domly generated boxes to the output results in a progressive way. Our work possesses an appealing property of flexibil-ity, which enables the dynamic number of boxes and itera-tive evaluation. The extensive experiments on the standard benchmarks show that DiffusionDet achieves favorable per-formance compared to previous well-established detectors.For example, DiffusionDet achieves 5.3 AP and 4.8 AP gains when evaluated with more boxes and iteration steps, under a zero-shot transfer setting from COCO to CrowdHu-man. Our code is available at https://github.com/ShoufaChen/DiffusionDet. 