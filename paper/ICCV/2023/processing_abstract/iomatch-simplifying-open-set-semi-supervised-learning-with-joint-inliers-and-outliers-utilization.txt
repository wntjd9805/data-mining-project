Semi-supervised learning (SSL) aims to leverage mas-sive unlabeled data when labels are expensive to obtain.Unfortunately, in many real-world applications, the col-lected unlabeled data will inevitably contain unseen-class outliers not belonging to any of the labeled classes. To deal with the challenging open-set SSL task, the mainstream methods tend to first detect outliers and then filter them out. However, we observe a surprising fact that such ap-proach could result in more severe performance degrada-tion when labels are extremely scarce, as the unreliable outlier detector may wrongly exclude a considerable por-tion of valuable inliers. To tackle with this issue, we in-troduce a novel open-set SSL framework, IOMatch, which can jointly utilize inliers and outliers, even when it is dif-ficult to distinguish exactly between them. Specifically, we propose to employ a multi-binary classifier in combination with the standard closed-set classifier for producing uni-fied open-set classification targets, which regard all out-liers as a single new class. By adopting these targets as open-set pseudo-labels, we optimize an open-set classifier with all unlabeled samples including both inliers and out-liers. Extensive experiments have shown that IOMatch sig-nificantly outperforms the baseline methods across differ-ent benchmark datasets and different settings despite its re-markable simplicity. Our code and models are available at https://github.com/nukezil/IOMatch. 