This paper sets out to solve the following problem: How can we turn a generative video captioning model into an open-world video/action classification model? Video cap-tioning models can naturally produce open-ended free-form descriptions of a given video which, however, might not be discriminative enough for video/action recognition. Unfor-tunately, when fine-tuned to auto-regress the class names directly, video captioning models overfit the base classes losing their open-world zero-shot capabilities. To alleviate base class overfitting, in this work, we propose to use rein-forcement learning to enforce the output of the video cap-tioning model to be more class-level discriminative. Specif-ically, we propose ReGen, a novel reinforcement learning based framework with a three-fold objective and reward functions: (1) a class-level discrimination reward that en-forces the generated caption to be correctly classified into the corresponding action class, (2) a CLIP reward that en-courages the generated caption to continue to be descriptive of the input video (i.e. video-specific), and (3) a grammar reward that preserves the grammatical correctness of the caption. We show that ReGen can train a model to produce captions that are: discriminative, video-specific and gram-matically correct. Importantly, when evaluated on standard benchmarks for zero- and few-shot action classification, Re-Gen significantly outperforms the previous state-of-the-art. 