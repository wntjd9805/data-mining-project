Network pruning aims to compress models while mini-mizing loss in accuracy. With the increasing focus on bias in AI systems, the bias inheriting or even magnification nature of traditional network pruning methods has raised a new perspective towards fairness-aware network prun-ing. Straightforward pruning plus debias methods and re-cent designs for monitoring disparities of demographic at-tributes during pruning have endeavored to enhance fair-ness in pruning. However, neither simple assembling of two tasks nor specifically designed pruning strategies could achieve the optimal trade-off among pruning ratio, accu-racy, and fairness. This paper proposes an end-to-end learnable framework for fairness-aware network pruning, which optimizes both pruning and debias tasks jointly by adversarial training against those final evaluation metrics like accuracy for pruning, and disparate impact (DI) andIn other words, our equalized odds (DEO) for fairness. fairness-aware adversarial pruning method would learn to prune without any handcraft rules. Therefore, our approach could flexibly adapt to variate network structures. Exhaus-tive experimentation demonstrates the generalization ca-pacity of our approach, as well as superior performance on pruning and debias simultaneously. To highlight, the proposed method could preserve the SOTA pruning per-formance while significantly improving fairness by around 50% as compared to traditional pruning methods. 