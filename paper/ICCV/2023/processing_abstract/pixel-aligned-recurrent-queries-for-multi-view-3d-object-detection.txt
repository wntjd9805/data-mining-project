We present PARQ â€“ a multi-view 3D object detector with transformer and pixel-aligned recurrent queries. Unlike previous works that use learnable features or only encode 3D point positions as queries in the decoder, PARQ lever-ages appearance-enhanced queries initialized from refer-ence points in 3D space and updates their 3D location with recurrent cross-attention operations.Incorporating pixel-aligned features and cross attention enables the model to encode the necessary 3D-to-2D correspondences and capture global contextual information of the input images.PARQ outperforms prior best methods on the ScanNet andARKitScenes datasets, learns and detects faster, is more ro-bust to distribution shifts in reference points, can leverage additional input views without retraining, and can adapt in-ference compute by changing the number of recurrent itera-tions. Code is available at https://ymingxie.github.io/parq. 