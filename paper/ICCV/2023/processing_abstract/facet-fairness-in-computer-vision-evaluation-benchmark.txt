Computer vision models have known performance dis-parities across attributes such as gender and skin tone. This means during tasks such as classiﬁcation and detection, model performance differs for certain classes based on the demographics of the people in the image. These dispari-ties have been shown to exist, but until now there has not been a uniﬁed approach to measure these differences for common use-cases of computer vision models. We present a new benchmark named FACET (FAirness in Computer Vi-sion EvaluaTion), a large, publicly available evaluation set of 32k images for some of the most common vision tasks- image classiﬁcation, object detection and segmentation.For every image in FACET, we hired expert reviewers to manually annotate person-related attributes such as per-ceived skin tone and hair type, manually draw bounding boxes and label ﬁne-grained person-related classes such as disk jockey or guitarist.In addition, we use FACET to benchmark state-of-the-art vision models and present a deeper understanding of potential performance dispari-ties and challenges across sensitive demographic attributes.With the exhaustive annotations collected, we probe models using single demographics attributes as well as multiple at-tributes using an intersectional approach (e.g. hair color and perceived skin tone). Our results show that classiﬁca-tion, detection, segmentation, and visual grounding mod-els exhibit performance disparities across demographic at-tributes and intersections of attributes. These harms sug-gest that not all people represented in datasets receive fair and equitable treatment in these vision tasks. We hope cur-rent and future results using our benchmark will contribute to fairer, more robust vision models. FACET is available publicly at https://facet.metademolab.com. 