In this paper, we provide the observation that too few queries assigned as positive samples in DETR with one-to-one set matching leads to sparse supervision on the en-coder’s output which considerably hurt the discriminative feature learning of the encoder and vice visa for attention learning in the decoder. To alleviate this, we present a novel collaborative hybrid assignments training scheme, namelyCo-DETR, to learn more efficient and effective DETR-based detectors from versatile label assignment manners. This new training scheme can easily enhance the encoder’s learning ability in end-to-end detectors by training the mul-tiple parallel auxiliary heads supervised by one-to-many la-bel assignments such as ATSS and Faster RCNN. In addi-tion, we conduct extra customized positive queries by ex-tracting the positive coordinates from these auxiliary heads to improve the training efficiency of positive samples in the decoder. In inference, these auxiliary heads are discarded and thus our method introduces no additional parameters and computational cost to the original detector while re-quiring no hand-crafted non-maximum suppression (NMS).We conduct extensive experiments to evaluate the effective-ness of the proposed approach on DETR variants, includingDAB-DETR, Deformable-DETR, and DINO-Deformable-DETR. The state-of-the-art DINO-Deformable-DETR withSwin-L can be improved from 58.5% to 59.5% AP on COCO val. Surprisingly, incorporated with ViT-L backbone, we achieve 66.0% AP on COCO test-dev and 67.9% AP onLVIS val, outperforming previous methods by clear mar-gins with much fewer model sizes. Codes are available at https://github.com/Sense-X/Co-DETR. 