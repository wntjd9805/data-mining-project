Gaze behaviors such as eye-contact or shared attention are important markers for diagnosing developmental dis-orders in children. While previous studies have looked at some of these elements, the analysis is usually performed on private datasets and is restricted to lab settings. Further-more, all publicly available gaze target prediction bench-marks mostly contain instances of adults, which makes mod-els trained on them less applicable to scenarios with young children. In this paper, we propose the first study for pre-dicting the gaze target of children and interacting adults. To this end, we introduce the ChildPlay dataset: a curated col-lection of short video clips featuring children playing and interacting with adults in uncontrolled environments (e.g. kindergarten, therapy centers, preschools etc.), which we annotate with rich gaze information. We further propose a new model for gaze target prediction that is geometrically grounded by explicitly identifying the scene parts in the 3D field of view (3DFoV) of the person, leveraging recent ge-ometry preserving depth inference methods. Our model achieves state of the art results on benchmark datasets and ChildPlay. Furthermore, results show that looking at faces prediction performance on children is much worse than on adults, and can be significantly improved by fine-tuning models using child gaze annotations. Our dataset is available at https://www.idiap.ch/en/dataset/ childplay-gaze. Code will be made available soon. 