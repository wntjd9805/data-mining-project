While deep learning models have become the predomi-nant method for medical image segmentation, they are typ-ically not capable of generalizing to unseen segmentation tasks involving new anatomies, image modalities, or labels.Given a new segmentation task, researchers generally have to train or fine-tune models. This is time-consuming and poses a substantial barrier for clinical researchers, who of-ten lack the resources and expertise to train neural networks.We present UniverSeg, a method for solving unseen med-ical segmentation tasks without additional training. Given a query image and an example set of image-label pairs that define a new segmentation task, UniverSeg employs a newCrossBlock mechanism to produce accurate segmentation maps without additional training. To achieve generalization to new tasks, we have gathered and standardized a collec-tion of 53 open-access medical segmentation datasets with over 22,000 scans, which we refer to as MegaMedical. We used this collection to train UniverSeg on a diverse set of anatomies and imaging modalities. We demonstrate that Uni-*Denotes equal contribution verSeg substantially outperforms several related methods on unseen tasks, and thoroughly analyze and draw insights about important aspects of the proposed system. The Uni-verSeg source code and model weights are freely available at https://universeg.csail.mit.edu 