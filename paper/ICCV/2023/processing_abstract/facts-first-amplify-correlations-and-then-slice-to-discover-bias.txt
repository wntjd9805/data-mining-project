Computer vision datasets frequently contain spurious correlations between task-relevant labels and (easy to learn) latent task-irrelevant attributes (e.g. context). Mod-els trained on such datasets learn “shortcuts” and under-perform on bias-conflicting slices of data where the corre-lation does not hold. In this work, we study the problem of identifying such slices to inform downstream bias mit-igation strategies. We propose First Amplify Correlations and Then Slice (FACTS), wherein we first amplify corre-lations to fit a simple bias-aligned hypothesis via strongly regularized empirical risk minimization. Next, we perform correlation-aware slicing via mixture modeling in bias-aligned feature space to discover underperforming data slices that capture distinct correlations. Despite its simplic-ity, our method considerably improves over prior work (by as much as 35% precision@10) in correlation bias identifi-cation across a range of diverse evaluation settings. Code: https://github.com/yvsriram/FACTS. 