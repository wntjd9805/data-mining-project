With the rapid advances in high-throughput sequencing technologies, the focus of survival analysis has shifted from examining clinical indicators to incorporating genomic pro-files with pathological images. However, existing methods either directly adopt a straightforward fusion of patholog-ical features and genomic profiles for survival prediction, or take genomic profiles as guidance to integrate the fea-tures of pathological images. The former would overlook intrinsic cross-modal correlations. The latter would discard pathological information irrelevant to gene expression. To address these issues, we present a Cross-Modal Transla-tion and Alignment (CMTA) framework to explore the in-trinsic cross-modal correlations and transfer potential com-plementary information. Specifically, we construct two par-allel encoder-decoder structures for multi-modal data to in-tegrate intra-modal information and generate cross-modal representation. Taking the generated cross-modal represen-tation to enhance and recalibrate intra-modal representa-tion can significantly improve its discrimination for com-prehensive survival analysis. To explore the intrinsic cross-modal correlations, we further design a cross-modal at-tention module as the information bridge between different modalities to perform cross-modal interactions and transfer complementary information. Our extensive experiments on five public TCGA datasets demonstrate that our proposed framework outperforms the state-of-the-art methods. The source code has been released â€ . 