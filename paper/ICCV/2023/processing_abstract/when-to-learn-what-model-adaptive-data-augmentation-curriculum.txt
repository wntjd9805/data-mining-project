Data augmentation (DA) is widely used to improve the generalization of neural networks by enforcing the invari-ances and symmetries to pre-defined transformations ap-plied to input data. However, a fixed augmentation pol-icy may have different effects on each sample in differ-ent training stages but existing approaches cannot adjust the policy to be adaptive to each sample and the training model. In this paper, we propose “Model-Adaptive DataAugmentation (MADAug)” that jointly trains an augmen-tation policy network to teach the model “when to learn what”. Unlike previous work, MADAug selects augmenta-tion operators for each input image by a model-adaptive policy varying between training stages, producing a data augmentation curriculum optimized for better generaliza-tion.In MADAug, we train the policy through a bi-level optimization scheme, which aims to minimize a validation-set loss of a model trained using the policy-produced data augmentations. We conduct an extensive evaluation ofMADAug on multiple image classification tasks and net-work architectures with thorough comparisons to existingDA approaches. MADAug outperforms or is on par with other baselines and exhibits better fairness: it brings im-provement to all classes and more to the difficult ones.Moreover, MADAug learned policy shows better perfor-mance when transferred to fine-grained datasets. In addi-tion, the auto-optimized policy in MADAug gradually in-troduces increasing perturbations and naturally forms an easy-to-hard curriculum. Our code is available at https://github.com/JackHck/MADAug. 