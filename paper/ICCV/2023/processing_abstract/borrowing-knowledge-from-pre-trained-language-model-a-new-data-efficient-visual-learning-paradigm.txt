The development of vision models for real-world ap-plications is hindered by the challenge of annotated data scarcity, which has necessitated the adoption of data-efficient visual learning techniques such as semi-supervised learning. Unfortunately, the prevalent cross-entropy super-vision is limited by its focus on category discrimination while disregarding the semantic connection between con-cepts, which ultimately results in the suboptimal exploita-tion of scarce labeled data. To address this issue, this paper presents a novel approach that seeks to leverage linguis-tic knowledge for data-efficient visual learning. The pro-posed approach, BorLan, Borrows knowledge from off-the-shelf pretrained Language models that are already endowed with rich semantics extracted from large corpora, to com-pensate the semantic deficiency due to limited annotation in visual training. Specifically, we design a distribution align-ment objective, which guides the vision model to learn both semantic-aware and domain-agnostic representations for the task through linguistic knowledge. One significant ad-vantage of this paradigm is its flexibility in combining vari-ous visual and linguistic models. Extensive experiments on semi-supervised learning, single domain generalization and few-shot learning validate its effectiveness. Code is avail-able at https://github.com/BIT-DA/BorLan. 