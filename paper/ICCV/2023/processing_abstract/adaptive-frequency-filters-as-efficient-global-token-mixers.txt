Recent vision transformers, large-kernel CNNs andMLPs have attained remarkable successes in broad vision tasks thanks to their effective information fusion in the global scope. However, their efficient deployments, espe-cially on mobile devices, still suffer from noteworthy chal-lenges due to the heavy computational costs of self-attention mechanisms, large kernels, or fully connected layers.In this work, we apply conventional convolution theorem to deep learning for addressing this and reveal that adap-tive frequency filters can serve as efficient global token mixers. With this insight, we propose Adaptive FrequencyFiltering (AFF) token mixer. This neural operator trans-fers a latent representation to the frequency domain via a Fourier transform and performs semantic-adaptive fre-quency filtering via an elementwise multiplication, which mathematically equals to a token mixing operation in the original latent space with a dynamic convolution kernel as large as the spatial resolution of this latent representation.We take AFF token mixers as primary neural operators to build a lightweight neural network, dubbed AFFNet. Exten-sive experiments demonstrate the effectiveness of our pro-posed AFF token mixer and show that AFFNet achieve su-perior accuracy and efficiency trade-offs compared to other lightweight network designs on broad visual tasks, includ-ing visual recognition and dense prediction tasks. Code is available at https://github.com/microsoft/TokenMixers. 