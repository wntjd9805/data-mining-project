Reconstructing 3D vehicles from noisy and sparse par-tial point clouds is of great significance to autonomous driving. Most existing 3D reconstruction methods can-not be directly applied to this problem because they are elaborately designed to deal with dense inputs with triv-ial noise.In this work, we propose a novel framework, dubbed MV-DeepSDF, which estimates the optimal SignedDistance Function (SDF) shape representation from multi-sweep point clouds to reconstruct vehicles in the wild. Al-though there have been some SDF-based implicit model-ing methods, they only focus on single-view-based recon-struction, resulting in low fidelity. In contrast, we first an-alyze multi-sweep consistency and complementarity in the latent feature space and propose to transform the implicit space shape estimation problem into an element-to-set fea-ture extraction problem. Then, we devise a new architecture to extract individual element-level representations and ag-gregate them to generate a set-level predicted latent code.This set-level latent code is an expression of the optimal 3D shape in the implicit space, and can be subsequently de-coded to a continuous SDF of the vehicle. In this way, our approach learns consistent and complementary information among multi-sweeps for 3D vehicle reconstruction. We con-duct thorough experiments on two real-world autonomous driving datasets (Waymo and KITTI) to demonstrate the su-periority of our approach over state-of-the-art alternative methods both qualitatively and quantitatively. 