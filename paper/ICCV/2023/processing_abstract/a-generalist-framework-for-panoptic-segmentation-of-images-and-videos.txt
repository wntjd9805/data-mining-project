Panoptic segmentation assigns semantic and instance ID labels to every pixel of an image. As permutations of in-stance IDs are also valid solutions, the task requires learn-ing of high-dimensional one-to-many mapping. As a re-sult, state-of-the-art approaches use customized architec-tures and task-speciÔ¨Åc loss functions. We formulate panop-tic segmentation as a discrete data generation problem, without relying on inductive bias of the task. A diffusion model is proposed to model panoptic masks, with a simple architecture and generic loss function. By simply adding past predictions as a conditioning signal, our method is ca-pable of modeling video (in a streaming setting) and thereby learns to track object instances automatically. With ex-tensive experiments, we demonstrate that our simple ap-proach can perform competitively to state-of-the-art spe-cialist methods in similar settings. 1 