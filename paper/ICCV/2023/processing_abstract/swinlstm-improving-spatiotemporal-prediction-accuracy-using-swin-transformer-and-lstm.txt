Integrating CNNs and RNNs to capture spatiotempo-ral dependencies is a prevalent strategy for spatiotempo-ral prediction tasks. However, the property of CNNs to learn local spatial information decreases their efficiency in capturing spatiotemporal dependencies, thereby limit-ing their prediction accuracy.In this paper, we propose a new recurrent cell, SwinLSTM, which integrates SwinTransformer blocks and the simplified LSTM, an extension that replaces the convolutional structure in ConvLSTM with the self-attention mechanism. Furthermore, we construct a network with SwinLSTM cell as the core for spatiotem-poral prediction. Without using unique tricks, SwinLSTM outperforms state-of-the-art methods on Moving MNIST,Human3.6m, TaxiBJ, and KTH datasets.In particular, it exhibits a significant improvement in prediction accuracy compared to ConvLSTM. Our competitive experimental re-sults demonstrate that learning global spatial dependencies is more advantageous for models to capture spatiotempo-ral dependencies. We hope that SwinLSTM can serve as a solid baseline to promote the advancement of spatiotempo-ral prediction accuracy. The codes are publicly available at https://github.com/SongTang-x/SwinLSTM. 