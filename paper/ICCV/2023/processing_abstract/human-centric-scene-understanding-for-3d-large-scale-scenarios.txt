Human-centric scene understanding is significant for real-world applications, but it is extremely challenging due to the existence of diverse human poses and ac-tions, complex human-environment interactions, severe oc-clusions in crowds, etc. In this paper, we present a large-scale multi-modal dataset for human-centric scene under-standing, dubbed HuCenLife, which is collected in diverse daily-life scenarios with rich and fine-grained annotations.Our HuCenLife can benefit many 3D perception tasks, such as segmentation, detection, action recognition, etc., and we also provide benchmarks for these tasks to facili-tate related research.In addition, we design novel mod-ules for LiDAR-based segmentation and action recognition, which are more applicable for large-scale human-centric*Equal contribution. â€  Corresponding author. This work was sup-ported by NSFC (No.62206173), Natural Science Foundation of Shang-hai (No.22dz1201900), MoE Key Laboratory of Intelligent Perception and Human-Machine Collaboration (ShanghaiTech University), Shang-hai Frontiers Science Center of Human-centered Artificial Intelligence (ShangHAI), Shanghai Engineering Research Center of Intelligent Vision and Imaging. scenarios and achieve state-of-the-art performance. The dataset and code can be found at https://github. com/4DVLab/HuCenLife.git. 