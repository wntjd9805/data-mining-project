We propose a method to estimate 3D human poses from substantially blurred images. The key idea is to tackle the inverse problem of image deblurring by modeling the for-ward problem with a 3D human model, a texture map, and a sequence of poses to describe human motion. The blur-ring process is then modeled by a temporal image aggre-gation step. Using a differentiable renderer, we can solve the inverse problem by backpropagating the pixel-wise re-projection error to recover the best human motion repre-sentation that explains a single or multiple input images.Since the image reconstruction loss alone is insufﬁcient, we present additional regularization terms. To the best of our knowledge, we present the ﬁrst method to tackle this prob-lem. Our method consistently outperforms other methods on signiﬁcantly blurry inputs since they lack one or mul-tiple key functionalities that our method uniﬁes, i.e. image deblurring with sub-frame accuracy and explicit 3D model-ing of non-rigid human motion. 