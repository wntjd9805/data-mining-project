Prompt learning has emerged as an efficient alternative for fine-tuning foundational models, such as CLIP, for var-ious downstream tasks. Conventionally trained using the task-specific objective, i.e., cross-entropy loss, prompts tend to overfit downstream data distributions and find it chal-lenging to capture task-agnostic general features from the frozen CLIP. This leads to the loss of the modelâ€™s original generalization capability. To address this issue, our work introduces a self-regularization framework for prompting called PromptSRC (Prompting with Self-regulating Con-straints). PromptSRC guides the prompts to optimize for both task-specific and task-agnostic general representa-tions using a three-pronged approach by: (a) regulat-ing prompted representations via mutual agreement max-imization with the frozen model, (b) regulating with self-ensemble of prompts over the training trajectory to encode their complementary strengths, and (c) regulating with tex-tual diversity to mitigate sample diversity imbalance with this the visual branch. To the best of our knowledge, is the first regularization framework for prompt learning that avoids overfitting by jointly attending to pre-trained model features, the training trajectory during prompting, and the textual diversity. PromptSRC explicitly steers the prompts to learn a representation space that maxi-mizes performance on downstream tasks without compro-mising CLIP generalization. We perform extensive exper-iments on 4 benchmarks where PromptSRC overall per-forms favorably well compared to the existing methods.Our code and pre-trained models are publicly available at: https://github.com/muzairkhattak/PromptSRC. 