Combined with the generative prior of pre-trained mod-els and the ﬂexibility of text, text-driven generative domain adaptation can generate images from a wide range of tar-get domains. However, current methods still suffer from overﬁtting and the mode collapse problem. In this paper, we analyze the mode collapse from the geometric point of view and reveal its relationship to the Hessian matrix of generator. To alleviate it, we propose the spectral consis-tency regularization to preserve the diversity of source do-main without restricting the semantic adaptation to target domain. We also design granularity adaptive regulariza-tion to ﬂexibly control the balance between diversity and stylization for target model. We conduct experiments for broad target domains compared with state-of-the-art meth-ods and extensive ablation studies. The experiments demon-strate the effectiveness of our method to preserve the di-versity of source domain and generate high ﬁdelity tar-get images. Source code has been released in https://github.com/Victarry/Adaptation-SCR. 