The vulnerability of deep neural networks to adversarial samples has been a major impediment to their broad appli-cations, despite their success in various fields. Recently, some works suggested that adversarially-trained models emphasize the importance of low-frequency information to achieve higher robustness. While several attempts have been made to leverage this frequency characteristic, they have all faced the issue that applying low-pass filters di-rectly to input images leads to irreversible loss of discrim-inative information and poor generalizability to datasets with distinct frequency features. This paper presents a plug-and-play module called the Frequency Preference ControlModule that adaptively reconfigures the low- and high-frequency components of intermediate feature representa-tions, providing better utilization of frequency in robust learning. Empirical studies show that our proposed mod-ule can be easily incorporated into any adversarial train-ing framework, further improving model robustness across different architectures and datasets. Additionally, experi-ments were conducted to examine how the frequency bias of robust models impacts the adversarial training process and its final robustness, revealing interesting insights. 