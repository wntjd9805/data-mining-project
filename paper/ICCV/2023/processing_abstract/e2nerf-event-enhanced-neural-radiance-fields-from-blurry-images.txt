Neural Radiance Fields (NeRF) achieves impressive ren-dering performance by learning volumetric 3D represen-tation from several images of different views. However, it is difficult to reconstruct a sharp NeRF from blurry input as often occurred in the wild. To solve this problem, we propose a novel Event-Enhanced NeRF (E2NeRF) by uti-lizing the combination data of a bio-inspired event cam-era and a standard RGB camera. To effectively introduce event stream into the learning process of neural volumet-ric representation, we propose a blur rendering loss and an event rendering loss, which guide the network via modelling real blur process and event generation process, respectively.Moreover, a camera pose estimation framework for real-world data is built with the guidance of event stream toIn con-generalize the method to practical applications.*Correspondence should be addressed to Lin Zhu and Jia Li. Website: https://cvteam.buaa.edu.cn trast to previous image-based or event-based NeRF, our framework effectively utilizes the internal relationship be-tween events and images. As a result, E2NeRF not only achieves image deblurring but also achieves high-quality novel view image generation. Extensive experiments on both synthetic data and real-world data demonstrate thatE2NeRF can effectively learn a sharp NeRF from blurry images, especially in complex and low-light scenes. Our code and datasets are publicly available at https:// github.com/iCVTEAM/E2NeRF. 