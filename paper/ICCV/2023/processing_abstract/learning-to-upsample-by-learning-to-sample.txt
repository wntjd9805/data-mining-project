We present DySample, an ultra-lightweight and effective dynamic upsampler. While impressive performance gains have been witnessed from recent kernel-based dynamic up-samplers such as CARAFE, FADE, and SAPA, they intro-duce much workload, mostly due to the time-consuming dy-namic convolution and the additional sub-network used to generate dynamic kernels. Further, the need for high-res feature guidance of FADE and SAPA somehow limits their application scenarios. To address these concerns, we by-pass dynamic convolution and formulate upsampling from the perspective of point sampling, which is more resource-efficient and can be easily implemented with the standard built-in function in PyTorch. We first showcase a naive de-sign, and then demonstrate how to strengthen its upsam-pling behavior step by step towards our new upsampler,DySample. Compared with former kernel-based dynamic upsamplers, DySample requires no customized CUDA pack-age and has much fewer parameters, FLOPs, GPU mem-ory, and latency. Besides the light-weight characteristics,DySample outperforms other upsamplers across five dense prediction tasks, including semantic segmentation, object detection, instance segmentation, panoptic segmentation, and monocular depth estimation. Code is available at https://github.com/tiny-smart/dysample. 