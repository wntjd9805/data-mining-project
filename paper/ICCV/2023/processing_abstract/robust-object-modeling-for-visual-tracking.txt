Object modeling has become a core part of recent track-ing frameworks. Current popular tackers use Transformer attention to extract the template feature separately or in-teractively with the search region. However, separate tem-plate learning lacks communication between the template and search regions, which brings difficulty in extracting dis-criminative target-oriented features. On the other hand, in-teractive template learning produces hybrid template fea-tures, which may introduce potential distractors to the tem-plate via the cluttered search regions. To enjoy the mer-its of both methods, we propose a robust object modeling framework for visual tracking (ROMTrack), which simulta-neously models the inherent template and the hybrid tem-plate features. As a result, harmful distractors can be sup-pressed by combining the inherent features of target objects with search regionsâ€™ guidance. Target-related features can also be extracted using the hybrid template, thus resulting in a more robust object modeling framework. To further en-hance robustness, we present novel variation tokens to de-pict the ever-changing appearance of target objects. Varia-tion tokens are adaptable to object deformation and appear-ance variations, which can boost overall performance with negligible computation. Experiments show that our ROM-Track sets a new state-of-the-art on multiple benchmarks. 