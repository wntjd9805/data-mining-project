Semantic occupancy perception is essential for au-tonomous driving, as automated vehicles require a fine-grained perception of the 3D urban structures. However, existing relevant benchmarks lack diversity in urban scenes, and they only evaluate front-view predictions. Towards a comprehensive benchmarking of surrounding perception al-gorithms, we propose OpenOccupancy, which is the first surrounding semantic occupancy perception benchmark. In the OpenOccupancy benchmark, we extend the large-scale nuScenes dataset with dense semantic occupancy annota-tions. Previous annotations rely on LiDAR points superim-position, where some occupancy labels are missed due to sparse LiDAR channels. To mitigate the problem, we intro-duce the Augmenting And Purifying (AAP) pipeline to ∼2× densify the annotations, where ∼4000 human hours are involved in the labeling process. Besides, camera-based,LiDAR-based and multi-modal baselines are established for the OpenOccupancy benchmark. Furthermore, con-sidering the complexity of surrounding occupancy percep-tion lies in the computational burden of high-resolution 3D predictions, we propose the Cascade Occupancy Network*These authors contributed equally to this work.†Corresponding authors. zhengzhu@ieee.org, xingang.wang@ia.ac.cn‡https://github.com/JeffWang987/OpenOccupancy (CONet) to refine the coarse prediction, which relatively enhances the performance by ∼30% than the baseline. We hope the OpenOccupancy benchmark ‡ will boost the devel-opment of surrounding occupancy perception algorithms. 