Generalizing deep learning models to unknown target domain distribution with low latency has motivated re-search into test-time training/adaptation (TTT/TTA). Exist-ing approaches often focus on improving test-time train-ing performance under well-curated target domain data.As figured out in this work, many state-of-the-art meth-ods fail to maintain the performance when the target do-main is contaminated with strong out-of-distribution (OOD) data, a.k.a. open-world test-time training (OWTTT). The failure is mainly due to the inability to distinguish strongOOD samples from regular weak OOD samples. To im-prove the robustness of OWTTT we first develop an adap-tive strong OOD pruning which improves the efficacy of the self-training TTT method. We further propose a way to dy-namically expand the prototypes to represent strong OOD samples for an improved weak/strong OOD data separa-tion. Finally, we regularize self-training with distribution alignment and the combination yields the state-of-the-art performance on 5 OWTTT benchmarks. The code is avail-able at https://github.com/Yushu-Li/OWTTT. 