For safety-related applications, it is crucial to pro-duce trustworthy deep neural networks whose prediction is associated with confidence that can represent the like-lihood of correctness for subsequent decision-making. Ex-isting dense binary classification models are prone to be-ing over-confident. To improve model calibration, we pro-pose Adaptive Stochastic Label Perturbation (ASLP) which learns a unique label perturbation level for each training image. ASLP employs our proposed Self-Calibrating Bi-nary Cross Entropy (SC-BCE) loss, which unifies label per-turbation processes including stochastic approaches (likeDisturbLabel), and label smoothing, to correct calibra-tion while maintaining classification rates. ASLP followsMaximum Entropy Inference of classic statistical mechan-ics to maximise prediction entropy with respect to missing information.It performs this while: (1) preserving clas-sification accuracy on known data as a conservative so-lution, or (2) specifically improves model calibration de-gree by minimising the gap between the prediction accu-racy and expected confidence of the target training label.Extensive results demonstrate that ASLP can significantly improve calibration degrees of dense binary classifica-tion models on both in-distribution and out-of-distribution data. The code is available on https://github.com/Carlisle-Liu/ASLP. 