Recently, methods for skeleton-based human activity recognition have been shown to be vulnerable to adversar-ial attacks. However, these attack methods require either the full knowledge of the victim (i.e. white-box attacks), ac-cess to training data (i.e. transfer-based attacks) or fre-quent model queries (i.e. black-box attacks). All their re-quirements are highly restrictive, raising the question of how detrimental the vulnerability is. In this paper, we show that the vulnerability indeed exists. To this end, we consider a new attack task: the attacker has no access to the vic-tim model or the training data or labels, where we coin the term hard no-box attack. Specifically, we first learn a mo-tion manifold where we define an adversarial loss to com-pute a new gradient for the attack, named skeleton-motion-informed (SMI) gradient. Our gradient contains informa-tion of the motion dynamics, which is different from existing gradient-based attack methods that compute the loss gra-dient assuming each dimension in the data is independent.The SMI gradient can augment many gradient-based attack methods, leading to a new family of no-box attack meth-ods. Extensive evaluation and comparison show that our method imposes a real threat to existing classifiers. They also show that the SMI gradient improves the transferability and imperceptibility of adversarial samples in both no-box and transfer-based black-box settings. 