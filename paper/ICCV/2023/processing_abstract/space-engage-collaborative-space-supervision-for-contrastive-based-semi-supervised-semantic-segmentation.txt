Semi-Supervised Semantic Segmentation (S4) aims to train a segmentation model with limited labeled images and a substantial volume of unlabeled images. To improve the robustness of representations, powerful methods introduce a pixel-wise contrastive learning approach in latent space (i.e., representation space) that aggregates the representa-tions to their prototypes in a fully supervised manner. How-ever, previous contrastive-based S4 methods merely rely on the supervision from the modelâ€™s output (logits) in logit space during unlabeled training. In contrast, we utilize the outputs in both logit space and representation space to ob-tain supervision in a collaborative way. The supervision from two spaces plays two roles: 1) reduces the risk of over-fitting to incorrect semantic information in logits with the help of representations; 2) enhances the knowledge ex-change between the two spaces. Furthermore, unlike pre-vious approaches, we use the similarity between represen-tations and prototypes as a new indicator to tilt training those under-performing representations and achieve a more efficient contrastive learning process. Results on two pub-lic benchmarks demonstrate the competitive performance of our method compared with state-of-the-art methods. 