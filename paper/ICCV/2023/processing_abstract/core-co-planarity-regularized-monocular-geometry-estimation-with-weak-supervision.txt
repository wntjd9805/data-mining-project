The ill-posed nature of monocular 3D geometry (depth map and surface normals) estimation makes it rely mostly on data-driven approaches such as Deep Neural Networks (DNN). However, data acquisition of surface normals, es-pecially the reliable normals, is acknowledged difficult.Commonly, reconstruction of surface normals with high quality is heuristic and time-consuming. Such fact urges methodologies to minimize dependency on ground-truth normals when predicting 3D geometry. In this work, we de-vise CO-planarity REgularized (CORE) loss functions andStructure-Aware Normal Estimator (SANE). Without involv-ing any knowledge of ground-truth normals, these two de-signs enable pixel-wise 3D geometry estimation weakly su-pervised by only ground-truth depth map. For CORE loss functions, the key idea is to exploit locally linear depth-normal orthogonality under spherical coordinates as pixel-level constraints, and utilize our designed Adaptive PolarRegularization (APR) to resolve underlying numerical de-generacies. Meanwhile, SANE easily establishes multi-task learning with CORE loss functions on both depth and sur-face normal estimation, leading to the whole performance leap. Extensive experiments present the effectiveness of our method on various DNN architectures and data bench-marks. The experimental results demonstrate that our depth estimation achieves the state-of-the-art performance across all metrics on indoor scenes and comparable performance on outdoor scenes. In addition, our surface normal estima-tion is overall superior. 