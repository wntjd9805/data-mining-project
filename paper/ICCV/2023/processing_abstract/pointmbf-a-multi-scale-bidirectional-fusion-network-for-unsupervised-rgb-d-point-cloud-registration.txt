Point cloud registration is a task to estimate the rigid transformation between two unaligned scans, which plays an important role in many computer vision applications.Previous learning-based works commonly focus on super-vised registration, which have limitations in practice. Re-cently, with the advance of inexpensive RGB-D sensors, sev-eral learning-based works utilize RGB-D data to achieve unsupervised registration. However, most of existing unsu-pervised methods follow a cascaded design or fuse RGB-D data in a unidirectional manner, which do not fully ex-ploit the complementary information in the RGB-D data. To leverage the complementary information more effectively, we propose a network implementing multi-scale bidirec-tional fusion between RGB images and point clouds gen-erated from depth images. By bidirectionally fusing vi-sual and geometric features in multi-scales, more distinc-tive deep features for correspondence estimation can be ob-tained, making our registration more accurate. Extensive experiments on ScanNet and 3DMatch demonstrate that our method achieves new state-of-the-art performance. Code will be released at https://github.com/phdymz/PointMBF. 