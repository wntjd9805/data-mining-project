Prompt learning has become one of the most efficient paradigms for adapting large pre-trained vision-language models to downstream tasks. Current state-of-the-art meth-ods, like CoOp and ProDA, tend to adopt soft prompts to learn an appropriate prompt for each specific task. Re-cent CoCoOp further boosts the base-to-new generalization performance via an image-conditional prompt. However, it directly fuses identical image semantics to prompts of dif-ferent labels and significantly weakens the discrimination among different classes as shown in our experiments. Mo-tivated by this observation, we first propose a class-aware text prompt (CTP) to enrich generated prompts with label-related image information. Unlike CoCoOp, CTP can effec-tively involve image semantics and avoid introducing extra ambiguities into different prompts. On the other hand, in-stead of reserving the complete image representations, we propose text-guided feature tuning (TFT) to make the im-age branch attend to class-related representation. A con-trastive loss is employed to align such augmented text and image representations on downstream tasks.In this way, the image-to-text CTP and text-to-image TFT can be mutu-ally promoted to enhance the adaptation of VLMs for down-stream tasks. Extensive experiments demonstrate that our method outperforms the existing methods by a significant margin. Especially, compared to CoCoOp, we achieve an average improvement of 4.03% on new classes and 3.19% on harmonic-mean over eleven classification benchmarks. 