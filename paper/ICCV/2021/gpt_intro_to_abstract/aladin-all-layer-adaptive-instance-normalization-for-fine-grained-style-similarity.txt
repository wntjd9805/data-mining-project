Digital artwork is diverse and encompasses a wide range of visual styles. However, accurately searching for artwork based on visual style poses a challenge due to the complexities of defining and annotating fine-grained variations in style. Previous research has primarily focused on coarse-grain discrimination of a limited number of styles. In this paper, we propose a novel architecture called ALADIN that learns a search embedding for fine-grained artistic style similarity. ALADIN is an encoder-decoder network that utilizes Adaptive Instance Normalization (AdaIN) statistics to discriminate both subtle and coarse-grained styles. We also contribute a new dataset called BAM-FG, consisting of 2.62 million images of artwork with 310K fine-grained style groupings. This dataset is obtained from Behance.net, a creative portfolio website. We leverage the co-occurrence of images within these groups as a weak cue for style similarity and further clean the data through crowd annotation. In terms of learning, we take a weakly supervised approach, training ALADIN using supervised contrastive learning without explicit labeling of fine-grained style. Our experimental results demonstrate that ALADIN achieves state-of-the-art performance in both coarse and fine-grained style search.