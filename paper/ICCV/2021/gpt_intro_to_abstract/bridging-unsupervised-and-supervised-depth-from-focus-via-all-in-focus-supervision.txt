This paper addresses the problem of depth estimation in computer vision and its importance in various applications such as augmented reality, virtual reality, and autonomous driving. The authors highlight the limitations of existing solutions, including the use of expensive and power-consuming hardware or the reliance on large amounts of high-quality paired training data. They introduce unsupervised learning approaches and the under-explored cue of defocus blur for depth estimation. The proposed method aims to jointly estimate depth and an all-in-focus image from an input focal stack, leveraging the relationship between these tasks. The authors propose a shared common network that can be trained supervisedly or unsupervisedly using ground truth depth maps or all-in-focus images, respectively. They also address the challenges of acquiring focal stacks with registered depth maps and the focus breathing phenomenon. The contributions of the paper include outperforming state-of-the-art methods when trained supervisedly, being the first to learn depth estimation unsupervisedly from all-in-focus images, and mitigating domain gaps through test-time optimization on real-world data.