This paper introduces a novel training methodology for semantic segmentation models that allows for scalability to a large number of semantic classes using only one GPU's memory. The authors propose reducing the output channels of existing networks and learning a low dimensional embedding of semantic classes to achieve this scalability. They also propose an efficient strategy to learn and utilize this embedding for the task of semantic image segmentation. Experimental results show that the proposed method achieves significantly better mIoU scores on a dataset with 1284 classes compared to existing approaches, while maintaining competitive performance for a lower number of classes. The authors also introduce an approximate method for cross-entropy measure and a semantic embedding space regularization term for efficiency and generalization. The proposed method is theoretically grounded and has applications in various image understanding tasks.