Event cameras with bio-inspired silicon retina sensors have a unique sensor design that allows them to measure scene radiance changes in an asynchronous manner, rather than capturing images at a fixed frame rate. These cameras detect brightness changes in a scene and send a stream of event data that are binary-signed recordings of brightness changes. Event cameras have high dynamic range, high temporal resolution, low latency, and low power consumption. However, most event cameras have low spatial resolution due to data transmission efficiency considerations. Previous reconstruction approaches for event data can only achieve low-resolution intensity reconstruction. In this paper, we propose a method to fuse intensity frames with event data to achieve high-quality super-resolution of intensity images. Our proposed EvIntSR-Net neural network learns to convert event data to multiple latent intensity frames and uses a multi-image super-resolution operator to enhance the resolution of target intensity frames. Experimental results demonstrate that EvIntSR-Net can successfully reconstruct super-resolved intensity images with higher fidelity compared to state-of-the-art approaches.