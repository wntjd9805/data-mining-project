Object change detection is a crucial task in remote sensing and earth vision, with applications in urban planning, environmental monitoring, and disaster assessment. Traditional methods for change detection rely on deep convolutional neural networks (ConvNet) and require pairwise labeled bitemporal high spatial resolution (HSR) remote sensing images for training. However, labeling such images is expensive and time-consuming, limiting the practicality of these methods. In this paper, we introduce a novel approach called Single-Temporal supervised leARning (STAR) that utilizes unpaired labeled images for object change detection. By relaxing the positional consistency condition and exploiting object changes between unpaired images as supervisory signals, STAR enables the training of a high-accuracy change detector. We demonstrate the effectiveness of the proposed STAR algorithm with a unified change detector called ChangeStar, which combines an arbitrary deep semantic segmentation model with the ChangeMixin module. This allows for the reuse of existing semantic segmentation architectures in change detection tasks. Our contributions include the introduction of single-temporal supervised learning to alleviate the need for paired labeled images, the exploration of temporal symmetry as an inductive bias to address overfitting, and the development of the ChangeStar architecture for joint semantic segmentation and change detection.