Learning transferable representations of visual data without explicit semantic supervision during training is an important problem in computer vision. Recent advancements in self-supervised methods have shown promise in learning features that rival, or even surpass, fully supervised methods. However, current self-supervised methods rely on aggressive image augmentation strategies to generate different views of an input image. This paper explores the use of context information, such as time and location, to select more useful and varied image pairs during self-supervised training. The authors evaluate different approaches and find that the choice of images has a greater impact on performance than the self-supervision algorithm. The evaluation is focused on camera trap images, which are automatically triggered and contain rich context data. The authors make three contributions: exploring the benefits of self-supervised learning on camera trap datasets, highlighting the importance of image selection during training, and demonstrating the robustness of current methods to incorrectly selected positive image pairs. These findings have implications for scalable global biodiversity monitoring.