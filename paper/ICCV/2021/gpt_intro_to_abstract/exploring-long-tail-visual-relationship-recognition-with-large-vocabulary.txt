This paper introduces the problem of long-tail visual relationship recognition (LTVRR) in the field of computer science. Most existing works in visual recognition assume abundant training data, but a more realistic scenario is when classes follow a long-tail distribution, with only few examples per class. The authors propose LTVRR as a challenging task where subject-object relationships also follow a long-tail distribution. They extend the long-tail setup used in long-tail object recognition to study visual relationship recognition. The paper presents benchmarks and evaluation metrics for LTVRR, and implements state-of-the-art models targeted at long-tail object classification in the LTVRR setup. Additionally, the authors propose a novel augmentation technique called RelMix and a hubless regularization loss called VilHub to improve performance in the tail classes. The paper makes three main contributions: adapting state-of-the-art approaches to the LTVRR setup, proposing a novel augmentation method, and introducing the VilHub loss for long-tail visual understanding. The authors evaluate the proposed methods on two benchmark datasets and analyze the models' performance based on semantic similarity to ground-truth categories. The experiments demonstrate the effectiveness of the proposed methods in improving performance across the class distribution, especially in the tail classes.