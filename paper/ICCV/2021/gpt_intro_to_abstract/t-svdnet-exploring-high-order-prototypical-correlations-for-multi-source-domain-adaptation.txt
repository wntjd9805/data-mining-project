Deep learning methods have shown impressive performance when trained on large amounts of data. However, when knowledge learned from one visual domain is directly transferred to other domains with different distributions, there is a significant decrease in performance due to domain shift. To address this problem, various approaches such as transfer learning and unsupervised domain adaptation (UDA) have been developed to extract domain-invariant features. Discrepancy-based methods minimize the difference between the source and target distributions, while adversarial methods align the domains through adversarial training or GAN-based loss. However, these methods only focus on domain adaptation with a single source, whereas many practical applications have multiple relevant sources available. Naively combining these sources can be ineffective and may perform worse than single-source methods due to confusion caused by domain gaps. Some Multi-Source Domain Adaptation (MDA) approaches focus on aligning multiple sources and a target domain by projecting them into a domain-invariant feature space. However, these methods may sacrifice discrimination ability and only achieve pair-wise matching, neglecting high-order relations among all domains. Another commonly used approach in MDA is distribution-weighted combining, but it does not consider intra-domain weightings among different training samples, leading to negative transfer. To address these limitations, we propose a novel method called T-SVDNet that incorporates tensor singular value decomposition into the neural network training pipeline. We assume that data from different domains should follow a certain category-wise structure and explore high-order relationships to enforce source and target alignment. We apply a Tensor-Low-Rank (TLR) constraint to a tensor composed of prototypical similarity matrices to ensure consistent category relationships across domains. Additionally, we introduce an uncertainty-aware weighting strategy to guide the adaptation process by assigning weights to different domains and training samples based on uncertainty estimation. We optimize the framework using an alternative optimization strategy and evaluate our method on multiple benchmark datasets, achieving significant improvements over existing MDA methods. The main contributions of our paper include the T-SVDNet model, the uncertainty-aware weighting strategy, and the alternative optimization method with low-rank regularization.