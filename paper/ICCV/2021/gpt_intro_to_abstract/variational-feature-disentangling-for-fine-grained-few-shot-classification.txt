Fine-grained visual data is difficult to collect and costly to annotate. Fine-grained few-shot learning (FSL) methods address this issue by learning discriminative class features using as few as 1 or 5 training instances. However, generating diverse data for FSL remains a challenge. Current approaches, such as adversarial frameworks and feature transfer, suffer from limited diversity or introduce class-discriminative features that alter the transformed features' class identity. In this paper, we propose a novel data augmentation framework for FSL. We disentangle features into intra-class variance and class-discriminative components and model intra-class variance using a common distribution. Our method achieves state-of-the-art few-shot classification performance on fine-grained datasets and generates data that closely approximates the distribution of real data. Our contributions include the proposal of a VAE-based feature disentanglement method, the training of the system using data from base classes, and outperforming state-of-the-art FSL methods in multiple fine-grained datasets.