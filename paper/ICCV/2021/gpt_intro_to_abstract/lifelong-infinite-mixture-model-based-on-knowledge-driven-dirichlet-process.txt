This paper focuses on lifelong learning (LLL) and the challenges it faces in adapting to new tasks while maintaining performance on previous tasks. The paper introduces the Generative Replay Mechanism (GRM), a popular approach that aims to overcome catastrophic forgetting. The GRM utilizes generative models to transform random variables into high-dimensional variables. However, the GRM faces difficulties in retaining knowledge across tasks and dealing with mode collapse. The paper proposes two solutions to address these issues: network expansion and ensemble structures. These approaches aim to preserve the best performance of previous tasks but lack a thorough theoretical analysis. In this paper, the authors provide a theoretical analysis of lifelong learning models. They examine the forgetting behavior of models when learning new tasks, showing that the increasing upper bound to target-risk affects performance. The proposed Lifelong Infinite Mixture (LIMix) model automatically grows its network architecture for novel tasks or updates components with small discrepancies. The Dirichlet process is used in these mechanisms to reduce computational costs. The paper also introduces a gating mechanism based on the Dirichlet process to infer indicator variables for data samples. The authors highlight the advantages of using a lightweight model in LLL, as it allows for fast inference and accumulation of knowledge across data domains. The main contributions of this paper are: 1. Analysis of forgetting behavior in LLL and the importance of the discrepancy distance between source and target distributions. 2. Theoretical insights into using mixture models for LLL and the performance changes when shifting the order of tasks. 3. Proposal of the LIMix model with theoretical guarantees for LLL and exploration of training a compact Student model from the mixture. Overall, this paper provides valuable theoretical analysis and proposes a novel lifelong mixture model for more efficient and effective lifelong learning.