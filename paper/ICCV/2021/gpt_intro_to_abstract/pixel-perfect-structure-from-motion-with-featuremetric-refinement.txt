Mapping the world is crucial for spatial intelligence applications in augmented reality and robotics, particularly for tasks like visual localization and path planning. Structure-from-Motion (SfM) is commonly used to build accurate 3D reconstructions from images, with sparse reconstruction being the most common approach due to its scalability and robustness. However, detecting keypoints from a single view is inherently inaccurate, which affects the accuracy of the overall reconstruction.To address this issue, we propose a new approach that leverages dense local information to refine sparse observations. By using direct image alignment in a learned feature space, we improve the accuracy of both keypoints and bundles throughout the SfM process. This approach combines the benefits of sparse and dense reconstructions, optimizing all locations over multiple views simultaneously.We also address the problem of subpixel estimation, a well-studied issue in correspondence search. Our approach uses techniques such as upsampling, polynomial fitting, and Gaussian distributions to improve the accuracy of keypoints.In addition, we unify keypoint and bundle optimizations into a joint framework that optimizes a featuremetric cost, resulting in more accurate geometries and a more efficient keypoint refinement.Our method has been validated through experiments evaluating the accuracy of 3D structure and camera poses in various conditions. We have demonstrated significant improvements using different local features, both hand-crafted and learned through off-the-shelf convolutional neural networks (CNNs). Our system produces accurate reconstructions and scales well to large scenes with thousands of images.We plan to release our code as an extension to existing software tools, such as COLMAP and hloc, with the goal of improving the accuracy of existing datasets and advancing subpixel accurate localization at a large scale.