3D object detection is a crucial task in autonomous driving and robotics. However, detecting objects from point clouds poses challenges due to their sparse and unstructured nature. Voxel-based detectors have shown superior performance by transforming point clouds into regular voxel-grids. In this paper, we propose Voxel Transformer (VoTr), a Transformer-based backbone that can be applied to voxel-based detectors to enhance their detection performance. Existing approaches can be divided into point-based and voxel-based methods. While point-based methods suffer from the sparse and non-uniform distribution of points, voxel-based methods are more efficient and achieve state-of-the-art performance. However, voxel-based models with 3D convolutional backbones have limited receptive fields, which makes it difficult to detect objects with only a few voxels. Increasing the receptive fields is computationally expensive. To address this limitation, we introduce VoTr, which can encode richer context information compared to convolutional backbones. We draw inspiration from recent advances in 2D object classification and detection using the Transformer architecture. However, applying standard Transformer modules directly to voxels is infeasible due to the sparsity and large number of voxels. Therefore, we propose special operations and attention mechanisms to efficiently attend to non-empty voxels. Our proposed VoTr significantly improves detection performance compared to conventional convolutional backbones while maintaining computational efficiency. Our contributions include the development of VoTr, the first Transformer-based 3D backbone for voxel-based 3D detectors, the introduction of sparse and submanifold voxel modules, and efficient attention mechanisms and querying processes. Experimental results demonstrate that VoTr achieves state-of-the-art performance on the Waymo and KITTI datasets.