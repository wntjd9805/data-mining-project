The task of optical flow computation involves estimating the motion of pixels in a video sequence. However, challenges such as lack of texture, occlusions, and blurring effects make this problem difficult to solve. Deep learning has been adopted for dense optical flow estimation, which has improved the accuracy and run time compared to previous approaches. However, the use of synthetic images for training often fails to generalize well to real data due to domain-shift. Fine-tuning on real images can partially address this issue, but achieving generalization without fine-tuning is desirable. Inspired by guided stereo matching, we propose a guided optical flow framework that uses sparse yet accurate optical flow values to modulate correlation scores and improve accuracy. We extend the guided stereo formulation to consider 2D cost surfaces and revise the state-of-the-art flow network to leverage the guide more effectively. We evaluate the effectiveness of our approach using both theoretical and real-world flow hints. Our experiments on synthetic and real datasets demonstrate that guided optical flow reduces the domain-shift effect and improves accuracy. We show that even though accurate flow hints are not readily available from sensors, a LIDAR sensor combined with a hand-crafted flow algorithm can provide a meaningful guide.