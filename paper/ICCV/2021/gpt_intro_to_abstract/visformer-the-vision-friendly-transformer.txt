In recent years, deep learning models for visual recognition have been heavily reliant on convolution. However, the introduction of the Transformer module, originally used in natural language processing, has led to a shift in this paradigm. The ViT model demonstrated that images can be divided into patches and the Transformer can be applied directly to these patches. However, ViT requires a large amount of training data and is prone to overfitting. Although efforts have been made to improve ViT, convolution-based models still outperform transformer-based models, especially with limited training data or moderate data augmentation.This paper aims to identify the reasons behind this performance difference between transformer-based and convolution-based models in order to design networks with higher lower-bound and upper-bound performance. Two different training settings on ImageNet are used to compare the performance of DeiT-S (transformer-based) and ResNet-50 (convolution-based) models. The results show that DeiT-S performs well under the elite setting but experiences a significant drop in accuracy under the base setting. On the other hand, ResNet-50 performs better under the base setting but has minimal improvement under the elite setting. By analyzing the differences between these models, a step-by-step transition process is conducted, leading to the development of Visformer, a vision-friendly transformer.The Visformer model outperforms both DeiT-S and ResNet-50 in ImageNet classification, achieving higher accuracy even with limited training data and classes. Additionally, the Visformer-Ti model outperforms Deit-Ti by more than 6% for tiny models. The contributions of this paper include the introduction of lower-bound and upper-bound concepts to investigate transformer-based models, the identification of design properties in transformer-based and convolution-based models through a gradual transition process, and the proposal of the Visformer model, which achieves both high lower-bound and upper-bound performance and scalability.