Video summarization is a crucial component of video understanding, aiming to provide users with a condensed version of a video that includes only the relevant content. This has various applications, such as semantic video editing and content filtering. Additionally, video summarization can reduce the length and processing time of videos for downstream tasks like action recognition. While video summarization is often related to highlight detection, it also considers diversity, representativeness, visual and semantic coherence, storytelling ability, and adaptability to the context. Past research in this field has focused on specific aspects of summarization criteria and different model settings. However, the challenge lies in the subjective nature of what is meaningful in a video, as it depends on the perspective of the end user. Few studies have explored customization of generated summaries, and a unique global summary may not satisfy the diverse perspectives and opinions of users. To address this, we propose a novel video summarization model that allows users to select from a set of summaries based on their preferences. Our model combines multiple sub-ranking models trained using pairwise comparisons to generate local summaries for each preference. The sub-ranking models are jointly trained to ensure a unique global summary. This approach enables users to interact with the model and select one or multiple preferences for personalized and global summary generation. We demonstrate the effectiveness of our method through experiments on benchmark datasets, showing that our pairwise ranking model achieves state-of-the-art results in supervised video summarization. Overall, our contributions lie in the development of a customizable video summarization model that can generate global, personalized, and local summaries based on user preferences.