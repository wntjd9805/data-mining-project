In recent years, LiDAR-based 3D detection has shown promising results in autonomous driving and robotics. However, the high cost of LiDAR sensors has limited its applications in low-cost products. On the other hand, stereo cameras are a more affordable alternative with higher resolutions. Stereo matching is a common depth sensing technique using only cameras. However, existing stereo-based 3D detection algorithms still have inferior performance compared to LiDAR-based algorithms. This paper proposes a method that utilizes features from LiDAR-based detection models to guide the training of stereo-based 3D detectors. By imitating the geometry-aware representations encoded by the LiDAR model, the proposed method aims to improve the accuracy and efficiency of stereo-based 3D detection. Additionally, the paper explores how to learn better semantic features for boosting the 3D detection performance by attaching an auxiliary 2D detection head. Experimental results show that the proposed method outperforms state-of-the-art models on the KITTI 3D detection benchmark. Overall, this research contributes to the advancement of stereo-based 3D detection, making it a more cost-effective solution for various applications in autonomous driving and robotics.