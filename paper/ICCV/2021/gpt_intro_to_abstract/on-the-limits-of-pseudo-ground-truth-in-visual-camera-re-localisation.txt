The availability of benchmark datasets has played a crucial role in advancing research on visual re-localisation, a technology essential for autonomous robots, self-driving cars, and augmented/mixed reality systems. These benchmarks provide camera poses for training and test images, allowing researchers to determine the 3D position and orientation of the camera with respect to the scene. However, benchmark datasets are typically generated using a reference algorithm, and the choice of this algorithm can significantly impact the ranking of methods on a benchmark. In this paper, we investigate the impact of reference algorithms on the measured performance of visual re-localisation algorithms. We compare two types of reference algorithms (depth-based SLAM and SfM) on two popular benchmark datasets and show that the choice of reference algorithm can have a profound impact on method rankings. Our results highlight the importance of considering the resemblance between approaches and the reference algorithm when drawing conclusions from benchmarks. We also provide a comparison of reference algorithms on widely used datasets and demonstrate that commonly accepted results from the literature are not absolute but depend on the choice of reference algorithm. This paper raises awareness of the limitations of pseudo ground truth for re-localisation and emphasizes the need for valid comparisons across methods.