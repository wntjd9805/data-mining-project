Self-contact plays a crucial role in human motion perception, indicating different behaviors and emotional states. While handling self-contact is essential for reconstructing, interpreting, and synthesizing human motion, accurately synthesizing contact for a skinned character requires knowledge of its 3D geometry. This paper presents a motion retargeting algorithm that preserves self-contact, ground contact, and reduces interpenetration. By identifying self-contact and foot contacts in the input motion and using an energy function, our method guarantees accurate transfer of contacts to the skinned and rendered motion. Leveraging previous work, we train a Recurrent Neural Network (RNN) for retargeting, and introduce encoder-space optimization to refine the RNN's predictions. Our method focuses on meaningful self-contacts involving the hands and demonstrates effectiveness across various character geometries. In qualitative and quantitative evaluations, our method outperforms state-of-the-art learning-based motion retargeting methods and generalizes well to real scenarios. Furthermore, our approach improves upon motion estimation methods that solely consider the skeleton.