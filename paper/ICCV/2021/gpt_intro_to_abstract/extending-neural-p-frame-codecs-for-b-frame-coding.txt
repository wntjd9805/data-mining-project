In this paper, we introduce a new approach for neural B-frame coding in the video coding domain. B-frames are inter-coded frames that use both past and future decoded frames as references to generate a prediction. However, current neural B-frame coding methods do not fully exploit the motion information provided by two references and often suffer from misalignment issues. To address this, we propose a simple yet effective method that involves interpolating two reference frames to obtain a single reference frame. This reference frame is then used by a P-frame model to predict the current frame, which is further refined using residuals. Our method takes advantage of the rich motion information available and does not suffer from the residual penalty due to misalignment.We demonstrate that by adding this frame interpolation component to an existing P-frame codec, the codec can efficiently encode both P-frames and B-frames. Our proposed B-frame coding approach, B-EPIC (B-Frame compression through Extended P-frame & Interpolation Codec), achieves state-of-the-art results and outperforms existing neural video codecs by a significant margin. Additionally, we provide a thorough analysis of the effect of Group of Pictures (GoP) structure on performance in video coding.Our contributions include introducing a novel B-frame coding approach, using weight-sharing for a single P-frame network to handle both P-frame and B-frame coding, analyzing the impact of GoP structure, and achieving new state-of-the-art results in neural video coding.