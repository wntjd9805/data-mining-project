Linear inverse problems are prevalent in computer vision and signal processing, with applications in super-resolution, image inpainting, and computed tomography. The objective of these problems is to recover a signal x from measurements y by inverting the forward process y = Ax + (cid:15), which is challenging due to the ill-conditioned operator A and noise. Traditional approaches involve linear reconstruction within Aâ€ y, or model-based approaches with prior information such as sparsity. Recent end-to-end learning solutions utilize deep neural networks to learn the inverse mapping directly from (x, y) samples, but require ground truth signals x for training, limiting their applicability. This paper explores the possibility of learning the reconstruction function without strong priors or knowledge of ground truth signals. By leveraging the properties of physical models, such as rotation or shift invariance, as mild prior information, an end-to-end equivariant imaging framework is proposed. This framework learns the reconstruction function from compressed measurements y alone, without the need for ground truth signals. Experimental results demonstrate the effectiveness of the framework in solving inverse problems, achieving comparable results to fully supervised networks trained with ground truth signals in sparse-view CT reconstruction and image inpainting tasks. The contributions of this paper include presenting a conceptually simple equivariant imaging paradigm, demonstrating its incorporation into deep learning pipelines, and validating its performance through qualitative and quantitative evaluations.