This paper addresses the role of contextual cues in object recognition and proposes a new context-aware architecture called Context-aware Recognition Transformer Network (CRTNet). The study leverages a 3D simulation engine and a virtual home environment to systematically study the effects of an object's context on recognition. The paper focuses on three fundamental aspects of context: gravity, object co-occurrences, and relative size. Psychophysics experiments are conducted to establish a human benchmark and compare it with state-of-the-art computer vision models. The proposed CRTNet model outperforms other models in normal context and demonstrates robustness to large contextual variations. The paper also introduces a new dataset for in- and out-of-context object recognition and provides the source code for CRTNet.