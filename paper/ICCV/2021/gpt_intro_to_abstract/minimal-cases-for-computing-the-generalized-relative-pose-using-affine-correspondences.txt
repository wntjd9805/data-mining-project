Relative pose estimation from multi-camera systems is a critical problem in computer vision that plays a significant role in applications such as simultaneous localization and mapping (SLAM) and structure-from-motion (SfM). This paper focuses on the problem of estimating the relative pose of multi-camera systems from affine correspondences (ACs). Multi-camera systems have the advantage of a large field-of-view and high accuracy due to multiple individual cameras connected to a single rigid body. However, the absence of a single projection center makes the relative pose estimation problem different from that of monocular cameras. Most state-of-the-art SLAM and SfM pipelines using multi-camera systems apply relative pose estimation algorithms repeatedly to remove outlier matches. The computational complexity of this process depends on the number of points required for relative pose estimation, affecting the real-time performance of SLAM and SfM. Therefore, finding minimal solutions for relative pose estimation is important, and previous works have explored this area. This paper introduces a new constraint that relates ACs to the generalized camera model under general motion. It also proposes three solvers for different scenarios: planar motion, known vertical direction, and general motion. These solvers use ACs instead of point correspondences and require fewer correspondences to estimate the relative pose. The proposed methods have advantages over existing point-based solvers and can improve the accuracy, efficiency, and robustness of relative pose estimation algorithms for multi-camera systems.