Photometric Stereo (PS) is a classic problem in computer vision that involves using multiple images with varying illumination to calculate local geometrical features at each pixel. This requires at least three input images to have a unique solution. One of the main challenges in this problem is retrieving the 3D shape from the light reflected off the object, as this reflection is dependent on the material properties and follows a non-linear relationship. Various mathematical models, such as the surface bidirectional reflectance distribution function (BRDF), have been proposed to account for different types of reflection phenomena. Recently, convolutional neural networks (CNNs) have been used to solve the PS problem by parametrizing it as a normal regression task. CNN-based approaches have shown superior performance compared to classical optimization methods, as they can handle a wide range of realistic reflectances. Additionally, CNNs can learn robustness to deviations from the irradiance equation, such as global illumination effects, if the training data includes them. However, rendering realistic data for training CNNs can be computationally expensive, especially for objects with complex geometry and materials. To address this, we propose a per-pixel observation map generation strategy that allows for efficient training data generation without the need for full image rendering. We also introduce an improved CNN-PS architecture and show that including RGB channels in the observation map can further improve performance. In the following sections, we discuss related work, describe our proposed CNN approach, present the experiment setup and results.