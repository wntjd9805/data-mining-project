This paper focuses on the task of establishing correspondences from 2D images to 3D human body models in computer vision. This task is crucial for analyzing human action and enables various applications such as texture transfer, virtual try-on, and 3D human reconstruction. The current state-of-the-art method, DensePose, uses the Skinned Multi-Person Linear (SMPL) model, but it has limitations in terms of its applicability in real-world scenarios and controllability.To address these limitations, this paper proposes a new 3D model called DeepDaz, which is based on the industry-recognized Daz2 model. DeepDaz overcomes the limitations of the SMPL model by introducing decoupling parameters with clear physical meanings that provide better control over the generation of human bodies. DeepDaz is also compatible with mainstream design software used in the CG industry, making it more practical and valuable.To evaluate the performance of DeepDaz, the authors also introduce a new synthetic dataset called UltraPose. This dataset contains 500K persons and 1.3B corresponding point annotations on the surface of the DeepDaz model. UltraPose has several appealing properties, including ultra-dense annotations, rich diversity without manual annotation costs, absolute truth values without any errors, and providing 3D parameters and depth information for further research.To tackle the challenge of dense pose estimation on this large-scale and diverse benchmark, the paper proposes a transformer-based model inspired by the combination of Transformers and U-Net. This model achieves state-of-the-art accuracy on the UltraPose benchmark and can be directly applied to real-world scenarios, demonstrating impressive performance.In summary, this work presents three major contributions: replacing the SMPL model with the DeepDaz model, proposing a realistic human body generation system and the UltraPose benchmark, and introducing a transformer-based method for ultra-dense pose estimation. These contributions enhance the applicability and performance of dense pose estimation in computer vision.