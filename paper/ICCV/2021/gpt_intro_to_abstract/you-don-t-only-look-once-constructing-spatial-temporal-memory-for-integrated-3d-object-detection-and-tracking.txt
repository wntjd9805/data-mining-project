Humans possess the ability to continuously locate, track, and recognize objects in 3D space, even under challenging conditions such as occlusion or truncation. However, existing tracking-by-detection systems still rely on processing each video frame individually, without utilizing the temporal memory of objects in the surrounding scene. In this paper, we propose a novel system called UDOLO that integrates spatial-temporal memory into the object detection and tracking pipeline. UDOLO maintains a dynamic object occupancy map (OOM) and object future state predictions as spatial-temporal memory to assist object detection in future frames. The OOM is constructed by registering 3D observations in previous frames to the world frame and fusing occupancy states. The proposed system integrates the spatial-temporal memory into a two-stage object detection pipeline at the early and middle stages. In the early stage, the Region Proposal Network (RPN) only extracts object proposals in regions with high object occupancy scores, reducing computational burden. In the middle stage, current-frame object proposals are fused with back-end object future state predictions to produce more accurate bounding boxes. Experimental results on the ScanNet and KITTI datasets demonstrate that the integration of spatial-temporal memory significantly enhances 3D object detection and multiple object tracking performance, especially in dynamic and occluded environments. The proposed framework contributes to the literature by presenting an integrated detection and tracking system that utilizes spatial-temporal memory, along with early and middle integration schemes for more efficient and accurate object detection and tracking.