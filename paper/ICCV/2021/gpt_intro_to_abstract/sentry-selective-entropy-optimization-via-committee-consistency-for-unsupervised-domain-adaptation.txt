Unsupervised domain adaptation (UDA) aims to transfer a predictive model from a labeled source domain to an unlabeled target domain. While UDA methods have been extensively studied under the assumption of covariate shift, many modern techniques implicitly assume that the label distribution remains unchanged across domains. However, in real-world scenarios, both the data distribution and label distribution can experience shifts. To address this joint data and label distribution shift, we propose a novel algorithm called Selective Entropy Optimization via Committee Consistency (SENTRY) for UDA. SENTRY first identifies reliable target instances for self-training based on their predictive consistency under a committee of random image transformations. Then, it performs selective entropy optimization, minimizing predictive entropy and increasing model confidence on highly consistent instances, while maximizing predictive entropy and reducing confidence on highly inconsistent instances. Our algorithm achieves state-of-the-art performance on various domain adaptation benchmarks, including DomainNet, OfficeHome, and VisDA.