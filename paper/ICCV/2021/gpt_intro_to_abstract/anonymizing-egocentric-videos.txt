This paper discusses the privacy breach in egocentric videos, where the recognition of the wearer from such videos can lead to a violation of privacy. The authors propose a solution to this problem by adding subtle 3D rotations to the egocentric videos, which can disrupt wearer recognition techniques without affecting other video analysis tasks. The effectiveness of the proposed transformation is demonstrated through experiments, showing that it significantly reduces wearer recognition ability while maintaining performance in other tasks. The paper highlights the importance of addressing privacy concerns in egocentric videos and the potential threat it poses to ongoing research. The authors introduce a perturbation technique that anonymizes egocentric videos by adding noise, noting that most state-of-the-art video analysis techniques are already resilient to some degree of noise. However, the addition of excessive noise may degrade video quality and impact other analysis tasks. The contributions of the paper include the proposal of the novel transformation technique that prevents privacy leaks without compromising performance in other tasks, the demonstration of the degradation in wearer recognition performance on benchmark datasets, and the introduction of a new technique for wearer recognition using self-attention and ar-c-softmax loss. Overall, this work addresses the urgent need for securing egocentric video datasets and proposes effective solutions to protect wearer privacy while maintaining data utility.