Deep neural networks (DNNs) have achieved impressive results in the classification problem. However, these classifiers often make overconfident predictions on out-of-distribution (OOD) samples, leading to unreliable results. Previous approaches have focused on calibrating the outputs between in- and out-of-distribution samples through OOD detection. However, the OOD overconfidence issue still persists, and the effectiveness of OOD detection depends on the performance of DNN classifiers. In this paper, we propose Chamfer OOD examples (CODEs), a subset of OOD samples that are generated to suppress predictions on them. We introduce a method that uses training data to generate CODEs by first creating seed examples that are OOD and then transforming their distribution using Chamfer generative adversarial network (GAN). Our approach effectively alleviates the OOD overconfidence issue without affecting the original classification accuracy on in-distribution (ID) samples. We conduct extensive experiments and demonstrate that CODEs outperform existing methods in alleviating the OOD overconfidence issue. Moreover, CODEs have broader applications in improving OOD detection and image classification. Our contributions include highlighting the importance of distribution distance in OOD examples, proposing a simple method to generate CODEs without extra data, validating the effectiveness of CODEs in addressing the OOD overconfidence issue, and demonstrating their applications in improving OOD detection and image classification.