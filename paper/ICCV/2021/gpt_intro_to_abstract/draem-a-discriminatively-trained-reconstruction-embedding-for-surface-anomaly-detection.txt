Surface anomaly detection is a challenging task in computer vision, particularly in quality control and defect localization applications. Unlike general anomaly detection, surface anomaly detection focuses on localizing small regions of an image that deviate from a normal appearance. This is in contrast to entire images being considered anomalous. Anomalies in surface anomaly detection are typically close to the distribution of the training set and occupy only a small fraction of the image pixels.In practice, it is difficult to obtain annotated images with anomalies, and the appearances of anomalies may vary significantly. This leads to imbalanced training sets that often contain only anomaly-free images. To address this, reconstructive methods such as Autoencoders and GANs have been explored extensively. These methods enable learning of a powerful reconstruction sub-space using only anomaly-free images. By thresholding the difference between the input image and its reconstructed appearance, anomalies can be detected based on their poor reconstruction capability.In this paper, we propose a new deep surface anomaly detection network that is trained in an end-to-end manner on synthetically generated out-of-distribution patterns. The network consists of a reconstructive sub-network and a discriminative sub-network. The reconstructive sub-network learns anomaly-free reconstruction, while the discriminative sub-network learns a model over the joint appearance of the original and reconstructed images, producing a per-pixel anomaly detection map.Unlike related approaches that learn surrogate generative tasks, our proposed model is trained discriminatively. It does not require the synthetic anomaly appearances to closely match the test-time anomalies, yet it outperforms state-of-the-art methods. By leveraging synthetic data and discriminative training, our approach offers a promising solution for surface anomaly detection with minimal supervision.