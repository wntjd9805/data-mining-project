Consumer cameras, such as webcams and mobile phones, often use CMOS sensors with rolling shutter (RS) mechanisms due to their low cost and simplicity in manufacturing. However, RS cameras generate images row-by-row sequentially, resulting in RS effects such as stretch and wobble in images and videos captured by a moving RS camera. Ignoring these RS effects can lead to performance degradation or failure in computer vision applications. This paper proposes a method to invert the RS imaging mechanism, recovering high framerate global shutter (GS) video from consecutive RS images. The goal is to perform RS temporal super-resolution (RSSR) by solving the underlying RS geometry, which is challenging due to subtle intra-frame motions, camera calibration, and iterative optimizations. The proposed RSSR pipeline uses bidirectional RS undistortion flows to characterize RS-aware pixel displacement and develop a data-driven solution that encapsulates the underlying RS geometry. The pipeline consists of estimating bidirectional optical flows, learning scaling factors for RS undistortion flows, and using softmax splatting to produce high framerate GS video frames. The approach outperforms existing methods in RS artifact removal and inference efficiency and can generate a smooth and continuous video sequence. The main contributions of this paper include identifying the scanline-dependent nature of RS undistortion flows, providing a theoretical motivation for learning-based RSSR, and demonstrating superior performance in RS effect removal and video sequence generation.