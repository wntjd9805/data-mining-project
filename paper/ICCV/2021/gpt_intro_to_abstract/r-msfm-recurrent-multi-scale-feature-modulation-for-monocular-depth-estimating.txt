This paper introduces Recurrent Multi-Scale Feature Modulation (R-MSFM), a lightweight deep learning architecture for monocular depth estimation. R-MSFM reduces the parameters of Monodepth2 by 73% while achieving state-of-the-art accuracy and reasonable inference speed. R-MSFM consists of a depth encoder, a parameter-shared depth decoder, a parameter-learned upsampling module, and a multi-scale feature modulation module. Unlike traditional coarse-to-fine architectures, R-MSFM performs progressive refinement at a fixed fine resolution, overcoming limitations such as error propagation and difficulty in delineating small objects. Experimental results demonstrate the superior performance of R-MSFM in terms of accuracy, model size, and speed.