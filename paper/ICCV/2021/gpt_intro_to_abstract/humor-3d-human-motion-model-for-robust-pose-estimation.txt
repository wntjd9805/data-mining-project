This paper introduces a learned, autoregressive, generative model called HuMoR that captures the dynamics of 3D human motion. HuMoR models the probability distribution of pose transitions, allowing for realistic motion generation. It is formulated as a conditional variational autoencoder and incorporates explicit predictions of ground contacts. The model is trained on a large motion capture dataset and is used as a motion prior at test time for 3D human perception from noisy and partial observations. The paper also presents a robust test-time optimization strategy that utilizes HuMoR to estimate parameters of 3D motion, body shape, ground plane, and contact points. The method outperforms state-of-the-art techniques in terms of accuracy and physical plausibility under occlusions, and demonstrates generalization to diverse motions and body shapes. The contributions of this work include the HuMoR generative motion prior, the robust test-time optimization approach, and the capability to operate on a variety of inputs for accurate and plausible motion estimation. The paper also suggests that neural nets for dynamics problems can benefit from architectures that model transitions, allowing for control structures similar to classical physical formulations.