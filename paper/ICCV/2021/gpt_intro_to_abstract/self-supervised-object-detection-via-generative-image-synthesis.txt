Object detection is a critical component of autonomous vision pipelines in robotics and self-driving applications. Current convolutional neural networks-based detection methods require large amounts of fully annotated human data, making the data acquisition process time-consuming. Additionally, these methods do not scale well when transitioning between different operating environments. To address these limitations, some existing works have explored training object detectors without bounding box annotations using self/weakly supervised paradigms or rendering-based methods. However, these methods still have their own drawbacks, such as relying on high-quality object proposals or having a large domain gap from real-world images. In this paper, we propose a novel self-supervised object detection framework called SSOD, which utilizes controllable generative synthesis via GANs. Our framework learns to both synthesize images and detect objects using unlabeled image collections, without the need for bounding box labels or 3D CAD assets. By leveraging the control over the 3D location and orientation of objects provided by controllable GANs, we are able to obtain corresponding bounding box annotations. We tightly couple the synthesis and detection networks in an end-to-end manner to train SSOD optimally. Furthermore, we demonstrate the ability of SSOD to adapt to multi-object target datasets without requiring labels for them, resulting in improved accuracy.We evaluate SSOD on the KITTI and Cityscapes datasets for car object detection and compare its performance to existing self-supervised and rendering-based methods. Our results show significant improvement in detection accuracy compared to the best prior self-supervised method and outperform the rendering-based baseline. We believe that SSOD, as the first work to explore the use of controllable GANs for fully self-supervised object detection, opens up new possibilities for advancing research in this area.