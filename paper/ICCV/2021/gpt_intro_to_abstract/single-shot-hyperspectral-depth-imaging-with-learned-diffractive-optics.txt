This paper introduces the concept of hyperspectral-depth (HS-D) imaging, which combines spectral information with depth imaging. HS-D imaging has applications in various fields such as remote sensing, food and agriculture, medical imaging, defense, robotics, autonomous driving, mobile photography, and augmented/mixed reality. Existing HS-D imaging systems use a combinational approach, capturing spectral and depth information separately and then combining the results. However, this approach has limitations in terms of form factor, cost, capture time, and alignment problems. To overcome these limitations, this paper proposes a compact single-shot HS-D imaging method using a diffractive optical element (DOE) in front of a conventional camera sensor. The key idea is that depth and spectrum are closely coupled in DOE-based imaging systems, enabling single-shot HS-D image capture. The researchers develop a fully differentiable image simulator that synthesizes a sensor image for a given DOE height profile, along with a convolutional neural network (CNN) that estimates depth and spectrum from the sensor image. This allows for joint optimization of the DOE and CNN through backpropagation.One challenge in this approach is the lack of a ground-truth HS-D dataset for supervision during optimization. To address this, the researchers build a benchtop HS-D imaging system and capture a dataset of hyperspectral reflectance images and depth maps. This dataset can be used for data-driven plenoptic imaging research and will be made publicly available.Experimental results demonstrate that the proposed HS-D imaging method outperforms existing single-shot HS-D imaging methods and alternative optical designs in terms of form factor and accuracy. The contributions of this work are a compact monocular HS-D imaging method with a learned DOE, a HS-D dataset acquired by a benchtop imaging system, and experimental verification through optimized DOE fabrication.