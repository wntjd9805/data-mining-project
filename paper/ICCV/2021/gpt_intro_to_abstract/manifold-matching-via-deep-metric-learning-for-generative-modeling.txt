Deep generative models, such as Variational Autoencoder (VAE) and Generative Adversarial Networks (GAN), have achieved great success in tasks like image and video synthesis. However, these models mainly focus on matching statistical distributions without considering the underlying metrics. This paper introduces a geometric perspective to generative models, treating the real data set as a manifold embedded in high-dimensional Euclidean space. The authors propose a Manifold Matching (MM) objective that learns intrinsic distances among data points, using shape descriptors and a metric generator. The distribution generator and metric generator work interchangeably during training to improve the generated distribution and metric. The learned distances can be used for energy-based loss functions and reveal meaningful geometric structures of the real data manifold. The proposed framework is applied to unconditional image generation and single image super-resolution tasks, demonstrating its feasibility and advantages. The contributions of this paper include the manifold matching approach for generative modeling, a flexible framework for modeling data and objectives, and experimental validation of the proposed framework.