The crowd counting task involves estimating the number of individuals in images or videos. Although data-driven models using CNN have achieved satisfactory results, they still require a large amount of annotated data. Annotating the positions of all heads is a labor-intensive task, leading to a high annotation cost. To address this, we propose a partial annotation learning approach, where only a patch of each training image is annotated. We observe that there are consistent patterns in head poses, lighting conditions, and viewing angles within an image. We leverage these patterns to reduce annotation cost while maintaining performance. Specifically, we use a memory bank to store feature patterns from annotated regions and match features from unannotated regions to those in the memory bank. We also introduce a Feature Distribution Consistency regularizer to ensure the similarity of feature distributions between annotated and unannotated head regions. Additionally, we utilize a Cross-regressor Consistency Regularization to learn visual representations in a self-supervised manner. Our experiments demonstrate that the proposed model achieves better performance with only 10% annotated regions compared to recent methods and baselines on various datasets under semi-supervised or active learning settings.