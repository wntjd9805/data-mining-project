Abstract:The proliferation of forgery images on the Internet has become a critical issue due to their potential use in creating fake news and rumors. This paper focuses on the detection and localization of splicing forgery images, which involve copying and pasting regions from source images onto target images. Conventional methods for detecting image forgery often fail due to their susceptibility to post-processing effects. On the other hand, convolutional neural network (CNN)-based methods face challenges in detecting tampered regions when artifacts are suppressed or reduced by image fakers. To address these issues, this paper proposes the use of Mixed Adversarial Generators (MAG) for image splicing forgery detection and localization. However, MAG requires computationally intensive class segmentations for retouching splicing forgery images. In this work, the authors rethink the principle of generating and detecting forgery images by considering the retouching process as an image style transform. They propose a fake-to-realistic transform generator (GT) and a localization generator (GM) to simulate the faker and detect tampered regions, respectively. The proposed method, named Reality Transform Adversarial Generators (RTAG), leverages α-learnable whitening and coloring transform blocks (α-learnable WCT) to progressively retouch splicing forgery images and improve detection and localization abilities. Experimental results demonstrate the effectiveness of the proposed method in detecting and locating tampered regions even when there are fewer tampering artifacts present. The contribution of this work lies in considering the retouching process as an image style transform, proposing GT and GM for forgery detection and localization, and achieving better detection results through adversarial training.