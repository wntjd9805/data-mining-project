Face alignment is a fundamental task in computer vision, playing a crucial role in applications such as face recognition, face synthesis, and face 3D reconstruction. Convolutional Neural Networks (CNNs) have greatly improved the accuracy of facial landmark detection and continue to drive advancements in this field. However, the presence of error-bias, which can be considered a special kind of AI-bias resulting from biased assumptions or prejudices during algorithm development or training, remains a challenge. This paper investigates error-bias in face alignment and proposes a novel approach to leverage this bias for improved model understanding and performance.The paper begins by highlighting the existence of error-bias in common face alignment models, with an analysis showing that the error-bias aligns with labeling-bias. It is observed that models have an easier time converging errors in the normal direction than in the tangent direction, likely due to noisy labels and semantic confusion. Inspired by this finding, the authors propose a new training framework called ADNet, which introduces stronger and weaker constraints in the normal and tangent directions, respectively.ADNet incorporates two key components: the Symmetric Direction Loss and the Anisotropic Attention Module. The Symmetric Direction Loss disentangles landmark errors into normal and tangent errors, applying a stronger constraint to the normal error and a weaker constraint to the tangent error. This loss function is an improved version of the Ln loss. The Anisotropic Attention Module combines point heatmap and edge heatmap to generate a combined attention heatmap that captures both landmarks information and local boundary information. By applying this heatmap as a mask to the landmarks heatmap, the model becomes more tolerant to errors in the tangent direction while being less tolerant in the normal direction.The proposed approach is evaluated on several academic datasets, including 300W, WFLW, and COFW. The results demonstrate that the method achieves state-of-the-art performance, highlighting its effectiveness and robustness.In summary, the contributions of this paper include: 1) identifying and unveiling error-bias in face alignment, proposing a guideline to leverage this bias for improved performance; 2) introducing the Anisotropic Direction Loss, which assigns uneven loss weights to normal and tangent errors to magnify error-bias; 3) proposing the Anisotropic Attention Module, which generates anisotropic attention masks to further magnify error-bias; 4) constructing an advanced end-to-end training pipeline and conducting extensive experiments on various datasets, demonstrating the superiority of the proposed method.