This paper focuses on the challenging task of visible infrared person re-identification (VI-REID) in video surveillance. While visible cameras have achieved remarkable performance in person re-identification, they are not effective in capturing identity information in the dark. To address this, infrared cameras are deployed alongside visible cameras for 24-hour video surveillance. The authors propose a syncretic modality collaborative learning model for VI-REID, which combines visible and three infrared image modalities to capture modality-invariant representations with high discriminability. They also introduce challenge enhanced homogeneity learning to increase the difficulty of infrared image classification and auxiliary distributional similarity learning to shrink the cross-modality gap. An incremental training scheme is developed to handle the distribution of heterogeneous images and learn more effective modality-shared discriminative representations. Experimental results validate the effectiveness of the proposed method, which outperforms state-of-the-art methods in VI-REID.