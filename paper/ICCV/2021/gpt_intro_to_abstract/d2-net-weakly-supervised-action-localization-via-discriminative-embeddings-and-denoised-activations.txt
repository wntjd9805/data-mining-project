Temporal action localization is a challenging problem in computer science that involves both classifying and localizing the temporal boundaries of actions in videos. Existing approaches for this problem rely on strong supervision, requiring manual annotations of temporal boundaries during training. However, this type of annotation is laborious, expensive, and prone to variations. In contrast, weakly supervised action localization learns to localize actions using only video-level supervision, making it more practical.Existing weakly supervised methods typically use video-level annotations in the form of action classes and learn class-specific scores called temporal class activation maps (TCAMs). These methods use a classification loss to obtain discriminative foreground regions in the TCAMs. Some approaches use action labels to learn TCAMs and then obtain temporal boundaries through post-processing, while others use a combination of TCAM-generating video classification and explicit localization branches to directly regress action boundaries. However, the quality of TCAMs heavily influences the localization performance, and in weakly supervised settings, the TCAMs often contain noisy activations, leading to false positives and false negatives.In this work, we propose a unified loss formulation for weakly supervised action localization that addresses the problem of foreground-background separation, as well as explicitly tackles the noise in TCAMs. Our loss formulation includes a discriminative loss term to separate background from actions and a denoising loss term to address the noisy outputs in TCAMs. We are the first to introduce a loss term that captures mutual information (MI) across multiple snippets within a video and across all videos in a batch for weakly supervised action localization.We evaluate our proposed method, called D2-Net, on multiple benchmarks including THUMOS14 and ActivityNet1.2. Our experiments show that D2-Net performs favorably compared to existing weakly supervised methods, achieving significant improvements in mAP at IoU=0.5 on THUMOS14.