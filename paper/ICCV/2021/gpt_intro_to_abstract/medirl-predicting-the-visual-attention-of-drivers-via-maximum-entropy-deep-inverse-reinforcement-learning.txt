Autonomous vehicles have made significant advancements in recent years, promising improved safety and freedom from the task of driving. However, one challenge is the ability of vision-based models integrated into these vehicles to quickly identify important visual cues and understand risks in urgent traffic situations. Humans have the ability to quickly detect relevant stimuli, direct attention to potential hazards, and selectively process information. In this paper, we introduce a novel approach called Maximum Entropy Deep Inverse Reinforcement Learning (MEDIRL) to learn task-specific visual attention policies for predicting attention in imminent rear-end collisions. We leverage human visual attention mechanisms and utilize inverse reinforcement learning algorithms to imitate the efficient attention allocation of expert drivers. Our proposed MEDIRL model predicts eye fixations as potential sources of reward and uses collective visual information to locate salient regions of a driving scene before collisions. We also introduce a new driver attention dataset called EyeCar, which captures attention before accidents in high-traffic environments. Extensive evaluations on benchmark datasets and EyeCar demonstrate that MEDIRL outperforms existing models in driver attention prediction. Our contributions include the proposal of MEDIRL, the introduction of the EyeCar dataset, and the determination of key factors (target, non-target, driving tasks) influencing driver attention prediction.