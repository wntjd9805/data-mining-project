Semantic segmentation of 3D point clouds is a vital task in computer vision with many practical applications. Current deep learning approaches for this task heavily rely on labeled point cloud data, which is time-consuming and labor-intensive to obtain. In contrast, collecting unlabeled point cloud data is less demanding through 3D scanning and data post-processing. Therefore, we propose exploring semi-supervised learning (SSL) to improve the efficiency and performance of deep segmentation models using unlabeled point clouds.While SSL has been extensively studied for 2D images, it is relatively underexplored for 3D point clouds. Consistency regularization is a common strategy in SSL that aligns features of the same image/pixel to maintain prediction consistency when using unlabeled data. Inspired by the contrastive loss used in self-supervised learning, we further enhance feature representation in SSL by introducing the guided point contrastive loss. This loss increases the distance between features of different categories using semantic predictions as guidance.Contrastive learning has been successful in 2D images and has recently been extended to 3D point clouds through methods like PointContrast. However, negative pairs in the same category can weaken the discriminative ability of features in the absence of labels. In our approach, we optimize the network model using labeled point clouds to produce point-level semantic predictions, and utilize the predictions as guidance for the contrastive loss computation. This pseudo-label guidance reduces the impact of intra-class negative pairs on feature learning. Additionally, we propose a category-balanced sampling strategy to mitigate class imbalance and improve feature diversity in contrastive learning.We conduct experiments using a combination of labeled and unlabeled data, demonstrating the effectiveness of our SSL method for indoor and outdoor scenes. Our method consistently outperforms supervised-only models with varying amounts of labeled data on multiple datasets. We also evaluate our method using only labeled data, showing that our guided point contrastive loss improves feature representation and discriminative ability even without additional unlabeled data.In summary, our contributions include the adoption of SSL for 3D scene semantic segmentation, the extension of contrastive learning to semi-supervised segmentation using pseudo-label and confidence guidance, and the proposal of a category-balanced sampling strategy to address class imbalance and increase embedding diversity.