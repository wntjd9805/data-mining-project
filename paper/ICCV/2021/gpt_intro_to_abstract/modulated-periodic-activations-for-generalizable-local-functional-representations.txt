Functional neural representations using Multi-Layer Perceptrons (MLPs) have gained recent interest due to their ability to approximate complex signals such as images, videos, and audio recordings. These representations have shown to be more compact and efficient than discrete counterparts. However, generalizing MLP-based representations to unseen signals remains challenging. Previous approaches require separate MLPs for each signal and have sought to improve generalization through various methods, but significant degradation in quality still occurs.In this paper, we propose a neural functional representation that achieves high-reconstruction quality and generalizes to multiple instances. Unlike previous works, our approach can encode functional representations for multiple discrete signals using a single model in a single feed-forward pass. Each signal is represented using a low-dimensional latent code, and two MLPs (a modulator and a synthesis network) are used for the functional mapping. The modulator plays a key role in generalization by consuming latent codes and modifying periodic activations in the synthesis network.We demonstrate that high-resolution images pose challenges for functional representations, as the quality degrades with increasing target resolution. To address this, we exploit the locality of images by partitioning the signal domain into a regular tiling and assigning a latent code to each tile. By focusing on local structures, functional approximations become more tractable. Our model architecture, combined with the exploitation of locality, allows for better functional representations of complex signals compared to previous methods.Our contributions include a local neural-functional representation that enables generalization and achieves high fidelity, as well as a new network architecture utilizing modulation and synthesis sub-networks for high-fidelity functional neural representations of images, shapes, and videos.