Single image super resolution (SISR) is a widely used technique for enhancing the resolution of low-quality images in various applications such as mobile phones, surveillance systems, and autonomous driving. With the advancement of deep learning, deep convolutional neural networks (CNNs) have been employed to address the SISR problem, outperforming traditional image recovery algorithms. The design of network architectures plays a crucial role in the performance of SISR models. Although many approaches have been proposed to improve quantitative results and visual quality, the computational cost needs to be considered for real-world applications. Several works have focused on reducing computation by constructing efficient SR models manually or using neural architecture search (NAS) algorithms. However, most existing methods process the entire image with the same computational strategy, resulting in inefficiency. Since natural images consist of distinct frequency signals, we propose a novel frequency-aware dynamic convolutional network (FADN) that exploits the frequencies of input instances to optimize the allocation of computations. In FADN, an input feature is divided into multiple components based on the discrete cosine transform (DCT) domain, such as high-frequency, medium-frequency, and low-frequency parts. These parts are processed using different convolutional layers with varying computation burdens. We conduct extensive experiments on benchmark datasets to validate the effectiveness of our approach. The results show that our method achieves comparable or even better super-resolution performance with fewer computations when compared to existing methods. The remaining sections of this paper discuss related works, describe our proposed method, present experimental results, and conclude the paper.