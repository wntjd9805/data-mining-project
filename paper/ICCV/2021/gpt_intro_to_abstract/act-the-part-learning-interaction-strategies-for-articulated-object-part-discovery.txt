This paper addresses the question of how perception and interaction are connected in understanding the physical world. While previous research has focused on static image and video datasets, this paper investigates the relationship between perception and interaction through articulated object part discovery and segmentation. The authors propose a novel approach, Act the Part (AtP), which learns interaction strategies to expose parts and generalize to unseen categories. The key insight is to couple action selection and segmentation inference, allowing the agent to reason about where to hold and push to move undiscovered parts. The approach is evaluated on multiple object categories, demonstrating effective interaction strategies, generalization to unseen instances and categories, and interpretable conditional reasoning. Additionally, the paper introduces a toolkit to enhance the PartNet-Mobility dataset for future research.