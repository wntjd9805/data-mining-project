Blind motion deblurring is a challenging problem in computer vision, as it aims to recover a sharp image from a degraded image caused by various factors such as depth variation, camera shakes, and object motions. Traditional approaches for image deblurring rely on estimating the blur kernel, but obtaining a satisfactory blur kernel remains an open problem. Recently, deep learning-based models have shown superior performance in learning the regression between blurry inputs and sharp images, particularly through a "coarse-to-fine" multi-scale architecture. However, these models suffer from challenges such as expensive runtime and structure redundancy. To address these challenges, we propose PyNAS, a lightweight multi-scale pyramid neural architecture search approach for image deblurring. PyNAS automatically optimizes hyper-parameters related to the scale-pyramid and patch-pyramid structures. Our main contributions are: 1) introducing a multi-scale architecture search algorithm for dynamic scene deblurring, 2) including the pyramid structure in the search space to handle non-uniform motion blurs, and 3) defining the hierarchical relationship among optimization variables and training the model in a top-to-bottom approach. We evaluate our algorithm on the GoPro and VideoDeblurring datasets and show that it outperforms state-of-the-art methods in terms of both performance and inference time.