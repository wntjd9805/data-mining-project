Image-to-image translation has gained significant attention in the field of computer vision, particularly with the introduction of GAN-based methods. These methods aim to decompose image representation into content and style spaces, allowing for the synthesis of new images by combining the content representation of a source image with a different style representation from a reference domain. However, existing solutions face challenges in preserving the identity of the source image, often resulting in over-adaptation to the reference domain and loss of original characteristics. To address these challenges, we propose a novel frequency-based image translation framework called FDIT. FDIT significantly improves identity preservation and enhances the realism of image hybrids compared to competitive baselines. Extensive experiments, ablations, and user studies demonstrate the superiority of FDIT in terms of identity preservation, image quality, and performance on various datasets. Additionally, our framework achieves state-of-the-art results on image translation and GAN-inversion tasks, showcasing its effectiveness and broad applicability.