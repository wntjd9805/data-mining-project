Efficient and accurate navigation within indoor environments is a crucial aspect for personal robots and has been extensively researched in the field of computer vision. In order to establish a common framework and standard metrics, the concept of PointGoal navigation was proposed. This task involves an agent randomly placed in an unfamiliar environment and tasked with navigating to a specific point relative to its initial location and orientation. The agent uses a discrete action space to navigate. Previous methods achieved near-perfect accuracy in noiseless scenarios. However, these assumptions are unrealistic in real-world scenarios where GPS sensors yield imprecise location data and perception and actuation are influenced by environmental factors. To address this, a recent benchmark was updated to include noisy actuation models and noise models for cameras. In this more realistic setting, the performance of existing policies dropped drastically to 0.3%. To understand the challenges of navigation in this realistic setting, this paper examines the effectiveness of three visual odometry (VO) techniques. These techniques leverage geometric invariances, incorporate discretization and ensembling, and utilize top-down orthographic projection of depth information as an additional signal. The experiments show that the VO techniques significantly improve navigation performance, achieving a success rate of 71.7% and an SPL of 52.5% on the PointNav benchmark. Additionally, using VO in the navigation policy executes 6.4 times faster than the previous state-of-the-art. Exhaustive ablations demonstrate the efficacy of each technique, and training the VO model separately allows for the reuse of navigation policies trained with perfect localization information. Overall, this study contributes to a better understanding of realistic PointGoal navigation and demonstrates the effectiveness of these VO techniques in enhancing navigation performance.