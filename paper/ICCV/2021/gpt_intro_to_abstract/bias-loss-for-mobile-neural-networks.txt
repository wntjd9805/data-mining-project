Deep CNNs have demonstrated remarkable performance in various computer vision tasks, but they often require a large number of parameters and heavy computational operations. In the context of AI applications on mobile devices, researchers have focused on developing high-performance yet resource-constrained CNN models. Compression techniques such as quantization, pruning, and knowledge distillation have been explored, but they often lead to a degradation in performance. Another approach is to design compact neural networks and architectural units that maintain performance without increasing parameters. However, these methods often rely on an increase in the number of parameters to achieve significant improvements. To address this issue, this paper proposes a task-specific objective function called Bias Loss, which weights each data point's contribution based on the diversity of features it provides. The authors use variance as a measure of diversity and design a nonlinear function to assign weights to the cross-entropy loss. Additionally, a new neural architecture called SkipblockNet is introduced to overcome the lack of extracted features in the last layer. Experimental results show that the proposed Bias Loss improves the performance of existing mobile models and exceeds the state-of-the-art compact neural networks on various tasks. The contributions of this paper include the design of a loss function to reduce misleading due to random predictions in compact CNNs, the introduction of an efficient neural architecture to increase unique descriptive features, and achieving state-of-the-art performance on the ImageNet classification task under resource-constrained settings.