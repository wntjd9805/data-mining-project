Optical aberration is a common problem in lens-based imaging systems, leading to a degradation in imaging quality. Modern camera lenses are designed with multiple lens elements to compensate for these artifacts, but this results in increased cost, weight, and lens flare. To address this issue, computational optical aberration correction techniques have been developed. These methods utilize algorithms to remove aberrations after the image is captured, rather than relying on complex lens designs. The aberrations can be formulated as convolution with spatially varying kernels, and their removal is achieved through deconvolution with image priors. This can be done using either non-blind or blind approaches, depending on whether the aberration model is calibrated beforehand. In this paper, we focus on the non-blind case, where the PSF is fixed and known. Previous research has proposed various algorithms for non-uniform deconvolution of the PSF caused by lens aberration. We also discuss the challenges of using deep neural networks for handling non-uniformity. To address these challenges, we propose a framework that combines deep network and model-based deconvolution in an iterative manner. We conduct experiments to evaluate the performance and efficiency of our approach, demonstrating state-of-the-art results with improved running efficiency.