Estimating physical distances between objects from a single view is a challenging problem in computer vision with wide applicability in real-world scenarios. Existing approaches often require complex calibration procedures or specialized hardware, limiting their usability. In this paper, we propose a distance estimation method that uses reference objects of known dimension present in a scene to auto-calibrate a fixed camera. Specifically, we utilize the presence of people in the imagery as a calibration pattern, making assumptions about their upright position on a common ground plane. We present a simpler and more accurate approach to solving camera parameters directly from keypoint measurements. Additionally, we jointly estimate the ground plane and 3D keypoints from a single view. Our system addresses the challenges of limited RGB output, expensive on-site calibration, and single-camera observation commonly faced in objects distance estimation. We contribute a direct formulation that estimates camera intrinsics, ground plane, and reconstructs 3D points from 2D keypoints. We also develop a fully automated system capable of estimating physical distances between people without manual calibration. To facilitate research in this area, we create the MEVADA dataset based on the publicly available MEVA dataset.