Deep neural networks have revolutionized many tasks in computer vision, but their security has become a major concern due to their vulnerability to adversarial attacks. In response, adversarial defense has become a critical topic in computer vision research. Various methods have been proposed to improve the robustness of deep models, but training a robust model remains challenging. Adversarial training with PGD attack has shown promise, but often leads to accuracy degradation on natural data classification. To address this issue, we propose a novel adversarial training scheme that significantly improves classification accuracy on natural data while achieving high robustness under black- and white-box attacks. Our approach leverages logits from a clean model trained only on natural data to guide the learning of a robust model. We illustrate the effectiveness of our method through experimental evaluations on CIFAR-10, CIFAR-100, and Tiny ImageNet datasets, demonstrating impressive performance and outperforming previous work by a large margin. Our method not only enhances model robustness, but also provides new insights for improving adversarial robustness in deep neural networks.