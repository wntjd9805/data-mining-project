This paper addresses the increasing demand for image compression by introducing a novel neural image compression method based on deep neural networks. The method employs autoencoders to model the compression and reconstruction process, optimizing the rate-distortion trade-off. Previous approaches have focused on network architecture optimization and entropy reduction. However, these approaches have limitations in faithfully restoring the original image and preserving spatial details. To overcome these limitations, the proposed Attentional Multi-scale Back Projection (AMBP) module aggregates intermediate features and extrapolates fine spatial details. Additionally, the method extracts and processes distinct frequency components of the input image. The method also incorporates a dual-branch encoder and a dual attention module to compress and recombine separate layer components. A rounding loss is added to reduce the quantization residual of the latent. The main contributions of this work are the novel back projection approach, the effective frequency decomposition and recombination scheme, and the finetuning strategy for rounding errors. Experimental results demonstrate the superiority of the proposed method in terms of rate-distortion performance compared to existing compression codecs.