Human behavior analysis using diverse data types has become a prominent research topic in computer vision. This is due to the wide range of potential applications, such as human-computer interaction, intelligent surveillance security, and virtual reality. Advanced sensors like Intel RealSense, Asus Xtion, and Microsoft Kinect have enabled the collection of various data modalities, including RGB and depth image sequences and videos. Traditionally, these modalities have been used separately or merged for action recognition tasks, yielding excellent results. However, the development of human pose estimation algorithms has made it possible to obtain accurate 3D skeleton data, which is less computationally expensive and more robust under different conditions. To analyze 3D skeleton motions, it is beneficial to consider their geometric shape independently of undesirable transformations. Therefore, we propose representing 3D skeleton landmarks in Kendall's shape space and modeling skeleton sequences as trajectories in this space. We introduce a novel geometric deep learning approach, called KShapeNet, for skeleton-based action recognition. The sequences are mapped to a linear tangent space and fed into a deep learning architecture that includes a transformation layer for optimizing rigid and non-rigid transformations of the skeletons to improve action recognition accuracy. The main contributions of this paper are the introduction of the KShapeNet architecture and the novel transformation layer for improved action recognition. The paper is organized as follows: Section 2 provides a brief review of existing solutions for action recognition and geometric deep learning, Section 3 describes the geometric modeling of skeleton trajectories on Kendall's shape space, Section 4 introduces the proposed KShapeNet architecture, Section 5 presents the experimental settings, results, and discussions, and Section 6 concludes the paper and outlines future research directions.