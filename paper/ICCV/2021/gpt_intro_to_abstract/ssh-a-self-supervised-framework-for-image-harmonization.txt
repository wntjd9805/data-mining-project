Abstract:In image compositing, it is important to adjust the appearance of a foreground object to match the background image for a more realistic composite. Traditional approaches have focused on transferring statistical information between the foreground and background regions, such as color and texture. Recently, deep neural networks have been trained to address the image harmonization problem, but these methods require a large-scale dataset of input-harmonized composite training pairs, which is challenging to obtain. Existing methods have attempted to bypass this issue by selecting foreground objects from existing images and perturbing their color to simulate an unharmonized composite. However, these approaches have limitations, such as limited availability of ground truth paired data and the need for accurately masking foreground objects. Therefore, there is a need for an improved approach to image harmonization in compositing.