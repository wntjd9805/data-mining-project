Fast and accurate image-based face reconstruction is crucial for various applications, including realistic videoconferencing, AR/VR experiences, special effects, and facial attribute manipulation/transfer. However, the complex interaction between light and faces, including shadows and specularities, poses a challenge for face reconstruction. Additionally, speed is essential for real-time use cases. While multi-view approaches exist, they may not be easily applied in certain applications such as VR or movies. Monocular face reconstruction methods that rely on parametric prior or optimization-based frameworks have limitations in terms of speed and handling difficult head poses and lighting conditions. Recent approaches incorporating ray tracing and CNN-based regression techniques have shown promise in terms of robustness and efficiency. However, current methods still fall short of the quality and robustness requirements for professional visual effects pipelines. To overcome these limitations, we propose a new approach that enables monocular reconstruction of detailed face geometry, spatially varying face reflectance, and complex scene illumination at high speed. Our approach utilizes a parametric face and scene model, CNN encoders, and an end-to-end differentiable ray tracing image formation model. Unlike previous methods, our approach achieves real-time performance, is independent of landmarks, and is suitable for in-the-wild conditions. Moreover, our method is the first self-supervised approach to achieve robust face reconstruction in challenging lighting conditions and captures person-specific albedo details. Our approach allows for various applications, such as relighting and light/albedo editing and transfer, and outperforms state-of-the-art methods in terms of robustness, accuracy, and versatility.