Recently, deep learning-based approaches in computational imaging have achieved state-of-the-art (SOTA) results. However, the complex network architectures and high computation overheads of these methods prevent real-time processing. Existing methods also struggle to produce visually pleasant results in real time. To address this challenge, hybrid methods that combine traditional image prior approaches with deep learning-based multi-level features have been proposed and achieved SOTA performance. However, these methods have limitations in considering local information and may produce less satisfactory results in certain areas, such as limited local contrast and color distortion. To overcome these issues, we present a novel CNN-based image enhancement approach that introduces spatial information to traditional 3D lookup tables (LUTs). Our method includes T spatial-aware 3D LUTs, each consisting of a set of M basic learnable 3D LUTs, and a two-head weight predictor trained simultaneously under a new loss function. The weight predictor incorporates global information for image-level scenario adaptation and pixel-wise category fusion for combining multiple LUTs. Enhanced images are obtained by fusing spatial-aware 3D LUTs based on the two types of weights. Our approach achieves high performance with an execution time of only 4 ms for processing a 4K resolution image on an NVIDIA V100 GPU. We make three main contributions: 1) proposing a spatial-aware 3D LUTs architecture for robust local enhancement, 2) designing a two-head weight predictor for learning image-level scenario and pixel-wise category information, and 3) conducting extensive experiments to demonstrate the advantages of our approach in terms of performance and efficiency compared to existing methods.