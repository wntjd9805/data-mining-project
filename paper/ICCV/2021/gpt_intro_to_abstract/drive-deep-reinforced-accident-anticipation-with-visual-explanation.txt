With the increasing demand for autonomous driving, anticipating future accidents is crucial for ensuring safe driving strategies. In this paper, we focus on the development of an accident anticipation model that utilizes dashcam videos to predict if and when a traffic accident will occur. Bridging the gap between visual perception and decision-making in driving control, we investigate where drivers look when predicting future accidents. This leads to the development of a visually explainable model that links low-level visual attention to high-level accident anticipation. The challenges in achieving accurate accident anticipation include capturing visual cues from limited and noisy video data before accidents occur, as well as balancing the trade-off between early and correct decision-making. To address these challenges, we propose the DRIVE model, which formulates the task as a Markov Decision Process (MDP) and utilizes deep reinforcement learning (DRL) to learn accident anticipation policies and fixation prediction. The model dynamically balances exploration and exploitation in the driving environment to maximize the total reward. We introduce novel dense anticipation and sparse fixation rewards to encourage early and accurate predictions and enable visual explanations. The DRIVE model is validated on the DADA-2000 dataset and can be easily extended to other datasets without fixation annotations. Compared to existing supervised learning frameworks, our DRL-based solution is superior in utilizing immediate observations for long-term goals. Additionally, our approach is introspectively explainable and validates that the learned visual attention is causally linked to agent outcomes. The main contributions of this paper are the development of the visually explainable DRIVE model for accident anticipation, the formulation of dense anticipation and sparse fixation rewards, and the improvement of the DRL training algorithm for effective model training.