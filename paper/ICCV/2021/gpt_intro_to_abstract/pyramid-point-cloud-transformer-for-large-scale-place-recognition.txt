Place recognition is a crucial task in the fields of computer vision and robotics, finding applications in areas such as autonomous driving, augmented reality, robot navigation, and simultaneous localization and mapping (SLAM). There are two main categories of place recognition: image-based and point cloud-based. Image-based recognition can be affected by environmental changes, while point cloud-based approaches have been proposed to overcome these limitations. In recent years, several point cloud processing methods have been developed, including PointNetVLAD, PCAN, LPD-Net, and SOE-Net. However, these methods have limitations in capturing local geometric structures and incorporating multi-scale structure information. In this paper, we propose a pyramid point cloud transformer network (PPT-Net) that utilizes a pyramid point transformer module to extract discriminative local features from point clouds at different contextual scales. We also introduce a pyramid VLAD module to aggregate these local features into discriminative global descriptors. Experimental results on benchmark datasets demonstrate the state-of-the-art performance of our method in point cloud-based place recognition. Our contributions include the development of the pyramid point transformer and pyramid VLAD modules, which enable adaptive learning of spatial relationships and aggregation of multi-scale feature maps, respectively.