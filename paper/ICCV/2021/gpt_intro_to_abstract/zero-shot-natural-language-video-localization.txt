The paper introduces the concept of natural language video localization (NLVL), which aims to locate a specific moment in a video based on a natural language query. The authors mention that recent advancements in deep learning methods and annotated data have improved the performance of NLVL models. However, the process of obtaining paired annotations for training NLVL models is laborious and expensive. To address this issue, the authors propose a weakly-supervised setup of NLVL where temporal alignment of the query sentence is not required. They also introduce the concept of zero-shot NLVL (ZS-NLVL), which aims to train an NLVL model without any paired annotation. Inspired by image captioning tasks, the authors propose using unpaired data including videos, natural language corpora, and an object detector to train the ZS-NLVL model. The main approach involves generating pseudo-supervision of candidate temporal regions in the video and corresponding sentences to train the model. The authors highlight the benefits of this approach and discuss the challenges involved in generating the pseudo-supervision. They also propose a simple NLVL model architecture and compare the performance of their Pseudo-Supervised Video Localization (PSVL) framework with stronger supervision on benchmark datasets. The paper concludes by summarizing the contributions of the study, including the introduction of the zero-shot NLVL task and the establishment of baselines for comparison.