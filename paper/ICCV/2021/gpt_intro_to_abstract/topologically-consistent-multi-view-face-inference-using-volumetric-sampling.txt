Creating high-fidelity digital humans is a growing interest in various industries, including film, gaming, and consumer applications. The current methods for digitizing avatars involve using high-resolution multi-view images and manual cleanup processes. In this paper, we propose a novel volumetric approach for 3D face mesh inference using multi-view images. Our method is three orders of magnitude faster than conventional methods and can capture a wider range of facial expressions and deformation details. We introduce a progressive mesh generation network that predicts vertex locations and volumetric features, incorporating the topological structure of the face. Our experiments show that our method, called ToFu, produces highly accurate geometry with consistent topology. It eliminates the need for manual clean-up and parameter tuning, making it suitable for scaled digitization of high-fidelity facial avatars. Additionally, our approach provides a critical solution for generating large facial datasets with reduced manual labor. We demonstrate state-of-the-art performance in terms of geometry and correspondence accuracy. The code and model of our proposed approach are publicly available.