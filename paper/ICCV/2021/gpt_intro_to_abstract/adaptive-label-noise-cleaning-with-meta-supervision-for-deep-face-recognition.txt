Deep face recognition heavily relies on training data, but label noise is often present due to deficiencies in data collection and preprocessing. Increasing the data scale of face recognition datasets is essential for training deep models, but it also increases the label noise rate. Label noise negatively affects face recognition accuracy, leading to a contradiction between data size and cleanliness. To address this issue, data cleaning solutions have been proposed. However, these solutions often struggle with the domain gap between labeled and unlabeled data. In this paper, we propose the Adaptive Meta Cleaner (AMC) framework, which uses meta-learning to transfer cleaning knowledge. AMC treats the labeled data as the source domain and the unlabeled data as the target domain. A graph-based unsupervised method is used to pseudo-label the target data, which is then used to transfer cleaning knowledge instead of directly training the cleaning model. To handle the drift of the decision boundary in transfer learning, AMC incorporates adaptive threshold learning. We evaluate AMC on real datasets and compare its performance with previous cleaning methods. The results demonstrate the effectiveness of AMC in improving face recognition performance. Overall, this paper contributes a new perspective on the data cleaning task and provides a solution for transferring signals and noise distribution in deep face recognition datasets.