Finding dense correspondences between images is a crucial problem in computer vision, with applications in video analysis, image registration, image manipulation, and style transfer. However, supervised deep learning methods for dense correspondence estimation are limited by the availability of ground-truth annotations, which are often challenging and costly to collect. Current approaches rely on artificially rendered datasets, sparsely computed matches, or sparse manual annotations, which lack realism, accuracy, or scalability.In this paper, we propose Warp Consistency, an unsupervised learning objective for dense correspondence regression. Unlike existing approaches that heavily rely on photometric and warp-supervision losses, our method leverages the concept of warp consistency graph to derive a family of flow-consistency constraints. We carefully analyze the properties of these constraints and propose an unsupervised loss based on predicting the flow by the composition of images via a third image. This loss is combined with the warp-supervision constraint, resulting in our final warp consistency objective.We conduct comprehensive empirical analysis and compare our objectives to existing unsupervised alternatives. Our warp consistency loss outperforms methods based on photometric consistency and warp-supervision on multiple geometric matching datasets. We also integrate our approach into three recent dense matching architectures for geometric and semantic matching tasks, achieving substantial performance gains on various benchmark datasets. Our method achieves state-of-the-art results on all four datasets considered in this study.Overall, our unsupervised learning approach for dense correspondence estimation addresses the limitations of existing methods, providing accurate and scalable solutions for real-world applications.