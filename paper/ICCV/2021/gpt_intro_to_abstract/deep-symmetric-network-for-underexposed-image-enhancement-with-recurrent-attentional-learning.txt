Digital photography has become increasingly popular with the widespread use of digital cameras. However, poor shooting conditions or lack of photographic skills can result in unsatisfactory image quality. Image enhancement, especially for underexposed images, remains a challenge. Traditional algorithms and recent methods based on deep neural networks have limitations in adjusting local details and preserving content features. In this paper, we propose an invertible feature transformation framework for underexposed image enhancement. We introduce a deep symmetric network based on an invertible feature transformer (IFT) inspired by invertible neural networks (INN). Our network employs two pairs of pre-trained encoder-decoder to convert between underexposed and enhanced images. We address the image color bias problem and propose a recurrent residual-attention module (RRAM) to accurately restore desired image features. Our method achieves state-of-the-art results and performs bidirectional feature learning synchronously. The recurrent learning scheme allows gradual color adjustment without increasing network parameters. Experimental results on public datasets demonstrate the superiority of our approach. Our contributions include introducing INN into underexposed image enhancement and proposing a recurrent learning scheme with RRAM for accurate feature restoration and color adjustment.