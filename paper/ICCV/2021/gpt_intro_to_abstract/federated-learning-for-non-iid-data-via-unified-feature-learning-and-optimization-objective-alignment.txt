Nowadays, machine learning based artificial intelligence (AI) technologies heavily rely on large amounts of training data, increasing the risks of privacy disclosure and abuse. To address this issue, federated learning (FL) has been proposed as a new machine learning paradigm that allows for data sharing and collaboration across different clients while protecting privacy. However, existing FL approaches often ignore the divergence in data distributions among clients, resulting in poor performance on non-independent and identical distribution (non-IID) data. In this paper, we propose a novel FL method called FedUFO, which aims to align optimization objectives across clients to improve performance and fairness. We introduce a group consensus loss and a global consensus loss to explicitly reduce optimization objective inconsistencies and an adversary scheme with a unified adversarial loss to implicitly align feature representations. Experimental results demonstrate the superiority of FedUFO in real-world applications, providing a more reliable and fair AI ecosystem. The contributions of this paper include the design of the group consensus loss and the global consensus loss, the proposal of the adversary scheme with unified adversarial loss, and the evaluation of FedUFO on various computer vision tasks.