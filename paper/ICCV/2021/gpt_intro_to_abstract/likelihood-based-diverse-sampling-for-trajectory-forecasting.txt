Self-driving cars face the challenge of accurately predicting the future trajectories of other vehicles. Traditional forecasting models aim to predict a single ground truth future, but a more effective approach is to predict the full range of plausible futures using a deep generative model. However, sampling from the prior distribution of a deep generative model may fail to cover all modes in the trajectory distribution due to natural biases and uneven distribution of real-world traffic maneuvers. In this paper, we propose a post-hoc approach called Likelihood-Based Diverse Sampling (LDS) to enhance the quality and diversity of samples from a pre-trained generative model. LDS learns a sampling distribution that maximizes both the likelihood of the trajectories according to the model and a goal-based diversity objective. By jointly optimizing for these objectives, LDS encourages a set of forecasts to cover modes in the underlying trajectory distribution. Our experiments demonstrate that LDS provides a reliable performance boost when integrated with existing forecasting models and outperforms competing approaches. Additionally, LDS can be leveraged in the setting of transductive learning, allowing it to improve predictions for novel test instances without prior training. We believe that LDS offers a valuable solution for accurately forecasting future trajectories in self-driving cars.