Convolutional Neural Networks (CNNs) are widely used in computer vision tasks, but their internal inference rules are often seen as black-boxes. This lack of interpretability limits the trustworthiness and adoption of CNN models in critical applications like autonomous driving and medical diagnosis. Attribution map generation, which assigns scores to individual pixels based on their contribution to the network output, has been explored as a strategy to visualize the decision process of CNNs. This paper introduces Disentangled Masked Backpropagation (DMBP) as a novel gradient-based approach for generating reliable attribution maps. DMBP decomposes the computation of network outputs into linear mappings that separate nuisance, positive, and negative factors. These factors correspond to non-influential information, discriminative pixels providing evidence for the target label, and the same but with opposite polarity, respectively. Experimental results on standard network architectures and benchmark datasets show that attribution maps produced by DMBP are more consistent, informative, and visually interpretable compared to previous methods.