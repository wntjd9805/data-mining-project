This paper introduces a training paradigm to improve out-of-distribution (OOD) generalization in machine learning models. The authors argue that the commonly used paradigm of empirical risk minimization (ERM) captures all statistical patterns present in the training data, including unreliable and spurious correlations. They propose partitioning the data into multiple training environments, where spurious correlations vary while reliable correlations remain stable. This approach aims to encourage the model to rely on stable correlations that are more likely to generalize well at test time. The authors provide empirical evidence of the effectiveness of their method on the task of visual question answering (VQA), specifically in addressing language biases, leveraging known relations of equivalence between training questions, and multi-dataset training. The contributions of this paper include the proposal of the partitioning approach, its application to three VQA use cases, and empirical evidence of improvements in OOD generalization.