In recent years, there has been a growing interest in contrastive learning of visual representations. This approach has been shown to outperform supervised pre-training methods in various visual recognition tasks. The key to contrastive learning is to construct different views and transformations of the same instance and learn a deep representation that is invariant to these changes. The most common way to construct different views is through data augmentation techniques. However, this method has its limitations and researchers have started exploring the use of videos as a source for obtaining positive pairs of training images. In this paper, we propose a new approach to contrastive learning that samples positive image pairs across different videos instead of the same video. We believe that this can capture higher-level semantics and categorical information beyond what previous approaches have achieved. Specifically, we explain one frame in a video by composing frames from other videos that are similar to it, and then compare the composed frames to another frame for contrastive learning. We call this process Cycle-Consistent Contrastive Learning. We perform this self-supervised representation learning on an unlabeled video dataset and transfer the learned representation to various downstream tasks. Our experimental results show significant improvements over state-of-the-art approaches. Our contributions include a novel cross-video cycle-consistent contrastive learning objective, a loss function that enforces image representations from the same category to be closer without the need for pseudo labels, and significant improvements in multiple downstream tasks.