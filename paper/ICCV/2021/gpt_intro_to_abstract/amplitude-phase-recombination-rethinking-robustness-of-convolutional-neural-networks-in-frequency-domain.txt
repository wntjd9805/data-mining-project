The past few years have seen significant advancements in deep learning, particularly in image recognition and classification tasks. However, neural networks exhibit unintuitive generalization behaviors, such as vulnerability to adversarial examples and overconfidence for out-of-distribution samples. Current deep learning models heavily depend on the training data to accurately represent encountered data during deployment. To explain these generalization behaviors, several theoretical breakthroughs have been made from different model or algorithm perspectives. Some studies have investigated the generalization behaviors of Convolutional Neural Networks (CNNs) from a data perspective in the frequency domain, demonstrating the importance of high-frequency components that are imperceptible to humans. This dependence on high-frequency components leads CNNs to converge at local optima associated with these components, resulting in counter-intuitive generalization behaviors. On the other hand, humans rely more on phase components for object recognition. Inspired by the robustness of the human visual system, this paper proposes a novel data augmentation method called Amplitude-Phase Recombination (APR) to encourage CNNs to focus on phase spectrum and be less sensitive to amplitude variations. The proposed APR method outperforms baselines in various generalization and calibration tasks, including adaptability to common corruptions and surface variations, out-of-distribution detection, and adversarial attacks. This approach also provides a unified explanation for the texture bias hypothesis and the CNN's behavior in handling perturbations and out-of-distribution samples. The main contributions of this paper are the proposition of robust CNNs that are insensitive to amplitude variations and prioritize phase spectrum, the introduction of the APR method for data augmentation, and the unified explanation for robustness and overconfidence behaviors of CNNs.