Semi-supervised video object segmentation (VOS) is a challenging task that aims to segment the target object in a video sequence using limited supervision provided in the first frame. This paper introduces a novel two-branch architecture that combines transductive reasoning and online inductive learning to improve the accuracy of VOS. The transduction branch leverages feature matching to retain temporal information, while the induction branch utilizes online discriminative learning for superior distractor discrimination. The proposed framework integrates these two models by designing a merging strategy and tightly connecting them to avoid redundant computations. Key designs include the use of a lightweight transformer architecture for temporal information propagation, a two-head label encoder for generating target information, and a mask encoding decoupling regularization to reduce redundancy and enhance differentiability. Experimental results on benchmark datasets demonstrate that the proposed approach outperforms other state-of-the-art methods in terms of accuracy and efficiency. This work contributes to the field of VOS by proposing an innovative architecture that combines the strengths of transductive reasoning and online inductive learning, leveraging a transformer architecture for spatio-temporal modeling, and introducing disentangled mask encodings to better exploit the complementary characteristics of the two branches.