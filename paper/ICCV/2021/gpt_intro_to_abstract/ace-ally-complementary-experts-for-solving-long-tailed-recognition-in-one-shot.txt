Abstract:Object recognition is a crucial application in computer vision, but current state-of-the-art methods struggle to classify real-world entities that are naturally distributed in a long-tailed manner. Existing models, driven by artificially-balanced datasets, focus on the majority classes and neglect the tails. This limitation significantly hinders the practical use of classification-related computer vision tasks. To address this issue, tail-sensitive classifiers have been proposed, including one-stage, two-stage with pre-training, and multi-stage multi-expert frameworks. However, existing solutions suffer from the "seesaw" phenomenon, where improving the tails' accuracy sacrifices the accuracy of majority classes. This trade-off raises concerns, as misclassification of rare classes can have serious consequences. Previous approaches attempt to tackle this problem through re-adjusting classifiers or building diverse experts, but they are sensitive to hyper-parameters and lack integration with other tasks. To overcome these challenges, we propose Ally Complementary Experts (ACE), a one-stage long-tailed recognition method. ACE leverages a multi-expert structure, where experts are trained in parallel with a shared backbone. Each expert specializes in a specific subset of imbalanced data, and their outputs are re-scaled and aggregated for optimal decision making. ACE is trained end-to-end without pre-training or staged-training and outperforms existing methods on various long-tailed datasets. Our approach improves accuracy across all frequency groups and surpasses multi-stage methods by a large margin.