Neural Architecture Search (NAS) methods have been successful in discovering high-performance architectures for computer vision tasks. However, the large computation overhead and inductive biases limit their practical usage. Weight-sharing techniques have improved search efficiency but have restrictions and biases. Predictor-based NAS methods have the advantage of reducing the number of evaluated networks but still require significant computation. This paper proposes RANK-NOSH, an efficient predictor-based framework that reduces search costs by training architectures for fewer epochs. The framework incorporates a non-uniform successive halving algorithm and a pairwise ranking loss for training the performance predictor. Experimental evaluations demonstrate the effectiveness and generality of RANK-NOSH, achieving better results with reduced search budgets in various search spaces and datasets.