Scene graph generation is an important task in computer vision that aims to identify objects and their relationships in real-world images. Traditional scene graph models require large amounts of human-labeled data, which is time-consuming and labor-intensive to construct. Additionally, these models often suffer from the long-tail distribution of relations in real-world scenarios, with a majority of relation categories having insufficient labeled instances. To address these issues, this paper proposes visual distant supervision, a novel paradigm of visual relation learning that utilizes large-scale unlabeled data with minimal human efforts. By aligning commonsense knowledge bases and images, the proposed method creates labeled data to provide distant supervision for visual relation learning. This approach can overcome the limitations of supervised and weakly supervised methods and alleviate the long-tail problem. Experimental results show that the proposed model outperforms existing weakly supervised and semi-supervised methods without using any human-labeled data, and can further improve fully supervised models when incorporating human-labeled data. Additionally, a denoising framework is proposed to mitigate the noise in distantly labeled data. The effectiveness of visual distant supervision and the denoising framework is demonstrated through comprehensive experiments. This paper contributes to the field by introducing a new paradigm for visual relation learning, proposing a denoising framework, and providing insights for future research directions.