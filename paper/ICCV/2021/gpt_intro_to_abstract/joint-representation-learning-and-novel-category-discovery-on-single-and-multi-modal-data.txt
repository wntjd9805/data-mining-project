This paper addresses the challenge of automatically discovering new categories in the open world setting using deep learning. While deep learning models have shown impressive performance on tasks like image recognition and object detection, they heavily rely on large amounts of data with human annotations, which is not always feasible or cost-effective in the real world. Conventional methods struggle to handle unlabeled data from new categories, while pure unsupervised clustering may produce inconsistent results. In this paper, the authors propose a framework that partitions unlabeled data from unknown categories into semantic groups, leveraging both labeled and unlabeled data to build unbiased feature representations. They extend contrastive learning to consider both instance discrimination and category discrimination, as well as cross-modal discrimination for multi-modal data. To utilize more unlabeled data, they use Winner-Take-All hashing to generate pseudo labels on-the-fly. The proposed framework is evaluated on large-scale multi-modal video benchmarks and single-modal image benchmarks, outperforming existing methods. The contributions of this paper include the proposed end-to-end framework, the extension of contrastive learning, the use of WTA hashing for pseudo supervision, and the thorough evaluation on challenging datasets.