The field of robustness in computer science lacks consensus on evaluation benchmarks and hypotheses, with conflicting results on the robustness of language and vision models. Previous works have proposed various interpretations of empirical results and debated the generality of conclusions drawn from synthetic benchmarks. However, existing robustness datasets have limitations in terms of variation and diversity. To address these issues, this paper introduces four new robustness datasets and a new data augmentation method. These datasets include ImageNet-Renditions, StreetView StoreFronts, DeepFashion Remixed, and Real Blurry Images. The paper also presents DeepAugment, a data augmentation technique that improves robustness. The authors test four classes of methods for improving robustness, including larger models, self-attention layers, diverse data augmentation, and pretraining. The results of the experiments on these datasets support certain hypotheses and rule out others. The paper concludes that robustness is not a simple scalar property and calls for more thorough evaluation and nuanced understanding in future research.