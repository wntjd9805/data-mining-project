Monocular depth estimation is a crucial aspect of computer vision with applications in augmented reality, robotics, and autonomous driving. Traditional methods rely on costly depth sensors, while self-supervised approaches utilize geometry cues in videos to estimate depth maps without relying on high-quality depth data. However, existing self-supervised methods struggle with challenging nighttime scenarios due to low visibility and varying illuminations. This paper proposes an efficient nighttime self-supervised framework for depth estimation with three key improvements. Firstly, a Priors-Based Regularization (PBR) module is introduced to constrain incorrect depth predictions in the neighborhoods of depth references. Secondly, a Mapping-Consistent Image Enhancement (MCIE) module is employed to handle low visibility while maintaining brightness consistency. Finally, a Statistics-Based Mask (SBM) is presented to better handle textureless regions by flexibly tuning masked pixels using dynamic statistics. Experimental results demonstrate that these contributions lead to state-of-the-art performance in nighttime depth estimation and effectively reduce weirdness in depth outputs.