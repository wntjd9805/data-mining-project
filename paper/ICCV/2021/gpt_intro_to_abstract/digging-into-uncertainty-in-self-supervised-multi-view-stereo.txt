Multi-view stereo (MVS) is a computer vision problem that aims to recover 3D information from multiple images. Traditional MVS methods have been extended to deep neural networks, achieving state-of-the-art performance. However, fully supervised learning requires tedious and expensive procedures for collecting ground truth depth annotations. To overcome this limitation, self-supervised MVS tasks have been proposed, transforming the depth estimation problem into an RGB image reconstruction problem. However, the effectiveness of self-supervision in multi-view depth estimation is not well understood. In this paper, we visualize the uncertainty in both fully supervised and self-supervised MVS to gain insights into the factors that may lead to the failure of self-supervision. Through this analysis, we identify two main challenges: ambiguous supervision in the foreground and invalid supervision in the background. To address these challenges, we propose a novel Uncertainty reduction Multi-view Stereo framework (U-MVS). U-MVS includes designs to handle ambiguous supervision in the foreground and invalid supervision in the background. Our framework utilizes prior correspondence and consistency losses to improve the reliability of self-supervision, and incorporates uncertainty-aware self-training consistency loss to filter unreliable supervision signals. Experimental results on benchmark datasets demonstrate the competitive performance of our proposed method compared to fully supervised approaches.