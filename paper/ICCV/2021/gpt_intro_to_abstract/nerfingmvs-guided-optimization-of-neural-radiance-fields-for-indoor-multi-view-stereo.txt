This paper introduces a new neural network based optimization framework for multi-view depth estimation in 3D scene reconstruction. Previous methods have relied on cross-view image patch comparison and cost volume based architectures, but suffer from inconsistencies and violated photometric consistency. The proposed method directly optimizes over volumes using a guided optimization scheme based on neural radiance fields. The shape-radiance ambiguity of NeRF poses challenges in accurate depth estimation, but the paper shows that adapting depth priors and performing direct optimization significantly improves depth quality. Experimental results demonstrate the superiority of the proposed framework over existing methods in multi-view depth estimation and view synthesis. Furthermore, the integration of SfM reconstruction enhances the synthesis quality on neural implicit representations.