This paper introduces a Plug-and-Play (PnP) adaption framework for generalizing gaze estimation to new domains. Gaze estimation, which is important for various applications, has seen advancements in appearance-based techniques using deep learning. However, the performance of gaze estimation models trained on a single dataset degrades when tested on a new dataset due to differences in subjects, backgrounds, and illuminations. Existing works have focused on the inter-person gap within the same dataset, but neglect the differences between datasets when generalizing models. This paper focuses on domain adaptation between different datasets, which is more common in practical applications. Unlike existing supervised learning approaches, this work aims to generalize gaze estimation in an unsupervised manner as ground-truth labels are not available in new domains. The proposed PnP-GA framework utilizes an outlier-guided collaborative learning strategy for unsupervised domain adaptation. By optimizing error-prone outliers, the framework achieves exceptional performance improvements over baseline systems in various gaze adaptation tasks. Overall, this work addresses the challenge of domain adaptation in gaze estimation and presents a framework that can be readily applied to existing gaze estimation networks without modifications to their architectures.