Visual object tracking (VOT) is crucial in various computer vision applications, including augmented reality, video surveillance, human-computer interaction, and traffic control. With the integration of deep learning, VOT has become more powerful and pervasive in on-device applications. However, VOT still faces challenges when dealing with less ideal video feed, particularly motion blur, which can severely impact tracking accuracy. Existing benchmarks and datasets lack the ability to comprehensively analyze the influence of motion blur on VOT. Moreover, current motion blur generation methods fail to reveal the adversarial vulnerabilities of visual object trackers. Therefore, this work investigates the robustness of visual trackers against motion blur through an adversarial blur attack (ABA) approach. The main objective is to transfer input frames to natural motion-blurred counterparts while misleading state-of-the-art trackers. Two methods are proposed: optimization-based ABA (OP-ABA) and one-step ABA (OS-ABA). OP-ABA synthesizes natural adversarial examples but is time-consuming, while OS-ABA efficiently estimates adversarial motion and accumulation parameters in a one-step manner. Experimental results on popular datasets demonstrate the effectiveness of the proposed methods in causing significant accuracy drops on state-of-the-art trackers while maintaining high transferability. This study is the first attempt to explore the adversarial robustness of VOT and its findings will benefit future-generation visual object trackers in real-world scenarios.