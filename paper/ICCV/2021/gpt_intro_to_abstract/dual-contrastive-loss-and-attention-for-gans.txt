This paper introduces improvements in the field of photorealistic image generation using generative adversarial networks (GANs). While GANs have shown promising results in various computer vision applications, there are still open issues, such as obvious artifacts in generated images. To address these issues, the paper focuses on two dimensions of improvement. Firstly, the loss function is optimized by replacing the logistic loss of StyleGAN2 with a newly designed dual contrastive loss, leveraging advancements in contrastive learning. This enhances the discriminative power of the generator and mitigates issues like mode collapse and discontinuity in generated samples. Secondly, the architecture of the generator and discriminator networks is revisited. Attention mechanisms are incorporated to model long-range dependencies across image regions, improving stability during GAN training. The paper explores the role of attention mechanisms in the state-of-the-art generator and significantly improves results by studying various attention mechanisms.In addition, a novel reference-attention discriminator architecture is proposed, which utilizes two irrelevant images as inputs to guide real/fake classification. This benefits datasets with limited scale.The contributions of this research include the proposal of a novel dual contrastive loss to enhance image generation quality, the investigation of attention mechanisms in GAN architecture to overcome convolutional issues, the design of a reference-attention discriminator architecture, and significant improvements in FID scores on benchmark datasets.Overall, this paper redefines the state of the art in photorealistic image generation by addressing open issues in GANs and achieving more realistic generation results.