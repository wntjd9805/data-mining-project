Supervised object localization and detection methods based on deep neural networks have made significant advancements in computer vision. However, these methods often require large amounts of training data with detailed annotations, which can be costly and time-consuming to obtain. In response, weakly supervised object localization has gained attention as a more efficient approach, only requiring image-level annotations.One limitation of classification networks is that they tend to focus on small and sparse regions when identifying patterns, rather than exploring the entire extent of objects. Class activation maps (CAM), which are weighted averages of high-level feature maps, are commonly used to identify discriminative regions of objects. However, CAM alone is not sufficient for accurate object localization. Various solutions have been proposed to address this issue, such as erasing the most discriminative regions to encourage the discovery of less discriminative regions. However, these approaches have limited potential in deriving complete and compact activation maps.To overcome these limitations, this paper proposes a two-stage learning framework for object localization. In the first stage, low-level features are used as region guidance to generate activation maps, providing rich contextual information for refinement. In the second stage, an entropy-guided refinement is designed to further explore the low-level features and obtain well-separated, complete, and compact activation maps, leading to accurate object localization.Experiments conducted on CUB-200-2011 and ImageNet-1K datasets demonstrate that the proposed method outperforms previous methods, achieving a new state-of-the-art performance. Additional experiments on different datasets confirm the robustness and generalization ability of the proposed method across various scenarios and species.