Generative Adversarial Networks (GANs) have revolutionized generative modeling in computer vision by synthesizing high-quality images. However, controlling the image generation process in GANs has been a challenging task. While conditional models and disentangled latent spaces have provided some degree of control, they have limitations in terms of requiring labels and providing limited control. The question of what knowledge GANs learn in the latent representation and how these representations can be used to manipulate images remains an ongoing research question. Previous attempts to control GANs' generation process include modifying latent codes and interpolating latent vectors. Recently, more principled approaches have been proposed to explore the structure of the latent space, discovering interpretable directions that can be used to manipulate image semantics. In this paper, we introduce LatentCLR, an optimization-based approach that uses self-supervised contrastive learning to discover interpretable directions in pre-trained GAN models. Our method finds distinct and fine-grained directions on various datasets and shows high transferability between ImageNet classes. We provide our implementation publicly to encourage further research in this area.