This paper focuses on multi-target multi-camera (MTMC) tracking, particularly in the case of synchronized cameras with overlapping views but without calibration information. The goal is to develop a method that can associate pedestrian trajectories across cameras without using calibration information. To achieve this, the paper proposes a novel video-based Re-Identification (Re-ID) model using Transformers, specifically utilizing attention models to learn representative and discriminative visual features. The paper evaluates the proposed method on a construction site dataset, as well as two public benchmark datasets, showcasing its superior performance in the time-synchronized uncalibrated setting and its ability to generalize to harder scenarios. The contributions of the paper include the introduction of a transformer-based inter-tracklet attention module for computing discriminative feature representation, an intra-tracklet attention module for learning person-specific motion and appearance features, and advancing the state of the art in MTMC tracking.