Saliency detection plays a crucial role in various sensory modalities by allowing humans and animals to allocate their attention to the most important subsets of data. In the field of computer vision, saliency prediction involves either predicting fixation locations or detecting salient objects. Early research identified that fixation locations are influenced by both high-level and low-level features of visual stimuli. The Itti-Koch model was the first to predict saliency maps from arbitrary images, leading to the development of numerous saliency prediction models. Currently, deep learning models dominate the field of saliency prediction, driven by large-scale saliency datasets. Due to the limited data available in the saliency domain, transfer learning has become essential for improving spatial saliency prediction. The use of transfer learning from ImageNet has significantly advanced saliency prediction models. However, there is still a substantial gap between existing models and the lower bound of explainable information in spatial saliency tasks. In this paper, we aim to improve spatial saliency modeling by studying well-calibrated probabilistic predictions. We propose a new state-of-the-art model and analyze the relationship between ImageNet performance and saliency prediction performance. Additionally, we investigate the complementarity between different models and leverage ensemble learning to achieve state-of-the-art results. We also examine the confidence calibration of the models and propose a new method for testing confidence calibration in high-entropy datasets. Our findings reveal that most individual models are overconfident on out-of-domain data, while ensemble models exhibit better confidence calibration, making them more reliable for unseen datasets.