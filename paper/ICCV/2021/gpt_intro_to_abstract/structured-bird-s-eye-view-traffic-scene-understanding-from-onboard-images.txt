In this computer science paper, the authors propose a method for road scene understanding in the context of autonomous driving. The current approach involves using expensive sensors and offline HD-maps, which limits scalability and increases operational costs. The authors present an end-to-end vision method that can extract lane graphs and detect objects using only a front-facing camera image. The proposed method directly estimates the graph structure of the road network and spline curves representing lane centerlines. Additionally, it can detect objects such as cars and pedestrians directly on the BEV plane. The output format of the method is ideal for downstream planning and prediction tasks. The authors compare their method to existing approaches and show that it outperforms them. They also discuss the challenges of understanding HD-maps and the limitations of existing methods. The proposed method aims to overcome these challenges and provide structured output suitable for various downstream tasks. The authors summarize their major contributions, which include proposing a unified method for structured BEV road network graph estimation and object detection, and demonstrating superior results compared to baselines. They also highlight the importance of their method for motion planning and navigation tasks. Overall, this work addresses the limitations of current approaches and provides a promising solution for road scene understanding in autonomous driving.