This paper explores the property that different layers of a generative convolutional neural network (CNN) capture different semantic concepts in terms of abstraction level. Similar to discriminative CNNs, generative CNNs also exhibit this property, as evidenced by studies on generative adversarial networks (GANs). However, while post-processing algorithms have been developed to identify and manipulate semantic attributes in well-trained generators, the generators themselves still lack explicit dimensions to directly control these attributes. To address this issue, this paper proposes EigenGAN, which embeds a linear subspace model with orthogonal basis into each generator layer. Through generative adversarial training, EigenGAN captures the principal variations of the data distribution, which are represented in different layers. The subspace model further separates these variations into different basis vectors, each corresponding to a distinct attribute or interpretable variation. For example, an eigen-dimension in a deep layer controls gender, while an eigen-dimension in a shallow layer controls hue. The paper also theoretically proves that EigenGAN can discover principal components like PCA does in the linear case. Additionally, EigenGAN is shown to decompose data generation modeling into layer-wise dimension expanding steps from a manifold perspective.