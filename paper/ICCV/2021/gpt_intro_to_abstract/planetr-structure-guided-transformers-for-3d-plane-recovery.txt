Recovering 3D planar structures from a single RGB image is a challenging problem in computer vision. The goal is to detect plane instances and estimate their 3D parameters. Previous methods have utilized geometric elements such as line segments and vanishing points, but they suffer from issues such as missing or incorrect detection and limited scenes. Convolutional Neural Networks (CNNs) have been used to address this problem, but they mainly rely on context information and ignore structure cues in the image. In this paper, we propose a learning-based framework that leverages line segments as geometric structures for 3D plane recovery. We utilize a Transformer model, called PlaneTR, to encode line segments and context features as tokenized sequences and interact them with learnable plane queries. We also employ an instance-to-pixel segmentation strategy to obtain pixel-wise plane segmentation results. Our method achieves state-of-the-art performance on the ScanNet and NYUv2 datasets, demonstrating its effectiveness in 3D plane recovery.