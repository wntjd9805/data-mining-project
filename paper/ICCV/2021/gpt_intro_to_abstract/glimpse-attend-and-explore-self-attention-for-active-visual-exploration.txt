In this paper, we propose a method for active vision in computer vision tasks, addressing limitations caused by biased datasets and limited observability. Our method autonomously explores a scene by sequentially gathering partial observations, simulating scenarios where an agent has a limited field of view. We introduce a self-supervised attention mechanism and a unified architecture for different tasks such as image reconstruction, classification, and semantic segmentation. We evaluate our method using various datasets and demonstrate the benefits of using contrastive learning to build a richer representation of the environment. Our contributions include a new attention mechanism, a unified architecture, and the application of contrastive learning for active visual exploration.