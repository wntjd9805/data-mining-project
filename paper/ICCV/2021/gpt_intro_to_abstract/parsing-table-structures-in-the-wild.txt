Tables are commonly used to record and summarize data for better visualization. With the popularity of smartphones and portable cameras, there is a growing need to automatically extract and parse table structures from photos or images. Existing approaches for table structure parsing focus on well-aligned document images with clean backgrounds. However, these approaches fail when applied to images taken in the wild, which often have complex backgrounds and lack alignment. To address this, we present a large-scale dataset called Wired Tables in the Wild (WTW) and propose a novel approach called Cycle-CenterNet. Our approach simultaneously detects the vertices and center points of table cells and groups them into tables using the common vertices. We also propose a pairing loss function to optimize the grouping process. Experimental results show that our approach significantly improves the accuracy of table structure parsing compared to baseline methods. Additionally, our method outperforms state-of-the-art approaches on the ICDAR2019 dataset and achieves competitive results on the ICDAR2013 dataset. This research contributes to the development of table structure parsing algorithms for images taken in the wild.