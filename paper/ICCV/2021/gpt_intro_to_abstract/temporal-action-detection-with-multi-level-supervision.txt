Temporal action detection is a crucial task in video understanding, requiring the classification of actions in a video and the localization of their start and end times. Current temporal action detection models heavily rely on large amounts of fully-labeled training data, including both classification and localization annotations. However, the annotation process, particularly for localization, is time-consuming and expensive. To address this issue, this paper explores the use of unlabeled and weakly-labeled data to improve temporal action detection performance while reducing annotation costs. Specifically, the paper introduces the Semi-supervised Action Detection (SSAD) task and establishes three SSAD baseline models by incorporating state-of-the-art Semi-Supervised Learning (SSL) models into a Fully-Supervised Action Detection (FSAD) backbone. Additionally, weakly-labeled data is included to form an Omni-supervised Action Detection (OSAD) framework. The paper proposes an unsupervised foreground attention module to improve action recognition in SSAD models and an information bottleneck method to address action-context confusion in OSAD models. Experimental evaluations are conducted on the SSAD and OSAD baselines, as well as the proposed modules, demonstrating the benefits of multi-level supervision and the advantages of the proposed methods.