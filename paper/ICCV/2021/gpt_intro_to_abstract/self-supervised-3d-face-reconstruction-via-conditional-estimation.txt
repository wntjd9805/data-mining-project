Reconstructing 3D faces from 2D images is a longstanding problem in computer vision. Current approaches represent the face as a combination of shape and texture and learn a regression model between 2D images and the corresponding 3D parameters. However, training data with both 2D images and 3D parameters are scarce, especially in natural in-the-wild environments. To address this, self-supervised learning methods have gained interest. The challenge is to account for factors such as illumination and viewpoint, as well as the ambiguity of combining different parameters to reconstruct the 2D image. Various regularizations, such as reflectance symmetry and smoothness, have been proposed to reduce ambiguities. Utilizing correspondences between multiple images of the same face can further improve regularization. Prior works consider individual estimation of parameters without considering their direct influences on each other, resulting in lost opportunities. In this paper, we propose a novel framework called CEST (Conditional Estimation) that explicitly considers the statistical dependencies among shape, viewpoint, reflectance, and illumination. Learning is self-supervised, and regularizers like reflectance symmetry and consistency are included through cross-frame reconstruction error terms. We present ablation studies and comparisons, demonstrating that CEST outperforms state-of-the-art methods in terms of reflectance, illumination, and shape estimation accuracy. Overall, our contributions include the proposal of CEST, a specific design for conditional estimation, and a stochastic optimization strategy for efficient training.