Scene graphs are structured descriptions of complex scenes and the relationships between objects. They are used in various Vision-and-Language tasks such as caption generation and image retrieval. Scene graph generation faces challenges due to the long-tailed nature of entity and predicate class distributions, leading to imbalances in tuple distributions. Previous approaches have focused on complex models without addressing these imbalances. In this paper, we propose a simpler model, DT2, that takes into account the long-tailed distributions of entity and predicate classes. We also introduce a novel sampling strategy, ACBS, to balance these distributions. Our results show that DT2-ACBS outperforms previous approaches on SGG tasks, demonstrating the effectiveness of considering long-tailed distributions in visual relation learning. This paper makes three contributions: 1) the development of a simple model architecture, DT2, for long-tailed SGG tasks, 2) the proposal of ACBS for capturing the interplay between entity and relation distributions, and 3) the demonstration of the superiority of DT2-ACBS over state-of-the-art methods on the Visual Genome benchmark.