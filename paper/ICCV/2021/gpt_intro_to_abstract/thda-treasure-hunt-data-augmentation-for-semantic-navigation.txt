This paper examines the ability of general-purpose neural models to navigate in a new environment when given a goal specified as an object name. The models are composed of navigation-agnostic components and trained without any specific structural components or auxiliary tasks. The authors find that while these models perform well in PointGoal Navigation tasks, they struggle to achieve non-trivial performance in ObjectNav tasks due to extreme overfitting. The paper identifies three main reasons for this poor generalization and proposes techniques to reduce their effect: limiting the sensor suite, introducing a new reward function that encourages exploration, and using Treasure Hunt Data Augmentation to increase training data. The authors show that addressing these causes of overfitting leads to improved performance on the ObjectNav benchmark, setting a new state of the art. The paper concludes by outlining the contributions of the study, including the improved RL baseline, the effective reward function, and the effectiveness of THDA in pre-training the model.