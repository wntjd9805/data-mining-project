Scene text detection is a crucial task in various computer vision applications, such as online education and product search. While deep learning-based methods have shown impressive performance on regular shaped text instances, arbitrary shape text detection has gained increasing interest due to its ability to adapt to real-world scenarios. Although recent arbitrary shape text detection methods have made significant progress, there are still challenges in handling the diverse characteristics of scene texts, including shape, texture, and scale variations. Segmentation-based methods have emerged as a promising approach, but they often struggle with separating adjacent text instances and produce inaccurate text contours. This is due to the complexity and inefficiency of the pixel-to-pixel merging process and the reliance on accurate contour detection. To address these issues, we propose a novel adaptive boundary proposal network for arbitrary shape text detection. Our approach consists of a boundary proposal model and an adaptive boundary deformation model. The boundary proposal model utilizes multi-layer dilated convolutions to generate coarse text boundaries, which are then refined by the adaptive boundary deformation model using prior information. Our method achieves state-of-the-art performance on publicly available datasets, and its contributions include a unified end-to-end trainable framework, direct generation of accurate text boundaries, and an adaptive boundary deformation model for refining text boundaries.