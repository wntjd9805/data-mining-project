Event cameras are neuromorphic vision sensors that encode visual information as a sequence of events, offering advantages such as high dynamic range, low energy consumption, and microsecond-scale temporal resolution. However, the lack of a large, fine-grained dataset for training and evaluating event-based vision algorithms has hindered their development. While there has been an increase in the number of event camera datasets, many lack size or label diversity. In this paper, we introduce N-ImageNet, an event camera dataset specifically designed for object recognition that surpasses existing datasets in both size and label granularity. We generate events by moving the sensor in front of an LCD monitor displaying images from ImageNet. N-ImageNet is expected to serve as a challenging benchmark for event-based object recognition algorithms. Evaluations on N-ImageNet demonstrate a significant room for improvement compared to other benchmarks. We also experimentally show the effectiveness of N-ImageNet pretraining, as models pretrained on N-ImageNet exhibit improved performance on various object recognition benchmarks. Additionally, we analyze the robustness of event-based object recognition algorithms under different camera trajectories and lighting conditions using variants of N-ImageNet. Our dataset is the first to provide quantitative benchmarks for robust event-based object recognition, and we propose a simple event representation called DiST that enhances robustness against external variations. Our contributions include N-ImageNet, N-ImageNet pretraining, variants of N-ImageNet for robustness evaluation, and the DiST event representation.