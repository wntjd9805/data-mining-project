This paper introduces an unsupervised learning approach to decompose images into layers, where each layer is a transformed instance of a prototypical object called a sprite. The aim is to create an interpretable and layered model of images that can be used for various applications such as object discovery, image editing, future frame prediction, object pose estimation, and environment abstraction. Unlike previous works that use autoencoder networks to generate layers, this approach explicitly models layers as transformations of sprites. The composition model is inspired by the classic computer graphics sprite model but with richer geometric transformations and color changes. The method jointly learns both the sprites and the parametric functions predicting their transformations. Experimental results show that the method performs well on synthetic datasets and can also be applied to real images, accurately identifying objects and their spatial extent. The contributions of this paper include the unsupervised learning approach, strong results on synthetic benchmarks with instance and semantic segmentation evaluation, and results on clustering and cosegmentation of real images. Code and data are available on the project webpage.