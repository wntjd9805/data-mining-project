This paper introduces a novel framework called multiview pseudo-labeling (MvPL) for semi-supervised learning in video recognition. Unlike traditional 3D convolutional neural networks (CNNs) that learn spatiotemporal features implicitly, MvPL explicitly forces a single model to learn both appearance and motion features by ingesting multiple complementary views of the same unlabeled video clip. The proposed method does not require additional modalities or changes to the model architecture. Two technical insights are presented: adapting optical flow and temporal gradients to the same input format as RGB frames, and using an ensemble approach to infer pseudo-labels for unlabeled data. Experimental results on Kinetics-400 and UCF101 datasets show that MvPL consistently improves accuracy compared to single-view methods and achieves state-of-the-art performance on UCF101 and HMDB-51 datasets. This work contributes to the exploration of semi-supervised learning in video understanding and provides a general framework for improving video recognition accuracy.