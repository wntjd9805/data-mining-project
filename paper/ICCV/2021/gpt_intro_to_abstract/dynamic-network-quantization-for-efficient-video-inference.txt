This paper introduces Video Instance-aware Quantization (VideoIQ), a novel approach for efficient video recognition. While existing methods focus on compact models or frame sampling, they often use 32-bit precision for processing all frames, limiting their efficiency. VideoIQ addresses this issue by dynamically selecting optimal quantization precision for each input clip, allowing for more efficient processing without sacrificing accuracy. The proposed approach includes a decision policy network that determines the precision to be used on a per-frame basis, and a single deep neural network for action recognition that can adjust numerical precision without performance degradation. Extensive experiments on standard video recognition datasets demonstrate that VideoIQ achieves significant computational and memory savings while outperforming state-of-the-art methods. The learned decision policies are also transferable across different datasets and correlate with visual patterns in video frames for improved efficiency.