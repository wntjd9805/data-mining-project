Image inpainting is a challenging task in computer vision that aims to fill in missing parts of images while maintaining semantic and visual consistency. This problem is particularly difficult for man-made scenes, where preserving low-level visual patterns such as edges, line segments, and junctions is essential. Traditional and deep learning-based approaches have made progress in generating visually realistic results, but they still struggle to produce structurally coherent inpainting results, especially for man-made scenes. These approaches often miss critical structures or transfer unreliable patterns to the masked regions, resulting in degraded performance and efficiency. To address these issues, we propose a novel Multi-scale Sketch Tensor (MST) network for image inpainting. The network consists of an encoder module that learns local and holistic structures using a Line Segment Masking (LSM) algorithm, and a decoder module that fills in the holes of images using restored structures. We introduce efficient modules such as partially gated convolutions, an efficient attention module, and Pyramid Decomposing Separable (PDS) blocks to enhance the training and inference process. Our proposed MST-net outperforms existing methods on real-world datasets, demonstrating the effectiveness of our approach.