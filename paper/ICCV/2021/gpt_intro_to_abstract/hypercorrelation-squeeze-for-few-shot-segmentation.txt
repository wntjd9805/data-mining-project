In recent years, deep convolutional neural networks have significantly improved various computer vision tasks, such as object tracking, visual correspondence, and semantic segmentation. However, these deep networks still require a large amount of annotated data, which is time-consuming and labor-intensive. To address this limitation, researchers have explored semi- and weakly-supervised segmentation approaches. However, even with limited annotated data, the poor generalization ability of deep networks remains a challenge for few-shot segmentation methods. In contrast, the human visual system can easily generalize appearances of new objects with limited supervision by finding reliable correspondences across different instances of the same class. Recent work on semantic correspondence has shown that leveraging dense intermediate features and processing correlation tensors with high-dimensional convolutions can establish accurate correspondences. However, most few-shot segmentation methods do not explore diverse levels of feature representations or construct pairwise feature correlations to capture fine-grained correlation patterns. In this paper, we propose a novel framework called Hypercorrelation Squeeze Networks (HSNet) that combines multi-level features and 4D convolutions for few-shot semantic segmentation. Our network utilizes diverse geometric/semantic feature representations from different intermediate CNN layers to construct hypercorrelation tensors, capturing multiple visual aspects. We also use pyramidal design to capture high-level semantic and low-level geometric cues for precise mask prediction. Additionally, we devise an efficient 4D kernel via weight-sparsification to reduce computational burden while maintaining effectiveness. Experimental results on standard few-shot segmentation benchmarks demonstrate the efficacy of our proposed method.