Deep learning has been successful in tasks involving 3D objects, such as autonomous driving. However, recent work has shown that these models are vulnerable to adversarial attacks in the form of semantic transformations and noise-based perturbations. While defenses have been proposed, they are often broken by stronger attacks. To address this issue, a proof of robustness is needed for deep learning models against any adversarial attack. This proof can be obtained by using a neural network veriﬁer, but no such veriﬁer currently exists for 3D point cloud models. In this work, the authors propose 3DCertify, the first veriﬁer for 3D point cloud models. The key challenge is designing scalable and precise convex relaxations that capture all possible point clouds resulting from transforming the original point cloud input. The authors address this challenge by introducing relaxations for various differentiable 3D transformations. Robustness certification is achieved by propagating the 3D relaxations through the network using existing veriﬁers. The authors also design a more precise max pool relaxation to address the loss of precision incurred at the max pool layer, a critical feature of 3D point cloud models.Using 3DCertify, the authors are able to certify the robustness of the PointNet model to semantic transformations on object classification and part segmentation tasks. The authors also make several key contributions, including a novel framework for fast computation of linear relaxations, a more precise linear relaxation for max pool, and an identification of accuracy-robustness trade-offs in point cloud networks. They also provide a comprehensive experimental evaluation of their method and make their implementation publicly available.