Person re-identification (ReID) is the task of matching pedestrian images obtained from different cameras in video surveillance systems. While conventional person ReID focuses on matching images from visible cameras, the use of infrared cameras has become increasingly common due to their ability to capture clear images in low-light conditions. This has led to the emergence of the VI-ReID task, which involves matching visible (VIS) and infrared (IR) pedestrian images. However, the discrepancy between the modalities poses a significant challenge in VI-ReID. Existing approaches have manually designed two-stream architectures to address the modality discrepancy by separating certain layers for modality-specific representations and sharing others for modality-sharable representations. However, there is no consensus on the optimal design of the neural architecture for VI-ReID. To investigate the impact of different separation schemes, this paper manually designs 195 two-stream architectures. The authors compare the performance of these architectures and observe that separating batch normalization (BN) layers within the block is superior to separating the entire block. Moreover, separating two blocks of BN layers generally outperforms separating a single one. Based on these observations, the authors conclude that appropriately separating all BN layers is crucial for achieving better cross-modality matching. However, manually exploring all possible separation schemes is time-consuming and labor-intensive. To address this problem, the authors propose a novel Cross-Modality Neural Architecture Search (CM-NAS) method. CM-NAS builds a BN-oriented search space that allows for the automatic determination of whether to separate or share each BN layer. In contrast to existing single-modality NAS methods, which are not capable of addressing the modality discrepancy, CM-NAS supports the learning of both modality-specific and modality-sharable representations. The proposed method achieves state-of-the-art performance on two VI-ReID benchmarks, SYSU-MM01 and RegDB, surpassing the baseline ResNet50 model. The authors hope that their method will serve as a foundation for future research in VI-ReID. In summary, the contributions of this paper are threefold: (1) the systematic analysis of different architectural designs, emphasizing the importance of separating BN layers; (2) the proposal of CM-NAS, a novel NAS approach for cross-modality matching; and (3) the achievement of superior performance on benchmark datasets.