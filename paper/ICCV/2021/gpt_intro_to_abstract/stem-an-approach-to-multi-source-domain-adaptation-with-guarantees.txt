Recent advances in deep learning have shown great success in visual learning tasks with large annotated datasets. However, transferring the knowledge from a trained model on a source domain to a new target domain can lead to performance degradation due to domain and label shifts. Various approaches have been proposed in domain adaptation to address these issues, ranging from shallow to deep domain adaptation. In real-world scenarios, labeled data is often collected from multiple domains, posing a practical and useful setting for transfer learning known as multi-source domain adaptation (MSDA).MSDA faces two fundamental challenges: diversity in the labeled source domains and domain shift between the target domain and the source domains. The diversity in source domains makes it difficult to train a single model that performs well across all domains. To overcome this challenge, we propose combining domain experts into a multi-source teacher by mixing their predictions using coefficients learned by a domain discriminator. Our theory shows that the performance of this teacher expert, predicting globally on the mixture of source domains, is at least better than the worst domain expert predicting locally on its domain. By training qualified domain experts, their combination leads to another qualified expert with broader coverage.To address the domain shift challenge, we use a joint feature extractor that maps the target domain and mixture of source domains into the same latent space through adversarial learning. We also train a target-domain student to imitate the multi-source teacher on both source and target examples while enforcing the clustering assumption to enhance the student's generalization ability.We propose a theoretical guarantee-driven approach called Student-Teacher Ensemble Multi-source Domain Adaptation (STEM) for multi-source domain adaptation. Our rigorous theory not only guides the development of STEM but also provides valuable insights into the influence of each component on the transferring performance.We perform extensive experiments on three benchmark datasets (Digits-five, Office-Caltech10, and DomainNet) and demonstrate that STEM achieves state-of-the-art performances. Specifically, on Digits-five and Office-Caltech10 datasets, STEM outperforms the baselines on all pairs and surpasses the runner-up baselines by an average of 3.2% and 1.5% respectively. For the DomainNet dataset, STEM outperforms the runner-up baseline on 5 out of 6 pairs, with an average improvement of 6.0%.Keywords: deep learning, visual learning, domain adaptation, multi-source domain adaptation, deep domain adaptation, transfer learning, student-teacher ensemble, theoretical guarantees, state-of-the-art performance, benchmark datasets.