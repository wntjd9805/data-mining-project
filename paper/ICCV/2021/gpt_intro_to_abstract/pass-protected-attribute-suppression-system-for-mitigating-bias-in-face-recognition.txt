In recent years, face recognition networks have significantly improved in accuracy and have been deployed in various applications. However, studies have shown that these networks encode information about protected attributes such as race, gender, and age, raising concerns about privacy and bias. Many systems store face descriptors instead of face images for faster lookup and verification, but these descriptors still contain sensitive information. Adversarial approaches and balanced training datasets have been proposed to address these concerns, but they have limitations in terms of performance and training requirements. In this paper, we propose a method called Protected Attribute Suppression System (PASS) that reduces the leakage of protected attributes in face descriptors without requiring expensive end-to-end training or balanced datasets. PASS operates on descriptor space and can be applied to any existing face recognition network. We demonstrate the effectiveness of PASS in reducing gender and skintone information in face descriptors and mitigating biases. We also introduce a novel discriminator training strategy and extend PASS to handle multiple attributes simultaneously. Finally, we introduce a new metric called Bias Performance Coefficient (BPC) to measure the trade-off between bias reduction and verification performance. Our results show that PASS outperforms existing baselines in terms of BPC values.