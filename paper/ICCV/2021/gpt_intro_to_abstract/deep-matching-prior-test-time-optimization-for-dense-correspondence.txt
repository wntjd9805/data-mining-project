Establishing dense correspondences across visually or semantically similar images is essential for various computer vision applications. Sparse correspondence methods detect and match sparse points, while dense correspondence aims to find matches at each pixel, utilizing prior knowledge about matches among nearby pixels. Traditional optimization-based methods formulate an objective function with matching data and prior terms to minimize on a single image pair. These methods can correct estimated correspondences during optimization but require a task-specific prior that is complex to formulate. Recent learning-based methods address this task as a learning problem and use convolutional neural networks (CNNs) to directly regress the correspondence. However, they require large training data with ground-truth correspondences, which are difficult to collect, or intensive learning. In this paper, we propose the Deep Matching Prior (DMP) framework, which optimizes untrained matching networks on a single pair of images to capture the matching prior without relying on large training data. DMP does not suffer from the generalization issue and achieves competitive or better performance compared to learning-based methods. We address the challenges of test-time optimization by introducing a residual matching network and a confidence-aware contrastive loss. Extensive experiments demonstrate the effectiveness of our approach on dense correspondence benchmarks and show that pre-trained networks achieve state-of-the-art performance.