Hand-drawn animation has been a popular form of digital entertainment for over a century. While the introduction of drawing tablets and digital software has made the animation process easier, it still requires manual drawing and editing of each frame. This presents an opportunity for new assistive tools that can enhance the workflow of artists.Existing commercial tools in this domain have used heuristic algorithms, but they often require artists to work in vector format or use complex character rigging, which can result in a loss of the hand-drawn feel. On the other hand, deep learning approaches can work directly on raw pixel input, but they struggle to scale to high-resolution images and do not effectively utilize the structure of hand-drawn animation drawings.This paper focuses on the task of learning visual correspondence in sequences of raster animation line drawings, which is a crucial step for assistive animation tools such as coloring, in-betweening, and texturing. By understanding visual correspondence, an animator can propagate colors through a sequence of images, saving time and effort. Additionally, new frames can be generated by morphing neighboring frames with correspondence information, reducing the need for additional line drawings.Despite the demand for a data-driven solution to the correspondence problem, progress has been limited due to the challenging design requirements and the lack of available data with correspondence labels. The proposed Animation Transformer (AnT) addresses these challenges by operating on line-enclosed segments in the line image using a Transformer-based architecture. By focusing on this representation, AnT can efficiently process high-resolution images and is trainable using colorized images as supervision.Extensive experiments demonstrate the effectiveness of AnT in various settings. When trained on ground-truth correspondence labels generated from 3D rendering software, AnT outperforms a strong pixel-based baseline. Even when trained solely on colorized images from real-world animation datasets, AnT achieves performance comparable to models trained on ground-truth correspondence labels. This shows the versatility of AnT and its potential as a creative tool.In conclusion, the proposed Animation Transformer (AnT) is a novel approach for learning visual correspondence in hand-drawn animation line drawings. It offers improvements over existing methods and demonstrates promising results in a variety of settings. With further development, AnT has the potential to greatly enhance the animation workflow and enable new creative possibilities in the field of hand-drawn animation.