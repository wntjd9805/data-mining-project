This paper introduces occlusion-aware video object inpainting, a novel approach that aims to recover moving objects with large occlusions in videos. Conventional methods often fail to accurately inpaint occluded regions, resulting in artifacts and irrelevant background colors. To overcome these limitations, the authors propose the VOIN (Video Object Inpainting Network), a unified multi-task framework that completes occluded video objects by recovering their shape and appearance in motion. To train the VOIN, a large-scale video object inpainting benchmark called YouTube-VOI is created, which includes diverse occlusion patterns and object classes. This dataset includes over 2 million occluded and visible masks for moving video objects, allowing for the generation of realistic training data. The authors also introduce the concept of the occlusion-aware flow completion module, which captures moving video objects and propagates consistent video content across frames.In addition to introducing the VOIN framework and the YouTube-VOI dataset, the authors evaluate VOIN and strong adapted baselines on the benchmark. Quantitative and qualitative results demonstrate the superiority of VOIN in terms of inpainting quality. This paper complements existing video inpainting techniques and paves the way for future research on repairing occluded video objects.