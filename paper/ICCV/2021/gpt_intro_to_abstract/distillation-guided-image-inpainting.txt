Image inpainting is a technique used to fill damaged or undesired areas of images with plausible and fine-grained contents. It has a wide range of applications in fields such as restoring damaged photographs and retouching pictures. Early conventional approaches rely on low-level features extracted from the incomplete input image and incorporate priors or auxiliary data to complete the missing regions. These methods have limitations in producing novel image contents and are restricted by available image statistics. In recent years, deep learning based methods have been introduced to overcome these limitations by utilizing large volumes of training images. However, these methods still face the challenge of the ill-posed nature of the inpainting task, as the hole regions provide insufficient guidance for neural networks to reconstruct the missing contents effectively. Existing methods typically employ either a two-stage architecture or a single network with some form of guidance at inference time to handle the ill-posedness. However, these methods have limitations related to the number of parameters required, slow inference speed, high computational cost, and the handcrafted choice of auxiliary information. The quality of the inpainted image greatly depends on the coarse network, and the removal of the coarse network from two-stage methods results in a significant drop in performance. This paper introduces a novel distillation-based training strategy for image inpainting. The proposed strategy utilizes a teacher-student framework, with the teacher network providing supervision signals for different layers of the student network. The encoder of the student network is guided by the ideal embeddings of the holes generated by the teacher network's feature maps, resulting in better embedding of the hole regions. The decoder incorporates a distillation-based attention transfer technique and a pixel-adaptive global-local feature fusion technique for refining the coarse embeddings and generating more coherent results. The proposed training strategy improves the performance of the inpainting network without the need for multiple generators or progressive refinement at inference time, thus increasing efficiency. Experimental results demonstrate the superiority of the proposed method on three standard datasets and its effectiveness in improving existing state-of-the-art methods.