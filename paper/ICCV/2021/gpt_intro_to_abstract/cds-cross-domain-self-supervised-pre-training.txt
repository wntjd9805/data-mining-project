Real-world image data often comes from various sources that differ in factors such as weather, viewpoints, lighting, and artistic styles. This diversity poses challenges for tasks that require visual representations that can generalize across multiple domains. Two such tasks are domain adaptation, which aims to transfer knowledge from a labeled source domain to an unlabeled target domain, and cross-domain image retrieval, which aims to match semantically related images regardless of domain shift. Previous work has shown the effectiveness of pre-training in deep neural networks for visual tasks, where models are pre-trained on a large-scale supervised auxiliary domain (e.g., ImageNet) and then fine-tuned for downstream tasks. However, ImageNet pre-training has limitations, such as biased representations and domain shift caused by changes in background, rotation, and viewpoints. This suggests that pre-training on a single domain may not encourage domain-invariant features and may not be suitable for downstream tasks that encounter new domains. To address these issues, we propose a two-stage pre-training approach that combines standard ImageNet pre-training with a self-supervised pre-training stage using unlabeled data from multiple domains. This two-stage pre-training approach provides a more robust representation that is better suited for downstream methods operating on multiple domains. We compare our approach with standard one-stage pre-training and demonstrate significant gains across multiple tasks and methods. We also introduce a new pre-training method called Cross-Domain Self-supervision (CDS) that overcomes the limitations of single-domain self-supervised learning methods. CDS effectively learns domain-invariant and discriminative features by leveraging unlabeled data from multiple domains. We evaluate CDS on various domain transfer tasks, including unsupervised cross-domain image retrieval, universal domain adaptation, and few-shot domain adaptation, and show that it outperforms existing state-of-the-art self-supervised learning methods and standard ImageNet pre-training. In summary, our work contributes a two-stage pre-training approach to improve generalization ability, introduces the CDS method for learning domain-invariant features, and demonstrates its superiority on various domain transfer tasks.