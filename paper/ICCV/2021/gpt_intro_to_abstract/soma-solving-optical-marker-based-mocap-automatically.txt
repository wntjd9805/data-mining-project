Marker-based optical motion capture systems are widely used in computer science to record and analyze human motion. However, the labeling of the captured data is a challenging and time-consuming task. Existing methods for automating the labeling process have limitations, such as being restricted to specific motions or body shapes. In this paper, we propose a data-driven approach that uses synthetic data to train a neural network with self-attention components and an optimal transport layer. The network is trained to predict the label assignment for each frame of mocap data, taking into account variations in marker layout, body shape, and motion. We also introduce a novel normalization technique and use post-processing steps to fit the labeled data to a deformable human body model. Our evaluation shows that our method outperforms existing techniques and is applicable to both new and archival mocap datasets. Our contributions include a novel neural network architecture, a system for processing sparse point cloud data, a synthetic data generation pipeline, and a robust solution for handling various mocap scenarios. We provide processed mocap data, trained models, and code for research purposes.