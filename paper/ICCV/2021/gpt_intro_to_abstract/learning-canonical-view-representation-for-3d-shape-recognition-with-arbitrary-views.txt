Understanding and recognizing objects in the 3D world is a fundamental problem in computer vision. In recent years, many view-based methods have been proposed for 3D shape recognition using deep neural networks and 2D images. However, most of these methods focus on settings with a fixed camera setup, which limits their applicability in practical scenarios where objects are observed from arbitrary views. This paper introduces a novel approach for 3D shape recognition with arbitrary views, addressing the challenges posed by unaligned inputs. The proposed method utilizes optimal transport to transform the features of arbitrary views into canonical view features aligned to a set of reference views, allowing for robust feature aggregation. A canonical view representation is generated by embedding the canonical view features into a Euclidean space. A discriminative global representation of the 3D shape is then generated by encoding and aggregating the aligned canonical view features. Experimental results on various datasets demonstrate the superiority of the proposed approach compared to state-of-the-art methods in the challenging task of 3D shape recognition with arbitrary views.