3D shape understanding is crucial for tasks such as autonomous driving. Point cloud data is a popular representation for 3D analysis due to its simplicity and effectiveness. However, the expensive labeling of point cloud data limits its potential utilization. Unsupervised learning on point clouds aims to learn useful information and representations without the need for manual labeling, providing an opportunity to leverage unlabeled data. Previous works have focused on unsupervised feature learning using autoencoders and generative adversarial networks, as well as self-supervised methods that encourage the network to capture structural and low-level information. However, existing methods have limitations, such as not being suitable for certain network architectures. In this paper, we propose a backbone-agnostic self-supervised framework that fully utilizes the local structure of shape parts to enhance unsupervised learning. We divide 3D shapes into shape parts and exploit their relationships through geometric constraints. Our framework involves destroying local shape parts and training the network to distinguish and restore them. The proposed framework is evaluated using modified versions of PointNet and RSCNN as feature extractors. Experimental results on shape classification and segmentation tasks demonstrate that our method achieves state-of-the-art performance among unsupervised models and exhibits strong transferability to real-world scanned datasets. Furthermore, pre-training with our framework significantly improves the performance of supervised models, and our method outperforms previous methods in a semi-supervised setting. Overall, our framework demonstrates the ability to learn strong representations of 3D shapes and enhances the performance of downstream tasks.