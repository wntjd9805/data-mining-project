This paper addresses the problem of learning physically plausible hand motions for various applications such as virtual reality, augmented reality, and manipulation planning. Traditional methods for collecting high fidelity hand motion data, such as data gloves and specialized hardware devices, are expensive and cumbersome. Recent advancements in deep learning have shown promising results in hand pose estimation from depth images and color images. However, it remains challenging to prepare and label sequences of hand motions due to their diversity and composability. To overcome these difficulties, this paper introduces a novel encoder-decoder network called TravelNet. The network is trained using a physics engine to generate motion sequences that are physically plausible and preserves details. A self-supervised learning paradigm is proposed to train the network, ensuring that the embedded space outputted by the encoder remains in the same pose manifold as the input space. Additionally, a hand model incorporating physical constraints is built to detect collisions and calculate inverse dynamics, providing prior knowledge for generating plausible motion sequences. The main contributions of this work include a robust learning paradigm for extracting key pose states and reconstructing hand motion, the adoption of a physical pose bound as a compact descriptor of hand motion, and the creation of an archive containing a large number of physical hand poses for plausible motion generation. The dataset and codes for this research will be made publicly available.