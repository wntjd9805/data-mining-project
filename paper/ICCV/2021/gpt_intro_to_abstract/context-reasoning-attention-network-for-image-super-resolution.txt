Image super-resolution (SR) is a fundamental task in computer vision, with applications in various fields such as security, medical imaging, and object recognition. However, it is an ill-posed problem with multiple possible solutions for low-resolution input images. To address this problem, deep convolutional neural networks (CNNs) have been widely used to learn mappings between low-resolution and high-resolution image pairs. While CNNs have achieved impressive results in image SR, they often focus on capturing local patterns and overlook the importance of global context. Recent advances in neuroscience have highlighted the significance of global context for effective perceptual tasks. Therefore, several methods have been proposed to incorporate global context modeling into SR networks. However, these methods mainly incorporate global context into local features, resulting in inaccurate texture directions in the output images. To overcome this limitation, we propose a context reasoning attention network (CRAN) for image SR. CRAN dynamically modifies the convolution kernels based on the global context, leveraging semantic reasoning and channel and spatial interactions. Our experiments demonstrate that CRAN outperforms existing methods in terms of both quantitative metrics and visual quality. The main contributions of this work include the introduction of a context reasoning attention network, the extraction of context information into latent representations, and the utilization of channel and spatial interactions to generate context reasoning attention masks. Overall, CRAN offers superior super-resolution results with favorable efficiency.