Video object segmentation (VOS) is a crucial task in computer vision that aims to accurately delineate pixel-level moving object masks in each frame of a video. It has diverse applications in areas such as robotics, autonomous cars, video editing, medicine, among others. There are two settings for addressing this task, namely semi-supervised and unsupervised VOS. In this paper, we focus on the unsupervised setting, specifically zero-shot VOS. Previous approaches have utilized appearance and motion cues to understand video content. However, they suffer from issues such as unreliable short-term dependency estimation and the inability to model appearance-based features accurately. To address these challenges, we propose a full-duplex strategy called FSNet that leverages the mutual restraint between appearance and motion cues. FSNet incorporates a bidirectional interaction module and a bidirectional purification module to ensure discriminative feature extraction and model robustness. Experimental results demonstrate that FSNet outperforms state-of-the-art models on five mainstream benchmarks, highlighting the effectiveness of the full-duplex strategy in spatial-temporal learning tasks.