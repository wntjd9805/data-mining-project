This paper focuses on understanding hand-object interactions in order to build agents that can perceive and act in the real world. The authors argue that fully capturing the richness of these interactions requires 3D understanding. However, the problem of recovering 3D from a single RGB image is challenging, especially in the case of hand-object interactions due to occlusions, a wide range of objects, and complex interactions. While progress has been made, existing datasets primarily focus on lab settings and lack diversity in participants and objects. To address this, the authors introduce a new dataset, MOW, consisting of 500 in-the-wild images with annotations of instance category, 3D objects and hand poses. The dataset can be used for evaluating reconstruction methods and studying human manipulation from images in the real world. The authors also introduce a novel optimization-based procedure, RHO, for reconstructing hand-object interactions. The paper presents quantitative and qualitative improvements over existing methods, particularly on in-the-wild settings. The authors encourage readers to refer to the extended version of the paper for supplementary materials and to visit the project page for more information.