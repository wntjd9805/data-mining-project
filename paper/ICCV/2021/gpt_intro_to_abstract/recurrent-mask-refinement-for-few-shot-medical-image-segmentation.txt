Medical image segmentation is a crucial task in medical image analysis, with applications in disease diagnosis and treatment planning. Manual segmentation by experienced doctors is time-consuming and tedious, prompting the use of automated segmentation tools. Deep convolutional neural networks have shown promising results in achieving accurate segmentation with fast processing times. However, training these systems requires large amounts of annotated data, which can be expensive and time-consuming to acquire. Few-shot learning has been proposed as a potential solution to address the challenges of limited data. While few-shot learning has shown success in natural image segmentation tasks, its application in medical image segmentation is still in early stages. Medical image segmentation differs from natural image segmentation due to the critical importance of local appearances and context information in determining the boundary between foreground and background regions. To address this, we propose a new network framework called RP-Net (Recurrent Prototypical Networks) for few-shot medical image segmentation. RP-Net incorporates a context relation encoder (CRE) to explicitly model the relationship between foreground and background feature maps, enhancing the boundary definition. A recurrent mask refinement module is also introduced, which iteratively refines the segmentation using CRE and prototypical networks. Through experiments on abdomen CT and MRI datasets, our proposed framework outperforms state-of-the-art few-shot frameworks for medical image segmentation in terms of Dice similarity coefficient (DSC).