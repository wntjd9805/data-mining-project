Data in real life is often noisy, requiring the use of deep models trained on clean datasets with high-quality human annotations. However, manual data cleaning and labeling is expensive and difficult to scale. On the other hand, there is a vast amount of noisy data available online. Deep neural networks (DNNs) need to be able to effectively utilize this noisy training data. However, DNNs are susceptible to overfitting to noise. This paper focuses on addressing the different types of noise present in real-world datasets, including label noise, out-of-distribution input, and input corruption. Previous methods have primarily focused on label noise and have not considered other types of noise. Additionally, using a model's own predictions to relabel samples can lead to confirmation bias. The proposed approach in this paper is to learn noise-robust low-dimensional representations and perform noise cleaning through a smoothness constraint on neighboring samples. The authors introduce two contrastive losses: an unsupervised consistency contrastive loss and a weakly-supervised prototypical contrastive loss. The first loss ensures inputs with perturbations have similar normalized embeddings, while the second loss computes class prototypes as mean embeddings and enforces each sample's embedding to be closer to its class prototype. Virtual training samples are constructed through linear interpolation of inputs, following the concept of Mixup. A new noise cleaning method is also proposed, leveraging the learned representations to enforce a smoothness constraint on neighboring samples. Pseudo-labels are created by aggregating information from top-k neighbors, and confident pseudo-labeled samples are selected for computing the weakly-supervised loss. This process effectively cleans both label noise and out-of-distribution noise. The experimental results show that the proposed method achieves state-of-the-art performance on datasets with controlled noise and real-world noise. The noise cleaning method effectively cleans a majority of label noise and learns a curriculum that leverages more samples as pseudo-labels become more accurate. The robustness of the learned low-dimensional representation is demonstrated through k-nearest neighbor classification outperforming the softmax classifier and effective separation of out-of-distribution samples from in-distribution samples.