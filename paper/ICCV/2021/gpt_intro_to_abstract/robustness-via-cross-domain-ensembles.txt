Neural networks used in real-world applications often encounter data with natural or adversarial distortions, leading to shifts from the training data distribution. While neural networks can effectively learn complex functions within the distribution, their predictions become unreliable in the presence of these shifts. This poses a significant challenge that needs to be addressed for neural networks to be practical in real-world scenarios. One common approach to learning a mapping from an input domain to a target domain is to have a direct path between them. However, this direct path is susceptible to any alterations in the input domain. An alternative approach is to introduce a middle domain that is invariant to these alterations. This middle domain acts as an intermediate step, abstracting away the distortions present in the input domain. However, determining which middle domain to use beforehand is challenging, as the specific distortions a model may encounter are not known in advance.To address these issues, we propose a method that employs an ensemble of predictions generated through K middle domains. Each of these paths reacts differently to different distribution shifts due to their inherent biases, potentially leading to varying prediction quality. We estimate the uncertainty of each path's prediction, allowing us to combine these predictions in a principled manner to obtain a final robust prediction.Importantly, our approach does not require prior knowledge of the relationship between middle domains or manual modification upon changes in these domains. The contribution of each middle domain to the final prediction is determined computationally based on their predicted uncertainties. Additionally, the middle domains we use can be programmatically extracted, eliminating the need for additional supervision or labeling. This framework is equally applicable if the middle domains are obtained through a learning-based approach.We demonstrate the effectiveness of our method in mitigating both non-adversarial and adversarial distribution shifts. The proposed approach generalizes well to different middle domain choices and shows robustness against various corruptions. Overall, our method provides a general and efficient solution to address the challenges posed by shifts in real-world data distribution for neural networks.