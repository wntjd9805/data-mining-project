Semantic segmentation is a critical task in computer vision, with applications in autonomous driving and medical diagnosis. However, pixel-wise labeling is time-consuming and labor-intensive. Synthetic datasets with freely available labels have been used for model training, but performance degradation occurs when applying these models to real data. Unsupervised domain adaptation (UDA) methods have been proposed to address this issue, by learning domain-invariant representations and exploring supervision signals from the target domain. However, the robustness of UDA methods against adversarial attacks has not been well explored. This lack of robustness raises safety concerns, particularly in security-related applications. Self-supervised learning (SSL) has shown promise in improving model robustness, but existing pretext tasks fail to provide supervision signals for fine-grained segmentation tasks. In this paper, we evaluate the robustness of existing UDA methods in semantic segmentation and propose a new UDA method called ASSUDA. ASSUDA leverages adversarial examples to provide fine-grained supervision signals and improve model robustness. Our contributions include a systematic study on the vulnerability of existing UDA methods to adversarial attacks, the proposal of a new UDA method that combines adversarial training and self-supervision, and comprehensive empirical studies demonstrating the robustness of our method on benchmark datasets.