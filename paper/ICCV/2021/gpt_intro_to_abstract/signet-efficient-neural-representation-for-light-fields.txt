Light fields are a rich source of information for both static and dynamic scenes. However, their widespread adoption is hindered by the lack of compact representations for high-dimensional data, making it impractical for storage, editing, and streaming. Existing compression methods such as JPEG and MPEG are not satisfactory due to the large number of images captured in a light field. This paper presents a new framework, called SIGNET (SInusoidal Gegenbauer NETwork), that efficiently represents light field content using neural networks. The framework incorporates a novel input transformation strategy based on orthogonal Gegenbauer polynomials, which works well with the sinusoidal activation functions in the neural network. SIGNET outperforms other Fourier-inspired input transformation strategies and achieves high reconstruction quality and compression rate. Additionally, the MLP-based approach enables view synthesis and super-resolution on the encoded light field scenes. The contributions of this work include a neural representation that offers high reconstruction quality, compression rate, and pixel-level random access to the encoded light field, an input transformation strategy using Gegenbauer polynomials that outperforms other techniques, and the ability to achieve super-resolution along spatial, angular, and temporal dimensions on light fields.