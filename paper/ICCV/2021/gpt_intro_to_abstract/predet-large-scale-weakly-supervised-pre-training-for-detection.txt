Large-scale weakly supervised pre-training for detection is a challenging problem in computer vision. While pre-trained classification models have been successful for detection tasks, they may not fully capture the specific requirements of detection, such as localization. In this paper, we propose a novel self-supervised pretext task called query-box lookup to address this limitation. We utilize bounding boxes from different views of an image and aim to retrieve the same or highly overlapping box from another view. This task ensures that boxes with high overlap are similar to each other, while non-overlapping boxes have distinct representations. To handle the large number of bounding boxes, we restrict the lookup to a representative set of proposal boxes generated by a contrastive Region Proposal Network (CRPN) and utilize the contrastive Region of Interest (ROI-head) module for retrieval. Our approach, called PreDet, demonstrates benefits over existing methods, including higher average precision (AP) and faster fine-tuning. Experiments on various detection datasets show the effectiveness of PreDet, particularly for larger models and smaller target datasets.