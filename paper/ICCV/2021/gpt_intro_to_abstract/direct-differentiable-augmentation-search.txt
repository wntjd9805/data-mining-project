Data augmentation plays a crucial role in improving the performance of deep neural networks (DNN) by creating variations of data samples to reduce overfitting. However, combining and adapting hand-crafted data augmentation techniques for new tasks or datasets is challenging and requires expertise and extensive experimentation. AutoAugment (AA) is a pioneering work that uses reinforcement learning (RL) to search for an optimal augmentation policy, but its search cost is still prohibitive. Other works achieve lower search costs but with noticeable performance degradation. Additionally, dynamic augmentation policies have been shown to perform better than fixed policies. To address these challenges, we propose Direct Differentiable Augmentation Search (DDAS), which aims to find an augmentation policy that maximizes network performance after a single step gradient update. DDAS organizes the augmentation policy into a two-level hierarchy, determining the probability of augmenting the data and the probability of each augmentation operation. This enables a differentiable search without the need for additional techniques like Gumbel-Softmax or second-order gradient approximation. We evaluate DDAS on various models and datasets, including CIFAR-10/100 and ImageNet, and demonstrate competitive or better performance while significantly reducing the search cost. We also show the feasibility of efficient augmentation search for object detection, which has traditionally been a computationally expensive task. Our contributions include the proposal of DDAS, an efficient differentiable augmentation policy search algorithm, a compact and flexible search space, and successful augmentation search for object detection.