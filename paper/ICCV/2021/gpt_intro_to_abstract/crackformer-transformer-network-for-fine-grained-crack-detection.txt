Pavement crack detection from images is a challenging task due to various factors such as intensity inhomogeneity, topology complexity, low contrast, and noisy texture background. Additionally, the diversity of cracks, including thin, grid, or thick cracks, makes detection even more difficult. While there have been numerous studies on crack detection, recent advancements have incorporated convolutional neural networks (CNNs) to improve accuracy. In this paper, we focus on detecting thin cracks from asphalt surface images. Detecting thin cracks is more challenging compared to thick cracks, thus the performance of crack detection methods is heavily influenced by their ability to detect thin cracks accurately. State-of-the-art methods primarily rely on Fully Convolutional Networks (FCNs) like SegNet and U-Net, which utilize an encoder-decoder architecture. However, these methods have limitations in complex segmentation tasks like detecting thin cracks or when there is low contrast between cracks and the background. In order to address these limitations, we propose a novel Crack Transformer network (CrackFormer) that combines self-attention and scaling-attention mechanisms for crack detection. This approach leverages the strengths of Transformer models to capture long-range interactions and uses small convolution kernels for fine-grained perception. We introduce a new self-attention block (Self-AB) that can extract contextual information across feature-channels and across the spatial domain. We also propose a scaling-attention block (Scal-AB) that generates attention masks to suppress non-semantic features and enhance semantic cracks. These blocks are integrated into a Transformer encoder-decoder structure. Our method achieves precise crack prediction, as demonstrated in the results. Our contributions include the development of the Self-AB, Scal-AB, and the integration of these blocks into the encoder-decoder structure.