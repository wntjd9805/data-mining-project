Semantic segmentation is a crucial problem in computer vision that aims to assign semantic labels to all pixels in an image. Recent advancements in the availability of large-scale datasets and convolutional networks have led to significant progress in semantic segmentation. The fully convolutional network (FCN) has become a cornerstone in deep learning techniques for segmentation. However, existing models often focus on local context within individual images and overlook the global context of the entire dataset. This raises the question of what a good segmentation embedding space should look like, considering both the categorization ability of individual pixel embeddings and the structural relationships among pixels from the same and different classes. Unsupervised contrastive learning has shown promising results in representation learning, where the goal is to learn to compare and distinguish similar and dissimilar samples in an embedding space. Inspired by the success of contrastive learning and the need for a better-structured embedding space, this paper proposes a pixel-wise contrastive algorithm for more effective dense representation learning in the fully supervised setting. This algorithm utilizes both the pixel-wise cross entropy loss for class discrimination and a pixel-wise contrastive loss to shape the pixel embedding space by exploring the structural information of labeled pixel samples. To address the nature of semantic segmentation, the paper introduces a region memory bank that stores pooled features of semantic regions instead of pixel-wise embeddings. This allows for pixel-to-region contrast in addition to pixel-to-pixel contrast. Different sampling strategies are also proposed to make better use of informative samples and focus on segmentation-hard pixels. The contributions of this work are three-fold: (1) proposing a supervised, pixel-wise contrastive learning method that learns a well-structured pixel semantic embedding space by leveraging global semantic similarities among labeled pixels, (2) introducing a region memory to explore the visual data space and support pixel-to-region contrast, and (3) demonstrating consistent improvements in segmentation scores over challenging datasets using state-of-the-art segmentation architectures and standard backbones. This work sheds light on the potential of metric learning in dense image prediction tasks and encourages further research on the role of global pixel relationships in segmentation network training.