In this paper, we address the challenging task of 3D object grounding in point clouds using free-form language descriptions. We propose a novel approach that combines a language scene graph module, a multi-level 3D proposal relation graph module, and a description 3D visual graph module. Our approach leverages the rich structure and context of free-form descriptions to guide the grounding process. We also incorporate 3D object detection to extract initial object proposals and strengthen their visual features using co-occurrence relationships. Our experimental results on benchmark datasets demonstrate that our approach outperforms existing methods and achieves state-of-the-art results. Overall, our proposed method provides an effective and end-to-end trainable solution for 3D object grounding in point clouds guided by free-form language descriptions.