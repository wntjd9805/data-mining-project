Visual recognition has made significant progress in recent years, particularly in the field of active recognition (AR) where intelligent agents explore different viewpoints and make decisions about what to observe. However, existing AR methods are limited to a classical learning setting, where recognition decisions can only be made for trained categories and large amounts of training data are required. In practical scenarios where novel categories continuously emerge and only a few samples are available, these models may not be effective. This underexplored problem is crucial in realistic autonomous agent applications, leading to the concept of lifelong active recognition (LAR) and its more challenging variant, few-shot lifelong active recognition (FLAR). FLAR requires the agent to dynamically expand its recognition abilities to novel classes with limited training samples. This paper proposes a novel approach to FLAR, addressing the challenges of limited training data, catastrophic forgetting, and overfitting. The proposed method learns an active recognition policy based on a newly designed reward that favors a closer distance between aggregated features and correct class prototypes in the embedding space. To mitigate the forgetting issue, a limited number of exemplars are stored in the agent memory and consistent outputs are reproduced for these exemplars using knowledge distillation. Additionally, the use of prototypes as robust representations enables adaptation to the few-training-sample challenge. The proposed approach provides an intelligent agent that can incrementally learn to explore and recognize novel categories with few training samples.