Densely-sampled light field (LF) images, which capture both appearance and geometry information of 3D scenes, have numerous applications such as 3D reconstruction, image post-refocusing, and virtual reality. However, the acquisition of densely-sampled LFs presents challenges due to the bulkiness or limited capabilities of camera arrays and gantries, as well as the trade-off between spatial and angular resolution in cost-effective LF cameras. Existing computational methods for reconstructing densely-sampled LFs from sparse ones struggle with the wide baseline between input views. Non-depth-based methods suffer from aliasing and artifact issues, while depth-based methods have limitations in reconstruction quality. To address these challenges, this paper proposes a novel approach called dynamic interpolation for LF reconstruction from sparse and wide-baseline inputs. This approach replaces the traditional warping operation with a learnable module that dynamically predicts interpolation weights for novel view synthesis. The proposed model also includes a refinement module for recovering spatial correlation and a disparity-oriented LF structure loss to constrain angular correlation. Experimental results show the superiority of the proposed model over traditional warping-based methods and other state-of-the-art techniques. The main contributions of this paper include a deep analysis of the limitations of the warping operation in LF reconstruction, and the introduction of dynamic interpolation as a solution that overcomes these limitations.