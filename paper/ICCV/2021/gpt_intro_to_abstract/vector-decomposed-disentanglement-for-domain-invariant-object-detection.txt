Object detection has made significant progress, but when the training and test data come from different domains, these methods often struggle due to poor generalization. Domain adaptive object detection (DAOD) has been proposed to address this issue, where a domain gap exists between the training and test domains. Previous methods focused on reducing the domain gap by aligning the feature-level distribution of the domains, but they neglected the domain-specific information in the aligned features. To tackle DAOD, we aim to extract domain-invariant representations (DIR) by employing disentangled representation learning (DRL). DRL aims to uncover independent factors in the data, which contain all the information. Inspired by this idea, we propose a novel disentangled method that utilizes vector decomposition to extract DIR. Specifically, we design an extractor to separate DIR from the feature map, while the difference between the feature map and DIR becomes the domain-specific representation (DSR). We also employ a domain classifier to enrich DSR with more domain-specific information. To ensure independence between DIR and DSR, we impose a constraint of vector orthogonalization. We employ a region proposal network (RPN) to extract object proposals from DIR. Our method includes a two-step optimization process to learn feature decomposition and promote DIR and DSR to be independent. Experimental evaluation on single-target and compound-target cases demonstrates the effectiveness of our method, and we also construct new adaptive scenes to further validate our approach. Our contributions include the introduction of vector-decomposed disentanglement, a new framework for DAOD, and a two-step training strategy for optimization.