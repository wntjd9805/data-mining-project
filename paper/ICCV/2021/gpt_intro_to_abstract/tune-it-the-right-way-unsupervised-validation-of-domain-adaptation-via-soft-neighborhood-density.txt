Deep neural networks have shown success in learning discriminative representations for visual recognition tasks. However, they often struggle to generalize well to new, out-of-domain data. Unsupervised Domain Adaptation (UDA) aims to transfer representations from a label-rich source domain to improve performance on a new target domain without additional supervision. Current UDA methods primarily rely on unsupervised learning techniques such as minimizing feature distribution shift, classifier confusion, clustering, and pseudo-label based approaches. While these methods have shown promising results in tasks like image classification, semantic segmentation, and object detection, they are highly sensitive to hyper-parameters and the number of training iterations. This introduces a challenge in validating the performance of adaptation methods in an unsupervised way. Existing validation criteria, such as evaluating accuracy in the source or target domain, have proven to be ineffective for hyper-parameter optimization (HPO) in UDA. In this paper, we propose a novel unsupervised validation criterion called Soft Neighborhood Density (SND) which considers the neighborhood density of unlabeled target samples. We empirically evaluate SND across various adaptation methods, datasets, and vision tasks and show that it outperforms existing criteria in terms of HPO. SND takes into account the implicit relationships between target samples and the collapse of the neighborhood structure, thus providing a more reliable measure of the effectiveness of domain adaptation methods. Our experiments demonstrate that SND is stable across different datasets and methods, and it consistently improves the performance of various UDA tasks including image classification and semantic segmentation. Overall, our contributions include re-evaluating existing criteria for UDA, proposing the SND metric, and showing its effectiveness in HPO for unsupervised domain adaptation.