This paper introduces the concept of adversarial examples and the security concerns they raise in deep neural networks. The authors propose a novel Neural Architecture Search (NAS) algorithm called AdvRush that aims to discover robust neural architectures. The existing NAS algorithms focus on improving standard accuracy and do not consider robustness. AdvRush, on the other hand, prioritizes architectures with smoother input loss landscapes, resulting in higher intrinsic robustness. Experimental results on CIFAR-10, CIFAR-100, SVHN, and Tiny-ImageNet demonstrate the effectiveness of AdvRush in improving robust accuracy compared to other architectures. The paper also provides theoretical justifications, visual analysis of the discovered architecture, and insights into the factors that make a neural architecture more robust against adversarial perturbations.