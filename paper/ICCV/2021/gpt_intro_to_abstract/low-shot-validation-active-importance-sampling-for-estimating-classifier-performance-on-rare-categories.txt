Model validation is an important but costly step in the development of machine learning models. While recent advancements in training techniques have reduced the need for large amounts of labeled data for model training, validation still requires large, human-annotated datasets. This paper focuses on the efficient validation of binary image classifiers for rare categories, where positive instances are only 0.1% of the dataset. The challenge lies in efficiently estimating the F-score of a model using a small number of annotated data samples. The paper proposes an active sampling algorithm that alternates between acquiring labels to train a calibration model for predicting the likelihood of a sample being positive, and using the calibrated model scores to importance-sample batches of data for metric estimation. The proposed algorithm shows significant improvements in estimating the F1 score compared to baselines, even in low-sample regimes. Additionally, the paper introduces a single-trial estimator of variance for the proposed method, allowing practitioners to assess the reliability of the estimates. The study also shows that validation sets specifically chosen for one model can efficiently validate other models trained for the same task. Overall, this paper presents an algorithm that produces accurate and reliable estimates of a model's F-score, outperforming other methods in low-sample regimes, and offers practical implications for model validation in real-world settings.