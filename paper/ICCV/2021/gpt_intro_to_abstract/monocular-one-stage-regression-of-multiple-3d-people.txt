Recently, significant progress has been made in monocular 3D human pose and shape estimation for images with a single person. However, the challenge lies in extending these methods to handle general scenes with multiple people, which involve truncation by the image frame, person-person occlusion, and environmental occlusion. Existing approaches follow a multi-stage design, using a 2D person detector to handle multi-person scenes. They first detect regions with people and then extract bounding-box-level features to regress each single 3D human mesh. However, this strategy fails to address multi-person occlusion and truncation cases effectively. To overcome these limitations, we propose ROMP, a one-stage network for regressing multiple 3D people in a per-pixel prediction fashion. ROMP predicts a Body Center heatmap and a Mesh Parameter map, allowing us to extract 3D body mesh parameter vectors for all individuals. By utilizing the body centers as guidance during training, the ambiguity of the regression target is reduced in crowded multi-person scenes. Moreover, we introduce a collision-aware representation to handle severe overlap, allowing the model to sample 3D mesh parameters from the visible body parts. ROMP outperforms previous state-of-the-art methods for both multi-person and single-person 3D mesh regression, demonstrating superior accuracy and efficiency on challenging benchmarks. Additionally, experiments on person-person occlusion datasets and real-world images showcase the effectiveness and robustness of our proposed collision-aware representation. Overall, ROMP presents a novel and efficient approach for monocular multi-person 3D mesh regression, with a focus on addressing occlusion and truncation challenges.