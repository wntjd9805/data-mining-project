This paper introduces the problem of view synthesis in interactive 3D scenes and the challenges it presents, such as precise geometry understanding and inpainting of occluded content. Existing methods, such as Structure-from-Motion and depth estimation, have limitations in acquiring accurate dense 3D geometry. To address this problem, the paper proposes a method called MINE, which combines the MPI and NeRF approaches to create a continuous 3D representation from a single image. MINE utilizes an encoder network to extract image features and a decoder network to generate a 4-channel representation of RGB and volume density values. Experimental results show that MINE outperforms existing methods in both indoor and outdoor view synthesis and depth estimation.