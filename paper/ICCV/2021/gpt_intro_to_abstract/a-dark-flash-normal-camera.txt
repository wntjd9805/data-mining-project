This paper introduces a method that uses a single "dark flash" near infrared (NIR) image and a single visible image taken under uncontrolled lighting to recover high-quality maps of surface normals, diffuse albedos, and specular intensities in a scene. The authors refer to these estimates as a "reflectance map," which can be used for various applications, such as refining depth estimates and digitally manipulating lighting. The use of controlled NIR lighting provides several benefits, including the ability to easily control the NIR lighting in a scene and simplify the estimation problem compared to existing techniques. The authors present a deep neural network that takes an RGB image and a monochrome NIR image as input and generates surface normal and reflectance estimates. The network is trained using stereo depth maps and photometric cues. The paper also includes an explicit model for specular reflectance of human skin and compares the proposed technique to baseline approaches and state-of-the-art methods. Two applications of integrating the technique into a mobile photography pipeline are also demonstrated. Overall, the contributions of this paper include a new network architecture, a new training strategy, and two practical applications in photography.