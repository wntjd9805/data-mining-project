3D object prediction from a single RGB image is a challenging task, as it requires estimating the depth information that is lost during the projection from 3D real world to the 2D image. Humans, on the other hand, are capable of making precise estimations when looking at an image due to their rich prior knowledge about object categories and their ability to leverage geometric relationships among different objects in a scene. Existing methods have attempted to reason about the object pose independently using prior knowledge, but this approach can lead to rough estimations and inaccurate results. To address this issue, we propose leveraging geometric relationships to add more constraints on each object, enabling more reasonable and precise estimation. By explicitly modeling the geometric relationships, we can exclude impossible solutions in the 3D space. We introduce Holistic Pose Estimation (HPE), which evaluates both the 3D bounding box of the independent object and the relative pose of each pair of objects. We evaluate our model on the SUN RGB-D dataset and demonstrate its effectiveness compared to previous methods, both in terms of existing metrics and HPE.