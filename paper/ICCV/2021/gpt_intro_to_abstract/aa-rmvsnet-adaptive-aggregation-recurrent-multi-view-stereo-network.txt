Multi-view stereo (MVS) is a crucial technique in various applications such as virtual reality, autonomous driving, and heritage conservation. While traditional MVS methods rely on hand-crafted matching metrics, recent deep-learning-based methods have achieved superior accuracy and completeness. However, there are still challenges to be addressed, including difficulties in handling thin structures or textureless surfaces and the lack of consideration for pixel-wise visibility issues. In addition, memory consumption is an important factor for scalable MVS algorithms. To tackle these problems, this paper introduces AA-RMVSNet, a novel LSTM-based recurrent multi-view stereo network with intra-view and inter-view adaptive aggregation modules. The proposed network uses adaptive feature extraction and cost volume aggregation to overcome the limitations of traditional methods. The experimental results demonstrate that AA-RMVSNet outperforms competing methods on benchmark datasets. The contributions of this work include the intra-view feature aggregation module and the inter-view cost volume aggregation module.