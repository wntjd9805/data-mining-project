Identifying relevant labels in images is crucial in computer vision applications. However, annotating a large number of diverse classes for real-world applications is time-consuming. Zero-shot (ZS) learning for multi-label classification allows recognition of unseen labels by transferring knowledge between seen and unseen labels. Previous studies focused on single-label recognition or used linear combinations of word vectors to rank labels. But these methods are limited in addressing high semantic diversity in images. Some approaches utilize object detectors or attention techniques, but they have scalability issues or complex loss functions. This paper proposes a method with multiple principal directions to handle label diversity and up-weights samples with higher semantic diversity for better generalization. The model achieves competitive results in tag-based image retrieval and image tagging on various datasets.