Deep Learning has achieved remarkable progress in supervised learning, but acquiring sufficient labeled data is impractical due to the high costs involved. Active Learning (AL) addresses this issue by selecting the most informative samples to query their labels, saving annotation costs while delivering competitive target models. However, traditional AL methods assume that labeled and unlabeled data are drawn from the same class distribution, which is not valid in many real-world scenarios. Unlabeled data often contains samples that are outside the class distribution of labeled data. This class distribution mismatch poses a challenge for AL algorithms, as focusing solely on informative samples can lead to a drop in performance. To address this problem, we introduce invalid query error and valid query error as a heuristic approach to improve the information of samples queried while reducing the cost for invalid queries. We propose the Continuous Class Activation Learning (CCAL) algorithm and provide theoretical proofs for its AL error under class distribution mismatch. The paper also includes a review of related work and experimental results.