This paper introduces a novel input encoding scheme for Spiking Neural Networks (SNNs) that allows for efficient inference with reduced timesteps. Unlike other rate-encoding methods, each timestep in the proposed scheme encodes distinct information. The scheme utilizes a block-wise Discrete Cosine Transform (DCT) to decompose spatial information into a weighted sum of bases, which are then presented to the spike generating layer. By ordering the frequency bases being input at each timestep, the scheme provides a principled way to trade-off accuracy for a reduced number of timesteps during inference. The proposed encoding scheme is used to train a DCT-SNN, which achieves lower timesteps (2-14X reduction) compared to other state-of-the-art SNNs while maintaining comparable accuracy. This work is the first to leverage frequency domain learning for SNNs in vision applications and orders timesteps by significance to enable trade-offs between accuracy and inference speed.