In this computer science paper, the authors address the problem of deep neural networks performing poorly on minor classes in class-imbalanced datasets. They analyze the training progress of a neural network and find that during the early stages of training, the network tends to under-fit the minor class data and classify it into major classes. This leads to feature deviation and over-fitting in later stages of training. The authors propose a learning strategy that equalizes the training progress between major and minor classes by weakening the features of major class data. They demonstrate the effectiveness of this strategy on benchmark datasets and achieve state-of-the-art results. Through their approach, they mitigate feature deviation and improve performance on minor classes in class-imbalanced deep learning.