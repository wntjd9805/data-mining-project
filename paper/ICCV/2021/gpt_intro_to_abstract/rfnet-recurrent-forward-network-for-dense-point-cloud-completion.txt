With the advancement of real-time 3D sensors like LiDAR and depth cameras, 3D data has gained increasing attention in the fields of computer vision and robotics. Point clouds, which provide a more comprehensive representation of a scene compared to 2D images, have been widely used in applications such as simultaneous localization and mapping (SLAM) and object detection. However, point clouds acquired from sensors often suffer from incompleteness and sparsity due to limitations in resolution and occlusion.This paper focuses on the task of point cloud completion, which aims to recover complete and high-resolution models from incomplete inputs. Previous research in this area has primarily relied on deep learning approaches, including methods based on 3D grids and convolutional neural networks (CNNs) as well as those built on the structure of PointNet and PointNet++. However, many of these networks are computationally expensive and suffer from high memory cost due to a large number of parameters. They also tend to overlook details of incomplete point clouds, leading to distortion in the completion results.To address these challenges, this paper proposes a novel recurrent forward point cloud completion framework called RFNet. Unlike the traditional backward framework like U-Net, the RFNet organizes operations in multiple recurrent levels. The framework consists of three modules: Recurrent Feature Extraction (RFE), Forward Dense Completion (FDC), and Raw Shape Protection (RSP). The RFE leverages multiple short global features at different recurrent levels to reduce computational cost. The FDC generates completed point clouds of different resolutions by creating an initial model and lifting it to higher resolutions with fewer lifting levels. The RSP module preserves details of the original incomplete model by driving points from the FDC towards their nearest neighbors in the original point clouds. The driving distances are controlled by a learnable parameter. To improve the shape capturing and result uniformity, the proposed method applies Sampling Chamfer Distance and a new Balanced Expansion Constraint.The contributions of this work include: 1) Introducing a novel recurrent forward framework for point cloud completion that improves completion results while reducing memory cost. 2) Proposing the Raw Shape Protection module to preserve original shapes in a learnable manner. 3) Introducing Sampling Chamfer Distance and Balanced Expansion Constraint to better capture shape differences and improve generation continuity. 4) Experimental evaluation on ShapeNet and KITTI datasets demonstrating the superiority of the proposed network over existing methods in the task of 3D completion.