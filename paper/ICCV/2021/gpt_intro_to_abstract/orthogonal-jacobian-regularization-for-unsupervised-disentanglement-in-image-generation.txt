Unsupervised disentanglement learning is a major challenge in artificial intelligence, particularly in the field of computer vision. It involves learning representations in which each dimension corresponds to a specific factor of variation and is independent of other factors. Several disentanglement methods have been proposed based on generative models such as Variational Autoencoder (VAE) and Generative Adversarial Networks (GAN), but their performance and the quality of generated images have remained limited. This paper introduces a new regularization term called Orthogonal Jacobian Regularization (OroJaR) to encourage the deep generative models to learn better disentangled representations. The method constrains the change caused by different latent dimensions to be uncorrelated by enforcing orthogonality in the Jacobian vectors. OroJaR is shown to be competitive in disentangling latent dimensions corresponding to spatially correlated variations. The proposed method is compared against state-of-the-art methods and is found to perform favorably on three datasets. Additionally, OroJaR can also be used to explore meaningful variations in pre-trained generators. The contributions of this work include the introduction of OroJaR, its application to multiple layers of the generator, and its effectiveness in learning and exploring disentangled representations.