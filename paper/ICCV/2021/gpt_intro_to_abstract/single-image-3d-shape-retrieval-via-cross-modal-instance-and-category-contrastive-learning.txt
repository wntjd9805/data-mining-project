The paper discusses the problem of image-based 3D shape retrieval in computer vision, specifically focusing on the challenges posed by the domain gap between single images and corresponding 3D shapes. Previous works have addressed this problem by mapping 3D shapes and query images into a common embedding space using techniques like triplet loss. However, this approach often requires hard-negative mining for optimal performance. In contrast, the paper introduces contrastive learning, which uses a larger number of negatives for each anchor, leading to state-of-the-art performance without hard-negative mining. The paper also explores the application of contrastive learning to the task of image-based 3D shape retrieval (IBSR), which involves different rendered images of the same object. Additionally, the paper discusses the importance of data augmentation in contrastive learning and proposes the use of a color transfer mechanism to improve generalization and decouple object and color in 2D images. The proposed approach involves converting 3D shapes into multi-view grayscale images and uses an attention mechanism to process them. It introduces an instance loss and a category loss based on self-supervised contrastive learning to ensure accurate shape retrieval at both instance and category levels. The approach is evaluated on three real-world datasets and outperforms previous state-of-the-art methods. The key contributions of this work include the proposed cross-modal Instance-Category loss, the introduction of the color transfer mechanism into contrastive learning, and the significant improvement in retrieval accuracy compared to previous state-of-the-art methods.