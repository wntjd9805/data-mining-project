Deep learning has made significant progress in visual recognition tasks, surpassing human performance in some cases. However, it heavily relies on labeled data, which can be challenging to collect and maintain. Few-shot learning aims to overcome the limitation of labeled samples and learn new categories with only one or a few labeled samples. This topic has gained academic interest due to its potential applications in artificial intelligence. Fine-tuning is a transfer learning method that transfers experience from previous tasks to new ones, but it struggles with domain adaptation when there is limited training data. Episodes-based training strategy has become the foundation of most few-shot learning methods, where each episode focuses on a specific classification task with only a few samples per class. Meta-based learning methods employ meta-learners to improve adaptability to different tasks. Metric learning methods aim to find effective distance metrics from episodic tasks to make class distributions more distinctive. Semi-supervised few-shot learning (SSFSL) focuses on utilizing unlabeled data to improve models, often by predicting pseudo-labels and selecting high-confidence data for iterative training. This approach suffers from lacking instances support for pseudo-label confidence inference in single tasks. To address this issue, this paper proposes a task-free credibility estimation approach called pseudo-loss confidence metric (PLCM) that selects credible pseudo-labeled data by building a unified confidence metric space. The method maps pseudo-labeled data to a pseudo-loss space, develops a selector and a filter to perform confidence metric for unselected and selected pseudo-labeled data, and adopts a self-training strategy to fit the mixed set in the evaluation process. The contributions of this work are: 1) the introduction of PLCM, a novel reliability estimation approach for semi-supervised few-shot learning that assesses confidence in a unified pseudo-loss metric space, 2) a multi-step training strategy that learns a more flexible pseudo-loss distribution to provide a stable confidence metric, and 3) experimental results demonstrating higher performance compared to other state-of-the-art methods on four benchmark datasets for few-shot learning.