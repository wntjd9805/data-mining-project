Convolutional Neural Networks (CNNs) have revolutionized machine learning, particularly in computer vision tasks. However, CNNs have a limited receptive field, making it difficult to capture long-range dependencies. Spatial self-attention modules have emerged as a solution to this issue by extracting non-local interactions among spatial positions and weighting them with learnable parameters. However, the computation of a similarity score for each pair of points in non-local blocks is computationally expensive. Although recent works have improved the computation of the similarity matrix, they lack a theoretical overview of the non-local block formulation. In this work, we propose Poly-NL, an efficient version of non-local neural networks that takes into account long-range dependencies without explicitly computing pairwise similarities. We establish a connection between polynomials and non-local layers, demonstrating that self-attention can be seen as a special case of 3rd-order polynomials. Poly-NL layers reduce the overall complexity from O(N^2) to O(N) with no performance loss. We also showcase the efficiency and effectiveness of our method in various tasks, including image recognition, instance segmentation, and face detection. Our contributions include bridging the formulation between high-order polynomials and non-local attention, proposing Poly-NL as a novel building block for neural networks, and demonstrating the efficacy of our approach in diverse computer vision tasks.