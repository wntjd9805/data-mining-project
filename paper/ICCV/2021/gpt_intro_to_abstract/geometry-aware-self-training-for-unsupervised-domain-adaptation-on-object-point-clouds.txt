This paper introduces the problem of unsupervised domain adaptation (UDA) in the context of object point clouds, aiming to improve the generalization of point cloud classifiers. Point clouds, which are widely used in 3D object classification due to their simplicity and ease of acquisition, can be generated through point sampling on object models. While synthetic point clouds can be easily generated and labeled, real point clouds require manual annotations, resulting in a limited amount of labeled data. Hence, the paper focuses on leveraging the labeled synthetic data to adapt to the unlabeled real data. Previous UDA methods for 2D image classification have been extensively studied, but few works have explored UDA for point clouds. Existing methods either align semantic features or use self-supervised feature encoding, but these approaches have limitations in effectively bridging the domain gap. This paper proposes a novel Geometry-Aware Self-Training (GAST) method for UDA on point clouds, which incorporates self-supervised tasks to regularize semantic feature encoding and mitigate geometric ambiguities. The proposed method outperforms state-of-the-art methods on a benchmark dataset, demonstrating its effectiveness in unsupervised domain adaptation for point cloud classification.