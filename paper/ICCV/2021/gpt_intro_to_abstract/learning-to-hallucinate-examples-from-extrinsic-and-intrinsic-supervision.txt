Few-shot learning is a challenging task in deep learning that aims to learn novel concepts from a limited number of annotated examples. Previous approaches have focused on meta-learning, where models are trained on simulated tasks with support and query sets. However, the performance of classifiers trained on hallucinated examples is still inferior to those trained on real examples. In this paper, we propose a framework that leverages two types of supervision – extrinsic and intrinsic – to improve the generation of hallucinated examples. The extrinsic supervision is obtained from large-sample learning, where a mentor model trained on a large set of real examples guides the generation of hallucinated examples. The intrinsic supervision ensures label consistency between hallucinated and real examples through contrastive learning. We introduce a dual mentor- and self-directed hallucinator that combines these supervision signals and can be used with different classification models to improve few-shot learning performance on various benchmarks. Our framework is model-agnostic and achieves competitive results on datasets such as ImageNet1K, miniImageNet, tieredImageNet, and CUB.