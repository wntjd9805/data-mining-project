Few-shot learning has gained significant interest in the field of artificial intelligence, as it seeks to enable systems to learn new concepts with only a limited number of labeled examples. Meta-learning, or learning-to-learn, has emerged as a prominent approach for few-shot learning. Optimization-based meta-learning, in particular, has been widely used due to its flexibility in various domains. Model-agnostic meta-learning (MAML) is a popular optimization-based meta-learning method that learns an initial set of network weights for achieving generalization. However, MAML often faces challenges in achieving generalization, especially when tasks are diverse or significantly different between training and testing phases. Existing methods have attempted to address this by improving the initialization or the fast adaptation process, but they typically rely on a simple loss function in the inner-loop optimization. This paper proposes a new framework called MeTAL (Meta-Learning with Task-Adaptive Loss Function) to address this limitation. MeTAL learns a task-adaptive loss function through two meta-learners, one for learning the loss function itself and another for generating parameters that transform the learned loss function. The proposed task-adaptive loss function allows for the use of both labeled and unlabeled examples during the inner-loop optimization to adapt the base learner to each task. Experimental results demonstrate that MeTAL significantly improves the generalization performance of MAML, and it also outperforms other MAML-based algorithms. This highlights the importance of a task-adaptive loss function in few-shot learning, and suggests that it is a complementary component to improving the inner-loop update or initialization.