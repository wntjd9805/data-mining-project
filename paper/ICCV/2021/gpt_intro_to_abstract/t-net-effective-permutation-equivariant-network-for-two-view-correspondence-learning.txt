This paper focuses on the problem of reliable feature matching in computer vision tasks such as Structure from Motion, visual Simultaneous Localization and Mapping, and image retrieval. The authors address the challenge of false correspondences caused by factors such as viewpoint changes and lack of texture. They propose a novel network architecture called T-Net that integrates the features from all iterations of the learning process to utilize all available information. Additionally, they introduce a new module called PCSE to capture contextual information effectively. The contributions of this work include the T-Net framework, the reformulation of the SE module, and achieving state-of-the-art performance in two-view correspondence learning. Experimental results demonstrate significant precision improvements compared to previous methods.