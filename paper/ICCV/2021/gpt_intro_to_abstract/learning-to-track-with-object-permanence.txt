In this paper, we introduce a deep learning-based method for multi-object tracking that incorporates the concept of object permanence, which is the ability to understand that occluded objects do not disappear. We focus on the online setting, where the method needs to associate current detections with previously established trajectories. Existing multi-object tracking algorithms operate in the tracking-by-detection paradigm, but they fail to maintain the trajectory of occluded objects once they become partially or fully invisible. To address this limitation, we propose an end-to-end trainable approach that leverages object permanence as an inductive prior. We extend the CenterTrack architecture to process arbitrary video sequences using a convolutional gated recurrent unit (Con-vGRU) to encode the spatio-temporal evolution of objects. This allows the model to reason about the locations of occluded instances. To address the challenge of supervising occluded objects, which lacks consistent annotations, we generate a synthetic dataset using the Parallel Domain simulation platform. By jointly training our model on synthetic and real data, we overcome the domain gap and achieve better performance on real-world multi-object tracking benchmarks. Our contributions include the proposed architecture, the ability to hallucinate trajectories of fully occluded objects, and the use of a mix of synthetic and real data for supervision, which outperforms the state of the art. The source code, models, and data are publicly available.