This paper focuses on the task of image generation from layouts, specifically the conversion of bounding boxes with object categories into photorealistic images. This task is challenging but holds potential for analyzing visual relations through analysis-by-synthesis. It also has various applications, such as collaborative creation between humans and computers. Existing works use layout-mask-image pipelines, where a semantic segmentation mask is first generated and then translated into the final image. However, overlapping object masks in the semantic mask can lead to confusion in the category distribution of pixels, affecting image generation. To address this, the authors propose the Locality-Aware Mask Adaption (LAMA) module, which aims to adapt the raw semantic mask to a cleaner one by considering objects' local relations. Experimental results show that LAMA improves visual quality and layout alignment compared to state-of-the-art methods. The contributions of this paper include the presentation and verification of the importance of clean semantic masks, the proposal of LAMA as a method for generating clean masks, and the introduction of a new evaluation metric called YOLO scores to measure object layout alignment. The paper provides a complete implementation with source code and evaluation metrics.