Given the success of deep neural networks (DNNs), there is interest in deploying them for real-world problems. However, DNNs are often criticized for producing overconfident predictions, raising concerns for the safety and reliability of using machine learning systems in real-world scenarios. Confidence calibration is crucial to address this issue, as it allows for more accurate diagnosis and safer handling. Existing methods for confidence calibration have overlooked the underlying problem of the inability to model uncertainty in output probabilities, which is caused by the closed-world nature of softmax. In this paper, we propose a novel approach called Energy-based Open-World Softmax (EOW-Softmax), which introduces an extra dimension to model uncertainty. We present a theoretical justification for our approach and develop an energy-based objective function to unify the learning of the classification task and uncertainty modeling. Experimental results on benchmark datasets demonstrate that our method leads to a better calibrated model compared to state-of-the-art methods. Our contributions include overcoming the closed-world softmax problem, developing a novel objective function, providing a theoretical proof, and demonstrating improved calibration through extensive experiments.