Deep Convolutional Neural Networks (CNNs) have achieved remarkable success in computer vision tasks, but their high computational complexity and memory footprint pose challenges for deployment on resource-constrained devices. Various methods, such as pruning and dynamic computing, have been proposed to improve CNN inference efficiency. However, existing methods have limitations in effectively leveraging redundancy and integrating spatial and channel redundancies. In this paper, we propose dual gating, a novel dynamic computing method for reducing model computations at runtime. Our approach, called DGNet, incorporates spatial and channel sparsity by utilizing the spatial and channel gating modules. The channel gating module produces a binary mask to turn feature maps on or off, while the spatial gating module uses a tiled binary mask to determine regions for evaluation. By integrating these gating modules with existing networks and jointly training end-to-end, our method achieves substantial computation reductions without sacrificing accuracy. Experimental results on CIFAR-10, ImageNet, and COCO datasets demonstrate that DGNet outperforms state-of-the-art dynamic computing and static pruning methods while maintaining excellent accuracy. Our contributions include the proposal of dual gating, the design of spatial and channel gating modules for flexible integration with CNN architectures, and the verification of performance on various datasets.