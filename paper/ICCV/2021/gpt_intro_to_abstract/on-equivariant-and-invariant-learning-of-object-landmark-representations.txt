Unsupervised learning of object landmarks from unlabeled images is a challenging task in machine learning and computer vision. Existing approaches, especially for few-shot image understanding tasks, have not yet achieved satisfactory performance compared to supervised learning. This paper focuses on the problem of learning representations that can establish correspondences across objects and predict landmarks using only a few labeled examples. One approach for inferring structure is to reason about global appearance in terms of disentangled factors like geometry and texture. Another approach is to learn a representation that transforms geometrically in the same way as the object, known as geometric equivariance. However, these approaches have limitations in handling clutter, occlusion, and inter-image variations. Contrastive learning, which aims to learn representations that are invariant to transformations while being distinctive across images, has shown promising results in unsupervised learning. This paper investigates the necessity of equivariant losses for unsupervised landmark discovery and explores the emergence of representations predictive of landmarks in intermediate layers of deep networks trained to be invariant. The study reveals that intermediate-layer representations trained to be invariant to geometric and photometric transformations are highly predictive of landmarks. The paper also introduces the concept of hypercolumn representation, which improves landmark predictions. The objectives used in equivariant learning can be seen as a contrastive loss within the same image, providing insights into the invariances learned by the two approaches. The paper validates the findings through experiments on landmark matching and detection benchmarks, demonstrating consistent improvements over previous approaches. Furthermore, dimensionality reduction based on equivariant learning improves performance in landmark matching and prediction tasks with limited data.