Human pose estimation is a fundamental task in computer vision that involves localizing human keypoints in 2D images. There are currently two main approaches to pose estimation: top-down and bottom-up methods. Top-down methods rely on a single human detection as input and aim to estimate the pose of that individual. However, in scenarios with crowded or occluded instances, top-down methods may fail to accurately detect poses, as they are limited to inferring a single configuration per human detection. This limitation has led to poor performance on datasets with higher proportions of occluded instances. In this paper, we propose a novel architecture for top-down pose estimation that allows for the prediction of multiple pose instances per bounding box. Our approach, called MIPNet, improves the performance of top-down methods, particularly in situations involving crowding and heavy occlusion. We introduce a Multi-Instance Modulation Block that modulates feature tensors based on a scalar instance-selector, enabling the network to index different pose instances. This approach can be easily incorporated into existing feature-extraction backbones and requires minimal changes to the code. Additionally, MIPNet can efficiently handle multiple instances within a given bounding box, with minimal increase in parameters and inference time. Experimental results demonstrate that MIPNet outperforms state-of-the-art top-down and occlusion-specific methods on various datasets, particularly those with more occlusions and crowding. Our contributions include advancing top-down pose estimation methods by addressing the limitations of the single person assumption, achieving state-of-the-art performance on challenging datasets, and improving resilience to bounding box confidence and missing detections.