The goal of semantic segmentation is to assign a semantic class label to each pixel in an image, which is crucial for tasks like medical imaging and autonomous driving. Deep convolutional neural networks have shown significant improvements in semantic segmentation, but they require large amounts of labeled data. However, labeling data is time-consuming and expensive, leading to a lack of labeled data for tasks like semantic segmentation. In this paper, we propose a novel approach for semi-supervised semantic segmentation using a teacher-student scheme and a contrastive learning module. Our module enforces class-separability of pixel-level features and aligns unlabeled and labeled data in the feature space. We introduce a pixel-level contrastive learning scheme that weights elements based on their relevance and utilize a memory bank for high-quality pixel-level features from labeled data. Experimental results on benchmark datasets show that our approach achieves state-of-the-art performance compared to other methods and is effective in handling semi-supervised domain adaptation tasks.