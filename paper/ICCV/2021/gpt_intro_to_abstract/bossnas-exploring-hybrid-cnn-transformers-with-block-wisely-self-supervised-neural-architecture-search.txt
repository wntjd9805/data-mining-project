The development of neural network architectures has led to significant advancements in visual recognition tasks. Attention-based architectures, such as ViT and DETR, have challenged the dominance of convolutional neural networks (CNNs) in the vision field and show promising performance on various vision tasks. However, manually designing well-optimized hybrid architectures can be challenging as the number of design choices increases. Neural Architecture Search (NAS) aims to automatically search for optimal architectures in a predefined search space, reducing human effort. While previous NAS methods have achieved success, they are computationally expensive. Weight-sharing NAS methods have been introduced to reduce search costs but suffer from inaccurate architecture ranking due to the size of the search space. To address this, previous works have used block-wise supervision but are limited by architectural bias introduced by the teacher model. Unsupervised NAS methods have also shown promise in achieving comparable performance, prompting the proposal of an unsupervised NAS method, Block-wisely Self-supervised Neural Architecture Search (BossNAS). BossNAS aims to address the issue of inaccurate predictive architecture ranking caused by large weight-sharing space while avoiding architectural bias. Instead of using distillation as intermediate supervision, BossNAS proposes a self-supervised representation learning scheme, ensemble bootstrapping, to optimize each block of the supernet. An unsupervised evaluation metric is proposed to ensure fairness in the searching stage. Additionally, a fabric-like hybrid CNN-transformer search space (HyTra) is introduced to evaluate BossNAS. The proposed method demonstrates superior architecture rating accuracy and outperforms previous state-of-the-art NAS methods on different search spaces and datasets, achieving promising results on ImageNet with comparable compute time. The proposed search space and method hold potential for future NAS works and hybrid architecture design.