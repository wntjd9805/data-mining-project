This paper introduces the problem of generic object tracking in computer vision, specifically focusing on RGBD tracking. The goal of this task is to locate an unknown object in a video sequence based on its position in the first frame. The paper highlights the differences between short-term and long-term tracking evaluation protocols and discusses the current lack of specialized trackers for thermal or depth features. The authors present a new fully annotated RGBD dataset called DepthTrack, which is larger and more diverse than previous datasets in this area. They also conduct extensive experiments with state-of-the-art RGB and RGBD trackers on DepthTrack, uncovering findings that can contribute to the development of better RGBD trackers and the collection of improved RGBD tracking datasets. Additionally, the paper introduces a new RGBD baseline tracker, DeT, trained with depth tracking data, which outperforms existing trackers. The authors provide the DepthTrack dataset, annotation metadata, and evaluation code compatible with the VOT 2020 Python Toolkit for easy evaluation of existing and new trackers.