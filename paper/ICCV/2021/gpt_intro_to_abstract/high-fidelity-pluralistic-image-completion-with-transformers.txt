Image completion, also known as image inpainting, is a significant problem in computer vision. It involves filling in missing parts of images with visually realistic and semantically appropriate contents. Traditional methods rely on finding similar patches within the image and pasting them into the missing regions. However, these methods often struggle to find appropriate information in the input image. In recent years, CNN-based solutions have shown significant progress in this field by training on large-scale datasets and learning rich texture patterns. However, CNN models have limitations in modeling global structures and often produce duplicated patterns or blurry artifacts. They are also inherently deterministic, limiting their ability to generate diverse completion outputs. The transformer, a well-explored architecture in language tasks, has gained popularity in computer vision tasks due to its ability to model long-term interactions with the dense attention module. Some preliminary works have also demonstrated its capacity in modeling structural relationships for image synthesis. Additionally, the transformer supports pluralistic outputs by optimizing the underlying data distribution. However, the transformer struggles with high-resolution image synthesis or processing due to its increased computational complexity. Most existing transformer-based generative models also work in an auto-regressive manner, limiting their application in image completion tasks with arbitrary shapes and sizes of missing regions. This paper proposes a new high-fidelity pluralistic image completion method that combines the strengths of transformers and CNN models. The method decouples image completion into two steps: reconstruction of pluralistic appearance priors with a transformer and low-resolution upsampling with a CNN. The transformer is used to sample low-resolution completion results, while the CNN is utilized to render high-fidelity textures for the missing regions. Unlike previous auto-regressive methods, the transformer in this method considers all available contexts to complete the missing regions. The proposed method outperforms state-of-the-art deterministic and pluralistic image completion approaches in terms of completion quality and diversity. It also demonstrates improved generalization in completing extremely large missing regions and large-scale datasets.