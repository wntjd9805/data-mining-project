Multi-object tracking (MOT) is a crucial aspect of computer vision and machine learning, with applications in various fields such as traffic flow estimation, human behavior prediction, and autonomous driving assistance. Over the past decade, significant progress has been made in MOT techniques, but challenges such as occlusion, crowded scenarios, detection errors, and camera motions still affect tracker performance. Appearance information has been widely used in MOT to improve performance, but it is sensitive to occlusions and requires additional computational cost. Motion consistency, on the other hand, offers a simpler and lighter approach by leveraging the assumption that objects' motions follow smooth patterns. However, establishing deep motion-based models faces difficulties, such as the limited information provided by motion alone and the need for accurate tracklet association to address long-term occlusion issues. This paper proposes a novel motion-based tracking approach called the local-global motion (LGM) tracker, which explores the effectiveness of motion-based models in vehicle tracking without using appearance information. The LGM tracker utilizes both local and global motion consistencies to tackle the occlusion issue and employs deep graph convolutional neural networks (GCN) for box and tracklet embeddings. The proposed LGM tracker is evaluated on benchmark datasets and achieves competitive performance with state-of-the-art trackers. The contributions of this paper include tackling vehicle tracking from a motion perspective, proposing a novel embedding method that utilizes both local and global motion consistencies, and achieving competitive performance in vehicle tracking tasks without using appearance information.