Video Object Segmentation (VOS) is an important task in computer vision that aims to accurately track moving objects with segmentation masks. VOS can be categorized into two scenarios: Semi-supervised VOS (SVOS) and Unsupervised VOS (UVOS). SVOS involves training a model with a ground-truth mask in the first frame to track the objects in subsequent frames, while UVOS does not have any prior information or ground-truth masks. UVOS focuses on discovering the primary objects that move against a video's background. In this paper, we specifically focus on UVOS as it does not require user interactions. Existing UVOS methods heavily rely on motion cues to identify primary objects, but they struggle with handling distracting signals in the input, such as static background objects or noisy optical flow estimation. To address this challenge, we propose a novel approach called TransportNet that aligns the motion and appearance cues using Optimal Structure Matching (OSM) to establish correspondence between the two modalities while suppressing distracting signals. Our proposed TransportNet leverages dense local features from optical flow and RGB images and computes the structural similarity using the Wasserstein distance. We integrate the OSM into a two-stream CNN by designing a differentiable neural network layer based on the Sinkhorn method, which optimizes the Wasserstein distance. To make the Sinkhorn method more efficient, we propose a Factorized Sinkhorn method that speeds up optimization and improves UVOS performance. We apply the Factorized Sinkhorn method as a building block in our network architecture called Long-Short SinkHorn (LSSH) block.We evaluate our approach on three benchmark datasets and demonstrate that TransportNet achieves state-of-the-art performance in UVOS. Our contributions include a novel model for noise-tolerant UVOS, a unique OSM mechanism for motion-appearance alignment, and a novel LSSH block for structural matching in end-to-end training.