Autonomous driving has become a topic of great interest in recent years, but achieving fully autonomous cars has proven to be more challenging than expected. One major limitation is the high cost of annotating self-driving datasets, making it difficult to obtain labeled data for training. Self-supervised learning (SSL) has emerged as a promising approach to address this issue by leveraging unlabeled data. However, existing SSL methods are primarily designed for single-centric-object datasets like ImageNet and may not perform well on high-resolution multi-instance images, such as those obtained from self-driving. In this paper, we propose a new approach called Multi-instance Siamese Network (MultiSiam) to adapt SSL methods to multi-instance circumstances. We address two key challenges: defining positive samples for cross-view consistency and calculating similarity between randomly generated views within multi-instance images. We introduce an IoU threshold during random cropping to control the proximity of the two views and ensure local-consistency. To handle feature misalignment caused by the presence of multiple instances, we incorporate RoI alignment and offset alignment techniques. Furthermore, we leverage the natural hierarchy of clusters in multi-instance images to model relationships between instances. We perform clustering within each image to mine intra-image similarity, using a self-attention mechanism for more precise cluster prediction. The learned representation also enhances translation-invariance, benefiting pixel-level visual tasks like semantic segmentation.Our contributions include the development of MultiSiam, which extends the cross-view consistency framework to multi-instance circumstances. We conduct experiments on Cityscapes and BDD100K datasets, demonstrating that MultiSiam pre-trained on Waymo data achieves state-of-the-art transfer performance compared to other SSL methods. We also show that MultiSiam pre-trained on a large-scale autonomous driving dataset (SODA10M) outperforms ImageNet pre-trained models, highlighting the potential of domain-specific pre-training. Importantly, our work is the first to apply SSL to large-scale high-resolution multi-instance street scene datasets, offering valuable insights for further autonomous driving research.