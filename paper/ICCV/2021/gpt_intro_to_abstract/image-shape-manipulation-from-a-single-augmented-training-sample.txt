Deep neural networks have greatly enhanced image manipulation tasks with large training datasets. However, there are situations where only a single unique image is available, making it challenging to train generative models. In this paper, we present DeepSIM, a method for training deep conditional generative models from a single image pair. Our method can handle various image manipulation tasks, including shape warping, object rearrangement, object removal, object addition, and the creation of painted and photorealistic animated clips. We create a primitive representation of the training image, which can be unsupervised or supervised. We then use a conditional image mapping network to learn the mapping between the primitive representation and the image. The user can manipulate the primitive representation to apply desired changes to the target image. We extend previous work on single image manipulation by exploring supervised image-to-image translation and using thin-plate-spline augmentation for training the models. Our approach achieves high-fidelity results while preserving the semantic and geometric attributes of the target image. Our contributions include a general-purpose approach for training conditional generators from a single image pair, the recognition of the importance of image augmentation in this task, and outstanding visual performance on various image manipulation applications.