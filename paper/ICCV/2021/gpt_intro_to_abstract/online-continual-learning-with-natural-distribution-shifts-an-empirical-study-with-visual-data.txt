Supervised learning aims to find models that can predict labels given input data, with satisfactory performance when evaluated on a specific population. However, the assumption of independent and identically distributed (iid.) training data points is challenged in continual learning, where the distribution changes over time. This is especially important for models deployed in interactive systems, where the environment continually evolves. Continual learning algorithms are typically evaluated in an offline setting, where tasks are sequentially introduced and information retention is assessed. However, learning efficacy is not evaluated in this setting. In this paper, we focus on online continual learning, where data arrives in a single online stream and the model needs to immediately predict labels for incoming data. We construct a new benchmark using geolocation-tagged images to study online continual visual learning. We empirically evaluate the natural distribution shift and analyze the behavior of gradient-based optimization in this setting. Our experiments reveal conflicting objectives between learning efficacy and information retention, requiring a careful trade-off. We propose strategies, such as online learning rate and replay buffer size adaptation algorithms, to improve gradient-based optimization for online continual learning. The benchmark and code will be made available to support future research in this area.