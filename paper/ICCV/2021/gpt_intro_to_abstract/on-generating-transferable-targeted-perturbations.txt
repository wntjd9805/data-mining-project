We study the problem of targeted transfer-ability of adversarial perturbations in computer science. The goal is to change the decision of an unknown model to a specific target class given an input sample from any source category. This task is more difficult than simply changing the decision to a random or similar class. Existing methods on targeted transferability have limitations, such as relying on class-boundary information learned by the model or exploiting class impressions learned by a neural network. We propose a novel generative training framework that maximizes the mutual agreement between the source and target distributions in the latent space of a pretrained discriminator. Our approach allows the generator to explore augmented adversarial space during training, enhances the transferability of adversarial examples, and eliminates the need for classiÔ¨Åcation boundary information. We also introduce a neighbourhood similarity matching objective to maximize the local alignment between adversarial and target class samples. Our experiments demonstrate state-of-the-art targeted transferability against various models and defenses.