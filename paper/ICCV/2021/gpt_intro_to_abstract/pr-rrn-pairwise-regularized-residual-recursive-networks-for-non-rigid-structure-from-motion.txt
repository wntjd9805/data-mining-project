The reconstruction of 3D object shapes and camera motions from 2D observations is an important problem in computer vision. Rigid Structure-from-Motion (SfM) methods can reliably solve this problem for rigid objects. However, Non-Rigid Structure-from-Motion (NRSfM) allows for deformations in the object shape, making it a more challenging and under-constrained problem. A common assumption in NRSfM is that the 3D shape in each frame is a linear combination of a small number of basis shapes. Several methods have been proposed to solve the factorization problem in NRSfM, including constraints on cameras, basis, and coefficients. Latent space constraints have been successfully applied in neural network-based models to reduce the indeterminacy of NRSfM. However, regularization becomes difficult when dealing with large-scale and orderless data. To address this, we propose a pairwise regularization approach for non-rigid shape reconstruction. We introduce Pairwise-Regularized Residual-Recursive Networks (PR-RRN), which consists of a Residual-Recursive Network (RRN) and two novel losses: Pairwise Contrastive Loss and Pairwise Consistency Loss. The RRN accurately reconstructs non-rigid shapes, and the pairwise losses further improve the reconstruction. The Pairwise Contrastive Loss encourages similarity between high-rigidity pairs of inputs, while the Pairwise Consistency Loss enforces consistency in the reconstruction. Experimental results show that PR-RRN achieves state-of-the-art reconstruction performance on large-scale human motion and categorical objects datasets. Our contributions include the introduction of the PR-RRN model, the Pairwise Contrastive Loss and Consistency Loss, and a novel pairwise rigidity measurement based on the minimal singular-value ratio.