This paper introduces Adaptive Convolutions with Dynamic Atoms (ACDA), a versatile and scalable convolutional layer that allows for per-pixel adaptive convolutions in any network layer. The proposed method addresses the limitations of existing per-image adaptive convolution methods by decomposing filters into dynamically generated low-dimensional filter atoms at each spatial location. These adaptive filters can then be reconstructed by linearly combining the per-pixel specific dynamic atoms with cross-location shared compositional coefficients. This decomposition enables a fast two-layer implementation of adaptive convolutions, reducing computation and memory footprints to match standard convolutions. Additionally, the paper demonstrates that ACDA can be used as a replacement for standard convolutional layers, effectively modeling intra-image variance in tasks such as image classification, crowd counting, and image restoration. The empirical results show the effectiveness of the proposed method in handling significant intra-image variance while preserving the desirable properties of CNNs, such as translation equivariance and weight sharing.