Super-resolution (SR) is a challenging task in image/video processing and computer vision, aiming to reconstruct high-resolution (HR) images/videos from their low-resolution (LR) counterparts. There are two main research branches in SR: single image super-resolution (SISR) and video super-resolution (VSR). VSR utilizes both spatial and temporal redundancies to reconstruct the HR video, making it attractive for HR video generation and enhancement. The recent progress in VSR research is largely attributed to the development of deep convolutional neural networks (CNNs), which have achieved state-of-the-art results on benchmarking VSR datasets. However, these datasets are mostly synthetic and do not accurately represent the complex degradation processes in real-world LR videos. To address this problem, a real-world VSR dataset called RealVSR is constructed using the multi-camera system of iPhone 11 Pro series. This dataset provides a benchmark for training and evaluating VSR algorithms for real-world degradations. However, due to misalignment and color differences between LR and HR sequences, directly training a CNN with simple losses is not suitable. To alleviate these issues, a specific training strategy is proposed on RealVSR, focusing on detail reconstruction. Experimental results validate the effectiveness of the RealVSR dataset and the proposed training strategy. The contributions of this work include the construction of the RealVSR dataset and the development of a training strategy for VSR models with a focus on detail reconstruction.