This paper introduces a new approach called contrastive detection to alleviate the computational burden of self-supervised pretraining in computer vision. The objective of contrastive detection is to maximize the similarity of object-level features across different augmentations. This approach has three main benefits: it extracts separate learning signals from all objects in an image, provides a larger set of diverse negative samples to contrast against, and is well-suited for learning from complex scenes with multiple objects. The authors leverage unsupervised segmentation algorithms to identify object-based regions in an image and apply the contrastive objective to each object-level feature separately. The effectiveness of this approach is tested on the ImageNet dataset and compared to other self-supervised objectives. The results show that contrastive detection achieves more accurate representations with significantly less training time. Additionally, this approach performs well on challenging tasks such as COCO detection and instance segmentation, semantic segmentation, and depth estimation. The authors also observe that contrastive detection bridges the gap with supervised transfer learning from the COCO dataset. The contributions of this work include the formulation of the contrastive objective, the reduction of computational burden in self-supervised transfer learning, the improvement in transfer performance, and the exploration of the impact of high-quality image segmentations on the contrastive learning paradigm.