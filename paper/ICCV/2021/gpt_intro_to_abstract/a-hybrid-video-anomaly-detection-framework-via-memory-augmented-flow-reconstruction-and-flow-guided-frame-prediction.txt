Video anomaly detection (VAD) is the task of identifying events that deviate from expected behavior in a video. This task is challenging because abnormal events occur less frequently than normal events and can take various forms in practical applications. To address this, unsupervised learning models are trained on normal data, and events recognized as outliers by the trained model are considered anomalies. In recent years, deep learning techniques have been successful in various real-world tasks, including VAD. Reconstruction-based and prediction-based methods have been proposed for VAD, but their results still have room for improvement. In this paper, we propose a novel hybrid framework called "HF2-VAD" that combines flow reconstruction and flow-guided frame prediction for video anomaly detection. We use a Multi-Level Memory-augmented Autoencoder with Skip Connections (ML-MemAE-SC) for flow reconstruction, which consistently produces larger reconstruction errors for abnormal input. We also utilize a Conditional Variational Autoencoder (CVAE) for future frame prediction, incorporating the reconstructed flows as conditions. By leveraging the quality gap between reconstructed normal and abnormal flows, our proposed HF2-VAD method improves anomaly detection accuracy. Our experiments on three public datasets demonstrate that HF2-VAD outperforms state-of-the-art methods in video anomaly detection.