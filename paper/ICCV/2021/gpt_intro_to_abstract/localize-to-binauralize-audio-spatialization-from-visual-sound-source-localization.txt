The perception of movement in animals is primarily guided by visual cues, which provide evolutionary advantages over other modalities like sound. However, audio does contain localization information that can be exploited. Binaural cues, such as interaural time difference (ITD) and interaural level difference (ILD), allow us to localize sounds in the environment. Binaural audio recordings that preserve localization information are relatively scarce, especially for videos, due to the need for special equipment and the high cost involved. In this paper, we propose a computational approach to make binaural audio more accessible. We investigate the use of object localization networks as a weak supervision signal for generating stereo audio from monaural audio. By leveraging the complementary nature of video and audio streams, we aim to minimize the amount of binaural recordings needed for self-supervision. We conduct experiments and show that as little as 10% of total binaural recordings are enough to generate high-quality binaural audio. The key contributions of our work include the proposal of an end-to-end model for converting monaural audio to stereo audio using object localization as weak supervision. We also demonstrate that incorporating localization information helps reduce the amount of binaural recordings needed for learning, making binaural audio more accessible.