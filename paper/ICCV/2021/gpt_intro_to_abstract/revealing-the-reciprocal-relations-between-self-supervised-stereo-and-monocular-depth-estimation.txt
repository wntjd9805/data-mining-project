This paper addresses the problem of depth estimation in computer vision, which is crucial for various applications such as robotic manipulation, augmented reality, and autonomous driving. While supervised depth estimation methods have made significant progress, they require expensive ground-truth data for training. In contrast, self-supervised methods, which only need raw images, have gained attention in recent years. However, existing self-supervised methods focus solely on either monocular or stereo depth estimation, ignoring the reciprocal relations between them. This paper proposes a framework that integrates the advantages of both stereo and monocular depth estimation networks. The framework consists of a self-supervised stereo depth estimation network named StereoNet and a monocular depth estimation network named SingleNet. Distilled depth from StereoNet is used to supervise SingleNet, resulting in improved performance. Additionally, an occlusion-aware fusion strategy is introduced to combine the estimated depth maps from both networks, leveraging their respective strengths. Experimental results on the KITTI benchmark demonstrate that the proposed method achieves state-of-the-art performance in both stereo and monocular depth estimation tasks. This work contributes by providing a simple yet effective framework that exploits the reciprocal relations between the two tasks and by introducing novel strategies for training and fusion.