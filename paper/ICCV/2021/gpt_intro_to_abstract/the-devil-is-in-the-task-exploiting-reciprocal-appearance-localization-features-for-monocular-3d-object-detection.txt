3D object detection using vision- and LiDAR-based techniques has gained attention in the field of autonomous driving and robotic navigation. While LiDAR-based methods have shown success, they are expensive. Monocular 3D object detection, a cheaper alternative, remains a challenging research field. This paper introduces a dynamic feature reflecting network (DFR-Net) that leverages reciprocal information between appearance perception and object localization tasks for monocular 3D object detection. The proposed network consists of an appearance-localization feature reflecting module (ALFR) and a dynamic intra-trading module (DIT), which optimize the multi-task learning process. The DFR-Net achieves superior performance compared to existing methods and can be easily integrated into other frameworks. The paper presents new state-of-the-art results on the KITTI benchmark.