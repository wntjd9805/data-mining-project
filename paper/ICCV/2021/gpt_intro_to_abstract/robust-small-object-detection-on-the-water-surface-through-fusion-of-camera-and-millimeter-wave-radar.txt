Unmanned surface vehicles (USVs) are increasingly being used for various autonomous activities on water surfaces. Accurate and robust environmental perception is crucial for safe navigation and efficient operation of USVs. Small object detection on water surfaces plays a vital role in USVs' environmental perception, especially for tasks such as avoiding obstacles and autonomous floating waste detection. However, vision-based small object detection on water surfaces faces challenges such as light reflection on the water surface, surrounding scene reflection interference, and a short detection range. To overcome these challenges, this paper proposes a method that utilizes the fusion of RGB images and MMW radar data for small object detection in USVs. By combining the strengths of vision and radar sensors, the proposed method aims to improve detection performance and robustness. The paper also discusses the difficulties in small object detection based on MMW radar, including weak echoes from non-metallic targets, interference caused by water surface clutter, and the lack of semantic information. To address these challenges, the paper introduces a novel approach for the deep-level fusion of MMW radar point clouds and RGB images. The proposed method achieves state-of-the-art accuracy and shows good robustness in detecting small objects on water surfaces. The paper also presents a real-time object detection system for USVs and evaluates its performance on a real-world dataset of floating bottles. Additionally, the paper releases the code and a radar-vision dataset for small object detection on water surfaces to benefit the research community. Overall, this paper contributes to the advancement of small object detection for USVs through the fusion of radar and vision data.