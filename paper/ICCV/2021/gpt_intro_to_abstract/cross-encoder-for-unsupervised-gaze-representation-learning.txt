Gaze estimation plays a crucial role in understanding human desires, intents, and states of mind. This paper focuses on 3D gaze estimation, which retrieves the direction of an observer's line of sight. Automatic gaze estimation has numerous applications in psychological research, human-computer interaction, driver distraction detection, and other areas. Previous efforts have been made to develop non-intrusive gaze estimators using facial or eye images and convolutional neural networks (CNNs) to handle practical challenges like head pose variations, eye occlusions, and variable eye shapes. However, training CNN-based methods requires large and diverse labeled data, which is difficult to acquire for precise gaze labels. Limited access to labeled data hinders the development of gaze estimation methods and makes supervised learning prone to overfitting and poor performance on new data. To address this issue, unsupervised or self-supervised learning strategies have been proposed, but they are primarily focused on general-purpose representation learning and may not be optimal for gaze estimation. This paper introduces a novel unsupervised learning framework called Cross-Encoder, which learns disentangled gaze features and eye features from eye images. The Cross-Encoder architecture is trained on paired images of the same eye or with similar gaze directions. Experimental results demonstrate the effectiveness of the learned gaze representation and validate the proposed Cross-Encoder method.