Blind video super-resolution (SR) is a challenging problem in computer vision and graphics, where the goal is to estimate high-resolution frames from low-resolution sequences with unknown blur kernels. Traditional approaches to blind video SR involve using hand-crafted priors and solving complex energy functions, limiting their performance. Recently, deep convolutional neural network (CNN) based methods have been proposed for single image SR, but these methods do not consider temporal information and cannot be easily applied to video SR. Existing algorithms for video SR focus on developing effective motion field and alignment estimation methods, as well as recurrent approaches and Generative Adversarial Networks (GANs) to improve results. However, these algorithms assume known or fixed blur kernels, leading to over-smoothed results. Although some algorithms explicitly estimate blur kernels for single image SR, they cannot be directly extended to video SR. In this paper, we propose an effective video SR algorithm that simultaneously estimates blur kernels, motion fields, and latent high-resolution videos using deep CNN models. Our algorithm avoids hand-crafted priors and explicitly estimates blur kernels from low-resolution input videos. We also develop an image deconvolution model based on video SR image formation to generate intermediate latent frames with sharp structural details. Additionally, we explore sharp features from the restored intermediate latent frames based on motion field estimation and transform them for better high-resolution video restoration. By training our algorithm in an end-to-end manner, we are able to generate clearer images with finer structural details. Experimental results demonstrate that our proposed algorithm outperforms state-of-the-art methods on benchmark datasets and real-world videos.