Visual human pose and shape estimation in computer vision is typically based on traditional cameras. However, the development of event cameras presents new opportunities due to their ability to asynchronously measure per-pixel brightness changes. This paper introduces a two-stage approach called EventHPE for estimating 3D human poses and shapes using events as the sole data source. The first stage, FlowNet, infers optical flow from events, while the second stage, ShapeNet, estimates shape variations over time based on the events and inferred optical flows. A novel coherence loss is proposed to ensure consistency between image-based flow and shape-based flow. The approach is evaluated against existing methods and demonstrates superior performance. Additionally, a new dataset, MMHPSD, is introduced, which is the largest publicly available event-based 3D human pose and shape dataset. The multi-modality nature of the dataset opens possibilities for further research.