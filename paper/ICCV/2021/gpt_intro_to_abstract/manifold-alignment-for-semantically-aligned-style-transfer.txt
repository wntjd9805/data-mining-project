Style transfer aims to generate a synthesized image by transferring the style of one image onto the content of another. Existing methods either rely on global statistics of deep features or local patch-based methods to represent image styles. However, these approaches often fail to preserve the local semantic structure or result in artifacts. To address these limitations, we propose a new style transfer method based on the assumption that image features from the same semantic region form a single manifold. We introduce a manifold alignment framework that learns a projection matrix to align the style and content features in their respective subspaces. This allows for the preservation of semantically aligned image regions and produces stylized output with similar style patterns to the style image. The proposed method can be easily integrated into existing auto-encoder based style transfer structures and supports user editing and semantic segmentation maps as guidance. Additionally, we propose an adaptive weight skip connection structure and orthogonal constraints to preserve the detailed spatial features of the content image and achieve photorealistic style transfer. Experimental results demonstrate the effectiveness and flexibility of our algorithm in achieving promising style transfer results.