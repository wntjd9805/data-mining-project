The goal of temporal action localization in computer science is to locate the starting and ending timestamps of action instances and classify them. While fully-supervised methods using frame-level labels have made significant progress, weakly-supervised models with video-level labels have been proposed to reduce annotation costs. However, these weakly-supervised models struggle to distinguish action and background frames, limiting their performance compared to fully-supervised models. To address this performance gap, a point-supervised setting has been introduced, where only a single timestamp with its action category is annotated for each action instance. Point-supervised methods offer affordable labeling costs and show comparable or superior performance to fully-supervised models under low IoU thresholds. However, these methods suffer from incomplete predictions under high IoU thresholds due to the sparse nature of point-level labels. In this paper, a new framework is proposed to enable models to learn action completeness under the point-supervised setting. Dense pseudo-labels are generated based on point annotations to provide completeness guidance to the model. The framework involves selecting pseudo background points and searching for optimal sequences based on action score contrast to measure instance completeness. Score contrastive loss and feature contrastive loss are introduced to facilitate action completeness learning. The proposed framework achieves state-of-the-art performance on four benchmarks and even outperforms fully-supervised approaches.