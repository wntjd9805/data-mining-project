Imbalanced datasets are a common issue in computer vision, leading to models that overfit to majority classes and perform poorly on minority classes. To address this problem, researchers have explored three main approaches: data-level, cost-sensitive re-weighting, and meta-learning. However, these approaches have limitations, such as computational burden and loss of valuable information. This paper focuses on the cost-sensitive re-weighting approach and proposes a new loss function called influence-balanced (IB) loss. The IB loss assigns different weights to samples based on their influence on the decision boundary, mitigating overfitting. Experimental results demonstrate the effectiveness of the proposed method compared to existing approaches. The contributions of this paper include the identification of overfitting issues in existing loss methods, the design of the IB loss function, and the improvement of generalization performance on imbalanced data. This method can be easily combined with other algorithms for class-imbalance problems.