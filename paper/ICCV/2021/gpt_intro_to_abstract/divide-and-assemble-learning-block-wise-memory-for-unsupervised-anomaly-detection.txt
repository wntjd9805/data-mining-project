Anomaly detection in computer vision is a challenging task due to the lack of abnormal training data. Existing methods rely on unsupervised learning to model the distribution of normality without abnormal samples. Reconstruction-based methods, particularly those based on convolutional neural networks (CNNs), have been widely used for unsupervised anomaly detection. However, the use of downsampling in autoencoder models can result in blurry output and large reconstruction errors for normal samples. To address this issue, we propose the Divide-and-Assemble Anomaly Detection (DAAD) framework. DAAD interprets image reconstruction as a divide-and-assemble procedure, using block-wise memory modules to model the block-level distribution of normal samples. This allows us to modulate the reconstruction capability of the model and achieve a tradeoff between good reconstruction for normal samples and poor reconstruction for abnormal samples. We also introduce skip connections to improve the reconstruction quality of normal samples. Furthermore, we incorporate an adversarially learned discriminator to capture low-dimensional semantic representations for anomaly detection. Our experiments on common unsupervised anomaly detection benchmarks demonstrate the superior reconstruction and detection performance of the proposed DAAD framework.