Vehicle re-identification (Re-ID) plays a crucial role in urban security surveillance and intelligent transportation systems. With the increasing availability of large vehicle datasets and advancements in deep learning approaches, significant progress has been made in vehicle re-identification. However, recognizing vehicle identities with large viewpoint variances still remains a challenge. Existing research tackles this challenge by focusing on data-driven methods and feature complementation. Data-driven methods attempt to synthesize more examples using 3D-based models or adversarial learning, but they do not explicitly regulate feature representations for cross-camera generalization. Feature complementation methods utilize discriminative regional features as a complement to global features, but heavily rely on accurate part annotations. In this paper, we propose a novel approach that incorporates both regional and cross-level features without the need for annotations. We introduce a heterogeneous relation complement network (HRCN) to dynamically fuse these features and construct robust representations. Additionally, we propose a new measure called the cross-camera generalization measure (CGM) to evaluate the models' performance more accurately. Our experiments demonstrate that the proposed method outperforms state-of-the-art approaches on multiple vehicle re-identification datasets.