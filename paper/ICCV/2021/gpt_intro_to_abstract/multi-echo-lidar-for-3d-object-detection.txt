LiDAR, a powerful sensor used for object detection, primarily captures 3D point cloud data and their reﬂectance values. However, other types of LiDAR measurements, such as multiple return signals (echoes), ambient scene illumination, and surface reﬂectance, have been largely ignored in existing LiDAR-based object detection algorithms. In this paper, we propose a multi-signal LiDAR-based 3D object detector (MSLiD) that leverages these features to improve 3D object detection performance. We introduce a multi-signal fusion (MSF) module that combines the dense visual information from ambient and reﬂectance signals with the sparse geometric information from the point cloud. Additionally, we propose a multi-echo aggregation (MEA) module to extract information encoded in different echo groups and improve location estimation. By cascading the MSF and MEA modules, MSLiD achieves accurate object localization and classiﬁcation. Experimental results on real-world and synthetic datasets demonstrate that our method outperforms state-of-the-art single-echo methods by up to 9.1%. Our contributions include the ﬁrst 3D detection framework to leverage ambient illumination, multiple echoes, and reﬂectance signals, as well as the introduction of the MSF and MEA modules for effective fusion and aggregation of multi-signal LiDAR measurements.