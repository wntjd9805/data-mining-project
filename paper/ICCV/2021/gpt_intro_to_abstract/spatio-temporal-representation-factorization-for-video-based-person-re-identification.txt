Video-based person re-identification (re-ID) is a challenging problem in computer vision with various applications in security and surveillance. While there has been progress in image-based re-ID, there are still challenges that hinder the widespread use of re-ID algorithms in real-world systems, such as appearance similarity, occlusions, and frame misalignment. To address these issues, this paper introduces a novel computational unit called Spatio-Temporal Representation Factorization (STRF) module. STRF extracts complementary information along both spatial and temporal dimensions by factorizing features into low-frequency (static/coarse) and high-frequency (dynamic/fine) components. This flexible and parameter-wise economic framework can be inserted into any 3D convolutional neural network (3D-CNN) based re-ID architecture. Experimental results on multiple datasets demonstrate that the proposed STRF module improves the performance of baseline architectures and achieves state-of-the-art results in re-ID evaluation protocols.