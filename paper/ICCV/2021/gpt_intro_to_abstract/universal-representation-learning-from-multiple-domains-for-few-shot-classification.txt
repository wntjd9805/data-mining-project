Deep neural networks have shown remarkable progress in improving results in computer vision tasks. However, these methods often rely on large amounts of hand-labeled data, which is expensive and time-consuming to obtain. Few-shot learning aims to address this issue by adapting classifiers to accommodate new classes with only a few labeled samples. Previous works in few-shot learning have focused on evaluating methods in homogeneous learning tasks where the meta-train and meta-test examples are sampled from a single dataset. However, there is now a growing interest in a more realistic and challenging setting where the goal is to generalize to previously unseen data distributions. In this paper, we propose an efficient and high-performance few-shot method called URL (Universal Representation Learning) that learns a single set of universal representations over multiple domains. Our method leverages useful information from multiple diverse domains while minimizing interference between them. We align the intermediate representations of our multi-domain network and adapt the learned features into new tasks. We evaluate our method on the Meta-Dataset benchmark and show that it outperforms state-of-the-art methods in both previously seen and unseen domain generalization.