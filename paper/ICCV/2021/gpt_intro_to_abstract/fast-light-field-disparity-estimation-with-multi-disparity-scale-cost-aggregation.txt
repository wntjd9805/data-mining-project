Disparity estimation from light fields has become a popular approach with the emergence of consumer-level light field cameras. While many algorithms have been proposed for estimating disparity maps from light field images, learning-based algorithms using 3D CNN architecture have shown improved performance. However, the high computational cost and GPU memory consumption of these methods make them impractical for training and deployment. This paper presents a fast and lightweight deep architecture that does not use 3D CNN modules for estimating disparity maps from light field images. The proposed method includes a physical-based multi-disparity-scale cost aggregation module for efficient cost regularization, as well as an edge guidance sub-network to preserve subtle details. Experimental results show that the proposed network achieves competitive performance compared to state-of-the-art methods, with faster computing speed and lower GPU memory consumption. The contributions of this work include the proposed network architecture, the multi-disparity-scale cost aggregation method, the edge guidance sub-network, and the reduction in computation cost and GPU memory consumption while achieving competitive performance.