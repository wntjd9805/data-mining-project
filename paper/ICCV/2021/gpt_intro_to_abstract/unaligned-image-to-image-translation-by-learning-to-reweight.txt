Recent advancements in Image-to-Image (I2I) translation have shown remarkable success in transferring complex appearance changes across different domains. This has also led to the formulation of other related tasks, such as image super-resolution and domain adaptation, as I2I problems. Supervised image translation methods, like Pix2pix, have been successful in generating high-quality target images when paired training data is available. However, collecting such paired data can be challenging or sometimes even impossible. In the absence of paired data, unsupervised I2I translation methods have achieved impressive results by combining Generative Adversarial Networks (GANs) with constraints like cycle consistency and shared latent space assumption. The fundamental assumption of unsupervised image translation is that the domains used for training are aligned, meaning that each image in one domain can be translated to a meaningful image in the other domain. However, collecting perfectly aligned domain images requires significant effort and attention. As an alternative, one may consider the setting with unaligned domains, which are easier to obtain. However, unaligned domains can contain unrelated or unwanted images, which can impact the quality of image translation and even cause the failure of certain methods.In this paper, we propose an algorithm to learn to translate between unaligned domains where some images in either domain may be unrelated to the main task. We assume the existence of unknown, aligned subsets in both domains, and our aim is to automatically discover these subsets and learn the mapping between them. To address this challenge, we propose a reweighted adversarial loss, which assigns importance weights to each sample during the distribution matching process. By estimating the importance weights, we can select the most relevant samples for sensible image translation. To address the importance weight estimation problem, we analyze the causal generating process of images and hypothesize that images in the aligned subsets can be translated faster than images in unaligned subsets. Based on this hypothesis, our reweighted adversarial loss approximates density ratios and enables image translation between the unknown aligned subsets. Additionally, we propose an effective sample size loss to prevent trivial solutions in the importance network. We evaluate our proposed method on various image-to-image translation problems and demonstrate significant improvements over strong baselines on unaligned datasets, validating the efficacy of our approach. The code and data for our method are available at the provided GitHub repository.