Large-scale annotated datasets are crucial for the success of deep learning models, but they are often expensive to obtain. To address this, various learning techniques such as unsupervised, semi-supervised, and weakly supervised learning have been explored. This paper focuses on active learning, which aims to selectively annotate unlabeled data with limited budgets while achieving high performance. In active learning, two main approaches have been studied: diversity-aware and uncertainty-aware approaches. However, the uncertainty heuristics used in the uncertainty-aware approach are often task-specific. In this paper, the authors propose a simple yet effective loss estimator called Temporal Output Discrepancy (TOD), which measures the potential loss of a sample based on the discrepancy of outputs given by models at different optimization steps. They then propose a deep active learning framework that leverages this loss estimator to select informative samples for annotation. The framework also incorporates a semi-supervised training scheme to further boost performance with unlabeled data. The authors demonstrate the effectiveness of their approach through experiments on image classification and semantic segmentation datasets, showing superior performance compared to existing baselines. The contributions of this paper include the proposal of TOD as a loss measure, the development of a deep active learning framework, and extensive evaluation of the proposed methods.