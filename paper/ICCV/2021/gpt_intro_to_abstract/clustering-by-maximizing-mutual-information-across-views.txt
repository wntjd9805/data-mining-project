In recent years, there has been an explosion of unlabeled data, particularly visual content, leading to a demand for effective organization of these data into distinct groups in an unsupervised manner. Clustering algorithms are commonly used to predict cluster assignments based on the similarity between samples. However, traditional similarity metrics are ineffective for high-dimensional data like images. To address this issue, modern image clustering methods have leveraged deep neural networks to transform high-dimensional data into low-dimensional representations for clustering. However, existing deep clustering methods often fail to satisfy both low inter-group similarity and high intra-group similarity. Some methods capture too much information, including distracting information like background or texture, while others can only differentiate objects belonging to different clusters, leading to low intra-group similarity. To overcome these limitations, a novel framework called Contrastive Representation Learning and Clustering (CRLC) is proposed. CRLC consists of two heads, a "representation learning" head (RL-head) and a "clustering" head (C-head), which share the same backbone network. The RL-head computes similarity at the instance level, while the C-head separates objects into different clusters. The backbone network facilitates information transfer between the two heads, allowing the C-head to extract correct coarse-grained cluster-level patterns. CRLC modulates inter-cluster and intra-cluster similarities between samples by minimizing a weighted sum of two contrastive losses. A novel critic called "log-of-dot-product" is proposed for the contrastive loss associated with the C-head to ensure a tight lower bound. Experimental results demonstrate that CRLC outperforms state-of-the-art single-stage clustering methods on various image clustering datasets. Additionally, the two-stage variant of CRLC achieves better results than a powerful two-stage clustering method on challenging ImageNet subsets. When some labeled data is available, CRLC can also surpass many semi-supervised learning algorithms. The main contributions of this work are: 1) a novel framework for joint representation learning and clustering using contrastive losses, 2) an optimal critic for the contrastive loss on probability vectors, and 3) extensive experiments and ablation studies to validate the proposed method. In summary, CRLC offers a promising approach for effective clustering of unlabeled visual data by leveraging deep neural networks and contrastive representation learning.