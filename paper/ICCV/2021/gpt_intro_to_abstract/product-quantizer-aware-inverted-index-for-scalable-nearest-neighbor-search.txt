Approximate nearest neighbor search has been a challenging problem in computer vision, especially with high-dimensional and large-scale datasets. Efficient indexing and compact data representation techniques, such as the Product Quantization (PQ), have emerged as popular solutions. PQ divides high-dimensional vectors into disjoint sub-vectors and quantizes them into sub-codewords. The PQ-based techniques have shown superior search quality compared to binary hashing methods. Inverted index provides non-exhaustive search by clustering the data, and a practical scalable search system combines inverted index and PQ. However, the relationship between the coarse and fine quantizers in this system is not jointly optimized. This paper raises the question of why the coarse and fine quantizers are learned separately and proposes a joint optimization approach. The proposed method does not introduce additional time and memory overhead and achieves state-of-the-art performance on large-scale ANN datasets.