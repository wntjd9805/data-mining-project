Predicting future human motions has various applications in autonomous driving, game animation, and human-robot interaction. Previous work has focused on deterministic prediction, but future human motion is naturally diverse. Existing methods that aim to produce diverse predictions using variational autoencoders tend to ignore minor distribution modes, resulting in limited output diversity. In this paper, we propose an end-to-end trainable approach for diverse motion prediction that does not require multiple mappings for diversity. Our framework allows for fully controllable motion prediction by fixing the motion of one body part and generating diverse predictions for the remaining parts. We observe that diverse motions are composed of valid human poses organized in smooth sequences, and leverage this observation to develop a pose prior and joint angle constraint to encourage smooth sequences in our generator. Our experiments demonstrate that our approach outperforms existing methods in terms of diversity and accuracy in human motion prediction.