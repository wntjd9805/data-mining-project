The use of wide-angle lenses for capturing wide field-of-view scenes has become increasingly common in recent years. Humans have the innate ability to rectify and understand the distorted scenes produced by such lenses. In computer vision, achieving this task involves recovering the realistic geometric distribution based on hand-crafted or deep features. Existing distortion rectification methods generate rectified images in either a rectangular or invagination form, both of which have limitations in displaying complete content and regular shape simultaneously. In this paper, we propose a Rectification OutPainting (ROP) method that aims to combine the advantages of both traditional rectification constructions while gaining a wider field-of-view. ROP is challenging due to variable painting regions and curve boundaries, which require a parametric framework for addressing these challenges. We design a distortion rectification module that rectifies the input image using invagination with general geometry supervision, and an outpainting module that extrapolates semantically consistent content into the blank region using a dual conditional expansion strategy. We also introduce a curve-aware correlation measurement to enforce local consistency in the extrapolated content. Our experiments demonstrate that ROP can recover realistic details from distorted images, with a complete scene and regular shape, and enable a wider field-of-view beyond the original wide-angle lens. Our contributions include proposing the ROP method to overcome the limitations of traditional rectification representations, designing a general geometry supervision and dual conditional expansion strategy for accurate rectification and outpainting, and introducing a curve-aware correlation measurement to ensure local consistency in extrapolation results.