Robust grasp pose detection for unstructured environments is a fundamental problem in robotics and has a wide range of applications. This paper introduces a novel approach to grasp pose detection in cluttered scenes that improves upon previous methods by addressing the problem of uniform sampling, which hinders the overall performance of the pipeline. The authors propose a geometrically based quality measure, called graspness, which distinguishes graspable areas in cluttered scenes. This graspness measure is calculated by exhaustively evaluating possible future grasp poses from a point. A graspness model is developed to approximate this process, which predicts point-wise graspness scores. This model is object agnostic and robust to variations in viewpoint, scene, and sensor, making it a general and transferable module for grasp point sampling. The authors also propose an end-to-end two-stage network, called Graspness-based Sampling Network (GSNet), that incorporates the graspness measure and sampling strategy. Extensive experiments demonstrate the effectiveness of the proposed graspness measure, model, and end-to-end network, with significant improvements in both speed and accuracy compared to previous methods. The code and models will be made publicly available to facilitate further research in this area.