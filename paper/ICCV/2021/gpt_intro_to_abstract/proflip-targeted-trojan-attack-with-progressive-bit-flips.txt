Deep Neural Networks (DNNs) have revolutionized various real-world applications due to their exceptional performance on complex tasks. However, the deployment of DNNs in safety-critical fields necessitates ensuring model security. Previous research has shown the vulnerability of DNNs to attacks such as adversarial samples and data poisoning. This work focuses on neural Trojan attacks, which manipulate both model parameters and inputs. The goal is to design an efficient approach for Trojan insertion without requiring poisoned training. Neural Trojan attacks involve trigger generation and Trojan insertion, where the trigger is a specific pattern that activates the Trojan. The adversary can insert the Trojan by training the model with poisoned data. The effectiveness of the attack requires a high probability of the model predicting the target class when the trigger is present, while stealthiness involves correct outputs on clean data. This paper presents ProFlip, a bit flip-based Trojan attack that inserts the Trojan into a quantized DNN by altering a few bits of model parameters in memory. The attack comprises three stages: identifying salient neurons, generating the trigger, and searching for critical bits. ProFlip determines the sequence of bit flips to maintain accuracy on clean data while predicting the target class with the trigger present. Evaluation results demonstrate the effectiveness of ProFlip with minimal bit flips required.