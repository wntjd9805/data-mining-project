Semantic segmentation is a fundamental problem in computer vision, aiming to understand image scenes at the pixel level. Recent advances in semantic segmentation have shown rapid progress on current datasets, but collecting large-scale real-world datasets with dense annotations is labor-intensive and time-consuming. To overcome this limitation, one solution is to train a model using synthetic and realistic datasets with free annotations and predict on real-world datasets. However, performance often drops significantly due to the domain shift between synthetic and real data. Unsupervised domain adaptation methods have been proposed to address this domain discrepancy, but they still lag behind supervised learning or semi-supervised learning. In this paper, we propose a target-guided uncertainty rectifying method and an uncertainty-aware pseudo labels assignment technique to improve domain adaptive semantic segmentation. We resample training source images based on the uncertainty statistics of the target domain to enhance distribution alignment and select reliable pseudo labels by fitting predictions to certainty and uncertainty modes using a Gaussian Mixture Model. Experimental results demonstrate the effectiveness of our proposed method in achieving state-of-the-art performance on both GTA5→Cityscapes and SYNTHIA→Cityscapes benchmarks.