This paper introduces the use of a Transformer model for human pose estimation in computer vision. While previous works have focused on improving the network structure of deep convolutional neural networks (CNNs) for pose estimation, the interpretability of these models and their ability to capture spatial relationships between body parts remain unclear. The proposed TransPose model addresses these issues by using Transformer to predict heatmap-based keypoints positions. The Transformer model allows for the interpretation of activation scores, providing insight into the specific image clues that contribute to the predicted locations. Experimental results show that TransPose models achieve competitive performances compared to CNN-based models, with fewer parameters and faster speeds. The model also demonstrates good transfer learning capabilities on the MPII benchmark dataset. Overall, the TransPose model provides a more interpretable and efficient approach to human pose estimation.