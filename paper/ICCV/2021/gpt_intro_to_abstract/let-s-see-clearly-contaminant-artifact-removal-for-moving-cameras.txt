With the increasing use of imaging devices, the occurrence of dirty lens artifacts has also become more common. These artifacts, caused by contaminants on the lens surface, can significantly deteriorate image quality and pose challenges for computer vision tasks. While traditional image inpainting methods are not suitable for removing these artifacts as they ignore the underlying structures and hallucinate content, existing approaches for single image artifact removal have limitations in handling the spatially variant degradation. To address these challenges, we propose a learning-based framework specifically designed for removing contaminant artifacts from moving cameras. Our approach leverages flow maps to identify the degraded regions and utilizes a flow completion network to restore the background motion information. Furthermore, we introduce a recurrent scheme that can iteratively restore each frame by referring to adjacent frames, leading to temporally consistent video results. We train our framework on a synthetic dataset that mimics contaminant artifacts and demonstrate its effectiveness in removing artifacts from real dirty lens videos. Our contributions include the first deep learning approach for addressing contaminant artifacts in moving cameras, a physics-inspired dataset, a flow completion module, and a recurrent scheme for temporal coherence in video restoration.