Semantic segmentation, the task of assigning pixel-level category labels to scenes, is important in computer vision. While deep learning models have achieved good performance on benchmark datasets, they still struggle with the domain shift between training and test data. Unsupervised domain adaptation (UDA) aims to bridge this domain gap by aligning domain distributions or refining target pseudo-labels. In this paper, we propose using self-supervised depth estimation to enhance semantic segmentation performance under UDA. We leverage the correlation between depth and semantics to improve target semantics. We incorporate this correlation in two ways: explicitly learning the task feature correlation and refining target semantic pseudo-labels using the estimated adaptation difficulty. Our approach, Correlation-Aware Domain Adaptation (CorDA), achieves state-of-the-art performance on SYNTHIA-to-Cityscapes and GTA-to-Cityscapes benchmark tasks. Our contributions include a novel UDA framework that utilizes self-supervised depth estimation to enhance semantic segmentation and achieves superior performance on benchmark tasks.