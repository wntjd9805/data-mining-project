Data augmentation, the practice of expanding a dataset by adding transformed copies of each example, is commonly used in image classification. Typically, data augmentation is performed during training, but it can also be used during testing to increase robustness, accuracy, or estimate uncertainty. Test-Time Augmentation (TTA) involves pooling predictions from multiple transformed versions of a test input to obtain a smoothed prediction. TTA is popular due to its ease of use and requires no changes to the underlying model or additional data. However, there is limited research on the design choices involved in TTA. This paper focuses on the aggregation of TTA predictions and analyzes how the standard TTA method of averaging model predictions on transformed versions can result in corruptions. The paper proposes a method that addresses these issues. The goal is to understand which predictions TTA changes and why, and to develop a method that enhances TTA performance. The paper provides insights into TTA and its corruptions through empirical analysis on ImageNet and Flowers-102 datasets. A learning-based method for TTA aggregation is presented, which learns optimal weights per augmentation for a given dataset and model. The proposed method offers a lightweight replacement for simple averaging and can improve Top-1 accuracy by up to 2.5% without increasing model size, training time, or implementation burden. The contributions of this paper include insights into TTA, a new TTA aggregation method that outperforms existing approaches, and practical recommendations for TTA usage.