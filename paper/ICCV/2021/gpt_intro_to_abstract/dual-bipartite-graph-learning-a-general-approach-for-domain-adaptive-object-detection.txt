Object detection has made significant progress in recent years due to advancements in deep learning and the availability of large labeled training datasets. However, the performance of object detection models heavily relies on the assumption that the training and test data are drawn from the same distribution, which is often not the case in real-world applications. Unsupervised Domain Adaptation (UDA) serves as a solution to address the domain shift problem by transferring knowledge from a source domain to a target domain. Existing UDA methods for object detection can be categorized into statistics matching and adversarial learning approaches. In this paper, we focus on investigating UDA techniques for object detection, specifically Domain Adaptive Object Detection (DAOD). Most existing DAOD methods emphasize adapting locally rather than holistically, but they are highly model-dependent. Additionally, previous feature alignment techniques neglect the topological relationships among different foreground objects. To address these challenges, we propose a general DAOD framework called Dual Bipartite Graph Learning (DBGL) that models the cross-domain topological relationships on pixel-level and semantic-level respectively. DBGL can be seamlessly integrated into any modern object detectors. We conduct experiments on benchmarks using two-stage (Faster R-CNN) and one-stage (SSD) object detectors, and our results demonstrate that our approach outperforms state-of-the-art DAOD methods. Overall, our contributions include formulating DAOD as an Open Set Domain Adaptation problem, proposing a method that bridges the gap between one-stage and two-stage DAOD, and conducting extensive experiments to validate the effectiveness of our approach.