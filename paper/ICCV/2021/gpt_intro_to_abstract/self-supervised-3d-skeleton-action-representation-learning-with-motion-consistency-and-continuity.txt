In recent years, there has been significant progress in 3D action recognition based on skeleton data using deep learning networks. However, these methods heavily rely on supervision and require time-consuming and labor-intensive labeling. Thus, there is a need for unsupervised learning techniques that can leverage large amounts of unlabeled data. Self-supervised learning (SSL) has been successful in the image domain, but applying SSL techniques to skeleton data, which represent 3D coordinate positions of key joints, is challenging.Some recent methods have attempted to apply existing video SSL techniques to skeleton data, but they face limitations due to the different speeds at which human skeleton motions move and the lack of appearance information in skeleton data. These limitations make it challenging to learn discriminative motion representation in skeleton data using SSL.In this paper, we propose a novel SSL method for learning 3D skeleton representation. We focus on two critical issues for learning motion representation: motion consistency and continuity. We observe that motion clips with different playback speeds can still look similar if they share the same intrinsic motion consistency. Additionally, we propose a skeleton interpolation module to model the motion continuity of human skeleton data.Our proposed method constructs positive and negative pairs of clips from the same motion sequence and trains the network to distinguish their motion consistency instead of predicting playback speed. The positive pairs have the same motion but different playback speeds, while the negative pairs have the same playback speeds but broken motion. By pulling the positive pairs closer and pushing the negative pairs farther in the latent space, the network can focus on learning discriminative feature representation of skeleton dynamic motion. We also design experiments to evaluate the effectiveness of our approach in 3D skeleton-based action understanding. The results demonstrate the superiority of our method and the ability to significantly improve performance without using additional labeled data. We make three main contributions: proposing a novel approach for self-supervised skeleton representation learning, using speed-changed and motion-broken clips to encourage learning of intrinsic motion consistency, and using skeleton interpolation to enhance the learning of motion features. The findings of our research can encourage further research on unsupervised pretext task design for 3D skeleton action understanding.