Transferring knowledge from a labeled source domain to an unlabeled target domain is desirable in many real-world applications. However, existing deep learning models struggle with domain shifts, leading to poor generalization. Unsupervised Domain Adaptation (UDA) addresses this issue by learning domain-invariant features. While recent UDA methods utilize transferable features learned by deep models pre-trained on large datasets like ImageNet, it has been found that these models are vulnerable to small adversarial changes in the input. This vulnerability raises concerns for their applicability in sensitive applications.Much attention has been given to countering adversarial examples, and several defense methods have been developed, with supervised adversarial training being one of the most successful approaches. However, adversarial training requires labeled data and assumes inputs from a single domain, which limits its use in UDA. This paper proposes a simple, unsupervised, and domain-agnostic method for robustness in UDA. The method does not require labels and leverages data from both the source and target domains, making it feasible for UDA. The approach is motivated by previous work on the transferability of robustness and the observation that adversarially trained models learn different features from normally trained counterparts. Our proposed method, called Robust Feature Adaptation (RFA), embeds the adaptation of robustness in the domain adaptation training by utilizing the feature space of adversarially pre-trained models. RFA instills robustness in the UDA model by minimizing the discrepancy between its features and those of the pre-trained models. This enables the model to learn both domain-invariant and robust features.Unlike previous transferability approaches, our method does not require labeled data or adversarial intervention during domain adaptation training. It only utilizes the intermediate features of the pre-trained robust models and a label-free distance measure between their feature spaces. This characteristic allows RFA to leverage both labeled source and unlabeled target domains. Additionally, RFA is a plug-in method that can be used with any UDA method to enhance its robustness. Experimental results demonstrate that RFA consistently improves the robustness of various UDA algorithms on benchmark datasets. For example, it significantly improves the adversarial robustness of the CDAN UDA algorithm on the challenging VisDA-2017 dataset while maintaining high clean accuracy.