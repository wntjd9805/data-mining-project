This paper introduces the concept of Generalized Zero-Shot Learning (GZSL) in the field of supervised machine learning. GZSL aims to address the limitation of traditional supervised learning algorithms, which can only classify samples belonging to classes seen during the training phase. GZSL aims to enable the classification of samples from previously unseen categories by transferring knowledge from intermediate semantics, such as attributes. Existing GZSL techniques can be divided into embedding-based and generative-based approaches. However, most GZSL approaches rely on visual features from pre-trained deep models, which may not be tailored for ZSL tasks and can lead to negative transfer. To overcome this limitation, the paper proposes a novel framework called Semantics Disentangling for Generalized Zero-Shot Learning (SDGZSL), which disentangles visual features into semantic-consistent and semantic-unrelated latent representations. The framework incorporates a relation module and a total correlation penalty to guide the learning process and ensure independence between the two representations. The proposed framework achieves better performance than state-of-the-art methods on various GZSL benchmarks. The contributions of this work are the introduction of SDGZSL, which disentangles visual features and improves performance in GZSL, and the incorporation of a total correlation penalty for more accurate characterization of semantically annotated features.