Brain tumor segmentation is an important task in clinical assessment and surgical planning. Most existing methods use four modalities simultaneously to improve segmentation accuracy. However, the problem of missing modalities is common in clinical practice. Incomplete multi-modal brain tumor segmentation methods have been proposed to address this issue, but they do not effectively exploit the relations between tumor regions and image modalities. In this paper, we propose a Region-aware Fusion Network (RFNet) that aggregates multi-modal features from different regions adaptively. We introduce a Region-aware Fusion Module (RFM) to establish the relations between modalities and tumor regions and generate attention weights to control the contributions of different modalities. The RFNet also incorporates a segmentation-based regularizer to tackle the problem of unbalanced training. Experimental results show that our method achieves higher segmentation accuracy compared to the state-of-the-art methods. Our contributions include the proposal of RFNet and RFM for incomplete multi-modal brain tumor segmentation, the introduction of a segmentation-based regularizer, and the demonstration of superior segmentation accuracy on benchmark datasets.