Camera relocalization is the process of estimating the 6 degree-of-freedom camera pose in a known environment. Traditional methods require building a 3D map of the environment and explicit matching to establish 2D pixels to 3D coordinates. With the emergence of deep neural networks, the problem can now be solved end-to-end by directly regressing the camera pose or 3D scene coordinates. However, these methods have limited scalability to larger environments with multiple scenes. This paper proposes a continual learning approach for visual localization, where scenes are encountered sequentially and only the data for the current scene needs to be stored in memory. This approach reduces computational and memory costs compared to joint training methods. The paper introduces different categories of continual learning approaches and highlights the challenges of catastrophic forgetting and non-stationary data distribution. The proposed buffering strategy, which considers the 3D geometry of the scene, outperforms existing methods on challenging datasets. The contributions of this work include the introduction of the problem of continual learning for visual localization, the creation of a strong experience-replay baseline, and the proposal of a new buffering strategy conditioned on the 3D geometry of the scene.