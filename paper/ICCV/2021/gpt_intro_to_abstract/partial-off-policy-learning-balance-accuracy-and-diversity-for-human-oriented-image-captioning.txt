This paper addresses the challenge of image captioning in the fields of computer vision and natural language processing. The goal is to develop models that can accurately and diversely generate captions for images, similar to how humans would describe them. Previous image captioning methods have focused on accuracy using deep reinforcement learning (RL) techniques, but they tend to lack diversity. Other methods have prioritized diversity using approaches like VAE or GAN, but at the expense of accuracy. To balance accuracy and diversity, the authors propose a novel partial off-policy learning scheme. They introduce an off-policy strategy into the RL-based image captioning framework, enabling more efficient exploration of new possibilities. Samples derived from this strategy are fed into the model and rewarded using a novel criterion called max-CIDEr, which encourages recurrence. By narrowing down the searching space to a certain sub-space, the training process becomes more effective.The contributions of this paper include the introduction of the off-policy strategy and the max-CIDEr reward for RL-based image captioning to promote diversity. They also propose the partial off-policy learning scheme to achieve a balance between diversity and accuracy. The method is evaluated on the MSCOCO dataset and demonstrates a significant boost in diversity compared to baseline methods, while maintaining high accuracy. The approach also shows a strong correlation with human evaluation. The authors emphasize the modularity of their work, making it applicable to future image captioning research.