Image denoising is an important task in computer vision, and it has gained significant interest in related fields. Most denoising methods rely on training with cropped small patches due to hardware limitations. However, these methods may fail when applied to real noisy images. In real images, there is context consistency between patches, which is not present in cropped patches. Additionally, there are significant differences between the Gaussian noise typically used in training and the real noise found in images. Real noise is generated through the image processing pipeline and is influenced by factors such as shot noise and read noise. Furthermore, due to difficulties in image capturing, there is a lack of real image training data with varying noise parameters. To address these challenges, this paper proposes CPNet, a patch-based deep learning method for real image denoising. CPNet leverages cross-patch consistency and contextual dependency using a Cross-Patch Graph Convolutional Network. It also utilizes a novel loss function to leverage noise level maps and proposes a method to generate realistic noisy images for training. Experimental results demonstrate that CPNet achieves state-of-the-art performance in real image denoising.