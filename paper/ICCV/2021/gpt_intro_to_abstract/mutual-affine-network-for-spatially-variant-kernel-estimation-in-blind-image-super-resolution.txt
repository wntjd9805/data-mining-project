Single image super-resolution (SR) is a classical vision problem in computer science, aiming to reconstruct a high-resolution (HR) image from a low-resolution (LR) image. Convolutional neural networks (CNNs) have become widely used in SR, but most existing methods assume an ideal and fixed blur kernel, resulting in poor performance when the real kernel deviates from the ideal one. This has led to a growing interest in blind SR, which deals with unknown blur kernels. However, existing blind SR methods have two inherent problems: they assume spatially invariant blur kernels and estimate a single kernel for the entire image. Real-world blur kernels are often spatially variant and estimating a single kernel is susceptible to the adverse effects of flat patches. This paper introduces the Mutual Affine Network (MANet), a kernel estimation framework with a moderate receptive field that can accurately estimate kernels from small LR image patches. The framework includes a feature extraction module and a kernel reconstruction module, with the Mutual Affine Convolution (MAConv) layer to enhance feature expressiveness without increasing the network's receptive field. MANet outperforms existing methods in both spatially variant and invariant kernel estimation, leading to state-of-the-art blind SR performance when combined with non-blind SR models. It also demonstrates good properties in accurately estimating kernels from non-flat patches and producing fixed kernels for flat patches.