Scene Graph Generation (SGG) is a computer vision task that involves detecting instances-of-interest and their relationships in an image. It plays a crucial role in bridging the gap between computer vision and natural language processing, supporting high-level tasks such as visual captioning and visual question answering. However, existing SGG methods have limitations in providing sufficient and informative scene graphs. This is mainly due to imbalances at both the semantic space level and the training sample level. The semantic space level imbalance arises from the fact that common predicates have large semantic spaces, while informative predicates with specific content have smaller semantic spaces. This leads to confusion and insufficient information in scene graph annotations. The training sample level imbalance occurs because informative predicate samples are dominated by common predicate categories. To address these challenges, we propose a pipeline called Scene Graph Generation with Balance Adjustment (BA-SGG) that incorporates two novel components: Semantic Adjustment (SA) and Balanced Predicate Learning (BPL). SA transforms common predictions into informative ones by exploiting semantic relations among predicates, while BPL mines informative predicates based on their information content. Our experiments using the Visual Genome dataset demonstrate that BA-SGG significantly outperforms state-of-the-art SGG approaches, achieving higher Mean Recall (mR) scores. Additionally, we propose a new metric, mRIC@K, to measure the information content of scene graph results. Overall, our work contributes to improving the performance and practical applicability of SGG by addressing imbalances in semantic space and training samples.