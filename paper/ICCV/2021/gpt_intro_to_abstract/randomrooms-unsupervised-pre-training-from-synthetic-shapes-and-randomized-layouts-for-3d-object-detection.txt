Recent advances in 3D deep learning have led to significant progress in point cloud tasks, including object-level understanding and scene-level understanding. However, the lack of large-scale real datasets has been a bottleneck in 3D object detection. To address this, we propose utilizing synthetic CAD object models for unsupervised pre-training, similar to 2D vision tasks. Previous works have focused on pre-training for single object-level tasks, while a recent work explored pre-training for higher-level scene understanding tasks but encountered domain gap issues and point-level representation limitations. In this work, we introduce RandomRoom, a framework that utilizes ShapeNet, a synthetic CAD model dataset, for 3D pre-training. We generate two different layouts using randomly sampled objects from ShapeNet and perform object-level contrastive learning to learn 3D scene representation. Unlike existing approaches, our method removes the requirement of point correspondence and supports more diverse backbone models. Experimental results demonstrate the effectiveness of our method, achieving state-of-the-art performance in 3D object detection on benchmark datasets. Our method also shows better performance with fewer training samples, indicating improved initialization for 3D object detection.