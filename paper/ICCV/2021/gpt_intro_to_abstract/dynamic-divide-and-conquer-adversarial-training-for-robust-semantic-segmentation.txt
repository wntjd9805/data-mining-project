Recent research has shown that deep learning models, particularly in the classification task, are susceptible to adversarial samples. These samples deceive the target model by generating imperceptible perturbations on clean samples. This vulnerability also exists in semantic segmentation. However, there is limited work on improving the robustness of semantic segmentation networks. Adversarial training has been shown to be effective in enhancing classification models, but its impact on semantic segmentation is unclear.In this paper, we investigate the effect of adversarial training on the semantic segmentation task. We find that adversarial training hinders convergence on clean samples, similar to its effect on classification. Our objective is to enable networks to perform well on adversarial examples while maintaining good performance on clean samples.To address this, we propose a dynamic divide-and-conquer adversarial training (DDC-AT) strategy. This strategy involves training multiple branches in the target model, each handling pixels with different properties towards adversarial perturbations. A "main branch" is responsible for adversarial samples and clean samples that are unlikely to be perturbed, while an "auxiliary branch" deals with sensitive clean samples.The divide-and-conquer setting is dynamic, as pixels near the decision boundary from clean samples start in the auxiliary branch but gradually move to the main branch during training. This dynamic procedure is implemented through a "mask branch." Our method reduces performance deterioration on clean samples and improves robustness against adversarial samples. Importantly, unused branches can be discarded during inference, keeping parameters and computation cost the same.We conduct extensive experiments using various segmentation models on the PASCAL VOC 2012 and Cityscapes datasets. Our results demonstrate the effectiveness of adversarial training in improving the robustness of segmentation networks. Furthermore, our DDC-AT strategy enhances this defense approach, achieving superior performance against both white- and black-box attacks.In summary, our contributions are threefold: (1) providing a comprehensive exploration of adversarial training in semantic segmentation, serving as a strong baseline for evaluating defense strategies; (2) introducing the DDC-AT strategy, significantly improving defense performance on both clean and adversarial samples; and (3) conducting experiments with different model structures and datasets to validate the effectiveness and generality of DDC-AT.