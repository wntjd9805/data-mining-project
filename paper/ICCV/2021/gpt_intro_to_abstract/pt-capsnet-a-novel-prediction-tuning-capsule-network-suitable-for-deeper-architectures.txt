Convolutional Neural Networks (CNNs) have been successful in capturing object features, similar to the human visual system, by using small kernels to identify patterns. CNNs have been widely used for various vision tasks due to their ability to learn feature representations from data. However, CNNs do not reflect the hierarchical sub-parts and relationships between object parts that humans naturally perceive. Capsule networks (CapsNets) address this limitation by representing distinct parts/instances as capsules, each encapsulating different attributes. Capsule layers consist of multiple capsules, and an agreement mechanism between layers enables parsing of different levels of capsules. Despite their advantages, existing CapsNets have limitations, such as an overemphasis on global information capture, a high number of parameters leading to reduced generalization ability, and computationally expensive routing mechanisms. In this paper, we propose a novel Prediction-Tuning Capsule Network (PT-CapsNet) to overcome these limitations. PT-CapsNet is scalable, equivariant, and exhibits sparser projections, resulting in improved robustness and generalization ability. Our contributions include introducing two instance layers, FC-PT-Caps and LC-PT-Caps, investigating different combinations to build PT-CapsNet, and validating its robustness to affine transformations. We also extend the model to larger architectures for classification, semantic segmentation, and object detection tasks, achieving comparable or better performance than CNN-based baselines with significantly fewer parameters.