Digital images can undergo quality degradation during processing, compression, and transmission. Image restoration algorithms have been developed to improve the quality of degraded images. Assessing the quality of restored images and evaluating image restoration algorithms is essential. Full-reference image quality assessment (FR-IQA) approaches compare restored images with their corresponding pristine-quality images. However, FR-IQA methods cannot be applied to blind image restoration tasks and real-world applications where pristine-quality images are unavailable. To address this issue, no-reference IQA (NR-IQA) methods directly regress restored images to quality scores. Unfortunately, the absence of reference information results in a significant drop in performance. In this paper, we propose a new solution called degraded-reference IQA (DR-IQA) that leverages reference information from degraded images to evaluate image restoration models without pristine-quality images. We introduce a Conditional Knowledge Distillation Network (CKDN) that consists of three modules: a degradation-tolerant embedding module, a quality-sensitive embedding module, and a convolutional score predictor. The CKDN effectively extracts reference information for IQA from degraded images and achieves comparable performance to FR-IQA on various image restoration tasks. We also study the influence of reference quality and the performance of current IQA methods on different image restoration tasks. Our findings contribute to the IQA and the blind super-resolution (SR) communities and provide insights for evaluating GAN-based models. Our main contributions include leveraging degraded images for IQA, proposing an effective conditional knowledge distillation network, and demonstrating the usefulness of degraded references for evaluating GAN-based images.