Recently, crowd counting has become a topic of great interest due to its various real-world applications. However, counting people in a crowd is a challenging task due to occlusions and scale variations caused by different factors. While state-of-the-art crowd counters have made significant progress, they still suffer from performance degradation when applied to unseen datasets. The lack of generalizability of existing crowd counting methods restricts their practical applications. This paper presents the problem of universal cross-dataset crowd counting and proposes a solution to improve counting performance and reduce deployment cost. The paper highlights the challenges of crowd counting, including the labor-intensive annotation process and the substantial variation in crowd density and scale distributions across different scenes. The paper investigates the robustness of crowd counting against scale shift and demonstrates that direct training of a universal model using images from multiple sources is difficult. Inspired by face alignment techniques, the paper introduces a scale alignment module to align scale distributions and facilitate learning a single model for various scenes. The paper presents a closed-form solution for optimizing scale translations and corresponding image rescaling factors. Additionally, the paper proposes SDNet, a neural network that predicts scale distributions without the need for person detection. A novel loss function based on joint distribution representation and sliced Wasserstein distance is proposed to optimize SDNet. The contributions of this paper include the development of scale alignment for crowd counting, a scale alignment method, a novel neural network for predicting scale distributions, and an efficient optimization technique. The paper's overall framework involves dividing images into patches, predicting scale distributions using SDNet, performing scale distribution alignment, and optimizing the rescaling factor for each patch.