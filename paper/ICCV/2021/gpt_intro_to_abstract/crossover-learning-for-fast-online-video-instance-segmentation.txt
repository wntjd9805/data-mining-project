Video instance segmentation (VIS) is a task in computer vision that aims to label instances within video sequences with per-pixel accuracy. It plays a crucial role in various applications, such as autonomous driving, video surveillance, and video editing. Although significant progress has been made in still-image object detection and instance segmentation, extending these methods to VIS remains a challenging task. Video sequences present unique challenges, including a large number of frames, heavy occlusion, object disappearing, and unconventional object-to-camera poses. To overcome these challenges and improve the performance of video understanding tasks, it is essential to leverage the temporal information among video frames. Previous deep learning-based methods have focused on pixel-level and instance-level feature aggregation, associating instances using metric learning, and post-processing techniques. In this paper, we propose a novel scheme called crossover learning, which uses instance features in the current frame to localize the same instance in other frames. Unlike previous methods, crossover learning does not require additional network blocks for feature alignment and fusion, and it enhances temporal information without increasing the computation cost. Furthermore, crossover learning is integrated with the instance segmentation loss, enabling efficient many-to-many relation learning across frames. We also introduce a global balanced instance embedding branch to improve association in video instance segmentation. Our proposed method, CrossVIS, achieves state-of-the-art performance on three challenging VIS benchmarks, YouTube-VIS-2019, OVIS, and YouTube-VIS-2021, and strikes a good speed-accuracy trade-off. We believe that CrossVIS can serve as a strong baseline for future research in this field.