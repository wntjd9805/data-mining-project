This computer science paper introduces two different paradigms for human mesh recovery: optimization-based methods and regression-based methods. Optimization-based methods fit models to 2D evidences, producing accurate results but can be slow and sensitive to initialization. Regression-based methods directly predict model parameters from images, showing promising results but suffer from coarse alignment between predicted meshes and image evidences. To address these challenges, the authors propose a Pyramid Mesh Alignment Feedback (PyMAF) loop in their regression network to exploit multi-scale contexts for better mesh-image alignment. They extract mesh-aligned evidences from spatial features and use them to correct parametric errors, improving alignment with input images. They also incorporate a feature pyramid and impose auxiliary pixel-wise supervision to enhance the reliability of spatial cues. The contributions of this work include the introduction of a mesh alignment feedback loop, the use of a feature pyramid for multi-scale alignment contexts, and the imposition of auxiliary pixel-wise supervision for more informative spatial features and relevant mesh-aligned evidences.