The ability to forecast human movements in real-world scenes is crucial for various applications in robotics, healthcare, and surveillance systems. However, this task is challenging due to factors such as social interactions, object influences, and occlusions. Existing solutions for human pose dynamics and trajectory forecasting often neglect these factors, leading to limited effectiveness in real-world scenarios. To address these challenges, we propose a novel model that considers all the mentioned factors by modeling human skeleton, social, and human-object interactions using attention graphs. We also introduce a message passing approach to fuse different levels of interactions and dynamically model spatio-temporal attentional relationships. Additionally, we address the issue of joint invisibility and propose a curriculum learning strategy to improve convergence and mitigate accumulative errors. Finally, we introduce a new benchmark dataset and evaluation metrics for this real-world problem. Our contributions aim to advance the current state of human pose dynamics and trajectory forecasting in practical scenarios.