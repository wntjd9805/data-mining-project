Measuring similarities among examples is a crucial task in computer vision, and metric learning aims to learn a distance metric that can distinguish samples from different classes. Deep metric learning (DML) methods, leveraging deep learning techniques, employ a combination of convolutional neural networks (CNNs) and fully connected layers (FCs) to map images to an embedding space and measure similarities using Euclidean distance. DML has outperformed conventional methods in various tasks, including image retrieval, face recognition, and person re-identification. However, existing metric learning methods focus on discriminative objectives that discard intraclass variations, which hinders performance in unseen class retrieval. This paper introduces the deep relational metric learning (DRML) framework, which learns to characterize instances comprehensively while distinguishing different instances. The framework utilizes a set of feature extractors to produce an ensemble of features, capturing different aspects of each image. A relational model is then employed to discover structural patterns in the feature ensemble and obtain a relation-aware embedding for similarity measurement. DRML offers a stronger relational bias compared to traditional deep metric learning methods, resulting in better generalization to unseen classes. Experimental results on several datasets validate the effectiveness of the proposed framework.