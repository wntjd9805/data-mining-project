Salient object detection (SOD) is an important task in computer vision with applications in image editing, image retrieval, visual tracking, and video object segmentation. However, different devices have unique properties and require different designs of SOD models. State-of-the-art SOD methods either have high inference latency or suffer from performance drop in resource-constrained scenarios. To address this, we propose a device-aware search scheme with an integral search space that considers both the backbone and saliency head of SOD models. We introduce a searchable multi-scale unit that supports parallel convolutions with different kernel sizes and reparameterizes multi-branch convolutions for low latency. We also generalize handcraft saliency heads into searchable parts, creating a rich search space for the saliency head. To explore the search space effectively, we propose a latency-group sampling method that guides sampling based on device latency. Through extensive evaluation on popular SOD datasets, our proposed method achieves similar performance to handcrafted methods but significantly reduces inference latency on various devices, enabling the scalability of SOD in different deployment scenarios.