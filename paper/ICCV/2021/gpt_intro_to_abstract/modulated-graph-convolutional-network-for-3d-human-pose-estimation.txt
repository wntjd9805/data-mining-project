3D human pose estimation (HPE) is a critical task in computer vision with applications in human-computer interaction, action recognition, and intelligent surveillance. However, it remains challenging due to the ill-posed nature of the problem. Deep neural networks have been widely used for 3D HPE, but most existing methods suffer from limitations such as weight sharing and suboptimal graph structures. In this paper, we propose a novel approach called the Modulated GCN to address these limitations. The Modulated GCN incorporates weight modulation and affinity modulation to disentangle feature transformations and adjust the graph structure, respectively. Our method significantly reduces the model size while achieving similar accuracy compared to state-of-the-art GCN methods. We also investigate different affinity modulation methods and regularizations to further improve the generalization ability. The experimental results demonstrate the effectiveness of our approach in terms of model complexity and accuracy.