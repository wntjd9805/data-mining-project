The development of object recognition in computer science heavily relies on large-scale data annotation and deep neural networks. However, the creation of new datasets often lags behind due to cost constraints. To address this issue, various learning paradigms have been developed, such as self-learning, semi-supervised learning, and transfer learning. In this paper, we propose a multi-source domain adaptation and label unification (mDALU) problem, where multiple source domains with partial-class annotation and different data modalities are combined to develop object recognition models for a target domain. We introduce novel modules, including domain attention, uncertainty maximization, and attention-guided adversarial alignment, to handle the challenge of negative transfer and align the distributions between source and target domains. We also propose a pseudo-label based supervision fusion module to further improve the results by transferring the supervision in the unified label space. Our method is evaluated on various tasks, including image classification and semantic segmentation, using both synthetic and real data, as well as images and LiDAR point clouds. The experimental results demonstrate the effectiveness of our approach in outperforming competing methods.