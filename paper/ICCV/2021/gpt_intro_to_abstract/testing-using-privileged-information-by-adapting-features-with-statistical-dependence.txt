Supervised learning often involves the use of additional information, known as privileged features, during training. However, in certain cases, these privileged features are only available during testing. This scenario, called testing using privileged information (TUPI), is different from retraining with new features and can be useful when the predictor is trained on a single feature but multiple features are available during deployment. This paper addresses the problem of TUPI, where the goal is to improve the prediction using additional features only available at testing time. The authors propose a method to denoise the statistical dependencies between the predictor and the additional features to enhance the prediction accuracy. They demonstrate the effectiveness of their approach on the task of visual attribute ranking, showing significant improvements over initial predictors. The paper also discusses the issue of hyperparameter tuning in the unsupervised setting and suggests using user sampling and validation labels to guide the selection process. Overall, the paper introduces a novel approach for utilizing privileged information at testing time to improve predictions in computer vision tasks.