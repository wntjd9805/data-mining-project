Convolutional neural networks (CNN) have achieved impressive performance in image classification tasks. However, humans are able to learn rapidly by leveraging prior knowledge and contextual information. This has led to increasing interest in few-shot learning (FSL), which aims to generalize to new tasks with limited samples. Existing FSL methods, such as transductive learning and metric learning, have shown promise but still have limitations. Transductive learning performs classification on unlabeled test examples as a whole, but may not capture the geometric properties of the data. Metric learning methods replace the fully connected layer in standard image classification, but may not generalize well to new tasks. To address these limitations, we propose the use of Riemannian geometry, specifically the oblique manifold (OM), for FSL. OM has advantages over other manifolds, such as not requiring whitening and having all columns with unit Euclidean norm. We argue that OM is superior for FSL because of these properties. To enhance the generalization of OM, we leverage the power of CNN features and propose a non-parametric RSSPP method. We also design an Oblique Discriminative Classifier (ODC) parameterized with weights and anchors. The anchors are initialized based on the Karcher mean among associated points, and prototypes are also embedded to OM. Finally, classification scores are obtained by performing a weighted sum over softmax on the Euclidean distance in tangent space. Our method is demonstrated through extensive experiments on multiple datasets, achieving state-of-the-art performance in FSL. Our contributions include the modeling of FSL on OM, the proposal of a non-parametric RSSPP method, the design of the ODC with weights and anchors, and the demonstration of improved performance in FSL tasks.