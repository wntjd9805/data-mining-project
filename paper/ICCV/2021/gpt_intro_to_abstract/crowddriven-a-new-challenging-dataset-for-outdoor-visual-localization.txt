Abstract:Visual localization, the estimation of camera pose from an image with respect to the scene, is crucial for computer vision and robotics applications. However, existing methods relying on local descriptors and 2D-3D matches have limitations in handling changing conditions. Benchmark datasets for localization under changing conditions are mostly captured in controlled environments, lacking control in real-world applications. To address this, we present a dataset mined from a crowd-sourced database, containing diverse visual changes and annotated with reliable poses. Our contributions include a workflow for mining and annotating challenging image sequences, the CrowdDriven dataset with geographically diverse scenarios, and experiments showcasing the challenges it poses for existing methods.