Progress in the field of autonomous driving requires challenging tasks and well-defined evaluation metrics. However, existing learning-to-drive models struggle with sample-complexity, safety, and unseen generalization, highlighting the need for more suitable benchmarks. This paper hypothesizes that high-fidelity simulation environments and well-defined evaluation procedures can lead to the development of more sophisticated agents. Simulated autonomous racing offers a complex task that requires real-time decision making, handling of realistic vehicle and environmental dynamics, leveraging of informative intrinsic reward schemes, and efficient use of offline demonstrations. The paper introduces the Arrival Autonomous Racing Simulator, a multimodal and continuous control environment for training and evaluating autonomous racing agents. This simulator provides competition-style racetracks, flexible sensor placements, and various vehicle dynamics profiles. It also offers tools for fine-grained agent evaluation. The paper also presents the Learn-to-Race (L2R) framework, which defines interfaces for sensor modalities and provides a training and testing environment for learning-based agents. The paper's contributions include the simulator, the L2R framework, an L2R task and dataset with expert demonstrations, and an academic release of the simulator and code.