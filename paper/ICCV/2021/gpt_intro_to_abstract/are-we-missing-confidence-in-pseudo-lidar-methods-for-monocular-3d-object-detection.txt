3D object detection is a vital technology for applications such as autonomous driving and augmented reality, as it provides information about the pose, location, and category of objects in 3D space. Existing solutions for accurate localization rely on depth information from stereo cameras or LiDAR sensors, but these have downsides like increased costs, recalibration routines, and limitations on product design. Monocular cameras offer a cheaper alternative but present challenges due to the absence of depth observations. In this paper, we highlight two main contributions. Firstly, we analyze the inconsistency between the performance of pseudo-LiDAR (PL)-based methods on the validation and test sets of the KITTI3D benchmark and identify a biased training protocol as the cause. Secondly, we propose introducing a mechanism for predicting a 3D confidence score in PL-based methods, which leads to significant performance gains. We demonstrate that training the 3D confidence through direct regression of the expected loss, expressed in relative terms, improves performance and establishes a new state-of-the-art on the KITTI3D benchmark.