Generic visual tracking is a challenging task in computer vision due to factors such as limited training samples, appearance variation, and background clutter. Siamese network based trackers have gained attention for their speed and accuracy in target matching. However, they struggle to effectively utilize background information. On the other hand, modern discriminative trackers exploit background information but have limitations in discrimination, localization, and efficiency. In this paper, we propose a novel discriminative tracker, DTT, based on the Transformer architecture. DTT effectively exploits scene information for classification and bounding box regression. It achieves state-of-the-art results on multiple benchmarks while running at over 50 FPS. Our contributions include the introduction of DTT, its ability to generate discriminative feature embeddings, dense prediction for location and bounding box, and its comparable performance to state-of-the-art trackers. We hope this method provides a new perspective for visual tracking.