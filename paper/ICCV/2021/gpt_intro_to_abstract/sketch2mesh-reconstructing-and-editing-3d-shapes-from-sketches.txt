This paper introduces a novel approach for reconstructing and editing 3D shapes from hand-drawn sketches. The authors highlight the potential of this technique in revolutionizing the way designers, engineers, and artists interact with CAD systems. While previous deep learning approaches have shown promise, they often yield coarse 3D surface representations that are difficult to edit and require multi-view sketches. Meanwhile, Single View Reconstruction (SVR) approaches have progressed rapidly for shape reconstruction but struggle with the sparse nature of sketch images and the variability in sketching styles. To overcome these challenges, the authors propose training an encoder/decoder architecture to produce a compact latent representation of 3D shapes. This latent vector is refined to match the input sketch using two different approaches: Sketch2Mesh/Render, which synthesizes foreground/background images from the sketches and uses differentiable rasterization, and Sketch2Mesh/Chamfer, which directly optimizes the position of the 3D shape's projected contours. Remarkably, Sketch2Mesh/Chamfer performs as well or better than Sketch2Mesh/Render and allows for local refinement using sparse contours. Additionally, it enables robust shape editing with sparse 2D pen strokes by leveraging a strong shape prior encoded in the latent vector.