Visual search or retrieval systems are widely used in various applications such as face recognition, person re-identification, car re-identification, and image retrieval. To improve these systems, models are often upgraded by training on larger datasets or using more powerful network structures. However, to benefit from these new models, a process known as "backfilling" or "re-indexing" is necessary to re-encode all images in the gallery set. This process can be impractical in scenarios where computational resources are limited or original images cannot be preserved without user authorization. Model compatibility techniques can greatly reduce the costs and time required for this process. There are two types of model compatibility methods: cross model compatibility (CMC) and compatible training (CT). CMC finds compatible mappings between previous and upgraded models, while CT upgrades models with compatibility constraints. The compatibility can be achieved through direct, backward, or forward methods. However, existing methods have limitations in terms of applicability and performance. In this paper, we propose a general framework called LCE for model compatibility. Our framework aligns feature classes across models and restricts mapped features to be distributed within the original boundaries. This approach not only ensures compatibility but also encourages the learning of more discriminative features. We evaluate our method on both CMC and CT problems and achieve remarkable results compared to current state-of-the-art methods.