This paper introduces the concept of stroke-based neural painting, which aims to generate artistic paintings by imitating the stroke-by-stroke process used by human painters. The traditional methods of image style transfer and image-to-image translation in computer-aided art creation have focused on pixel-wise operations or optimization-based approaches, but they lack the authenticity and human-like quality of stroke-based creation. The paper proposes a novel approach called Paint Transformer, which predicts a set of strokes to generate paintings that resemble real human-created works. To train the stroke set predictor, a self-training pipeline is utilized, using synthesized stroke images. The experiments conducted demonstrate that the feed-forward method of stroke-based neural painting achieves better quality paintings at a lower cost compared to existing methods. The contributions of the paper include a new perspective on stroke-based painting, the development of the Paint Transformer model, and experimental validation of the approach's visual quality and efficiency.