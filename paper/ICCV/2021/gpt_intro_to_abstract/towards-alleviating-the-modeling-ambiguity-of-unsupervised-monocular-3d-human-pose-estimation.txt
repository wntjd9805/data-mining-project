Human pose estimation is a fundamental module in computer vision and has various applications. The high cost and time-consuming nature of annotating 3D skeletons have led to the emergence of unsupervised 3D pose estimation. Recent approaches have used 2D annotations, unlabelled multi-view imagery, or learned 3D priors to bypass the need for 3D annotation. However, there are still challenges related to scale and pose ambiguity. Scale consistency alone does not lead to accurate 3D skeleton estimation, and lifting 2D pose to 3D is inherently ambiguous. Previous approaches have proposed constraints to address these challenges, but they are considered as auxiliary losses and can lead to sub-optimal results. To tackle these challenges, we propose a two-step approach, optimizing 2D pose via scale estimation and lifting the pose to 3D. We also incorporate temporal consistency constraints to address scale and pose ambiguity. The proposed framework achieves state-of-the-art performance on 3D human motion datasets and outperforms previous unsupervised and weakly supervised methods. Ablation studies are conducted to evaluate the contributions of each component of the proposed framework.