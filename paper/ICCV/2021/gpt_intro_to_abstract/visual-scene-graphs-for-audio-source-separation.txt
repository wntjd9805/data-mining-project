Real-world events often involve interactions between objects in both the visual and auditory domains when captured as videos. The knowledge of objects and the sounds they produce is crucial for designing artificial intelligence systems that can produce meaningful deductions. Previous algorithms in the intersection of visual and auditory domains have made significant progress in visually-guided source separation, but they often lack the richness to capture spatio-temporal audio-visual context. Additionally, the association of a visual embedding of a sound source to its corresponding audio can be a one-to-many mapping, making the problem ill-posed. It is also desirable for algorithms to be scalable to new sounds and their visual associations, as well as be able to handle naturally occurring sounds that can emanate from a multitude of interactions. In this paper, we propose the Audio Visual Scene Graph Segmenter (AVSGS) framework for the task of sound source separation. We represent the visual scene using spatio-temporal scene graphs and design a recursive source separation algorithm that produces embeddings of sub-graphs of the visual scene graph. These embeddings are then used as conditioning information for an audio separation network. We enforce that these embeddings be mutually orthogonal and train our model using a self-supervised approach. We validate our method on the Multimodal Sources of Instrument Combinations (MUSIC) dataset and a newly adapted version of the AudioCaps dataset, called Audio Separation in the Wild (ASIW). Our experiments demonstrate the importance of visual context in sound separation, and our AVSGS framework outperforms previous state-of-the-art methods on both datasets.The key contributions of our work include the use of scene graph representation for visually-guided audio source separation, the AVSGS framework trained to produce mutually-orthogonal embeddings of visual sub-graphs, the ASIW dataset for the source separation task, and the state-of-the-art performance of our AVSGS framework on both datasets.