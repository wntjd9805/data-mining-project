This paper introduces the ACDC dataset, a large-scale driving dataset specialized for adverse visual conditions in autonomous driving. While existing datasets primarily focus on normal visual conditions, ACDC addresses the need for datasets that include adverse domains, such as fog, night, rain, and snow, which are essential for developing perception algorithms that perform well in real-world driving environments. ACDC consists of 4006 images with pixel-level semantic annotations, distributed equally among the adverse conditions. The dataset also includes corresponding normal-condition images for weakly supervised methods. ACDC supports standard semantic segmentation as well as uncertainty-aware semantic segmentation, where regions with indiscernible semantic content are included in the annotation and evaluation. ACDC serves as a benchmark for supervised segmentation approaches as well as domain adaptation methods. The paper presents experiments with ACDC, showing the importance of ground truth annotations under adverse conditions and the challenges of domain adaptation. The uncertainty-aware annotations in ACDC provide opportunities for improving conÔ¨Ådence prediction and advancing semantic segmentation methods that consider uncertainty.