In recent years, self-supervised pre-training has shown superior performance compared to supervised pre-training for various computer vision tasks. One key factor contributing to this progress is the use of instance discrimination, where a network learns image-level features that are invariant to certain augmentations. However, existing instance discrimination techniques treat images as a whole and do not enforce spatial consistency in the convolutional feature maps. This lack of spatial alignment poses a challenge for downstream tasks such as object detection that rely on spatial information. To address this issue, we propose Region Similarity Representation Learning (ReSim), a self-supervised pre-training method that learns spatially consistent features across multiple convolutional layers. ReSim operates by sliding a fixed-size window over the overlapping region between two image views, aligning the corresponding regions in the convolutional feature maps, and maximizing their similarity. We demonstrate that maximizing the similarity of these feature regions improves object localization in object detection and instance segmentation tasks. Additionally, we incorporate feature pyramid layers and region-level self-supervised similarity learning to further enhance the performance on downstream tasks. Experimental results on PASCAL VOC, COCO, and Cityscapes datasets show that ReSim significantly improves classification and localization performance compared to a MoCo-v2 baseline.