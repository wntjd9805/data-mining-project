The interest in visual Simultaneous Localization and Mapping (SLAM) has grown due to its applications in various computer vision tasks such as augmented reality, autonomous driving, and robotics navigation. Different types of sensors, including lidar, monocular camera, and RGB-D camera, are utilized for SLAM algorithms. Among them, the RGB-D camera has gained popularity in visual SLAM due to its ability to provide rich 3D information at a relatively low cost. However, existing RGB-D SLAM methods are designed for environments with opaque objects and fail to properly function in the presence of transparent objects. Transparent objects, such as glass bottles and windows, are common in our surroundings, making it essential to develop RGB-D SLAM algorithms that can handle transparent objects. The presence of transparent objects poses challenges in depth estimation, as they violate the classic geometric light path assumptions of stereo vision algorithms. Additionally, transparent objects can cause distortion and occlusion in the depth map, affecting the accuracy of the SLAM system. This paper introduces a novel RGB-D SLAM approach called Transfusion, which addresses these challenges by accurately estimating camera pose and recovering the correct shape of the scene, including transparent objects. The proposed approach employs the Transparent Objects Cut Iterative Closest Points (TC-ICP) algorithm to detect and remove transparent objects, reducing depth errors. The Transparent Objects Reconstruction (TO-Reconstruction) algorithm is then used to reconstruct the scene's 3D model by leveraging RGB images, masks, and camera pose information. To evaluate the proposed algorithm, a new RGB-D database called Trans-SLAM with sequences containing transparent objects is constructed. The contributions of this paper include the Transfusion approach and the Trans-SLAM database, both dedicated to advancing SLAM algorithms in environments with transparent objects.