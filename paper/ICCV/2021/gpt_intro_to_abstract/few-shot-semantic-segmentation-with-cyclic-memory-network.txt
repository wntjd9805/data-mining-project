This paper introduces the problem of training high performance semantic segmentation models that require large amounts of human-annotated training data. However, data annotation by humans is costly and labor-intensive, and these models fail to segment novel objects with limited training images. To address this, the paper explores few-shot semantic segmentation (FSS), which leverages support images with ground-truth masks to segment unseen objects from a query image. A novel cyclic memory network (CMN) is proposed to tackle FSS by learning to read abundant support information from all resolution features. The CMN circularly takes cross-resolution features as memory guidance, allowing for the full exploitation of cross-resolution relationships and better handling of object appearance and scale changes. The paper also introduces query feature re-adding and recursive updating mechanisms to improve the performance of the CMN. Experimental results demonstrate that the proposed CMN achieves state-of-the-art performances on FSS benchmarks.