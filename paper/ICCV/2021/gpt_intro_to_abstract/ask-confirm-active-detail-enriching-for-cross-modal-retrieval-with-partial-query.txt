Recently, text-based image retrieval has gained attention in cross-modal retrieval. Existing methods for text-based retrieval have shown significant improvement, but their retrieval results are often unsatisfactory when users only describe some local regions in an image. This work introduces the concept of a partial-query problem in text-based image retrieval, where the initial text query only describes some objects in the target image. Studies have shown that people tend to focus on the objects that stand out the most, which can lead to retrieval problems when these objects are not discriminative enough. To address this issue, a new interactive retrieval framework called Ask&Confirm is proposed. This framework actively selects discriminative object candidates for users to confirm their presence, narrowing down the range of candidates and eventually locating the target image. The framework uses reinforcement learning to optimize the interactive policy, making it more efficient and user-friendly compared to previous interactive retrieval models. Experimental results demonstrate the effectiveness and robustness of the proposed framework with partial queries. Overall, this work contributes to addressing the problem of partial queries in cross-modal retrieval and introduces an active object-based interaction approach for improved retrieval results.