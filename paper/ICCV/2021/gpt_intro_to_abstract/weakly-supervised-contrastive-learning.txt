In this paper, we address the class collision problem in contrastive learning by proposing a weakly supervised contrastive learning (WCL) framework. We recognize that instances with similar characteristics should be treated as positive pairs rather than being pushed apart as is done in traditional instance discrimination methods. To determine the weak labels, we model each batch of instances as a nearest neighbor graph and assign weak labels to instances within connected components. We also employ a K-Nearest Neighbor based multi-crops strategy to expand the graph and propagate weak labels. We adopt a two-head framework to handle both the weakly supervised task and the regular instance discrimination task. Experimental results demonstrate the effectiveness of the proposed method in different settings and datasets. Our contributions include the introduction of a two-head framework, a parameter-free method to find similar samples adaptively, and a multi-crops strategy that provides diverse information. The experimental results show that WCL achieves state-of-the-art performance in contrastive learning based methods, surpassing even SimCLRv2 with ResNet101 on ImageNet with only 1% and 10% labeled samples.