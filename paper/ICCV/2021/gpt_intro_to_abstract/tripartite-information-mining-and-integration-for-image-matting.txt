The digital matting task in computer vision involves accurately estimating the opacity of foreground objects in images and video sequences. This has applications in film production and digital image editing. The input image is modeled as a combination of foreground and background colors, with the opacity of each pixel represented by alpha. This problem is highly ill-posed, requiring the solution of seven unknown values with only three known quantities. Existing methods utilize trimap as a constraint information to reduce the solution space, but there is still a gap between real-world and synthetic images. Trimap-based methods perform transition optimization explicitly, while trimap-free methods construct pseudo-trimaps implicitly. However, these approaches often neglect the coordination between global and local attributes. To address these challenges, we propose a Tripartite Information Mining and Integration Network (TIMI-Net) that captures global information by mining and integrating multi-modal information from RGB and Trimap. We introduce functionally specific RGB and Trimap units for separate information mining and a Tripartite Information Integration (T I 2) module inspired by Non-Local to effectively combine the different types of global and local information. Additionally, we present a large-scale human matting dataset and demonstrate through experiments that TIMI-Net achieves state-of-the-art performance on both synthetic and real-world images.