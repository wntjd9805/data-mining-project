Perceiving 3D shapes and poses of surrounding obstacles is crucial for autonomous driving perception systems. Existing 3D object detectors primarily rely on depth sensors, such as LiDAR or stereo cameras. However, these sensors have limitations in terms of cost and online calibration issues. Monocular camera-based 3D object detection emerges as a promising alternative but faces challenges in obtaining accurate depth information. Recent deep learning-based approaches have achieved good results in depth estimation from a single image. By reconstructing a pseudo LiDAR point cloud using the estimated depth map, 3D detectors designed for LiDAR point cloud can be applied. However, these two-stage approaches suffer from heavy computation burden. To improve efficiency, direct regression-based approaches have been proposed, achieving promising results. However, these approaches fail to capture the detailed shape of the object, leading to location ambiguity. In this paper, we propose a novel approach that learns meaningful keypoints on the object surface and uses them as additional geometric constraints for 3D object detection. We design an automatic deformable model-fitting pipeline to generate 2D/3D correspondences and train a deep neural network to learn the keypoints. The proposed framework achieves real-time performance and demonstrates state-of-the-art results on the KITTI dataset.