Convolutional neural networks (CNNs) have been highly successful in computer vision tasks, but this paper aims to explore alternative backbone networks beyond CNNs. Specifically, it introduces the Pyramid Vision Transformer (PVT) as a pure Transformer backbone for dense prediction tasks such as object detection, semantic and instance segmentation, and image classification. The PVT overcomes limitations of previous approaches by using fine-grained image patches, introducing a progressive shrinking pyramid, and adopting a spatial-reduction attention layer to reduce computational and memory costs. Comparisons with traditional CNN backbones and the Vision Transformer (ViT) show that PVT outperforms in terms of performance and flexibility. The paper's main contributions are the proposal of PVT as the first pure Transformer backbone for dense prediction tasks, the development of an end-to-end object detection system without convolutions, and the exploration of multi-scale and high-resolution features. Experimental results demonstrate the superiority of PVT over previous methods in various tasks.