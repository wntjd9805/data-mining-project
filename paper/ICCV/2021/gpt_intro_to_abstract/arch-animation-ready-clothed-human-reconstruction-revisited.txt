Digital humans have become increasingly important in AR/VR applications, requiring higher levels of realism for truly immersive experiences. However, current methods for building photorealistic avatars involve manual work or expensive capture systems. This paper introduces ARCH++, a method for reconstructing animatable avatars from a single image using pixel-aligned implicit functions. The authors propose an end-to-end geometry encoder based on PointNet++ to address depth ambiguity and lack of semantic information. They also address limitations in the formulation and representation of previous work, including topology changes during unposing and degraded geometry and texture in occluded regions. ARCH++ outperforms prior methods on synthetic and in-the-wild images, making several contributions including a geometry encoder, a co-supervising framework for occupancy fields, and a surface refinement strategy. The paper highlights the importance of digital humans in various applications and presents an innovative approach for reconstructing realistic avatars.