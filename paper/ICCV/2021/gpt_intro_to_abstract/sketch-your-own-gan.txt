Deep generative models, such as Generative Adversarial Networks (GANs), have the ability to synthesize realistic, diverse, and novel content with minimal user effort. However, training high-quality generative models requires expensive computing platforms and large-scale data collection and pre-processing. This raises the question of how ordinary users can create their own customized generative models. In this paper, we propose the task of creating a generative model using just a handful of hand-drawn sketches. We aim to understand if it is possible to create a generative model of realistic images from these sketches. We develop a method that adjusts a subset of pre-trained generative model weights to match the user sketches, preserving color, texture, and background context. We demonstrate that our method can successfully modify the object pose and zoom in cat faces with just four hand-drawn sketches. We create several customized GAN models using our method for applications such as generating new samples, interpolating between images, and editing natural photographs. Our method requires minimal user input and does not require manual filtering or image alignment. We benchmark our method to evaluate its performance and provide code and models on our webpage.