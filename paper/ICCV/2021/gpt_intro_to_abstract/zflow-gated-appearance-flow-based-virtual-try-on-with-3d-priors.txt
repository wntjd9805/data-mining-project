In recent years, there has been a growing interest in providing smart and intuitive online shopping experiences to compensate for the lack of in-store interaction. Virtual try-on, which involves visualizing clothes in a personalized setting, is crucial for various real-world applications. While previous methods have employed a two-step process of warping the garment image and fusing textures, there are limitations in accurately handling non-rigid garments and understanding the 3D geometry of the garment and model. This paper introduces an end-to-end try-on framework called ZFlow, which utilizes gated appearance flow estimates and dense geometric priors to improve the quality of virtual try-on. The proposed framework is evaluated through quantitative and qualitative comparisons and a user study, demonstrating its superiority over existing methods. Ablation studies are also conducted to analyze the impact of different design choices, and the efficacy of the gated appearance flow is further validated in improving human pose transfer.