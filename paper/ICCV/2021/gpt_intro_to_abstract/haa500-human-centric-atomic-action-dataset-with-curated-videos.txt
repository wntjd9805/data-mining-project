The introduction discusses the limitations of existing action recognition datasets, including the issue of coarse annotation and the presence of irrelevant actions. It introduces several datasets that have attempted to address these limitations but states that some actions are still coarse and can be further split into atomic classes. The challenge of encompassing different visual postures into a single class is also highlighted, explaining the low performance of existing architecture in some datasets. Another problem mentioned is the limited or broad field-of-view in videos, where only a part of a human interacting with an object is shown or multiple human figures with different actions are present. The introduction then introduces the Human-centric Atomic Action dataset (HAA500) as a contribution to the field. HAA500 is constructed with curated videos that have been annotated with fine-grained labels to avoid ambiguity and with dense per-frame action labeling. It contains a wide variety of atomic actions and is scalable. The introduction concludes by stating that the precise annotation of fine-grained classes leads to preferable properties in action recognition datasets.