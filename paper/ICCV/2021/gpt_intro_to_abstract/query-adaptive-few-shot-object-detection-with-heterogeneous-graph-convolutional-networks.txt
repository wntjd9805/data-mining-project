Few-shot object detection (FSOD) aims to detect novel object instances in an image given only a few examples of the novel object and abundant examples of other objects. While deep neural networks perform well on data-abundant base classes, adapting the model to few-shot novel classes is challenging. Current approaches either use long-tailed learning methods or meta-learning to address this problem. Meta-learning approaches learn how to match between regions in the query image and few-shot class examples. However, these approaches have limitations such as not modeling multi-class relations, potential discrepancy between prototypes and proposal features, and not considering contextual information. To address these challenges, we propose a graph convolutional network (GCN)-based FSOD model called QA-FewDet. Our model utilizes graph propagation to learn context-aware proposal features and query-adaptive, multiclass-enhanced class prototypes. We construct a graph with three types of edges: class-class, class-proposal, and proposal-proposal, to enable efficient communication. We also propose a novel heterogeneous graph structure for efficient message passing. Our model achieves significantly better results than current state-of-the-art methods on FSOD benchmarks. Our contributions include proposing a graph model that considers various relationships in few-shot object detection and a novel heterogeneous graph structure for efficient message passing.