This paper introduces Multiscale Vision Transformers (MViT), a transformer-based architecture for modeling visual data such as images and videos. The authors connect the idea of multiscale feature hierarchies with the transformer model, proposing that the principles of resolution and channel scaling can be beneficial for transformer models in visual recognition tasks. MViT incorporates several channel-resolution scale stages, hierarchically expanding the channel capacity while reducing the spatial resolution to create a multiscale pyramid of feature activations. The architecture allows early layers to model simple low-level visual information at high spatial resolution, while deeper layers focus on spatially coarse but complex high-level features to model visual semantics. MViT demonstrates strong temporal bias and outperforms concurrent video transformers without external pre-training data. The authors also apply MViT to ImageNet classification and observe significant gains over single-scale vision transformers. The code and models for MViT are publicly available.