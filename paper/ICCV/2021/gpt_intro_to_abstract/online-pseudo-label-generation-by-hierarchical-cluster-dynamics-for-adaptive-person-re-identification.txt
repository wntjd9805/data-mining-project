This paper focuses on the challenge of person re-identification (ReID), which involves retrieving images of the same person across different cameras. Despite advancements in deep learning models for ReID, the task remains challenging due to the varying distributions of images captured by different camera systems, known as domain shift. To address this challenge, the paper proposes Unsupervised Adaptive Person Re-identification (Adaptive ReID), which aims to transfer knowledge from a labeled source domain to accurately measure the inter-instance affinities in an unlabeled target domain. Clustering-based methods have dominated the state-of-the-art performances in adaptive and unsupervised ReID tasks. However, these methods generate pseudo labels offline, which fail to capture the varying feature distributions during network optimization. Additionally, existing methods treat all data points equally, ignoring the fine-grained distributions of real-world data. To tackle these challenges, the paper proposes an online pseudo label generation strategy that dynamically and progressively updates pseudo labels under a bottom-up framework. This approach captures fine-grained feature distributions and instant semantic variation of the feature space. The proposed method conducts feature learning and pseudo label generation simultaneously in each training iteration. It introduces a feature bank and hierarchical label bank for storing and updating features and pseudo labels, respectively. The online pseudo label generation is achieved by momentum updating relevant sample features and refining corresponding labels through merging or splitting clusters. This is done through a process called "cluster dynamics," which propagates pseudo labels among clusters based on affinity. The hierarchical label refinement structure captures complex feature distributions of real images. The paper's contributions include the introduction of online pseudo label generation for adaptive ReID, a novel cluster dynamics method for pseudo label progression and refinement, and extensive experiments that demonstrate the effectiveness of capturing varying and fine-grained feature distributions.