This paper introduces a method for rendering neural radiance fields (NeRFs) in real-time, addressing the current limitation of slow runtime performance. The proposed approach utilizes a hierarchical 3D volumetric representation called PlenOctree, which distills the NeRF into a tabulated view-dependent volume. By pre-sampling the NeRF and storing appearance and density values in the leaves of the PlenOctree, real-time rendering is achieved without the need for a deep neural network during test time. The representation is compatible with modern web technologies, allowing for interactive rendering in web browsers. The method also includes a modification to the NeRF network to predict appearances in terms of spherical harmonics, enabling efficient representation within the PlenOctree. Additionally, the paper demonstrates how the proposed pipeline can be used to accelerate NeRF model training by converting it into a PlenOctree. Experimental results show significant acceleration without sacrificing image quality, achieving state-of-the-art performance in terms of image quality and rendering speed. The interactive viewer allows for various operations such as object insertion, visualizing radiance distributions, decomposing the spherical harmonics components, and slicing the scene, providing useful tools for visualizing and debugging NeRF-based representations. The contributions of this work include the first method for real-time rendering of NeRFs with similar or improved quality, NeRF-SH (a modified NeRF trained to output appearances in terms of spherical basis functions), the PlenOctree data structure for efficient view-dependent rendering, and an accelerated NeRF training method using early termination and fine-tuning on PlenOctree values.