This paper introduces a lightweight, unsupervised, and end-to-end learning-based framework for recovering hyperspectral (HS) images from single RGB images captured by commercial cameras. Traditional methods for acquiring HS images are expensive, so computational methods that utilize deep neural networks (DNNs) have been developed. However, these DNNs typically require paired RGB and HS images for training, which are difficult to collect. To address this issue, the proposed framework estimates the camera spectral response functions (SRFs) of input RGB images using a prior-driven method and then generates an HS image by progressively spreading the information of the difference between input RGB images and re-projected RGB images obtained through the estimated SRFs. The framework incorporates adversarial learning to ensure the generated HS images resemble real HS images and embeds semantic information to encourage similarity or dissimilarity between pixels in reconstructed HS images with identical or different semantics, respectively. The contributions of this paper include an unsupervised HS image reconstruction framework, imaging degradation model-aware HS image generation, unsupervised estimation of camera SRFs, efficient embedding of semantic information, a strategy for stabilizing and boosting adversarial learning, and a visual tracking-based quality evaluation of HS images recovered from real RGB images.