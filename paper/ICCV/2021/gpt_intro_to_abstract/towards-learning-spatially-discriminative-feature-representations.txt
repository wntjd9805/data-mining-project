In recent years, convolutional neural networks (CNNs) have achieved remarkable success in visual classification tasks. However, deep networks are susceptible to overfitting. Various regularization techniques have been proposed to address this issue, but they often come with increased computational cost. Another approach is to design different loss functions to enhance the feature representations of CNNs. This paper introduces a novel loss function called CAM-loss, which leverages class activation maps (CAMs) to capture spatial information. CAMs indicate the discriminative regions for identifying specific categories, while a class-agnostic activation map (CAAM) shows the spatial distribution of embedded features. By constraining CAAMs closer to CAMs, CAM-loss promotes intra-class compactness and inter-class separability. Experimental results demonstrate that CAM-loss effectively improves the performance of various classification models. Additionally, CAM-loss can be combined with existing regularization methods and exhibits strong generalization ability in transfer learning and few-shot learning tasks. The paper also proposes a knowledge distillation method called CAAM-CAM matching, which significantly enhances student networks by directly supervising the CAAMs generated by the student network with the CAMs generated by the teacher network. Overall, this work contributes a novel loss function that enhances spatial information and improves classification performance, as well as a knowledge distillation method that matches different types of knowledge between teacher and student networks.