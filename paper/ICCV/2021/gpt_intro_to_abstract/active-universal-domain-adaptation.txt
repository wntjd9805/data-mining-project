Recent advances in deep neural networks have shown great potential in learning effective models on large datasets. However, when applying these models to new domains, there is often a large domain gap that can degrade their performance. Unsupervised Domain Adaptation (UDA) methods aim to address this issue by learning a classification model with labeled source data and unlabeled target data. Existing UDA methods can be categorized into closed set domain adaptation, partial domain adaptation, open set domain adaptation, and universal domain adaptation. However, universal domain adaptation methods still have limitations, particularly in inferring actual labels for samples belonging to unknown categories. To overcome this, we propose a new paradigm called Active Universal Domain Adaptation (AUDA), which combines domain adaptation with active learning. AUDA algorithms leverage a labeled source domain and a target domain without restrictions on classes for model training. The algorithms first recognize the "known" or "unknown" label for test samples in the target domain and then infer actual class labels for both "known" and "unknown" samples. Since labeling unknown samples is challenging without any labeled training data, our proposed approach utilizes active learning to annotate a subset of target data, including labels for target "unknown" samples. We address two technical challenges in AUDA: the domain gap and semantic shift between the source and target domains, and the selection of informative target instances for annotation during active learning. We propose an Active Universal Adaptation Network that simultaneously adapts the model and performs active learning. Our experiments demonstrate that the proposed AUDA model achieves significant classification results.