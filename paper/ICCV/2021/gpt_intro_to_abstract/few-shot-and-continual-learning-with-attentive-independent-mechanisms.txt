This paper addresses the issue of catastrophic forgetting in deep learning methods, which struggle to retain previously learned concepts after being presented with new concepts. The authors propose that the stability-plasticity dilemma, which refers to the trade-off between retaining old information and acquiring new concepts, is the cause of this problem. They argue that scaling up existing architectures can improve generalization and focus on two research directions: few-shot learning and continual learning. The authors introduce Attentive Independent Mechanisms (AIM) as a novel module that promotes fast learning without forgetting. AIM selectively activates mechanisms that best explain an input representation, leading to sparse modeling on an architectural level. The potential of AIM is demonstrated through experiments on few-shot classification and continual learning benchmarks, showing significant improvement in accuracy compared to prior methods. The contributions of the paper include a detailed formulation of AIM and its application in both few-shot and continual learning tasks, with qualitative and quantitative results provided for each.