Few-shot image classification is a task that aims to classify query images into target classes using only a small number of support images. Meta-learning deep embedding functions have been used to tackle this problem, but they often overfit to irrelevant features and fail to transfer to new classes. In this paper, we propose a new approach that leverages relational patterns within and between images to learn more generalizable embeddings for few-shot learning. We introduce two modules, self-correlational representation (SCR) and cross-correlational attention (CCA), to capture structural patterns and semantic correspondence relations. The SCR module transforms a base representation into its self-correlation tensor to extract relevant structural patterns from the image. The CCA module computes cross-correlation between image representations to produce co-attention based on semantic relations. We combine these modules to learn relational embeddings in an end-to-end manner. Experimental results on benchmark datasets demonstrate the effectiveness of our approach in highlighting target object regions and improving few-shot image classification accuracy.