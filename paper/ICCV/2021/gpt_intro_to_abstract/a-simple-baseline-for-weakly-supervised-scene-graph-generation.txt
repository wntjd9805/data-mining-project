Scene graph generation (SGG) is an important task in computer vision, involving the generation of a scene graph that represents the objects and relationships in an image. Current SGG models are typically supervised trained with scene graph annotations, which have limitations in terms of expensive annotations and lack of generalization to out-of-domain objects or relations. To overcome these limitations, we propose a weakly-supervised SGG (WS-SGG) approach that only requires ungrounded scene graph labels without object locations. We utilize language parsers to obtain ungrounded scene graph labels from image captions, providing a large amount of training data and addressing the generalization problem. Our approach tackles the graph matching challenge by considering node and relationship similarity and proposes a simple baseline that decouples the problem into a weakly-supervised graph matching module and a supervised SGG model. We employ the first-order graph matching algorithm and contrastive learning objective to train the graph matching module and use the matched scene graph as pseudo ground truth for training the SGG model. Our simple baseline outperforms the current state-of-the-art method in terms of graph matching and SGG. We also explore the advantages of graph matching over grounding models, the selection of negative samples and loss for contrastive learning, and the potential benefits of higher-order graph matching. Overall, our contribution is a versatile baseline that significantly improves SGG performance and can be adapted to various SGG models. The rest of the paper reviews related works, presents the problem formulation and model pipeline, discusses experimental settings and results, and concludes the paper.