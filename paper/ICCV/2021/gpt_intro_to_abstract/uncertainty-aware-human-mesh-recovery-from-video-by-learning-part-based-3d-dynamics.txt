Reconstructing 3D human meshes from 2D images or videos is a challenging task due to limited data and the ambiguity of projections. Existing methods have limitations in producing smooth and consistent 3D motion. This paper proposes a novel approach that simultaneously learns 3D pose and motion dynamics by utilizing uncertainty and probabilistic encoding. The method divides the body into local regions to accurately estimate 3D motion dynamics. Experimental results demonstrate the superior performance of the proposed method compared to state-of-the-art approaches. The contributions of this paper include the introduction of two different features for 3D pose and motion estimation, the use of a view-invariant probabilistic encoder to address uncertainty, and a decoder that considers local body regions to model spatial relationships.