Deep learning has achieved remarkable success in various vision tasks, but the availability of labeled data for training is often limited and expensive. Few-shot learning has been proposed to address this issue by mimicking human vision systems and learning the visual appearance of new objects with only a few instances. Meta-learning has been employed to facilitate fast model adaptation for few-shot learning, either through designing optimal algorithms or by learning a shared feature space. Prototype classification methods estimate few-shot prototypes by averaging the features of a few labeled samples, and a new sample is classified by comparing its cosine similarity with the prototypes. In this paper, we propose a Partner-Assisted Learning (PAL) framework for representation learning in few-shot classification. PAL involves training a Partner Encoder and a Main Encoder sequentially, where the features from the Partner Encoder serve as soft-anchors to regularize the training of the Main Encoder. We propose alignment approaches at both the feature-level and logit-level to utilize the soft-anchors for regularization during training with class labels. Our experiments show that PAL consistently achieves state-of-the-art performance on four few-shot benchmarks and improves classification accuracy in a supervised learning setting. We also provide comprehensive ablation studies to validate the effectiveness of each component of PAL.