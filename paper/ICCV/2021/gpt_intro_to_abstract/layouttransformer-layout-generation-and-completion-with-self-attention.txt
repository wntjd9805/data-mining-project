This paper introduces a framework called LayoutTransformer that aims to generate realistic scene layouts in various domains, such as documents, mobile apps, natural scenes, and 3D shapes. The authors argue that understanding and generating the layout of a scene is crucial for generating plausible scenes without the need for proxy representations. The proposed model utilizes a masked Transformer decoder to predict the placement and attributes of new primitives based on the representations of existing primitives in the layout. The authors present several contributions, including the LayoutTransformer model itself, the separate modeling of layout attributes, the discovery of semantic relationships between objects through layout generation, and the adaptability of the model across diverse domains. The performance of the model is demonstrated on four layout datasets, showing competitive results compared to state-of-the-art approaches. Overall, LayoutTransformer provides a powerful auto-regressive model for synthesizing layouts, completing partial layouts, and computing likelihood of existing layouts.