Semantic segmentation plays a crucial role in computer vision by assigning category labels to each pixel in an image. It has been widely used in various applications such as autonomous driving, scene understanding, and image editing. Recent advancements in large-scale datasets and fully convolutional networks (FCNs) have led to significant progress in semantic segmentation. However, current methods primarily focus on mining contextual information within the image, neglecting the potential relation information from other images. This limitation calls for feature learning from a holistic view of the whole dataset.Unsupervised contrastive learning has gained attention for pre-training strong feature extractors. While most works focus on classification problems, semantic segmentation requires more semantic information. To address this, we propose a new contrastive learning paradigm, specifically targeting semantic segmentation. Our approach involves performing contrastive learning in a fully supervised manner using pixel-level contrastive learning instead of image-level contrastive learning. We establish memory banks containing different class pixel embeddings and retrieve positive and negative samples from these memory banks for each pixel. However, the straightforward approach results in memory burden and slow training speed due to the large number of pixels in the dataset.To overcome these challenges, we introduce region-aware contrastive learning (RegionContrast). Instead of storing all pixel embeddings, we construct region centers for different categories within each image. These region centers represent the features of all pixels belonging to a particular class. We generate one region center for each class of an image, even if the image contains multiple regions belonging to the same category. To facilitate feature learning for hard-to-classify pixels, we propose a dynamic sampling method. Region-aware contrastive learning is then performed using positive and negative samples retrieved from memory banks. Our proposed RegionContrast can easily be applied to any segmentation models, requiring minimal computation resources during training and no extra overhead for testing.Our contributions include proposing a contrastive learning setting in a fully supervised manner for semantic segmentation and developing RegionContrast to explore semantic relations from a holistic viewpoint of the whole dataset in a memory-efficient way. We conducted extensive experiments and achieved state-of-the-art performance on three semantic segmentation benchmarks.