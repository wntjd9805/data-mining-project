This paper introduces a dialog-based facial editing framework called Talk-to-Edit, which aims to provide users with more flexible and intuitive ways to manipulate facial images. Unlike previous methods that have limited user interactions or fixed control patterns, Talk-to-Edit allows users to make requests and receive feedback from the system in a round-by-round manner. The system utilizes natural language as a means of communication, making it more expressive and easy to use for users. To achieve continuous and fine-grained attribute manipulations, the authors propose the use of a "semantic field," which is a vector field that describes location-specific directions and magnitudes for attribute changes in the latent space of a deep generative model. The curves in the semantic field take into account the non-linear nature of attribute transitions, preserving the identity of the edited facial image and avoiding artifacts. The proposed editing strategy is embedded into the dialog system, where user requests guide the semantic field editing and the system provides feedback and suggestions for further refinements. To facilitate the learning of the semantic field and dialog-based editing, the authors contribute a large-scale visual-language dataset called CelebA-Dialog, which provides fine-grained attribute labels and textual descriptions. Overall, the proposed Talk-to-Edit framework offers a more interactive and user-friendly approach to facial editing, achieving superior editing results with better identity preservation and smoother attribute changes compared to existing methods.