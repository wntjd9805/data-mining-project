The image segmentation problem is crucial for understanding the appearance and geometry of objects in computer vision. Traditional image segmentation algorithms are based on the variational framework, where an objective function is optimized to partition the image domain into distinct regions. While unsupervised algorithms have been successful, they have limitations such as the complexity of characterizing regions of interest. Supervised algorithms using neural networks have shown improvement but require extensive manual annotations. To address these challenges, unsupervised segmentation algorithms using partial or crude labels have been developed, including generative adversarial networks (GANs). However, learning the distribution of object appearance and geometry remains difficult. This paper proposes an unsupervised segmentation algorithm that learns an embedding function for a bipartitioning model based on the statistical homogeneity of appearance, incorporating a shape prior constraint in a GAN framework. The algorithm focuses on learning the geometric property of objects, simplifying the distribution to be learned and improving effectiveness. The proposed algorithm also learns an intrinsic image representation that is robust against bias in an unsupervised manner, reducing sensitivity to object appearance inhomogeneity. The unified framework combines the intrinsic image representation model and the segmentation model with a shape constraint learned by GAN.