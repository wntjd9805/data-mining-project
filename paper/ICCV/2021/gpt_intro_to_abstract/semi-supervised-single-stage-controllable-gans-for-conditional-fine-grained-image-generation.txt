Deep generative learning has gained significant attention in recent years due to its ability to learn complex data distributions. Most existing generative models, such as GANs and VAEs, achieve success in image synthesis through unsupervised or supervised training patterns. However, these models either lack control over class semantics or require a large number of labeled samples. To address this issue, researchers have focused on semi-supervised generative learning, assuming that there is an adequate amount of unlabeled data. However, this assumption does not hold for fine-grained data, where data acquisition and annotation can be expensive and require extensive expertise. In this paper, we propose a Single-Stage Controllable GAN (SSC-GAN) for semi-supervised class-conditional generative modeling of fine-grained object categories. SSC-GAN synthesizes high-fidelity images conditioned on a class-independent variable, a cross-class variable, and a class variable. We improve upon existing semi-supervised GAN models by incorporating additional discriminators to match the marginal distribution between real and synthesized data, mapping images to a latent space via an encoder, and regularizing the feature space of the class label-embedded discriminator. Our contributions include proposing SSC-GAN as a single-stage, controllable generative model for conditional fine-grained image generation without requiring object-level annotations, disentangling the class-independent, cross-class, and class variables, and achieving effective optimization without heavy tuning.