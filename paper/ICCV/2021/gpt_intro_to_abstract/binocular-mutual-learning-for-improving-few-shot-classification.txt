In this computer science paper, the authors address the challenge of few-shot classification (FSC) where limited labeled data is available. They propose a new paradigm called Binocular Mutual Learning (BML) that combines a global view and a local view of the data. The global view involves learning classifiers in the whole base class space, while the local view focuses on matching unlabeled query data to its correct class using a small labeled support set. The authors argue that the combination of these two complementary views improves classification accuracy. They introduce an elastic loss to adjust the optimization difficulty of the local view and promote knowledge transfer between the views. The authors compare their BML paradigm with other existing methods and highlight its advantages in terms of transferability and time-efficiency. Experimental results on multiple benchmarks validate the effectiveness of BML in different scenarios.