Images often experience degradation during the data acquisition process, particularly under non-ideal imaging conditions. Factors such as precipitation, raindrops on the camera lens, relative motion between the camera and scene elements, and harsh illumination conditions can lead to spatially-varying degradations in the image. Restoring these degraded images is important for improving their aesthetic quality and performance in downstream tasks. Current convolutional neural network (CNN) based approaches for image restoration have limitations in their ability to handle image-dependent and spatially-varying degradations, as well as in their utilization of distortion-localization information from labeled datasets. In this paper, we propose a distortion-aware model called SPAIR, which consists of a distortion-localization network (NetL) and a spatially-guided restoration network (NetR). NetL estimates a binary mask to localize high-intensity distortions in the image, which guides the processing in NetR to selectively improve only the degraded regions. NetR includes three distortion-guided blocks - a spatial feature modulator (SFM), a sparse convolution module (SC), and a custom sparse non-local module (SNL) - to enhance features in the spatially-sparse degraded regions in an image-dependent manner, while preserving the features in clean regions. Our contributions include a two-stage framework for addressing diverse spatially-varying degradations, distortion-guided modulation of feature statistics in NetR, and distortion-guided feature extraction using SC and SNL. We demonstrate the versatility of SPAIR by achieving state-of-the-art performance on various spatially-varying restoration tasks across synthetic and real-world datasets.