This paper introduces the concept of memory-augmented dynamic neural relational inference (MemDNRI) for predicting interaction relations and forecasting trajectories in computer vision tasks. The authors highlight the importance of modeling and reasoning interactive relations in understanding dynamic systems and subsequent tasks such as behavior prediction. They argue that while previous approaches implicitly model relations using graph neural networks or attention models, they lack interoperability and powerful priors. Therefore, they propose MemDNRI as an explicit representation and inference model for interaction among entities. MemDNRI utilizes memory pools, called RelMem and EntMem, to maintain long-term temporally global information of relations and entities. They customize memory modules for scalability and practicality, enabling the model to dynamically infer relations and forecast trajectories. The authors demonstrate the effectiveness of MemDNRI through experiments on synthetic and real datasets.