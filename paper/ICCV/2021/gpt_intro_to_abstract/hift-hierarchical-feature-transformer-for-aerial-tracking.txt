Visual object tracking has become a significant area of research, particularly for unmanned aerial vehicles (UAVs) applications such as aerial cinematography, visual localization, and collision warning. Despite progress in the field, efficient and effective aerial tracking is still challenging due to limited computational resources and various difficulties like fast motion, low resolution, and frequent occlusion. Deep learning-based trackers have shown promise in visual tracking, but lightweight convolutional neural networks (CNNs) struggle to extract robust features necessary for tracking performance in complex aerial scenarios. The use of larger kernel sizes or deeper backbones can improve performance but sacrifices efficiency and practicality. The dilated convolution has been proposed to expand the receptive field but still lacks stability when handling small objects. In this paper, we propose a hierarchical feature transformer (HiFT) tracker inspired by the transformer's global relationship modeling capabilities. We exploit the transformer's architecture to effectively fuse multi-level features and achieve promising performance in aerial tracking. We address the efficiency and small object handling limitations by using low-resolution features from deeper layers instead of object queries, feeding shallow layers into the transformer to discover a tracking-tailored feature space, and designing a novel feature modulation layer. Our HiFT tracker achieves robust performance in complex scenarios, outperforming other state-of-the-art trackers and demonstrating superior efficiency and effectiveness in real-world scenarios.