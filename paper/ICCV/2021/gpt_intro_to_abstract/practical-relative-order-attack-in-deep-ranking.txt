Deep ranking algorithms have made significant progress in learning-to-rank tasks, thanks to the widespread use of deep neural networks. However, these algorithms have inherited the adversarial vulnerabilities of neural networks. Adversarial examples can intentionally alter the ranking results by perturbing the query image. Previous attacks on ranking models have focused on changing the absolute ranks of candidates, neglecting the manipulation of relative order. In some applications, such as e-commerce platforms powered by content-based image retrieval, an altered relative order can be disruptive. This vulnerability can be exploited in business competitions among top-ranked products. We propose the Order Attack (OA) as a new adversarial attack problem in deep ranking. The goal of OA is to find an imperceptible perturbation to the query image that converts the relative order of selected candidates according to a predefined permutation vector. We initially assume a white-box threat model, where the attacker has access to the ranking model details and gradients. We formulate OA as an optimization problem based on a triplet-style loss function and a semantics-preserving penalty term. In a real-world black-box attack scenario, we propose a Short-range Ranking Correlation (SRC) metric as a surrogate objective for optimizing OA. We validate the white-box and black-box OA through experiments on Fashion-MNIST and Stanford-Online-Product datasets. We also demonstrate successful attacks on a major e-commerce platform, JD SnapShop. Our contributions include the formulation of OA, a triplet-style loss for white-box OA, the SRC metric for practical black-box OA, and extensive evaluations of OA. This is the first work that tampers with the relative order in deep ranking, revealing a new type of ranking model vulnerability.