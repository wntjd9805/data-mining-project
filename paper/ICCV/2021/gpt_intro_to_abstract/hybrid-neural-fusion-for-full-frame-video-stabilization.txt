Video stabilization has become increasingly important due to the growth of video content on internet platforms. Casual cellphone videos are often shaky and unpleasant to watch, presenting challenges for stabilization algorithms. Existing methods consist of motion estimation, motion smoothing, and stable frame generation. However, these methods often result in missing pixels and require aggressive cropping, leading to resolution loss. Full-frame video stabilization aims to address these limitations and maintain the original field of view. Two-stage methods using flow-based video completion may suffer from inaccuracies, while learning-based methods can produce distortion and blur artifacts. This paper presents a new algorithm that takes a shaky video and smooth motion fields as inputs to produce a full-frame stable video. The algorithm uses a learned CNN representation and fusion mechanisms to improve the visual quality of the synthesized results. To balance smoothing camera motion and maximizing frame coverage, a path adjustment method is proposed. The algorithm is evaluated against state-of-the-art methods on benchmark datasets and demonstrates favorable performance. The main contributions of this paper are the application of neural fusion for full-frame video stabilization, the presentation of a hybrid fusion method, and the validation of various design choices through ablation studies.