In this paper, we address the challenges of inflexible and annotation-dependent communication in real-world vision-dialog navigation tasks. We propose a Self-Motivated Communication Agent (SCoA) that learns to determine whether and what to communicate with a human oracle to acquire instructive feedback for navigation. Our approach includes a whether-to-ask (WeTA) module that predicts when to communicate and a what-to-ask (WaTA) module that generates informative questions. We model uncertainty using action probability distribution entropy and generate question candidates on-the-fly based on a small set of direction-related sentences. We introduce question and answer score vectors to guide the learning process. Our agent combines imitation learning and reinforcement learning and is equipped with a communication frequency penalty and a navigation progress reward. Our experiments show that SCoA outperforms baselines by generating informative questions without relying on extensive dialog annotations. The performance of SCoA is comparable to models using rich dialog annotations, demonstrating its effectiveness in real-world navigation tasks.