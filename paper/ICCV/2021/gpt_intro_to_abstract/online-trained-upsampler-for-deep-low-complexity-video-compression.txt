This paper discusses the use of deep learning in image and video compression, which has led to improved algorithms that outperform conventional codecs. The authors propose a method that utilizes an online-trained upsampler to exploit an extended scope of frames, allowing for low computational expenses compared to deep learning compression models. The authors use a conventional codec for compression at a lower resolution signal and train the upsampler on a group of frames to efficiently reconstruct the high-resolution signal. The experiments cover both offline and zero-latency settings, demonstrating the effectiveness of the proposed approach.