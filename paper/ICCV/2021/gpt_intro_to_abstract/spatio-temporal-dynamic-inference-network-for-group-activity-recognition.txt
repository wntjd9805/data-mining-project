Group activity recognition (GAR) is the task of determining the overall activity performed by a group of people in a scene. This research paper focuses on the problem of inferring a group-level activity representation given a video clip, which requires well-designed reasoning modules. Previous methods in GAR often incorporate spatio-temporal interactive factors, such as recurrent neural networks, attention mechanisms, and graph neural networks (GNNs). GNNs, in particular, have been widely used in GAR and have achieved competitive results. However, existing GNN-based methods rely on a predefined graph structure to model interactions between individuals, which has several limitations. This paper proposes a Dynamic Interaction Network (DIN) for GAR, which allows for a more flexible modeling of interactions. The proposed DIN utilizes dynamic weights (DW) to update features based on the locally initialized interaction field, and experimental results demonstrate its effectiveness. The DIN achieves state-of-the-art performance on two benchmark datasets while minimizing computational overhead.