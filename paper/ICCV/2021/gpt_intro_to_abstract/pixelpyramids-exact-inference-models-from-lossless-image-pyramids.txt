Deep generative models, such as Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs), have made significant progress in capturing the probability density of complex data, such as natural images and raw audio. However, GANs do not provide exact density estimates, and VAEs only approximate the true distribution with intractable likelihoods. In contrast, autoregressive models and normalizing flows are exact inference approaches that estimate the exact likelihood of the data. Autoregressive models factorize the joint distribution into a product of conditional distributions, encoding complex dependencies for density estimation. However, their sequential nature makes efficient parallelization difficult. Normalizing flows map the input data to a known base distribution through invertible transformations, enabling efficient sampling, but their expressiveness and density estimation performance lag behind autoregressive models. Recent work has explored multi-scale feature representations, such as wavelet or pyramid representations, to improve the performance of exact inference models. However, these approaches rely on specific design choices or higher quantization levels that make encoding challenging. In this paper, we propose PixelPyramids, an expressive and computationally efficient block-autoregressive model for the joint distribution of pixels in images. PixelPyramids leverage ideas from lossless image coding to encode images in a coarse-to-fine manner, with each scale's generative model conditioned on the previous scale's image. The models at each scale exploit U-Net architecture and Convolutional LSTM to capture global context and spatial dependencies within each component. The conditioning on coarser scales allows for a more localized spatial dependency structure in each fine component. Additionally, the fine components at different scales are conditionally independent, allowing for parallel training and synthesis of high-resolution images. PixelPyramids achieve state-of-the-art density estimation and image synthesis on standard datasets with lower computational cost compared to previous exact inference models.