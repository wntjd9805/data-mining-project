Abstract:This paper addresses the challenge of teaching artificial intelligence (AI) new skills through instructional videos. While humans can easily learn new skills by watching demonstrations, AI systems struggle to understand the underlying decision-making process necessary for skill acquisition. Previous research has focused on action recognition, neglecting the need to model the actions required to achieve desired goals. This paper introduces a method for learning goal-directed actions from instructional videos, specifically focusing on procedure planning. The proposed model plans a sequence of actions and retrieves intermediate steps to achieve a given visual goal. Unlike typical image-language translation problems, this task involves interchangeable actions to achieve the same goal, making sequence mapping difficult. To overcome this, the task is formalized as a planning problem with short-term action separation and long-term action association. The proposed approach incorporates contextual information and potential action consequences to improve policy learning and facilitate action exploration. Experimental results on a real-world instructional video dataset demonstrate the effectiveness of the proposed method in uncovering human decision-making processes and learning meaningful representations of environment dynamics. The contributions of this work include a novel method for procedure planning, a neural network structure for embedding task information, and model-based imitation learning algorithms for accurate planning.