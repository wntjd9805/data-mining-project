The rapid development of deep learning has led to significant advancements in computer vision tasks. However, trained models often experience a drop in performance when deployed in new environments. This is due to the domain gap between the training and testing data. To address this issue without manual annotation, unsupervised domain adaptation (UDA) has been extensively explored. UDA aims to learn from labeled source domain and unlabeled target domain data. Most UDA methods use adversarial training, where a domain discriminator is trained to distinguish between the source and target domains, and a feature extractor is trained to minimize the difference between the two domains. However, as training progresses, the discrimination capability of the domain discriminator deteriorates, hindering effective optimization. In this paper, we propose a new optimization strategy called Re-enforceable Adversarial Domain Adaptation (RADA) to re-energize the domain discriminator during training. Instead of using static domain labels, we dynamically relabel well-aligned target samples as source domain samples. This makes the two distributions more separable, leading to a more powerful domain discriminator and improved feature alignment. Our experiments show that RADA outperforms state-of-the-art UDA approaches and can be easily integrated into existing adversarial learning-based domain adaptation methods without changing the network architecture of the domain discriminator.