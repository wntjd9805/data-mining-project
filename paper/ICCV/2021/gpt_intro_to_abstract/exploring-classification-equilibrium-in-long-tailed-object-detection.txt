Object detection is a crucial task in computer vision, and recent object detectors have achieved impressive results on datasets with a few categories and a balanced class distribution. However, in real-world scenarios, the distribution of data is long-tailed, with a few categories having a large number of instances while the majority of categories contain only a few instances. This poses a challenge for existing detectors designed for balanced data. The performance degradation for long-tailed datasets is mainly caused by the underfitting of tail classes due to a lack of instances and the overwhelming presence of head classes during training. Additionally, the increase in the number of categories leads to a higher chance of misclassification, especially for tail classes with low classification scores. Prior works have attempted to address the issue of long-tail learning through data resampling or loss reweighting, but these approaches have limitations such as overfitting or instability when dealing with imbalanced category distribution. To overcome these problems, this paper proposes a method that monitors the learning status of each category during training using the mean classification score. This score is found to have a positive correlation with classification accuracy and acts as an effective indicator of learning progress. The proposed method, referred to as Long-tailed Object detector with Classification Equilibrium (LOCE), introduces an Equilibrium Loss (EBL) and a Memory-augmented Feature Sampling (MFS) technique to dynamically balance the classification of different classes. EBL assigns different loss margins between classes based on their mean classification scores, while MFS enhances the adjustment of the decision boundary for weak classes by extracting instance features and reusing them across training iterations. Experimental results on the LVIS dataset demonstrate the superiority of LOCE, with significant improvements in AP for tail classes compared to state-of-the-art object detectors.