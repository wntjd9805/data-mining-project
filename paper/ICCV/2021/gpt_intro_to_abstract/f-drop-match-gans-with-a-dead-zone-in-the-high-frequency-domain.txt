Generative adversarial networks (GANs) have gained significant attention in the computer vision community for their ability to synthesize high-quality images. However, recent studies have found that GANs fail to replicate data in the frequency domain. This "frequency gap" makes it easy to detect generated images as fake. Previous studies have focused on the aliasing caused by upsampling in convolutional neural networks (CNNs) as the cause of the frequency gap but have found it to be insufficient for correcting the flaws in the frequency domain. In this paper, we explore another cause of the frequency gap and propose two novel techniques called frequency dropping (F-Drop) and frequency matching (F-Match) to address it. F-Drop filters out high-frequency components from the input images of the discriminators, allowing them to focus on lower frequency components. F-Match minimizes the mean error in the frequency domain to synthesize realistic frequency components. Our experiments show that the combination of F-Drop and F-Match improves the quality of generated images in both the frequency and spatial domains. Our contributions include demonstrating the sensitivity of GAN discriminators to high-frequency perturbations and proposing effective techniques for reducing the frequency gap between real and generated images.