Self-supervised learning (SSL) of visual representation has made significant progress in recent years, enabling various downstream tasks. Contrastive learning based SSL methods have shown strong performance on image classification tasks, closing the performance gap with supervised learning methods. However, these methods rely on the semantic consistency (SC) assumption, which may not hold for datasets beyond ImageNet. Initial studies indicate that extending these methods to other datasets does not yield satisfactory results. Motivated by this, we propose contrastive mask prediction as a pretext task for SSL. We design a novel SSL method called Mask Contrast (MaskCo) that utilizes region-level features and incorporates a mask prediction head to bridge the domain gap between masked and unmasked regions. Experimental results demonstrate the effectiveness of MaskCo, achieving comparable or superior performance compared to state-of-the-art SSL methods on various datasets. This suggests that MaskCo relaxes the SC assumption and has potential for learning image representations in unconstrained datasets.