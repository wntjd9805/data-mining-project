Single object tracking (SOT) in 3D scenes is vital for various applications such as autonomous driving, semantic understanding, and assistive robotics. LiDAR is a popular 3D sensor due to its precise measurement capabilities, reasonable cost, and insensitivity to ambient light variations. This paper focuses on SOT on LiDAR data, which can be represented as 3D point clouds. However, the irregular and incomplete nature of LiDAR-generated point clouds poses significant challenges for the SOT task.Feature comparison plays a crucial role in 3D SOT, where the goal is to measure similarity between candidate regions and the object template. Existing approaches rely on comparing features extracted from pure LiDAR point clouds, which suffer from limitations such as the inability to encode object size information and the lack of explicit part-aware structure information within each object bounding box (BBox). These shortcomings lead to ambiguities and weaken the tracking performance.To address these issues, this paper proposes a novel object representation called BoxCloud, which enhances object features by explicitly utilizing the BBox. The BoxCloud represents an object point using a canonical box coordinate, encoding size and part information. By computing the BoxCloud for the target template using the BBox given in the first frame, the size and part priors of the target object can be directly inferred. Additionally, a box-aware feature fusion (BAFF) module is introduced to perform a correlation between the template and search area, generating target-specific search area features. The BAFF module aggregates top-k similar template points into each corresponding searching point, resulting in a high-quality target-specific search area. These components are integrated into the P2B framework, creating the Box-Aware Tracker (BAT), which captures shape constraints and part-aware information, enabling effective and robust tracking on LiDAR point clouds.The contributions of this paper include the utilization of box information to enhance the performance of the 3D SOT task, the design of a size-aware and part-aware BoxCloud feature for improved feature comparison, and the proposal of a dedicated box-aware feature fusion module. Experimental results on KITTI and NuScenes benchmarks validate the superiority of BAT over existing methods, particularly in scenarios with extremely sparse data.