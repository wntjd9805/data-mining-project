Representing 3D shapes with a compact set of atomic primitives has been a well-established idea in computer science. While this idea has mainly been used for machine perception, it is also important for enabling editing capabilities in downstream applications. The problem of fitting primitives to scanned data is challenging, as different primitive configurations can result in similar fitting errors. Previous approaches, such as RANSAC, have been widely used but suffer from combinatorial complexity and require manual parameter tuning. To address this challenge, a supervised framework called SPFN has been proposed, which learns the best configuration of primitives for each 3D scan. However, SPFN struggles with processing high-resolution data due to memory limitations. In this work, we propose a novel framework called CPFN, which uses cascaded networks to capture local details in scans and fit small primitives. Our framework includes a patch selection network to detect regions with small primitives, and a merging algorithm to combine the outputs of the two networks. Experimental results show that our cascaded networks outperform previous approaches in fitting primitives of all scales, with a significant improvement for smaller primitives. Additionally, the local fitting network can benefit from contextual information learned by the global fitting network. Our contributions include the development of CPFN, the introduction of a merging algorithm, and the demonstration of improved performance using contextual information.