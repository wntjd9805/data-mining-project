The paper introduces the concept of Neural Architecture Search (NAS) in the field of computer vision. The authors highlight the limitations of common Deep Neural Networks (DNNs) which are designed by human experts and require significant computation resources and domain-specific knowledge. They discuss the emergence of NAS as an automated way to search for neural architectures, which reduces the dependence on human experts and achieves remarkable performance. The paper focuses on the Differentiable Neural Architecture Search (DNAS) method, specifically the DARTS (Differentiable Architecture Search) approach. The authors identify two optimization gaps in DARTS: the operation gap caused by different numbers of trainable parameters in different operations, and the structure gap caused by inconsistent model structures between the search and retraining stages. To address these gaps, the authors propose a new method called EC-DARTS (Equalized and Consistent Differentiable Architecture Search). EC-DARTS includes a Cross-Edge Normalization (CEN) technique to equalize the dominance of each operation and a Induced Structural Transition (IST) approach to improve consistency between the search and retraining stages. The paper presents experiments on various datasets and demonstrates that EC-DARTS achieves state-of-the-art performance in terms of test error and model size. Overall, the paper introduces a novel approach to NAS in computer vision and provides empirical evidence of its effectiveness.