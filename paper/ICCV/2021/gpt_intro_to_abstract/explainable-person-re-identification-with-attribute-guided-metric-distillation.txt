Person Re-identification (ReID) is the task of identifying the same person across multiple cameras. While Convolutional Neural Networks (CNNs) have improved the accuracy of ReID models, there is a need for interpretable models, especially for critical scenarios. Existing methods for interpreting CNNs mainly focus on classification problems and cannot be directly applied to ReID, which is an open-set retrieval task. This paper proposes Attribute-guided Metric Distillation, a method for interpreting CNN-based ReID models. The method utilizes semantic attributes to answer questions about the differences between persons and the impact of each attribute. The proposed method employs a pluggable interpreter network with an attribute decomposition head to visualize discriminative attributes and quantify their contribution to the overall distance. Two loss functions, metric distillation loss and attribute prior loss, are designed to guide the learning of the interpreter. The effectiveness and compatibility of the interpreter are demonstrated through experiments on different datasets. The results show improved performance of state-of-the-art ReID models with the proposed interpreter. This work contributes to the explanation and improvement of ReID models using semantic attributes.