The emergence of consumer-grade panorama cameras is revolutionizing the real-estate industry, allowing for full-360 interior views to be easily captured and browsed by potential buyers or renters. The mass-consumer crowd sourcing of these panoramas, particularly from the THETA series by RICOH, has resulted in a market growth of 100 million panoramas specifically for real-estate applications. However, the simplicity of the operation, which only requires users to take a picture in the middle of each room, leads to panorama images with little to no visual overlaps, making the pose estimation challenging for existing techniques. To address this problem, this paper proposes an extreme Structure from Motion (SfM) problem for indoor panoramas with little to no visual overlaps and presents a novel solution. The key idea is to learn the arrangement of rooms, doors, and windows, and solve for camera parameters that maximize the realism of their arrangement. The proposed method involves applying Manhattan-rectification, inferring a room layout, detecting doors/windows, and classifying room types for each panorama. The inferred semantic information is then re-projected into a top-down view, and arrangement candidates are generated based on door detections. A convolutional message passing neural network is used to score the generated arrangements, and the one with the highest score is selected as the final reconstruction. The proposed system is evaluated using a dataset of 1029 panoramas from 286 houses, where a standard SfM approach fails to align even two panoramas for most houses. The results show that the proposed system is able to reconstruct compelling arrangements, with a mean positional error of less than 1.0 meter in the top five reconstructions for 78% of the test houses. The contribution of this paper includes the introduction of a new extreme indoor SfM problem in the context of the real-estate market, a unique SfM algorithm that learns to evaluate the arrangement of semantic information, and state-of-the-art performance compared to existing techniques. The code, models, and data will be made available to the public.