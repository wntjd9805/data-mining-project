3D human pose and mesh reconstruction from a single image is a challenging task due to the complex body articulation. Recent advancements in Transformers and Graph Convolutional Neural Networks (GCNNs) have shown promise in improving human mesh reconstruction. However, both Transformers and CNNs have their own limitations in capturing fine-grained local information and global context, respectively. In this paper, we propose a graph-convolution-reinforced transformer called Mesh Graphformer to address these challenges. We inject graph convolutions into the transformer blocks to enhance local interactions among neighboring vertices and joints. By leveraging the power of graph convolutions, our approach effectively models both local and global interactions and outperforms previous state-of-the-art methods in human pose and mesh reconstruction. Our extensive experiments demonstrate the effectiveness of Mesh Graphformer on various datasets. Our contributions include the development of a novel graph-convolution-reinforced transformer and the improvement of both local and global interactions for 3D reconstruction of human pose and mesh. Furthermore, our approach allows joints and mesh vertices to attend to image grid features, resulting in refined 3D coordinate predictions.