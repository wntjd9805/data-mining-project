In recent years, there has been a growing interest in developing deep neural networks (DNNs) for reconstructing three-dimensional (3D) shapes or projections of opaque objects. However, there is still a significant gap in advancing the reconstruction of 3D heterogeneous volumetric translucent fields, such as the atmosphere. This paper aims to address this gap by proposing a learning-based system, called 3DeepCT, for inferring 3D scattering computed tomography (CT) of clouds. The proposed system leverages the power of DNNs to learn the richness of large translucent fields and the physical processes that generate both 3D translucent objects and their images. Unlike traditional linear image formation models, the nonlinear and continuous nature of the tomographic model makes it challenging to apply existing DNNs. Moreover, the scarcity of ground-truth data for volumetric heterogeneous translucent objects further complicates the task. By utilizing a large and diverse database generated through physics-based simulations, the proposed system overcomes these challenges and achieves significant improvements in inference speed compared to explicit physics-based optimization methods. The paper presents the architecture of 3DeepCT, including a convolutional neural network (CNN) based on 2D convolutions, the size of its receptive field and layer-depth, and avoidance of dimensionality reduction. Experimental results demonstrate that 3DeepCT performs comparably to explicit physics-based methods while being five orders of magnitude faster. Additionally, the system has the potential to scale to broad cloud fields by leveraging GPU parallelism. This work contributes to the advancement of reconstructing 3D heterogeneous volumetric translucent fields and provides insights into the application of DNNs in computed tomography.