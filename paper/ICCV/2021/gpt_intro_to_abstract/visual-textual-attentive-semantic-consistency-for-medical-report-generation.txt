Abstract: The automatic diagnosis of diseases using chest X-Ray images has become a significant research topic in the medical imaging community. This paper proposes a method for predicting key findings and generating detailed descriptions by combining radiographs with clinical information. The proposed model utilizes a multi-modality semantic attention (MMSA) model to combine different modality features into context vectors for the decoder. Additionally, topic-level losses are introduced to optimize the sequential sentence and word decoders, ensuring accurate and suitable sentence-level topics. Experimental results demonstrate the effectiveness of the proposed multi-attention model and losses, with the introduction of a new metric, normalized Key Term Distance (nKTD), for evaluating medical report generation performance. Overall, this research contributes to the automatic diagnosis of diseases through chest X-Ray images, enhancing the interpretation process and reducing the potential for mistakes.