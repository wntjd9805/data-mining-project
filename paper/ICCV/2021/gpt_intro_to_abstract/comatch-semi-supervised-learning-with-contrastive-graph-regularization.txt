Semi-supervised learning (SSL) has long been a challenge in computer vision and machine learning. Current state-of-the-art SSL methods primarily rely on either pseudo-labeling or self-supervised learning techniques. However, these methods have several limitations, such as suffering from confirmation bias and producing suboptimal representations for classification tasks. In this paper, we propose a new SSL method called CoMatch that addresses these limitations. CoMatch utilizes two compact representations for each image - a class probability produced by the classification head and a low-dimensional embedding produced by the projection head. These representations interact and evolve jointly in a co-training framework. The classification head is trained using memory-smoothed pseudo-labels, refined by aggregating information from nearby samples in the embedding space. The projection head is trained using contrastive learning on a pseudo-label graph, ensuring similar embeddings for samples with similar pseudo-labels. CoMatch outperforms state-of-the-art baselines in multiple benchmarks, especially in scenarios with limited labeled data. Our experiments demonstrate superior performance in terms of accuracy and representation learning in downstream tasks.