Typography plays a crucial role in visually arranging letters and text in graphic design. In the field of computer vision, optical character recognition (OCR) has primarily focused on identifying characters in images, disregarding typographic information such as font style or effects. This paper introduces a novel approach to raster text editing by treating it as a text vectorization problem. Previous work has approached text editing as a style transfer problem in the pixel domain, but this approach often results in artifacts and is resolution-dependent. The proposed approach leverages the advantages of vector format for display media, providing consistent and sharp rendering results regardless of resolution. The paper addresses three key sub-problems: OCR, background inpainting, and styling attribute recognition. Neural networks are trained to predict statistically plausible parameters for parsing the text and styling attributes. The model employs both feedforward and feedback inference, incorporating differentiable rendering to reproduce the given raster text. Experimental results demonstrate the effectiveness of the vectorization model in accurately parsing text information and successfully utilizing it in downstream editing tasks. The contributions of this work include formulating raster text editing as a de-rendering problem, proposing a vectorization model that leverages differentiable rendering for parsing detailed text information, and showcasing the high quality parsing of rendering parameters and its utility in 2D graphics engine for downstream editing.