Convolutional Neural Networks (CNNs) have shown remarkable success in image recognition tasks. However, applying CNNs to video recognition is challenging due to the temporal nature and complexity of videos. This paper introduces a new approach called Informative Frame Synthesis (IFS), which early fuses the information from video sequences into a synthetic frame. The IFS architecture consists of a convolutional encoder-decoder network, three objective tasks, and two regularizers. By jointly optimizing the transformation network, the IFS network learns to capture both visual appearance and temporal evolution from just one synthetic frame. Experimental results on the Kinetics dataset demonstrate that the IFS network achieves comparable performance to more computationally expensive 3D CNNs. Additionally, using the synthetic frames as a video summary for 3D CNN classification leads to higher performance than existing methods. This work contributes a novel approach for video recognition using 2D CNNs and provides insights into the impact of different tasks and regularizers on frame synthesis.