Zero-shot learning (ZSL) is a key challenge in artificial intelligence, aiming to classify images of unseen classes by establishing a mapping relationship between semantic and visual domains. This paper focuses on the generalized ZSL (GZSL) setting, which can predict both seen and unseen classes. GZSL has made significant progress but faces problems such as visual-semantic domain gaps and seen-unseen bias. The authors observe that the unsatisfying performance in GZSL is closely related to the cross-dataset bias between ImageNet and GZSL benchmarks. This bias leads to a distribution mismatch and poor-quality visual features. Fine-tuning can alleviate the bias, but it results in overfitting. To address these challenges, the authors propose a novel GZSL method called feature refinement for generalized zero-shot learning (FREE). FREE refines visual features using a unified generative model, incorporating a feature refinement (FR) module. They introduce a self-adaptive margin center loss (SAMC-loss) to enhance intra-class compactness and inter-class separability. Experimental results on multiple benchmarks demonstrate the advantages of FREE over baseline methods and state-of-the-art approaches. The contributions of the paper are (1) proposing the FREE method to address the cross-dataset bias in GZSL and boost performance, (2) introducing the SAMC-loss to enhance discriminative features, and (3) providing extensive experimental results on multiple benchmarks.