Large labeled datasets like COCO are crucial for deep neural network-based instance segmentation methods. However, collecting groundtruth masks can be time-consuming compared to bounding box annotations. In COCO, mask annotations take approximately 80 seconds on average, while bounding box annotations can be obtained in 7 seconds using methods like Extreme Clicking. This paper addresses the problem of "partially supervised" instance segmentation, where only a subset of classes have mask annotations and all classes have bounding box annotations. The goal is to produce accurate masks for unseen classes, which requires strong generalization capabilities of the model. The paper focuses on a general family of crop-then-segment models, where a feature map is extracted from the image, and a differentiable crop is performed using a tight bounding box. The cropped feature map is then fed into a mask-head subnetwork to generate a final mask prediction. The authors revisit the Mask R-CNN model and find that training the mask-head with only groundtruth boxes significantly improves its performance on unseen classes. They also investigate the impact of different mask-head architectures and discover that deeper architectures tend to generalize better to unseen classes. The authors propose two models, Deep-MAC and Deep-MARC, based on CenterNet and Mask R-CNN respectively, which achieve state-of-the-art results on the COCO partially supervised instance segmentation task. The paper presents several auxiliary findings, such as the benefits of self-distillation and the saturation point of mask quality on COCO. The main contributions of the paper are the identification of the strong mask generalization effect, the importance of training with groundtruth boxes, and the characteristics of mask-head architectures that lead to strong generalization.