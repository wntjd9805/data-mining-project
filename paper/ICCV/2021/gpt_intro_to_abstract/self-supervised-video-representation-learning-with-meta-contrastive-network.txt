Convolutional Neural Networks (CNNs) have achieved great success in supervised video representation learning. However, labeling large-scale video data is expensive and laborious. To address this challenge, self-supervised learning for image has emerged as a solution, using contrastive loss to discriminate different data samples. This approach has also been applied to videos, but it lacks the ability to capture common category information, reducing the generalization of pre-training parameters. In this paper, we propose a novel Meta-Contrastive Network (MCN) that combines meta learning with self-supervised learning to improve the generalization and adaptation ability of video representation learning. MCN utilizes a contrastive branch and a meta branch in a multi-task learning process. We also design a two-stage training process based on MAML. Our method achieves state-of-the-art performance on action recognition and retrieval tasks, demonstrating the effectiveness of combining meta learning with self-supervised video representation learning.