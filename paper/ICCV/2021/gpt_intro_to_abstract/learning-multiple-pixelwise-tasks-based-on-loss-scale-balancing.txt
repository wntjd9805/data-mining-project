Multi-task learning (MTL) is a machine learning technique that aims to simultaneously solve multiple learning tasks, leveraging the commonalities and differences across these tasks. MTL has shown to enhance learning efficiency and prediction accuracy compared to independent models for individual tasks. With the rise of deep learning, MTL has been widely applied in computer vision, natural language processing, reinforcement learning, and speech recognition. In computer vision, MTL models using convolutional neural networks (CNNs) have been particularly prevalent, allowing for joint learning of multiple pixelwise tasks such as depth estimation, surface normal estimation, and semantic segmentation. These models share a significant portion of network parameters, benefiting from reduced complexity, inference time, and learning efficiency. To develop effective deep MTL algorithms, two key factors need to be considered: architecture and training scheme. The architecture should be designed to learn task-specific and task-shared representations, while the training scheme should prevent bias towards a specific task. In this paper, we propose a novel loss weighting algorithm called loss scale balancing (LSB) for MTL of pixelwise computer vision tasks. LSB dynamically adjusts weights to effectively learn all tasks, balancing the loss scales periodically and focusing on difficult tasks based on their previous loss records. Experimental results demonstrate that LSB improves the performance of each task, outperforming conventional weighting algorithms consistently across different MTL architectures, datasets, and encoder backbones. The contributions of this paper include proposing the use of balanced loss scales instead of losses themselves to enhance MTL performance, improving performance by tuning loss scales based on task difficulties, and demonstrating the superiority of the proposed algorithm over conventional approaches.