Human parsing and pose estimation are two important tasks in analyzing human behaviors. Human parsing involves segmenting the human body into semantic regions, while pose estimation aims to locate keypoints on the body and analyze structural information. These tasks are closely related, as the semantic information from human parsing can help accurately locate keypoints for pose estimation. Additionally, the group of keypoints contains structural information that can guide the generation of semantic parts. Convolutional neural networks (CNNs) have been widely used to address these tasks, typically using encoder-decoder architectures. However, existing models struggle to simultaneously improve pose estimation and human parsing, as there is an inconsistency between the two tasks. There is a need for a better network architecture that allows both tasks to benefit from each other. In this paper, we propose NPPNet, an end-to-end network entirely searched by Neural Architecture Search (NAS), to tackle both human parsing and pose estimation simultaneously. NPPNet includes task-specific encoder-decoder structures, multi-scale feature interaction, and high-level feature fusion. We design three search spaces to extract discriminative features and establish optimal connections between the two tasks. Experimental results on the LIP and extended PASCAL-Person-Part datasets demonstrate that NPPNet achieves state-of-the-art performance on both tasks. Overall, this paper contributes a novel approach using NAS for joint learning of human parsing and pose estimation.