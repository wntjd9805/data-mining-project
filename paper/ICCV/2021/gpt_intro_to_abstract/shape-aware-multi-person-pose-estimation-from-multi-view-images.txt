Markerless human motion capture is a fundamental problem in computer vision, with significant progress made in estimating human body configurations in 2D and 3D from single RGB images. However, challenges arise when multiple people are depicted, especially when they are interacting closely, leading to occlusions and depth ambiguities. To address this, multi-camera setups are necessary to provide additional observations from different views. Previous approaches have attempted to predict poses of multiple people from multiple cameras, with some formulating the problem as a cross-view matching and association problem. However, these methods suffer from limitations such as computational complexity and reliance on volumetric feature representation requiring extensive training data. In this paper, we propose a coarse-to-fine pipeline for estimating 3D multi-person poses from multi-view images. Our approach combines elements from bottom-up and top-down methods, leveraging confident 2D features and employing a confidence-aware majority voting technique to obtain initial 3D proposals. We then refine these proposals using a novel 2D-3D objective and a parametric body model, optimizing the 3D joint locations directly and aligning SMPL parameters to the updated 3D observations. Experimental results show that our approach outperforms existing methods in terms of detection performance and achieves state-of-the-art performance on public datasets. Our contributions include a confidence-aware pipeline to aggregate 2D observations into 3D space and a refinement pipeline for optimizing 3D poses and SMPL models. Our method is general and relies on off-the-shelf pose detectors and motion capture data.