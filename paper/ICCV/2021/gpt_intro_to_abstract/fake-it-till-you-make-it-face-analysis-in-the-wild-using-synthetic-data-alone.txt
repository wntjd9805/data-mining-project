This paper discusses the use of synthetic data in the domain of human-related computer vision, specifically for training machine learning models. The authors argue that collecting and labeling real data is slow, expensive, and subject to bias, making synthetic data a preferable alternative. They highlight the challenge of rendering convincing humans in computer graphics and the limitations of previous approaches in synthesizing realistic facial training data. The paper introduces a new method for acquiring training data for faces by rendering 3D face models with unprecedented realism and diversity. The authors explain the process of procedurally constructing synthetic faces, including randomizing identity, expression, texture, hair, and clothing, and rendering them in random environments. They emphasize that synthetic data can be used to solve real-world problems without relying on any real data. The authors acknowledge that developing a synthetic data framework with minimal domain gap requires expertise and investment. However, once implemented, it enables the generation of a wide variety of training data with minimal effort. They provide examples of how synthetic data can be beneficial, such as regenerating clean and consistent labels or developing computer vision algorithms for new cameras. The authors describe their experiments which demonstrate that models trained with a generic synthetic dataset can achieve results comparable to those trained with task-specific real datasets. They highlight the potential of synthetic data for addressing various face-related tasks instead of relying on real data. The contributions of the paper include the description of the method for synthesizing realistic and diverse training data for face analysis, validation of the steps taken to achieve photorealism through ablation studies, and the availability of the synthetic dataset itself.