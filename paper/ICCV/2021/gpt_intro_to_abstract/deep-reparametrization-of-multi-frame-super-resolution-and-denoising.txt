Multi-frame image restoration (MFIR) is a computer vision problem that aims to reconstruct a clean and sharp output image from multiple degraded and noisy input images. It has diverse applications in areas such as burst photography and remote sensing. Current approaches to MFIR typically model the image formation process and use maximum a posteriori (MAP) estimation to reconstruct the original image. However, these approaches have challenges, such as the assumption of a known degradation operator and the need for manual tuning of the regularization term. In this paper, we propose a deep reparametrization of the MAP objective that leverages the advantages of the traditional approach while also benefiting from end-to-end learning. Our method replaces the L2 norm with a learnable error metric and reparametrizes the target image with a decoder network. We integrate strong learned image priors and directly learn the effects of complex degradation operators in the deep latent space of our formulation. We also introduce a network component to estimate the certainty weights of all observations to improve robustness. Our experimental results on two multi-frame image restoration tasks demonstrate the superiority of our approach over recent deep learning-based methods in terms of performance and set a new state-of-the-art. We also conduct ablative experiments to analyze the impact of each contribution.