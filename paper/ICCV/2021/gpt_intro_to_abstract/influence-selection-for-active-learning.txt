Active learning is an important technique in computer vision that aims to reduce annotation costs by improving model performance with fewer labeled training samples. While weakly supervised learning and semi-supervised learning have made rapid progress, active learning in computer vision is still limited, particularly in the area of image classification. Current active learning algorithms for image classification primarily fall into two categories: uncertainty-based methods and diversity-based methods. However, relying solely on uncertainty measures may lead to inaccurate sample importance estimates and degrade the performance of active learning algorithms. Additionally, diversity-based methods do not consider the model state and have high computational complexity when dealing with large-scale datasets. In this paper, we propose a task-agnostic and model-agnostic active learning algorithm called Influence Selection for Active Learning (ISAL). ISAL selects samples based on their positive influence on model performance, determined by calculating their expected gradient using the Untrained Unlabeled sample Influence Calculation (UUIC) method. Unlike other algorithms, ISAL does not rely on feature distance or expected loss measurements. Experimental results demonstrate that ISAL outperforms existing active learning algorithms for both image classification and object detection tasks, achieving significant annotation cost savings. The contributions of this paper are the proposal of ISAL, the design of UUIC, and the comprehensive evaluation of ISAL's performance in various experiment settings.