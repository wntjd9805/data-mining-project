This paper addresses the problem of rendering a scene from unobserved viewpoints using Novel View Synthesis (NVS) techniques. NeRF (Neural Radiance Fields) is a state-of-the-art method for this task, but it suffers from long training and rendering times. This paper presents KiloNeRF, a modified version of NeRF that significantly increases rendering speed without sacrificing visual quality. The key idea is to represent the scene using thousands of small Multi-Layer Perceptron (MLP) networks instead of a single large MLP. To mitigate the loss in image quality caused by reducing network size, a three-stage training strategy is employed, involving a regular NeRF as a teacher model. The proposed KiloNeRF model achieves the same visual fidelity as NeRF but can synthesize novel views three orders of magnitude faster. The paper also provides an efficient implementation of KiloNeRF using PyTorch, MAGMA, Thrust, and custom CUDA kernels, which is available on GitHub.