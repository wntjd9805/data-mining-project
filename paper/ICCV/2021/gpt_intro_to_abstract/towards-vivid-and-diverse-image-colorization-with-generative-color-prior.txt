Colorization, the process of adding color to black-and-white photos, has various applications in fields such as photography, advertising, and film industry. However, colorization is a challenging task as it involves estimating missing color information from grayscale images, which is inherently an ill-posed problem. Traditional reference-based methods require example color images as guidance, but retrieving desirable reference images is a cumbersome process. Convolutional neural network (CNN) based methods have been proposed to automate colorization, but they often produce unsatisfactory artifacts and inconsistent colors. In this work, we aim to combine the strengths of both reference-based and CNN-based methods to achieve realistic and vivid colorization results in an automatic manner. We introduce the concept of using a Generative Adversarial Network (GAN) to leverage a diverse range of color information as a generative color prior. This eliminates the need for explicit example retrieval and allows us to incorporate it into the colorization process. Additionally, our method is capable of producing diverse colorizations by modifying GAN latent codes and achieving smooth transitions in the color space. Experimental results demonstrate that our method generates more vivid and diverse colorization results compared to previous approaches. Overall, our unified framework provides a novel approach to automatic colorization with enhanced visual qualities.