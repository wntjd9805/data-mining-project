Deep Convolutional Neural Networks (DCNN) have shown remarkable success in computer vision benchmarks. However, their performance heavily relies on manually labeled data, which is costly to collect. Unsupervised representation learning, which can learn representations without human annotations, has gained increasing interest. Previous unsupervised methods rely on manually designed pretext tasks, which have limitations in their applicability to downstream tasks. Recently, the instance discrimination paradigm has emerged as a powerful approach in unsupervised representation learning. This paradigm treats each sample as its own category and trains the CNN to separate different samples from each other. The instance discrimination paradigm incorporates a teacher-student framework, with an Exponential Moving Average (EMA) teacher network that enforces instance spatial consistency. However, the current EMA teacher has limitations. It only focuses on instance spatial consistency and ignores instance temporal consistency, leading to varying outputs of the same sample and potential catastrophic forgetting. Additionally, the EMA manner assumes the importance of later models, disregarding the benefits of earlier epochs. In this paper, we propose a novel algorithm called Temporal Knowledge Consistency (TKC) that integrates instance temporal consistency into the instance discrimination paradigm. TKC includes a temporal teacher that introduces temporal knowledge from previous models and a knowledge transformer that dynamically learns the importance of different temporal teachers. We demonstrate the effectiveness of TKC through extensive experiments on various tasks and benchmarks, achieving state-of-the-art performance and scalability. Our contributions include integrating instance temporal consistency into the EMA teacher, proposing TKC as a strong algorithm for ensemble learning, and providing a computation-economical implementation.