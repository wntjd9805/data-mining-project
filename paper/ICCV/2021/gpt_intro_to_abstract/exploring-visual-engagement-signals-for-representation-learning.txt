This paper explores the concept of visual engagement on social media platforms and its potential as a supervisory signal for representation learning in computer vision tasks. Visual engagement refers to the rich semantic descriptions and emotional context conveyed by user interactions such as comments, likes, and shares on posted photos. These interactions provide a more nuanced understanding of the image content compared to conventional computer vision annotations. The paper proposes the use of visual engagement signals (VisE) as a means to learn image representations that capture private states expressed in the images. The authors hypothesize that mapping image content to human reactions can infer these private states and augment current computer vision research focused on objectively present factual information. The authors propose a framework for learning image representations from VisE, leveraging cluster assignments obtained from clustering each type of visual engagement. The paper considers two forms of human responses, comments and reactions, and evaluates the learned representations on downstream tasks related to private states detection. The main contribution of the paper is the demonstration that social media engagement can provide supervision for learning image representations that outperform ImageNet-supervised models in subjective downstream tasks. The authors employ a VisE model pre-trained on a large corpus of social media posts, and their experiments highlight the potential of VisE to bridge the gap between machine and human intelligence in representation learning.