Recent advancements in Generative Adversarial Networks (GANs) have shown remarkable results in visual applications such as image synthesis and image-to-image translation. However, most of these models require significant computational resources, making it challenging to deploy on resource-constrained devices like mobile phones and IoT devices. To address this issue, GAN compression has emerged as a crucial task. Existing compression techniques for GANs have limitations, including the use of generic model compression techniques that are not tailored for GANs, multi-stage compression processes, and high computational costs. In this paper, we propose a novel Online Multi-Granularity Distillation (OMGD) framework for learning efficient GANs. Our approach replaces the complex multi-stage compression process with a GAN-specific online distillation strategy, enabling compressed model optimization in a one-step process. We leverage multiple levels and granularities of information to optimize the compressed models, resulting in improved visual fidelity. Experimental results on benchmark datasets demonstrate that OMGD significantly reduces computational costs without compromising image quality compared to existing methods. Additionally, OMGD achieves impressive results, making it suitable for deployment on resource-constrained devices and real-time image translation on mobile devices.