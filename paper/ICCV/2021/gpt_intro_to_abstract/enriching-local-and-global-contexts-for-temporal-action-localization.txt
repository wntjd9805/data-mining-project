Temporal action localization (TAL) is an important task in video understanding, with applications in action retrieval, video summarization, and intelligent security. TAL methods can be divided into one-stage and two-stage approaches. One-stage approaches classify and locate action instances in a single shot, while two-stage approaches generate action proposals and then perform classification and temporal boundary refinement. This paper introduces a novel network architecture called ContextLoc, which leverages rich local and global contexts for TAL. The local context refers to snippets within a proposal, capturing fine-grained temporal information for localization. The global context refers to the entire video, providing discriminative information for action classification. Existing TAL models have largely ignored the global context. ContextLoc consists of three sub-networks: L-Net, G-Net, and P-Net. L-Net uses a proposal to query snippets and retrieve the local context, enhancing fine-grained temporal information. G-Net integrates the video-level representation with proposal-level features, adapting the global context to different proposals. P-Net models context-aware inter-proposal relations. The proposed ContextLoc outperforms state-of-the-art methods on popular TAL benchmarks, THUMOS14 and ActivityNet v1.3. The contributions of this paper include the introduction of snippet-level local context and video-level global context within a two-stage TAL framework, the novel network architecture of ContextLoc, and its superior performance in TAL.