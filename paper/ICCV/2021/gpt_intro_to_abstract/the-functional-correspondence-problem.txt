Computer vision and visual representation learning in computer science have predominantly focused on semantic categories, limiting their effectiveness in capturing affordances for robotics tasks and generalizing to new object categories. In contrast, humans possess the ability to think beyond categories and identify correspondences between semantically different objects. In this paper, we introduce the problem of functional correspondence, which aims to establish correspondences between objects for a given task. We present a new dataset called FunKPoint, which contains ground-truth keypoints labeled for 10 tasks across 20 object categories. We propose a modular task-driven architecture that effectively models functional correspondences. Additionally, in proof-of-concept experiments, we demonstrate the promise of learning functional correspondence for few-shot learning, outperforming semantically-learned representations. We believe that functional correspondence is a crucial task in visual learning as it enables the prediction of object affordances, generalization beyond semantic categories, and task-driven representations.