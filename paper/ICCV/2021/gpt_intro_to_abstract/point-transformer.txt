This paper introduces the use of Point Transformers for deep learning on 3D point clouds. Unlike images, point clouds are sets embedded in continuous space, making them structurally different and challenging to apply deep network designs. The authors explore various approaches, including voxelization, continuous convolutions, and graph-based message passing. Inspired by the success of transformers in natural language processing and image analysis, the authors propose a self-attention layer for point cloud processing. They investigate the application of self-attention to local neighborhoods, encoding positional information, and develop Point Transformer networks for 3D understanding tasks. The experiments show that Point Transformers achieve state-of-the-art performance in object analysis and scene parsing, surpassing previous work on various benchmarks. The main contributions include the design of a highly expressive Point Transformer layer, the construction of high-performing networks, and extensive experiments in multiple domains. The full implementation and trained models will be released upon acceptance.