The robust detection and segmentation of moving people is a challenging task for less common activities such as skiing due to the lack of training databases. In this paper, we propose a self-supervised approach that utilizes a multi-camera setup and explicitly encodes the 3D geometry of the scene to overcome these limitations. Our trained network can handle single images at inference time and outperforms previous techniques. We introduce an object proposal strategy that leverages multi-view training data as weak supervision, allowing for prediction consistency across views. Our approach can handle unusual activities and fast motion, as demonstrated on the skiing dataset and other datasets. We show that the proposed multi-view training improves single-image accuracy and outperforms state-of-the-art approaches. Our code is publicly available at the provided GitHub link.