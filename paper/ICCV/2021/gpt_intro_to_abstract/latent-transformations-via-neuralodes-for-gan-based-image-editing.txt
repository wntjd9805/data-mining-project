Generative Adversarial Networks (GANs) have made significant advancements in image processing and controllable generation. Many recent works explore the semantically meaningful vector space arithmetic of GANs' latent spaces, particularly for face images. However, most existing methods for latent editing only consider linear transformations, which may not be universally applicable for all domains and attributes. In this paper, we analyze the distributions of attribute values in GAN latent spaces trained on various datasets and demonstrate that linear latent shifts are often insufficient for non-face images. To address this limitation, we propose a novel parametrization of the latent transformation based on Neural ODE work, enabling gradient-based optimization and supporting existing methods for latent space exploration. Through extensive experiments, we show that nonlinear transformations are more effective for achieving controllable generation, especially for global content changes. Our contributions include the analysis of attribute value distributions in latent spaces, the proposal of a Neural ODE-based parametrization for nonlinear controls, and the demonstration of improved editing quality on non-face datasets.