Facial landmark detection has seen significant improvement in recent years through the use of multi-stage stacked networks. However, these models often suffer from overfitting, particularly when trained on small or unbalanced datasets. To address this issue, researchers have explored various data augmentation techniques and unsupervised learning methods. However, these approaches have their limitations and may still fail to generalize well in unconstrained environments. In this paper, we propose a sample-adaptive adversarial training (SAAT) approach to enhance the robustness of facial landmark detectors. Our method leverages adversarial attacks to fool the detector and trains it to defend against these attacks. Unlike existing attacks, our approach utilizes a sample-adaptive black-box attacker that does not require a pre-trained model and crafts adversarial perturbations based on real-time feedback from the detector. We also allow these perturbations to be visible, diversifying the adversarial examples and helping the detector defend against real-world attacks. Furthermore, we employ a structure-guided conditional adversarial architecture and a semantic reconstruction loss to ensure that the adversarial examples maintain face structure and semantic consistency with the original faces. To prevent the degradation caused by false samples, we introduce a sample-adaptive weight that adjusts the contribution of different adversarial examples based on their structural similarity to the original faces. Our approach improves the robustness of facial landmark detectors without increasing model parameters and human annotations. It effectively addresses the challenges faced by existing methods and shows promising results in robust facial landmark detection.