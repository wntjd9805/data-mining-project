This paper introduces Pathdreamer, a generic visual world model for agents navigating indoor environments. The goal is to generate high-resolution visual observations for viewpoints that have not been visited before, even in previously unseen buildings. The paper addresses challenges such as synthesizing completions of partially visible objects and predicting around corners. Pathdreamer consists of two stages - Structure Generator and Image Generator - that generate depth, semantic segmentations, and realistic RGB images. The model achieves plausible views for unseen scenes and successfully addresses the room reveal problem. The performance of Pathdreamer is evaluated using trajectory rollouts and compared against prior work and baselines. Furthermore, the paper explores the potential of Pathdreamer in Vision-and-Language Navigation (VLN) tasks and presents promising results. The contributions of this work include proposing the study of visual world models for indoor environments, introducing Pathdreamer, and providing extensive experiments to validate its performance.