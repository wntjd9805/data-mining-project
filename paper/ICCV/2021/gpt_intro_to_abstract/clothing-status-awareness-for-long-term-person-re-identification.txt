Person re-Identification (re-ID) aims to verify the identity of individuals in visual traces. Two scenarios for person re-ID are Short-Term re-ID (ST-reID), which deals with short time gaps between footages, and Long-Term re-ID (LT-reID), which considers longer time gaps. LT-reID presents additional challenges caused by changes in clothing and accessories. Existing approaches for LT-reID can be categorized into biometrics-based methods, which use stable biometric features, and data adaptation-based methods, which fine-tune pretrained models. However, these approaches have limitations in terms of reliability and handling no-clothing-change cases. This paper proposes the Regularization via Clothing Status Awareness Network (RCSANet) for LT-reID. RCSANet separates ID discriminative feature learning and clothing status awareness learning, and uses a Feature Regularization Module (FRM) to encourage consistency in ID features when an individual wears the same clothes. RCSANet achieves improved performance on both clothing-change and no-clothing-change cases in LT-reID without requiring extra clothing annotations. Experimental results demonstrate the effectiveness of RCSANet on three LT-reID benchmarks.