This paper introduces the concept of person re-identification (Re-ID) in computer science, which aims to identify the same person across different cameras. The paper focuses on the challenge of learning a robust and discriminative identity representation due to variations in image quality and semantic factors. The authors propose a new approach called Global-Aware and Attack-Guided perceptual data generation (GAAG), which combines disentangled image generation and adversarial attack to address low-level perceptual variations in real-world surveillance scenarios. The approach includes a lightweight disentangled generative model that predicts image quality scores and adjusts images accordingly. Additionally, the authors introduce synthetic-to-real feature constraints to improve the robustness of identity features. Experimental results on cross-resolution re-id benchmarks demonstrate the effectiveness of the proposed approach. The paper concludes with the main contributions, including the novel framework, lightweight generative model, domain gap narrowing, and competitive performance compared to state-of-the-art methods.