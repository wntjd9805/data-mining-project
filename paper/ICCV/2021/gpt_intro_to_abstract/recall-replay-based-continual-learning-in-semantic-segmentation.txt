Many machine learning applications require the ability to learn a sequence of tasks incrementally, rather than using a single-shot training procedure on a large dataset. This is especially important for image classification tasks, where introducing new classes can lead to forgetting of previous tasks and an inability to learn new ones. This phenomenon, known as catastrophic forgetting, occurs when the model is exposed to samples of novel classes without additional provisions. While methods have been proposed to mitigate forgetting in image classification, the problem of incremental learning on dense tasks, such as semantic segmentation, has only recently been explored. Initial studies have shown that catastrophic forgetting is even more severe in this context. Current approaches for class-incremental semantic segmentation rely on knowledge distillation strategies, but they often fail when multiple incremental steps are performed or when background shift occurs. In this paper, we propose a different strategy called RECALL (REplay in ContinuAL Learning) that uses replay data instead of knowledge distillation. We generate samples of old classes and mix them with the available training data, while using a self-inpainting strategy to reduce background shift. We explore two approaches for generating representations of past classes: using a pre-trained generative model conditioned to produce samples of an input class, or crawling images from the web based on class names. We also introduce a side labeling module to generate pseudo-labels for semantic segmentation. Our contributions include the first use of replay data in continual semantic segmentation, the introduction of the webly-supervised paradigm in continual learning, a background inpainting strategy to overcome background shift, and state-of-the-art results in a wide range of scenarios, particularly for multiple incremental steps.