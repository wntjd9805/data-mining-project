High dynamic range (HDR) photography has become popular among both professional and non-professional photographers. However, displaying HDR images on conventional devices requires a tone-mapping step to reduce their dynamic range. Different methods have been developed for tone-mapping, with early approaches focusing on global tone-reproduction curves (TRC) and more modern approaches focusing on preserving local contrasts. In this paper, we propose a new deep neural network (DNN)-based tone-mapping operator (TMO) that is trained to reproduce the visual characteristics of native low dynamic range (LDR) images. We use unsupervised adversarial training, incorporating several new steps and components including range compression, structure preservation, and an ensemble of discriminator networks. Our method efficiently produces artifact-free and natural-looking LDR renditions of challenging HDR scenes, outperforming established image quality metrics and visual distances.