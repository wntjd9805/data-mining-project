Recent advances in efficient convolutional neural network (CNN) architectures have significantly reduced the computational cost of ImageNet classification. However, when reducing the computational cost further, these architectures experience a significant performance degradation. In this paper, we aim to improve the accuracy at extremely low computational costs of 4M to 21M multiply-adds (MAdds). We address this challenge by focusing on node connectivity and non-linearity, which are related to network width and depth. Specifically, we propose a Micro-Factorized convolution (MF-Conv) to factorize pointwise convolutions and a new activation function called Dynamic Shift-Max (DY-Shift-Max) to enhance the representation power of the network. Using these novel operators, we develop a family of models called MicroNets, which outperform state-of-the-art efficient networks at low FLOP regimes. Our MicroNet models achieve higher accuracy than MobileNetV3 while using substantially less computational cost, making them suitable for fast inference on edge devices. Furthermore, MicroNet also surpasses MobileNetV3 on object detection and keypoint detection tasks.