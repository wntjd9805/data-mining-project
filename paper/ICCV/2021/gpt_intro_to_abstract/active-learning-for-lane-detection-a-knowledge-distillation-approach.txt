Lane detection is a crucial task for autonomous driving, and deep learning has shown great advances in improving its performance. However, deep models require a large amount of training data, which can be expensive and cumbersome to annotate. Active learning, a technique to reduce annotation cost, has been successful in image classification and object detection tasks but has not been effective in lane detection. The existing methods are hindered by two problems: unsuitable entropy metrics and label noise in lane annotations. In this paper, we propose an active learning method for lane detection that addresses these issues. We introduce Knowledge Distillation (KD) to explore uncertain samples and transfer useful knowledge from a teacher model to a student model. We also train an independent student model to distinguish noisy labels from hard-to-learn knowledge. To select informative data, we propose a novel uncertainty metric that captures both knowledge and noise. We also incorporate a diversity metric based on reverse nearest neighbors to address data redundancy. Our extensive experiments on benchmark datasets demonstrate that our method achieves state-of-the-art performance in lane detection and can be extended to other visual recognition tasks. Our contributions include the first active learning method for lane detection, a novel uncertainty metric, and a diversity metric that is effective and extendable to other tasks.