Gait recognition is a biometric technology that relies on the unique walking posture of individuals. It can be used in various fields such as video surveillance and intelligent transportation due to its ability to capture gait in long-distance conditions without requiring the subject's cooperation. However, the performance of gait recognition is hindered by challenges such as changing clothing, carrying conditions, cross-view, speed change, and resolution. To improve the performance of gait recognition in complex external environments, many existing methods utilize convolutional neural networks (CNNs) to generate gait feature representations. These feature representations can be categorized into global and local feature based representations. While global feature based methods extract gait features from entire gait frames, local feature based methods combine local gait features from specific parts of the gait. However, these methods solely rely on either global or local features, limiting their recognition performance. Additionally, traditional 3D CNNs are not able to handle videos of different lengths. In this paper, we propose a novel cross-view gait recognition framework that leverages both global and local features by introducing a new Global and Local Feature Extractor (GLFE) module in the 3D CNNs framework. We design a Global and Local Convolutional layer (GLConv) to extract global and local features in a principled manner. Our framework also utilizes a novel Local Temporal Aggregation (LTA) operation to preserve spatial information while aggregating temporal information. Experimental results on public datasets demonstrate the effectiveness of our proposed method in achieving state-of-the-art performance, particularly in complex conditions.