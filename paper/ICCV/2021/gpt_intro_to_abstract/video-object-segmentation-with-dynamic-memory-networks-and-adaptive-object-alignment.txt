Semi-supervised video object segmentation (VOS) is a task in computer vision that aims to distinguish target objects from their background in a video at the pixel level. This task is challenging due to the drastic changes in object appearances caused by object movements, camera movements, and occlusions. Two approaches have been explored in the VOS community: pixel matching based VOS (PVOS) and object matching based VOS (OVOS). While PVOS methods have achieved state-of-the-art performance by exploiting all past frames with memory networks, OVOS methods have not been able to surpass PVOS methods, mainly due to two challenges. Firstly, OVOS requires a specific memory module to store object features, which has not been addressed in existing methods. Secondly, the matching of object features between templates and proposals in OVOS is hampered by misalignments caused by object deformations across frames. To address these challenges, we propose a novel dynamic memory network and adaptive object alignment module for OVOS. The dynamic memory network utilizes memory of object features in past frames to generate dynamic object templates, allowing for accumulation of new object information. The adaptive object alignment module incorporates a non-local region translation function to align object proposals with templates. Our proposed OVOS framework outperforms all state-of-the-art PVOS methods, demonstrating its effectiveness in video object segmentation. Contributions of our work include the development of an easy-to-extend object-matching framework for the VOS task, the exploration of all frames in a video for OVOS using a dynamic memory network, and the introduction of an adaptive object alignment module to address misalignments.