Stereo depth estimation is an important task in computer vision as it allows for the reconstruction of 3D information. Recent deep learning approaches have shown promising results in stereo depth estimation, but there are still several challenges that need to be addressed. One such challenge is the limited disparity range that these approaches are constrained to. This fixed disparity range is necessary for memory feasibility but is not flexible to the properties of the physical scene and camera setup. Additionally, geometric properties and constraints such as occlusion and matching uniqueness are often missing from learning-based approaches. Occluded regions do not have a valid disparity, and prior algorithms infer disparities for these regions using a piece-wise smoothness assumption. It would be advantageous to provide a confidence estimate along with the disparity value to enable downstream analysis. Most existing approaches do not provide such information. Furthermore, pixels in one image should not be matched to multiple pixels in the other image, but many existing learning-based methods do not impose this constraint. These problems arise from the shortcomings of the contemporary view of stereo matching, which constructs a cost volume. To address these challenges, we propose a new end-to-end-trained stereo depth estimation network called STereo TRansformer (STTR). STTR computes pixel-wise correlation densely and does not construct a fixed-disparity cost volume, mitigating the drawbacks of contemporary approaches without compromising performance. We present technical advances in the form of a Transformer with alternating self- and cross-attentions combined with optimal transport theory for sparse feature matching, relative pixel distance encoding, and a memory-feasible implementation of STTR. Our experiments demonstrate competitive performance on synthetic and real image benchmarks, and we show that STTR trained only on synthetic images generalizes well to other domains.