Point cloud segmentation, an essential technique in 3D understanding, has made significant progress due to advanced network architectures and large-scale datasets. However, deep-learning-based methods for point cloud segmentation require a lot of training data with point-level annotations, leading to high annotation costs. To address this issue, this paper proposes an unsupervised method for point cloud co-segmentation, inspired by 2D image object co-segmentation. The method involves three components: a pair of competitive point samplers to tackle the unordered and unstructured nature of point clouds, a mutual attention module to capture cross-cloud point correlation, and a co-contrastive loss to derive the samplers and their associated attention modules. The proposed method is the first end-to-end trainable network for point cloud object co-segmentation and shows promising results on real datasets.