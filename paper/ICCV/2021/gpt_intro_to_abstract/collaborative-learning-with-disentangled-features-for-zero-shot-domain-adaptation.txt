Recent deep learning methods in computer vision have achieved success in tasks such as image classification, segmentation, and object detection. However, when the training data and testing data come from different domains, these deep-learned models often suffer from performance degradation due to domain shift. This problem is known as domain adaptation. In real-world applications, obtaining unlabeled target domain data that shares the same label space as the source domain data is often not feasible. This gives rise to a new transfer learning task called zero-shot domain adaptation (ZSDA). The objective of ZSDA is to transfer the domain shift from an irrelevant task to a task of interest. This paper proposes a novel approach for ZSDA that involves collaboratively learning class-agnostic domain feature representations and domain-invariant semantic feature representations. The proposed method includes two phases: disentanglement and refinement. In the disentanglement stage, class-agnostic domain features and domain-invariant features are simultaneously learned. In the refinement stage, a domain feature is transformed into a spatial attention map to emphasize the domain-specific salient parts of the domain-invariant semantic feature. The main contributions of this paper are: (1) an end-to-end framework for zero-shot domain adaptation that does not require any additional information or assumptions, (2) a collaborative feature refinement with disentangled feature representations to prevent negative transfer effects, and (3) state-of-the-art performance in extensive experiments on various benchmarks for zero-shot domain adaptation tasks.