Convolutional Neural Networks (CNNs) have achieved state-of-the-art performance in computer vision tasks, but their computational complexity and storage overhead can hinder their deployment in real-time applications. Quantization, which approximates weights and activations with lower bit-width representations, has emerged as a hardware-friendly approach to reduce storage consumption and inference latency. However, existing quantization methods often assign a uniform bit-width to all layers, which can lead to accuracy degradation and miss out on the benefits of emerging hardware accelerators that support mixed-precision computation. Mixed-precision quantization, which finds the optimal bit-width for each layer, is challenging due to the huge search space and the need for time-consuming performance evaluation. This paper introduces a novel and principled framework for mixed-precision quantization. It formulates the problem as a discrete constrained optimization and proposes an efficient method to compute the Hessian matrix for each layer. The problem is then reformulated as a Multiple-Choice Knapsack Problem (MCKP) and solved using a greedy search algorithm. Compared to existing approaches, the proposed method is computationally efficient, interpretable, and achieves a better trade-off between search-based and criterion-based methods. Extensive experiments on the ImageNet dataset and various network architectures demonstrate the superiority of the proposed method. The contributions of this paper include the formulation of mixed-precision quantization as a constrained optimization problem, the efficient computation of the Hessian matrix, and the demonstration of the efficiency and effectiveness of the proposed method through extensive experiments.