Instance image retrieval is a challenging task that aims to effectively identify images containing the same object or describing the same scene as the query image from a large image corpus. This task is particularly difficult due to various conditions observed in large-scale datasets, such as lighting variation, occlusion, and viewpoint changes. To address this challenge, many research efforts have focused on image representation using descriptive and discriminative local features. The extraction of local features involves local region detection and image patch description. While early methods used hand-crafted features, the introduction of deep learning in computer vision has led to significant progress in local feature learning. However, previous methods typically generate a single attention map to measure the significance of each deep local feature. This limitation fails to comprehensively capture all potential semantic patterns in an image. In this paper, we propose a novel framework with multiple dynamic attentions to detect diverse local features corresponding to different semantic patterns. Our approach uses intermediate feature maps from convolutional neural networks (CNNs) to generate attention maps and introduces a channel mapping layer to decouple different semantic patterns. We design a new dynamic attention module that ensures different attention heads focus on different patterns within the image. In the testing stage, we use these dynamic attention maps to select deep local features for image representation. Our approach achieves superior performance compared to existing state-of-the-art methods in instance image retrieval tasks on the Revisited Oxford and Paris datasets mixed with a million distractors. The effectiveness of the channel mapping layer, dynamic attention module, and diversity regularization loss are justified through ablation studies.