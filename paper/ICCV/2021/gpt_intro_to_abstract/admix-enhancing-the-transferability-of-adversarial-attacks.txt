Deep neural networks (DNNs) are susceptible to adversarial examples, which are maliciously crafted inputs that can induce misclassification. This vulnerability poses threats to security-sensitive applications and has led to extensive research on adversarial attacks. Adversarial examples also exhibit transferability across neural network models, which is concerning for real-world attacks. However, existing attacks have shown low transferability against models with defense mechanisms. To improve transferability, various techniques have been proposed, including input transformations. However, current methods only apply transformations on a single input image. This paper explores the idea of enhancing transferability by incorporating information from other categories during the adversarial attack process. The authors propose a novel attack method called Admix, which calculates the gradient on an admixed image combined with the original input and randomly selected images from other categories. The Admix attack achieves significantly higher success rates under black-box settings and maintains comparable performance under white-box settings compared to existing input transformations. When combined with other input transformations, the transferability of the crafted adversaries is further improved. Evaluation against advanced defense methods demonstrates that the final integrated method, Admix-TI-DIM, outperforms the state-of-the-art method by a clear margin, highlighting the effectiveness of Admix.