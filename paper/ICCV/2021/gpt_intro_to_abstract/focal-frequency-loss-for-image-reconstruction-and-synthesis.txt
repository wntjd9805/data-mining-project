In recent years, there has been significant progress in image reconstruction and synthesis using generative models and deep learning-based approaches. However, there are still gaps between real and generated images, resulting in discernible artifacts. These gaps can be observed in the form of artifacts or through frequency spectrum analysis. Studies in media forensics have identified periodic patterns in the frequency spectra of manipulated images, which may correspond to artifacts in the spatial domain. This paper explores the frequency domain gap between real and fake images and proposes a novel frequency-level objective function, called focal frequency loss, to narrow this gap. The proposed loss function optimizes generative models in the frequency domain by mapping spectrum coordinate values to Euclidean vectors and down-weighting easy frequencies using a dynamic spectrum weight matrix. Extensive experiments demonstrate the effectiveness of the proposed loss on various baselines and its potential to improve state-of-the-art models.