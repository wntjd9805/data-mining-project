Object recognition is a fundamental task in computer vision, but it remains challenging when objects undergo severe geometric deformations, such as scale, pose, and part variations. Recent methods address this issue by decomposing object variation into appearance and 2D spatial variation and removing spatial variation through warping. However, these methods do not consider the fact that object variation is also due to 3D shape and camera viewpoint changes. In this paper, we propose a method that estimates 3D object information, including shape, appearance, and camera viewpoint, in a canonical configuration. Our method allows for handling subtle intra-class variations by extracting both appearance and 3D shape features. We use a differentiable renderer to infer 3D shape, without the need for ground-truth 3D annotations. Our method disentangles object variation using an encoder-decoder architecture and incorporates multiple hypothesis camera prediction. Unlike conventional methods that focus on 2D spatial variation, our method reconfigures appearance features in a canonical space and enables dense semantic alignment. We also introduce a shape encoder to utilize 3D shape deformation as an additional cue. Our method improves representation learning and 3D shape reconstruction in fine-grained image recognition and vehicle re-identification tasks.