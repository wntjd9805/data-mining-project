Image composition is a crucial aspect of professional photography, involving the organization of visual elements. However, ordinary people often lack the skills and knowledge necessary to compose photos effectively. As a result, there is a growing demand for automatic composition techniques. One existing approach is image cropping, which aims to find the most aesthetically pleasing sub-region within an image. Traditionally, candidate views are ranked based on manually designed evaluation criteria, which may not align with users' preferences. More recently, data-driven methods have emerged, using convolutional models to predict scores based on region-aware features. However, these methods focus on the presence of visual elements rather than the organization or composition of those elements. In this paper, we argue that the harmony and organization of visual elements are key to good composition. We propose the TransView model, which leverages the transformer architecture to encode dependencies between visual elements. These dependencies, known as attraction and repulsion, capture the relationships and arrangements of the elements. Our experimental results demonstrate that TransView outperforms existing methods and effectively models attraction and repulsion without supervision. Furthermore, feature visualizations show that TransView can distinguish between similar views based on the explicit encoding of these dependencies.