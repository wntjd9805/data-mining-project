The field of lifespan face synthesis, which aims to synthesize a person's face throughout their entire life based on a single snapshot, has gained significant attention due to its applications in various areas such as cross-age face recognition and finding lost children. One of the main challenges in lifespan face synthesis is age editing, as aging is a complex transformation process that involves changes in both shape and texture of the face over time. While several models have been proposed in the past, none of them have successfully met the three requirements of being age-sensitive, identity-preserving, and reconfigurable. In this paper, we propose a novel lifespan face synthesis model that disentangles the latent face representation into shape, texture, and identity components. Our model utilizes conditional generative adversarial networks (GANs) and introduces feature transformation modules for shape and texture, as well as a regularization loss for shaping. Through extensive experiments, we demonstrate that our model outperforms existing alternatives in terms of meeting all three requirements and accurately synthesizing lifelike face images throughout the lifespan.