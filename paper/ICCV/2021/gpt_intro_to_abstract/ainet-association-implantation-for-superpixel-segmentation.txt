Superpixels are image regions formed by grouping similar pixels, which provide a more efficient representation for image data and improve the computational efficiency of vision algorithms. Superpixel segmentation plays a crucial role in various computer vision tasks. Traditional methods utilize hand-crafted features and clustering or graph-based methods for membership estimation, but these suffer from the limitations of hand-crafted features and are difficult to integrate into deep learning frameworks. Recently, deep learning techniques have been applied to superpixel segmentation, but previous methods introduce noise by incorporating low-level features with skip connections. To address this issue, we propose an Association Implantation (AI) module that directly implants grid features to the surrounding of each pixel. This module captures the relationship between pixels and their neighboring grid cells, providing the necessary context for superpixel segmentation. Our AI module simplifies the process and allows the network to explicitly perceive the context between pixels and neighboring grids. Additionally, we propose a boundary-perceiving loss that enhances the discrimination of features around boundaries. This encourages the model to pay more attention to boundary pixels, resulting in improved boundary precision. Quantitative and qualitative results on BSDS500 and NYUv2 datasets show that our method outperforms state-of-the-art superpixel segmentation methods. In summary, our contributions include the proposal of the AI module, which captures the pixel-grid relationship, and the design of a boundary-perceiving loss, which improves boundary precision in superpixel segmentation.