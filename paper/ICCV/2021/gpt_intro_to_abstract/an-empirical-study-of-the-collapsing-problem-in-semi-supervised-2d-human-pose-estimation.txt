2D human pose estimation has many practical applications, such as 3D pose modeling and action recognition. Deep learning methods for pose estimation have evolved from directly regressing joint coordinates from images to adopting a heatmap-based framework for better supervision. However, a significant problem that remains less explored is learning robust models that perform well on unseen wild images. Two possible solutions are to increase training images infinitely or to transfer pre-trained models to new domains by unsupervised fine-tuning. Semi-Supervised Learning (SSL) plays a crucial role in both approaches, leveraging unlabeled images to obtain a generalizable model. Previous SSL works have primarily focused on the classification task, with strategies such as pseudo-labeling and similar predictions for augmentations. However, these approaches encounter the collapsing problem in 2D pose estimation, where models start predicting every pixel in unlabeled images as background, leading to decreased accuracy. This issue is critical for tasks like human pose estimation, known for severe class imbalance. To address this problem, this work proposes a simple approach using easy-hard augmentation pairs, wherein a network should achieve better accuracy on a dataset with easy augmentation compared to hard augmentation. By teaching the network using accurate predictions on the easy augmentation, the collapsing problem can be avoided. This approach is evaluated on multiple public datasets, and it significantly improves pose estimation performance when the number of labeled images is small. It also shows promising results in semi-supervised pre-training and domain adaptation tasks, making it a valuable contribution to various practical applications.