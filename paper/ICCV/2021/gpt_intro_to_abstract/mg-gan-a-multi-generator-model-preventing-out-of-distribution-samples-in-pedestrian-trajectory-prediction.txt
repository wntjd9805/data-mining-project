To address the challenge of predicting human motion in crowded scenes, this paper focuses on the use of conditional generative adversarial networks (GANs) to learn a distribution over trajectories. While these GAN methods have shown improvement over deterministic models, they still suffer from mode collapse and the prediction of undesired out-of-distribution (OOD) samples, resulting in non-realistic trajectories. This becomes problematic in scenarios such as autonomous vehicles interacting with pedestrians, where accurate predictions are crucial for safety. To understand the production of OOD samples in GANs, the underlying geometry of the problem is examined. It is observed that the trajectory distribution consists of several disconnected modes, each representing different plausible paths. Existing GAN models fail to consider this property and generate OOD samples in between modes. This is attributed to the inability of single-generator GANs to learn a mapping from a continuous latent space to a disconnected, multimodal target distribution.To address this issue, the paper proposes a novel multi-generator GAN that treats the multimodal target distribution as a mixture of multiple continuous trajectory distributions. Each mode is optimized using a separate generator, allowing for better representation of the disconnected modes. Unlike previous multi-generator models, this approach adapts to different scenes by using a fixed number of generators and learning the necessary number of modes directly from visual scene information. The paper also introduces a second module that estimates the categorical probability distribution over the individual generators, conditioned on the input observations. During testing, a specific generator is selected based on its categorical probability, and trajectories specialized to that particular mode are generated. The quality of predictions is measured using precision and recall metrics, in addition to traditional L2 error measures.The experimental evaluation shows that the proposed multi-generator GAN outperforms state-of-the-art and single-generator methods in predicting OOD samples. The main contributions of this paper are: (i) the identification of limitations in single-generator GANs, (ii) the proposal of a multi-generator method for learning a multimodal distribution over trajectories, and (iii) the introduction of recall and precision metrics for evaluating the quality of the predictive distribution. Extensive ablations demonstrate the efficiency and robustness of the proposed method. The source code for the model and experiments is available online.