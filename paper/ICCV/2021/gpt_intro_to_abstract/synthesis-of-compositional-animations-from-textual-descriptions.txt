Abstract:Creating realistic animation of humans performing complex motions is a challenging task. Motion synthesis based on textual descriptions has various applications, such as robotics task planning, instructional videos, and visualizing movie scripts. However, mapping natural language text descriptions to 3D pose sequences for human motions is non-trivial, especially for complex sentences that describe multiple sequential or simultaneous actions. Existing text-to-motion mapping methods fail to handle long-range dependencies and correlations in complex sentences and do not generalize well to motions beyond locomotion.In this paper, we propose a hierarchical, two-stream, sequential network that can synthesize 3D pose sequences of human motions from complex textual descriptions. Our method separates the intermediate pose embeddings into upper body and lower body embeddings, and hierarchically decomposes them into limb embeddings to capture semantic variations in the sentence. We introduce a sequential two-stream network with an autoencoder architecture to focus on different parts of the body and generate representations for the upper and lower body poses separately, improving the robustness of the synthesized motion. We utilize the state-of-the-art BERT model with handpicked word feature embeddings to enhance text understanding. Additionally, we incorporate additional loss terms and a pose discriminator to improve the learning and plausibility of the synthesized motions.Experimental results demonstrate that our method outperforms baseline methods significantly in both quantitative metrics and qualitative evaluations. Our approach contributes to the practical applicability of text-based motion synthesis systems and enables the generation of realistic motions from complex textual descriptions.