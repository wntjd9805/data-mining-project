Finetuning from ImageNet supervised pre-training networks for downstream tasks is a popular approach in computer vision. Self-supervised contrastive learning has emerged as a promising alternative, acquiring positive and negative pairs through data augmentation. However, existing data augmentation methods lack interpretability and may not guarantee effectiveness. In this paper, we propose a visualization tool to analyze score distributions and gain insights into the model's performance. We observe that smaller positive scores indicate larger view variance and better performance. Inspired by this, we introduce an extrapolation operation on positive pairs to increase view variance and acquire "hard positives." Additionally, we propose random interpolation among negatives to provide diversified negatives for improved discriminability. Our feature transformation reshapes the feature distribution without additional training examples, making the model less task-biased. Experimental results demonstrate the effectiveness of our approach on various downstream tasks and achieve state-of-the-art performance. Our visualization tool and feature transformation are generic and applicable to different self-supervised contrastive learning methods. Overall, our contributions include the visualization tool, the effective feature transformation, and the improved model performance.