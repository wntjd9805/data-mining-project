In this paper, we address the question of how humans are able to quickly acquire concepts through contrasting and comparing new sensory inputs with previous experiences. We propose a self-supervised learning method called Nearest-Neighbour Contrastive Learning of visual Representations (NNCLR) that goes beyond single instance positives in instance discrimination tasks. Unlike current methods that rely on random augmentations, NNCLR utilizes a support set to find nearest neighbors in the learned representation space as positives. We make several contributions: introducing NNCLR, showing its performance improvement in contrastive learning methods, achieving state-of-the-art performance in ImageNet classification, outperforming existing methods in transfer learning tasks, and reducing reliance on data augmentation strategies. Our results demonstrate the significance of considering similarities across items for better self-supervised representation learning.