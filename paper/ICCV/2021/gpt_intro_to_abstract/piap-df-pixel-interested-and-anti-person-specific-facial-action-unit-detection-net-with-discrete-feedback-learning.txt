Facial expression plays a crucial role in human communication and emotion recognition tasks. Microexpressions, which are rapid and involuntary facial movements, are of particular interest in various domains such as diagnosing depression and analyzing criminal conversations. The Facial Action Coding System (FACS) is commonly used to detect microexpressions, but it relies on local information and precise annotation of facial regions. Deep learning methods have shown promise in facial expression detection, but they often suffer from limited generalization due to the small number of participants in existing datasets. To address these limitations, this paper introduces PIAP-DF, a comprehensive approach for AU detection networks. PIAP combines Pixel-Interested (PI) learning, which captures local information and pixel-level correlations, and Anti Person-Specific (AP) learning, which removes person-specific features. Additionally, the paper proposes a semi-supervised learning strategy called Discrete Feedback (DF) to improve network robustness. The proposed method utilizes an EfficientNet-B1 as the AU encoder and can be adapted for real-world scenarios. The main contributions of this paper include the introduction of Pixel-Interested and Anti Person-Specific learning methods, as well as a semi-supervised learning strategy with discrete feedback. These techniques aim to improve the performance and generalization ability of AU detection networks.