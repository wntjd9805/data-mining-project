With the increasing use of neural networks, the vulnerability of these networks to adversarial examples has become a major concern. Adversarial examples refer to imperceptible perturbations in the input data that can cause the neural network to make incorrect predictions. This can have serious consequences, such as face recognition technology being tricked into recognizing the wrong person for payment purposes. Adversarial attacks and defenses are two complementary aspects in addressing this issue. Previous research has focused on improving the success rate of attacks against white-box models, where the attacker has access to model parameters. However, in real-world scenarios, attackers often lack information about the target model, resulting in black-box attacks. Strategies have been developed to leverage the transferability of adversarial examples to conduct black-box attacks with limited success due to the differences between white-box and black-box models. In this paper, we propose a novel architecture called Meta Gradient Adversarial Attack (MGAA), which incorporates the principles of meta-learning. The main idea behind MGAA is to iteratively simulate white-box and black-box attacks to improve the transferability of adversarial examples. In each iteration, multiple models are randomly sampled to compose a task. The meta-train step uses an ensemble of models to simulate a white-box attack and generate temporary adversarial examples, which are then used as a basis for the meta-test step to simulate a black-box attack and obtain the perturbations. The perturbations obtained are added to the adversarial examples from the previous iteration. Through theoretical analyses, we demonstrate that MGAA narrows the gap between white-box and black-box attack gradient directions, thereby improving the transferability of adversarial examples. Unlike traditional meta-learning methods that enhance generalization through model training, MGAA directly utilizes gradient information to improve transferability without the need for an extra model. Our experiments on the CIFAR10 and ImageNet datasets show that MGAA significantly improves the success rates of white-box and black-box attacks. When integrated with the TI-DIM method, our architecture achieves a substantial increase in attack success rates on ImageNet, demonstrating its superiority. The main contributions of this paper are the proposed Meta Gradient Adversarial Attack architecture, which iteratively simulates white-box and black-box attacks to improve transferability, the plug-and-play compatibility of our architecture with existing gradient-based attack methods, and extensive experiments showing significant improvements in attack success rates under both white-box and black-box settings.