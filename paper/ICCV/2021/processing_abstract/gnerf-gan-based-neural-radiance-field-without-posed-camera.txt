We introduce GNeRF, a framework to marry GenerativeAdversarial Networks (GAN) with Neural Radiance Field (NeRF) reconstruction for the complex scenarios with un-known and even randomly initialized camera poses. RecentNeRF-based advances have gained popularity for remark-able realistic novel view synthesis. However, most of them heavily rely on accurate camera poses estimation, while few recent methods can only optimize the unknown camera poses in roughly forward-facing scenes with relatively short camera trajectories and require rough camera poses initial-ization. Differently, our GNeRF only utilizes randomly ini-tialized poses for complex outside-in scenarios. We propose a novel two-phases end-to-end framework. The first phase takes the use of GANs into the new realm for optimizing coarse camera poses and radiance fields jointly, while the second phase refines them with additional photometric loss.We overcome local minima using a hybrid and iterative op-timization scheme. Extensive experiments on a variety of synthetic and natural scenes demonstrate the effectiveness of GNeRF. More impressively, our approach outperforms the baselines favorably in those scenes with repeated pat-terns or even low textures that are regarded as extremely challenging before. 