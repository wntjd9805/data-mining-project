Reconstructing 3D shape from 2D sketches has long been an open problem because the sketches only provide very sparse and ambiguous information. In this paper, we use an encoder/decoder architecture for the sketch to mesh translation. When integrated into a user interface that pro-vides camera parameters for the sketches, this enables us to leverage its latent parametrization to represent and reﬁne a 3D mesh so that its projections match the external contours outlined in the sketch. We will show that this approach is easy to deploy, robust to style changes, and effective. Fur-thermore, it can be used for shape reﬁnement given only single pen strokes.We compare our approach to state-of-the-art methods on sketches—both hand-drawn and synthesized—and demon-strate that we outperform them. 