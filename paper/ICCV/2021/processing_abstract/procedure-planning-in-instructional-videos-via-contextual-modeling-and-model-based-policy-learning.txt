Learning new skills by observing humans’ behaviors is an essential capability of AI. In this work, we leverage in-structional videos to study humans’ decision-making pro-cesses, focusing on learning a model to plan goal-directed actions in real-life videos. In contrast to conventional ac-tion recognition, goal-directed actions are based on expec-tations of their outcomes requiring causal knowledge of po-tential consequences of actions. Thus, integrating the en-vironment structure with goals is critical for solving this task. Previous works learn a single world model will fail to distinguish various tasks, resulting in an ambiguous la-tent space; planning through it will gradually neglect the desired outcomes since the global information of the future goal degrades quickly as the procedure evolves. We address these limitations with a new formulation of procedure plan-ning and propose novel algorithms to model human behav-iors through Bayesian Inference and model-based ImitationLearning. Experiments conducted on real-world instruc-tional videos show that our method can achieve state-of-the-art performance in reaching the indicated goals. Fur-thermore, the learned contextual information presents in-teresting features for planning in a latent space. 