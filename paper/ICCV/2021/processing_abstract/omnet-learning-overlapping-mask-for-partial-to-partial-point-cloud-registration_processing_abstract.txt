Point cloud registration is a key task in many compu-tational fields. Previous correspondence matching based methods require the inputs to have distinctive geometric structures to fit a 3D rigid transformation according to point-wise sparse feature matches. However, the accuracy of transformation heavily relies on the quality of extracted features, which are prone to errors with respect to partial-ity and noise. In addition, they can not utilize the geomet-ric knowledge of all the overlapping regions. On the other hand, previous global feature based approaches can utilize the entire point cloud for the registration, however they ig-nore the negative effect of non-overlapping points when ag-gregating global features. In this paper, we present OM-Net, a global feature based iterative network for partial-to-partial point cloud registration. We learn overlapping masks to reject non-overlapping regions, which converts the partial-to-partial registration to the registration of the same shape. Moreover, the previously used data is sampled only once from the CAD models for each object, resulting in the same point clouds for the source and reference. We propose a more practical manner of data generation where a CAD model is sampled twice for the source and reference, avoid-ing the previously prevalent over-fitting issue. Experimental results show that our method achieves state-of-the-art per-formance compared to traditional and deep learning based methods. Code is available at https://github.com/megvii-research/OMNet. 