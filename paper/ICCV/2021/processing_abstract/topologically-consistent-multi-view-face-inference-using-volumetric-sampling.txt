High-fidelity face digitization solutions often combine multi-view stereo (MVS) techniques for 3D reconstruction and a non-rigid registration step to establish dense corre-spondence across identities and expressions. A common problem is the need for manual clean-up after the MVS step, as 3D scans are typically affected by noise and outliers and contain hairy surface regions that need to be cleaned up by artists. Furthermore, mesh registration tends to fail for extreme facial expressions. Most learning-based meth-ods use an underlying 3D morphable model (3DMM) to ensure robustness, but this limits the output accuracy for extreme facial expressions.In addition, the global bot-tleneck of regression architectures cannot produce meshes that tightly fit the ground truth surfaces. We propose ToFu,Topological consistent Face from multi-view, a geometry inference framework that can produce topologically con-sistent meshes across facial identities and expressions us-ing a volumetric representation instead of an explicit un-derlying 3DMM. Our novel progressive mesh generation network embeds the topological structure of the face in a feature volume, sampled from geometry-aware local fea-tures. A coarse-to-fine architecture facilitates dense and accurate facial mesh predictions in a consistent mesh topol-ogy. ToFu further captures displacement maps for pore-level geometric details and facilitates high-quality render-ing in the form of albedo and specular reflectance maps.These high-quality assets are readily usable by production studios for avatar creation, animation and physically-based skin rendering. We demonstrate state-of-the-art geometric and correspondence accuracy , while only taking 0.385 sec-onds to compute a mesh with 10K vertices, which is three orders of magnitude faster than traditional techniques. The code and the model are available for research purposes at https://tianyeli.github.io/tofu. 