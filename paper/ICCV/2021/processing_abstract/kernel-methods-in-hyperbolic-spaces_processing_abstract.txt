Embedding data in hyperbolic spaces has proven ben-eﬁcial for many advanced machine learning applications such as image classiﬁcation and word embeddings. How-ever, working in hyperbolic spaces is not without difﬁcul-ties as a result of its curved geometry (e.g., computing theFrechet mean of a set of points requires an iterative algo-rithm). Furthermore, in Euclidean spaces, one can resort to kernel machines that not only enjoy rich theoretical prop-erties but that can also lead to superior representational power (e.g., inﬁnite-width neural networks). In this paper, we introduce positive deﬁnite kernel functions for hyper-bolic spaces. This brings in two major advantages, 1. ker-nelization will pave the way to seamlessly beneﬁt from ker-nel machines in conjunction with hyperbolic embeddings, and 2. the rich structure of the Hilbert spaces associated with kernel machines enables us to simplify various opera-tions involving hyperbolic data. That said, identifying valid kernel functions on curved spaces is not straightforward and is indeed considered an open problem in the learning community. Our work addresses this gap and develops sev-eral valid positive deﬁnite kernels in hyperbolic spaces, in-cluding the universal ones (e.g., RBF). We comprehensively study the proposed kernels on a variety of challenging tasks including few-shot learning, zero-shot learning, person re-identiﬁcation and knowledge distillation, showing the supe-riority of the kernelization for hyperbolic representations. 