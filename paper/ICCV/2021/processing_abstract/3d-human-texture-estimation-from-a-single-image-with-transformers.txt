We propose a Transformer-based framework for 3D hu-man texture estimation from a single image. The proposedTransformer is able to effectively exploit the global infor-mation of the input image, overcoming the limitations of existing methods that are solely based on convolutional neural networks.In addition, we also propose a mask-fusion strategy to combine the advantages of the RGB-based and texture-flow-based models. We further intro-duce a part-style loss to help reconstruct high-fidelity col-ors without introducing unpleasant artifacts. Extensive ex-periments demonstrate the effectiveness of the proposed method against state-of-the-art 3D human texture estima-tion approaches both quantitatively and qualitatively. The project page is at https://www.mmlab-ntu.com/ project/texformer. 