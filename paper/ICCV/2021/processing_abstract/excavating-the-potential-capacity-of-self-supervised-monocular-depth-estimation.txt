Self-supervised methods play an increasingly important role in monocular depth estimation due to their great poten-tial and low annotation cost. To close the gap with super-vised methods, recent works take advantage of extra con-straints, e.g., semantic segmentation. However, these meth-ods will inevitably increase the burden on the model. In this paper, we show theoretical and empirical evidence that the potential capacity of self-supervised monocular depth esti-mation can be excavated without increasing this cost. In particular, we propose (1) a novel data augmentation ap-proach called data grafting, which forces the model to ex-plore more cues to infer depth besides the vertical image po-sition, (2) an exploratory self-distillation loss, which is su-pervised by the self-distillation label generated by our new post-processing method - selective post-processing, and (3) the full-scale network, designed to endow the encoder with the specialization of depth estimation task and enhance the representational power of the model. Extensive experiments show that our contributions can bring signiÔ¨Åcant perfor-mance improvement to the baseline with even less compu-tational overhead, and our model, named EPCDepth, sur-passes the previous state-of-the-art methods even those su-pervised by additional constraints. Code is available at https://github.com/prstrive/EPCDepth. 