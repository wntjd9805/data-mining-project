Self-supervised depth estimation for indoor environ-ments is more challenging than its outdoor counterpart in at least the following two aspects: (i) the depth range of in-door sequences varies a lot across different frames, making it difficult for the depth network to induce consistent depth cues, whereas the maximum distance in outdoor scenes mostly stays the same as the camera usually sees the sky; (ii) the indoor sequences contain much more rotational mo-tions, which cause difficulties for the pose network, while the motions of outdoor sequences are pre-dominantly trans-lational, especially for driving datasets such as KITTI. In this paper, special considerations are given to those chal-lenges and a set of good practices are consolidated for improving the performance of self-supervised monocular depth estimation in indoor environments. The proposed method mainly consists of two novel modules, i.e., a depth factorization module and a residual pose estimation mod-ule, each of which is designed to respectively tackle the aforementioned challenges. The effectiveness of each mod-ule is shown through a carefully conducted ablation study and the demonstration of the state-of-the-art performance on three indoor datasets, i.e., EuRoC, NYUv2 and 7-Scenes. 