A major challenge in DeepFake forgery detection is that state-of-the-art algorithms are mostly trained to detect a speciﬁc fake method. As a result, these approaches show poor generalization across different types of facial manip-ulations, e.g., from face swapping to facial reenactment.To this end, we introduce ID-Reveal, a new approach that learns temporal facial features, speciﬁc of how a person moves while talking, by means of metric learning coupled with an adversarial training strategy. The advantage is that we do not need any training data of fakes, but only train on real videos. Moreover, we utilize high-level semantic fea-tures, which enables robustness to widespread and disrup-tive forms of post-processing. We perform a thorough exper-imental analysis on several publicly available benchmarks.Compared to state of the art, our method improves gener-alization and is more robust to low-quality videos, that are usually spread over social networks. In particular, we ob-tain an average improvement of more than 15% in terms of accuracy for facial reenactment on high compressed videos. 