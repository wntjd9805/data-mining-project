Although recent research has witnessed a significant progress on the video deblurring task, these methods strug-gle to reconcile inference efficiency and visual quality si-multaneously, especially on ultra-high-definition (UHD) videos (e.g., 4K resolution). To address the problem, we propose a novel deep model for fast and accurate UHDVideo Deblurring (UHDVD). The proposed UHDVD is achieved by a separable-patch architecture, which collab-orates with a multi-scale integration scheme to achieve a large receptive field without adding the number of generic convolutional layers and kernels. Additionally, we design a residual channel-spatial attention (RCSA) module to im-prove accuracy and reduce the depth of the network appro-priately. The proposed UHDVD is the first real-time de-blurring model for 4K videos at 35 fps. To train the pro-posed model, we build a new dataset comprised of 4K blurry videos and corresponding sharp frames using three differ-ent smartphones. Comprehensive experimental results show that our network performs favorably against the state-of-the-art methods on both the 4K dataset and public bench-marks in terms of accuracy, speed, and model size. 