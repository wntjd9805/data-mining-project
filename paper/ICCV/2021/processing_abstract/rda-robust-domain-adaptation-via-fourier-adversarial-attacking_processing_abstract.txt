w/o FAA w/ FAAUnsupervised domain adaptation (UDA) involves a su-pervised loss in a labeled source domain and an unsuper-vised loss in an unlabeled target domain, which often faces more severe overﬁtting (than classical supervised learning) as the supervised source loss has clear domain gap and the unsupervised target loss is often noisy due to the lack of annotations. This paper presents RDA, a robust domain adaptation technique that introduces adversarial attacking to mitigate overﬁtting in UDA. We achieve robust domain adaptation by a novel Fourier adversarial attacking (FAA) method that allows large magnitude of perturbation noises but has minimal modiﬁcation of image semantics, the for-mer is critical to the effectiveness of its generated adversar-ial samples due to the existence of ‘domain gaps’. Speciﬁ-cally, FAA decomposes images into multiple frequency com-ponents (FCs) and generates adversarial samples by just perturbating certain FCs that capture little semantic in-formation. With FAA-generated samples, the training can continue the ‘random walk’ and drift into an area with aﬂat loss landscape, leading to more robust domain adapta-tion. Extensive experiments over multiple domain adapta-tion tasks show that RDA can work with different computer vision tasks with superior performance. 