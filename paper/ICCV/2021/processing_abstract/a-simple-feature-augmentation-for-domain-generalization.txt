The topical domain generalization (DG) problem asks trained models to perform well on an unseen target domain with different data statistics from the source training do-mains. In computer vision, data augmentation has proven one of the most effective ways of better exploiting the source data to improve domain generalization. However, existing approaches primarily rely on image-space data augmenta-tion, which requires careful augmentation design, and pro-vides limited diversity of augmented data. We argue that feature augmentation is a more promising direction for DG.We find that an extremely simple technique of perturbing the feature embedding with Gaussian noise during train-ing leads to a classifier with domain-generalization perfor-mance comparable to existing state of the art. To model more meaningful statistics reflective of cross-domain vari-ability, we further estimate the full class-conditional feature covariance matrix iteratively during training. Subsequent joint stochastic feature augmentation provides an effective domain randomization method, perturbing features in the directions of intra-class/cross-domain variability. We verify our proposed method on three standard domain generaliza-tion benchmarks, Digit-DG, VLCS and PACS, and show it is outperforming or comparable to the state of the art in all setups, together with experimental analysis to illustrate how our method works towards training a robust generalisable model. 