Dynamic interacting systems are prevalent in vision tasks. These interactions are usually difÔ¨Åcult to observe and measure directly, and yet understanding latent interac-tions is essential for performing inference tasks on dynamic systems like forecasting. Neural relational inference (NRI) techniques are thus introduced to explicitly estimate inter-pretable relations between the entities in the system for tra-jectory prediction. However, NRI assumes static relations; thus, dynamic neural relational inference (DNRI) was pro-posed to handle dynamic relations using LSTM. Unfortu-nately, the older information will be washed away when theLSTM updates the latent variable as a whole, which is whyDNRI struggles with modeling long-term dependences and forecasting long sequences. This motivates us to propose a memory-augmented dynamic neural relational inference method, which maintains two associative memory pools: one for the interactive relations and the other for the in-dividual entities. The two memory pools help retain use-ful relation features and node features for the estimation in the future steps. Our model dynamically estimates the rela-tions by learning better embeddings and utilizing the long-range information stored in the memory. With the novel memory modules and customized structures, our memory-augmented DNRI can update and access the memory adap-tively as required. The memory pools also serve as global latent variables across time to maintain detailed long-term temporal relations readily available for other components to use. Experiments on synthetic and real-world datasets show the effectiveness of the proposed method on modeling dynamic relations and forecasting complex trajectories. 