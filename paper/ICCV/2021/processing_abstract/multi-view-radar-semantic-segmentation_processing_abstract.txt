Understanding the scene around the ego-vehicle is key to assisted and autonomous driving. Nowadays, this is mostly conducted using cameras and laser scanners, de-spite their reduced performance in adverse weather con-ditions. Automotive radars are low-cost active sensors that measure properties of surrounding objects, including their relative speed, and have the key advantage of not being im-pacted by rain, snow or fog. However, they are seldom used for scene understanding due to the size and complexity of radar raw data and the lack of annotated datasets. For-tunately, recent open-sourced datasets have opened up re-search on classification, object detection and semantic seg-mentation with raw radar signals using end-to-end train-able models.In this work, we propose several novel ar-chitectures, and their associated losses, which analyse mul-tiple “views” of the range-angle-Doppler radar tensor to segment it semantically. Experiments conducted on the re-cent CARRADA dataset demonstrate that our best model outperforms alternative models, derived either from the se-mantic segmentation of natural images or from radar scene understanding, while requiring significantly fewer param-eters. Both our code and trained models are available at https://github.com/valeoai/MVRSS. 