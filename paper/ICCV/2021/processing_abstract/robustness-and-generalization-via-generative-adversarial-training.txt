While deep neural networks have achieved remarkable success in various computer vision tasks, they often fail to generalize to new domains and subtle variations of input images. Several defenses have been proposed to improve the robustness against these variations. However, current defenses can only withstand the speciﬁc attack used in train-ing, and the models often remain vulnerable to other input variations. Moreover, these methods often degrade perfor-mance of the model on clean images and do not generalize to out-of-domain samples. In this paper we present Gener-ative Adversarial Training, an approach to simultaneously improve the model’s generalization to the test set and out-of-domain samples as well as its robustness to unseen ad-versarial attacks. Instead of altering a low-level pre-deﬁned aspect of images, we generate a spectrum of low-level, mid-level and high-level changes using generative models with a disentangled latent space. Adversarial training with these examples enable the model to withstand a wide range of attacks by observing a variety of input alterations during training. We show that our approach not only improves per-formance of the model on clean images and out-of-domain samples but also makes it robust against unforeseen attacks and outperforms prior work. We validate effectiveness of our method by demonstrating results on various tasks such as classiﬁcation, segmentation and object detection. 