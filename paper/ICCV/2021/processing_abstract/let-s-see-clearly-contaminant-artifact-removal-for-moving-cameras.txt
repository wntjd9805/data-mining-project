Contaminants such as dust, dirt and moisture adhering to the camera lens can greatly affect the quality and clar-ity of the resulting image or video. In this paper, we pro-pose a video restoration method to automatically remove these contaminants and produce a clean video. Our ap-proach first seeks to detect attention maps that indicate the regions that need to be restored. In order to leverage the corresponding clean pixels from adjacent frames, we pro-pose a flow completion module to hallucinate the flow of the background scene to the attention regions degraded by the contaminants. Guided by the attention maps and com-pleted flows, we propose a recurrent technique to restore the input frame by fetching clean pixels from adjacent frames.Finally, a multi-frame processing stage is used to further process the entire video sequence in order to enforce tempo-ral consistency. The entire network is trained on a synthetic dataset that approximates the physical lighting properties of contaminant artifacts. This new dataset and our novel framework lead to our method that is able to address differ-ent contaminants and outperforms competitive restoration approaches both qualitatively and quantitatively. 