PointGoal Navigation (Habitat+Gibson)Furniture Moving (AI2-THOR) 3 vs. 1 with Keeper (Google Football)While deep reinforcement learning (RL) promises free-dom from hand-labeled data, great successes, especially for Embodied AI, require signiﬁcant work to create supervi-sion via carefully shaped rewards. Indeed, without shaped rewards, i.e., with only terminal rewards, present-day Em-bodied AI results degrade signiﬁcantly across Embodied AI problems from single-agent Habitat-based PointGoal Navi-gation (SPL drops from 55 to 0) and two-agent AI2-THOR-based Furniture Moving (success drops from 58% to 1%) to three-agent Google Football-based 3 vs. 1 with Keeper (game score drops from 0.6 to 0.1). As training from shaped rewards doesn’t scale to more realistic tasks, the commu-nity needs to improve the success of training with termi-nal rewards. For this we propose GRIDTOPIX: 1) train agents with terminal rewards in gridworlds that generically mirror Embodied AI environments, i.e., they are indepen-dent of the task; 2) distill the learned policy into agents that reside in complex visual worlds. Despite learning from only terminal rewards with identical models and RL algo-rithms, GRIDTOPIX signiﬁcantly improves results across tasks: from PointGoal Navigation (SPL improves from 0 to 64) and Furniture Moving (success improves from 1% to 25%) to football gameplay (game score improves from 0.1 to 0.6). GRIDTOPIX even helps to improve the results of shaped reward training. 