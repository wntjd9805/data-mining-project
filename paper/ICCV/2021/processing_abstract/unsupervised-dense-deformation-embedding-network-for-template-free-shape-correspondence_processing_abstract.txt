Shape correspondence from 3D deformation learning has attracted appealing academy interests recently. Nev-ertheless, current deep learning based methods require the supervision of dense annotations to learn per-point trans-lations, which severely over-parameterize the deformation process. Moreover, they fail to capture local geometric de-tails of original shape via global feature embedding. To address these challenges, we develop a new UnsupervisedDense Deformation Embedding Network (i.e., UD2E-Net), which learns to predict deformations between non-rigid shapes from dense local features. Since it is non-trivial to match deformation-variant local features for deformation prediction, we develop an Extrinsic-Intrinsic Autoencoder to first encode extrinsic geometric features from source into intrinsic coordinates in a shared canonical shape, with which the decoder then synthesizes corresponding target features. Moreover, a bounded maximum mean discrep-ancy loss is developed to mitigate the distribution diver-gence between the synthesized and original features. To learn natural deformation without dense supervision, we introduce a coarse parameterized deformation graph, for which a novel trace and propagation algorithm is proposed to improve both the quality and efficiency of the deforma-tion. Our UD2E-Net outperforms state-of-the-art unsuper-vised methods by 24% on Faust Inter challenge and even supervised methods by 13% on Faust Intra challenge. 