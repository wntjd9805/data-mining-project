Recently, video deblurring has attracted considerable research attention, and several works suggest that events at high time rate can beneﬁt deblurring. Existing video deblurring methods assume consecutively blurry frames, while neglecting the fact that sharp frames usually appearIn this paper, we develop a princi-nearby blurry frame. pled framework D2Nets for video deblurring to exploit non-consecutively blurry frames, and propose a ﬂexible event fu-sion module (EFM) to bridge the gap between event-driven and video deblurring. In D2Nets, we propose to ﬁrst de-tect nearest sharp frames (NSFs) using a bidirectional LST-M detector, and then perform deblurring guided by NSFs.Furthermore, the proposed EFM is ﬂexible to be incorpo-rated into D2Nets, in which events can be leveraged to no-tably boost the deblurring performance. EFM can also be easily incorporated into existing deblurring networks, mak-ing event-driven deblurring task beneﬁt from state-of-the-art deblurring methods. On synthetic and real-world blurry datasets, our methods achieve better results than competing methods, and EFM not only beneﬁts D2Nets but also signif-icantly improves the competing deblurring networks. 