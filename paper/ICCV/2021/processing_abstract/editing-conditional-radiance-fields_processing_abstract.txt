A neural radiance ﬁeld (NeRF) is a scene model support-ing high-quality view synthesis, optimized per scene. In this paper, we explore enabling user editing of a category-levelNeRF – also known as a conditional radiance ﬁeld – trained on a shape category. Speciﬁcally, we introduce a method for propagating coarse 2D user scribbles to the 3D space, to modify the color or shape of a local region. First, we propose a conditional radiance ﬁeld that incorporates new modular network components, including a shape branch that is shared across object instances. Observing multiple instances of the same category, our model learns underlying part semantics without any supervision, thereby allowing the propagation of coarse 2D user scribbles to the entire 3D region (e.g., chair seat). Next, we propose a hybrid network update strategy that targets speciﬁc network components, which balances efﬁciency and accuracy. During user interaction, we formu-late an optimization problem that both satisﬁes the user’s constraints and preserves the original object structure. We demonstrate our editing approach on rendered views of three shape datasets and show that it outperforms prior neural editing approaches. Finally, we edit the appearance and shape of a single-view real photograph and show that the edit propagates to extrapolated novel views. 