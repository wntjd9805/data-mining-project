Images underAugmentationsNetworkHeatmap (cid:55)(cid:85)(cid:68)(cid:81)(cid:86)(cid:73)(cid:82)(cid:85)(cid:80)(cid:72)(cid:71)(cid:3)(cid:43)(cid:72)(cid:68)(cid:87)(cid:80)(cid:68)(cid:83)Most semi-supervised learning models are consistency-based, which leverage unlabeled images by maximizing the similarity between different augmentations of an image. But when we apply them to human pose estimation that has ex-tremely imbalanced class distribution, they often collapse and predict every pixel in unlabeled images as background.We ﬁnd this is because the decision boundary passes the high-density areas of the minor class so more and more pixels are gradually mis-classiﬁed as background. In this work, we present a surprisingly simple approach to drive the model to learn in the correct direction. For each image, it composes a pair of easy-hard augmentations and uses the more accurate predictions on the easy image to teach the network to learn pose information of the hard one. The ac-curacy superiority of teaching signals allows the network to be “monotonically” improved which effectively avoids collapsing. We apply our method to the state-of-the-art pose estimators and it further improves their performance on three public datasets. 