Facial editing is an important task in vision and graph-ics with numerous applications. However, existing works are incapable to deliver a continuous and fine-grained edit-ing mode (e.g., editing a slightly smiling face to a big laughing one) with natural interactions with users. In this work, we propose Talk-to-Edit, an interactive facial editing framework that performs fine-grained attribute manipula-tion through dialog between the user and the system. Our key insight is to model a continual “semantic field” in theGAN latent space. 1) Unlike previous works that regard the editing as traversing straight lines in the latent space, here the fine-grained editing is formulated as finding a curving trajectory that respects fine-grained attribute landscape on the semantic field. 2) The curvature at each step is location-specific and determined by the input image as well as the users’ language requests. 3) To engage the users in a mean-ingful dialog, our system generates language feedback by considering both the user request and the current state of the semantic field.We also contribute CelebA-Dialog, a visual-language fa-cial editing dataset to facilitate large-scale study. Specifi-cally, each image has manually annotated fine-grained at-tribute annotations as well as template-based textual de-scriptions in natural language. Extensive quantitative and∗Equal contribution. qualitative experiments demonstrate the superiority of our framework in terms of 1) the smoothness of fine-grained editing, 2) the identity/attribute preservation, and 3) the visual photorealism and dialog fluency. Notably, user study validates that our overall system is consistently fa-vored by around 80% of the participants. Our project page is https://www.mmlab-ntu.com/project/ talkedit/. 