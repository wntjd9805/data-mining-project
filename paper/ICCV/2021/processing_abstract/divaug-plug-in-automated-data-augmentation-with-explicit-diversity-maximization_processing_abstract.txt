Human-designed data augmentation strategies have been replaced by automatically learned augmentation pol-icy in the past two years. Specifically, recent work has em-pirically shown that the superior performance of the au-tomated data augmentation methods stems from increasing the diversity of augmented data [4, 5]. However, two factors regarding the diversity of augmented data are still missing: 1) the explicit definition (and thus measurement) of diver-sity and 2) the quantifiable relationship between diversity and its regularization effects. To bridge this gap, we pro-pose a diversity measure called Variance Diversity and the-oretically show that the regularization effect of data aug-mentation is promised by Variance Diversity. We validate in experiments that the relative gain from automated data aug-mentation in test accuracy is highly correlated to VarianceDiversity. An unsupervised sampling-based framework, Di-vAug, is designed to directly maximize Variance Diver-sity and hence strengthen the regularization effect. With-out requiring a separate search process, the performance gain from DivAug is comparable with the state-of-the-art method with better efficiency. Moreover, under the semi-supervised setting, our framework can further improve the performance of semi-supervised learning algorithms com-pared to RandAugment, making it highly applicable to real-world problems, where labeled data is scarce. The code is available at https://github.com/warai-0toko/DivAug. 