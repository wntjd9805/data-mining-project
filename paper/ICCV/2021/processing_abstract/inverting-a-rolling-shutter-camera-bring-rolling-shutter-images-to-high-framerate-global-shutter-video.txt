Rolling shutter (RS) images can be viewed as the result of the row-wise combination of global shutter (GS) images captured by a virtual moving GS camera over the period of camera readout time. The RS effect brings tremendous difﬁculties for the downstream applications.In this pa-per, we propose to invert the above RS imaging mechanism, i.e., recovering a high framerate GS video from consecutiveRS images to achieve RS temporal super-resolution (RSSR).This extremely challenging problem, e.g., recovering 1440GS images from two 720-height RS images, is far from be-ing solved end-to-end. To address this challenge, we ex-ploit the geometric constraint in the RS camera model, thus achieving geometry-aware inversion. Speciﬁcally, we make three contributions in resolving the above difﬁculties: (i) formulating the bidirectional RS undistortion ﬂows under the constant velocity motion model, (ii) building the connec-tion between the RS undistortion ﬂow and optical ﬂow via a scaling operation, and (iii) developing a mutual conversion scheme between varying RS undistortion ﬂows that corre-spond to different scanlines. Building upon these formu-lations, we propose the ﬁrst RS temporal super-resolution network in a cascaded structure to extract high framerate global shutter video. Our method explores the underly-*Corresponding author ing spatio-temporal geometric relationships within a deep learning framework, where no extra supervision besides the middle-scanline ground truth GS image is needed. Essen-tially, our method can be very efﬁcient for explicit propa-gation to generate GS images under any scanline. Experi-mental results on both synthetic and real data show that our method can produce high-quality GS image sequences with rich details, outperforming state-of-the-art methods. 