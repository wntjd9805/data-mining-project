Contrastive learning shows great potential in unpaired image-to-image translation, but sometimes the translated results are in poor quality and the contents are not pre-served consistently. In this paper, we uncover that the neg-ative examples play a critical role in the performance of contrastive learning for image translation. The negative ex-amples in previous methods are randomly sampled from the patches of different positions in the source image, which are not effective to push the positive examples close to the query examples. To address this issue, we present instance-wise hard Negative Example Generation for Contrastive learn-ing in Unpaired image-to-image Translation (NEGCUT).Speciﬁcally, we train a generator to produce negative exam-ples online. The generator is novel from two perspectives: 1) it is instance-wise which means that the generated exam-ples are based on the input image, and 2) it can generate hard negative examples since it is trained with an adversar-ial loss. With the generator, the performance of unpaired image-to-image translation is signiﬁcantly improved. Ex-periments on three benchmark datasets demonstrate that the proposed NEGCUT framework achieves state-of-the-art performance compared to previous methods. 