Data augmentation is an intuitive step towards solving the problem of few-shot classification. However, ensuring both discriminability and diversity in the augmented sam-ples is challenging. To address this, we propose a feature disentanglement framework that allows us to augment fea-tures with randomly sampled intra-class variations while preserving their class-discriminative features. Specifically, we disentangle a feature representation into two compo-nents: one represents the intra-class variance and the other encodes the class-discriminative information. We assume that the intra-class variance induced by variations in poses, backgrounds, or illumination conditions is shared across all classes and can be modelled via a common distribution.Then we sample features repeatedly from the learned intra-class variability distribution and add them to the class-discriminative features to get the augmented features. Such a data augmentation scheme ensures that the augmented features inherit crucial class-discriminative features while exhibiting large intra-class variance. Our method signif-icantly outperforms the state-of-the-art methods on multi-ple challenging fine-grained few-shot image classification benchmarks. Code is available at: https://github. com/cvlab-stonybrook/vfd-iccv21 