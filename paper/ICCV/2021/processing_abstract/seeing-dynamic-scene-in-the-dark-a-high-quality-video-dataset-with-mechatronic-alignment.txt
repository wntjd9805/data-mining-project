Low-light video enhancement is an important task. Previ-ous work is mostly trained on paired static images or videos.We compile a new dataset formed by our new strategy that contains high-quality spatially-aligned video pairs from dy-namic scenes in low- and normal-light conditions. We built it using a mechatronic system to precisely control the dy-namics during the video capture process, and further align the video pairs, both spatially and temporally, by identify-ing the systemâ€™s uniform motion stage. Besides the dataset, we propose an end-to-end framework, in which we design a self-supervised strategy to reduce noise, while enhanc-ing the illumination based on the Retinex theory. Exten-sive experiments based on various metrics and large-scale user study demonstrate the value of our dataset and effec-tiveness of our method. The dataset and code are available at https://github.com/dvlab-research/SDSD. 