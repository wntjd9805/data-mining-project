Appearance and motion are two important sources of information in video object segmentation (VOS). Previous methods mainly focus on using simplex solutions, lower-ing the upper bound of feature collaboration among and across these two cues. In this paper, we study a novel frame-work, termed the FSNet (Full-duplex Strategy Network), which designs a relational cross-attention module (RCAM) to achieve the bidirectional message propagation across embedding subspaces. Furthermore, the bidirectional pu-rification module (BPM) is introduced to update the incon-sistent features between the spatial-temporal embeddings, effectively improving the model robustness. By considering the mutual restraint within the full-duplex strategy, our FS-Net performs the cross-modal feature-passing (i.e., trans-mission and receiving) simultaneously before the fusion and decoding stage, making it robust to various challeng-ing scenarios (e.g., motion blur, occlusion) in VOS. Exten-sive experiments on five popular benchmarks (i.e., DAVIS16,FBMS, MCL, SegTrack-V2, and DAVSOD19) show that ourFSNet outperforms other state-of-the-arts for both the VOS and video salient object detection tasks. 