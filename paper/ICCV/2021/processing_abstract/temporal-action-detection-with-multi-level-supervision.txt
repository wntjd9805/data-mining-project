Training temporal action detection in videos requires large amounts of labeled data, yet such annotation is expen-sive to collect. Incorporating unlabeled or weakly-labeled data to train action detection model could help reduce an-In this work, we ﬁrst introduce the Semi-notation cost. supervised Action Detection (SSAD) task with a mixture of labeled and unlabeled data and analyze different types of errors in the proposed SSAD baselines which are di-rectly adapted from the semi-supervised classiﬁcation lit-erature. Identifying that the main source of error is action incompleteness (i.e., missing parts of actions), we allevi-ate it by designing an unsupervised foreground attention (UFA) module utilizing the conditional independence be-tween foreground and background motion. Then we incor-porate weakly-labeled data into SSAD and propose Omni-supervised Action Detection (OSAD) with three levels of su-pervision. To overcome the accompanying action-context confusion problem in OSAD baselines, an information bot-tleneck (IB) is designed to suppress the scene information in non-action frames while preserving the action informa-tion. We extensively benchmark against the baselines forSSAD and OSAD on our created data splits in THUMOS14 and ActivityNet1.2, and demonstrate the effectiveness of the proposed UFA and IB methods. Lastly, the beneﬁt of our fullOSAD-IB model under limited annotation budgets is shown by exploring the optimal annotation strategy for labeled, unlabeled and weakly-labeled data. 1 