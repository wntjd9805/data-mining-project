Despite recent advancements in single-domain or single-object image generation, it is still challenging to gener-ate complex scenes containing diverse, multiple objects and their interactions. Scene graphs, composed of nodes as ob-jects and directed-edges as relationships among objects, of-fer an alternative representation of a scene that is more se-mantically grounded than images. We hypothesize that a generative model for scene graphs might be able to learn the underlying semantic structure of real-world scenes more effectively than images, and hence, generate realistic novel scenes in the form of scene graphs. In this work, we ex-plore a new task for the unconditional generation of seman-tic scene graphs. We develop a deep auto-regressive model called SceneGraphGen which can directly learn the proba-bility distribution over labelled and directed graphs using a hierarchical recurrent architecture. The model takes a seed object as input and generates a scene graph in a sequence of steps, each step generating an object node, followed by a sequence of relationship edges connecting to the previous nodes. We show that the scene graphs generated by Scene-GraphGen are diverse and follow the semantic patterns of real-world scenes. Additionally, we demonstrate the appli-cation of the generated graphs in image synthesis, anomaly detection and scene graph completion. 