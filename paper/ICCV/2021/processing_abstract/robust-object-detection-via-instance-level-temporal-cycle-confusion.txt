Building reliable object detectors that are robust to do-main shifts, such as various changes in context, viewpoint, and object appearances, is critical for real-world applica-tions. In this work, we study the effectiveness of auxiliary self-supervised tasks to improve the out-of-distribution gen-eralization of object detectors. Inspired by the principle of maximum entropy, we introduce a novel self-supervised task, instance-level temporal cycle confusion (CycConf), which operates on the region features of the object detectors. For each object, the task is to find the most different object pro-posals in the adjacent frame in a video and then cycle back to itself for self-supervision. CycConf encourages the object de-tector to explore invariant structures across instances under various motions, which leads to improved model robustness in unseen domains at test time. We observe consistent out-of-domain performance improvements when training object detectors in tandem with self-supervised tasks on various do-main adaptation benchmarks with static images (Cityscapes,Foggy Cityscapes, Sim10K) and large-scale video datasets (BDD100K and Waymo open data)1. 