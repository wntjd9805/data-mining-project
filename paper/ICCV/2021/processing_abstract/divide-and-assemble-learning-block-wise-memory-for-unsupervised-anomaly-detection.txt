Reconstruction-based methods play an important role in unsupervised anomaly detection in images. Ideally, we ex-pect a perfect reconstruction for normal samples and poor reconstruction for abnormal samples. Since the general-izability of deep neural networks is difficult to control, ex-isting models such as autoencoder do not work well.In this work, we interpret the reconstruction of an image as a divide-and-assemble procedure. Surprisingly, by vary-ing the granularity of division on feature maps, we are able to modulate the reconstruction capability of the model for both normal and abnormal samples. That is, finer granu-larity leads to better reconstruction, while coarser granu-larity leads to poorer reconstruction. With proper granu-larity, the gap between the reconstruction error of normal and abnormal samples can be maximized. The divide-and-assemble framework is implemented by embedding a novel multi-scale block-wise memory module into an autoencoder network. Besides, we introduce adversarial learning and explore the semantic latent representation of the discrim-inator, which improves the detection of subtle anomaly.We achieve state-of-the-art performance on the challengingMVTec AD dataset. Remarkably, we improve the vanilla autoencoder model by 10.1% in terms of the AUROC score. 