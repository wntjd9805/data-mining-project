We propose a novel framework for video inpainting by adopting an internal learning strategy. Unlike previous methods that use optical ﬂow for cross-frame context prop-agation to inpaint unknown regions, we show that this can be achieved implicitly by ﬁtting a convolutional neural net-work to known regions. Moreover, to handle challenging se-quences with ambiguous backgrounds or long-term occlu-sion, we design two regularization terms to preserve high-frequency details and long-term temporal consistency. Ex-tensive experiments on the DAVIS dataset demonstrate that the proposed method achieves state-of-the-art inpainting∗Equal contribution quality quantitatively and qualitatively. We further extend the proposed method to another challenging task: learn-ing to remove an object from a video giving a single object mask in only one frame in a 4K video. Our source code is available at https://tengfei-wang.github.io/Implicit-Internal-Video-Inpainting/. 