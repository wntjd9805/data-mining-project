We present GANcraft, an unsupervised neural rendering framework for generating photorealistic images of large 3D block worlds such as those created in Minecraft. Our method takes a semantic block world as input, where each block is assigned a semantic label such as dirt, grass, or water. We represent the world as a continuous volumetric function and train our model to render view-consistent photorealistic im-ages for a user-controlled camera. In the absence of paired ground truth real images for the block world, we devise a training technique based on pseudo-ground truth and adver-sarial training. This stands in contrast to prior work on neu-ral rendering for view synthesis, which requires ground truth images to estimate scene geometry and view-dependent ap-pearance. In addition to camera trajectory, GANcraft allows user control over both scene semantics and output style. Ex-perimental results with comparison to strong baselines show the effectiveness of GANcraft on this novel task of photoreal-istic 3D block world synthesis. The project website is avail-able at https://nvlabs.github.io/GANcraft/. 