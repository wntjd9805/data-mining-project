This paper presents a neural network built upon Trans-formers, namely PlaneTR, to simultaneously detect and re-construct planes from a single image. Different from pre-vious methods, PlaneTR jointly leverages the context in-formation and the geometric structures in a sequence-to-sequence way to holistically detect plane instances in oneSpecifically, we represent the geometric forward pass. structures as line segments and conduct the network with three main components: (i) context and line segments en-coders, (ii) a structure-guided plane decoder, (iii) a pixel-wise plane embedding decoder. Given an image and its detected line segments, PlaneTR generates the context and line segment sequences via two specially designed encoders and then feeds them into a Transformers-based decoder to directly predict a sequence of plane instances by simulta-neously considering the context and global structure cues.Finally, the pixel-wise embeddings are computed to assign each pixel to one predicted plane instance which is near-est to it in embedding space. Comprehensive experiments demonstrate that PlaneTR achieves state-of-the-art perfor-mance on the ScanNet and NYUv2 datasets. 