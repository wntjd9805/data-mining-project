Inspired by human visual attention, we propose a novel inverse reinforcement learning formulation using MaximumEntropy Deep Inverse Reinforcement Learning (MEDIRL) for predicting the visual attention of drivers in accident-prone situations. MEDIRL predicts fixation locations that lead to maximal rewards by learning a task-sensitive re-ward function from eye fixation patterns recorded from at-tentive drivers. Additionally, we introduce EyeCar, a new driver attention dataset in accident-prone situations. We conduct comprehensive experiments to evaluate our pro-posed model on three common benchmarks: (DR(eye)VE,BDD-A, DADA-2000), and our EyeCar dataset. Results in-dicate that MEDIRL outperforms existing models for pre-dicting attention and achieves state-of-the-art performance.We present extensive ablation studies to provide more in-sights into different features of our proposed model.1 