In image retrieval, learning local features with deep con-volutional networks has been demonstrated effective to im-prove the performance. To discriminate deep local features, some research efforts turn to attention learning. However, existing attention-based methods only generate a single at-tention map for each image, which limits the exploration of diverse visual patterns. To this end, we propose a novel deep local feature learning architecture to simultaneously focus on multiple discriminative local patterns in an image.In our framework, we ﬁrst adaptively reorganize the chan-nels of activation maps for multiple heads. For each head, a new dynamic attention module is designed to learn the po-tential attentions. The whole architecture is trained as met-ric learning of weighted-sum-pooled global image features, with only image-level relevance label. After the architec-ture training, for each database image, we select local fea-tures based on their multi-head dynamic attentions, which are further indexed for efﬁcient retrieval. Extensive experi-ments show the proposed method outperforms the state-of-the-art methods on the Revisited Oxford and Paris datasets.Besides, it typically achieves competitive results even using local features with lower dimensions. Code will be released at https://github.com/CHANWH/MDA. 