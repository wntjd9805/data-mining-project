Automatic augmentation methods have recently become a crucial pillar for strong model performance in vision tasks. While existing automatic augmentation methods need to trade off simplicity, cost and performance, we present a most simple baseline, TrivialAugment, that out-performs previous methods for almost free. TrivialAugment is parameter-free and only applies a single augmentation to each image. Thus, TrivialAugment's effectiveness is very unexpected to us and we performed very thorough exper-iments to study its performance. First, we compare Triv-ialAugment to previous state-of-the-art methods in a variety of image classification scenarios. Then, we perform mul-tiple ablation studies with different augmentation spaces, augmentation methods and setups to understand the crucial requirements for its performance. Additionally, we provide a simple interface to facilitate the widespread adoption of automatic augmentation methods, as well as our full code base for reproducibility1. Since our work reveals a stag-nation in many parts of automatic augmentation research, we end with a short proposal of best practices for sustained future progress in automatic augmentation methods.Input imageSample strengthSample augmentation and apply itFigure 1: A visualization of TA. For each image, TA (uni-formly) samples an augmentation strength and an augmen-tation. This augmentation is then applied to the image with the sampled strength.MethodAARAFast AATA (ours)SearchCIFAR-10 CIFAR-100 SVHN ImageNetOverhead ShakeShake WRN WRN ResNet 40 - 800× 4 - 80× 1× 0× 77.6 77.6 77.6 78.1 98.0 98.0 98.0 98.2 82.9 83.3 82.7 84.3 98.9 99.0 98.8 98.9Table 1: TrivialAugment compares very favourably to previous augmentation methods.In this table we sum-marize some results from Table 2 and present augmentation search overhead estimates. 