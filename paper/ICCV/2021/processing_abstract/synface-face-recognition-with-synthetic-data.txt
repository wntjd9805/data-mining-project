With the recent success of deep neural networks, remark-able progress has been achieved on face recognition. How-ever, collecting large-scale real-world training data for face recognition has turned out to be challenging, especially due to the label noise and privacy issues. Meanwhile, existing face recognition datasets are usually collected from web im-ages, lacking detailed annotations on attributes (e.g., pose and expression), so the inﬂuences of different attributes on face recognition have been poorly investigated. In this pa-per, we address the above-mentioned issues in face recog-nition using synthetic face images, i.e., SynFace. Speciﬁ-cally, we ﬁrst explore the performance gap between recent state-of-the-art face recognition models trained with syn-thetic and real face images. We then analyze the underlying causes behind the performance gap, e.g., the poor intra-class variations and the domain gap between synthetic and real face images. Inspired by this, we devise the SynFace with identity mixup (IM) and domain mixup (DM) to miti-gate the above performance gap, demonstrating the great potentials of synthetic data for face recognition. Further-more, with the controllable face synthesis model, we can easily manage different factors of synthetic face genera-tion, including pose, expression, illumination, the number of identities, and samples per identity. Therefore, we also per-form a systematically empirical analysis on synthetic face images to provide some insights on how to effectively utilize synthetic data for face recognition. 