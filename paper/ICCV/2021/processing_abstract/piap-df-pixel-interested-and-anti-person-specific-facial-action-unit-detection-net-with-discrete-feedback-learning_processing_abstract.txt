Facial Action Units (AUs) are of great significance in communication. Automatic AU detection can improve the understanding of psychological conditions and emotional status. Recently, several deep learning methods have been proposed to detect AUs automatically. However, several challenges, such as poor extraction of fine-grained and ro-bust local AUs information, model overfitting on person-specific features, as well as the limitation of datasets with wrong labels, remain to be addressed. In this paper, we pro-pose a joint strategy called PIAP-DF to solve these prob-lems, which involves 1) a multi-stage Pixel-Interested learn-ing method with pixel-level attention for each AU; 2) anAnti Person-Specific method aiming to eliminate features associated with any individual as much as possible; 3) a semi-supervised learning method with Discrete Feedback, designed to effectively utilize unlabeled data and mitigate the negative impacts of wrong labels. Experimental results on the two popular AU detection datasets BP4D and DISFA prove that PIAP-DF can be the new state-of-the-art method.Compared with the current best method, PIAP-DF improves the average F1 score by 3.2% on BP4D and by 0.5% onDISFA. All modules of PIAP-DF can be easily removed af-ter training to obtain a lightweight model for practical ap-plication. 