Recent progress in stochastic motion prediction, i.e., pre-dicting multiple possible future human motions given a sin-gle past pose sequence, has led to producing truly diverse future motions and even providing control over the motion of some body parts. However, to achieve this, the state-of-the-art method requires learning several mappings for di-versity and a dedicated model for controllable motion pre-diction.In this paper, we introduce a uniﬁed deep gen-erative network for both diverse and controllable motion prediction. To this end, we leverage the intuition that re-alistic human motions consist of smooth sequences of valid poses, and that, given limited data, learning a pose prior is much more tractable than a motion one. We there-fore design a generator that predicts the motion of dif-ferent body parts sequentially, and introduce a normaliz-ing ﬂow based pose prior, together with a joint angle loss, to achieve motion realism. Our experiments on two stan-dard benchmark datasets, Human3.6M and HumanEva-I, demonstrate that our approach outperforms the state-of-the-art baselines in terms of both sample diversity and accu-racy. The code is available at https://github.com/ wei-mao-2019/gsps 