State-of-the-art object detection approaches typically rely on pre-trained classiﬁcation models to achieve better performance and faster convergence. We hypothesize that classiﬁcation pre-training strives to achieve translation in-variance, and consequently ignores the localization aspect of the problem. We propose a new large-scale pre-training strategy for detection, where noisy class labels are avail-In this set-able for all images, but not bounding-boxes. ting, we augment standard classiﬁcation pre-training with a new detection-speciﬁc pretext task. Motivated by the noise-contrastive learning based self-supervised approaches, we design a task that forces bounding boxes with high-overlap to have similar representations in different views of an im-age, compared to non-overlapping boxes. We redesignFaster R-CNN modules to perform this task efﬁciently. Our experimental results show signiﬁcant improvements over existing weakly-supervised and self-supervised pre-training approaches in both detection accuracy as well as ﬁne-tuning speed. 