scale environments).For several emerging technologies such as augmented reality, autonomous driving and robotics, visual localiza-tion is a critical component. Directly regressing cam-era pose/3D scene coordinates from the input image using deep neural networks has shown great potential. However, such methods assume a stationary data distribution with all scenes simultaneously available during training. In this pa-per, we approach the problem of visual localization in a continual learning setup – whereby the model is trained on scenes in an incremental manner. Our results show that similar to the classification domain, non-stationary data in-duces catastrophic forgetting in deep networks for visual localization. To address this issue, a strong baseline based on storing and replaying images from a fixed buffer is pro-posed. Furthermore, we propose a new sampling method based on coverage score (Buff-CS) that adapts the existing sampling strategies in the buffering process to the problem of visual localization. Results demonstrate consistent im-provements over standard buffering methods on two chal-lenging datasets – 7Scenes, 12Scenes, and also 19Scenes by combining the former scenes1. 