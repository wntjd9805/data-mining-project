Monocular 3D object detection is of great signiﬁcance for autonomous driving but remains challenging. The core challenge is to predict the distance of objects in the ab-sence of explicit depth information. Unlike regressing the distance as a single variable in most existing methods, we propose a novel geometry-based distance decomposition to recover the distance by its factors. The decomposition fac-tors the distance of objects into the most representative and stable variables, i.e. the physical height and the projected visual height in the image plane. Moreover, the decomposi-tion maintains the self-consistency between the two heights, leading to robust distance prediction when both predicted heights are inaccurate. The decomposition also enables us to trace the causes of the distance uncertainty for different scenarios. Such decomposition makes the distance predic-tion interpretable, accurate, and robust. Our method di-rectly predicts 3D bounding boxes from RGB images with a compact architecture, making the training and inference simple and efﬁcient. The experimental results show that our method achieves the state-of-the-art performance on the monocular 3D Object Detection and Bird’s Eye View tasks of the KITTI dataset, and can generalize to images with dif-ferent camera intrinsics 1. 