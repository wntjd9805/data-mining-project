Adversarial training is one effective approach for train-ing robust deep neural networks against adversarial at-tacks. While being able to bring reliable robustness, adver-sarial training (AT) methods in general favor high capac-ity models, i.e., the larger the model the better the robust-ness. This tends to limit their effectiveness on small models, which are more preferable in scenarios where storage or computing resources are very limited (e.g., mobile devices).In this paper, we leverage the concept of knowledge distil-lation to improve the robustness of small models by distill-ing from adversarially trained large models. We ﬁrst revisit several state-of-the-art AT methods from a distillation per-spective and identify one common technique that can lead to improved robustness: the use of robust soft labels – pre-dictions of a robust model. Following this observation, we propose a novel adversarial robustness distillation method called Robust Soft Label Adversarial Distillation (RSLAD) to train robust small student models. RSLAD fully exploits the robust soft labels produced by a robust (adversarially-trained) large teacher model to guide the student’s learning on both natural and adversarial examples in all loss terms.We empirically demonstrate the effectiveness of our RSLAD approach over existing adversarial training and distilla-tion methods in improving the robustness of small models against state-of-the-art attacks including the AutoAttack.We also provide a set of understandings on our RSLAD and the importance of robust soft labels for adversarial robust-ness distillation. Code: https://github.com/zibojia/RSLAD. 