Light field images contain both angular and spatial in-formation of captured light rays. The rich information of light fields enables straightforward disparity recovery capa-bility but demands high computational cost as well. In this paper, we design a lightweight disparity estimation model with physical-based multi-disparity-scale cost volume ag-gregation for fast disparity estimation. By introducing a sub-network of edge guidance, we significantly improve the recovery of geometric details near edges and improve the overall performance. We test the proposed model exten-sively on both synthetic and real-captured datasets, which provide both densely and sparsely sampled light fields. Fi-nally, we significantly reduce computation cost and GPU memory consumption, while achieving comparable perfor-mance with state-of-the-art disparity estimation methods for light fields. Our source code is available at https://github.com/zcong17huang/FastLFnet. 