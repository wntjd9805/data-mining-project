The crux of self-supervised video representation learning is to build general features from unlabeled videos. How-ever, most recent works have mainly focused on high-level semantics and neglected lower-level representations and their temporal relationship which are crucial for general video understanding. To address these challenges, this pa-per proposes a multi-level feature optimization framework to improve the generalization and temporal modeling abil-ity of learned video representations. Concretely, high-level features obtained from naive and prototypical contrastive learning are utilized to build distribution graphs, guid-ing the process of low-level and mid-level feature learn-ing. We also devise a simple temporal modeling module from multi-level features to enhance motion pattern learn-ing. Experiments demonstrate that multi-level feature opti-mization with the graph constraint and temporal modeling can greatly improve the representation ability in video un-derstanding. Code is available here. 