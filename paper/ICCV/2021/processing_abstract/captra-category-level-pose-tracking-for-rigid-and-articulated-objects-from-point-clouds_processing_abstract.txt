In this work, we tackle the problem of category-level on-line pose tracking of objects from point cloud sequences.For the ﬁrst time, we propose a uniﬁed framework that can handle 9DoF pose tracking for novel rigid object instances as well as per-part pose tracking for articulated objects from known categories. Here the 9DoF pose, comprising 6D pose and 3D size, is equivalent to a 3D amodal bound-ing box representation with free 6D pose. Given the depth point cloud at the current frame and the estimated pose from the last frame, our novel end-to-end pipeline learns to ac-curately update the pose. Our pipeline is composed of three modules: 1) a pose canonicalization module that normal-*: equal contributions,Project page: https://yijiaweng.github.io/CAPTRA: corresponding author† izes the pose of the input depth point cloud; 2) RotationNet, a module that directly regresses small interframe delta ro-tations; and 3) CoordinateNet, a module that predicts the normalized coordinates and segmentation, enabling analyt-ical computation of the 3D size and translation. Leverag-ing the small pose regime in the pose-canonicalized point clouds, our method integrates the best of both worlds by combining dense coordinate prediction and direct rota-tion regression, thus yielding an end-to-end differentiable pipeline optimized for 9DoF pose accuracy (without us-ing non-differentiable RANSAC). Our extensive experiments demonstrate that our method achieves new state-of-the-art performance on category-level rigid object pose (NOCS-REAL275 [29]) and articulated object pose benchmarks (SAPIEN [34], BMVC [18]) at the fastest FPS 12.⇠