Human pose forecasting is a complex structured-data sequence-modelling task, which has received increasing at-tention, also due to numerous potential applications. Re-search has mainly addressed the temporal dimension as time series and the interaction of human body joints with a kinematic tree or by a graph. This has decoupled the two aspects and leveraged progress from the relevant ﬁelds, but it has also limited the understanding of the complex struc-tural joint spatio-temporal dynamics of the human pose.Here we propose a novel Space-Time-Separable GraphConvolutional Network (STS-GCN) for pose forecasting.For the ﬁrst time, STS-GCN models the human pose dynam-ics only with a graph convolutional network (GCN), includ-ing the temporal evolution and the spatial joint interaction within a single-graph framework, which allows the cross-talk of motion and spatial correlations. Concurrently, STS-GCN is the ﬁrst space-time-separable GCN: the space-time graph connectivity is factored into space and time afﬁn-ity matrices, which bottlenecks the space-time cross-talk, while enabling full joint-joint and time-time correlations.Both afﬁnity matrices are learnt end-to-end, which results in connections substantially deviating from the standard kine-matic tree and the linear-time time series.In experimental evaluation on three complex, recent and large-scale benchmarks, Human3.6M [24], AMASS [34] and 3DPW [48], STS-GCN outperforms the state-of-the-art, surpassing the current best technique [35] by over 32% in average at the most difﬁcult long-term predictions, while only requiring 1.7% of its parameters. We explain the re-sults qualitatively and illustrate the graph interactions by the factored joint-joint and time-time learnt graph connec-tions. Our source code is available at: https://github.com/FraLuca/STSGCN 