Most existing Siamese-based tracking methods execute the classiﬁcation and regression of the target object based on the similarity maps. However, they either employ a sin-gle map from the last convolutional layer which degrades the localization accuracy in complex scenarios or sepa-rately use multiple maps for decision making, introduc-ing intractable computations for aerial mobile platforms.Thus, in this work, we propose an efﬁcient and effective hierarchical feature transformer (HiFT) for aerial track-ing. Hierarchical similarity maps generated by multi-level convolutional layers are fed into the feature transformer to achieve the interactive fusion of spatial (shallow layers) and semantics cues (deep layers). Consequently, not only the global contextual information can be raised, facilitat-ing the target search, but also our end-to-end architecture with the transformer can efﬁciently learn the interdepen-dencies among multi-level features, thereby discovering a tracking-tailored feature space with strong discriminabil-ity. Comprehensive evaluations on four aerial benchmarks have proven the effectiveness of HiFT. Real-world tests on the aerial platform have strongly validated its practicability with a real-time speed. Our code is available at https://github.com/vision4robotics/HiFT. 