In this work, we present a new multi-view depth estima-tion method that utilizes both conventional SfM reconstruc-tion and learning-based priors over the recently proposed neural radiance fields (NeRF). Unlike existing neural net-work based optimization method that relies on estimated correspondences, our method directly optimizes over im-plicit volumes, eliminating the challenging step of matching pixels in indoor scenes. The key to our approach is to utilize the learning-based priors to guide the optimization process of NeRF. Our system firstly adapts a monocular depth net-work over the target scene by finetuning on its sparse SfM reconstruction. Then, we show that the shape-radiance am-biguity of NeRF still exists in indoor environments and pro-pose to address the issue by employing the adapted depth priors to monitor the sampling process of volume render-ing. Finally, a per-pixel confidence map acquired by er-ror computation on the rendered image can be used to fur-*Corresponding author. ther improve the depth quality. Experiments show that our proposed framework significantly outperforms state-of-the-art methods on indoor scenes, with surprising findings pre-sented on the effectiveness of correspondence-based opti-mization and NeRF-based optimization over the adaptedIn addition, we show that the guided opti-depth priors. mization scheme does not sacrifice the original synthesis capability of neural radiance fields, improving the render-ing quality on both seen and novel views. Code is available at https://github.com/weiyithu/NerfingMVS. 