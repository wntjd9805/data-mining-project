We design a family of image classification architectures that optimize the trade-off between accuracy and efficiency in a high-speed regime. Our work exploits recent findings in attention-based architectures, which are competitive on highly parallel processing hardware. We revisit principles from the extensive literature on convolutional neural net-works to apply them to transformers, in particular activa-tion maps with decreasing resolutions. We also introduce the attention bias, a new way to integrate positional infor-mation in vision transformers.As a result, we propose LeViT: a hybrid neural network for fast inference image classification. We consider differ-ent measures of efficiency on different hardware platforms, so as to best reflect a wide range of application scenar-ios. Our extensive experiments empirically validate our technical choices and show they are suitable to most ar-chitectures. Overall, LeViT significantly outperforms ex-isting convnets and vision transformers with respect to the speed/accuracy tradeoff. For example, at 80% ImageNet top-1 accuracy, LeViT is 5 times faster than EfficientNet onCPU. We release the code at https://github.com/ facebookresearch/LeViT. 