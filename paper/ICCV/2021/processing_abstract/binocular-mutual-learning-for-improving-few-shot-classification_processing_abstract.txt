Most of the few-shot learning methods learn to transfer knowledge from datasets with abundant labeled data (i.e., the base set). From the perspective of class space on base set, existing methods either focus on utilizing all classes un-der a global view by normal pretraining, or pay more atten-tion to adopt an episodic manner to train meta-tasks within few classes in a local view. However, the interaction of the two views is rarely explored. As the two views capture com-plementary information, we naturally think of the compati-bility of them for achieving further performance gains. In-spired by the mutual learning paradigm and binocular par-allax, we propose a unified framework, namely BinocularMutual Learning (BML), which achieves the compatibility of the global view and the local view through both intra-view and cross-view modeling. Concretely, the global view learns in the whole class space to capture rich inter-class relationships. Meanwhile, the local view learns in the lo-cal class space within each episode, focusing on matching positive pairs correctly. In addition, cross-view mutual in-teraction further promotes the collaborative learning and the implicit exploration of useful knowledge from each oth-er. During meta-test, binocular embeddings are aggregated together to support decision-making, which greatly improve the accuracy of classification. Extensive experiments con-ducted on multiple benchmarks including cross-domain val-idation confirm the effectiveness of our method1. 