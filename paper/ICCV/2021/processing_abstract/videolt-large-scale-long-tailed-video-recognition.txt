Label distributions in real-world are oftentimes long-tailed and imbalanced, resulting in biased models towards dominant labels. While long-tailed recognition has been extensively studied for image classiﬁcation tasks, limited ef-fort has been made for the video domain. In this paper, we introduce VideoLT, a large-scale long-tailed video recog-nition dataset, as a step toward real-world video recog-nition. VideoLT contains 256,218 untrimmed videos, an-notated into 1,004 classes with a long-tailed distribution.Through extensive studies, we demonstrate that state-of-the-art methods used for long-tailed image recognition do not perform well in the video domain due to the additional temporal dimension in videos. This motivates us to pro-pose FrameStack, a simple yet effective method for long-tailed video recognition.In particular, FrameStack per-forms sampling at the frame-level in order to balance class distributions, and the sampling ratio is dynamically deter-mined using knowledge derived from the network during training. Experimental results demonstrate that FrameS-tack can improve classiﬁcation performance without sacri-ﬁcing the overall accuracy. Code and dataset are available at: https://github.com/17Skye17/VideoLT. 