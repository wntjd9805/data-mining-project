Semantic segmentation is a challenging task in the ab-sence of densely labelled data. Only relying on class activa-tion maps (CAM) with image-level labels provides deﬁcient segmentation supervision. Prior works thus consider pre-trained models to produce coarse saliency maps to guide the generation of pseudo segmentation labels. However, the commonly used off-line heuristic generation process cannot fully exploit the beneﬁts of these coarse saliency maps. Mo-tivated by the signiﬁcant inter-task correlation, we propose a novel weakly supervised multi-task framework termed asAuxSegNet, to leverage saliency detection and multi-label image classiﬁcation as auxiliary tasks to improve the pri-mary task of semantic segmentation using only image-level ground-truth labels. Inspired by their similar structured se-mantics, we also propose to learn a cross-task global pixel-level afﬁnity map from the saliency and segmentation rep-resentations. The learned cross-task afﬁnity can be used to reﬁne saliency predictions and propagate CAM maps to provide improved pseudo labels for both tasks. The mutual boost between pseudo label updating and cross-task afﬁn-ity learning enables iterative improvements on segmenta-tion performance. Extensive experiments demonstrate the effectiveness of the proposed auxiliary learning network structure and the cross-task afﬁnity learning method. The proposed approach achieves state-of-the-art weakly super-vised segmentation performance on the challenging PAS-CAL VOC 2012 and MS COCO benchmarks. 1 