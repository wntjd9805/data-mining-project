Surface reconstruction from point clouds is a fundamen-tal problem in the computer vision and graphics commu-nity. Recent state-of-the-arts solve this problem by indi-vidually optimizing each local implicit ﬁeld during infer-ence. Without considering the geometric relationships be-tween local ﬁelds, they typically require accurate normals to avoid the sign conﬂict problem in overlapped regions of local ﬁelds, which severely limits their applicability to raw scans where surface normals could be unavailable. Al-though SAL breaks this limitation via sign-agnostic learn-ing, further works still need to explore how to extend this technique for local shape modeling. To this end, we propose to learn implicit surface reconstruction by sign-agnostic op-timization of convolutional occupancy networks, to simulta-neously achieve advanced scalability to large-scale scenes, generality to novel shapes, and applicability to raw scans inCorrespondence to Dan Xu and Kui Jia. a uniﬁed framework. Concretely, we achieve this goal by a simple yet effective design, which further optimizes the pre-trained occupancy prediction networks with an unsigned cross-entropy loss during inference. The learning of occu-pancy ﬁelds is conditioned on convolutional features from an hourglass network architecture. Extensive experimental comparisons with previous state-of-the-arts on both object-level and scene-level datasets demonstrate the superior ac-curacy of our approach for surface reconstruction from un-orientated point clouds. The code is available at https://github.com/tangjiapeng/SA-ConvONet. 