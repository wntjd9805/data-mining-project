Gait recognition is one of the most important biometric technologies and has been applied in many ﬁelds. Recent gait recognition frameworks represent each gait frame by descriptors extracted from either global appearances or lo-cal regions of humans. However, the representations based on global information often neglect the details of the gait frame, while local region based descriptors cannot cap-ture the relations among neighboring regions, thus reduc-ing their discriminativeness.In this paper, we propose a novel feature extraction and fusion framework to achieve discriminative feature representations for gait recognition.Towards this goal, we take advantage of both global vi-sual information and local region details and develop aGlobal and Local Feature Extractor (GLFE). Speciﬁcally, our GLFE module is composed of our newly designed mul-tiple global and local convolutional layers (GLConv) to ensemble global and local features in a principle manner.Furthermore, we present a novel operation, namely LocalTemporal Aggregation (LTA), to further preserve the spa-tial information by reducing the temporal resolution to ob-tain higher spatial resolution. With the help of our GLFE and LTA, our method signiﬁcantly improves the discrimi-nativeness of our visual features, thus improving the gait recognition performance. Extensive experiments demon-strate that our proposed method outperforms state-of-the-art gait recognition methods on two popular datasets. 