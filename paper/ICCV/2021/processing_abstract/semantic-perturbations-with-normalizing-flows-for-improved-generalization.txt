Data augmentation is a widely adopted technique for avoiding overﬁtting when training deep neural networks.However, this approach requires domain-speciﬁc knowl-edge and is often limited to a ﬁxed set of hard-coded trans-formations. Recently, several works proposed to use gen-erative models for generating semantically meaningful per-turbations to train a classiﬁer. However, because accurate encoding and decoding are critical, these methods, which use architectures that approximate the latent-variable in-ference, remained limited to pilot studies on small datasets.Exploiting the exactly reversible encoder-decoder struc-ture of normalizing ﬂows, we perform on-manifold per-turbations in the latent space to deﬁne fully unsupervised data augmentations. We demonstrate that such perturba-tions match the performance of advanced data augmenta-tion techniques—reaching 96.6% test accuracy for CIFAR-10 using ResNet-18 and outperform existing methods, par-ticularly in low data regimes—yielding 10–25% relative im-provement of test accuracy from classical training. We ﬁnd that our latent adversarial perturbations adaptive to the classiﬁer throughout its training are most effective, yield-ing the ﬁrst test accuracy improvement results on real-world datasets—CIFAR-10/100—via latent-space perturbations. 