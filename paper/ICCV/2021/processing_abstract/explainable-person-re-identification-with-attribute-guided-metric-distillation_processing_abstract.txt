Despite the great progress of person re-identification (ReID) with the adoption of Convolutional Neural Net-works, current ReID models are opaque and only outputs a scalar distance between two persons. There are few meth-ods providing users semantically understandable explana-tions for why two persons are the same one or not.In this paper, we propose a post-hoc method, named Attribute-guided Metric Distillation (AMD), to explain existing ReID models. This is the first method to explore attributes to answer: 1) what and where the attributes make two per-sons different, and 2) how much each attribute contributes to the difference.In AMD, we design a pluggable inter-preter network for target models to generate quantitative contributions of attributes and visualize accurate attention maps of the most discriminative attributes. To achieve this goal, we propose a metric distillation loss by which the in-terpreter learns to decompose the distance of two persons into components of attributes with knowledge distilled from the target model. Moreover, we propose an attribute prior loss to make the interpreter generate attribute-guided at-tention maps and to eliminate biases caused by the imbal-anced distribution of attributes. This loss can guide the in-terpreter to focus on the exclusive and discriminative at-tributes rather than the large-area but common attributes of two persons. Comprehensive experiments show that the interpreter can generate effective and intuitive explanations for varied models and generalize well under cross-domain settings. As a by-product, the accuracy of target models can be further improved with our interpreter. 1 