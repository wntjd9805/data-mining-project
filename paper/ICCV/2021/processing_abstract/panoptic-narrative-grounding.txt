This paper proposes Panoptic Narrative Grounding, a spatially fine and general formulation of the natural lan-guage visual grounding problem. We establish an ex-perimental framework for the study of this new task, in-cluding new ground truth and metrics, and we propose a strong baseline method to serve as stepping stone for fu-ture work. We exploit the intrinsic semantic richness in an image by including panoptic categories, and we approach visual grounding at a fine-grained level by using segmen-In terms of ground truth, we propose an algo-tations. rithm to automatically transfer Localized Narratives anno-tations to specific regions in the panoptic segmentations of the MS COCO dataset. To guarantee the quality of our an-notations, we take advantage of the semantic structure con-tained in WordNet to exclusively incorporate noun phrases that are grounded to a meaningfully related panoptic seg-mentation region. The proposed baseline achieves a perfor-mance of 55.4 absolute Average Recall points. This result is a suitable foundation to push the envelope further in the development of methods for Panoptic Narrative Grounding. 