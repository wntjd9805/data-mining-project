Image reconstruction and synthesis have witnessed re-markable progress thanks to the development of generative models. Nonetheless, gaps could still exist between the real and generated images, especially in the frequency domain.In this study, we show that narrowing gaps in the frequency domain can ameliorate image reconstruction and synthe-sis quality further. We propose a novel focal frequency loss, which allows a model to adaptively focus on frequency com-ponents that are hard to synthesize by down-weighting the easy ones. This objective function is complementary to ex-isting spatial losses, offering great impedance against the loss of important frequency information due to the inher-ent bias of neural networks. We demonstrate the versatility and effectiveness of focal frequency loss to improve popular models, such as VAE, pix2pix, and SPADE, in both percep-tual quality and quantitative performance. We further show its potential on StyleGAN2.1, 2 