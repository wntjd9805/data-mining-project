Humans are able to continuously detect and track sur-rounding objects by constructing a spatial-temporal memory of the objects when looking around. In contrast, 3D ob-ject detectors in existing tracking-by-detection systems often search for objects in every new video frame from scratch, without fully leveraging memory from previous detection results.In this work, we propose a novel system for in-tegrated 3D object detection and tracking, which uses a dynamic object occupancy map and previous object states as spatial-temporal memory to assist object detection in fu-ture frames. This memory, together with the ego-motion from back-end odometry, guides the detector to achieve more efÔ¨Åcient object proposal generation and more accurate ob-ject state estimation. The experiments demonstrate the ef-fectiveness of the proposed system and its performance on the ScanNet and KITTI datasets. Moreover, the proposed system produces stable bounding boxes and pose trajecto-ries over time, while being able to handle occluded and truncated objects. Code is available at the project page: https://zju3dv.github.io/UDOLO. 