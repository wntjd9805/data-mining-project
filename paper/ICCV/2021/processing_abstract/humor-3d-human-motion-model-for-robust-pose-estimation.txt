We introduce HuMoR: a 3D Human Motion Model forRobust Estimation of temporal pose and shape. Though substantial progress has been made in estimating 3D hu-man motion and shape from dynamic observations, recov-ering plausible pose sequences in the presence of noise and occlusions remains a challenge. For this purpose, we propose an expressive generative model in the form of a conditional variational autoencoder, which learns a distribution of the change in pose at each step of a motion sequence.Furthermore, we introduce a ï¬‚exi-ble optimization-based approach that leverages HuMoR as a motion prior to robustly estimate plausible pose and shape from ambiguous observations. Through extensive evaluations, we demonstrate that our model generalizes to diverse motions and body shapes after training on a large motion capture dataset, and enables motion recon-struction from multiple input modalities including 3D key-points and RGB(-D) videos.See the project page at geometry.stanford.edu/projects/humor. 