Extensive Unsupervised Domain Adaptation (UDA) studies have shown great success in practice by learning transfer-able representations across a labeled source domain and an unlabeled target domain with deep models. However, current work focuses on improving the generalization ability of UDA models on clean examples without considering the adversarial robustness, which is crucial in real-world ap-plications. Conventional adversarial training methods are not suitable for the adversarial robustness on the unlabeled target domain of UDA since they train models with adver-sarial examples generated by the supervised loss function.In this work, we propose to leverage intermediate represen-tations learned by robust ImageNet models to improve the robustness of UDA models. Our method works by align-ing the features of the UDA model with the robust features learned by ImageNet pre-trained models along with domain adaptation training. It utilizes both labeled and unlabeled domains and instills robustness without any adversarial in-tervention or label requirement during domain adaptation training. Our experimental results show that our method signiÔ¨Åcantly improves adversarial robustness compared to the baseline while keeping clean accuracy on various UDA benchmarks. 