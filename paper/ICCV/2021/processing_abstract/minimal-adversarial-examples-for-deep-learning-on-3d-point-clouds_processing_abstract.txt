With recent developments of convolutional neural net-works, deep learning for 3D point clouds has shown sig-niﬁcant progress in various 3D scene understanding tasks, e.g., object recognition, semantic segmentation. In a safety-critical environment, it is however not well understood how such deep learning models are vulnerable to adversarial ex-amples.In this work, we explore adversarial attacks for point cloud-based neural networks. We propose a uniﬁed formulation for adversarial point cloud generation that can generalise two different attack strategies. Our method gen-erates adversarial examples by attacking the classiﬁcation ability of point cloud-based networks while considering the perceptibility of the examples and ensuring the minimal level of point manipulations. Experimental results show that our method achieves the state-of-the-art performance with higher than 89% and 90% of attack success rate on synthetic and real-world data respectively, while manipu-lating only about 4% of the total points. 