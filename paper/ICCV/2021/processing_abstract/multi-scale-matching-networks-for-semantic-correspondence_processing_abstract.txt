Deep features have been proven powerful in building ac-curate dense semantic correspondences in various previ-ous works. However, the multi-scale and pyramidal hier-archy of convolutional neural networks has not been well studied to learn discriminative pixel-level features for se-mantic correspondence. In this paper, we propose a multi-scale matching network that is sensitive to tiny seman-tic differences between neighboring pixels. We follow the coarse-to-ﬁne matching strategy and build a top-down fea-ture and matching enhancement scheme that is coupled with the multi-scale hierarchy of deep convolutional neu-ral networks. During feature enhancement, intra-scale en-hancement fuses same-resolution feature maps from multi-ple layers together via local self-attention and cross-scale enhancement hallucinates higher-resolution feature maps along the top-down pathway. Besides, we learn comple-mentary matching details at different scales thus the over-all matching score is reﬁned by features of different se-mantic levels gradually. Our multi-scale matching net-work can be trained end-to-end easily with few additional*Corresponding author: wfge@fudan.edu.cn learnable parameters. Experimental results demonstrate that the proposed method achieves state-of-the-art perfor-mance on three popular benchmarks with high computa-tional efﬁciency. The code has been released at https://github.com/wintersun661/MMNet. 