While learning-based multi-view stereo (MVS) methods have recently shown successful performances in quality and efﬁciency, limited MVS data hampers generalization to un-seen environments. A simple solution is to generate vari-ous large-scale MVS datasets, but generating dense ground truth for 3D structure requires a huge amount of time and resources. On the other hand, if the reliance on dense ground truth is relaxed, MVS systems will generalize more smoothly to new environments. To this end, we ﬁrst intro-duce a novel semi-supervised multi-view stereo framework called a Sparse Ground truth-based MVS Network (SGT-MVSNet) that can reliably reconstruct the 3D structures even with a few ground truth 3D points. Our strategy is to divide the accurate and erroneous regions and individu-ally conquer them based on our observation that a proba-bility map can separate these regions. We propose a self-supervision loss called the 3D Point Consistency Loss to enhance the 3D reconstruction performance, which forces the 3D points back-projected from the corresponding pixels by the predicted depth values to meet at the same 3D co-ordinates. Finally, we propagate these improved depth pre-dictions toward edges and occlusions by the Coarse-to-ﬁneReliable Depth Propagation module. We generate the spare ground truth of the DTU dataset for evaluation and exten-sive experiments verify that our SGT-MVSNet outperforms the state-of-the-art MVS methods on the sparse ground truth setting. Moreover, our method shows comparable recon-struction results to the supervised MVS methods though we only used tens and hundreds of ground truth 3D points. 