Recently, contrastive learning has achieved great results in self-supervised learning, where the main idea is to pull two augmentations of an image (positive pairs) closer com-pared to other random images (negative pairs). We argue that not all negative images are equally negative. Hence, we introduce a self-supervised learning algorithm where we use a soft similarity for the negative images rather than a binary distinction between positive and negative pairs. We iteratively distill a slowly evolving teacher model to the stu-dent model by capturing the similarity of a query image to some random images and transferring that knowledge to the student. Specifically, our method should handle unbal-anced and unlabeled data better than existing contrastive learning methods, because the randomly chosen negative set might include many samples that are semantically simi-lar to the query image. In this case, our method labels them as highly similar while standard contrastive methods label them as negatives. Our method achieves comparable results to the state-of-the-art models. Our code is available here: https://github.com/UMBCvision/ISD. 