With the development of 3D scanning technologies, 3D vision tasks have become a popular research area. Ow-ing to the large amount of data acquired by sensors, un-supervised learning is essential for understanding and uti-lizing point clouds without an expensive annotation pro-cess.In this paper, we propose a novel framework and an effective auto-encoder architecture named “PSG-Net” for reconstruction-based learning of point clouds. Unlike existing studies that used fixed or random 2D points, our framework generates input-dependent point-wise features for the latent point set. PSG-Net uses the encoded input to produce point-wise features through the seed generation module and extracts richer features in multiple stages with gradually increasing resolution by applying the seed fea-ture propagation module progressively. We prove the effec-tiveness of PSG-Net experimentally; PSG-Net shows state-of-the-art performances in point cloud reconstruction and unsupervised classification, and achieves comparable per-formance to counterpart methods in supervised completion. 