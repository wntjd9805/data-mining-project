Achieving backward compatibility when rolling out new models can highly reduce costs or even bypass feature re-encoding of existing gallery images for in-production vi-sual retrieval systems. Previous related works usually lever-age losses used in knowledge distillation which can cause performance degradations or not guarantee compatibility.To address these issues, we propose a general framework called Learning Compatible Embeddings (LCE) which is applicable for both cross model compatibility and com-patible training in direct/forward/backward manners. Our compatibility is achieved by aligning class centers between models directly or via a transformation, and restricting more compact intra-class distributions for the new model.Experiments are conducted in extensive scenarios such as changes of training dataset, loss functions, network archi-tectures as well as feature dimensions, and demonstrate thatLCE efficiently enables model compatibility with marginal sacrifices of accuracies. The code will be available at https://github.com/IrvingMeng/LCE. 