Contrastive learning, which aims at minimizing the dis-tance between positive pairs while maximizing that of neg-ative ones, has been widely and successfully applied in un-supervised feature learning, where the design of positive and negative (pos/neg) pairs is one of its keys.In this paper, we attempt to devise a feature-level data manipu-lation, differing from data augmentation, to enhance the generic contrastive self-supervised learning. To this end, we first design a visualization scheme for pos/neg score1 distribution, which enables us to analyze, interpret and un-derstand the learning process. To our knowledge, this is the first attempt of its kind. More importantly, leveraging this tool, we gain some significant observations, which in-spire our novel Feature Transformation proposals includ-ing the extrapolation of positives. This operation creates harder positives to boost the learning because hard pos-itives enable the model to be more view-invariant. Be-sides, we propose the interpolation among negatives, which provides diversified negatives and makes the model more discriminative.It is the first attempt to deal with both challenges simultaneously. Experiment results show that our proposed Feature Transformation can improve at least 6.0% accuracy on ImageNet-100 over MoCo baseline, and about 2.0% accuracy on ImageNet-1K over the MoCoV2 baseline. Transferring to the downstream tasks success-fully demonstrate our model is less task-bias. Visualization tools and codes: https://github.com/DTennant/CL-Visualizing-Feature-Transformation. 