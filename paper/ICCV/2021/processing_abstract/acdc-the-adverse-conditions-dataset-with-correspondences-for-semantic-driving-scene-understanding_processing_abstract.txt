Level 5 autonomy for self-driving cars requires a robust visual perception system that can parse input images under any visual condition. However, existing semantic segmenta-tion datasets are either dominated by images captured un-der normal conditions or are small in scale. To address this, we introduce ACDC, the Adverse Conditions Dataset withCorrespondences for training and testing semantic segmen-tation methods on adverse visual conditions. ACDC con-sists of a large set of 4006 images which are equally dis-tributed between four common adverse conditions: fog, nighttime, rain, and snow. Each adverse-condition image comes with a high-quality ﬁne pixel-level semantic anno-tation, a corresponding image of the same scene taken un-der normal conditions, and a binary mask that distinguishes between intra-image regions of clear and uncertain seman-tic content. Thus, ACDC supports both standard semantic segmentation and the newly introduced uncertainty-aware semantic segmentation. A detailed empirical study demon-strates the challenges that the adverse domains of ACDC pose to state-of-the-art supervised and unsupervised ap-proaches and indicates the value of our dataset in steering future progress in the ﬁeld. Our dataset and benchmark are publicly available. 