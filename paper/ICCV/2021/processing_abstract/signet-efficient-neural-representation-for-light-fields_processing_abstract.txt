We present a novel neural representation for light ﬁeld content that enables compact storage and easy local recon-struction with high ﬁdelity. We use a fully-connected neural network to learn the mapping function between each lightﬁeld pixel’s coordinates and its corresponding color val-ues. Since neural networks that simply take in raw coor-dinates are unable to accurately learn data containing ﬁne details, we present an input transformation strategy based on the Gegenbauer polynomials, which previously showed theoretical advantages over the Fourier basis. We conduct experiments that show our Gegenbauer-based design com-bined with sinusoidal activation functions leads to a bet-ter light ﬁeld reconstruction quality than a variety of net-work designs, including those with Fourier-inspired tech-niques introduced by prior works. Moreover, our SInusoidalGegenbauer NETwork, or SIGNET, can represent light ﬁeld scenes more compactly than the state-of-the-art compres-sion methods while maintaining a comparable reconstruc-tion quality. SIGNET also innately allows random access to encoded light ﬁeld pixels due to its functional design. We further demonstrate that SIGNET’s super-resolution capa-bility without any additional training. 