Unsupervised disentanglement learning is a crucial is-sue for understanding and exploiting deep generative mod-els. Recently, SeFa tries to find latent disentangled direc-tions by performing SVD on the first projection of a pre-trained GAN. However, it is only applied to the first layer and works in a post-processing way. Hessian Penalty mini-mizes the off-diagonal entries of the output’s Hessian ma-trix to facilitate disentanglement, and can be applied to multi-layers. However, it constrains each entry of output independently, making it not sufficient in disentangling the latent directions (e.g., shape, size, rotation, etc.) of spa-tially correlated variations. In this paper, we propose a sim-ple Orthogonal Jacobian Regularization (OroJaR) to en-courage deep generative model to learn disentangled rep-resentations. It simply encourages the variation of output caused by perturbations on different latent dimensions to be orthogonal, and the Jacobian with respect to the in-put is calculated to represent this variation. We show that our OroJaR also encourages the output’s Hessian matrix to be diagonal in an indirect manner.In contrast to theHessian Penalty, our OroJaR constrains the output in a holistic way, making it very effective in disentangling la-tent dimensions corresponding to spatially correlated vari-ations. Quantitative and qualitative experimental results show that our method is effective in disentangled and con-trollable image generation, and performs favorably against the state-of-the-art methods. Our code is available at https://github.com/csyxwei/OroJaR. 