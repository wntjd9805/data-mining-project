Motion blur is one of the major challenges remaining for visual odometry methods. In low-light conditions where longer exposure times are necessary, motion blur can ap-pear even for relatively slow camera motions. In this paper we present a novel hybrid visual odometry pipeline with di-rect approach that explicitly models and estimates the cam-eraâ€™s local trajectory within the exposure time. This al-lows us to actively compensate for any motion blur that occurs due to the camera motion.In addition, we also contribute a novel benchmarking dataset for motion blur aware visual odometry. In experiments we show that by di-rectly modeling the image formation process, we are able to improve robustness of the visual odometry, while keep-ing comparable accuracy as that for images without mo-tion blur. Both the code and the datasets can be found from https://github.com/ethliup/MBA-VO. 