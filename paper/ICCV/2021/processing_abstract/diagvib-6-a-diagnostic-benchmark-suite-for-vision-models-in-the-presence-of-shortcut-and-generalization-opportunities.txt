Common deep neural networks (DNNs) for image clas-siﬁcation have been shown to rely on shortcut opportunities (SO) in the form of predictive and easy-to-represent visual factors. This is known as shortcut learning and leads to im-paired generalization. In this work, we show that commonDNNs also suffer from shortcut learning when predicting only basic visual object factors of variation (FoV) such as shape, color, or texture. We argue that besides shortcut op-portunities, generalization opportunities (GO) are also an inherent part of real-world vision data and arise from par-tial independence between predicted classes and FoVs. We also argue that it is necessary for DNNs to exploit GO to overcome shortcut learning. Our core contribution is to in-troduce the Diagnostic Vision Benchmark suite DiagViB-6, which includes datasets and metrics to study a network’s shortcut vulnerability and generalization capability for six independent FoV. In particular, DiagViB-6 allows control-ling the type and degree of SO and GO in a dataset. We benchmark a wide range of popular vision architectures and show that they can exploit GO only to a limited extent.) 2 r o t c a f e p a h s d e t c i d e r p ( 4 3 blue red green hue factor? test (OOD) shortcut opp. gen. opp. trainFigure 1: Exemplar study in our proposed benchmark. The network is trained to predict factor classes 2, 4, 3 for the shape factor with varying hue. All ﬁve depicted train-ing combinations are uniformly shown during training. The shape 2 co-occurs solely with the blue class of the hue factor, which poses a shortcut opportunity. The shapes 4 and 3 occur uniformly with hue red and green; these combinations pose a generalization opportunity, since they reduce the predictiveness of the hue factor for the shape factor. Test accuracy is computed on examples from OOD factor combinations to evaluate a model’s shortcut vulnera-bility in the context of the given generalization opportunity. 