Instance-level image retrieval is the task of searching in a large database for images that match an object in a query image. To address this task, systems usually rely on a retrieval step that uses global image descriptors, and a subsequent step that performs domain-speciﬁc reﬁnements or reranking by leveraging operations such as geometric veriﬁcation based on local features. In this work, we pro-pose Reranking Transformers (RRTs) as a general model to incorporate both local and global features to rerank the matching images in a supervised fashion and thus replace the relatively expensive process of geometric veriﬁcation.RRTs are lightweight and can be easily parallelized so that reranking a set of top matching results can be performed in a single forward-pass. We perform extensive experiments on the Revisited Oxford and Paris datasets, and the GoogleLandmarks v2 dataset, showing that RRTs outperform pre-vious reranking approaches while using much fewer local descriptors. Moreover, we demonstrate that, unlike exist-ing approaches, RRTs can be optimized jointly with the fea-ture extractor, which can lead to feature representations tai-lored to downstream tasks and further accuracy improve-ments. The code and trained models are publicly available at https://github.com/uvavision/RerankingTransformer. 