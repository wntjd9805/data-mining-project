Recently, the power of unconditional image synthesis has signiﬁcantly advanced through the use of Generative Ad-versarial Networks (GANs). The task of inverting an image into its corresponding latent code of the trained GAN is of utmost importance as it allows for the manipulation of real images, leveraging the rich semantics learned by the net-work. Recognizing the limitations of current inversion ap-proaches, in this work we present a novel inversion scheme that extends current encoder-based inversion methods by in-troducing an iterative reﬁnement mechanism. Instead of di-rectly predicting the latent code of a given real image us-ing a single pass, the encoder is tasked with predicting a residual with respect to the current estimate of the inverted latent code in a self-correcting manner. Our residual-based encoder, named ReStyle, attains improved accuracy compared to current state-of-the-art encoder-based meth-ods with a negligible increase in inference time. We ana-lyze the behavior of ReStyle to gain valuable insights into its iterative nature. We then evaluate the performance of our residual encoder and analyze its robustness com-pared to optimization-based inversion and state-of-the-art encoders. Code is available via our project page: https://yuval-alaluf.github.io/restyle-encoder/ 