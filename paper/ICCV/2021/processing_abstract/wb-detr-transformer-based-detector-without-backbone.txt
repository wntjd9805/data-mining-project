Transformer-based detector is a new paradigm in ob-ject detection, which aims to achieve pretty-well perfor-mance while eliminates the priori knowledge driven com-ponents, e.g., anchors, proposals and the NMS. DETR, the state-of-the-art model among them, is composed of three sub-modules, i.e., a CNN-based backbone and paired trans-former encoder-decoder. The CNN is applied to extract lo-cal features and the transformer is used to capture global contexts. This pipeline, however, is not concise enough. In this paper, we propose WB-DETR (DETR-based detectorWithout Backbone) to prove that the reliance on CNN fea-tures extraction for a transformer-based detector is not nec-essary. Unlike the original DETR, WB-DETR is composed of only an encoder and a decoder without CNN backbone.For an input image, WB-DETR serializes it directly to en-code the local features into each individual token. To make up the deﬁciency of transformer in modeling local informa-tion, we design an LIE-T2T (local information enhancement tokens to token) module to enhance the internal information of tokens after unfolding. Experimental results demonstrate that WB-DETR, the ﬁrst pure-transformer detector withoutCNN to our knowledge, yields on par accuracy and faster inference speed with only half number of parameters com-pared with DETR baseline. 