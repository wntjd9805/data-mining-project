We describe a simple pre-training approach for point clouds. It works in three steps: 1. Mask all points occluded in a camera view; 2. Learn an encoder-decoder model to reconstruct the occluded points; 3. Use the encoder weights as initialisation for downstream point cloud tasks.We ﬁnd that even when we pre-train on a single dataset (ModelNet40), this method improves accuracy across dif-ferent datasets and encoders, on a wide range of down-stream tasks. Speciﬁcally, we show that our method out-performs previous pre-training methods in object classi-ﬁcation, and both part-based and semantic segmentation tasks. We study the pre-trained features and ﬁnd that they lead to wide downstream minima, have high transforma-tion invariance, and have activations that are highly cor-related with part labels. Code and data are available at: https://github.com/hansen7/OcCo 