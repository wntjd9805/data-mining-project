Style transfer aims to reproduce content images with the styles from reference images. Existing universal style trans-fer methods successfully deliver arbitrary styles to origi-nal images either in an artistic or a photo-realistic way.However, the range of “arbitrary style” defined by exist-ing works is bounded in the particular domain due to their structural limitation. Specifically, the degrees of content preservation and stylization are established according to a predefined target domain. As a result, both photo-realistic and artistic models have difficulty in performing the desired style transfer for the other domain. To overcome this lim-itation, we propose a unified architecture, Domain-awareStyle Transfer Networks (DSTN) that transfer not only the style but also the property of domain (i.e., domainness) from* Corresponding author a given reference image. To this end, we design a novel domainness indicator that captures the domainness value from the texture and structural features of reference images.Moreover, we introduce a unified framework with domain-aware skip connection to adaptively transfer the stroke and palette to the input contents guided by the domainness in-dicator. Our extensive experiments validate that our model produces better qualitative results and outperforms pre-vious methods in terms of proxy metrics on both artistic and photo-realistic stylizations. All codes and pre-trained weights are available at Kibeom-Hong/Domain-Aware-Style-Transfer. 