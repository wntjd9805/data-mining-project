Transformers have been recently adapted for large scale image classiﬁcation, achieving high scores shaking up the long supremacy of convolutional neural networks. However the optimization of vision transformers has been little stud-ied so far. In this work, we build and optimize deeper trans-former networks for image classiﬁcation. In particular, we investigate the interplay of architecture and optimization of such dedicated transformers. We make two architec-ture changes that signiﬁcantly improve the accuracy of deep transformers. This leads us to produce models whose per-formance does not saturate early with more depth, for in-stance we obtain 86.5% top-1 accuracy on Imagenet when training with no external data, we thus attain the current sate of the art with less ﬂoating-point operations and pa-rameters. Our best model establishes the new state of the art on Imagenet with Reassessed labels and Imagenet-V2 / match frequency, in the setting with no additional training data. We share our code and models1. 