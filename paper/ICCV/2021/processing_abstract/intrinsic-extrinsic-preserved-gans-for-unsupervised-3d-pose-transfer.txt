With the strength of deep generative models, 3D pose transfer regains intensive research interests in recent years.Existing methods mainly rely on a variety of constraints to achieve the pose transfer over 3D meshes, e.g., the need for manually encoding for shape and pose disentangle-ment. In this paper, we present an unsupervised approach to conduct the pose transfer between any arbitrate given 3D meshes. Speciﬁcally, a novel Intrinsic-Extrinsic PreservedGenerative Adversarial Network (IEP-GAN) is presented for both intrinsic (i.e., shape) and extrinsic (i.e., pose) in-formation preservation. Extrinsically, we propose a co-occurrence discriminator to capture the structural/pose in-variance from distinct Laplacians of the mesh. Meanwhile, intrinsically, a local intrinsic-preserved loss is introduced to preserve the geodesic priors while avoiding heavy com-putations. At last, we show the possibility of using IEP-GAN to manipulate 3D human meshes in various ways, including pose transfer, identity swapping and pose interpolation with latent code vector arithmetic. The extensive experiments on various 3D datasets of humans, animals and hands qualita-tively and quantitatively demonstrate the generality of our approach. Our proposed model produces better results and is substantially more efﬁcient compared to recent state-of-the-art methods. Code is available: https://github. com/mikecheninoulu/Unsupervised_IEPGAN 