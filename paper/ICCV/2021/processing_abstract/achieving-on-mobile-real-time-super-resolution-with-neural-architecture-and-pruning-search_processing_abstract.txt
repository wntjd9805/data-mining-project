Though recent years have witnessed remarkable progress in single image super-resolution (SISR) tasks with the prosperous development of deep neural networks (DNNs), the deep learning methods are confronted with the computation and memory consumption issues in prac-tice, especially for resource-limited platforms such as mo-bile devices. To overcome the challenge and facilitate the real-time deployment of SISR tasks on mobile, we combine neural architecture search with pruning search and propose an automatic search framework that derives sparse super-resolution (SR) models with high image quality while sat-isfying the real-time inference requirement. To decrease the search cost, we leverage the weight sharing strat-egy by introducing a supernet and decouple the search problem into three stages, including supernet construc-tion, compiler-aware architecture and pruning search, and compiler-aware pruning ratio search. With the proposed framework, we are the Ô¨Årst to achieve real-time SR infer-ence (with only tens of milliseconds per frame) for imple-menting 720p resolution with competitive image quality (in terms of PSNR and SSIM) on mobile platforms (SamsungGalaxy S20). 