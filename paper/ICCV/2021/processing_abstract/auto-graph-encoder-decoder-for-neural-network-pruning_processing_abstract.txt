Model compression aims to deploy deep neural networks (DNN) on mobile devices with limited computing and stor-age resources. However, most of the existing model com-pression methods rely on manually defined rules, which re-quire domain expertise. DNNs are essentially computa-tional graphs, which contain rich structural information.In this paper, we aim to find a suitable compression policy from DNNs’ structural information. We propose an auto-matic graph encoder-decoder model compression (AGMC) method combined with graph neural networks (GNN) and reinforcement learning (RL). We model the target DNN as a graph and use GNN to learn the DNN’s embeddings auto-matically. We compared our method with rule-based DNN embedding model compression methods to show the effec-tiveness of our method. Results show that our learning-based DNN embedding achieves better performance and a higher compression ratio with fewer search steps. We evalu-ated our method on over-parameterized and mobile-friendlyDNNs and compared our method with handcrafted and learning-based model compression approaches. On over parameterized DNNs, such as ResNet-56, our method out-performed handcrafted and learning-based methods with 4.36% and 2.56% higher accuracy, respectively. Further-more, on MobileNet-v2, we achieved a higher compression ratio than state-of-the-art methods with just 0.93% accu-racy loss. 