We present LaLaLoc to localise in environments with-out the need for prior visitation, and in a manner that is robust to large changes in scene appearance, such as a full rearrangement of furniture. Specifically, LaLaLoc per-forms localisation through latent representations of room layout. LaLaLoc learns a rich embedding space shared be-tween RGB panoramas and layouts inferred from a known floor plan that encodes the structural similarity between lo-cations. Further, LaLaLoc introduces direct, cross-modal pose optimisation in its latent space. Thus, LaLaLoc en-ables fine-grained pose estimation in a scene without the need for prior visitation, as well as being robust to dy-namics, such as a change in furniture configuration. We show that in a domestic environment LaLaLoc is able to ac-curately localise a single RGB panorama image to within 8.3cm, given only a floor plan as a prior. 