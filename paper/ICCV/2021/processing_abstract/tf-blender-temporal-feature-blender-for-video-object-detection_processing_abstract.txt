Video objection detection is a challenging task because isolated video frames may encounter appearance deterio-ration, which introduces great confusion for detection. One of the popular solutions is to exploit the temporal informa-tion and enhance per-frame representation through aggre-gating features from neighboring frames. Despite achiev-ing improvements in detection, existing methods focus on the selection of higher-level video frames for aggregation rather than modeling lower-level temporal relations to in-crease the feature representation. To address this lim-itation, we propose a novel solution named TF-Blender, which includes three modules: 1) Temporal relation mod-els the relations between the current frame and its neigh-boring frames to preserve spatial information. 2). Fea-ture adjustment enriches the representation of every neigh-boring feature map; 3) Feature blender combines out-puts from the Ô¨Årst two modules and produces stronger fea-tures for the later detection tasks. For its simplicity, TF-Blender can be effortlessly plugged into any detection net-work to improve detection behavior. Extensive evalua-tions on ImageNet VID and YouTube-VIS benchmarks in-dicate the performance guarantees of using TF-Blender on recent state-of-the-art methods. Code is available at https://github.com/goodproj13/TF-Blender. 