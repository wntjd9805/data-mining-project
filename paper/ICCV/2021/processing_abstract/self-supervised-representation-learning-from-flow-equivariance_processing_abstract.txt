Self-supervised representation learning is able to learn semantically meaningful features; however, much of its re-cent success relies on multiple crops of an image with very few objects. Instead of learning view-invariant representa-tion from simple images, humans learn representations in a complex world with changing scenes by observing ob-ject movement, deformation, pose variation and ego motion.Motivated by this ability, we present a new self-supervised learning representation framework that can be directly de-ployed on a video stream of complex scenes with many mov-ing objects. Our framework features a simple flow equiv-ariance objective that encourages the network to predict the features of another frame by applying a flow transformation to the features of the current frame. Our representations, learned from high-resolution raw video, can be readily used for downstream tasks on static images. Readout experi-ments on challenging semantic segmentation, instance seg-mentation, and object detection benchmarks show that we are able to outperform representations obtained from pre-vious state-of-the-art methods including SimCLR [6] andBYOL [18]. 