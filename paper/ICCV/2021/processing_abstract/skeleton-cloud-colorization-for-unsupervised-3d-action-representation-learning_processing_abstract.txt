Skeleton-based human action recognition has attracted increasing attention in recent years. However, most of the existing works focus on supervised learning which re-quiring a large number of annotated action sequences that are often expensive to collect. We investigate unsuper-vised representation learning for skeleton action recogni-tion, and design a novel skeleton cloud colorization tech-nique that is capable of learning skeleton representations from unlabeled skeleton sequence data. Specifically, we represent a skeleton action sequence as a 3D skeleton cloud and colorize each point in the cloud according to its temporal and spatial orders in the original (unanno-tated) skeleton sequence. Leveraging the colorized skele-ton point cloud, we design an auto-encoder framework that can learn spatial-temporal features from the artificial color labels of skeleton joints effectively. We evaluate our skeleton cloud colorization approach with action classifiers trained under different configurations, including unsuper-vised, semi-supervised and fully-supervised settings. Exten-sive experiments on NTU RGB+D and NW-UCLA datasets show that the proposed method outperforms existing unsu-pervised and semi-supervised 3D action recognition meth-ods by large margins, and it achieves competitive perfor-mance in supervised 3D action recognition as well. 