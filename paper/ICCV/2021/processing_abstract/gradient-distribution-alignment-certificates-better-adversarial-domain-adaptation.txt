The latest heuristic for handling the domain shift in un-supervised domain adaptation tasks is to reduce the data distribution discrepancy using adversarial learning. Recent studies improve the conventional adversarial domain adap-tation methods with discriminative information by integrat-ing the classifierâ€™s outputs into distribution divergence mea-surement. However, they still suffer from the equilibrium problem of adversarial learning in which even if the dis-criminator is fully confused, sufficient similarity between two distributions cannot be guaranteed. To overcome this problem, we propose a novel approach named feature gra-dient distribution alignment (FGDA)1. We demonstrate the rationale of our method both theoretically and empirically.In particular, we show that the distribution discrepancy can be reduced by constraining feature gradients of two do-mains to have similar distributions. Meanwhile, our method enjoys a theoretical guarantee that a tighter error upper bound for target samples can be obtained than that of con-ventional adversarial domain adaptation methods. By inte-grating the proposed method with existing adversarial do-main adaptation models, we achieve state-of-the-art perfor-mance on two real-world benchmark datasets.Illustration of Feature Gradient Distribution Align-Figure 1. ment (FGDA). (a)-(c): When features of two domains distribute very differently due to large domain shift, their gradients in non-overlapping regions may disperse in distinct parts of the highly complicated decision boundary, which leads to a large gradient distribution discrepancy. With the gradient alignment, the over-(a)-(b): lapping region is enlarged to reduce the domain shift.Domain shift measured by the conventional adversarial domain adaptation method tends to be zero when two mean features are close enough. In this case, conventional methods fail to further reduce the domain shift. (b)-(c): Even if the distance between two mean features is small, the domain shift measured by our method (in terms of feature gradient discrepancy) can be still observed due to obvious different gradients in non-overlapping regions. FGDA can certificate a further domain shift reduction. 