There has been a booming demand for integrating Con-volutional Neural Networks (CNNs) powered functionali-ties into Internet-of-Thing (IoT) devices to enable ubiqui-tous intelligent “IoT cameras”. However, more extensive applications of such IoT systems are still limited by two challenges. First, some applications, especially medicine-and wearable-related ones, impose stringent requirements on the camera form factor. Second, powerful CNNs of-ten require considerable storage and energy cost, whereasIoT devices often suffer from limited resources. PhlatCam, with its form factor potentially reduced by orders of magni-tude, has emerged as a promising solution to the first afore-mentioned challenge, while the second one remains a bot-tleneck. Existing compression techniques, which can po-tentially tackle the second challenge, are far from realiz-ing the full potential in storage and energy reduction, be-cause they mostly focus on the CNN algorithm itself. To this end, this work proposes SACoD, a Sensor Algorithm Co-Design framework to develop more efficient CNN-poweredPhlatCam.In particular, the mask coded in the Phlat-Cam sensor and the backend CNN model are jointly op-timized in terms of both model parameters and architec-tures via differential neural architecture search. Extensive experiments including both simulation and physical mea-surement on manufactured masks show that the proposedSACoD framework achieves aggressive model compression and energy savings while maintaining or even boosting the task accuracy, when benchmarking over two state-of-the-art (SOTA) designs with six datasets across four different vision tasks including classification, segmentation, image translation, and face recognition. Our codes are available at: https://github.com/RICE-EIC/SACoD. 