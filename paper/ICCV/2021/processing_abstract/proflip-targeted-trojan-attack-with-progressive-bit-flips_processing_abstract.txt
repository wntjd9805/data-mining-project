The security of Deep Neural Networks (DNNs) is of great importance due to their employment in various safety-critical applications. DNNs are shown to be vulnerable against the Trojan attack that manipulates model param-eters via poisoned training and gets activated by the pre-defined trigger during inference. In this work, we presentProFlip, the first targeted Trojan attack framework that can divert the prediction of the DNN to the target class by pro-gressively identifying and flipping a small set of bits in model parameters. At its core, ProFlip consists of three key phases: (i) Determining significant neurons in the last layer; (ii) Generating an effective trigger pattern for the tar-get class; (iii) Identifying a sequence of susceptible bits ofDNN parameters stored in the main memory (e.g., DRAM).After model deployment, the adversary can insert the Tro-jan by flipping the critical bits found by ProFlip using bit flip techniques such as Row Hammer or laser beams. As the result, the altered DNN predicts the target class when the trigger pattern is present in any inputs. We perform ex-tensive evaluations of ProFlip on CIFAR10, SVHN, and Im-ageNet datasets with ResNet-18 and VGG-16 architectures.Empirical results show that, to reach an attack success rate (ASR) of over 94%, ProFlip requires only 12 bit flips out of 88 million parameter bits for ResNet-18 with CIFAR-10, and 15 bit flips for ResNet-18 with ImageNet. Compared to the SOTA, ProFlip reduces the number of required bits flips by 28× ∼ 34× while reaching the same or higher ASR. 