We propose a novel approach for probabilistic genera-tive modeling of 3D shapes. Unlike most existing models that learn to deterministically translate a latent vector to a shape, our model, Point-Voxel Diffusion (PVD), is a unified, probabilistic formulation for unconditional shape genera-tion and conditional, multi-modal shape completion. PVD marries denoising diffusion models with the hybrid, point-voxel representation of 3D shapes. It can be viewed as a series of denoising steps, reversing the diffusion process from observed point cloud data to Gaussian noise, and is trained by optimizing a variational lower bound to the (con-ditional) likelihood function. Experiments demonstrate thatPVD is capable of synthesizing high-fidelity shapes, com-pleting partial point clouds, and generating multiple com-pletion results from single-view depth scans of real objects. 