The key challenge in learning dense correspondences lies in the lack of ground-truth matches for real image pairs.While photometric consistency losses provide unsupervised alternatives, they struggle with large appearance changes, which are ubiquitous in geometric and semantic matching tasks. Moreover, methods relying on synthetic training pairs often suffer from poor generalisation to real data.We propose Warp Consistency, an unsupervised learn-ing objective for dense correspondence regression. Our objective is effective even in settings with large appear-ance and view-point changes. Given a pair of real im-ages, we first construct an image triplet by applying a ran-domly sampled warp to one of the original images. We derive and analyze all flow-consistency constraints aris-ing between the triplet. From our observations and em-pirical results, we design a general unsupervised objec-tive employing two of the derived constraints. We val-idate our warp consistency loss by training three recent dense correspondence networks for the geometric and se-mantic matching tasks. Our approach sets a new state-of-the-art on several challenging benchmarks, includingMegaDepth, RobotCar and TSS. Code and models are at github.com/PruneTruong/DenseMatching. 