In this paper, we propose MINE to perform novel view synthesis and depth estimation via dense 3D reconstruc-tion from a single image. Our approach is a continu-ous depth generalization of the Multiplane Images (MPI) by introducing the NEural radiance fields (NeRF). Given a single image as input, MINE predicts a 4-channel im-age (RGB and volume density) at arbitrary depth values to jointly reconstruct the camera frustum and fill in oc-cluded contents. The reconstructed and inpainted frustum can then be easily rendered into novel RGB or depth views using differentiable rendering. Extensive experiments onRealEstate10K, KITTI and Flowers Light Fields show that our MINE outperforms state-of-the-art by a large margin in novel view synthesis. We also achieve competitive results in depth estimation on iBims-1 and NYU-v2 without anno-tated depth supervision. Our source code is available at https://github.com/vincentfung13/MINE. 