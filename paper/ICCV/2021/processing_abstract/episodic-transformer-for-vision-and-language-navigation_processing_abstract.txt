Interaction and navigation deﬁned by natural language instructions in dynamic environments pose signiﬁcant chal-lenges for neural agents. This paper focuses on addressing two challenges: handling long sequence of subtasks, and understanding complex human instructions. We proposeEpisodic Transformer (E.T.), a multimodal transformer that encodes language inputs and the full episode history of vi-sual observations and actions. To improve training, we leverage synthetic instructions as an intermediate represen-tation that decouples understanding the visual appearance of an environment from the variations of natural language instructions. We demonstrate that encoding the history with a transformer is critical to solve compositional tasks, and that pretraining and joint training with synthetic instruc-tions further improve the performance. Our approach sets a new state of the art on the challenging ALFRED bench-mark, achieving 38.4% and 8.5% task success rates on seen and unseen test splits. 