Forecasting complex vehicle and pedestrian multi-modal distributions requires powerful probabilistic approaches.Normalizing ﬂows (NF) have recently emerged as an attrac-tive tool to model such distributions. However, a key draw-back is that independent samples drawn from a ﬂow model often do not adequately capture all the modes in the under-lying distribution. We propose Likelihood-Based DiverseSampling (LDS), a method for improving the quality and the diversity of trajectory samples from a pre-trained ﬂow model. Rather than producing individual samples, LDS pro-duces a set of trajectories in one shot. Given a pre-trained forecasting ﬂow model, we train LDS using gradients from the model, to optimize an objective function that rewards high likelihood for individual trajectories in the predicted set, together with high spatial separation among trajecto-ries. LDS outperforms state-of-art post-hoc neural diverse forecasting methods for various pre-trained ﬂow models as well as conditional variational autoencoder (CVAE) mod-els. Crucially, it can also be used for transductive trajectory forecasting, where the diverse forecasts are trained on-the-ﬂy on unlabeled test examples. LDS is easy to implement, and we show that it offers a simple plug-in improvement over baselines on two challenging benchmarks. Code is at: https://github.com/JasonMa2016/LDS 