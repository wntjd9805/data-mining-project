Applying feature dependent network weights have been proved to be effective in many ﬁelds. However, in prac-tice, restricted by the enormous size of model parameters and memory footprints, scalable and versatile dynamic con-volutions with per-pixel adapted ﬁlters are yet to be fully explored. In this paper, we address this challenge by de-composing ﬁlters, adapted to each spatial position, over dy-namic ﬁlter atoms generated by a light-weight network from local features. Adaptive receptive ﬁelds can be supported by further representing each ﬁlter atom over sets of pre-ﬁxed multi-scale bases. As plug-and-play replacements to convolutional layers, the introduced adaptive convolutions with per-pixel dynamic atoms enable explicit modeling of intra-image variance, while avoiding heavy computation, parameters, and memory cost. Our method preserves the appealing properties of conventional convolutions as be-ing translation-equivariant and parametrically efﬁcient. We present experiments to show that, the proposed method de-livers comparable or even better performance across tasks, and are particularly effective on handling tasks with signif-icant intra-image variance. 