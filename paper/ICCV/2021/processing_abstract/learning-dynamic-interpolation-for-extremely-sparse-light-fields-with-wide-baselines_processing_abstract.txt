In this paper, we tackle the problem of dense light field (LF) reconstruction from sparsely-sampled ones with wide baselines and propose a learnable model, namely dy-namic interpolation, to replace the commonly-used geome-try warping operation. Specifically, with the estimated ge-ometric relation between input views, we first construct a lightweight neural network to dynamically learn weights for interpolating neighbouring pixels from input views to synthesize each pixel of novel views independently. In con-trast to the fixed and content-independent weights employed in the geometry warping operation, the learned interpo-lation weights implicitly incorporate the correspondences between the source and novel views and adapt to differ-ent image content information. Then, we recover the spa-tial correlation between the independently synthesized pix-els of each novel view by referring to that of input views using a geometry-based spatial refinement module. We also constrain the angular correlation between the novel views through a disparity-oriented LF structure loss. Experimen-tal results on LF datasets with wide baselines show that the reconstructed LFs achieve much higher PSNR/SSIM and preserve the LF parallax structure better than state-of-the-art methods. The source code is publicly available at https://github.com/MantangGuo/DI4SLF. 