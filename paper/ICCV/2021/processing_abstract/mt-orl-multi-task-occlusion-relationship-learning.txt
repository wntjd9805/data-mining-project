Retrieving occlusion relation among objects in a single image is challenging due to sparsity of boundaries in im-age. We observe two key issues in existing works: ﬁrstly, lack of an architecture which can exploit the limited amount of coupling in the decoder stage between the two subtasks, namely occlusion boundary extraction and occlusion orien-tation prediction, and secondly, improper representation ofIn this paper, we propose a novel occlusion orientation. architecture called Occlusion-shared and Path-separatedNetwork (OPNet), which solves the ﬁrst issue by exploit-ing rich occlusion cues in shared high-level features and structured spatial information in task-speciﬁc low-level fea-tures. We then design a simple but effective orthogonal occlusion representation (OOR) to tackle the second is-sue. Our method surpasses the state-of-the-art methods by 6.1%/8.3% Boundary-AP and 6.5%/10% Orientation-AP on standard PIOD/BSDS ownership datasets. Code is available at https://github.com/fengpanhe/MT-ORL. 