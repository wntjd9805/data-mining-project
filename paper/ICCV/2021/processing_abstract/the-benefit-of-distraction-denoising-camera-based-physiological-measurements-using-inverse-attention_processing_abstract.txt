Attention networks perform well on diverse computer vi-sion tasks. The core idea is that the signal of interest is stronger in some pixels (“foreground”), and by selectively focusing computation on these pixels, networks can extract subtle information buried in noise and other sources of cor-ruption. Our paper is based on one key observation: in many real-world applications, many sources of corruption, such as illumination and motion, are often shared between the “foreground” and the “background” pixels. Can we utilize this to our advantage? We propose the utility of inverse attention networks, which focus on extracting in-formation about these shared sources of corruption. We show that this helps to effectively suppress shared covari-ates and amplify signal information, resulting in improved performance. We illustrate this on the task of camera-based physiological measurement where the signal of interest is weak and global illumination variations and motion act as signiﬁcant shared sources of corruption. We perform ex-periments on three datasets and show that our approach of inverse attention produces state-of-the-art results, increas-ing the signal-to-noise ratio by up to 5.8 dB, reducing heart rate and breathing rate estimation errors by as much as 30%, recovering subtle waveform dynamics, and generalizing from RGB to NIR videos without retraining. 