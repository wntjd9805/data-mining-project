The performance of computer vision models signiﬁcantly improves with more labeled data. However, the acquisition of labeled data is limited by the high cost. To mitigate the reliance on large labeled datasets, active learning (AL) and semi-supervised learning (SSL) are frequently adopted. Al-though current mainstream methods begin to combine SSL and AL (SSL-AL) to excavate the diverse expressions of un-labeled samples, these methods’ fully supervised task mod-els are still trained only with labeled data. Besides, these method’s SSL-AL frameworks suffer from mismatch prob-lems. Here, we propose a graph-based SSL-AL framework to unleash the SSL task models’ power and make an effec-tive SSL-AL interaction. In the framework, SSL leverages graph-based label propagation to deliver virtual labels to unlabeled samples, rendering AL samples’ structural distri-bution and boosting AL. AL ﬁnds samples near the clusters’ boundary to help SSL perform better label propagation by exploiting adversarial examples. The information exchange in the closed-loop realizes mutual enhancement of SSL andAL. Experimental results show that our method outperforms the state-of-the-art methods against classiﬁcation and seg-mentation benchmarks. 