Performing simple household tasks based on language directives is very natural to humans, yet it remains an open challenge for AI agents. The ‘interactive instruction follow-ing’ task attempts to make progress towards building agents that jointly navigate, interact, and reason in the environ-ment at every step. To address the multifaceted problem, we propose a model that factorizes the task into interactive perception and action policy streams with enhanced com-ponents and name it as MOCA, a Modular Object-CentricApproach. We empirically validate that MOCA outperforms prior arts by signiﬁcant margins on the ALFRED bench-mark with improved generalization. 