Generative adversarial networks built from deep convo-lutional neural networks (GANs) lack the ability to exactly replicate the high-frequency components of natural images.To alleviate this issue, we introduce two novel training tech-niques called frequency dropping (F-Drop) and frequency matching (F-Match). The key idea of F-Drop is to ﬁlter out unnecessary high-frequency components from the in-put images of the discriminators. This simple modiﬁcation prevents the discriminators from being confused by pertur-bations of the high-frequency components. In addition, F-Drop makes the GANs focus on ﬁtting in the low-frequency domain, in which there are the dominant components of natural images. F-Match minimizes the difference between real and fake images in the frequency domain for generating more realistic images. F-Match is implemented as a regu-larization term in the objective functions of the generators; it penalizes the batch mean error in the frequency domain.F-Match helps the generators to ﬁt in the high-frequency domain ﬁltered out by F-Drop to the real image. We exper-imentally demonstrate that the combination of F-Drop andF-Match improves the generative performance of GANs in both the frequency and spatial domain on multiple image benchmarks. 