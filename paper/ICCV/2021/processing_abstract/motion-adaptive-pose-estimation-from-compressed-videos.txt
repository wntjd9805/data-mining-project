Human pose estimation from videos has many real-world applications. Existing methods focus on applying models with a uniform computation proﬁle on fully de-coded frames, ignoring the freely-available motion signals and motion-compensation residuals from the compressed stream. A novel model, called Motion Adaptive Pose Net is proposed to exploit the compressed streams to efﬁciently de-code pose sequences from videos. The model incorporates aMotion Compensated ConvLSTM to propagate the spatially aligned features, along with an adaptive gate to dynami-cally determine if the computationally expensive features should be extracted from fully decoded frames to compen-sate the motion-warped features, solely based on the resid-ual errors. Leveraging the informative yet readily available signals from compressed streams, we propagate the latent features through our Motion Adaptive Pose Net efﬁcientlyOur model outperforms the state-of-the-art models in pose-estimation accuracy on two widely used datasets with only around half of the computation complexity. 