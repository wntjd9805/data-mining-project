Support MaskMeta-learnedA few-shot semantic segmentation model is typically composed of a CNN encoder, a CNN decoder and a simple classiﬁer (separating foreground and background pixels).Most existing methods meta-learn all three model compo-nents for fast adaptation to a new class. However, given that as few as a single support set image is available, ef-fective model adaption of all three components to the new class is extremely challenging. In this work we propose to simplify the meta-learning task by focusing solely on the simplest component – the classiﬁer, whilst leaving the en-coder and decoder to pre-training. We hypothesize that if we pre-train an off-the-shelf segmentation model over a set of diverse training classes with sufﬁcient annotations, the encoder and decoder can capture rich discriminative fea-tures applicable for any unseen classes, rendering the sub-sequent meta-learning stage unnecessary. For the classi-ﬁer meta-learning, we introduce a Classiﬁer Weight Trans-former (CWT) designed to dynamically adapt the support-set trained classiﬁer’s weights to each query image in an in-ductive way. Extensive experiments on two standard bench-marks show that despite its simplicity, our method outper-forms the state-of-the-art alternatives, often by a large mar-gin. Code is available on https://github.com/zhiheLu/CWT-for-FSS. 