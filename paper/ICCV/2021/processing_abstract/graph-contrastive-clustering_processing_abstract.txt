Recently, some contrastive learning methods have been proposed to simultaneously learn representations and clus-improvements. tering assignments, achieving signiﬁcantHowever, these methods do not take the category infor-mation and clustering objective into consideration, thus the learned representations are not optimal for clustering and the performance might be limited. Towards this issue, we ﬁrst propose a novel graph contrastive learning frame-work, and then apply it to the clustering task, resulting in the Graph Constrastive Clustering (GCC) method. Dif-ferent from basic contrastive clustering that only assumes an image and its augmentation should share similar repre-sentation and clustering assignments, we lift the instance-level consistency to the cluster-level consistency with the assumption that samples in one cluster and their augmen-tations should all be similar. Speciﬁcally, on the one hand, we propose the graph Laplacian based contrastive loss to learn more discriminative and clustering-friendly features.On the other hand, we propose a novel graph-based con-trastive learning strategy to learn more compact cluster-ing assignments. Both of them incorporate the latent cat-egory information to reduce the intra-cluster variance as well as increase the inter-cluster variance. Experiments on six commonly used datasets demonstrate the superiority of our proposed approach over the state-of-the-art methods.1 