As an attempt towards assessing the robustness of em-bodied navigation agents, we propose ROBUSTNAV, a framework to quantify the performance of embodied nav-igation agents when exposed to a wide variety of visual – affecting RGB inputs – and dynamics – affecting transi-tion dynamics – corruptions. Most recent efforts in visual navigation have typically focused on generalizing to novel target environments with similar appearance and dynam-ics characteristics. With ROBUSTNAV, we find that some standard embodied navigation agents significantly under-perform (or fail) in the presence of visual or dynamics cor-ruptions. We systematically analyze the kind of idiosyn-crasies that emerge in the behavior of such agents when operating under corruptions. Finally, for visual corrup-tions in ROBUSTNAV, we show that while standard tech-niques to improve robustness such as data-augmentation and self-supervised adaptation offer some zero-shot resis-tance and improvements in navigation performance, there is still a long way to go in terms of recovering lost perfor-mance relative to clean “non-corrupt” settings, warranting more research in this direction. Our code is available at https://github.com/allenai/robustnav. 