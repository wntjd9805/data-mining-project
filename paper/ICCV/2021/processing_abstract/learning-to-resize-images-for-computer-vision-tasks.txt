For all the ways convolutional neural nets have revo-lutionized computer vision in recent years, one important aspect has received surprisingly little attention: the effect of image size on the accuracy of tasks being trained for.Typically, to be efﬁcient, the input images are resized to a relatively small spatial resolution (e.g. 224 × 224), and both training and inference are carried out at this resolu-tion. The actual mechanism for this re-scaling has been an afterthought: Namely, off-the-shelf image resizers such as bilinear and bicubic are commonly used in most machine learning software frameworks. But do these resizers limit the on-task performance of the trained networks? The an-swer is yes. Indeed, we show that the typical linear resizer can be replaced with learned resizers that can substantially improve performance. Importantly, while the classical re-sizers typically result in better perceptual quality of the downscaled images, our proposed learned resizers do not necessarily give better visual quality, but instead improve task performance.Our learned image resizer is jointly trained with a base-line vision model. This learned CNN-based resizer creates machine friendly visual manipulations that lead to a con-sistent improvement of the end task metric over the baseline model. Speciﬁcally, here we focus on the classiﬁcation task with the ImageNet dataset [26], and experiment with four different models to learn resizers adapted to each model.Moreover, we show that the proposed resizer can also be useful for ﬁne-tuning the classiﬁcation baselines for other vision tasks. To this end, we experiment with three different baselines to develop image quality assessment (IQA) mod-els on the AVA dataset [24]. 