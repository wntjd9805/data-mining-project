Due to the superior ability of global dependency mod-eling, Transformer and its variants have become the pri-mary choice of many vision-and-language tasks. How-ever, in tasks like Visual Question Answering (VQA) andReferring Expression Comprehension (REC), the multi-modal prediction often requires visual information from macro- to micro-views. Therefore, how to dynamically schedule the global and local dependency modeling inTransformer has become an emerging issue.In this pa-per, we propose an example-dependent routing scheme called TRAnsformer Routing (TRAR) to address this issue1.Specifically, in TRAR, each visual Transformer layer is equipped with a routing module with different attention spans. The model can dynamically select the correspond-ing attentions based on the output of the previous infer-ence step, so as to formulate the optimal routing path for each example. Notably, with careful designs, TRAR can re-duce the additional computation and memory overhead to almost negligible. To validate TRAR, we conduct extensive experiments on five benchmark datasets of VQA and REC, and achieve superior performance gains than the standardTransformers and a bunch of state-of-the-art methods. 