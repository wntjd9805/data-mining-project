Human Pose Estimation (HPE) aims at retrieving the 3D position of human joints from images or videos. We show that current 3D HPE methods suffer a lack of view-point equivariance, namely they tend to fail or perform poorly when dealing with viewpoints unseen at training time. Deep learning methods often rely on either scale-invariant, translation-invariant, or rotation-invariant oper-ations, such as max-pooling. However, the adoption of such procedures does not necessarily improve viewpoint gener-alization, rather leading to more data-dependent methods.To tackle this issue, we propose a novel capsule autoen-coder network with fast Variational Bayes capsule rout-ing, named DECA. By modeling each joint as a capsule entity, combined with the routing algorithm, our approach can preserve the jointsâ€™ hierarchical and geometrical struc-ture in the feature space, independently from the viewpoint.By achieving viewpoint equivariance, we drastically re-duce the network data dependency at training time, result-ing in an improved ability to generalize for unseen view-points. In the experimental validation, we outperform other methods on depth images from both seen and unseen view-points, both top-view, and front-view. In the RGB domain, the same network gives state-of-the-art results on the chal-lenging viewpoint transfer task, also establishing a new framework for top-view HPE. The code can be found at https://github.com/mmlab-cv/DECA.