Generative Adversarial Networks (GANs) have wit-nessed prevailing success in yielding outstanding images, however, they are burdensome to deploy on resource-constrained devices due to ponderous computational costs and hulking memory usage. Although recent efforts on com-pressing GANs have acquired remarkable results, they still exist potential model redundancies and can be further com-pressed. To solve this issue, we propose a novel online multi-granularity distillation (OMGD) scheme to obtain lightweight GANs, which contributes to generating high-ﬁdelity images with low computational demands. We of-fer the ﬁrst attempt to popularize single-stage online dis-tillation for GAN-oriented compression, where the pro-gressively promoted teacher generator helps to reﬁne the discriminator-free based student generator. Complemen-tary teacher generators and network layers provide com-prehensive and multi-granularity concepts to enhance vi-sual ﬁdelity from diverse dimensions. Experimental re-sults on four benchmark datasets demonstrate that OMGD successes to compress 40× MACs and 82.5× parameters on Pix2Pix and CycleGAN, without loss of image qual-1These authors contributed equally to this work. ity. It reveals that OMGD provides a feasible solution for the deployment of real-time image translation on resource-constrained devices. Our code and models are made public at: https://github.com/bytedance/OMGD 