The point cloud representation of an object can have a large geometric variation in view of inconsistent data ac-quisition procedure, which thus leads to domain discrep-ancy due to diverse and uncontrollable shape represen-tation cross datasets. To improve discrimination on un-seen distribution of point-based geometries in a practi-cal and feasible perspective, this paper proposes a new method of geometry-aware self-training (GAST) for unsu-pervised domain adaptation of object point cloud classiﬁca-tion. Speciﬁcally, this paper aims to learn a domain-shared representation of semantic categories, via two novel self-supervised geometric learning tasks as feature regulariza-tion. On one hand, the representation learning is empow-ered by a linear mixup of point cloud samples with their self-generated rotation labels, to capture a global topo-logical conﬁguration of local geometries. On the other hand, a diverse point distribution across datasets can be normalized with a novel curvature-aware distortion local-ization. Experiments on the PointDA-10 dataset show that our GAST method can signiﬁcantly outperform the state-of-the-art methods. Source codes and pre-trained models are available at https://github.com/zou-longkun/GAST. 