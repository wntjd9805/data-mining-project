Fine-tuning from pre-trained ImageNet models has been a simple, effective, and popular approach for various com-puter vision tasks. The common practice of fine-tuning is to adopt a default hyperparameter setting with a fixed pre-trained model, while both of them are not optimized for spe-cific tasks and time constraints. Moreover, in cloud comput-ing or GPU clusters where the tasks arrive sequentially in a stream, faster online fine-tuning is a more desired and re-alistic strategy for saving money, energy consumption, andCO2 emission. In this paper, we propose a joint Neural Ar-chitecture Search and Online Adaption framework namedNASOA towards a faster task-oriented fine-tuning upon the request of users. Specifically, NASOA first adopts an of-fline NAS to identify a group of training-efficient networks to form a pretrained model zoo. We propose a novel joint block and macro level search space to enable a flexible and effi-cient search. Then, by estimating fine-tuning performance via an adaptive model by accumulating experience from the past tasks, an online schedule generator is proposed to pick up the most suitable model and generate a personalized training regime with respect to each desired task in a one-shot fashion. The resulting model zoo1 is more training effi-cient than SOTA models, e.g. 6x faster than RegNetY-16GF, and 1.7x faster than EfficientNetB3. Experiments on mul-tiple datasets also show that NASOA achieves much better improving around 2.1% accuracy fine-tuning results, i.e. than the best performance in RegNet series under various constraints and tasks; 40x faster compared to the BOHB. 