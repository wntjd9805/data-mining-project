This paper studies the task of estimating the 3D human poses of multiple persons from multiple calibrated camera views. Following the top-down paradigm, we decompose the task into two stages, i.e. person localization and pose es-timation. Both stages are processed in coarse-to-ﬁne man-ners. And we propose three task-speciﬁc graph neural net-works for effective message passing. For 3D person lo-calization, we ﬁrst use Multi-view Matching Graph Mod-ule (MMG) to learn the cross-view association and recover coarse human proposals. The Center Reﬁnement GraphModule (CRG) further reﬁnes the results via ﬂexible point-based prediction. For 3D pose estimation, the Pose Regres-sion Graph Module (PRG) learns both the multi-view ge-ometry and structural relations between human joints. Our approach achieves state-of-the-art performance on CMUPanoptic and Shelf datasets with signiﬁcantly lower com-putation complexity. 