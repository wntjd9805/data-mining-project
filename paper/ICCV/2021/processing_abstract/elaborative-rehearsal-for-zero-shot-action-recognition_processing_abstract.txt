The growing number of action classes has posed a new challenge for video understanding, making Zero-Shot Ac-tion Recognition (ZSAR) a thriving direction. The ZSAR task aims to recognize target (unseen) actions without train-ing examples by leveraging semantic representations to bridge seen and unseen actions. However, due to the com-plexity and diversity of actions, it remains challenging to semantically represent action classes and transfer knowl-edge from seen data.In this work, we propose an ER-enhanced ZSAR model inspired by an effective human mem-ory technique Elaborative Rehearsal (ER), which involves elaborating a new concept and relating it to known con-cepts. Specifically, we expand each action class as an Elab-orative Description (ED) sentence, which is more discrim-inative than a class name and less costly than manual-defined attributes. Besides directly aligning class seman-tics with videos, we incorporate objects from the video asElaborative Concepts (EC) to improve video semantics and generalization from seen actions to unseen actions. OurER-enhanced ZSAR model achieves state-of-the-art results on three existing benchmarks. Moreover, we propose a new ZSAR evaluation protocol on the Kinetics dataset to overcome limitations of current benchmarks and first com-pare with few-shot learning baselines on this more realis-tic setting. Our codes and collected EDs are released at https://github.com/DeLightCMU/ElaborativeRehearsal. 