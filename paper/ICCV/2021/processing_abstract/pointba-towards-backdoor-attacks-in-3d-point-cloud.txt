3D deep learning has been increasingly more popular for a variety of tasks including many safety-critical appli-cations. However, recently several works raise the security issues of 3D deep models. Although most of them consider adversarial attacks, we identify that backdoor attack is in-deed a more serious threat to 3D deep learning systems but remains unexplored. We present the backdoor attacks in 3D point cloud with a unified framework that exploitsIn par-the unique properties of 3D data and networks. ticular, we design two attack approaches on point cloud: the poison-label backdoor attack (PointPBA) and the clean-label backdoor attack (PointCBA). The first one is straight-forward and effective in practice, while the latter is more sophisticated assuming there are certain data inspections.The attack algorithms are mainly motivated and developed by 1) the recent discovery of 3D adversarial samples sug-gesting the vulnerability of deep models under spatial trans-formation; 2) the proposed feature disentanglement tech-nique that manipulates the feature of the data through opti-mization methods and its potential to embed a new task. Ex-tensive experiments show the efficacy of the PointPBA with over 95% success rate across various 3D datasets and mod-els, and the more stealthy PointCBA with around 50% suc-cess rate. Our proposed backdoor attack in 3D point cloud is expected to perform as a baseline for improving the ro-bustness of 3D deep models. 