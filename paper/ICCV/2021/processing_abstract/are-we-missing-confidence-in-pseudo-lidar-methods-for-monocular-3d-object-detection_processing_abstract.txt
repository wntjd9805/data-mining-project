Pseudo-LiDAR-based methods for monocular 3D ob-ject detection have received considerable attention in the community due to the performance gains exhibited on theKITTI3D benchmark, in particular on the commonly re-ported validation split. This generated a distorted impres-sion about the superiority of Pseudo-LiDAR-based (PL-based) approaches over methods working with RGB images only. Our ﬁrst contribution consists in rectifying this view by pointing out and showing experimentally that the vali-dation results published by PL-based methods are substan-tially biased. The source of the bias resides in an overlap between the KITTI3D object detection validation set and the training/validation sets used to train depth predictors feeding PL-based methods. Surprisingly, the bias remains also after geographically removing the overlap. This leaves the test set as the only reliable set for comparison, where published PL-based methods do not excel. Our second con-tribution brings PL-based methods back up in the ranking with the design of a novel deep architecture which intro-duces a 3D conﬁdence prediction module. We show that 3D conﬁdence estimation techniques derived from RGB-only 3D detection approaches can be successfully integrated into our framework and, more importantly, that improved per-formance can be obtained with a newly designed 3D conﬁ-dence measure, leading to state-of-the-art performance on the KITTI3D benchmark. 