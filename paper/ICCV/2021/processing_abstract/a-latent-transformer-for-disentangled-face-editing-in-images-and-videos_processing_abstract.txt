Source codes are available at https://github.com/InterDigitalInc/latent-transformer.High quality facial image editing is a challenging prob-lem in the movie post-production industry, requiring a high degree of control and identity preservation. Previous works that attempt to tackle this problem may suffer from the en-tanglement of facial attributes and the loss of the personâ€™s identity. Furthermore, many algorithms are limited to a cer-tain task. To tackle these limitations, we propose to edit facial attributes via the latent space of a StyleGAN gen-erator, by training a dedicated latent transformation net-work and incorporating explicit disentanglement and iden-tity preservation terms in the loss function. We further intro-duce a pipeline to generalize our face editing to videos. Our model achieves a disentangled, controllable, and identity-preserving facial attribute editing, even in the challenging case of real (i.e., non-synthetic) images and videos. We conduct extensive experiments on image and video datasets and show that our model outperforms other state-of-the-art methods in visual quality and quantitative evaluation. 