We present a general learning-based solution for restor-ing images suffering from spatially-varying degradations.Prior approaches are typically degradation-speciﬁc and employ the same processing across different images and different pixels within. However, we hypothesize that such spatially rigid processing is suboptimal for simultaneously restoring the degraded pixels as well as reconstructing the clean regions of the image. To overcome this lim-itation, we propose SPAIR, a network design that har-nesses distortion-localization information and dynamically adjusts computation to difﬁcult regions in the image. SPAIR comprises of two components, (1) a localization network that identiﬁes degraded pixels, and (2) a restoration net-work that exploits knowledge from the localization net-work in ﬁlter and feature domain to selectively and adap-tively restore degraded pixels. Our key idea is to exploit the non-uniformity of heavy degradations in spatial-domain and suitably embed this knowledge within distortion-guided modules performing sparse normalization, feature extrac-tion and attention. Our architecture is agnostic to physi-cal formation model and generalizes across several types of spatially-varying degradations. We demonstrate the ef-ﬁcacy of SPAIR individually on four restoration tasks- re-moval of rain-streaks, raindrops, shadows and motion blur.Extensive qualitative and quantitative comparisons with prior art on 11 benchmark datasets demonstrate that our degradation-agnostic network design offers signiﬁcant per-formance gains over state-of-the-art degradation-speciﬁc architectures. Code available at https://github.com/human-analysis/spatially-adaptive-image-restoration. 