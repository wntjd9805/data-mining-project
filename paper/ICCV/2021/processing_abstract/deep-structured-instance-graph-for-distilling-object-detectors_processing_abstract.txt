Effectively structuring deep knowledge plays a pivotal role in transfer from teacher to student, especially in seman-tic vision tasks. In this paper, we present a simple knowl-edge structure to exploit and encode information inside the detection system to facilitate detector knowledge distilla-tion. Specifically, aiming at solving the feature imbalance problem while further excavating the missing relation inside semantic instances, we design a graph whose nodes corre-spond to instance proposal-level features and edges repre-sent the relation between nodes. To further refine this graph, we design an adaptive background loss weight to reduce node noise and background samples mining to prune trivial edges. We transfer the entire graph as encoded knowledge representation from teacher to student, capturing local and global information simultaneously.We achieve new state-of-the-art results on the chal-lenging COCO object detection task with diverse student-teacher pairs on both one- and two-stage detectors. We also experiment with instance segmentation to demonstrate robustness of our method.It is notable that distilledFaster R-CNN with ResNet18-FPN and ResNet50-FPN yields 38.68 and 41.82 Box AP respectively on the COCO benchmark, Faster R-CNN with ResNet101-FPN signifi-cantly achieves 43.38 AP, which outperforms ResNet152-FPN teacher about 0.7 AP. Code: https://github. com/dvlab-research/Dsig. 