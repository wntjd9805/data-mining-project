In this work, we propose a camera self-calibration algo-rithm for generic cameras with arbitrary non-linear distor-tions. We jointly learn the geometry of the scene and the ac-curate camera parameters without any calibration objects.Our camera model consists of a pinhole model, a fourth or-der radial distortion, and a generic noise model that can learn arbitrary non-linear camera distortions. While tradi-tional self-calibration algorithms mostly rely on geometric constraints, we additionally incorporate photometric con-sistency. This requires learning the geometry of the scene, and we use Neural Radiance Fields (NeRF). We also pro-pose a new geometric loss function, viz., projected ray dis-tance loss, to incorporate geometric consistency for com-plex non-linear camera models. We validate our approach on standard real image datasets and demonstrate that our model can learn the camera intrinsics and extrinsics (pose) from scratch without COLMAP initialization. Also, we show that learning accurate camera models in a differen-tiable manner allows us to improve PSNR over baselines.Our module is an easy-to-use plugin that can be applied toNeRF variants to improve performance. The code and data are currently available at https://github.com/POSTECH-CVLab/SCNeRF 