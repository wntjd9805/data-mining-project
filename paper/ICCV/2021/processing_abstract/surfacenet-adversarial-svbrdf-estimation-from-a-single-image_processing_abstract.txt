In this paper we present SurfaceNet, an approach for estimating spatially-varying bidirectional reﬂectance distri-bution function (SVBRDF) material properties from a sin-gle image. We pose the problem as an image translation task and propose a novel patch-based generative adver-sarial network (GAN) that is able to produce high-quality, high-resolution surface reﬂectance maps. The employment of the GAN paradigm has a twofold objective: 1) allowing the model to recover ﬁner details than standard translation models; 2) reducing the domain shift between synthetic and real data distributions in an unsupervised way.An extensive evaluation, carried out on a public benchmark of synthetic and real images under different illumination conditions, shows that SurfaceNet largely outperforms ex-isting SVBRDF reconstruction methods, both quantitatively and qualitatively. Furthermore, SurfaceNet exhibits a re-markable ability in generating high-quality maps from real samples without any supervision at training time.Source code available at https://github.com/ perceivelab/surfacenet. 