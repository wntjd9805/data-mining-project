In this paper, we present a novel approach to synthesize realistic images based on their semantic layouts. It hypoth-esizes that for objects with similar appearance, they share similar representation. Our method establishes dependen-cies between regions according to their appearance corre-lation, yielding both spatially variant and associated rep-resentations. Conditioning on these features, we propose a dynamic weighted network constructed by spatially con-ditional computation (with both convolution and normaliza-tion). More than preserving semantic distinctions, the given dynamic network strengthens semantic relevance, beneÔ¨Åt-ing global structure and detail synthesis. We demonstrate that our method gives the compelling generation perfor-mance qualitatively and quantitatively with extensive exper-iments on benchmarks. 