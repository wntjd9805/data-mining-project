In this paper, we introduce a novel self-supervised visual representation learning method which understands both im-ages and videos in a joint learning fashion. The proposed neural network architecture and objectives are designed to obtain two different Convolutional Neural Networks for solving visual recognition tasks in the domain of videos and images. Our method called Video/Image for VisualContrastive Learning of Representation(Vi2CLR) uses un-labeled videos to exploit dynamic and static visual cues for self-supervised and instances similarity/dissimilarity learn-ing. Vi2CLR optimization pipeline consists of visual clus-tering part and representation learning based on groups of similar positive instances within a cluster and negative ones from other clusters and learning visual clusters and their distances. We show how a joint self-supervised visual clus-tering and instance similarity learning with 2D (image) and 3D (video) CovNet encoders yields such robust and near to supervised learning performance.We extensively evaluate the method on downstream tasks like large scale action recognition, image and object classi-ﬁcation on datasets like Kinetics, ImageNet, Pascal VOC’07 and UCF101 and achieve outstanding results compared to state-of-the-art self-supervised methods. 