One-stage object detection is commonly implemented by optimizing two sub-tasks: object classiﬁcation and localiza-tion, using heads with two parallel branches, which might lead to a certain level of spatial misalignment in predic-tions between the two tasks.In this work, we propose aTask-aligned One-stage Object Detection (TOOD) that ex-plicitly aligns the two tasks in a learning-based manner.First, we design a novel Task-aligned Head (T-Head) which offers a better balance between learning task-interactive and task-speciﬁc features, as well as a greater ﬂexibility to learn the alignment via a task-aligned predictor. Second, we propose Task Alignment Learning (TAL) to explicitly pull closer (or even unify) the optimal anchors for the two tasks during training via a designed sample assignment scheme and a task-aligned loss. Extensive experiments are con-ducted on MS-COCO, where TOOD achieves a 51.1 AP at single-model single-scale testing. This surpasses the recent one-stage detectors by a large margin, such as ATSS [30] (47.7 AP), GFL [14] (48.2 AP), and PAA [9] (49.0 AP), with fewer parameters and FLOPs. Qualitative results also demonstrate the effectiveness of TOOD for better aligning the tasks of object classiﬁcation and localization. Code is available at https://github.com/fcjian/TOOD. 