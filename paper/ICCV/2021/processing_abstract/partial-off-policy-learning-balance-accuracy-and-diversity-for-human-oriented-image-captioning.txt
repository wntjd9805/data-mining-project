Human-oriented image captioning with both high diver-sity and accuracy is a challenging task in vision+language modeling. The reinforcement learning (RL) based frame-works promote the accuracy of image captioning, yet seri-ously hurt the diversity. In contrast, other methods based on variational auto-encoder (VAE) or generative adversar-ial network (GAN) can produce diverse yet less accurate captions.In this work, we devote our attention to pro-mote the diversity of RL-based image captioning. To be specific, we devise a partial off-policy learning scheme to balance accuracy and diversity. First, we keep the model exposed to varied candidate captions by sampling from the initial state before RL launched. Second, a novel criterion named max-CIDEr is proposed to serve as the reward for promoting diversity. We combine the above-mentioned off-policy strategy with the on-policy one to moderate the ex-ploration effect, further balancing the diversity and accu-racy for human-like image captioning. Experiments show that our method locates the closest to human performance in the diversity-accuracy space, and achieves the highestPearson correlation as 0.337 with human performance. 