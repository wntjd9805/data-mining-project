We present a graph-convolution-reinforced transformer, named Mesh Graphormer, for 3D human pose and mesh reconstruction from a single image. Recently both trans-formers and graph convolutional neural networks (GC-NNs) have shown promising progress in human mesh re-construction. Transformer-based approaches are effective in modeling non-local interactions among 3D mesh ver-tices and body joints, whereas GCNNs are good at ex-ploiting neighborhood vertex interactions based on a pre-specified mesh topology.In this paper, we study how to combine graph convolutions and self-attentions in a trans-former to model both local and global interactions. Ex-perimental results show that our proposed method, MeshGraphormer, significantly outperforms the previous state-of-the-art methods on multiple benchmarks, including Hu-man3.6M, 3DPW, and FreiHAND datasets. Code and pre-trained models are available at https://github. com/microsoft/MeshGraphormer. 