Despite the success of deep learning on supervised point cloud semantic segmentation, obtaining large-scale point-by-point manual annotations is still a significant chal-lenge. To reduce the huge annotation burden, we pro-pose a Region-based and Diversity-aware Active Learning (ReDAL), a general framework for many deep learning ap-proaches, aiming to automatically select only informative and diverse sub-scene regions for label acquisition. Ob-serving that only a small portion of annotated regions are sufficient for 3D scene understanding with deep learning, we use softmax entropy, color discontinuity, and structural complexity to measure the information of sub-scene regions.A diversity-aware selection algorithm is also developed to avoid redundant annotations resulting from selecting infor-mative but similar regions in a querying batch. Extensive experiments show that our method highly outperforms pre-vious active learning strategies, and we achieve the perfor-mance of 90% fully supervised learning, while less than 15% and 5% annotations are required on S3DIS and Se-manticKITTI datasets, respectively. 