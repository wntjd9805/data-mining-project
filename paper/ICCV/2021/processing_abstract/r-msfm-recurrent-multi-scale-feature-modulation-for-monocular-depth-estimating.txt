In this paper, we propose Recurrent Multi-Scale Fea-ture Modulation (R-MSFM), a new deep network architec-ture for self-supervised monocular depth estimation. R-MSFM extracts per-pixel features, builds a multi-scale fea-ture modulation module, and iteratively updates an inverse depth through a parameter-shared decoder at the fixed res-olution. This architecture enables our R-MSFM to main-tain semantically richer while spatially more precise rep-resentations and avoid the error propagation caused by the traditional U-Net-like coarse-to-fine architecture wide-ly used in this domain, resulting in strong generalization and efficient parameter count. Experimental results demon-strate the superiority of our proposed R-MSFM both at model size and inference speed, and show the state-of-the-art results on the KITTI benchmark. Code is available at https://github.com/jsczzzk/R-MSFM 