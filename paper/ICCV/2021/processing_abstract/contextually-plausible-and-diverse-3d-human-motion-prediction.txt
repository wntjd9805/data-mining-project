We tackle the task of diverse 3D human motion predic-tion, that is, forecasting multiple plausible future 3D poses given a sequence of observed 3D poses.In this context, a popular approach consists of using a Conditional Varia-tional Autoencoder (CVAE). However, existing approaches that do so either fail to capture the diversity in human mo-tion, or generate diverse but semantically implausible con-tinuations of the observed motion.In this paper, we ad-dress both of these problems by developing a new varia-tional framework that accounts for both diversity and con-text of the generated future motion. To this end, and in con-trast to existing approaches, we condition the sampling of the latent variable that acts as source of diversity on the rep-resentation of the past observation, thus encouraging it to carry relevant information. Our experiments demonstrate that our approach yields motions not only of higher quality while retaining diversity, but also that preserve the contex-tual information contained in the observed motion. 