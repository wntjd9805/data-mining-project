Recent learning-based multi-view stereo (MVS) methods show excellent performance with dense cameras and small depth ranges. However, non-learning based approaches still outperform for scenes with large depth ranges and sparser wide-baseline views, in part due to their PatchMatch opti-mization over pixelwise estimates of depth, normals, and visibility. In this paper, we propose an end-to-end trainablePatchMatch-based MVS approach that combines advantages of trainable costs and regularizations with pixelwise esti-mates. To overcome the challenge of the non-differentiablePatchMatch optimization that involves iterative sampling and hard decisions, we use reinforcement learning to minimize expected photometric cost and maximize likelihood of ground truth depth and normals. We incorporate normal estimation by using dilated patch kernels and propose a recurrent cost regularization that applies beyond frontal plane-sweep algo-rithms to our pixelwise depth/normal estimates. We evaluate our method on widely used MVS benchmarks, ETH3D andTanks and Temples (TnT). On ETH3D, our method outper-forms other recent learning-based approaches and performs comparably on advanced TnT. 