Image generation has been heavily investigated in com-puter vision, where one core research challenge is to gen-erate images from arbitrarily complex distributions with lit-tle supervision. Generative Adversarial Networks (GANs) as an implicit approach have achieved great successes in this direction and therefore been employed widely. How-ever, GANs are known to suffer from issues such as mode collapse, non-structured latent space, being unable to com-pute likelihoods, etc. In this paper, we propose a new unsu-pervised non-parametric method named mixture of inÔ¨Ånite conditional GANs or MIC-GANs, to tackle several GAN is-sues together, aiming for image generation with parsimo-nious prior knowledge. Through comprehensive evalua-tions across different datasets, we show that MIC-GANs are effective in structuring the latent space and avoiding mode collapse, and outperform state-of-the-art methods. MIC-GANs are adaptive, versatile, and robust. They offer a promising solution to several well-known GAN issues. Code available: github.com/yinghdb/MICGANs. 