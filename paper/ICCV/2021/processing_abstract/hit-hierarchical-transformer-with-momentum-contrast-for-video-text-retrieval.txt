Video-Text Retrieval has been a hot research topic with the growth of multimedia data on the internet. Transformer for video-text learning has attracted increasing attention due to its promising performance. However, existing cross-modal transformer approaches typically suffer from two major limitations: 1) Exploitation of the transformer archi-tecture where different layers have different feature charac-teristics is limited; 2) End-to-end training mechanism limits negative sample interactions in a mini-batch. In this paper, we propose a novel approach named Hierarchical Trans-former (HiT) for video-text retrieval. HiT performs Hierar-chical Cross-modal Contrastive Matching in both feature-level and semantic-level, achieving multi-view and compre-hensive retrieval results. Moreover, inspired by MoCo, we propose Momentum Cross-modal Contrast for cross-modal learning to enable large-scale negative sample interactions on-the-ï¬‚y, which contributes to the generation of more pre-cise and discriminative representations. Experimental re-sults on the three major Video-Text Retrieval benchmark datasets demonstrate the advantages of our method. 