■ r✌✍ ✎✏✑ ✭■✎✒✁✁✂✂❛♥❛✁✎✏✑❢ ■✍✏✍ ✭✎■✒❛ (cid:0)♥✂✁✂ (cid:0)Typical domain adaptation techniques aim to transfer the knowledge learned from a label-rich source domain to a label-scarce target domain in the same label space. How-ever, it is often hard to get even the unlabeled target do-main data of a task of interest.In such a case, we can capture the domain shift between the source domain and target domain from an unseen task and transfer it to the task of interest, which is known as zero-shot domain adap-tation (ZSDA). Most of existing state-of-the-art methods forZSDA attempted to generate target domain data. However, training such generative models causes signiﬁcant compu-tational overhead and is hardly optimized. In this paper, we propose a novel ZSDA method that learns a task-agnostic domain shift by collaborative training of domain-invariant semantic features and task-invariant domain features via adversarial learning. Meanwhile, the spatial attention map is learned from disentangled feature representations to se-lectively emphasize the domain-speciﬁc salient parts of the domain-invariant features. Experimental results show that our ZSDA method achieves state-of-the-art performance on several benchmarks. 