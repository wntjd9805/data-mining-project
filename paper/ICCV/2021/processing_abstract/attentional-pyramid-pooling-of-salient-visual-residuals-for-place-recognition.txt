The core of visual place recognition (VPR) lies in how to identify task-relevant visual cues and embed them into dis-criminative representations. Focusing on these two points, we propose a novel encoding strategy named AttentionalPyramid Pooling of Salient Visual Residuals (APPSVR). It incorporates three types of attention modules to model the saliency of local features in individual, spatial and cluster (1) To inhibit task-irrelevant lo-dimensions respectively. cal features, a semantic-reinforced local weighting scheme is employed for local feature reÔ¨Ånement; (2) To leverage the spatial context, an attentional pyramid structure is con-structed to adaptively encode regional features according to their relative spatial saliency; (3) To distinguish the dif-ferent importance of visual clusters to the task, a para-metric normalization is proposed to adjust their contribu-tion to image descriptor generation. Experiments demon-strate APPSVR outperforms the existing techniques and achieves a new state-of-the-art performance on VPR bench-mark datasets. The visualization shows the saliency map learned in a weakly supervised manner is largely consistent with human cognition. 