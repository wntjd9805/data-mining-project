Top-k multi-label learning, which returns the top-k pre-dicted labels from an input, has many practical applications such as image annotation, document analysis, and web search engine. However, the vulnerabilities of such algo-rithms with regards to dedicated adversarial perturbation attacks have not been extensively studied previously. In this work, we develop methods to create adversarial perturba-tions that can be used to attack top-k multi-label learning-based image annotation systems (TkML-AP). Our methods explicitly consider the top-k ranking relation and are based on novel loss functions. Experimental evaluations on large-scale benchmark datasets including PASCAL VOC and MSCOCO demonstrate the effectiveness of our methods in re-ducing the performance of state-of-the-art top-k multi-label learning methods, under both untargeted and targeted at-tacks. 