While the untargeted black-box transferability of adver-sarial perturbations has been extensively studied before, changing an unseen model’s decisions to a speciﬁc ‘tar-geted’ class remains a challenging feat.In this paper, we propose a new generative approach for highly trans-ferable targeted perturbations (TTP). We note that the ex-isting methods are less suitable for this task due to their reliance on class-boundary information that changes from one model to another, thus reducing transferability. In con-trast, our approach matches the perturbed image ‘distri-bution’ with that of the target class, leading to high tar-geted transferability rates. To this end, we propose a new objective function that not only aligns the global distribu-tions of source and target images, but also matches the local neighbourhood structure between the two domains.Based on the proposed objective, we train a generator function that can adaptively synthesize perturbations spe-ciﬁc to a given input. Our generative approach is in-dependent of the source or target domain labels, while consistently performs well against state-of-the-art methods on a wide range of attack settings. As an example, we achieve 32.63% target transferability from (an adversari-ally weak) VGG19BN to (a strong) WideResNet on Ima-geNet val. set, which is 4 higher than the previous best⇥ generative attack and 16 better than instance-speciﬁc it-erative attack. Code is available at: https://github. com/Muzammal-Naseer/TTP.⇥ 