3D object grounding aims to locate the most relevant target object in a raw point cloud scene based on a free-form language description. Understanding complex and di-verse descriptions, and lifting them directly to a point cloud is a new and challenging topic due to the irregular and sparse nature of point clouds. There are three main chal-lenges in 3D object grounding: to Ô¨Ånd the main focus in the complex and diverse description; to understand the point cloud scene; and to locate the target object.In this pa-per, we address all three challenges. Firstly, we propose a language scene graph module to capture the rich struc-ture and long-distance phrase correlations. Secondly, we introduce a multi-level 3D proposal relation graph module to extract the object-object and object-scene co-occurrence relationships, and strengthen the visual features of the ini-tial proposals. Lastly, we develop a description guided 3D visual graph module to encode global contexts of phrases and proposals by a nodes matching strategy. Extensive experiments on challenging benchmark datasets (ScanRe-fer [3] and Nr3D [42]) show that our algorithm outper-forms existing state-of-the-art. Our code is available at https://github.com/PNXD/FFL-3DOG. 