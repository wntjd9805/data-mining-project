Surface normal estimation from a single image is an important task in 3D scene understanding. In this paper, we address two limitations shared by the existing meth-ods: the inability to estimate the aleatoric uncertainty and lack of detail in the prediction. The proposed network es-timates the per-pixel surface normal probability distribu-tion. We introduce a new parameterization for the distribu-tion, such that its negative log-likelihood is the angular loss with learned attenuation. The expected value of the angu-lar error is then used as a measure of the aleatoric uncer-tainty. We also present a novel decoder framework where pixel-wise multi-layer perceptrons are trained on a subset of pixels sampled based on the estimated uncertainty. The proposed uncertainty-guided sampling prevents the bias in training towards large planar surfaces and improves the quality of prediction, especially near object boundaries and on small structures. Experimental results show that the proposed method outperforms the state-of-the-art in Scan-Net [4] and NYUv2 [33], and that the estimated uncer-tainty correlates well with the prediction error. Code is available at https://github.com/baegwangbin/ surface_normal_uncertainty. 