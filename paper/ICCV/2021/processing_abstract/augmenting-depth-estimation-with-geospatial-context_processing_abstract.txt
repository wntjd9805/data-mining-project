Modern cameras are equipped with a wide array of sen-sors that enable recording the geospatial context of an im-age. Taking advantage of this, we explore depth estimation under the assumption that the camera is geocalibrated, a problem we refer to as geo-enabled depth estimation. Our key insight is that if capture location is known, the corre-sponding overhead viewpoint offers a valuable resource for understanding the scale of the scene. We propose an end-to-end architecture for depth estimation that uses geospatial context to infer a synthetic ground-level depth map from a co-located overhead image, then fuses it inside of an en-coder/decoder style segmentation network. To support eval-uation of our methods, we extend a recently released dataset with overhead imagery and corresponding height maps. Re-sults demonstrate that integrating geospatial context signif-icantly reduces error compared to baselines, both at close ranges and when evaluating at much larger distances than existing benchmarks consider. 