pooling and strided convolution).Extracting robust feature representation is one of the key challenges in object re-identiﬁcation (ReID). Although convolution neural network (CNN)-based methods have they only process one local achieved great success, neighborhood at a time and suffer from information loss on details caused by convolution and downsampling operators (e.g.To overcome these limitations, we propose a pure transformer-based object ReID framework named TransReID. Speciﬁcally, we ﬁrst encode an image as a sequence of patches and build a transformer-based strong baseline with a improvements, which achieves competitive few critical results on several ReID benchmarks with CNN-based methods. To further enhance the robust feature learning in the context of two novel modules transformers, are carefully designed. (i) The jigsaw patch module (JPM) is proposed to rearrange the patch embeddings via shift and patch shufﬂe operations which generates robust features with improved discrimination ability and more diversiﬁed coverage. (ii) The side information embeddings (SIE) is introduced to mitigate feature bias towards camera/view variations by plugging in learnable embeddings to incorporate these non-visual clues. To the best of our knowledge, this is the ﬁrst work to adopt a pure transformer for ReID research. Experimental results of TransReID are superior promising, which achieve state-of-the-art performance on both person and vehicle ReID benchmarks. Code is available at https://github. com/heshuting555/TransReID. 