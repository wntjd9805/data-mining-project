Existing GAN inversion methods are stuck in a para-dox that the inverted codes can either achieve high-ﬁdelity reconstruction, or retain the editing capability. Having only one of them clearly cannot realize real image edit-ing. In this paper, we resolve this paradox by introducing consecutive images (e.g., video frames or the same person with different poses) into the inversion process. The ratio-nale behind our solution is that the continuity of consecu-tive images leads to inherent editable directions. This in-born property is used for two unique purposes: 1) regu-larizing the joint inversion process, such that each of the inverted codes is semantically accessible from one of the other and fastened in an editable domain; 2) enforcing inter-image coherence, such that the ﬁdelity of each in-verted code can be maximized with the complement of other images. Extensive experiments demonstrate that our al-ternative signiﬁcantly outperforms state-of-the-art methods in terms of reconstruction ﬁdelity and editability on both the real image dataset and synthesis dataset. Furthermore,∗Corresponding authors ({xuemx,hesfe}@scut.edu.cn). our method provides the ﬁrst support of video-based GAN inversion and an interesting application of unsupervised semantic transfer from consecutive images. Source code can be found at: https://github.com/cnnlstm/InvertingGANs_with_ConsecutiveImgs. 