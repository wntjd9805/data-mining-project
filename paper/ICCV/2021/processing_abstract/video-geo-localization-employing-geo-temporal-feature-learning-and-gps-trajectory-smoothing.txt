In this paper, we address the problem of video geo-localization by proposing a Geo-Temporal Feature Learn-ing (GTFL) Network to simultaneously learn the discrimi-native features for the query video frames and the gallery images for estimating the geo-spatial trajectory of a query video. Based on a transformer encoder architecture, ourGTFL model encodes query and gallery data separately, via two dedicated branches. The proposed GPS Loss andClip Triplet Loss exploit the geographical and temporal proximity between the frames and the clips to jointly learn the query and the gallery features. We also propose a deep learning approach to trajectory smoothing by pre-dicting the outliers in the estimated GPS positions and learning the offsets to smooth the trajectory. We build a large dataset from four different regions of USA; NewYork, San Francisco, Berkeley and Bay Area using BDD driving videos as query, and by collecting correspondingGoogle StreetView (GSV) Images for gallery. Extensive evaluations of proposed method on this new dataset are pro-vided . Code and dataset details is publicly available at https://github.com/kregmi/VTE. 