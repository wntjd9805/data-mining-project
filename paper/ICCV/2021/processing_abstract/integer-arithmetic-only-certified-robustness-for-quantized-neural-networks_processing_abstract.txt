Adversarial data examples have drawn significant atten-tion from the machine learning and security communities.A line of work on tackling adversarial examples is certified robustness via randomized smoothing that can provide a the-oretical robustness guarantee. However, such a mechanism usually uses floating-point arithmetic for calculations in in-ference and requires large memory footprints and daunting computational costs. These defensive models cannot run efficiently on edge devices nor be deployed on integer-only logical units such as Turing Tensor Cores or integer-onlyARM processors. To overcome these challenges, we propose an integer randomized smoothing approach with quantiza-tion to convert any classifier into a new smoothed classifier, which uses integer-only arithmetic for certified robustness against adversarial perturbations. We prove a tight robust-ness guarantee under ℓ2-norm for the proposed approach.We show our approach can obtain a comparable accuracy and 4× ∼ 5× speedup over floating-point arithmetic certi-fied robust methods on general-purpose CPUs and mobile devices on two distinct datasets (CIFAR-10 and Caltech-101). 