We tackle catastrophic forgetting problem in the con-text of class-incremental learning for video recognition, which has not been explored actively despite the popular-ity of continual learning. Our framework addresses this challenging task by introducing time-channel importance maps and exploiting the importance maps for learning the representations of incoming examples via knowledge dis-tillation. We also incorporate a regularization scheme in our objective function, which encourages individual fea-tures obtained from different time steps in a video to be un-correlated and eventually improves accuracy by alleviating catastrophic forgetting. We evaluate the proposed approach on brand-new splits of class-incremental action recognition benchmarks constructed upon the UCF101, HMDB51, andSomething-Something V2 datasets, and demonstrate the ef-fectiveness of our algorithm in comparison to the existing continual learning methods that are originally designed for image data. 