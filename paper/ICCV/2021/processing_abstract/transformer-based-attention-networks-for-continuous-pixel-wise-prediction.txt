While convolutional neural networks have shown a tremendous impact on various computer vision tasks, they generally demonstrate limitations in explicitly modeling long-range dependencies due to the intrinsic locality ofInitially designed for natural the convolution operation. language processing tasks, Transformers have emerged as alternative architectures with innate global self-attention mechanisms to capture long-range dependencies.In this paper, we propose TransDepth, an architecture that bene-ﬁts from both convolutional neural networks and transform-ers. To avoid the network losing its ability to capture local-level details due to the adoption of transformers, we pro-pose a novel decoder that employs attention mechanisms based on gates. Notably, this is the ﬁrst paper that ap-plies transformers to pixel-wise prediction problems involv-ing continuous labels (i.e., monocular depth prediction and surface normal estimation). Extensive experiments demon-strate that the proposed TransDepth achieves state-of-the-art performance on three challenging datasets. Our code is available at: https://github.com/ygjwd12345/TransDepth. 