This paper investigates the problem of reconstructing hyperspectral (HS) images from single RGB images cap-tured by commercial cameras, without using paired HS andRGB images during training. To tackle this challenge, we propose a new lightweight and end-to-end learning-based framework. Specifically, on the basis of the intrinsic imag-ing degradation model of RGB images from HS images, we progressively spread the differences between input RGB im-ages and re-projected RGB images from recovered HS im-ages via effective unsupervised camera spectral response function estimation. To enable the learning without paired ground-truth HS images as supervision, we adopt the adver-sarial learning manner and boost it with a simple yet effec-tive L1 gradient clipping scheme. Besides, we embed the se-mantic information of input RGB images to locally regular-ize the unsupervised learning, which is expected to promote pixels with identical semantics to have consistent spectral signatures. In addition to conducting quantitative experi-ments over two widely-used datasets for HS image recon-struction from synthetic RGB images, we also evaluate our method by applying recovered HS images from real RGB images to HS-based visual tracking. Extensive results show that our method significantly outperforms state-of-the-art unsupervised methods and even exceeds the latest super-vised method under some settings. The source code is pub-lic available at https://github.com/zbzhzhy/Unsupervised-Spectral-Reconstruction. 