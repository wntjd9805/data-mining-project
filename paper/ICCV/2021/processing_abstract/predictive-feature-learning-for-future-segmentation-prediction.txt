Future segmentation prediction aims to predict the seg-mentation masks for unobserved future frames. Most ex-isting works addressed it by directly predicting the inter-mediate features extracted by existing segmentation mod-els. However, these segmentation features are learned to be local discriminative (with rich details) and are always of high resolution/dimension. Hence, the complicated spatio-temporal variations of these features are difficult to predict, which motivates us to learn a more predictive representa-tion. In this work, we develop a novel framework called Pre-dictive Feature Autoencoder. In the proposed framework, we construct an autoencoder which serves as a bridge be-tween the segmentation features and the predictor. In the latent feature learned by the autoencoder, global structures are enhanced and local details are suppressed so that it is more predictive.In order to reduce the risk of vanishing the suppressed details during recurrent feature prediction, we further introduce a reconstruction constraint in the pre-diction module. Extensive experiments show the effective-ness of the proposed approach and our method outperforms state-of-the-arts by a considerable margin. 