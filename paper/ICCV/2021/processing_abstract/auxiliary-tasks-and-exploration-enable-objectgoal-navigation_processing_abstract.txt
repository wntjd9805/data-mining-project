ObjectGoal Navigation (OBJECTNAV) is an embodied task wherein agents are to navigate to an object instance in an un-seen environment. Prior works have shown that end-to-endOBJECTNAV agents that use vanilla visual and recurrent modules, e.g. a CNN+RNN, perform poorly due to overfitting and sample inefficiency. This has motivated current state-of-the-art methods to mix analytic and learned components and operate on explicit spatial maps of the environment. We instead re-enable a generic learned agent by adding auxil-iary learning tasks and an exploration reward. Our agents achieve 24.5% success and 8.1% SPL, a 37% and 8% rel-ative improvement over prior state-of-the-art, respectively, on the Habitat ObjectNav Challenge [35]. From our analy-sis, we propose that agents will act to simplify their visual inputs so as to smooth their RNN dynamics, and that aux-iliary tasks reduce overfitting by minimizing effective RNN dimensionality; i.e. a performant OBJECTNAV agent that must maintain coherent plans over long horizons does so by learning smooth, low-dimensional recurrent dynamics.Site: joel99.github.io/objectnav/ 