Graph-based predictors have recently shown promising results on neural architecture search (NAS). Despite their efficiency, current graph-based predictors treat all opera-tions equally, resulting in biased topological knowledge of cell architectures. Intuitively, not all operations are equally significant during forwarding propagation when aggregat-ing information from these operations to another opera-tion. To address the above issue, we propose a Hierar-chical Operation-adaptive Predictor (HOP) for NAS. HOP contains an operation-adaptive attention module (OAM) to capture the diverse knowledge between operations by learn-ing the relative significance of operations in cell architec-tures during aggregation over iterations. In addition, a cell-hierarchical gated module (CGM) further refines and en-riches the obtained topological knowledge of cell architec-tures, by integrating cell information from each iteration ofOAM. The experimental results compared with state-of-the-art predictors demonstrate the capability of our proposedHOP. 