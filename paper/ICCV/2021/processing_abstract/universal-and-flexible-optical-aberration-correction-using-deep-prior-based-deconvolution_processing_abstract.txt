High quality imaging usually requires bulky and expen-sive lenses to compensate geometric and chromatic aberra-tions. This poses high constraints on the optical hash or low cost applications. Although one can utilize algorithmic reconstruction to remove the artifacts of low-end lenses, the degeneration from optical aberrations is spatially varying and the computation has to trade off efﬁciency for perfor-mance. For example, we need to conduct patch-wise opti-mization or train a large set of local deep neural networks to achieve high reconstruction performance across the whole image. In this paper, we propose a PSF aware deep net-work, which takes the aberrant image and PSF map as input and produces the latent high quality version via in-corporating deep priors, thus leading to a universal andﬂexible optical aberration correction method. Speciﬁcally, we pre-train a base model from a set of diverse lenses and then adapt it to a given lens by quickly reﬁning the param-eters, which largely alleviates the time and memory con-sumption of model learning. The approach is of high ef-ﬁciency in both training and testing stages. Extensive re-sults verify the promising applications of our proposed ap-proach for compact low-end cameras. The code is available at https://github.com/leehsiu/UABC (a) (b) (c)Figure 1: One example of computationally reconstructing high quality image with a simple lens. (a) A camera with a simple double glued lens (Thorlabs, AC254-075-A-ML). (b) The calibrated PSF of the camera in (a). (c) The input degenerated image (upper row) and our reconstruction re-sult (bottom row). 