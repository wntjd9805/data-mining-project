We aim at improving the computational efﬁciency of graph convolutional networks (GCNs) for learning on point clouds. The basic graph convolution that is composed of aK-nearest neighbor (KNN) search and a multilayer percep-tron (MLP) is examined. By mathematically analyzing the operations there, two ﬁndings to improve the efﬁciency ofGCNs are obtained. (1) The local geometric structure infor-mation of 3D representations propagates smoothly across the GCN that relies on KNN search to gather neighborhood features. This motivates the simpliﬁcation of multiple KNN searches in GCNs. (2) Shufﬂing the order of graph fea-ture gathering and an MLP leads to equivalent or similar composite operations. Based on those ﬁndings, we optimize the computational procedure in GCNs. A series of experi-ments show that the optimized networks have reduced com-putational complexity, decreased memory consumption, and accelerated inference speed while maintaining comparable accuracy for learning on point clouds. 