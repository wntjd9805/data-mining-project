How would a static scene react to a local poke? What are the effects on other parts of an object if you could lo-cally push it? There will be distinctive movement, despite evident variations caused by the stochastic nature of our world. These outcomes are governed by the characteris-tic kinematics of objects that dictate their overall motion caused by a local interaction. Conversely, the movement of an object provides crucial information about its underlying distinctive kinematics and the interdependencies between its parts. This two-way relation motivates learning a bijec-tive mapping between object kinematics and plausible future image sequences. Therefore, we propose iPOKE – invert-ible Prediction of Object Kinematics – that, conditioned on an initial frame and a local poke, allows to sample object kinematics and establishes a one-to-one correspondence to the corresponding plausible videos, thereby providing a con-trolled stochastic video synthesis. In contrast to previous works, we do not generate arbitrary realistic videos, but provide efﬁcient control of movements, while still capturing the stochastic nature of our environment and the diversity of plausible outcomes it entails. Moreover, our approach can transfer kinematics onto novel object instances and is not conﬁned to particular object classes. Our project page is available at https://bit.ly/3dJN4Lf. 