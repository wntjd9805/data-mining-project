Meta-learning has been the most common framework for few-shot learning in recent years. It learns the model from collections of few-shot classiﬁcation tasks, which is believed to have a key advantage of making the training objective consistent with the testing objective. However, some re-cent works report that by training for whole-classiﬁcation, i.e. classiﬁcation on the whole label-set, it can get compa-rable or even better embedding than many meta-learning algorithms. The edge between these two lines of works has yet been underexplored, and the effectiveness of meta-learning in few-shot learning remains unclear. In this paper, we explore a simple process: meta-learning over a whole-classiﬁcation pre-trained model on its evaluation metric.We observe this simple method achieves competitive per-formance to state-of-the-art methods on standard bench-marks. Our further analysis shed some light on understand-ing the trade-offs between the meta-learning objective and the whole-classiﬁcation objective in few-shot learning. Our code is available at https://github.com/yinboc/ few-shot-meta-baseline. 