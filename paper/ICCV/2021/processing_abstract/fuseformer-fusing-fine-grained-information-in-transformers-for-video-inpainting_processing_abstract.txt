Transformer, as a strong and ﬂexible architecture for modelling long-range relations, has been widely explored in vision tasks. However, when used in video inpainting that requires ﬁne-grained representation, existed method still suffers from yielding blurry edges in detail due to the hard patch splitting. Here we aim to tackle this problem by proposing FuseFormer, a Transformer model designed for video inpainting via ﬁne-grained feature fusion based on novel Soft Split and Soft Composition operations. The soft split divides feature map into many patches with given overlapping interval. On the contrary, the soft composi-tion operates by stitching different patches into a whole fea-ture map where pixels in overlapping regions are summed up. These two modules are ﬁrst used in tokenization be-fore Transformer layers and de-tokenization after Trans-former layers, for effective mapping between tokens and features. Therefore, sub-patch level information interaction is enabled for more effective feature propagation between neighboring patches, resulting in synthesizing vivid con-tent for hole regions in videos. Moreover, in FuseFormer, we elaborately insert the soft composition and soft split in-to the feed-forward network, enabling the 1D linear layers to have the capability of modelling 2D structure. And, the sub-patch level feature fusion ability is further enhanced.In both quantitative and qualitative evaluations, our pro-posed FuseFormer surpasses state-of-the-art methods. We also conduct detailed analysis to examine its superiori-ty. Code and pretrained models are available at https://github.com/ruiliu-ai/FuseFormer. (cid:3)The ﬁrst three authors contribute equally to this work.Figure 1. Illustration of different patch split/composition strategies for Transformer model. The top row shows hard split/composition, based on which the trained model generates rough inpainting re-sults. The bottom row shows soft split/composition, based on which the trained model generates smooth results due to interac-tion of features between neighbor patches. Double arrow indicates the corresponding overlapped regions between adjacent patches. 