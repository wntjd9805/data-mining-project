Stereo depth estimation relies on optimal correspon-dence matching between pixels on epipolar lines in the left and right images to infer depth. In this work, we re-visit the problem from a sequence-to-sequence correspon-dence perspective to replace cost volume construction with dense pixel matching using position information and atten-tion. This approach, named STereo TRansformer (STTR), has several advantages: It 1) relaxes the limitation of a fixed disparity range, 2) identifies occluded regions and pro-vides confidence estimates, and 3) imposes uniqueness con-straints during the matching process. We report promis-ing results on both synthetic and real-world datasets and demonstrate that STTR generalizes across different do-mains, even without fine-tuning. 