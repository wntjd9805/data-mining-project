Invariance and equivariance to the rotation group have been widely discussed in the 3D deep learning community for pointclouds. Yet most proposed methods either use com-plex mathematical tools that may limit their accessibility, or are tied to specific input data types and network archi-tectures. In this paper, we introduce a general framework built on top of what we call Vector Neuron representations for creating SO(3)-equivariant neural networks for point-cloud processing. Extending neurons from 1D scalars to 3D vectors, our vector neurons enable a simple mapping ofSO(3) actions to latent spaces thereby providing a frame-work for building equivariance in common neural opera-tions â€“ including linear layers, non-linearities, pooling, and normalizations. Due to their simplicity, vector neurons are versatile and, as we demonstrate, can be incorporated into diverse network architecture backbones, allowing them to process geometry inputs in arbitrary poses. Despite its sim-plicity, our method performs comparably well in accuracy and generalization with other more complex and special-ized state-of-the-art methods on classification and segmen-tation tasks. We also show for the first time a rotation equiv-ariant reconstruction network. Source code is available at https://github.com/FlyingGiraffe/vnn. 