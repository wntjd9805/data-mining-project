Scene Graph Generators (SGGs) are models that, given an image, build a directed graph where each edge repre-sents a predicted subject predicate object triplet.Most SGGs silently exploit datasets’ bias on relationships’ context, i.e. its subject and object, to improve recall and neglect spatial and visual evidence, e.g. having seen a glut of data for person wearing shirt, they are overconﬁ-dent that every person is wearing every shirt. Such imprecise predictions are mainly ascribed to the lack of negative examples for most relationships, which obstructs models from meaningfully learning predicates, even those that have ample positive examples. We ﬁrst present an in-depth investigation of the context bias issue to showcase that all examined state-of-the-art SGGs share the above vulnerabilities. In response, we propose a semi-supervised scheme that forces predicted triplets to be grounded con-sistently back to the image, in a closed-loop manner. The developed spatial common sense can be then distilled to a student SGG and substantially enhance its spatial reason-ing ability. This Grounding Consistency Distillation (GCD) approach is model-agnostic and beneﬁts from the superﬂu-ous unlabeled samples to retain the valuable context infor-mation and avert memorization of annotations. Further-more, we demonstrate that current metrics disregard unla-beled samples, rendering themselves incapable of reﬂecting context bias, then we mine and incorporate during evalu-ation hard-negatives to reformulate precision as a reliable metric. Extensive experimental comparisons exhibit large quantitative - up to 70% relative precision boost on VG200 dataset - and qualitative improvements to prove the signif-icance of our GCD method and our metrics towards refo-cusing graph generation as a core aspect of scene under-standing. Code available at https://github.com/ deeplab-ai/grounding-consistent-vrd. 