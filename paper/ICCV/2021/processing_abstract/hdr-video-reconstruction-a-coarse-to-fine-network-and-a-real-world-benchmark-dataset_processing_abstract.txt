EV+2EV-2EV+0EV+2High dynamic range (HDR) video reconstruction from sequences captured with alternating exposures is a very challenging problem. Existing methods often align low dy-namic range (LDR) input sequence in the image space using optical ﬂow, and then merge the aligned images to produceHDR output. However, accurate alignment and fusion in the image space are difﬁcult due to the missing details in the over-exposed regions and noise in the under-exposed regions, resulting in unpleasing ghosting artifacts. To en-able more accurate alignment and HDR fusion, we intro-duce a coarse-to-ﬁne deep learning framework for HDR video reconstruction. Firstly, we perform coarse alignment and pixel blending in the image space to estimate the coarseHDR video. Secondly, we conduct more sophisticated align-ment and temporal fusion in the feature space of the coarseHDR video to produce better reconstruction. Considering the fact that there is no publicly available dataset for quan-titative and comprehensive evaluation of HDR video recon-struction methods, we collect such a benchmark dataset, which contains 97 sequences of static scenes and 184 test-ing pairs of dynamic scenes. Extensive experiments show that our method outperforms previous state-of-the-art meth-ods. Our code and dataset can be found at https:// guanyingc.github.io/DeepHDRVideo. 