Instance segmentation in 3D scenes is fundamental in many applications of scene understanding. It is yet chal-lenging due to the compound factors of data irregularity and uncertainty in the numbers of instances. State-of-the-art methods largely rely on a general pipeline that first learns point-wise features discriminative at semantic and instance levels, followed by a separate step of point group-ing for proposing object instances. While promising, they have the shortcomings that (1) the second step is not super-vised by the main objective of instance segmentation, and (2) their point-wise feature learning and grouping are less effective to deal with data irregularities, possibly resulting in fragmented segmentations. To address these issues, we propose in this work an end-to-end solution of SemanticSuperpoint Tree Network (SSTNet) for proposing object in-stances from scene points. Key in SSTNet is an interme-diate, semantic superpoint tree (SST), which is constructed based on the learned semantic features of superpoints, and which will be traversed and split at intermediate tree nodes for proposals of object instances. We also design in SST-Net a refinement module, termed CliqueNet, to prune super-points that may be wrongly grouped into instance propos-als. Experiments on the benchmarks of ScanNet and S3DIS show the efficacy of our proposed method. At the time of submission, SSTNet ranks top on the ScanNet (V2) leader-board, with 2% higher of mAP than the second best method.The source code in PyTorch is available at https:// github.com/Gorilla-Lab-SCUT/SSTNet. 