Person Re-Identification (ReID) has achieved remark-able performance along with the deep learning era. How-ever, most approaches carry out ReID only based upon holistic pedestrian regions.In contrast, real-world sce-narios involve occluded pedestrians, which provide par-tial visual appearances and destroy the ReID accuracy. A common strategy is to locate visible body parts by auxil-iary model, which however suffers from significant domain gaps and data bias issues. To avoid such problematic mod-els in occluded person ReID, we propose the Occlusion-Aware Mask Network (OAMN). In particular, we incor-porate an attention-guided mask module, which requires guidance from labeled occlusion data. To this end, we propose a novel occlusion augmentation scheme that pro-duces diverse and precisely labeled occlusion for any holis-tic dataset. The proposed scheme suits real-world scenarios better than existing schemes, which consider only limited types of occlusions. We also offer a novel occlusion uni-fication scheme to tackle ambiguity information at the test phase. The above three components enable existing atten-tion mechanisms to precisely capture body parts regardless of the occlusion. Comprehensive experiments on a variety of person ReID benchmarks demonstrate the superiority ofOAMN over state-of-the-arts. 