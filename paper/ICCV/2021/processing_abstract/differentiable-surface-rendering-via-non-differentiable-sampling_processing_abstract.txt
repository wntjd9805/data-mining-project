We present a method for differentiable rendering of 3D surfaces that supports both explicit and implicit represen-tations, provides derivatives at occlusion boundaries, and is fast and simple to implement. The method ﬁrst samples the surface using non-differentiable rasterization, then ap-plies differentiable, depth-aware point splatting to produce the ﬁnal image. Our approach requires no differentiable meshing or rasterization steps, making it efﬁcient for large 3D models and applicable to isosurfaces extracted from im-plicit surface deﬁnitions. We demonstrate the effectiveness of our method for implicit-, mesh-, and parametric-surface-based inverse rendering and neural-network training appli-cations. In particular, we show for the ﬁrst time efﬁcient, differentiable rendering of an isosurface extracted from a neural radiance ﬁeld (NeRF), and demonstrate surface-based, rather than volume-based, rendering of a NeRF. 