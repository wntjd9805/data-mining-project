We present a novel graph-structured memory for visual navigation, called visual graph memory (VGM), which con-sists of unsupervised image representations obtained from navigation history. The proposed VGM is constructed in-crementally based on the similarities among the unsuper-vised representations of observed images, and these rep-resentations are learned from an unlabeled image dataset.We also propose a navigation framework that can utilize the proposed VGM to tackle visual navigation problems. By incorporating a graph convolutional network and the at-tention mechanism, the proposed agent refers to the VGM to navigate the environment while simultaneously building the VGM. Using the VGM, the agent can embed its naviga-tion history and other useful task-related information. We validate our approach on the visual navigation tasks us-ing the Habitat simulator with the Gibson dataset, which provides a photo-realistic simulation environment. The ex-tensive experimental results show that the proposed navi-gation agent with VGM surpasses the state-of-the-art ap-proaches on image-goal navigation tasks. Project Page: https://sites.google.com/view/iccv2021vgm 