This paper tackles the task of category-level pose esti-mation for garments. With a near infinite degree of free-dom, a garment’s full configuration (i.e., poses) is often described by the per-vertex 3D locations of its entire 3D surface. However, garments are also commonly subject to extreme cases of self-occlusion, especially when folded or crumpled, making it challenging to perceive their full 3D surface. To address these challenges, we propose Garment-Nets, where the key idea is to formulate the deformable ob-ject pose estimation problem as a shape completion task in the canonical space. This canonical space is defined across garments instances within a category, therefore, specifies the shared category-level pose. By mapping the observed partial surface to the canonical space and completing it in this space, the output representation describes the gar-ment’s full configuration using a complete 3D mesh with the per-vertex canonical coordinate label. To properly han-dle the thin 3D structure presented on garments, we pro-posed a novel 3D shape representation using the general-ized winding number field. Experiments demonstrate thatGarmentNets is able to generalize to unseen garment in-stances and achieve significantly better performance com-pared to alternative approaches. Code and data can be found in https://garmentnets.cs.columbia.edu. 