We propose to address the problem of few-shot classi-fication by meta-learning “what to observe” and “where to attend” in a relational perspective. Our method lever-ages relational patterns within and between images via self-correlational representation (SCR) and cross-correlational attention (CCA). Within each image, the SCR module trans-forms a base feature map into a self-correlation tensor and learns to extract structural patterns from the tensor.Between the images, the CCA module computes cross-correlation between two image representations and learns to produce co-attention between them. Our Relational Em-bedding Network (RENet) combines the two relational mod-ules to learn relational embedding in an end-to-end man-ner. In experimental evaluation, it achieves consistent im-provements over state-of-the-art methods on four widely used few-shot classification benchmarks of miniImageNet, tieredImageNet, CUB-200-2011, and CIFAR-FS. 