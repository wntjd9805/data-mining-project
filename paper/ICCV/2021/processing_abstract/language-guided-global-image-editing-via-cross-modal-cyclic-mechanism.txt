Editing an image automatically via a linguistic re-quest can signiﬁcantly save laborious manual work and is friendly to photography novice. In this paper, we focus on the task of language-guided global image editing. Existing works suffer from imbalanced and insufﬁcient data distri-bution of real-world datasets and thus fail to understand language requests well. To handle this issue, we propose to create a cycle with our image generator by creating a novel model called Editing Description Network (EDNet) which predicts an editing embedding given a pair of im-ages. Given the cycle, we propose several free augmenta-tion strategies to help our model understand various edit-ing requests given the imbalanced dataset. In addition, two other novel ideas are proposed: an Image-Request Atten-tion (IRA) module which allows our method to edit an image spatial-adaptively when the image requires different editing degree at different regions, as well as a new evaluation met-ric for this task which is more semantic and reasonable than conventional pixel losses (e.g. L1). Extensive experiments on two benchmark datasets demonstrate the effectiveness of our method over existing approaches. 