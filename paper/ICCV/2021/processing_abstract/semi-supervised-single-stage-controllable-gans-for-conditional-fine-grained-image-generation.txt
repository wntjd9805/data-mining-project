Previous state-of-the-art deep generative models im-prove fine-grained image generation quality by design-ing hierarchical model structures and synthesizing images across multiple stages. The learning process is typical-ly performed without any supervision in object categories.To address this issue, while at the same time to alleviate the level of complexity of both model design and train-ing, we propose a Single-Stage Controllable GAN (SSC-GAN) for conditional fine-grained image synthesis in a semi-supervised setting. Considering the fact that fine-grained object categories may have subtle distinctions and shared attributes, we take into account three factors of vari-ation for generative modeling: class-independent content, cross-class attributes and class semantics, and associate them with different variables. To ensure disentanglement among the variables, we maximize mutual information be-tween the class-independent variable and synthesized im-ages, map real data to the latent space of a generator to perform consistency regularization of cross-class attributes, and incorporate class semantic-based regularization into a discriminatorâ€™s feature space. We show that the proposed approach delivers a single-stage controllable generator and high-fidelity synthesized images of fine-grained categories.SSC-GAN establishes state-of-the-art semi-supervised im-age synthesis results across multiple fine-grained datasets. 