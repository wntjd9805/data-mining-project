Existing Unsupervised Domain Adaptation (UDA) liter-ature adopts the covariate shift and conditional shift as-sumptions, which essentially encourage models to learn common features across domains. However, due to the lack of supervision in the target domain, they suffer from the semantic loss: the feature will inevitably lose non-discriminative semantics in source domain, which is how-ever discriminative in target domain. We use a causal view—transportability theory [40]—to identify that such loss is in fact a confounding effect, which can only be re-moved by causal intervention. However, the theoretical solution provided by transportability is far from practical for UDA, because it requires the stratiﬁcation and repre-sentation of the unobserved confounder that is the cause of the domain gap. To this end, we propose a practi-cal solution: Transporting Causal Mechanisms (TCM), to identify the confounder stratum and representations by us-ing the domain-invariant disentangled causal mechanisms, which are discovered in an unsupervised fashion. OurTCM is both theoretically and empirically grounded. Ex-tensive experiments show that TCM achieves state-of-the-art performance on three challenging UDA benchmarks:ImageCLEF-DA, Ofﬁce-Home, and VisDA-2017. Codes are available at https://github.com/yue-zhongqi/ tcm. 