Deep convolutional neural networks (CNNs) have pushed forward the frontier of super-resolution (SR) re-search. However, current CNN models exhibit a majorﬂaw: they are biased towards learning low-frequency sig-nals. This bias becomes more problematic for the image SR task which targets reconstructing all ﬁne details and image textures. To tackle this challenge, we propose to improve the learning of high-frequency features both locally and glob-ally and introduce two novel architectural units to exist-ing SR models. Speciﬁcally, we propose a dynamic high-pass ﬁltering (HPF) module that locally applies adaptiveﬁlter weights for each spatial location and channel group to preserve high-frequency signals. We also propose a ma-trix multi-spectral channel attention (MMCA) module that predicts the attention map of features decomposed in the frequency domain. This module operates in a global con-text to adaptively recalibrate feature responses at differ-ent frequencies. Extensive qualitative and quantitative re-sults demonstrate that our proposed modules achieve better accuracy and visual improvements against state-of-the-art methods on several benchmark datasets. 