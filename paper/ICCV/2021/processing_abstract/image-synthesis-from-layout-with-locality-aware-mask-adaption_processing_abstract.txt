This paper is concerned with synthesizing images con-ditioned on a layout (a set of bounding boxes with ob-ject categories). Existing works construct a layout-mask-image pipeline. Object masks are generated separately and mapped to bounding boxes to form a whole semantic seg-mentation mask (layout-to-mask), with which a new image is generated (mask-to-image). However, overlapped boxes in layouts result in overlapped object masks, which reduces the mask clarity and causes confusion in image generation.We hypothesize the importance of generating clean and se-mantically clear semantic masks. The hypothesis is sup-ported by the finding that the performance of state-of-the-art LostGAN decreases when input masks are tainted. Mo-tivated by this hypothesis, we propose Locality-Aware MaskAdaption (LAMA) module to adapt overlapped or nearby object masks in the generation. Experimental results show our proposed model with LAMA outperforms existing ap-proaches regarding visual fidelity and alignment with input layouts. On COCO-stuff in 256 256, our method improves the state-of-the-art FID score from 41.65 to 31.12 and theSceneFID from 22.00 to 18.64.Ã— 