In this paper, we propose a novel solution for object-matching based semi-supervised video object segmentation, where the target object masks in the ﬁrst frame are pro-vided. Existing object-matching based methods focus on the matching between the raw object features of the current frame and the ﬁrst/previous frames. However, two issues are still not solved by these object-matching based meth-ods. As the appearance of the video object changes drasti-cally over time, 1) unseen parts/details of the object present in the current frame, resulting in incomplete annotation in the ﬁrst annotated frame (e.g. view/scale changes). 2) even for the seen parts/details of the object in the current frame, their positions change relatively (e.g. pose changes/camera motion), leading to a misalignment for the object match-ing. To obtain the complete information of the target ob-ject, we propose a novel object-based dynamic memory net-work that exploits visual contents of all the past frames. To solve the misalignment problem caused by position changes of visual contents, we propose an adaptive object align-ment module by incorporating a region translation function that aligns object proposals towards templates in the feature space. Our method achieves state-of-the-art results on lat-est benchmark datasets DAVIS 2017 (J of 81.4% and F of 87.5% on the validation set) and YouTube-VOS (the overall score of 82.7% on the validation set) with a very efﬁcient inference time (0.16 second/frame on DAVIS 2017 valida-tion set). Code is available at: https://github.com/ liang4sx/DMN-AOA. 