Conventional deep image inpainting methods are based on auto-encoder architecture, in which the spatial details of images will be lost in the down-sampling process, lead-ing to the degradation of generated results. Also, the struc-ture information in deep layers and texture information in shallow layers of the auto-encoder architecture can not be well integrated. Differing from the conventional image in-painting architecture, we design a parallel multi-resolution inpainting network with multi-resolution partial convolu-tion, in which low-resolution branches focus on the global structure while high-resolution branches focus on the local texture details. All these high- and low-resolution streams are in parallel and fused repeatedly with multi-resolution masked representation fusion so that the reconstructed im-ages are semantically robust and textually plausible. Ex-perimental results show that our method can effectively fuse structure and texture information, producing more realistic results than state-of-the-art methods. 