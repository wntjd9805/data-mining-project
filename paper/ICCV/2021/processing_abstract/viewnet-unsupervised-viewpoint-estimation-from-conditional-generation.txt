Understanding the 3D world without supervision is cur-rently a major challenge in computer vision as the annota-tions required to supervise deep networks for tasks in this domain are expensive to obtain on a large scale.In this paper, we address the problem of unsupervised viewpoint estimation. We formulate this as a self-supervised learning task, where image reconstruction provides the supervision needed to predict the camera viewpoint. Specifically, we make use of pairs of images of the same object at train-ing time, from unknown viewpoints, to self-supervise train-ing by combining the viewpoint information from one image with the appearance information from the other. We demon-strate that using a perspective spatial transformer allows efficient viewpoint learning, outperforming existing unsu-pervised approaches on synthetic data, and obtains com-petitive results on the challenging PASCAL3D+ dataset. 