Recent learning approaches that implicitly represent sur-face geometry using coordinate-based neural representa-tions have shown impressive results in the problem of multi-view 3D reconstruction. The effectiveness of these tech-niques is, however, subject to the availability of a large number (several tens) of input views of the scene, and com-In this paper, we putationally demanding optimizations. tackle these limitations for the specific problem of few-shot full 3D head reconstruction, by endowing coordinate-based representations with a probabilistic shape prior that en-ables faster convergence and better generalization when using few input images (down to three). First, we learn a shape model of 3D heads from thousands of incomplete raw scans using implicit representations. At test time, we jointly overfit two coordinate-based neural networks to the scene, one modelling the geometry and another estimat-ing the surface radiance, using implicit differentiable ren-dering. We devise a two-stage optimization strategy in which the learned prior is used to initialize and constrain the geometry during an initial optimization phase. Then, the prior is unfrozen and fine-tuned to the scene. By do-ing this, we achieve high-fidelity head reconstructions, in-cluding hair and shoulders, and with a high level of detail that consistently outperforms both state-of-the-art 3D Mor-phable Models methods in the few-shot scenario, and non-parametric methods when large sets of views are available. 