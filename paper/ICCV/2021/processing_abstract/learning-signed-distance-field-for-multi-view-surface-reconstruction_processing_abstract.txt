Recent works on implicit neural representations have shown promising results for multi-view surface reconstruc-tion. However, most approaches are limited to relatively simple geometries and usually require clean object masks for reconstructing complex and concave objects.In this work, we introduce a novel neural surface reconstruction framework that leverages the knowledge of stereo match-ing and feature consistency to optimize the implicit surface representation. More speciﬁcally, we apply a signed dis-tance ﬁeld (SDF) and a surface light ﬁeld to represent the scene geometry and appearance respectively. The SDF is directly supervised by geometry from stereo matching, and is reﬁned by optimizing the multi-view feature consistency and the ﬁdelity of rendered images. Our method is able to improve the robustness of geometry estimation and support reconstruction of complex scene topologies. Extensive ex-periments have been conducted on DTU, EPFL and Tanks and Temples datasets. Compared to previous state-of-the-art methods, our method achieves better mesh reconstruc-tion in wide open scenes without masks as input. 