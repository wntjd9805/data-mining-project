Instance segmentation can detect where the objects are in an image, but hard to understand the relationship be-tween them. We pay attention to a typical relationship, relative saliency. A closely related task, salient object detection, predicts a binary map highlighting a visually salient region while hard to distinguish multiple objects. Di-rectly combining two tasks by post-processing also leads to poor performance. There is a lack of research on relative saliency at present, limiting the practical applications such as content-aware image cropping, video summary, and im-age labeling.In this paper, we study the Salient Object Ranking (SOR) task, which manages to assign a ranking order of each de-tected object according to its visual saliency. We propose the first end-to-end framework of the SOR task and solve it in a multi-task learning fashion. The framework han-dles instance segmentation and salient object ranking si-multaneously. In this framework, the SOR branch is inde-pendent and flexible to cooperate with different detection methods, so that easy to use as a plugin. We also intro-duce a Position-Preserved Attention (PPA) module tailored for the SOR branch. It consists of the position embedding stage and feature interaction stage. Considering the im-portance of position in saliency comparison, we preserve absolute coordinates of objects in ROI pooling operation and then fuse positional information with semantic features in the first stage. In the feature interaction stage, we ap-ply the attention mechanism to obtain proposalsâ€™ contextu-alized representations to predict their relative ranking or-ders. Extensive experiments have been conducted on theASR dataset. Without bells and whistles, our proposed method outperforms the former state-of-the-art method sig-nificantly. The code will be released publicly available on https://github.com/EricFH/SOR. 