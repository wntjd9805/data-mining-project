Simulators can efÔ¨Åciently generate large amounts of la-beled synthetic data with perfect supervision for hard-to-label tasks like semantic segmentation. However, they in-troduce a domain gap that severely hurts real-world per-formance. We propose to use self-supervised monocu-lar depth estimation as a proxy task to bridge this gap and improve sim-to-real unsupervised domain adaptation (UDA). Our Geometric Unsupervised Domain Adaptation method (GUDA)1 learns a domain-invariant representation via a multi-task objective combining synthetic semantic su-pervision with real-world geometric constraints on videos.GUDA establishes a new state of the art in UDA for seman-tic segmentation on three benchmarks, outperforming meth-ods that use domain adversarial learning, self-training, or other self-supervised proxy tasks. Furthermore, we show that our method scales well with the quality and quantity of synthetic data while also improving depth prediction. 