We present Voxel Transformer (VoTr), a novel and effec-tive voxel-based Transformer backbone for 3D object de-tection from point clouds. Conventional 3D convolutional backbones in voxel-based 3D detectors cannot efﬁciently capture large context information, which is crucial for ob-ject recognition and localization, owing to the limited re-ceptive ﬁelds. In this paper, we resolve the problem by intro-ducing a Transformer-based architecture that enables long-range relationships between voxels by self-attention. Given the fact that non-empty voxels are naturally sparse but nu-merous, directly applying standard Transformer on voxels is non-trivial. To this end, we propose the sparse voxel module and the submanifold voxel module, which can operate on the empty and non-empty voxel positions effectively. To fur-ther enlarge the attention range while maintaining compa-rable computational overhead to the convolutional counter-parts, we propose two attention mechanisms for multi-head attention in those two modules: Local Attention and DilatedAttention, and we further propose Fast Voxel Query to ac-celerate the querying process in multi-head attention. VoTr contains a series of sparse and submanifold voxel modules, and can be applied in most voxel-based detectors. Our pro-posed VoTr shows consistent improvement over the convolu-tional baselines while maintaining computational efﬁciency on the KITTI dataset and the Waymo Open dataset. 