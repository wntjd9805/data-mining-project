RGB-D based 6D pose estimation has recently achieved remarkable progress, but still suffers from two major limita-tions: (1) ineffective representation of depth data and (2) in-sufficient integration of different modalities. This paper pro-poses a novel deep learning approach, namely Graph Con-volutional Network with Point Refinement (PR-GCN), to si-multaneously address the issues above in a unified way. It first introduces the Point Refinement Network (PRN) to pol-ish 3D point clouds, recovering missing parts with noise re-moved. Subsequently, the Multi-Modal Fusion Graph Con-volutional Network (MMF-GCN) is presented to strengthenRGB-D combination, which captures geometry-aware inter-modality correlation through local information propagation in the graph convolutional network. Extensive experiments are conducted on three widely used benchmarks, and state-of-the-art performance is reached. Besides, it is also shown that the proposed PRN and MMF-GCN modules are well generalized to other frameworks. 