While CNN-based models have made remarkable progress on human pose estimation, what spatial depen-dencies they capture to localize keypoints remains un-In this work, we propose a model called Trans-clear.Pose, which introduces Transformer for human pose esti-mation. The attention layers built in Transformer enable our model to capture long-range relationships efficiently and also can reveal what dependencies the predicted key-points rely on. To predict keypoint heatmaps, the last at-tention layer acts as an aggregator, which collects contri-butions from image clues and forms maximum positions of keypoints. Such a heatmap-based localization approach viaTransformer conforms to the principle of Activation Maxi-mization [19]. And the revealed dependencies are image-specific and fine-grained, which also can provide evidence of how the model handles special cases, e.g., occlusion.The experiments show that TransPose achieves 75.8 AP and 75.0 AP on COCO validation and test-dev sets, while being more lightweight and faster than mainstream CNN archi-tectures. The TransPose model also transfers very well onMPII benchmark, achieving superior performance on the test set when fine-tuned with small training costs. Code and pre-trained models are publicly available1. 