Conventional techniques to establish dense correspon-dences across visually or semantically similar images fo-cused on designing a task-speciﬁc matching prior, which is difﬁcult to model in general. To overcome this, recent learning-based methods have attempted to learn a good matching prior within a model itself on large training data.The performance improvement was apparent, but the need for sufﬁcient training data and intensive learning hinders their applicability. Moreover, using the ﬁxed model at test time does not account for the fact that a pair of images may require their own prior, thus providing limited performance and poor generalization to unseen images.In this paper, we show that an image pair-speciﬁc prior can be captured by solely optimizing the untrained match-ing networks on an input pair of images. Tailored for such test-time optimization for dense correspondence, we present a residual matching network and a conﬁdence-aware con-trastive loss to guarantee a meaningful convergence. Ex-periments demonstrate that our framework, dubbed DeepMatching Prior (DMP), is competitive, or even outper-forms, against the latest learning-based methods on several benchmarks for geometric matching and semantic match-ing, even though it requires neither large training data nor intensive learning. With the networks pre-trained, DMP at-tains state-of-the-art performance on all benchmarks. 