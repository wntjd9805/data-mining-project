Self-supervised learning has been successfully applied to pre-train video representations, which aims at efﬁcient adaptation from pre-training domain to downstream tasks.Existing approaches merely leverage contrastive loss to learn instance-level discrimination. However, lack of cat-egory information will lead to hard-positive problem that constrains the generalization ability of this kind of meth-ods. We ﬁnd that the multi-task process of meta learning can provide a solution to this problem. In this paper, we propose a Meta-Contrastive Network (MCN), which com-bines the contrastive learning and meta learning, to en-hance the learning ability of existing self-supervised ap-proaches. Our method contains two training stages based on model-agnostic meta learning (MAML), each of which consists of a contrastive branch and a meta branch. Ex-tensive evaluations demonstrate the effectiveness of our method. For two downstream tasks, i.e., video action recog-nition and video retrieval, MCN outperforms state-of-the-art approaches on UCF101 and HMDB51 datasets. To be more speciﬁc, with R(2+1)D backbone, MCN achieves Top-1 accuracies of 84.8% and 54.5% for video action recogni-tion, as well as 52.5% and 23.7% for video retrieval. 