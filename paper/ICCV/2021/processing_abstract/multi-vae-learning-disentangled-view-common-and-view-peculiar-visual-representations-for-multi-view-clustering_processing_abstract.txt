Multi-view clustering, a long-standing and important re-search problem, focuses on mining complementary infor-mation from diverse views. However, existing works often fuse multiple views’ representations or handle clustering in a common feature space, which may result in their entan-glement especially for visual representations. To address this issue, we present a novel VAE-based multi-view clus-tering framework (Multi-VAE) by learning disentangled vi-sual representations. Concretely, we define a view-common variable and multiple view-peculiar variables in the gen-erative model. The prior of view-common variable obeys approximately discrete Gumbel Softmax distribution, which is introduced to extract the common cluster factor of multi-ple views. Meanwhile, the prior of view-peculiar variable follows continuous Gaussian distribution, which is used to represent each view’s peculiar visual factors. By controlling the mutual information capacity to disentangle the view-common and view-peculiar representations, continuous vi-sual information of multiple views can be separated so that their common discrete cluster information can be effectively mined. Experimental results demonstrate that Multi-VAE enjoys the disentangled and explainable visual represen-tations, while obtaining superior clustering performance compared with state-of-the-art methods. 