Domain adaptation for semantic segmentation aims to improve the model performance in the presence of a distri-bution shift between source and target domain. Leverag-ing the supervision from auxiliary tasks (such as depth esti-mation) has the potential to heal this shift because many visual tasks are closely related to each other. However, such a supervision is not always available. In this work, we leverage the guidance from self-supervised depth esti-mation, which is available on both domains, to bridge the domain gap. On the one hand, we propose to explicitly learn the task feature correlation to strengthen the target semantic predictions with the help of target depth estima-tion. On the other hand, we use the depth prediction dis-crepancy from source and target depth decoders to approx-imate the pixel-wise adaptation difﬁculty. The adaptation difﬁculty, inferred from depth, is then used to reﬁne the target semantic segmentation pseudo-labels. The proposed method can be easily implemented into existing segmenta-tion frameworks. We demonstrate the effectiveness of our approach on the benchmark tasks SYNTHIA-to-Cityscapes and GTA-to-Cityscapes, on which we achieve the new state-of-the-art performance of 55.0% and 56.6%, respectively.Our code is available at https://qin.ee/corda. 