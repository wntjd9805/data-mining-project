Most existing convolution neural network (CNN) based super-resolution (SR) methods generate their paired train-ing dataset by artiﬁcially synthesizing low-resolution (LR) images from the high-resolution (HR) ones. However, this dataset preparation strategy harms the application of theseCNNs in real-world scenarios due to the inherent domain gap between the training and testing data. A popular at-tempts towards the challenge is unpaired generative ad-versarial networks, which generate “real” LR counterparts from real HR images using image-to-image translation and then perform super-resolution from “real” LR→SR. De-spite great progress, it is still difﬁcult to synthesize perfect“real” LR images for super-resolution. In this paper, weﬁrstly consider the real-world SR problem from the tradi-tional domain adaptation perspective. We propose a novel unpaired SR training framework based on feature distri-bution alignment, with which we can obtain degradation-indistinguishable feature maps and then map them to HR images. In order to generate better SR images for targetLR domain, we introduce several regularization losses to force the aligned feature to locate around the target domain.Our experiments indicate that our SR network obtains the state-of-the-art performance over both blind and unpairedSR methods on diverse datasets. 