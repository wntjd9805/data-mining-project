The class activation mapping, or CAM, has been the cor-nerstone of feature attribution methods for multiple vision tasks. Its simplicity and effectiveness have led to wide appli-cations in the explanation of visual predictions and weakly-supervised localization tasks. However, CAM has its own shortcomings. The computation of attribution maps relies on ad-hoc calibration steps that are not part of the train-ing computational graph, making it difﬁcult for us to un-derstand the real meaning of the attribution values. In this paper, we improve CAM by explicitly incorporating a la-tent variable encoding the location of the cue for recogni-tion in the formulation, thereby subsuming the attribution map into the training computational graph. The result-ing model, class activation latent mapping, or CALM, is trained with the expectation-maximization algorithm. Our experiments show that CALM identiﬁes discriminative at-tributes for image classiﬁers more accurately than CAM and other visual attribution baselines. CALM also shows performance improvements over prior arts on the weakly-supervised object localization benchmarks. Our code is available at https://github.com/naver-ai/calm. 