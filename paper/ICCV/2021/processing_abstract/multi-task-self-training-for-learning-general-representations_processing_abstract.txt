Despite the fast progress in training specialized mod-els for various tasks, learning a single general model that works well for many tasks is still challenging for computer vision. Here we introduce multi-task self-training (MuST), which harnesses the knowledge in independent specialized teacher models (e.g., ImageNet model on classiﬁcation) to train a single general student model. Our approach has three steps. First, we train specialized teachers indepen-dently on labeled datasets. We then use the specialized teachers to label an unlabeled dataset to create a multi-task pseudo labeled dataset. Finally, the dataset, which now contains pseudo labels from teacher models trained on different datasets/tasks, is then used to train a student model with multi-task learning. We evaluate the feature rep-resentations of the student model on 6 vision tasks including image recognition (classiﬁcation, detection, segmentation) and 3D geometry estimation (depth and surface normal es-timation). MuST is scalable with unlabeled or partially la-beled datasets and outperforms both specialized supervised models and self-supervised models when training on large scale datasets. Lastly, we show MuST can improve upon already strong checkpoints [23] trained with billions of ex-amples. The results suggest self-training is a promising di-rection to aggregate labeled and unlabeled training data for learning general feature representations. 