Gaze following, i.e., detecting the gaze target of a hu-man subject, in 2D images has become an active topic in computer vision. However, it usually suffers from the out of frame issue due to the limited field-of-view (FoV) of 2D im-ages. In this paper, we introduce a novel task, gaze follow-ing in 360-degree images which provide an omnidirectionalFoV and can alleviate the out of frame issue. We collect the first dataset, “GazeFollow360”1, for this task, contain-ing around 10,000 360-degree images with complex gaze behaviors under various scenes. Existing 2D gaze follow-ing methods suffer from performance degradation in 360-degree images since they may use the assumption that a gaze target is in the 2D gaze sight line. However, this as-sumption is no longer true for long-distance gaze behav-iors in 360-degree images, due to the distortion brought by sphere-to-plane projection. To address this challenge, we propose a 3D sight line guided dual-pathway framework, to detect the gaze target within a local region (here) and from a distant region (there), parallelly. Specifically, the lo-cal region is obtained as a 2D cone-shaped field along the 2D projection of the sight line starting at the human sub-ject’s head position, and the distant region is obtained by searching along the sight line in 3D sphere space. Finally, the location of the gaze target is determined by fusing the estimations from both the local region and the distant re-gion. Experimental results show that our method achieves significant improvements over previous 2D gaze following methods on our GazeFollow360 dataset. 