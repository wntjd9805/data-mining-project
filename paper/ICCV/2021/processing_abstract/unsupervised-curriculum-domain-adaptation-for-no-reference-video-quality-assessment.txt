During the last years, convolutional neural networks (C-NNs) have triumphed over video quality assessment (VQA) tasks. However, CNN-based approaches heavily rely on annotated data which are typically not available in VQA, leading to the difﬁculty of model generalization. Recent ad-vances in domain adaptation technique makes it possible to adapt models trained on source data to unlabeled target data. However, due to the distortion diversity and content variation of the collected videos, the intrinsic subjectivi-ty of VQA tasks hampers the adaptation performance. In this work, we propose a curriculum-style unsupervised do-main adaptation to handle the cross-domain no-referenceVQA problem. The proposed approach could be divided into two stages.In the ﬁrst stage, we conduct an adap-tation between source and target domains to predict the rating distribution for target samples, which can better re-veal the subjective nature of VQA. From this adaptation, we split the data in target domain into conﬁdent and un-certain subdomains using the proposed uncertainty-based ranking function, through measuring their prediction conﬁ-dences. In the second stage, by regarding samples in con-ﬁdent subdomain as the easy tasks in the curriculum, aﬁne-level adaptation is conducted between two subdomain-s to ﬁne-tune the prediction model. Extensive experimen-tal results on benchmark datasets highlight the superiori-ty of the proposed method over the competing methods in both accuracy and speed. The source code is released at https://github.com/cpf0079/UCDA. 