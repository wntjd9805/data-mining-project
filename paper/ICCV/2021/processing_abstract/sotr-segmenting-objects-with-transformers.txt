Most recent transformer-based models show impressive performance on vision tasks, even better than Convolu-tion Neural Networks (CNN). In this work, we present a novel, ﬂexible, and effective transformer-based model for high-quality instance segmentation. The proposed method,Segmenting Objects with TRansformers (SOTR), simpliﬁes the segmentation pipeline, building on an alternative CNN backbone appended with two parallel subtasks: (1) predict-ing per-instance category via transformer and (2) dynami-cally generating segmentation mask with the multi-level up-sampling module. SOTR can effectively extract lower-level feature representations and capture long-range context de-pendencies by Feature Pyramid Network (FPN) and twin transformer, respectively. Meanwhile, compared with the original transformer, the proposed twin transformer is time-and resource-efﬁcient since only a row and a column at-tention are involved to encode pixels. Moreover, SOTR is easy to be incorporated with various CNN backbones and transformer model variants to make considerable improve-ments for the segmentation accuracy and training conver-gence. Extensive experiments show that our SOTR performs well on the MS COCO dataset and surpasses state-of-the-art instance segmentation approaches. We hope our sim-ple but strong framework could serve as a preferment base-line for instance-level recognition. Our code is available at https://github.com/easton-cau/SOTR. 