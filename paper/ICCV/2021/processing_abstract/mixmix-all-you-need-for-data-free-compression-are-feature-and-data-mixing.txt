User data confidentiality protection is becoming a rising challenge in the present deep learning research. Without access to data, conventional data-driven model compres-sion faces a higher risk of performance degradation. Re-cently, some works propose to generate images from a spe-cific pretrained model to serve as training data. However, the inversion process only utilizes biased feature statistics stored in one model and is from low-dimension to high-dimension. As a consequence, it inevitably encounters the difficulties of generalizability and inexact inversion, which leads to unsatisfactory performance. To address these prob-lems, we propose MixMix based on two simple yet effective techniques: (1) Feature Mixing: utilizes various models to construct a universal feature space for generalized inver-sion; (2) Data Mixing: mixes the synthesized images and labels to generate exact label information. We prove the effectiveness of MixMix from both theoretical and empiri-cal perspectives. Extensive experiments show that MixMix outperforms existing methods on the mainstream compres-sion tasks, including quantization, knowledge distillation and pruning. Specifically, MixMix achieves up to 4% and 20% accuracy uplift on quantization and pruning, respec-tively, compared to existing data-free compression work. 