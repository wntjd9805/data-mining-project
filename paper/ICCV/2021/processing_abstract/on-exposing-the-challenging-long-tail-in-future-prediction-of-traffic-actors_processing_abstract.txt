Predicting the states of dynamic traffic actors into the fu-ture is important for autonomous systems to operate safely and efficiently. Remarkably, the most critical scenarios are much less frequent and more complex than the uncritical ones. Therefore, uncritical cases dominate the prediction.In this paper, we address specifically the challenging sce-narios at the long tail of the dataset distribution. Our anal-ysis shows that the common losses tend to place challeng-ing cases sub-optimally in the embedding space. As a con-sequence, we propose to supplement the usual loss with a loss that places challenging cases closer to each other. This triggers sharing information among challenging cases and learning specific predictive features. We show on four pub-lic datasets that this leads to improved performance on the challenging scenarios while the overall performance stays stable. The approach is agnostic w.r.t. the used network architecture, input modality or viewpoint, and can be inte-grated into existing solutions easily. Code is available at github. 