Every recent image-to-image translation model inher-ently requires either image-level (i.e. input-output pairs) or set-level (i.e. domain labels) supervision. However, even set-level supervision can be a severe bottleneck for data col-lection in practice. In this paper, we tackle image-to-image translation in a fully unsupervised setting, i.e., neither paired images nor domain labels. To this end, we propose a truly unsupervised image-to-image translation model (TU-NIT) that simultaneously learns to separate image domains and translates input images into the estimated domains. Ex-perimental results show that our model achieves compara-ble or even better performance than the set-level supervised model trained with full labels, generalizes well on various datasets, and is robust against the choice of hyperparam-eters (e.g. the preset number of pseudo domains). Fur-thermore, TUNIT can be easily extended to semi-supervised learning with a few labeled data. 