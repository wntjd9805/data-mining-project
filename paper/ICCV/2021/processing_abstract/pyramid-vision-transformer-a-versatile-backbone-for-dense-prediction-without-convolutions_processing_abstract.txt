Although convolutional neural networks (CNNs) have achieved great success in computer vision, this work inves-tigates a simpler, convolution-free backbone network use-ful for many dense prediction tasks. Unlike the recently-proposed Vision Transformer (ViT) that was designed for image classification specifically, we introduce the Pyra-mid Vision Transformer (PVT), which overcomes the diffi-culties of porting Transformer to various dense prediction tasks. PVT has several merits compared to current state of the arts. (1) Different from ViT that typically yields low-resolution outputs and incurs high computational and mem-ory costs, PVT not only can be trained on dense partitions of an image to achieve high output resolution, which is im-portant for dense prediction, but also uses a progressive shrinking pyramid to reduce the computations of large fea-ture maps. (2) PVT inherits the advantages of both CNN and Transformer, making it a unified backbone for vari-(cid:66) Corresponding authors: Deng-Ping Fan (dengpfan@gmail.com);Tong Lu (lutong@nju.edu.cn). ous vision tasks without convolutions, where it can be used as a direct replacement for CNN backbones. (3) We val-idate PVT through extensive experiments, showing that it boosts the performance of many downstream tasks, includ-ing object detection, instance and semantic segmentation.For example, with a comparable number of parameters,PVT+RetinaNet achieves 40.4 AP on the COCO dataset, surpassing ResNet50+RetinNet (36.3 AP) by 4.1 absoluteAP (see Figure 2). We hope that PVT could serve as an alternative and useful backbone for pixel-level predictions and facilitate future research. 