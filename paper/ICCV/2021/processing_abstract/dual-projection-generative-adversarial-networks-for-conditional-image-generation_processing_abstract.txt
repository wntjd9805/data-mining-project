Conditional Generative Adversarial Networks (cGANs) extend the standard unconditional GAN framework to learning joint data-label distributions from samples, and have been established as powerful generative models ca-pable of generating high-fidelity imagery. A challenge of training such a model lies in properly infusing class infor-mation into its generator and discriminator. For the dis-criminator, class conditioning can be achieved by either (1) directly incorporating labels as input or (2) involving labels in an auxiliary classification loss. In this paper, we show that the former directly aligns the class-conditioned fake-and-real data distributions P (image|class) (data match-ing), while the latter aligns data-conditioned class distribu-tions P (class|image) (label matching). Although class sep-arability does not directly translate to sample quality and becomes a burden if classification itself is intrinsically dif-ficult, the discriminator cannot provide useful guidance for the generator if features of distinct classes are mapped to the same point and thus become inseparable. Motivated by this intuition, we propose a Dual Projection GAN (P2GAN) model that learns to balance between data matching and la-bel matching. We then propose an improved cGAN model with Auxiliary Classification that directly aligns the fake and real conditionals P (class|image) by minimizing their f -divergence. Experiments on a synthetic Mixture of Gaus-sian (MoG) dataset and a variety of real-world datasets in-cluding CIFAR100, ImageNet, and VGGFace2 demonstrate the efficacy of our proposed models. 