A variety of effective face-swap and face-reenactment methods have been publicized in recent years, democratiz-ing the face synthesis technology to a great extent. Videos generated as such have come to be called deepfakes with a negative connotation, for various social problems they have caused. Facing the emerging threat of deepfakes, we have built the Korean DeepFake Detection Dataset (KoDF), a large-scale collection of synthesized and real videos focused on Korean subjects. In this paper, we pro-vide a detailed description of methods used to construct the dataset, experimentally show the discrepancy between the distributions of KoDF and existing deepfake detec-tion datasets, and underline the importance of using mul-tiple datasets for real-world generalization. KoDF is pub-licly available at https://moneybrain-research. github.io/kodf in its entirety (i.e. real clips, synthe-sized clips, clips with adversarial attack, and metadata). 