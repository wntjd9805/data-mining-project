A lifespan face synthesis (LFS) model aims to generate a set of photo-realistic face images of a personâ€™s whole life, given only one snapshot as reference. The generated face image given a target age code is expected to be age-sensitive reflected by bio-plausible transformations of shape and texture, while being identity preserving. This is ex-tremely challenging because the shape and texture char-acteristics of a face undergo separate and highly nonlin-ear transformations w.r.t. age. Most recent LFS models are based on generative adversarial networks (GANs) whereby age code conditional transformations are applied to a la-tent face representation. They benefit greatly from the re-cent advancements of GANs. However, without explic-itly disentangling their latent representations into the tex-ture, shape and identity factors, they are fundamentally lim-ited in modeling the nonlinear age-related transformation on texture and shape whilst preserving identity.In this work, a novel LFS model is proposed to disentangle the*Equal contribution key face characteristics including shape, texture and iden-tity so that the unique shape and texture age transforma-tions can be modeled effectively. This is achieved by ex-tracting shape, texture and identity features separately from an encoder. Critically, two transformation modules, one conditional convolution based and the other channel atten-tion based, are designed for modeling the nonlinear shape and texture feature transformations respectively. This is to accommodate their rather distinct aging processes and ensure that our synthesized images are both age-sensitive and identity preserving. Extensive experiments show that our LFS model is clearly superior to the state-of-the-art al-ternatives. Codes and demo are available on our project website: https://senhe.github.io/projects/ iccv_2021_lifespan_face. 