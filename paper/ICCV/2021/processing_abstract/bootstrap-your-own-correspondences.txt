Geometric feature extraction is a crucial component of point cloud registration pipelines. Recent work has demon-strated how supervised learning can be leveraged to learn better and more compact 3D features. However, those ap-proachesâ€™ reliance on ground-truth annotation limits their scalability. We propose BYOC: a self-supervised approach that learns visual and geometric features from RGB-D video without relying on ground-truth pose or correspon-dence. Our key observation is that randomly-initializedCNNs readily provide us with good correspondences; al-lowing us to bootstrap the learning of both visual and ge-ometric features. Our approach combines classic ideas from point cloud registration with more recent representa-tion learning approaches. We evaluate our approach on in-door scene datasets and find that our method outperforms traditional and learned descriptors, while being competitive with current state-of-the-art supervised approaches. 