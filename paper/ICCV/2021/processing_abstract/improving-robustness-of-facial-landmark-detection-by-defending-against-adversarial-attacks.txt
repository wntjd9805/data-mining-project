Many recent developments in facial landmark detection have been driven by stacking model parameters or aug-menting annotations. However, three subsequent challenges remain, including 1) an increase in computational over-head, 2) the risk of overﬁtting caused by increasing model parameters, and 3) the burden of labor-intensive annota-tion by humans. We argue that exploring the weaknesses of the detector so as to remedy them is a promising method of robust facial landmark detection. To achieve this, we propose a sample-adaptive adversarial training (SAAT) ap-proach to interactively optimize an attacker and a detec-tor, which improves facial landmark detection as a defense against sample-adaptive black-box attacks. By leveraging adversarial attacks, the proposed SAAT exploits adversar-ial perturbations beyond the handcrafted transformations to improve the detector. Speciﬁcally, an attacker gener-ates adversarial perturbations to reﬂect the weakness of the detector. Then, the detector must improve its robust-ness to adversarial perturbations to defend against adver-sarial attacks. Moreover, a sample-adaptive weight is de-signed to balance the risks and beneﬁts of augmenting ad-versarial examples to train the detector. We also intro-duce a masked face alignment dataset, Masked-300W, to evaluate our method. Experiments show that our SAAT performed comparably to existing state-of-the-art methods.The dataset and model are publicly available at https://github.com/zhuccly/SAAT. 