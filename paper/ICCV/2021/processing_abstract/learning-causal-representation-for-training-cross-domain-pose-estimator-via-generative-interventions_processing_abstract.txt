3D pose estimation has attracted increasing attention with the availability of high-quality benchmark datasets.However, prior works show that deep learning models tend to learn spurious correlations, which fail to generalize be-yond the specific dataset they are trained on. In this work, we take a step towards training robust models for cross-domain pose estimation task, which brings together ideas from causal representation learning and generative adver-sarial networks. Specifically, this paper introduces a novel framework for causal representation learning which ex-plicitly exploits the causal structure of the task. We con-sider changing domain as interventions on images under the data-generation process and steer the generative model to produce counterfactual features. This help the model learn transferable and causal relations across different domains.Our framework is able to learn with various types of unla-beled datasets. We demonstrate the efficacy of our proposed method on both human and hand pose estimation task. The experiment results show the proposed approach achieves state-of-the-art performance on most datasets for both do-main adaptation and domain generalization settings. 