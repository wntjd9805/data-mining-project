Recent studies on Generative Adversarial Network (GAN) reveal that different layers of a generative CNN hold different semantics of the synthesized images. However, fewGAN models have explicit dimensions to control the seman-tic attributes represented in a speciﬁc layer. This paper pro-poses EigenGAN which is able to unsupervisedly mine in-terpretable and controllable dimensions from different gen-erator layers. Speciﬁcally, EigenGAN embeds one linear subspace with orthogonal basis into each generator layer.Via generative adversarial training to learn a target distri-bution, these layer-wise subspaces automatically discover a set of “eigen-dimensions” at each layer corresponding to a set of semantic attributes or interpretable variations. By traversing the coefﬁcient of a speciﬁc eigen-dimension, the generator can produce samples with continuous changes corresponding to a speciﬁc semantic attribute. Taking the human face for example, EigenGAN can discover control-lable dimensions for high-level concepts such as pose and gender in the subspace of deep layers, as well as low-level concepts such as hue and color in the subspace of shal-low layers. Moreover, in the linear case, we theoretically prove that our algorithm derives the principal components as PCA does. Codes can be found in https://github. com/LynnHo/EigenGAN-Tensorflow. 