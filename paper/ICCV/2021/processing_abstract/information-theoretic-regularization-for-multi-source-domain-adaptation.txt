Adversarial learning strategy has demonstrated remark-able performance in dealing with single-source DomainAdaptation (DA) problems, and it has recently been applied to Multi-source DA (MDA) problems. Although most exist-ing MDA strategies rely on a multiple domain discriminator setting, its effect on the latent space representations has been poorly understood. Here we adopt an information-theoretic approach to identify and resolve the potential adverse effect of the multiple domain discriminators on MDA: disintegra-tion of domain-discriminative information, limited compu-tational scalability, and a large variance in the gradient of the loss during training. We examine the above issues by situating adversarial DA in the context of information regu-larization. This also provides a theoretical justification for using a single and unified domain discriminator. Based on this idea, we implement a novel neural architecture called aMulti-source Information-regularized Adaptation Networks (MIAN). Large-scale experiments demonstrate that MIAN, despite its structural simplicity, reliably and significantly outperforms other state-of-the-art methods. 