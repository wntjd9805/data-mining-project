In real-life applications, machine learning models of-ten face scenarios where there is a change in data distri-bution between training and test domains. When the aim is to make predictions on distributions different from those seen at training, we incur in a domain generalization prob-lem. Methods to address this issue learn a model using data from multiple source domains, and then apply this model to the unseen target domain. Our hypothesis is that when training with multiple domains, conflicting gradients within each mini-batch contain information specific to the individ-ual domains which is irrelevant to the others, including the test domain. If left untouched, such disagreement may de-grade generalization performance. In this work, we char-acterize the conflicting gradients emerging in domain shift scenarios and devise novel gradient agreement strategies based on gradient surgery to alleviate their effect. We val-idate our approach in image classification tasks with three multi-domain datasets, showing the value of the proposed agreement strategy in enhancing the generalization capa-bility of deep learning models in domain shift scenarios. 