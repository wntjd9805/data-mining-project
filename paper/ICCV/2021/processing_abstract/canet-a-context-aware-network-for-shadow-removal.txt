In this paper, we propose a novel two-stage context-aware network named CANet for shadow removal, in which the contextual information from non-shadow regions is transferred to shadow regions at the embedded feature spaces. At Stage-I, we propose a contextual patch match-ing (CPM) module to generate a set of potential match-ing pairs of shadow and non-shadow patches. Combined with the potential contextual relationships between shadow and non-shadow regions, our well-designed contextual fea-ture transfer (CFT) mechanism can transfer contextual in-formation from non-shadow to shadow regions at differ-ent scales. With the reconstructed feature maps, we re-move shadows at L and A/B channels separately. At Stage-II, we use an encoder-decoder to reﬁne current results and generate the ﬁnal shadow removal results. We eval-uate our proposed CANet on two benchmark datasets and some real-world shadow images with complex scenes. Ex-tensive experimental results strongly demonstrate the efﬁ-cacy of our proposed CANet and exhibit superior perfor-mance to state-of-the-arts. Our source code is available at https://github.com/Zipei-Chen/CANet. 