In this paper, we challenge the common assumption that collapsing the spatial dimensions of a 3D (spatial-channel) tensor in a convolutional neural network (CNN) into a vector via global pooling removes all spatial information. Specifi-cally, we demonstrate that positional information is encoded based on the ordering of the channel dimensions, while semantic information is largely not. Following this demon-stration, we show the real world impact of these findings by applying them to two applications. First, we propose a simple yet effective data augmentation strategy and loss func-tion which improves the translation invariance of a CNN’s output. Second, we propose a method to efficiently deter-mine which channels in the latent representation are re-sponsible for (i) encoding overall position information or (ii) region-specific positions. We first show that semantic segmentation has a significant reliance on the overall po-sition channels to make predictions. We then show for the first time that it is possible to perform a ‘region-specific’ attack, and degrade a network’s performance in a particular part of the input. We believe our findings and demonstrated applications will benefit research areas concerned with un-derstanding the characteristics of CNNs. Code is available at: https://github.com/islamamirul/PermuteNet. 