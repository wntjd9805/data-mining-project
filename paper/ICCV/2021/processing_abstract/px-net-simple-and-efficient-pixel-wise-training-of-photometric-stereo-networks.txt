Retrieving accurate 3D reconstructions of objects from the way they reﬂect light is a very challenging task in com-puter vision. Despite more than four decades since the deﬁnition of the Photometric Stereo problem, most of the literature has had limited success when global illumina-tion effects such as cast shadows, self-reﬂections and am-bient light come into play, especially for specular surfaces.Recent approaches have leveraged the capabilities of deep learning in conjunction with computer graphics in order to cope with the need of a vast number of training data to in-vert the image irradiance equation and retrieve the geom-etry of the object. However, rendering global illumination effects is a slow process which can limit the amount of train-ing data that can be generated.In this work we propose a novel pixel-wise training pro-cedure for normal prediction by replacing the training data (observation maps) of globally rendered images with in-dependent per-pixel generated data. We show that global physical effects can be approximated on the observation map domain and this simpliﬁes and speeds up the data cre-ation procedure. Our network, PX-NET, achieves state-of-the-art performance compared to other pixelwise methods on synthetic datasets, as well as the DiLiGenT real dataset on both dense and sparse light settings. 