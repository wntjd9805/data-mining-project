We address the problem of domain generalizable object detection, which aims to learn a domain-invariant detec-tor from multiple “seen” domains so that it can generalize well to other “unseen” domains. The generalization abil-ity is crucial in practical scenarios especially when it is difficult to collect data. Compared to image classification, domain generalization in object detection has seldom been explored with more challenges brought by domain gaps on both image and instance levels.In this paper, we pro-pose a novel generalizable object detection model, termedDomain-Invariant Disentangled Network (DIDN). In con-trast to directly aligning multiple sources, we integrate a disentangled network into Faster R-CNN. By disentangling representations on both image and instance levels, DIDN is able to learn domain-invariant representations that are suitable for generalized object detection. Furthermore, we design a cross-level representation reconstruction to com-plement this two-level disentanglement so that informative object representations could be preserved. Extensive exper-iments are conducted on five benchmark datasets and the results demonstrate that our model achieves state-of-the-art performances on domain generalization for object de-tection. 