This paper introduces Panoptic Narrative Grounding, a comprehensive approach to solving the natural language visual grounding problem. It presents a new experimental framework, along with ground truth and metrics, to facilitate research in this area. Additionally, a strong baseline method is proposed to support future work. The approach leverages the semantic richness of images by incorporating panoptic categories and performs visual grounding at a detailed level using segmentations. To improve the quality of ground truth annotations, an algorithm is developed to automatically transfer localized narratives to specific regions in the panoptic segmentations of the MS COCO dataset. This algorithm ensures that only noun phrases that are meaningfully related to the panoptic segmentation region are incorporated, using WordNet's semantic structure. The proposed baseline achieves a performance of 55.4 absolute Average Recall points, providing a solid foundation for further advancements in Panoptic Narrative Grounding methods.