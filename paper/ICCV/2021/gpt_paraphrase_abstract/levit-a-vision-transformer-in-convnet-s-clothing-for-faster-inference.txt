We have developed a series of image classification architectures that prioritize both accuracy and efficiency in high-speed scenarios. Our approach builds upon attention-based architectures, which are known for their competitiveness on parallel processing hardware. By combining principles from convolutional neural networks and transformers, specifically the use of activation maps with decreasing resolutions, we have created a new neural network called LeViT. LeViT incorporates attention bias to integrate positional information in vision transformers. We have evaluated the efficiency of LeViT on different hardware platforms to ensure its applicability across a wide range of scenarios. Through extensive experimentation, we have confirmed the effectiveness of our technical choices and demonstrated that LeViT outperforms existing convolutional neural networks and vision transformers in terms of the speed/accuracy tradeoff. For instance, when achieving 80% ImageNet top-1 accuracy, LeViT is five times faster than EfficientNet on CPU. The code for LeViT is publicly available at https://github.com/facebookresearch/LeViT.