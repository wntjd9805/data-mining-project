This paper presents a new approach called Dynamic DETR that addresses the limitations of the DETR model in terms of small feature resolution and slow training convergence. To overcome the limitation of small feature resolution, a dynamic encoder is proposed, which approximates the attention mechanism of the Transformer encoder using a convolution-based dynamic encoder with different types of attention. This dynamic encoder can adjust attentions based on factors such as scale importance, spatial importance, and feature dimension importance. To address the slow training convergence, a dynamic decoder is introduced, which replaces the cross-attention module with a region of interest (ROI)-based dynamic attention in the Transformer decoder. This dynamic decoder helps the Transformer focus on regions of interest in a coarse-to-fine manner, leading to faster convergence with fewer training epochs. Experimental results demonstrate the advantages of Dynamic DETR, including significantly reducing training epochs (by 14x) while achieving better performance (3.6 increase in mAP). Additionally, using the proposed approach with a ResNet-50 backbone achieves a new state-of-the-art performance, further validating the effectiveness of the proposed approach.