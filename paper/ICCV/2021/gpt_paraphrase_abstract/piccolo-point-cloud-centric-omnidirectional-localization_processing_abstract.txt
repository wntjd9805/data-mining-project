We introduce PICCOLO, a straightforward and efficient algorithm for omnidirectional localization. Our goal is to determine the camera pose from which a 360˝ panorama image was captured, using a colored point cloud and the panorama image as inputs. Unlike other methods, our approach does not rely on training neural networks or acquiring ground-truth image poses. Instead, we utilize gradient-descent optimization to match each point cloud color to the holistic view of the panorama image, allowing us to estimate the camera pose. Our novel loss function, called sampling loss, is point cloud-centric and evaluates the projected location of every point in the point cloud. In comparison, traditional photometric loss is image-centric and compares colors at each pixel location. By shifting the focus to the point cloud, sampling loss effectively addresses the visual distortion commonly found in omnidirectional images and leverages the global context provided by the 360˝ view to handle challenging localization scenarios. In evaluations across different environments, PICCOLO surpasses existing algorithms for omnidirectional localization in terms of accuracy and stability.