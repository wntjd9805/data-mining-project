Training sample re-weighting is an effective approach for addressing data biases, such as imbalanced and corrupted labels. Recent methods have developed learning-based algorithms that simultaneously learn sample re-weighting strategies and train models using reinforcement learning and meta learning frameworks. However, these methods have limited applicability because they rely on additional unbiased reward data. Additionally, existing learning-based sample re-weighting methods involve nested optimizations of models and weight-ing parameters, which require computationally expensive second-order computation. To address these issues, this paper proposes a novel learning-based fast sample re-weighting (FSR) method that eliminates the need for additional reward data. The FSR method is based on two key ideas: learning from historical data to create proxy reward data and sharing features to reduce optimization costs. Experimental results demonstrate that the proposed method achieves competitive performance compared to state-of-the-art approaches in terms of label noise robustness and long-tailed recognition, while significantly improving training efficiency.  The source code for the proposed method is publicly available at https://github.com/google-research/ in the google-research/tree/master/ieg repository.