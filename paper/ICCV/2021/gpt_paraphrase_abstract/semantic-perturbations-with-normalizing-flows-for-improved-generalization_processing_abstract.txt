Data augmentation is a commonly used technique in deep neural network training to prevent overfitting. However, it often requires specific knowledge of the domain and is limited to a fixed set of predetermined transformations. Some recent studies have proposed using generative models to generate meaningful perturbations for training classifiers. However, these methods have been restricted to small datasets due to the need for accurate encoding and decoding, as well as approximations in latent-variable inference. To overcome these limitations, we leverage the reversible encoder-decoder structure of normalizing flows to perform on-manifold perturbations in the latent space, enabling fully unsupervised data augmentation. Our experiments demonstrate that these perturbations achieve similar performance to advanced data augmentation techniques, with a test accuracy of 96.6% on CIFAR-10 using ResNet-18. They also outperform existing methods, particularly in low data scenarios, with a relative improvement of 10-25% in test accuracy compared to traditional training. We find that our latent adversarial perturbations, which adapt to the classifier during training, are the most effective, resulting in the first improvement in test accuracy on real-world datasets (CIFAR-10/100) through latent-space perturbations.