This paper aims to identify the reasons behind two common failures in Semantic Segmentation (SS) and proposes a solution using Self-Regulation (SR) losses. The first failure is the inability to detect small objects or minor parts of objects, while the second failure involves mislabeling minor parts of large objects. The authors find that these failures occur due to the underutilization of detailed features and visual contexts, respectively. To address this, they introduce SR losses for training SS neural networks. These losses allow the model to regulate the deep layer features with the shallow ones to preserve more details, and regulate the shallow layer classification logits with the deep ones to capture more semantics. The authors conduct extensive experiments on both weakly and fully supervised SS tasks, demonstrating that their approach consistently outperforms baseline methods. They also confirm that implementing SR losses in various state-of-the-art SS models incurs minimal computational overhead during training and none during testing.