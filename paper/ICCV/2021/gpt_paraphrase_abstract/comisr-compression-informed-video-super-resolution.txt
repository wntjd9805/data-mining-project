Most existing video super-resolution methods focus on restoring high-resolution frames from low-resolution videos without considering compression. However, since most videos on the web or mobile devices are compressed, severe compression artifacts can occur when bandwidth is limited. This paper introduces a novel compression-informed video super-resolution model that aims to restore high-resolution content without introducing compression-related artifacts. The proposed model consists of three modules: bi-directional recurrent warping, detail-preserving flow estimation, and Laplacian enhancement. These modules are designed to address compression properties such as the location of intra-frames in the input and smoothness in the output frames. To evaluate the performance of the proposed method, extensive experiments were conducted on standard datasets with various compression rates, covering a wide range of real video use cases. The results demonstrate that our method not only successfully recovers high-resolution content from uncompressed frames in widely-used benchmark datasets but also achieves state-of-the-art performance in super-resolving compressed videos, as measured by various quantitative metrics. Additionally, the effectiveness and robustness of the proposed method were evaluated by simulating streaming from YouTube. The source codes and trained models for the proposed method are publicly available at https://github.com/google-research/google-research/tree/master/comisr.