Transfer learning has been the main driving force behind the improvement of spatial saliency prediction since 2014. However, progress in this area has been stagnant in the past 3-5 years. In order to address this, we conducted a large-scale study on transfer learning, specifically focusing on the use of different ImageNet backbones while keeping the same readout architecture and learning protocol from DeepGaze II.

By replacing the VGG19 backbone of DeepGaze II with ResNet50 features, we were able to enhance the performance of saliency prediction from 78% to 85%. Despite this improvement, further experiments with better ImageNet models, such as EfficientNetB5, did not yield any additional enhancements in saliency prediction.

Upon analyzing the backbones in more detail, we discovered that their generalization to other datasets varied significantly, with the models consistently displaying overconfidence in their fixation predictions. To address this issue, we propose a method of combining multiple backbones in a principled manner, which leads to improved confidence calibration on unseen datasets.

This new model, called "DeepGaze IIE," achieves a significant leap in benchmark performance both within and outside of its domain. It exhibits a 15 percent point improvement over DeepGaze II, achieving a state-of-the-art performance of 93% on the MIT1003 dataset. This marks a new milestone on the MIT/Tuebingen Saliency Benchmark, surpassing previous records in all available metrics (AUC: 88.3%, sAUC: 79.4%, CC: 82.4%).