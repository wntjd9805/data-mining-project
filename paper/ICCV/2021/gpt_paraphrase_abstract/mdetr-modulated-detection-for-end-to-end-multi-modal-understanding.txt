This study introduces MDETR, a novel modulated detector that detects objects in images based on raw text queries such as captions or questions. Unlike traditional object detectors, MDETR is trained end-to-end and incorporates a transformer-based architecture to jointly reason over text and image modalities. The network is pre-trained on a large dataset of text-image pairs with explicit alignment between phrases in the text and objects in the image. Fine-tuning on various downstream tasks like phrase grounding, referring expression comprehension, and segmentation leads to state-of-the-art results on popular benchmarks. The study also explores the usefulness of MDETR as an object detector in few-shot settings, particularly for handling object categories with limited labeled instances. Additionally, MDETR demonstrates competitive performance in visual question answering tasks, specifically on GQA and CLEVR datasets. The code and models associated with MDETR are publicly available on GitHub.