Deep neural networks have been shown to be vulnerable to adversarial examples. These examples often exist outside the natural image data manifold and the intrinsic dimension of image data is much smaller than its pixel space dimension. To address this, we propose a framework called the Embedding Regularized Classifier (ER-Classifier) that embeds high-dimensional input images into a low-dimensional space and applies regularization to push adversarial examples back to the manifold. This framework improves the classifier's adversarial robustness through embedding regularization. Additionally, it can be combined with detection methods to identify adversarial examples. Experimental results on benchmark datasets demonstrate that our proposed framework performs well against strong adversarial attack methods.