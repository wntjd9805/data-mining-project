Recent self-supervised learning (SSL) algorithms typically learn features by contrasting instances of images or by clustering images and then contrasting between the image clusters. In this study, we propose a simple mean-shift algorithm that learns representations by grouping images together without relying on contrastive methods or prior assumptions about cluster structure or number. Our approach involves shifting the embedding of each image to be closer to the mean of its augmented neighbors. Notably, our model is equivalent to BYOL when using only one nearest neighbor, compared to the five used in our experiments. When evaluated on ImageNet linearly with ResNet50 over 200 epochs, our model achieves an accuracy of 72.4%, surpassing BYOL. Furthermore, our method significantly outperforms the current state-of-the-art when using weak augmentations only, which promotes the adoption of SSL for other modalities. The code for our approach is available at https://github.com/UMBCvision/MSF.