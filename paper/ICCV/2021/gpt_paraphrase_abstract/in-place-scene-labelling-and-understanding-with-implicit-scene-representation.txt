Semantic labelling is closely related to geometry and radiance reconstruction, as objects with similar shape and appearance are likely to belong to the same category. Implicit neural reconstruction techniques have gained popularity because they don't require pre-existing training data. However, these techniques cannot be applied directly to semantic labelling because labels are defined by humans. To address this limitation, we propose an extension to neural radiance fields (NeRF) that incorporates semantics along with appearance and geometry. This allows us to achieve complete and accurate 2D semantic labels with minimal in-place annotations specific to the scene. The inherent multi-view consistency and smoothness of NeRF facilitate efficient propagation of sparse labels. We demonstrate the effectiveness of this approach in scenarios where labels are sparse or noisy, particularly in room-scale scenes. Furthermore, we illustrate the advantages of our approach in various applications such as an efficient scene labeling tool, novel semantic view synthesis, label denoising, super-resolution, label interpolation, and multi-view semantic label fusion in visual semantic mapping systems.