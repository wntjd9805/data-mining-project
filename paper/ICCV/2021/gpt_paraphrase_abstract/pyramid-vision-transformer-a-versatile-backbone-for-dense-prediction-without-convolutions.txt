This study explores a convolution-free backbone network called the Pyramid Vision Transformer (PVT) for dense prediction tasks in computer vision. Unlike the Vision Transformer (ViT) designed specifically for image classification, PVT overcomes the challenges of applying the Transformer architecture to dense prediction tasks. PVT offers several advantages over current state-of-the-art models. Firstly, it can be trained on dense image partitions to achieve high-resolution outputs, which is crucial for dense prediction. Additionally, PVT utilizes a progressive shrinking pyramid to reduce the computational requirements of large feature maps. Secondly, PVT combines the strengths of both Convolutional Neural Networks (CNNs) and Transformers, making it a versatile backbone for various vision tasks without convolutions. It can directly replace CNN backbones. Lastly, extensive experiments validate the effectiveness of PVT in boosting the performance of downstream tasks such as object detection, instance segmentation, and semantic segmentation. For instance, PVT+RetinaNet achieves 40.4 AP on the COCO dataset, surpassing ResNet50+RetinaNet by 4.1 absolute AP. The authors hope that PVT can serve as an alternative and valuable backbone for pixel-level predictions, contributing to future research in the field.