The popularity of 3D vision tasks has increased with the advancement of 3D scanning technologies. However, the large amount of data obtained from sensors requires unsupervised learning methods to understand and utilize point clouds without costly annotation processes. This paper introduces a new framework called "PSG-Net" and an auto-encoder architecture for reconstruction-based learning of point clouds. Unlike previous studies that used fixed or random 2D points, our framework generates input-dependent point-wise features for the latent point set. PSG-Net utilizes the encoded input to generate point-wise features through the seed generation module and progressively extracts richer features with increasing resolution using the seed feature propagation module. Experimentally, PSG-Net demonstrates superior performance in point cloud reconstruction and unsupervised classification, and achieves comparable results to supervised completion methods.