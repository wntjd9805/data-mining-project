Boundary Representations (B-Reps) are widely used in 3D Computer Aided Design/Manufacturing (CAD/CAM) and industrial design to accurately depict stylistic details. However, B-Reps have been overlooked in 3D style research. Existing 3D style metrics focus on meshes or point clouds, but do not consider the subjective nature of style. They either rely on fixed definitions of style obtained through crowd-sourcing or hand-crafted features. To address this gap, we propose UVStyle-Net, a style similarity measure for B-Reps. UVStyle-Net utilizes the style signals present in the second order statistics of activations from a pre-trained (unsupervised) 3D encoder and learns the relative importance of these signals to an end-user's subjective preference through few-shot learning.Our approach stands out from existing data-driven 3D style methods as it can be used in unsupervised settings, which is advantageous due to the limited availability of labeled B-Rep datasets. Additionally, the few-shot learning component accounts for the inherent subjectivity associated with style. Our quantitative analysis demonstrates that UVStyle-Net captures stronger style signals in B-Reps compared to alternative methods focused on meshes and point clouds, while also being significantly more computationally efficient. We further show that UVStyle-Net can generate meaningful style gradients based on the input shape, and that few-shot learning with just two positive examples chosen by an end-user significantly improves the style measure.To validate the efficacy of UVStyle-Net, we apply it to a large unlabeled public dataset of CAD models. The results demonstrate its effectiveness in measuring style in this dataset. The source code and data for UVStyle-Net are publicly available at github.com/AutodeskAILab/UVStyle-Net.