State-of-the-art few-shot learning methods experience a significant decrease in performance when faced with domain differences between the source and target datasets. Despite their strong discrimination ability on the source dataset, they do not necessarily achieve high classification accuracy on the target dataset. To address this issue, we enhance the model's generalization capability by teaching it to capture a wider range of variations in feature distributions using a novel noise-enhanced supervised autoencoder (NSAE). The NSAE trains the model by reconstructing inputs and predicting the labels of inputs and their reconstructed pairs simultaneously. Theoretical analysis based on intra-class correlation (ICC) reveals that the feature embeddings learned from NSAE exhibit stronger discrimination and generalization abilities in the target domain. Additionally, we leverage the NSAE structure to propose a two-step fine-tuning procedure that enhances adaptation and improves classification performance in the target domain. We conduct extensive experiments and ablation studies to demonstrate the effectiveness of our proposed method. The experimental results consistently demonstrate that our method outperforms state-of-the-art methods under various conditions.