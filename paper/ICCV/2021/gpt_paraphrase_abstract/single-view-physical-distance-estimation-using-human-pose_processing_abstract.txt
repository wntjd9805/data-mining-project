We present a fully automated system that can estimate camera intrinsics, ground plane, and physical distances between people using a single RGB image or video captured from a fixed viewpoint. By incorporating prior knowledge of human pose, we have developed a unique approach for pose-based auto-calibration and distance estimation, which achieves state-of-the-art performance on existing datasets. This system eliminates the need for a dedicated calibration process or range sensors, making it suitable for various applications such as social distancing and workplace safety. Additionally, we contribute to the MEVA dataset by providing distance annotations, creating a benchmark called "MEVADA" for evaluating pose-based auto-calibration and distance estimation methods.