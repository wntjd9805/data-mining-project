We introduce a technique to enhance the resilience of neural network predictions against changes in the distribution of training data. Our approach involves utilizing a diverse set of cues, referred to as 'middle domains', and combining them to form a strong prediction. The underlying concept is that predictions made using different cues exhibit varying responses to distribution shifts, making it possible to merge them into a reliable final prediction. We merge these predictions in a simple but systematic manner based on the uncertainty associated with each prediction. We evaluate our method on various tasks and datasets, including Taskonomy, Replica, ImageNet, and CIFAR, considering both adversarial and non-adversarial distribution shifts. The results demonstrate that our proposed method outperforms standard learning approaches, conventional deep ensembles, and several other benchmarks in terms of robustness.