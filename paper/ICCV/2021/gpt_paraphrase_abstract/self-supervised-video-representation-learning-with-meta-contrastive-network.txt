Self-supervised learning has been successfully used for pre-training video representations, but existing methods that rely on contrastive loss suffer from a lack of category information, leading to difficulties in generalization. To address this, we propose a Meta-Contrastive Network (MCN) that combines contrastive learning with meta learning. Our approach involves two stages of training using model-agnostic meta learning (MAML), each comprising a contrastive branch and a meta branch. Extensive evaluations on UCF101 and HMDB51 datasets demonstrate that MCN outperforms state-of-the-art methods in video action recognition and video retrieval tasks. Specifically, when using an R(2+1)D backbone, MCN achieves Top-1 accuracies of 84.8% and 54.5% for video action recognition, and 52.5% and 23.7% for video retrieval.