This paper introduces a method for enabling user editing of a category-level neural radiance field (NeRF), which is a scene model used for high-quality view synthesis. The proposed method allows users to modify the color or shape of a specific region in a 3D space by propagating coarse 2D user scribbles. The authors propose a conditional radiance field that incorporates new modular network components, including a shared shape branch for object instances. By observing multiple instances of the same category, the model learns underlying part semantics without supervision, enabling the propagation of user scribbles to the entire 3D region. The authors also propose a hybrid network update strategy that balances efficiency and accuracy by targeting specific network components. During user interaction, an optimization problem is formulated to satisfy the user's constraints while preserving the original object structure. The proposed editing approach is demonstrated on rendered views of three shape datasets and is shown to outperform previous neural editing approaches. Furthermore, the appearance and shape of a single-view real photograph are edited, and the edit is shown to propagate to extrapolated novel views.