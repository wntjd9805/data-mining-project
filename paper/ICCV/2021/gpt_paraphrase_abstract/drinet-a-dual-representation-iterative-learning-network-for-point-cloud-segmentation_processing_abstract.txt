We introduce a new and flexible architecture called DRINet for segmenting point clouds using dual-representation iterative learning. Point cloud processing involves different representations, each with its own advantages and disadvantages. Therefore, it is important to find suitable ways to represent point cloud data structure while preserving its internal physical properties, such as permutation and scale-invariance. Our proposed DRINet serves as the foundation for dual-representation learning, offering great flexibility in feature transferring and reduced computational cost, particularly for large-scale point clouds. DRINet comprises two modules: Sparse Point-Voxel Feature Extraction and Sparse Voxel-Point Feature Extraction. These modules allow iterative propagation of features between the two representations. Additionally, we introduce a novel multi-scale pooling layer to enhance the propagation of contextual information for pointwise locality learning. Our network achieves state-of-the-art results in point cloud classification and segmentation tasks across multiple datasets, while maintaining high runtime efficiency. In large-scale outdoor scenarios, our method outperforms existing approaches with a real-time inference time of 62ms per frame.