This paper proposes a new approach to self-supervised video representation learning that focuses on both high-level semantics and lower-level representations. Previous works have overlooked the importance of lower-level representations and their temporal relationship in video understanding. To address this, the authors introduce a multi-level feature optimization framework that enhances the generalization and temporal modeling ability of learned video representations. The framework utilizes high-level features obtained from contrastive learning to guide the learning process of low-level and mid-level features. Additionally, a temporal modeling module is developed to improve motion pattern learning. Experimental results demonstrate that the proposed multi-level feature optimization approach, incorporating graph constraints and temporal modeling, significantly enhances the representation ability in video understanding. The authors provide the code for their approach.