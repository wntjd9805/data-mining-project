This paper presents a self-supervised learning framework for event-based motion deblurring. The framework utilizes real-world events to address the issue of data inconsistency and improve performance. The approach involves predicting optical flows from events and using blurry consistency and photometric consistency to enable self-supervision for the deblurring network. Additionally, a piece-wise linear motion model is proposed to accurately capture the non-linearities of motion blurs in real-world scenarios. The algorithm is evaluated on both synthetic and real motion blur datasets and demonstrates significant improvements in bridging the gap between simulated and real-world motion blurs, achieving remarkable performance in event-based motion deblurring for real-world scenarios.