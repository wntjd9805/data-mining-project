We propose novel techniques to improve self-supervised monocular depth estimation by incorporating semantic information. Existing methods lack supervision in weak texture regions and object boundaries. To address this, we introduce a metric learning approach that uses semantics to optimize depth representations and a feature fusion module that leverages cross-modality between two different feature representations. We evaluate our methods on the KITTI dataset and show that they outperform current state-of-the-art approaches. The source code can be found at https://github.com/hyBlue/FSRE-Depth.