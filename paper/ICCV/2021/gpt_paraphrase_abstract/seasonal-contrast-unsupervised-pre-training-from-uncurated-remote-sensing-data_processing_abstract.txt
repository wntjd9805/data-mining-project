Remote sensing and automatic earth monitoring play a crucial role in addressing global challenges like disaster prevention, land use monitoring, and climate change mitigation. Despite the availability of large volumes of remote sensing data, most of it lacks labels, making it inaccessible for supervised learning algorithms. Transfer learning methods can reduce the data requirements for deep learning algorithms. However, these methods are typically pre-trained on ImageNet and may not generalize well to remote sensing imagery due to domain differences. In this study, we propose a pipeline called Seasonal Contrast (SeCo) to effectively utilize unlabeled data for in-domain pre-training of remote sensing representations. The SeCo pipeline consists of two main components. First, a systematic procedure is developed to collect large-scale, unlabeled, and uncurated remote sensing datasets that include images from various locations on Earth at different time points. Second, a self-supervised algorithm is employed, leveraging time and position invariance to learn transferable representations for remote sensing applications. Through empirical analysis, we demonstrate that models trained with SeCo outperform their ImageNet pre-trained counterparts and state-of-the-art self-supervised learning methods in multiple downstream tasks. To facilitate transfer learning and accelerate progress in remote sensing applications, we will make the datasets and models used in SeCo publicly available.