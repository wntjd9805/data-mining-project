The objective of 3D object grounding is to locate the most relevant target object in a point cloud scene using a language description. This is a challenging task due to the irregular and sparse nature of point clouds. There are three main challenges in 3D object grounding: identifying the main focus in complex descriptions, understanding the point cloud scene, and locating the target object. In this paper, we propose solutions for all three challenges. Firstly, we introduce a language scene graph module to capture the structure and correlations in the description. Secondly, we use a multi-level 3D proposal relation graph module to extract relationships between objects and between objects and the scene, enhancing the visual features of initial proposals. Lastly, we develop a description guided 3D visual graph module to encode global contexts of phrases and proposals using a nodes matching strategy. Our experiments on benchmark datasets (ScanRefer and Nr3D) demonstrate that our algorithm outperforms existing state-of-the-art methods. Our code is available at https://github.com/PNXD/FFL-3DOG.