We present a new approach to video inpainting using internal learning. Instead of relying on optical flow for context propagation, we demonstrate that this can be achieved implicitly by training a convolutional neural network on known regions. To address difficulties such as ambiguous backgrounds and long-term occlusion, we introduce two regularization terms to preserve details and temporal consistency. Our method achieves state-of-the-art results on the DAVIS dataset, both quantitatively and qualitatively. Additionally, we extend our approach to the task of removing an object from a 4K video using a single object mask. The source code for our method can be found at https://tengfei-wang.github.io/Implicit-Internal-Video-Inpainting/.