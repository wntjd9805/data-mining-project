This paper introduces a new graph-based framework called SlideGCN for event cameras, which capture asynchronous event streams containing pixel location, trigger time, and polarity of brightness changes. Unlike other graph-based methods, SlideGCN can efficiently process data event-by-event, maintaining the graph's structure internally while achieving low latency. To construct the graph quickly, a radius search algorithm is developed, leveraging the partial regular structure of event cloud. Experimental results demonstrate that our approach reduces computational complexity significantly compared to current graph-based methods while achieving state-of-the-art object recognition performance. Furthermore, the superiority of event-wise processing is verified, as our method allows for early recognition with high confidence when the state becomes stable.