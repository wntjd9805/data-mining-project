This paper presents an innovative approach to self-supervised visual representation learning that simultaneously learns from both images and videos. The proposed method, called Vi2CLR, utilizes unlabeled videos to extract visual cues and learn similarities and dissimilarities between instances. The Vi2CLR optimization pipeline consists of visual clustering and representation learning, wherein positive instances within a cluster and negative instances from other clusters are used to train Convolutional Neural Networks for visual recognition tasks in both the image and video domains. By combining 2D and 3D CovNet encoders, the joint self-supervised learning approach achieves robust performance comparable to supervised learning. Extensive evaluations on various datasets demonstrate the effectiveness of Vi2CLR in tasks such as action recognition, image classification, and object classification, surpassing other state-of-the-art self-supervised methods.