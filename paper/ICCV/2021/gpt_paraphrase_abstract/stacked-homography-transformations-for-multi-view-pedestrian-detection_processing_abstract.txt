This paper introduces the Stacked HOmography Transformations (SHOT) approach for multi-view pedestrian detection. The goal is to predict a bird's eye view (BEV) occupancy map using information from multiple camera views. The approach addresses the challenges of establishing 3D correspondences and assembling occupancy information across views. SHOT approximates projections in 3D world coordinates by constructing a stack of transformations for projecting views to the ground plane at different height levels. A soft selection module is designed to enable the network to learn the likelihood of the stack of transformations. The paper also provides a theoretical analysis of constructing SHOT and its approximation of projections in 3D world coordinates. Empirical verification shows that SHOT is capable of accurately estimating correspondences from individual views to the BEV map, resulting in improved performance compared to existing methods on standard evaluation benchmarks.