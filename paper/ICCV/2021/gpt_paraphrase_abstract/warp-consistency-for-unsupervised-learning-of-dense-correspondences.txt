Paraphrased:The main difficulty in learning dense correspondences is the lack of known matches for real image pairs. Although photometric consistency losses offer unsupervised alternatives, they struggle with significant changes in appearance, which are common in geometric and semantic matching tasks. Additionally, methods that rely on synthetic training pairs often do not perform well on real data. To address these challenges, we propose an unsupervised learning objective called Warp Consistency for dense correspondence regression. Our objective is effective even when there are large changes in appearance and viewpoint. We achieve this by constructing an image triplet from a pair of real images and applying a randomly sampled warp to one of the original images. We derive and analyze flow-consistency constraints that arise between the triplet. Based on our observations and empirical results, we design a general unsupervised objective that incorporates two of the derived constraints. We validate our warp consistency loss by training three recent dense correspondence networks for both geometric and semantic matching tasks. Our approach achieves state-of-the-art performance on several challenging benchmarks, including MegaDepth, RobotCar, and TSS. The code and models for our method are available on GitHub at github.com/PruneTruong/DenseMatching.