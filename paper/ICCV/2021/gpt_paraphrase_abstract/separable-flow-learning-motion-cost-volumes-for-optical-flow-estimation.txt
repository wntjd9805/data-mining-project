Current optical flow methods rely heavily on full-motion cost volumes, which are constructed using simple feature correlations. However, these cost volumes are limited in their ability to incorporate prior knowledge or non-local information. As a result, they produce artifacts in regions with poor constraints, such as occluded or textureless areas. To address this issue, we propose a separable cost volume module that replaces correlation cost volumes. This module utilizes non-local aggregation layers to leverage global context cues and prior knowledge, thereby improving the disambiguation of motions in these problematic regions. Our approach outperforms existing methods on widely used optical flow benchmarks, including Sintel and KITTI, in terms of accuracy. Additionally, our method demonstrates better generalization from synthetic to real data.