The progress in 3D semantic segmentation heavily relies on deep network models, which require large amounts of labeled data for training. However, labeling 3D point clouds is costly and challenging. To overcome this, we propose a method for semi-supervised point cloud semantic segmentation that incorporates unlabeled data into the training process to enhance model performance. We introduce the guided point contrastive loss, inspired by self-supervised tasks, which improves feature representation and model generalization in the semi-supervised setting. By using semantic predictions on unlabeled point clouds as pseudo-label guidance in our loss function, we ensure that negative pairs in the same category are avoided. Additionally, we employ confidence guidance to ensure high-quality feature learning. To address class imbalance, we propose a category-balanced sampling strategy for selecting positive and negative samples. Our experiments on three datasets (ScanNet V2, S3DIS, and SemanticKITTI) demonstrate the effectiveness of our semi-supervised approach in improving prediction quality using unlabeled data.