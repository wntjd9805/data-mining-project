This research paper addresses the problem of reconstructing hyperspectral (HS) images from single RGB images taken by commercial cameras, without the need for paired HS and RGB images during training. To overcome this challenge, a new lightweight and end-to-end learning-based framework is proposed. The framework utilizes an intrinsic imaging degradation model to progressively minimize the differences between input RGB images and re-projected RGB images from recovered HS images. This is achieved through unsupervised camera spectral response function estimation. Adversarial learning is employed to enable learning without paired ground-truth HS images, along with an effective L1 gradient clipping scheme. Additionally, semantic information from input RGB images is incorporated to locally regulate the unsupervised learning process, enhancing consistency in spectral signatures for pixels with similar semantics. The proposed method is evaluated using quantitative experiments on two widely-used datasets for HS image reconstruction from synthetic RGB images. Furthermore, the method is applied to HS-based visual tracking using recovered HS images from real RGB images. Extensive results demonstrate that the proposed method surpasses state-of-the-art unsupervised methods and even outperforms the latest supervised method in certain scenarios. The source code for the method is publicly available at https://github.com/zbzhzhy/Unsupervised-Spectral-Reconstruction.