In recent years, there have been advancements in contrastive learning methods that aim to simultaneously learn representations and clustering assignments. However, these methods overlook the importance of category information and clustering objectives, resulting in suboptimal representations for clustering tasks and limited performance. To address this issue, we propose a new framework called Graph Contrastive Clustering (GCC). Unlike basic contrastive clustering methods that focus on similarity between an image and its augmentation, GCC introduces cluster-level consistency by assuming that samples within a cluster and their augmentations should all be similar. We introduce a graph Laplacian based contrastive loss to learn more discriminative and clustering-friendly features, and a novel graph-based contrastive learning strategy to achieve more compact clustering assignments. Both of these strategies incorporate latent category information to reduce intra-cluster variance and increase inter-cluster variance. Our experiments on six commonly used datasets demonstrate the superiority of GCC over existing state-of-the-art methods.