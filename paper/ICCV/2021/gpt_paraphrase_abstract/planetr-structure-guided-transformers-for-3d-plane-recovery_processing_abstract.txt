This paper introduces PlaneTR, a neural network based on Trans-formers, for the simultaneous detection and reconstruction of planes from a single image. Unlike previous methods, PlaneTR combines contextual information and geometric structures to detect plane instances in a holistic manner. The network consists of three main components: context and line segment encoders, a structure-guided plane decoder, and a pixel-wise plane embedding decoder. By utilizing these components, PlaneTR predicts a sequence of plane instances by considering both the context and global structure cues. Additionally, pixel-wise embeddings are computed to assign each pixel to the nearest predicted plane instance in embedding space. Extensive experiments on the ScanNet and NYUv2 datasets demonstrate that PlaneTR achieves state-of-the-art performance.