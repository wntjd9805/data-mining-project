Recent advancements in multi-view stereo (MVS) methods based on machine learning have shown impressive results when applied to scenarios with many cameras and small depth ranges. However, traditional non-learning based approaches still outperform these methods when dealing with scenes that have large depth ranges and fewer wide-baseline views. This is mainly due to the PatchMatch optimization technique used in these traditional methods, which produces better results than the pixelwise estimates of depth, normals, and visibility used in learning-based approaches.

In this paper, we propose a novel MVS approach that combines the benefits of trainable costs and regularizations with pixelwise estimates, using the PatchMatch optimization technique. To address the challenge of the non-differentiable nature of PatchMatch that involves iterative sampling and hard decisions, we employ reinforcement learning. This allows us to minimize the expected photometric cost and maximize the likelihood of obtaining accurate ground truth depth and normals.

In addition, we introduce a method for estimating normals by utilizing dilated patch kernels, and we present a recurrent cost regularization technique that extends beyond frontal plane-sweep algorithms to improve the accuracy of our pixelwise depth and normal estimates.

We evaluate our proposed method on two widely used MVS benchmarks, ETH3D and Tanks and Temples (TnT). The results demonstrate that our approach outperforms other recent learning-based methods on ETH3D, and performs comparably to advanced techniques on the TnT benchmark.