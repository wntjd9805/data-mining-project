This paper presents a method to improve the rendering speed of NeRF, a technique that generates high-quality novel views of a scene by fitting a neural radiance field to RGB images. Although NeRF produces impressive results, it is computationally expensive due to the need to query a deep Multi-Layer Perceptron (MLP) millions of times. To address this issue, the authors propose using thousands of small MLPs instead of a single large MLP, allowing for faster rendering times. Each individual MLP only needs to represent a portion of the scene, enabling the use of smaller and more efficient MLPs. By combining this divide-and-conquer approach with additional optimizations, the rendering process is accelerated by three orders of magnitude compared to the original NeRF model, without incurring significant storage costs. The authors also demonstrate that the proposed method maintains visual quality by employing teacher-student distillation for training. Overall, this approach offers real-time rendering capabilities while preserving the core features of NeRF.