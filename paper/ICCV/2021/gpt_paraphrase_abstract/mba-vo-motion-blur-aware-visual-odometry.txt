This paper introduces a new approach to address the challenge of motion blur in visual odometry methods. It focuses specifically on low-light conditions where longer exposure times are necessary, resulting in motion blur even for slow camera movements. The proposed method is a hybrid visual odometry pipeline that incorporates a direct approach to model and estimate the camera's local trajectory during the exposure time. By actively compensating for motion blur caused by camera motion, this approach improves the robustness of visual odometry. The paper also presents a benchmarking dataset for evaluating motion blur aware visual odometry algorithms. Experimental results demonstrate that by directly modeling the image formation process, the proposed method achieves improved robustness while maintaining comparable accuracy to images without motion blur. The code and datasets related to this work can be accessed at https://github.com/ethliup/MBA-VO.