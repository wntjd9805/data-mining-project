Monocular 3D object detection in autonomous driving is a challenging task as it requires predicting object distances without explicit depth information. Existing methods typically regress distance as a single variable, but we propose a novel approach that decomposes distance into its factors. We decompose distance into the physical height and the projected visual height in the image plane, which are representative and stable variables. Our decomposition maintains self-consistency between the two heights, ensuring robust distance prediction even when both heights are inaccurate. This decomposition also allows us to understand the causes of distance uncertainty in different scenarios, making distance prediction interpretable, accurate, and robust.

Our method directly predicts 3D bounding boxes from RGB images using a compact architecture, making training and inference simple and efficient. Experimental results on the KITTI dataset demonstrate that our method achieves state-of-the-art performance in monocular 3D object detection and Bird's Eye View tasks. Furthermore, our method can generalize to images with different camera intrinsics.