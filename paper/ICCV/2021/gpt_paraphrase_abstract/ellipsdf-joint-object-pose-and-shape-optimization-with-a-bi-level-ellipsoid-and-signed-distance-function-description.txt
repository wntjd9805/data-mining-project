This paper presents a model and algorithm for optimizing the pose and shape of objects in autonomous systems. The goal is to create a map of objects based on observations from multi-view RGB-D cameras. The proposed model captures various attributes of objects, such as their identities, positions, orientations, and shapes. It also utilizes a low-dimensional latent representation of implicit object shape, allowing for efficient storage of large object maps. Unlike other approaches, this model considers both coarse-scale and fine-scale details of object shape. The effectiveness of the proposed approach is demonstrated through evaluation on the ScanNet dataset, comparing it to state-of-the-art methods.