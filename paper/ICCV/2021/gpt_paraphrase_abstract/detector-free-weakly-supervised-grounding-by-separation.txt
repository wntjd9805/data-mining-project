Currently, there is an abundance of data consisting of images and accompanying free-form text that loosely relates to these images. Weakly Supervised phrase-Grounding (WSG) is a method used to learn how to localize specific text phrases within images without any additional annotations. However, most recent state-of-the-art (SotA) techniques for WSG assume the presence of a pre-trained object detector to assist with localization. In this study, we focus on a Detector-Free WSG (DF-WSG) approach that does not rely on a pre-trained detector. Our proposed method, Grounding by Separation (GbS), involves creating associations between 'text to image-regions' by blending random pairs of images together and using the corresponding text as conditions to recover the alpha map (indicating the importance of each region) through a segmentation network. During testing, this enables the use of a query phrase as a condition for a non-blended query image, allowing for the interpretation of the test image as a combination of a region corresponding to the phrase and the complementary region. Our GbS method achieves an accuracy improvement of 8.5% compared to the previous DF-WSG SotA on various benchmarks, including Flickr30K, Visual Genome, and ReferIt. Furthermore, it also outperforms detector-based approaches for WSG by more than 7%.