Current techniques for manipulating faces have made significant progress in terms of quality and control. However, these techniques struggle to generate face videos that are temporally coherent. In this study, we focus on utilizing temporal coherence to detect forged face videos. We propose a new framework consisting of two main stages. The first stage is a fully temporal convolution network (FTCN) that reduces the spatial convolution kernel size to 1 while keeping the temporal convolution kernel size unchanged. Surprisingly, this design improves the model's ability to extract temporal features and enhances its generalization capability. The second stage is a Temporal Transformer network that explores long-term temporal coherence. Our framework is versatile and can be trained from scratch without any pre-training models or external datasets. Extensive experiments demonstrate that our framework outperforms existing methods and remains effective in detecting new types of face forgery videos.