This paper introduces a novel tracking architecture that utilizes an encoder-decoder transformer as its main component. The encoder captures the global spatio-temporal relationships between target objects and search regions, while the decoder learns to predict the spatial positions of the target objects. Unlike existing methods, our approach treats object tracking as a direct bounding box prediction task, eliminating the need for proposals or predefined anchors. By employing the encoder-decoder transformer, the object prediction process is simplified using a fully-convolutional network that directly estimates the object corners. Our method is end-to-end and does not require any additional post-processing steps, such as cosine window and bounding box smoothing, thereby streamlining existing tracking pipelines. The proposed tracker achieves state-of-the-art performance on various challenging short-term and long-term benchmarks, while operating in real-time and being 6 times faster than Siam R-CNN. The code and models for our tracker are publicly available at https://github.com/researchmm/Stark.