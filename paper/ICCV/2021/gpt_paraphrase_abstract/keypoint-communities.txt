We introduce a rapid approach for simultaneously detecting over 100 keypoints on humans or objects, known as human/object pose estimation. To accomplish this, we represent the keypoints of a human or object as a graph, or pose, and employ principles from community detection to measure the independence of these keypoints. Through graph centrality, we assign training weights to different parts of a pose, measuring how strongly a keypoint is connected to its surrounding area. Our experiments demonstrate that our method surpasses previous techniques for human pose estimation, specifically for fine-grained keypoint annotations on the face, hands, and feet, encompassing a total of 133 keypoints. Additionally, we validate the effectiveness of our method on car poses.