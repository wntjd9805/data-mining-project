This abstract discusses the limitations of current learned video codecs and proposes novel ideas to improve their efficiency for low-latency mode. The proposed approach outperforms mainstream video standards and other ML codecs in terms of quality metrics such as PSNR, MS-SSIM, and VMAF. Additionally, it runs significantly faster and has fewer parameters than existing ML codecs. The contributions include a flexible-rate framework, an optimized backbone, and a new prediction scheme for more efficient compression. The proposed method, called ELF-VC, is benchmarked on popular video test sets and shows substantial improvements in BD-rate compared to H.264, H.265, AV1, and the best ML codec. The encoding/decoding performance on an NVIDIA Titan V GPU is also provided.