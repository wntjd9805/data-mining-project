Retrieving occlusion relationship among objects in an image is difficult due to the scarcity of boundaries. Existing works face two main challenges: the lack of an architecture that can effectively utilize the limited coupling between occlusion boundary extraction and occlusion orientation prediction, and the improper representation of occlusion. To address these issues, this paper proposes a new architecture called Occlusion-shared and Path-separated Network (OPNet). OPNet leverages rich occlusion cues in shared high-level features and utilizes structured spatial information in task-specific low-level features to overcome the first challenge. Additionally, a simple yet effective orthogonal occlusion representation (OOR) is designed to tackle the second challenge. Experimental results demonstrate that our method outperforms state-of-the-art approaches, achieving improvements of 6.1%/8.3% in Boundary-AP and 6.5%/10% in Orientation-AP on the standard PIOD/BSDS ownership datasets. The code for our method is available at https://github.com/fengpanhe/MT-ORL.