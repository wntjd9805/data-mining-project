Deep neural networks are highly susceptible to adversarial examples in white-box scenarios. Adversarial examples crafted on one model often have black-box transferability to other models with different architectures. Input transformation is a popular method to enhance adversarial transferability. However, existing transformations are applied on a single image, limiting their effectiveness. In this study, we propose a new attack method called Admix that considers the input image and a set of randomly sampled images from different categories. Instead of calculating the gradient on the original input, Admix calculates the gradient on the input image mixed with a small portion of each additional image. This approach generates more transferable adversaries while maintaining the original label of the input. Experimental results on the ImageNet dataset demonstrate that Admix achieves significantly better transferability than existing input transformation methods in both single model and ensemble model settings. When combined with existing input transformations, our method further improves transferability and outperforms the current state-of-the-art combination of input transformations when attacking nine advanced defense models in an ensemble model setting. The code for Admix is available at https://github.com/JHL-HUST/Admix.