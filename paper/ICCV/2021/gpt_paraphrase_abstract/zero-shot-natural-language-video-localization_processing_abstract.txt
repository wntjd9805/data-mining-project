We aim to develop a natural language video localization model without the need for expensive annotated video regions and language queries. Instead, we propose a zero-shot approach using random text corpora, unlabeled video collections, and an off-the-shelf object detector. To generate pseudo-supervision, we pair candidate temporal regions with corresponding query sentences. We then train a simple NLVL model using this pseudo-supervision. Our experiments demonstrate that this approach outperforms baseline methods and even methods with stronger supervision on Charades-STA and ActivityNet-Captions datasets.