The abstract discusses the importance of human pose estimation from videos and highlights the limitations of existing methods. These methods focus on using models on fully decoded frames, ignoring the motion signals and motion-compensation residuals available in the compressed stream. To address this, a new model called Motion Adaptive Pose Net is proposed. This model utilizes the compressed streams to efficiently decode pose sequences from videos. It incorporates a Motion Compensated ConvLSTM to propagate spatially aligned features and an adaptive gate to determine if computationally expensive features should be extracted from fully decoded frames based on residual errors. By leveraging the informative signals from compressed streams, the Motion Adaptive Pose Net efficiently propagates latent features. The model outperforms state-of-the-art models in pose estimation accuracy on two commonly used datasets while reducing computation complexity by approximately half.