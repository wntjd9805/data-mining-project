We propose a novel framework for training Generative Adversarial Networks (GANs) that allows for explicit control over the generated facial images. Unlike previous approaches that achieve partial control through latent space disentanglement, we leverage contrastive learning to obtain GANs with an explicitly disentangled latent space. This enables us to train control-encoders that map human-interpretable inputs to suitable latent vectors, thus providing explicit control over attributes such as age, pose, expression, hair color, and illumination. Our approach is not limited to human faces and can be extended to other domains like painted portraits and dog image generation. We demonstrate the effectiveness of our framework by achieving state-of-the-art performance both qualitatively and quantitatively.