DeepFake forgery detection is a difficult task because current algorithms are trained to detect specific methods of fakes, leading to poor generalization across different types of facial manipulations. In order to address this challenge, we propose a new approach called ID-Reveal. This approach focuses on learning temporal facial features that are specific to how a person's face moves while talking. We achieve this by utilizing metric learning combined with an adversarial training strategy. One of the advantages of our approach is that it does not require any training data of fakes, but instead only trains on real videos. Additionally, we incorporate high-level semantic features, which enhances the robustness of our approach against various forms of post-processing that may disrupt the detection process. We conduct a comprehensive experimental analysis using multiple publicly available benchmarks. Our method outperforms the state-of-the-art algorithms in terms of generalization and robustness, especially when dealing with low-quality videos commonly found on social networks. In particular, we achieve an average improvement of over 15% in accuracy for facial reenactment on highly compressed videos.