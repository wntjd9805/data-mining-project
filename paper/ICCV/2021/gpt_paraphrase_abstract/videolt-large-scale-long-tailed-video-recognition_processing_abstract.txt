Label imbalances are a common issue in real-world datasets, leading to biased models that favor dominant labels. While long-tailed recognition has been extensively studied in image classification tasks, there has been limited effort in the video domain. To address this gap, we present VideoLT, a large-scale dataset for long-tailed video recognition. This dataset consists of 256,218 untrimmed videos annotated into 1,004 classes with a long-tailed distribution. Our research shows that current state-of-the-art methods for long-tailed image recognition do not perform well in the video domain due to the additional temporal dimension. To overcome this challenge, we propose a simple yet effective method called FrameStack. FrameStack performs sampling at the frame-level to balance class distributions, and the sampling ratio is dynamically determined using knowledge derived from the network during training. Experimental results demonstrate that FrameStack improves classification performance without compromising overall accuracy. The code and dataset for VideoLT are publicly available at https://github.com/17Skye17/VideoLT.