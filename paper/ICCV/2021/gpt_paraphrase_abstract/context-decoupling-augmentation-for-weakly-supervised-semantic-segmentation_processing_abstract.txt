Data augmentation is crucial for enhancing the performance of deep learning neural networks by providing a large number of training samples. While weakly supervised semantic segmentation (WSSS) has been extensively studied, traditional data augmentation techniques for WSSS mainly focus on geometric transformations, random cropping, and color adjustments. However, simply increasing the contextual semantic data does not significantly improve the network's ability to differentiate between objects. For example, correctly classifying an image as "aeroplane" may not solely depend on recognizing the object itself but also considering its co-occurring context, such as the "sky." This dependence on contextual information may divert the model's attention away from object features. 

To address this issue, we propose a method called Context Decoupling Augmentation (CDA), which alters the inherent context surrounding objects. By doing so, we encourage the network to disregard the reliance on contextual information when identifying object instances. Extensive experiments conducted on the PASCAL VOC 2012 and COCO datasets, using various network architectures, validate the effectiveness of CDA. The results demonstrate that CDA significantly improves the performance of popular WSSS methods, surpassing the current state-of-the-art. The code for CDA is available at https://github.com/suyukun666/CDA.