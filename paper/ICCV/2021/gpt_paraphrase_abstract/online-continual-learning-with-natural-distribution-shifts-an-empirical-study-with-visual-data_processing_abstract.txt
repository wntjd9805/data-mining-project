Continual learning involves acquiring and maintaining knowledge over time, across multiple tasks and environments. Previous research has mainly focused on incremental classification, where new tasks are added at specific time intervals. However, this "offline" approach does not accurately evaluate an agent's ability to learn effectively and efficiently, as it allows for unlimited learning epochs when a new task is added. To address this, we propose an "online" continual learning approach, where data is presented as a continuous stream without task boundaries. This allows for evaluating both information retention and online learning effectiveness. In this online approach, each small batch of incoming data is first tested and then added to the training set, making the learning process truly online. Trained models are later evaluated on historical data to assess information retention. We introduce a new benchmark for online continual visual learning that incorporates large-scale and natural distribution shifts. Through extensive analysis, we discover important and previously overlooked phenomena related to gradient-based optimization in continual learning. We also propose effective strategies for enhancing gradient-based online continual learning using real data. The source code and dataset for our work can be found at: https://github.com/IntelLabs/continuallearning.