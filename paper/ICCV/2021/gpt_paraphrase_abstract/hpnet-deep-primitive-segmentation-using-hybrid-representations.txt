This research presents HPNet, an innovative deep-learning method for segmenting a point cloud representation of a 3D shape into primitive patches. The key factor in achieving accurate primitive segmentation lies in learning a feature representation that can effectively differentiate between points belonging to different primitives. Unlike previous approaches that rely on a single feature representation, HPNet utilizes hybrid representations that combine a learned semantic descriptor, two spectral descriptors derived from predicted geometric parameters, and an adjacency matrix that encodes sharp edges. Rather than simply concatenating these descriptors, HPNet optimally combines them by learning combination weights using an entropy-based weighting module. The final primitive segmentation is obtained through a mean-shift clustering module. Experimental evaluations on the ANSI and ABCParts benchmark datasets demonstrate that HPNet outperforms baseline approaches, resulting in significant improvements in performance.