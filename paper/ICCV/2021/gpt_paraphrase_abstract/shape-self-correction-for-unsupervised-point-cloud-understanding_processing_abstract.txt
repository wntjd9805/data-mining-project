We present a new method called Shape Self-Correction for analyzing point clouds using self-supervised learning. Our approach is based on the idea that an effective shape representation should be able to identify and correct distorted parts of a shape. In order to learn robust shape representations without labeled data, we introduce a shape-disorganizing module that selectively destroys local shape parts of an object. The destroyed shape and the original shape are then processed through a point cloud network to obtain representations, which are used to segment the points belonging to distorted parts and reconstruct them to restore the shape to its normal state. To improve performance in these two related tasks, the network is trained to capture informative shape features from the object, indicating that the point cloud network can encode valuable geometric and contextual information. The learned feature extractor demonstrates good transferability to downstream classification and segmentation tasks. Our experiments on ModelNet, ScanNet, and ShapeNet-Part datasets demonstrate that our method achieves state-of-the-art performance compared to other unsupervised methods. Furthermore, we show that pre-training with our framework significantly enhances the performance of supervised models. Our framework is versatile and can be applied to various deep learning networks for point cloud analysis.