We present a new approach for generating high-quality, fine-grained images using a Single-Stage Controllable GAN (SSC-GAN). Previous models have used hierarchical structures and multiple stages, but our approach simplifies the model design and training process. We address the lack of supervision in object categories by incorporating three factors of variation in generative modeling: class-independent content, cross-class attributes, and class semantics. To ensure that these factors are disentangled, we maximize the mutual information between the class-independent variable and synthesized images, perform consistency regularization of cross-class attributes by mapping real data to the latent space of a generator, and incorporate class semantic-based regularization into a discriminator's feature space. Our experiments demonstrate that SSC-GAN produces high-fidelity images of fine-grained categories in a single stage. It achieves state-of-the-art results in semi-supervised image synthesis across multiple fine-grained datasets.