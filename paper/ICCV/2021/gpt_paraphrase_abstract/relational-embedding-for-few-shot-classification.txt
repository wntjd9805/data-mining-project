We propose a solution to the problem of few-shot classification by using a meta-learning approach that focuses on "what to observe" and "where to attend" from a relational perspective. Our method utilizes self-correlational representation (SCR) and cross-correlational attention (CCA) to leverage relational patterns within and between images. The SCR module transforms a base feature map into a self-correlation tensor, allowing for the extraction of structural patterns. The CCA module computes cross-correlation between two image representations and learns to establish co-attention between them. These two relational modules are combined in our Relational Embedding Network (RENet), which learns relational embedding in an end-to-end manner. Through experimental evaluation, RENet consistently outperforms state-of-the-art methods on four widely used few-shot classification benchmarks: miniImageNet, tieredImageNet, CUB-200-2011, and CIFAR-FS.