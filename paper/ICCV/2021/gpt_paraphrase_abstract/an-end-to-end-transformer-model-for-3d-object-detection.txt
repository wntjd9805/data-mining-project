We propose 3DETR, a novel object detection model for 3D point clouds that is based on the Transformer architecture. Unlike existing methods that heavily rely on 3D-specific biases, 3DETR requires minimal modifications to the vanilla Transformer block. Surprisingly, we find that a standard Transformer with non-parametric queries and Fourier positional embeddings performs competitively with specialized architectures that use 3D-specific operators. Despite its simplicity, 3DETR allows for easy implementation and can be further enhanced by incorporating 3D domain knowledge. Through extensive experiments on the ScanNetV2 dataset, we demonstrate that 3DETR surpasses the well-established and optimized VoteNet baselines by 9.5%. Furthermore, we show that 3DETR can be applied to other 3D tasks beyond detection and can serve as a foundational component for future research.