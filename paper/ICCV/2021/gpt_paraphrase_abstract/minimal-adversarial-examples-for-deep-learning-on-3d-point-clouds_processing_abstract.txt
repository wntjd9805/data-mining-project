Recent advancements in convolutional neural networks have led to significant progress in deep learning for 3D point clouds, specifically in tasks related to understanding 3D scenes like object recognition and semantic segmentation. However, the vulnerability of these deep learning models to adversarial examples in safety-critical environments remains poorly understood. In this study, we investigate adversarial attacks on neural networks that operate on point cloud data. We propose a unified approach for generating adversarial point clouds, encompassing two different attack strategies. Our method focuses on attacking the classification ability of point cloud-based networks while considering the perceptibility of the generated examples and minimizing the manipulation of points. Experimental results demonstrate that our approach achieves state-of-the-art performance, achieving attack success rates above 89% and 90% on synthetic and real-world data, respectively, while manipulating only around 4% of the total points.