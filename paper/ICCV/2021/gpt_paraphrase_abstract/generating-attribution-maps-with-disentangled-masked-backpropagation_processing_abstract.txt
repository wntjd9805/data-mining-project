Attribution map visualization is a valuable technique for understanding how Convolutional Neural Networks make inferences. The aim is to assign a score to each pixel in an image based on its contribution to the network's output. This paper presents a new method called Disentangled Masked Backpropagation (DMBP) that uses the piecewise linear nature of ReLU networks to break down the model function into different linear mappings. This decomposition helps separate the attribution maps into positive, negative, and nuisance factors by learning variables that mask the contribution of each filter during backpropagation. The effectiveness of DMBP is demonstrated through evaluations on standard architectures (ResNet50 and VGG16) and benchmark datasets (PASCAL VOC and ImageNet), showing that it produces more visually interpretable attribution maps compared to previous methods. Furthermore, quantitative analysis reveals that the maps generated by DMBP align better with the true contribution of each pixel to the final network output.