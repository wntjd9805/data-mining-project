Our proposed method, Nearest-Neighbor Contrastive Learning of visual Representations (NNCLR), improves self-supervised learning algorithms by using nearest neighbors from the dataset as positives instead of pre-defined transformations of the same instance. By sampling nearest neighbors in the latent space, we introduce more semantic variations to the training process. This approach significantly enhances the performance of image classification on ImageNet, with an increase from 71.7% to 75.6% using ResNet-50 under the linear evaluation protocol, surpassing previous state-of-the-art methods. In semi-supervised learning benchmarks with only 1% ImageNet labels available, our method improves performance from 53.8% to 56.5%. Additionally, our method outperforms state-of-the-art methods, including supervised learning with ImageNet, on 8 out of 12 transfer learning benchmarks. Notably, our method demonstrates reduced reliance on complex data augmentations, as we achieve a mere 2.1% reduction in ImageNet Top-1 accuracy when trained solely using random crops.