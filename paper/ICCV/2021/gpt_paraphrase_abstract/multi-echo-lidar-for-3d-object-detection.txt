The utilization of LiDAR sensors extends beyond capturing a basic 3D point cloud, as they can acquire various measurement signals that can enhance perception tasks such as 3D object detection. Each laser pulse can generate multiple measurements, known as echoes, due to partial reflection from multiple objects along its path. These echoes provide valuable information about object contours and semi-transparent surfaces, enabling improved object identification and localization. Additionally, LiDAR devices can measure surface reflectance (intensity of laser pulse return) and ambient light of the scene (sunlight reflected by objects). Despite these signals being available in commercial LiDAR devices, they have not been widely utilized in existing LiDAR-based detection models. This research introduces a 3D object detection model that effectively leverages the complete range of measurement signals provided by LiDAR. The model incorporates a multi-signal fusion (MSF) module, which combines the reflectance and ambient features extracted using a 2D CNN, along with point cloud features extracted using a 3D graph neural network (GNN). Furthermore, a multi-echo aggregation (MEA) module is proposed to integrate information encoded in different sets of echo points. Compared to traditional single echo point cloud methods, the proposed Multi-Signal LiDAR Detector (MSLiD) extracts more comprehensive context information from a broader range of sensing measurements, leading to more accurate 3D object detection. Experimental results demonstrate that by incorporating the multi-modality of LiDAR, the proposed method outperforms the current state-of-the-art by a relative improvement of up to 9.1%.