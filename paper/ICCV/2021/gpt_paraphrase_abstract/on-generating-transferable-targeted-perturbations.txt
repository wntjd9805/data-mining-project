This paper introduces a new approach for creating targeted perturbations in images that can be transferred between different models. The existing methods for generating perturbations rely on class-boundary information, which limits their transferability. In contrast, the proposed approach aligns the perturbed image distribution with that of the target class, resulting in higher transferability rates. This is achieved by introducing a new objective function that aligns both the global distributions and the local neighborhood structure between source and target images. A generator function is trained based on this objective, allowing for the adaptive synthesis of perturbations specific to a given input. The proposed approach is independent of the source or target domain labels and outperforms state-of-the-art methods in various attack settings. For instance, it achieves a 32.63% target transferability from a weak model to a strong model on the ImageNet validation set, surpassing previous generative and iterative attacks. The code for this approach is available on GitHub.