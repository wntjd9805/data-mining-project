Recent studies have demonstrated the possibility of identifying meaningful directions in the hidden spaces of pre-trained Generative Adversarial Networks (GANs). These directions facilitate controlled image generation and support various semantic editing operations like zooming or rotating. However, the existing methods for discovering such directions rely on supervised or semi-supervised techniques that involve manual annotations, limiting their practical applicability. In contrast, unsupervised discovery allows for the identification of subtle directions that are challenging to detect beforehand. To address this limitation, we propose a self-supervised approach based on contrastive learning to uncover semantic directions in the latent space of pre-trained GANs. Our method successfully identifies dimensions that carry semantic significance and aligns with state-of-the-art techniques.