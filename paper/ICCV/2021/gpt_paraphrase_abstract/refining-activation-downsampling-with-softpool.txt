Soft-Pool is a novel method proposed to address the issue of information loss during the pooling process in Convolutional Neural Networks (CNNs). Pooling is an important operation in CNNs as it reduces the size of activation maps, increasing the receptive fields and reducing computational requirements. However, it is crucial to minimize information loss while keeping the computation and memory overhead low.To tackle this challenge, Soft-Pool introduces exponentially weighted activation downsampling. Through experiments on various architectures and pooling methods, Soft-Pool demonstrates its ability to retain more information in the downscaled activation maps. This refined downsampling technique leads to improvements in the classification accuracy of CNNs.The effectiveness of Soft-Pool is further validated through experiments on ImageNet1K, where pooling layers are substituted with Soft-Pool. These experiments show increased accuracy compared to both the original architectures and other pooling methods. Additionally, Soft-Pool is also tested on video datasets for action recognition, and consistent performance improvements are observed while keeping computational loads and memory requirements limited.In summary, Soft-Pool is a fast and efficient method for exponentially weighted activation downsampling in CNNs. It successfully minimizes information loss during pooling, resulting in improved classification accuracy for various architectures and pooling methods. Its effectiveness is demonstrated in both image and video datasets, making it a promising technique for enhancing CNN performance.