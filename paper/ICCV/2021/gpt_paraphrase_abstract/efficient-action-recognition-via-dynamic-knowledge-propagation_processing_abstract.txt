Efficient action recognition is crucial for various real-world applications. While most existing methods focus on reducing computation cost by selecting salient frames, our approach aims to optimize the selected frames. We utilize two networks with different capabilities in tandem to efficiently recognize actions. The lighter network processes more frames, while the heavier one processes only a few. To facilitate effective interaction between the two networks, we introduce dynamic knowledge propagation using a cross-attention mechanism. This dynamic student-teacher framework, where the teacher model interacts with the student model during inference, is the main component of our proposed framework. Extensive experiments demonstrate the effectiveness of each component. Our approach outperforms state-of-the-art methods on ActivityNet-v1.3 and Mini-Kinetics datasets. Figure 1 illustrates the mAP vs. GFLOPs curves on ActivityNet-v1.3, showing that our dynamic student-teacher framework achieves similar or better performance compared to recent state-of-the-art methods at a much lower computational cost. More experimental results can be found in Section 4.