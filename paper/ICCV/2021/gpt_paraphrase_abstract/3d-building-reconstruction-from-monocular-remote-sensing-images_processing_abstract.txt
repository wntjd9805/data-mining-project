The task of reconstructing 3D buildings from monocular remote sensing imagery is an important area of research and offers an economical solution for large-scale city modeling. Compared to using LiDAR data and multi-view imagery, this approach has its advantages. However, there are several challenges that need to be overcome, such as the partial invisibility of building footprints and facades, the presence of shadows, and the significant variation in building height across large areas. These challenges have limited the existing studies on monocular image-based building reconstruction to certain scenarios, such as modeling simple low-rise buildings from near-nadir images.

To address these difficulties and provide a solution for more complex scenarios, we propose a novel method for 3D building reconstruction from monocular remote sensing images. Our approach involves designing a multi-task building reconstruction network called MTBR-Net. This network learns the geometric properties of oblique images, the key components of a 3D building model, and their relationships through four semantic-related tasks and three offset-related tasks. The outputs of the network are then integrated using a 3D model optimization method based on prior knowledge to generate the final 3D building models.

We have evaluated our method using a public 3D reconstruction dataset and a newly released dataset. The results demonstrate that our approach significantly improves the accuracy of height estimation by over 40% and the segmentation F1-score by 2% - 4% compared to the current state-of-the-art methods.

In summary, our proposed method addresses the challenges associated with monocular image-based building reconstruction, offering a more advanced and effective solution for reconstructing 3D buildings from remote sensing imagery.