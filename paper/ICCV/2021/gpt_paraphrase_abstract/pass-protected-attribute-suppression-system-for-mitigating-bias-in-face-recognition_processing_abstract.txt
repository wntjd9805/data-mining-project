We propose a novel approach called Protected Attribute Suppression System (PASS) to address the issues of privacy leakage and bias in face recognition networks. These networks often encode sensitive attributes during training, which can lead to privacy concerns and biased results. Existing bias mitigation methods require end-to-end training and struggle to achieve high verification accuracy.

However, PASS offers a descriptor-based adversarial debiasing solution that can be trained on top of any previously trained high-performing network. It simultaneously classifies identities while reducing the encoding of sensitive attributes, eliminating the need for end-to-end training. To achieve this, PASS incorporates a unique discriminator training strategy that discourages the network from encoding protected attribute information.

We demonstrate the effectiveness of PASS in reducing gender and skintone information in descriptors obtained from state-of-the-art face recognition networks like Arcface. Our experiments on the IJB-C dataset show that PASS descriptors outperform existing methods in reducing gender and skintone bias while maintaining a high verification accuracy. This approach provides a promising solution to address privacy concerns and bias in face recognition networks without compromising performance.