The vulnerabilities of top-k multi-label learning algorithms in the face of adversarial perturbation attacks have not been thoroughly explored. This study aims to address this gap by developing techniques to create adversarial perturbations specifically designed to attack top-k multi-label learning-based image annotation systems (TkML-AP). The methods proposed in this work take into account the top-k ranking relationship and utilize innovative loss functions. Experiments conducted on widely-used benchmark datasets, including PASCAL VOC and MSCOCO, demonstrate the efficacy of our approach in significantly undermining the performance of state-of-the-art top-k multi-label learning methods, both in untargeted and targeted attacks.