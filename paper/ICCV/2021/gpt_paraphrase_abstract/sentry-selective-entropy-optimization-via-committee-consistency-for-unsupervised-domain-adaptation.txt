Many current methods for unsupervised domain adaptation (UDA) focus on adapting to changes in data distribution, but struggle to handle shifts in label distribution across domains. Recent research has shown promise in using self-training with target pseudolabels, but this approach can be unreliable and lead to errors and misalignment when facing challenging shifts. To address this issue, we propose a UDA algorithm called SENTRY (Selective Entropy Optimization via Committee Consistency). SENTRY assesses the reliability of target instances based on their predictive consistency under a committee of random image transformations. Our algorithm then selectively minimizes predictive entropy to increase confidence in highly consistent target instances, while maximizing predictive entropy to reduce confidence in highly inconsistent ones. Additionally, we incorporate pseudolabel-based approximate target class balancing. With this combined approach, we achieve significant improvements over the current state-of-the-art on 27 out of 31 domain shifts in standard UDA benchmarks, including benchmarks specifically designed to test adaptation under label distribution shift. To access our code, please visit https://github.com/virajprabhu/SENTRY.