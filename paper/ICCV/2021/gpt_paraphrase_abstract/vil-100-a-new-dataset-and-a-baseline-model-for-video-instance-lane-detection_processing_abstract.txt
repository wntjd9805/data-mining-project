Lane detection is a crucial component of autonomous driving systems. However, current methods for lane detection focus on individual images and neglect the dynamic information present in video streams captured by car cameras. To address this limitation, we have developed a new dataset called VIL-100, containing 100 videos with a total of 10,000 frames, captured from various real-world traffic scenarios. Each frame in the dataset has been meticulously annotated with high-quality instance-level lane information. Additionally, we have included frame-level and video-level metrics for accurate quantitative evaluation of lane detection performance.Furthermore, we introduce a novel baseline model called MMA-Net (multi-level memory aggregation network) for video instance lane detection. Our approach enhances the representation of the current frame by attentively aggregating local and global memory features from other frames in the video. Experimental results on the VIL-100 dataset demonstrate that MMA-Net surpasses state-of-the-art lane detection and video object segmentation methods in terms of performance. To facilitate further research in this area, we have made our dataset and code publicly available at https://github.com/yujun0-0/MMA-Net.