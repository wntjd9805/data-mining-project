This paper introduces a novel temporal adaptive module (TAM) for effectively capturing the complex temporal dynamics in video data. TAM utilizes a two-level adaptive modeling scheme, separating the dynamic kernel into an importance map and an aggregation weight. The importance map captures short-term information within a local temporal window, while the aggregation weight focuses on long-term structure from a global view. TAM can be integrated into 2D CNNs to create a powerful video architecture called TANet, with minimal additional computational cost. Experimental results on the Kinetics-400 and Something-Something datasets demonstrate that TAM consistently outperforms other temporal modeling methods and achieves state-of-the-art performance. The code for TAM is available at https://github.com/liu-zhy/temporal-adaptive-module.