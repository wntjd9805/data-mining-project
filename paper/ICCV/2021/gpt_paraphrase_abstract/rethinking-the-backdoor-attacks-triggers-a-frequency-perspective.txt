Backdoor attacks pose a significant security threat to deep learning models, as they can cause abnormal behavior on specific inputs while maintaining high performance on clean data. While these attacks have been extensively studied in the image domain, there has been a lack of analysis in the frequency domain. This paper addresses this gap by examining existing backdoor triggers from a frequency perspective. The findings reveal that many current backdoor attacks exhibit severe high-frequency artifacts that persist across different datasets and resolutions. Additionally, the study demonstrates that these high-frequency artifacts can be exploited to detect existing backdoor triggers with a detection rate of 98.50%, even without prior knowledge of the attack details or target model. Building on the weaknesses of previous attacks, the paper proposes a practical approach to creating smooth backdoor triggers that do not contain high-frequency artifacts and investigates their detectability. The results indicate that defense mechanisms can benefit from incorporating these smooth triggers into their design considerations. Furthermore, the study demonstrates that a detector trained on stronger smooth triggers can effectively identify weaker smooth triggers. Overall, the research highlights the importance of considering frequency analysis when developing both backdoor attacks and defenses in the field of deep learning.