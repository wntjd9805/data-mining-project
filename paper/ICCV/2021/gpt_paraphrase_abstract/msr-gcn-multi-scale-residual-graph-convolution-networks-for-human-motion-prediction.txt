The task of predicting human motion is difficult due to the unpredictable nature of future poses. However, the use of graph convolutional networks has shown promise in learning the relationships between pose joints, aiding in pose prediction. Additionally, abstracting a human pose recursively can provide a set of poses at different scales, with higher levels of abstraction resulting in more stable motion, which benefits pose prediction. In this paper, we introduce a new approach called Multi-Scale Residual Graph Convolution Network (MSR-GCN) for end-to-end human pose prediction. Our method utilizes GCNs to extract features from fine to coarse scales and vice versa. These features are then combined and decoded to determine the differences between the input and target poses. To improve feature representation, intermediate supervisions are applied to all predicted poses. We evaluate our approach on two benchmark datasets, Human3.6M and CMU Mocap, and our experimental results demonstrate that our method outperforms existing approaches. The code and pre-trained models for our approach are available at https://github.com/Droliven/MSRGCN.