Current action localization networks consist of a feature encoder sub-network and a localization sub-network. The feature encoder transforms input videos into useful features for the localization sub-network to generate action proposals. However, existing approaches lack an attention mechanism that allows the localization sub-network to prioritize important features. To address this issue, we propose a new attention mechanism called Class Semantics-based Attention (CSA). CSA learns from the temporal distribution of action class semantics in a video to determine the importance scores of encoded features. These scores are then used to provide attention to the most useful features. Our experiments on two popular action detection datasets demonstrate that incorporating our attention mechanism significantly improves the performance of competitive action detection models. For example, we achieve a 6.2% improvement over the BMN action detection baseline, reaching a mean Average Precision (mAP) of 47.5% on the THUMOS-14 dataset. Additionally, we achieve a new state-of-the-art mAP of 36.25% on the ActivityNet v1.3 dataset. Furthermore, our CSA localization model family, including BMN-CSA, was part of the second-placed submission at the 2021 ActivityNet action localization challenge. Our attention mechanism surpasses previous self-attention modules like squeeze-and-excitation in action detection tasks. Interestingly, we find that our attention mechanism complements these self-attention modules, as performance improvements are observed when they are used together.