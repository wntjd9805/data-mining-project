Adversarial training is a useful technique for training deep neural networks to defend against adversarial attacks. However, current methods of adversarial training tend to favor larger models, which limits their effectiveness on smaller models that are more suitable for resource-constrained scenarios like mobile devices. To address this limitation, we propose a new method called Robust Soft Label Adversarial Distillation (RSLAD) that leverages knowledge distillation to improve the robustness of small models. RSLAD utilizes the predictions of a robust large model, known as robust soft labels, to guide the learning of the small student model on both natural and adversarial examples. We demonstrate the effectiveness of RSLAD in improving the robustness of small models against state-of-the-art attacks, including the AutoAttack. Our results outperform existing adversarial training and distillation methods. We also provide insights into the importance of robust soft labels for adversarial robustness distillation. The code for implementing our RSLAD method is available at https://github.com/zibojia/RSLAD.