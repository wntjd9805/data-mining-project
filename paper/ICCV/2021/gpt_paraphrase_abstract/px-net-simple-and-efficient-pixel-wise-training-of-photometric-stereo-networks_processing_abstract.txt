Obtaining accurate 3D reconstructions of objects based on their light reflections is a difficult task in computer vision. Despite the Photometric Stereo problem being defined over four decades ago, previous literature has struggled to handle global illumination effects like cast shadows, self-reflections, and ambient light, especially for specular surfaces. Recent approaches have combined deep learning and computer graphics to address the need for a large amount of training data to solve the image irradiance equation and determine the object's geometry. However, generating training data using global illumination effects is time-consuming, limiting the available data for training. 

In this study, we propose a new pixel-wise training procedure for predicting normals by replacing the globally rendered image training data (observation maps) with independently generated per-pixel data. We demonstrate that global physical effects can be approximated in the observation map domain, simplifying and accelerating the data creation process. Our network, PX-NET, achieves state-of-the-art performance compared to other pixel-wise methods on both synthetic datasets and the real-world DiLiGenT dataset, in both dense and sparse light settings.