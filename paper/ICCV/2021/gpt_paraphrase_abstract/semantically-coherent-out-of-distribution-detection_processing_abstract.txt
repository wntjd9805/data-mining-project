The current method of creating out-of-distribution (OOD) detection benchmarks involves defining one dataset as in-distribution (ID) and all others as OOD. However, this approach has limitations as it sets unrealistic goals for models, such as perfectly distinguishing between similar datasets with negligible differences. To address this issue, we propose the semantically coherent out-of-distribution detection (SC-OOD) benchmarks, which better reflect real-world applications. Existing methods struggle with SC-OOD benchmarks due to their sensitivity to minor differences between data sources, disregarding the inherent semantics. To overcome this challenge, we introduce the unsupervised dual grouping (UDG) framework, which leverages an external unlabeled dataset to enhance the model's semantic knowledge and improve ID classification and OOD detection simultaneously. Through extensive experiments, we demonstrate that our approach achieves state-of-the-art performance on SC-OOD benchmarks. The code and benchmarks can be accessed on our project page: https://jingkang50.github.io/projects/scood.