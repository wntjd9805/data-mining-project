This study focuses on the task of anomaly detection, which involves identifying unusual samples in data. Typically, anomaly detection requires a large number of training samples. However, this work addresses the challenge of few-shot anomaly detection in images, where only a limited number of training images are available. To tackle this problem, the researchers propose a hierarchical generative model that captures the distribution of patches at multiple scales in each training image.  To enhance the model's representation, the researchers incorporate image transformations and optimize scale-specific patch-discriminators. These discriminators are designed to differentiate between real and fake patches within the image, as well as between different transformations applied to those patches. By aggregating the patch-based votes of the correct transformation across scales and image regions, an anomaly score is obtained.  The effectiveness of the proposed method is demonstrated in both one-shot and few-shot settings using various datasets, including Paris, CIFAR10, MNIST, FashionMNIST, and defect detection on MVTec. In comparison to recent baseline methods, the proposed method consistently outperforms them in all cases.