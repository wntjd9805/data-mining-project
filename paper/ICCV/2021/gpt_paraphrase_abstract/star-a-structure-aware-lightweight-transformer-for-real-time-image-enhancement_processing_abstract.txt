Improving the quality of images and videos on smartphones, particularly in terms of color, low light conditions, and tone mapping, is a difficult task due to limited resources. Previous approaches have relied on deep convolutional neural networks (CNNs) or large Transformer models. In this study, we introduce a lightweight Transformer model called STAR that is specifically designed for real-time image enhancement. STAR is designed to capture the long-range dependencies between different patches of an image, thereby implicitly capturing the structural relationships between various regions. It is a versatile architecture that can be easily adapted to different image enhancement tasks. Our experiments demonstrate that STAR effectively enhances the quality and efficiency of various tasks such as improving illumination, achieving auto white balance, and retouching photos. These tasks are crucial for image processing on smartphones. Notably, STAR outperforms the recent state-of-the-art model on the MIT-Adobe FiveK dataset, achieving a 1.8dB improvement in peak signal-to-noise ratio (PSNR) with 25% fewer parameters and 13% less floating-point operations.