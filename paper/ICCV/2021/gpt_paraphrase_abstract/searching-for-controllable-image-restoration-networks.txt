We introduce an innovative framework called TASNet for controllable image restoration, capable of effectively restoring various types and levels of degradation in a corrupted image. Our model is automatically determined using a neural architecture search algorithm, optimizing the trade-off between efficiency and accuracy. TASNet utilizes shared layers for different restoration tasks, enhancing efficiency, and adapts the remaining layers specifically for each task to improve restoration quality. We propose a new data sampling strategy to further enhance overall restoration performance. As a result, TASNet achieves faster GPU latency and lower FLOPs compared to existing state-of-the-art models, while also producing visually appealing outputs. The source code and pre-trained models can be found at https://github.com/ghimhw/TASNet.