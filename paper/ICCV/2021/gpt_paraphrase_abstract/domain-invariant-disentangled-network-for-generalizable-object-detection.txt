We propose a novel approach called Domain-Invariant Disentangled Network (DIDN) to address the problem of domain generalizable object detection. This problem involves learning a detector that can perform well on unseen domains by leveraging data from multiple seen domains. Unlike previous approaches that directly align multiple sources, our method integrates a disentangled network into the Faster R-CNN model. This disentangled network allows us to learn domain-invariant representations on both image and instance levels, improving the generalization ability of the detector. Additionally, we introduce a cross-level representation reconstruction technique to preserve informative object representations. We evaluate our model on five benchmark datasets and achieve state-of-the-art performance in domain generalization for object detection.