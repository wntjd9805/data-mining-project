This study focuses on semantic segmentation tasks, where input images can have multiple valid labels due to potential ambiguities. Previous research has explored the use of probabilistic networks to capture these uncertainties. However, these networks may not accurately represent the empirical distribution. In this work, a strategy is presented to learn a calibrated predictive distribution over semantic maps, where the probability associated with each prediction reflects its likelihood of being correct. To achieve this, a two-stage, cascaded approach called calibrated adversarial refinement is proposed. Firstly, a standard segmentation network is trained using categorical cross entropy to predict a pixelwise probability distribution over semantic classes. Secondly, an adversarially trained stochastic network is employed to refine the output of the first network by modeling inter-pixel correlations and generating coherent samples. Importantly, the refinement network is calibrated and prevents mode collapse by matching the expectation of the samples in the second stage to the predicted probabilities in the first stage. The versatility and robustness of the approach are demonstrated by achieving state-of-the-art results on the multigrader LIDC dataset and a modified Cityscapes dataset with injected ambiguities. Furthermore, the core design of the approach can be adapted to other tasks that require learning a calibrated predictive distribution, as shown by experiments on a toy regression dataset. An open source implementation of the method is provided at https://github.com/EliasKassapis/CARSSS.