This paper focuses on improving the accuracy of low-cost monocular 3D object detection for autonomous driving. The authors propose a Dynamic Feature-Reflecting Network (DFR-Net) that reformulates the object detection task into sub-tasks of object localization and appearance perception. DFR-Net consists of two standalone modules: the Appearance-Localization Feature Reflecting module (ALFR) that separates task-specific features and reflects reciprocal features, and the Dynamic Intra-Trading module (DIT) that adaptively realigns the training processes of different sub-tasks. The effectiveness and generalization of DFR-Net are demonstrated through extensive experiments on the KITTI dataset, where it achieves the top ranking among all monocular 3D object detectors. The proposed method can be easily integrated into existing 3D detection frameworks without significant cost, and the code will be made publicly available.