Despite the success of deep learning in supervised point cloud semantic segmentation, obtaining manual annotations for large-scale datasets remains a significant challenge. To address this issue, we propose a general framework called Region-based and Diversity-aware Active Learning (ReDAL). The aim of ReDAL is to automatically select informative and diverse sub-scene regions for label acquisition, thus reducing the burden of annotation. We observe that only a small portion of annotated regions is necessary for 3D scene understanding using deep learning. Therefore, we utilize softmax entropy, color discontinuity, and structural complexity to measure the information content of sub-scene regions. Additionally, we have developed a diversity-aware selection algorithm to prevent redundant annotations caused by selecting similar but informative regions in a querying batch. Our extensive experiments demonstrate that our method significantly outperforms previous active learning strategies. In fact, we achieve a performance level equivalent to 90% fully supervised learning, while requiring less than 15% and 5% annotations on the S3DIS and SemanticKITTI datasets, respectively.