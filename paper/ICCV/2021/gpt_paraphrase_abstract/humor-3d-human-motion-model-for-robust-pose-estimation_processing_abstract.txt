We present HuMoR, a 3D Human Motion Model that aims to accurately estimate temporal pose and shape despite challenges such as noise and occlusions. While previous efforts have made progress in estimating 3D human motion and shape, recovering plausible pose sequences remains difficult. To address this, we propose a generative model called a conditional variational autoencoder. This model learns the distribution of pose changes at each step of a motion sequence. Additionally, we introduce a flexible optimization-based approach that utilizes HuMoR as a motion prior to robustly estimate plausible pose and shape from ambiguous observations. Our model demonstrates generalization to various motions and body shapes after training on a large motion capture dataset. It also enables motion reconstruction from multiple input modalities, including 3D keypoints and RGB(-D) videos. Further details can be found on our project page at geometry.stanford.edu/projects/humor.