Using feature dependent network weights has proven effective in various fields. However, the practical implementation of dynamic convolutions with per-pixel adapted filters is limited by the large size of model parameters and memory requirements. To overcome this challenge, we introduce a method that decomposes filters into dynamic filter atoms generated by a lightweight network from local features. This allows for adaptive receptive fields by representing each filter atom using sets of pre-fixed multi-scale bases. Our method, which can replace convolutional layers, enables explicit modeling of intra-image variance while minimizing computation, parameters, and memory usage. It maintains the desirable properties of conventional convolutions such as translation-equivariance and parametric efficiency. Experimental results demonstrate that our approach achieves comparable or better performance across tasks, particularly in handling tasks with significant intra-image variance.