The task of recognizing multiple objects in a single image is still a difficult challenge due to various factors such as object scales, inconsistent appearances, and inter-class relationships. Previous research has utilized statistical label co-occurrences and linguistic word embedding to improve semantic understanding. However, this paper proposes a new approach called the Transformer-based DualRelation learning framework, which focuses on constructing complementary relationships through two types of correlation: structural relation graph and semantic relation graph. The structural relation graph captures long-range correlations by utilizing a cross-scale transformer-based architecture, while the semantic graph dynamically models the semantic meanings of image objects with explicit semantic-aware constraints. Additionally, the learned structural relationship is integrated into the semantic graph, creating a joint relation graph for robust representations. By combining the collaborative learning of these two relation graphs, our approach achieves state-of-the-art performance on two widely-used multi-label recognition benchmarks, namely MS-COCO and VOC 2007 datasets.