The convolutional neural network (CNN) is susceptible to degraded images, even with slight variations such as corrupted or adversarial samples. This vulnerability may arise from the CNN's tendency to focus on the most discriminative regions while disregarding auxiliary features during the learning process. Consequently, this lack of feature diversity hampers the network's ability to make accurate judgments. To address this issue, we propose a method that dynamically suppresses significant activation values of the CNN through group-wise inhibition. Unlike fixed or random handling methods, our approach tailors the treatment of these values during training. Furthermore, we process feature maps with different activation distributions separately to consider feature independence. By incorporating this regularization technique, we guide the CNN to learn more diverse and discriminative features hierarchically, thereby enhancing its robust classification capabilities. We extensively evaluate our method under various scenarios, including classification against corruptions, adversarial attacks, and low data availability. Our experimental results demonstrate that our proposed method significantly improves both robustness and generalization performance compared to existing state-of-the-art methods. To facilitate further research, we have made the code available at https://github.com/LinusWu/TENET_Training.