We introduce a technique for differentiable rendering of 3D surfaces that supports explicit and implicit representations, provides derivatives at occlusion boundaries, and is easy to implement. Our method involves sampling the surface using non-differentiable rasterization, followed by differentiable point splatting that takes depth into account to generate the final image. This approach does not require differentiable meshing or rasterization steps, making it efficient for large 3D models and applicable to isosurfaces extracted from implicit surface definitions. We demonstrate the effectiveness of our method in inverse rendering and neural network training applications using implicit, mesh, and parametric surface representations. In particular, we achieve efficient, differentiable rendering of an isosurface extracted from a neural radiance field (NeRF) for the first time and showcase surface-based rendering instead of volume-based rendering for a NeRF.