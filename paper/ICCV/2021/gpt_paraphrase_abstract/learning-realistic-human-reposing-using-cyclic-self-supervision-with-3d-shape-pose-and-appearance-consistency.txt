The task of synthesizing images of a person in different poses from a single image is challenging and often requires paired training data. However, obtaining large datasets with paired images is difficult and expensive. Previous methods that do not rely on paired data lack realism. To address this issue, we propose a self-supervised framework called SPICE (Self-supervised Person ImageCrEation) that narrows the gap in image quality compared to supervised methods. The key insight behind self-supervision is leveraging 3D information about the human body. This includes ensuring that the 3D body shape remains unchanged when reposing, using 3D body pose representation to consider self occlusions, and maintaining similar appearance features for 3D body parts before and after reposing. Once trained, SPICE can take an image of a person and generate a new image of that person in a different pose. SPICE achieves state-of-the-art performance on the DeepFashion dataset, significantly improving the FID score compared to previous unsupervised methods. It also performs similarly to the state-of-the-art supervised method. Furthermore, SPICE can generate temporally coherent videos when given an input image and a sequence of poses, even though it is trained on static images only.