Unsupervised domain adaptation (UDA) involves using a supervised loss in a labeled source domain and an unsupervised loss in an unlabeled target domain. However, UDA often faces more severe overfitting compared to classical supervised learning. This is because the supervised source loss has a clear domain gap, and the unsupervised target loss is often noisy due to the lack of annotations. To mitigate overfitting in UDA, this paper introduces RDA, a robust domain adaptation technique that incorporates adversarial attacking. RDA achieves robust domain adaptation through a novel method called Fourier adversarial attacking (FAA). FAA allows for large perturbation noises while minimally modifying image semantics, which is crucial for the effectiveness of its generated adversarial samples in the presence of domain gaps. Specifically, FAA decomposes images into multiple frequency components (FCs) and perturbs certain FCs that capture little semantic information to generate adversarial samples. By using these FAA-generated samples, the training process can continue in a "random walk" manner and drift into an area with a flat loss landscape, resulting in more robust domain adaptation.Extensive experiments conducted on multiple domain adaptation tasks demonstrate that RDA can be applied to various computer vision tasks and achieves superior performance.