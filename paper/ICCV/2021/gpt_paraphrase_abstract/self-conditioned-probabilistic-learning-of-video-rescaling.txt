In this study, we introduce a self-conditioned probabilistic framework for video rescaling that aims to improve the performance of downstream tasks while reducing the storage burden and speeding up processing. Bicubic downscaling is commonly used for these purposes, but it can lead to performance deterioration and non-trivial upscaling challenges. Our framework simultaneously learns the downscaled and upscaled procedures by maximizing the probability of the information lost in downscaling conditioned on strong spatial-temporal prior information within the downscaled video. This approach preserves more meaningful information, benefiting both the upscaling step and downstream tasks such as video action recognition. Additionally, we extend the framework to a lossy video compression system and propose a gradient estimator for non-differential industrial lossy codecs to enable end-to-end training of the entire system. Comprehensive experiments demonstrate the superiority of our approach in video rescaling, video compression, and efficient action recognition tasks.