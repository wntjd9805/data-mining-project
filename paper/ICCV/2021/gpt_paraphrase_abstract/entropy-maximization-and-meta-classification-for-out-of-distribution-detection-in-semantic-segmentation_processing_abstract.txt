Deep neural networks (DNNs) are commonly used for semantic segmentation of images with a predefined set of object classes. However, in real-world scenarios, DNNs need to be able to detect objects outside of this predefined set. This ability, known as out-of-distribution (OoD) detection, is crucial for applications such as automated driving to ensure functional safety. The current baseline approach for OoD detection is to use pixel-wise softmax entropy thresholding.In this study, we propose a two-step procedure to enhance the OoD detection performance. Firstly, we utilize samples from the COCO dataset as proxies for OoD samples and introduce a new training objective to maximize the softmax entropy on these samples. By retraining pretrained semantic segmentation networks on different in-distribution datasets, we consistently observe improved OoD detection performance when evaluating on completely different OoD datasets.Secondly, we implement a transparent post-processing step called "meta classification" to eliminate false positive OoD samples. This step involves applying linear models to hand-crafted metrics derived from the DNN's softmax probabilities. By doing this, we achieve a significant gain in OoD detection performance, reducing the number of detection errors by 52% compared to the best baseline approach. Importantly, this improvement in OoD detection does not come at a significant cost to the original segmentation performance.Overall, our method contributes to the development of safer DNNs with more reliable system performance in an open-world setting.