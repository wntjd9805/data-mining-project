We present a novel method for identifying deepfake images by analyzing the inconsistency of source features within the manipulated images. Our approach is based on the assumption that unique source features can still be extracted from deepfake images generated using advanced techniques. To accomplish this, we introduce a new technique called pair-wise self-consistency learning (PCL), which trains Convolutional Neural Networks (ConvNets) to extract these source features and identify deepfake images. Additionally, we propose a new image synthesis approach called the inconsistency image generator (I2G), which generates annotated training data for PCL. Our experimental results on seven widely-used datasets demonstrate that our models significantly outperform existing methods, improving the average AUC from 96.45% to 98.05% in within-dataset evaluation and from 86.03% to 92.18% in cross-dataset evaluation.