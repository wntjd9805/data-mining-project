In real-world surveillance situations, person re-identification (Re-ID) models often struggle with various low-level perceptual variations, such as differences in resolution and lighting conditions. Existing models have limited generalization capabilities to handle unknown perceptual interferences due to the narrow range of training data. To address this issue, we propose two distinct methods for generating additional data to enhance the robustness of Re-ID models. Firstly, we use a dense resampling technique based on the estimated perceptual distribution, considering the sparse and imbalanced nature of samples in the perceptual space. Secondly, we introduce a graph-based white-box attacker to guide the data generation process by focusing on intra-batch ranking and discriminating attention, enabling us to obtain more representative generated samples for identity representation learning. Furthermore, we incorporate synthetic-to-real feature constraints into the Re-ID training process to mitigate any domain bias introduced by the generated data. Our method is effective, easy to implement, and can be used with any network architecture. Even when applied to a ResNet-50 baseline, our approach achieves competitive results, surpassing state-of-the-art methods by 1.2% at Rank-1 on the MLR-CUHK03 dataset.