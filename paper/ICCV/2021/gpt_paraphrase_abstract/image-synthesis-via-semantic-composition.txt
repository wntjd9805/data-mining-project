This paper introduces a new method for generating realistic images based on their semantic layouts. The method suggests that objects with similar appearances have similar representations. The approach establishes relationships between regions based on their appearance correlation, resulting in both spatially variant and associated representations. By conditioning on these features, the method proposes a dynamic weighted network created through spatially conditional computation using convolution and normalization. This dynamic network not only preserves semantic differences but also enhances semantic relevance, improving the synthesis of global structure and details. Extensive experiments on benchmarks demonstrate that the proposed method achieves compelling generation performance both qualitatively and quantitatively.