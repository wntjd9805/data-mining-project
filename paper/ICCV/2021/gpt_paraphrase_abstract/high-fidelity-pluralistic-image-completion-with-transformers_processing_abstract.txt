Convolutional neural networks (CNNs) have been successful in image completion due to their ability to model textures. However, they struggle with understanding global structures and supporting pluralistic completion due to local inductive priors like invariant kernels. On the other hand, transformers excel in modeling long-term relationships and generating diverse results, but their computation complexity hinders their application in processing high-resolution images. This paper proposes a novel approach to pluralistic image completion by combining the strengths of transformers and CNNs. The transformer module reconstructs pluralistic coherent structures and coarse textures, while the CNN module enhances local texture details guided by high-resolution masked images. The proposed method outperforms existing techniques in terms of image fidelity, diversity, and generalization ability on large masks and generic datasets like ImageNet. The code and pre-trained models are publicly available at the given GitHub repository.