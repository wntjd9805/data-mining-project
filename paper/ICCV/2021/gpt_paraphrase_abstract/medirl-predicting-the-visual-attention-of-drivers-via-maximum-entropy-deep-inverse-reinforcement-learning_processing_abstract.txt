We introduce a new approach called Maximum Entropy Deep Inverse Reinforcement Learning (MEDIRL) that predicts the visual attention of drivers in dangerous situations, inspired by human visual attention. MEDIRL learns a task-sensitive reward function by analyzing eye fixation patterns of attentive drivers and predicts fixation locations that lead to maximum rewards. We also introduce a new dataset called EyeCar, which consists of driver attention data in accident-prone situations. Our proposed model is evaluated on three common benchmarks (DR(eye)VE, BDD-A, DADA-2000) as well as the EyeCar dataset. The results show that MEDIRL outperforms existing models and achieves state-of-the-art performance in attention prediction. Extensive ablation studies are presented to gain more insights into the different features of our model.