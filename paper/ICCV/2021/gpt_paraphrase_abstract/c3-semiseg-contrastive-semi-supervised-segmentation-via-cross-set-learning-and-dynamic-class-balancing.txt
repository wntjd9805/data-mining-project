Semi-supervised semantic segmentation methods aim to improve the accuracy of image labeling by utilizing both labeled and unlabeled data. However, current approaches face limitations in terms of feature misalignment and a lack of consideration for semantic dependencies. In this study, we present a new method called C 3-SemiSeg, which addresses these limitations by enhancing feature alignment and discriminative ability. We achieve this by implementing a cross-set region-level data augmentation strategy to reduce feature discrepancies between labeled and unlabeled data. Additionally, we integrate cross-set pixel-wise contrastive learning to improve feature representation. To deal with noisy labels, we propose a dynamic confidence region selection strategy that focuses on high confidence regions for loss calculation. We evaluate our approach on the Cityscapes and BDD100K datasets and show that it outperforms other state-of-the-art semi-supervised semantic segmentation methods.