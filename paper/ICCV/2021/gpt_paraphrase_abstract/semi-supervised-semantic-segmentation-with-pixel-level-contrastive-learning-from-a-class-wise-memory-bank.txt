This study introduces an innovative method for semi-supervised semantic segmentation. The main component of this method is a contrastive learning module that ensures the segmentation network produces similar pixel-level feature representations for samples of the same class across the entire dataset. To accomplish this, a memory bank is utilized, which is continuously updated with relevant and high-quality feature vectors from labeled data. During end-to-end training, the features from both labeled and unlabeled data are optimized to resemble same-class samples from the memory bank. Our approach not only surpasses the current leading approach for semi-supervised semantic segmentation but also achieves superior results for semi-supervised domain adaptation on widely recognized public benchmarks. It particularly excels in challenging scenarios with limited labeled data. The code for this approach is available at https://github.com/Shathe/SemiSeg-Contrastive.