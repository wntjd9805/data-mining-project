Self-supervised learning (SSL) has been shown to be highly effective in learning representations from unlabeled image data. However, there is limited research exploring its usefulness in 3D skeleton-based action recognition. Existing SSL techniques for 3D skeleton learning suffer from trivial solutions and imprecise representations. To address these issues, we focus on the consistency and continuity of motion at different playback speeds. In this study, we propose a novel SSL method to learn 3D skeleton representation more effectively. Our approach involves constructing positive clips (speed-changed) and negative clips (motion-broken) from sampled action sequences. By encouraging the positive pairs to be closer and pushing the negative pairs apart, we force the network to learn intrinsic dynamic motion consistency information. Additionally, we utilize skeleton interpolation to enhance the learning features and model the continuity of human skeleton data. We evaluate the effectiveness of our method on Kinetics, NTU60, NTU120, and PKUMMD datasets using various network architectures. Experimental results demonstrate the superiority of our approach, leading to significant performance improvement without the need for extra labeled data.