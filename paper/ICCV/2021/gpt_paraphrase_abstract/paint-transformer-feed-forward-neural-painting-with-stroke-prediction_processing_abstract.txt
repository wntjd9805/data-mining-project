Neural painting involves using neural networks to recreate an image in a non-photo-realistic style through a series of strokes. Current methods for generating stroke sequences using reinforcement learning (RL) are unstable and difficult to train. Stroke optimization methods, on the other hand, are inefficient due to the large search space. In this paper, we propose a new approach called Paint Transformer, which formulates the task as a set prediction problem and uses a Transformer-based framework to generate stroke parameters in parallel. Our model can create a final painting of size 512 Ã— 512 in near real time. To overcome the lack of training data, we develop a self-training pipeline that achieves excellent generalization capability without relying on existing datasets. Experimental results show that our method outperforms previous approaches in terms of painting quality while being more cost-effective for training and inference. The code and models are available at https://github.com/wzmsltw/PaintTransformer.