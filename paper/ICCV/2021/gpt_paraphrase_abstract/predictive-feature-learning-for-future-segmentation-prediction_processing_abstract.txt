This study focuses on the prediction of segmentation masks for future frames. Previous methods have attempted to predict intermediate features extracted from existing segmentation models. However, these features are highly detailed and of high resolution, making it challenging to predict their complex spatio-temporal variations. To address this, the authors propose a novel framework called Predictive Feature Autoencoder. This framework incorporates an autoencoder that enhances global structures and suppresses local details in the learned latent features, resulting in a more predictive representation. To prevent the loss of suppressed details during recurrent feature prediction, a reconstruction constraint is introduced. Experimental results demonstrate the effectiveness of the proposed approach, surpassing state-of-the-art methods by a significant margin.