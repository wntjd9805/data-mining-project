This paper addresses two limitations of existing methods for estimating surface normals from a single image: the inability to estimate uncertainty and the lack of detail in predictions. The proposed network solves these issues by estimating the per-pixel surface normal probability distribution using a new parameterization. This allows for the calculation of the angular loss with learned attenuation, which serves as the negative log-likelihood of the distribution. The expected value of the angular error is then used as a measure of the uncertainty. Additionally, a novel decoder framework is presented, where pixel-wise multi-layer perceptrons are trained on a subset of pixels sampled based on the estimated uncertainty. This uncertainty-guided sampling prevents bias in training towards large planar surfaces and improves prediction quality, particularly near object boundaries and on small structures. Experimental results demonstrate that the proposed method outperforms the state-of-the-art in Scan-Net and NYUv2 datasets, and that the estimated uncertainty is highly correlated with the prediction error. The code for this method is available at https://github.com/baegwangbin/surface_normal_uncertainty.