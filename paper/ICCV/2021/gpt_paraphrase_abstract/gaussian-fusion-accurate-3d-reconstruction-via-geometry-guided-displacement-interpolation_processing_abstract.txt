We propose a novel approach for reconstructing intricate geometric details using consumer RGB-D sensors, which is challenging due to uncertainties in sensor depth and poses. Our approach involves a unique geometry-guided fusion framework. Firstly, we characterize fusion correspondences by utilizing geodesic curves derived from the Monge-Kantorovich problem. These curves provide a deeper understanding of the local surface's geometric structures compared to traditional depth map back-projection methods. Secondly, we move points along the geodesic curves, guided by local geometric properties such as Gaussian curvature and mean curvature. This approach differs from existing methods by fully leveraging the meaningful geometric features of the local surface, resulting in improved reconstruction accuracy and completeness. Through extensive experimentation on actual object data, we demonstrate the superior performance of our method. Specifically, our technique excels in capturing the delicate geometric details of thin objects, where the original depth map back-projection fusion scheme tends to produce severe artifacts (refer to Fig.1).