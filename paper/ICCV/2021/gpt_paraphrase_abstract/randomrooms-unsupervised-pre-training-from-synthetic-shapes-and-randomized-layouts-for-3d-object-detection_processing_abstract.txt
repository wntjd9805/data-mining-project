The scarcity of annotated real datasets is a major obstacle in 3D point cloud understanding. To overcome this, researchers propose utilizing synthetic datasets to enhance learning on real datasets through pre-training and fine-tuning. However, previous attempts at 3D pre-training have failed to transfer features learned on synthetic objects to real-world applications. In this study, a new method called RandomRooms is introduced to address this issue. The method involves generating random layouts of a scene using objects from the synthetic CAD dataset and applying object-level contrastive learning on two random scenes created from the same set of synthetic objects. The pre-trained model can then be used as a better initialization for fine-tuning on the 3D object detection task. Experimental results demonstrate consistent improvement in downstream 3D detection tasks, especially when limited training data is available. The proposed method achieves state-of-the-art performance on popular 3D detection benchmarks, ScanNetV2 and SUN RGB-D, by leveraging the rich semantic knowledge and diverse objects from synthetic data. This approach provides a new perspective for bridging object and scene-level 3D understanding.