The use of base primitives to represent human-made objects has been widely used in computer vision and reverse engineering. However, existing approaches struggle to detect both large and detailed primitives in high-resolution point cloud scans. Classical methods like RANSAC require parameter tuning, while state-of-the-art networks like PointNet++ are limited by memory consumption and fail to detect fine-scale primitives. To address this, we propose Cascaded Primitive Fitting Networks (CPFN), which combines global and local primitive detection networks using an adaptive patch sampling network. We also introduce a merging formulation that dynamically aggregates primitives across different scales. Our evaluation shows that CPFN outperforms SPFN, the current state-of-the-art, by 13-14% on high-resolution point cloud datasets. Furthermore, CPFN significantly improves the detection of fine-scale primitives by 20-22%. Our code is available at: https://github.com/erictuanle/CPFN.