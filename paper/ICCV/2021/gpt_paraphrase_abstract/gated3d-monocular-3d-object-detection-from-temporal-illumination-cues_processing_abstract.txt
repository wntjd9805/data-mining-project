Current state-of-the-art methods for detecting 3D objects rely on lidar, stereo, or monocular cameras. While lidar-based methods offer the highest accuracy, they have limitations in terms of size, cost, and angular sampling rates, resulting in lower spatial resolution at longer distances. On the other hand, low-cost monocular or stereo camera approaches have the potential to overcome these limitations but struggle in low-light or low-contrast environments due to their reliance on passive CMOS sensors. To address this, we propose a new method for 3D object detection that utilizes temporal illumination cues from a low-cost monocular gated imager.

To enable this, we introduce a novel deep detection architecture called Gated3D, which is specifically designed to leverage temporal illumination cues in gated images. This allows us to make use of well-established 2D object feature extractors that guide the 3D predictions by estimating frustum segments. We evaluate our proposed method on a dataset comprising gated images captured over 10,000 km of driving data, and compare it against state-of-the-art monocular and stereo methods. Our experimental results demonstrate that our method outperforms these existing approaches, presenting a new sensor modality that has the potential to replace lidar in autonomous driving.

For more information about our proposed method, please visit our website: https://light.princeton.edu/gated3d.