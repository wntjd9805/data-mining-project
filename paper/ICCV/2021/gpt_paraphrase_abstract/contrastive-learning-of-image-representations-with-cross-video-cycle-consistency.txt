Recent advancements in self-supervised representation learning have greatly improved performance. These methods primarily focus on intra-image invariance learning, where positive sample pairs are created by applying different transformations to the same image instance. By comparing these pairs, various tasks are designed to learn invariant representations. Similarly, in the case of video data, representations of frames from the same video are trained to be more similar than frames from different videos, known as intra-video invariance. However, the exploration of cross-video relations for visual representation learning is limited. Unlike intra-video invariance, obtaining ground-truth labels for cross-video relations typically requires human labor. To address this, we propose a novel contrastive learning method that utilizes cycle-consistency to explore cross-video relations for general image representation learning. This approach enables the collection of positive sample pairs across different video instances, which we believe will result in higher-level semantics. We evaluate our method by transferring our image representation to multiple downstream tasks such as visual object tracking, image classification, and action recognition. Our results demonstrate significant improvements over state-of-the-art contrastive learning methods. More information about our project can be found at https://happywu.github.io/cycle_contrast_video.