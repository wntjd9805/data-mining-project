The graph convolutional network (GCN) has made great strides in 3D human pose estimation (HPE) by capturing the relationships between body parts. However, previous GCN approaches have two major limitations. Firstly, they use the same feature transformation for each node within a graph convolution layer, preventing them from learning different relationships between body joints. Secondly, the graph is usually defined according to the human skeleton, which is suboptimal because human activities often involve motion patterns beyond the natural connections of body joints. To overcome these limitations, we propose a novel Modulated GCN for 3D HPE. This model consists of two key components: weight modulation and affinity modulation. Weight modulation enables the learning of different modulation vectors for different nodes, disentangling the feature transformations while maintaining a small model size. Affinity modulation adjusts the graph structure in the GCN to capture additional edges beyond the human skeleton. We explore various affinity modulation methods and examine the impact of regularizations. Rigorous experiments demonstrate that both types of modulation improve performance with minimal overhead. Compared to state-of-the-art GCNs for 3DHPE, our approach significantly reduces estimation errors by approximately 10% while maintaining a small model size, or dramatically reduces the model size (e.g., from 4.22M to 0.29M, a 14.5Ã— reduction) while achieving comparable performance. Results on two benchmarks demonstrate that our Modulated GCN outperforms recent state-of-the-art methods. Our code is available at https://github.com/ZhimingZo/Modulated-GCN.