This paper focuses on generating images based on a layout, which consists of bounding boxes with object categories. Current methods use a pipeline that involves generating object masks separately and then mapping them to the bounding boxes to create a complete semantic segmentation mask. However, this approach leads to overlapping object masks, resulting in reduced clarity and confusion in image generation. We propose the Locality-Aware Mask Adaption (LAMA) module to address this issue by adapting overlapped or nearby object masks during the generation process. Our experimental results demonstrate that our proposed model with LAMA outperforms existing methods in terms of visual fidelity and alignment with input layouts. Specifically, on the COCO-stuff dataset at a resolution of 256x256, our method improves the state-of-the-art FID score from 41.65 to 31.12 and the SceneFID from 22.00 to 18.64.