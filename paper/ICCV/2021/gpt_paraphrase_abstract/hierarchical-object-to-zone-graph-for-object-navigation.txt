The objective of object navigation is to guide an agent to locate specific objects in unfamiliar environments using visual cues. Existing approaches typically utilize deep models to train agents to predict actions in real-time. However, in unseen environments where the target object is not within the agent's field of view, the lack of guidance may result in suboptimal decision-making. To address this issue, we propose a hierarchical object-to-zone (HOZ) graph that guides the agent in a step-by-step manner. Additionally, we introduce an online-learning mechanism to update the HOZ graph based on real-time observations in new environments. The HOZ graph consists of scene nodes, zone nodes, and object nodes. By leveraging the pre-learned HOZ graph, real-time observations, and the target goal, the agent can continually plan an optimal path from zone to zone. In this estimated path, the next potential zone serves as a sub-goal and is incorporated into the deep reinforcement learning model for action prediction. We evaluate our approach on the AI2-Thor simulator, using established evaluation metrics such as SR and SPL, as well as a novel metric called SAE which focuses on the effectiveness of actions. Experimental results demonstrate the effectiveness and efficiency of our proposed method. The code for our approach is publicly available at https://github.com/sx-zhang/HOZ.git.