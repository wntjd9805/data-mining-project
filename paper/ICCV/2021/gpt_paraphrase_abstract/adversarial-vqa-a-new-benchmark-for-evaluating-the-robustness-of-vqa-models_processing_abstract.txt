Leveraging the benefits of extensive pre-training, significant improvements have been observed in the performance of Visual Question Answering (VQA) tasks. However, it remains uncertain whether these state-of-the-art models can handle real-world examples effectively. 

To address this, we introduce Adversarial VQA, a large-scale benchmark for VQA that was collected through an iterative process involving human annotators and models. This new benchmark has led to several interesting findings. 

Firstly, it is surprising to note that non-expert annotators were able to successfully attack state-of-the-art VQA models during the dataset collection process. Additionally, both large-scale pre-trained models and adversarial training methods perform significantly worse on the Adversarial VQA benchmark compared to the standard VQA v2 dataset. This highlights the fragility of these models and demonstrates the effectiveness of our adversarial dataset. 

Furthermore, when used for data augmentation, our dataset proves to be effective in enhancing model performance on other robust VQA benchmarks. We believe that our Adversarial VQA dataset can contribute to the study of robustness in the research community and serve as a valuable benchmark for future work.