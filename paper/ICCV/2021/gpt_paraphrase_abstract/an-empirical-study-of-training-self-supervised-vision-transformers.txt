This paper examines the importance of self-supervised learning for Vision Transformers (ViT) in computer vision. While there has been significant progress in training convolutional networks, the recipes for ViT are still being developed, especially in the challenging self-supervised scenarios. The study focuses on fundamental components for training self-supervised ViT and identifies instability as a major issue that affects accuracy. The paper uncovers that seemingly good results are actually partial failures that can be improved by enhancing training stability. The authors conduct benchmarking of ViT results in MoCo v3 and other self-supervised frameworks, along with various ablations. The paper discusses both positive evidence and challenges, aiming to provide valuable insights and experiences for future research.