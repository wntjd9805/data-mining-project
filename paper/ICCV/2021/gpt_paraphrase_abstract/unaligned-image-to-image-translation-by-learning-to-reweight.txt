Unsupervised image-to-image translation aims to learn how to convert images from one domain to another without using paired images for training. However, this approach assumes that the two domains are already aligned, which may not always be the case. This paper addresses the challenge of image translation between unaligned domains, where the source and target domains do not share a clear correspondence. To overcome this, the proposed method involves selecting images based on their importance and learning the weights for translation. The method is compared to existing image translation approaches, and both qualitative and quantitative results are presented for various tasks with unaligned domains. Extensive empirical evidence supports the effectiveness of the proposed problem formulation and demonstrates the superiority of the proposed method.