Current one-step multi-object tracking and segmentation (MOTS) methods are not as advanced as recent two-step methods. Two-step methods have an advantage in that they separate the instance segmentation stage from the tracking stage, allowing them to utilize non-video datasets for training instance segmentation. Additionally, two-step methods can gather instances with different IDs from different frames, which enables more effective hard example mining during tracker training. To address this gap, we propose a novel data augmentation strategy called continuous copy-paste (CCP). CCP leverages the pixel-wise annotations provided by MOTS to increase the number of instances and unique instance IDs during training. By training current MOTS methods with CCP, significant performance improvements can be achieved without any modifications to the frameworks. Building on CCP, we introduce CCPNet, the first effective one-stage online MOTS method that generates instance masks and tracking results simultaneously. CCPNet outperforms all state-of-the-art methods by significant margins, achieving 3.8% higher sMOTSA and 4.1% higher MOTSA for pedestrians on the KITTI MOTS Validation dataset, and it ranks 1st on the KITTI MOTS leaderboard. Evaluations on three datasets validate the effectiveness of both CCP and CCPNet. Our code is publicly available at: https://github.com/detectRecog/CCP.