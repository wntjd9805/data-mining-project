This study focuses on enhancing the efficiency of current action recognition models on trimmed videos. Most existing solutions use dense sampling, which is time-consuming. Instead, we propose a method called Selective Feature Compression (SFC) to improve inference efficiency without sacrificing accuracy. Unlike previous approaches that compress kernel size or decrease channel dimension, SFC compresses features along the spatio-temporal dimensions without altering backbone parameters. Our experiments on three datasets demonstrate that SFC reduces inference speed by 6-7x and memory usage by 5-6x compared to dense sampling, while also slightly improving accuracy. We provide comprehensive evaluation and show how SFC learns to prioritize important video regions for action recognition.