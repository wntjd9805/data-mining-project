This abstract discusses the importance of perceiving 3D shapes of objects from RGB images for understanding semantic scenes in real-world environments. The authors propose a new method to establish a connection between 2D images and 3D CAD models by utilizing CAD model priors from large databases. This approach constructs a joint embedding space between image patches and CAD geometry patches, allowing for part similarity reasoning and retrieval of CAD models that closely match a new image view. The patch embedding technique enhances CAD retrieval for shape estimation of detected objects in a single input image. The effectiveness of the proposed method is demonstrated through experiments on complex real-world imagery, showing superior performance compared to existing approaches when exact CAD matches are not available.