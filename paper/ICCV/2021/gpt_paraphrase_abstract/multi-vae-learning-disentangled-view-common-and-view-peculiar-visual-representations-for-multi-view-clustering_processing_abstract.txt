Multi-view clustering is a research problem that involves extracting valuable information from different perspectives. However, current approaches often combine representations from multiple views or perform clustering in a shared feature space, which can lead to confusion, especially with visual representations. To address this issue, we propose a new framework called Multi-VAE for multi-view clustering. This framework utilizes a disentangled learning approach to generate visual representations. Specifically, we introduce a view-common variable and multiple view-peculiar variables in the generative model. The view-common variable captures the common cluster factor across multiple views using an approximately discrete Gumbel Softmax distribution. On the other hand, the view-peculiar variables represent the unique visual factors of each view using a continuous Gaussian distribution. By controlling the mutual information capacity, we separate the continuous visual information of multiple views and effectively extract their common discrete cluster information. Experimental results demonstrate that Multi-VAE provides disentangled and interpretable visual representations, outperforming state-of-the-art methods in terms of clustering performance.