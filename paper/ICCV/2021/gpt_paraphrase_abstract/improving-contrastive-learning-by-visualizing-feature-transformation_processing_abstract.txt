This paper introduces a novel approach to enhance the effectiveness of contrastive self-supervised learning through feature-level data manipulation. Unlike traditional data augmentation techniques, the proposed method focuses on the design of positive and negative pairs. A visualization scheme is developed to analyze the distribution of positive and negative scores, providing insights into the learning process. Based on these observations, the authors propose Feature Transformation techniques such as extrapolation of positives and interpolation among negatives. These operations aim to create harder positives and diversified negatives, respectively, improving the model's ability to be view-invariant and discriminative. The experimental results demonstrate that the proposed Feature Transformation approach achieves significant accuracy improvements over baseline methods on ImageNet-100 and ImageNet-1K datasets. Furthermore, the model's successful transferability to downstream tasks suggests reduced task-bias. The paper also provides access to visualization tools and codes for further exploration.