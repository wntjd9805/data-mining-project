The performance of computer vision models greatly improves with more labeled data, but obtaining labeled data is expensive. To address this, active learning (AL) and semi-supervised learning (SSL) are commonly used. However, current methods combining SSL and AL still rely on labeled data for training fully supervised task models and suffer from mismatch issues. To overcome these limitations, we propose a graph-based SSL-AL framework that maximizes the potential of SSL task models and facilitates effective SSL-AL interaction. Our framework employs graph-based label propagation in SSL to assign virtual labels to unlabeled samples, enhancing AL by considering the structural distribution of AL samples. AL, in turn, identifies samples near cluster boundaries to improve SSL label propagation through the use of adversarial examples. This closed-loop information exchange leads to mutual enhancement of SSL and AL. Experimental results demonstrate that our method outperforms state-of-the-art approaches on classification and segmentation benchmarks.