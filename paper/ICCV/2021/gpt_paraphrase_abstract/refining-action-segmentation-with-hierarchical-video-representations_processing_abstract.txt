This paper introduces the Hierarchical Action Segmentation Refiner (HASR), a method that improves the temporal action segmentation results obtained from different models by considering the overall context of a video in a hierarchical manner. The proposed model utilizes a backbone model for action segmentation to estimate the video's segmentation and extracts segment-level representations based on frame-level features. It also extracts a video-level representation based on these segment-level representations. By utilizing these hierarchical representations, the model can understand the overall context of the video and correct segment labels that are out of context. HASR can be integrated into various action segmentation models (MS-TCN, SSTDA, ASRF) and enhances their performance on challenging datasets (GTEA, 50Salads, and Breakfast). For instance, in the 50Salads dataset, the segmental edit score improves from 67.9% to 77.4% (MS-TCN), from 75.8% to 77.3% (SSTDA), and from 79.3% to 81.0% (ASRF). Furthermore, HASR can refine the segmentation results even from unseen backbone models that were not used during its training, demonstrating its generalization capability. This ability to boost existing approaches for temporal action segmentation makes HASR a valuable tool. The code for implementing HASR is available at https://github.com/cotton-ahn/HASR_iccv2021.