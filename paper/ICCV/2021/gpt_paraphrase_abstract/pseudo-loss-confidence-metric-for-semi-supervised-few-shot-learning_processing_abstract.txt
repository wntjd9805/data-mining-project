This study introduces a new approach called pseudo-loss confidence metric (PLCM) for semi-supervised few-shot learning. The goal is to train a classifier that can adapt to new tasks using limited labeled data and a fixed amount of unlabeled data. Most existing methods in this domain select pseudo-labeled data from the unlabeled set based on task-specific confidence estimation. 

In PLCM, data credibility is measured by the loss distribution of pseudo-labels, taking into account multiple tasks. The pseudo-labeled data from different tasks are mapped to a unified metric space using the pseudo-loss model, enabling the learning of the prior pseudo-loss distribution. The confidence of pseudo-labeled data is then estimated based on the distribution component confidence of its pseudo-loss. This allows for the selection of highly reliable pseudo-labeled data to enhance the classifier's performance. 

To address the issue of pseudo-loss distribution shift and improve the effectiveness of the classifier, a multi-step training strategy is proposed. This strategy is coordinated with class balance measures such as class-apart selection and class weight. 

Experimental results on four popular benchmark datasets demonstrate that the proposed approach effectively selects pseudo-labeled data and achieves state-of-the-art performance in semi-supervised few-shot learning.