This paper presents a new approach called ROMP for regressing multiple 3D people from a single RGB image. Unlike existing methods that use a multi-stage pipeline, ROMP performs the regression in a one-stage fashion without the need for bounding boxes. The proposed method learns a per-pixel representation by simultaneously predicting a Body Center heatmap and a Mesh Parameter map. Through a body-center-guided sampling process, the body mesh parameters of all people in the image can be easily extracted. This fine-grained representation allows ROMP to be more robust to occlusion and achieve superior performance compared to state-of-the-art methods on challenging multi-person benchmarks. The experiments conducted on crowded and occluded datasets demonstrate the robustness of ROMP under various types of occlusion. The code for ROMP is publicly available, making it the first real-time implementation of monocular multi-person 3D mesh regression.