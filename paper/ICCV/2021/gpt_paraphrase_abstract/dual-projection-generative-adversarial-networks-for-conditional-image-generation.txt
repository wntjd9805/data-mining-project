Conditional Generative Adversarial Networks (cGANs) are advanced generative models that can generate high-quality images by learning joint data-label distributions. However, effectively incorporating class information into the generator and discriminator during training is a challenge. There are two approaches to achieve class conditioning in the discriminator: (1) directly including labels as input or (2) involving labels in an auxiliary classification loss. The former aligns the distributions of class-conditioned fake and real data, while the latter aligns the distributions of data-conditioned classes. It is important to note that class separability does not guarantee sample quality, and if features of different classes are mapped to the same point and become inseparable, the discriminator cannot provide useful guidance for the generator.To address this issue, we propose the Dual Projection GAN (P2GAN) model, which aims to find a balance between data matching and label matching. Additionally, we introduce an improved cGAN model with Auxiliary Classification that directly aligns the conditional distributions of fake and real data by minimizing their f-divergence. We evaluate the performance of our proposed models on both synthetic and real-world datasets, including CIFAR100, ImageNet, and VGGFace2. The experiments demonstrate the effectiveness of our models in generating high-quality images.