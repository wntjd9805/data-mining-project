We propose a novel method for generating high-resolution semantic images. Our approach involves using one main image generator along with multiple generators specific to different object classes. The main generator produces high-quality images based on a segmentation map. To enhance the quality of individual objects, we train separate class-specific Generative Adversarial Networks (GANs). This approach offers several advantages, such as dedicated weights for each class, aligned data for each model, additional training data from various sources, potential for higher resolution and quality, and easy manipulation of specific objects within the image. Experimental results demonstrate that our method can generate high-quality, high-resolution images while also providing object-level control through the use of class-specific generators.