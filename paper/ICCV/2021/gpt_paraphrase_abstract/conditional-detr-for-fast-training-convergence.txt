The DETR approach, which utilizes transformer encoder and decoder architecture for object detection, has shown promising results. However, it suffers from slow training convergence. To address this issue, we propose a solution called conditional DETR. Our approach introduces a conditional cross-attention mechanism that improves the efficiency of DETR training. The key idea is to incorporate a conditional spatial query from the decoder embedding, allowing each cross-attention head to focus on a specific region, such as an object extremity or a region inside the object box. This reduces the reliance on content embeddings and makes the training process easier. Experimental results demonstrate that conditional DETR achieves convergence 6.7× faster for R50 and R101 backbones, and 10× faster for stronger backbones like DC5-R50 and DC5-R101. The code for conditional DETR can be found at https://github.com/Atten4Vis/ConditionalDETR.