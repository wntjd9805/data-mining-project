The study focuses on gait recognition, which has become a popular research area. However, accurately representing the subtle differences in gait patterns in the spatial domain is challenging. The researchers propose a new network called the context-sensitive temporal feature learning (CSTL) network, which incorporates temporal contextual information by aggregating temporal features at different scales. This allows the network to adaptively enhance important scales and suppress less important ones. To address misalignment issues caused by temporal operations, a salient spatial feature learning (SSFL) module is introduced to extract the most discriminative parts across the entire sequence. The proposed approach achieves both adaptive temporal learning and salient spatial mining simultaneously. Experimental results on two datasets demonstrate the state-of-the-art performance of the proposed method. The rank-1 accuracies achieved on the CASIA-B dataset are 98.0%, 95.4%, and 87.0% under normal walking, bag-carrying, and coat-wearing conditions, respectively. On the OU-MVLP dataset, a rank-1 accuracy of 90.2% is achieved. The source code for the proposed method will be made available at https://github.com/OliverHxh/CSTL.