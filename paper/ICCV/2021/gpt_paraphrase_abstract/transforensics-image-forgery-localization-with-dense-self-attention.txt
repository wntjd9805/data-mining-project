Modern image editing tools and techniques have made it increasingly difficult to detect tampered images, posing challenges for image forensics and authenticity verification. To address this problem, we propose TransForensics, an innovative approach inspired by Transformers. Our framework consists of two key components: dense self-attention encoders and dense correction modules. The former enables modeling of global context and pairwise interactions between local patches at various scales, while the latter enhances transparency of hidden layers and corrects outputs from different branches. In comparison to traditional and deep learning methods, TransForensics not only captures distinguishing representations and generates high-quality mask predictions, but also overcomes limitations related to tampering types and patch sequence orders. Through experiments on standard benchmarks, our results demonstrate that TransForensics significantly outperforms existing state-of-the-art methods.