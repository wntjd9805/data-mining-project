Generating complex scenes with multiple objects and their interactions remains a challenge in image generation. To address this, scene graphs, which represent scenes using objects and their relationships, offer a more semantically grounded alternative to images. We propose that generative models for scene graphs can effectively learn the underlying semantic structure of real-world scenes and generate realistic novel scenes. In this study, we introduce a new task of unconditionally generating semantic scene graphs. We develop SceneGraphGen, a deep auto-regressive model that learns the probability distribution of labeled and directed graphs using a hierarchical recurrent architecture. The model takes a seed object as input and generates a scene graph step by step, with each step generating an object node and relationship edges connecting to previous nodes. Our results demonstrate that the scene graphs generated by SceneGraphGen exhibit diversity and adhere to semantic patterns found in real-world scenes. Furthermore, we showcase the practical applications of the generated graphs in image synthesis, anomaly detection, and scene graph completion.