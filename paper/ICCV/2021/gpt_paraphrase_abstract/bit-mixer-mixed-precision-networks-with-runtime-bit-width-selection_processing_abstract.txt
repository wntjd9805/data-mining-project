Mixed-precision networks enable different bit-width quantization for each layer in the network. However, current approaches require predefining the bit-width for each layer during training, limiting flexibility when device characteristics change during runtime. In this study, we introduce Bit-Mixer, the first method to train a meta-quantized network that allows any layer to change its bit-width during test time without affecting overall network accuracy. We make two key contributions: (a) Transitional Batch-Norms, and (b) a 3-stage optimization process that effectively trains such a network. Our method enables mixed precision networks with the desired flexibility for on-device deployment while maintaining accuracy. The code for our method will be made publicly available.