Most cross-modal knowledge distillation (KD) methods in video understanding are designed for classifying trimmed videos. However, action detection requires not only categorizing actions but also localizing them in untrimmed videos. This task necessitates transferring knowledge about temporal relations, which is lacking in existing cross-modal KD frameworks. To address this, we propose a KD framework that learns an augmented RGB representation for action detection by leveraging additional modalities during training. Our framework consists of two levels of distillation. At the atomic level, the RGB student learns sub-representations of actions from the teacher in a contrastive manner. At the sequence level, the student learns temporal knowledge from the teacher, including Global Contextual Relations and Action Boundary Saliency. The result is an Augmented-RGB stream that achieves competitive performance similar to a two-stream network but only requires RGB input during inference. Extensive experiments demonstrate the effectiveness of our proposed distillation framework, which outperforms other popular cross-modal distillation methods in the action detection task.