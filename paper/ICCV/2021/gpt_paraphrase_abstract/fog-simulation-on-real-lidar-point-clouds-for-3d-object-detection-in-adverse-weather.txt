This study addresses the difficult task of detecting 3D objects using LiDAR in foggy weather conditions. Gathering and annotating data in such conditions is time-consuming, labor-intensive, and expensive. To overcome this challenge, the authors propose a method that simulates realistic fog in clear-weather scenes. By doing so, they can repurpose existing datasets captured in clear weather for their task. The main contributions of this work are twofold. Firstly, the authors develop a fog simulation technique that can be applied to any LiDAR dataset, allowing for the generation of large-scale foggy training data without extra costs. These partially synthetic data can be used to enhance the performance of various perception methods, including 3D object detection, tracking, and simultaneous localization and mapping, on real foggy data. Secondly, through extensive experiments using state-of-the-art detection approaches, the authors demonstrate that their fog simulation method significantly improves the performance of 3D object detection in the presence of fog. This study also presents the first strong 3D object detection baselines on the Seeing Through Fog dataset. The code for the fog simulation is available at www.trace.ethz.ch/lidar fog simulation.