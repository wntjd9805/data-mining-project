We present ARCH++, a new method for creating 3D avatars with different clothing styles using images. Our avatars are highly realistic and ready for animation, both in the visible regions from the input views and in the regions that are not visible. While previous research has shown promise in reconstructing clothed humans with different body shapes, we have identified limitations that result in sub-optimal reconstruction quality. In this paper, we address these limitations with ARCH++. Firstly, we introduce a point-based geometry encoder that accurately describes the underlying 3D human body, replacing the previous manually crafted features. Secondly, to tackle the ambiguity in occupancy caused by changes in the topology of clothed humans in a standard pose, we propose a co-supervising framework that estimates occupancy in both the posed and canonical spaces simultaneously. Lastly, we use image-to-image translation networks to enhance the geometric details and texture on the reconstructed surface, resulting in improved fidelity and consistency from different viewpoints. Our experiments demonstrate that ARCH++ outperforms existing methods in terms of reconstruction quality and realism, as shown by both public benchmarks and user studies.