This study proposes a Multi-robust ReID system called Expert Adversarial Attack Detection (MEAAD) to address the vulnerability of deep neural network-based person re-identification (ReID) systems to visually inconspicuous adversarial perturbations. The MEEAD approach detects adversarial attacks by examining context inconsistency in three ways: 1) the embedding distances between a perturbed query person image and its top-K retrievals are generally larger than those between a benign query image and its top-K retrievals, 2) the embedding distances among the top-K retrievals of a perturbed query image are larger than those of a benign query image, and 3) the top-K retrievals of a benign query image obtained with multiple expert ReID models tend to be consistent, which is not preserved when attacks are present. Experimental results on the Market1501 and DukeMTMC-ReID datasets demonstrate that MEAAD effectively detects various adversarial attacks with a high ROC-AUC of over 97.5%, making it the first adversarial attack detection approach for ReID.