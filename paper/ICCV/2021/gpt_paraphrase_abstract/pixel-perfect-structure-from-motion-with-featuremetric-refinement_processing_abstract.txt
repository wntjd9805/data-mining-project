The traditional method of image matching for 3D reconstruction often produces poorly-localized features and large errors in the final geometry. This paper proposes a new approach that directly aligns low-level image information from multiple views to refine the keypoint locations and camera poses. The refinement process is robust to detection noise and appearance changes, as it optimizes a featuremetric error using dense features predicted by a neural network. This approach significantly improves the accuracy of camera poses and scene geometry, even in challenging viewing conditions and with off-the-shelf deep features. The system can handle large image collections, making it suitable for crowd-sourced localization at scale. The code for this system is publicly available as an add-on to the popular SfM software COLMAP on GitHub.