In this study, we propose a Region-aware Fusion Network (RFNet) to improve brain tumor segmentation in cases where certain modalities of magnetic resonance imaging (MRI) images are missing. Existing methods rely on multi-modal data for accurate segmentation, but the absence of certain images can lead to poor performance. RFNet addresses this issue by adaptively and effectively utilizing available modalities for segmentation. We introduce a Region-aware Fusion Module (RFM) within RFNet to fuse modal features based on different brain tumor regions. This allows RFNet to effectively segment tumor regions even when some modalities are missing. Additionally, we develop a segmentation-based regularizer to address the training challenges caused by incomplete multi-modal data. This regularizer not only provides segmentation results from fused modal features but also individually segments each image modality. This forces each modal encoder to learn discriminative features, thereby improving the representation ability of the fused features. Experimental results on BRATS2020, BRATS2018, and BRATS2015 datasets demonstrate that RFNet outperforms existing methods significantly.