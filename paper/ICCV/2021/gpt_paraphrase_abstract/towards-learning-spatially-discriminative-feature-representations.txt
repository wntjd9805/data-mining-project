The traditional CNN classifier typically consists of a feature extractor followed by a linear layer for classification. We introduce a new loss function called CAM-loss that constrains the embedded feature maps using class activation maps (CAMs). These CAMs identify the spatially discriminative regions of an image for specific categories. By using CAM-loss, the feature representations become more discriminative as the backbone expresses the features of the target category while suppressing the features of non-target categories or background. The implementation of CAM-loss is straightforward in any CNN architecture without significant additional parameters or calculations. Our experimental results demonstrate the effectiveness of CAM-loss across various network structures and its compatibility with mainstream regularization methods, leading to improved image classification performance. Furthermore, CAM-loss exhibits strong generalization ability in transfer learning and few-shot learning tasks. Building upon CAM-loss, we propose a novel method called CAAM-CAM matching knowledge distillation. This method utilizes CAMs generated by the teacher network to supervise the CAAMs generated by the student network, resulting in enhanced accuracy and convergence rate for the student network.