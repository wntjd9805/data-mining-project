The detection of human-object interactions (HOI) is a crucial task in computer vision, aimed at identifying and localizing interactions between humans and objects. Previous research has primarily focused on analyzing visual and linguistic features of humans and objects, overlooking the valuable high-level and semantic relationships present in the image. These relationships provide contextual and detailed relational knowledge necessary for accurate HOI inference. To address this limitation, we propose a novel method called SG2HOI, which leverages scene graph information for HOI detection. SG2HOI incorporates scene graph information in two ways: (1) by embedding a scene graph into a global context clue, which serves as scene-specific environmental context, and (2) by using a relation-aware message-passing module to gather relationships from objects' neighborhood and transfer them into interactions. Experimental evaluation demonstrates that our SG2HOI method surpasses the state-of-the-art approaches on two benchmark HOI datasets: V-COCO and HICO-DET. The code for our method is available at https://github.com/ht014/SG2HOI.