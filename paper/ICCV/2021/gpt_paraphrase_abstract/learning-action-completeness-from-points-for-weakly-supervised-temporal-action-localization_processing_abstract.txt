We address the problem of localizing temporal intervals of actions using only a single frame label for each action instance during training. Previous approaches have struggled with this due to a lack of labeled data, resulting in incomplete action predictions. In this study, we propose a new framework that generates dense pseudo-labels to guide the model towards completeness. Specifically, we identify pseudo background points to supplement the action labels and then search for the optimal sequence that likely contains complete action instances while aligning with the seeds. To learn completeness from this sequence, we introduce two novel losses that compare action instances with background ones based on action score and feature similarity. Our experimental results demonstrate that our approach significantly improves the model's ability to locate complete action instances, particularly at high IoU thresholds. We also show that our method outperforms existing state-of-the-art methods on four benchmarks: THUMOS'14, GTEA, BEOID, and ActivityNet. Notably, our method achieves comparable performance to recent fully-supervised methods at a much lower annotation cost. The code for our framework is available at https://github.com/Pilhyeon.