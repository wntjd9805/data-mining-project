We have created a new dataset called ACDC, which is designed to train and test semantic segmentation methods for self-driving cars under adverse visual conditions. Currently, existing datasets are limited in their ability to handle adverse conditions or are too small in scale. ACDC consists of 4006 images, evenly distributed across four common adverse conditions: fog, nighttime, rain, and snow. Each image in ACDC includes a high-quality, fine pixel-level semantic annotation, a corresponding image of the same scene taken under normal conditions, and a binary mask that differentiates between regions of clear and uncertain semantic content within the image. This dataset supports both standard semantic segmentation and a newly introduced uncertainty-aware semantic segmentation. Through an empirical study, we demonstrate the challenges that ACDC poses to current supervised and unsupervised approaches, highlighting the value of our dataset in advancing the field. Our dataset and benchmark are publicly available for further research.