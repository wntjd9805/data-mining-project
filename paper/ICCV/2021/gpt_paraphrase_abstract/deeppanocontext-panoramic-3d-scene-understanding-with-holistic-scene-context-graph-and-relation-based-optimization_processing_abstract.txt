This paper introduces a novel approach for panoramic 3D scene understanding by exploiting the larger field-of-view and enriched scene context information provided by panorama images. The method aims to recover the 3D layout of the room as well as the shape, pose, position, and semantic category of each object in the scene using a single full-view panorama image. To make the most of the contextual information, the authors propose a graph neural network based context model to predict the relationship between objects and room layout. Additionally, they introduce a differentiable relationship-based optimization module to optimize object arrangement using well-designed objective functions in real-time. To address the limitations of existing data, the authors create a synthetic dataset with diverse room layouts, furniture placements, and realistic image quality for comprehensive panoramic 3D scene understanding. Experimental results demonstrate that the proposed method outperforms existing approaches in terms of both geometry accuracy and object arrangement. The code for this method is available at https://chengzhag.github.io/publication/dpc.