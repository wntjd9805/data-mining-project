In this paper, we propose a pyramid point cloud transformer network (PPT-Net) to extract discriminative global descriptors from point clouds for efficient retrieval in the place recognition task. We address the challenge of extracting local features from sparse point clouds by developing a pyramid point transformer module that learns the spatial relationship of neighboring points. We introduce grouped self-attention to extract discriminative local features, which enhances long-term dependencies and reduces computational cost. To obtain discriminative global descriptors, we construct a pyramid VLAD module that aggregates multi-scale feature maps. By applying VLAD pooling and context gating mechanism, we adaptively weight the multi-scale global context information into the final global descriptor. Our method achieves state-of-the-art results on the point cloud based place recognition task, as demonstrated on the Oxford dataset and three in-house datasets. The code for our method is available at https://github.com/fpthink/PPT-Net.