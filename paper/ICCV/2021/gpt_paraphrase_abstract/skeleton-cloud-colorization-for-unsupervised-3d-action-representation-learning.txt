Skeleton-based human action recognition has gained significant attention, but most research focuses on supervised learning, which requires annotated action sequences that are costly to collect. This study explores unsupervised representation learning for skeleton action recognition by introducing a novel technique called skeleton cloud colorization. This technique learns skeleton representations from unlabeled skeleton sequence data. In this approach, a skeleton action sequence is represented as a 3D skeleton cloud, and each point in the cloud is colorized based on its temporal and spatial orders in the original unannotated sequence. By leveraging the colorized skeleton point cloud, an auto-encoder framework is designed to effectively learn spatial-temporal features from the artificial color labels of skeleton joints. The proposed skeleton cloud colorization approach is evaluated using action classifiers trained under different configurations, including unsupervised, semi-supervised, and fully-supervised settings. Extensive experiments conducted on NTU RGB+D and NW-UCLA datasets demonstrate the superiority of the proposed method over existing unsupervised and semi-supervised 3D action recognition methods. Furthermore, the proposed approach achieves competitive performance in supervised 3D action recognition as well.