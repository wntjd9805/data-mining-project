This study focuses on addressing the challenging task of scene parsing by considering the correlation between pixels in an image. Instead of treating pixels independently, the study recognizes that pixels from the same semantic region are highly correlated. To take advantage of these correlations, the study treats each region in the image as a whole and captures the structure topology and affinity among different regions. The study divides the feature maps into regions and extracts global features from them. A directed graph is then constructed, with nodes representing regional features and bi-directional edges representing the affinities between regions. The affinity-aware nodes in the graph are transferred back to the corresponding regions of the image to model region dependencies and reduce unrealistic results. Additionally, a region-level loss is proposed to enhance the correlation among pixels. This loss evaluates all pixels in a region as a whole and encourages the network to learn exclusive regional features for each class. By adopting this approach, the study achieves state-of-the-art segmentation results on PASCAL-Context, ADE20K, and COCO-Stuff consistently.