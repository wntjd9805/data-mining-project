Outlier rejection, also known as inlier set optimization, plays a crucial role in various computer vision applications, such as filtering point-matches in camera pose estimation or estimating planes and normals in point clouds. While multiple methods exist, dealing with large-scale scenarios leads to a combinatorial explosion of potential solutions. State-of-the-art techniques like RANSAC, Hough transform, or Branch&Bound necessitate a minimum inlier ratio or prior knowledge to remain practical. However, in certain cases like camera posing in extremely large scenes, these approaches become ineffective due to exponential runtime growth. To address this issue, we propose an efficient and versatile algorithm for outlier rejection based on the intersection of k-dimensional surfaces in Rd. We offer a framework for formulating various geometric problems as finding a point in Rd that maximizes the number of nearby surfaces, thereby increasing the number of inliers. The resulting algorithm exhibits linear worst-case complexity and has a runtime that depends on the desired proximity of a query to its result, surpassing competing algorithms. Additionally, it does not require specific domain bounds. Our approach incorporates a space decomposition scheme that limits the number of computations by progressively rounding and grouping surfaces. Through our recipe and open-source code, individuals can develop fast solutions for new problems across diverse domains. We validate our method by applying it to several camera posing problems involving numerous matches and a low inlier ratio. Our approach achieves state-of-the-art results while significantly reducing processing times.