The use of deep neural networks has led to significant advancements in face recognition. However, collecting large-scale real-world training data for this task has proven to be challenging due to label noise and privacy concerns. Additionally, existing face recognition datasets lack detailed annotations on attributes such as pose and expression, limiting our understanding of how these attributes affect face recognition. To address these issues, we propose using synthetic face images, specifically a dataset called SynFace. We compare the performance of state-of-the-art face recognition models trained on synthetic and real face images and identify the causes of the performance gap, such as poor intra-class variations and domain differences between synthetic and real face images. To bridge this gap, we introduce identity mixup and domain mixup techniques in SynFace, which show the potential of synthetic data for improving face recognition. Additionally, our controllable face synthesis model allows us to manipulate various factors in synthetic face generation, such as pose, expression, illumination, number of identities, and samples per identity. Through empirical analysis, we provide insights on how to effectively utilize synthetic data for face recognition.