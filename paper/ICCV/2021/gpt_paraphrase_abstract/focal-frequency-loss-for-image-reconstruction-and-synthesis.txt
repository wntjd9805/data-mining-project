The advancement of generative models has greatly improved image reconstruction and synthesis. However, there are still discrepancies between real and generated images, particularly in the frequency domain. This study aims to address this issue by proposing a new focal frequency loss. This loss function allows the model to focus on difficult-to-synthesize frequency components by reducing the importance of easier ones. By incorporating this objective function alongside existing spatial losses, we can mitigate the loss of crucial frequency information caused by the inherent biases of neural networks. Our experiments demonstrate the effectiveness and versatility of the focal frequency loss in enhancing popular models like VAE, pix2pix, and SPADE, both in terms of perceptual quality and quantitative performance. Furthermore, we showcase its potential in improving StyleGAN2.1 and 2. Overall, narrowing the gaps in the frequency domain can significantly enhance image reconstruction and synthesis quality.