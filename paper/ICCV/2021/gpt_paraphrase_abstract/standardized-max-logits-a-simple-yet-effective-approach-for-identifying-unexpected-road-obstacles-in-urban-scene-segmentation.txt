Detecting unexpected objects on roads, such as dogs, is crucial for safety-critical applications. Current methods either rely on external datasets or require additional training, which can be labor-intensive or time-consuming. One alternative is to use prediction scores from a pre-trained network, like the max logits, to detect these objects. However, the distribution of max logits for each class is different, leading to poor performance in urban-scene segmentation. To address this, we propose a simple yet effective approach that standardizes the max logits to align the distributions and reflect their relative meanings within each class. Additionally, we consider local regions from two perspectives, assuming neighboring pixels share similar semantic information. Unlike previous methods, our approach does not rely on external datasets or require additional training, making it widely applicable to pre-trained segmentation models. We achieve a new state-of-the-art performance on the Fishyscapes Lost & Found leaderboard with our straightforward approach. Our code is publicly available at the provided link.