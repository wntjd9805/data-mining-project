Pathdreamer is a visual world model designed to enhance the navigation capabilities of computational agents in unfamiliar indoor environments. By utilizing previous visual observations, Pathdreamer generates realistic high-resolution 360Â° visual observations, including RGB, semantic segmentation, and depth, for viewpoints that have not been visited before. In areas of uncertainty, such as predicting what is around corners or imagining the contents of unseen rooms, Pathdreamer can generate diverse scenes, enabling agents to sample multiple realistic outcomes for a given trajectory. The usefulness and accessibility of Pathdreamer's visual, spatial, and semantic knowledge about human environments are demonstrated through its application in the Vision-and-Language Navigation (VLN) task. It is shown that planning ahead with Pathdreamer provides approximately half the benefit of actually observing unobserved parts of the environment. Pathdreamer holds promise in enabling model-based approaches to challenging navigation tasks involving object specification and VLN.