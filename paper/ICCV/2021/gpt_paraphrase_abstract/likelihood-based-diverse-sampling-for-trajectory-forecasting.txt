Forecasting complex vehicle and pedestrian multi-modal distributions is important but challenging. Normalizing flows (NF) have become popular for modeling such distributions, but they often fail to capture all the modes in the underlying distribution when generating independent samples. To address this limitation, we propose a method called Likelihood-Based Diverse Sampling (LDS). LDS improves the quality and diversity of trajectory samples from a pre-trained flow model by producing a set of trajectories instead of individual samples. We train LDS using gradients from the model to optimize an objective function that rewards high likelihood for individual trajectories and encourages spatial separation among trajectories. Our experiments show that LDS outperforms existing neural diverse forecasting methods for various pre-trained flow models and conditional variational autoencoder (CVAE) models. Importantly, LDS can also be used for transductive trajectory forecasting, where diverse forecasts are trained on-the-fly on unlabeled test examples. LDS is easy to implement and offers a simple plug-in improvement over baselines on challenging benchmarks. The code is available at the provided GitHub link.