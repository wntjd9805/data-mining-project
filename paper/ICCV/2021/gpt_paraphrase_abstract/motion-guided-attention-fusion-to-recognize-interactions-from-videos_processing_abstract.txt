We propose a new method for accurately identifying detailed interactions in videos. This approach builds upon previous techniques that utilize dual-stream systems, but we differentiate between the static and dynamic aspects of objects and interactions by incorporating separate pathways for motion and object detection. To capture the temporal aspects of actions, we introduce a Motion-Guided Attention Fusion module that combines features from the motion pathway with those obtained from object detections. Our method demonstrates strong generalization capabilities across different appearances and effectively recognizes actions involving unfamiliar objects. We evaluate our approach on the compositional action recognition task using the Something-Something-v2 dataset, surpassing the performance of existing state-of-the-art methods. Additionally, we showcase the ability of our method to excel in real-world scenarios by achieving state-of-the-art results in recognizing humans assembling various IKEA furniture pieces on the IKEA-ASM dataset.