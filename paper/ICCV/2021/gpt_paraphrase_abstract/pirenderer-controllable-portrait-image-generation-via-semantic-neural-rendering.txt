This paper introduces a Portrait Image Neural Renderer (PIRenderer) that allows for the generation of portrait images by controlling the movements of existing faces. The model utilizes three-dimensional morphable face models (3DMMs) to modify the parameters and achieve accurate and intuitive modifications. The proposed PIRenderer is capable of generating photo-realistic portraits with realistic movements. The model's superiority is demonstrated through experiments on both direct and indirect editing tasks. Additionally, the model is extended to address the audio-driven facial reenactment task by extracting sequential motions from audio inputs. The PIRenderer can generate coherent videos with convincing movements using just a single reference image and an audio stream. The paper also provides example results of the PIRenderer's capabilities. The source code for the model is available on GitHub.