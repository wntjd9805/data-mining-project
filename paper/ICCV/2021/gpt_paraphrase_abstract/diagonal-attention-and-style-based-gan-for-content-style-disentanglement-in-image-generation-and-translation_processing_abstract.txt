This study focuses on disentangling spatial contents and styles in image generative models. While StyleGAN can generate content feature vectors, its control over spatial content variations is limited and the disentanglement of global content and styles is incomplete. To address this, the researchers propose a novel approach called hierarchical adaptive Diagonal spatialATtention (DAT) layers. By combining DAT and AdaIN, their method enables the separate manipulation of spatial contents and styles at different levels of granularity. The researchers also integrate their generator into the GAN inversion framework, allowing for flexible control over the content and style of translated images in multi-domain image translation tasks. Through experiments with various datasets, the proposed method is shown to outperform existing models in disentanglement scores and offers more flexible control over spatial features in the generated images.