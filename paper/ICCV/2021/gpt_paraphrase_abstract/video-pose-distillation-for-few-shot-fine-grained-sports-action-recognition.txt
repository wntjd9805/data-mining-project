Human pose is an important factor in understanding sports actions in detail. However, existing pose estimators often fail to perform reliably on sports videos due to various challenges such as motion blur and occlusions. As a result, downstream tasks like action recognition suffer from low accuracy when relying on pose information. While end-to-end learning can bypass the need for pose, it requires a large number of labels to generalize well.To address these issues, we propose a technique called Video Pose Distillation (VPD) which enables learning features for new video domains, specifically individual sports that pose challenges for pose estimation. In VPD, a student network is trained to extract robust pose features from RGB frames in the sports video. These features are designed to match the output of a pretrained teacher pose detector whenever the pose is considered reliable. By combining the strengths of both pose estimation and end-to-end learning, VPD leverages the rich visual patterns present in raw video frames while ensuring that the learned features align with the athletes' pose and motion in the target video domain. This prevents the model from overfitting to irrelevant patterns unrelated to athletes' motion.Experimental results on four real-world sports video datasets demonstrate the effectiveness of VPD features in enhancing performance on few-shot, fine-grained action recognition, retrieval, and detection tasks. Importantly, our technique achieves this improvement without requiring additional ground-truth pose annotations.