This paper addresses the challenge of estimating the pose of garments at the category level. Garments have a wide range of possible configurations, which are typically described by the 3D locations of each vertex on the garment's surface. However, garments often experience self-occlusion, particularly when folded or crumpled, making it difficult to perceive their complete 3D surface. To overcome this challenge, the authors propose Garment-Nets, a method that formulates the problem of estimating garment pose as a shape completion task in a canonical space. This canonical space is defined based on instances of garments within a category and represents the shared category-level pose. By mapping the observed partial surface to the canonical space and completing it, Garment-Nets generate a representation of the garment's full configuration using a complete 3D mesh with canonical coordinate labels for each vertex. To effectively handle the thin 3D structure of garments, the authors introduce a novel 3D shape representation using the generalized winding number field. Experimental results demonstrate that Garment-Nets can generalize to unseen garment instances and outperform alternative approaches. The code and data for Garment-Nets can be accessed at https://garmentnets.cs.columbia.edu.