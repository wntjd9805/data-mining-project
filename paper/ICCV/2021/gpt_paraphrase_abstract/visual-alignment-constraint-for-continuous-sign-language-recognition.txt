This study focuses on addressing the problem of overfitting in Vision-based Continuous Sign Language Recognition (CSLR) training. Previous research has shown that the iterative training scheme can partially solve this problem but at the cost of increased training time. The authors revisit this scheme and realize that training the feature extractor adequately is crucial for solving overfitting. Therefore, they propose a Visual Alignment Constraint (VAC) to enhance the feature extractor by incorporating alignment supervision. The VAC consists of two auxiliary losses: one for visual features and the other for enforcing prediction alignment between the feature extractor and the alignment module. Additionally, the authors propose two metrics to measure the prediction inconsistency between the feature extractor and the alignment module, which reflect overfitting. Experimental results on two challenging CSLR datasets demonstrate that the proposed VAC enables end-to-end trainable CSLR networks and achieves competitive performance.