We propose a method called Distortion-Guided Network (DG-Net) to enhance the quality of underwater images by mitigating the negative effects of water surface fluctuations. Our approach involves using a distortion map to guide the training of a convolutional neural network. This distortion map represents the displacement of pixels caused by water refraction. Firstly, we employ a physically constrained convolutional network to estimate the distortion map based on the refracted image. Then, we utilize a generative adversarial network, guided by the distortion map, to restore the original sharp and distortion-free image. By leveraging the distortion map, which establishes correspondences between the distorted and undistorted images, our network is able to make more accurate predictions. We evaluate the performance of our approach on various real and synthetic underwater image datasets and demonstrate its superiority over existing algorithms, particularly when dealing with significant distortions. Additionally, we showcase the effectiveness of our method in complex scenarios, such as drone-captured outdoor swimming pool images and cellphone camera-captured indoor aquarium images.