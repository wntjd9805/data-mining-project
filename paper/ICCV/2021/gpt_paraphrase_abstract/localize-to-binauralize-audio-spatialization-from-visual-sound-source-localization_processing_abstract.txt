The goal of this study is to synthesize binaural audio for videos that only have monaural audio. The researchers propose a weakly semi-supervised approach, where they use a proxy task that requires binaural audio as supervision for generating binaural audio. They introduce a two-stage architecture called the Localize-to-Binauralize Network (L2BNet) to accomplish this. The first stage of L2BNet, the Stereo Generation (SG) network, generates two-stream audio from monaural audio using visual frame information. In the second stage, the Audio Localization (AL) network uses the synthesized two-stream audio to localize sound sources in the visual frames. The entire network is trained end-to-end so that the AL network provides the necessary supervision for the SG network. The results of experiments show that their weakly-supervised framework generates two-stream audio with binaural cues. User study results further confirm that their proposed approach produces binaural-quality audio with as little as 10% explicit binaural supervision data for the SG network.