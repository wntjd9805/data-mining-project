This paper introduces a novel deep network architecture called Recurrent Multi-Scale Feature Modulation (R-MSFM) for self-supervised monocular depth estimation. R-MSFM employs per-pixel feature extraction, a multi-scale feature modulation module, and an inverse depth update process using a parameter-shared decoder at a fixed resolution. Unlike the traditional coarse-to-fine architecture, R-MSFM maintains both semantically richer and spatially more precise representations, effectively avoiding error propagation. This leads to improved generalization and parameter efficiency. Experimental results demonstrate the superiority of R-MSFM in terms of model size and inference speed, achieving state-of-the-art performance on the KITTI benchmark. The code for R-MSFM is available at https://github.com/jsczzzk/R-MSFM.