The problem of topical domain generalization (DG) involves training models to perform well on a new target domain that has different data statistics compared to the source training domains. In computer vision, data augmentation has been effective in utilizing source data to enhance domain generalization. However, current approaches mainly rely on augmenting the data in image-space, which requires careful design and provides limited diversity in augmented data. We propose that feature augmentation is a more promising approach for DG. We discovered that a simple technique of perturbing the feature embedding with Gaussian noise during training produces a classifier with domain-generalization performance similar to the state-of-the-art methods. To capture more meaningful statistical variations across domains, we estimate the complete class-conditional feature covariance matrix iteratively during training. By subsequently applying joint stochastic feature augmentation, we introduce an effective domain randomization method that perturbs features in the directions of intra-class and cross-domain variability. We evaluate our proposed method on three widely-used domain generalization benchmarks (Digit-DG, VLCS, and PACS) and demonstrate that it outperforms or achieves comparable results to the state-of-the-art methods in all scenarios. We also provide experimental analysis to explain how our method contributes to training a robust and generalizable model.