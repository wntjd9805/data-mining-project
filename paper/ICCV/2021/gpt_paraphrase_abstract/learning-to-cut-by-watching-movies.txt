Video content creation is growing rapidly, but creating engaging stories through video editing remains challenging. The difficulty lies in automating certain aspects of video editing due to the lack of raw video materials. This paper introduces a new task called "raking cut plausibility" in computational video editing. The approach involves leveraging pre-edited content to learn audiovisual patterns that trigger cuts. A dataset of over 10K videos is collected, extracting more than 255K cuts. A model is developed using contrastive learning to distinguish between real and artificial cuts. This model outperforms existing baselines in video cut generation. Human studies conducted on unedited videos confirm that the model produces better cuts compared to random and alternative baselines.