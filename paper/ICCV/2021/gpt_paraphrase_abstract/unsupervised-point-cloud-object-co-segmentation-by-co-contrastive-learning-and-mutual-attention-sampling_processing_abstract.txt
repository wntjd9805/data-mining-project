We introduce a novel task called point cloud object co-segmentation, which aims to segment common 3D objects within a collection of point clouds. Our approach involves solving an object point sampling problem using two deep neural network-based point samplers: an object sampler and a background sampler. The object sampler selects points belonging to common objects, while the background sampler focuses on the remaining points. To capture point-wise correlation across point clouds, we incorporate a mutual attention module into both samplers, enabling the identification of points with strong cross-cloud correlation. After extracting features from the selected points, we optimize the networks using a co-contrastive loss function. This loss function minimizes feature discrepancy among the estimated object points and maximizes feature separation between the estimated object and background points. Our method is applicable to point clouds of any object class, is end-to-end trainable, and does not require point-level annotations. We evaluate our approach on the ScanObjectNN and S3DIS datasets, achieving promising results. The source code for our method is available at https://github.com/jimmy15923/unsup_point_coseg.