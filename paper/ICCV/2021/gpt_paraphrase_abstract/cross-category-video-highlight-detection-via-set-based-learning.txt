Autonomous highlight detection is crucial for improving the efficiency of video browsing on social media platforms. However, in many cases, highlight annotations are not available for the target video category being used. In these situations, one can transfer highlight knowledge from a source video category to the target category to develop an effective highlight detector. This problem, known as cross-category video highlight detection, has not been extensively studied before. To address this practical problem, we propose a Dual-Learner-based Video Highlight Detection (DL-VHD) framework. This framework includes a Set-based Learning module (SL-module) that enhances the conventional pair-based learning by considering the broader context of video segments. We introduce two different learners to capture the distinguishing features of target category videos and the characteristics of highlight moments in the source category. These two types of highlight knowledge are then combined using knowledge distillation. Our experiments on three benchmark datasets demonstrate the effectiveness of the SL-module, and the DL-VHD method outperforms five typical Unsupervised Domain Adaptation (UDA) algorithms in various cross-category highlight detection tasks. The code for our approach is available at https://github.com/ChrisAllenMing/Cross_Category_Video_Highlight.