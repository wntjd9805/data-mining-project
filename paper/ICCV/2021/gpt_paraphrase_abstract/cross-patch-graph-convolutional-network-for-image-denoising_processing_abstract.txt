Deep learning-based methods for image denoising have shown significant improvements compared to traditional methods. However, these methods often use small cropped patches for training due to hardware limitations. This approach overlooks the fact that real noisy images are typically high resolution and fails to consider the contextual dependency between patches in the entire image. To address this, we propose Cross-Patch Net (CPNet), the first deep learning-based method for denoising high resolution images. Additionally, we introduce a novel loss function guided by the noise level map to enhance performance. Our approach effectively utilizes cross-patch contextual dependency, unlike vanilla patch-based training strategies. Generating training data with paired real noisy and noise-free images is challenging, so we present a method to generate realistic sRGB noisy images from clean sRGB images for denoiser training. Experimental results on real-world sRGB images demonstrate the effectiveness of our proposed method, which achieves state-of-the-art performance in practical sRGB noisy image denoising.