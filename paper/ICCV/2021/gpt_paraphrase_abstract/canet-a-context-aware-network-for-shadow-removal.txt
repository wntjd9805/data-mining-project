We introduce a new context-aware network called CANet for shadow removal. CANet transfers contextual information from non-shadow regions to shadow regions in two stages. In Stage-I, a contextual patch matching (CPM) module generates potential matching pairs of shadow and non-shadow patches. The contextual feature transfer (CFT) mechanism then transfers contextual information from non-shadow to shadow regions at different scales. Shadows are removed separately at the L and A/B channels using reconstructed feature maps. In Stage-II, an encoder-decoder refines the results and produces the final shadow removal results. We evaluate CANet on benchmark datasets and real-world shadow images, demonstrating its effectiveness and outperforming existing methods. The source code is available at https://github.com/Zipei-Chen/CANet.