Unsupervised domain adaptation (UDA) methods have shown great potential in improving generalization on unlabeled target domains. However, selecting optimal hyper-parameters is crucial for achieving high accuracy and avoiding negative transfer. However, without labeled target data, it is not possible to perform supervised hyper-parameter validation. This raises the question of how to realistically validate unsupervised adaptation techniques. In this study, we examine existing criteria and find that they are not effective for tuning hyper-parameters. We propose a novel unsupervised validation criterion based on the assumption that a well-trained source classifier should embed target samples of the same class nearby, forming dense neighborhoods in feature space. Our criterion measures the density of soft neighborhoods by computing the entropy of the similarity distribution between points. Compared to other validation methods, our criterion is simpler yet more effective. It can be used to tune hyper-parameters and the number of training iterations in both image classification and semantic segmentation models. The code used for this study is available at https://github.com/VisionLearningGroup/SND.