Hand pose estimation in a three-dimensional space has reached a mature stage, allowing for practical applications involving a single hand. However, accurately estimating the pose of two hands that are closely interacting remains a challenge due to occlusion. In this study, we propose a novel algorithm that effectively estimates hand poses in such complex scenarios. Our algorithm is based on a framework that trains the estimators of both interacting hands together, taking advantage of their interdependence. Additionally, we utilize a GAN-type discriminator to identify physically implausible hand configurations, such as intersecting fingers, and leverage the visibility of joints to improve the estimation of intermediate 2D poses. These techniques are integrated into a single model that learns to detect hands and estimate their poses using a unified accuracy criterion. To the best of our knowledge, this is the first attempt to develop an end-to-end network that can detect and estimate the poses of two closely interacting hands, as well as single hands. Through experiments conducted on three challenging real-world datasets, our algorithm consistently and significantly outperformed existing state-of-the-art methods.