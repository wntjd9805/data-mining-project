This study aims to generate physically realistic hand motion from single color images. Current approaches that estimate motion frame by frame do not directly ensure physical plausibility, such as avoiding penetration or jittering. To address this, the researchers incorporate physical constraints into the per-frame motion estimation process in both spatial and temporal dimensions. They propose a self-supervised learning strategy to train a new encoder-decoder model called TravelNet. The training data for TravelNet is generated by a physics engine using discrete pose states. Inspired by keyframes in animation, TravelNet captures important pose states from hand motion sequences as compact motion descriptors. It is able to extract these key states from perturbations without relying on manual annotations, and reconstruct the motions while preserving fine details and physical plausibility. Experimental results demonstrate that TravelNet's outputs exhibit finger synergism and time consistency. The proposed framework allows for accurate reconstruction and flexible re-editing of hand motions, surpassing existing methods.