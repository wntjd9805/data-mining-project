We propose DTT, a novel single-object discriminative tracker, that improves upon the conventional discriminative model used in end-to-end trackers. Our approach utilizes an encoder-decoder Transformer architecture with self- and encoder-decoder attention mechanisms to exploit rich scene information in an end-to-end manner. This eliminates the need for hand-designed discriminative models. In online tracking, DTT performs dense prediction at all spatial positions, obtaining both the location and bounding box of the target object robustly. DTT is simple and easy to implement, achieving state-of-the-art performance on popular benchmarks (GOT-10k, LaSOT, NfS, and TrackingNet) while running at over 50FPS. We believe DTT offers a fresh perspective for single-object visual tracking.