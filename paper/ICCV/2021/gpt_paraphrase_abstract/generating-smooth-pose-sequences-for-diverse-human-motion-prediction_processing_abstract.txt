The recent advancements in stochastic motion prediction have enabled the generation of diverse future human motions and even control over specific body parts. However, existing methods require multiple mappings for diversity and a separate model for controllable motion prediction. In this study, we propose a unified deep generative network that can handle both diverse and controllable motion prediction. We exploit the idea that realistic human motions consist of smooth sequences of valid poses, and learning a pose prior is more feasible than learning a motion one with limited data. Our generator predicts the motion of different body parts in a sequential manner, and we introduce a pose prior based on normalizing flow, along with a joint angle loss, to ensure realistic motion. Experimental results on two benchmark datasets, Human3.6M and HumanEva-I, demonstrate that our approach surpasses current state-of-the-art methods in terms of both sample diversity and accuracy. The code for our method is publicly available at the given GitHub link.