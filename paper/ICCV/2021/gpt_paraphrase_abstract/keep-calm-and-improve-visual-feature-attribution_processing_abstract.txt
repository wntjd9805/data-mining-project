The class activation mapping (CAM) is widely used in explaining visual predictions and weakly-supervised localization tasks. However, CAM has limitations as it relies on ad-hoc calibration steps that are not part of the training computational graph, making it difficult to understand the true meaning of the attribution values. To address this, we propose an improved version called class activation latent mapping (CALM). CALM incorporates a latent variable that encodes the cue location for recognition, integrating the attribution map into the training computational graph. We train CALM using the expectation-maximization algorithm and our experiments demonstrate that CALM accurately identifies discriminative attributes for image classifiers compared to CAM and other visual attribution baselines. CALM also outperforms prior methods on weakly-supervised object localization benchmarks. Our code is available at https://github.com/naver-ai/calm.