We introduce Multiscale Vision Transformers (MViT) for image and video recognition. By combining the concept of multiscale feature hierarchies with transformer models, MViT utilizes multiple channel-resolution scale stages. These stages progressively increase the channel capacity while decreasing the spatial resolution, resulting in a multiscale pyramid of features. The early layers of the pyramid operate at high spatial resolution to capture simple low-level visual information, while the deeper layers model complex, high-dimensional features at a coarse spatial resolution. We evaluate MViT on various video recognition tasks and find that it outperforms existing vision transformers that rely on large-scale external pre-training, while being computationally and parameter-wise more efficient (5-10 times less). Additionally, we apply MViT to image classification by removing the temporal dimension and observe superior performance compared to previous vision transformer approaches. The code for MViT is publicly available at https://github.com/facebookresearch/SlowFast.