We introduce a manifold matching approach for generative models that consists of a distribution generator and a metric generator. In this approach, we consider the real data set as a manifold embedded in a high-dimensional Euclidean space. The distribution generator generates samples that follow a distribution condensed around the real data manifold by matching two sets of points using their geometric shape descriptors and a learned distance metric. The metric generator learns a distance metric that approximates the intrinsic geodesic distance on the real data manifold using both real data and generated samples. This distance metric is then used for manifold matching. Both networks learn simultaneously during training. We apply this approach to unsupervised and supervised learning tasks, achieving competitive results in unconditional image generation compared to existing generative models and improving visual qualities in super-resolution tasks by producing samples with more natural textures. Our experiments and analysis demonstrate the feasibility and effectiveness of this framework.