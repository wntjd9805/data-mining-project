This paper addresses the challenge of reconstructing 3D shapes from 2D sketches, which has been a longstanding problem due to the limited and unclear information provided by the sketches. The authors propose an encoder/decoder architecture for translating sketches into 3D meshes. By incorporating camera parameters into a user interface, the authors leverage the latent parametrization of the architecture to accurately represent and refine the 3D mesh, aligning it with the contours outlined in the sketch. The authors demonstrate that this approach is easily deployable, resilient to changes in artistic style, and highly effective. Additionally, they show that their method can refine shape even with single pen strokes. Through comparisons with state-of-the-art techniques on both hand-drawn and synthesized sketches, the authors illustrate that their approach outperforms existing methods.