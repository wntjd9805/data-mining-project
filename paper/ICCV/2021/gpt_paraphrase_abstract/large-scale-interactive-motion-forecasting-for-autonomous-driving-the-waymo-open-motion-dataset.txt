Motion forecasting is becoming increasingly important in the development of autonomous driving systems. Traditional prediction methods that focus on individual object motion are not sufficient for interactive situations such as merges and turns. To address this, there is a need for high-quality motion data that captures interactions between multiple objects. In this study, we present a diverse interactive motion dataset that contains over 100,000 scenes, each lasting 20 seconds at a frequency of 10 Hz. This dataset, which covers 1750 km of roadways across six US cities, was collected by identifying interesting interactions between vehicles, pedestrians, and cyclists. To ensure accuracy, we used a 3D auto-labeling system to generate precise 3D bounding boxes for each road agent and provided corresponding high-definition 3D maps for each scene. Additionally, we introduce a comprehensive set of metrics to evaluate both single agent and joint agent interaction motion forecasting models. Finally, we offer strong baseline models for individual-agent prediction and joint-prediction. We believe that this extensive interactive motion dataset will open up new possibilities for advancing motion forecasting models.