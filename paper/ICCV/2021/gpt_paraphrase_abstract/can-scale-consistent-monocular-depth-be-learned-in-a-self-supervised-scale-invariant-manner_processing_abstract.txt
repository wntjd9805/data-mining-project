Geometric constraints are utilized to address the scale ambiguity problem in self-supervised monocular depth estimation. Additionally, scale-invariant losses are employed to focus on learning relative depth, resulting in precise relative depth prediction. To combine the advantages of both approaches, we propose a scale-aware geometric (SAG) loss that ensures scale consistency through point cloud alignment. Unlike previous methods, the SAG loss considers relative scale during relative motion estimation, facilitating more accurate alignment and explicit supervision for scale inference. Furthermore, we introduce a novel two-stream architecture for depth estimation that separates scale from depth estimation, enabling scale-invariant learning of depth. The integration of the SAG loss and two-stream network enhances scale inference consistency and improves relative depth estimation accuracy. Our method achieves state-of-the-art performance in both scale-invariant and scale-dependent evaluation scenarios.