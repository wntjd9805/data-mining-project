This paper presents a new approach for single-frame temporal action localization (STAL) in untrimmed videos. Unlike existing methods that use a one-stage framework, our proposed method adopts a two-stage framework. In the first stage, we use location supervision to determine the number of action instances and divide the video into multiple clips, each containing one complete action instance. In the second stage, we use category supervision to localize the action instance within each clip. To effectively represent the action instance, we introduce a proposal-based representation and a differentiable mask generator for end-to-end training supervised by category labels. Our method achieves superior performance compared to state-of-the-art methods on THUMOS14, GTEA, and BEOID datasets, with average mAP improvements of 3.5%, 2.7%, and 4.8% respectively. Extensive experiments confirm the effectiveness of our approach.