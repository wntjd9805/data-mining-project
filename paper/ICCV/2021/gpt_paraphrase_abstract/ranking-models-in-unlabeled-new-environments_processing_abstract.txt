In a scenario where multiple models are available for use, trained on a specific domain, and the goal is to apply the most suitable models to different domains based on their performance, we face the challenge of ranking these models in unlabeled target domains. Annotating a validation set for each new target environment can be costly. To address this, we propose using a proxy dataset that is fully labeled and accurately represents the true rankings of models in a given target environment, using the performance rankings on the proxy sets as substitutes. We select labeled datasets as the proxy, with a focus on finding datasets that closely resemble the unlabeled target domain to better preserve the relative performance rankings. To do this, we sample images from various datasets with similar distributions as the target. We demonstrate the effectiveness of our approach on the task of person re-identification, utilizing publicly available datasets. We show that constructing a carefully curated proxy set allows for accurate capturing of the relative performance rankings in new environments. The code for our approach is available at https://github.com/sxzrt/Proxy-Set.