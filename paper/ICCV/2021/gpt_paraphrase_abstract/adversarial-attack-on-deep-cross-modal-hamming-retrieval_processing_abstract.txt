Cross-Modal Hamming space Retrieval (CMHR) has gained significant attention due to the representation capability of deep neural networks. However, the vulnerability of deep networks makes them susceptible to safety risks such as adversarial attacks. This paper introduces a novel Adversarial Attack on Deep Cross-Modal Hamming Retrieval (AACH) that deceives a target deep CMHR model in a black-box setting. The approach involves constructing a substitute model to exploit cross-modal correlations and generate adversarial examples by querying the target model. Additionally, a triplet construction module is designed to enhance attack efficiency by utilizing cross-modal positive and negative instances. By manipulating the perturbations in a way that distances the perturbed examples from positive instances and brings them closer to negative instances, the target model can be effectively fooled. Extensive experiments on widely used cross-modal retrieval benchmarks demonstrate the superiority of AACH. It successfully attacks deep CMHR models with fewer interactions and performs on par with previous state-of-the-art attacks.