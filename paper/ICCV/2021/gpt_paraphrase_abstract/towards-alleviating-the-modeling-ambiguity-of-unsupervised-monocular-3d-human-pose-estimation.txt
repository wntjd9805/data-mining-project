This study focuses on addressing the problem of ambiguity in unsupervised 3D human pose estimation from 2D poses. The scale ambiguity arises from the challenge of accurately capturing the scale of the 3D pose without explicit annotation. Additionally, the lifting procedure from 2D to 3D poses is inherently ambiguous, as one 2D pose can correspond to multiple 3D gestures (pose ambiguity). Previous methods have used temporal constraints to mitigate these issues but often produce sub-optimal results by enforcing multiple training objectives simultaneously. In contrast, this work proposes a two-step approach. First, a scale estimation module optimizes the 2D input poses, followed by a pose lifting module that maps the optimized 2D poses to their 3D counterparts. Two temporal constraints are introduced to alleviate scale and pose ambiguity. These two modules are optimized using an iterative training scheme with corresponding temporal constraints, resulting in improved performance and reduced learning difficulty. Experimental results on the Human3.6M dataset demonstrate a 23.1% improvement compared to previous methods and outperform weakly supervised approaches relying on 3D annotations. The project is available at the provided website.