Camera pose estimation, a crucial aspect of Structure-from-Motion (SfM) and SLAM systems, involves determining the accurate global camera position. Pose-graph optimization (PGO) is commonly used to solve for globally-consistent absolute camera poses based on relative camera poses. This study introduces a novel PGO approach called PoGO-Net, which utilizes graph neural networks (GNN) and multiple rotation averaging (MRA) to regress the absolute camera pose. PoGO-Net takes a noisy view-graph as input, with nodes and edges encoding geometric constraints and local graph consistency. An implicit edge-dropping scheme is employed to remove outlier edges using parameterized networks. Additionally, a joint loss function incorporating the MRA formulation enables robust inference and real-time performance, even for large-scale scenes. The proposed network is trained end-to-end on public benchmarks and outperforms existing methods in terms of efficiency and robustness.