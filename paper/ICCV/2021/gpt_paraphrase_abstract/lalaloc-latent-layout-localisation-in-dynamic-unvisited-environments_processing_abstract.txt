We introduce LaLaLoc, a method for localizing in unfamiliar environments without the need for prior exploration, while also being able to handle significant changes in scene appearance, such as furniture rearrangement. LaLaLoc achieves this by utilizing latent representations of room layouts. It learns a comprehensive embedding space that is shared between RGB panoramas and layouts derived from a known floor plan, which captures the structural similarity between different locations. Additionally, LaLaLoc incorporates direct, cross-modal pose optimization within its latent space, enabling precise pose estimation without the requirement of prior visits and ensuring robustness to dynamic changes like furniture configuration. Through experimentation in a domestic setting, we demonstrate that LaLaLoc can accurately localize a single RGB panorama image within a margin of only 8.3cm, solely relying on a floor plan as prior information.