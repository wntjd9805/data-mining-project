Recent advancements in cross-domain object detection and semantic segmentation have been remarkable. Current approaches mainly focus on addressing domain shifts caused by external factors such as changes in background, lighting, or weather conditions. However, little attention has been given to the impact of camera intrinsic parameters across different domains on domain adaptation.   This study explores the rarely investigated concept of the Field of View (FoV) gap, which leads to noticeable differences in instance appearance between the source and target domains. The authors also find that the FoV gap negatively affects domain adaptation performance in both cases where the FoV increases (source FoV < target FoV) and decreases.   Based on these observations, the authors propose a novel method called Position-Invariant Transform (PIT) to better align images from different domains. Additionally, they introduce a reverse PIT to map the transformed/aligned images back to the original image space. They also design a loss re-weighting strategy to expedite the training process. Importantly, their method can be easily integrated into existing cross-domain detection/segmentation frameworks without significant computational overhead.   Extensive experiments validate the effectiveness of the proposed method. It significantly enhances the performance of state-of-the-art techniques in cross-domain object detection and segmentation. The code for the proposed method is publicly available at https://github.com/sheepooo/PIT-Position-Invariant-Transform.