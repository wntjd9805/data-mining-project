Predicting the future states of dynamic traffic actors is crucial for the safe and efficient operation of autonomous systems. However, the most critical and complex scenarios are less common than the less critical ones, resulting in the dominance of uncritical cases in prediction. This paper focuses on addressing the challenging scenarios that are at the tail end of the dataset distribution. Our analysis reveals that common loss functions tend to poorly position challenging cases in the embedding space. To overcome this, we propose augmenting the usual loss function with a new loss that brings challenging cases closer together. This encourages the sharing of information among these challenging cases and facilitates the learning of specific predictive features. We demonstrate on four public datasets that this approach enhances performance in challenging scenarios while maintaining overall stability. Importantly, this approach is compatible with various network architectures, input modalities, and viewpoints, and can be easily integrated into existing solutions. The code for this approach is available on GitHub.