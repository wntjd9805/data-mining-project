The problem of accurately estimating the 6 degrees-of-freedom (6DoF) object pose in a cluttered environment using a single RGB image is challenging. While end-to-end methods have shown promising results in terms of efficiency, they are still not as accurate as PnP/RANSAC-based approaches for pose estimation. To address this limitation, we propose a novel approach called SO-Pose that considers self-occlusion reasoning to improve the accuracy of end-to-end 6D pose estimation. Our framework utilizes a two-layer representation for 3D objects, generated by a shared encoder and two separate decoders, to establish 2D-3D correspondences and self-occlusion information. These outputs are then fused to directly estimate the 6DoF pose parameters. By incorporating cross-layer consistencies that align correspondences, self-occlusion, and 6D pose, our approach achieves higher accuracy and robustness compared to other state-of-the-art methods on challenging datasets.