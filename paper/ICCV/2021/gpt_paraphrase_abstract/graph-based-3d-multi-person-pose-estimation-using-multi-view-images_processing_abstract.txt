This study focuses on estimating the 3D poses of multiple individuals from multiple calibrated camera views. The task is divided into two stages: person localization and pose estimation. The paper proposes three task-specific graph neural networks to facilitate effective message passing. To localize 3D persons, a Multi-view Matching Graph Module (MMG) is used to learn cross-view associations and generate rough human proposals. The Center Refinement Graph Module (CRG) further improves the results through flexible point-based prediction. For 3D pose estimation, the Pose Regression Graph Module (PRG) learns both multi-view geometry and structural relationships between human joints. The proposed approach achieves state-of-the-art performance on CMUPanoptic and Shelf datasets while significantly reducing computational complexity.