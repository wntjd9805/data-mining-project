This study introduces a new method for unsupervised domain adaptation (UDA) that deals with conditional and label shifts. The objective is to align the distributions of both p(x|y) and p(y). Traditional adversarial UDA methods assume that p(y) remains unchanged across domains and focus on aligning p(x) instead of p(x|y) because labels are not available in the target domain. To address this limitation, a comprehensive theoretical and empirical analysis of conventional adversarial UDA methods under both conditional and label shifts is presented. A novel and practical optimization scheme for adversarial UDA is proposed. The scheme involves iteratively inferring the marginal p(y) and aligning p(x|y) during the training stage, and accurately aligning the posterior p(y|x) during the testing stage. Experimental results demonstrate the effectiveness of this method in classification, segmentation, and partial UDA scenarios.