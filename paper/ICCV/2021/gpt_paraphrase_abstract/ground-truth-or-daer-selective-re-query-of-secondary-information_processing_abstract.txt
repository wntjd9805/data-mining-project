Many vision tasks rely on secondary information, known as a seed, to assist computer vision models in solving problems. However, current approaches assume that the seed is always reliable, which is often not the case in real-world scenarios where seeds can be noisy or inaccurate. This paper introduces the concept of seed rejection, which involves determining whether to reject a seed based on the expected decrease in performance compared to a gold-standard seed. The authors provide a formal definition of the problem and focus on two main objectives: understanding the causes of error and analyzing the model's response to noisy seeds given the primary input. To tackle these objectives, a novel training method and evaluation metrics for the seed rejection problem are proposed. The authors conduct experiments using viewpoint estimation and fine-grained classification tasks with seeded versions to evaluate their contributions. The results demonstrate that their method can reduce the number of seeds that need to be reviewed for a desired performance by more than 23% compared to strong baselines.