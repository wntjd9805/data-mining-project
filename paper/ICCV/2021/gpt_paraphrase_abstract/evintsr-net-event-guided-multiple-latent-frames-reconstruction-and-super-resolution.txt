The abstract describes the limitations of event cameras in terms of spatial resolution but highlights their advantages in detecting scene radiance changes and sending asynchronous event streams with high dynamic range, temporal resolution, and low latency. To address the issue of limited spatial resolution, the authors propose a solution called EvIntSR-Net, which converts event data into multiple latent intensity frames to achieve super-resolution on intensity images. EvIntSR-Net bridges the gap between event streams and intensity frames by learning to merge a sequence of latent intensity frames in a recurrent updating manner. Experimental results demonstrate that EvIntSR-Net is capable of reconstructing super-resolved intensity images with higher dynamic range and fewer blurry artifacts by combining events with intensity frames, both in simulated and real-world data. Additionally, EvIntSR-Net can generate high-frame-rate videos with super-resolved frames.