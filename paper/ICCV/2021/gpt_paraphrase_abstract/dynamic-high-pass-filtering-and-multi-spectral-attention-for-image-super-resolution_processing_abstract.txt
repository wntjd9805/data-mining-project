Deep convolutional neural networks (CNNs) have advanced the field of super-resolution (SR) research. However, current CNN models have a significant drawback: they are biased towards learning low-frequency signals. This bias becomes problematic for the image SR task, which aims to reconstruct fine details and image textures. To address this challenge, we propose enhancing the learning of high-frequency features at both local and global levels by introducing two new architectural units into existing SR models. Firstly, we propose a dynamic high-pass filtering (HPF) module that applies adaptive filter weights to each spatial location and channel group, preserving high-frequency signals. This module allows for local adjustments to better capture fine details. Additionally, we introduce a matrix multi-spectral channel attention (MMCA) module that predicts the attention map of features decomposed in the frequency domain. Operating in a global context, this module recalibrates feature responses at different frequencies to adaptively enhance high-frequency information. Our proposed modules are evaluated extensively, both qualitatively and quantitatively, and demonstrate superior accuracy and visual improvements compared to state-of-the-art methods on various benchmark datasets.