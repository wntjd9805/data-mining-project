We introduce a new method for semantic segmentation that combines two important segmentation model properties: label-space consistency between image augmentations and feature-space contrast among different pixels. We utilize the pixel-level â„“2 loss and pixel contrastive loss to achieve these goals, respectively. To address efficiency and false negative noise issues in the pixel contrastive loss, we explore different negative sampling techniques. Our extensive experiments using the DeepLab-v3+ architecture in various semi-supervised settings derived from VOC, Cityscapes, and COCO datasets demonstrate the exceptional performance of our method (PC2Seg), surpassing existing approaches.