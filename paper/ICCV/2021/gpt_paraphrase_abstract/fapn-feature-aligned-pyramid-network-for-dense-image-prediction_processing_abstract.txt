Deep neural networks have made significant advancements in dense image prediction. However, existing approaches often neglect the issue of feature alignment for simplicity. This leads to misaligned contexts and misclassifications, particularly on object boundaries. To address this problem, we propose a feature alignment module that learns transformation offsets to align upsampled higher-level features. Additionally, we introduce a feature selection module to emphasize lower-level features with spatial details. These modules are integrated into a top-down pyramidal architecture called the Feature-aligned Pyramid Network (FaPN). We extensively evaluate FaPN on four dense prediction tasks and four datasets, and the results demonstrate its effectiveness. When paired with Faster/Mask R-CNN, FaPN achieves an overall improvement of 1.2-2.6 points in average precision (AP) and mean intersection over union (mIoU) over the Feature Pyramid Network (FPN). Notably, our FaPN achieves a state-of-the-art mIoU of 56.7% on the ADE20K dataset when integrated within Mask-Former. The code for FaPN is available at https://github.com/EMI-Group/FaPN.