Unsupervised representation learning has achieved impressive results by utilizing centralized data from the Internet. However, concerns regarding privacy protection have limited the sharing of decentralized unlabeled image data, which is rapidly growing across multiple parties such as mobile phones and cameras. This presents a challenge of how to leverage this data for learning visual representations while still maintaining data privacy. To address this issue, we propose a new framework called FedU, which is based on federated unsupervised learning. In this framework, each party independently trains models using contrastive learning with an online network and a target network. These trained models are then aggregated by a central server, which updates the clients' models with the aggregated model. This approach ensures data privacy as each party only has access to its own raw data. However, decentralized data from multiple parties are often non-independent and identically distributed (non-IID), which can lead to a decrease in performance. To overcome this challenge, we introduce two simple yet effective methods. Firstly, we design a communication protocol that only uploads the encoders of online networks for server aggregation, updating them with the aggregated encoder. Secondly, we introduce a new module that dynamically determines how to update predictors based on the divergence caused by non-IID. The predictor is the other component of the online network. Through extensive experiments and ablations, we demonstrate the effectiveness and significance of FedU. It surpasses training with only one party by more than 5% and outperforms other methods by over 14% in linear and semi-supervised evaluation on non-IID data.