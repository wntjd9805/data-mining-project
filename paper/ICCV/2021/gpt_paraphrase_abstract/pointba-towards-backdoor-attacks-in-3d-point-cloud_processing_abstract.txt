The popularity of 3D deep learning has increased for various tasks, including safety-critical applications. While previous works have focused on adversarial attacks, we highlight the unexplored threat of backdoor attacks on 3D deep learning systems. We introduce a unified framework for backdoor attacks on 3D point cloud data and networks, consisting of the poison-label backdoor attack (PointPBA) and the clean-label backdoor attack (PointCBA). These attacks leverage the unique properties of 3D data and networks. The motivation behind our attack algorithms stems from the vulnerability of deep models to spatial transformations, as demonstrated by the discovery of 3D adversarial samples, and the potential of feature disentanglement techniques to manipulate data features and embed new tasks. Extensive experiments confirm the effectiveness of PointPBA with a success rate exceeding 95% across various 3D datasets and models, and PointCBA with a stealthier success rate of around 50%. Our proposed backdoor attack in 3D point cloud serves as a baseline for enhancing the robustness of 3D deep models.