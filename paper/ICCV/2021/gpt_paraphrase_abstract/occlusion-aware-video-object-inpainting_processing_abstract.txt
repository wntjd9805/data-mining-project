This paper introduces a new approach called occlusion-aware video object inpainting, which addresses the limitations of conventional video inpainting methods by considering object-oriented and occlusion-aware techniques. The proposed method aims to recover both the shape and appearance of occluded objects in videos based on their visible mask segmentation. To support this research, the authors have created a large-scale benchmark dataset called YouTube-VOI, which provides realistic occlusion scenarios along with occluded and visible object masks. The main technical contribution of this work is the VOIN algorithm, which combines video object shape completion and occluded texture generation. The shape completion module focuses on maintaining object coherence across frames, while the flow completion module accurately recovers motion flow boundaries to ensure temporally-consistent texture propagation for moving objects. To enhance realism, VOIN is optimized using T-PatchGAN and a new spatio-temporal attention-based multi-class discriminator. The authors conducted experiments comparing VOIN with strong baselines using the YouTube-VOI dataset, demonstrating the effectiveness of their method in inpainting complex and dynamic objects. It is worth noting that VOIN gracefully handles inaccurate input visible masks.