Previous studies have shown that GANs do not replicate training images without significant changes to the training procedure. This has prompted research into identifying the conditions necessary for GANs to overfit to the training data. While several factors have been identified theoretically or empirically, the impact of dataset size and complexity on GAN replication remains unclear. Through empirical analysis using BigGAN and StyleGAN2 on CelebA, Flower, and LSUN-bedroom datasets, we demonstrate that dataset size and complexity are crucial factors in GAN replication and the perceptual quality of generated images. We also establish a quantifiable relationship, revealing that the percentage of replication decreases exponentially as dataset size and complexity increase, with a consistent decaying factor across different GAN-dataset combinations. Additionally, we observe a U-shaped trend in the perceptual image quality concerning dataset size. These findings provide a practical tool for estimating the minimal dataset size required to prevent GAN replication, thereby aiding in dataset construction and selection.