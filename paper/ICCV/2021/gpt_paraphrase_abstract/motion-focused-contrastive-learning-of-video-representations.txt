Motion is crucial for video representation learning, as it captures changes over time. This paper explores the importance of motion in self-supervised video representation learning. The authors propose a method called Motion-focused Contrastive Learning (MCL) that leverages motion for both data augmentation and feature learning. MCL uses optical flow to sample sequences of frame patches as data augmentations and aligns gradient maps of convolutional layers with optical flow maps to incorporate motion information into feature learning. Experimental results using the R(2+1)D backbone demonstrate the effectiveness of MCL. On UCF101, the linear classifier trained on MCL representations achieves 81.91% top-1 accuracy, surpassing ImageNet supervised pre-training by 6.78%. On Kinetics-400, MCL achieves 66.62% top-1 accuracy under the linear protocol.