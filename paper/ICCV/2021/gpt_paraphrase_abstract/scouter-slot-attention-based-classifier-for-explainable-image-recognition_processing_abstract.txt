Explainable artificial intelligence (AI) has garnered attention recently, but most existing methods rely on gradients or intermediate features that are not directly involved in the decision-making process of the classifier. This paper introduces SCOUTER, a slot attention-based classifier that aims to provide transparent and accurate classification. SCOUTER differs from other attention-based methods in two significant ways. Firstly, its explanation is incorporated in the final confidence score for each category, allowing for more intuitive interpretation. Secondly, SCOUTER provides positive or negative explanations for all categories, offering insights into why an image belongs or does not belong to a specific category. A novel loss function is designed specifically for SCOUTER to control the model's behavior in switching between positive and negative explanations and determining the size of explanatory regions. Experimental results demonstrate that SCOUTER outperforms other methods in terms of visual explanations across various metrics while maintaining good accuracy, particularly on small and medium-sized datasets. The code for SCOUTER is publicly available.