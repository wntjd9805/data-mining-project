We propose a novel approach to detect human-object interactions in images using graphical neural networks. Unlike traditional methods, where nodes send identical messages to their neighbors, we suggest conditioning messages on the spatial relationships between node pairs. This results in different messages being sent to neighbors of the same node. We explore different ways of implementing spatial conditioning within a multi-branch structure. Extensive experiments demonstrate the benefits of spatial conditioning for computing adjacency structures, messages, and refined graph features. Our findings reveal that as the quality of bounding boxes improves, the contribution of coarse appearance features to disambiguate interactions decreases compared to spatial information. Our method achieves impressive results with an mAP of 31.33% on HICO-DET and 54.2% on V-COCO, outperforming the current state-of-the-art on fine-tuned detections.