Data augmentation is an important approach for addressing the problem of few-shot classification. However, it is difficult to achieve both discriminability and diversity in the augmented samples. To overcome this challenge, we propose a feature disentanglement framework that allows us to augment features by incorporating random intra-class variations while preserving their class-discriminative features. Our approach involves separating the feature representation into two components: one that captures the intra-class variance and another that encodes the class-discriminative information. We assume that the intra-class variance, which is caused by variations in poses, backgrounds, or illumination conditions, is shared across all classes and can be modeled using a common distribution. We then repeatedly sample features from this learned intra-class variability distribution and combine them with the class-discriminative features to obtain the augmented features. This data augmentation scheme ensures that the augmented features retain important class-discriminative features while exhibiting significant intra-class variance. Our method outperforms state-of-the-art methods on various challenging fine-grained few-shot image classification benchmarks. The code for our method is available at the following GitHub repository: https://github.com/cvlab-stonybrook/vfd-iccv21.