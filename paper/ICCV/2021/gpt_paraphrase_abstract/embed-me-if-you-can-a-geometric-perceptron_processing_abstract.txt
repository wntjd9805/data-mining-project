Using machine learning to solve geometric tasks with point clouds is a challenging problem. Standard feed-forward neural networks, which consist of linear or affine layers and activation functions, have limited geometric modeling capabilities. To address this limitation, the multilayer hypersphere perceptron (MLHP) was introduced, which utilizes a conformal embedding of Euclidean space to create hypersphere neurons. These neurons are implemented using the Cartesian dot product of inputs and weights, thanks to Clifford algebra. By embedding the input space geometry consistently, the decision surfaces of the model units become combinations of hyperspheres, making the decision-making process interpretable for humans. We propose an extension of the MLHP model called the multilayer geometric perceptron (MLGP) that is consistent with 3D geometry. The MLGP employs geometric neurons in its respective layers, which provide a geometric understanding of the learned coefficients. Notably, the activations of these geometric neurons are isometric in 3D, enabling rotation and translation equivariance. In our experiments classifying 3D Tetris shapes, we demonstrate that our model outperforms the vanilla multilayer perceptron without the need for activation functions in the hidden layers, relying solely on the embedding. Furthermore, our model outperforms the MLHP in the presence of data noise.