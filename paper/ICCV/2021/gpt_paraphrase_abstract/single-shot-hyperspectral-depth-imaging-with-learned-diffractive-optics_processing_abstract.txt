The combination of imaging depth and spectrum has been studied separately for many years. However, a new method called hyperspectral-depth (HS-D) imaging has recently emerged, which allows for the simultaneous capture of both types of information using two different imaging systems. This approach is accurate but comes with drawbacks such as increased size, cost, capture time, and alignment issues. In this study, we propose a more compact and efficient single-shot monocular HS-D imaging method. We utilize a diffractive optical element (DOE) that has a point spread function changing with depth and spectrum. This enables us to reconstruct both depth and spectrum from a single captured image. To achieve this, we develop a differentiable simulator and a neural network-based reconstruction method that are jointly optimized using automatic differentiation. To aid in the learning of the DOE, we create a HS-D dataset by constructing a benchtop HS-D imager that acquires accurate ground truth data. We evaluate our method using synthetic and real experiments, building an experimental prototype, and achieving state-of-the-art HS-D imaging results.In summary, we propose a more efficient HS-D imaging method that overcomes the limitations of the combinational approach. This method utilizes a diffractive optical element and a neural network-based reconstruction method, and we have created a dataset and experimental prototype to validate its effectiveness. Our results demonstrate significant improvements in HS-D imaging.