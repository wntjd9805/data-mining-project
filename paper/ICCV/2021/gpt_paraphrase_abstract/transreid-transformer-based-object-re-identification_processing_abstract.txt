The object re-identification (ReID) task faces challenges in extracting robust feature representations. While convolution neural network (CNN)-based methods have achieved success, they suffer from information loss due to convolution and downsampling. To address these limitations, we propose TransReID, a pure transformer-based framework for object ReID. TransReID encodes an image as a sequence of patches and builds a transformer-based baseline with improvements, achieving competitive results on ReID benchmarks compared to CNN-based methods. We introduce two novel modules to enhance robust feature learning: the jigsaw patch module (JPM) rearranges patch embeddings to generate more discriminative and diverse features, and the side information embeddings (SIE) mitigate feature bias towards camera/view variations. This is the first work to use a pure transformer for ReID research. Experimental results demonstrate the superiority of TransReID, achieving state-of-the-art performance on person and vehicle ReID benchmarks. The code for TransReID is available at https://github.com/heshuting555/TransReID.