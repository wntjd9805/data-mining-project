Creating image captions that are both diverse and accurate is a difficult task in vision+language modeling. While reinforcement learning (RL) methods improve accuracy, they often sacrifice diversity. On the other hand, variational auto-encoder (VAE) or generative adversarial network (GAN) approaches generate diverse but less accurate captions. In this study, we focus on enhancing the diversity of RL-based image captioning. We propose a partial off-policy learning scheme to balance accuracy and diversity. Firstly, we expose the model to various candidate captions by sampling from the initial state before RL training. Secondly, we introduce a new criterion called max-CIDEr to serve as the reward for promoting diversity. By combining the off-policy strategy with on-policy methods, we manage to moderate the exploration effect and achieve a better balance of diversity and accuracy in human-like image captioning. Experimental results demonstrate that our approach performs closest to humans in terms of diversity and accuracy, with a Pearson correlation of 0.337 with human performance.