Multi-label zero-shot learning (ZSL) is a more realistic version of single-label ZSL as it acknowledges that natural images can contain multiple objects. However, the presence of multiple objects complicates the reasoning process and requires region-specific processing of visual features to maintain their contextual information. The existing approach to multi-label ZSL uses shared attention maps for all classes, resulting in diffused attention that does not focus discriminatively on relevant locations, especially when there are many classes. Additionally, mapping spatially-pooled visual features to class semantics leads to feature entanglement between classes, which hinders classification accuracy.In this study, we propose an alternative approach to region-based discriminability-preserving multi-label zero-shot classification. Our approach preserves spatial resolution to retain region-level characteristics and incorporates both region and scene context information through a bi-level attention module (BiAM) to enhance the features. The enriched region-level features are then mapped to class semantics, and only their class predictions are spatially pooled to obtain image-level predictions, ensuring that the multi-class features remain disentangled. Our approach achieves state-of-the-art performance on two large-scale multi-label zero-shot benchmarks: NUS-WIDE and Open Images. Specifically, on NUS-WIDE, our approach improves ZSL performance by 6.9% mAP compared to the best previously published results. The source code is available at https://github.com/akshitac8/BiAM.