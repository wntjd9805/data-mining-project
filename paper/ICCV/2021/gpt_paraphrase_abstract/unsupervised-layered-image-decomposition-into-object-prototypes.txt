We introduce an unsupervised learning framework for separating images into layers containing object models that are automatically discovered. Unlike recent methods that use autoencoder networks to model image layers, we represent them as explicit transformations of a small set of prototype images. Our framework consists of three main components: (i) a set of learnable object prototypes called sprites, which are images with a transparency channel; (ii) differentiable parametric functions that predict occlusions and transformation parameters required to instantiate the sprites in a given image; and (iii) a layered image formation model that incorporates occlusion to compose these instances into complete images along with the background. By simultaneously learning the sprites and occlusion/transformation predictors to reconstruct images, our approach not only achieves accurate layered image decompositions but also identifies object categories and instance parameters. We initially validate our method by obtaining results comparable to the state of the art on standard multi-object synthetic benchmarks (Tetrominoes, Multi-dSprites, CLEVR6). Additionally, we demonstrate the applicability of our model to real images in various tasks such as clustering (SVHN, GTSRB), cosegmentation (Weizmann Horse), and object discovery from unfiltered social network images. To the best of our knowledge, our approach is the first algorithm for layered image decomposition that learns an explicit and shared concept of object type, and it is robust enough to be applied to real images.