This paper introduces a new neural rendering system for generating realistic renderings of clustered real-world scenes with editing capabilities. Existing methods typically encode the entire scene as a whole, without considering object identity, which limits the ability to perform high-level editing tasks such as moving or adding furniture. In contrast, our system utilizes a two-pathway architecture, with one pathway encoding scene geometry and appearance, and the other pathway encoding each individual object using learnable object activation codes. To address the challenges posed by heavily cluttered scenes, we propose a scene-guided training strategy that resolves 3D space ambiguity in occluded regions and learns sharp boundaries for each object. Our experiments demonstrate that our system achieves competitive performance for novel-view synthesis of static scenes and produces realistic renderings for object-level editing.