Point cloud registration is a crucial task in various computational fields. Existing methods for correspondence matching rely on distinctive geometric structures and sparse feature matches, but the accuracy of transformation is limited by the quality of extracted features, which are prone to errors and do not utilize all overlapping regions. On the other hand, global feature based approaches can use the entire point cloud for registration, but they overlook the negative impact of non-overlapping points. This paper introduces OM-Net, an iterative network for partial-to-partial point cloud registration that utilizes global features. It learns overlapping masks to reject non-overlapping regions, transforming the registration task into aligning the same shape. A new data generation method is proposed, sampling CAD models twice for the source and reference to avoid overfitting. Experimental results demonstrate that our method outperforms traditional and deep learning based approaches. The code for OM-Net is available at https://github.com/megvii-research/OMNet.