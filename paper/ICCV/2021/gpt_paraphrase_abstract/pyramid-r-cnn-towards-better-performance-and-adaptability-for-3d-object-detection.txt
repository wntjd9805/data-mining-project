We introduce Pyramid R-CNN, a flexible and high-performance framework for 3D object detection from point clouds. Existing methods struggle with the sparsity and non-uniform distribution of points, leading to failures in detecting objects that are far away. To address this, we propose the pyramid RoI head, a novel second-stage module that learns features from sparse points of interest. This module consists of three key components. Firstly, we propose the RoI-grid Pyramid, which collects points of interest for each RoI in a pyramid manner, mitigating the sparsity problem. Secondly, we introduce RoI-grid Attention, an operation that encodes richer information from sparse points by combining attention-based and graph-based point operators. Thirdly, we propose the Density-Aware Radius Prediction (DARP) module, which dynamically adjusts the focusing range of RoIs based on point density levels. By combining these components, our pyramid RoI head is robust to sparse and imbalanced circumstances and can be used with different 3D backbones to consistently improve detection performance. Extensive experiments demonstrate that Pyramid R-CNN significantly outperforms state-of-the-art 3D detection models on both the KITTI dataset and the Waymo Open dataset.