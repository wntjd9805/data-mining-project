Neural implicit 3D representations have become popular for surface reconstruction and view synthesis. However, current methods require accurate object masks for supervision. On the other hand, neural radiance fields have improved view synthesis but struggle with surface reconstruction. We propose a unified approach that combines implicit surface models and radiance fields, allowing for both surface and volume rendering with the same model. This perspective enables more efficient sampling and accurate surface reconstruction without the need for input masks. Our method outperforms NeRF in terms of reconstruction quality and performs similarly to IDR without requiring masks. We validate our approach on multiple datasets, including DTU, BlendedMVS, and a synthetic indoor dataset.