This paper introduces a video reconstruction pipeline for capturing High Dynamic Range (HDR) scenarios using event cameras. Event cameras are good at capturing HDR visual information without blur, but they struggle with static or slowly changing scenes. On the other hand, conventional image sensors perform well in measuring the absolute intensity of slowly changing scenes but struggle with high dynamic range or quickly changing scenes. 

To address this issue, the proposed algorithm includes a pre-processing step called frame augmentation. This step utilizes events to de-blur and temporally interpolate frame data. The augmented frame data, along with the event data, is then fused using a novel asynchronous Kalman filter. This filter operates under a unified uncertainty model for both event cameras and conventional image sensors.

The experimental results of the proposed algorithm are evaluated on publicly available datasets with challenging lighting conditions and fast motions. Additionally, a new dataset with HDR reference is created for evaluation. The algorithm outperforms state-of-the-art methods in terms of both absolute intensity error (with a 48% reduction) and image similarity indexes (with an average 11% improvement).