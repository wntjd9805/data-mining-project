Gaze following in 2D images is a popular topic in computer vision, but it often faces challenges with out of frame issues due to the limited field-of-view. To overcome this, we introduce a new task of gaze following in 360-degree images, which provide an omnidirectional field-of-view and can solve the out of frame problem. We have created a dataset called "GazeFollow360" consisting of 10,000 360-degree images with complex gaze behaviors in different scenes. Existing 2D gaze following methods struggle with performance in 360-degree images because they assume that the gaze target is within the 2D gaze sight line. However, this assumption does not hold for long-distance gaze behaviors in 360-degree images due to distortion caused by sphere-to-plane projection. To tackle this challenge, we propose a 3D sight line guided dual-pathway framework that detects the gaze target in both a local region and a distant region simultaneously. The local region is obtained as a 2D cone-shaped field along the sight line starting from the head position of the human subject, while the distant region is obtained by searching along the sight line in 3D sphere space. The location of the gaze target is determined by combining the estimations from both the local and distant regions. Experimental results demonstrate that our method outperforms previous 2D gaze following methods on our GazeFollow360 dataset.