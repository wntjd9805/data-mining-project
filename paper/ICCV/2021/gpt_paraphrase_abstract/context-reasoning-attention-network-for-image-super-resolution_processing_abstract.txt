Deep convolutional neural networks (CNNs) have been successful in image super-resolution (SR), but they lack the ability to capture global context. To address this limitation, previous studies have incorporated global context into local feature representation using global feature interaction methods. However, recent findings in neuroscience suggest that neurons need to dynamically adjust their functions based on context, which is often overlooked in CNN-based SR methods. Motivated by these observations, we propose the context reasoning attention network (CRAN) to modulate the convolution kernel based on global context. We extract global context descriptors and enhance them with semantic reasoning. We then introduce channel and spatial interactions to generate a context reasoning attention mask, which is used to adaptively modify the convolution kernel. This modulated convolution layer serves as the basic component for building blocks and networks. Extensive experiments on benchmark datasets with various degradation models demonstrate that CRAN achieves superior results and strikes a favorable balance between performance and model complexity.