The paper introduces a Self-Motivated Communication Agent (SCoA) for Vision-Dialog Navigation (VDN) that aims to improve real-world human-robot communication and cooperation. Unlike conventional approaches that rely on predefined locations for asking questions, SCoA learns whether and what to communicate with humans in an adaptive manner. This eliminates the need for expensive dialogue annotations and allows for navigation in unseen environments.The proposed approach consists of two policies: the whether-to-ask (WeTA) policy and the what-to-ask (WaTA) policy. The WeTA policy determines whether the agent should ask a question by considering the uncertainty of which action to choose. The WaTA policy, on the other hand, learns to score question candidates based on the oracle's answers and aims to select the most informative question for navigation while mimicking the oracle's answering.By jointly optimizing communication and navigation in a unified imitation learning and reinforcement learning framework, SCoA can navigate in a self-Q&A manner even in real-world environments where human assistance is often unavailable. This approach reduces communication costs by asking questions only when necessary and obtaining hints for guiding the agent towards the target.Experimental results on both seen and unseen environments demonstrate that SCoA outperforms existing baselines without dialogue annotations and performs competitively compared to counterparts that rely on rich dialogue annotations. The answer format of the paper only provides the abstract, and no additional information is given.