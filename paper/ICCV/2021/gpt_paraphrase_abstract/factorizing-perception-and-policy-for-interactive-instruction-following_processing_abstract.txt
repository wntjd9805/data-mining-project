AI agents face a challenge in being able to perform simple household tasks based on language instructions, despite it being a natural ability for humans. The 'interactive instruction following' task aims to develop agents that can navigate, interact, and reason in the environment. To tackle this complex problem, we propose MOCA, a Modular Object-Centric Approach. MOCA divides the task into interactive perception and action policy streams, incorporating enhanced components. Through empirical validation, we demonstrate that MOCA outperforms previous approaches by a significant margin on the ALFRED benchmark, showing improved generalization.