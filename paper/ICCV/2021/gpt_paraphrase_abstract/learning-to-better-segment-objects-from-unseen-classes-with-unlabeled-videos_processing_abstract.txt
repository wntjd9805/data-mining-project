This paper aims to address the need for improved performance on localizing and segmenting objects from unseen classes. Currently, acquiring additional training data for unseen classes is time-consuming and costly due to manual annotation. To overcome this challenge, the paper explores the use of unlabeled video sequences to automatically generate training data for unseen class objects. While existing video segmentation methods can be applied to unlabeled videos to obtain object masks, the experiments conducted in this paper show that these methods are not effective enough for this purpose. Therefore, a Bayesian method is introduced, specifically designed to automatically create a training set. This method utilizes object proposals and uses analysis-by-synthesis to select the correct ones through efficient optimization across all frames. Extensive experiments demonstrate that this method can generate a high-quality training set, significantly improving the performance of segmenting objects from unseen classes. Consequently, the paper suggests that this method has the potential to facilitate open-world instance segmentation by leveraging abundant Internet videos.