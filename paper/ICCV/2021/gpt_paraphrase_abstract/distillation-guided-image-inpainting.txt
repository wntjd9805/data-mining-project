Recent advancements in image inpainting techniques have been achieved through the use of deep neural networks. However, many of these methods often result in distorted structures or inconsistent textures. This issue arises from the encoder layers' inability to effectively create a complete and accurate representation of the missing regions. Existing solutions, such as course-to-fine, progressive refinement, and structural guidance, have drawbacks such as high computational costs, limited handcrafted features, and suboptimal utilization of ground truth information. To address these challenges, we propose a distillation-based approach to inpainting.In our approach, we incorporate direct feature level supervision during training. This is accomplished through the use of cross and self-distillation techniques, as well as the design of a dedicated completion-block in the encoder. These enhancements enable us to generate more precise encodings of the holes. Additionally, we improve the attention module of the inpainting network by leveraging a distillation-based attention transfer technique. Furthermore, we enhance coherence by employing a pixel-adaptive global-local feature fusion.To validate the effectiveness of our method, we conduct extensive evaluations on multiple datasets. Our approach not only achieves significant improvements over previous state-of-the-art methods but also demonstrates its ability to enhance existing inpainting works. This distillation-based approach addresses the shortcomings of encoder layers and produces more accurate and visually appealing inpainted images.