With the advancement of image editing tools and convolutional neural networks (CNNs), forgery images are becoming more realistic, posing a challenge for authenticators to verify them. This paper explores the concept of Generative Adversarial Networks (GANs) in generating and detecting forgery images. The authors focus on retouching forgery images to suppress tampering artifacts and preserve structural information, treating this process as an image style transformation. They propose a fake-to-realistic transform generator called GT, and a localization generator known as GM for detecting tampered regions. By training these two generators adversarially, the proposed α-learnable whitening and coloring transform (α-learnable WCT) block in GT effectively eliminates tampering artifacts. Additionally, GM's detection and localization abilities are enhanced by learning from the forgery images retouched by GT. Experimental results demonstrate that the proposed GAN generators accurately simulate the interaction between the faker and the authenticator, with GM outperforming existing methods in detecting and localizing splicing forgery across multiple datasets.