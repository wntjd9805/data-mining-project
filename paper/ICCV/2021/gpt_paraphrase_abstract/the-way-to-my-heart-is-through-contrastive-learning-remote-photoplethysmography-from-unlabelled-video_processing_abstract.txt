This study introduces a novel approach to remote photoplethysmography (rPPG), which is the measurement of blood volume changes using facial or skin observations. Unlike existing methods, this approach utilizes fully self-supervised training, eliminating the need for expensive ground truth physiological training data. The proposed method employs contrastive learning with a weak prior on the target signal's frequency and temporal smoothness. The evaluation of this approach on four rPPG datasets demonstrates comparable or superior results to recent supervised deep learning methods, without the use of any annotations. Additionally, a learned saliency resampling module is incorporated into both the unsupervised and supervised approaches, reducing the reliance on hand-engineered features and providing insights into the model's behavior. The code for the complete training and evaluation pipeline is made available to promote reproducible progress in this field.