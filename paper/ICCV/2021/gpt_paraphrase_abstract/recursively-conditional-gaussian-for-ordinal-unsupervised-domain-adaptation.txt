Unsupervised domain adaptation (UDA) is commonly used to address the issue of limited data availability. However, current UDA approaches primarily focus on classifying discrete labels independently. In tasks such as medical diagnosis, where labels are distributed successively and in a discrete manner, UDA for ordinal classification becomes necessary. This involves establishing a non-trivial ordinal distribution prior in the latent space. To achieve this, a partially ordered set (poset) is defined to constrain the latent vector. Instead of the usual i.i.d. Gaussian latent prior, this study introduces a recursively conditional Gaussian (RCG) set for modeling ordered constraints, which allows for a manageable joint distribution prior. Additionally, the density of content vectors that violate the poset constraints can be controlled using a simple "three-sigma rule". The cross-domain images are explicitly separated into a shared ordinal content space induced by a shared ordinal prior, and two distinct source/target ordinal-unrelated spaces. Self-training is exclusively performed on the shared space to align domains in an ordinal-aware manner. Extensive experiments on UDA in medical diagnoses and facial age estimation confirm the effectiveness of this approach.