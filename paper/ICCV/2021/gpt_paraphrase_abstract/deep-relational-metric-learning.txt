This study introduces a deep relational metric learning (DRML) framework that aims to improve image clustering and retrieval. While current deep metric learning methods focus on increasing distances between different classes and decreasing distances within the same class, they often overlook the importance of intraclass variations for identifying samples from unseen classes. To overcome this limitation, the authors propose an adaptive approach that learns an ensemble of features to capture both interclass and intraclass distributions. Additionally, a relational module is employed to capture correlations among the features and create a graph representation of each image. By performing relational inference on the graph, the ensemble is integrated to obtain a relation-aware embedding that measures similarities. The effectiveness of the proposed framework is demonstrated through extensive experiments on popular datasets, such as CUB-200-2011, Cars196, and Stanford Online Products, where it outperforms existing deep metric learning methods and achieves competitive results.