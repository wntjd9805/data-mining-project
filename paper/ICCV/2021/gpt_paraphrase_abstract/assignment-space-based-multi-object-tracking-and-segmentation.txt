MOTS, or multi-object tracking and segmentation, is crucial for analyzing dynamic scenes in video data. While current methods excel at detecting and segmenting multiple objects in individual frames, tracking objects over time remains a difficult task. Existing MOTS approaches handle tracking locally, on a frame-by-frame basis, which leads to less than optimal outcomes. Traditional global methods for tracking operate directly on object detections, resulting in exponential growth in the detection space. In contrast, our approach formulates a global method for MOTS based on assignments rather than detections. We first identify all top-k assignments of detected and segmented objects between consecutive frames and develop a structured prediction formulation to evaluate assignment sequences across any number of frames. We utilize dynamic programming to find the global optimizer of this formulation efficiently. Additionally, we establish connections between objects that reappear after being out of view for a period of time, addressing this issue through an assignment problem. Our method achieves state-of-the-art results on challenging datasets without using depth data, as demonstrated on the KITTI-MOTS and MOTSChallenge datasets.