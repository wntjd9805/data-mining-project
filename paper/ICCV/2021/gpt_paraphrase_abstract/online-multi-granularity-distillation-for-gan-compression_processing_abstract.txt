Generative Adversarial Networks (GANs) have achieved great success in producing high-quality images. However, their deployment on devices with limited resources is challenging due to high computational costs and memory usage. Although some methods have been developed to compress GANs, they still have redundancies and can be further improved. To address this issue, we propose a new approach called online multi-granularity distillation (OMGD) to create lightweight GANs that generate high-quality images with low computational demands. Our method introduces a teacher generator that progressively improves a student generator, eliminating the need for a discriminator. By combining complementary teacher generators and network layers, we enhance visual fidelity from multiple perspectives. Experimental results on four benchmark datasets demonstrate that OMGD can compress MACs by 40× and parameters by 82.5× for Pix2Pix and CycleGAN without sacrificing image quality. This research provides a practical solution for real-time image translation on devices with limited resources. Our code and models are publicly available at: https://github.com/bytedance/OMGD.