Sketching a single example can be used to create a deep generative model, eliminating the need for a large dataset and specialized knowledge in deep learning. This paper introduces GAN Sketching, a method that allows novice users to train GAN models by modifying the weights based on user sketches. The model is trained to match the sketches through a cross-domain adversarial loss, while preserving diversity and image quality using different regularization methods. Experimental results demonstrate that this approach can produce realistic and diverse GAN outputs that match specified shapes and poses. The resulting GAN can also be used for latent space interpolation and image editing.