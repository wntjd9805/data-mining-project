Deep learning-based 3D object detection has made significant progress with the use of large-scale autonomous driving datasets. However, there is still a major challenge when it comes to deploying these models in different domains, as they often suffer from a significant drop in performance. Existing methods for adapting 3D object detection to different domains typically rely on having access to annotations from the target domain, which is often not feasible in real-world scenarios. To tackle this challenge, we propose a more realistic approach called unsupervised 3D domain adaptive detection, which only uses annotations from the source domain. Firstly, we extensively investigate the factors that contribute to the domain gap in 3D detection and find that geometric mismatch plays a crucial role. Based on this insight, we introduce a novel framework called Multi-Level Consistency Network (MLC-Net), which leverages a teacher-student paradigm to generate adaptive and reliable pseudo-targets. MLC-Net incorporates point-, instance-, and neural statistics-level consistency to facilitate knowledge transfer across domains. Extensive experiments demonstrate that our MLC-Net outperforms existing state-of-the-art methods, even those that utilize additional target domain information, on standard benchmarks. Importantly, our approach is detector-agnostic and consistently improves the performance of both single- and two-stage 3D detectors. We will release the code for our method.