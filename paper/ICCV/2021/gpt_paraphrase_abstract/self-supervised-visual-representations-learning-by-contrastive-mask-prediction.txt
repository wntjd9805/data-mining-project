Advanced techniques for self-supervised visual representation learning rely on the instance discrimination (ID) task. However, we argue that the ID task assumes semantic consistency (SC), which may not be valid in real-world datasets. To address this issue, we propose a new task called contrastive mask prediction (CMP) for visual representation learning. Our framework, called MaskCo, contrasts region-level features instead of view-level features, allowing us to identify positive samples without making any assumptions. To bridge the domain gap between masked and unmasked features, we introduce a dedicated mask prediction head in MaskCo, which plays a crucial role in the CMP's success. We evaluate MaskCo on various training datasets and compare its performance with MoCo V2. Our results demonstrate that MaskCo performs similarly to MoCo V2 when trained on ImageNet but outperforms it on a range of downstream tasks when trained on COCO or Conceptual Captions. Consequently, MaskCo provides a promising alternative to ID-based methods for self-supervised learning in real-world scenarios.