Domain adaptation techniques are commonly used to transfer knowledge from a label-rich source domain to a label-scarce target domain that shares the same label space. However, obtaining unlabeled target domain data for a specific task is often challenging. In such cases, zero-shot domain adaptation (ZSDA) can be employed to capture the domain shift between the source and target domains using an unseen task and apply it to the task of interest. Existing ZSDA methods mostly focus on generating target domain data, which is computationally expensive and difficult to optimize. This paper introduces a new ZSDA approach that learns a task-agnostic domain shift through collaborative training of domain-invariant semantic features and task-invariant domain features using adversarial learning. Additionally, disentangled feature representations are used to learn a spatial attention map that selectively highlights the domain-specific salient parts of the domain-invariant features. Experimental results demonstrate that this ZSDA method achieves state-of-the-art performance on various benchmarks.