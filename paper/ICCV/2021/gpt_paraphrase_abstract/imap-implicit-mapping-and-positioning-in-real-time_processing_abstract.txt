We present the first study demonstrating that a multilayer perceptron (MLP) can be used as the sole scene representation in a real-time simultaneous localization and mapping (SLAM) system for a handheld RGB-D camera. Our approach involves training the MLP in real-time without prior data, generating a dense 3D model of occupancy and color specific to the scene, which is immediately used for tracking. Achieving real-time SLAM through continual training of a neural network against a live image stream necessitates significant innovation. Our iMAP algorithm employs a keyframe structure and multi-processing computation flow, incorporating dynamic information-guided pixel sampling to optimize speed. We achieve tracking at 10 Hz and global map updating at 2 Hz. The implicit MLP offers several advantages over traditional dense SLAM techniques, including efficient geometry representation with automatic detail control and realistic filling-in of unobserved regions, such as the back surfaces of objects.