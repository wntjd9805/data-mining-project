Many CNN-based super-resolution (SR) methods use artificially synthesized low-resolution (LR) images from high-resolution (HR) images to create paired training datasets. However, this approach limits the application of these CNNs in real-world scenarios due to the difference between the training and testing data. To address this challenge, researchers have explored unpaired generative adversarial networks that generate realistic LR images from real HR images and then perform super-resolution from LR to HR. Despite progress, generating perfect LR images for super-resolution remains difficult. In this paper, the authors propose a novel unpaired SR training framework that focuses on aligning feature distributions. This framework allows for the creation of degradation-indistinguishable feature maps that can be mapped to HR images. To improve the generation of SR images for the target LR domain, several regularization losses are introduced to ensure that the aligned features are located around the target domain. Experimental results demonstrate that the proposed SR network achieves state-of-the-art performance in both blind and unpaired SR methods across diverse datasets.