Recent advancements in learning-based multi-view stereo (MVS) methods have demonstrated their effectiveness in terms of quality and efficiency. However, the limited availability of MVS data poses a challenge for generalizing these methods to unseen environments. One possible solution is to generate large-scale MVS datasets, but creating dense ground truth for 3D structures is time-consuming and resource-intensive. Alternatively, relaxing the dependency on dense ground truth can lead to smoother generalization of MVS systems to new environments.  To address this issue, we propose a novel semi-supervised framework called Sparse Ground truth-based MVS Network (SGT-MVSNet). This framework allows for reliable reconstruction of 3D structures even with a limited number of ground truth 3D points. Our approach involves dividing the regions into accurate and erroneous segments based on a probability map that can effectively separate them. We introduce a self-supervision loss, referred to as the 3D Point Consistency Loss, which enhances the 3D reconstruction performance by ensuring that the 3D points projected from the predicted depth values converge at the same 3D coordinates.  To further improve the accuracy, we employ the Coarse-to-fine Reliable Depth Propagation module, which propagates the refined depth predictions to edges and occlusions. In order to evaluate our method, we generate sparse ground truth for the DTU dataset. Extensive experiments demonstrate that SGT-MVSNet outperforms state-of-the-art MVS methods in the sparse ground truth setting. Remarkably, even with only tens or hundreds of ground truth 3D points, our method achieves comparable reconstruction results to fully supervised MVS methods.  In summary, our proposed SGT-MVSNet introduces a semi-supervised approach to multi-view stereo reconstruction that can reliably reconstruct 3D structures using sparse ground truth. By dividing regions and addressing them individually, leveraging self-supervision loss, and employing depth propagation techniques, our method achieves superior performance compared to existing methods while requiring fewer ground truth 3D points.