A new deep learning approach called Graph Convolutional Network with Point Refinement (PR-GCN) is proposed in this paper to address two limitations in RGB-D based 6D pose estimation. The first limitation is the ineffective representation of depth data, which is overcome by the introduction of the Point Refinement Network (PRN) that enhances 3D point clouds by removing noise and recovering missing parts. The second limitation is the insufficient integration of different modalities, which is addressed by the Multi-Modal Fusion Graph Convolutional Network (MMF-GCN) that captures geometry-aware inter-modality correlation through local information propagation in the graph convolutional network. The performance of the proposed approach is evaluated on three widely used benchmarks and achieves state-of-the-art results. Additionally, it is demonstrated that the PRN and MMF-GCN modules can be effectively generalized to other frameworks.