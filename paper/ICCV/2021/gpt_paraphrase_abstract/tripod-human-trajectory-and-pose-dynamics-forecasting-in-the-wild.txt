We present a novel approach called TRiPOD for joint forecasting of human trajectory and pose dynamics. This is crucial for applications like robotics, autonomous driving, and surveillance systems. Our method utilizes graph attentional networks to capture human-human and human-object interactions in both the input and output spaces. We also incorporate a message passing interface to effectively fuse these interactions. Additionally, we address the challenge of occlusion or being outside the sensor field of view by learning an indicator for the visibility of body joints in each frame. To evaluate our approach, we introduce a new benchmark using two challenging datasets and propose evaluation metrics for predictions in the global space, including cases with invisible joints. Our evaluation demonstrates that TRiPOD outperforms previous methods and state-of-the-art approaches specifically designed for trajectory and pose forecasting tasks.