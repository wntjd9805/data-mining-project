Recent research suggests that softmax cross-entropy losses are not only effective for fixed-set classification tasks but also outperform losses designed specifically for open-set tasks like few-shot learning and retrieval. Previous studies have examined softmax classifiers using different embedding geometries (Euclidean, hyperbolic, and spherical) and claimed superiority of one over the others, but a systematic comparison with careful controls has been lacking. To address this gap, we empirically investigate the impact of embedding geometry on softmax losses for various fixed-set classification and image retrieval tasks. Notably, we uncover an interesting property of spherical losses, leading us to propose a probabilistic classifier based on the von Mises-Fisher distribution, which achieves competitive performance compared to state-of-the-art methods and exhibits improved out-of-the-box calibration. Additionally, we offer guidance on the trade-offs between different loss functions and provide recommendations for choosing among them.