Contrastive learning methods have greatly reduced the disparity between supervised and unsupervised learning in computer vision tasks. This study focuses on applying these methods to geo-located datasets, such as remote sensing, where there is an abundance of unlabeled data but a scarcity of labeled data. The researchers initially find that there still exists a significant gap between contrastive and supervised learning on standard benchmarks due to their distinct characteristics. To bridge this gap, they propose innovative training techniques that utilize the spatial and temporal structure of remote sensing data. By utilizing spatially aligned images over time, they create temporal positive pairs for contrastive learning and incorporate geo-location information for designing pretext tasks. Through experiments, they demonstrate that their proposed method successfully closes the gap between contrastive and supervised learning in tasks like image classification, object detection, and semantic segmentation for remote sensing. Additionally, they showcase the applicability of their approach to geo-tagged ImageNet images, resulting in improved performance in downstream tasks.