CNN has made significant advancements in face alignment performance. However, little attention has been given to the error-bias related to the distribution of errors in facial landmarks. This error-bias is important as it is connected to the ambiguous task of labeling landmarks. Based on this observation, we propose the anisotropic direction loss (ADL) and anisotropic attention module (AAM) to improve the convergence of CNN models. ADL enforces a strong binding force in the normal direction for each landmark point on facial boundaries, while AAM is an attention module that focuses on the region of a point and its local edge connected by adjacent points, with a stronger response in the tangent direction. These two methods complement each other by learning both facial structures and texture details. We integrate them into a training pipeline called ADNet, which achieves state-of-the-art results on 300W, WFLW, and COFW datasets, demonstrating its effectiveness and robustness.