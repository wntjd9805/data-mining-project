We introduce GANcraft, an unsupervised neural rendering framework that can generate realistic images of large 3D block worlds, such as those found in Minecraft. Our approach utilizes a semantic block world, where each block is labeled with a specific semantic category (e.g., dirt, grass, water). We represent the block world as a continuous volumetric function and train our model to generate photorealistic images that are consistent with the user's perspective.  Since there is no paired ground truth data available for the block world, we employ a training technique that relies on pseudo-ground truth and adversarial training. This differs from previous neural rendering methods for view synthesis, which typically require ground truth images to estimate scene geometry and appearance from different perspectives.  In addition to controlling the camera's trajectory, GANcraft allows users to manipulate scene semantics and output style. We conducted experiments and compared GANcraft to strong baseline methods, demonstrating its effectiveness in synthesizing photorealistic images of 3D block worlds. More information about the project can be found at https://nvlabs.github.io/GANcraft/.