The challenges of self-supervised depth estimation in indoor environments are addressed in this paper. Indoor sequences have a wide range of depth variations across frames, making it difficult for the depth network to establish consistent depth cues. In contrast, outdoor scenes usually have a constant maximum distance as the camera primarily captures the sky. Additionally, indoor sequences involve more rotational motions, posing difficulties for the pose network. On the other hand, outdoor sequences, especially in driving datasets like KITTI, mainly consist of translational motions. To overcome these challenges, the paper proposes two novel modules: a depth factorization module and a residual pose estimation module. The depth factorization module aims to handle the varying depth range in indoor sequences, while the residual pose estimation module addresses the rotational motions. The effectiveness of each module is demonstrated through an ablation study, and the proposed method achieves state-of-the-art performance on three indoor datasets: EuRoC, NYUv2, and 7-Scenes.