Few-shot semantic segmentation (FSS) is a crucial task for segmenting novel objects when there is limited data available. However, existing FSS methods often rely on one-way feature aggregation, such as using support prototypes for query prediction or using high-resolution features to guide low-resolution ones. This approach fails to effectively capture the relationships between features of different resolutions, resulting in inaccurate segmentation estimates.To address this issue, we propose a cyclic memory network (CMN) that learns to read support information from all resolution features in a cyclic manner. Firstly, we generate multiple pairs of query features with different resolutions based on the support feature and its mask. Then, we iteratively select one pair as the query to be segmented while the remaining pairs are written into an external memory. This process is repeated for each pair. In each cycle, the query feature is updated by matching its key and value with the memory, allowing for comprehensive coverage of spatial locations across different resolutions. Additionally, we incorporate mechanisms for query feature re-adding and recursive updating into the memory reading operation. These enhancements enable CMN to capture cross-resolution relationships and effectively handle object appearance and scale variations in FSS.We conducted experiments on PASCAL-5i and COCO-20i datasets, which confirmed the effectiveness of our CMN model for FSS. Figure 1 illustrates a comparison between existing FSS methods and our CMN. Existing methods fail to overcome object variations and incorrectly predict some car regions as airplanes. In contrast, CMN accurately predicts the airplane in the query image, benefiting from its cyclic memory reading on multi-resolution features.