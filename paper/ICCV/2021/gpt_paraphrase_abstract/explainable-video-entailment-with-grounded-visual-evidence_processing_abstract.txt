Video entailment involves determining whether a textual statement is supported or contradicted by a video. The main challenge in video entailment lies in comprehending complex and narrative-driven videos, requiring detailed reasoning. To address this, we propose incorporating visual grounding by explicitly connecting the entities mentioned in the statement to evidence in the video. By grounding the entities in the video, we can improve the accuracy of the entailment judgment by focusing on the frames where these entities appear. Additionally, the entailment dataset consists of pairs of statements that are subtly different, with one being entailed and the other contradicted by the video. This allows us to employ an explanation module to identify the specific words or phrases that contribute to the contradiction, thereby facilitating the training of the entailment judgment. Our experimental results demonstrate that our approach surpasses the performance of existing methods.