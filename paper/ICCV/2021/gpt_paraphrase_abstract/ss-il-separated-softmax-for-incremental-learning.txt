We examine the problem of class incremental learning (CIL), where an agent continuously learns new classes from incoming training data and aims to predict accurately on all previously learned classes. The main challenge in CIL is catastrophic forgetting, which occurs when the agent forgets previously learned classes when learning new ones. This issue is commonly caused by a bias in the classification scores due to imbalanced data between the new and old classes in the exemplar-memory of the agent. Previous methods have attempted to address this bias through post-processing techniques such as score re-scaling or balanced fine-tuning, but there has been no systematic analysis of the root cause of the bias.In this study, we analyze that the bias may originate from computing softmax probabilities by combining the output scores for both old and new classes. Based on this analysis, we propose a novel method called Separated Softmax for Incremental Learning (SS-IL). SS-IL utilizes a separated softmax output layer in conjunction with task-wise knowledge distillation to alleviate the bias. Our extensive experiments on various large-scale CIL benchmark datasets demonstrate that SS-IL achieves state-of-the-art accuracy by achieving more balanced prediction scores across old and new classes. Notably, SS-IL does not require any additional post-processing techniques.