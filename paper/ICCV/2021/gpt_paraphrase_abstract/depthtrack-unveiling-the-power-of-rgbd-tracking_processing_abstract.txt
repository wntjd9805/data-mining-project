RGBD object tracking is becoming more popular with the rise of RGBD sensors in various fields, including robotics. However, the current best RGBD trackers are essentially extensions of deep RGB trackers. These trackers are trained using RGB data, with the depth channel serving as a supplementary feature for tasks like detecting occlusion. The reason for this is the lack of sufficiently large RGBD datasets that can be used to train "deep depth trackers" or challenge RGB trackers in scenarios where depth cues are crucial. To address this issue, this study introduces a new RGBD tracking dataset called Depth-Track. This dataset contains twice as many sequences (200) and scene types (40) compared to the largest existing dataset. It also includes three times more objects (90), longer sequences (average length of 1473), more deformable objects (16), and a greater number of annotated tracking attributes (15). Additionally, the proposed DeT baseline is established by running state-of-the-art RGB and RGBD trackers on the Depth-Track dataset. This baseline demonstrates that deep RGBD tracking indeed benefits from genuine training data. The code and dataset for DeT are publicly available at https://github.com/xiaozai/DeT.