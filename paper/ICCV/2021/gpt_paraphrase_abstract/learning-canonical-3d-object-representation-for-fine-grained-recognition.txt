We present a new framework for fine-grained object recognition that can learn to recognize objects in 3D space using a single image. Unlike traditional methods that rely on ground-truth 3D annotation, our approach represents an object as a combination of its 3D shape and appearance, while disregarding the camera viewpoint. By reconfiguring the appearance feature in a canonical 3D space, our method ensures that the subsequent object classifier is invariant to 3D geometric variation. Additionally, our representation allows us to incorporate 3D shape variation as an additional cue for object recognition, surpassing existing methods. To train the model without ground-truth 3D annotation, we utilize a differentiable renderer within an analysis-by-synthesis framework. By combining 3D shape and appearance in a deep representation, our method learns a discriminative representation of the object and achieves competitive performance in fine-grained image recognition and vehicle re-identification. Furthermore, we demonstrate that learning fine-grained shape deformation in a boosting manner improves the performance of 3D shape reconstruction.