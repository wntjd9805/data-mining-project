In recent years, there has been a growing interest in RGB-D semantic segmentation. However, existing methods tend to treat RGB and depth features equally, despite their inherent differences. RGB values capture the appearance properties in the image space, while depth features encode both local geometry and its location in a larger context. The shape component of depth is more inherent and connected to semantics, making it crucial for accurate segmentation. To address this, we propose a Shape-aware Convolutional layer (ShapeConv) for processing depth features. This layer decomposes the depth feature into shape and base components, introduces learnable weights for each component, and applies a convolution on the re-weighted combination. ShapeConv can be easily integrated into most CNNs for semantic segmentation and has been tested on three challenging benchmarks, demonstrating its effectiveness across various architectures. Importantly, ShapeConv improves performance without increasing computation or memory usage during inference, as the learned weights become constants and can be fused into the following convolution.