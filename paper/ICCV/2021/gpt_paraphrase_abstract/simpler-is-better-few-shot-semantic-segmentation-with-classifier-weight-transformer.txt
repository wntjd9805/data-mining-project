A few-shot semantic segmentation model typically consists of a CNN encoder, a CNN decoder, and a classifier. Existing methods often meta-learn all three components to adapt quickly to new classes. However, this becomes extremely challenging when there is only one support set image available for adaptation. To simplify the meta-learning task, we propose focusing on meta-learning the classifier while pre-training the encoder and decoder. We believe that if we pre-train a segmentation model on a diverse set of annotated training classes, the encoder and decoder can capture discriminative features that can be applied to unseen classes, eliminating the need for meta-learning. For the classifier meta-learning, we introduce a Classifer Weight Transformer (CWT) that dynamically adapts the weights of the support-set trained classifier to each query image in an inductive manner. Our extensive experiments on two standard benchmarks demonstrate that our method outperforms state-of-the-art alternatives by a significant margin, despite its simplicity. The code for our method is available on https://github.com/zhiheLu/CWT-for-FSS.