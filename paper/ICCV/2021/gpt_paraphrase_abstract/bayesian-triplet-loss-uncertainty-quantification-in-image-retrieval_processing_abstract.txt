The problem of uncertainty quantification in image retrieval is important but challenging. Existing methods for estimating uncertainties are either poorly calibrated, computationally expensive, or based on heuristics. We propose a novel approach that considers image embeddings as stochastic features rather than deterministic ones. Our approach has two main contributions: (1) a likelihood function that satisfies the triplet constraint and calculates the probability of an anchor image being closer to a positive image than a negative image, and (2) a prior distribution over the feature space that justifies the conventional l2 normalization. To ensure computational efficiency, we introduce a variational approximation of the posterior, called the Bayesian triplet loss, which provides accurate uncertainty estimates and achieves comparable predictive performance to current state-of-the-art methods.