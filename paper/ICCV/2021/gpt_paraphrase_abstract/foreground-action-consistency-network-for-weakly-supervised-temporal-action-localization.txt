Weakly supervised temporal action localization is a challenging task in video understanding. Most existing methods use a localization-by-classification framework, where a selector is used to choose snippets with high action probabilities, or foreground. However, these methods only consider the relation from foreground to actions, which can lead to inconsistencies. In this paper, we propose a framework called FAC-Net that addresses this issue. FAC-Net consists of three branches: class-wise foreground classification, class-agnostic attention, and multiple instance learning. The class-wise foreground classification branch maximizes the separation between foreground and background to ensure foreground-action consistency. The attention branch and multiple instance learning branch further regularize this consistency and aid in learning a meaningful foreground classifier. Each branch employs a hybrid attention mechanism that focuses on both discriminative and less-discriminative snippets to capture full action boundaries. Experimental results on THUMOS14 and ActivityNet1.3 datasets demonstrate that our method achieves state-of-the-art performance.