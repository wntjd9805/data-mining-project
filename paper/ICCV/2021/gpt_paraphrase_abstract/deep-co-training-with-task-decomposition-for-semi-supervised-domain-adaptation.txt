Semi-supervised domain adaptation (SSDA) is a technique used to adapt models trained on a labeled source domain to a similar but different target domain. Current methods overlook the inherent differences between the source and target domains, resulting in a model that does not effectively utilize the labeled target data. In this paper, we propose a new approach called Deep Co-training with Task decomposition (DECOTA) that explicitly distinguishes between the labeled target data and the unsupervised domain adaptation task. By decomposing the SSDA task into two sub-tasks, DECOTA is able to leverage the corresponding supervision more effectively, resulting in different classifiers for each sub-task. DECOTA combines the strengths of these classifiers using the co-training framework, where they exchange their confident predictions to improve each other's performance in the target domain. Unlike other methods, DECOTA does not require adversarial training and is easy to implement. Additionally, DECOTA is theoretically grounded in the conditions for successful co-training. Experimental results on several SSDA datasets, including DomainNet, show that DECOTA outperforms prior art by a significant margin of 4%. The code for DECOTA is available at https://github.com/LoyoYang/DeCoTa.