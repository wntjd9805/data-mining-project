Person re-identification (ReID) has made significant advancements in recent years. However, occlusion remains a prevalent and challenging issue for ReID methods. Many existing approaches utilize additional cues, such as human pose information, to distinguish human body parts from obstacles and mitigate the occlusion problem. Despite achieving promising results, these methods heavily rely on accurate and detailed extra cues, making them susceptible to estimation errors. In this study, we demonstrate that current methods can degrade when the extra information is sparse or noisy. To address this, we propose a straightforward yet effective method that is resilient to sparse and noisy pose information. We achieve this by discretizing pose information into visibility labels for body parts, thereby minimizing the impact of occluded regions. Our experiments show that leveraging pose information in this manner is more effective and robust. Furthermore, our method can be easily incorporated into most person ReID models. Extensive experiments confirm the efficacy of our model on commonly used occluded person ReID datasets.