We introduce a novel learning-based method for restoring images that have spatially-varying degradations. Previous approaches have focused on specific types of degradation and applied the same processing to all images and pixels, which we believe is not optimal for restoring both degraded and clean regions. To overcome this limitation, we propose a network called SPAIR that incorporates distortion-localization information and dynamically adjusts computation for challenging regions. SPAIR consists of a localization network to identify degraded pixels and a restoration network that selectively and adaptively restores them using knowledge from the localization network. Our approach takes advantage of the non-uniformity of heavy degradations in the spatial domain and incorporates this knowledge into sparse normalization, feature extraction, and attention modules. Our architecture is versatile and can handle various types of spatially-varying degradations without relying on a specific formation model. We evaluate SPAIR on four restoration tasks: removing rain-streaks, raindrops, shadows, and motion blur. Extensive qualitative and quantitative comparisons with previous methods on 11 benchmark datasets demonstrate that our degradation-agnostic network design significantly outperforms state-of-the-art degradation-specific architectures. The code for SPAIR is available at https://github.com/human-analysis/spatially-adaptive-image-restoration.