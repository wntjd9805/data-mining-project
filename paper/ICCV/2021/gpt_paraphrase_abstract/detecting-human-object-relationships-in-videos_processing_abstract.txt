We focus on the problem of detecting human-object relationships in videos, which has been primarily addressed in static image scenarios without considering the importance of temporal dynamics. To overcome this limitation, we propose a model that combines Intra- and Inter-Transformers to facilitate spatial and temporal reasoning for various visual concepts including objects, relationships, and human poses. By incorporating attention mechanisms among spatio-temporally distributed features, we significantly enhance our ability to understand human-object relationships. We validate our method using two datasets, Action Genome and CAD-120-EVAR, and demonstrate its superior performance compared to existing approaches.