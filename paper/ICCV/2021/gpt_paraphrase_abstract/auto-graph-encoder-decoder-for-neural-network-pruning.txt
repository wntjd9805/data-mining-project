Model compression techniques aim to deploy deep neural networks (DNNs) on mobile devices that have limited computing and storage resources. However, most existing methods for model compression rely on manually defined rules, which require domain expertise. DNNs can be represented as computational graphs that contain valuable structural information. This paper introduces an automatic graph encoder-decoder model compression (AGMC) method that combines graph neural networks (GNN) and reinforcement learning (RL). The target DNN is modeled as a graph, and GNN is used to automatically learn the embeddings of the DNN. Our method is compared with rule-based DNN embedding model compression methods to demonstrate its effectiveness. The results indicate that our learning-based DNN embedding approach achieves superior performance and a higher compression ratio with fewer search steps. We evaluated our method on over-parameterized and mobile-friendly DNNs and compared it with handcrafted and learning-based model compression approaches. On over-parameterized DNNs like ResNet-56, our method outperformed handcrafted and learning-based methods with an accuracy improvement of 4.36% and 2.56%, respectively. Moreover, on MobileNet-v2, our method achieved a higher compression ratio than state-of-the-art techniques with only a 0.93% loss in accuracy.