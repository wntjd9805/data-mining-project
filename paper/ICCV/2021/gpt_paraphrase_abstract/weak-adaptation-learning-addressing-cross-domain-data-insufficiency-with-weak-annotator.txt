In data-driven learning methods, the availability and quality of data are essential. However, certain problem domains lack sufficient data samples, which can impede the learning process. To overcome this challenge, domain adaptation can be utilized by leveraging data from similar domains. However, obtaining high-quality labeled data for these source domains can be difficult and expensive. To address the issue of insufficient data for classification problems in a target domain, we propose a solution called weak adaptation learning (WAL). WAL utilizes unlabeled data from a similar source domain, a low-cost weak annotator that produces labels based on heuristics or rules (though with some inaccuracy), and a small amount of labeled data in the target domain. Our approach involves a theoretical analysis of the classifier's error bound in relation to the data quantity and the weak annotator's performance. We then introduce a multi-stage weak adaptation learning method to lower the error bound and train an accurate classifier. Our experiments demonstrate the effectiveness of our approach in learning an accurate classifier using limited labeled data in the target domain and unlabeled data in the source domain.