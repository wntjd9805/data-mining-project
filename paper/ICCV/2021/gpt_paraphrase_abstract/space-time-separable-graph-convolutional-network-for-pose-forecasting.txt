Human pose forecasting is a challenging task that has gained attention due to its various potential applications. Previous research has focused on the temporal dimension and the interaction of human body joints using either a kinematic tree or a graph. However, this approach has limited our understanding of the complex spatio-temporal dynamics of human pose. In this study, we propose a new approach called Space-Time-Separable Graph Convolutional Network (STS-GCN) for pose forecasting. For the first time, STS-GCN models human pose dynamics using a graph convolutional network, incorporating both temporal evolution and spatial joint interaction within a single graph framework. This allows for the consideration of motion and spatial correlations. STS-GCN is also the first space-time-separable GCN, meaning that the space-time graph connectivity is factored into separate space and time affinity matrices. This limits the cross-talk between space and time while still enabling joint-joint and time-time correlations. Both affinity matrices are learned end-to-end, resulting in connections that differ from the standard kinematic tree and linear-time time series. Experimental evaluation on three complex benchmarks shows that STS-GCN outperforms the state-of-the-art technique, achieving a 32% improvement in average long-term predictions while only requiring 1.7% of its parameters. The qualitative results and learned graph connections provide insight into the interactions within the graph. The source code for STS-GCN is available at the provided GitHub link.