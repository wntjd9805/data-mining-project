Image inpainting is a technique used to fill in missing or corrupted regions of images with realistic content. Current methods typically use generative adversarial networks to balance reconstruction and perceptual quality. However, combining these two objectives often leads to conflicts between different frequencies and compromised inpainting results. This paper introduces WaveFill, a wavelet-based inpainting network that decomposes images into multiple frequency bands and fills in the missing regions in each band separately. By using the discrete wavelet transform, WaveFill preserves spatial information during decomposition. The network applies an L1 reconstruction loss to the low-frequency bands and an adversarial loss to the high-frequency bands, effectively addressing inter-frequency conflicts and completing images in the spatial domain. To handle inconsistencies between frequency bands and merge features with different statistical properties, a novel normalization scheme is designed. Experimental results demonstrate that WaveFill achieves superior image inpainting quality both qualitatively and quantitatively. Previous approaches have attempted to balance reconstruction and perceptual quality by combining different loss functions or employing a Coarse-to-Fine strategy. However, these methods often produce inconsistent distributions and artifacts. In contrast, WaveFill disentangles images into multiple frequency bands and applies relevant losses to each band separately, resulting in more realistic structures and details. The performance of WaveFill is evaluated using Earth Mover's Distance to measure the differences between ground-truth and predicted histograms in both low-frequency and high-frequency bands.