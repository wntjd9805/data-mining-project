ALADIN (All Layer AdaIN) is a new architecture designed for image search based on artistic style similarity. In visual search, the learned search embedding plays a crucial role in determining the similarity between images. However, discriminating fine-grained variations in style is challenging due to the lack of clear definitions and labels for style. To address this issue, ALADIN takes a weakly supervised approach and leverages BAM-FG, a large-scale dataset consisting of user-generated content groupings collected from the internet. By utilizing BAM-FG, ALADIN achieves state-of-the-art accuracy for style-based visual search, surpassing previous methods on both coarse labeled style data (BAM) and BAM-FG. This work also contributes a new dataset called BAM-FG, which includes 2.62 million images categorized into 310,000 fine-grained style groups.