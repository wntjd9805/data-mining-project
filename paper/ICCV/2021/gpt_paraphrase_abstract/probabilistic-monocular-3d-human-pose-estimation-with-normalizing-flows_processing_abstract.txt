3D human pose estimation from monocular images is a challenging problem due to depth ambiguities and occlusions. However, existing methods often overlook these issues and only provide a single solution. In contrast, our approach generates a diverse set of hypotheses that represent the full range of possible 3D poses. We achieve this by using a normalizing flow based method that leverages the deterministic 3D-to-2D mapping to solve the ambiguous inverse 2D-to-3D problem. We also effectively handle uncertain detections and occlusions by incorporating the uncertainty information from the 2D detector. Key factors contributing to our success include a learned 3D pose prior and a generalized best-of-M loss. Our approach surpasses all comparable methods in most metrics on the benchmark datasets Human3.6M and MPI-INF-3DHP. The implementation of our method is available on GitHub1.