This study presents a lightweight model for estimating disparities in light field images. Light fields contain both angular and spatial information of captured light rays, allowing for straightforward disparity recovery but requiring high computational cost. To address this, the researchers develop a physical-based multi-disparity-scale cost volume aggregation model that reduces computation cost and GPU memory consumption. By incorporating a sub-network of edge guidance, the model improves the recovery of geometric details near edges and overall performance. The proposed model is extensively tested on synthetic and real-captured datasets with densely and sparsely sampled light fields. Despite the reduced computational requirements, the model achieves comparable performance to state-of-the-art disparity estimation methods for light fields. The source code for the model is available at https://github.com/zcong17huang/FastLFnet.