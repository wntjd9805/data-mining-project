The use of part-level interpretable neural network architectures has been proposed as a way for humans to explain their reasoning in image classification tasks. However, these architectures struggle with the complexity of data structure and fail to accurately determine the effect of individual parts on the output category. This study introduces a new interpretable image recognition deep network called TesNet, which incorporates a plug-in transparent embedding space. This space is constructed using category-aware and orthogonal basis concepts on the Grassmann manifold, allowing for disentanglement and transparency in the reasoning process. TesNet outperforms other interpretable methods in classification tasks, providing better interpretability and improving accuracy. The code for TesNet is available at https://github.com/JackeyWang96/TesNet.