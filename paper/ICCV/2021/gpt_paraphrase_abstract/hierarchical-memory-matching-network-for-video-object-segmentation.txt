We introduce the Hierarchical Memory Matching Network (HMMN) for semi-supervised video object segmentation. Building upon a recent memory-based method, we propose two advanced memory read modules that allow us to perform memory reading at multiple scales while also considering temporal smoothness. Instead of using the commonly adopted non-local dense memory read, we propose a kernel guided memory matching module that enforces temporal smoothness in memory retrieval, resulting in accurate memory retrieval. Additionally, we introduce a hierarchical memory matching scheme and propose a top-k guided memory matching module, where memory read on a fine-scale is guided by that on a coarse-scale. This allows us to efficiently perform memory read at multiple scales and utilize both high-level semantic and low-level fine-grained memory features to predict detailed object masks. Our network achieves state-of-the-art performance on the validation sets of DAVIS 2016/2017 (90.8% and 84.7%) and YouTube-VOS 2018/2019 (82.6% and 82.5%), as well as the test-dev set of DAVIS 2017 (78.6%). The source code and model can be found online at: https://github.com/Hongje/HMMN.