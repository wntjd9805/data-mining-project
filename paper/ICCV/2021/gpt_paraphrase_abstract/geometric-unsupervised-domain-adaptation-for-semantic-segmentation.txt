Simulators can effectively generate large amounts of labeled synthetic data for difficult labeling tasks like semantic segmentation. However, there is a domain gap between the simulated data and real-world performance. To address this issue, we propose using self-supervised monocular depth estimation as a proxy task to bridge the gap and enhance sim-to-real unsupervised domain adaptation (UDA). Our method, called Geometric Unsupervised Domain Adaptation (GUDA), learns a domain-invariant representation by combining synthetic semantic supervision with real-world geometric constraints on videos. GUDA achieves state-of-the-art results in UDA for semantic segmentation on three benchmarks, surpassing methods that use domain adversarial learning, self-training, or other self-supervised proxy tasks. Additionally, our method demonstrates scalability with the quality and quantity of synthetic data, while also improving depth prediction.