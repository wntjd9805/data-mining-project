This paper presents a solution to the problem of video geo-localization through the introduction of the Geo-Temporal Feature Learning (GTFL) Network. The GTFL model, built on a transformer encoder architecture, simultaneously learns discriminative features for query video frames and gallery images to estimate the geo-spatial trajectory of a query video. The model utilizes separate branches to encode query and gallery data. The GPS Loss and Clip Triplet Loss, proposed in this study, leverage the proximity between frames and clips in both geographical and temporal aspects to jointly learn query and gallery features. Additionally, the paper introduces a deep learning approach to trajectory smoothing by predicting outliers in GPS positions and learning offsets to enhance the trajectory. The researchers constructed a comprehensive dataset using BDD driving videos as queries and corresponding Google StreetView (GSV) Images as gallery from four different regions in the USA, namely New York, San Francisco, Berkeley, and Bay Area. The effectiveness of the proposed method is extensively evaluated on this dataset, and the code and dataset details are publicly available at https://github.com/kregmi/VTE.