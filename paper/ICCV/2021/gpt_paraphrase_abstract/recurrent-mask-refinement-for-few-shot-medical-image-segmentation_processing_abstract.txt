Deep convolutional neural networks have been successful in medical image segmentation but require large annotated datasets for training and struggle with generalizing to unseen classes. Few-shot learning has the potential to overcome these challenges by learning new classes with only a few labeled examples. This study introduces a novel framework for few-shot medical image segmentation using prototypical networks. The framework includes a context relation encoder (CRE) that captures local relation features between foreground and background regions, and a recurrent mask refinement module that iteratively refines the segmentation mask by utilizing the CRE and a prototypical network. Experimental results on two abdomen CT datasets and an abdomen MRI dataset demonstrate significant improvements over state-of-the-art methods, with average increases of 16.32%, 8.45%, and 6.24% in terms of DSC, respectively. The code for the proposed method is publicly available.