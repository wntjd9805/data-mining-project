The problem of noisy data affects the performance of machine learning systems during both training and testing phases. Previous research has focused on learning with in-distribution noisy labels, where some training samples are labeled incorrectly. However, the influence of out-of-distribution samples, which do not belong to any known classes, has not been adequately explored. To address this, we introduce a new problem called Learning with Open-world Noisy Data (LOND). LOND aims to simultaneously learn a classifier and an out-of-distribution detector from datasets with mixed in-distribution and out-of-distribution noise. In this paper, we propose a new graph-based framework called Noisy Graph Cleaning (NGC) that identifies clean samples by leveraging the geometric structure of the data and model confidence. NGC can detect and reject out-of-distribution samples during the testing phase without any additional training. We evaluate our method on multiple benchmarks with different types of noise and our results demonstrate its superior performance compared to existing approaches.