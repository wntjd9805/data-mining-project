Deep neural networks have achieved impressive results in computer vision tasks. However, they struggle to handle new domains and subtle variations in input images. Several defenses have been proposed to address these issues, but they only work against specific attacks used during training and fail to protect against other input variations. Additionally, these defenses often decrease the model's performance on clean images and do not generalize well to out-of-domain samples. To overcome these limitations, we introduce Generative Adversarial Training. This approach aims to enhance the model's ability to generalize to the test set, out-of-domain samples, and unseen adversarial attacks. Instead of modifying low-level predefined aspects of images, we employ generative models with a disentangled latent space to generate a wide range of low-level, mid-level, and high-level changes. By training the model adversarially with these examples, it becomes capable of withstanding various attacks by experiencing diverse input alterations during training. Our approach not only improves the model's performance on clean images and out-of-domain samples but also enhances its robustness against unforeseen attacks, surpassing previous methods. We validate the effectiveness of our approach through experiments on classification, segmentation, and object detection tasks.