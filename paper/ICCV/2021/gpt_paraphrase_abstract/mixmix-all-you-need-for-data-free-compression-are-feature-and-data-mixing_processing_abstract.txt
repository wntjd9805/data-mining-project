Maintaining user data confidentiality in deep learning research is increasingly challenging. Traditional data-driven model compression methods face performance degradation without access to data. Some recent approaches generate images from a pretrained model for training data, but this inversion process has limitations in generalizability and accuracy. To address these issues, we propose MixMix, which utilizes feature mixing and data mixing techniques. MixMix outperforms existing methods in compression tasks such as quantization, knowledge distillation, and pruning. It achieves significant accuracy improvements compared to existing data-free compression methods.