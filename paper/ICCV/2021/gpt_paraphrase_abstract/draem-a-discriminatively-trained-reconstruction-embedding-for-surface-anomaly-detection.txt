Visual surface anomaly detection is the task of identifying image regions that deviate significantly from the normal appearance. Current methods rely on generative models to accurately reconstruct normal areas and fail on anomalies. However, these methods are limited to training on anomaly-free images and often require manual post-processing to locate the anomalies, hindering optimal feature extraction.To address these limitations, we propose a discriminatively trained reconstruction anomaly embedding model (DRÆM) that views surface anomaly detection as a discriminative problem. Our approach learns a joint representation of an anomalous image and its anomaly-free reconstruction, while simultaneously learning a decision boundary between normal and anomalous examples. This allows for direct anomaly localization without the need for complex post-processing. Furthermore, our method can be trained using simple and general anomaly simulations.We evaluate our approach on the challenging MVTec anomaly detection dataset and demonstrate that DRÆM outperforms the current state-of-the-art unsupervised methods by a large margin. Additionally, our method achieves detection performance comparable to fully-supervised methods on the widely used DAGM surface-defect detection dataset, while significantly surpassing them in terms of localization accuracy.Overall, our proposed method offers a more effective and efficient solution for visual surface anomaly detection, with improved performance and simplified anomaly localization. The code for our method can be found at github.com/VitjanZ/DRAEM.