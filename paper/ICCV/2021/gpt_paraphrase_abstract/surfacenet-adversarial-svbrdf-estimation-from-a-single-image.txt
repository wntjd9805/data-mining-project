This paper introduces SurfaceNet, a method for estimating spatially-varying bidirectional reflectance distribution function (SVBRDF) material properties from a single image. The approach treats the problem as an image translation task and proposes a novel patch-based generative adversarial network (GAN) that can generate high-quality, high-resolution surface reflectance maps. The use of GANs serves two purposes: 1) enabling the model to capture finer details compared to standard translation models, and 2) reducing the discrepancy between synthetic and real data distributions in an unsupervised manner. Extensive evaluation on synthetic and real images, considering various illumination conditions, demonstrates that SurfaceNet outperforms existing SVBRDF reconstruction methods both quantitatively and qualitatively. Notably, SurfaceNet achieves impressive results in generating high-quality maps from real samples without any supervision during training. The source code for SurfaceNet is available at https://github.com/perceivelab/surfacenet.