Recently, there have been attempts to use deep convolutional networks for superpixel segmentation. The usual approach involves dividing the image into a predetermined number of grids and learning to associate each pixel with its surrounding grids. However, this method only implicitly captures the relationships between pixels and their surrounding grids using convolution operations with limited receptive fields. As a result, existing methods often struggle to provide effective context when inferring the association map. To address this issue, we propose a new module called Association Implantation (AI) that allows the network to explicitly capture the relations between pixels and their surrounding grids. The AI module directly implants grid features around the central pixel and performs convolution on the padded window to transfer knowledge between them adaptively. This implantation operation enables the network to explicitly capture the pixel-grid level context, which is more aligned with the goal of superpixel segmentation compared to pixel-wise relations. Additionally, to improve boundary precision, we introduce a boundary-perceiving loss that helps the network identify pixels around boundaries in hidden feature levels. This benefits the subsequent inference modules in accurately identifying more boundary pixels. Extensive experiments on BSDS500 and NYUv2 datasets demonstrate that our method achieves state-of-the-art performance. The code and pre-trained model are available at https://github.com/wangyxxjtu/AINet-ICCV2021.