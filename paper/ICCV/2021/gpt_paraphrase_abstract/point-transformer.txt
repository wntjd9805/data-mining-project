Self-attention networks have had a significant impact on natural language processing and are now being applied to image analysis tasks as well. In this study, we explore the potential of self-attention networks in processing 3D point clouds. We develop self-attention layers specifically designed for point clouds and utilize them to create self-attention networks for tasks such as semantic scene segmentation, object part segmentation, and object classification. Our Point Transformer design outperforms previous approaches in various domains and tasks. For instance, when applied to the challenging S3DIS dataset for large-scale semantic scene segmentation, the Point Transformer achieves an mIoU (mean Intersection over Union) of 70.4% on Area 5. This surpasses the performance of the best previous model by 3.3 percentage points, and it is the first time a model has crossed the 70% mIoU threshold in this dataset.