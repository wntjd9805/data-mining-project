We introduce imGHUM, the first comprehensive generative model for representing 3D human shape and articulated pose using a signed distance function. Unlike previous approaches, our model represents the entire human body implicitly without relying on an explicit template mesh. To achieve this, we propose a novel network architecture and learning paradigm that enable the learning of a detailed generative model capable of capturing human pose, shape, and semantics with high fidelity, comparable to state-of-the-art mesh-based models. Our model preserves important details such as articulated pose, hand motion, facial expressions, and a wide range of shape variations. Moreover, it can be queried at any resolution and spatial location. Additionally, our model incorporates spatial semantics, facilitating the establishment of correspondences between different shape instances. This feature opens up possibilities for applications that are challenging to address using traditional implicit representations. Through extensive experiments, we validate the accuracy of our model and demonstrate its utility in solving current research problems.