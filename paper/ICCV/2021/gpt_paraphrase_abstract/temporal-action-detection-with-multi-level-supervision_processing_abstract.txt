Training temporal action detection in videos requires a large amount of labeled data, which can be expensive to collect. To address this issue, this study introduces the Semi-supervised Action Detection (SSAD) task, which combines labeled and unlabeled data. The researchers analyze the errors in the proposed SSAD baselines and identify action incompleteness as the main source of error. To mitigate this issue, they design an unsupervised foreground attention (UFA) module that leverages the conditional independence between foreground and background motion.Furthermore, weakly-labeled data is incorporated into SSAD, resulting in the Omni-supervised Action Detection (OSAD) approach with three levels of supervision. However, OSAD baselines suffer from action-context confusion. To overcome this problem, an information bottleneck (IB) is designed to suppress scene information in non-action frames while preserving action information.The proposed methods are extensively evaluated against the baselines for SSAD and OSAD using data splits from THUMOS14 and ActivityNet1.2 datasets. The effectiveness of the UFA and IB methods is demonstrated. Additionally, the study explores the optimal annotation strategy for labeled, unlabeled, and weakly-labeled data, showcasing the benefits of the full OSAD-IB model under limited annotation budgets.