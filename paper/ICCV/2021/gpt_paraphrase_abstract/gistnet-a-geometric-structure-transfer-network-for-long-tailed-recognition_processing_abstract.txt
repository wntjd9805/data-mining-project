The issue of long-tailed recognition, where there is a significant imbalance in the number of examples per class, is addressed in this study. The authors propose a novel approach to transfer learning by exploiting the tendency of standard classifier training to overfit to popular classes. Instead of trying to eliminate this overfitting, the learning algorithm should utilize it to transfer geometric information from popular classes to low-shot classes. To achieve this, a new classifier architecture called GistNet is introduced, which uses constellations of classifier parameters to encode class geometry. Additionally, a new learning algorithm called GeometrIc Structure Transfer (GIST) is proposed, which combines class-balanced and random sampling to restrict overfitting to geometric parameters while leveraging it to transfer class geometry. This approach allows for better generalization to few-shot classes without the need for manual specification of class weights or explicit grouping of classes. Experimental results on two long-tailed recognition datasets demonstrate that GistNet outperforms existing solutions for this problem.