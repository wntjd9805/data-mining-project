Few-shot classification aims to classify categories of a new task with only a small number of labeled examples. One effective approach is to use a prior model trained on a large base domain and fine-tune it on the new task to obtain generalized representations. However, fine-tuning on a specific task can lead to overfitting when there are not enough training examples. To address this issue, we propose a novel fine-tuning approach based on contrastive learning that incorporates unlabeled examples from the base domain as distractors. Unlike prior works, these distractors belong to classes that are different from the novel categories. We demonstrate that including distractors can significantly improve few-shot generalization. Our approach involves stochastic pairing of examples with the same category in the few-shot task and a weighting term that determines the influence of task-specific negatives and distractors. Importantly, our fine-tuning objective is independent of distractor labels and can be applied to different base domain settings. Compared to state-of-the-art methods, our approach achieves accuracy gains of up to 12% in cross-domain scenarios and up to 5% in unsupervised prior-learning settings. Our code is available at [GitHub URL].