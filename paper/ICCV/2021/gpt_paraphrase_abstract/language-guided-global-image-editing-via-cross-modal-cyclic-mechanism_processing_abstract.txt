This paper focuses on language-guided global image editing and addresses the issue of imbalanced and insufficient data distribution in existing works. To overcome this problem, the authors propose a cycle with an image generator and introduce a new model called Editing Description Network (EDNet) that predicts an editing embedding based on a pair of images. To enhance the model's understanding of various editing requests, several free augmentation strategies are proposed. Additionally, two novel ideas are presented: an Image-Request Attention (IRA) module that allows spatial-adaptive image editing and a new evaluation metric that is more semantic and reasonable than conventional pixel losses. Extensive experiments on benchmark datasets validate the effectiveness of the proposed method compared to existing approaches.