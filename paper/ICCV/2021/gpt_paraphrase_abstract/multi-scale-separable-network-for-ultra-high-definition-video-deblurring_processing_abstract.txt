Recent research has made significant progress in video deblurring. However, existing methods struggle to balance inference efficiency and visual quality, particularly for ultra-high-definition (UHD) videos such as 4K resolution. To address this issue, we propose a new deep learning model called UHDVideo Deblurring (UHDVD). UHDVD utilizes a separable-patch architecture combined with a multi-scale integration scheme to achieve a large receptive field without increasing the number of convolutional layers and kernels. We also introduce a residual channel-spatial attention (RCSA) module to enhance accuracy and reduce network depth. UHDVD is the first real-time deblurring model for 4K videos at 35 frames per second (fps). We train the model using a new dataset consisting of 4K blurry videos and corresponding sharp frames captured by three different smartphones. Through comprehensive experiments, we demonstrate that our network outperforms state-of-the-art methods in terms of accuracy, speed, and model size, both on the 4K dataset and public benchmarks.