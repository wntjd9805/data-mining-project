Adversarial learning has become a popular heuristic for addressing the domain shift problem in unsupervised domain adaptation tasks. However, existing methods still face the issue of equilibrium in adversarial learning, where the discriminator may be confused but the similarity between distributions cannot be guaranteed. To address this problem, we propose a novel approach called feature gradient distribution alignment (FGDA). Our method reduces the distribution discrepancy by constraining the feature gradients of two domains to have similar distributions. We provide both theoretical and empirical evidence to support the effectiveness of our method. Additionally, our approach offers a theoretical guarantee of obtaining a tighter error upper bound for target samples compared to conventional adversarial domain adaptation methods. By incorporating FGDA into existing models, we achieve state-of-the-art performance on two benchmark datasets. We illustrate the concept of FGDA through a figure, showing how it enlarges the overlapping region between domains and reduces the domain shift. We also highlight the limitations of conventional methods, which fail to further reduce the domain shift even when the mean features are close, and explain how FGDA can overcome this limitation by considering feature gradient discrepancy.