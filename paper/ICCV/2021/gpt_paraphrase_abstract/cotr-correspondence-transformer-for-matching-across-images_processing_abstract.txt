We present a new approach to finding correspondences in images using a deep neural network. Our framework allows for querying specific points of interest or all points in an image, resulting in sparse or dense mappings, respectively. To capture both local and global information, we utilize a transformer model that relates image regions using relevant priors. During inference, we recursively zoom in around the estimates, creating a multiscale pipeline that produces highly accurate correspondences. Our method outperforms existing techniques on sparse and dense correspondence problems across various datasets and tasks, such as wide-baseline stereo and optical flow. We are committed to providing the necessary data, code, and tools for reproducibility and training from scratch.