The problem of unbalanced and long-tailed real-world data poses challenges for deep learning models, as they struggle to recognize rare classes amidst frequent classes. Existing studies have focused on balancing the data, loss, or classifier to reduce classification bias towards the dominant classes, but have overlooked the impact on the learned latent representations. This study highlights that the feature extractor component of deep networks is significantly affected by this bias. To address this issue, a novel loss function inspired by robustness theory is proposed, aiming to encourage the model to learn high-quality representations for both dominant and rare classes. While the computation of the robustness loss may be complex, an alternative easy-to-compute upper bound is derived, enabling efficient minimization. By applying this method, representation bias towards dominant classes is reduced in the feature space, leading to state-of-the-art results on various benchmark datasets. Notably, the proposed approach improves the recognition accuracy of rare classes while maintaining the accuracy of dominant classes. Moreover, the robustness loss can be combined with different classifier balancing techniques and can be applied to representations at multiple layers of the deep model.