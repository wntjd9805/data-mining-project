We introduce a deep learning pipeline that utilizes network self-prior to reconstruct a complete 3D model, including a triangular mesh and a texture map, from a colored 3D point cloud. Unlike previous approaches that rely on either 2D self-prior for image editing or 3D self-prior for surface reconstruction, we propose a novel hybrid 2D-3D self-prior in deep neural networks to greatly enhance the quality of the geometry and generate a high-resolution texture map. This is particularly important as commodity-level 3D scanners often lack a detailed texture map in their output. Our method involves generating an initial mesh using a 3D convolutional neural network with 3D self-prior, and then encoding both 3D and color information in a 2D UV atlas, which is further refined by 2D convolutional neural networks with self-prior. By incorporating both 2D and 3D self-priors, we are able to recover the mesh and texture with high quality, without the need for additional training data. Experimental results demonstrate that our approach outperforms state-of-the-art methods in terms of both geometry and texture quality for 3D textured mesh model recovery from sparse input.