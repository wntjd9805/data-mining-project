Previous research on physical adversarial attacks has focused primarily on the effectiveness of the attacks, without considering the appearance of the generated adversarial patches. As a result, these patches often contain noticeable and attention-grabbing patterns that can easily be detected by humans. In order to address this issue, we propose a new method for creating physical adversarial patches for object detectors. This method utilizes the learned image manifold of a pretrained generative adversarial network (GAN) such as BigGAN or StyleGAN, which has been trained on real-world images. By sampling the most optimal image from the GAN, our method is able to generate adversarial patches that look natural while still maintaining a high level of attack performance. We conducted extensive experiments in both digital and physical domains, as well as multiple subjective surveys, to evaluate the effectiveness of our proposed method. The results demonstrate that our method produces significantly more realistic and natural looking patches compared to several state-of-the-art baselines, while still achieving competitive attack performance.