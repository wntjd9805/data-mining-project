This study presents a new approach to improve monocular 3D object detection in autonomous driving by incorporating shape-aware constraints into the detection framework. Unlike existing methods that only model objects as rotated 3D cuboids, this approach considers the geometric shape of the objects. A deep neural network is used to learn 2D keypoints in the image domain and regress their corresponding 3D coordinates in the object's local 3D coordinate system. Geometric constraints between the 2D and 3D keypoints are then built to enhance the detection performance for each object. To generate the ground truth of the keypoints, an automatic model-fitting approach is proposed, which fits a deformed 3D object model and the object mask in the 2D image. The proposed framework is evaluated on the KITTI dataset and the results show significant improvements in detection performance compared to the baseline method. Furthermore, the proposed framework achieves state-of-the-art performance in real time. The data and code for this study are available at https://github.com/zongdai/AutoShape.