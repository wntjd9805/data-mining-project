We propose a new self-supervised method for 3D hand pose estimation using contrastive learning. Contrastive learning, which has been successful in image classification tasks, aims to learn invariant feature representations by utilizing unlabeled data. In the case of 3D hand pose estimation, it is important to have invariance to appearance transformations such as color jitter, but also equivariance under affine transformations like rotation and translation. To address this, we introduce an equivariant contrastive objective and demonstrate its effectiveness in improving 3D hand pose estimation. Through experiments, we analyze the impact of invariant and equivariant contrastive objectives and find that learning equivariant features results in better representations for this task. Additionally, we show that standard ResNets with sufficient depth, trained on unlabeled data, achieve state-of-the-art performance without the need for specialized architectures. Our code and models are available at the following link: https://ait.ethz.ch/projects/2021/PeCLR/.