This paper introduces a simple knowledge structure to enhance the transfer of knowledge from teacher to student in semantic vision tasks. The structure utilizes a graph representation to encode information within the detection system, addressing the feature imbalance problem and uncovering missing relations between semantic instances. The graph is refined through adaptive background loss weight and background samples mining techniques. The entire graph is then transferred as knowledge representation from teacher to student, capturing both local and global information. The proposed method achieves state-of-the-art results on the challenging COCO object detection task using various student-teacher pairs of detectors. Furthermore, the method is also tested on instance segmentation, demonstrating its robustness. Notably, the distilled Faster R-CNN models with ResNet18-FPN, ResNet50-FPN, and ResNet101-FPN achieve high Box AP scores of 38.68, 41.82, and 43.38 respectively on the COCO benchmark. The code for the method is available on GitHub at https://github.com/dvlab-research/Dsig.