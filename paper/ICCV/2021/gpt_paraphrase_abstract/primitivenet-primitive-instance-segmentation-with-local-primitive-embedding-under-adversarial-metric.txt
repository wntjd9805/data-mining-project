We introduce PrimitiveNet, a new technique for accurately segmenting primitive instances from large-scale point clouds. Our approach involves transforming the global segmentation problem into smaller, localized tasks. We train a high-resolution primitive embedding network to predict explicit geometry features and implicit latent features for each point. Additionally, we utilize an adversarial network as a primitive discriminator to determine if points belong to the same primitive instance within local neighborhoods. This local supervision encourages the embedding network and discriminator to effectively describe local surface properties and accurately differentiate between different instances. During inference, the network's predictions are refined using a region growing method to achieve final segmentation results. Experimental results demonstrate that our method surpasses existing state-of-the-art techniques, achieving a significant improvement of 46.3% in mean average precision on the ABC dataset. Furthermore, our method is capable of processing extremely large real scenes spanning over 0.1km2. Ablation studies further validate the effectiveness of our core designs. Finally, our method has the potential to enhance geometry processing algorithms by abstracting scans into lightweight models. The code and data for our method will be made available in PyTorch and Mindspore frameworks.