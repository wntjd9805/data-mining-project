This paper introduces MINE, a method for generating new views and estimating depth from a single image through dense 3D reconstruction. MINE builds upon the concept of Multiplane Images (MPI) and incorporates NEural radiance fields (NeRF) to achieve continuous depth generalization. By taking a single image as input, MINE predicts a 4-channel image (RGB and volume density) at various depth levels, allowing for the reconstruction of the camera frustum and filling in of occluded areas. The reconstructed and inpainted frustum can then be easily rendered to produce novel RGB or depth views using differentiable rendering. The performance of MINE is evaluated on RealEstate10K, KITTI, and Flowers Light Fields datasets, demonstrating significantly better results compared to existing methods in novel view synthesis. Additionally, MINE achieves competitive outcomes in depth estimation on iBims-1 and NYU-v2 datasets without the need for annotated depth supervision. The source code for MINE is publicly available at https://github.com/vincentfung13/MINE.