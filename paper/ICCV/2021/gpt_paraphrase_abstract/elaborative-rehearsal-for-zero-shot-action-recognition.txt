The increasing number of action classes presents a challenge for video understanding, leading to the emergence of Zero-Shot Action Recognition (ZSAR) as a promising field. ZSAR aims to recognize unseen actions without training examples by utilizing semantic representations to connect known and unknown actions. However, effectively representing action classes and transferring knowledge from known data remains difficult due to the complexity and diversity of actions. To address this, we propose an enhanced ZSAR model inspired by the Elaborative Rehearsal (ER) technique, a memory technique that involves relating new concepts to existing ones. Our approach involves expanding each action class into an Elaborative Description (ED) sentence, which is more informative than a class name and less resource-intensive than manually-defined attributes. Additionally, we incorporate objects from the videos as Elaborative Concepts (EC) to enhance video semantics and improve generalization from known to unknown actions. Our ER-enhanced ZSAR model achieves state-of-the-art performance on three benchmark datasets. Furthermore, we introduce a new evaluation protocol on the Kinetics dataset to address limitations of current benchmarks and compare our model with few-shot learning baselines in a more realistic setting. We have made our codes and collected Elaborative Descriptions available at https://github.com/DeLightCMU/ElaborativeRehearsal.