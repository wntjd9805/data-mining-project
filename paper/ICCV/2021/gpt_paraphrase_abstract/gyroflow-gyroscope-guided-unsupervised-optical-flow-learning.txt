Current optical flow methods struggle in challenging scenarios such as fog, rain, and night due to violations of fundamental optical flow assumptions like brightness and gradient constancy. In order to tackle this issue, we introduce an unsupervised learning approach that incorporates gyroscope data into optical flow learning. This involves converting gyroscope readings into motion fields, which are then combined with optical flow using a self-guided fusion module. This fusion process helps extract background motion from the gyroscope data and guides the network to focus on capturing motion details. To the best of our knowledge, this is the first deep learning-based framework that integrates gyroscope data and image content for optical flow learning. To evaluate our approach, we introduce a new dataset that encompasses both typical and challenging scenes. Experimental results demonstrate that our method surpasses state-of-the-art techniques in both regular and challenging scenarios. The code and dataset for our approach can be accessed at https://github.com/megvii-research/GyroFlow.