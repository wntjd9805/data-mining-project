We propose a new method to extract human pose features from videos of human actions. The aim is to isolate the poses of the actions while disregarding other factors such as backgrounds, subjects' physical characteristics, and viewpoints. These pose features enable the comparison of pose similarity and can be used for tasks like aligning human action videos and retrieving specific poses. Our approach involves normalizing the poses by mapping them onto a predefined 3D skeleton, which separates physical features and aligns global orientations. The normalized poses are then transformed into a high-level feature space using unsupervised metric learning. We assess the effectiveness of our normalized features through visualizations and by performing a video alignment task on the Human3.6M dataset and an action recognition task on the Penn Action dataset.