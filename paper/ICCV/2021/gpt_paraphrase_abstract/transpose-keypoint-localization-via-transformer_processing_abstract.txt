We propose a model called Trans-clear.Pose that uses a Transformer for human pose estimation. This model captures long-range relationships efficiently and reveals the dependencies of predicted keypoints. The last attention layer acts as an aggregator to form maximum positions of keypoints. This heatmap-based localization approach via Transformer follows the principle of Activation Maximization. The revealed dependencies are image-specific and fine-grained, providing evidence of how the model handles special cases like occlusion. Experimental results show that TransPose achieves high accuracy on COCO and MPII benchmarks while being lightweight and faster than mainstream CNN architectures. The TransPose model can be easily accessed through publicly available code and pre-trained models.