ODAM is a system designed for localizing objects and estimating their 3D extent in order to enhance the understanding of 3D scenes, particularly in the fields of Augmented Reality and Robotics. It utilizes posed RGB videos to perform 3D Object Detection, Association, and Mapping. The system employs a deep learning front-end to detect 3D objects in an RGB frame and then associates them with a global object-based map using a graph neural network (GNN). To optimize the representation of object bounding volumes, which are represented as super-quadrics, the back-end of the system takes into account multi-view geometry constraints and the object scale prior. The proposed system is evaluated on ScanNet and demonstrates a significant improvement compared to existing methods that solely rely on RGB information.