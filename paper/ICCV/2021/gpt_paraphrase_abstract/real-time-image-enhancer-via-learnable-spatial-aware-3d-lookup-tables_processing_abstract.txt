Recently, deep learning algorithms for enhancing images have achieved state-of-the-art performance on publicly available datasets. However, these methods often fail to meet practical requirements in terms of visual perception and computational efficiency, particularly for high-resolution images. In this study, we propose a new real-time image enhancer using learnable spatial-aware 3-dimensional lookup tables (3D LUTs) that consider both global and local spatial information. Our approach involves a lightweight two-head weight predictor with two outputs. The first output is a 1-dimensional weight vector used for adapting to image-level scenarios, while the second output is a 3-dimensional weight map for pixel-wise category fusion. We train the spatial-aware 3D LUTs and combine them based on the aforementioned weights in an end-to-end manner. The fused LUT is then used to efficiently transform the source image into the desired tone. Extensive results demonstrate that our model surpasses state-of-the-art image enhancement methods in terms of subjective and objective evaluations on public datasets. Furthermore, our model can process a 4K resolution image in just 4ms on one NVIDIA V100 GPU.